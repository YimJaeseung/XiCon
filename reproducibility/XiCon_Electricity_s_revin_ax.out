Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3897
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6098225
	speed: 0.0150s/iter; left time: 356.7371s
	iters: 200, epoch: 1 | loss: 0.5742673
	speed: 0.0099s/iter; left time: 235.3241s
Epoch: 1 cost time: 2.878549575805664
Epoch: 1, Steps: 239 Train Loss: 0.6515 (Forecasting Loss:0.6226 + XiCon Loss:2.8886 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.4445
Validation loss decreased (inf --> 0.327659).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3272142
	speed: 0.0129s/iter; left time: 304.5915s
	iters: 200, epoch: 2 | loss: 0.2982206
	speed: 0.0106s/iter; left time: 248.8282s
Epoch: 2 cost time: 2.7477834224700928
Epoch: 2, Steps: 239 Train Loss: 0.3410 (Forecasting Loss:0.3123 + XiCon Loss:2.8739 x Lambda(0.01)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.2790
Validation loss decreased (0.327659 --> 0.205994).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2962680
	speed: 0.0124s/iter; left time: 289.9633s
	iters: 200, epoch: 3 | loss: 0.3126878
	speed: 0.0108s/iter; left time: 250.2339s
Epoch: 3 cost time: 2.7720227241516113
Epoch: 3, Steps: 239 Train Loss: 0.3011 (Forecasting Loss:0.2725 + XiCon Loss:2.8597 x Lambda(0.01)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.2691
Validation loss decreased (0.205994 --> 0.197324).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2747529
	speed: 0.0125s/iter; left time: 287.8580s
	iters: 200, epoch: 4 | loss: 0.2761624
	speed: 0.0100s/iter; left time: 230.9881s
Epoch: 4 cost time: 2.6799802780151367
Epoch: 4, Steps: 239 Train Loss: 0.2946 (Forecasting Loss:0.2661 + XiCon Loss:2.8547 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2660
Validation loss decreased (0.197324 --> 0.195245).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3151367
	speed: 0.0127s/iter; left time: 290.8785s
	iters: 200, epoch: 5 | loss: 0.2843025
	speed: 0.0099s/iter; left time: 226.1595s
Epoch: 5 cost time: 2.650895595550537
Epoch: 5, Steps: 239 Train Loss: 0.2915 (Forecasting Loss:0.2630 + XiCon Loss:2.8494 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2657
Validation loss decreased (0.195245 --> 0.193771).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2827827
	speed: 0.0130s/iter; left time: 293.4988s
	iters: 200, epoch: 6 | loss: 0.2828593
	speed: 0.0107s/iter; left time: 240.7344s
Epoch: 6 cost time: 2.7850029468536377
Epoch: 6, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2617 + XiCon Loss:2.8511 x Lambda(0.01)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2639
Validation loss decreased (0.193771 --> 0.193119).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2987959
	speed: 0.0132s/iter; left time: 295.4206s
	iters: 200, epoch: 7 | loss: 0.2982826
	speed: 0.0102s/iter; left time: 226.6616s
Epoch: 7 cost time: 2.7844276428222656
Epoch: 7, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2606 + XiCon Loss:2.8496 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2636
Validation loss decreased (0.193119 --> 0.192619).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2448646
	speed: 0.0132s/iter; left time: 292.6765s
	iters: 200, epoch: 8 | loss: 0.2872455
	speed: 0.0110s/iter; left time: 242.0828s
Epoch: 8 cost time: 2.874242067337036
Epoch: 8, Steps: 239 Train Loss: 0.2887 (Forecasting Loss:0.2602 + XiCon Loss:2.8491 x Lambda(0.01)), Vali MSE Loss: 0.1927 Test MSE Loss: 0.2633
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2546223
	speed: 0.0120s/iter; left time: 262.6339s
	iters: 200, epoch: 9 | loss: 0.3186100
	speed: 0.0103s/iter; left time: 225.0084s
Epoch: 9 cost time: 2.6527976989746094
Epoch: 9, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2604 + XiCon Loss:2.8487 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2633
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2728238
	speed: 0.0127s/iter; left time: 275.9563s
	iters: 200, epoch: 10 | loss: 0.3053477
	speed: 0.0104s/iter; left time: 223.5262s
Epoch: 10 cost time: 2.763241767883301
Epoch: 10, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2597 + XiCon Loss:2.8494 x Lambda(0.01)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2806610
	speed: 0.0118s/iter; left time: 253.2894s
	iters: 200, epoch: 11 | loss: 0.2770734
	speed: 0.0093s/iter; left time: 199.0785s
Epoch: 11 cost time: 2.5332796573638916
Epoch: 11, Steps: 239 Train Loss: 0.2884 (Forecasting Loss:0.2599 + XiCon Loss:2.8488 x Lambda(0.01)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.2632
Validation loss decreased (0.192619 --> 0.192203).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3154299
	speed: 0.0128s/iter; left time: 270.8029s
	iters: 200, epoch: 12 | loss: 0.2738103
	speed: 0.0098s/iter; left time: 205.8821s
Epoch: 12 cost time: 2.68813419342041
Epoch: 12, Steps: 239 Train Loss: 0.2886 (Forecasting Loss:0.2601 + XiCon Loss:2.8488 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2769778
	speed: 0.0126s/iter; left time: 264.1925s
	iters: 200, epoch: 13 | loss: 0.2883585
	speed: 0.0103s/iter; left time: 215.0621s
Epoch: 13 cost time: 2.7152249813079834
Epoch: 13, Steps: 239 Train Loss: 0.2884 (Forecasting Loss:0.2600 + XiCon Loss:2.8486 x Lambda(0.01)), Vali MSE Loss: 0.1927 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2939635
	speed: 0.0120s/iter; left time: 248.0050s
	iters: 200, epoch: 14 | loss: 0.2792827
	speed: 0.0104s/iter; left time: 213.3241s
Epoch: 14 cost time: 2.70452618598938
Epoch: 14, Steps: 239 Train Loss: 0.2886 (Forecasting Loss:0.2601 + XiCon Loss:2.8505 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3180636
	speed: 0.0118s/iter; left time: 241.8369s
	iters: 200, epoch: 15 | loss: 0.2339393
	speed: 0.0105s/iter; left time: 214.2159s
Epoch: 15 cost time: 2.6471147537231445
Epoch: 15, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2603 + XiCon Loss:2.8481 x Lambda(0.01)), Vali MSE Loss: 0.1927 Test MSE Loss: 0.2632
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3001068
	speed: 0.0127s/iter; left time: 257.5648s
	iters: 200, epoch: 16 | loss: 0.2722182
	speed: 0.0119s/iter; left time: 239.7004s
Epoch: 16 cost time: 2.910912036895752
Epoch: 16, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2597 + XiCon Loss:2.8499 x Lambda(0.01)), Vali MSE Loss: 0.1924 Test MSE Loss: 0.2632
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2639212
	speed: 0.0122s/iter; left time: 244.1318s
	iters: 200, epoch: 17 | loss: 0.2789041
	speed: 0.0100s/iter; left time: 199.1558s
Epoch: 17 cost time: 2.629228115081787
Epoch: 17, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2597 + XiCon Loss:2.8495 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2804483
	speed: 0.0125s/iter; left time: 246.1015s
	iters: 200, epoch: 18 | loss: 0.2950668
	speed: 0.0109s/iter; left time: 214.0999s
Epoch: 18 cost time: 2.726876735687256
Epoch: 18, Steps: 239 Train Loss: 0.2883 (Forecasting Loss:0.2599 + XiCon Loss:2.8474 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3063338
	speed: 0.0121s/iter; left time: 236.8762s
	iters: 200, epoch: 19 | loss: 0.3283336
	speed: 0.0109s/iter; left time: 211.2861s
Epoch: 19 cost time: 2.736644744873047
Epoch: 19, Steps: 239 Train Loss: 0.2883 (Forecasting Loss:0.2598 + XiCon Loss:2.8509 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3007602
	speed: 0.0122s/iter; left time: 234.9570s
	iters: 200, epoch: 20 | loss: 0.3063922
	speed: 0.0099s/iter; left time: 190.3828s
Epoch: 20 cost time: 2.6319046020507812
Epoch: 20, Steps: 239 Train Loss: 0.2884 (Forecasting Loss:0.2599 + XiCon Loss:2.8493 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2974346
	speed: 0.0130s/iter; left time: 247.3489s
	iters: 200, epoch: 21 | loss: 0.2732798
	speed: 0.0107s/iter; left time: 202.4680s
Epoch: 21 cost time: 2.8123247623443604
Epoch: 21, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2597 + XiCon Loss:2.8476 x Lambda(0.01)), Vali MSE Loss: 0.1924 Test MSE Loss: 0.2632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20617954432964325, mae:0.3202575743198395, mape:2.3342702388763428, mspe:3209.58544921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5739
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6287858
	speed: 0.0121s/iter; left time: 288.3452s
	iters: 200, epoch: 1 | loss: 0.4893091
	speed: 0.0107s/iter; left time: 254.3846s
Epoch: 1 cost time: 2.729937791824341
Epoch: 1, Steps: 239 Train Loss: 0.6412 (Forecasting Loss:0.6124 + XiCon Loss:2.8801 x Lambda(0.01)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.4345
Validation loss decreased (inf --> 0.322189).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3478490
	speed: 0.0137s/iter; left time: 322.1474s
	iters: 200, epoch: 2 | loss: 0.2857315
	speed: 0.0104s/iter; left time: 243.6143s
Epoch: 2 cost time: 2.8211722373962402
Epoch: 2, Steps: 239 Train Loss: 0.3409 (Forecasting Loss:0.3121 + XiCon Loss:2.8791 x Lambda(0.01)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.2778
Validation loss decreased (0.322189 --> 0.202110).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2914893
	speed: 0.0131s/iter; left time: 306.0349s
	iters: 200, epoch: 3 | loss: 0.2717554
	speed: 0.0109s/iter; left time: 252.7686s
Epoch: 3 cost time: 2.8256611824035645
Epoch: 3, Steps: 239 Train Loss: 0.3017 (Forecasting Loss:0.2729 + XiCon Loss:2.8851 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2716
Validation loss decreased (0.202110 --> 0.194488).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2308824
	speed: 0.0127s/iter; left time: 293.2087s
	iters: 200, epoch: 4 | loss: 0.2871639
	speed: 0.0104s/iter; left time: 238.5443s
Epoch: 4 cost time: 2.7429537773132324
Epoch: 4, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2660 + XiCon Loss:2.8854 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2652
Validation loss decreased (0.194488 --> 0.191348).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2868483
	speed: 0.0125s/iter; left time: 286.0394s
	iters: 200, epoch: 5 | loss: 0.2971396
	speed: 0.0096s/iter; left time: 217.9772s
Epoch: 5 cost time: 2.6095943450927734
Epoch: 5, Steps: 239 Train Loss: 0.2913 (Forecasting Loss:0.2624 + XiCon Loss:2.8872 x Lambda(0.01)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.2641
Validation loss decreased (0.191348 --> 0.189933).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2812075
	speed: 0.0125s/iter; left time: 283.0947s
	iters: 200, epoch: 6 | loss: 0.3114686
	speed: 0.0098s/iter; left time: 221.3739s
Epoch: 6 cost time: 2.6438426971435547
Epoch: 6, Steps: 239 Train Loss: 0.2896 (Forecasting Loss:0.2608 + XiCon Loss:2.8829 x Lambda(0.01)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.2631
Validation loss decreased (0.189933 --> 0.188759).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2752523
	speed: 0.0120s/iter; left time: 267.6012s
	iters: 200, epoch: 7 | loss: 0.2696371
	speed: 0.0104s/iter; left time: 231.6278s
Epoch: 7 cost time: 2.719433307647705
Epoch: 7, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2603 + XiCon Loss:2.8844 x Lambda(0.01)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.2627
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2720427
	speed: 0.0123s/iter; left time: 271.5820s
	iters: 200, epoch: 8 | loss: 0.3421837
	speed: 0.0105s/iter; left time: 230.2921s
Epoch: 8 cost time: 2.710365056991577
Epoch: 8, Steps: 239 Train Loss: 0.2886 (Forecasting Loss:0.2598 + XiCon Loss:2.8846 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2626
Validation loss decreased (0.188759 --> 0.188142).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3012404
	speed: 0.0122s/iter; left time: 267.4141s
	iters: 200, epoch: 9 | loss: 0.3014662
	speed: 0.0107s/iter; left time: 233.3319s
Epoch: 9 cost time: 2.755417585372925
Epoch: 9, Steps: 239 Train Loss: 0.2880 (Forecasting Loss:0.2591 + XiCon Loss:2.8851 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2813053
	speed: 0.0121s/iter; left time: 262.3979s
	iters: 200, epoch: 10 | loss: 0.3122763
	speed: 0.0096s/iter; left time: 207.8514s
Epoch: 10 cost time: 2.5964980125427246
Epoch: 10, Steps: 239 Train Loss: 0.2881 (Forecasting Loss:0.2593 + XiCon Loss:2.8825 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2623
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2832871
	speed: 0.0125s/iter; left time: 267.1400s
	iters: 200, epoch: 11 | loss: 0.2948434
	speed: 0.0106s/iter; left time: 225.5008s
Epoch: 11 cost time: 2.7428483963012695
Epoch: 11, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2594 + XiCon Loss:2.8816 x Lambda(0.01)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.2623
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3037856
	speed: 0.0121s/iter; left time: 255.1323s
	iters: 200, epoch: 12 | loss: 0.2927826
	speed: 0.0099s/iter; left time: 209.2266s
Epoch: 12 cost time: 2.6132264137268066
Epoch: 12, Steps: 239 Train Loss: 0.2878 (Forecasting Loss:0.2589 + XiCon Loss:2.8823 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2622
Validation loss decreased (0.188142 --> 0.188073).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2960653
	speed: 0.0124s/iter; left time: 258.9933s
	iters: 200, epoch: 13 | loss: 0.3029006
	speed: 0.0106s/iter; left time: 220.5982s
Epoch: 13 cost time: 2.7336459159851074
Epoch: 13, Steps: 239 Train Loss: 0.2879 (Forecasting Loss:0.2590 + XiCon Loss:2.8846 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2622
Validation loss decreased (0.188073 --> 0.188010).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2847969
	speed: 0.0120s/iter; left time: 249.2554s
	iters: 200, epoch: 14 | loss: 0.2863041
	speed: 0.0105s/iter; left time: 216.5365s
Epoch: 14 cost time: 2.685793876647949
Epoch: 14, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2593 + XiCon Loss:2.8843 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2622
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3163745
	speed: 0.0126s/iter; left time: 258.0210s
	iters: 200, epoch: 15 | loss: 0.2727250
	speed: 0.0110s/iter; left time: 224.0402s
Epoch: 15 cost time: 2.8048572540283203
Epoch: 15, Steps: 239 Train Loss: 0.2876 (Forecasting Loss:0.2588 + XiCon Loss:2.8829 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2622
Validation loss decreased (0.188010 --> 0.187914).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2850321
	speed: 0.0127s/iter; left time: 257.3468s
	iters: 200, epoch: 16 | loss: 0.2925106
	speed: 0.0102s/iter; left time: 204.9609s
Epoch: 16 cost time: 2.6606791019439697
Epoch: 16, Steps: 239 Train Loss: 0.2878 (Forecasting Loss:0.2590 + XiCon Loss:2.8857 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2622
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2619636
	speed: 0.0133s/iter; left time: 266.3868s
	iters: 200, epoch: 17 | loss: 0.2947865
	speed: 0.0100s/iter; left time: 199.1514s
Epoch: 17 cost time: 2.7594048976898193
Epoch: 17, Steps: 239 Train Loss: 0.2883 (Forecasting Loss:0.2595 + XiCon Loss:2.8851 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2622
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2991942
	speed: 0.0128s/iter; left time: 251.9016s
	iters: 200, epoch: 18 | loss: 0.3013907
	speed: 0.0107s/iter; left time: 209.4425s
Epoch: 18 cost time: 2.7648119926452637
Epoch: 18, Steps: 239 Train Loss: 0.2881 (Forecasting Loss:0.2593 + XiCon Loss:2.8848 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2622
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3305168
	speed: 0.0119s/iter; left time: 232.8818s
	iters: 200, epoch: 19 | loss: 0.3077914
	speed: 0.0097s/iter; left time: 189.0149s
Epoch: 19 cost time: 2.5725622177124023
Epoch: 19, Steps: 239 Train Loss: 0.2885 (Forecasting Loss:0.2596 + XiCon Loss:2.8844 x Lambda(0.01)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.2622
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.2757960
	speed: 0.0132s/iter; left time: 255.0767s
	iters: 200, epoch: 20 | loss: 0.2699848
	speed: 0.0104s/iter; left time: 198.8384s
Epoch: 20 cost time: 2.7695889472961426
Epoch: 20, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2594 + XiCon Loss:2.8832 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2622
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.3207438
	speed: 0.0123s/iter; left time: 234.6314s
	iters: 200, epoch: 21 | loss: 0.3214836
	speed: 0.0104s/iter; left time: 195.9737s
Epoch: 21 cost time: 2.7234079837799072
Epoch: 21, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2594 + XiCon Loss:2.8862 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2622
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2660367
	speed: 0.0120s/iter; left time: 226.1009s
	iters: 200, epoch: 22 | loss: 0.2628360
	speed: 0.0100s/iter; left time: 187.3206s
Epoch: 22 cost time: 2.6272263526916504
Epoch: 22, Steps: 239 Train Loss: 0.2879 (Forecasting Loss:0.2591 + XiCon Loss:2.8837 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2622
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2779077
	speed: 0.0123s/iter; left time: 228.7600s
	iters: 200, epoch: 23 | loss: 0.3102603
	speed: 0.0101s/iter; left time: 186.0540s
Epoch: 23 cost time: 2.6909587383270264
Epoch: 23, Steps: 239 Train Loss: 0.2880 (Forecasting Loss:0.2592 + XiCon Loss:2.8801 x Lambda(0.01)), Vali MSE Loss: 0.1885 Test MSE Loss: 0.2622
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2787009
	speed: 0.0124s/iter; left time: 226.3256s
	iters: 200, epoch: 24 | loss: 0.2704791
	speed: 0.0098s/iter; left time: 178.1575s
Epoch: 24 cost time: 2.5962538719177246
Epoch: 24, Steps: 239 Train Loss: 0.2882 (Forecasting Loss:0.2594 + XiCon Loss:2.8826 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2622
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.3119742
	speed: 0.0130s/iter; left time: 234.5457s
	iters: 200, epoch: 25 | loss: 0.2779633
	speed: 0.0101s/iter; left time: 180.8245s
Epoch: 25 cost time: 2.7459163665771484
Epoch: 25, Steps: 239 Train Loss: 0.2877 (Forecasting Loss:0.2589 + XiCon Loss:2.8848 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2622
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20380501449108124, mae:0.32069337368011475, mape:2.532810926437378, mspe:4464.48486328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4236
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6057305
	speed: 0.0124s/iter; left time: 295.7365s
	iters: 200, epoch: 1 | loss: 0.6380069
	speed: 0.0099s/iter; left time: 235.3638s
Epoch: 1 cost time: 2.6648919582366943
Epoch: 1, Steps: 239 Train Loss: 0.6730 (Forecasting Loss:0.6435 + XiCon Loss:2.9454 x Lambda(0.01)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.4547
Validation loss decreased (inf --> 0.331912).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3480059
	speed: 0.0124s/iter; left time: 293.0773s
	iters: 200, epoch: 2 | loss: 0.3289139
	speed: 0.0100s/iter; left time: 234.6304s
Epoch: 2 cost time: 2.6506643295288086
Epoch: 2, Steps: 239 Train Loss: 0.3454 (Forecasting Loss:0.3161 + XiCon Loss:2.9339 x Lambda(0.01)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.2813
Validation loss decreased (0.331912 --> 0.205691).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3187793
	speed: 0.0132s/iter; left time: 308.8006s
	iters: 200, epoch: 3 | loss: 0.3363066
	speed: 0.0106s/iter; left time: 245.9573s
Epoch: 3 cost time: 2.8253941535949707
Epoch: 3, Steps: 239 Train Loss: 0.3080 (Forecasting Loss:0.2789 + XiCon Loss:2.9145 x Lambda(0.01)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.2748
Validation loss decreased (0.205691 --> 0.200439).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3225999
	speed: 0.0125s/iter; left time: 287.8948s
	iters: 200, epoch: 4 | loss: 0.3110791
	speed: 0.0101s/iter; left time: 231.6650s
Epoch: 4 cost time: 2.7227649688720703
Epoch: 4, Steps: 239 Train Loss: 0.3018 (Forecasting Loss:0.2727 + XiCon Loss:2.9086 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2722
Validation loss decreased (0.200439 --> 0.197897).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3000588
	speed: 0.0122s/iter; left time: 279.0076s
	iters: 200, epoch: 5 | loss: 0.3156222
	speed: 0.0103s/iter; left time: 234.8338s
Epoch: 5 cost time: 2.675154447555542
Epoch: 5, Steps: 239 Train Loss: 0.2987 (Forecasting Loss:0.2697 + XiCon Loss:2.8991 x Lambda(0.01)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.2689
Validation loss decreased (0.197897 --> 0.196213).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2977186
	speed: 0.0125s/iter; left time: 282.8169s
	iters: 200, epoch: 6 | loss: 0.2677559
	speed: 0.0101s/iter; left time: 226.2417s
Epoch: 6 cost time: 2.686075448989868
Epoch: 6, Steps: 239 Train Loss: 0.2969 (Forecasting Loss:0.2679 + XiCon Loss:2.8972 x Lambda(0.01)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.2683
Validation loss decreased (0.196213 --> 0.195408).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2794052
	speed: 0.0124s/iter; left time: 277.5974s
	iters: 200, epoch: 7 | loss: 0.3051851
	speed: 0.0100s/iter; left time: 221.8036s
Epoch: 7 cost time: 2.66024112701416
Epoch: 7, Steps: 239 Train Loss: 0.2964 (Forecasting Loss:0.2675 + XiCon Loss:2.8957 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2677
Validation loss decreased (0.195408 --> 0.195177).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2949880
	speed: 0.0125s/iter; left time: 277.3247s
	iters: 200, epoch: 8 | loss: 0.3223948
	speed: 0.0102s/iter; left time: 225.2889s
Epoch: 8 cost time: 2.706430435180664
Epoch: 8, Steps: 239 Train Loss: 0.2959 (Forecasting Loss:0.2669 + XiCon Loss:2.8956 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
Validation loss decreased (0.195177 --> 0.194576).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2471766
	speed: 0.0135s/iter; left time: 294.4913s
	iters: 200, epoch: 9 | loss: 0.2809041
	speed: 0.0107s/iter; left time: 232.8888s
Epoch: 9 cost time: 2.820282459259033
Epoch: 9, Steps: 239 Train Loss: 0.2955 (Forecasting Loss:0.2666 + XiCon Loss:2.8929 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
Validation loss decreased (0.194576 --> 0.194466).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2997533
	speed: 0.0120s/iter; left time: 260.0938s
	iters: 200, epoch: 10 | loss: 0.3186936
	speed: 0.0102s/iter; left time: 219.7463s
Epoch: 10 cost time: 2.627519369125366
Epoch: 10, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2663 + XiCon Loss:2.8970 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2500120
	speed: 0.0123s/iter; left time: 263.7201s
	iters: 200, epoch: 11 | loss: 0.3298123
	speed: 0.0101s/iter; left time: 214.3239s
Epoch: 11 cost time: 2.6389176845550537
Epoch: 11, Steps: 239 Train Loss: 0.2951 (Forecasting Loss:0.2662 + XiCon Loss:2.8954 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2673
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2726122
	speed: 0.0117s/iter; left time: 246.7449s
	iters: 200, epoch: 12 | loss: 0.2878546
	speed: 0.0100s/iter; left time: 210.4778s
Epoch: 12 cost time: 2.6119627952575684
Epoch: 12, Steps: 239 Train Loss: 0.2954 (Forecasting Loss:0.2664 + XiCon Loss:2.8956 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2522343
	speed: 0.0123s/iter; left time: 257.6407s
	iters: 200, epoch: 13 | loss: 0.3176474
	speed: 0.0107s/iter; left time: 223.5531s
Epoch: 13 cost time: 2.7401857376098633
Epoch: 13, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8918 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2963337
	speed: 0.0133s/iter; left time: 275.7325s
	iters: 200, epoch: 14 | loss: 0.3037435
	speed: 0.0100s/iter; left time: 205.0618s
Epoch: 14 cost time: 2.7513418197631836
Epoch: 14, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2661 + XiCon Loss:2.8942 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2853982
	speed: 0.0126s/iter; left time: 257.9630s
	iters: 200, epoch: 15 | loss: 0.3079074
	speed: 0.0100s/iter; left time: 203.3248s
Epoch: 15 cost time: 2.701993703842163
Epoch: 15, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8929 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2673
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3120002
	speed: 0.0128s/iter; left time: 258.8152s
	iters: 200, epoch: 16 | loss: 0.2678700
	speed: 0.0098s/iter; left time: 196.7665s
Epoch: 16 cost time: 2.66274094581604
Epoch: 16, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8942 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2673
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2882011
	speed: 0.0130s/iter; left time: 260.4835s
	iters: 200, epoch: 17 | loss: 0.2969973
	speed: 0.0101s/iter; left time: 200.4401s
Epoch: 17 cost time: 2.8044233322143555
Epoch: 17, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8928 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2673
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2987219
	speed: 0.0126s/iter; left time: 248.8102s
	iters: 200, epoch: 18 | loss: 0.3247553
	speed: 0.0104s/iter; left time: 204.0151s
Epoch: 18 cost time: 2.7161426544189453
Epoch: 18, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2660 + XiCon Loss:2.8926 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2673
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2827437
	speed: 0.0123s/iter; left time: 239.2003s
	iters: 200, epoch: 19 | loss: 0.2858638
	speed: 0.0099s/iter; left time: 192.8860s
Epoch: 19 cost time: 2.6631131172180176
Epoch: 19, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8995 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2673
Validation loss decreased (0.194466 --> 0.194449).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3080890
	speed: 0.0123s/iter; left time: 236.9904s
	iters: 200, epoch: 20 | loss: 0.2858354
	speed: 0.0099s/iter; left time: 190.2420s
Epoch: 20 cost time: 2.6509265899658203
Epoch: 20, Steps: 239 Train Loss: 0.2952 (Forecasting Loss:0.2663 + XiCon Loss:2.8930 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2722487
	speed: 0.0117s/iter; left time: 222.6482s
	iters: 200, epoch: 21 | loss: 0.3095015
	speed: 0.0099s/iter; left time: 188.0482s
Epoch: 21 cost time: 2.611258029937744
Epoch: 21, Steps: 239 Train Loss: 0.2954 (Forecasting Loss:0.2664 + XiCon Loss:2.8942 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3047709
	speed: 0.0125s/iter; left time: 235.5183s
	iters: 200, epoch: 22 | loss: 0.3073581
	speed: 0.0103s/iter; left time: 192.6223s
Epoch: 22 cost time: 2.6755707263946533
Epoch: 22, Steps: 239 Train Loss: 0.2954 (Forecasting Loss:0.2665 + XiCon Loss:2.8969 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2673
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2761601
	speed: 0.0130s/iter; left time: 241.2974s
	iters: 200, epoch: 23 | loss: 0.3043140
	speed: 0.0112s/iter; left time: 206.7408s
Epoch: 23 cost time: 2.8453993797302246
Epoch: 23, Steps: 239 Train Loss: 0.2952 (Forecasting Loss:0.2662 + XiCon Loss:2.8955 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2673
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2869407
	speed: 0.0135s/iter; left time: 246.6963s
	iters: 200, epoch: 24 | loss: 0.2949675
	speed: 0.0101s/iter; left time: 184.3274s
Epoch: 24 cost time: 2.758575201034546
Epoch: 24, Steps: 239 Train Loss: 0.2954 (Forecasting Loss:0.2663 + XiCon Loss:2.9013 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2673
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2945697
	speed: 0.0131s/iter; left time: 237.5446s
	iters: 200, epoch: 25 | loss: 0.3365199
	speed: 0.0108s/iter; left time: 194.2908s
Epoch: 25 cost time: 2.838020086288452
Epoch: 25, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2661 + XiCon Loss:2.8923 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2673
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.3085317
	speed: 0.0128s/iter; left time: 227.4299s
	iters: 200, epoch: 26 | loss: 0.2548255
	speed: 0.0107s/iter; left time: 189.2705s
Epoch: 26 cost time: 2.7979257106781006
Epoch: 26, Steps: 239 Train Loss: 0.2952 (Forecasting Loss:0.2663 + XiCon Loss:2.8917 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2673
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2988487
	speed: 0.0136s/iter; left time: 238.8529s
	iters: 200, epoch: 27 | loss: 0.2859449
	speed: 0.0107s/iter; left time: 186.2794s
Epoch: 27 cost time: 2.8530068397521973
Epoch: 27, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2664 + XiCon Loss:2.8912 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.3270171
	speed: 0.0122s/iter; left time: 212.3322s
	iters: 200, epoch: 28 | loss: 0.2783201
	speed: 0.0097s/iter; left time: 166.8616s
Epoch: 28 cost time: 2.634161949157715
Epoch: 28, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2660 + XiCon Loss:2.8952 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2673
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2514849
	speed: 0.0124s/iter; left time: 212.0798s
	iters: 200, epoch: 29 | loss: 0.2979752
	speed: 0.0104s/iter; left time: 176.2503s
Epoch: 29 cost time: 2.7133703231811523
Epoch: 29, Steps: 239 Train Loss: 0.2952 (Forecasting Loss:0.2662 + XiCon Loss:2.8961 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2673
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21010467410087585, mae:0.3245164453983307, mape:2.392991781234741, mspe:3041.589599609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4468
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6578760
	speed: 0.0124s/iter; left time: 294.1886s
	iters: 200, epoch: 1 | loss: 0.6006833
	speed: 0.0099s/iter; left time: 235.4128s
Epoch: 1 cost time: 2.6661856174468994
Epoch: 1, Steps: 239 Train Loss: 0.6462 (Forecasting Loss:0.6176 + XiCon Loss:2.8611 x Lambda(0.01)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.4338
Validation loss decreased (inf --> 0.318359).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3477640
	speed: 0.0121s/iter; left time: 284.2850s
	iters: 200, epoch: 2 | loss: 0.3195195
	speed: 0.0108s/iter; left time: 252.7216s
Epoch: 2 cost time: 2.7282397747039795
Epoch: 2, Steps: 239 Train Loss: 0.3424 (Forecasting Loss:0.3139 + XiCon Loss:2.8504 x Lambda(0.01)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.2828
Validation loss decreased (0.318359 --> 0.207287).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3077602
	speed: 0.0121s/iter; left time: 281.0938s
	iters: 200, epoch: 3 | loss: 0.3282432
	speed: 0.0100s/iter; left time: 232.9670s
Epoch: 3 cost time: 2.6609747409820557
Epoch: 3, Steps: 239 Train Loss: 0.3061 (Forecasting Loss:0.2776 + XiCon Loss:2.8441 x Lambda(0.01)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.2733
Validation loss decreased (0.207287 --> 0.201201).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2792330
	speed: 0.0133s/iter; left time: 306.9878s
	iters: 200, epoch: 4 | loss: 0.3527552
	speed: 0.0105s/iter; left time: 240.8532s
Epoch: 4 cost time: 2.826669931411743
Epoch: 4, Steps: 239 Train Loss: 0.2990 (Forecasting Loss:0.2706 + XiCon Loss:2.8406 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2679
Validation loss decreased (0.201201 --> 0.195236).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3019751
	speed: 0.0125s/iter; left time: 286.3026s
	iters: 200, epoch: 5 | loss: 0.2839733
	speed: 0.0103s/iter; left time: 234.1471s
Epoch: 5 cost time: 2.724313735961914
Epoch: 5, Steps: 239 Train Loss: 0.2955 (Forecasting Loss:0.2671 + XiCon Loss:2.8384 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2670
Validation loss decreased (0.195236 --> 0.194921).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3061424
	speed: 0.0131s/iter; left time: 296.6274s
	iters: 200, epoch: 6 | loss: 0.2946647
	speed: 0.0101s/iter; left time: 226.3600s
Epoch: 6 cost time: 2.7391021251678467
Epoch: 6, Steps: 239 Train Loss: 0.2938 (Forecasting Loss:0.2654 + XiCon Loss:2.8356 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2654
Validation loss decreased (0.194921 --> 0.194826).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2956125
	speed: 0.0128s/iter; left time: 285.3024s
	iters: 200, epoch: 7 | loss: 0.2561989
	speed: 0.0102s/iter; left time: 226.7999s
Epoch: 7 cost time: 2.7178306579589844
Epoch: 7, Steps: 239 Train Loss: 0.2931 (Forecasting Loss:0.2648 + XiCon Loss:2.8346 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2649
Validation loss decreased (0.194826 --> 0.193867).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2620255
	speed: 0.0125s/iter; left time: 277.2251s
	iters: 200, epoch: 8 | loss: 0.2807928
	speed: 0.0099s/iter; left time: 218.3747s
Epoch: 8 cost time: 2.665508985519409
Epoch: 8, Steps: 239 Train Loss: 0.2925 (Forecasting Loss:0.2641 + XiCon Loss:2.8391 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2648
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3005061
	speed: 0.0135s/iter; left time: 296.1123s
	iters: 200, epoch: 9 | loss: 0.2963287
	speed: 0.0102s/iter; left time: 223.2983s
Epoch: 9 cost time: 2.7947089672088623
Epoch: 9, Steps: 239 Train Loss: 0.2921 (Forecasting Loss:0.2637 + XiCon Loss:2.8352 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193867 --> 0.193741).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3078136
	speed: 0.0124s/iter; left time: 269.3342s
	iters: 200, epoch: 10 | loss: 0.3061688
	speed: 0.0101s/iter; left time: 217.3410s
Epoch: 10 cost time: 2.662315845489502
Epoch: 10, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2637 + XiCon Loss:2.8346 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3214690
	speed: 0.0134s/iter; left time: 287.0584s
	iters: 200, epoch: 11 | loss: 0.2999096
	speed: 0.0102s/iter; left time: 217.5098s
Epoch: 11 cost time: 2.7833051681518555
Epoch: 11, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2637 + XiCon Loss:2.8374 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193741 --> 0.193729).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3250248
	speed: 0.0118s/iter; left time: 249.2134s
	iters: 200, epoch: 12 | loss: 0.2622995
	speed: 0.0097s/iter; left time: 205.1835s
Epoch: 12 cost time: 2.5684359073638916
Epoch: 12, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2637 + XiCon Loss:2.8385 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193729 --> 0.193392).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2880580
	speed: 0.0128s/iter; left time: 268.3159s
	iters: 200, epoch: 13 | loss: 0.2744499
	speed: 0.0103s/iter; left time: 213.5621s
Epoch: 13 cost time: 2.756190776824951
Epoch: 13, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2633 + XiCon Loss:2.8344 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2706771
	speed: 0.0127s/iter; left time: 262.7795s
	iters: 200, epoch: 14 | loss: 0.3050688
	speed: 0.0108s/iter; left time: 222.0796s
Epoch: 14 cost time: 2.777479410171509
Epoch: 14, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2635 + XiCon Loss:2.8365 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2646
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2731061
	speed: 0.0121s/iter; left time: 248.3524s
	iters: 200, epoch: 15 | loss: 0.2836379
	speed: 0.0102s/iter; left time: 208.2702s
Epoch: 15 cost time: 2.6640305519104004
Epoch: 15, Steps: 239 Train Loss: 0.2921 (Forecasting Loss:0.2637 + XiCon Loss:2.8337 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2646
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2662822
	speed: 0.0126s/iter; left time: 255.1719s
	iters: 200, epoch: 16 | loss: 0.2960655
	speed: 0.0097s/iter; left time: 196.0637s
Epoch: 16 cost time: 2.6701138019561768
Epoch: 16, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2635 + XiCon Loss:2.8368 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2646
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2982706
	speed: 0.0128s/iter; left time: 255.4135s
	iters: 200, epoch: 17 | loss: 0.2736451
	speed: 0.0104s/iter; left time: 206.3130s
Epoch: 17 cost time: 2.7462053298950195
Epoch: 17, Steps: 239 Train Loss: 0.2924 (Forecasting Loss:0.2641 + XiCon Loss:2.8333 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2646
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2860323
	speed: 0.0125s/iter; left time: 246.1929s
	iters: 200, epoch: 18 | loss: 0.3011882
	speed: 0.0104s/iter; left time: 204.1112s
Epoch: 18 cost time: 2.7325663566589355
Epoch: 18, Steps: 239 Train Loss: 0.2922 (Forecasting Loss:0.2638 + XiCon Loss:2.8350 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2646
Validation loss decreased (0.193392 --> 0.193388).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2804424
	speed: 0.0126s/iter; left time: 245.8496s
	iters: 200, epoch: 19 | loss: 0.3027859
	speed: 0.0105s/iter; left time: 203.2299s
Epoch: 19 cost time: 2.7637393474578857
Epoch: 19, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2636 + XiCon Loss:2.8383 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3143895
	speed: 0.0124s/iter; left time: 238.7786s
	iters: 200, epoch: 20 | loss: 0.2883743
	speed: 0.0104s/iter; left time: 198.9153s
Epoch: 20 cost time: 2.739279270172119
Epoch: 20, Steps: 239 Train Loss: 0.2921 (Forecasting Loss:0.2637 + XiCon Loss:2.8366 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2646
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2888466
	speed: 0.0116s/iter; left time: 221.0690s
	iters: 200, epoch: 21 | loss: 0.3210520
	speed: 0.0094s/iter; left time: 178.2511s
Epoch: 21 cost time: 2.4986674785614014
Epoch: 21, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2634 + XiCon Loss:2.8365 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2646
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3057293
	speed: 0.0120s/iter; left time: 225.8345s
	iters: 200, epoch: 22 | loss: 0.3062719
	speed: 0.0103s/iter; left time: 191.8207s
Epoch: 22 cost time: 2.6710972785949707
Epoch: 22, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2636 + XiCon Loss:2.8343 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2646
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2644830
	speed: 0.0130s/iter; left time: 240.5241s
	iters: 200, epoch: 23 | loss: 0.2780827
	speed: 0.0105s/iter; left time: 193.4202s
Epoch: 23 cost time: 2.7657577991485596
Epoch: 23, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2632 + XiCon Loss:2.8386 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3119628
	speed: 0.0124s/iter; left time: 227.6636s
	iters: 200, epoch: 24 | loss: 0.2882254
	speed: 0.0096s/iter; left time: 175.2783s
Epoch: 24 cost time: 2.5979974269866943
Epoch: 24, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2635 + XiCon Loss:2.8360 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2646
Validation loss decreased (0.193388 --> 0.193382).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2806841
	speed: 0.0125s/iter; left time: 226.0124s
	iters: 200, epoch: 25 | loss: 0.2910739
	speed: 0.0104s/iter; left time: 186.3968s
Epoch: 25 cost time: 2.7028441429138184
Epoch: 25, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2634 + XiCon Loss:2.8361 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2646
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2779098
	speed: 0.0123s/iter; left time: 218.9194s
	iters: 200, epoch: 26 | loss: 0.2987592
	speed: 0.0097s/iter; left time: 172.3844s
Epoch: 26 cost time: 2.5957136154174805
Epoch: 26, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2635 + XiCon Loss:2.8381 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2646
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2873643
	speed: 0.0130s/iter; left time: 228.1788s
	iters: 200, epoch: 27 | loss: 0.2863954
	speed: 0.0098s/iter; left time: 171.1014s
Epoch: 27 cost time: 2.7086315155029297
Epoch: 27, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2632 + XiCon Loss:2.8376 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2777866
	speed: 0.0129s/iter; left time: 223.4935s
	iters: 200, epoch: 28 | loss: 0.2934299
	speed: 0.0105s/iter; left time: 181.2754s
Epoch: 28 cost time: 2.755079984664917
Epoch: 28, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2636 + XiCon Loss:2.8325 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2646
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.3096998
	speed: 0.0125s/iter; left time: 213.2269s
	iters: 200, epoch: 29 | loss: 0.3049017
	speed: 0.0110s/iter; left time: 186.5791s
Epoch: 29 cost time: 2.806095600128174
Epoch: 29, Steps: 239 Train Loss: 0.2914 (Forecasting Loss:0.2630 + XiCon Loss:2.8360 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.2607190
	speed: 0.0124s/iter; left time: 208.4326s
	iters: 200, epoch: 30 | loss: 0.2736532
	speed: 0.0106s/iter; left time: 178.3509s
Epoch: 30 cost time: 2.7442433834075928
Epoch: 30, Steps: 239 Train Loss: 0.2921 (Forecasting Loss:0.2638 + XiCon Loss:2.8347 x Lambda(0.01)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2646
Validation loss decreased (0.193382 --> 0.193207).  Saving model ...
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3033526
	speed: 0.0122s/iter; left time: 202.9430s
	iters: 200, epoch: 31 | loss: 0.2712215
	speed: 0.0102s/iter; left time: 168.0147s
Epoch: 31 cost time: 2.642784833908081
Epoch: 31, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2636 + XiCon Loss:2.8360 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2646
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.2523704
	speed: 0.0129s/iter; left time: 210.7015s
	iters: 200, epoch: 32 | loss: 0.2600902
	speed: 0.0101s/iter; left time: 164.4209s
Epoch: 32 cost time: 2.7203786373138428
Epoch: 32, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2637 + XiCon Loss:2.8331 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.2833006
	speed: 0.0131s/iter; left time: 211.0757s
	iters: 200, epoch: 33 | loss: 0.3075710
	speed: 0.0102s/iter; left time: 163.7397s
Epoch: 33 cost time: 2.7175326347351074
Epoch: 33, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2636 + XiCon Loss:2.8347 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2754884
	speed: 0.0129s/iter; left time: 205.5506s
	iters: 200, epoch: 34 | loss: 0.3408717
	speed: 0.0104s/iter; left time: 164.2105s
Epoch: 34 cost time: 2.766028881072998
Epoch: 34, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2634 + XiCon Loss:2.8361 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2646
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2813355
	speed: 0.0131s/iter; left time: 205.2620s
	iters: 200, epoch: 35 | loss: 0.3251957
	speed: 0.0107s/iter; left time: 166.7262s
Epoch: 35 cost time: 2.796314001083374
Epoch: 35, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2637 + XiCon Loss:2.8358 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.2761110
	speed: 0.0121s/iter; left time: 186.3776s
	iters: 200, epoch: 36 | loss: 0.3075113
	speed: 0.0096s/iter; left time: 146.4862s
Epoch: 36 cost time: 2.5469181537628174
Epoch: 36, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2636 + XiCon Loss:2.8358 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2646
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2809888
	speed: 0.0138s/iter; left time: 209.3346s
	iters: 200, epoch: 37 | loss: 0.3167790
	speed: 0.0104s/iter; left time: 156.3440s
Epoch: 37 cost time: 2.868497848510742
Epoch: 37, Steps: 239 Train Loss: 0.2922 (Forecasting Loss:0.2638 + XiCon Loss:2.8357 x Lambda(0.01)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2646
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2776060
	speed: 0.0118s/iter; left time: 176.6524s
	iters: 200, epoch: 38 | loss: 0.3405631
	speed: 0.0098s/iter; left time: 146.2350s
Epoch: 38 cost time: 2.576735496520996
Epoch: 38, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2636 + XiCon Loss:2.8355 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.2956846
	speed: 0.0133s/iter; left time: 195.4661s
	iters: 200, epoch: 39 | loss: 0.2856379
	speed: 0.0106s/iter; left time: 155.1309s
Epoch: 39 cost time: 2.804150104522705
Epoch: 39, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2636 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
	iters: 100, epoch: 40 | loss: 0.2991100
	speed: 0.0125s/iter; left time: 180.4207s
	iters: 200, epoch: 40 | loss: 0.2812428
	speed: 0.0097s/iter; left time: 138.7676s
Epoch: 40 cost time: 2.6356217861175537
Epoch: 40, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2633 + XiCon Loss:2.8363 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2646
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20758336782455444, mae:0.32170724868774414, mape:2.4004061222076416, mspe:3339.47265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3994
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6364586
	speed: 0.0121s/iter; left time: 287.3591s
	iters: 200, epoch: 1 | loss: 0.5364804
	speed: 0.0101s/iter; left time: 238.7456s
Epoch: 1 cost time: 2.642536163330078
Epoch: 1, Steps: 239 Train Loss: 0.6654 (Forecasting Loss:0.6367 + XiCon Loss:2.8674 x Lambda(0.01)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.4405
Validation loss decreased (inf --> 0.327543).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3505568
	speed: 0.0126s/iter; left time: 297.8594s
	iters: 200, epoch: 2 | loss: 0.3163390
	speed: 0.0094s/iter; left time: 220.1802s
Epoch: 2 cost time: 2.6070752143859863
Epoch: 2, Steps: 239 Train Loss: 0.3451 (Forecasting Loss:0.3165 + XiCon Loss:2.8582 x Lambda(0.01)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.2813
Validation loss decreased (0.327543 --> 0.206743).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3400453
	speed: 0.0119s/iter; left time: 278.3816s
	iters: 200, epoch: 3 | loss: 0.2930531
	speed: 0.0100s/iter; left time: 232.6372s
Epoch: 3 cost time: 2.637876272201538
Epoch: 3, Steps: 239 Train Loss: 0.3063 (Forecasting Loss:0.2777 + XiCon Loss:2.8575 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2705
Validation loss decreased (0.206743 --> 0.197901).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2987679
	speed: 0.0120s/iter; left time: 277.0368s
	iters: 200, epoch: 4 | loss: 0.2783592
	speed: 0.0105s/iter; left time: 241.7480s
Epoch: 4 cost time: 2.639138698577881
Epoch: 4, Steps: 239 Train Loss: 0.2973 (Forecasting Loss:0.2686 + XiCon Loss:2.8625 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2669
Validation loss decreased (0.197901 --> 0.194389).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3433070
	speed: 0.0132s/iter; left time: 301.9798s
	iters: 200, epoch: 5 | loss: 0.3025514
	speed: 0.0103s/iter; left time: 234.2008s
Epoch: 5 cost time: 2.7372348308563232
Epoch: 5, Steps: 239 Train Loss: 0.2931 (Forecasting Loss:0.2644 + XiCon Loss:2.8692 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2650
Validation loss decreased (0.194389 --> 0.192929).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2795365
	speed: 0.0125s/iter; left time: 282.3171s
	iters: 200, epoch: 6 | loss: 0.2684856
	speed: 0.0102s/iter; left time: 229.9643s
Epoch: 6 cost time: 2.7389795780181885
Epoch: 6, Steps: 239 Train Loss: 0.2910 (Forecasting Loss:0.2622 + XiCon Loss:2.8745 x Lambda(0.01)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.2634
Validation loss decreased (0.192929 --> 0.192139).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3124304
	speed: 0.0120s/iter; left time: 267.7810s
	iters: 200, epoch: 7 | loss: 0.2778293
	speed: 0.0102s/iter; left time: 226.1081s
Epoch: 7 cost time: 2.657197952270508
Epoch: 7, Steps: 239 Train Loss: 0.2899 (Forecasting Loss:0.2612 + XiCon Loss:2.8709 x Lambda(0.01)), Vali MSE Loss: 0.1917 Test MSE Loss: 0.2630
Validation loss decreased (0.192139 --> 0.191739).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3014227
	speed: 0.0124s/iter; left time: 275.2148s
	iters: 200, epoch: 8 | loss: 0.3278698
	speed: 0.0103s/iter; left time: 226.7799s
Epoch: 8 cost time: 2.69317364692688
Epoch: 8, Steps: 239 Train Loss: 0.2897 (Forecasting Loss:0.2609 + XiCon Loss:2.8738 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.2628
Validation loss decreased (0.191739 --> 0.191622).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2841491
	speed: 0.0126s/iter; left time: 275.1493s
	iters: 200, epoch: 9 | loss: 0.2655489
	speed: 0.0095s/iter; left time: 206.5064s
Epoch: 9 cost time: 2.619218349456787
Epoch: 9, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2602 + XiCon Loss:2.8750 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2626
Validation loss decreased (0.191622 --> 0.191240).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2766798
	speed: 0.0119s/iter; left time: 256.9854s
	iters: 200, epoch: 10 | loss: 0.2819316
	speed: 0.0099s/iter; left time: 212.6065s
Epoch: 10 cost time: 2.562176465988159
Epoch: 10, Steps: 239 Train Loss: 0.2893 (Forecasting Loss:0.2605 + XiCon Loss:2.8769 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3005688
	speed: 0.0131s/iter; left time: 280.0115s
	iters: 200, epoch: 11 | loss: 0.3323659
	speed: 0.0106s/iter; left time: 224.9108s
Epoch: 11 cost time: 2.788022518157959
Epoch: 11, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2600 + XiCon Loss:2.8776 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
Validation loss decreased (0.191240 --> 0.191210).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2920014
	speed: 0.0123s/iter; left time: 261.1213s
	iters: 200, epoch: 12 | loss: 0.2912228
	speed: 0.0099s/iter; left time: 208.3329s
Epoch: 12 cost time: 2.642021417617798
Epoch: 12, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2604 + XiCon Loss:2.8744 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3043976
	speed: 0.0131s/iter; left time: 273.8575s
	iters: 200, epoch: 13 | loss: 0.3122106
	speed: 0.0098s/iter; left time: 203.6051s
Epoch: 13 cost time: 2.679856300354004
Epoch: 13, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2602 + XiCon Loss:2.8786 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2676733
	speed: 0.0135s/iter; left time: 279.0450s
	iters: 200, epoch: 14 | loss: 0.2681984
	speed: 0.0098s/iter; left time: 202.1963s
Epoch: 14 cost time: 2.768108367919922
Epoch: 14, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2603 + XiCon Loss:2.8781 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2868834
	speed: 0.0127s/iter; left time: 259.2871s
	iters: 200, epoch: 15 | loss: 0.2997857
	speed: 0.0103s/iter; left time: 209.7030s
Epoch: 15 cost time: 2.733227252960205
Epoch: 15, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2605 + XiCon Loss:2.8748 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2939751
	speed: 0.0123s/iter; left time: 248.9882s
	iters: 200, epoch: 16 | loss: 0.3242797
	speed: 0.0098s/iter; left time: 196.2871s
Epoch: 16 cost time: 2.653485059738159
Epoch: 16, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2602 + XiCon Loss:2.8732 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3001483
	speed: 0.0137s/iter; left time: 273.2527s
	iters: 200, epoch: 17 | loss: 0.2922355
	speed: 0.0106s/iter; left time: 211.1379s
Epoch: 17 cost time: 2.8782293796539307
Epoch: 17, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2601 + XiCon Loss:2.8738 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
Validation loss decreased (0.191210 --> 0.191197).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2942794
	speed: 0.0128s/iter; left time: 252.0006s
	iters: 200, epoch: 18 | loss: 0.2749265
	speed: 0.0107s/iter; left time: 209.4960s
Epoch: 18 cost time: 2.794471263885498
Epoch: 18, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2603 + XiCon Loss:2.8791 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2924158
	speed: 0.0126s/iter; left time: 245.9351s
	iters: 200, epoch: 19 | loss: 0.3044158
	speed: 0.0100s/iter; left time: 193.3519s
Epoch: 19 cost time: 2.6616246700286865
Epoch: 19, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2600 + XiCon Loss:2.8789 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3010076
	speed: 0.0121s/iter; left time: 233.5339s
	iters: 200, epoch: 20 | loss: 0.2383336
	speed: 0.0094s/iter; left time: 179.6624s
Epoch: 20 cost time: 2.536680221557617
Epoch: 20, Steps: 239 Train Loss: 0.2895 (Forecasting Loss:0.2607 + XiCon Loss:2.8766 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2893811
	speed: 0.0129s/iter; left time: 246.3158s
	iters: 200, epoch: 21 | loss: 0.2911321
	speed: 0.0097s/iter; left time: 182.7541s
Epoch: 21 cost time: 2.705610513687134
Epoch: 21, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2606 + XiCon Loss:2.8794 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2625
Validation loss decreased (0.191197 --> 0.191101).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2945395
	speed: 0.0114s/iter; left time: 214.5716s
	iters: 200, epoch: 22 | loss: 0.3062282
	speed: 0.0098s/iter; left time: 182.1917s
Epoch: 22 cost time: 2.5037505626678467
Epoch: 22, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2601 + XiCon Loss:2.8761 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2942916
	speed: 0.0119s/iter; left time: 221.3755s
	iters: 200, epoch: 23 | loss: 0.2777168
	speed: 0.0093s/iter; left time: 171.4574s
Epoch: 23 cost time: 2.524709939956665
Epoch: 23, Steps: 239 Train Loss: 0.2886 (Forecasting Loss:0.2599 + XiCon Loss:2.8738 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2987575
	speed: 0.0120s/iter; left time: 219.7352s
	iters: 200, epoch: 24 | loss: 0.2615675
	speed: 0.0098s/iter; left time: 179.0481s
Epoch: 24 cost time: 2.600830078125
Epoch: 24, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2601 + XiCon Loss:2.8728 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2632638
	speed: 0.0133s/iter; left time: 240.7498s
	iters: 200, epoch: 25 | loss: 0.2815317
	speed: 0.0105s/iter; left time: 187.9781s
Epoch: 25 cost time: 2.7855429649353027
Epoch: 25, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2604 + XiCon Loss:2.8742 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2537166
	speed: 0.0120s/iter; left time: 213.3005s
	iters: 200, epoch: 26 | loss: 0.2934635
	speed: 0.0102s/iter; left time: 181.3732s
Epoch: 26 cost time: 2.6359775066375732
Epoch: 26, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2604 + XiCon Loss:2.8759 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2585328
	speed: 0.0126s/iter; left time: 222.0959s
	iters: 200, epoch: 27 | loss: 0.3110232
	speed: 0.0100s/iter; left time: 174.5525s
Epoch: 27 cost time: 2.6641054153442383
Epoch: 27, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2602 + XiCon Loss:2.8748 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2625
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2884016
	speed: 0.0128s/iter; left time: 222.2332s
	iters: 200, epoch: 28 | loss: 0.3022690
	speed: 0.0101s/iter; left time: 174.1895s
Epoch: 28 cost time: 2.714017629623413
Epoch: 28, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2604 + XiCon Loss:2.8740 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2736727
	speed: 0.0123s/iter; left time: 211.0384s
	iters: 200, epoch: 29 | loss: 0.2876232
	speed: 0.0100s/iter; left time: 170.1401s
Epoch: 29 cost time: 2.6499433517456055
Epoch: 29, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2604 + XiCon Loss:2.8742 x Lambda(0.01)), Vali MSE Loss: 0.1910 Test MSE Loss: 0.2625
Validation loss decreased (0.191101 --> 0.190955).  Saving model ...
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.3101042
	speed: 0.0131s/iter; left time: 220.8305s
	iters: 200, epoch: 30 | loss: 0.2832233
	speed: 0.0109s/iter; left time: 182.4903s
Epoch: 30 cost time: 2.814664602279663
Epoch: 30, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2603 + XiCon Loss:2.8741 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3104572
	speed: 0.0124s/iter; left time: 205.9483s
	iters: 200, epoch: 31 | loss: 0.2968763
	speed: 0.0097s/iter; left time: 161.0190s
Epoch: 31 cost time: 2.6308226585388184
Epoch: 31, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2601 + XiCon Loss:2.8762 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2625
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.3366940
	speed: 0.0123s/iter; left time: 202.1989s
	iters: 200, epoch: 32 | loss: 0.2638162
	speed: 0.0101s/iter; left time: 165.1872s
Epoch: 32 cost time: 2.6640970706939697
Epoch: 32, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2602 + XiCon Loss:2.8768 x Lambda(0.01)), Vali MSE Loss: 0.1915 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.3000227
	speed: 0.0123s/iter; left time: 198.0446s
	iters: 200, epoch: 33 | loss: 0.2616030
	speed: 0.0102s/iter; left time: 164.1895s
Epoch: 33 cost time: 2.6707077026367188
Epoch: 33, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2603 + XiCon Loss:2.8736 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2855912
	speed: 0.0120s/iter; left time: 190.8574s
	iters: 200, epoch: 34 | loss: 0.2542080
	speed: 0.0103s/iter; left time: 163.2266s
Epoch: 34 cost time: 2.626964569091797
Epoch: 34, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2602 + XiCon Loss:2.8753 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2625
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2631491
	speed: 0.0125s/iter; left time: 196.6427s
	iters: 200, epoch: 35 | loss: 0.2893847
	speed: 0.0096s/iter; left time: 150.2385s
Epoch: 35 cost time: 2.6196720600128174
Epoch: 35, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2600 + XiCon Loss:2.8746 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.2999745
	speed: 0.0119s/iter; left time: 183.5795s
	iters: 200, epoch: 36 | loss: 0.2847031
	speed: 0.0096s/iter; left time: 146.8898s
Epoch: 36 cost time: 2.592963457107544
Epoch: 36, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2603 + XiCon Loss:2.8765 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2846378
	speed: 0.0124s/iter; left time: 188.2212s
	iters: 200, epoch: 37 | loss: 0.2954108
	speed: 0.0103s/iter; left time: 155.7275s
Epoch: 37 cost time: 2.7358925342559814
Epoch: 37, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2603 + XiCon Loss:2.8726 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2625
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2636881
	speed: 0.0122s/iter; left time: 181.7909s
	iters: 200, epoch: 38 | loss: 0.3116492
	speed: 0.0104s/iter; left time: 153.9305s
Epoch: 38 cost time: 2.712855339050293
Epoch: 38, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2603 + XiCon Loss:2.8744 x Lambda(0.01)), Vali MSE Loss: 0.1917 Test MSE Loss: 0.2625
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.3344340
	speed: 0.0130s/iter; left time: 191.5160s
	iters: 200, epoch: 39 | loss: 0.3080516
	speed: 0.0101s/iter; left time: 146.9864s
Epoch: 39 cost time: 2.7121427059173584
Epoch: 39, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2600 + XiCon Loss:2.8775 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20509883761405945, mae:0.31984826922416687, mape:2.4711716175079346, mspe:4027.31396484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2066+-0.00301, MAE:0.3214+-0.00232, MAPE:2.4263+-0.09539, MSPE:3616.4895+-750.33193, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5723
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.5358868
	speed: 0.0168s/iter; left time: 383.6015s
	iters: 200, epoch: 1 | loss: 3.4687715
	speed: 0.0120s/iter; left time: 273.5733s
Epoch: 1 cost time: 3.2508904933929443
Epoch: 1, Steps: 230 Train Loss: 3.5359 (Forecasting Loss:0.7227 + XiCon Loss:2.8133 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.5301
Validation loss decreased (inf --> 0.330921).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.0741138
	speed: 0.0138s/iter; left time: 312.6683s
	iters: 200, epoch: 2 | loss: 2.9999599
	speed: 0.0120s/iter; left time: 270.3737s
Epoch: 2 cost time: 2.974449634552002
Epoch: 2, Steps: 230 Train Loss: 3.1347 (Forecasting Loss:0.4231 + XiCon Loss:2.7115 x Lambda(1.0)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.3746
Validation loss decreased (0.330921 --> 0.215945).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0322621
	speed: 0.0136s/iter; left time: 304.3397s
	iters: 200, epoch: 3 | loss: 3.0049844
	speed: 0.0120s/iter; left time: 267.7928s
Epoch: 3 cost time: 2.915083646774292
Epoch: 3, Steps: 230 Train Loss: 3.0193 (Forecasting Loss:0.3795 + XiCon Loss:2.6398 x Lambda(1.0)), Vali MSE Loss: 0.2054 Test MSE Loss: 0.3660
Validation loss decreased (0.215945 --> 0.205431).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 2.9836450
	speed: 0.0140s/iter; left time: 310.8384s
	iters: 200, epoch: 4 | loss: 3.0088222
	speed: 0.0113s/iter; left time: 250.6450s
Epoch: 4 cost time: 2.904541015625
Epoch: 4, Steps: 230 Train Loss: 3.0008 (Forecasting Loss:0.3711 + XiCon Loss:2.6298 x Lambda(1.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.3603
Validation loss decreased (0.205431 --> 0.203633).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.0773957
	speed: 0.0138s/iter; left time: 302.9188s
	iters: 200, epoch: 5 | loss: 2.9686007
	speed: 0.0116s/iter; left time: 253.1511s
Epoch: 5 cost time: 2.939775228500366
Epoch: 5, Steps: 230 Train Loss: 2.9952 (Forecasting Loss:0.3677 + XiCon Loss:2.6275 x Lambda(1.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.3611
Validation loss decreased (0.203633 --> 0.203303).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.0476184
	speed: 0.0135s/iter; left time: 294.6098s
	iters: 200, epoch: 6 | loss: 2.9977622
	speed: 0.0112s/iter; left time: 242.7175s
Epoch: 6 cost time: 2.840334415435791
Epoch: 6, Steps: 230 Train Loss: 2.9944 (Forecasting Loss:0.3659 + XiCon Loss:2.6284 x Lambda(1.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.3592
Validation loss decreased (0.203303 --> 0.202699).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0258429
	speed: 0.0145s/iter; left time: 312.2176s
	iters: 200, epoch: 7 | loss: 3.0063672
	speed: 0.0124s/iter; left time: 265.2769s
Epoch: 7 cost time: 3.064157247543335
Epoch: 7, Steps: 230 Train Loss: 2.9910 (Forecasting Loss:0.3650 + XiCon Loss:2.6260 x Lambda(1.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.3581
Validation loss decreased (0.202699 --> 0.202548).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.0824199
	speed: 0.0143s/iter; left time: 304.3843s
	iters: 200, epoch: 8 | loss: 3.0036514
	speed: 0.0118s/iter; left time: 250.7422s
Epoch: 8 cost time: 2.9902503490448
Epoch: 8, Steps: 230 Train Loss: 2.9942 (Forecasting Loss:0.3642 + XiCon Loss:2.6300 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3578
Validation loss decreased (0.202548 --> 0.202247).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 2.9734027
	speed: 0.0137s/iter; left time: 288.2333s
	iters: 200, epoch: 9 | loss: 2.9997168
	speed: 0.0115s/iter; left time: 241.1502s
Epoch: 9 cost time: 2.928513526916504
Epoch: 9, Steps: 230 Train Loss: 2.9894 (Forecasting Loss:0.3640 + XiCon Loss:2.6254 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3578
Validation loss decreased (0.202247 --> 0.202141).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 2.9543958
	speed: 0.0145s/iter; left time: 301.4623s
	iters: 200, epoch: 10 | loss: 3.0312707
	speed: 0.0112s/iter; left time: 233.0824s
Epoch: 10 cost time: 2.9432199001312256
Epoch: 10, Steps: 230 Train Loss: 2.9893 (Forecasting Loss:0.3637 + XiCon Loss:2.6256 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3578
Validation loss decreased (0.202141 --> 0.202034).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 2.9114254
	speed: 0.0141s/iter; left time: 289.7759s
	iters: 200, epoch: 11 | loss: 2.9753919
	speed: 0.0114s/iter; left time: 234.3133s
Epoch: 11 cost time: 2.916715145111084
Epoch: 11, Steps: 230 Train Loss: 2.9858 (Forecasting Loss:0.3635 + XiCon Loss:2.6222 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3577
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 2.9640095
	speed: 0.0144s/iter; left time: 294.2393s
	iters: 200, epoch: 12 | loss: 3.0040975
	speed: 0.0118s/iter; left time: 239.0648s
Epoch: 12 cost time: 2.9904332160949707
Epoch: 12, Steps: 230 Train Loss: 2.9918 (Forecasting Loss:0.3647 + XiCon Loss:2.6271 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3578
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 2.9678288
	speed: 0.0145s/iter; left time: 292.1269s
	iters: 200, epoch: 13 | loss: 2.9503305
	speed: 0.0116s/iter; left time: 233.1233s
Epoch: 13 cost time: 2.9662716388702393
Epoch: 13, Steps: 230 Train Loss: 2.9855 (Forecasting Loss:0.3641 + XiCon Loss:2.6214 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3577
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.0179403
	speed: 0.0139s/iter; left time: 276.5670s
	iters: 200, epoch: 14 | loss: 2.9881635
	speed: 0.0115s/iter; left time: 228.0824s
Epoch: 14 cost time: 2.92056941986084
Epoch: 14, Steps: 230 Train Loss: 2.9892 (Forecasting Loss:0.3635 + XiCon Loss:2.6257 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3577
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.0217104
	speed: 0.0141s/iter; left time: 277.0385s
	iters: 200, epoch: 15 | loss: 2.9431334
	speed: 0.0119s/iter; left time: 232.5232s
Epoch: 15 cost time: 2.973752737045288
Epoch: 15, Steps: 230 Train Loss: 2.9894 (Forecasting Loss:0.3641 + XiCon Loss:2.6253 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3577
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 2.9829555
	speed: 0.0137s/iter; left time: 266.1420s
	iters: 200, epoch: 16 | loss: 2.9606097
	speed: 0.0112s/iter; left time: 216.8603s
Epoch: 16 cost time: 2.8866090774536133
Epoch: 16, Steps: 230 Train Loss: 2.9875 (Forecasting Loss:0.3641 + XiCon Loss:2.6234 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3577
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 2.9520082
	speed: 0.0140s/iter; left time: 269.8950s
	iters: 200, epoch: 17 | loss: 2.9730501
	speed: 0.0125s/iter; left time: 238.8631s
Epoch: 17 cost time: 3.039111375808716
Epoch: 17, Steps: 230 Train Loss: 2.9892 (Forecasting Loss:0.3636 + XiCon Loss:2.6255 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3577
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 2.9633775
	speed: 0.0142s/iter; left time: 269.5437s
	iters: 200, epoch: 18 | loss: 3.0546293
	speed: 0.0116s/iter; left time: 219.0314s
Epoch: 18 cost time: 2.9484503269195557
Epoch: 18, Steps: 230 Train Loss: 2.9898 (Forecasting Loss:0.3635 + XiCon Loss:2.6263 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3577
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 2.9270930
	speed: 0.0144s/iter; left time: 269.2251s
	iters: 200, epoch: 19 | loss: 2.9790051
	speed: 0.0113s/iter; left time: 211.6187s
Epoch: 19 cost time: 2.9757425785064697
Epoch: 19, Steps: 230 Train Loss: 2.9882 (Forecasting Loss:0.3639 + XiCon Loss:2.6244 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3577
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 2.9681444
	speed: 0.0141s/iter; left time: 260.6888s
	iters: 200, epoch: 20 | loss: 3.0453987
	speed: 0.0118s/iter; left time: 217.3395s
Epoch: 20 cost time: 2.9572296142578125
Epoch: 20, Steps: 230 Train Loss: 2.9926 (Forecasting Loss:0.3640 + XiCon Loss:2.6286 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3577
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3076554238796234, mae:0.4079643785953522, mape:4.26197624206543, mspe:28230.8515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4784
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6332011
	speed: 0.0143s/iter; left time: 327.2008s
	iters: 200, epoch: 1 | loss: 3.4150481
	speed: 0.0117s/iter; left time: 267.0651s
Epoch: 1 cost time: 2.996488571166992
Epoch: 1, Steps: 230 Train Loss: 3.5627 (Forecasting Loss:0.7213 + XiCon Loss:2.8414 x Lambda(1.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.5348
Validation loss decreased (inf --> 0.328899).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1800165
	speed: 0.0135s/iter; left time: 307.1776s
	iters: 200, epoch: 2 | loss: 3.0519063
	speed: 0.0118s/iter; left time: 267.1962s
Epoch: 2 cost time: 2.9257025718688965
Epoch: 2, Steps: 230 Train Loss: 3.1364 (Forecasting Loss:0.4218 + XiCon Loss:2.7146 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.3629
Validation loss decreased (0.328899 --> 0.213435).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0350678
	speed: 0.0142s/iter; left time: 319.6181s
	iters: 200, epoch: 3 | loss: 3.0615509
	speed: 0.0111s/iter; left time: 248.6111s
Epoch: 3 cost time: 2.909914493560791
Epoch: 3, Steps: 230 Train Loss: 3.0204 (Forecasting Loss:0.3754 + XiCon Loss:2.6450 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.3527
Validation loss decreased (0.213435 --> 0.207225).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.0402560
	speed: 0.0143s/iter; left time: 317.0477s
	iters: 200, epoch: 4 | loss: 3.0529592
	speed: 0.0122s/iter; left time: 269.4602s
Epoch: 4 cost time: 3.0049986839294434
Epoch: 4, Steps: 230 Train Loss: 3.0058 (Forecasting Loss:0.3664 + XiCon Loss:2.6394 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3496
Validation loss decreased (0.207225 --> 0.204838).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 2.9732301
	speed: 0.0141s/iter; left time: 310.3560s
	iters: 200, epoch: 5 | loss: 2.9335060
	speed: 0.0117s/iter; left time: 255.8058s
Epoch: 5 cost time: 2.9640769958496094
Epoch: 5, Steps: 230 Train Loss: 2.9984 (Forecasting Loss:0.3628 + XiCon Loss:2.6357 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3467
Validation loss decreased (0.204838 --> 0.204801).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 2.9833038
	speed: 0.0141s/iter; left time: 306.6844s
	iters: 200, epoch: 6 | loss: 2.9703150
	speed: 0.0117s/iter; left time: 252.4356s
Epoch: 6 cost time: 2.9569218158721924
Epoch: 6, Steps: 230 Train Loss: 2.9957 (Forecasting Loss:0.3600 + XiCon Loss:2.6357 x Lambda(1.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.3458
Validation loss decreased (0.204801 --> 0.204012).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.9905672
	speed: 0.0133s/iter; left time: 285.7849s
	iters: 200, epoch: 7 | loss: 3.0389280
	speed: 0.0115s/iter; left time: 246.1733s
Epoch: 7 cost time: 2.869230031967163
Epoch: 7, Steps: 230 Train Loss: 2.9920 (Forecasting Loss:0.3591 + XiCon Loss:2.6328 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.3460
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.9850798
	speed: 0.0143s/iter; left time: 304.6957s
	iters: 200, epoch: 8 | loss: 3.0276599
	speed: 0.0120s/iter; left time: 253.3106s
Epoch: 8 cost time: 3.0120151042938232
Epoch: 8, Steps: 230 Train Loss: 2.9925 (Forecasting Loss:0.3584 + XiCon Loss:2.6341 x Lambda(1.0)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.3460
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 2.9849727
	speed: 0.0142s/iter; left time: 299.4266s
	iters: 200, epoch: 9 | loss: 2.9385085
	speed: 0.0119s/iter; left time: 250.1201s
Epoch: 9 cost time: 2.982475757598877
Epoch: 9, Steps: 230 Train Loss: 2.9883 (Forecasting Loss:0.3582 + XiCon Loss:2.6301 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.3455
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 2.9292979
	speed: 0.0139s/iter; left time: 289.4819s
	iters: 200, epoch: 10 | loss: 2.9732122
	speed: 0.0114s/iter; left time: 235.3007s
Epoch: 10 cost time: 2.9180479049682617
Epoch: 10, Steps: 230 Train Loss: 2.9834 (Forecasting Loss:0.3581 + XiCon Loss:2.6253 x Lambda(1.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.3454
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 2.9853430
	speed: 0.0142s/iter; left time: 293.3646s
	iters: 200, epoch: 11 | loss: 3.0580034
	speed: 0.0120s/iter; left time: 246.9996s
Epoch: 11 cost time: 3.009678602218628
Epoch: 11, Steps: 230 Train Loss: 2.9858 (Forecasting Loss:0.3576 + XiCon Loss:2.6282 x Lambda(1.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.3454
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0268250
	speed: 0.0139s/iter; left time: 283.1391s
	iters: 200, epoch: 12 | loss: 2.9917030
	speed: 0.0120s/iter; left time: 242.4638s
Epoch: 12 cost time: 2.966783046722412
Epoch: 12, Steps: 230 Train Loss: 2.9889 (Forecasting Loss:0.3581 + XiCon Loss:2.6308 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3454
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 2.9742782
	speed: 0.0142s/iter; left time: 286.0481s
	iters: 200, epoch: 13 | loss: 3.0215986
	speed: 0.0116s/iter; left time: 232.6367s
Epoch: 13 cost time: 2.9906845092773438
Epoch: 13, Steps: 230 Train Loss: 2.9894 (Forecasting Loss:0.3579 + XiCon Loss:2.6315 x Lambda(1.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.3454
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 2.9582500
	speed: 0.0141s/iter; left time: 281.1204s
	iters: 200, epoch: 14 | loss: 2.9677715
	speed: 0.0116s/iter; left time: 230.4172s
Epoch: 14 cost time: 3.002819061279297
Epoch: 14, Steps: 230 Train Loss: 2.9884 (Forecasting Loss:0.3581 + XiCon Loss:2.6302 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3454
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 2.9868467
	speed: 0.0136s/iter; left time: 267.6141s
	iters: 200, epoch: 15 | loss: 3.0729346
	speed: 0.0116s/iter; left time: 227.4015s
Epoch: 15 cost time: 2.9263975620269775
Epoch: 15, Steps: 230 Train Loss: 2.9907 (Forecasting Loss:0.3582 + XiCon Loss:2.6325 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.3454
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.0586288
	speed: 0.0141s/iter; left time: 273.6200s
	iters: 200, epoch: 16 | loss: 2.9163342
	speed: 0.0118s/iter; left time: 229.1069s
Epoch: 16 cost time: 2.970893383026123
Epoch: 16, Steps: 230 Train Loss: 2.9913 (Forecasting Loss:0.3582 + XiCon Loss:2.6331 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3454
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.29295244812965393, mae:0.39862191677093506, mape:4.058281421661377, mspe:25888.017578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4265
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6133063
	speed: 0.0140s/iter; left time: 321.6626s
	iters: 200, epoch: 1 | loss: 3.4569402
	speed: 0.0113s/iter; left time: 257.8575s
Epoch: 1 cost time: 2.9173741340637207
Epoch: 1, Steps: 230 Train Loss: 3.5475 (Forecasting Loss:0.7257 + XiCon Loss:2.8218 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.5382
Validation loss decreased (inf --> 0.331614).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1253128
	speed: 0.0143s/iter; left time: 324.1549s
	iters: 200, epoch: 2 | loss: 3.0382321
	speed: 0.0119s/iter; left time: 268.8005s
Epoch: 2 cost time: 3.013711929321289
Epoch: 2, Steps: 230 Train Loss: 3.1361 (Forecasting Loss:0.4343 + XiCon Loss:2.7019 x Lambda(1.0)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.3891
Validation loss decreased (0.331614 --> 0.220840).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 2.9783659
	speed: 0.0145s/iter; left time: 324.4967s
	iters: 200, epoch: 3 | loss: 3.0050979
	speed: 0.0111s/iter; left time: 247.9221s
Epoch: 3 cost time: 2.9063849449157715
Epoch: 3, Steps: 230 Train Loss: 3.0270 (Forecasting Loss:0.3910 + XiCon Loss:2.6360 x Lambda(1.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.3766
Validation loss decreased (0.220840 --> 0.214096).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.0206642
	speed: 0.0142s/iter; left time: 314.9721s
	iters: 200, epoch: 4 | loss: 3.0086646
	speed: 0.0117s/iter; left time: 259.1723s
Epoch: 4 cost time: 2.9685769081115723
Epoch: 4, Steps: 230 Train Loss: 3.0053 (Forecasting Loss:0.3736 + XiCon Loss:2.6316 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3676
Validation loss decreased (0.214096 --> 0.208740).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 2.9983559
	speed: 0.0140s/iter; left time: 307.9781s
	iters: 200, epoch: 5 | loss: 2.9977105
	speed: 0.0115s/iter; left time: 251.9499s
Epoch: 5 cost time: 2.938453435897827
Epoch: 5, Steps: 230 Train Loss: 2.9959 (Forecasting Loss:0.3667 + XiCon Loss:2.6292 x Lambda(1.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.3676
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.0177045
	speed: 0.0143s/iter; left time: 310.2168s
	iters: 200, epoch: 6 | loss: 3.0292492
	speed: 0.0116s/iter; left time: 251.1989s
Epoch: 6 cost time: 2.961916208267212
Epoch: 6, Steps: 230 Train Loss: 2.9971 (Forecasting Loss:0.3640 + XiCon Loss:2.6331 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3656
Validation loss decreased (0.208740 --> 0.208237).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.9400735
	speed: 0.0142s/iter; left time: 305.5710s
	iters: 200, epoch: 7 | loss: 3.0144844
	speed: 0.0117s/iter; left time: 250.3363s
Epoch: 7 cost time: 2.9599709510803223
Epoch: 7, Steps: 230 Train Loss: 2.9898 (Forecasting Loss:0.3631 + XiCon Loss:2.6267 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3653
Validation loss decreased (0.208237 --> 0.208167).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.0109386
	speed: 0.0141s/iter; left time: 299.6570s
	iters: 200, epoch: 8 | loss: 2.9388311
	speed: 0.0109s/iter; left time: 230.6424s
Epoch: 8 cost time: 2.876199722290039
Epoch: 8, Steps: 230 Train Loss: 2.9885 (Forecasting Loss:0.3628 + XiCon Loss:2.6258 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3652
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0384951
	speed: 0.0142s/iter; left time: 298.7045s
	iters: 200, epoch: 9 | loss: 3.0456626
	speed: 0.0123s/iter; left time: 257.0625s
Epoch: 9 cost time: 3.0283870697021484
Epoch: 9, Steps: 230 Train Loss: 2.9862 (Forecasting Loss:0.3627 + XiCon Loss:2.6235 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3654
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0124948
	speed: 0.0142s/iter; left time: 294.8090s
	iters: 200, epoch: 10 | loss: 3.0429196
	speed: 0.0117s/iter; left time: 242.2574s
Epoch: 10 cost time: 2.9702391624450684
Epoch: 10, Steps: 230 Train Loss: 2.9892 (Forecasting Loss:0.3620 + XiCon Loss:2.6272 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3652
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 2.9754264
	speed: 0.0142s/iter; left time: 292.5264s
	iters: 200, epoch: 11 | loss: 2.9813516
	speed: 0.0117s/iter; left time: 239.3749s
Epoch: 11 cost time: 2.9462451934814453
Epoch: 11, Steps: 230 Train Loss: 2.9845 (Forecasting Loss:0.3619 + XiCon Loss:2.6226 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3651
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0586424
	speed: 0.0144s/iter; left time: 294.1124s
	iters: 200, epoch: 12 | loss: 2.9809568
	speed: 0.0117s/iter; left time: 237.7456s
Epoch: 12 cost time: 2.9871416091918945
Epoch: 12, Steps: 230 Train Loss: 2.9885 (Forecasting Loss:0.3622 + XiCon Loss:2.6263 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.0077486
	speed: 0.0141s/iter; left time: 284.3301s
	iters: 200, epoch: 13 | loss: 2.9916375
	speed: 0.0113s/iter; left time: 226.3216s
Epoch: 13 cost time: 2.9291024208068848
Epoch: 13, Steps: 230 Train Loss: 2.9889 (Forecasting Loss:0.3621 + XiCon Loss:2.6268 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 2.9673245
	speed: 0.0142s/iter; left time: 283.1417s
	iters: 200, epoch: 14 | loss: 2.9690018
	speed: 0.0111s/iter; left time: 219.4331s
Epoch: 14 cost time: 2.8944506645202637
Epoch: 14, Steps: 230 Train Loss: 2.9860 (Forecasting Loss:0.3621 + XiCon Loss:2.6239 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.3650
Validation loss decreased (0.208167 --> 0.208097).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 2.9705689
	speed: 0.0145s/iter; left time: 285.5738s
	iters: 200, epoch: 15 | loss: 2.9946465
	speed: 0.0120s/iter; left time: 234.7789s
Epoch: 15 cost time: 3.012631893157959
Epoch: 15, Steps: 230 Train Loss: 2.9895 (Forecasting Loss:0.3617 + XiCon Loss:2.6278 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 2.9219246
	speed: 0.0143s/iter; left time: 277.4894s
	iters: 200, epoch: 16 | loss: 2.9288306
	speed: 0.0120s/iter; left time: 231.2888s
Epoch: 16 cost time: 3.0087294578552246
Epoch: 16, Steps: 230 Train Loss: 2.9863 (Forecasting Loss:0.3621 + XiCon Loss:2.6242 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 2.9264965
	speed: 0.0144s/iter; left time: 276.8302s
	iters: 200, epoch: 17 | loss: 2.9941971
	speed: 0.0123s/iter; left time: 236.1281s
Epoch: 17 cost time: 3.038233995437622
Epoch: 17, Steps: 230 Train Loss: 2.9868 (Forecasting Loss:0.3621 + XiCon Loss:2.6247 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 2.9140165
	speed: 0.0138s/iter; left time: 263.0225s
	iters: 200, epoch: 18 | loss: 2.9788923
	speed: 0.0120s/iter; left time: 227.4638s
Epoch: 18 cost time: 2.9530832767486572
Epoch: 18, Steps: 230 Train Loss: 2.9925 (Forecasting Loss:0.3610 + XiCon Loss:2.6314 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3650
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 2.9377537
	speed: 0.0141s/iter; left time: 264.9219s
	iters: 200, epoch: 19 | loss: 3.0069013
	speed: 0.0121s/iter; left time: 224.9525s
Epoch: 19 cost time: 3.015793561935425
Epoch: 19, Steps: 230 Train Loss: 2.9878 (Forecasting Loss:0.3617 + XiCon Loss:2.6262 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3650
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 2.9812360
	speed: 0.0138s/iter; left time: 255.1458s
	iters: 200, epoch: 20 | loss: 2.9727924
	speed: 0.0117s/iter; left time: 215.9325s
Epoch: 20 cost time: 2.9298932552337646
Epoch: 20, Steps: 230 Train Loss: 2.9851 (Forecasting Loss:0.3621 + XiCon Loss:2.6230 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 2.9801984
	speed: 0.0138s/iter; left time: 252.0816s
	iters: 200, epoch: 21 | loss: 2.9827495
	speed: 0.0116s/iter; left time: 211.0480s
Epoch: 21 cost time: 2.909348487854004
Epoch: 21, Steps: 230 Train Loss: 2.9870 (Forecasting Loss:0.3617 + XiCon Loss:2.6253 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.3650
Validation loss decreased (0.208097 --> 0.208087).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 2.9727132
	speed: 0.0148s/iter; left time: 267.1174s
	iters: 200, epoch: 22 | loss: 2.9631920
	speed: 0.0119s/iter; left time: 213.6987s
Epoch: 22 cost time: 3.0396478176116943
Epoch: 22, Steps: 230 Train Loss: 2.9863 (Forecasting Loss:0.3618 + XiCon Loss:2.6245 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 2.9700418
	speed: 0.0133s/iter; left time: 236.7626s
	iters: 200, epoch: 23 | loss: 2.9934769
	speed: 0.0116s/iter; left time: 206.2649s
Epoch: 23 cost time: 2.8635568618774414
Epoch: 23, Steps: 230 Train Loss: 2.9860 (Forecasting Loss:0.3618 + XiCon Loss:2.6242 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.3650
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 2.9966722
	speed: 0.0136s/iter; left time: 238.9498s
	iters: 200, epoch: 24 | loss: 2.9917350
	speed: 0.0116s/iter; left time: 203.2805s
Epoch: 24 cost time: 2.890969753265381
Epoch: 24, Steps: 230 Train Loss: 2.9876 (Forecasting Loss:0.3622 + XiCon Loss:2.6255 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.0063546
	speed: 0.0143s/iter; left time: 249.0066s
	iters: 200, epoch: 25 | loss: 2.9251914
	speed: 0.0115s/iter; left time: 199.4127s
Epoch: 25 cost time: 2.9691414833068848
Epoch: 25, Steps: 230 Train Loss: 2.9868 (Forecasting Loss:0.3618 + XiCon Loss:2.6250 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3650
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 2.9407732
	speed: 0.0142s/iter; left time: 244.0939s
	iters: 200, epoch: 26 | loss: 2.9831052
	speed: 0.0124s/iter; left time: 211.0501s
Epoch: 26 cost time: 3.032782793045044
Epoch: 26, Steps: 230 Train Loss: 2.9862 (Forecasting Loss:0.3618 + XiCon Loss:2.6244 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 2.9843755
	speed: 0.0142s/iter; left time: 240.8434s
	iters: 200, epoch: 27 | loss: 3.0145440
	speed: 0.0118s/iter; left time: 198.1734s
Epoch: 27 cost time: 2.9942829608917236
Epoch: 27, Steps: 230 Train Loss: 2.9840 (Forecasting Loss:0.3622 + XiCon Loss:2.6217 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3650
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 2.9753406
	speed: 0.0139s/iter; left time: 231.7652s
	iters: 200, epoch: 28 | loss: 2.9711161
	speed: 0.0112s/iter; left time: 185.0611s
Epoch: 28 cost time: 2.878099203109741
Epoch: 28, Steps: 230 Train Loss: 2.9894 (Forecasting Loss:0.3622 + XiCon Loss:2.6271 x Lambda(1.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.3650
Validation loss decreased (0.208087 --> 0.207988).  Saving model ...
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 2.9616425
	speed: 0.0143s/iter; left time: 235.1336s
	iters: 200, epoch: 29 | loss: 2.9238594
	speed: 0.0118s/iter; left time: 192.7272s
Epoch: 29 cost time: 3.0214431285858154
Epoch: 29, Steps: 230 Train Loss: 2.9864 (Forecasting Loss:0.3615 + XiCon Loss:2.6249 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 2.9719033
	speed: 0.0144s/iter; left time: 234.1145s
	iters: 200, epoch: 30 | loss: 3.0750837
	speed: 0.0119s/iter; left time: 192.1142s
Epoch: 30 cost time: 3.0257837772369385
Epoch: 30, Steps: 230 Train Loss: 2.9879 (Forecasting Loss:0.3613 + XiCon Loss:2.6266 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3650
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 3.0439084
	speed: 0.0155s/iter; left time: 248.5021s
	iters: 200, epoch: 31 | loss: 2.9418263
	speed: 0.0130s/iter; left time: 205.9421s
Epoch: 31 cost time: 3.25808048248291
Epoch: 31, Steps: 230 Train Loss: 2.9880 (Forecasting Loss:0.3619 + XiCon Loss:2.6261 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.3650
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 2.9467115
	speed: 0.0145s/iter; left time: 228.5138s
	iters: 200, epoch: 32 | loss: 3.0196648
	speed: 0.0121s/iter; left time: 189.2801s
Epoch: 32 cost time: 3.0481009483337402
Epoch: 32, Steps: 230 Train Loss: 2.9906 (Forecasting Loss:0.3621 + XiCon Loss:2.6285 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 3.0194919
	speed: 0.0136s/iter; left time: 211.4849s
	iters: 200, epoch: 33 | loss: 3.0823915
	speed: 0.0115s/iter; left time: 177.4576s
Epoch: 33 cost time: 2.8866891860961914
Epoch: 33, Steps: 230 Train Loss: 2.9856 (Forecasting Loss:0.3620 + XiCon Loss:2.6236 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 2.9554183
	speed: 0.0145s/iter; left time: 221.8007s
	iters: 200, epoch: 34 | loss: 2.9655743
	speed: 0.0125s/iter; left time: 189.4459s
Epoch: 34 cost time: 3.0986759662628174
Epoch: 34, Steps: 230 Train Loss: 2.9872 (Forecasting Loss:0.3613 + XiCon Loss:2.6259 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 3.0345387
	speed: 0.0138s/iter; left time: 208.0304s
	iters: 200, epoch: 35 | loss: 3.0120370
	speed: 0.0115s/iter; left time: 172.0711s
Epoch: 35 cost time: 2.9078986644744873
Epoch: 35, Steps: 230 Train Loss: 2.9861 (Forecasting Loss:0.3617 + XiCon Loss:2.6244 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 3.0152497
	speed: 0.0138s/iter; left time: 204.9879s
	iters: 200, epoch: 36 | loss: 2.9402392
	speed: 0.0121s/iter; left time: 178.0858s
Epoch: 36 cost time: 2.976726531982422
Epoch: 36, Steps: 230 Train Loss: 2.9850 (Forecasting Loss:0.3619 + XiCon Loss:2.6231 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3650
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 2.9738829
	speed: 0.0138s/iter; left time: 201.6110s
	iters: 200, epoch: 37 | loss: 2.9089844
	speed: 0.0119s/iter; left time: 173.3898s
Epoch: 37 cost time: 2.955660104751587
Epoch: 37, Steps: 230 Train Loss: 2.9890 (Forecasting Loss:0.3619 + XiCon Loss:2.6271 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 2.9829488
	speed: 0.0142s/iter; left time: 204.9998s
	iters: 200, epoch: 38 | loss: 2.9574435
	speed: 0.0124s/iter; left time: 177.3673s
Epoch: 38 cost time: 3.056993246078491
Epoch: 38, Steps: 230 Train Loss: 2.9906 (Forecasting Loss:0.3618 + XiCon Loss:2.6288 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3650
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.316183865070343, mae:0.4139098525047302, mape:3.76605224609375, mspe:18604.369140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5239
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.5875411
	speed: 0.0149s/iter; left time: 342.2828s
	iters: 200, epoch: 1 | loss: 3.4432735
	speed: 0.0123s/iter; left time: 280.4555s
Epoch: 1 cost time: 3.1014955043792725
Epoch: 1, Steps: 230 Train Loss: 3.5802 (Forecasting Loss:0.7428 + XiCon Loss:2.8373 x Lambda(1.0)), Vali MSE Loss: 0.3417 Test MSE Loss: 0.5678
Validation loss decreased (inf --> 0.341746).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1098950
	speed: 0.0134s/iter; left time: 303.9400s
	iters: 200, epoch: 2 | loss: 3.0940881
	speed: 0.0118s/iter; left time: 265.3717s
Epoch: 2 cost time: 2.9209272861480713
Epoch: 2, Steps: 230 Train Loss: 3.1329 (Forecasting Loss:0.4236 + XiCon Loss:2.7093 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.3606
Validation loss decreased (0.341746 --> 0.219436).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0906606
	speed: 0.0151s/iter; left time: 338.1790s
	iters: 200, epoch: 3 | loss: 2.9882183
	speed: 0.0123s/iter; left time: 275.5557s
Epoch: 3 cost time: 3.1526036262512207
Epoch: 3, Steps: 230 Train Loss: 3.0145 (Forecasting Loss:0.3715 + XiCon Loss:2.6430 x Lambda(1.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.3616
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 2.9516559
	speed: 0.0153s/iter; left time: 339.1332s
	iters: 200, epoch: 4 | loss: 2.9435115
	speed: 0.0129s/iter; left time: 285.7402s
Epoch: 4 cost time: 3.2132387161254883
Epoch: 4, Steps: 230 Train Loss: 2.9945 (Forecasting Loss:0.3614 + XiCon Loss:2.6330 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.3634
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 2.9980059
	speed: 0.0150s/iter; left time: 330.3917s
	iters: 200, epoch: 5 | loss: 2.9428692
	speed: 0.0129s/iter; left time: 282.5542s
Epoch: 5 cost time: 3.210963726043701
Epoch: 5, Steps: 230 Train Loss: 2.9823 (Forecasting Loss:0.3569 + XiCon Loss:2.6254 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.3686
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 2.9832621
	speed: 0.0149s/iter; left time: 324.8644s
	iters: 200, epoch: 6 | loss: 3.0185618
	speed: 0.0124s/iter; left time: 267.9675s
Epoch: 6 cost time: 3.1465351581573486
Epoch: 6, Steps: 230 Train Loss: 2.9777 (Forecasting Loss:0.3547 + XiCon Loss:2.6230 x Lambda(1.0)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.3578
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.9188070
	speed: 0.0142s/iter; left time: 305.3063s
	iters: 200, epoch: 7 | loss: 3.0018148
	speed: 0.0125s/iter; left time: 266.9204s
Epoch: 7 cost time: 3.0611228942871094
Epoch: 7, Steps: 230 Train Loss: 2.9703 (Forecasting Loss:0.3538 + XiCon Loss:2.6165 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.3568
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.9871545
	speed: 0.0145s/iter; left time: 307.8935s
	iters: 200, epoch: 8 | loss: 3.0446181
	speed: 0.0126s/iter; left time: 266.3625s
Epoch: 8 cost time: 3.1164863109588623
Epoch: 8, Steps: 230 Train Loss: 2.9755 (Forecasting Loss:0.3536 + XiCon Loss:2.6219 x Lambda(1.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.3582
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 2.9425464
	speed: 0.0148s/iter; left time: 311.0633s
	iters: 200, epoch: 9 | loss: 3.0017433
	speed: 0.0127s/iter; left time: 265.9947s
Epoch: 9 cost time: 3.151118516921997
Epoch: 9, Steps: 230 Train Loss: 2.9716 (Forecasting Loss:0.3531 + XiCon Loss:2.6185 x Lambda(1.0)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.3589
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 2.9886842
	speed: 0.0152s/iter; left time: 316.1622s
	iters: 200, epoch: 10 | loss: 2.9915001
	speed: 0.0126s/iter; left time: 261.4426s
Epoch: 10 cost time: 3.1790971755981445
Epoch: 10, Steps: 230 Train Loss: 2.9714 (Forecasting Loss:0.3531 + XiCon Loss:2.6182 x Lambda(1.0)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.3587
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 2.9249902
	speed: 0.0149s/iter; left time: 307.7260s
	iters: 200, epoch: 11 | loss: 2.9784462
	speed: 0.0126s/iter; left time: 257.9261s
Epoch: 11 cost time: 3.1697587966918945
Epoch: 11, Steps: 230 Train Loss: 2.9707 (Forecasting Loss:0.3531 + XiCon Loss:2.6176 x Lambda(1.0)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.3589
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 2.9049368
	speed: 0.0149s/iter; left time: 303.3301s
	iters: 200, epoch: 12 | loss: 2.9786429
	speed: 0.0125s/iter; left time: 253.7452s
Epoch: 12 cost time: 3.1392338275909424
Epoch: 12, Steps: 230 Train Loss: 2.9699 (Forecasting Loss:0.3528 + XiCon Loss:2.6170 x Lambda(1.0)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.3589
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3091486394405365, mae:0.41214728355407715, mape:3.5500729084014893, mspe:14026.087890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4157
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6077418
	speed: 0.0150s/iter; left time: 342.3912s
	iters: 200, epoch: 1 | loss: 3.3292382
	speed: 0.0116s/iter; left time: 264.8484s
Epoch: 1 cost time: 3.0352365970611572
Epoch: 1, Steps: 230 Train Loss: 3.5457 (Forecasting Loss:0.7264 + XiCon Loss:2.8193 x Lambda(1.0)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.5239
Validation loss decreased (inf --> 0.328214).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1269622
	speed: 0.0143s/iter; left time: 324.4138s
	iters: 200, epoch: 2 | loss: 3.0757174
	speed: 0.0117s/iter; left time: 264.0848s
Epoch: 2 cost time: 2.964738607406616
Epoch: 2, Steps: 230 Train Loss: 3.1065 (Forecasting Loss:0.4065 + XiCon Loss:2.7000 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.3800
Validation loss decreased (0.328214 --> 0.213359).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0166953
	speed: 0.0137s/iter; left time: 307.4495s
	iters: 200, epoch: 3 | loss: 2.9216325
	speed: 0.0116s/iter; left time: 259.0751s
Epoch: 3 cost time: 2.9149723052978516
Epoch: 3, Steps: 230 Train Loss: 2.9951 (Forecasting Loss:0.3678 + XiCon Loss:2.6273 x Lambda(1.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.3736
Validation loss decreased (0.213359 --> 0.207041).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 2.9604514
	speed: 0.0142s/iter; left time: 315.6849s
	iters: 200, epoch: 4 | loss: 2.9504421
	speed: 0.0117s/iter; left time: 258.2428s
Epoch: 4 cost time: 2.9465854167938232
Epoch: 4, Steps: 230 Train Loss: 2.9602 (Forecasting Loss:0.3604 + XiCon Loss:2.5998 x Lambda(1.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3679
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 2.9975901
	speed: 0.0140s/iter; left time: 308.2179s
	iters: 200, epoch: 5 | loss: 3.0256643
	speed: 0.0117s/iter; left time: 257.0974s
Epoch: 5 cost time: 2.969435930252075
Epoch: 5, Steps: 230 Train Loss: 2.9533 (Forecasting Loss:0.3571 + XiCon Loss:2.5962 x Lambda(1.0)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.3718
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 2.9277339
	speed: 0.0146s/iter; left time: 317.0349s
	iters: 200, epoch: 6 | loss: 3.0047617
	speed: 0.0116s/iter; left time: 250.8808s
Epoch: 6 cost time: 2.9674534797668457
Epoch: 6, Steps: 230 Train Loss: 2.9465 (Forecasting Loss:0.3555 + XiCon Loss:2.5910 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3685
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.9843636
	speed: 0.0145s/iter; left time: 311.2814s
	iters: 200, epoch: 7 | loss: 2.9473934
	speed: 0.0120s/iter; left time: 258.0082s
Epoch: 7 cost time: 3.0293121337890625
Epoch: 7, Steps: 230 Train Loss: 2.9482 (Forecasting Loss:0.3552 + XiCon Loss:2.5929 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3719
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.9306479
	speed: 0.0143s/iter; left time: 305.2230s
	iters: 200, epoch: 8 | loss: 2.9766996
	speed: 0.0121s/iter; left time: 255.8196s
Epoch: 8 cost time: 3.019447088241577
Epoch: 8, Steps: 230 Train Loss: 2.9455 (Forecasting Loss:0.3543 + XiCon Loss:2.5911 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3721
Validation loss decreased (0.207041 --> 0.206847).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 2.9202003
	speed: 0.0139s/iter; left time: 293.4246s
	iters: 200, epoch: 9 | loss: 2.9089622
	speed: 0.0118s/iter; left time: 248.2865s
Epoch: 9 cost time: 2.95216965675354
Epoch: 9, Steps: 230 Train Loss: 2.9449 (Forecasting Loss:0.3541 + XiCon Loss:2.5908 x Lambda(1.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.3711
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 2.9158967
	speed: 0.0148s/iter; left time: 309.1164s
	iters: 200, epoch: 10 | loss: 2.9855912
	speed: 0.0114s/iter; left time: 236.3186s
Epoch: 10 cost time: 2.9965672492980957
Epoch: 10, Steps: 230 Train Loss: 2.9467 (Forecasting Loss:0.3538 + XiCon Loss:2.5928 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.3713
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 2.8980246
	speed: 0.0144s/iter; left time: 296.5081s
	iters: 200, epoch: 11 | loss: 2.8828912
	speed: 0.0122s/iter; left time: 249.1419s
Epoch: 11 cost time: 3.009453535079956
Epoch: 11, Steps: 230 Train Loss: 2.9451 (Forecasting Loss:0.3539 + XiCon Loss:2.5911 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3713
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 2.9866629
	speed: 0.0145s/iter; left time: 294.4871s
	iters: 200, epoch: 12 | loss: 2.9682617
	speed: 0.0119s/iter; left time: 240.6580s
Epoch: 12 cost time: 3.02693510055542
Epoch: 12, Steps: 230 Train Loss: 2.9459 (Forecasting Loss:0.3539 + XiCon Loss:2.5920 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.3711
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 2.9711671
	speed: 0.0145s/iter; left time: 292.1248s
	iters: 200, epoch: 13 | loss: 2.9593654
	speed: 0.0124s/iter; left time: 247.8470s
Epoch: 13 cost time: 3.10587215423584
Epoch: 13, Steps: 230 Train Loss: 2.9466 (Forecasting Loss:0.3537 + XiCon Loss:2.5930 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.3711
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 2.9707749
	speed: 0.0140s/iter; left time: 278.9247s
	iters: 200, epoch: 14 | loss: 2.9695945
	speed: 0.0123s/iter; left time: 243.6011s
Epoch: 14 cost time: 3.011580228805542
Epoch: 14, Steps: 230 Train Loss: 2.9437 (Forecasting Loss:0.3538 + XiCon Loss:2.5899 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3712
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 2.9229496
	speed: 0.0142s/iter; left time: 279.0106s
	iters: 200, epoch: 15 | loss: 2.9460106
	speed: 0.0118s/iter; left time: 231.3430s
Epoch: 15 cost time: 2.992997169494629
Epoch: 15, Steps: 230 Train Loss: 2.9469 (Forecasting Loss:0.3543 + XiCon Loss:2.5926 x Lambda(1.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.3712
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.0018392
	speed: 0.0140s/iter; left time: 271.8445s
	iters: 200, epoch: 16 | loss: 2.9186265
	speed: 0.0120s/iter; left time: 231.3087s
Epoch: 16 cost time: 2.9744350910186768
Epoch: 16, Steps: 230 Train Loss: 2.9460 (Forecasting Loss:0.3537 + XiCon Loss:2.5923 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3712
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 2.9183533
	speed: 0.0139s/iter; left time: 266.8966s
	iters: 200, epoch: 17 | loss: 2.9906058
	speed: 0.0114s/iter; left time: 217.8281s
Epoch: 17 cost time: 2.900566339492798
Epoch: 17, Steps: 230 Train Loss: 2.9479 (Forecasting Loss:0.3540 + XiCon Loss:2.5939 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3712
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 2.9180603
	speed: 0.0142s/iter; left time: 270.4749s
	iters: 200, epoch: 18 | loss: 2.9169159
	speed: 0.0121s/iter; left time: 229.1942s
Epoch: 18 cost time: 3.016192674636841
Epoch: 18, Steps: 230 Train Loss: 2.9451 (Forecasting Loss:0.3538 + XiCon Loss:2.5913 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3712
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3237030506134033, mae:0.4205503761768341, mape:4.166853427886963, mspe:24263.359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3099+-0.01420, MAE:0.4106+-0.01006, MAPE:3.9606+-0.36692, MSPE:22202.5352+-7185.88485, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4795
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.5690448
	speed: 0.0230s/iter; left time: 499.5407s
	iters: 200, epoch: 1 | loss: 3.6597540
	speed: 0.0176s/iter; left time: 381.0182s
Epoch: 1 cost time: 4.410226345062256
Epoch: 1, Steps: 218 Train Loss: 3.6717 (Forecasting Loss:0.8373 + XiCon Loss:2.8344 x Lambda(1.0)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.6849
Validation loss decreased (inf --> 0.336284).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1431489
	speed: 0.0202s/iter; left time: 434.3708s
	iters: 200, epoch: 2 | loss: 3.1289861
	speed: 0.0174s/iter; left time: 371.7009s
Epoch: 2 cost time: 4.102059841156006
Epoch: 2, Steps: 218 Train Loss: 3.2003 (Forecasting Loss:0.4987 + XiCon Loss:2.7016 x Lambda(1.0)), Vali MSE Loss: 0.2148 Test MSE Loss: 0.4228
Validation loss decreased (0.336284 --> 0.214817).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0376930
	speed: 0.0200s/iter; left time: 424.8168s
	iters: 200, epoch: 3 | loss: 3.0054994
	speed: 0.0178s/iter; left time: 376.5927s
Epoch: 3 cost time: 4.126499176025391
Epoch: 3, Steps: 218 Train Loss: 3.0702 (Forecasting Loss:0.4230 + XiCon Loss:2.6472 x Lambda(1.0)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.4304
Validation loss decreased (0.214817 --> 0.212120).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.0878782
	speed: 0.0209s/iter; left time: 440.8395s
	iters: 200, epoch: 4 | loss: 2.9862978
	speed: 0.0184s/iter; left time: 385.5509s
Epoch: 4 cost time: 4.3129377365112305
Epoch: 4, Steps: 218 Train Loss: 3.0309 (Forecasting Loss:0.4000 + XiCon Loss:2.6309 x Lambda(1.0)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.4189
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.0597680
	speed: 0.0202s/iter; left time: 420.4353s
	iters: 200, epoch: 5 | loss: 3.0286925
	speed: 0.0177s/iter; left time: 367.5350s
Epoch: 5 cost time: 4.140574216842651
Epoch: 5, Steps: 218 Train Loss: 3.0098 (Forecasting Loss:0.3909 + XiCon Loss:2.6189 x Lambda(1.0)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.4110
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 2.9676688
	speed: 0.0198s/iter; left time: 407.3498s
	iters: 200, epoch: 6 | loss: 3.0092969
	speed: 0.0177s/iter; left time: 362.2340s
Epoch: 6 cost time: 4.10236382484436
Epoch: 6, Steps: 218 Train Loss: 2.9956 (Forecasting Loss:0.3864 + XiCon Loss:2.6092 x Lambda(1.0)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.4173
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 2.9530504
	speed: 0.0198s/iter; left time: 403.0637s
	iters: 200, epoch: 7 | loss: 2.9451072
	speed: 0.0179s/iter; left time: 363.0127s
Epoch: 7 cost time: 4.114521503448486
Epoch: 7, Steps: 218 Train Loss: 2.9921 (Forecasting Loss:0.3843 + XiCon Loss:2.6078 x Lambda(1.0)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.4098
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.9807398
	speed: 0.0202s/iter; left time: 407.8084s
	iters: 200, epoch: 8 | loss: 3.0004046
	speed: 0.0177s/iter; left time: 354.9494s
Epoch: 8 cost time: 4.138290882110596
Epoch: 8, Steps: 218 Train Loss: 2.9887 (Forecasting Loss:0.3828 + XiCon Loss:2.6058 x Lambda(1.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.4147
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 2.9290187
	speed: 0.0201s/iter; left time: 401.7567s
	iters: 200, epoch: 9 | loss: 2.9697320
	speed: 0.0177s/iter; left time: 350.9329s
Epoch: 9 cost time: 4.130814552307129
Epoch: 9, Steps: 218 Train Loss: 2.9889 (Forecasting Loss:0.3825 + XiCon Loss:2.6063 x Lambda(1.0)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.4096
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0309854
	speed: 0.0203s/iter; left time: 399.8758s
	iters: 200, epoch: 10 | loss: 3.0425074
	speed: 0.0180s/iter; left time: 354.0140s
Epoch: 10 cost time: 4.184993743896484
Epoch: 10, Steps: 218 Train Loss: 2.9859 (Forecasting Loss:0.3821 + XiCon Loss:2.6039 x Lambda(1.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.4112
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0216076
	speed: 0.0202s/iter; left time: 393.5156s
	iters: 200, epoch: 11 | loss: 3.0000396
	speed: 0.0181s/iter; left time: 351.9239s
Epoch: 11 cost time: 4.181715726852417
Epoch: 11, Steps: 218 Train Loss: 2.9907 (Forecasting Loss:0.3817 + XiCon Loss:2.6090 x Lambda(1.0)), Vali MSE Loss: 0.2277 Test MSE Loss: 0.4106
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0101008
	speed: 0.0201s/iter; left time: 388.3284s
	iters: 200, epoch: 12 | loss: 2.9620569
	speed: 0.0184s/iter; left time: 352.9685s
Epoch: 12 cost time: 4.219698190689087
Epoch: 12, Steps: 218 Train Loss: 2.9871 (Forecasting Loss:0.3819 + XiCon Loss:2.6052 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.4108
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 2.9979496
	speed: 0.0197s/iter; left time: 375.8982s
	iters: 200, epoch: 13 | loss: 2.9977040
	speed: 0.0184s/iter; left time: 348.5592s
Epoch: 13 cost time: 4.160650253295898
Epoch: 13, Steps: 218 Train Loss: 2.9861 (Forecasting Loss:0.3815 + XiCon Loss:2.6046 x Lambda(1.0)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.4108
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.38463133573532104, mae:0.47618037462234497, mape:6.267561912536621, mspe:111062.2265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5714
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.6469054
	speed: 0.0211s/iter; left time: 456.9999s
	iters: 200, epoch: 1 | loss: 3.5192673
	speed: 0.0181s/iter; left time: 389.9251s
Epoch: 1 cost time: 4.284300327301025
Epoch: 1, Steps: 218 Train Loss: 3.6494 (Forecasting Loss:0.8367 + XiCon Loss:2.8127 x Lambda(1.0)), Vali MSE Loss: 0.3328 Test MSE Loss: 0.6594
Validation loss decreased (inf --> 0.332839).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1105340
	speed: 0.0204s/iter; left time: 438.5392s
	iters: 200, epoch: 2 | loss: 3.1174374
	speed: 0.0182s/iter; left time: 389.2999s
Epoch: 2 cost time: 4.234703302383423
Epoch: 2, Steps: 218 Train Loss: 3.1933 (Forecasting Loss:0.4738 + XiCon Loss:2.7195 x Lambda(1.0)), Vali MSE Loss: 0.2215 Test MSE Loss: 0.5395
Validation loss decreased (0.332839 --> 0.221511).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1114814
	speed: 0.0201s/iter; left time: 428.0830s
	iters: 200, epoch: 3 | loss: 3.1163821
	speed: 0.0179s/iter; left time: 378.0569s
Epoch: 3 cost time: 4.145680665969849
Epoch: 3, Steps: 218 Train Loss: 3.1326 (Forecasting Loss:0.4121 + XiCon Loss:2.7205 x Lambda(1.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.4144
Validation loss decreased (0.221511 --> 0.220267).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.0834022
	speed: 0.0204s/iter; left time: 429.4557s
	iters: 200, epoch: 4 | loss: 3.1352177
	speed: 0.0178s/iter; left time: 372.3531s
Epoch: 4 cost time: 4.1734983921051025
Epoch: 4, Steps: 218 Train Loss: 3.1441 (Forecasting Loss:0.3954 + XiCon Loss:2.7487 x Lambda(1.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.3985
Validation loss decreased (0.220267 --> 0.216588).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1692247
	speed: 0.0205s/iter; left time: 427.3253s
	iters: 200, epoch: 5 | loss: 3.1969323
	speed: 0.0181s/iter; left time: 374.9946s
Epoch: 5 cost time: 4.216856002807617
Epoch: 5, Steps: 218 Train Loss: 3.1387 (Forecasting Loss:0.3827 + XiCon Loss:2.7561 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.3995
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.0554845
	speed: 0.0204s/iter; left time: 421.4793s
	iters: 200, epoch: 6 | loss: 3.0084009
	speed: 0.0180s/iter; left time: 369.8265s
Epoch: 6 cost time: 4.1950523853302
Epoch: 6, Steps: 218 Train Loss: 3.1349 (Forecasting Loss:0.3782 + XiCon Loss:2.7567 x Lambda(1.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.3928
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1179290
	speed: 0.0199s/iter; left time: 405.9976s
	iters: 200, epoch: 7 | loss: 3.0371730
	speed: 0.0181s/iter; left time: 366.8540s
Epoch: 7 cost time: 4.1553497314453125
Epoch: 7, Steps: 218 Train Loss: 3.1282 (Forecasting Loss:0.3760 + XiCon Loss:2.7522 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3958
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2040675
	speed: 0.0201s/iter; left time: 406.3533s
	iters: 200, epoch: 8 | loss: 3.0720813
	speed: 0.0181s/iter; left time: 362.5175s
Epoch: 8 cost time: 4.1759843826293945
Epoch: 8, Steps: 218 Train Loss: 3.1288 (Forecasting Loss:0.3749 + XiCon Loss:2.7540 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.3937
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1610234
	speed: 0.0202s/iter; left time: 403.8159s
	iters: 200, epoch: 9 | loss: 3.0971084
	speed: 0.0179s/iter; left time: 355.5989s
Epoch: 9 cost time: 4.168557405471802
Epoch: 9, Steps: 218 Train Loss: 3.1264 (Forecasting Loss:0.3742 + XiCon Loss:2.7523 x Lambda(1.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.3942
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1005397
	speed: 0.0204s/iter; left time: 403.6255s
	iters: 200, epoch: 10 | loss: 3.0805907
	speed: 0.0182s/iter; left time: 356.9043s
Epoch: 10 cost time: 4.232916355133057
Epoch: 10, Steps: 218 Train Loss: 3.1266 (Forecasting Loss:0.3735 + XiCon Loss:2.7531 x Lambda(1.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.3945
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1577725
	speed: 0.0205s/iter; left time: 400.1031s
	iters: 200, epoch: 11 | loss: 3.1440380
	speed: 0.0184s/iter; left time: 357.5060s
Epoch: 11 cost time: 4.238023996353149
Epoch: 11, Steps: 218 Train Loss: 3.1283 (Forecasting Loss:0.3740 + XiCon Loss:2.7544 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.3940
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1156931
	speed: 0.0205s/iter; left time: 396.0846s
	iters: 200, epoch: 12 | loss: 3.1393890
	speed: 0.0183s/iter; left time: 352.2628s
Epoch: 12 cost time: 4.2308571338653564
Epoch: 12, Steps: 218 Train Loss: 3.1314 (Forecasting Loss:0.3736 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.3943
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1981535
	speed: 0.0206s/iter; left time: 392.7396s
	iters: 200, epoch: 13 | loss: 3.1973181
	speed: 0.0178s/iter; left time: 338.6635s
Epoch: 13 cost time: 4.196439743041992
Epoch: 13, Steps: 218 Train Loss: 3.1290 (Forecasting Loss:0.3737 + XiCon Loss:2.7554 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3943
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.0265415
	speed: 0.0200s/iter; left time: 377.3929s
	iters: 200, epoch: 14 | loss: 3.0941253
	speed: 0.0179s/iter; left time: 336.6000s
Epoch: 14 cost time: 4.1406168937683105
Epoch: 14, Steps: 218 Train Loss: 3.1314 (Forecasting Loss:0.3738 + XiCon Loss:2.7576 x Lambda(1.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.3942
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.34943848848342896, mae:0.4474864602088928, mape:5.38855504989624, mspe:73853.453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4462
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.5430610
	speed: 0.0207s/iter; left time: 448.5887s
	iters: 200, epoch: 1 | loss: 3.4776387
	speed: 0.0178s/iter; left time: 384.9562s
Epoch: 1 cost time: 4.194401025772095
Epoch: 1, Steps: 218 Train Loss: 3.6539 (Forecasting Loss:0.8398 + XiCon Loss:2.8141 x Lambda(1.0)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.6816
Validation loss decreased (inf --> 0.336977).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1624315
	speed: 0.0205s/iter; left time: 440.5942s
	iters: 200, epoch: 2 | loss: 3.1784427
	speed: 0.0190s/iter; left time: 406.5590s
Epoch: 2 cost time: 4.366302967071533
Epoch: 2, Steps: 218 Train Loss: 3.1859 (Forecasting Loss:0.4904 + XiCon Loss:2.6955 x Lambda(1.0)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.4662
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0448337
	speed: 0.0247s/iter; left time: 525.9735s
	iters: 200, epoch: 3 | loss: 3.1447444
	speed: 0.0228s/iter; left time: 483.4136s
Epoch: 3 cost time: 5.2196550369262695
Epoch: 3, Steps: 218 Train Loss: 3.1091 (Forecasting Loss:0.3881 + XiCon Loss:2.7210 x Lambda(1.0)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.7594
Validation loss decreased (0.336977 --> 0.299137).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1081176
	speed: 0.0260s/iter; left time: 546.9973s
	iters: 200, epoch: 4 | loss: 3.0074239
	speed: 0.0239s/iter; left time: 500.6937s
Epoch: 4 cost time: 5.4625654220581055
Epoch: 4, Steps: 218 Train Loss: 3.1008 (Forecasting Loss:0.3733 + XiCon Loss:2.7275 x Lambda(1.0)), Vali MSE Loss: 0.2769 Test MSE Loss: 0.7382
Validation loss decreased (0.299137 --> 0.276865).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.0812058
	speed: 0.0269s/iter; left time: 560.6490s
	iters: 200, epoch: 5 | loss: 3.1398427
	speed: 0.0247s/iter; left time: 511.2528s
Epoch: 5 cost time: 5.643948078155518
Epoch: 5, Steps: 218 Train Loss: 3.0986 (Forecasting Loss:0.3677 + XiCon Loss:2.7308 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.7033
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1464076
	speed: 0.0267s/iter; left time: 550.9065s
	iters: 200, epoch: 6 | loss: 3.0878992
	speed: 0.0242s/iter; left time: 495.6832s
Epoch: 6 cost time: 5.560391426086426
Epoch: 6, Steps: 218 Train Loss: 3.0921 (Forecasting Loss:0.3654 + XiCon Loss:2.7267 x Lambda(1.0)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.7223
Validation loss decreased (0.276865 --> 0.258670).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0556040
	speed: 0.0267s/iter; left time: 544.7783s
	iters: 200, epoch: 7 | loss: 2.9664612
	speed: 0.0240s/iter; left time: 486.0857s
Epoch: 7 cost time: 5.540717601776123
Epoch: 7, Steps: 218 Train Loss: 3.0970 (Forecasting Loss:0.3640 + XiCon Loss:2.7330 x Lambda(1.0)), Vali MSE Loss: 0.2763 Test MSE Loss: 0.7007
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1664205
	speed: 0.0272s/iter; left time: 548.0249s
	iters: 200, epoch: 8 | loss: 3.1444654
	speed: 0.0240s/iter; left time: 480.8328s
Epoch: 8 cost time: 5.577487230300903
Epoch: 8, Steps: 218 Train Loss: 3.0896 (Forecasting Loss:0.3639 + XiCon Loss:2.7257 x Lambda(1.0)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.7085
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0475802
	speed: 0.0263s/iter; left time: 525.4305s
	iters: 200, epoch: 9 | loss: 3.0668218
	speed: 0.0244s/iter; left time: 483.5961s
Epoch: 9 cost time: 5.536876440048218
Epoch: 9, Steps: 218 Train Loss: 3.0929 (Forecasting Loss:0.3631 + XiCon Loss:2.7299 x Lambda(1.0)), Vali MSE Loss: 0.2680 Test MSE Loss: 0.7065
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0977731
	speed: 0.0268s/iter; left time: 528.8038s
	iters: 200, epoch: 10 | loss: 3.0198364
	speed: 0.0247s/iter; left time: 485.2673s
Epoch: 10 cost time: 5.6438610553741455
Epoch: 10, Steps: 218 Train Loss: 3.0889 (Forecasting Loss:0.3635 + XiCon Loss:2.7255 x Lambda(1.0)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.7055
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0690055
	speed: 0.0265s/iter; left time: 518.2168s
	iters: 200, epoch: 11 | loss: 3.2871556
	speed: 0.0242s/iter; left time: 469.0463s
Epoch: 11 cost time: 5.544273853302002
Epoch: 11, Steps: 218 Train Loss: 3.0892 (Forecasting Loss:0.3631 + XiCon Loss:2.7261 x Lambda(1.0)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.7033
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1172891
	speed: 0.0263s/iter; left time: 507.2886s
	iters: 200, epoch: 12 | loss: 3.0417376
	speed: 0.0241s/iter; left time: 463.2635s
Epoch: 12 cost time: 5.509740352630615
Epoch: 12, Steps: 218 Train Loss: 3.0943 (Forecasting Loss:0.3632 + XiCon Loss:2.7312 x Lambda(1.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.7042
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1099925
	speed: 0.0263s/iter; left time: 502.1180s
	iters: 200, epoch: 13 | loss: 3.0336165
	speed: 0.0241s/iter; left time: 457.3510s
Epoch: 13 cost time: 5.512405872344971
Epoch: 13, Steps: 218 Train Loss: 3.0996 (Forecasting Loss:0.3635 + XiCon Loss:2.7361 x Lambda(1.0)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.7050
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2101853
	speed: 0.0265s/iter; left time: 500.5039s
	iters: 200, epoch: 14 | loss: 3.1104512
	speed: 0.0245s/iter; left time: 459.3560s
Epoch: 14 cost time: 5.587402105331421
Epoch: 14, Steps: 218 Train Loss: 3.0915 (Forecasting Loss:0.3634 + XiCon Loss:2.7281 x Lambda(1.0)), Vali MSE Loss: 0.2660 Test MSE Loss: 0.7052
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 2.9816768
	speed: 0.0267s/iter; left time: 497.0493s
	iters: 200, epoch: 15 | loss: 3.0720625
	speed: 0.0243s/iter; left time: 449.9170s
Epoch: 15 cost time: 5.55267596244812
Epoch: 15, Steps: 218 Train Loss: 3.0879 (Forecasting Loss:0.3633 + XiCon Loss:2.7246 x Lambda(1.0)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.7048
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1112735
	speed: 0.0269s/iter; left time: 494.9954s
	iters: 200, epoch: 16 | loss: 3.0552351
	speed: 0.0246s/iter; left time: 451.1928s
Epoch: 16 cost time: 5.6225502490997314
Epoch: 16, Steps: 218 Train Loss: 3.0896 (Forecasting Loss:0.3632 + XiCon Loss:2.7264 x Lambda(1.0)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.7047
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.7548039555549622, mae:0.6897783875465393, mape:4.932823181152344, mspe:21601.04296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3114
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.6318221
	speed: 0.0209s/iter; left time: 453.2755s
	iters: 200, epoch: 1 | loss: 3.5278437
	speed: 0.0178s/iter; left time: 384.7083s
Epoch: 1 cost time: 4.221790313720703
Epoch: 1, Steps: 218 Train Loss: 3.6595 (Forecasting Loss:0.8423 + XiCon Loss:2.8172 x Lambda(1.0)), Vali MSE Loss: 0.3345 Test MSE Loss: 0.6685
Validation loss decreased (inf --> 0.334526).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1227915
	speed: 0.0200s/iter; left time: 430.2450s
	iters: 200, epoch: 2 | loss: 3.1359951
	speed: 0.0181s/iter; left time: 387.6863s
Epoch: 2 cost time: 4.170674562454224
Epoch: 2, Steps: 218 Train Loss: 3.1702 (Forecasting Loss:0.4756 + XiCon Loss:2.6946 x Lambda(1.0)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.4479
Validation loss decreased (0.334526 --> 0.221157).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.0474482
	speed: 0.0206s/iter; left time: 437.4600s
	iters: 200, epoch: 3 | loss: 3.0286725
	speed: 0.0179s/iter; left time: 379.0378s
Epoch: 3 cost time: 4.206310272216797
Epoch: 3, Steps: 218 Train Loss: 3.0601 (Forecasting Loss:0.4171 + XiCon Loss:2.6430 x Lambda(1.0)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.4381
Validation loss decreased (0.221157 --> 0.216478).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 2.9929507
	speed: 0.0206s/iter; left time: 433.4349s
	iters: 200, epoch: 4 | loss: 3.0472279
	speed: 0.0175s/iter; left time: 366.5008s
Epoch: 4 cost time: 4.161694288253784
Epoch: 4, Steps: 218 Train Loss: 3.0388 (Forecasting Loss:0.4028 + XiCon Loss:2.6360 x Lambda(1.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.4450
Validation loss decreased (0.216478 --> 0.216288).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.0206931
	speed: 0.0203s/iter; left time: 423.1221s
	iters: 200, epoch: 5 | loss: 3.0743270
	speed: 0.0176s/iter; left time: 364.5319s
Epoch: 5 cost time: 4.14021635055542
Epoch: 5, Steps: 218 Train Loss: 3.0271 (Forecasting Loss:0.3958 + XiCon Loss:2.6313 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.4309
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.0901108
	speed: 0.0205s/iter; left time: 421.6352s
	iters: 200, epoch: 6 | loss: 3.0165877
	speed: 0.0177s/iter; left time: 362.3850s
Epoch: 6 cost time: 4.1700050830841064
Epoch: 6, Steps: 218 Train Loss: 3.0281 (Forecasting Loss:0.3921 + XiCon Loss:2.6360 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.4321
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0371008
	speed: 0.0204s/iter; left time: 416.6237s
	iters: 200, epoch: 7 | loss: 3.0263674
	speed: 0.0180s/iter; left time: 365.8533s
Epoch: 7 cost time: 4.198282241821289
Epoch: 7, Steps: 218 Train Loss: 3.0228 (Forecasting Loss:0.3895 + XiCon Loss:2.6332 x Lambda(1.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.4277
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 2.9982963
	speed: 0.0201s/iter; left time: 406.0285s
	iters: 200, epoch: 8 | loss: 3.0606604
	speed: 0.0181s/iter; left time: 363.9226s
Epoch: 8 cost time: 4.177748918533325
Epoch: 8, Steps: 218 Train Loss: 3.0195 (Forecasting Loss:0.3885 + XiCon Loss:2.6310 x Lambda(1.0)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.4283
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0086262
	speed: 0.0202s/iter; left time: 402.6887s
	iters: 200, epoch: 9 | loss: 3.0534382
	speed: 0.0179s/iter; left time: 356.0660s
Epoch: 9 cost time: 4.1698009967803955
Epoch: 9, Steps: 218 Train Loss: 3.0175 (Forecasting Loss:0.3882 + XiCon Loss:2.6293 x Lambda(1.0)), Vali MSE Loss: 0.2217 Test MSE Loss: 0.4284
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 2.9997652
	speed: 0.0205s/iter; left time: 405.0925s
	iters: 200, epoch: 10 | loss: 3.0340285
	speed: 0.0182s/iter; left time: 357.9937s
Epoch: 10 cost time: 4.2190611362457275
Epoch: 10, Steps: 218 Train Loss: 3.0175 (Forecasting Loss:0.3875 + XiCon Loss:2.6299 x Lambda(1.0)), Vali MSE Loss: 0.2217 Test MSE Loss: 0.4284
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0146742
	speed: 0.0204s/iter; left time: 397.5734s
	iters: 200, epoch: 11 | loss: 3.0127668
	speed: 0.0179s/iter; left time: 348.5035s
Epoch: 11 cost time: 4.19640851020813
Epoch: 11, Steps: 218 Train Loss: 3.0230 (Forecasting Loss:0.3879 + XiCon Loss:2.6351 x Lambda(1.0)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.4287
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0138302
	speed: 0.0204s/iter; left time: 393.0967s
	iters: 200, epoch: 12 | loss: 3.0012085
	speed: 0.0182s/iter; left time: 349.4908s
Epoch: 12 cost time: 4.229359149932861
Epoch: 12, Steps: 218 Train Loss: 3.0193 (Forecasting Loss:0.3878 + XiCon Loss:2.6315 x Lambda(1.0)), Vali MSE Loss: 0.2215 Test MSE Loss: 0.4286
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.0574827
	speed: 0.0202s/iter; left time: 385.5106s
	iters: 200, epoch: 13 | loss: 2.9951706
	speed: 0.0183s/iter; left time: 347.2980s
Epoch: 13 cost time: 4.213866949081421
Epoch: 13, Steps: 218 Train Loss: 3.0186 (Forecasting Loss:0.3876 + XiCon Loss:2.6310 x Lambda(1.0)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.4285
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 2.9999330
	speed: 0.0205s/iter; left time: 387.3464s
	iters: 200, epoch: 14 | loss: 3.0076873
	speed: 0.0179s/iter; left time: 335.5793s
Epoch: 14 cost time: 4.199387311935425
Epoch: 14, Steps: 218 Train Loss: 3.0183 (Forecasting Loss:0.3874 + XiCon Loss:2.6309 x Lambda(1.0)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.4285
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.40405189990997314, mae:0.4858929514884949, mape:6.192666530609131, mspe:103963.1796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3450
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.6974154
	speed: 0.0209s/iter; left time: 453.9576s
	iters: 200, epoch: 1 | loss: 3.6197791
	speed: 0.0182s/iter; left time: 392.8072s
Epoch: 1 cost time: 4.276191234588623
Epoch: 1, Steps: 218 Train Loss: 3.6571 (Forecasting Loss:0.8342 + XiCon Loss:2.8229 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.6596
Validation loss decreased (inf --> 0.332937).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2341118
	speed: 0.0209s/iter; left time: 449.0492s
	iters: 200, epoch: 2 | loss: 3.0367904
	speed: 0.0181s/iter; left time: 386.0992s
Epoch: 2 cost time: 4.2520482540130615
Epoch: 2, Steps: 218 Train Loss: 3.2024 (Forecasting Loss:0.5120 + XiCon Loss:2.6904 x Lambda(1.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.4435
Validation loss decreased (0.332937 --> 0.225809).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2129798
	speed: 0.0200s/iter; left time: 424.7397s
	iters: 200, epoch: 3 | loss: 3.1993561
	speed: 0.0180s/iter; left time: 380.6297s
Epoch: 3 cost time: 4.1804890632629395
Epoch: 3, Steps: 218 Train Loss: 3.1275 (Forecasting Loss:0.4277 + XiCon Loss:2.6998 x Lambda(1.0)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.4018
Validation loss decreased (0.225809 --> 0.217694).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2015495
	speed: 0.0202s/iter; left time: 425.4352s
	iters: 200, epoch: 4 | loss: 3.2184477
	speed: 0.0175s/iter; left time: 365.6052s
Epoch: 4 cost time: 4.117753505706787
Epoch: 4, Steps: 218 Train Loss: 3.1612 (Forecasting Loss:0.4211 + XiCon Loss:2.7401 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.3872
Validation loss decreased (0.217694 --> 0.214185).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1209474
	speed: 0.0202s/iter; left time: 420.4031s
	iters: 200, epoch: 5 | loss: 3.0652387
	speed: 0.0180s/iter; left time: 373.5150s
Epoch: 5 cost time: 4.169426202774048
Epoch: 5, Steps: 218 Train Loss: 3.1567 (Forecasting Loss:0.4173 + XiCon Loss:2.7393 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3934
Validation loss decreased (0.214185 --> 0.213293).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1312287
	speed: 0.0202s/iter; left time: 417.2933s
	iters: 200, epoch: 6 | loss: 3.1679869
	speed: 0.0182s/iter; left time: 372.2832s
Epoch: 6 cost time: 4.195101976394653
Epoch: 6, Steps: 218 Train Loss: 3.1571 (Forecasting Loss:0.4147 + XiCon Loss:2.7424 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.3888
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1371145
	speed: 0.0205s/iter; left time: 417.0898s
	iters: 200, epoch: 7 | loss: 3.1213751
	speed: 0.0177s/iter; left time: 358.6892s
Epoch: 7 cost time: 4.168490171432495
Epoch: 7, Steps: 218 Train Loss: 3.1536 (Forecasting Loss:0.4132 + XiCon Loss:2.7403 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.3912
Validation loss decreased (0.213293 --> 0.212695).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.0809269
	speed: 0.0205s/iter; left time: 412.9504s
	iters: 200, epoch: 8 | loss: 3.2161736
	speed: 0.0178s/iter; left time: 357.3528s
Epoch: 8 cost time: 4.176072120666504
Epoch: 8, Steps: 218 Train Loss: 3.1570 (Forecasting Loss:0.4124 + XiCon Loss:2.7446 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.3904
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0161693
	speed: 0.0206s/iter; left time: 410.3630s
	iters: 200, epoch: 9 | loss: 3.1999490
	speed: 0.0180s/iter; left time: 356.9529s
Epoch: 9 cost time: 4.20658016204834
Epoch: 9, Steps: 218 Train Loss: 3.1565 (Forecasting Loss:0.4125 + XiCon Loss:2.7440 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.3901
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1742883
	speed: 0.0204s/iter; left time: 402.1978s
	iters: 200, epoch: 10 | loss: 3.2735376
	speed: 0.0181s/iter; left time: 355.3605s
Epoch: 10 cost time: 4.200785875320435
Epoch: 10, Steps: 218 Train Loss: 3.1511 (Forecasting Loss:0.4124 + XiCon Loss:2.7387 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.3907
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1065602
	speed: 0.0202s/iter; left time: 395.2311s
	iters: 200, epoch: 11 | loss: 3.1810746
	speed: 0.0179s/iter; left time: 348.5783s
Epoch: 11 cost time: 4.186841011047363
Epoch: 11, Steps: 218 Train Loss: 3.1492 (Forecasting Loss:0.4115 + XiCon Loss:2.7377 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.3906
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1478827
	speed: 0.0203s/iter; left time: 392.5930s
	iters: 200, epoch: 12 | loss: 3.1624267
	speed: 0.0177s/iter; left time: 339.0204s
Epoch: 12 cost time: 4.151507139205933
Epoch: 12, Steps: 218 Train Loss: 3.1539 (Forecasting Loss:0.4113 + XiCon Loss:2.7426 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3905
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1152713
	speed: 0.0201s/iter; left time: 383.5460s
	iters: 200, epoch: 13 | loss: 3.0540800
	speed: 0.0177s/iter; left time: 336.5381s
Epoch: 13 cost time: 4.138967752456665
Epoch: 13, Steps: 218 Train Loss: 3.1545 (Forecasting Loss:0.4112 + XiCon Loss:2.7433 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3905
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1769481
	speed: 0.0199s/iter; left time: 375.8712s
	iters: 200, epoch: 14 | loss: 3.1707096
	speed: 0.0181s/iter; left time: 339.5670s
Epoch: 14 cost time: 4.170806169509888
Epoch: 14, Steps: 218 Train Loss: 3.1529 (Forecasting Loss:0.4119 + XiCon Loss:2.7410 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.3905
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.0905859
	speed: 0.0201s/iter; left time: 374.4756s
	iters: 200, epoch: 15 | loss: 3.1493218
	speed: 0.0180s/iter; left time: 333.4653s
Epoch: 15 cost time: 4.173650503158569
Epoch: 15, Steps: 218 Train Loss: 3.1585 (Forecasting Loss:0.4117 + XiCon Loss:2.7468 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3906
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2489676
	speed: 0.0204s/iter; left time: 376.5533s
	iters: 200, epoch: 16 | loss: 3.2517800
	speed: 0.0183s/iter; left time: 335.3317s
Epoch: 16 cost time: 4.234082460403442
Epoch: 16, Steps: 218 Train Loss: 3.1518 (Forecasting Loss:0.4119 + XiCon Loss:2.7399 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3906
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1963813
	speed: 0.0206s/iter; left time: 374.9207s
	iters: 200, epoch: 17 | loss: 3.1218083
	speed: 0.0180s/iter; left time: 325.5140s
Epoch: 17 cost time: 4.202718257904053
Epoch: 17, Steps: 218 Train Loss: 3.1548 (Forecasting Loss:0.4119 + XiCon Loss:2.7429 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3906
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.33972305059432983, mae:0.44261831045150757, mape:5.556650638580322, mspe:84262.40625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4465+-0.21641, MAE:0.5084+-0.12796, MAPE:5.6677+-0.69846, MSPE:78948.4609+-43899.24892, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.8410
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 24.2977085
	speed: 0.0195s/iter; left time: 406.8662s
	iters: 200, epoch: 1 | loss: 23.7575207
	speed: 0.0143s/iter; left time: 296.8024s
Epoch: 1 cost time: 3.5383429527282715
Epoch: 1, Steps: 210 Train Loss: 23.8066 (Forecasting Loss:0.8382 + XiCon Loss:2.2968 x Lambda(10.0)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.6922
Validation loss decreased (inf --> 0.279657).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 22.6910839
	speed: 0.0170s/iter; left time: 350.8352s
	iters: 200, epoch: 2 | loss: 22.7625446
	speed: 0.0145s/iter; left time: 297.5460s
Epoch: 2 cost time: 3.3244922161102295
Epoch: 2, Steps: 210 Train Loss: 22.1381 (Forecasting Loss:0.5840 + XiCon Loss:2.1554 x Lambda(10.0)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.4945
Validation loss decreased (0.279657 --> 0.273393).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 22.0617371
	speed: 0.0176s/iter; left time: 359.7299s
	iters: 200, epoch: 3 | loss: 21.5470238
	speed: 0.0156s/iter; left time: 318.2638s
Epoch: 3 cost time: 3.5022165775299072
Epoch: 3, Steps: 210 Train Loss: 22.4220 (Forecasting Loss:0.5347 + XiCon Loss:2.1887 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.5136
Validation loss decreased (0.273393 --> 0.233033).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 21.4539452
	speed: 0.0185s/iter; left time: 374.9518s
	iters: 200, epoch: 4 | loss: 22.2246399
	speed: 0.0156s/iter; left time: 313.7267s
Epoch: 4 cost time: 3.593092918395996
Epoch: 4, Steps: 210 Train Loss: 21.9048 (Forecasting Loss:0.4935 + XiCon Loss:2.1411 x Lambda(10.0)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.5408
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 20.8178253
	speed: 0.0187s/iter; left time: 375.6661s
	iters: 200, epoch: 5 | loss: 21.1814518
	speed: 0.0155s/iter; left time: 308.5848s
Epoch: 5 cost time: 3.6084797382354736
Epoch: 5, Steps: 210 Train Loss: 21.7488 (Forecasting Loss:0.4847 + XiCon Loss:2.1264 x Lambda(10.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.5294
Validation loss decreased (0.233033 --> 0.229946).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 21.1615448
	speed: 0.0182s/iter; left time: 362.0905s
	iters: 200, epoch: 6 | loss: 21.1108398
	speed: 0.0154s/iter; left time: 304.6332s
Epoch: 6 cost time: 3.5575857162475586
Epoch: 6, Steps: 210 Train Loss: 21.6445 (Forecasting Loss:0.4799 + XiCon Loss:2.1165 x Lambda(10.0)), Vali MSE Loss: 0.2390 Test MSE Loss: 0.5433
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 20.8814411
	speed: 0.0177s/iter; left time: 347.1713s
	iters: 200, epoch: 7 | loss: 22.2502995
	speed: 0.0156s/iter; left time: 305.5511s
Epoch: 7 cost time: 3.518016815185547
Epoch: 7, Steps: 210 Train Loss: 21.6826 (Forecasting Loss:0.4785 + XiCon Loss:2.1204 x Lambda(10.0)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.5458
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 21.4497223
	speed: 0.0184s/iter; left time: 357.1715s
	iters: 200, epoch: 8 | loss: 23.0944443
	speed: 0.0155s/iter; left time: 298.7445s
Epoch: 8 cost time: 3.5729613304138184
Epoch: 8, Steps: 210 Train Loss: 21.7396 (Forecasting Loss:0.4771 + XiCon Loss:2.1263 x Lambda(10.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.5325
Validation loss decreased (0.229946 --> 0.227458).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 21.1703129
	speed: 0.0183s/iter; left time: 351.0778s
	iters: 200, epoch: 9 | loss: 21.0474815
	speed: 0.0160s/iter; left time: 306.8809s
Epoch: 9 cost time: 3.619481086730957
Epoch: 9, Steps: 210 Train Loss: 21.6695 (Forecasting Loss:0.4769 + XiCon Loss:2.1193 x Lambda(10.0)), Vali MSE Loss: 0.2336 Test MSE Loss: 0.5416
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 21.7987022
	speed: 0.0179s/iter; left time: 339.8629s
	iters: 200, epoch: 10 | loss: 21.2508678
	speed: 0.0159s/iter; left time: 300.0525s
Epoch: 10 cost time: 3.568995237350464
Epoch: 10, Steps: 210 Train Loss: 21.6374 (Forecasting Loss:0.4768 + XiCon Loss:2.1161 x Lambda(10.0)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.5437
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.0458488
	speed: 0.0181s/iter; left time: 339.4946s
	iters: 200, epoch: 11 | loss: 23.1202202
	speed: 0.0157s/iter; left time: 293.7725s
Epoch: 11 cost time: 3.5729641914367676
Epoch: 11, Steps: 210 Train Loss: 21.6426 (Forecasting Loss:0.4756 + XiCon Loss:2.1167 x Lambda(10.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.5400
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 21.9856873
	speed: 0.0182s/iter; left time: 337.8645s
	iters: 200, epoch: 12 | loss: 21.6533833
	speed: 0.0159s/iter; left time: 293.5626s
Epoch: 12 cost time: 3.6055641174316406
Epoch: 12, Steps: 210 Train Loss: 21.6662 (Forecasting Loss:0.4764 + XiCon Loss:2.1190 x Lambda(10.0)), Vali MSE Loss: 0.2306 Test MSE Loss: 0.5386
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 21.1319408
	speed: 0.0178s/iter; left time: 328.0150s
	iters: 200, epoch: 13 | loss: 21.4547424
	speed: 0.0158s/iter; left time: 289.1057s
Epoch: 13 cost time: 3.5566904544830322
Epoch: 13, Steps: 210 Train Loss: 21.7077 (Forecasting Loss:0.4756 + XiCon Loss:2.1232 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.5408
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 22.8711205
	speed: 0.0177s/iter; left time: 320.8836s
	iters: 200, epoch: 14 | loss: 22.4464645
	speed: 0.0158s/iter; left time: 285.3694s
Epoch: 14 cost time: 3.5412042140960693
Epoch: 14, Steps: 210 Train Loss: 21.7153 (Forecasting Loss:0.4761 + XiCon Loss:2.1239 x Lambda(10.0)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.5401
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 21.1689529
	speed: 0.0184s/iter; left time: 330.2847s
	iters: 200, epoch: 15 | loss: 21.9629917
	speed: 0.0155s/iter; left time: 276.6927s
Epoch: 15 cost time: 3.5720460414886475
Epoch: 15, Steps: 210 Train Loss: 21.8067 (Forecasting Loss:0.4760 + XiCon Loss:2.1331 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.5402
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 22.2098675
	speed: 0.0181s/iter; left time: 321.1403s
	iters: 200, epoch: 16 | loss: 21.6171455
	speed: 0.0159s/iter; left time: 280.9217s
Epoch: 16 cost time: 3.5860416889190674
Epoch: 16, Steps: 210 Train Loss: 21.6741 (Forecasting Loss:0.4758 + XiCon Loss:2.1198 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.5403
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 20.2370625
	speed: 0.0180s/iter; left time: 316.4387s
	iters: 200, epoch: 17 | loss: 21.4071960
	speed: 0.0154s/iter; left time: 269.0436s
Epoch: 17 cost time: 3.5329463481903076
Epoch: 17, Steps: 210 Train Loss: 21.7183 (Forecasting Loss:0.4757 + XiCon Loss:2.1243 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5403
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 21.2827816
	speed: 0.0179s/iter; left time: 309.7551s
	iters: 200, epoch: 18 | loss: 20.7427406
	speed: 0.0158s/iter; left time: 271.8460s
Epoch: 18 cost time: 3.5534443855285645
Epoch: 18, Steps: 210 Train Loss: 21.6730 (Forecasting Loss:0.4762 + XiCon Loss:2.1197 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5403
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5144376754760742, mae:0.5505541563034058, mape:4.333928108215332, mspe:24736.587890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.6386
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 23.9044399
	speed: 0.0170s/iter; left time: 355.2547s
	iters: 200, epoch: 1 | loss: 23.6015186
	speed: 0.0137s/iter; left time: 284.1084s
Epoch: 1 cost time: 3.2324748039245605
Epoch: 1, Steps: 210 Train Loss: 23.7757 (Forecasting Loss:0.8427 + XiCon Loss:2.2933 x Lambda(10.0)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.6767
Validation loss decreased (inf --> 0.279452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 21.5603905
	speed: 0.0193s/iter; left time: 398.3674s
	iters: 200, epoch: 2 | loss: 23.5948677
	speed: 0.0168s/iter; left time: 346.5857s
Epoch: 2 cost time: 3.806065320968628
Epoch: 2, Steps: 210 Train Loss: 22.3800 (Forecasting Loss:0.6626 + XiCon Loss:2.1717 x Lambda(10.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.5508
Validation loss decreased (0.279452 --> 0.261176).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 22.3496933
	speed: 0.0191s/iter; left time: 391.6309s
	iters: 200, epoch: 3 | loss: 23.9589844
	speed: 0.0162s/iter; left time: 330.2486s
Epoch: 3 cost time: 3.7252895832061768
Epoch: 3, Steps: 210 Train Loss: 22.3435 (Forecasting Loss:0.5301 + XiCon Loss:2.1813 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.5421
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 21.8009033
	speed: 0.0193s/iter; left time: 390.9679s
	iters: 200, epoch: 4 | loss: 20.9385700
	speed: 0.0167s/iter; left time: 337.5396s
Epoch: 4 cost time: 3.8137474060058594
Epoch: 4, Steps: 210 Train Loss: 22.0361 (Forecasting Loss:0.5145 + XiCon Loss:2.1522 x Lambda(10.0)), Vali MSE Loss: 0.2709 Test MSE Loss: 0.5394
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.8299789
	speed: 0.0183s/iter; left time: 367.6226s
	iters: 200, epoch: 5 | loss: 22.5483494
	speed: 0.0164s/iter; left time: 326.9086s
Epoch: 5 cost time: 3.6625568866729736
Epoch: 5, Steps: 210 Train Loss: 21.9738 (Forecasting Loss:0.5083 + XiCon Loss:2.1466 x Lambda(10.0)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.5327
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 21.5592384
	speed: 0.0187s/iter; left time: 371.5732s
	iters: 200, epoch: 6 | loss: 22.5746193
	speed: 0.0161s/iter; left time: 317.0567s
Epoch: 6 cost time: 3.69209361076355
Epoch: 6, Steps: 210 Train Loss: 21.9902 (Forecasting Loss:0.5055 + XiCon Loss:2.1485 x Lambda(10.0)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.5276
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 21.3270321
	speed: 0.0182s/iter; left time: 358.4084s
	iters: 200, epoch: 7 | loss: 21.8042564
	speed: 0.0161s/iter; left time: 313.8953s
Epoch: 7 cost time: 3.6272037029266357
Epoch: 7, Steps: 210 Train Loss: 21.8971 (Forecasting Loss:0.5053 + XiCon Loss:2.1392 x Lambda(10.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.5246
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 21.4932041
	speed: 0.0189s/iter; left time: 367.0802s
	iters: 200, epoch: 8 | loss: 22.2718639
	speed: 0.0165s/iter; left time: 318.2877s
Epoch: 8 cost time: 3.7313976287841797
Epoch: 8, Steps: 210 Train Loss: 21.8857 (Forecasting Loss:0.5037 + XiCon Loss:2.1382 x Lambda(10.0)), Vali MSE Loss: 0.2675 Test MSE Loss: 0.5243
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 21.6743889
	speed: 0.0187s/iter; left time: 359.7059s
	iters: 200, epoch: 9 | loss: 22.0795460
	speed: 0.0163s/iter; left time: 312.2770s
Epoch: 9 cost time: 3.7143495082855225
Epoch: 9, Steps: 210 Train Loss: 21.9723 (Forecasting Loss:0.5028 + XiCon Loss:2.1469 x Lambda(10.0)), Vali MSE Loss: 0.2679 Test MSE Loss: 0.5245
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.0787239
	speed: 0.0184s/iter; left time: 350.4530s
	iters: 200, epoch: 10 | loss: 22.2741985
	speed: 0.0162s/iter; left time: 306.9692s
Epoch: 10 cost time: 3.672982692718506
Epoch: 10, Steps: 210 Train Loss: 21.9792 (Forecasting Loss:0.5028 + XiCon Loss:2.1476 x Lambda(10.0)), Vali MSE Loss: 0.2679 Test MSE Loss: 0.5246
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 21.7430458
	speed: 0.0187s/iter; left time: 352.4469s
	iters: 200, epoch: 11 | loss: 21.8373718
	speed: 0.0171s/iter; left time: 319.5042s
Epoch: 11 cost time: 3.7686429023742676
Epoch: 11, Steps: 210 Train Loss: 21.8609 (Forecasting Loss:0.5028 + XiCon Loss:2.1358 x Lambda(10.0)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.5248
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 21.6766930
	speed: 0.0193s/iter; left time: 359.4816s
	iters: 200, epoch: 12 | loss: 21.9081554
	speed: 0.0163s/iter; left time: 300.7401s
Epoch: 12 cost time: 3.7514092922210693
Epoch: 12, Steps: 210 Train Loss: 21.9062 (Forecasting Loss:0.5028 + XiCon Loss:2.1403 x Lambda(10.0)), Vali MSE Loss: 0.2684 Test MSE Loss: 0.5248
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5320378541946411, mae:0.5695021748542786, mape:3.508504629135132, mspe:6866.951171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.6904
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 23.8605480
	speed: 0.0164s/iter; left time: 341.9066s
	iters: 200, epoch: 1 | loss: 23.6397343
	speed: 0.0138s/iter; left time: 287.4101s
Epoch: 1 cost time: 3.1918983459472656
Epoch: 1, Steps: 210 Train Loss: 23.6524 (Forecasting Loss:0.8485 + XiCon Loss:2.2804 x Lambda(10.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.7031
Validation loss decreased (inf --> 0.281212).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 21.7172585
	speed: 0.0174s/iter; left time: 360.5668s
	iters: 200, epoch: 2 | loss: 22.4593792
	speed: 0.0158s/iter; left time: 324.6502s
Epoch: 2 cost time: 3.5196783542633057
Epoch: 2, Steps: 210 Train Loss: 22.0795 (Forecasting Loss:0.6924 + XiCon Loss:2.1387 x Lambda(10.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.5429
Validation loss decreased (0.281212 --> 0.243579).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 23.2828274
	speed: 0.0200s/iter; left time: 410.3722s
	iters: 200, epoch: 3 | loss: 22.2350197
	speed: 0.0167s/iter; left time: 339.5384s
Epoch: 3 cost time: 3.8752896785736084
Epoch: 3, Steps: 210 Train Loss: 22.9976 (Forecasting Loss:0.5410 + XiCon Loss:2.2457 x Lambda(10.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.5230
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.2750511
	speed: 0.0194s/iter; left time: 392.4843s
	iters: 200, epoch: 4 | loss: 21.8471622
	speed: 0.0167s/iter; left time: 335.9375s
Epoch: 4 cost time: 3.802744150161743
Epoch: 4, Steps: 210 Train Loss: 22.5643 (Forecasting Loss:0.5108 + XiCon Loss:2.2054 x Lambda(10.0)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.5183
Validation loss decreased (0.243579 --> 0.233805).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.6022530
	speed: 0.0193s/iter; left time: 387.9047s
	iters: 200, epoch: 5 | loss: 22.3050594
	speed: 0.0166s/iter; left time: 330.4792s
Epoch: 5 cost time: 3.7940144538879395
Epoch: 5, Steps: 210 Train Loss: 22.3806 (Forecasting Loss:0.5020 + XiCon Loss:2.1879 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.5268
Validation loss decreased (0.233805 --> 0.229527).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 22.3907089
	speed: 0.0191s/iter; left time: 379.7743s
	iters: 200, epoch: 6 | loss: 23.4411240
	speed: 0.0168s/iter; left time: 331.5851s
Epoch: 6 cost time: 3.811901330947876
Epoch: 6, Steps: 210 Train Loss: 22.2252 (Forecasting Loss:0.4967 + XiCon Loss:2.1729 x Lambda(10.0)), Vali MSE Loss: 0.2306 Test MSE Loss: 0.5290
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 22.7033634
	speed: 0.0186s/iter; left time: 365.9138s
	iters: 200, epoch: 7 | loss: 22.0254288
	speed: 0.0170s/iter; left time: 332.5848s
Epoch: 7 cost time: 3.7616658210754395
Epoch: 7, Steps: 210 Train Loss: 22.1877 (Forecasting Loss:0.4940 + XiCon Loss:2.1694 x Lambda(10.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.5281
Validation loss decreased (0.229527 --> 0.226425).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 21.9792938
	speed: 0.0184s/iter; left time: 357.4219s
	iters: 200, epoch: 8 | loss: 22.5128040
	speed: 0.0167s/iter; left time: 322.8364s
Epoch: 8 cost time: 3.7013611793518066
Epoch: 8, Steps: 210 Train Loss: 22.1392 (Forecasting Loss:0.4924 + XiCon Loss:2.1647 x Lambda(10.0)), Vali MSE Loss: 0.2248 Test MSE Loss: 0.5275
Validation loss decreased (0.226425 --> 0.224802).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 22.4821243
	speed: 0.0192s/iter; left time: 368.8125s
	iters: 200, epoch: 9 | loss: 21.8907204
	speed: 0.0167s/iter; left time: 319.0830s
Epoch: 9 cost time: 3.7799477577209473
Epoch: 9, Steps: 210 Train Loss: 22.1762 (Forecasting Loss:0.4913 + XiCon Loss:2.1685 x Lambda(10.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.5269
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.4467297
	speed: 0.0190s/iter; left time: 360.7278s
	iters: 200, epoch: 10 | loss: 22.6500320
	speed: 0.0162s/iter; left time: 306.6617s
Epoch: 10 cost time: 3.7169723510742188
Epoch: 10, Steps: 210 Train Loss: 22.0908 (Forecasting Loss:0.4915 + XiCon Loss:2.1599 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5270
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.1919651
	speed: 0.0190s/iter; left time: 357.6371s
	iters: 200, epoch: 11 | loss: 22.4868565
	speed: 0.0160s/iter; left time: 299.8997s
Epoch: 11 cost time: 3.699428081512451
Epoch: 11, Steps: 210 Train Loss: 22.2149 (Forecasting Loss:0.4910 + XiCon Loss:2.1724 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5271
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 21.6851997
	speed: 0.0189s/iter; left time: 350.7288s
	iters: 200, epoch: 12 | loss: 22.5853195
	speed: 0.0165s/iter; left time: 305.4077s
Epoch: 12 cost time: 3.742121696472168
Epoch: 12, Steps: 210 Train Loss: 22.1752 (Forecasting Loss:0.4908 + XiCon Loss:2.1684 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5272
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 21.6012917
	speed: 0.0190s/iter; left time: 348.8148s
	iters: 200, epoch: 13 | loss: 21.8422661
	speed: 0.0163s/iter; left time: 297.7148s
Epoch: 13 cost time: 3.7308177947998047
Epoch: 13, Steps: 210 Train Loss: 22.1607 (Forecasting Loss:0.4910 + XiCon Loss:2.1670 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5272
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 22.2241287
	speed: 0.0190s/iter; left time: 344.8465s
	iters: 200, epoch: 14 | loss: 22.3573837
	speed: 0.0167s/iter; left time: 302.6187s
Epoch: 14 cost time: 3.7780559062957764
Epoch: 14, Steps: 210 Train Loss: 22.1725 (Forecasting Loss:0.4906 + XiCon Loss:2.1682 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5272
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 21.9242668
	speed: 0.0189s/iter; left time: 338.7313s
	iters: 200, epoch: 15 | loss: 22.8799362
	speed: 0.0169s/iter; left time: 301.4448s
Epoch: 15 cost time: 3.775541067123413
Epoch: 15, Steps: 210 Train Loss: 22.0936 (Forecasting Loss:0.4909 + XiCon Loss:2.1603 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5272
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 20.8957081
	speed: 0.0190s/iter; left time: 337.4546s
	iters: 200, epoch: 16 | loss: 21.7205334
	speed: 0.0164s/iter; left time: 289.9499s
Epoch: 16 cost time: 3.753861665725708
Epoch: 16, Steps: 210 Train Loss: 22.1077 (Forecasting Loss:0.4908 + XiCon Loss:2.1617 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5272
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 22.9546986
	speed: 0.0188s/iter; left time: 328.9512s
	iters: 200, epoch: 17 | loss: 22.2900925
	speed: 0.0165s/iter; left time: 287.7852s
Epoch: 17 cost time: 3.7282040119171143
Epoch: 17, Steps: 210 Train Loss: 22.1885 (Forecasting Loss:0.4909 + XiCon Loss:2.1698 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5272
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 22.1563969
	speed: 0.0186s/iter; left time: 322.7604s
	iters: 200, epoch: 18 | loss: 22.4605923
	speed: 0.0163s/iter; left time: 280.4630s
Epoch: 18 cost time: 3.687938928604126
Epoch: 18, Steps: 210 Train Loss: 22.1342 (Forecasting Loss:0.4910 + XiCon Loss:2.1643 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5272
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5018321871757507, mae:0.5531313419342041, mape:3.689479112625122, mspe:9471.595703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.4767
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 24.0479145
	speed: 0.0168s/iter; left time: 351.3318s
	iters: 200, epoch: 1 | loss: 22.7904854
	speed: 0.0143s/iter; left time: 296.4902s
Epoch: 1 cost time: 3.269284248352051
Epoch: 1, Steps: 210 Train Loss: 23.6569 (Forecasting Loss:0.8315 + XiCon Loss:2.2825 x Lambda(10.0)), Vali MSE Loss: 0.2768 Test MSE Loss: 0.6305
Validation loss decreased (inf --> 0.276753).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.0012131
	speed: 0.0166s/iter; left time: 343.1163s
	iters: 200, epoch: 2 | loss: 21.7040539
	speed: 0.0146s/iter; left time: 300.0090s
Epoch: 2 cost time: 3.323305368423462
Epoch: 2, Steps: 210 Train Loss: 22.3390 (Forecasting Loss:0.6475 + XiCon Loss:2.1691 x Lambda(10.0)), Vali MSE Loss: 0.2645 Test MSE Loss: 0.5663
Validation loss decreased (0.276753 --> 0.264472).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 21.2996235
	speed: 0.0182s/iter; left time: 372.7265s
	iters: 200, epoch: 3 | loss: 21.4154282
	speed: 0.0152s/iter; left time: 309.6988s
Epoch: 3 cost time: 3.5286402702331543
Epoch: 3, Steps: 210 Train Loss: 21.9296 (Forecasting Loss:0.5653 + XiCon Loss:2.1364 x Lambda(10.0)), Vali MSE Loss: 0.2411 Test MSE Loss: 0.5299
Validation loss decreased (0.264472 --> 0.241127).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.0263176
	speed: 0.0179s/iter; left time: 361.8940s
	iters: 200, epoch: 4 | loss: 21.3033733
	speed: 0.0154s/iter; left time: 311.3186s
Epoch: 4 cost time: 3.5167438983917236
Epoch: 4, Steps: 210 Train Loss: 21.8355 (Forecasting Loss:0.5260 + XiCon Loss:2.1309 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.5300
Validation loss decreased (0.241127 --> 0.235346).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 21.0579433
	speed: 0.0178s/iter; left time: 356.8760s
	iters: 200, epoch: 5 | loss: 22.3125057
	speed: 0.0156s/iter; left time: 311.1605s
Epoch: 5 cost time: 3.524292469024658
Epoch: 5, Steps: 210 Train Loss: 21.7671 (Forecasting Loss:0.5094 + XiCon Loss:2.1258 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5282
Validation loss decreased (0.235346 --> 0.231662).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 21.8768826
	speed: 0.0180s/iter; left time: 357.3886s
	iters: 200, epoch: 6 | loss: 21.6549377
	speed: 0.0154s/iter; left time: 304.8699s
Epoch: 6 cost time: 3.529111862182617
Epoch: 6, Steps: 210 Train Loss: 21.7588 (Forecasting Loss:0.5029 + XiCon Loss:2.1256 x Lambda(10.0)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.5250
Validation loss decreased (0.231662 --> 0.229315).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 21.5064316
	speed: 0.0174s/iter; left time: 341.4864s
	iters: 200, epoch: 7 | loss: 21.7959232
	speed: 0.0149s/iter; left time: 291.4869s
Epoch: 7 cost time: 3.408296585083008
Epoch: 7, Steps: 210 Train Loss: 21.7793 (Forecasting Loss:0.4997 + XiCon Loss:2.1280 x Lambda(10.0)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.5297
Validation loss decreased (0.229315 --> 0.227554).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 20.9638863
	speed: 0.0177s/iter; left time: 343.0281s
	iters: 200, epoch: 8 | loss: 21.5493507
	speed: 0.0147s/iter; left time: 283.8445s
Epoch: 8 cost time: 3.4164884090423584
Epoch: 8, Steps: 210 Train Loss: 21.7794 (Forecasting Loss:0.4979 + XiCon Loss:2.1282 x Lambda(10.0)), Vali MSE Loss: 0.2257 Test MSE Loss: 0.5292
Validation loss decreased (0.227554 --> 0.225690).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 21.4054260
	speed: 0.0178s/iter; left time: 341.2337s
	iters: 200, epoch: 9 | loss: 21.7036018
	speed: 0.0153s/iter; left time: 292.4925s
Epoch: 9 cost time: 3.493133783340454
Epoch: 9, Steps: 210 Train Loss: 21.7052 (Forecasting Loss:0.4980 + XiCon Loss:2.1207 x Lambda(10.0)), Vali MSE Loss: 0.2257 Test MSE Loss: 0.5288
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 21.3859806
	speed: 0.0177s/iter; left time: 335.6232s
	iters: 200, epoch: 10 | loss: 21.2301693
	speed: 0.0151s/iter; left time: 286.4694s
Epoch: 10 cost time: 3.4592559337615967
Epoch: 10, Steps: 210 Train Loss: 21.6783 (Forecasting Loss:0.4963 + XiCon Loss:2.1182 x Lambda(10.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.5293
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 21.0548134
	speed: 0.0178s/iter; left time: 334.6665s
	iters: 200, epoch: 11 | loss: 22.3652344
	speed: 0.0151s/iter; left time: 282.8604s
Epoch: 11 cost time: 3.478355884552002
Epoch: 11, Steps: 210 Train Loss: 21.6589 (Forecasting Loss:0.4960 + XiCon Loss:2.1163 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5295
Validation loss decreased (0.225690 --> 0.225458).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 21.1887131
	speed: 0.0178s/iter; left time: 330.3160s
	iters: 200, epoch: 12 | loss: 21.3368988
	speed: 0.0148s/iter; left time: 273.6541s
Epoch: 12 cost time: 3.4490246772766113
Epoch: 12, Steps: 210 Train Loss: 21.7839 (Forecasting Loss:0.4958 + XiCon Loss:2.1288 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5296
Validation loss decreased (0.225458 --> 0.225328).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 22.0749779
	speed: 0.0175s/iter; left time: 321.3869s
	iters: 200, epoch: 13 | loss: 21.3913498
	speed: 0.0152s/iter; left time: 277.3469s
Epoch: 13 cost time: 3.4497861862182617
Epoch: 13, Steps: 210 Train Loss: 21.6858 (Forecasting Loss:0.4962 + XiCon Loss:2.1190 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5295
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 21.5765018
	speed: 0.0176s/iter; left time: 319.6474s
	iters: 200, epoch: 14 | loss: 22.0556068
	speed: 0.0150s/iter; left time: 271.2790s
Epoch: 14 cost time: 3.436217784881592
Epoch: 14, Steps: 210 Train Loss: 21.7531 (Forecasting Loss:0.4960 + XiCon Loss:2.1257 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5296
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.2443562
	speed: 0.0180s/iter; left time: 323.9837s
	iters: 200, epoch: 15 | loss: 22.0595627
	speed: 0.0149s/iter; left time: 266.9957s
Epoch: 15 cost time: 3.481599807739258
Epoch: 15, Steps: 210 Train Loss: 21.6829 (Forecasting Loss:0.4959 + XiCon Loss:2.1187 x Lambda(10.0)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.5296
Validation loss decreased (0.225328 --> 0.225236).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 22.5759716
	speed: 0.0176s/iter; left time: 312.1797s
	iters: 200, epoch: 16 | loss: 22.7550507
	speed: 0.0148s/iter; left time: 261.1684s
Epoch: 16 cost time: 3.4245524406433105
Epoch: 16, Steps: 210 Train Loss: 21.7238 (Forecasting Loss:0.4964 + XiCon Loss:2.1227 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5296
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 21.8837757
	speed: 0.0176s/iter; left time: 307.8633s
	iters: 200, epoch: 17 | loss: 21.1695347
	speed: 0.0150s/iter; left time: 261.1109s
Epoch: 17 cost time: 3.44206166267395
Epoch: 17, Steps: 210 Train Loss: 21.6407 (Forecasting Loss:0.4964 + XiCon Loss:2.1144 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5296
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 21.6852417
	speed: 0.0178s/iter; left time: 307.8590s
	iters: 200, epoch: 18 | loss: 21.1982460
	speed: 0.0149s/iter; left time: 256.0152s
Epoch: 18 cost time: 3.4516820907592773
Epoch: 18, Steps: 210 Train Loss: 21.7185 (Forecasting Loss:0.4959 + XiCon Loss:2.1223 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5296
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 21.2165833
	speed: 0.0177s/iter; left time: 302.7676s
	iters: 200, epoch: 19 | loss: 21.7524681
	speed: 0.0150s/iter; left time: 255.3512s
Epoch: 19 cost time: 3.4781851768493652
Epoch: 19, Steps: 210 Train Loss: 21.6400 (Forecasting Loss:0.4965 + XiCon Loss:2.1144 x Lambda(10.0)), Vali MSE Loss: 0.2251 Test MSE Loss: 0.5296
Validation loss decreased (0.225236 --> 0.225135).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 22.6070919
	speed: 0.0177s/iter; left time: 298.9758s
	iters: 200, epoch: 20 | loss: 23.5339622
	speed: 0.0156s/iter; left time: 262.2849s
Epoch: 20 cost time: 3.5272445678710938
Epoch: 20, Steps: 210 Train Loss: 21.6715 (Forecasting Loss:0.4958 + XiCon Loss:2.1176 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5296
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 22.3902683
	speed: 0.0178s/iter; left time: 296.9257s
	iters: 200, epoch: 21 | loss: 22.2851219
	speed: 0.0153s/iter; left time: 253.9840s
Epoch: 21 cost time: 3.4987547397613525
Epoch: 21, Steps: 210 Train Loss: 21.7115 (Forecasting Loss:0.4958 + XiCon Loss:2.1216 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5296
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 20.8289776
	speed: 0.0178s/iter; left time: 292.9643s
	iters: 200, epoch: 22 | loss: 21.5299492
	speed: 0.0152s/iter; left time: 249.6443s
Epoch: 22 cost time: 3.4830803871154785
Epoch: 22, Steps: 210 Train Loss: 21.6720 (Forecasting Loss:0.4958 + XiCon Loss:2.1176 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5296
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 21.5342941
	speed: 0.0177s/iter; left time: 288.9124s
	iters: 200, epoch: 23 | loss: 21.9145679
	speed: 0.0152s/iter; left time: 246.6425s
Epoch: 23 cost time: 3.485477924346924
Epoch: 23, Steps: 210 Train Loss: 21.6349 (Forecasting Loss:0.4961 + XiCon Loss:2.1139 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5296
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 22.2572346
	speed: 0.0181s/iter; left time: 290.4684s
	iters: 200, epoch: 24 | loss: 21.5657520
	speed: 0.0152s/iter; left time: 242.3339s
Epoch: 24 cost time: 3.5101351737976074
Epoch: 24, Steps: 210 Train Loss: 21.6750 (Forecasting Loss:0.4957 + XiCon Loss:2.1179 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5296
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 21.4632359
	speed: 0.0174s/iter; left time: 276.3199s
	iters: 200, epoch: 25 | loss: 21.6797352
	speed: 0.0156s/iter; left time: 245.4316s
Epoch: 25 cost time: 3.4828526973724365
Epoch: 25, Steps: 210 Train Loss: 21.7093 (Forecasting Loss:0.4960 + XiCon Loss:2.1213 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5296
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 21.4618511
	speed: 0.0175s/iter; left time: 274.4323s
	iters: 200, epoch: 26 | loss: 20.6876183
	speed: 0.0155s/iter; left time: 240.8445s
Epoch: 26 cost time: 3.4821324348449707
Epoch: 26, Steps: 210 Train Loss: 21.6818 (Forecasting Loss:0.4959 + XiCon Loss:2.1186 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5296
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 21.5599651
	speed: 0.0180s/iter; left time: 277.3523s
	iters: 200, epoch: 27 | loss: 22.4783897
	speed: 0.0148s/iter; left time: 226.7446s
Epoch: 27 cost time: 3.461153268814087
Epoch: 27, Steps: 210 Train Loss: 21.7172 (Forecasting Loss:0.4959 + XiCon Loss:2.1221 x Lambda(10.0)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.5296
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 21.0715199
	speed: 0.0177s/iter; left time: 269.3495s
	iters: 200, epoch: 28 | loss: 21.7895298
	speed: 0.0154s/iter; left time: 232.4902s
Epoch: 28 cost time: 3.485492706298828
Epoch: 28, Steps: 210 Train Loss: 21.7304 (Forecasting Loss:0.4955 + XiCon Loss:2.1235 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5296
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 21.4825974
	speed: 0.0179s/iter; left time: 268.8967s
	iters: 200, epoch: 29 | loss: 22.1088219
	speed: 0.0150s/iter; left time: 224.3877s
Epoch: 29 cost time: 3.4759621620178223
Epoch: 29, Steps: 210 Train Loss: 21.7305 (Forecasting Loss:0.4960 + XiCon Loss:2.1234 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5296
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5064124464988708, mae:0.5528725385665894, mape:3.6091275215148926, mspe:11636.2626953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.5993
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 22.8921757
	speed: 0.0171s/iter; left time: 356.4726s
	iters: 200, epoch: 1 | loss: 23.3978767
	speed: 0.0144s/iter; left time: 299.1277s
Epoch: 1 cost time: 3.3204185962677
Epoch: 1, Steps: 210 Train Loss: 23.7224 (Forecasting Loss:0.8403 + XiCon Loss:2.2882 x Lambda(10.0)), Vali MSE Loss: 0.2799 Test MSE Loss: 0.6864
Validation loss decreased (inf --> 0.279875).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 21.9690113
	speed: 0.0191s/iter; left time: 395.8515s
	iters: 200, epoch: 2 | loss: 23.1516209
	speed: 0.0168s/iter; left time: 346.2542s
Epoch: 2 cost time: 3.7898409366607666
Epoch: 2, Steps: 210 Train Loss: 22.4712 (Forecasting Loss:0.6608 + XiCon Loss:2.1810 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.5481
Validation loss decreased (0.279875 --> 0.249893).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 21.4084206
	speed: 0.0188s/iter; left time: 385.3368s
	iters: 200, epoch: 3 | loss: 22.2072010
	speed: 0.0169s/iter; left time: 344.5208s
Epoch: 3 cost time: 3.7806556224823
Epoch: 3, Steps: 210 Train Loss: 22.2819 (Forecasting Loss:0.5071 + XiCon Loss:2.1775 x Lambda(10.0)), Vali MSE Loss: 0.2236 Test MSE Loss: 0.5715
Validation loss decreased (0.249893 --> 0.223558).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 21.2899799
	speed: 0.0189s/iter; left time: 383.3223s
	iters: 200, epoch: 4 | loss: 21.9191875
	speed: 0.0164s/iter; left time: 330.6424s
Epoch: 4 cost time: 3.7249717712402344
Epoch: 4, Steps: 210 Train Loss: 21.8476 (Forecasting Loss:0.4844 + XiCon Loss:2.1363 x Lambda(10.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.5568
Validation loss decreased (0.223558 --> 0.222212).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.5540237
	speed: 0.0192s/iter; left time: 385.8900s
	iters: 200, epoch: 5 | loss: 21.1862354
	speed: 0.0162s/iter; left time: 323.4523s
Epoch: 5 cost time: 3.7434396743774414
Epoch: 5, Steps: 210 Train Loss: 21.7704 (Forecasting Loss:0.4761 + XiCon Loss:2.1294 x Lambda(10.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.5588
Validation loss decreased (0.222212 --> 0.218625).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 21.8812065
	speed: 0.0185s/iter; left time: 366.7313s
	iters: 200, epoch: 6 | loss: 21.0971966
	speed: 0.0159s/iter; left time: 314.4848s
Epoch: 6 cost time: 3.64192795753479
Epoch: 6, Steps: 210 Train Loss: 21.8153 (Forecasting Loss:0.4722 + XiCon Loss:2.1343 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5535
Validation loss decreased (0.218625 --> 0.217987).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 21.6490440
	speed: 0.0188s/iter; left time: 368.4605s
	iters: 200, epoch: 7 | loss: 22.9214840
	speed: 0.0158s/iter; left time: 309.0592s
Epoch: 7 cost time: 3.647543430328369
Epoch: 7, Steps: 210 Train Loss: 21.7872 (Forecasting Loss:0.4725 + XiCon Loss:2.1315 x Lambda(10.0)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.5556
Validation loss decreased (0.217987 --> 0.216880).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.0743446
	speed: 0.0185s/iter; left time: 358.6439s
	iters: 200, epoch: 8 | loss: 21.5012054
	speed: 0.0161s/iter; left time: 312.0078s
Epoch: 8 cost time: 3.650653600692749
Epoch: 8, Steps: 210 Train Loss: 21.7476 (Forecasting Loss:0.4691 + XiCon Loss:2.1279 x Lambda(10.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.5527
Validation loss decreased (0.216880 --> 0.216306).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 22.4134464
	speed: 0.0186s/iter; left time: 357.1568s
	iters: 200, epoch: 9 | loss: 22.9067993
	speed: 0.0165s/iter; left time: 316.1080s
Epoch: 9 cost time: 3.7041871547698975
Epoch: 9, Steps: 210 Train Loss: 21.7694 (Forecasting Loss:0.4692 + XiCon Loss:2.1300 x Lambda(10.0)), Vali MSE Loss: 0.2160 Test MSE Loss: 0.5538
Validation loss decreased (0.216306 --> 0.216022).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 21.3781662
	speed: 0.0189s/iter; left time: 359.1684s
	iters: 200, epoch: 10 | loss: 20.6370792
	speed: 0.0164s/iter; left time: 309.3080s
Epoch: 10 cost time: 3.7138030529022217
Epoch: 10, Steps: 210 Train Loss: 21.7604 (Forecasting Loss:0.4697 + XiCon Loss:2.1291 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5527
Validation loss decreased (0.216022 --> 0.215635).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.0813751
	speed: 0.0191s/iter; left time: 359.5605s
	iters: 200, epoch: 11 | loss: 20.9905891
	speed: 0.0159s/iter; left time: 296.5944s
Epoch: 11 cost time: 3.6941328048706055
Epoch: 11, Steps: 210 Train Loss: 21.7862 (Forecasting Loss:0.4686 + XiCon Loss:2.1318 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5537
Validation loss decreased (0.215635 --> 0.215566).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 22.3464603
	speed: 0.0185s/iter; left time: 343.7984s
	iters: 200, epoch: 12 | loss: 21.5933228
	speed: 0.0163s/iter; left time: 301.9692s
Epoch: 12 cost time: 3.6778805255889893
Epoch: 12, Steps: 210 Train Loss: 21.7867 (Forecasting Loss:0.4686 + XiCon Loss:2.1318 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5534
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 20.9704037
	speed: 0.0186s/iter; left time: 341.2666s
	iters: 200, epoch: 13 | loss: 21.4674301
	speed: 0.0162s/iter; left time: 295.4090s
Epoch: 13 cost time: 3.674489974975586
Epoch: 13, Steps: 210 Train Loss: 21.7552 (Forecasting Loss:0.4693 + XiCon Loss:2.1286 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5532
Validation loss decreased (0.215566 --> 0.215475).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 21.7814083
	speed: 0.0190s/iter; left time: 345.7787s
	iters: 200, epoch: 14 | loss: 21.5458012
	speed: 0.0164s/iter; left time: 295.5514s
Epoch: 14 cost time: 3.7617247104644775
Epoch: 14, Steps: 210 Train Loss: 21.7138 (Forecasting Loss:0.4682 + XiCon Loss:2.1246 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5530
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.4257259
	speed: 0.0187s/iter; left time: 335.4687s
	iters: 200, epoch: 15 | loss: 21.4274368
	speed: 0.0160s/iter; left time: 286.1567s
Epoch: 15 cost time: 3.6624443531036377
Epoch: 15, Steps: 210 Train Loss: 21.7779 (Forecasting Loss:0.4683 + XiCon Loss:2.1310 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.5530
Validation loss decreased (0.215475 --> 0.215428).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 21.4517860
	speed: 0.0184s/iter; left time: 327.0141s
	iters: 200, epoch: 16 | loss: 22.6264019
	speed: 0.0164s/iter; left time: 288.9010s
Epoch: 16 cost time: 3.6780102252960205
Epoch: 16, Steps: 210 Train Loss: 21.7022 (Forecasting Loss:0.4687 + XiCon Loss:2.1233 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5530
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 21.0361538
	speed: 0.0184s/iter; left time: 323.4843s
	iters: 200, epoch: 17 | loss: 21.4388218
	speed: 0.0161s/iter; left time: 281.1775s
Epoch: 17 cost time: 3.6494951248168945
Epoch: 17, Steps: 210 Train Loss: 21.7618 (Forecasting Loss:0.4694 + XiCon Loss:2.1292 x Lambda(10.0)), Vali MSE Loss: 0.2152 Test MSE Loss: 0.5530
Validation loss decreased (0.215428 --> 0.215213).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 21.3377857
	speed: 0.0185s/iter; left time: 320.3735s
	iters: 200, epoch: 18 | loss: 20.8600159
	speed: 0.0166s/iter; left time: 285.8357s
Epoch: 18 cost time: 3.7071151733398438
Epoch: 18, Steps: 210 Train Loss: 21.7186 (Forecasting Loss:0.4687 + XiCon Loss:2.1250 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.5530
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 21.7560196
	speed: 0.0191s/iter; left time: 327.5581s
	iters: 200, epoch: 19 | loss: 21.1809769
	speed: 0.0162s/iter; left time: 274.9456s
Epoch: 19 cost time: 3.7173871994018555
Epoch: 19, Steps: 210 Train Loss: 21.7380 (Forecasting Loss:0.4685 + XiCon Loss:2.1270 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.5530
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 21.7830734
	speed: 0.0191s/iter; left time: 323.6395s
	iters: 200, epoch: 20 | loss: 22.2823467
	speed: 0.0162s/iter; left time: 272.5944s
Epoch: 20 cost time: 3.7492313385009766
Epoch: 20, Steps: 210 Train Loss: 21.8122 (Forecasting Loss:0.4687 + XiCon Loss:2.1344 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.5530
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 21.2892189
	speed: 0.0182s/iter; left time: 303.3059s
	iters: 200, epoch: 21 | loss: 21.1397266
	speed: 0.0162s/iter; left time: 268.9683s
Epoch: 21 cost time: 3.6473982334136963
Epoch: 21, Steps: 210 Train Loss: 21.7243 (Forecasting Loss:0.4687 + XiCon Loss:2.1256 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5530
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 21.6389904
	speed: 0.0189s/iter; left time: 311.4775s
	iters: 200, epoch: 22 | loss: 20.5063248
	speed: 0.0162s/iter; left time: 265.2572s
Epoch: 22 cost time: 3.697005033493042
Epoch: 22, Steps: 210 Train Loss: 21.7462 (Forecasting Loss:0.4683 + XiCon Loss:2.1278 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5530
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 21.5268002
	speed: 0.0194s/iter; left time: 315.4933s
	iters: 200, epoch: 23 | loss: 22.6674328
	speed: 0.0161s/iter; left time: 260.3549s
Epoch: 23 cost time: 3.7563986778259277
Epoch: 23, Steps: 210 Train Loss: 21.7571 (Forecasting Loss:0.4678 + XiCon Loss:2.1289 x Lambda(10.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.5530
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 22.4204063
	speed: 0.0186s/iter; left time: 298.3771s
	iters: 200, epoch: 24 | loss: 21.3749466
	speed: 0.0169s/iter; left time: 269.3429s
Epoch: 24 cost time: 3.736396312713623
Epoch: 24, Steps: 210 Train Loss: 21.7784 (Forecasting Loss:0.4681 + XiCon Loss:2.1310 x Lambda(10.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.5530
Validation loss decreased (0.215213 --> 0.214959).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 21.7794456
	speed: 0.0188s/iter; left time: 298.6199s
	iters: 200, epoch: 25 | loss: 22.8044834
	speed: 0.0158s/iter; left time: 248.8008s
Epoch: 25 cost time: 3.654301166534424
Epoch: 25, Steps: 210 Train Loss: 21.7457 (Forecasting Loss:0.4685 + XiCon Loss:2.1277 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5530
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 21.5084915
	speed: 0.0185s/iter; left time: 289.0874s
	iters: 200, epoch: 26 | loss: 21.5147419
	speed: 0.0161s/iter; left time: 250.1797s
Epoch: 26 cost time: 3.6514720916748047
Epoch: 26, Steps: 210 Train Loss: 21.7072 (Forecasting Loss:0.4685 + XiCon Loss:2.1239 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5530
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 22.2947769
	speed: 0.0185s/iter; left time: 286.1824s
	iters: 200, epoch: 27 | loss: 21.1177311
	speed: 0.0160s/iter; left time: 245.0294s
Epoch: 27 cost time: 3.646796226501465
Epoch: 27, Steps: 210 Train Loss: 21.6873 (Forecasting Loss:0.4691 + XiCon Loss:2.1218 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.5530
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 21.0895023
	speed: 0.0187s/iter; left time: 285.1232s
	iters: 200, epoch: 28 | loss: 23.5423698
	speed: 0.0161s/iter; left time: 243.4186s
Epoch: 28 cost time: 3.678867816925049
Epoch: 28, Steps: 210 Train Loss: 21.7673 (Forecasting Loss:0.4681 + XiCon Loss:2.1299 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.5530
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 23.0927906
	speed: 0.0188s/iter; left time: 282.4483s
	iters: 200, epoch: 29 | loss: 22.0325203
	speed: 0.0160s/iter; left time: 238.0239s
Epoch: 29 cost time: 3.670488119125366
Epoch: 29, Steps: 210 Train Loss: 21.7480 (Forecasting Loss:0.4691 + XiCon Loss:2.1279 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5530
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 21.9323330
	speed: 0.0183s/iter; left time: 270.6435s
	iters: 200, epoch: 30 | loss: 21.4929295
	speed: 0.0160s/iter; left time: 235.7945s
Epoch: 30 cost time: 3.625135898590088
Epoch: 30, Steps: 210 Train Loss: 21.7377 (Forecasting Loss:0.4681 + XiCon Loss:2.1270 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.5530
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 22.7461624
	speed: 0.0185s/iter; left time: 269.8776s
	iters: 200, epoch: 31 | loss: 21.8740597
	speed: 0.0164s/iter; left time: 238.1015s
Epoch: 31 cost time: 3.699470043182373
Epoch: 31, Steps: 210 Train Loss: 21.6867 (Forecasting Loss:0.4688 + XiCon Loss:2.1218 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5530
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 20.6119022
	speed: 0.0186s/iter; left time: 267.2823s
	iters: 200, epoch: 32 | loss: 21.8112240
	speed: 0.0162s/iter; left time: 231.1056s
Epoch: 32 cost time: 3.673929214477539
Epoch: 32, Steps: 210 Train Loss: 21.7302 (Forecasting Loss:0.4690 + XiCon Loss:2.1261 x Lambda(10.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.5530
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 21.8641205
	speed: 0.0187s/iter; left time: 265.8921s
	iters: 200, epoch: 33 | loss: 20.8506069
	speed: 0.0159s/iter; left time: 224.0300s
Epoch: 33 cost time: 3.6605207920074463
Epoch: 33, Steps: 210 Train Loss: 21.7267 (Forecasting Loss:0.4690 + XiCon Loss:2.1258 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.5530
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 22.1884842
	speed: 0.0186s/iter; left time: 259.9602s
	iters: 200, epoch: 34 | loss: 21.7407722
	speed: 0.0159s/iter; left time: 220.5882s
Epoch: 34 cost time: 3.6535115242004395
Epoch: 34, Steps: 210 Train Loss: 21.7528 (Forecasting Loss:0.4684 + XiCon Loss:2.1284 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.5530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5392436981201172, mae:0.5667504668235779, mape:3.7958414554595947, mspe:14329.6640625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5188+-0.02015, MAE:0.5586+-0.01098, MAPE:3.7874+-0.40135, MSPE:13408.2129+-8571.21567, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
