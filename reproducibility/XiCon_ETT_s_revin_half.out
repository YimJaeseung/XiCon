Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2632
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3180280
	speed: 0.0147s/iter; left time: 186.6455s
Epoch: 1 cost time: 1.7652239799499512
Epoch: 1, Steps: 128 Train Loss: 3.3407 (Forecasting Loss:0.2444 + XiCon Loss:3.0963 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173681).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1741128
	speed: 0.0125s/iter; left time: 156.6082s
Epoch: 2 cost time: 1.5519022941589355
Epoch: 2, Steps: 128 Train Loss: 3.1469 (Forecasting Loss:0.2457 + XiCon Loss:2.9012 x Lambda(1.0)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1336
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1321490
	speed: 0.0122s/iter; left time: 151.6811s
Epoch: 3 cost time: 1.520582675933838
Epoch: 3, Steps: 128 Train Loss: 3.1516 (Forecasting Loss:0.2318 + XiCon Loss:2.9197 x Lambda(1.0)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1237
Validation loss decreased (0.173681 --> 0.168545).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0899553
	speed: 0.0122s/iter; left time: 149.9764s
Epoch: 4 cost time: 1.5231049060821533
Epoch: 4, Steps: 128 Train Loss: 3.1296 (Forecasting Loss:0.2219 + XiCon Loss:2.9076 x Lambda(1.0)), Vali MSE Loss: 0.1681 Test MSE Loss: 0.1165
Validation loss decreased (0.168545 --> 0.168069).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0579777
	speed: 0.0129s/iter; left time: 157.4930s
Epoch: 5 cost time: 1.5959115028381348
Epoch: 5, Steps: 128 Train Loss: 3.1211 (Forecasting Loss:0.2162 + XiCon Loss:2.9050 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1172
Validation loss decreased (0.168069 --> 0.166569).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0240734
	speed: 0.0120s/iter; left time: 144.7535s
Epoch: 6 cost time: 1.5106663703918457
Epoch: 6, Steps: 128 Train Loss: 3.1081 (Forecasting Loss:0.2141 + XiCon Loss:2.8940 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1159
Validation loss decreased (0.166569 --> 0.164659).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1177835
	speed: 0.0131s/iter; left time: 156.3338s
Epoch: 7 cost time: 1.6087963581085205
Epoch: 7, Steps: 128 Train Loss: 3.1009 (Forecasting Loss:0.2130 + XiCon Loss:2.8879 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1175
Validation loss decreased (0.164659 --> 0.163816).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0645223
	speed: 0.0125s/iter; left time: 147.2505s
Epoch: 8 cost time: 1.5683841705322266
Epoch: 8, Steps: 128 Train Loss: 3.1057 (Forecasting Loss:0.2123 + XiCon Loss:2.8934 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.2331619
	speed: 0.0119s/iter; left time: 138.8159s
Epoch: 9 cost time: 1.4940590858459473
Epoch: 9, Steps: 128 Train Loss: 3.0986 (Forecasting Loss:0.2116 + XiCon Loss:2.8870 x Lambda(1.0)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0765584
	speed: 0.0128s/iter; left time: 147.6853s
Epoch: 10 cost time: 1.589829683303833
Epoch: 10, Steps: 128 Train Loss: 3.1005 (Forecasting Loss:0.2113 + XiCon Loss:2.8892 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1165
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0670271
	speed: 0.0120s/iter; left time: 137.5568s
Epoch: 11 cost time: 1.4999456405639648
Epoch: 11, Steps: 128 Train Loss: 3.0974 (Forecasting Loss:0.2115 + XiCon Loss:2.8858 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1166
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0924540
	speed: 0.0118s/iter; left time: 133.4752s
Epoch: 12 cost time: 1.479093313217163
Epoch: 12, Steps: 128 Train Loss: 3.0968 (Forecasting Loss:0.2110 + XiCon Loss:2.8858 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1166
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1413038
	speed: 0.0121s/iter; left time: 135.0749s
Epoch: 13 cost time: 1.5105273723602295
Epoch: 13, Steps: 128 Train Loss: 3.0995 (Forecasting Loss:0.2111 + XiCon Loss:2.8884 x Lambda(1.0)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1166
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0894263
	speed: 0.0123s/iter; left time: 136.2246s
Epoch: 14 cost time: 1.533050775527954
Epoch: 14, Steps: 128 Train Loss: 3.0954 (Forecasting Loss:0.2113 + XiCon Loss:2.8842 x Lambda(1.0)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1166
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1083441
	speed: 0.0120s/iter; left time: 130.8947s
Epoch: 15 cost time: 1.4949591159820557
Epoch: 15, Steps: 128 Train Loss: 3.1014 (Forecasting Loss:0.2115 + XiCon Loss:2.8898 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1166
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0459726
	speed: 0.0128s/iter; left time: 137.4744s
Epoch: 16 cost time: 1.5905287265777588
Epoch: 16, Steps: 128 Train Loss: 3.0990 (Forecasting Loss:0.2113 + XiCon Loss:2.8877 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1166
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0578089
	speed: 0.0123s/iter; left time: 131.4668s
Epoch: 17 cost time: 1.5388624668121338
Epoch: 17, Steps: 128 Train Loss: 3.0939 (Forecasting Loss:0.2113 + XiCon Loss:2.8826 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1166
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05521232634782791, mae:0.17969655990600586, mape:0.14290063083171844, mspe:0.03805474936962128 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1768
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2712445
	speed: 0.0123s/iter; left time: 156.2294s
Epoch: 1 cost time: 1.5321080684661865
Epoch: 1, Steps: 128 Train Loss: 3.3167 (Forecasting Loss:0.2417 + XiCon Loss:3.0751 x Lambda(1.0)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.173852).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1341534
	speed: 0.0132s/iter; left time: 166.3290s
Epoch: 2 cost time: 1.6973068714141846
Epoch: 2, Steps: 128 Train Loss: 3.1236 (Forecasting Loss:0.2444 + XiCon Loss:2.8792 x Lambda(1.0)), Vali MSE Loss: 0.1787 Test MSE Loss: 0.1215
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2096720
	speed: 0.0122s/iter; left time: 152.2071s
Epoch: 3 cost time: 1.5210485458374023
Epoch: 3, Steps: 128 Train Loss: 3.1757 (Forecasting Loss:0.2325 + XiCon Loss:2.9432 x Lambda(1.0)), Vali MSE Loss: 0.1681 Test MSE Loss: 0.1212
Validation loss decreased (0.173852 --> 0.168131).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1050754
	speed: 0.0119s/iter; left time: 146.1165s
Epoch: 4 cost time: 1.4787054061889648
Epoch: 4, Steps: 128 Train Loss: 3.1249 (Forecasting Loss:0.2227 + XiCon Loss:2.9022 x Lambda(1.0)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1186
Validation loss decreased (0.168131 --> 0.166865).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0604539
	speed: 0.0123s/iter; left time: 149.7428s
Epoch: 5 cost time: 1.5348806381225586
Epoch: 5, Steps: 128 Train Loss: 3.0814 (Forecasting Loss:0.2179 + XiCon Loss:2.8635 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1164
Validation loss decreased (0.166865 --> 0.164818).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0771902
	speed: 0.0128s/iter; left time: 154.5825s
Epoch: 6 cost time: 1.5903074741363525
Epoch: 6, Steps: 128 Train Loss: 3.0764 (Forecasting Loss:0.2158 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1165
Validation loss decreased (0.164818 --> 0.164339).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1010334
	speed: 0.0123s/iter; left time: 146.9512s
Epoch: 7 cost time: 1.5500519275665283
Epoch: 7, Steps: 128 Train Loss: 3.0623 (Forecasting Loss:0.2142 + XiCon Loss:2.8481 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
Validation loss decreased (0.164339 --> 0.163800).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1499138
	speed: 0.0121s/iter; left time: 142.5643s
Epoch: 8 cost time: 1.5112931728363037
Epoch: 8, Steps: 128 Train Loss: 3.0635 (Forecasting Loss:0.2134 + XiCon Loss:2.8501 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1147
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1003079
	speed: 0.0121s/iter; left time: 140.9918s
Epoch: 9 cost time: 1.4976799488067627
Epoch: 9, Steps: 128 Train Loss: 3.0676 (Forecasting Loss:0.2132 + XiCon Loss:2.8544 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0889790
	speed: 0.0118s/iter; left time: 136.8474s
Epoch: 10 cost time: 1.4844443798065186
Epoch: 10, Steps: 128 Train Loss: 3.0642 (Forecasting Loss:0.2131 + XiCon Loss:2.8512 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1146
Validation loss decreased (0.163800 --> 0.163672).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1135857
	speed: 0.0124s/iter; left time: 141.5938s
Epoch: 11 cost time: 1.5495026111602783
Epoch: 11, Steps: 128 Train Loss: 3.0616 (Forecasting Loss:0.2130 + XiCon Loss:2.8486 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 2.9854581
	speed: 0.0127s/iter; left time: 143.0960s
Epoch: 12 cost time: 1.5636723041534424
Epoch: 12, Steps: 128 Train Loss: 3.0651 (Forecasting Loss:0.2129 + XiCon Loss:2.8522 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1145
Validation loss decreased (0.163672 --> 0.163582).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0403545
	speed: 0.0120s/iter; left time: 134.1782s
Epoch: 13 cost time: 1.5099239349365234
Epoch: 13, Steps: 128 Train Loss: 3.0644 (Forecasting Loss:0.2130 + XiCon Loss:2.8514 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9532406
	speed: 0.0128s/iter; left time: 141.6571s
Epoch: 14 cost time: 1.609745979309082
Epoch: 14, Steps: 128 Train Loss: 3.0551 (Forecasting Loss:0.2130 + XiCon Loss:2.8421 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0485382
	speed: 0.0119s/iter; left time: 129.7449s
Epoch: 15 cost time: 1.4896388053894043
Epoch: 15, Steps: 128 Train Loss: 3.0656 (Forecasting Loss:0.2129 + XiCon Loss:2.8527 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1122708
	speed: 0.0129s/iter; left time: 139.2541s
Epoch: 16 cost time: 1.5869801044464111
Epoch: 16, Steps: 128 Train Loss: 3.0643 (Forecasting Loss:0.2129 + XiCon Loss:2.8514 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0618217
	speed: 0.0123s/iter; left time: 131.5441s
Epoch: 17 cost time: 1.5645978450775146
Epoch: 17, Steps: 128 Train Loss: 3.0713 (Forecasting Loss:0.2128 + XiCon Loss:2.8585 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1145
Validation loss decreased (0.163582 --> 0.163421).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0120161
	speed: 0.0119s/iter; left time: 125.2008s
Epoch: 18 cost time: 1.515643835067749
Epoch: 18, Steps: 128 Train Loss: 3.0581 (Forecasting Loss:0.2128 + XiCon Loss:2.8453 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0391092
	speed: 0.0121s/iter; left time: 125.3291s
Epoch: 19 cost time: 1.5042619705200195
Epoch: 19, Steps: 128 Train Loss: 3.0607 (Forecasting Loss:0.2130 + XiCon Loss:2.8476 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1391404
	speed: 0.0121s/iter; left time: 124.0209s
Epoch: 20 cost time: 1.5147135257720947
Epoch: 20, Steps: 128 Train Loss: 3.0573 (Forecasting Loss:0.2130 + XiCon Loss:2.8443 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0183637
	speed: 0.0120s/iter; left time: 121.9711s
Epoch: 21 cost time: 1.5030772686004639
Epoch: 21, Steps: 128 Train Loss: 3.0640 (Forecasting Loss:0.2129 + XiCon Loss:2.8511 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1468983
	speed: 0.0124s/iter; left time: 124.5936s
Epoch: 22 cost time: 1.5369462966918945
Epoch: 22, Steps: 128 Train Loss: 3.0655 (Forecasting Loss:0.2129 + XiCon Loss:2.8526 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0099409
	speed: 0.0119s/iter; left time: 117.8573s
Epoch: 23 cost time: 1.4911777973175049
Epoch: 23, Steps: 128 Train Loss: 3.0613 (Forecasting Loss:0.2130 + XiCon Loss:2.8484 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1145
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0132365
	speed: 0.0120s/iter; left time: 117.4463s
Epoch: 24 cost time: 1.5048644542694092
Epoch: 24, Steps: 128 Train Loss: 3.0553 (Forecasting Loss:0.2129 + XiCon Loss:2.8424 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1145
Validation loss decreased (0.163421 --> 0.163410).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0234954
	speed: 0.0120s/iter; left time: 115.4796s
Epoch: 25 cost time: 1.4958126544952393
Epoch: 25, Steps: 128 Train Loss: 3.0652 (Forecasting Loss:0.2130 + XiCon Loss:2.8522 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0652785
	speed: 0.0126s/iter; left time: 119.7442s
Epoch: 26 cost time: 1.561692714691162
Epoch: 26, Steps: 128 Train Loss: 3.0640 (Forecasting Loss:0.2128 + XiCon Loss:2.8512 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0590501
	speed: 0.0120s/iter; left time: 112.8165s
Epoch: 27 cost time: 1.5176291465759277
Epoch: 27, Steps: 128 Train Loss: 3.0632 (Forecasting Loss:0.2130 + XiCon Loss:2.8502 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0786541
	speed: 0.0129s/iter; left time: 118.8332s
Epoch: 28 cost time: 1.6117525100708008
Epoch: 28, Steps: 128 Train Loss: 3.0635 (Forecasting Loss:0.2129 + XiCon Loss:2.8506 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0460722
	speed: 0.0120s/iter; left time: 109.1122s
Epoch: 29 cost time: 1.501326560974121
Epoch: 29, Steps: 128 Train Loss: 3.0593 (Forecasting Loss:0.2129 + XiCon Loss:2.8464 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0032041
	speed: 0.0120s/iter; left time: 108.1294s
Epoch: 30 cost time: 1.501251459121704
Epoch: 30, Steps: 128 Train Loss: 3.0563 (Forecasting Loss:0.2128 + XiCon Loss:2.8435 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1136372
	speed: 0.0124s/iter; left time: 109.8715s
Epoch: 31 cost time: 1.5420136451721191
Epoch: 31, Steps: 128 Train Loss: 3.0640 (Forecasting Loss:0.2130 + XiCon Loss:2.8510 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0589719
	speed: 0.0123s/iter; left time: 107.3159s
Epoch: 32 cost time: 1.5313901901245117
Epoch: 32, Steps: 128 Train Loss: 3.0603 (Forecasting Loss:0.2128 + XiCon Loss:2.8474 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.1132092
	speed: 0.0132s/iter; left time: 113.3129s
Epoch: 33 cost time: 1.6432209014892578
Epoch: 33, Steps: 128 Train Loss: 3.0675 (Forecasting Loss:0.2129 + XiCon Loss:2.8547 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0296750
	speed: 0.0120s/iter; left time: 101.5930s
Epoch: 34 cost time: 1.4988529682159424
Epoch: 34, Steps: 128 Train Loss: 3.0596 (Forecasting Loss:0.2130 + XiCon Loss:2.8466 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05311879888176918, mae:0.17580664157867432, mape:0.14003074169158936, mspe:0.03667549043893814 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2386
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2466989
	speed: 0.0123s/iter; left time: 156.7538s
Epoch: 1 cost time: 1.539396047592163
Epoch: 1, Steps: 128 Train Loss: 3.2984 (Forecasting Loss:0.2446 + XiCon Loss:3.0538 x Lambda(1.0)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1204
Validation loss decreased (inf --> 0.173095).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1522558
	speed: 0.0127s/iter; left time: 159.5140s
Epoch: 2 cost time: 1.5769739151000977
Epoch: 2, Steps: 128 Train Loss: 3.1483 (Forecasting Loss:0.2445 + XiCon Loss:2.9038 x Lambda(1.0)), Vali MSE Loss: 0.1778 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 2.9283013
	speed: 0.0120s/iter; left time: 149.3902s
Epoch: 3 cost time: 1.4986169338226318
Epoch: 3, Steps: 128 Train Loss: 3.0189 (Forecasting Loss:0.2283 + XiCon Loss:2.7906 x Lambda(1.0)), Vali MSE Loss: 0.1687 Test MSE Loss: 0.1204
Validation loss decreased (0.173095 --> 0.168718).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1408448
	speed: 0.0134s/iter; left time: 164.7437s
Epoch: 4 cost time: 1.6967101097106934
Epoch: 4, Steps: 128 Train Loss: 3.1796 (Forecasting Loss:0.2199 + XiCon Loss:2.9597 x Lambda(1.0)), Vali MSE Loss: 0.1695 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2205505
	speed: 0.0126s/iter; left time: 153.8361s
Epoch: 5 cost time: 1.6029648780822754
Epoch: 5, Steps: 128 Train Loss: 3.1503 (Forecasting Loss:0.2128 + XiCon Loss:2.9376 x Lambda(1.0)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1640556
	speed: 0.0123s/iter; left time: 148.3701s
Epoch: 6 cost time: 1.5356025695800781
Epoch: 6, Steps: 128 Train Loss: 3.1279 (Forecasting Loss:0.2096 + XiCon Loss:2.9183 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1143
Validation loss decreased (0.168718 --> 0.162976).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1204240
	speed: 0.0122s/iter; left time: 146.1297s
Epoch: 7 cost time: 1.5324203968048096
Epoch: 7, Steps: 128 Train Loss: 3.1262 (Forecasting Loss:0.2069 + XiCon Loss:2.9193 x Lambda(1.0)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0370538
	speed: 0.0122s/iter; left time: 144.0726s
Epoch: 8 cost time: 1.5245771408081055
Epoch: 8, Steps: 128 Train Loss: 3.1108 (Forecasting Loss:0.2052 + XiCon Loss:2.9056 x Lambda(1.0)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1136
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1211221
	speed: 0.0127s/iter; left time: 147.9163s
Epoch: 9 cost time: 1.5705881118774414
Epoch: 9, Steps: 128 Train Loss: 3.1248 (Forecasting Loss:0.2050 + XiCon Loss:2.9198 x Lambda(1.0)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1133
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2046206
	speed: 0.0123s/iter; left time: 141.6731s
Epoch: 10 cost time: 1.5285656452178955
Epoch: 10, Steps: 128 Train Loss: 3.1155 (Forecasting Loss:0.2043 + XiCon Loss:2.9111 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1137
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2429335
	speed: 0.0129s/iter; left time: 147.6072s
Epoch: 11 cost time: 1.6235160827636719
Epoch: 11, Steps: 128 Train Loss: 3.1187 (Forecasting Loss:0.2044 + XiCon Loss:2.9144 x Lambda(1.0)), Vali MSE Loss: 0.1668 Test MSE Loss: 0.1135
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0412061
	speed: 0.0121s/iter; left time: 136.8535s
Epoch: 12 cost time: 1.5170948505401611
Epoch: 12, Steps: 128 Train Loss: 3.1190 (Forecasting Loss:0.2042 + XiCon Loss:2.9148 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1135
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0713177
	speed: 0.0123s/iter; left time: 137.4032s
Epoch: 13 cost time: 1.5386924743652344
Epoch: 13, Steps: 128 Train Loss: 3.1175 (Forecasting Loss:0.2043 + XiCon Loss:2.9132 x Lambda(1.0)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1135
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0543020
	speed: 0.0121s/iter; left time: 133.1798s
Epoch: 14 cost time: 1.5053439140319824
Epoch: 14, Steps: 128 Train Loss: 3.1122 (Forecasting Loss:0.2040 + XiCon Loss:2.9082 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1135
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1279047
	speed: 0.0120s/iter; left time: 131.2238s
Epoch: 15 cost time: 1.5064246654510498
Epoch: 15, Steps: 128 Train Loss: 3.1222 (Forecasting Loss:0.2040 + XiCon Loss:2.9181 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1135
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1030598
	speed: 0.0124s/iter; left time: 133.5617s
Epoch: 16 cost time: 1.5581185817718506
Epoch: 16, Steps: 128 Train Loss: 3.1156 (Forecasting Loss:0.2042 + XiCon Loss:2.9113 x Lambda(1.0)), Vali MSE Loss: 0.1664 Test MSE Loss: 0.1135
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.053098276257514954, mae:0.175545334815979, mape:0.14095792174339294, mspe:0.038902558386325836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2197
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2718141
	speed: 0.0122s/iter; left time: 154.6242s
Epoch: 1 cost time: 1.5120139122009277
Epoch: 1, Steps: 128 Train Loss: 3.3195 (Forecasting Loss:0.2453 + XiCon Loss:3.0741 x Lambda(1.0)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1223
Validation loss decreased (inf --> 0.171989).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1773844
	speed: 0.0132s/iter; left time: 165.7665s
Epoch: 2 cost time: 1.6346113681793213
Epoch: 2, Steps: 128 Train Loss: 3.1658 (Forecasting Loss:0.2440 + XiCon Loss:2.9218 x Lambda(1.0)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1261
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.3354592
	speed: 0.0122s/iter; left time: 152.4169s
Epoch: 3 cost time: 1.527660608291626
Epoch: 3, Steps: 128 Train Loss: 3.1139 (Forecasting Loss:0.2307 + XiCon Loss:2.8832 x Lambda(1.0)), Vali MSE Loss: 0.1675 Test MSE Loss: 0.1181
Validation loss decreased (0.171989 --> 0.167505).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1537194
	speed: 0.0124s/iter; left time: 152.7919s
Epoch: 4 cost time: 1.538893461227417
Epoch: 4, Steps: 128 Train Loss: 3.2397 (Forecasting Loss:0.2214 + XiCon Loss:3.0183 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1172
Validation loss decreased (0.167505 --> 0.166639).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1039474
	speed: 0.0122s/iter; left time: 148.6039s
Epoch: 5 cost time: 1.520620346069336
Epoch: 5, Steps: 128 Train Loss: 3.1773 (Forecasting Loss:0.2169 + XiCon Loss:2.9603 x Lambda(1.0)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1214
Validation loss decreased (0.166639 --> 0.165995).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1073039
	speed: 0.0122s/iter; left time: 146.6782s
Epoch: 6 cost time: 1.5202484130859375
Epoch: 6, Steps: 128 Train Loss: 3.1427 (Forecasting Loss:0.2148 + XiCon Loss:2.9279 x Lambda(1.0)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1147
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1275339
	speed: 0.0123s/iter; left time: 146.9700s
Epoch: 7 cost time: 1.537736415863037
Epoch: 7, Steps: 128 Train Loss: 3.1435 (Forecasting Loss:0.2138 + XiCon Loss:2.9297 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
Validation loss decreased (0.165995 --> 0.164015).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0605228
	speed: 0.0127s/iter; left time: 149.8376s
Epoch: 8 cost time: 1.604238510131836
Epoch: 8, Steps: 128 Train Loss: 3.1367 (Forecasting Loss:0.2131 + XiCon Loss:2.9236 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1149
Validation loss decreased (0.164015 --> 0.163736).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1592894
	speed: 0.0121s/iter; left time: 141.8414s
Epoch: 9 cost time: 1.5216200351715088
Epoch: 9, Steps: 128 Train Loss: 3.1219 (Forecasting Loss:0.2126 + XiCon Loss:2.9093 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1144
Validation loss decreased (0.163736 --> 0.163359).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0880485
	speed: 0.0122s/iter; left time: 140.5153s
Epoch: 10 cost time: 1.5231881141662598
Epoch: 10, Steps: 128 Train Loss: 3.1252 (Forecasting Loss:0.2125 + XiCon Loss:2.9127 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1147
Validation loss decreased (0.163359 --> 0.163274).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0983684
	speed: 0.0126s/iter; left time: 143.6360s
Epoch: 11 cost time: 1.5646772384643555
Epoch: 11, Steps: 128 Train Loss: 3.1228 (Forecasting Loss:0.2123 + XiCon Loss:2.9105 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.163274 --> 0.162994).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2122469
	speed: 0.0121s/iter; left time: 137.0720s
Epoch: 12 cost time: 1.5172815322875977
Epoch: 12, Steps: 128 Train Loss: 3.1261 (Forecasting Loss:0.2124 + XiCon Loss:2.9137 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.162994 --> 0.162983).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1036146
	speed: 0.0124s/iter; left time: 138.8504s
Epoch: 13 cost time: 1.5564613342285156
Epoch: 13, Steps: 128 Train Loss: 3.1258 (Forecasting Loss:0.2123 + XiCon Loss:2.9135 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1286340
	speed: 0.0123s/iter; left time: 136.1607s
Epoch: 14 cost time: 1.546708583831787
Epoch: 14, Steps: 128 Train Loss: 3.1278 (Forecasting Loss:0.2121 + XiCon Loss:2.9157 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1280594
	speed: 0.0121s/iter; left time: 131.7412s
Epoch: 15 cost time: 1.512592077255249
Epoch: 15, Steps: 128 Train Loss: 3.1230 (Forecasting Loss:0.2122 + XiCon Loss:2.9108 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1979318
	speed: 0.0122s/iter; left time: 131.3129s
Epoch: 16 cost time: 1.5187335014343262
Epoch: 16, Steps: 128 Train Loss: 3.1286 (Forecasting Loss:0.2123 + XiCon Loss:2.9163 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1297445
	speed: 0.0120s/iter; left time: 128.2750s
Epoch: 17 cost time: 1.5082921981811523
Epoch: 17, Steps: 128 Train Loss: 3.1221 (Forecasting Loss:0.2123 + XiCon Loss:2.9098 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1954508
	speed: 0.0120s/iter; left time: 126.4581s
Epoch: 18 cost time: 1.5224485397338867
Epoch: 18, Steps: 128 Train Loss: 3.1290 (Forecasting Loss:0.2123 + XiCon Loss:2.9167 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0494988
	speed: 0.0124s/iter; left time: 128.9963s
Epoch: 19 cost time: 1.5424866676330566
Epoch: 19, Steps: 128 Train Loss: 3.1215 (Forecasting Loss:0.2122 + XiCon Loss:2.9093 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0854340
	speed: 0.0126s/iter; left time: 129.0411s
Epoch: 20 cost time: 1.5791773796081543
Epoch: 20, Steps: 128 Train Loss: 3.1225 (Forecasting Loss:0.2122 + XiCon Loss:2.9103 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1056335
	speed: 0.0125s/iter; left time: 126.3951s
Epoch: 21 cost time: 1.570500135421753
Epoch: 21, Steps: 128 Train Loss: 3.1201 (Forecasting Loss:0.2123 + XiCon Loss:2.9078 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1412010
	speed: 0.0128s/iter; left time: 128.0361s
Epoch: 22 cost time: 1.5819041728973389
Epoch: 22, Steps: 128 Train Loss: 3.1262 (Forecasting Loss:0.2123 + XiCon Loss:2.9138 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.162983 --> 0.162976).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1486635
	speed: 0.0124s/iter; left time: 122.9674s
Epoch: 23 cost time: 1.5496535301208496
Epoch: 23, Steps: 128 Train Loss: 3.1256 (Forecasting Loss:0.2123 + XiCon Loss:2.9133 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.2097588
	speed: 0.0122s/iter; left time: 118.8249s
Epoch: 24 cost time: 1.5229158401489258
Epoch: 24, Steps: 128 Train Loss: 3.1251 (Forecasting Loss:0.2122 + XiCon Loss:2.9129 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0587535
	speed: 0.0121s/iter; left time: 116.5993s
Epoch: 25 cost time: 1.5164666175842285
Epoch: 25, Steps: 128 Train Loss: 3.1224 (Forecasting Loss:0.2123 + XiCon Loss:2.9101 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0603235
	speed: 0.0126s/iter; left time: 120.0909s
Epoch: 26 cost time: 1.5697894096374512
Epoch: 26, Steps: 128 Train Loss: 3.1268 (Forecasting Loss:0.2122 + XiCon Loss:2.9146 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0863135
	speed: 0.0121s/iter; left time: 113.2956s
Epoch: 27 cost time: 1.5159637928009033
Epoch: 27, Steps: 128 Train Loss: 3.1223 (Forecasting Loss:0.2124 + XiCon Loss:2.9099 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0484450
	speed: 0.0122s/iter; left time: 112.5949s
Epoch: 28 cost time: 1.5219950675964355
Epoch: 28, Steps: 128 Train Loss: 3.1293 (Forecasting Loss:0.2123 + XiCon Loss:2.9170 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1297145
	speed: 0.0121s/iter; left time: 109.9599s
Epoch: 29 cost time: 1.5017261505126953
Epoch: 29, Steps: 128 Train Loss: 3.1259 (Forecasting Loss:0.2123 + XiCon Loss:2.9135 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1559846
	speed: 0.0124s/iter; left time: 111.0553s
Epoch: 30 cost time: 1.53828763961792
Epoch: 30, Steps: 128 Train Loss: 3.1232 (Forecasting Loss:0.2121 + XiCon Loss:2.9111 x Lambda(1.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1148
Validation loss decreased (0.162976 --> 0.162778).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1160293
	speed: 0.0134s/iter; left time: 118.6392s
Epoch: 31 cost time: 1.6451294422149658
Epoch: 31, Steps: 128 Train Loss: 3.1273 (Forecasting Loss:0.2122 + XiCon Loss:2.9152 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0826759
	speed: 0.0123s/iter; left time: 107.6193s
Epoch: 32 cost time: 1.5341923236846924
Epoch: 32, Steps: 128 Train Loss: 3.1227 (Forecasting Loss:0.2124 + XiCon Loss:2.9104 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.1028237
	speed: 0.0123s/iter; left time: 105.7087s
Epoch: 33 cost time: 1.5314710140228271
Epoch: 33, Steps: 128 Train Loss: 3.1258 (Forecasting Loss:0.2122 + XiCon Loss:2.9136 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0994489
	speed: 0.0124s/iter; left time: 105.4652s
Epoch: 34 cost time: 1.537440299987793
Epoch: 34, Steps: 128 Train Loss: 3.1257 (Forecasting Loss:0.2122 + XiCon Loss:2.9134 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.1355650
	speed: 0.0128s/iter; left time: 106.7045s
Epoch: 35 cost time: 1.5787405967712402
Epoch: 35, Steps: 128 Train Loss: 3.1206 (Forecasting Loss:0.2120 + XiCon Loss:2.9086 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.2565629
	speed: 0.0129s/iter; left time: 106.1490s
Epoch: 36 cost time: 1.6203844547271729
Epoch: 36, Steps: 128 Train Loss: 3.1222 (Forecasting Loss:0.2123 + XiCon Loss:2.9099 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.1348796
	speed: 0.0121s/iter; left time: 97.8471s
Epoch: 37 cost time: 1.5180883407592773
Epoch: 37, Steps: 128 Train Loss: 3.1227 (Forecasting Loss:0.2122 + XiCon Loss:2.9105 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.1419632
	speed: 0.0122s/iter; left time: 96.9203s
Epoch: 38 cost time: 1.5406718254089355
Epoch: 38, Steps: 128 Train Loss: 3.1222 (Forecasting Loss:0.2124 + XiCon Loss:2.9098 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 3.1297970
	speed: 0.0126s/iter; left time: 98.7061s
Epoch: 39 cost time: 1.5919063091278076
Epoch: 39, Steps: 128 Train Loss: 3.1193 (Forecasting Loss:0.2121 + XiCon Loss:2.9072 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 3.0731404
	speed: 0.0122s/iter; left time: 94.2531s
Epoch: 40 cost time: 1.5309839248657227
Epoch: 40, Steps: 128 Train Loss: 3.1179 (Forecasting Loss:0.2122 + XiCon Loss:2.9057 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05388272553682327, mae:0.17568673193454742, mape:0.13970763981342316, mspe:0.037136260420084 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2544
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3271246
	speed: 0.0124s/iter; left time: 157.2585s
Epoch: 1 cost time: 1.5512259006500244
Epoch: 1, Steps: 128 Train Loss: 3.3322 (Forecasting Loss:0.2453 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1239
Validation loss decreased (inf --> 0.175428).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1363096
	speed: 0.0125s/iter; left time: 156.6166s
Epoch: 2 cost time: 1.5508286952972412
Epoch: 2, Steps: 128 Train Loss: 3.1752 (Forecasting Loss:0.2504 + XiCon Loss:2.9248 x Lambda(1.0)), Vali MSE Loss: 0.1761 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1573439
	speed: 0.0123s/iter; left time: 153.0469s
Epoch: 3 cost time: 1.5291104316711426
Epoch: 3, Steps: 128 Train Loss: 3.2330 (Forecasting Loss:0.2290 + XiCon Loss:3.0041 x Lambda(1.0)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1200
Validation loss decreased (0.175428 --> 0.167791).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1865640
	speed: 0.0125s/iter; left time: 154.4600s
Epoch: 4 cost time: 1.5574049949645996
Epoch: 4, Steps: 128 Train Loss: 3.2086 (Forecasting Loss:0.2210 + XiCon Loss:2.9875 x Lambda(1.0)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1171
Validation loss decreased (0.167791 --> 0.167709).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1211641
	speed: 0.0126s/iter; left time: 153.6264s
Epoch: 5 cost time: 1.570838212966919
Epoch: 5, Steps: 128 Train Loss: 3.1576 (Forecasting Loss:0.2173 + XiCon Loss:2.9403 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1184
Validation loss decreased (0.167709 --> 0.165203).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1866145
	speed: 0.0125s/iter; left time: 150.2693s
Epoch: 6 cost time: 1.5576119422912598
Epoch: 6, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2150 + XiCon Loss:2.9171 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
Validation loss decreased (0.165203 --> 0.163426).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2017152
	speed: 0.0122s/iter; left time: 145.9168s
Epoch: 7 cost time: 1.5260088443756104
Epoch: 7, Steps: 128 Train Loss: 3.1280 (Forecasting Loss:0.2139 + XiCon Loss:2.9141 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0500185
	speed: 0.0122s/iter; left time: 143.9930s
Epoch: 8 cost time: 1.521348476409912
Epoch: 8, Steps: 128 Train Loss: 3.1137 (Forecasting Loss:0.2133 + XiCon Loss:2.9004 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0814576
	speed: 0.0122s/iter; left time: 141.9665s
Epoch: 9 cost time: 1.515887975692749
Epoch: 9, Steps: 128 Train Loss: 3.1215 (Forecasting Loss:0.2131 + XiCon Loss:2.9083 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
Validation loss decreased (0.163426 --> 0.163362).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0494740
	speed: 0.0127s/iter; left time: 146.6489s
Epoch: 10 cost time: 1.5937747955322266
Epoch: 10, Steps: 128 Train Loss: 3.1152 (Forecasting Loss:0.2130 + XiCon Loss:2.9022 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
Validation loss decreased (0.163362 --> 0.163228).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0562916
	speed: 0.0124s/iter; left time: 141.2445s
Epoch: 11 cost time: 1.5515575408935547
Epoch: 11, Steps: 128 Train Loss: 3.1151 (Forecasting Loss:0.2130 + XiCon Loss:2.9021 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2530890
	speed: 0.0126s/iter; left time: 142.2478s
Epoch: 12 cost time: 1.5607573986053467
Epoch: 12, Steps: 128 Train Loss: 3.1161 (Forecasting Loss:0.2127 + XiCon Loss:2.9033 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1436300
	speed: 0.0121s/iter; left time: 135.6285s
Epoch: 13 cost time: 1.515035629272461
Epoch: 13, Steps: 128 Train Loss: 3.1185 (Forecasting Loss:0.2128 + XiCon Loss:2.9057 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1784475
	speed: 0.0120s/iter; left time: 132.6646s
Epoch: 14 cost time: 1.5054197311401367
Epoch: 14, Steps: 128 Train Loss: 3.1176 (Forecasting Loss:0.2127 + XiCon Loss:2.9048 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
Validation loss decreased (0.163228 --> 0.163097).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0976343
	speed: 0.0122s/iter; left time: 133.2110s
Epoch: 15 cost time: 1.524055004119873
Epoch: 15, Steps: 128 Train Loss: 3.1160 (Forecasting Loss:0.2128 + XiCon Loss:2.9032 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0917444
	speed: 0.0123s/iter; left time: 132.6983s
Epoch: 16 cost time: 1.526771068572998
Epoch: 16, Steps: 128 Train Loss: 3.1149 (Forecasting Loss:0.2128 + XiCon Loss:2.9021 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1152
Validation loss decreased (0.163097 --> 0.163003).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0399528
	speed: 0.0123s/iter; left time: 130.6399s
Epoch: 17 cost time: 1.5478966236114502
Epoch: 17, Steps: 128 Train Loss: 3.1213 (Forecasting Loss:0.2127 + XiCon Loss:2.9087 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1202965
	speed: 0.0122s/iter; left time: 128.1923s
Epoch: 18 cost time: 1.5239894390106201
Epoch: 18, Steps: 128 Train Loss: 3.1106 (Forecasting Loss:0.2128 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0688629
	speed: 0.0126s/iter; left time: 131.1115s
Epoch: 19 cost time: 1.5540199279785156
Epoch: 19, Steps: 128 Train Loss: 3.1196 (Forecasting Loss:0.2127 + XiCon Loss:2.9069 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0613437
	speed: 0.0123s/iter; left time: 125.8365s
Epoch: 20 cost time: 1.5262119770050049
Epoch: 20, Steps: 128 Train Loss: 3.1120 (Forecasting Loss:0.2128 + XiCon Loss:2.8992 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0853181
	speed: 0.0124s/iter; left time: 125.4314s
Epoch: 21 cost time: 1.556067705154419
Epoch: 21, Steps: 128 Train Loss: 3.1243 (Forecasting Loss:0.2129 + XiCon Loss:2.9114 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1304202
	speed: 0.0124s/iter; left time: 123.7263s
Epoch: 22 cost time: 1.534970998764038
Epoch: 22, Steps: 128 Train Loss: 3.1121 (Forecasting Loss:0.2128 + XiCon Loss:2.8993 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1368666
	speed: 0.0125s/iter; left time: 123.2547s
Epoch: 23 cost time: 1.550537109375
Epoch: 23, Steps: 128 Train Loss: 3.1161 (Forecasting Loss:0.2129 + XiCon Loss:2.9032 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.2043233
	speed: 0.0131s/iter; left time: 127.7715s
Epoch: 24 cost time: 1.6506357192993164
Epoch: 24, Steps: 128 Train Loss: 3.1185 (Forecasting Loss:0.2127 + XiCon Loss:2.9058 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1152
Validation loss decreased (0.163003 --> 0.162885).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0660965
	speed: 0.0123s/iter; left time: 118.6756s
Epoch: 25 cost time: 1.5307011604309082
Epoch: 25, Steps: 128 Train Loss: 3.1063 (Forecasting Loss:0.2128 + XiCon Loss:2.8935 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1638784
	speed: 0.0129s/iter; left time: 122.7148s
Epoch: 26 cost time: 1.614875316619873
Epoch: 26, Steps: 128 Train Loss: 3.1171 (Forecasting Loss:0.2128 + XiCon Loss:2.9043 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1049647
	speed: 0.0121s/iter; left time: 113.1104s
Epoch: 27 cost time: 1.5073485374450684
Epoch: 27, Steps: 128 Train Loss: 3.1180 (Forecasting Loss:0.2128 + XiCon Loss:2.9052 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1015565
	speed: 0.0132s/iter; left time: 121.9405s
Epoch: 28 cost time: 1.6572144031524658
Epoch: 28, Steps: 128 Train Loss: 3.1169 (Forecasting Loss:0.2127 + XiCon Loss:2.9042 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1258519
	speed: 0.0124s/iter; left time: 113.3864s
Epoch: 29 cost time: 1.5472452640533447
Epoch: 29, Steps: 128 Train Loss: 3.1186 (Forecasting Loss:0.2128 + XiCon Loss:2.9058 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1268070
	speed: 0.0122s/iter; left time: 109.9307s
Epoch: 30 cost time: 1.5205729007720947
Epoch: 30, Steps: 128 Train Loss: 3.1204 (Forecasting Loss:0.2127 + XiCon Loss:2.9076 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1317303
	speed: 0.0120s/iter; left time: 106.2350s
Epoch: 31 cost time: 1.4997503757476807
Epoch: 31, Steps: 128 Train Loss: 3.1194 (Forecasting Loss:0.2128 + XiCon Loss:2.9066 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0940769
	speed: 0.0121s/iter; left time: 105.3527s
Epoch: 32 cost time: 1.505502700805664
Epoch: 32, Steps: 128 Train Loss: 3.1163 (Forecasting Loss:0.2127 + XiCon Loss:2.9037 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.1306136
	speed: 0.0123s/iter; left time: 105.8761s
Epoch: 33 cost time: 1.5287935733795166
Epoch: 33, Steps: 128 Train Loss: 3.1197 (Forecasting Loss:0.2128 + XiCon Loss:2.9069 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1152
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0614555
	speed: 0.0122s/iter; left time: 103.0286s
Epoch: 34 cost time: 1.5183820724487305
Epoch: 34, Steps: 128 Train Loss: 3.1159 (Forecasting Loss:0.2127 + XiCon Loss:2.9033 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05418981984257698, mae:0.17619098722934723, mape:0.13990332186222076, mspe:0.03710946813225746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0539+-0.00109, MAE:0.1766+-0.00218, MAPE:0.1407+-0.00164, MSPE:0.0376+-0.00111, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2575
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.4279842
	speed: 0.0163s/iter; left time: 204.2658s
Epoch: 1 cost time: 1.9423558712005615
Epoch: 1, Steps: 126 Train Loss: 31.4816 (Forecasting Loss:0.2773 + XiCon Loss:3.1204 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1441
Validation loss decreased (inf --> 0.197673).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3647003
	speed: 0.0151s/iter; left time: 186.2802s
Epoch: 2 cost time: 1.853658676147461
Epoch: 2, Steps: 126 Train Loss: 29.5322 (Forecasting Loss:0.2606 + XiCon Loss:2.9272 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.1408
Validation loss decreased (0.197673 --> 0.193049).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0076447
	speed: 0.0147s/iter; left time: 180.3279s
Epoch: 3 cost time: 1.8259053230285645
Epoch: 3, Steps: 126 Train Loss: 29.5277 (Forecasting Loss:0.2494 + XiCon Loss:2.9278 x Lambda(10.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1402
Validation loss decreased (0.193049 --> 0.185577).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.7469444
	speed: 0.0150s/iter; left time: 181.4903s
Epoch: 4 cost time: 1.8496713638305664
Epoch: 4, Steps: 126 Train Loss: 29.0997 (Forecasting Loss:0.2420 + XiCon Loss:2.8858 x Lambda(10.0)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1365
Validation loss decreased (0.185577 --> 0.184759).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.5435963
	speed: 0.0154s/iter; left time: 184.2746s
Epoch: 5 cost time: 1.8877828121185303
Epoch: 5, Steps: 126 Train Loss: 28.8908 (Forecasting Loss:0.2391 + XiCon Loss:2.8652 x Lambda(10.0)), Vali MSE Loss: 0.1824 Test MSE Loss: 0.1348
Validation loss decreased (0.184759 --> 0.182390).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3451118
	speed: 0.0149s/iter; left time: 176.4337s
Epoch: 6 cost time: 1.8416807651519775
Epoch: 6, Steps: 126 Train Loss: 28.7832 (Forecasting Loss:0.2378 + XiCon Loss:2.8545 x Lambda(10.0)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.1349
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.7266178
	speed: 0.0144s/iter; left time: 169.4068s
Epoch: 7 cost time: 1.7897775173187256
Epoch: 7, Steps: 126 Train Loss: 28.7234 (Forecasting Loss:0.2372 + XiCon Loss:2.8486 x Lambda(10.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1356
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.0814934
	speed: 0.0147s/iter; left time: 171.2126s
Epoch: 8 cost time: 1.8234715461730957
Epoch: 8, Steps: 126 Train Loss: 28.7139 (Forecasting Loss:0.2367 + XiCon Loss:2.8477 x Lambda(10.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.3686543
	speed: 0.0150s/iter; left time: 172.2544s
Epoch: 9 cost time: 1.856285810470581
Epoch: 9, Steps: 126 Train Loss: 28.7866 (Forecasting Loss:0.2361 + XiCon Loss:2.8551 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1349
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.3956985
	speed: 0.0145s/iter; left time: 165.3718s
Epoch: 10 cost time: 1.7998111248016357
Epoch: 10, Steps: 126 Train Loss: 28.6909 (Forecasting Loss:0.2368 + XiCon Loss:2.8454 x Lambda(10.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1350
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.6507320
	speed: 0.0147s/iter; left time: 165.7587s
Epoch: 11 cost time: 1.83241868019104
Epoch: 11, Steps: 126 Train Loss: 28.6602 (Forecasting Loss:0.2366 + XiCon Loss:2.8424 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1350
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6281528
	speed: 0.0147s/iter; left time: 163.5086s
Epoch: 12 cost time: 1.8230128288269043
Epoch: 12, Steps: 126 Train Loss: 28.7421 (Forecasting Loss:0.2363 + XiCon Loss:2.8506 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1350
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0048046
	speed: 0.0157s/iter; left time: 172.1085s
Epoch: 13 cost time: 1.9396612644195557
Epoch: 13, Steps: 126 Train Loss: 28.6932 (Forecasting Loss:0.2363 + XiCon Loss:2.8457 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.4697781
	speed: 0.0145s/iter; left time: 157.0219s
Epoch: 14 cost time: 1.7931244373321533
Epoch: 14, Steps: 126 Train Loss: 28.6429 (Forecasting Loss:0.2366 + XiCon Loss:2.8406 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1350
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.6768608
	speed: 0.0147s/iter; left time: 157.4232s
Epoch: 15 cost time: 1.8081495761871338
Epoch: 15, Steps: 126 Train Loss: 28.7339 (Forecasting Loss:0.2366 + XiCon Loss:2.8497 x Lambda(10.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1350
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06906658411026001, mae:0.20049884915351868, mape:0.1553662270307541, mspe:0.04367082566022873 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2200
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.2639332
	speed: 0.0134s/iter; left time: 167.2057s
Epoch: 1 cost time: 1.6511716842651367
Epoch: 1, Steps: 126 Train Loss: 31.3731 (Forecasting Loss:0.2793 + XiCon Loss:3.1094 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1449
Validation loss decreased (inf --> 0.198164).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.6624985
	speed: 0.0151s/iter; left time: 186.5711s
Epoch: 2 cost time: 1.9039440155029297
Epoch: 2, Steps: 126 Train Loss: 29.4266 (Forecasting Loss:0.2639 + XiCon Loss:2.9163 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1404
Validation loss decreased (0.198164 --> 0.197777).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8903656
	speed: 0.0157s/iter; left time: 191.8340s
Epoch: 3 cost time: 1.9384510517120361
Epoch: 3, Steps: 126 Train Loss: 29.6764 (Forecasting Loss:0.2536 + XiCon Loss:2.9423 x Lambda(10.0)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.1389
Validation loss decreased (0.197777 --> 0.189865).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.5017357
	speed: 0.0153s/iter; left time: 185.0504s
Epoch: 4 cost time: 1.89725923538208
Epoch: 4, Steps: 126 Train Loss: 29.5149 (Forecasting Loss:0.2475 + XiCon Loss:2.9267 x Lambda(10.0)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.1375
Validation loss decreased (0.189865 --> 0.188444).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4010010
	speed: 0.0153s/iter; left time: 183.3127s
Epoch: 5 cost time: 1.9132258892059326
Epoch: 5, Steps: 126 Train Loss: 29.3809 (Forecasting Loss:0.2431 + XiCon Loss:2.9138 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1326
Validation loss decreased (0.188444 --> 0.186508).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.0276928
	speed: 0.0153s/iter; left time: 182.1452s
Epoch: 6 cost time: 1.906038761138916
Epoch: 6, Steps: 126 Train Loss: 29.2491 (Forecasting Loss:0.2402 + XiCon Loss:2.9009 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1339
Validation loss decreased (0.186508 --> 0.186297).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.2856941
	speed: 0.0152s/iter; left time: 178.7750s
Epoch: 7 cost time: 1.8907575607299805
Epoch: 7, Steps: 126 Train Loss: 29.2687 (Forecasting Loss:0.2384 + XiCon Loss:2.9030 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1335
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3184605
	speed: 0.0155s/iter; left time: 180.3103s
Epoch: 8 cost time: 1.9241478443145752
Epoch: 8, Steps: 126 Train Loss: 29.1867 (Forecasting Loss:0.2376 + XiCon Loss:2.8949 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1334
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.7810192
	speed: 0.0153s/iter; left time: 175.8621s
Epoch: 9 cost time: 1.8975169658660889
Epoch: 9, Steps: 126 Train Loss: 29.1600 (Forecasting Loss:0.2373 + XiCon Loss:2.8923 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1333
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.7150440
	speed: 0.0153s/iter; left time: 174.4545s
Epoch: 10 cost time: 1.905341386795044
Epoch: 10, Steps: 126 Train Loss: 29.1787 (Forecasting Loss:0.2370 + XiCon Loss:2.8942 x Lambda(10.0)), Vali MSE Loss: 0.1867 Test MSE Loss: 0.1333
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.9786339
	speed: 0.0155s/iter; left time: 174.6525s
Epoch: 11 cost time: 1.93617582321167
Epoch: 11, Steps: 126 Train Loss: 29.1308 (Forecasting Loss:0.2367 + XiCon Loss:2.8894 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1333
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.9333706
	speed: 0.0153s/iter; left time: 170.0607s
Epoch: 12 cost time: 1.8977560997009277
Epoch: 12, Steps: 126 Train Loss: 29.1654 (Forecasting Loss:0.2369 + XiCon Loss:2.8928 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1333
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2444305
	speed: 0.0156s/iter; left time: 171.2545s
Epoch: 13 cost time: 1.9274146556854248
Epoch: 13, Steps: 126 Train Loss: 29.1750 (Forecasting Loss:0.2366 + XiCon Loss:2.8938 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1333
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.5726032
	speed: 0.0152s/iter; left time: 165.1173s
Epoch: 14 cost time: 1.8908443450927734
Epoch: 14, Steps: 126 Train Loss: 29.1429 (Forecasting Loss:0.2368 + XiCon Loss:2.8906 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1333
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9729786
	speed: 0.0154s/iter; left time: 164.9791s
Epoch: 15 cost time: 1.9034934043884277
Epoch: 15, Steps: 126 Train Loss: 29.1648 (Forecasting Loss:0.2369 + XiCon Loss:2.8928 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1333
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.0940609
	speed: 0.0157s/iter; left time: 166.0709s
Epoch: 16 cost time: 1.9537513256072998
Epoch: 16, Steps: 126 Train Loss: 29.1648 (Forecasting Loss:0.2369 + XiCon Loss:2.8928 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1333
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06726232916116714, mae:0.20047800242900848, mape:0.15416648983955383, mspe:0.04125165939331055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1365
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.3304539
	speed: 0.0137s/iter; left time: 170.8129s
Epoch: 1 cost time: 1.6839404106140137
Epoch: 1, Steps: 126 Train Loss: 31.3998 (Forecasting Loss:0.2787 + XiCon Loss:3.1121 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1455
Validation loss decreased (inf --> 0.198668).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.2921333
	speed: 0.0144s/iter; left time: 178.1233s
Epoch: 2 cost time: 1.8023107051849365
Epoch: 2, Steps: 126 Train Loss: 30.7236 (Forecasting Loss:0.2639 + XiCon Loss:3.0460 x Lambda(10.0)), Vali MSE Loss: 0.1919 Test MSE Loss: 0.1435
Validation loss decreased (0.198668 --> 0.191933).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.0465641
	speed: 0.0148s/iter; left time: 181.0011s
Epoch: 3 cost time: 1.826580286026001
Epoch: 3, Steps: 126 Train Loss: 30.7140 (Forecasting Loss:0.2515 + XiCon Loss:3.0462 x Lambda(10.0)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1380
Validation loss decreased (0.191933 --> 0.189374).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.6499329
	speed: 0.0149s/iter; left time: 180.2480s
Epoch: 4 cost time: 1.8504126071929932
Epoch: 4, Steps: 126 Train Loss: 30.2547 (Forecasting Loss:0.2476 + XiCon Loss:3.0007 x Lambda(10.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6974411
	speed: 0.0151s/iter; left time: 180.5825s
Epoch: 5 cost time: 1.8656432628631592
Epoch: 5, Steps: 126 Train Loss: 29.9109 (Forecasting Loss:0.2452 + XiCon Loss:2.9666 x Lambda(10.0)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1369
Validation loss decreased (0.189374 --> 0.185911).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3432884
	speed: 0.0151s/iter; left time: 179.0747s
Epoch: 6 cost time: 1.8621745109558105
Epoch: 6, Steps: 126 Train Loss: 29.6992 (Forecasting Loss:0.2435 + XiCon Loss:2.9456 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.0994015
	speed: 0.0149s/iter; left time: 175.5395s
Epoch: 7 cost time: 1.8562226295471191
Epoch: 7, Steps: 126 Train Loss: 29.6769 (Forecasting Loss:0.2431 + XiCon Loss:2.9434 x Lambda(10.0)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1369
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2138138
	speed: 0.0152s/iter; left time: 176.7468s
Epoch: 8 cost time: 1.881162405014038
Epoch: 8, Steps: 126 Train Loss: 29.6696 (Forecasting Loss:0.2427 + XiCon Loss:2.9427 x Lambda(10.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1367
Validation loss decreased (0.185911 --> 0.185590).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.0106392
	speed: 0.0148s/iter; left time: 170.6109s
Epoch: 9 cost time: 1.842226266860962
Epoch: 9, Steps: 126 Train Loss: 29.6289 (Forecasting Loss:0.2428 + XiCon Loss:2.9386 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.3378258
	speed: 0.0148s/iter; left time: 168.1915s
Epoch: 10 cost time: 1.8410427570343018
Epoch: 10, Steps: 126 Train Loss: 29.6134 (Forecasting Loss:0.2426 + XiCon Loss:2.9371 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.6350250
	speed: 0.0150s/iter; left time: 168.9245s
Epoch: 11 cost time: 1.8613362312316895
Epoch: 11, Steps: 126 Train Loss: 29.6251 (Forecasting Loss:0.2424 + XiCon Loss:2.9383 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1364
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3404732
	speed: 0.0151s/iter; left time: 168.0133s
Epoch: 12 cost time: 1.8690235614776611
Epoch: 12, Steps: 126 Train Loss: 29.6021 (Forecasting Loss:0.2424 + XiCon Loss:2.9360 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6826096
	speed: 0.0159s/iter; left time: 174.3147s
Epoch: 13 cost time: 1.9419147968292236
Epoch: 13, Steps: 126 Train Loss: 29.5686 (Forecasting Loss:0.2423 + XiCon Loss:2.9326 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1364
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1978474
	speed: 0.0150s/iter; left time: 163.2642s
Epoch: 14 cost time: 1.8747529983520508
Epoch: 14, Steps: 126 Train Loss: 29.6094 (Forecasting Loss:0.2423 + XiCon Loss:2.9367 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.9882774
	speed: 0.0149s/iter; left time: 159.5480s
Epoch: 15 cost time: 1.8459558486938477
Epoch: 15, Steps: 126 Train Loss: 29.6087 (Forecasting Loss:0.2425 + XiCon Loss:2.9366 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1364
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.1447239
	speed: 0.0152s/iter; left time: 161.1910s
Epoch: 16 cost time: 1.8760433197021484
Epoch: 16, Steps: 126 Train Loss: 29.5871 (Forecasting Loss:0.2423 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.8307590
	speed: 0.0152s/iter; left time: 159.6704s
Epoch: 17 cost time: 1.8813257217407227
Epoch: 17, Steps: 126 Train Loss: 29.5731 (Forecasting Loss:0.2421 + XiCon Loss:2.9331 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1364
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.4436359
	speed: 0.0149s/iter; left time: 154.3115s
Epoch: 18 cost time: 1.8465688228607178
Epoch: 18, Steps: 126 Train Loss: 29.5815 (Forecasting Loss:0.2424 + XiCon Loss:2.9339 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1364
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07016231119632721, mae:0.20318494737148285, mape:0.1551457941532135, mspe:0.04157741740345955 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2988
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.0717239
	speed: 0.0136s/iter; left time: 170.6039s
Epoch: 1 cost time: 1.6860988140106201
Epoch: 1, Steps: 126 Train Loss: 31.2923 (Forecasting Loss:0.2792 + XiCon Loss:3.1013 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1442
Validation loss decreased (inf --> 0.196079).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.2506809
	speed: 0.0155s/iter; left time: 192.1277s
Epoch: 2 cost time: 1.9341790676116943
Epoch: 2, Steps: 126 Train Loss: 29.6400 (Forecasting Loss:0.2639 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1515
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6129551
	speed: 0.0152s/iter; left time: 186.5806s
Epoch: 3 cost time: 1.901695966720581
Epoch: 3, Steps: 126 Train Loss: 30.5563 (Forecasting Loss:0.2499 + XiCon Loss:3.0306 x Lambda(10.0)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.1373
Validation loss decreased (0.196079 --> 0.187953).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.0712566
	speed: 0.0153s/iter; left time: 185.7242s
Epoch: 4 cost time: 1.8903634548187256
Epoch: 4, Steps: 126 Train Loss: 30.3199 (Forecasting Loss:0.2461 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1383
Validation loss decreased (0.187953 --> 0.186470).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8399353
	speed: 0.0155s/iter; left time: 185.7828s
Epoch: 5 cost time: 1.9134540557861328
Epoch: 5, Steps: 126 Train Loss: 30.0806 (Forecasting Loss:0.2439 + XiCon Loss:2.9837 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1346
Validation loss decreased (0.186470 --> 0.185812).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.9040565
	speed: 0.0154s/iter; left time: 182.9904s
Epoch: 6 cost time: 1.915116310119629
Epoch: 6, Steps: 126 Train Loss: 29.9956 (Forecasting Loss:0.2421 + XiCon Loss:2.9753 x Lambda(10.0)), Vali MSE Loss: 0.1860 Test MSE Loss: 0.1333
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0498829
	speed: 0.0153s/iter; left time: 179.6036s
Epoch: 7 cost time: 1.8863446712493896
Epoch: 7, Steps: 126 Train Loss: 30.0239 (Forecasting Loss:0.2411 + XiCon Loss:2.9783 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1347
Validation loss decreased (0.185812 --> 0.185332).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2161522
	speed: 0.0160s/iter; left time: 185.6649s
Epoch: 8 cost time: 1.9967670440673828
Epoch: 8, Steps: 126 Train Loss: 29.9030 (Forecasting Loss:0.2406 + XiCon Loss:2.9662 x Lambda(10.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1347
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.5434933
	speed: 0.0152s/iter; left time: 175.1304s
Epoch: 9 cost time: 1.8886425495147705
Epoch: 9, Steps: 126 Train Loss: 29.9671 (Forecasting Loss:0.2402 + XiCon Loss:2.9727 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
Validation loss decreased (0.185332 --> 0.185304).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6315250
	speed: 0.0152s/iter; left time: 172.3304s
Epoch: 10 cost time: 1.8789784908294678
Epoch: 10, Steps: 126 Train Loss: 29.8968 (Forecasting Loss:0.2401 + XiCon Loss:2.9657 x Lambda(10.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1348
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5992107
	speed: 0.0153s/iter; left time: 171.4491s
Epoch: 11 cost time: 1.891505241394043
Epoch: 11, Steps: 126 Train Loss: 29.9628 (Forecasting Loss:0.2398 + XiCon Loss:2.9723 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.0455036
	speed: 0.0155s/iter; left time: 171.7611s
Epoch: 12 cost time: 1.9115345478057861
Epoch: 12, Steps: 126 Train Loss: 29.9420 (Forecasting Loss:0.2399 + XiCon Loss:2.9702 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6255474
	speed: 0.0154s/iter; left time: 169.5311s
Epoch: 13 cost time: 1.9499435424804688
Epoch: 13, Steps: 126 Train Loss: 29.9065 (Forecasting Loss:0.2400 + XiCon Loss:2.9667 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
Validation loss decreased (0.185304 --> 0.185282).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1656170
	speed: 0.0164s/iter; left time: 177.7728s
Epoch: 14 cost time: 2.043414354324341
Epoch: 14, Steps: 126 Train Loss: 29.9217 (Forecasting Loss:0.2399 + XiCon Loss:2.9682 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
Validation loss decreased (0.185282 --> 0.185254).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.7089958
	speed: 0.0152s/iter; left time: 162.9014s
Epoch: 15 cost time: 1.8747625350952148
Epoch: 15, Steps: 126 Train Loss: 29.9136 (Forecasting Loss:0.2398 + XiCon Loss:2.9674 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6805191
	speed: 0.0151s/iter; left time: 160.1633s
Epoch: 16 cost time: 1.871321201324463
Epoch: 16, Steps: 126 Train Loss: 29.8683 (Forecasting Loss:0.2401 + XiCon Loss:2.9628 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.0051327
	speed: 0.0158s/iter; left time: 165.2770s
Epoch: 17 cost time: 1.9747328758239746
Epoch: 17, Steps: 126 Train Loss: 29.9396 (Forecasting Loss:0.2398 + XiCon Loss:2.9700 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0089512
	speed: 0.0153s/iter; left time: 158.5444s
Epoch: 18 cost time: 1.895056962966919
Epoch: 18, Steps: 126 Train Loss: 29.9895 (Forecasting Loss:0.2400 + XiCon Loss:2.9749 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.4925385
	speed: 0.0159s/iter; left time: 162.6682s
Epoch: 19 cost time: 1.9501469135284424
Epoch: 19, Steps: 126 Train Loss: 29.8669 (Forecasting Loss:0.2399 + XiCon Loss:2.9627 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.3723221
	speed: 0.0160s/iter; left time: 161.9919s
Epoch: 20 cost time: 1.9956386089324951
Epoch: 20, Steps: 126 Train Loss: 29.9989 (Forecasting Loss:0.2398 + XiCon Loss:2.9759 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.0984554
	speed: 0.0150s/iter; left time: 150.0648s
Epoch: 21 cost time: 1.8627004623413086
Epoch: 21, Steps: 126 Train Loss: 29.9794 (Forecasting Loss:0.2398 + XiCon Loss:2.9740 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.1899529
	speed: 0.0152s/iter; left time: 149.5130s
Epoch: 22 cost time: 1.8783059120178223
Epoch: 22, Steps: 126 Train Loss: 29.9663 (Forecasting Loss:0.2396 + XiCon Loss:2.9727 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.6708641
	speed: 0.0151s/iter; left time: 146.9033s
Epoch: 23 cost time: 1.8716793060302734
Epoch: 23, Steps: 126 Train Loss: 29.9470 (Forecasting Loss:0.2400 + XiCon Loss:2.9707 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.8554478
	speed: 0.0154s/iter; left time: 148.0832s
Epoch: 24 cost time: 1.8972861766815186
Epoch: 24, Steps: 126 Train Loss: 29.8977 (Forecasting Loss:0.2398 + XiCon Loss:2.9658 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1348
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06884467601776123, mae:0.20077981054782867, mape:0.15355676412582397, mspe:0.041155047714710236 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2432
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.1902905
	speed: 0.0145s/iter; left time: 181.0057s
Epoch: 1 cost time: 1.7914493083953857
Epoch: 1, Steps: 126 Train Loss: 31.3797 (Forecasting Loss:0.2768 + XiCon Loss:3.1103 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1449
Validation loss decreased (inf --> 0.195462).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4729805
	speed: 0.0159s/iter; left time: 196.2848s
Epoch: 2 cost time: 1.9841995239257812
Epoch: 2, Steps: 126 Train Loss: 29.3285 (Forecasting Loss:0.2636 + XiCon Loss:2.9065 x Lambda(10.0)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1445
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.1424370
	speed: 0.0151s/iter; left time: 184.7684s
Epoch: 3 cost time: 1.8734230995178223
Epoch: 3, Steps: 126 Train Loss: 29.0740 (Forecasting Loss:0.2504 + XiCon Loss:2.8824 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1338
Validation loss decreased (0.195462 --> 0.186242).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7509155
	speed: 0.0152s/iter; left time: 183.7712s
Epoch: 4 cost time: 1.8792214393615723
Epoch: 4, Steps: 126 Train Loss: 29.6050 (Forecasting Loss:0.2465 + XiCon Loss:2.9359 x Lambda(10.0)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1367
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4418793
	speed: 0.0154s/iter; left time: 184.4763s
Epoch: 5 cost time: 1.9282493591308594
Epoch: 5, Steps: 126 Train Loss: 29.4936 (Forecasting Loss:0.2450 + XiCon Loss:2.9249 x Lambda(10.0)), Vali MSE Loss: 0.1860 Test MSE Loss: 0.1322
Validation loss decreased (0.186242 --> 0.185967).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3247337
	speed: 0.0153s/iter; left time: 181.9092s
Epoch: 6 cost time: 1.8888840675354004
Epoch: 6, Steps: 126 Train Loss: 29.3353 (Forecasting Loss:0.2432 + XiCon Loss:2.9092 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1351
Validation loss decreased (0.185967 --> 0.185291).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.3331547
	speed: 0.0146s/iter; left time: 171.9718s
Epoch: 7 cost time: 1.8199970722198486
Epoch: 7, Steps: 126 Train Loss: 29.2751 (Forecasting Loss:0.2426 + XiCon Loss:2.9033 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1347
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.8714848
	speed: 0.0150s/iter; left time: 173.7090s
Epoch: 8 cost time: 1.8515639305114746
Epoch: 8, Steps: 126 Train Loss: 29.3354 (Forecasting Loss:0.2421 + XiCon Loss:2.9093 x Lambda(10.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1831551
	speed: 0.0152s/iter; left time: 174.7623s
Epoch: 9 cost time: 1.8784935474395752
Epoch: 9, Steps: 126 Train Loss: 29.2827 (Forecasting Loss:0.2419 + XiCon Loss:2.9041 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
Validation loss decreased (0.185291 --> 0.185285).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7324696
	speed: 0.0145s/iter; left time: 164.6282s
Epoch: 10 cost time: 1.7968263626098633
Epoch: 10, Steps: 126 Train Loss: 29.2700 (Forecasting Loss:0.2417 + XiCon Loss:2.9028 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0769424
	speed: 0.0146s/iter; left time: 163.9490s
Epoch: 11 cost time: 1.8086192607879639
Epoch: 11, Steps: 126 Train Loss: 29.2707 (Forecasting Loss:0.2415 + XiCon Loss:2.9029 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3652172
	speed: 0.0149s/iter; left time: 165.2872s
Epoch: 12 cost time: 1.835526943206787
Epoch: 12, Steps: 126 Train Loss: 29.2473 (Forecasting Loss:0.2418 + XiCon Loss:2.9006 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.7531013
	speed: 0.0154s/iter; left time: 169.0422s
Epoch: 13 cost time: 1.8908607959747314
Epoch: 13, Steps: 126 Train Loss: 29.2406 (Forecasting Loss:0.2416 + XiCon Loss:2.8999 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2486191
	speed: 0.0147s/iter; left time: 159.4003s
Epoch: 14 cost time: 1.8217175006866455
Epoch: 14, Steps: 126 Train Loss: 29.2610 (Forecasting Loss:0.2413 + XiCon Loss:2.9020 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.1471939
	speed: 0.0148s/iter; left time: 158.9286s
Epoch: 15 cost time: 1.8490853309631348
Epoch: 15, Steps: 126 Train Loss: 29.2794 (Forecasting Loss:0.2416 + XiCon Loss:2.9038 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1343
Validation loss decreased (0.185285 --> 0.185248).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.8821030
	speed: 0.0147s/iter; left time: 156.3684s
Epoch: 16 cost time: 1.824371576309204
Epoch: 16, Steps: 126 Train Loss: 29.2899 (Forecasting Loss:0.2416 + XiCon Loss:2.9048 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.8071461
	speed: 0.0151s/iter; left time: 158.0203s
Epoch: 17 cost time: 1.8680675029754639
Epoch: 17, Steps: 126 Train Loss: 29.2944 (Forecasting Loss:0.2417 + XiCon Loss:2.9053 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0470963
	speed: 0.0147s/iter; left time: 152.5429s
Epoch: 18 cost time: 1.8287885189056396
Epoch: 18, Steps: 126 Train Loss: 29.2459 (Forecasting Loss:0.2413 + XiCon Loss:2.9005 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8707600
	speed: 0.0150s/iter; left time: 153.2106s
Epoch: 19 cost time: 1.8489229679107666
Epoch: 19, Steps: 126 Train Loss: 29.3065 (Forecasting Loss:0.2416 + XiCon Loss:2.9065 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.0517635
	speed: 0.0145s/iter; left time: 147.0259s
Epoch: 20 cost time: 1.8079330921173096
Epoch: 20, Steps: 126 Train Loss: 29.3020 (Forecasting Loss:0.2414 + XiCon Loss:2.9061 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.1042347
	speed: 0.0146s/iter; left time: 145.6888s
Epoch: 21 cost time: 1.8255138397216797
Epoch: 21, Steps: 126 Train Loss: 29.2757 (Forecasting Loss:0.2415 + XiCon Loss:2.9034 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.0444508
	speed: 0.0148s/iter; left time: 145.7096s
Epoch: 22 cost time: 1.832247018814087
Epoch: 22, Steps: 126 Train Loss: 29.2733 (Forecasting Loss:0.2415 + XiCon Loss:2.9032 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.3209496
	speed: 0.0146s/iter; left time: 142.3530s
Epoch: 23 cost time: 1.8390898704528809
Epoch: 23, Steps: 126 Train Loss: 29.2527 (Forecasting Loss:0.2415 + XiCon Loss:2.9011 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 28.8265419
	speed: 0.0146s/iter; left time: 140.3552s
Epoch: 24 cost time: 1.8134980201721191
Epoch: 24, Steps: 126 Train Loss: 29.2443 (Forecasting Loss:0.2416 + XiCon Loss:2.9003 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 28.9524155
	speed: 0.0146s/iter; left time: 138.1911s
Epoch: 25 cost time: 1.810290813446045
Epoch: 25, Steps: 126 Train Loss: 29.3374 (Forecasting Loss:0.2415 + XiCon Loss:2.9096 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1343
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06867095082998276, mae:0.19996985793113708, mape:0.15272067487239838, mspe:0.04074931517243385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0688+-0.00129, MAE:0.2010+-0.00157, MAPE:0.1542+-0.00137, MSPE:0.0417+-0.00143, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3158
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 31.4219608
	speed: 0.0207s/iter; left time: 254.5258s
Epoch: 1 cost time: 2.4607152938842773
Epoch: 1, Steps: 124 Train Loss: 31.4522 (Forecasting Loss:0.2940 + XiCon Loss:3.1158 x Lambda(10.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1623
Validation loss decreased (inf --> 0.216244).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6733074
	speed: 0.0179s/iter; left time: 218.3006s
Epoch: 2 cost time: 2.2285866737365723
Epoch: 2, Steps: 124 Train Loss: 30.0022 (Forecasting Loss:0.2815 + XiCon Loss:2.9721 x Lambda(10.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1608
Validation loss decreased (0.216244 --> 0.208625).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.1338348
	speed: 0.0222s/iter; left time: 267.1519s
Epoch: 3 cost time: 2.7425620555877686
Epoch: 3, Steps: 124 Train Loss: 30.0460 (Forecasting Loss:0.2652 + XiCon Loss:2.9781 x Lambda(10.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3282204
	speed: 0.0228s/iter; left time: 271.7421s
Epoch: 4 cost time: 2.8013246059417725
Epoch: 4, Steps: 124 Train Loss: 29.5979 (Forecasting Loss:0.2585 + XiCon Loss:2.9339 x Lambda(10.0)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1461
Validation loss decreased (0.208625 --> 0.205931).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5510941
	speed: 0.0229s/iter; left time: 269.8681s
Epoch: 5 cost time: 2.809072971343994
Epoch: 5, Steps: 124 Train Loss: 29.5015 (Forecasting Loss:0.2550 + XiCon Loss:2.9247 x Lambda(10.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1449
Validation loss decreased (0.205931 --> 0.204975).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.1085339
	speed: 0.0229s/iter; left time: 266.9963s
Epoch: 6 cost time: 2.833921194076538
Epoch: 6, Steps: 124 Train Loss: 29.4346 (Forecasting Loss:0.2528 + XiCon Loss:2.9182 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1456
Validation loss decreased (0.204975 --> 0.203190).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1111183
	speed: 0.0230s/iter; left time: 265.7227s
Epoch: 7 cost time: 2.8145711421966553
Epoch: 7, Steps: 124 Train Loss: 29.3492 (Forecasting Loss:0.2518 + XiCon Loss:2.9097 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1446
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.9845104
	speed: 0.0225s/iter; left time: 256.9955s
Epoch: 8 cost time: 2.776766300201416
Epoch: 8, Steps: 124 Train Loss: 29.3147 (Forecasting Loss:0.2511 + XiCon Loss:2.9064 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1452
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4271946
	speed: 0.0228s/iter; left time: 257.2816s
Epoch: 9 cost time: 2.797168016433716
Epoch: 9, Steps: 124 Train Loss: 29.3694 (Forecasting Loss:0.2511 + XiCon Loss:2.9118 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1455
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0883865
	speed: 0.0224s/iter; left time: 250.8319s
Epoch: 10 cost time: 2.77040433883667
Epoch: 10, Steps: 124 Train Loss: 29.3649 (Forecasting Loss:0.2510 + XiCon Loss:2.9114 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1453
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.9871788
	speed: 0.0227s/iter; left time: 250.9052s
Epoch: 11 cost time: 2.7918856143951416
Epoch: 11, Steps: 124 Train Loss: 29.3712 (Forecasting Loss:0.2512 + XiCon Loss:2.9120 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1452
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.8683586
	speed: 0.0225s/iter; left time: 246.5146s
Epoch: 12 cost time: 2.7690064907073975
Epoch: 12, Steps: 124 Train Loss: 29.3697 (Forecasting Loss:0.2510 + XiCon Loss:2.9119 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1452
Validation loss decreased (0.203190 --> 0.203121).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4863110
	speed: 0.0225s/iter; left time: 243.2475s
Epoch: 13 cost time: 2.76763653755188
Epoch: 13, Steps: 124 Train Loss: 29.3481 (Forecasting Loss:0.2505 + XiCon Loss:2.9098 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1452
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.8891239
	speed: 0.0230s/iter; left time: 245.8323s
Epoch: 14 cost time: 2.8146677017211914
Epoch: 14, Steps: 124 Train Loss: 29.3476 (Forecasting Loss:0.2505 + XiCon Loss:2.9097 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1452
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9945774
	speed: 0.0225s/iter; left time: 237.2039s
Epoch: 15 cost time: 2.766758918762207
Epoch: 15, Steps: 124 Train Loss: 29.3618 (Forecasting Loss:0.2505 + XiCon Loss:2.9111 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1452
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.4309845
	speed: 0.0227s/iter; left time: 237.3088s
Epoch: 16 cost time: 2.8032913208007812
Epoch: 16, Steps: 124 Train Loss: 29.3856 (Forecasting Loss:0.2510 + XiCon Loss:2.9135 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1452
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6606159
	speed: 0.0229s/iter; left time: 236.4687s
Epoch: 17 cost time: 2.8349692821502686
Epoch: 17, Steps: 124 Train Loss: 29.3371 (Forecasting Loss:0.2504 + XiCon Loss:2.9087 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1452
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.9277802
	speed: 0.0227s/iter; left time: 231.4600s
Epoch: 18 cost time: 2.786168336868286
Epoch: 18, Steps: 124 Train Loss: 29.3150 (Forecasting Loss:0.2508 + XiCon Loss:2.9064 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1452
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.4745083
	speed: 0.0224s/iter; left time: 225.5262s
Epoch: 19 cost time: 2.7609293460845947
Epoch: 19, Steps: 124 Train Loss: 29.3551 (Forecasting Loss:0.2506 + XiCon Loss:2.9105 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1452
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.7657585
	speed: 0.0225s/iter; left time: 224.1960s
Epoch: 20 cost time: 2.775296926498413
Epoch: 20, Steps: 124 Train Loss: 29.3777 (Forecasting Loss:0.2508 + XiCon Loss:2.9127 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1452
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.3830795
	speed: 0.0228s/iter; left time: 223.7244s
Epoch: 21 cost time: 2.8016951084136963
Epoch: 21, Steps: 124 Train Loss: 29.4062 (Forecasting Loss:0.2506 + XiCon Loss:2.9156 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1452
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.3354759
	speed: 0.0226s/iter; left time: 219.1114s
Epoch: 22 cost time: 2.790369749069214
Epoch: 22, Steps: 124 Train Loss: 29.3773 (Forecasting Loss:0.2507 + XiCon Loss:2.9127 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1452
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07469039410352707, mae:0.21572966873645782, mape:0.1635431945323944, mspe:0.045614805072546005 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2479
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 31.1827049
	speed: 0.0179s/iter; left time: 220.5571s
Epoch: 1 cost time: 2.2046499252319336
Epoch: 1, Steps: 124 Train Loss: 31.4200 (Forecasting Loss:0.2945 + XiCon Loss:3.1125 x Lambda(10.0)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1619
Validation loss decreased (inf --> 0.215884).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.5796967
	speed: 0.0189s/iter; left time: 230.3295s
Epoch: 2 cost time: 2.3291614055633545
Epoch: 2, Steps: 124 Train Loss: 30.1926 (Forecasting Loss:0.2818 + XiCon Loss:2.9911 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1533
Validation loss decreased (0.215884 --> 0.215319).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5883808
	speed: 0.0198s/iter; left time: 238.8780s
Epoch: 3 cost time: 2.470292329788208
Epoch: 3, Steps: 124 Train Loss: 30.4705 (Forecasting Loss:0.2677 + XiCon Loss:3.0203 x Lambda(10.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.1573
Validation loss decreased (0.215319 --> 0.214963).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7680130
	speed: 0.0216s/iter; left time: 257.4966s
Epoch: 4 cost time: 2.6512773036956787
Epoch: 4, Steps: 124 Train Loss: 30.0191 (Forecasting Loss:0.2579 + XiCon Loss:2.9761 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1543
Validation loss decreased (0.214963 --> 0.208034).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6928596
	speed: 0.0219s/iter; left time: 259.0188s
Epoch: 5 cost time: 2.6932544708251953
Epoch: 5, Steps: 124 Train Loss: 29.9432 (Forecasting Loss:0.2546 + XiCon Loss:2.9689 x Lambda(10.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.1525
Validation loss decreased (0.208034 --> 0.204834).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4367561
	speed: 0.0216s/iter; left time: 252.0038s
Epoch: 6 cost time: 2.6702141761779785
Epoch: 6, Steps: 124 Train Loss: 29.9117 (Forecasting Loss:0.2530 + XiCon Loss:2.9659 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1497
Validation loss decreased (0.204834 --> 0.203551).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.2591877
	speed: 0.0219s/iter; left time: 253.2256s
Epoch: 7 cost time: 2.6973516941070557
Epoch: 7, Steps: 124 Train Loss: 29.8086 (Forecasting Loss:0.2514 + XiCon Loss:2.9557 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1498
Validation loss decreased (0.203551 --> 0.202965).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3513412
	speed: 0.0223s/iter; left time: 255.3102s
Epoch: 8 cost time: 2.7529091835021973
Epoch: 8, Steps: 124 Train Loss: 29.7425 (Forecasting Loss:0.2509 + XiCon Loss:2.9492 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1501
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.5310459
	speed: 0.0221s/iter; left time: 249.6512s
Epoch: 9 cost time: 2.715092658996582
Epoch: 9, Steps: 124 Train Loss: 29.7434 (Forecasting Loss:0.2510 + XiCon Loss:2.9492 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1497
Validation loss decreased (0.202965 --> 0.202787).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.4619904
	speed: 0.0221s/iter; left time: 247.2041s
Epoch: 10 cost time: 2.7101571559906006
Epoch: 10, Steps: 124 Train Loss: 29.8194 (Forecasting Loss:0.2510 + XiCon Loss:2.9568 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1498
Validation loss decreased (0.202787 --> 0.202742).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1810551
	speed: 0.0222s/iter; left time: 245.6329s
Epoch: 11 cost time: 2.743530750274658
Epoch: 11, Steps: 124 Train Loss: 29.7714 (Forecasting Loss:0.2506 + XiCon Loss:2.9521 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1499
Validation loss decreased (0.202742 --> 0.202633).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0394135
	speed: 0.0223s/iter; left time: 243.5585s
Epoch: 12 cost time: 2.7322146892547607
Epoch: 12, Steps: 124 Train Loss: 29.7762 (Forecasting Loss:0.2503 + XiCon Loss:2.9526 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1499
Validation loss decreased (0.202633 --> 0.202439).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4336414
	speed: 0.0220s/iter; left time: 237.3926s
Epoch: 13 cost time: 2.7063381671905518
Epoch: 13, Steps: 124 Train Loss: 29.7884 (Forecasting Loss:0.2501 + XiCon Loss:2.9538 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1499
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4519882
	speed: 0.0222s/iter; left time: 237.3561s
Epoch: 14 cost time: 2.7473526000976562
Epoch: 14, Steps: 124 Train Loss: 29.7407 (Forecasting Loss:0.2502 + XiCon Loss:2.9491 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1499
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.7260838
	speed: 0.0224s/iter; left time: 236.3581s
Epoch: 15 cost time: 2.747859001159668
Epoch: 15, Steps: 124 Train Loss: 29.7918 (Forecasting Loss:0.2500 + XiCon Loss:2.9542 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1498
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8711281
	speed: 0.0224s/iter; left time: 234.2002s
Epoch: 16 cost time: 2.758481025695801
Epoch: 16, Steps: 124 Train Loss: 29.7893 (Forecasting Loss:0.2504 + XiCon Loss:2.9539 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1498
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6792660
	speed: 0.0223s/iter; left time: 229.6484s
Epoch: 17 cost time: 2.740906000137329
Epoch: 17, Steps: 124 Train Loss: 29.7982 (Forecasting Loss:0.2506 + XiCon Loss:2.9548 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1498
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.4157162
	speed: 0.0218s/iter; left time: 222.6089s
Epoch: 18 cost time: 2.6953847408294678
Epoch: 18, Steps: 124 Train Loss: 29.8185 (Forecasting Loss:0.2500 + XiCon Loss:2.9568 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1498
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.7075920
	speed: 0.0222s/iter; left time: 223.0741s
Epoch: 19 cost time: 2.7231388092041016
Epoch: 19, Steps: 124 Train Loss: 29.7558 (Forecasting Loss:0.2502 + XiCon Loss:2.9506 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1498
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.7559490
	speed: 0.0220s/iter; left time: 218.4786s
Epoch: 20 cost time: 2.7055327892303467
Epoch: 20, Steps: 124 Train Loss: 29.7597 (Forecasting Loss:0.2505 + XiCon Loss:2.9509 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1498
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.4654388
	speed: 0.0218s/iter; left time: 214.3628s
Epoch: 21 cost time: 2.6937646865844727
Epoch: 21, Steps: 124 Train Loss: 29.7949 (Forecasting Loss:0.2502 + XiCon Loss:2.9545 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1498
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.0507755
	speed: 0.0224s/iter; left time: 217.5251s
Epoch: 22 cost time: 2.7724225521087646
Epoch: 22, Steps: 124 Train Loss: 29.8654 (Forecasting Loss:0.2505 + XiCon Loss:2.9615 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1498
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07825363427400589, mae:0.22146731615066528, mape:0.16615575551986694, mspe:0.04624762013554573 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1816
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 31.1817684
	speed: 0.0181s/iter; left time: 223.2425s
Epoch: 1 cost time: 2.220062732696533
Epoch: 1, Steps: 124 Train Loss: 31.5185 (Forecasting Loss:0.2989 + XiCon Loss:3.1220 x Lambda(10.0)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1631
Validation loss decreased (inf --> 0.217386).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.6863213
	speed: 0.0182s/iter; left time: 222.0334s
Epoch: 2 cost time: 2.307340145111084
Epoch: 2, Steps: 124 Train Loss: 30.4399 (Forecasting Loss:0.2853 + XiCon Loss:3.0155 x Lambda(10.0)), Vali MSE Loss: 0.2170 Test MSE Loss: 0.1557
Validation loss decreased (0.217386 --> 0.217019).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8680439
	speed: 0.0205s/iter; left time: 247.5716s
Epoch: 3 cost time: 2.5586562156677246
Epoch: 3, Steps: 124 Train Loss: 30.5889 (Forecasting Loss:0.2644 + XiCon Loss:3.0325 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1458
Validation loss decreased (0.217019 --> 0.209262).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1682472
	speed: 0.0209s/iter; left time: 248.8398s
Epoch: 4 cost time: 2.5675289630889893
Epoch: 4, Steps: 124 Train Loss: 30.1842 (Forecasting Loss:0.2537 + XiCon Loss:2.9931 x Lambda(10.0)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1474
Validation loss decreased (0.209262 --> 0.205888).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9693527
	speed: 0.0210s/iter; left time: 248.2854s
Epoch: 5 cost time: 2.572890281677246
Epoch: 5, Steps: 124 Train Loss: 29.9902 (Forecasting Loss:0.2491 + XiCon Loss:2.9741 x Lambda(10.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1469
Validation loss decreased (0.205888 --> 0.205515).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6684856
	speed: 0.0207s/iter; left time: 241.5572s
Epoch: 6 cost time: 2.5470380783081055
Epoch: 6, Steps: 124 Train Loss: 29.8464 (Forecasting Loss:0.2466 + XiCon Loss:2.9600 x Lambda(10.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1438
Validation loss decreased (0.205515 --> 0.204871).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4492416
	speed: 0.0206s/iter; left time: 237.8971s
Epoch: 7 cost time: 2.5428965091705322
Epoch: 7, Steps: 124 Train Loss: 29.8297 (Forecasting Loss:0.2465 + XiCon Loss:2.9583 x Lambda(10.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1421
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9397354
	speed: 0.0207s/iter; left time: 236.6203s
Epoch: 8 cost time: 2.547464609146118
Epoch: 8, Steps: 124 Train Loss: 29.7863 (Forecasting Loss:0.2457 + XiCon Loss:2.9541 x Lambda(10.0)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.1423
Validation loss decreased (0.204871 --> 0.203832).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.0903835
	speed: 0.0208s/iter; left time: 235.0925s
Epoch: 9 cost time: 2.5700581073760986
Epoch: 9, Steps: 124 Train Loss: 29.8115 (Forecasting Loss:0.2456 + XiCon Loss:2.9566 x Lambda(10.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1421
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.3610649
	speed: 0.0212s/iter; left time: 237.1350s
Epoch: 10 cost time: 2.6067566871643066
Epoch: 10, Steps: 124 Train Loss: 29.7672 (Forecasting Loss:0.2453 + XiCon Loss:2.9522 x Lambda(10.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1420
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2735271
	speed: 0.0209s/iter; left time: 231.2142s
Epoch: 11 cost time: 2.567798614501953
Epoch: 11, Steps: 124 Train Loss: 29.7838 (Forecasting Loss:0.2459 + XiCon Loss:2.9538 x Lambda(10.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1420
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4483776
	speed: 0.0209s/iter; left time: 228.6440s
Epoch: 12 cost time: 2.572158098220825
Epoch: 12, Steps: 124 Train Loss: 29.7442 (Forecasting Loss:0.2460 + XiCon Loss:2.9498 x Lambda(10.0)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.1420
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.7741756
	speed: 0.0209s/iter; left time: 226.1045s
Epoch: 13 cost time: 2.5597705841064453
Epoch: 13, Steps: 124 Train Loss: 29.7770 (Forecasting Loss:0.2461 + XiCon Loss:2.9531 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1420
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2442112
	speed: 0.0206s/iter; left time: 219.7413s
Epoch: 14 cost time: 2.539456367492676
Epoch: 14, Steps: 124 Train Loss: 29.7685 (Forecasting Loss:0.2455 + XiCon Loss:2.9523 x Lambda(10.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1420
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.2435474
	speed: 0.0208s/iter; left time: 219.6477s
Epoch: 15 cost time: 2.554988384246826
Epoch: 15, Steps: 124 Train Loss: 29.7330 (Forecasting Loss:0.2454 + XiCon Loss:2.9488 x Lambda(10.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1420
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.7516975
	speed: 0.0207s/iter; left time: 215.9888s
Epoch: 16 cost time: 2.549635171890259
Epoch: 16, Steps: 124 Train Loss: 29.7597 (Forecasting Loss:0.2461 + XiCon Loss:2.9514 x Lambda(10.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1420
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5205479
	speed: 0.0209s/iter; left time: 215.4267s
Epoch: 17 cost time: 2.556284189224243
Epoch: 17, Steps: 124 Train Loss: 29.7186 (Forecasting Loss:0.2457 + XiCon Loss:2.9473 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1420
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6128292
	speed: 0.0206s/iter; left time: 210.0032s
Epoch: 18 cost time: 2.5467629432678223
Epoch: 18, Steps: 124 Train Loss: 29.7236 (Forecasting Loss:0.2457 + XiCon Loss:2.9478 x Lambda(10.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1420
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.0718173235654831, mae:0.21285900473594666, mape:0.16088572144508362, mspe:0.043943896889686584 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2317
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 31.0361195
	speed: 0.0178s/iter; left time: 219.1776s
Epoch: 1 cost time: 2.1865408420562744
Epoch: 1, Steps: 124 Train Loss: 31.3509 (Forecasting Loss:0.2976 + XiCon Loss:3.1053 x Lambda(10.0)), Vali MSE Loss: 0.2173 Test MSE Loss: 0.1587
Validation loss decreased (inf --> 0.217341).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3354034
	speed: 0.0197s/iter; left time: 239.5891s
Epoch: 2 cost time: 2.5077450275421143
Epoch: 2, Steps: 124 Train Loss: 29.7889 (Forecasting Loss:0.2828 + XiCon Loss:2.9506 x Lambda(10.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.1593
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.3717270
	speed: 0.0207s/iter; left time: 249.4601s
Epoch: 3 cost time: 2.571922779083252
Epoch: 3, Steps: 124 Train Loss: 30.1725 (Forecasting Loss:0.2661 + XiCon Loss:2.9906 x Lambda(10.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1443
Validation loss decreased (0.217341 --> 0.204982).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.5158329
	speed: 0.0213s/iter; left time: 254.6805s
Epoch: 4 cost time: 2.6172702312469482
Epoch: 4, Steps: 124 Train Loss: 30.3665 (Forecasting Loss:0.2564 + XiCon Loss:3.0110 x Lambda(10.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1475
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3519688
	speed: 0.0210s/iter; left time: 247.4470s
Epoch: 5 cost time: 2.5693302154541016
Epoch: 5, Steps: 124 Train Loss: 30.1932 (Forecasting Loss:0.2541 + XiCon Loss:2.9939 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1445
Validation loss decreased (0.204982 --> 0.204125).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3446255
	speed: 0.0208s/iter; left time: 243.1874s
Epoch: 6 cost time: 2.5529024600982666
Epoch: 6, Steps: 124 Train Loss: 30.1077 (Forecasting Loss:0.2521 + XiCon Loss:2.9856 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1440
Validation loss decreased (0.204125 --> 0.202556).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7503433
	speed: 0.0207s/iter; left time: 239.3243s
Epoch: 7 cost time: 2.5593159198760986
Epoch: 7, Steps: 124 Train Loss: 30.1031 (Forecasting Loss:0.2512 + XiCon Loss:2.9852 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1430
Validation loss decreased (0.202556 --> 0.201888).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9386292
	speed: 0.0206s/iter; left time: 235.0492s
Epoch: 8 cost time: 2.520725965499878
Epoch: 8, Steps: 124 Train Loss: 30.0514 (Forecasting Loss:0.2508 + XiCon Loss:2.9801 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1439
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8452721
	speed: 0.0210s/iter; left time: 237.3673s
Epoch: 9 cost time: 2.5714664459228516
Epoch: 9, Steps: 124 Train Loss: 30.1149 (Forecasting Loss:0.2503 + XiCon Loss:2.9865 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1432
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8039188
	speed: 0.0207s/iter; left time: 231.4861s
Epoch: 10 cost time: 2.546055316925049
Epoch: 10, Steps: 124 Train Loss: 30.0953 (Forecasting Loss:0.2505 + XiCon Loss:2.9845 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1433
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7292786
	speed: 0.0203s/iter; left time: 224.0312s
Epoch: 11 cost time: 2.5114688873291016
Epoch: 11, Steps: 124 Train Loss: 30.0281 (Forecasting Loss:0.2505 + XiCon Loss:2.9778 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1433
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.7331581
	speed: 0.0207s/iter; left time: 226.8541s
Epoch: 12 cost time: 2.5428287982940674
Epoch: 12, Steps: 124 Train Loss: 30.1075 (Forecasting Loss:0.2504 + XiCon Loss:2.9857 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.0221195
	speed: 0.0204s/iter; left time: 220.1639s
Epoch: 13 cost time: 2.5010719299316406
Epoch: 13, Steps: 124 Train Loss: 30.0183 (Forecasting Loss:0.2502 + XiCon Loss:2.9768 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1433
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1636620
	speed: 0.0207s/iter; left time: 221.0867s
Epoch: 14 cost time: 2.5387582778930664
Epoch: 14, Steps: 124 Train Loss: 30.0504 (Forecasting Loss:0.2507 + XiCon Loss:2.9800 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1434
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4832153
	speed: 0.0206s/iter; left time: 217.9768s
Epoch: 15 cost time: 2.5404887199401855
Epoch: 15, Steps: 124 Train Loss: 30.0050 (Forecasting Loss:0.2504 + XiCon Loss:2.9755 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1434
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4886017
	speed: 0.0207s/iter; left time: 215.6613s
Epoch: 16 cost time: 2.538832902908325
Epoch: 16, Steps: 124 Train Loss: 30.0781 (Forecasting Loss:0.2504 + XiCon Loss:2.9828 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1434
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4521427
	speed: 0.0205s/iter; left time: 211.6006s
Epoch: 17 cost time: 2.5198278427124023
Epoch: 17, Steps: 124 Train Loss: 30.0061 (Forecasting Loss:0.2502 + XiCon Loss:2.9756 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1434
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07310812920331955, mae:0.2129586786031723, mape:0.16032283008098602, mspe:0.043114520609378815 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2981
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 31.3984394
	speed: 0.0176s/iter; left time: 216.8175s
Epoch: 1 cost time: 2.16683292388916
Epoch: 1, Steps: 124 Train Loss: 31.4822 (Forecasting Loss:0.2950 + XiCon Loss:3.1187 x Lambda(10.0)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1598
Validation loss decreased (inf --> 0.217714).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.9741745
	speed: 0.0207s/iter; left time: 251.7884s
Epoch: 2 cost time: 2.590261220932007
Epoch: 2, Steps: 124 Train Loss: 29.8322 (Forecasting Loss:0.2814 + XiCon Loss:2.9551 x Lambda(10.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1491
Validation loss decreased (0.217714 --> 0.206356).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1679745
	speed: 0.0188s/iter; left time: 227.1491s
Epoch: 3 cost time: 2.299398899078369
Epoch: 3, Steps: 124 Train Loss: 30.3841 (Forecasting Loss:0.2676 + XiCon Loss:3.0117 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1484
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.4492512
	speed: 0.0194s/iter; left time: 231.3335s
Epoch: 4 cost time: 2.3969554901123047
Epoch: 4, Steps: 124 Train Loss: 29.9271 (Forecasting Loss:0.2634 + XiCon Loss:2.9664 x Lambda(10.0)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1579
Validation loss decreased (0.206356 --> 0.205948).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5284729
	speed: 0.0198s/iter; left time: 233.3044s
Epoch: 5 cost time: 2.421125650405884
Epoch: 5, Steps: 124 Train Loss: 29.6632 (Forecasting Loss:0.2573 + XiCon Loss:2.9406 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1592
Validation loss decreased (0.205948 --> 0.202384).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3168316
	speed: 0.0198s/iter; left time: 231.6680s
Epoch: 6 cost time: 2.43601393699646
Epoch: 6, Steps: 124 Train Loss: 29.6382 (Forecasting Loss:0.2524 + XiCon Loss:2.9386 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1599
Validation loss decreased (0.202384 --> 0.201144).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8145313
	speed: 0.0198s/iter; left time: 228.4341s
Epoch: 7 cost time: 2.434260606765747
Epoch: 7, Steps: 124 Train Loss: 29.5896 (Forecasting Loss:0.2503 + XiCon Loss:2.9339 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1605
Validation loss decreased (0.201144 --> 0.200218).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.4148521
	speed: 0.0199s/iter; left time: 227.9758s
Epoch: 8 cost time: 2.4571590423583984
Epoch: 8, Steps: 124 Train Loss: 29.5460 (Forecasting Loss:0.2497 + XiCon Loss:2.9296 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.2127151
	speed: 0.0201s/iter; left time: 226.8669s
Epoch: 9 cost time: 2.4598135948181152
Epoch: 9, Steps: 124 Train Loss: 29.5012 (Forecasting Loss:0.2492 + XiCon Loss:2.9252 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1598
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.9777412
	speed: 0.0201s/iter; left time: 225.2382s
Epoch: 10 cost time: 2.4637863636016846
Epoch: 10, Steps: 124 Train Loss: 29.5838 (Forecasting Loss:0.2495 + XiCon Loss:2.9334 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1595
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.7533836
	speed: 0.0200s/iter; left time: 220.7748s
Epoch: 11 cost time: 2.4577388763427734
Epoch: 11, Steps: 124 Train Loss: 29.5133 (Forecasting Loss:0.2491 + XiCon Loss:2.9264 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1594
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1861286
	speed: 0.0201s/iter; left time: 220.2807s
Epoch: 12 cost time: 2.4606800079345703
Epoch: 12, Steps: 124 Train Loss: 29.4719 (Forecasting Loss:0.2491 + XiCon Loss:2.9223 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2782211
	speed: 0.0197s/iter; left time: 213.2570s
Epoch: 13 cost time: 2.4341068267822266
Epoch: 13, Steps: 124 Train Loss: 29.4854 (Forecasting Loss:0.2488 + XiCon Loss:2.9237 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1595
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.5390396
	speed: 0.0200s/iter; left time: 214.1046s
Epoch: 14 cost time: 2.463484048843384
Epoch: 14, Steps: 124 Train Loss: 29.5363 (Forecasting Loss:0.2489 + XiCon Loss:2.9287 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.0604000
	speed: 0.0200s/iter; left time: 211.0939s
Epoch: 15 cost time: 2.455963611602783
Epoch: 15, Steps: 124 Train Loss: 29.4744 (Forecasting Loss:0.2488 + XiCon Loss:2.9226 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1595
Validation loss decreased (0.200218 --> 0.200099).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6979618
	speed: 0.0198s/iter; left time: 206.4322s
Epoch: 16 cost time: 2.427964210510254
Epoch: 16, Steps: 124 Train Loss: 29.5267 (Forecasting Loss:0.2492 + XiCon Loss:2.9278 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.0947819
	speed: 0.0201s/iter; left time: 207.2992s
Epoch: 17 cost time: 2.471299171447754
Epoch: 17, Steps: 124 Train Loss: 29.5833 (Forecasting Loss:0.2490 + XiCon Loss:2.9334 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1595
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.8908615
	speed: 0.0200s/iter; left time: 204.2474s
Epoch: 18 cost time: 2.472519874572754
Epoch: 18, Steps: 124 Train Loss: 29.4756 (Forecasting Loss:0.2489 + XiCon Loss:2.9227 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1595
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3603859
	speed: 0.0198s/iter; left time: 199.3574s
Epoch: 19 cost time: 2.4324750900268555
Epoch: 19, Steps: 124 Train Loss: 29.6059 (Forecasting Loss:0.2490 + XiCon Loss:2.9357 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.5802383
	speed: 0.0197s/iter; left time: 196.1373s
Epoch: 20 cost time: 2.427001714706421
Epoch: 20, Steps: 124 Train Loss: 29.5311 (Forecasting Loss:0.2489 + XiCon Loss:2.9282 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.6638851
	speed: 0.0200s/iter; left time: 195.9880s
Epoch: 21 cost time: 2.4462714195251465
Epoch: 21, Steps: 124 Train Loss: 29.4850 (Forecasting Loss:0.2490 + XiCon Loss:2.9236 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1595
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.7054310
	speed: 0.0200s/iter; left time: 194.1435s
Epoch: 22 cost time: 2.4621386528015137
Epoch: 22, Steps: 124 Train Loss: 29.4969 (Forecasting Loss:0.2490 + XiCon Loss:2.9248 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1595
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.8068848
	speed: 0.0202s/iter; left time: 193.0199s
Epoch: 23 cost time: 2.4736366271972656
Epoch: 23, Steps: 124 Train Loss: 29.5211 (Forecasting Loss:0.2487 + XiCon Loss:2.9272 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1595
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.0401211
	speed: 0.0203s/iter; left time: 191.8654s
Epoch: 24 cost time: 2.485442638397217
Epoch: 24, Steps: 124 Train Loss: 29.5314 (Forecasting Loss:0.2489 + XiCon Loss:2.9283 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1595
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.0487213
	speed: 0.0200s/iter; left time: 186.7216s
Epoch: 25 cost time: 2.4599623680114746
Epoch: 25, Steps: 124 Train Loss: 29.5507 (Forecasting Loss:0.2491 + XiCon Loss:2.9302 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08745062351226807, mae:0.2316236048936844, mape:0.1746104657649994, mspe:0.052707165479660034 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0771+-0.00781, MAE:0.2189+-0.00982, MAPE:0.1651+-0.00720, MSPE:0.0463+-0.00470, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2981
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3705085
	speed: 0.0437s/iter; left time: 511.0403s
Epoch: 1 cost time: 5.101586818695068
Epoch: 1, Steps: 118 Train Loss: 0.3626 (Forecasting Loss:0.3594 + XiCon Loss:3.1495 x Lambda(0.001)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.258898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2760351
	speed: 0.0416s/iter; left time: 481.8642s
Epoch: 2 cost time: 5.090743541717529
Epoch: 2, Steps: 118 Train Loss: 0.2995 (Forecasting Loss:0.2963 + XiCon Loss:3.1436 x Lambda(0.001)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1498
Validation loss decreased (0.258898 --> 0.251848).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2396940
	speed: 0.0543s/iter; left time: 623.0835s
Epoch: 3 cost time: 6.436665058135986
Epoch: 3, Steps: 118 Train Loss: 0.2371 (Forecasting Loss:0.2339 + XiCon Loss:3.1206 x Lambda(0.001)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1443
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2132561
	speed: 0.0539s/iter; left time: 612.0063s
Epoch: 4 cost time: 6.406063556671143
Epoch: 4, Steps: 118 Train Loss: 0.2225 (Forecasting Loss:0.2194 + XiCon Loss:3.1126 x Lambda(0.001)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1472
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2093226
	speed: 0.0551s/iter; left time: 618.2870s
Epoch: 5 cost time: 6.602290153503418
Epoch: 5, Steps: 118 Train Loss: 0.2168 (Forecasting Loss:0.2137 + XiCon Loss:3.1106 x Lambda(0.001)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1465
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2190803
	speed: 0.0576s/iter; left time: 640.3787s
Epoch: 6 cost time: 6.823870420455933
Epoch: 6, Steps: 118 Train Loss: 0.2142 (Forecasting Loss:0.2111 + XiCon Loss:3.1087 x Lambda(0.001)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1477
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2126445
	speed: 0.0614s/iter; left time: 675.3781s
Epoch: 7 cost time: 7.257771968841553
Epoch: 7, Steps: 118 Train Loss: 0.2128 (Forecasting Loss:0.2097 + XiCon Loss:3.1068 x Lambda(0.001)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1487
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2140642
	speed: 0.0582s/iter; left time: 632.9175s
Epoch: 8 cost time: 6.895768642425537
Epoch: 8, Steps: 118 Train Loss: 0.2121 (Forecasting Loss:0.2090 + XiCon Loss:3.1054 x Lambda(0.001)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1472
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2035627
	speed: 0.0585s/iter; left time: 628.9762s
Epoch: 9 cost time: 6.9138569831848145
Epoch: 9, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2083 + XiCon Loss:3.1061 x Lambda(0.001)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1476
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2219912
	speed: 0.0593s/iter; left time: 630.6995s
Epoch: 10 cost time: 7.041052341461182
Epoch: 10, Steps: 118 Train Loss: 0.2116 (Forecasting Loss:0.2085 + XiCon Loss:3.1061 x Lambda(0.001)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1479
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2222831
	speed: 0.0579s/iter; left time: 609.3034s
Epoch: 11 cost time: 6.869475603103638
Epoch: 11, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2083 + XiCon Loss:3.1068 x Lambda(0.001)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.1475
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2061067
	speed: 0.0629s/iter; left time: 654.5968s
Epoch: 12 cost time: 7.376222610473633
Epoch: 12, Steps: 118 Train Loss: 0.2112 (Forecasting Loss:0.2081 + XiCon Loss:3.1055 x Lambda(0.001)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.1477
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07759431004524231, mae:0.22204016149044037, mape:0.1672726720571518, mspe:0.04886304959654808 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1950
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3101986
	speed: 0.0412s/iter; left time: 482.5598s
Epoch: 1 cost time: 4.893397331237793
Epoch: 1, Steps: 118 Train Loss: 0.3566 (Forecasting Loss:0.3535 + XiCon Loss:3.1434 x Lambda(0.001)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.1627
Validation loss decreased (inf --> 0.256374).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2834659
	speed: 0.0417s/iter; left time: 482.5570s
Epoch: 2 cost time: 4.920682668685913
Epoch: 2, Steps: 118 Train Loss: 0.3035 (Forecasting Loss:0.3004 + XiCon Loss:3.1343 x Lambda(0.001)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.1479
Validation loss decreased (0.256374 --> 0.218560).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2453810
	speed: 0.0413s/iter; left time: 474.0211s
Epoch: 3 cost time: 4.906190633773804
Epoch: 3, Steps: 118 Train Loss: 0.2588 (Forecasting Loss:0.2556 + XiCon Loss:3.1256 x Lambda(0.001)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1470
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2381194
	speed: 0.0421s/iter; left time: 477.5881s
Epoch: 4 cost time: 4.978040456771851
Epoch: 4, Steps: 118 Train Loss: 0.2407 (Forecasting Loss:0.2375 + XiCon Loss:3.1258 x Lambda(0.001)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.1457
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2279031
	speed: 0.0424s/iter; left time: 475.7376s
Epoch: 5 cost time: 5.0020434856414795
Epoch: 5, Steps: 118 Train Loss: 0.2317 (Forecasting Loss:0.2286 + XiCon Loss:3.1250 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1447
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2348268
	speed: 0.0444s/iter; left time: 493.2362s
Epoch: 6 cost time: 5.181250333786011
Epoch: 6, Steps: 118 Train Loss: 0.2281 (Forecasting Loss:0.2250 + XiCon Loss:3.1252 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1449
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2346047
	speed: 0.0435s/iter; left time: 477.7738s
Epoch: 7 cost time: 5.118870735168457
Epoch: 7, Steps: 118 Train Loss: 0.2266 (Forecasting Loss:0.2234 + XiCon Loss:3.1251 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1450
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2385256
	speed: 0.0416s/iter; left time: 452.8535s
Epoch: 8 cost time: 4.926598310470581
Epoch: 8, Steps: 118 Train Loss: 0.2253 (Forecasting Loss:0.2222 + XiCon Loss:3.1250 x Lambda(0.001)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2214785
	speed: 0.0429s/iter; left time: 461.6820s
Epoch: 9 cost time: 5.050037622451782
Epoch: 9, Steps: 118 Train Loss: 0.2249 (Forecasting Loss:0.2218 + XiCon Loss:3.1257 x Lambda(0.001)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1445
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2341250
	speed: 0.0415s/iter; left time: 441.5027s
Epoch: 10 cost time: 4.936652660369873
Epoch: 10, Steps: 118 Train Loss: 0.2248 (Forecasting Loss:0.2216 + XiCon Loss:3.1238 x Lambda(0.001)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2324249
	speed: 0.0437s/iter; left time: 459.7242s
Epoch: 11 cost time: 5.161769390106201
Epoch: 11, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.1255 x Lambda(0.001)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1447
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2194403
	speed: 0.0419s/iter; left time: 436.3681s
Epoch: 12 cost time: 4.989715576171875
Epoch: 12, Steps: 118 Train Loss: 0.2249 (Forecasting Loss:0.2218 + XiCon Loss:3.1245 x Lambda(0.001)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07553967088460922, mae:0.2203165739774704, mape:0.16625462472438812, mspe:0.04609458148479462 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1905
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3267195
	speed: 0.0414s/iter; left time: 484.9498s
Epoch: 1 cost time: 4.896688938140869
Epoch: 1, Steps: 118 Train Loss: 0.3577 (Forecasting Loss:0.3545 + XiCon Loss:3.1431 x Lambda(0.001)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1640
Validation loss decreased (inf --> 0.253626).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2710668
	speed: 0.0431s/iter; left time: 498.6833s
Epoch: 2 cost time: 5.197804927825928
Epoch: 2, Steps: 118 Train Loss: 0.3043 (Forecasting Loss:0.3011 + XiCon Loss:3.1101 x Lambda(0.001)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1451
Validation loss decreased (0.253626 --> 0.251196).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2399550
	speed: 0.0496s/iter; left time: 568.3308s
Epoch: 3 cost time: 5.936666250228882
Epoch: 3, Steps: 118 Train Loss: 0.2416 (Forecasting Loss:0.2385 + XiCon Loss:3.0697 x Lambda(0.001)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1535
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2141993
	speed: 0.0511s/iter; left time: 580.1315s
Epoch: 4 cost time: 6.117410182952881
Epoch: 4, Steps: 118 Train Loss: 0.2230 (Forecasting Loss:0.2200 + XiCon Loss:3.0704 x Lambda(0.001)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1477
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2178346
	speed: 0.0533s/iter; left time: 598.1890s
Epoch: 5 cost time: 6.309379577636719
Epoch: 5, Steps: 118 Train Loss: 0.2164 (Forecasting Loss:0.2133 + XiCon Loss:3.0678 x Lambda(0.001)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.1512
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2181170
	speed: 0.0559s/iter; left time: 620.6212s
Epoch: 6 cost time: 6.602780103683472
Epoch: 6, Steps: 118 Train Loss: 0.2131 (Forecasting Loss:0.2100 + XiCon Loss:3.0693 x Lambda(0.001)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.1491
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2168766
	speed: 0.0545s/iter; left time: 598.6650s
Epoch: 7 cost time: 6.469019651412964
Epoch: 7, Steps: 118 Train Loss: 0.2116 (Forecasting Loss:0.2085 + XiCon Loss:3.0682 x Lambda(0.001)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1510
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2065441
	speed: 0.0535s/iter; left time: 581.9404s
Epoch: 8 cost time: 6.352295160293579
Epoch: 8, Steps: 118 Train Loss: 0.2108 (Forecasting Loss:0.2078 + XiCon Loss:3.0684 x Lambda(0.001)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1500
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2123464
	speed: 0.0571s/iter; left time: 613.8514s
Epoch: 9 cost time: 6.6935906410217285
Epoch: 9, Steps: 118 Train Loss: 0.2105 (Forecasting Loss:0.2074 + XiCon Loss:3.0660 x Lambda(0.001)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.1501
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2048435
	speed: 0.0556s/iter; left time: 591.3733s
Epoch: 10 cost time: 6.602524995803833
Epoch: 10, Steps: 118 Train Loss: 0.2103 (Forecasting Loss:0.2072 + XiCon Loss:3.0670 x Lambda(0.001)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1502
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2243288
	speed: 0.0547s/iter; left time: 574.9930s
Epoch: 11 cost time: 6.4889421463012695
Epoch: 11, Steps: 118 Train Loss: 0.2101 (Forecasting Loss:0.2071 + XiCon Loss:3.0665 x Lambda(0.001)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1506
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2156196
	speed: 0.0565s/iter; left time: 587.9425s
Epoch: 12 cost time: 6.66642951965332
Epoch: 12, Steps: 118 Train Loss: 0.2102 (Forecasting Loss:0.2071 + XiCon Loss:3.0680 x Lambda(0.001)), Vali MSE Loss: 0.2630 Test MSE Loss: 0.1503
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07444801926612854, mae:0.21567824482917786, mape:0.16298821568489075, mspe:0.0482945553958416 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2153
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3242366
	speed: 0.0413s/iter; left time: 483.2191s
Epoch: 1 cost time: 4.907767295837402
Epoch: 1, Steps: 118 Train Loss: 0.3552 (Forecasting Loss:0.3521 + XiCon Loss:3.1442 x Lambda(0.001)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1590
Validation loss decreased (inf --> 0.255511).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2623875
	speed: 0.0416s/iter; left time: 482.0994s
Epoch: 2 cost time: 4.936322212219238
Epoch: 2, Steps: 118 Train Loss: 0.3165 (Forecasting Loss:0.3133 + XiCon Loss:3.1322 x Lambda(0.001)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.1382
Validation loss decreased (0.255511 --> 0.229211).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2463968
	speed: 0.0466s/iter; left time: 533.9496s
Epoch: 3 cost time: 5.499114990234375
Epoch: 3, Steps: 118 Train Loss: 0.2464 (Forecasting Loss:0.2433 + XiCon Loss:3.1019 x Lambda(0.001)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.1369
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2253585
	speed: 0.0494s/iter; left time: 560.9651s
Epoch: 4 cost time: 5.882701396942139
Epoch: 4, Steps: 118 Train Loss: 0.2281 (Forecasting Loss:0.2250 + XiCon Loss:3.0892 x Lambda(0.001)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.1405
Validation loss decreased (0.229211 --> 0.228773).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2325430
	speed: 0.0486s/iter; left time: 545.3251s
Epoch: 5 cost time: 5.762681245803833
Epoch: 5, Steps: 118 Train Loss: 0.2222 (Forecasting Loss:0.2191 + XiCon Loss:3.0883 x Lambda(0.001)), Vali MSE Loss: 0.2325 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2099067
	speed: 0.0516s/iter; left time: 573.1082s
Epoch: 6 cost time: 6.072481393814087
Epoch: 6, Steps: 118 Train Loss: 0.2190 (Forecasting Loss:0.2159 + XiCon Loss:3.0870 x Lambda(0.001)), Vali MSE Loss: 0.2369 Test MSE Loss: 0.1365
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2154846
	speed: 0.0501s/iter; left time: 550.7054s
Epoch: 7 cost time: 5.9521284103393555
Epoch: 7, Steps: 118 Train Loss: 0.2177 (Forecasting Loss:0.2146 + XiCon Loss:3.0889 x Lambda(0.001)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1370
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2233890
	speed: 0.0495s/iter; left time: 537.9977s
Epoch: 8 cost time: 5.953935384750366
Epoch: 8, Steps: 118 Train Loss: 0.2170 (Forecasting Loss:0.2139 + XiCon Loss:3.0873 x Lambda(0.001)), Vali MSE Loss: 0.2379 Test MSE Loss: 0.1375
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2227280
	speed: 0.0490s/iter; left time: 527.4519s
Epoch: 9 cost time: 5.808352708816528
Epoch: 9, Steps: 118 Train Loss: 0.2166 (Forecasting Loss:0.2136 + XiCon Loss:3.0879 x Lambda(0.001)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1369
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2219942
	speed: 0.0516s/iter; left time: 548.6783s
Epoch: 10 cost time: 6.113508224487305
Epoch: 10, Steps: 118 Train Loss: 0.2165 (Forecasting Loss:0.2134 + XiCon Loss:3.0859 x Lambda(0.001)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2201650
	speed: 0.0517s/iter; left time: 543.5649s
Epoch: 11 cost time: 6.096728324890137
Epoch: 11, Steps: 118 Train Loss: 0.2163 (Forecasting Loss:0.2132 + XiCon Loss:3.0877 x Lambda(0.001)), Vali MSE Loss: 0.2400 Test MSE Loss: 0.1368
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2129376
	speed: 0.0497s/iter; left time: 517.2601s
Epoch: 12 cost time: 5.884932041168213
Epoch: 12, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2130 + XiCon Loss:3.0894 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1368
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2263905
	speed: 0.0527s/iter; left time: 542.3837s
Epoch: 13 cost time: 6.170973300933838
Epoch: 13, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2131 + XiCon Loss:3.0886 x Lambda(0.001)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1368
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2031047
	speed: 0.0528s/iter; left time: 536.6947s
Epoch: 14 cost time: 6.208214998245239
Epoch: 14, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2131 + XiCon Loss:3.0885 x Lambda(0.001)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07014244049787521, mae:0.2107873558998108, mape:0.15736828744411469, mspe:0.04250003397464752 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1999
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3340836
	speed: 0.0417s/iter; left time: 487.6809s
Epoch: 1 cost time: 4.936852931976318
Epoch: 1, Steps: 118 Train Loss: 0.3566 (Forecasting Loss:0.3535 + XiCon Loss:3.1437 x Lambda(0.001)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1621
Validation loss decreased (inf --> 0.255393).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2745214
	speed: 0.0423s/iter; left time: 489.5142s
Epoch: 2 cost time: 4.991070032119751
Epoch: 2, Steps: 118 Train Loss: 0.3057 (Forecasting Loss:0.3026 + XiCon Loss:3.1303 x Lambda(0.001)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.1477
Validation loss decreased (0.255393 --> 0.227279).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2415855
	speed: 0.0425s/iter; left time: 487.3566s
Epoch: 3 cost time: 5.044130802154541
Epoch: 3, Steps: 118 Train Loss: 0.2494 (Forecasting Loss:0.2462 + XiCon Loss:3.1051 x Lambda(0.001)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1347
Validation loss decreased (0.227279 --> 0.222641).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2246436
	speed: 0.0456s/iter; left time: 517.0522s
Epoch: 4 cost time: 5.339745044708252
Epoch: 4, Steps: 118 Train Loss: 0.2279 (Forecasting Loss:0.2249 + XiCon Loss:3.0799 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1378
Validation loss decreased (0.222641 --> 0.216247).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2108956
	speed: 0.0434s/iter; left time: 487.6275s
Epoch: 5 cost time: 5.128237962722778
Epoch: 5, Steps: 118 Train Loss: 0.2212 (Forecasting Loss:0.2181 + XiCon Loss:3.0766 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2097417
	speed: 0.0437s/iter; left time: 485.7952s
Epoch: 6 cost time: 5.150623083114624
Epoch: 6, Steps: 118 Train Loss: 0.2185 (Forecasting Loss:0.2154 + XiCon Loss:3.0745 x Lambda(0.001)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1390
Validation loss decreased (0.216247 --> 0.215637).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2098013
	speed: 0.0478s/iter; left time: 525.0705s
Epoch: 7 cost time: 5.57014012336731
Epoch: 7, Steps: 118 Train Loss: 0.2171 (Forecasting Loss:0.2141 + XiCon Loss:3.0744 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2056731
	speed: 0.0434s/iter; left time: 471.7299s
Epoch: 8 cost time: 5.156421422958374
Epoch: 8, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2130 + XiCon Loss:3.0720 x Lambda(0.001)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1369
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2093191
	speed: 0.0454s/iter; left time: 488.7885s
Epoch: 9 cost time: 5.328254222869873
Epoch: 9, Steps: 118 Train Loss: 0.2159 (Forecasting Loss:0.2128 + XiCon Loss:3.0753 x Lambda(0.001)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1381
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2004592
	speed: 0.0458s/iter; left time: 486.9989s
Epoch: 10 cost time: 5.361972808837891
Epoch: 10, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.0726 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1384
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2243154
	speed: 0.0483s/iter; left time: 508.4252s
Epoch: 11 cost time: 5.631895065307617
Epoch: 11, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.0739 x Lambda(0.001)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1385
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2165094
	speed: 0.0444s/iter; left time: 461.8419s
Epoch: 12 cost time: 5.248115301132202
Epoch: 12, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2126 + XiCon Loss:3.0731 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1386
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2122201
	speed: 0.0451s/iter; left time: 463.9676s
Epoch: 13 cost time: 5.2998528480529785
Epoch: 13, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2125 + XiCon Loss:3.0731 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1385
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2156225
	speed: 0.0438s/iter; left time: 445.3257s
Epoch: 14 cost time: 5.2414937019348145
Epoch: 14, Steps: 118 Train Loss: 0.2151 (Forecasting Loss:0.2120 + XiCon Loss:3.0736 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1385
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2302073
	speed: 0.0435s/iter; left time: 437.2488s
Epoch: 15 cost time: 5.143588542938232
Epoch: 15, Steps: 118 Train Loss: 0.2152 (Forecasting Loss:0.2121 + XiCon Loss:3.0731 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1386
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2179441
	speed: 0.0455s/iter; left time: 452.0178s
Epoch: 16 cost time: 5.378546714782715
Epoch: 16, Steps: 118 Train Loss: 0.2153 (Forecasting Loss:0.2122 + XiCon Loss:3.0737 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1386
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0682465061545372, mae:0.20980927348136902, mape:0.15856720507144928, mspe:0.04334846884012222 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0732+-0.00482, MAE:0.2157+-0.00681, MAPE:0.1625+-0.00552, MSPE:0.0458+-0.00354, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2576
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2799475
	speed: 0.0162s/iter; left time: 205.7120s
Epoch: 1 cost time: 1.9572923183441162
Epoch: 1, Steps: 128 Train Loss: 3.3678 (Forecasting Loss:0.2930 + XiCon Loss:3.0748 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.277091).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0972376
	speed: 0.0133s/iter; left time: 166.7383s
Epoch: 2 cost time: 1.6393308639526367
Epoch: 2, Steps: 128 Train Loss: 3.1543 (Forecasting Loss:0.2571 + XiCon Loss:2.8972 x Lambda(1.0)), Vali MSE Loss: 0.2572 Test MSE Loss: 0.2188
Validation loss decreased (0.277091 --> 0.257246).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2604191
	speed: 0.0138s/iter; left time: 171.9563s
Epoch: 3 cost time: 1.7131156921386719
Epoch: 3, Steps: 128 Train Loss: 3.2114 (Forecasting Loss:0.2438 + XiCon Loss:2.9677 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2206
Validation loss decreased (0.257246 --> 0.251093).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1933413
	speed: 0.0135s/iter; left time: 165.9604s
Epoch: 4 cost time: 1.7059540748596191
Epoch: 4, Steps: 128 Train Loss: 3.1686 (Forecasting Loss:0.2377 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.2063
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1662109
	speed: 0.0127s/iter; left time: 154.8517s
Epoch: 5 cost time: 1.588820457458496
Epoch: 5, Steps: 128 Train Loss: 3.1479 (Forecasting Loss:0.2346 + XiCon Loss:2.9133 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2073
Validation loss decreased (0.251093 --> 0.249507).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1974573
	speed: 0.0140s/iter; left time: 168.8060s
Epoch: 6 cost time: 1.735541820526123
Epoch: 6, Steps: 128 Train Loss: 3.1465 (Forecasting Loss:0.2327 + XiCon Loss:2.9138 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2056
Validation loss decreased (0.249507 --> 0.249461).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1307139
	speed: 0.0134s/iter; left time: 160.0165s
Epoch: 7 cost time: 1.6626675128936768
Epoch: 7, Steps: 128 Train Loss: 3.1324 (Forecasting Loss:0.2316 + XiCon Loss:2.9008 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2063
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0874984
	speed: 0.0130s/iter; left time: 153.6147s
Epoch: 8 cost time: 1.6277267932891846
Epoch: 8, Steps: 128 Train Loss: 3.1318 (Forecasting Loss:0.2315 + XiCon Loss:2.9003 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2424562
	speed: 0.0128s/iter; left time: 149.8091s
Epoch: 9 cost time: 1.6058192253112793
Epoch: 9, Steps: 128 Train Loss: 3.1352 (Forecasting Loss:0.2315 + XiCon Loss:2.9037 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2051
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0874295
	speed: 0.0134s/iter; left time: 154.2486s
Epoch: 10 cost time: 1.6605262756347656
Epoch: 10, Steps: 128 Train Loss: 3.1318 (Forecasting Loss:0.2311 + XiCon Loss:2.9007 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1270726
	speed: 0.0128s/iter; left time: 146.3989s
Epoch: 11 cost time: 1.6013984680175781
Epoch: 11, Steps: 128 Train Loss: 3.1305 (Forecasting Loss:0.2312 + XiCon Loss:2.8993 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0628567
	speed: 0.0128s/iter; left time: 144.3023s
Epoch: 12 cost time: 1.5979728698730469
Epoch: 12, Steps: 128 Train Loss: 3.1234 (Forecasting Loss:0.2310 + XiCon Loss:2.8924 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2051
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0371101
	speed: 0.0131s/iter; left time: 146.7151s
Epoch: 13 cost time: 1.6399917602539062
Epoch: 13, Steps: 128 Train Loss: 3.1353 (Forecasting Loss:0.2312 + XiCon Loss:2.9041 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2051
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1070259
	speed: 0.0132s/iter; left time: 145.5426s
Epoch: 14 cost time: 1.6452057361602783
Epoch: 14, Steps: 128 Train Loss: 3.1238 (Forecasting Loss:0.2307 + XiCon Loss:2.8931 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2051
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1708312
	speed: 0.0129s/iter; left time: 140.6874s
Epoch: 15 cost time: 1.6097593307495117
Epoch: 15, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2309 + XiCon Loss:2.9012 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2051
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1214688
	speed: 0.0129s/iter; left time: 139.0337s
Epoch: 16 cost time: 1.63889479637146
Epoch: 16, Steps: 128 Train Loss: 3.1268 (Forecasting Loss:0.2312 + XiCon Loss:2.8956 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2051
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13151203095912933, mae:0.27964267134666443, mape:0.6616082191467285, mspe:19.804601669311523 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1916
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2713466
	speed: 0.0136s/iter; left time: 173.0222s
Epoch: 1 cost time: 1.695744276046753
Epoch: 1, Steps: 128 Train Loss: 3.3535 (Forecasting Loss:0.2939 + XiCon Loss:3.0595 x Lambda(1.0)), Vali MSE Loss: 0.2728 Test MSE Loss: 0.2296
Validation loss decreased (inf --> 0.272831).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2503004
	speed: 0.0125s/iter; left time: 157.7558s
Epoch: 2 cost time: 1.569664478302002
Epoch: 2, Steps: 128 Train Loss: 3.2022 (Forecasting Loss:0.2579 + XiCon Loss:2.9442 x Lambda(1.0)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.2188
Validation loss decreased (0.272831 --> 0.264639).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5552371
	speed: 0.0126s/iter; left time: 157.0458s
Epoch: 3 cost time: 1.5806705951690674
Epoch: 3, Steps: 128 Train Loss: 3.3745 (Forecasting Loss:0.2427 + XiCon Loss:3.1318 x Lambda(1.0)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.2091
Validation loss decreased (0.264639 --> 0.256512).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4315522
	speed: 0.0127s/iter; left time: 156.9626s
Epoch: 4 cost time: 1.600327491760254
Epoch: 4, Steps: 128 Train Loss: 3.4849 (Forecasting Loss:0.2375 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2069
Validation loss decreased (0.256512 --> 0.249146).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5084679
	speed: 0.0126s/iter; left time: 154.1797s
Epoch: 5 cost time: 1.5870366096496582
Epoch: 5, Steps: 128 Train Loss: 3.4911 (Forecasting Loss:0.2344 + XiCon Loss:3.2568 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2093
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3989708
	speed: 0.0127s/iter; left time: 152.8646s
Epoch: 6 cost time: 1.5791044235229492
Epoch: 6, Steps: 128 Train Loss: 3.4749 (Forecasting Loss:0.2327 + XiCon Loss:3.2423 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5559051
	speed: 0.0127s/iter; left time: 151.2454s
Epoch: 7 cost time: 1.5900907516479492
Epoch: 7, Steps: 128 Train Loss: 3.4334 (Forecasting Loss:0.2320 + XiCon Loss:3.2014 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2053
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4377108
	speed: 0.0131s/iter; left time: 155.0521s
Epoch: 8 cost time: 1.6406188011169434
Epoch: 8, Steps: 128 Train Loss: 3.4270 (Forecasting Loss:0.2315 + XiCon Loss:3.1955 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2053
Validation loss decreased (0.249146 --> 0.249142).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4750669
	speed: 0.0129s/iter; left time: 151.0006s
Epoch: 9 cost time: 1.6072659492492676
Epoch: 9, Steps: 128 Train Loss: 3.4387 (Forecasting Loss:0.2311 + XiCon Loss:3.2076 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2052
Validation loss decreased (0.249142 --> 0.248448).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3230968
	speed: 0.0127s/iter; left time: 146.3609s
Epoch: 10 cost time: 1.5890331268310547
Epoch: 10, Steps: 128 Train Loss: 3.4205 (Forecasting Loss:0.2310 + XiCon Loss:3.1895 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2052
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4338305
	speed: 0.0127s/iter; left time: 145.2521s
Epoch: 11 cost time: 1.5941781997680664
Epoch: 11, Steps: 128 Train Loss: 3.4145 (Forecasting Loss:0.2309 + XiCon Loss:3.1835 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2052
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4445131
	speed: 0.0126s/iter; left time: 142.0656s
Epoch: 12 cost time: 1.579247236251831
Epoch: 12, Steps: 128 Train Loss: 3.4208 (Forecasting Loss:0.2310 + XiCon Loss:3.1898 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2051
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2719388
	speed: 0.0128s/iter; left time: 142.7238s
Epoch: 13 cost time: 1.5931792259216309
Epoch: 13, Steps: 128 Train Loss: 3.4194 (Forecasting Loss:0.2309 + XiCon Loss:3.1885 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2051
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3643787
	speed: 0.0128s/iter; left time: 141.2985s
Epoch: 14 cost time: 1.599132776260376
Epoch: 14, Steps: 128 Train Loss: 3.4256 (Forecasting Loss:0.2308 + XiCon Loss:3.1948 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2051
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4302881
	speed: 0.0129s/iter; left time: 140.6464s
Epoch: 15 cost time: 1.6355550289154053
Epoch: 15, Steps: 128 Train Loss: 3.4241 (Forecasting Loss:0.2309 + XiCon Loss:3.1933 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2051
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4263210
	speed: 0.0130s/iter; left time: 140.0893s
Epoch: 16 cost time: 1.6496076583862305
Epoch: 16, Steps: 128 Train Loss: 3.4169 (Forecasting Loss:0.2309 + XiCon Loss:3.1860 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2051
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1938972
	speed: 0.0127s/iter; left time: 134.9758s
Epoch: 17 cost time: 1.5909137725830078
Epoch: 17, Steps: 128 Train Loss: 3.4282 (Forecasting Loss:0.2308 + XiCon Loss:3.1975 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2051
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5196447
	speed: 0.0128s/iter; left time: 134.2598s
Epoch: 18 cost time: 1.6004207134246826
Epoch: 18, Steps: 128 Train Loss: 3.4215 (Forecasting Loss:0.2309 + XiCon Loss:3.1906 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2051
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3899555
	speed: 0.0129s/iter; left time: 133.6546s
Epoch: 19 cost time: 1.5998802185058594
Epoch: 19, Steps: 128 Train Loss: 3.4194 (Forecasting Loss:0.2310 + XiCon Loss:3.1884 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2051
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13082484900951385, mae:0.2796423137187958, mape:0.6587988138198853, mspe:19.375276565551758 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2924
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3375490
	speed: 0.0139s/iter; left time: 176.7134s
Epoch: 1 cost time: 1.724287748336792
Epoch: 1, Steps: 128 Train Loss: 3.3769 (Forecasting Loss:0.2878 + XiCon Loss:3.0890 x Lambda(1.0)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.2263
Validation loss decreased (inf --> 0.271935).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2936232
	speed: 0.0139s/iter; left time: 174.9659s
Epoch: 2 cost time: 1.7496485710144043
Epoch: 2, Steps: 128 Train Loss: 3.2191 (Forecasting Loss:0.2553 + XiCon Loss:2.9638 x Lambda(1.0)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.2168
Validation loss decreased (0.271935 --> 0.262404).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0867205
	speed: 0.0129s/iter; left time: 161.0777s
Epoch: 3 cost time: 1.6215400695800781
Epoch: 3, Steps: 128 Train Loss: 3.2048 (Forecasting Loss:0.2400 + XiCon Loss:2.9648 x Lambda(1.0)), Vali MSE Loss: 0.2628 Test MSE Loss: 0.2194
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2181730
	speed: 0.0128s/iter; left time: 157.3063s
Epoch: 4 cost time: 1.5957157611846924
Epoch: 4, Steps: 128 Train Loss: 3.1629 (Forecasting Loss:0.2294 + XiCon Loss:2.9335 x Lambda(1.0)), Vali MSE Loss: 0.2608 Test MSE Loss: 0.2296
Validation loss decreased (0.262404 --> 0.260842).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1350789
	speed: 0.0128s/iter; left time: 156.0187s
Epoch: 5 cost time: 1.6012537479400635
Epoch: 5, Steps: 128 Train Loss: 3.1410 (Forecasting Loss:0.2234 + XiCon Loss:2.9177 x Lambda(1.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2260
Validation loss decreased (0.260842 --> 0.258348).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1403956
	speed: 0.0130s/iter; left time: 156.8360s
Epoch: 6 cost time: 1.6198720932006836
Epoch: 6, Steps: 128 Train Loss: 3.1293 (Forecasting Loss:0.2204 + XiCon Loss:2.9088 x Lambda(1.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.2269
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1082227
	speed: 0.0131s/iter; left time: 156.1127s
Epoch: 7 cost time: 1.633702278137207
Epoch: 7, Steps: 128 Train Loss: 3.1197 (Forecasting Loss:0.2185 + XiCon Loss:2.9012 x Lambda(1.0)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.2287
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1060781
	speed: 0.0129s/iter; left time: 152.2140s
Epoch: 8 cost time: 1.617685079574585
Epoch: 8, Steps: 128 Train Loss: 3.1141 (Forecasting Loss:0.2180 + XiCon Loss:2.8961 x Lambda(1.0)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.2287
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0292015
	speed: 0.0129s/iter; left time: 151.1729s
Epoch: 9 cost time: 1.6210994720458984
Epoch: 9, Steps: 128 Train Loss: 3.1161 (Forecasting Loss:0.2174 + XiCon Loss:2.8987 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2277
Validation loss decreased (0.258348 --> 0.258164).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0797029
	speed: 0.0128s/iter; left time: 147.7433s
Epoch: 10 cost time: 1.5981554985046387
Epoch: 10, Steps: 128 Train Loss: 3.1187 (Forecasting Loss:0.2176 + XiCon Loss:2.9011 x Lambda(1.0)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.2278
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0483973
	speed: 0.0134s/iter; left time: 153.2432s
Epoch: 11 cost time: 1.6848196983337402
Epoch: 11, Steps: 128 Train Loss: 3.1175 (Forecasting Loss:0.2170 + XiCon Loss:2.9005 x Lambda(1.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.2278
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1540051
	speed: 0.0131s/iter; left time: 147.8466s
Epoch: 12 cost time: 1.6272478103637695
Epoch: 12, Steps: 128 Train Loss: 3.1151 (Forecasting Loss:0.2171 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.2279
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1170540
	speed: 0.0127s/iter; left time: 142.2968s
Epoch: 13 cost time: 1.5935850143432617
Epoch: 13, Steps: 128 Train Loss: 3.1148 (Forecasting Loss:0.2162 + XiCon Loss:2.8986 x Lambda(1.0)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.2279
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1115136
	speed: 0.0128s/iter; left time: 141.6863s
Epoch: 14 cost time: 1.6062166690826416
Epoch: 14, Steps: 128 Train Loss: 3.1143 (Forecasting Loss:0.2168 + XiCon Loss:2.8975 x Lambda(1.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2279
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1046271
	speed: 0.0131s/iter; left time: 142.6267s
Epoch: 15 cost time: 1.6258032321929932
Epoch: 15, Steps: 128 Train Loss: 3.1135 (Forecasting Loss:0.2172 + XiCon Loss:2.8963 x Lambda(1.0)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2279
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1658914
	speed: 0.0127s/iter; left time: 137.1550s
Epoch: 16 cost time: 1.5900261402130127
Epoch: 16, Steps: 128 Train Loss: 3.1187 (Forecasting Loss:0.2168 + XiCon Loss:2.9019 x Lambda(1.0)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2279
Validation loss decreased (0.258164 --> 0.258079).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0766039
	speed: 0.0127s/iter; left time: 135.6812s
Epoch: 17 cost time: 1.594900131225586
Epoch: 17, Steps: 128 Train Loss: 3.1145 (Forecasting Loss:0.2164 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2279
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.0971613
	speed: 0.0131s/iter; left time: 137.5879s
Epoch: 18 cost time: 1.6304106712341309
Epoch: 18, Steps: 128 Train Loss: 3.1235 (Forecasting Loss:0.2167 + XiCon Loss:2.9068 x Lambda(1.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.2279
Validation loss decreased (0.258079 --> 0.257710).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1682827
	speed: 0.0126s/iter; left time: 131.0594s
Epoch: 19 cost time: 1.5760440826416016
Epoch: 19, Steps: 128 Train Loss: 3.1152 (Forecasting Loss:0.2168 + XiCon Loss:2.8984 x Lambda(1.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2279
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0541687
	speed: 0.0132s/iter; left time: 135.3670s
Epoch: 20 cost time: 1.6388306617736816
Epoch: 20, Steps: 128 Train Loss: 3.1134 (Forecasting Loss:0.2165 + XiCon Loss:2.8969 x Lambda(1.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2279
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1001041
	speed: 0.0129s/iter; left time: 130.6464s
Epoch: 21 cost time: 1.606452226638794
Epoch: 21, Steps: 128 Train Loss: 3.1185 (Forecasting Loss:0.2169 + XiCon Loss:2.9017 x Lambda(1.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.2279
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.0841000
	speed: 0.0127s/iter; left time: 127.1246s
Epoch: 22 cost time: 1.5853214263916016
Epoch: 22, Steps: 128 Train Loss: 3.1145 (Forecasting Loss:0.2170 + XiCon Loss:2.8975 x Lambda(1.0)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.2279
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1063807
	speed: 0.0128s/iter; left time: 126.1131s
Epoch: 23 cost time: 1.5973048210144043
Epoch: 23, Steps: 128 Train Loss: 3.1137 (Forecasting Loss:0.2173 + XiCon Loss:2.8964 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2279
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1299043
	speed: 0.0128s/iter; left time: 125.1304s
Epoch: 24 cost time: 1.6076860427856445
Epoch: 24, Steps: 128 Train Loss: 3.1102 (Forecasting Loss:0.2171 + XiCon Loss:2.8930 x Lambda(1.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2279
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1325247
	speed: 0.0131s/iter; left time: 126.2179s
Epoch: 25 cost time: 1.6412420272827148
Epoch: 25, Steps: 128 Train Loss: 3.1143 (Forecasting Loss:0.2164 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2279
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.0756538
	speed: 0.0127s/iter; left time: 121.0506s
Epoch: 26 cost time: 1.5927867889404297
Epoch: 26, Steps: 128 Train Loss: 3.1134 (Forecasting Loss:0.2168 + XiCon Loss:2.8965 x Lambda(1.0)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.2279
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.0253193
	speed: 0.0130s/iter; left time: 121.9270s
Epoch: 27 cost time: 1.685727834701538
Epoch: 27, Steps: 128 Train Loss: 3.1141 (Forecasting Loss:0.2164 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2279
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.0967736
	speed: 0.0127s/iter; left time: 117.2171s
Epoch: 28 cost time: 1.5869135856628418
Epoch: 28, Steps: 128 Train Loss: 3.1198 (Forecasting Loss:0.2167 + XiCon Loss:2.9031 x Lambda(1.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.2279
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15160620212554932, mae:0.30424144864082336, mape:0.7332698106765747, mspe:24.084049224853516 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2279
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3253527
	speed: 0.0129s/iter; left time: 163.5639s
Epoch: 1 cost time: 1.6114356517791748
Epoch: 1, Steps: 128 Train Loss: 3.3647 (Forecasting Loss:0.2942 + XiCon Loss:3.0705 x Lambda(1.0)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.2304
Validation loss decreased (inf --> 0.276503).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0882668
	speed: 0.0128s/iter; left time: 161.4257s
Epoch: 2 cost time: 1.6047260761260986
Epoch: 2, Steps: 128 Train Loss: 3.1522 (Forecasting Loss:0.2549 + XiCon Loss:2.8973 x Lambda(1.0)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.2257
Validation loss decreased (0.276503 --> 0.254127).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1631820
	speed: 0.0128s/iter; left time: 159.3626s
Epoch: 3 cost time: 1.599175214767456
Epoch: 3, Steps: 128 Train Loss: 3.1679 (Forecasting Loss:0.2439 + XiCon Loss:2.9240 x Lambda(1.0)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.2111
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1782577
	speed: 0.0127s/iter; left time: 156.6221s
Epoch: 4 cost time: 1.5907201766967773
Epoch: 4, Steps: 128 Train Loss: 3.1779 (Forecasting Loss:0.2367 + XiCon Loss:2.9412 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2117
Validation loss decreased (0.254127 --> 0.246969).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0715764
	speed: 0.0130s/iter; left time: 157.8815s
Epoch: 5 cost time: 1.6456515789031982
Epoch: 5, Steps: 128 Train Loss: 3.1521 (Forecasting Loss:0.2333 + XiCon Loss:2.9187 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1088381
	speed: 0.0127s/iter; left time: 153.5944s
Epoch: 6 cost time: 1.5918710231781006
Epoch: 6, Steps: 128 Train Loss: 3.1442 (Forecasting Loss:0.2285 + XiCon Loss:2.9157 x Lambda(1.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2069
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0949225
	speed: 0.0128s/iter; left time: 152.5106s
Epoch: 7 cost time: 1.5989649295806885
Epoch: 7, Steps: 128 Train Loss: 3.1335 (Forecasting Loss:0.2267 + XiCon Loss:2.9067 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2054
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0861013
	speed: 0.0129s/iter; left time: 152.1313s
Epoch: 8 cost time: 1.614635944366455
Epoch: 8, Steps: 128 Train Loss: 3.1281 (Forecasting Loss:0.2259 + XiCon Loss:2.9022 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2057
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1407464
	speed: 0.0128s/iter; left time: 149.4538s
Epoch: 9 cost time: 1.6008522510528564
Epoch: 9, Steps: 128 Train Loss: 3.1263 (Forecasting Loss:0.2249 + XiCon Loss:2.9014 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.2058
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1411691
	speed: 0.0128s/iter; left time: 147.3845s
Epoch: 10 cost time: 1.5923726558685303
Epoch: 10, Steps: 128 Train Loss: 3.1223 (Forecasting Loss:0.2247 + XiCon Loss:2.8976 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0607336
	speed: 0.0128s/iter; left time: 146.1553s
Epoch: 11 cost time: 1.6039204597473145
Epoch: 11, Steps: 128 Train Loss: 3.1270 (Forecasting Loss:0.2249 + XiCon Loss:2.9021 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2058
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0897856
	speed: 0.0132s/iter; left time: 149.0103s
Epoch: 12 cost time: 1.6442697048187256
Epoch: 12, Steps: 128 Train Loss: 3.1190 (Forecasting Loss:0.2242 + XiCon Loss:2.8949 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2058
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1476622
	speed: 0.0127s/iter; left time: 142.2710s
Epoch: 13 cost time: 1.5972943305969238
Epoch: 13, Steps: 128 Train Loss: 3.1243 (Forecasting Loss:0.2245 + XiCon Loss:2.8998 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2058
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1927927
	speed: 0.0130s/iter; left time: 143.3290s
Epoch: 14 cost time: 1.6292297840118408
Epoch: 14, Steps: 128 Train Loss: 3.1247 (Forecasting Loss:0.2246 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2058
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1373511403799057, mae:0.2860124111175537, mape:0.6873433589935303, mspe:21.31500244140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2758
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3092332
	speed: 0.0130s/iter; left time: 165.0631s
Epoch: 1 cost time: 1.6172266006469727
Epoch: 1, Steps: 128 Train Loss: 3.3486 (Forecasting Loss:0.2908 + XiCon Loss:3.0577 x Lambda(1.0)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2264
Validation loss decreased (inf --> 0.272502).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0778959
	speed: 0.0129s/iter; left time: 162.0112s
Epoch: 2 cost time: 1.6105365753173828
Epoch: 2, Steps: 128 Train Loss: 3.1519 (Forecasting Loss:0.2591 + XiCon Loss:2.8928 x Lambda(1.0)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2311
Validation loss decreased (0.272502 --> 0.260238).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0625615
	speed: 0.0129s/iter; left time: 160.6340s
Epoch: 3 cost time: 1.6090586185455322
Epoch: 3, Steps: 128 Train Loss: 3.1484 (Forecasting Loss:0.2420 + XiCon Loss:2.9064 x Lambda(1.0)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.2057
Validation loss decreased (0.260238 --> 0.260069).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0298307
	speed: 0.0133s/iter; left time: 164.2562s
Epoch: 4 cost time: 1.6629078388214111
Epoch: 4, Steps: 128 Train Loss: 3.1191 (Forecasting Loss:0.2367 + XiCon Loss:2.8824 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.2162
Validation loss decreased (0.260069 --> 0.253563).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1271853
	speed: 0.0130s/iter; left time: 158.8664s
Epoch: 5 cost time: 1.6252427101135254
Epoch: 5, Steps: 128 Train Loss: 3.1549 (Forecasting Loss:0.2347 + XiCon Loss:2.9202 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2049
Validation loss decreased (0.253563 --> 0.250521).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2290726
	speed: 0.0131s/iter; left time: 157.4034s
Epoch: 6 cost time: 1.6442492008209229
Epoch: 6, Steps: 128 Train Loss: 3.1996 (Forecasting Loss:0.2330 + XiCon Loss:2.9666 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2095
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0734160
	speed: 0.0129s/iter; left time: 153.7128s
Epoch: 7 cost time: 1.6073668003082275
Epoch: 7, Steps: 128 Train Loss: 3.2249 (Forecasting Loss:0.2321 + XiCon Loss:2.9928 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2053
Validation loss decreased (0.250521 --> 0.249373).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1818233
	speed: 0.0138s/iter; left time: 162.6631s
Epoch: 8 cost time: 1.7127535343170166
Epoch: 8, Steps: 128 Train Loss: 3.2160 (Forecasting Loss:0.2317 + XiCon Loss:2.9843 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1096842
	speed: 0.0142s/iter; left time: 165.9546s
Epoch: 9 cost time: 1.758425235748291
Epoch: 9, Steps: 128 Train Loss: 3.2316 (Forecasting Loss:0.2312 + XiCon Loss:3.0004 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2052
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2604828
	speed: 0.0130s/iter; left time: 150.6252s
Epoch: 10 cost time: 1.6385231018066406
Epoch: 10, Steps: 128 Train Loss: 3.2351 (Forecasting Loss:0.2312 + XiCon Loss:3.0039 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2051
Validation loss decreased (0.249373 --> 0.249192).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3754795
	speed: 0.0134s/iter; left time: 152.8319s
Epoch: 11 cost time: 1.6559867858886719
Epoch: 11, Steps: 128 Train Loss: 3.2444 (Forecasting Loss:0.2312 + XiCon Loss:3.0132 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2052
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3245022
	speed: 0.0128s/iter; left time: 145.0150s
Epoch: 12 cost time: 1.6067020893096924
Epoch: 12, Steps: 128 Train Loss: 3.2371 (Forecasting Loss:0.2311 + XiCon Loss:3.0060 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2438328
	speed: 0.0128s/iter; left time: 143.0708s
Epoch: 13 cost time: 1.6026782989501953
Epoch: 13, Steps: 128 Train Loss: 3.2335 (Forecasting Loss:0.2311 + XiCon Loss:3.0024 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2052
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3375561
	speed: 0.0127s/iter; left time: 140.0491s
Epoch: 14 cost time: 1.5961081981658936
Epoch: 14, Steps: 128 Train Loss: 3.2300 (Forecasting Loss:0.2311 + XiCon Loss:2.9989 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2052
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3225293
	speed: 0.0139s/iter; left time: 151.1691s
Epoch: 15 cost time: 1.7004401683807373
Epoch: 15, Steps: 128 Train Loss: 3.2350 (Forecasting Loss:0.2313 + XiCon Loss:3.0037 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2052
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2019780
	speed: 0.0132s/iter; left time: 142.2522s
Epoch: 16 cost time: 1.6449790000915527
Epoch: 16, Steps: 128 Train Loss: 3.2282 (Forecasting Loss:0.2313 + XiCon Loss:2.9969 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2052
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2606962
	speed: 0.0128s/iter; left time: 136.1168s
Epoch: 17 cost time: 1.607574701309204
Epoch: 17, Steps: 128 Train Loss: 3.2350 (Forecasting Loss:0.2312 + XiCon Loss:3.0038 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2052
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2778299
	speed: 0.0134s/iter; left time: 140.5854s
Epoch: 18 cost time: 1.6660451889038086
Epoch: 18, Steps: 128 Train Loss: 3.2404 (Forecasting Loss:0.2310 + XiCon Loss:3.0094 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2052
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3424442
	speed: 0.0130s/iter; left time: 135.1980s
Epoch: 19 cost time: 1.6201398372650146
Epoch: 19, Steps: 128 Train Loss: 3.2367 (Forecasting Loss:0.2311 + XiCon Loss:3.0056 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3570156
	speed: 0.0130s/iter; left time: 133.9138s
Epoch: 20 cost time: 1.6361896991729736
Epoch: 20, Steps: 128 Train Loss: 3.2301 (Forecasting Loss:0.2313 + XiCon Loss:2.9988 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13096114993095398, mae:0.2793150544166565, mape:0.661761462688446, mspe:19.566532135009766 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1365+-0.01105, MAE:0.2858+-0.01329, MAPE:0.6806+-0.03932, MSPE:20.8291+-2.45115, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3000
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3760810
	speed: 0.0171s/iter; left time: 213.5390s
Epoch: 1 cost time: 2.038525104522705
Epoch: 1, Steps: 126 Train Loss: 3.3972 (Forecasting Loss:0.3209 + XiCon Loss:3.0763 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.2701
Validation loss decreased (inf --> 0.310689).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1835535
	speed: 0.0153s/iter; left time: 189.0234s
Epoch: 2 cost time: 1.8998851776123047
Epoch: 2, Steps: 126 Train Loss: 3.1938 (Forecasting Loss:0.2931 + XiCon Loss:2.9008 x Lambda(1.0)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.2548
Validation loss decreased (0.310689 --> 0.301603).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1690845
	speed: 0.0160s/iter; left time: 195.7727s
Epoch: 3 cost time: 1.9789693355560303
Epoch: 3, Steps: 126 Train Loss: 3.1196 (Forecasting Loss:0.2797 + XiCon Loss:2.8399 x Lambda(1.0)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.2592
Validation loss decreased (0.301603 --> 0.292790).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0948226
	speed: 0.0164s/iter; left time: 198.4776s
Epoch: 4 cost time: 2.026203155517578
Epoch: 4, Steps: 126 Train Loss: 3.1951 (Forecasting Loss:0.2713 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.2921 Test MSE Loss: 0.2448
Validation loss decreased (0.292790 --> 0.292123).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2863641
	speed: 0.0158s/iter; left time: 189.1391s
Epoch: 5 cost time: 1.9609122276306152
Epoch: 5, Steps: 126 Train Loss: 3.2310 (Forecasting Loss:0.2677 + XiCon Loss:2.9633 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2435
Validation loss decreased (0.292123 --> 0.288621).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1359951
	speed: 0.0159s/iter; left time: 188.8459s
Epoch: 6 cost time: 1.9749047756195068
Epoch: 6, Steps: 126 Train Loss: 3.2511 (Forecasting Loss:0.2658 + XiCon Loss:2.9853 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2442
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3334126
	speed: 0.0159s/iter; left time: 187.2068s
Epoch: 7 cost time: 1.9900622367858887
Epoch: 7, Steps: 126 Train Loss: 3.2515 (Forecasting Loss:0.2646 + XiCon Loss:2.9868 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.2435
Validation loss decreased (0.288621 --> 0.288469).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2416742
	speed: 0.0162s/iter; left time: 187.7002s
Epoch: 8 cost time: 2.0103137493133545
Epoch: 8, Steps: 126 Train Loss: 3.2540 (Forecasting Loss:0.2640 + XiCon Loss:2.9900 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2427
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2254744
	speed: 0.0161s/iter; left time: 185.4410s
Epoch: 9 cost time: 1.9911396503448486
Epoch: 9, Steps: 126 Train Loss: 3.2521 (Forecasting Loss:0.2638 + XiCon Loss:2.9883 x Lambda(1.0)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.2434
Validation loss decreased (0.288469 --> 0.287816).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3151903
	speed: 0.0160s/iter; left time: 181.5341s
Epoch: 10 cost time: 1.9844694137573242
Epoch: 10, Steps: 126 Train Loss: 3.2551 (Forecasting Loss:0.2634 + XiCon Loss:2.9917 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2432
Validation loss decreased (0.287816 --> 0.287525).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3585670
	speed: 0.0158s/iter; left time: 177.5612s
Epoch: 11 cost time: 1.9601953029632568
Epoch: 11, Steps: 126 Train Loss: 3.2564 (Forecasting Loss:0.2636 + XiCon Loss:2.9929 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2020617
	speed: 0.0160s/iter; left time: 178.1862s
Epoch: 12 cost time: 1.992278814315796
Epoch: 12, Steps: 126 Train Loss: 3.2738 (Forecasting Loss:0.2633 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
Validation loss decreased (0.287525 --> 0.287489).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4196525
	speed: 0.0159s/iter; left time: 174.8937s
Epoch: 13 cost time: 1.9798243045806885
Epoch: 13, Steps: 126 Train Loss: 3.2636 (Forecasting Loss:0.2635 + XiCon Loss:3.0001 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2081070
	speed: 0.0163s/iter; left time: 176.6916s
Epoch: 14 cost time: 2.019719123840332
Epoch: 14, Steps: 126 Train Loss: 3.2582 (Forecasting Loss:0.2633 + XiCon Loss:2.9949 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3560472
	speed: 0.0158s/iter; left time: 169.7254s
Epoch: 15 cost time: 1.9540746212005615
Epoch: 15, Steps: 126 Train Loss: 3.2446 (Forecasting Loss:0.2633 + XiCon Loss:2.9813 x Lambda(1.0)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.2431
Validation loss decreased (0.287489 --> 0.287448).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2903652
	speed: 0.0158s/iter; left time: 168.0585s
Epoch: 16 cost time: 1.969257116317749
Epoch: 16, Steps: 126 Train Loss: 3.2469 (Forecasting Loss:0.2634 + XiCon Loss:2.9835 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2445347
	speed: 0.0160s/iter; left time: 167.5542s
Epoch: 17 cost time: 1.9847216606140137
Epoch: 17, Steps: 126 Train Loss: 3.2602 (Forecasting Loss:0.2633 + XiCon Loss:2.9969 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2720404
	speed: 0.0165s/iter; left time: 171.0237s
Epoch: 18 cost time: 2.0381617546081543
Epoch: 18, Steps: 126 Train Loss: 3.2641 (Forecasting Loss:0.2635 + XiCon Loss:3.0006 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4386387
	speed: 0.0161s/iter; left time: 164.2745s
Epoch: 19 cost time: 1.9907567501068115
Epoch: 19, Steps: 126 Train Loss: 3.2550 (Forecasting Loss:0.2631 + XiCon Loss:2.9919 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3674204
	speed: 0.0158s/iter; left time: 159.8492s
Epoch: 20 cost time: 1.9677789211273193
Epoch: 20, Steps: 126 Train Loss: 3.2559 (Forecasting Loss:0.2632 + XiCon Loss:2.9927 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3271518
	speed: 0.0163s/iter; left time: 162.2682s
Epoch: 21 cost time: 2.0172364711761475
Epoch: 21, Steps: 126 Train Loss: 3.2583 (Forecasting Loss:0.2633 + XiCon Loss:2.9950 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3106101
	speed: 0.0159s/iter; left time: 156.6107s
Epoch: 22 cost time: 1.9742820262908936
Epoch: 22, Steps: 126 Train Loss: 3.2629 (Forecasting Loss:0.2631 + XiCon Loss:2.9998 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2736084
	speed: 0.0161s/iter; left time: 156.5169s
Epoch: 23 cost time: 1.9891273975372314
Epoch: 23, Steps: 126 Train Loss: 3.2532 (Forecasting Loss:0.2629 + XiCon Loss:2.9902 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3066380
	speed: 0.0163s/iter; left time: 156.9941s
Epoch: 24 cost time: 2.027019739151001
Epoch: 24, Steps: 126 Train Loss: 3.2525 (Forecasting Loss:0.2633 + XiCon Loss:2.9892 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3839064
	speed: 0.0159s/iter; left time: 150.6519s
Epoch: 25 cost time: 1.9730212688446045
Epoch: 25, Steps: 126 Train Loss: 3.2432 (Forecasting Loss:0.2633 + XiCon Loss:2.9799 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2431
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1657160073518753, mae:0.32040277123451233, mape:0.6800358891487122, mspe:20.166685104370117 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2025
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3661478
	speed: 0.0147s/iter; left time: 184.1134s
Epoch: 1 cost time: 1.8042843341827393
Epoch: 1, Steps: 126 Train Loss: 3.3849 (Forecasting Loss:0.3205 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.3077 Test MSE Loss: 0.2612
Validation loss decreased (inf --> 0.307703).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2522347
	speed: 0.0150s/iter; left time: 185.1868s
Epoch: 2 cost time: 1.8818788528442383
Epoch: 2, Steps: 126 Train Loss: 3.2311 (Forecasting Loss:0.2913 + XiCon Loss:2.9398 x Lambda(1.0)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.2638
Validation loss decreased (0.307703 --> 0.300596).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1869438
	speed: 0.0157s/iter; left time: 192.4229s
Epoch: 3 cost time: 1.955819845199585
Epoch: 3, Steps: 126 Train Loss: 3.1983 (Forecasting Loss:0.2733 + XiCon Loss:2.9251 x Lambda(1.0)), Vali MSE Loss: 0.2879 Test MSE Loss: 0.2512
Validation loss decreased (0.300596 --> 0.287910).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1264124
	speed: 0.0158s/iter; left time: 191.5520s
Epoch: 4 cost time: 1.9956371784210205
Epoch: 4, Steps: 126 Train Loss: 3.1696 (Forecasting Loss:0.2683 + XiCon Loss:2.9014 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2539
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1255512
	speed: 0.0160s/iter; left time: 191.4098s
Epoch: 5 cost time: 1.9793689250946045
Epoch: 5, Steps: 126 Train Loss: 3.1455 (Forecasting Loss:0.2640 + XiCon Loss:2.8815 x Lambda(1.0)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.2453
Validation loss decreased (0.287910 --> 0.287622).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1234002
	speed: 0.0163s/iter; left time: 193.1404s
Epoch: 6 cost time: 2.0071535110473633
Epoch: 6, Steps: 126 Train Loss: 3.1319 (Forecasting Loss:0.2621 + XiCon Loss:2.8698 x Lambda(1.0)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2470
Validation loss decreased (0.287622 --> 0.283872).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1882215
	speed: 0.0158s/iter; left time: 185.5510s
Epoch: 7 cost time: 1.9587159156799316
Epoch: 7, Steps: 126 Train Loss: 3.1343 (Forecasting Loss:0.2609 + XiCon Loss:2.8734 x Lambda(1.0)), Vali MSE Loss: 0.2840 Test MSE Loss: 0.2462
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1367862
	speed: 0.0159s/iter; left time: 184.1882s
Epoch: 8 cost time: 1.9856913089752197
Epoch: 8, Steps: 126 Train Loss: 3.1325 (Forecasting Loss:0.2599 + XiCon Loss:2.8727 x Lambda(1.0)), Vali MSE Loss: 0.2847 Test MSE Loss: 0.2473
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0723541
	speed: 0.0158s/iter; left time: 182.1300s
Epoch: 9 cost time: 1.970585823059082
Epoch: 9, Steps: 126 Train Loss: 3.1261 (Forecasting Loss:0.2600 + XiCon Loss:2.8661 x Lambda(1.0)), Vali MSE Loss: 0.2847 Test MSE Loss: 0.2467
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0772049
	speed: 0.0161s/iter; left time: 183.1176s
Epoch: 10 cost time: 1.9866738319396973
Epoch: 10, Steps: 126 Train Loss: 3.1237 (Forecasting Loss:0.2595 + XiCon Loss:2.8642 x Lambda(1.0)), Vali MSE Loss: 0.2844 Test MSE Loss: 0.2464
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0928144
	speed: 0.0161s/iter; left time: 181.3311s
Epoch: 11 cost time: 1.9921057224273682
Epoch: 11, Steps: 126 Train Loss: 3.1205 (Forecasting Loss:0.2593 + XiCon Loss:2.8612 x Lambda(1.0)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.2465
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0848916
	speed: 0.0159s/iter; left time: 176.7213s
Epoch: 12 cost time: 1.9655306339263916
Epoch: 12, Steps: 126 Train Loss: 3.1206 (Forecasting Loss:0.2596 + XiCon Loss:2.8609 x Lambda(1.0)), Vali MSE Loss: 0.2841 Test MSE Loss: 0.2465
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2152147
	speed: 0.0157s/iter; left time: 172.9204s
Epoch: 13 cost time: 1.9541418552398682
Epoch: 13, Steps: 126 Train Loss: 3.1221 (Forecasting Loss:0.2594 + XiCon Loss:2.8626 x Lambda(1.0)), Vali MSE Loss: 0.2843 Test MSE Loss: 0.2464
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1996655
	speed: 0.0164s/iter; left time: 178.2022s
Epoch: 14 cost time: 2.0233664512634277
Epoch: 14, Steps: 126 Train Loss: 3.1231 (Forecasting Loss:0.2596 + XiCon Loss:2.8635 x Lambda(1.0)), Vali MSE Loss: 0.2841 Test MSE Loss: 0.2465
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1711903
	speed: 0.0158s/iter; left time: 169.3386s
Epoch: 15 cost time: 1.9611501693725586
Epoch: 15, Steps: 126 Train Loss: 3.1262 (Forecasting Loss:0.2594 + XiCon Loss:2.8668 x Lambda(1.0)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.2465
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1122117
	speed: 0.0157s/iter; left time: 166.5322s
Epoch: 16 cost time: 1.9472625255584717
Epoch: 16, Steps: 126 Train Loss: 3.1193 (Forecasting Loss:0.2593 + XiCon Loss:2.8600 x Lambda(1.0)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.2465
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16830094158649445, mae:0.32564878463745117, mape:0.6828287243843079, mspe:18.224618911743164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2632
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3450117
	speed: 0.0143s/iter; left time: 178.7610s
Epoch: 1 cost time: 1.7589473724365234
Epoch: 1, Steps: 126 Train Loss: 3.3863 (Forecasting Loss:0.3207 + XiCon Loss:3.0656 x Lambda(1.0)), Vali MSE Loss: 0.3035 Test MSE Loss: 0.2628
Validation loss decreased (inf --> 0.303524).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3618593
	speed: 0.0159s/iter; left time: 197.0100s
Epoch: 2 cost time: 1.9566962718963623
Epoch: 2, Steps: 126 Train Loss: 3.2412 (Forecasting Loss:0.2914 + XiCon Loss:2.9498 x Lambda(1.0)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.2623
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3432817
	speed: 0.0153s/iter; left time: 187.3668s
Epoch: 3 cost time: 1.8924620151519775
Epoch: 3, Steps: 126 Train Loss: 3.2989 (Forecasting Loss:0.2771 + XiCon Loss:3.0218 x Lambda(1.0)), Vali MSE Loss: 0.3001 Test MSE Loss: 0.2536
Validation loss decreased (0.303524 --> 0.300081).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2025845
	speed: 0.0153s/iter; left time: 185.0949s
Epoch: 4 cost time: 1.8948264122009277
Epoch: 4, Steps: 126 Train Loss: 3.2405 (Forecasting Loss:0.2699 + XiCon Loss:2.9706 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2482
Validation loss decreased (0.300081 --> 0.296797).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1429658
	speed: 0.0157s/iter; left time: 188.6525s
Epoch: 5 cost time: 1.9755439758300781
Epoch: 5, Steps: 126 Train Loss: 3.2171 (Forecasting Loss:0.2674 + XiCon Loss:2.9497 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2472
Validation loss decreased (0.296797 --> 0.290572).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2176700
	speed: 0.0155s/iter; left time: 184.5887s
Epoch: 6 cost time: 1.9235703945159912
Epoch: 6, Steps: 126 Train Loss: 3.2025 (Forecasting Loss:0.2652 + XiCon Loss:2.9373 x Lambda(1.0)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.2462
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2612455
	speed: 0.0156s/iter; left time: 182.8919s
Epoch: 7 cost time: 1.9358904361724854
Epoch: 7, Steps: 126 Train Loss: 3.2027 (Forecasting Loss:0.2645 + XiCon Loss:2.9382 x Lambda(1.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2439
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0972292
	speed: 0.0155s/iter; left time: 179.6274s
Epoch: 8 cost time: 1.9168219566345215
Epoch: 8, Steps: 126 Train Loss: 3.1941 (Forecasting Loss:0.2632 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2453
Validation loss decreased (0.290572 --> 0.289569).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2645617
	speed: 0.0158s/iter; left time: 181.7145s
Epoch: 9 cost time: 1.953350305557251
Epoch: 9, Steps: 126 Train Loss: 3.1922 (Forecasting Loss:0.2629 + XiCon Loss:2.9293 x Lambda(1.0)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.2446
Validation loss decreased (0.289569 --> 0.289462).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2183394
	speed: 0.0156s/iter; left time: 177.8109s
Epoch: 10 cost time: 1.9344885349273682
Epoch: 10, Steps: 126 Train Loss: 3.1956 (Forecasting Loss:0.2630 + XiCon Loss:2.9326 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2445
Validation loss decreased (0.289462 --> 0.289381).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2488854
	speed: 0.0156s/iter; left time: 175.5579s
Epoch: 11 cost time: 1.9306538105010986
Epoch: 11, Steps: 126 Train Loss: 3.1913 (Forecasting Loss:0.2634 + XiCon Loss:2.9279 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2445
Validation loss decreased (0.289381 --> 0.289269).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2285109
	speed: 0.0154s/iter; left time: 171.3927s
Epoch: 12 cost time: 1.9120919704437256
Epoch: 12, Steps: 126 Train Loss: 3.1911 (Forecasting Loss:0.2631 + XiCon Loss:2.9280 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
Validation loss decreased (0.289269 --> 0.289151).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1803398
	speed: 0.0154s/iter; left time: 169.5907s
Epoch: 13 cost time: 1.9128522872924805
Epoch: 13, Steps: 126 Train Loss: 3.1923 (Forecasting Loss:0.2624 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1470609
	speed: 0.0154s/iter; left time: 167.5738s
Epoch: 14 cost time: 1.9058644771575928
Epoch: 14, Steps: 126 Train Loss: 3.1924 (Forecasting Loss:0.2630 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1735163
	speed: 0.0154s/iter; left time: 165.5651s
Epoch: 15 cost time: 1.9131064414978027
Epoch: 15, Steps: 126 Train Loss: 3.1878 (Forecasting Loss:0.2631 + XiCon Loss:2.9247 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
Validation loss decreased (0.289151 --> 0.289082).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1364706
	speed: 0.0155s/iter; left time: 164.5840s
Epoch: 16 cost time: 1.9201686382293701
Epoch: 16, Steps: 126 Train Loss: 3.1917 (Forecasting Loss:0.2632 + XiCon Loss:2.9285 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1936831
	speed: 0.0155s/iter; left time: 162.8946s
Epoch: 17 cost time: 1.9250082969665527
Epoch: 17, Steps: 126 Train Loss: 3.1919 (Forecasting Loss:0.2624 + XiCon Loss:2.9295 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1400542
	speed: 0.0156s/iter; left time: 161.8541s
Epoch: 18 cost time: 1.9263412952423096
Epoch: 18, Steps: 126 Train Loss: 3.1885 (Forecasting Loss:0.2629 + XiCon Loss:2.9255 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1160686
	speed: 0.0158s/iter; left time: 161.8570s
Epoch: 19 cost time: 1.9561381340026855
Epoch: 19, Steps: 126 Train Loss: 3.1883 (Forecasting Loss:0.2627 + XiCon Loss:2.9256 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2832077
	speed: 0.0159s/iter; left time: 160.4357s
Epoch: 20 cost time: 1.9567506313323975
Epoch: 20, Steps: 126 Train Loss: 3.1917 (Forecasting Loss:0.2632 + XiCon Loss:2.9284 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1492078
	speed: 0.0153s/iter; left time: 153.0509s
Epoch: 21 cost time: 1.9041056632995605
Epoch: 21, Steps: 126 Train Loss: 3.1996 (Forecasting Loss:0.2631 + XiCon Loss:2.9365 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2249370
	speed: 0.0154s/iter; left time: 151.2782s
Epoch: 22 cost time: 1.9029581546783447
Epoch: 22, Steps: 126 Train Loss: 3.1869 (Forecasting Loss:0.2628 + XiCon Loss:2.9241 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1289103
	speed: 0.0155s/iter; left time: 150.3814s
Epoch: 23 cost time: 1.9103291034698486
Epoch: 23, Steps: 126 Train Loss: 3.1920 (Forecasting Loss:0.2626 + XiCon Loss:2.9293 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2338343
	speed: 0.0157s/iter; left time: 150.3865s
Epoch: 24 cost time: 1.9441132545471191
Epoch: 24, Steps: 126 Train Loss: 3.1942 (Forecasting Loss:0.2632 + XiCon Loss:2.9310 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2445
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1780512
	speed: 0.0156s/iter; left time: 147.5261s
Epoch: 25 cost time: 1.9278857707977295
Epoch: 25, Steps: 126 Train Loss: 3.1962 (Forecasting Loss:0.2628 + XiCon Loss:2.9334 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16712486743927002, mae:0.3218255639076233, mape:0.6785117387771606, mspe:19.86524772644043 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2747
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3350716
	speed: 0.0150s/iter; left time: 187.0299s
Epoch: 1 cost time: 1.8558592796325684
Epoch: 1, Steps: 126 Train Loss: 3.3935 (Forecasting Loss:0.3215 + XiCon Loss:3.0719 x Lambda(1.0)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.2691
Validation loss decreased (inf --> 0.306498).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1828279
	speed: 0.0159s/iter; left time: 196.7855s
Epoch: 2 cost time: 1.9593136310577393
Epoch: 2, Steps: 126 Train Loss: 3.1942 (Forecasting Loss:0.2942 + XiCon Loss:2.9000 x Lambda(1.0)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2644
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1672049
	speed: 0.0159s/iter; left time: 194.7258s
Epoch: 3 cost time: 1.978827714920044
Epoch: 3, Steps: 126 Train Loss: 3.1609 (Forecasting Loss:0.2784 + XiCon Loss:2.8825 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2509
Validation loss decreased (0.306498 --> 0.290702).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4046521
	speed: 0.0162s/iter; left time: 195.8139s
Epoch: 4 cost time: 1.9922785758972168
Epoch: 4, Steps: 126 Train Loss: 3.3406 (Forecasting Loss:0.2725 + XiCon Loss:3.0681 x Lambda(1.0)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.2471
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3193076
	speed: 0.0158s/iter; left time: 189.7038s
Epoch: 5 cost time: 1.9814224243164062
Epoch: 5, Steps: 126 Train Loss: 3.3374 (Forecasting Loss:0.2695 + XiCon Loss:3.0679 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2456
Validation loss decreased (0.290702 --> 0.289792).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3514814
	speed: 0.0161s/iter; left time: 190.7903s
Epoch: 6 cost time: 1.9828133583068848
Epoch: 6, Steps: 126 Train Loss: 3.3163 (Forecasting Loss:0.2680 + XiCon Loss:3.0484 x Lambda(1.0)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.2445
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2754748
	speed: 0.0161s/iter; left time: 189.3991s
Epoch: 7 cost time: 1.9916443824768066
Epoch: 7, Steps: 126 Train Loss: 3.3045 (Forecasting Loss:0.2673 + XiCon Loss:3.0373 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2431
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1855588
	speed: 0.0159s/iter; left time: 184.5091s
Epoch: 8 cost time: 1.9671142101287842
Epoch: 8, Steps: 126 Train Loss: 3.3016 (Forecasting Loss:0.2668 + XiCon Loss:3.0348 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2438
Validation loss decreased (0.289792 --> 0.289399).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3687356
	speed: 0.0158s/iter; left time: 181.5680s
Epoch: 9 cost time: 1.9687120914459229
Epoch: 9, Steps: 126 Train Loss: 3.3016 (Forecasting Loss:0.2664 + XiCon Loss:3.0352 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2436
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2820098
	speed: 0.0156s/iter; left time: 177.8759s
Epoch: 10 cost time: 1.946960687637329
Epoch: 10, Steps: 126 Train Loss: 3.3065 (Forecasting Loss:0.2661 + XiCon Loss:3.0404 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2438
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2508082
	speed: 0.0161s/iter; left time: 181.2376s
Epoch: 11 cost time: 2.016437530517578
Epoch: 11, Steps: 126 Train Loss: 3.2949 (Forecasting Loss:0.2662 + XiCon Loss:3.0287 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2438
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3261399
	speed: 0.0160s/iter; left time: 177.9511s
Epoch: 12 cost time: 1.9969379901885986
Epoch: 12, Steps: 126 Train Loss: 3.3121 (Forecasting Loss:0.2657 + XiCon Loss:3.0464 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2437
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3871224
	speed: 0.0163s/iter; left time: 178.9889s
Epoch: 13 cost time: 2.022426128387451
Epoch: 13, Steps: 126 Train Loss: 3.2893 (Forecasting Loss:0.2659 + XiCon Loss:3.0234 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2437
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4103942
	speed: 0.0158s/iter; left time: 171.6692s
Epoch: 14 cost time: 1.9621362686157227
Epoch: 14, Steps: 126 Train Loss: 3.3044 (Forecasting Loss:0.2655 + XiCon Loss:3.0389 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2437
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3073807
	speed: 0.0159s/iter; left time: 170.5901s
Epoch: 15 cost time: 1.9729032516479492
Epoch: 15, Steps: 126 Train Loss: 3.3081 (Forecasting Loss:0.2659 + XiCon Loss:3.0422 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2437
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2876377
	speed: 0.0160s/iter; left time: 169.3308s
Epoch: 16 cost time: 1.9898700714111328
Epoch: 16, Steps: 126 Train Loss: 3.3004 (Forecasting Loss:0.2659 + XiCon Loss:3.0345 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2437
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3892827
	speed: 0.0159s/iter; left time: 166.3270s
Epoch: 17 cost time: 1.969020128250122
Epoch: 17, Steps: 126 Train Loss: 3.3033 (Forecasting Loss:0.2658 + XiCon Loss:3.0374 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2437
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2702415
	speed: 0.0163s/iter; left time: 168.5954s
Epoch: 18 cost time: 2.01716947555542
Epoch: 18, Steps: 126 Train Loss: 3.2956 (Forecasting Loss:0.2661 + XiCon Loss:3.0295 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2437
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1667555868625641, mae:0.3208245038986206, mape:0.691576361656189, mspe:21.189680099487305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2205
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3283138
	speed: 0.0146s/iter; left time: 182.4283s
Epoch: 1 cost time: 1.7894670963287354
Epoch: 1, Steps: 126 Train Loss: 3.3858 (Forecasting Loss:0.3219 + XiCon Loss:3.0639 x Lambda(1.0)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.2661
Validation loss decreased (inf --> 0.308111).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2370756
	speed: 0.0151s/iter; left time: 187.1679s
Epoch: 2 cost time: 1.875473976135254
Epoch: 2, Steps: 126 Train Loss: 3.2650 (Forecasting Loss:0.2947 + XiCon Loss:2.9702 x Lambda(1.0)), Vali MSE Loss: 0.3009 Test MSE Loss: 0.2578
Validation loss decreased (0.308111 --> 0.300897).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2275410
	speed: 0.0150s/iter; left time: 183.9095s
Epoch: 3 cost time: 1.8698148727416992
Epoch: 3, Steps: 126 Train Loss: 3.3381 (Forecasting Loss:0.2792 + XiCon Loss:3.0588 x Lambda(1.0)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.2424
Validation loss decreased (0.300897 --> 0.295104).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2883179
	speed: 0.0152s/iter; left time: 184.8696s
Epoch: 4 cost time: 1.8972241878509521
Epoch: 4, Steps: 126 Train Loss: 3.3162 (Forecasting Loss:0.2720 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2471
Validation loss decreased (0.295104 --> 0.290570).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3209045
	speed: 0.0156s/iter; left time: 187.6648s
Epoch: 5 cost time: 1.9288699626922607
Epoch: 5, Steps: 126 Train Loss: 3.3100 (Forecasting Loss:0.2689 + XiCon Loss:3.0412 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2450
Validation loss decreased (0.290570 --> 0.289407).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2786367
	speed: 0.0152s/iter; left time: 180.3515s
Epoch: 6 cost time: 1.8853414058685303
Epoch: 6, Steps: 126 Train Loss: 3.3107 (Forecasting Loss:0.2664 + XiCon Loss:3.0443 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2457
Validation loss decreased (0.289407 --> 0.288287).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3204942
	speed: 0.0163s/iter; left time: 190.8770s
Epoch: 7 cost time: 1.990870475769043
Epoch: 7, Steps: 126 Train Loss: 3.3038 (Forecasting Loss:0.2653 + XiCon Loss:3.0385 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2453
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4134848
	speed: 0.0152s/iter; left time: 176.8298s
Epoch: 8 cost time: 1.8855509757995605
Epoch: 8, Steps: 126 Train Loss: 3.3049 (Forecasting Loss:0.2648 + XiCon Loss:3.0401 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2441
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3985469
	speed: 0.0153s/iter; left time: 175.4014s
Epoch: 9 cost time: 1.9206812381744385
Epoch: 9, Steps: 126 Train Loss: 3.3003 (Forecasting Loss:0.2643 + XiCon Loss:3.0360 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2440
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4492679
	speed: 0.0152s/iter; left time: 172.4883s
Epoch: 10 cost time: 1.889604091644287
Epoch: 10, Steps: 126 Train Loss: 3.3076 (Forecasting Loss:0.2639 + XiCon Loss:3.0437 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2441
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2795134
	speed: 0.0153s/iter; left time: 172.2216s
Epoch: 11 cost time: 1.9048995971679688
Epoch: 11, Steps: 126 Train Loss: 3.3094 (Forecasting Loss:0.2640 + XiCon Loss:3.0454 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2441
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3697844
	speed: 0.0157s/iter; left time: 174.8639s
Epoch: 12 cost time: 1.9375207424163818
Epoch: 12, Steps: 126 Train Loss: 3.3026 (Forecasting Loss:0.2638 + XiCon Loss:3.0387 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2441
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4044118
	speed: 0.0153s/iter; left time: 167.7608s
Epoch: 13 cost time: 1.8918514251708984
Epoch: 13, Steps: 126 Train Loss: 3.2920 (Forecasting Loss:0.2639 + XiCon Loss:3.0281 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2441
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2791779
	speed: 0.0162s/iter; left time: 175.8221s
Epoch: 14 cost time: 1.9930357933044434
Epoch: 14, Steps: 126 Train Loss: 3.3066 (Forecasting Loss:0.2640 + XiCon Loss:3.0426 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2441
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1763849
	speed: 0.0153s/iter; left time: 163.8525s
Epoch: 15 cost time: 1.8981349468231201
Epoch: 15, Steps: 126 Train Loss: 3.3031 (Forecasting Loss:0.2638 + XiCon Loss:3.0393 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2441
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2409425
	speed: 0.0153s/iter; left time: 162.1103s
Epoch: 16 cost time: 1.8942012786865234
Epoch: 16, Steps: 126 Train Loss: 3.3229 (Forecasting Loss:0.2639 + XiCon Loss:3.0590 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2441
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1678723841905594, mae:0.3235689103603363, mape:0.6773430109024048, mspe:19.739349365234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1672+-0.00125, MAE:0.3225+-0.00269, MAPE:0.6821+-0.00708, MSPE:19.8371+-1.32407, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2579
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3542612
	speed: 0.0191s/iter; left time: 234.8676s
Epoch: 1 cost time: 2.2516605854034424
Epoch: 1, Steps: 124 Train Loss: 3.4205 (Forecasting Loss:0.3418 + XiCon Loss:3.0787 x Lambda(1.0)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2925
Validation loss decreased (inf --> 0.346347).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1555912
	speed: 0.0180s/iter; left time: 219.4222s
Epoch: 2 cost time: 2.2192158699035645
Epoch: 2, Steps: 124 Train Loss: 3.2139 (Forecasting Loss:0.3139 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.2871
Validation loss decreased (0.346347 --> 0.339277).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2876606
	speed: 0.0187s/iter; left time: 225.1905s
Epoch: 3 cost time: 2.321146249771118
Epoch: 3, Steps: 124 Train Loss: 3.2181 (Forecasting Loss:0.3021 + XiCon Loss:2.9161 x Lambda(1.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.2743
Validation loss decreased (0.339277 --> 0.330766).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4045804
	speed: 0.0194s/iter; left time: 231.0564s
Epoch: 4 cost time: 2.3678925037384033
Epoch: 4, Steps: 124 Train Loss: 3.4067 (Forecasting Loss:0.2938 + XiCon Loss:3.1129 x Lambda(1.0)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2724
Validation loss decreased (0.330766 --> 0.327180).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4253395
	speed: 0.0190s/iter; left time: 224.1121s
Epoch: 5 cost time: 2.337759017944336
Epoch: 5, Steps: 124 Train Loss: 3.4453 (Forecasting Loss:0.2890 + XiCon Loss:3.1563 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2707
Validation loss decreased (0.327180 --> 0.324149).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3772452
	speed: 0.0191s/iter; left time: 223.4990s
Epoch: 6 cost time: 2.3390121459960938
Epoch: 6, Steps: 124 Train Loss: 3.4349 (Forecasting Loss:0.2872 + XiCon Loss:3.1476 x Lambda(1.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2681
Validation loss decreased (0.324149 --> 0.323304).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3864489
	speed: 0.0188s/iter; left time: 216.7033s
Epoch: 7 cost time: 2.311868906021118
Epoch: 7, Steps: 124 Train Loss: 3.4401 (Forecasting Loss:0.2861 + XiCon Loss:3.1540 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2685
Validation loss decreased (0.323304 --> 0.321833).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5326779
	speed: 0.0189s/iter; left time: 216.1622s
Epoch: 8 cost time: 2.3150486946105957
Epoch: 8, Steps: 124 Train Loss: 3.4483 (Forecasting Loss:0.2856 + XiCon Loss:3.1627 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2681
Validation loss decreased (0.321833 --> 0.321690).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2158184
	speed: 0.0191s/iter; left time: 215.9914s
Epoch: 9 cost time: 2.3415558338165283
Epoch: 9, Steps: 124 Train Loss: 3.4311 (Forecasting Loss:0.2855 + XiCon Loss:3.1456 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2675
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4757879
	speed: 0.0188s/iter; left time: 210.4385s
Epoch: 10 cost time: 2.3032662868499756
Epoch: 10, Steps: 124 Train Loss: 3.4274 (Forecasting Loss:0.2850 + XiCon Loss:3.1424 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2676
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5497088
	speed: 0.0187s/iter; left time: 206.3179s
Epoch: 11 cost time: 2.294393539428711
Epoch: 11, Steps: 124 Train Loss: 3.4265 (Forecasting Loss:0.2850 + XiCon Loss:3.1415 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2678
Validation loss decreased (0.321690 --> 0.321138).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4881895
	speed: 0.0190s/iter; left time: 208.1863s
Epoch: 12 cost time: 2.3343584537506104
Epoch: 12, Steps: 124 Train Loss: 3.4213 (Forecasting Loss:0.2853 + XiCon Loss:3.1359 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2677
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3513839
	speed: 0.0193s/iter; left time: 208.8340s
Epoch: 13 cost time: 2.3567922115325928
Epoch: 13, Steps: 124 Train Loss: 3.4393 (Forecasting Loss:0.2847 + XiCon Loss:3.1546 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2676
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4497199
	speed: 0.0189s/iter; left time: 201.9379s
Epoch: 14 cost time: 2.3249783515930176
Epoch: 14, Steps: 124 Train Loss: 3.4298 (Forecasting Loss:0.2850 + XiCon Loss:3.1448 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2677
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3104208
	speed: 0.0190s/iter; left time: 200.9638s
Epoch: 15 cost time: 2.330940008163452
Epoch: 15, Steps: 124 Train Loss: 3.4279 (Forecasting Loss:0.2847 + XiCon Loss:3.1433 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2676
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4439855
	speed: 0.0186s/iter; left time: 193.8321s
Epoch: 16 cost time: 2.287036180496216
Epoch: 16, Steps: 124 Train Loss: 3.4578 (Forecasting Loss:0.2850 + XiCon Loss:3.1728 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2676
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3412561
	speed: 0.0190s/iter; left time: 195.9840s
Epoch: 17 cost time: 2.3408384323120117
Epoch: 17, Steps: 124 Train Loss: 3.4352 (Forecasting Loss:0.2848 + XiCon Loss:3.1504 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2676
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4837983
	speed: 0.0192s/iter; left time: 195.7903s
Epoch: 18 cost time: 2.344003438949585
Epoch: 18, Steps: 124 Train Loss: 3.4275 (Forecasting Loss:0.2849 + XiCon Loss:3.1425 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2676
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.5264571
	speed: 0.0188s/iter; left time: 189.2251s
Epoch: 19 cost time: 2.3096985816955566
Epoch: 19, Steps: 124 Train Loss: 3.4340 (Forecasting Loss:0.2848 + XiCon Loss:3.1492 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2676
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4125457
	speed: 0.0192s/iter; left time: 190.7836s
Epoch: 20 cost time: 2.350043296813965
Epoch: 20, Steps: 124 Train Loss: 3.4361 (Forecasting Loss:0.2848 + XiCon Loss:3.1513 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2676
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4503357
	speed: 0.0193s/iter; left time: 189.6490s
Epoch: 21 cost time: 2.362520456314087
Epoch: 21, Steps: 124 Train Loss: 3.4485 (Forecasting Loss:0.2850 + XiCon Loss:3.1634 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2676
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18708965182304382, mae:0.34844180941581726, mape:0.6823269724845886, mspe:18.458654403686523 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2967
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3383226
	speed: 0.0166s/iter; left time: 204.7764s
Epoch: 1 cost time: 2.0285701751708984
Epoch: 1, Steps: 124 Train Loss: 3.4090 (Forecasting Loss:0.3370 + XiCon Loss:3.0720 x Lambda(1.0)), Vali MSE Loss: 0.3436 Test MSE Loss: 0.2854
Validation loss decreased (inf --> 0.343578).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3134108
	speed: 0.0183s/iter; left time: 223.1520s
Epoch: 2 cost time: 2.2496674060821533
Epoch: 2, Steps: 124 Train Loss: 3.2476 (Forecasting Loss:0.3146 + XiCon Loss:2.9330 x Lambda(1.0)), Vali MSE Loss: 0.3351 Test MSE Loss: 0.2843
Validation loss decreased (0.343578 --> 0.335111).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3840673
	speed: 0.0184s/iter; left time: 222.1970s
Epoch: 3 cost time: 2.2614686489105225
Epoch: 3, Steps: 124 Train Loss: 3.3845 (Forecasting Loss:0.3022 + XiCon Loss:3.0823 x Lambda(1.0)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.2740
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4376056
	speed: 0.0187s/iter; left time: 222.5798s
Epoch: 4 cost time: 2.2854628562927246
Epoch: 4, Steps: 124 Train Loss: 3.4883 (Forecasting Loss:0.2971 + XiCon Loss:3.1912 x Lambda(1.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.2753
Validation loss decreased (0.335111 --> 0.330567).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4280341
	speed: 0.0191s/iter; left time: 225.6059s
Epoch: 5 cost time: 2.3343918323516846
Epoch: 5, Steps: 124 Train Loss: 3.4791 (Forecasting Loss:0.2931 + XiCon Loss:3.1859 x Lambda(1.0)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2713
Validation loss decreased (0.330567 --> 0.326909).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.5666678
	speed: 0.0187s/iter; left time: 218.6374s
Epoch: 6 cost time: 2.295692205429077
Epoch: 6, Steps: 124 Train Loss: 3.4738 (Forecasting Loss:0.2909 + XiCon Loss:3.1829 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2763
Validation loss decreased (0.326909 --> 0.322858).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.6943016
	speed: 0.0186s/iter; left time: 214.7908s
Epoch: 7 cost time: 2.2825446128845215
Epoch: 7, Steps: 124 Train Loss: 3.4749 (Forecasting Loss:0.2900 + XiCon Loss:3.1849 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2755
Validation loss decreased (0.322858 --> 0.322336).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4875762
	speed: 0.0193s/iter; left time: 220.7484s
Epoch: 8 cost time: 2.3932816982269287
Epoch: 8, Steps: 124 Train Loss: 3.4836 (Forecasting Loss:0.2893 + XiCon Loss:3.1942 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2755
Validation loss decreased (0.322336 --> 0.322138).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4583139
	speed: 0.0192s/iter; left time: 216.8100s
Epoch: 9 cost time: 2.347717523574829
Epoch: 9, Steps: 124 Train Loss: 3.4680 (Forecasting Loss:0.2892 + XiCon Loss:3.1789 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2750
Validation loss decreased (0.322138 --> 0.322093).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4639554
	speed: 0.0190s/iter; left time: 212.5827s
Epoch: 10 cost time: 2.3293440341949463
Epoch: 10, Steps: 124 Train Loss: 3.4672 (Forecasting Loss:0.2891 + XiCon Loss:3.1781 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2750
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5070000
	speed: 0.0189s/iter; left time: 209.0603s
Epoch: 11 cost time: 2.3405239582061768
Epoch: 11, Steps: 124 Train Loss: 3.4862 (Forecasting Loss:0.2889 + XiCon Loss:3.1973 x Lambda(1.0)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2750
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3763793
	speed: 0.0189s/iter; left time: 206.4181s
Epoch: 12 cost time: 2.3061373233795166
Epoch: 12, Steps: 124 Train Loss: 3.4584 (Forecasting Loss:0.2885 + XiCon Loss:3.1700 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2750
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3651133
	speed: 0.0188s/iter; left time: 203.1868s
Epoch: 13 cost time: 2.3054492473602295
Epoch: 13, Steps: 124 Train Loss: 3.4788 (Forecasting Loss:0.2888 + XiCon Loss:3.1900 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2750
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.7601900
	speed: 0.0191s/iter; left time: 203.6841s
Epoch: 14 cost time: 2.333462715148926
Epoch: 14, Steps: 124 Train Loss: 3.4659 (Forecasting Loss:0.2890 + XiCon Loss:3.1769 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2750
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3433499
	speed: 0.0188s/iter; left time: 198.5711s
Epoch: 15 cost time: 2.329411506652832
Epoch: 15, Steps: 124 Train Loss: 3.4690 (Forecasting Loss:0.2888 + XiCon Loss:3.1802 x Lambda(1.0)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2750
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.5338428
	speed: 0.0191s/iter; left time: 199.1743s
Epoch: 16 cost time: 2.3423471450805664
Epoch: 16, Steps: 124 Train Loss: 3.4704 (Forecasting Loss:0.2889 + XiCon Loss:3.1815 x Lambda(1.0)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2750
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4758151
	speed: 0.0189s/iter; left time: 195.0158s
Epoch: 17 cost time: 2.3120181560516357
Epoch: 17, Steps: 124 Train Loss: 3.4723 (Forecasting Loss:0.2890 + XiCon Loss:3.1832 x Lambda(1.0)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.2750
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3645041
	speed: 0.0187s/iter; left time: 191.0403s
Epoch: 18 cost time: 2.3112614154815674
Epoch: 18, Steps: 124 Train Loss: 3.4807 (Forecasting Loss:0.2890 + XiCon Loss:3.1917 x Lambda(1.0)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2750
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.5922656
	speed: 0.0193s/iter; left time: 194.0857s
Epoch: 19 cost time: 2.3640661239624023
Epoch: 19, Steps: 124 Train Loss: 3.4887 (Forecasting Loss:0.2889 + XiCon Loss:3.1997 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2750
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19473916292190552, mae:0.3552628755569458, mape:0.6737235188484192, mspe:17.97337532043457 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2182
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3484974
	speed: 0.0159s/iter; left time: 195.3123s
Epoch: 1 cost time: 1.9349236488342285
Epoch: 1, Steps: 124 Train Loss: 3.3996 (Forecasting Loss:0.3412 + XiCon Loss:3.0583 x Lambda(1.0)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.2862
Validation loss decreased (inf --> 0.341480).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1169388
	speed: 0.0181s/iter; left time: 220.6041s
Epoch: 2 cost time: 2.2266387939453125
Epoch: 2, Steps: 124 Train Loss: 3.2136 (Forecasting Loss:0.3149 + XiCon Loss:2.8987 x Lambda(1.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2840
Validation loss decreased (0.341480 --> 0.337362).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2581406
	speed: 0.0183s/iter; left time: 220.3921s
Epoch: 3 cost time: 2.242759943008423
Epoch: 3, Steps: 124 Train Loss: 3.1865 (Forecasting Loss:0.3027 + XiCon Loss:2.8838 x Lambda(1.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.2740
Validation loss decreased (0.337362 --> 0.330591).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3054581
	speed: 0.0188s/iter; left time: 223.8138s
Epoch: 4 cost time: 2.283973217010498
Epoch: 4, Steps: 124 Train Loss: 3.3101 (Forecasting Loss:0.2959 + XiCon Loss:3.0142 x Lambda(1.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2794
Validation loss decreased (0.330591 --> 0.322811).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4064853
	speed: 0.0187s/iter; left time: 221.1440s
Epoch: 5 cost time: 2.2914669513702393
Epoch: 5, Steps: 124 Train Loss: 3.3946 (Forecasting Loss:0.2921 + XiCon Loss:3.1025 x Lambda(1.0)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2761
Validation loss decreased (0.322811 --> 0.319756).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3026195
	speed: 0.0183s/iter; left time: 213.9691s
Epoch: 6 cost time: 2.24413800239563
Epoch: 6, Steps: 124 Train Loss: 3.3969 (Forecasting Loss:0.2898 + XiCon Loss:3.1071 x Lambda(1.0)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2787
Validation loss decreased (0.319756 --> 0.319143).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3340819
	speed: 0.0185s/iter; left time: 214.3515s
Epoch: 7 cost time: 2.2646806240081787
Epoch: 7, Steps: 124 Train Loss: 3.4122 (Forecasting Loss:0.2883 + XiCon Loss:3.1239 x Lambda(1.0)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.2788
Validation loss decreased (0.319143 --> 0.317116).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3514068
	speed: 0.0184s/iter; left time: 210.6185s
Epoch: 8 cost time: 2.262148857116699
Epoch: 8, Steps: 124 Train Loss: 3.4002 (Forecasting Loss:0.2877 + XiCon Loss:3.1125 x Lambda(1.0)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2772
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3472285
	speed: 0.0186s/iter; left time: 209.9666s
Epoch: 9 cost time: 2.265660524368286
Epoch: 9, Steps: 124 Train Loss: 3.4115 (Forecasting Loss:0.2875 + XiCon Loss:3.1240 x Lambda(1.0)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.2772
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3978245
	speed: 0.0185s/iter; left time: 206.4842s
Epoch: 10 cost time: 2.2644927501678467
Epoch: 10, Steps: 124 Train Loss: 3.4198 (Forecasting Loss:0.2873 + XiCon Loss:3.1324 x Lambda(1.0)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2777
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2902586
	speed: 0.0183s/iter; left time: 202.9657s
Epoch: 11 cost time: 2.263913154602051
Epoch: 11, Steps: 124 Train Loss: 3.4138 (Forecasting Loss:0.2868 + XiCon Loss:3.1270 x Lambda(1.0)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2776
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5135121
	speed: 0.0181s/iter; left time: 198.1733s
Epoch: 12 cost time: 2.2468581199645996
Epoch: 12, Steps: 124 Train Loss: 3.4078 (Forecasting Loss:0.2870 + XiCon Loss:3.1207 x Lambda(1.0)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2777
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3993275
	speed: 0.0182s/iter; left time: 197.2761s
Epoch: 13 cost time: 2.2596142292022705
Epoch: 13, Steps: 124 Train Loss: 3.4103 (Forecasting Loss:0.2869 + XiCon Loss:3.1234 x Lambda(1.0)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2777
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.6057134
	speed: 0.0185s/iter; left time: 197.8360s
Epoch: 14 cost time: 2.262648344039917
Epoch: 14, Steps: 124 Train Loss: 3.4237 (Forecasting Loss:0.2871 + XiCon Loss:3.1367 x Lambda(1.0)), Vali MSE Loss: 0.3178 Test MSE Loss: 0.2777
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3766689
	speed: 0.0184s/iter; left time: 194.6014s
Epoch: 15 cost time: 2.264024019241333
Epoch: 15, Steps: 124 Train Loss: 3.4194 (Forecasting Loss:0.2870 + XiCon Loss:3.1324 x Lambda(1.0)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2777
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3048542
	speed: 0.0183s/iter; left time: 190.7484s
Epoch: 16 cost time: 2.2343695163726807
Epoch: 16, Steps: 124 Train Loss: 3.4183 (Forecasting Loss:0.2870 + XiCon Loss:3.1314 x Lambda(1.0)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2777
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4538193
	speed: 0.0183s/iter; left time: 189.0632s
Epoch: 17 cost time: 2.2488913536071777
Epoch: 17, Steps: 124 Train Loss: 3.4175 (Forecasting Loss:0.2870 + XiCon Loss:3.1305 x Lambda(1.0)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2777
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19807536900043488, mae:0.3595382571220398, mape:0.6813352704048157, mspe:18.373193740844727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2978
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3467541
	speed: 0.0163s/iter; left time: 200.0873s
Epoch: 1 cost time: 1.9838135242462158
Epoch: 1, Steps: 124 Train Loss: 3.4130 (Forecasting Loss:0.3366 + XiCon Loss:3.0764 x Lambda(1.0)), Vali MSE Loss: 0.3424 Test MSE Loss: 0.2787
Validation loss decreased (inf --> 0.342360).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3485975
	speed: 0.0160s/iter; left time: 195.2188s
Epoch: 2 cost time: 1.9843292236328125
Epoch: 2, Steps: 124 Train Loss: 3.2681 (Forecasting Loss:0.3031 + XiCon Loss:2.9651 x Lambda(1.0)), Vali MSE Loss: 0.3468 Test MSE Loss: 0.2948
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1908736
	speed: 0.0171s/iter; left time: 206.4294s
Epoch: 3 cost time: 2.1059060096740723
Epoch: 3, Steps: 124 Train Loss: 3.2478 (Forecasting Loss:0.2867 + XiCon Loss:2.9612 x Lambda(1.0)), Vali MSE Loss: 0.3145 Test MSE Loss: 0.2674
Validation loss decreased (0.342360 --> 0.314539).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2006950
	speed: 0.0186s/iter; left time: 221.9078s
Epoch: 4 cost time: 2.2853240966796875
Epoch: 4, Steps: 124 Train Loss: 3.2117 (Forecasting Loss:0.2750 + XiCon Loss:2.9367 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2595
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1724055
	speed: 0.0186s/iter; left time: 220.1029s
Epoch: 5 cost time: 2.2806620597839355
Epoch: 5, Steps: 124 Train Loss: 3.1708 (Forecasting Loss:0.2700 + XiCon Loss:2.9008 x Lambda(1.0)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2597
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0777688
	speed: 0.0186s/iter; left time: 216.7653s
Epoch: 6 cost time: 2.280684471130371
Epoch: 6, Steps: 124 Train Loss: 3.1599 (Forecasting Loss:0.2683 + XiCon Loss:2.8916 x Lambda(1.0)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2580
Validation loss decreased (0.314539 --> 0.313131).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1843252
	speed: 0.0188s/iter; left time: 217.1187s
Epoch: 7 cost time: 2.306617259979248
Epoch: 7, Steps: 124 Train Loss: 3.1629 (Forecasting Loss:0.2666 + XiCon Loss:2.8963 x Lambda(1.0)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.2583
Validation loss decreased (0.313131 --> 0.308241).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1423008
	speed: 0.0185s/iter; left time: 211.9856s
Epoch: 8 cost time: 2.2778215408325195
Epoch: 8, Steps: 124 Train Loss: 3.1604 (Forecasting Loss:0.2655 + XiCon Loss:2.8949 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2578
Validation loss decreased (0.308241 --> 0.308035).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1851578
	speed: 0.0189s/iter; left time: 213.7647s
Epoch: 9 cost time: 2.3178038597106934
Epoch: 9, Steps: 124 Train Loss: 3.1621 (Forecasting Loss:0.2654 + XiCon Loss:2.8968 x Lambda(1.0)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2579
Validation loss decreased (0.308035 --> 0.307377).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1491623
	speed: 0.0184s/iter; left time: 206.2908s
Epoch: 10 cost time: 2.267606735229492
Epoch: 10, Steps: 124 Train Loss: 3.1548 (Forecasting Loss:0.2650 + XiCon Loss:2.8898 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2575
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1778817
	speed: 0.0187s/iter; left time: 206.4575s
Epoch: 11 cost time: 2.2905821800231934
Epoch: 11, Steps: 124 Train Loss: 3.1532 (Forecasting Loss:0.2653 + XiCon Loss:2.8879 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2574
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0868487
	speed: 0.0185s/iter; left time: 201.9353s
Epoch: 12 cost time: 2.259815216064453
Epoch: 12, Steps: 124 Train Loss: 3.1651 (Forecasting Loss:0.2648 + XiCon Loss:2.9003 x Lambda(1.0)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2575
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1058054
	speed: 0.0184s/iter; left time: 199.4239s
Epoch: 13 cost time: 2.267874240875244
Epoch: 13, Steps: 124 Train Loss: 3.1560 (Forecasting Loss:0.2652 + XiCon Loss:2.8908 x Lambda(1.0)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.2575
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1310840
	speed: 0.0187s/iter; left time: 200.0576s
Epoch: 14 cost time: 2.2874057292938232
Epoch: 14, Steps: 124 Train Loss: 3.1566 (Forecasting Loss:0.2650 + XiCon Loss:2.8917 x Lambda(1.0)), Vali MSE Loss: 0.3084 Test MSE Loss: 0.2575
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1910856
	speed: 0.0183s/iter; left time: 193.5593s
Epoch: 15 cost time: 2.250591516494751
Epoch: 15, Steps: 124 Train Loss: 3.1562 (Forecasting Loss:0.2649 + XiCon Loss:2.8913 x Lambda(1.0)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2575
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3085346
	speed: 0.0187s/iter; left time: 195.1060s
Epoch: 16 cost time: 2.28464674949646
Epoch: 16, Steps: 124 Train Loss: 3.1604 (Forecasting Loss:0.2652 + XiCon Loss:2.8952 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2575
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1756241
	speed: 0.0191s/iter; left time: 197.0496s
Epoch: 17 cost time: 2.324798345565796
Epoch: 17, Steps: 124 Train Loss: 3.1522 (Forecasting Loss:0.2651 + XiCon Loss:2.8871 x Lambda(1.0)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.2575
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1897786
	speed: 0.0187s/iter; left time: 190.1634s
Epoch: 18 cost time: 2.2803752422332764
Epoch: 18, Steps: 124 Train Loss: 3.1517 (Forecasting Loss:0.2649 + XiCon Loss:2.8867 x Lambda(1.0)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2575
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0860422
	speed: 0.0185s/iter; left time: 186.5757s
Epoch: 19 cost time: 2.2841861248016357
Epoch: 19, Steps: 124 Train Loss: 3.1550 (Forecasting Loss:0.2653 + XiCon Loss:2.8897 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2575
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.17863717675209045, mae:0.3371516168117523, mape:0.6830539107322693, mspe:18.865768432617188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2960
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4332702
	speed: 0.0164s/iter; left time: 201.4833s
Epoch: 1 cost time: 1.986144781112671
Epoch: 1, Steps: 124 Train Loss: 3.4273 (Forecasting Loss:0.3399 + XiCon Loss:3.0874 x Lambda(1.0)), Vali MSE Loss: 0.3398 Test MSE Loss: 0.2818
Validation loss decreased (inf --> 0.339850).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1398153
	speed: 0.0184s/iter; left time: 223.8615s
Epoch: 2 cost time: 2.246661424636841
Epoch: 2, Steps: 124 Train Loss: 3.2196 (Forecasting Loss:0.3166 + XiCon Loss:2.9030 x Lambda(1.0)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2901
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3135695
	speed: 0.0187s/iter; left time: 225.4860s
Epoch: 3 cost time: 2.303163766860962
Epoch: 3, Steps: 124 Train Loss: 3.2772 (Forecasting Loss:0.3017 + XiCon Loss:2.9755 x Lambda(1.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2780
Validation loss decreased (0.339850 --> 0.336531).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4808674
	speed: 0.0189s/iter; left time: 225.1395s
Epoch: 4 cost time: 2.3288161754608154
Epoch: 4, Steps: 124 Train Loss: 3.3736 (Forecasting Loss:0.2938 + XiCon Loss:3.0798 x Lambda(1.0)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.2773
Validation loss decreased (0.336531 --> 0.327336).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3566103
	speed: 0.0188s/iter; left time: 221.7756s
Epoch: 5 cost time: 2.3021836280822754
Epoch: 5, Steps: 124 Train Loss: 3.3815 (Forecasting Loss:0.2899 + XiCon Loss:3.0916 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2780
Validation loss decreased (0.327336 --> 0.322179).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3651123
	speed: 0.0192s/iter; left time: 223.7899s
Epoch: 6 cost time: 2.349985122680664
Epoch: 6, Steps: 124 Train Loss: 3.3754 (Forecasting Loss:0.2875 + XiCon Loss:3.0878 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2731
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2734475
	speed: 0.0190s/iter; left time: 219.6944s
Epoch: 7 cost time: 2.339625358581543
Epoch: 7, Steps: 124 Train Loss: 3.3634 (Forecasting Loss:0.2860 + XiCon Loss:3.0774 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2732
Validation loss decreased (0.322179 --> 0.321913).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3728530
	speed: 0.0189s/iter; left time: 216.5465s
Epoch: 8 cost time: 2.326514959335327
Epoch: 8, Steps: 124 Train Loss: 3.3510 (Forecasting Loss:0.2853 + XiCon Loss:3.0656 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2733
Validation loss decreased (0.321913 --> 0.320760).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3308640
	speed: 0.0188s/iter; left time: 212.4102s
Epoch: 9 cost time: 2.3008158206939697
Epoch: 9, Steps: 124 Train Loss: 3.3571 (Forecasting Loss:0.2849 + XiCon Loss:3.0722 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4220986
	speed: 0.0192s/iter; left time: 214.2469s
Epoch: 10 cost time: 2.3336985111236572
Epoch: 10, Steps: 124 Train Loss: 3.3612 (Forecasting Loss:0.2847 + XiCon Loss:3.0765 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2738
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4030018
	speed: 0.0188s/iter; left time: 207.4180s
Epoch: 11 cost time: 2.3074309825897217
Epoch: 11, Steps: 124 Train Loss: 3.3573 (Forecasting Loss:0.2846 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2739
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5004761
	speed: 0.0190s/iter; left time: 208.1684s
Epoch: 12 cost time: 2.3369147777557373
Epoch: 12, Steps: 124 Train Loss: 3.3690 (Forecasting Loss:0.2844 + XiCon Loss:3.0846 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2740
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2564929
	speed: 0.0192s/iter; left time: 207.0893s
Epoch: 13 cost time: 2.3602161407470703
Epoch: 13, Steps: 124 Train Loss: 3.3610 (Forecasting Loss:0.2844 + XiCon Loss:3.0766 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2740
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2708685
	speed: 0.0189s/iter; left time: 201.7404s
Epoch: 14 cost time: 2.315615177154541
Epoch: 14, Steps: 124 Train Loss: 3.3654 (Forecasting Loss:0.2843 + XiCon Loss:3.0811 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2740
Validation loss decreased (0.320760 --> 0.320744).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4076791
	speed: 0.0189s/iter; left time: 199.1799s
Epoch: 15 cost time: 2.316316604614258
Epoch: 15, Steps: 124 Train Loss: 3.3782 (Forecasting Loss:0.2845 + XiCon Loss:3.0938 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2740
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4545138
	speed: 0.0189s/iter; left time: 197.5962s
Epoch: 16 cost time: 2.3176076412200928
Epoch: 16, Steps: 124 Train Loss: 3.3615 (Forecasting Loss:0.2843 + XiCon Loss:3.0772 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2740
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3044665
	speed: 0.0186s/iter; left time: 191.9754s
Epoch: 17 cost time: 2.2977893352508545
Epoch: 17, Steps: 124 Train Loss: 3.3579 (Forecasting Loss:0.2844 + XiCon Loss:3.0735 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2740
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3913388
	speed: 0.0189s/iter; left time: 193.1242s
Epoch: 18 cost time: 2.324859142303467
Epoch: 18, Steps: 124 Train Loss: 3.3659 (Forecasting Loss:0.2846 + XiCon Loss:3.0813 x Lambda(1.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2740
Validation loss decreased (0.320744 --> 0.320459).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3170767
	speed: 0.0187s/iter; left time: 187.7933s
Epoch: 19 cost time: 2.2885401248931885
Epoch: 19, Steps: 124 Train Loss: 3.3473 (Forecasting Loss:0.2845 + XiCon Loss:3.0628 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2740
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4744992
	speed: 0.0189s/iter; left time: 187.5521s
Epoch: 20 cost time: 2.3201990127563477
Epoch: 20, Steps: 124 Train Loss: 3.3619 (Forecasting Loss:0.2845 + XiCon Loss:3.0774 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2740
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3345149
	speed: 0.0189s/iter; left time: 186.0787s
Epoch: 21 cost time: 2.322964668273926
Epoch: 21, Steps: 124 Train Loss: 3.3628 (Forecasting Loss:0.2845 + XiCon Loss:3.0783 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2740
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3243253
	speed: 0.0192s/iter; left time: 185.7786s
Epoch: 22 cost time: 2.3460118770599365
Epoch: 22, Steps: 124 Train Loss: 3.3759 (Forecasting Loss:0.2842 + XiCon Loss:3.0917 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2740
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2519665
	speed: 0.0187s/iter; left time: 179.3443s
Epoch: 23 cost time: 2.2990734577178955
Epoch: 23, Steps: 124 Train Loss: 3.3514 (Forecasting Loss:0.2842 + XiCon Loss:3.0673 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2740
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4512939
	speed: 0.0191s/iter; left time: 180.3675s
Epoch: 24 cost time: 2.346165418624878
Epoch: 24, Steps: 124 Train Loss: 3.3619 (Forecasting Loss:0.2845 + XiCon Loss:3.0774 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2740
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3167925
	speed: 0.0190s/iter; left time: 177.2314s
Epoch: 25 cost time: 2.35304594039917
Epoch: 25, Steps: 124 Train Loss: 3.3552 (Forecasting Loss:0.2842 + XiCon Loss:3.0711 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2740
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3426609
	speed: 0.0186s/iter; left time: 170.9468s
Epoch: 26 cost time: 2.282212257385254
Epoch: 26, Steps: 124 Train Loss: 3.3729 (Forecasting Loss:0.2845 + XiCon Loss:3.0884 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2740
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3311589
	speed: 0.0191s/iter; left time: 172.9200s
Epoch: 27 cost time: 2.342325448989868
Epoch: 27, Steps: 124 Train Loss: 3.3728 (Forecasting Loss:0.2843 + XiCon Loss:3.0885 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2740
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.3464563
	speed: 0.0187s/iter; left time: 167.3392s
Epoch: 28 cost time: 2.3072047233581543
Epoch: 28, Steps: 124 Train Loss: 3.3712 (Forecasting Loss:0.2845 + XiCon Loss:3.0868 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19400650262832642, mae:0.35394787788391113, mape:0.6672393679618835, mspe:17.957521438598633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1905+-0.00962, MAE:0.3509+-0.01072, MAPE:0.6775+-0.00852, MSPE:18.3257+-0.46925, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2292
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4554065
	speed: 0.0191s/iter; left time: 223.2506s
Epoch: 1 cost time: 2.1836929321289062
Epoch: 1, Steps: 118 Train Loss: 0.4767 (Forecasting Loss:0.4736 + XiCon Loss:3.1504 x Lambda(0.001)), Vali MSE Loss: 0.4757 Test MSE Loss: 0.3612
Validation loss decreased (inf --> 0.475684).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3712719
	speed: 0.0163s/iter; left time: 188.2381s
Epoch: 2 cost time: 1.9093549251556396
Epoch: 2, Steps: 118 Train Loss: 0.3498 (Forecasting Loss:0.3466 + XiCon Loss:3.1494 x Lambda(0.001)), Vali MSE Loss: 0.3779 Test MSE Loss: 0.2872
Validation loss decreased (0.475684 --> 0.377945).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3064533
	speed: 0.0161s/iter; left time: 184.6518s
Epoch: 3 cost time: 1.8900604248046875
Epoch: 3, Steps: 118 Train Loss: 0.3136 (Forecasting Loss:0.3104 + XiCon Loss:3.1476 x Lambda(0.001)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.2778
Validation loss decreased (0.377945 --> 0.373654).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3192958
	speed: 0.0161s/iter; left time: 182.9608s
Epoch: 4 cost time: 1.8961567878723145
Epoch: 4, Steps: 118 Train Loss: 0.3087 (Forecasting Loss:0.3056 + XiCon Loss:3.1442 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2798
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3113033
	speed: 0.0163s/iter; left time: 183.2003s
Epoch: 5 cost time: 1.9157042503356934
Epoch: 5, Steps: 118 Train Loss: 0.3066 (Forecasting Loss:0.3034 + XiCon Loss:3.1429 x Lambda(0.001)), Vali MSE Loss: 0.3832 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2907208
	speed: 0.0163s/iter; left time: 181.5785s
Epoch: 6 cost time: 1.91831374168396
Epoch: 6, Steps: 118 Train Loss: 0.3055 (Forecasting Loss:0.3023 + XiCon Loss:3.1451 x Lambda(0.001)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.2802
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3088580
	speed: 0.0166s/iter; left time: 182.6149s
Epoch: 7 cost time: 1.9388253688812256
Epoch: 7, Steps: 118 Train Loss: 0.3056 (Forecasting Loss:0.3025 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2805
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2895610
	speed: 0.0162s/iter; left time: 176.0518s
Epoch: 8 cost time: 1.9006571769714355
Epoch: 8, Steps: 118 Train Loss: 0.3046 (Forecasting Loss:0.3015 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.3755 Test MSE Loss: 0.2807
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3028466
	speed: 0.0163s/iter; left time: 175.2412s
Epoch: 9 cost time: 1.908935308456421
Epoch: 9, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.1447 x Lambda(0.001)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.2808
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3064212
	speed: 0.0162s/iter; left time: 172.6578s
Epoch: 10 cost time: 1.9027841091156006
Epoch: 10, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.1450 x Lambda(0.001)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.2808
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2957939
	speed: 0.0162s/iter; left time: 170.2349s
Epoch: 11 cost time: 1.899034023284912
Epoch: 11, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.1453 x Lambda(0.001)), Vali MSE Loss: 0.3765 Test MSE Loss: 0.2808
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3164936
	speed: 0.0166s/iter; left time: 172.7615s
Epoch: 12 cost time: 1.9443726539611816
Epoch: 12, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.1465 x Lambda(0.001)), Vali MSE Loss: 0.3770 Test MSE Loss: 0.2808
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2932847
	speed: 0.0162s/iter; left time: 166.4063s
Epoch: 13 cost time: 1.8974671363830566
Epoch: 13, Steps: 118 Train Loss: 0.3046 (Forecasting Loss:0.3014 + XiCon Loss:3.1432 x Lambda(0.001)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2808
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19793018698692322, mae:0.3575896620750427, mape:0.6932328939437866, mspe:23.380695343017578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1621
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4365933
	speed: 0.0165s/iter; left time: 193.1178s
Epoch: 1 cost time: 1.931699514389038
Epoch: 1, Steps: 118 Train Loss: 0.4717 (Forecasting Loss:0.4685 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.4889 Test MSE Loss: 0.3764
Validation loss decreased (inf --> 0.488925).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3001640
	speed: 0.0160s/iter; left time: 185.3054s
Epoch: 2 cost time: 1.8795392513275146
Epoch: 2, Steps: 118 Train Loss: 0.3484 (Forecasting Loss:0.3453 + XiCon Loss:3.1622 x Lambda(0.001)), Vali MSE Loss: 0.3578 Test MSE Loss: 0.2695
Validation loss decreased (0.488925 --> 0.357847).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2869016
	speed: 0.0166s/iter; left time: 190.4327s
Epoch: 3 cost time: 1.9537513256072998
Epoch: 3, Steps: 118 Train Loss: 0.2813 (Forecasting Loss:0.2782 + XiCon Loss:3.1625 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2673
Validation loss decreased (0.357847 --> 0.315686).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2612309
	speed: 0.0170s/iter; left time: 192.7392s
Epoch: 4 cost time: 1.99332857131958
Epoch: 4, Steps: 118 Train Loss: 0.2714 (Forecasting Loss:0.2682 + XiCon Loss:3.1564 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2658
Validation loss decreased (0.315686 --> 0.311976).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2670114
	speed: 0.0171s/iter; left time: 191.8775s
Epoch: 5 cost time: 2.0062737464904785
Epoch: 5, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2652 + XiCon Loss:3.1518 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2559895
	speed: 0.0174s/iter; left time: 193.7898s
Epoch: 6 cost time: 2.0348548889160156
Epoch: 6, Steps: 118 Train Loss: 0.2668 (Forecasting Loss:0.2637 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2678
Validation loss decreased (0.311976 --> 0.311326).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2712138
	speed: 0.0172s/iter; left time: 189.2858s
Epoch: 7 cost time: 2.018339157104492
Epoch: 7, Steps: 118 Train Loss: 0.2661 (Forecasting Loss:0.2629 + XiCon Loss:3.1481 x Lambda(0.001)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2566861
	speed: 0.0170s/iter; left time: 184.4131s
Epoch: 8 cost time: 1.9909498691558838
Epoch: 8, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1482 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2516561
	speed: 0.0169s/iter; left time: 182.2229s
Epoch: 9 cost time: 2.009091854095459
Epoch: 9, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2626 + XiCon Loss:3.1480 x Lambda(0.001)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2676
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2709888
	speed: 0.0170s/iter; left time: 180.8970s
Epoch: 10 cost time: 2.0031445026397705
Epoch: 10, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1470 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2758244
	speed: 0.0173s/iter; left time: 181.9044s
Epoch: 11 cost time: 2.035429000854492
Epoch: 11, Steps: 118 Train Loss: 0.2654 (Forecasting Loss:0.2623 + XiCon Loss:3.1477 x Lambda(0.001)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2581069
	speed: 0.0174s/iter; left time: 180.5133s
Epoch: 12 cost time: 2.0296471118927
Epoch: 12, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1493 x Lambda(0.001)), Vali MSE Loss: 0.3137 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2824812
	speed: 0.0171s/iter; left time: 176.0858s
Epoch: 13 cost time: 2.006640672683716
Epoch: 13, Steps: 118 Train Loss: 0.2653 (Forecasting Loss:0.2622 + XiCon Loss:3.1487 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.2680
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2551371
	speed: 0.0173s/iter; left time: 175.9266s
Epoch: 14 cost time: 2.0255184173583984
Epoch: 14, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1476 x Lambda(0.001)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.2680
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2687675
	speed: 0.0171s/iter; left time: 171.4496s
Epoch: 15 cost time: 2.0002121925354004
Epoch: 15, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2623 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2608389
	speed: 0.0171s/iter; left time: 169.4648s
Epoch: 16 cost time: 2.0042037963867188
Epoch: 16, Steps: 118 Train Loss: 0.2652 (Forecasting Loss:0.2621 + XiCon Loss:3.1475 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.186106339097023, mae:0.3495650291442871, mape:0.673611581325531, mspe:18.201919555664062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1697
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4507805
	speed: 0.0166s/iter; left time: 194.0957s
Epoch: 1 cost time: 1.9421238899230957
Epoch: 1, Steps: 118 Train Loss: 0.4724 (Forecasting Loss:0.4693 + XiCon Loss:3.1462 x Lambda(0.001)), Vali MSE Loss: 0.4768 Test MSE Loss: 0.3596
Validation loss decreased (inf --> 0.476795).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.2846947
	speed: 0.0168s/iter; left time: 195.1114s
Epoch: 2 cost time: 1.9989302158355713
Epoch: 2, Steps: 118 Train Loss: 0.3436 (Forecasting Loss:0.3404 + XiCon Loss:3.1175 x Lambda(0.001)), Vali MSE Loss: 0.3618 Test MSE Loss: 0.2610
Validation loss decreased (0.476795 --> 0.361822).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2800852
	speed: 0.0180s/iter; left time: 206.0511s
Epoch: 3 cost time: 2.1133944988250732
Epoch: 3, Steps: 118 Train Loss: 0.2830 (Forecasting Loss:0.2799 + XiCon Loss:3.0888 x Lambda(0.001)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2590
Validation loss decreased (0.361822 --> 0.338566).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2749482
	speed: 0.0180s/iter; left time: 204.6885s
Epoch: 4 cost time: 2.1160876750946045
Epoch: 4, Steps: 118 Train Loss: 0.2753 (Forecasting Loss:0.2722 + XiCon Loss:3.0826 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2585
Validation loss decreased (0.338566 --> 0.318332).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2665918
	speed: 0.0181s/iter; left time: 203.1155s
Epoch: 5 cost time: 2.121328353881836
Epoch: 5, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.0781 x Lambda(0.001)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.2578
Validation loss decreased (0.318332 --> 0.314897).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2838763
	speed: 0.0182s/iter; left time: 202.6094s
Epoch: 6 cost time: 2.1429572105407715
Epoch: 6, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2673 + XiCon Loss:3.0759 x Lambda(0.001)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.2593
Validation loss decreased (0.314897 --> 0.313394).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2653636
	speed: 0.0184s/iter; left time: 202.1112s
Epoch: 7 cost time: 2.1606788635253906
Epoch: 7, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2665 + XiCon Loss:3.0756 x Lambda(0.001)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2586
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2600767
	speed: 0.0181s/iter; left time: 197.1873s
Epoch: 8 cost time: 2.136347770690918
Epoch: 8, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2661 + XiCon Loss:3.0728 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2757599
	speed: 0.0185s/iter; left time: 198.8840s
Epoch: 9 cost time: 2.165435791015625
Epoch: 9, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2662 + XiCon Loss:3.0741 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2676319
	speed: 0.0183s/iter; left time: 195.1140s
Epoch: 10 cost time: 2.16009259223938
Epoch: 10, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2658 + XiCon Loss:3.0739 x Lambda(0.001)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2594
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2744607
	speed: 0.0180s/iter; left time: 189.6936s
Epoch: 11 cost time: 2.1172924041748047
Epoch: 11, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2660 + XiCon Loss:3.0730 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2594
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2780262
	speed: 0.0185s/iter; left time: 192.5091s
Epoch: 12 cost time: 2.1669423580169678
Epoch: 12, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2657 + XiCon Loss:3.0713 x Lambda(0.001)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2594
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3100964
	speed: 0.0186s/iter; left time: 191.1586s
Epoch: 13 cost time: 2.1730055809020996
Epoch: 13, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2659 + XiCon Loss:3.0729 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2594
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2490344
	speed: 0.0183s/iter; left time: 185.6876s
Epoch: 14 cost time: 2.148318290710449
Epoch: 14, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0735 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2732110
	speed: 0.0182s/iter; left time: 182.7566s
Epoch: 15 cost time: 2.135542154312134
Epoch: 15, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0747 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2890850
	speed: 0.0183s/iter; left time: 181.6596s
Epoch: 16 cost time: 2.1531896591186523
Epoch: 16, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0744 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17643308639526367, mae:0.3420862555503845, mape:0.6958782076835632, mspe:21.348548889160156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2933
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4674888
	speed: 0.0170s/iter; left time: 198.4527s
Epoch: 1 cost time: 1.970900297164917
Epoch: 1, Steps: 118 Train Loss: 0.4995 (Forecasting Loss:0.4964 + XiCon Loss:3.1492 x Lambda(0.001)), Vali MSE Loss: 0.5422 Test MSE Loss: 0.4452
Validation loss decreased (inf --> 0.542249).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3096410
	speed: 0.0164s/iter; left time: 189.6683s
Epoch: 2 cost time: 1.9224767684936523
Epoch: 2, Steps: 118 Train Loss: 0.3703 (Forecasting Loss:0.3671 + XiCon Loss:3.1499 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2744
Validation loss decreased (0.542249 --> 0.358910).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2780795
	speed: 0.0171s/iter; left time: 195.5957s
Epoch: 3 cost time: 2.007054090499878
Epoch: 3, Steps: 118 Train Loss: 0.2913 (Forecasting Loss:0.2882 + XiCon Loss:3.1609 x Lambda(0.001)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2682
Validation loss decreased (0.358910 --> 0.326726).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2773184
	speed: 0.0174s/iter; left time: 197.2902s
Epoch: 4 cost time: 2.044689655303955
Epoch: 4, Steps: 118 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.1638 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2660
Validation loss decreased (0.326726 --> 0.322232).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2734490
	speed: 0.0178s/iter; left time: 199.3319s
Epoch: 5 cost time: 2.0921578407287598
Epoch: 5, Steps: 118 Train Loss: 0.2715 (Forecasting Loss:0.2683 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.3174 Test MSE Loss: 0.2655
Validation loss decreased (0.322232 --> 0.317378).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2611406
	speed: 0.0182s/iter; left time: 201.9677s
Epoch: 6 cost time: 2.1374094486236572
Epoch: 6, Steps: 118 Train Loss: 0.2699 (Forecasting Loss:0.2667 + XiCon Loss:3.1579 x Lambda(0.001)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2836238
	speed: 0.0177s/iter; left time: 194.6337s
Epoch: 7 cost time: 2.080564022064209
Epoch: 7, Steps: 118 Train Loss: 0.2686 (Forecasting Loss:0.2655 + XiCon Loss:3.1599 x Lambda(0.001)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2651
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2594900
	speed: 0.0178s/iter; left time: 193.1127s
Epoch: 8 cost time: 2.114487648010254
Epoch: 8, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2651 + XiCon Loss:3.1600 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2582530
	speed: 0.0178s/iter; left time: 191.0603s
Epoch: 9 cost time: 2.083129405975342
Epoch: 9, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2648 + XiCon Loss:3.1585 x Lambda(0.001)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2525958
	speed: 0.0178s/iter; left time: 189.0436s
Epoch: 10 cost time: 2.0979301929473877
Epoch: 10, Steps: 118 Train Loss: 0.2678 (Forecasting Loss:0.2646 + XiCon Loss:3.1591 x Lambda(0.001)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2807139
	speed: 0.0178s/iter; left time: 187.2894s
Epoch: 11 cost time: 2.0954363346099854
Epoch: 11, Steps: 118 Train Loss: 0.2677 (Forecasting Loss:0.2645 + XiCon Loss:3.1570 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2637899
	speed: 0.0181s/iter; left time: 188.1101s
Epoch: 12 cost time: 2.1157236099243164
Epoch: 12, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2649 + XiCon Loss:3.1576 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2652280
	speed: 0.0182s/iter; left time: 186.7443s
Epoch: 13 cost time: 2.1250855922698975
Epoch: 13, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2647 + XiCon Loss:3.1572 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2664699
	speed: 0.0179s/iter; left time: 182.0749s
Epoch: 14 cost time: 2.099118232727051
Epoch: 14, Steps: 118 Train Loss: 0.2681 (Forecasting Loss:0.2650 + XiCon Loss:3.1566 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2561430
	speed: 0.0180s/iter; left time: 180.7768s
Epoch: 15 cost time: 2.112459182739258
Epoch: 15, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2648 + XiCon Loss:3.1596 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18284472823143005, mae:0.34813326597213745, mape:0.7116711735725403, mspe:20.312747955322266 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2942
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4438057
	speed: 0.0164s/iter; left time: 192.0351s
Epoch: 1 cost time: 1.920400857925415
Epoch: 1, Steps: 118 Train Loss: 0.4780 (Forecasting Loss:0.4748 + XiCon Loss:3.1799 x Lambda(0.001)), Vali MSE Loss: 0.5074 Test MSE Loss: 0.4006
Validation loss decreased (inf --> 0.507354).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3169235
	speed: 0.0163s/iter; left time: 188.5751s
Epoch: 2 cost time: 1.907562017440796
Epoch: 2, Steps: 118 Train Loss: 0.3506 (Forecasting Loss:0.3475 + XiCon Loss:3.1635 x Lambda(0.001)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.2702
Validation loss decreased (0.507354 --> 0.351474).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2703553
	speed: 0.0164s/iter; left time: 187.8037s
Epoch: 3 cost time: 1.915548324584961
Epoch: 3, Steps: 118 Train Loss: 0.2854 (Forecasting Loss:0.2822 + XiCon Loss:3.1208 x Lambda(0.001)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2723
Validation loss decreased (0.351474 --> 0.327559).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2672114
	speed: 0.0162s/iter; left time: 183.2778s
Epoch: 4 cost time: 1.895113468170166
Epoch: 4, Steps: 118 Train Loss: 0.2774 (Forecasting Loss:0.2743 + XiCon Loss:3.1168 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2662
Validation loss decreased (0.327559 --> 0.319456).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2879466
	speed: 0.0161s/iter; left time: 181.2508s
Epoch: 5 cost time: 1.8922092914581299
Epoch: 5, Steps: 118 Train Loss: 0.2744 (Forecasting Loss:0.2713 + XiCon Loss:3.1155 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.2611
Validation loss decreased (0.319456 --> 0.317553).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2724700
	speed: 0.0168s/iter; left time: 186.8337s
Epoch: 6 cost time: 1.9744038581848145
Epoch: 6, Steps: 118 Train Loss: 0.2734 (Forecasting Loss:0.2703 + XiCon Loss:3.1161 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2617
Validation loss decreased (0.317553 --> 0.316888).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2807165
	speed: 0.0161s/iter; left time: 177.0056s
Epoch: 7 cost time: 1.8893492221832275
Epoch: 7, Steps: 118 Train Loss: 0.2726 (Forecasting Loss:0.2694 + XiCon Loss:3.1147 x Lambda(0.001)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2604
Validation loss decreased (0.316888 --> 0.316681).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2458611
	speed: 0.0165s/iter; left time: 179.2266s
Epoch: 8 cost time: 1.929121494293213
Epoch: 8, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1145 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2596
Validation loss decreased (0.316681 --> 0.315233).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2666706
	speed: 0.0169s/iter; left time: 182.0645s
Epoch: 9 cost time: 1.9750683307647705
Epoch: 9, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1144 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2599
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2874802
	speed: 0.0164s/iter; left time: 174.4794s
Epoch: 10 cost time: 1.9192936420440674
Epoch: 10, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1159 x Lambda(0.001)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2599
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2521876
	speed: 0.0163s/iter; left time: 171.0170s
Epoch: 11 cost time: 1.904313087463379
Epoch: 11, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2690 + XiCon Loss:3.1159 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2598
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2675732
	speed: 0.0165s/iter; left time: 171.2208s
Epoch: 12 cost time: 1.925612449645996
Epoch: 12, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.1147 x Lambda(0.001)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2598
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2423994
	speed: 0.0163s/iter; left time: 167.7193s
Epoch: 13 cost time: 1.905541181564331
Epoch: 13, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.1154 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2774286
	speed: 0.0166s/iter; left time: 168.6776s
Epoch: 14 cost time: 1.934072494506836
Epoch: 14, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.1130 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2598
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2705583
	speed: 0.0163s/iter; left time: 164.0797s
Epoch: 15 cost time: 1.9120428562164307
Epoch: 15, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1161 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.2598
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2600012
	speed: 0.0162s/iter; left time: 161.3593s
Epoch: 16 cost time: 1.9009320735931396
Epoch: 16, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1145 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2598
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2623484
	speed: 0.0161s/iter; left time: 158.2121s
Epoch: 17 cost time: 1.8936645984649658
Epoch: 17, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1172 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2893267
	speed: 0.0160s/iter; left time: 155.3545s
Epoch: 18 cost time: 1.882565975189209
Epoch: 18, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1142 x Lambda(0.001)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.2598
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17702047526836395, mae:0.3422480523586273, mape:0.7658507823944092, mspe:23.963350296020508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1841+-0.01086, MAE:0.3479+-0.00791, MAPE:0.7080+-0.04349, MSPE:21.4415+-2.90519, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.1395
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3712201
	speed: 0.0409s/iter; left time: 1083.5313s
	iters: 200, epoch: 1 | loss: 3.2986884
	speed: 0.0354s/iter; left time: 933.8782s
Epoch: 1 cost time: 9.95863652229309
Epoch: 1, Steps: 266 Train Loss: 3.3805 (Forecasting Loss:0.1679 + XiCon Loss:3.2126 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0793
Validation loss decreased (inf --> 0.115218).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3640749
	speed: 0.0374s/iter; left time: 982.1892s
	iters: 200, epoch: 2 | loss: 3.3553953
	speed: 0.0358s/iter; left time: 935.3101s
Epoch: 2 cost time: 9.714325666427612
Epoch: 2, Steps: 266 Train Loss: 3.3412 (Forecasting Loss:0.1505 + XiCon Loss:3.1907 x Lambda(1.0)), Vali MSE Loss: 0.1118 Test MSE Loss: 0.0761
Validation loss decreased (0.115218 --> 0.111771).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1592753
	speed: 0.0377s/iter; left time: 980.1554s
	iters: 200, epoch: 3 | loss: 3.0979905
	speed: 0.0369s/iter; left time: 955.4255s
Epoch: 3 cost time: 9.852113008499146
Epoch: 3, Steps: 266 Train Loss: 3.1774 (Forecasting Loss:0.1452 + XiCon Loss:3.0323 x Lambda(1.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.0761
Validation loss decreased (0.111771 --> 0.109819).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1148767
	speed: 0.0387s/iter; left time: 993.6603s
	iters: 200, epoch: 4 | loss: 3.1137486
	speed: 0.0355s/iter; left time: 907.8476s
Epoch: 4 cost time: 9.812512159347534
Epoch: 4, Steps: 266 Train Loss: 3.1602 (Forecasting Loss:0.1433 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0749
Validation loss decreased (0.109819 --> 0.108613).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1308188
	speed: 0.0377s/iter; left time: 959.2334s
	iters: 200, epoch: 5 | loss: 3.1581948
	speed: 0.0360s/iter; left time: 912.6546s
Epoch: 5 cost time: 9.765233039855957
Epoch: 5, Steps: 266 Train Loss: 3.1537 (Forecasting Loss:0.1425 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0744
Validation loss decreased (0.108613 --> 0.107791).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1336739
	speed: 0.0383s/iter; left time: 963.2257s
	iters: 200, epoch: 6 | loss: 3.1166737
	speed: 0.0358s/iter; left time: 896.8859s
Epoch: 6 cost time: 9.756888389587402
Epoch: 6, Steps: 266 Train Loss: 3.1467 (Forecasting Loss:0.1421 + XiCon Loss:3.0046 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0742
Validation loss decreased (0.107791 --> 0.107753).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0783255
	speed: 0.0386s/iter; left time: 960.1951s
	iters: 200, epoch: 7 | loss: 3.1117311
	speed: 0.0358s/iter; left time: 887.3220s
Epoch: 7 cost time: 9.786345720291138
Epoch: 7, Steps: 266 Train Loss: 3.1423 (Forecasting Loss:0.1418 + XiCon Loss:3.0005 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
Validation loss decreased (0.107753 --> 0.107523).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2057257
	speed: 0.0377s/iter; left time: 927.6882s
	iters: 200, epoch: 8 | loss: 3.1213598
	speed: 0.0366s/iter; left time: 897.2427s
Epoch: 8 cost time: 9.767627716064453
Epoch: 8, Steps: 266 Train Loss: 3.1445 (Forecasting Loss:0.1416 + XiCon Loss:3.0028 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1053843
	speed: 0.0386s/iter; left time: 941.7306s
	iters: 200, epoch: 9 | loss: 3.1172395
	speed: 0.0364s/iter; left time: 884.6522s
Epoch: 9 cost time: 9.942138195037842
Epoch: 9, Steps: 266 Train Loss: 3.1423 (Forecasting Loss:0.1416 + XiCon Loss:3.0007 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0972383
	speed: 0.0385s/iter; left time: 928.2860s
	iters: 200, epoch: 10 | loss: 3.1632979
	speed: 0.0362s/iter; left time: 868.6299s
Epoch: 10 cost time: 9.863430738449097
Epoch: 10, Steps: 266 Train Loss: 3.1440 (Forecasting Loss:0.1416 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1719816
	speed: 0.0378s/iter; left time: 901.7467s
	iters: 200, epoch: 11 | loss: 3.1716089
	speed: 0.0360s/iter; left time: 855.8328s
Epoch: 11 cost time: 9.73472809791565
Epoch: 11, Steps: 266 Train Loss: 3.1375 (Forecasting Loss:0.1415 + XiCon Loss:2.9960 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0818217
	speed: 0.0370s/iter; left time: 872.3288s
	iters: 200, epoch: 12 | loss: 3.1574800
	speed: 0.0355s/iter; left time: 834.0654s
Epoch: 12 cost time: 9.679604768753052
Epoch: 12, Steps: 266 Train Loss: 3.1429 (Forecasting Loss:0.1415 + XiCon Loss:3.0014 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107523 --> 0.107511).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1324296
	speed: 0.0376s/iter; left time: 876.3860s
	iters: 200, epoch: 13 | loss: 3.1831372
	speed: 0.0373s/iter; left time: 865.1050s
Epoch: 13 cost time: 9.918036222457886
Epoch: 13, Steps: 266 Train Loss: 3.1455 (Forecasting Loss:0.1415 + XiCon Loss:3.0040 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.0778499
	speed: 0.0405s/iter; left time: 933.8064s
	iters: 200, epoch: 14 | loss: 3.1915998
	speed: 0.0347s/iter; left time: 796.5735s
Epoch: 14 cost time: 10.016139030456543
Epoch: 14, Steps: 266 Train Loss: 3.1399 (Forecasting Loss:0.1415 + XiCon Loss:2.9984 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107511 --> 0.107456).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2072847
	speed: 0.0385s/iter; left time: 876.8459s
	iters: 200, epoch: 15 | loss: 3.0437005
	speed: 0.0351s/iter; left time: 797.0077s
Epoch: 15 cost time: 9.71073317527771
Epoch: 15, Steps: 266 Train Loss: 3.1412 (Forecasting Loss:0.1415 + XiCon Loss:2.9997 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1754658
	speed: 0.0377s/iter; left time: 847.6966s
	iters: 200, epoch: 16 | loss: 3.1939254
	speed: 0.0357s/iter; left time: 799.1492s
Epoch: 16 cost time: 9.727885484695435
Epoch: 16, Steps: 266 Train Loss: 3.1397 (Forecasting Loss:0.1415 + XiCon Loss:2.9982 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1236305
	speed: 0.0378s/iter; left time: 840.3555s
	iters: 200, epoch: 17 | loss: 3.1601739
	speed: 0.0365s/iter; left time: 809.3930s
Epoch: 17 cost time: 9.7857506275177
Epoch: 17, Steps: 266 Train Loss: 3.1400 (Forecasting Loss:0.1415 + XiCon Loss:2.9985 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1684067
	speed: 0.0378s/iter; left time: 829.8730s
	iters: 200, epoch: 18 | loss: 3.1142981
	speed: 0.0359s/iter; left time: 785.0715s
Epoch: 18 cost time: 9.739063024520874
Epoch: 18, Steps: 266 Train Loss: 3.1378 (Forecasting Loss:0.1415 + XiCon Loss:2.9963 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1929653
	speed: 0.0374s/iter; left time: 812.3350s
	iters: 200, epoch: 19 | loss: 3.0663443
	speed: 0.0359s/iter; left time: 776.4558s
Epoch: 19 cost time: 9.698437690734863
Epoch: 19, Steps: 266 Train Loss: 3.1405 (Forecasting Loss:0.1415 + XiCon Loss:2.9990 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1067793
	speed: 0.0380s/iter; left time: 815.9868s
	iters: 200, epoch: 20 | loss: 3.0887511
	speed: 0.0362s/iter; left time: 773.3662s
Epoch: 20 cost time: 9.885623931884766
Epoch: 20, Steps: 266 Train Loss: 3.1396 (Forecasting Loss:0.1414 + XiCon Loss:2.9982 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1149073
	speed: 0.0386s/iter; left time: 817.3662s
	iters: 200, epoch: 21 | loss: 3.1484699
	speed: 0.0365s/iter; left time: 770.3828s
Epoch: 21 cost time: 9.876455545425415
Epoch: 21, Steps: 266 Train Loss: 3.1397 (Forecasting Loss:0.1415 + XiCon Loss:2.9982 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2951846
	speed: 0.0376s/iter; left time: 786.7979s
	iters: 200, epoch: 22 | loss: 3.1749845
	speed: 0.0362s/iter; left time: 753.1584s
Epoch: 22 cost time: 9.7964026927948
Epoch: 22, Steps: 266 Train Loss: 3.1421 (Forecasting Loss:0.1415 + XiCon Loss:3.0006 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107456 --> 0.107438).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.0521581
	speed: 0.0382s/iter; left time: 788.4221s
	iters: 200, epoch: 23 | loss: 3.1543522
	speed: 0.0354s/iter; left time: 726.6802s
Epoch: 23 cost time: 9.724483013153076
Epoch: 23, Steps: 266 Train Loss: 3.1440 (Forecasting Loss:0.1415 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1499560
	speed: 0.0380s/iter; left time: 773.9713s
	iters: 200, epoch: 24 | loss: 3.1360960
	speed: 0.0354s/iter; left time: 718.6788s
Epoch: 24 cost time: 9.774120569229126
Epoch: 24, Steps: 266 Train Loss: 3.1397 (Forecasting Loss:0.1415 + XiCon Loss:2.9982 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1832340
	speed: 0.0381s/iter; left time: 766.6761s
	iters: 200, epoch: 25 | loss: 3.0588775
	speed: 0.0355s/iter; left time: 711.1391s
Epoch: 25 cost time: 9.711398124694824
Epoch: 25, Steps: 266 Train Loss: 3.1425 (Forecasting Loss:0.1415 + XiCon Loss:3.0011 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1095519
	speed: 0.0381s/iter; left time: 756.1683s
	iters: 200, epoch: 26 | loss: 3.1441042
	speed: 0.0361s/iter; left time: 713.6507s
Epoch: 26 cost time: 9.843084812164307
Epoch: 26, Steps: 266 Train Loss: 3.1417 (Forecasting Loss:0.1415 + XiCon Loss:3.0002 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1979785
	speed: 0.0378s/iter; left time: 740.8366s
	iters: 200, epoch: 27 | loss: 3.0730264
	speed: 0.0360s/iter; left time: 702.2118s
Epoch: 27 cost time: 9.795823335647583
Epoch: 27, Steps: 266 Train Loss: 3.1418 (Forecasting Loss:0.1415 + XiCon Loss:3.0003 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.0704901
	speed: 0.0376s/iter; left time: 725.6658s
	iters: 200, epoch: 28 | loss: 3.1571352
	speed: 0.0357s/iter; left time: 686.9510s
Epoch: 28 cost time: 9.72989535331726
Epoch: 28, Steps: 266 Train Loss: 3.1374 (Forecasting Loss:0.1415 + XiCon Loss:2.9959 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1294360
	speed: 0.0385s/iter; left time: 733.3193s
	iters: 200, epoch: 29 | loss: 3.2106841
	speed: 0.0361s/iter; left time: 684.5613s
Epoch: 29 cost time: 9.834726333618164
Epoch: 29, Steps: 266 Train Loss: 3.1419 (Forecasting Loss:0.1415 + XiCon Loss:3.0004 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.1783462
	speed: 0.0375s/iter; left time: 704.9538s
	iters: 200, epoch: 30 | loss: 3.0965929
	speed: 0.0353s/iter; left time: 659.9562s
Epoch: 30 cost time: 9.572435855865479
Epoch: 30, Steps: 266 Train Loss: 3.1438 (Forecasting Loss:0.1415 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1234560
	speed: 0.0381s/iter; left time: 704.9964s
	iters: 200, epoch: 31 | loss: 3.1521797
	speed: 0.0360s/iter; left time: 663.5365s
Epoch: 31 cost time: 9.805479764938354
Epoch: 31, Steps: 266 Train Loss: 3.1433 (Forecasting Loss:0.1415 + XiCon Loss:3.0018 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1381330
	speed: 0.0382s/iter; left time: 697.0654s
	iters: 200, epoch: 32 | loss: 3.2534676
	speed: 0.0368s/iter; left time: 667.4626s
Epoch: 32 cost time: 9.939256191253662
Epoch: 32, Steps: 266 Train Loss: 3.1405 (Forecasting Loss:0.1415 + XiCon Loss:2.9990 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02639099396765232, mae:0.12187593430280685, mape:0.09850121289491653, mspe:0.01960735395550728 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0947
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3686707
	speed: 0.0385s/iter; left time: 1019.4779s
	iters: 200, epoch: 1 | loss: 3.3227804
	speed: 0.0351s/iter; left time: 925.4758s
Epoch: 1 cost time: 9.6745924949646
Epoch: 1, Steps: 266 Train Loss: 3.3896 (Forecasting Loss:0.1670 + XiCon Loss:3.2226 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0778
Validation loss decreased (inf --> 0.115219).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4485679
	speed: 0.0379s/iter; left time: 994.0561s
	iters: 200, epoch: 2 | loss: 3.4428201
	speed: 0.0350s/iter; left time: 914.6923s
Epoch: 2 cost time: 9.647333860397339
Epoch: 2, Steps: 266 Train Loss: 3.4203 (Forecasting Loss:0.1504 + XiCon Loss:3.2699 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.0762
Validation loss decreased (0.115219 --> 0.111037).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3069806
	speed: 0.0382s/iter; left time: 991.5021s
	iters: 200, epoch: 3 | loss: 3.1885440
	speed: 0.0362s/iter; left time: 937.1019s
Epoch: 3 cost time: 9.780366897583008
Epoch: 3, Steps: 266 Train Loss: 3.2576 (Forecasting Loss:0.1454 + XiCon Loss:3.1122 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.0752
Validation loss decreased (0.111037 --> 0.108818).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4087758
	speed: 0.0378s/iter; left time: 970.3215s
	iters: 200, epoch: 4 | loss: 3.1834106
	speed: 0.0353s/iter; left time: 903.6771s
Epoch: 4 cost time: 9.682245969772339
Epoch: 4, Steps: 266 Train Loss: 3.2315 (Forecasting Loss:0.1433 + XiCon Loss:3.0882 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0749
Validation loss decreased (0.108818 --> 0.108379).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1882510
	speed: 0.0387s/iter; left time: 984.1201s
	iters: 200, epoch: 5 | loss: 3.2819297
	speed: 0.0358s/iter; left time: 907.3469s
Epoch: 5 cost time: 9.819054126739502
Epoch: 5, Steps: 266 Train Loss: 3.2197 (Forecasting Loss:0.1426 + XiCon Loss:3.0771 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0747
Validation loss decreased (0.108379 --> 0.107974).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1664469
	speed: 0.0377s/iter; left time: 948.8980s
	iters: 200, epoch: 6 | loss: 3.2602367
	speed: 0.0357s/iter; left time: 894.9749s
Epoch: 6 cost time: 9.685672283172607
Epoch: 6, Steps: 266 Train Loss: 3.2113 (Forecasting Loss:0.1421 + XiCon Loss:3.0692 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0743
Validation loss decreased (0.107974 --> 0.107770).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3378789
	speed: 0.0375s/iter; left time: 932.7604s
	iters: 200, epoch: 7 | loss: 3.2181463
	speed: 0.0352s/iter; left time: 872.8205s
Epoch: 7 cost time: 9.629156351089478
Epoch: 7, Steps: 266 Train Loss: 3.2084 (Forecasting Loss:0.1418 + XiCon Loss:3.0666 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107770 --> 0.107484).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1996169
	speed: 0.0385s/iter; left time: 948.7796s
	iters: 200, epoch: 8 | loss: 3.1509063
	speed: 0.0349s/iter; left time: 856.5812s
Epoch: 8 cost time: 9.590570449829102
Epoch: 8, Steps: 266 Train Loss: 3.2004 (Forecasting Loss:0.1417 + XiCon Loss:3.0587 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107484 --> 0.107464).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2016432
	speed: 0.0373s/iter; left time: 908.4332s
	iters: 200, epoch: 9 | loss: 3.2799003
	speed: 0.0351s/iter; left time: 851.5532s
Epoch: 9 cost time: 9.602257251739502
Epoch: 9, Steps: 266 Train Loss: 3.2008 (Forecasting Loss:0.1416 + XiCon Loss:3.0592 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1645646
	speed: 0.0381s/iter; left time: 918.8280s
	iters: 200, epoch: 10 | loss: 3.2145112
	speed: 0.0356s/iter; left time: 853.9685s
Epoch: 10 cost time: 9.72623610496521
Epoch: 10, Steps: 266 Train Loss: 3.2046 (Forecasting Loss:0.1416 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107464 --> 0.107452).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2317076
	speed: 0.0379s/iter; left time: 902.4161s
	iters: 200, epoch: 11 | loss: 3.1827583
	speed: 0.0356s/iter; left time: 845.9837s
Epoch: 11 cost time: 9.724859476089478
Epoch: 11, Steps: 266 Train Loss: 3.1998 (Forecasting Loss:0.1416 + XiCon Loss:3.0583 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107452 --> 0.107414).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2343674
	speed: 0.0384s/iter; left time: 906.3912s
	iters: 200, epoch: 12 | loss: 3.2978995
	speed: 0.0353s/iter; left time: 827.6026s
Epoch: 12 cost time: 9.737557172775269
Epoch: 12, Steps: 266 Train Loss: 3.2020 (Forecasting Loss:0.1415 + XiCon Loss:3.0605 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107414 --> 0.107410).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1394947
	speed: 0.0376s/iter; left time: 876.6443s
	iters: 200, epoch: 13 | loss: 3.1745720
	speed: 0.0363s/iter; left time: 841.9010s
Epoch: 13 cost time: 9.828050374984741
Epoch: 13, Steps: 266 Train Loss: 3.2067 (Forecasting Loss:0.1415 + XiCon Loss:3.0651 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107410 --> 0.107402).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2446358
	speed: 0.0380s/iter; left time: 875.9313s
	iters: 200, epoch: 14 | loss: 3.1965075
	speed: 0.0347s/iter; left time: 797.2651s
Epoch: 14 cost time: 9.614417791366577
Epoch: 14, Steps: 266 Train Loss: 3.2051 (Forecasting Loss:0.1415 + XiCon Loss:3.0636 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2257013
	speed: 0.0376s/iter; left time: 857.0885s
	iters: 200, epoch: 15 | loss: 3.1570697
	speed: 0.0358s/iter; left time: 812.9421s
Epoch: 15 cost time: 9.703002214431763
Epoch: 15, Steps: 266 Train Loss: 3.2045 (Forecasting Loss:0.1416 + XiCon Loss:3.0629 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1262736
	speed: 0.0386s/iter; left time: 868.3337s
	iters: 200, epoch: 16 | loss: 3.1647739
	speed: 0.0349s/iter; left time: 782.8139s
Epoch: 16 cost time: 9.693024396896362
Epoch: 16, Steps: 266 Train Loss: 3.1958 (Forecasting Loss:0.1415 + XiCon Loss:3.0543 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1579370
	speed: 0.0378s/iter; left time: 839.7587s
	iters: 200, epoch: 17 | loss: 3.2750583
	speed: 0.0353s/iter; left time: 782.1561s
Epoch: 17 cost time: 9.660337448120117
Epoch: 17, Steps: 266 Train Loss: 3.2053 (Forecasting Loss:0.1416 + XiCon Loss:3.0638 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107402 --> 0.107389).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2075896
	speed: 0.0378s/iter; left time: 830.2869s
	iters: 200, epoch: 18 | loss: 3.1280184
	speed: 0.0356s/iter; left time: 779.0693s
Epoch: 18 cost time: 9.75061845779419
Epoch: 18, Steps: 266 Train Loss: 3.2010 (Forecasting Loss:0.1416 + XiCon Loss:3.0595 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107389 --> 0.107331).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2046809
	speed: 0.0374s/iter; left time: 812.1645s
	iters: 200, epoch: 19 | loss: 3.2219820
	speed: 0.0355s/iter; left time: 766.5900s
Epoch: 19 cost time: 9.692943334579468
Epoch: 19, Steps: 266 Train Loss: 3.2088 (Forecasting Loss:0.1415 + XiCon Loss:3.0673 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2502260
	speed: 0.0378s/iter; left time: 811.0119s
	iters: 200, epoch: 20 | loss: 3.3058946
	speed: 0.0355s/iter; left time: 757.2842s
Epoch: 20 cost time: 9.659116983413696
Epoch: 20, Steps: 266 Train Loss: 3.2052 (Forecasting Loss:0.1415 + XiCon Loss:3.0637 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107331 --> 0.107320).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1445374
	speed: 0.0380s/iter; left time: 804.3769s
	iters: 200, epoch: 21 | loss: 3.2426057
	speed: 0.0356s/iter; left time: 751.5260s
Epoch: 21 cost time: 9.684406280517578
Epoch: 21, Steps: 266 Train Loss: 3.2093 (Forecasting Loss:0.1416 + XiCon Loss:3.0677 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2252986
	speed: 0.0373s/iter; left time: 779.0915s
	iters: 200, epoch: 22 | loss: 3.2005708
	speed: 0.0350s/iter; left time: 728.1802s
Epoch: 22 cost time: 9.631403923034668
Epoch: 22, Steps: 266 Train Loss: 3.2034 (Forecasting Loss:0.1415 + XiCon Loss:3.0619 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1718907
	speed: 0.0374s/iter; left time: 772.9083s
	iters: 200, epoch: 23 | loss: 3.2252340
	speed: 0.0357s/iter; left time: 734.1448s
Epoch: 23 cost time: 9.696019649505615
Epoch: 23, Steps: 266 Train Loss: 3.2065 (Forecasting Loss:0.1415 + XiCon Loss:3.0650 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1285954
	speed: 0.0387s/iter; left time: 788.5673s
	iters: 200, epoch: 24 | loss: 3.3358412
	speed: 0.0358s/iter; left time: 726.3074s
Epoch: 24 cost time: 9.81547737121582
Epoch: 24, Steps: 266 Train Loss: 3.2060 (Forecasting Loss:0.1416 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1557591
	speed: 0.0376s/iter; left time: 756.1291s
	iters: 200, epoch: 25 | loss: 3.1850128
	speed: 0.0354s/iter; left time: 708.7712s
Epoch: 25 cost time: 9.671946048736572
Epoch: 25, Steps: 266 Train Loss: 3.1998 (Forecasting Loss:0.1416 + XiCon Loss:3.0582 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1396620
	speed: 0.0373s/iter; left time: 739.6707s
	iters: 200, epoch: 26 | loss: 3.1527236
	speed: 0.0361s/iter; left time: 713.6849s
Epoch: 26 cost time: 9.696872472763062
Epoch: 26, Steps: 266 Train Loss: 3.2033 (Forecasting Loss:0.1415 + XiCon Loss:3.0618 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2981079
	speed: 0.0376s/iter; left time: 736.9061s
	iters: 200, epoch: 27 | loss: 3.1082318
	speed: 0.0351s/iter; left time: 683.0022s
Epoch: 27 cost time: 9.655874729156494
Epoch: 27, Steps: 266 Train Loss: 3.2041 (Forecasting Loss:0.1415 + XiCon Loss:3.0626 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1920085
	speed: 0.0375s/iter; left time: 725.2890s
	iters: 200, epoch: 28 | loss: 3.1454778
	speed: 0.0352s/iter; left time: 676.2124s
Epoch: 28 cost time: 9.663801670074463
Epoch: 28, Steps: 266 Train Loss: 3.2000 (Forecasting Loss:0.1415 + XiCon Loss:3.0585 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1602426
	speed: 0.0381s/iter; left time: 725.8973s
	iters: 200, epoch: 29 | loss: 3.2018936
	speed: 0.0354s/iter; left time: 671.1056s
Epoch: 29 cost time: 9.690305709838867
Epoch: 29, Steps: 266 Train Loss: 3.2012 (Forecasting Loss:0.1415 + XiCon Loss:3.0597 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.1654279
	speed: 0.0380s/iter; left time: 713.4956s
	iters: 200, epoch: 30 | loss: 3.2516885
	speed: 0.0359s/iter; left time: 670.7873s
Epoch: 30 cost time: 9.81166934967041
Epoch: 30, Steps: 266 Train Loss: 3.2020 (Forecasting Loss:0.1416 + XiCon Loss:3.0604 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026372838765382767, mae:0.1218016967177391, mape:0.09840521216392517, mspe:0.019571876153349876 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9197
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3537221
	speed: 0.0377s/iter; left time: 1000.1774s
	iters: 200, epoch: 1 | loss: 3.3026032
	speed: 0.0351s/iter; left time: 927.1748s
Epoch: 1 cost time: 9.679567575454712
Epoch: 1, Steps: 266 Train Loss: 3.3584 (Forecasting Loss:0.1687 + XiCon Loss:3.1897 x Lambda(1.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.0808
Validation loss decreased (inf --> 0.117922).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5939667
	speed: 0.0375s/iter; left time: 983.9662s
	iters: 200, epoch: 2 | loss: 3.5220246
	speed: 0.0372s/iter; left time: 971.4545s
Epoch: 2 cost time: 9.857877254486084
Epoch: 2, Steps: 266 Train Loss: 3.5292 (Forecasting Loss:0.1509 + XiCon Loss:3.3784 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.0789
Validation loss decreased (0.117922 --> 0.113621).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3532696
	speed: 0.0388s/iter; left time: 1008.6321s
	iters: 200, epoch: 3 | loss: 3.2250652
	speed: 0.0371s/iter; left time: 958.5222s
Epoch: 3 cost time: 9.959006309509277
Epoch: 3, Steps: 266 Train Loss: 3.4001 (Forecasting Loss:0.1456 + XiCon Loss:3.2545 x Lambda(1.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.0753
Validation loss decreased (0.113621 --> 0.109820).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2019489
	speed: 0.0386s/iter; left time: 992.9810s
	iters: 200, epoch: 4 | loss: 3.4657698
	speed: 0.0361s/iter; left time: 923.8532s
Epoch: 4 cost time: 9.869481563568115
Epoch: 4, Steps: 266 Train Loss: 3.3528 (Forecasting Loss:0.1436 + XiCon Loss:3.2092 x Lambda(1.0)), Vali MSE Loss: 0.1085 Test MSE Loss: 0.0750
Validation loss decreased (0.109820 --> 0.108515).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2780294
	speed: 0.0376s/iter; left time: 957.3955s
	iters: 200, epoch: 5 | loss: 3.4147732
	speed: 0.0365s/iter; left time: 925.0086s
Epoch: 5 cost time: 9.78954529762268
Epoch: 5, Steps: 266 Train Loss: 3.3312 (Forecasting Loss:0.1425 + XiCon Loss:3.1887 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0746
Validation loss decreased (0.108515 --> 0.108097).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3382115
	speed: 0.0384s/iter; left time: 966.3519s
	iters: 200, epoch: 6 | loss: 3.1621094
	speed: 0.0363s/iter; left time: 910.1964s
Epoch: 6 cost time: 9.877493143081665
Epoch: 6, Steps: 266 Train Loss: 3.3310 (Forecasting Loss:0.1421 + XiCon Loss:3.1889 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
Validation loss decreased (0.108097 --> 0.107608).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2582469
	speed: 0.0390s/iter; left time: 970.5828s
	iters: 200, epoch: 7 | loss: 3.3580351
	speed: 0.0357s/iter; left time: 886.2299s
Epoch: 7 cost time: 9.883423805236816
Epoch: 7, Steps: 266 Train Loss: 3.3175 (Forecasting Loss:0.1417 + XiCon Loss:3.1758 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0743
Validation loss decreased (0.107608 --> 0.107581).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3499374
	speed: 0.0384s/iter; left time: 946.0047s
	iters: 200, epoch: 8 | loss: 3.2402852
	speed: 0.0360s/iter; left time: 882.8170s
Epoch: 8 cost time: 9.806481838226318
Epoch: 8, Steps: 266 Train Loss: 3.3110 (Forecasting Loss:0.1415 + XiCon Loss:3.1695 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107581 --> 0.107431).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2267785
	speed: 0.0377s/iter; left time: 918.8993s
	iters: 200, epoch: 9 | loss: 3.2934518
	speed: 0.0361s/iter; left time: 876.7874s
Epoch: 9 cost time: 9.865403890609741
Epoch: 9, Steps: 266 Train Loss: 3.3085 (Forecasting Loss:0.1415 + XiCon Loss:3.1670 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2272484
	speed: 0.0383s/iter; left time: 922.8069s
	iters: 200, epoch: 10 | loss: 3.2969134
	speed: 0.0359s/iter; left time: 862.5863s
Epoch: 10 cost time: 9.775708675384521
Epoch: 10, Steps: 266 Train Loss: 3.3196 (Forecasting Loss:0.1414 + XiCon Loss:3.1782 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107431 --> 0.107416).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2094352
	speed: 0.0382s/iter; left time: 911.3322s
	iters: 200, epoch: 11 | loss: 3.4171393
	speed: 0.0361s/iter; left time: 857.9396s
Epoch: 11 cost time: 9.828288555145264
Epoch: 11, Steps: 266 Train Loss: 3.3172 (Forecasting Loss:0.1414 + XiCon Loss:3.1758 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3725688
	speed: 0.0385s/iter; left time: 906.5663s
	iters: 200, epoch: 12 | loss: 3.3617356
	speed: 0.0368s/iter; left time: 864.0615s
Epoch: 12 cost time: 9.975036859512329
Epoch: 12, Steps: 266 Train Loss: 3.3139 (Forecasting Loss:0.1414 + XiCon Loss:3.1725 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3132713
	speed: 0.0381s/iter; left time: 886.9240s
	iters: 200, epoch: 13 | loss: 3.3231261
	speed: 0.0364s/iter; left time: 844.1188s
Epoch: 13 cost time: 9.937658071517944
Epoch: 13, Steps: 266 Train Loss: 3.3156 (Forecasting Loss:0.1414 + XiCon Loss:3.1742 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3800430
	speed: 0.0386s/iter; left time: 888.5994s
	iters: 200, epoch: 14 | loss: 3.3961077
	speed: 0.0361s/iter; left time: 827.3679s
Epoch: 14 cost time: 9.94776701927185
Epoch: 14, Steps: 266 Train Loss: 3.3107 (Forecasting Loss:0.1414 + XiCon Loss:3.1693 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1860027
	speed: 0.0390s/iter; left time: 887.5336s
	iters: 200, epoch: 15 | loss: 3.1868858
	speed: 0.0365s/iter; left time: 826.9622s
Epoch: 15 cost time: 9.983544111251831
Epoch: 15, Steps: 266 Train Loss: 3.3036 (Forecasting Loss:0.1413 + XiCon Loss:3.1623 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1611078
	speed: 0.0383s/iter; left time: 862.2259s
	iters: 200, epoch: 16 | loss: 3.3769803
	speed: 0.0362s/iter; left time: 811.4414s
Epoch: 16 cost time: 9.8962562084198
Epoch: 16, Steps: 266 Train Loss: 3.3143 (Forecasting Loss:0.1414 + XiCon Loss:3.1729 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2491398
	speed: 0.0387s/iter; left time: 861.0403s
	iters: 200, epoch: 17 | loss: 3.1828446
	speed: 0.0363s/iter; left time: 803.7216s
Epoch: 17 cost time: 9.906525611877441
Epoch: 17, Steps: 266 Train Loss: 3.3177 (Forecasting Loss:0.1413 + XiCon Loss:3.1764 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
Validation loss decreased (0.107416 --> 0.107399).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3684421
	speed: 0.0391s/iter; left time: 859.6097s
	iters: 200, epoch: 18 | loss: 3.2142653
	speed: 0.0365s/iter; left time: 798.1158s
Epoch: 18 cost time: 9.914697408676147
Epoch: 18, Steps: 266 Train Loss: 3.3091 (Forecasting Loss:0.1413 + XiCon Loss:3.1678 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2272966
	speed: 0.0389s/iter; left time: 843.6634s
	iters: 200, epoch: 19 | loss: 3.2881613
	speed: 0.0359s/iter; left time: 776.1408s
Epoch: 19 cost time: 9.908074140548706
Epoch: 19, Steps: 266 Train Loss: 3.3132 (Forecasting Loss:0.1413 + XiCon Loss:3.1719 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3561208
	speed: 0.0385s/iter; left time: 826.2868s
	iters: 200, epoch: 20 | loss: 3.2806447
	speed: 0.0360s/iter; left time: 769.4567s
Epoch: 20 cost time: 9.919991493225098
Epoch: 20, Steps: 266 Train Loss: 3.3114 (Forecasting Loss:0.1414 + XiCon Loss:3.1700 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4840200
	speed: 0.0382s/iter; left time: 809.3525s
	iters: 200, epoch: 21 | loss: 3.3707500
	speed: 0.0368s/iter; left time: 775.8152s
Epoch: 21 cost time: 9.919464111328125
Epoch: 21, Steps: 266 Train Loss: 3.3127 (Forecasting Loss:0.1414 + XiCon Loss:3.1713 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3182826
	speed: 0.0386s/iter; left time: 807.4890s
	iters: 200, epoch: 22 | loss: 3.2739868
	speed: 0.0360s/iter; left time: 749.4621s
Epoch: 22 cost time: 9.876073837280273
Epoch: 22, Steps: 266 Train Loss: 3.3102 (Forecasting Loss:0.1413 + XiCon Loss:3.1689 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2568059
	speed: 0.0389s/iter; left time: 803.7166s
	iters: 200, epoch: 23 | loss: 3.2104537
	speed: 0.0364s/iter; left time: 748.3782s
Epoch: 23 cost time: 9.945765733718872
Epoch: 23, Steps: 266 Train Loss: 3.3168 (Forecasting Loss:0.1414 + XiCon Loss:3.1754 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1997995
	speed: 0.0389s/iter; left time: 792.5262s
	iters: 200, epoch: 24 | loss: 3.3637822
	speed: 0.0363s/iter; left time: 737.1401s
Epoch: 24 cost time: 9.927358865737915
Epoch: 24, Steps: 266 Train Loss: 3.3152 (Forecasting Loss:0.1413 + XiCon Loss:3.1739 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0743
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2912378
	speed: 0.0379s/iter; left time: 762.7788s
	iters: 200, epoch: 25 | loss: 3.2313988
	speed: 0.0366s/iter; left time: 732.4792s
Epoch: 25 cost time: 9.875390529632568
Epoch: 25, Steps: 266 Train Loss: 3.3106 (Forecasting Loss:0.1414 + XiCon Loss:3.1693 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.4065390
	speed: 0.0382s/iter; left time: 758.0981s
	iters: 200, epoch: 26 | loss: 3.2800736
	speed: 0.0366s/iter; left time: 722.8472s
Epoch: 26 cost time: 9.87313437461853
Epoch: 26, Steps: 266 Train Loss: 3.3070 (Forecasting Loss:0.1414 + XiCon Loss:3.1657 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3933711
	speed: 0.0383s/iter; left time: 749.8552s
	iters: 200, epoch: 27 | loss: 3.1582816
	speed: 0.0371s/iter; left time: 723.6759s
Epoch: 27 cost time: 9.943330526351929
Epoch: 27, Steps: 266 Train Loss: 3.3128 (Forecasting Loss:0.1413 + XiCon Loss:3.1714 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02652621828019619, mae:0.12208282947540283, mape:0.09874387085437775, mspe:0.019933195784687996 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.3329
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4339643
	speed: 0.0389s/iter; left time: 1030.5137s
	iters: 200, epoch: 1 | loss: 3.2768934
	speed: 0.0351s/iter; left time: 926.9881s
Epoch: 1 cost time: 9.691307306289673
Epoch: 1, Steps: 266 Train Loss: 3.3874 (Forecasting Loss:0.1668 + XiCon Loss:3.2206 x Lambda(1.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.0787
Validation loss decreased (inf --> 0.113976).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6370232
	speed: 0.0379s/iter; left time: 994.9868s
	iters: 200, epoch: 2 | loss: 3.3883374
	speed: 0.0352s/iter; left time: 920.6340s
Epoch: 2 cost time: 9.727862358093262
Epoch: 2, Steps: 266 Train Loss: 3.4970 (Forecasting Loss:0.1508 + XiCon Loss:3.3461 x Lambda(1.0)), Vali MSE Loss: 0.1104 Test MSE Loss: 0.0766
Validation loss decreased (0.113976 --> 0.110416).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5690186
	speed: 0.0384s/iter; left time: 997.2724s
	iters: 200, epoch: 3 | loss: 3.5383472
	speed: 0.0363s/iter; left time: 937.7651s
Epoch: 3 cost time: 9.85055685043335
Epoch: 3, Steps: 266 Train Loss: 3.4786 (Forecasting Loss:0.1452 + XiCon Loss:3.3333 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.0753
Validation loss decreased (0.110416 --> 0.109094).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4556983
	speed: 0.0378s/iter; left time: 972.1263s
	iters: 200, epoch: 4 | loss: 3.2130971
	speed: 0.0359s/iter; left time: 918.9358s
Epoch: 4 cost time: 9.750847101211548
Epoch: 4, Steps: 266 Train Loss: 3.4040 (Forecasting Loss:0.1436 + XiCon Loss:3.2605 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0748
Validation loss decreased (0.109094 --> 0.108039).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2985480
	speed: 0.0382s/iter; left time: 972.1097s
	iters: 200, epoch: 5 | loss: 3.3335950
	speed: 0.0352s/iter; left time: 891.4292s
Epoch: 5 cost time: 9.638566255569458
Epoch: 5, Steps: 266 Train Loss: 3.3648 (Forecasting Loss:0.1425 + XiCon Loss:3.2223 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0743
Validation loss decreased (0.108039 --> 0.107753).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3544569
	speed: 0.0379s/iter; left time: 954.7942s
	iters: 200, epoch: 6 | loss: 3.3512886
	speed: 0.0358s/iter; left time: 896.4997s
Epoch: 6 cost time: 9.75424599647522
Epoch: 6, Steps: 266 Train Loss: 3.3430 (Forecasting Loss:0.1420 + XiCon Loss:3.2010 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0743
Validation loss decreased (0.107753 --> 0.107616).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5198255
	speed: 0.0385s/iter; left time: 959.0912s
	iters: 200, epoch: 7 | loss: 3.5162988
	speed: 0.0358s/iter; left time: 888.5355s
Epoch: 7 cost time: 9.796369314193726
Epoch: 7, Steps: 266 Train Loss: 3.3406 (Forecasting Loss:0.1418 + XiCon Loss:3.1988 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
Validation loss decreased (0.107616 --> 0.107466).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2100406
	speed: 0.0376s/iter; left time: 926.2841s
	iters: 200, epoch: 8 | loss: 3.2548416
	speed: 0.0363s/iter; left time: 891.1170s
Epoch: 8 cost time: 9.75684666633606
Epoch: 8, Steps: 266 Train Loss: 3.3310 (Forecasting Loss:0.1416 + XiCon Loss:3.1894 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2711987
	speed: 0.0377s/iter; left time: 920.0178s
	iters: 200, epoch: 9 | loss: 3.1941617
	speed: 0.0355s/iter; left time: 861.8334s
Epoch: 9 cost time: 9.701386213302612
Epoch: 9, Steps: 266 Train Loss: 3.3357 (Forecasting Loss:0.1415 + XiCon Loss:3.1942 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2930603
	speed: 0.0376s/iter; left time: 907.4894s
	iters: 200, epoch: 10 | loss: 3.4301748
	speed: 0.0361s/iter; left time: 866.4838s
Epoch: 10 cost time: 9.732742547988892
Epoch: 10, Steps: 266 Train Loss: 3.3378 (Forecasting Loss:0.1415 + XiCon Loss:3.1963 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
Validation loss decreased (0.107466 --> 0.107453).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2783093
	speed: 0.0382s/iter; left time: 911.5130s
	iters: 200, epoch: 11 | loss: 3.3047564
	speed: 0.0365s/iter; left time: 867.4482s
Epoch: 11 cost time: 9.796016693115234
Epoch: 11, Steps: 266 Train Loss: 3.3343 (Forecasting Loss:0.1414 + XiCon Loss:3.1928 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
Validation loss decreased (0.107453 --> 0.107366).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2301841
	speed: 0.0380s/iter; left time: 895.1666s
	iters: 200, epoch: 12 | loss: 3.2762969
	speed: 0.0358s/iter; left time: 839.4342s
Epoch: 12 cost time: 9.734786033630371
Epoch: 12, Steps: 266 Train Loss: 3.3397 (Forecasting Loss:0.1415 + XiCon Loss:3.1982 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3401058
	speed: 0.0382s/iter; left time: 890.2183s
	iters: 200, epoch: 13 | loss: 3.4196031
	speed: 0.0361s/iter; left time: 838.4318s
Epoch: 13 cost time: 9.823126554489136
Epoch: 13, Steps: 266 Train Loss: 3.3379 (Forecasting Loss:0.1415 + XiCon Loss:3.1965 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3077798
	speed: 0.0384s/iter; left time: 885.5474s
	iters: 200, epoch: 14 | loss: 3.3243065
	speed: 0.0351s/iter; left time: 804.5404s
Epoch: 14 cost time: 9.746512413024902
Epoch: 14, Steps: 266 Train Loss: 3.3330 (Forecasting Loss:0.1414 + XiCon Loss:3.1916 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3184371
	speed: 0.0377s/iter; left time: 857.8927s
	iters: 200, epoch: 15 | loss: 3.3750284
	speed: 0.0361s/iter; left time: 818.0180s
Epoch: 15 cost time: 9.74646544456482
Epoch: 15, Steps: 266 Train Loss: 3.3342 (Forecasting Loss:0.1415 + XiCon Loss:3.1928 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4113181
	speed: 0.0385s/iter; left time: 865.8205s
	iters: 200, epoch: 16 | loss: 3.3100922
	speed: 0.0359s/iter; left time: 803.6951s
Epoch: 16 cost time: 9.819549322128296
Epoch: 16, Steps: 266 Train Loss: 3.3370 (Forecasting Loss:0.1414 + XiCon Loss:3.1956 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3756964
	speed: 0.0382s/iter; left time: 849.5731s
	iters: 200, epoch: 17 | loss: 3.2831819
	speed: 0.0348s/iter; left time: 770.5861s
Epoch: 17 cost time: 9.641546249389648
Epoch: 17, Steps: 266 Train Loss: 3.3385 (Forecasting Loss:0.1414 + XiCon Loss:3.1971 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2994065
	speed: 0.0381s/iter; left time: 836.6574s
	iters: 200, epoch: 18 | loss: 3.3136759
	speed: 0.0356s/iter; left time: 779.3232s
Epoch: 18 cost time: 9.746259689331055
Epoch: 18, Steps: 266 Train Loss: 3.3348 (Forecasting Loss:0.1414 + XiCon Loss:3.1934 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3047254
	speed: 0.0385s/iter; left time: 836.3221s
	iters: 200, epoch: 19 | loss: 3.1939156
	speed: 0.0358s/iter; left time: 774.3556s
Epoch: 19 cost time: 9.777240514755249
Epoch: 19, Steps: 266 Train Loss: 3.3351 (Forecasting Loss:0.1415 + XiCon Loss:3.1936 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2340877
	speed: 0.0381s/iter; left time: 817.6864s
	iters: 200, epoch: 20 | loss: 3.3436739
	speed: 0.0352s/iter; left time: 751.9602s
Epoch: 20 cost time: 9.715794563293457
Epoch: 20, Steps: 266 Train Loss: 3.3364 (Forecasting Loss:0.1414 + XiCon Loss:3.1950 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2939160
	speed: 0.0383s/iter; left time: 810.7870s
	iters: 200, epoch: 21 | loss: 3.3655336
	speed: 0.0358s/iter; left time: 754.4789s
Epoch: 21 cost time: 9.73026728630066
Epoch: 21, Steps: 266 Train Loss: 3.3387 (Forecasting Loss:0.1415 + XiCon Loss:3.1973 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026637857779860497, mae:0.12235403060913086, mape:0.09878041595220566, mspe:0.019660983234643936 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4001
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3781595
	speed: 0.0382s/iter; left time: 1011.0545s
	iters: 200, epoch: 1 | loss: 3.2813706
	speed: 0.0348s/iter; left time: 919.9713s
Epoch: 1 cost time: 9.649336099624634
Epoch: 1, Steps: 266 Train Loss: 3.3960 (Forecasting Loss:0.1692 + XiCon Loss:3.2268 x Lambda(1.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.0800
Validation loss decreased (inf --> 0.115636).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6706080
	speed: 0.0389s/iter; left time: 1020.1453s
	iters: 200, epoch: 2 | loss: 3.2093604
	speed: 0.0368s/iter; left time: 961.2607s
Epoch: 2 cost time: 9.911546468734741
Epoch: 2, Steps: 266 Train Loss: 3.4448 (Forecasting Loss:0.1504 + XiCon Loss:3.2943 x Lambda(1.0)), Vali MSE Loss: 0.1115 Test MSE Loss: 0.0762
Validation loss decreased (0.115636 --> 0.111496).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2551475
	speed: 0.0374s/iter; left time: 970.7156s
	iters: 200, epoch: 3 | loss: 3.2699609
	speed: 0.0362s/iter; left time: 935.9808s
Epoch: 3 cost time: 9.779159784317017
Epoch: 3, Steps: 266 Train Loss: 3.2663 (Forecasting Loss:0.1450 + XiCon Loss:3.1212 x Lambda(1.0)), Vali MSE Loss: 0.1101 Test MSE Loss: 0.0755
Validation loss decreased (0.111496 --> 0.110078).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2616992
	speed: 0.0374s/iter; left time: 961.0482s
	iters: 200, epoch: 4 | loss: 3.3491445
	speed: 0.0362s/iter; left time: 927.2889s
Epoch: 4 cost time: 9.713220119476318
Epoch: 4, Steps: 266 Train Loss: 3.2563 (Forecasting Loss:0.1434 + XiCon Loss:3.1129 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0747
Validation loss decreased (0.110078 --> 0.108398).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2212241
	speed: 0.0378s/iter; left time: 962.2431s
	iters: 200, epoch: 5 | loss: 3.2094774
	speed: 0.0351s/iter; left time: 889.6250s
Epoch: 5 cost time: 9.703874349594116
Epoch: 5, Steps: 266 Train Loss: 3.2447 (Forecasting Loss:0.1426 + XiCon Loss:3.1021 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0741
Validation loss decreased (0.108398 --> 0.108114).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3025486
	speed: 0.0383s/iter; left time: 962.8009s
	iters: 200, epoch: 6 | loss: 3.3172498
	speed: 0.0356s/iter; left time: 892.6426s
Epoch: 6 cost time: 9.780399322509766
Epoch: 6, Steps: 266 Train Loss: 3.2407 (Forecasting Loss:0.1419 + XiCon Loss:3.0988 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0742
Validation loss decreased (0.108114 --> 0.107840).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2421989
	speed: 0.0377s/iter; left time: 939.6830s
	iters: 200, epoch: 7 | loss: 3.2296162
	speed: 0.0353s/iter; left time: 876.0319s
Epoch: 7 cost time: 9.675225734710693
Epoch: 7, Steps: 266 Train Loss: 3.2437 (Forecasting Loss:0.1417 + XiCon Loss:3.1020 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0741
Validation loss decreased (0.107840 --> 0.107693).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2895956
	speed: 0.0373s/iter; left time: 918.5131s
	iters: 200, epoch: 8 | loss: 3.1780057
	speed: 0.0361s/iter; left time: 886.5608s
Epoch: 8 cost time: 9.662610292434692
Epoch: 8, Steps: 266 Train Loss: 3.2422 (Forecasting Loss:0.1416 + XiCon Loss:3.1007 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2921557
	speed: 0.0379s/iter; left time: 922.8567s
	iters: 200, epoch: 9 | loss: 3.1749516
	speed: 0.0353s/iter; left time: 857.5965s
Epoch: 9 cost time: 9.692639589309692
Epoch: 9, Steps: 266 Train Loss: 3.2372 (Forecasting Loss:0.1415 + XiCon Loss:3.0956 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0739
Validation loss decreased (0.107693 --> 0.107643).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2023284
	speed: 0.0378s/iter; left time: 910.8081s
	iters: 200, epoch: 10 | loss: 3.2414486
	speed: 0.0349s/iter; left time: 837.2142s
Epoch: 10 cost time: 9.627047538757324
Epoch: 10, Steps: 266 Train Loss: 3.2393 (Forecasting Loss:0.1415 + XiCon Loss:3.0978 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107643 --> 0.107601).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2538118
	speed: 0.0384s/iter; left time: 915.1723s
	iters: 200, epoch: 11 | loss: 3.1993420
	speed: 0.0351s/iter; left time: 834.3238s
Epoch: 11 cost time: 9.717349529266357
Epoch: 11, Steps: 266 Train Loss: 3.2392 (Forecasting Loss:0.1414 + XiCon Loss:3.0977 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107601 --> 0.107590).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2550869
	speed: 0.0380s/iter; left time: 895.3254s
	iters: 200, epoch: 12 | loss: 3.1849661
	speed: 0.0356s/iter; left time: 834.9438s
Epoch: 12 cost time: 9.723696947097778
Epoch: 12, Steps: 266 Train Loss: 3.2339 (Forecasting Loss:0.1414 + XiCon Loss:3.0925 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107590 --> 0.107567).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3286619
	speed: 0.0382s/iter; left time: 890.0938s
	iters: 200, epoch: 13 | loss: 3.1905181
	speed: 0.0358s/iter; left time: 830.8940s
Epoch: 13 cost time: 9.795084238052368
Epoch: 13, Steps: 266 Train Loss: 3.2375 (Forecasting Loss:0.1415 + XiCon Loss:3.0960 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107567 --> 0.107553).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2863860
	speed: 0.0379s/iter; left time: 873.9785s
	iters: 200, epoch: 14 | loss: 3.1820850
	speed: 0.0355s/iter; left time: 813.6571s
Epoch: 14 cost time: 9.745206594467163
Epoch: 14, Steps: 266 Train Loss: 3.2371 (Forecasting Loss:0.1414 + XiCon Loss:3.0956 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2653775
	speed: 0.0382s/iter; left time: 869.8574s
	iters: 200, epoch: 15 | loss: 3.2077799
	speed: 0.0355s/iter; left time: 805.5396s
Epoch: 15 cost time: 9.685837030410767
Epoch: 15, Steps: 266 Train Loss: 3.2379 (Forecasting Loss:0.1415 + XiCon Loss:3.0964 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2865667
	speed: 0.0382s/iter; left time: 860.9467s
	iters: 200, epoch: 16 | loss: 3.1739264
	speed: 0.0359s/iter; left time: 803.7000s
Epoch: 16 cost time: 9.85815167427063
Epoch: 16, Steps: 266 Train Loss: 3.2383 (Forecasting Loss:0.1414 + XiCon Loss:3.0969 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2351334
	speed: 0.0381s/iter; left time: 846.7441s
	iters: 200, epoch: 17 | loss: 3.2374666
	speed: 0.0361s/iter; left time: 798.5151s
Epoch: 17 cost time: 9.88341236114502
Epoch: 17, Steps: 266 Train Loss: 3.2362 (Forecasting Loss:0.1415 + XiCon Loss:3.0947 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1732683
	speed: 0.0385s/iter; left time: 846.7450s
	iters: 200, epoch: 18 | loss: 3.2715840
	speed: 0.0353s/iter; left time: 771.8866s
Epoch: 18 cost time: 9.704017639160156
Epoch: 18, Steps: 266 Train Loss: 3.2336 (Forecasting Loss:0.1415 + XiCon Loss:3.0921 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2712898
	speed: 0.0378s/iter; left time: 820.5374s
	iters: 200, epoch: 19 | loss: 3.2328699
	speed: 0.0355s/iter; left time: 766.8373s
Epoch: 19 cost time: 9.771904945373535
Epoch: 19, Steps: 266 Train Loss: 3.2360 (Forecasting Loss:0.1415 + XiCon Loss:3.0945 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107553 --> 0.107519).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2021732
	speed: 0.0372s/iter; left time: 797.6579s
	iters: 200, epoch: 20 | loss: 3.1869640
	speed: 0.0344s/iter; left time: 734.6462s
Epoch: 20 cost time: 9.492064952850342
Epoch: 20, Steps: 266 Train Loss: 3.2407 (Forecasting Loss:0.1415 + XiCon Loss:3.0992 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2106662
	speed: 0.0394s/iter; left time: 834.0121s
	iters: 200, epoch: 21 | loss: 3.1713419
	speed: 0.0357s/iter; left time: 751.7849s
Epoch: 21 cost time: 9.914196014404297
Epoch: 21, Steps: 266 Train Loss: 3.2396 (Forecasting Loss:0.1415 + XiCon Loss:3.0981 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1976385
	speed: 0.0379s/iter; left time: 792.7242s
	iters: 200, epoch: 22 | loss: 3.2264633
	speed: 0.0361s/iter; left time: 752.2825s
Epoch: 22 cost time: 9.788397789001465
Epoch: 22, Steps: 266 Train Loss: 3.2381 (Forecasting Loss:0.1414 + XiCon Loss:3.0967 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1969855
	speed: 0.0384s/iter; left time: 792.6921s
	iters: 200, epoch: 23 | loss: 3.1887362
	speed: 0.0352s/iter; left time: 723.7285s
Epoch: 23 cost time: 9.777577877044678
Epoch: 23, Steps: 266 Train Loss: 3.2366 (Forecasting Loss:0.1415 + XiCon Loss:3.0951 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2785168
	speed: 0.0391s/iter; left time: 797.4885s
	iters: 200, epoch: 24 | loss: 3.2139297
	speed: 0.0359s/iter; left time: 728.1698s
Epoch: 24 cost time: 9.901032447814941
Epoch: 24, Steps: 266 Train Loss: 3.2359 (Forecasting Loss:0.1415 + XiCon Loss:3.0944 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1581903
	speed: 0.0372s/iter; left time: 748.2657s
	iters: 200, epoch: 25 | loss: 3.1973855
	speed: 0.0352s/iter; left time: 704.6105s
Epoch: 25 cost time: 9.52597713470459
Epoch: 25, Steps: 266 Train Loss: 3.2366 (Forecasting Loss:0.1415 + XiCon Loss:3.0951 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3752007
	speed: 0.0371s/iter; left time: 736.4948s
	iters: 200, epoch: 26 | loss: 3.2142618
	speed: 0.0356s/iter; left time: 702.4414s
Epoch: 26 cost time: 9.607835054397583
Epoch: 26, Steps: 266 Train Loss: 3.2383 (Forecasting Loss:0.1415 + XiCon Loss:3.0968 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1966288
	speed: 0.0382s/iter; left time: 748.6541s
	iters: 200, epoch: 27 | loss: 3.1727591
	speed: 0.0353s/iter; left time: 687.7496s
Epoch: 27 cost time: 9.679925680160522
Epoch: 27, Steps: 266 Train Loss: 3.2427 (Forecasting Loss:0.1415 + XiCon Loss:3.1012 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2963097
	speed: 0.0375s/iter; left time: 724.8214s
	iters: 200, epoch: 28 | loss: 3.3644686
	speed: 0.0361s/iter; left time: 693.6610s
Epoch: 28 cost time: 9.744683742523193
Epoch: 28, Steps: 266 Train Loss: 3.2391 (Forecasting Loss:0.1415 + XiCon Loss:3.0976 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1896601
	speed: 0.0381s/iter; left time: 726.1659s
	iters: 200, epoch: 29 | loss: 3.2995648
	speed: 0.0354s/iter; left time: 670.2558s
Epoch: 29 cost time: 9.711720705032349
Epoch: 29, Steps: 266 Train Loss: 3.2383 (Forecasting Loss:0.1414 + XiCon Loss:3.0968 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0262607391923666, mae:0.12167467176914215, mape:0.09855575114488602, mspe:0.019751669839024544 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0264+-0.00018, MAE:0.1220+-0.00033, MAPE:0.0986+-0.00020, MSPE:0.0197+-0.00018, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.8296
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.3108635
	speed: 0.0506s/iter; left time: 1336.4848s
	iters: 200, epoch: 1 | loss: 31.3458214
	speed: 0.0450s/iter; left time: 1182.4172s
Epoch: 1 cost time: 12.504018545150757
Epoch: 1, Steps: 265 Train Loss: 32.2158 (Forecasting Loss:0.2098 + XiCon Loss:3.2006 x Lambda(10.0)), Vali MSE Loss: 0.1484 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.148442).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 36.2112732
	speed: 0.0503s/iter; left time: 1313.9168s
	iters: 200, epoch: 2 | loss: 34.3759842
	speed: 0.0463s/iter; left time: 1206.2473s
Epoch: 2 cost time: 12.748176336288452
Epoch: 2, Steps: 265 Train Loss: 34.5421 (Forecasting Loss:0.1985 + XiCon Loss:3.4344 x Lambda(10.0)), Vali MSE Loss: 0.1454 Test MSE Loss: 0.0961
Validation loss decreased (0.148442 --> 0.145374).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.9223862
	speed: 0.0495s/iter; left time: 1280.6064s
	iters: 200, epoch: 3 | loss: 31.9070206
	speed: 0.0471s/iter; left time: 1214.2970s
Epoch: 3 cost time: 12.716163873672485
Epoch: 3, Steps: 265 Train Loss: 33.4868 (Forecasting Loss:0.1930 + XiCon Loss:3.3294 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0958
Validation loss decreased (0.145374 --> 0.143603).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.4986763
	speed: 0.0499s/iter; left time: 1276.4773s
	iters: 200, epoch: 4 | loss: 33.2929802
	speed: 0.0473s/iter; left time: 1206.4939s
Epoch: 4 cost time: 12.774965763092041
Epoch: 4, Steps: 265 Train Loss: 32.8211 (Forecasting Loss:0.1912 + XiCon Loss:3.2630 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0961
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.5032120
	speed: 0.0491s/iter; left time: 1244.9815s
	iters: 200, epoch: 5 | loss: 32.8915482
	speed: 0.0473s/iter; left time: 1194.5775s
Epoch: 5 cost time: 12.771196603775024
Epoch: 5, Steps: 265 Train Loss: 32.7209 (Forecasting Loss:0.1904 + XiCon Loss:3.2530 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0956
Validation loss decreased (0.143603 --> 0.142641).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.4455242
	speed: 0.0498s/iter; left time: 1247.7815s
	iters: 200, epoch: 6 | loss: 32.2784691
	speed: 0.0475s/iter; left time: 1186.8859s
Epoch: 6 cost time: 12.86228084564209
Epoch: 6, Steps: 265 Train Loss: 32.7587 (Forecasting Loss:0.1898 + XiCon Loss:3.2569 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0948
Validation loss decreased (0.142641 --> 0.141912).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9968491
	speed: 0.0492s/iter; left time: 1219.6909s
	iters: 200, epoch: 7 | loss: 33.1950836
	speed: 0.0474s/iter; left time: 1172.1560s
Epoch: 7 cost time: 12.745418310165405
Epoch: 7, Steps: 265 Train Loss: 32.6728 (Forecasting Loss:0.1895 + XiCon Loss:3.2483 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8474293
	speed: 0.0495s/iter; left time: 1213.8133s
	iters: 200, epoch: 8 | loss: 31.8461914
	speed: 0.0477s/iter; left time: 1165.8951s
Epoch: 8 cost time: 12.82375979423523
Epoch: 8, Steps: 265 Train Loss: 32.6469 (Forecasting Loss:0.1894 + XiCon Loss:3.2458 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0948
Validation loss decreased (0.141912 --> 0.141879).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1985435
	speed: 0.0491s/iter; left time: 1193.0956s
	iters: 200, epoch: 9 | loss: 31.8016949
	speed: 0.0461s/iter; left time: 1114.1004s
Epoch: 9 cost time: 12.729255437850952
Epoch: 9, Steps: 265 Train Loss: 32.6864 (Forecasting Loss:0.1892 + XiCon Loss:3.2497 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
Validation loss decreased (0.141879 --> 0.141836).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.7641792
	speed: 0.0489s/iter; left time: 1174.1498s
	iters: 200, epoch: 10 | loss: 32.6236877
	speed: 0.0464s/iter; left time: 1110.4449s
Epoch: 10 cost time: 12.60616683959961
Epoch: 10, Steps: 265 Train Loss: 32.6199 (Forecasting Loss:0.1892 + XiCon Loss:3.2431 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.141836 --> 0.141695).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.2256966
	speed: 0.0497s/iter; left time: 1180.6141s
	iters: 200, epoch: 11 | loss: 32.4374771
	speed: 0.0481s/iter; left time: 1138.0252s
Epoch: 11 cost time: 12.914073705673218
Epoch: 11, Steps: 265 Train Loss: 32.7278 (Forecasting Loss:0.1892 + XiCon Loss:3.2539 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.8697014
	speed: 0.0492s/iter; left time: 1156.2717s
	iters: 200, epoch: 12 | loss: 32.1450462
	speed: 0.0472s/iter; left time: 1102.7012s
Epoch: 12 cost time: 12.757818937301636
Epoch: 12, Steps: 265 Train Loss: 32.7156 (Forecasting Loss:0.1891 + XiCon Loss:3.2526 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.141695 --> 0.141661).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.2155151
	speed: 0.0493s/iter; left time: 1145.8553s
	iters: 200, epoch: 13 | loss: 32.9866943
	speed: 0.0471s/iter; left time: 1088.5987s
Epoch: 13 cost time: 12.802506923675537
Epoch: 13, Steps: 265 Train Loss: 32.6250 (Forecasting Loss:0.1891 + XiCon Loss:3.2436 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2092094
	speed: 0.0504s/iter; left time: 1156.2519s
	iters: 200, epoch: 14 | loss: 32.8283768
	speed: 0.0477s/iter; left time: 1090.2869s
Epoch: 14 cost time: 12.884296178817749
Epoch: 14, Steps: 265 Train Loss: 32.5954 (Forecasting Loss:0.1892 + XiCon Loss:3.2406 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.9300232
	speed: 0.0495s/iter; left time: 1123.1353s
	iters: 200, epoch: 15 | loss: 31.6060944
	speed: 0.0472s/iter; left time: 1065.5620s
Epoch: 15 cost time: 12.827768564224243
Epoch: 15, Steps: 265 Train Loss: 32.7055 (Forecasting Loss:0.1890 + XiCon Loss:3.2516 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0385933
	speed: 0.0497s/iter; left time: 1114.6459s
	iters: 200, epoch: 16 | loss: 33.5833817
	speed: 0.0468s/iter; left time: 1045.6393s
Epoch: 16 cost time: 12.752363204956055
Epoch: 16, Steps: 265 Train Loss: 32.6517 (Forecasting Loss:0.1891 + XiCon Loss:3.2463 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
Validation loss decreased (0.141661 --> 0.141607).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.9962006
	speed: 0.0491s/iter; left time: 1087.8501s
	iters: 200, epoch: 17 | loss: 32.3581200
	speed: 0.0471s/iter; left time: 1039.6959s
Epoch: 17 cost time: 12.796170949935913
Epoch: 17, Steps: 265 Train Loss: 32.7071 (Forecasting Loss:0.1891 + XiCon Loss:3.2518 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3424797
	speed: 0.0492s/iter; left time: 1078.2829s
	iters: 200, epoch: 18 | loss: 33.3594284
	speed: 0.0469s/iter; left time: 1022.7313s
Epoch: 18 cost time: 12.719810247421265
Epoch: 18, Steps: 265 Train Loss: 32.6660 (Forecasting Loss:0.1890 + XiCon Loss:3.2477 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.7982159
	speed: 0.0497s/iter; left time: 1074.8543s
	iters: 200, epoch: 19 | loss: 32.4841003
	speed: 0.0478s/iter; left time: 1029.7347s
Epoch: 19 cost time: 12.881713151931763
Epoch: 19, Steps: 265 Train Loss: 32.7182 (Forecasting Loss:0.1891 + XiCon Loss:3.2529 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.5471458
	speed: 0.0489s/iter; left time: 1043.9048s
	iters: 200, epoch: 20 | loss: 32.7443314
	speed: 0.0479s/iter; left time: 1019.2150s
Epoch: 20 cost time: 12.855468034744263
Epoch: 20, Steps: 265 Train Loss: 32.6456 (Forecasting Loss:0.1891 + XiCon Loss:3.2456 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.4031754
	speed: 0.0502s/iter; left time: 1059.9813s
	iters: 200, epoch: 21 | loss: 32.5456657
	speed: 0.0472s/iter; left time: 992.0369s
Epoch: 21 cost time: 12.839784145355225
Epoch: 21, Steps: 265 Train Loss: 32.7371 (Forecasting Loss:0.1891 + XiCon Loss:3.2548 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.2023811
	speed: 0.0502s/iter; left time: 1046.1034s
	iters: 200, epoch: 22 | loss: 34.4368629
	speed: 0.0482s/iter; left time: 998.6213s
Epoch: 22 cost time: 12.971876382827759
Epoch: 22, Steps: 265 Train Loss: 32.8353 (Forecasting Loss:0.1891 + XiCon Loss:3.2646 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.1502838
	speed: 0.0489s/iter; left time: 1004.9627s
	iters: 200, epoch: 23 | loss: 34.2897263
	speed: 0.0468s/iter; left time: 957.2820s
Epoch: 23 cost time: 12.671425580978394
Epoch: 23, Steps: 265 Train Loss: 32.6665 (Forecasting Loss:0.1892 + XiCon Loss:3.2477 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.6184540
	speed: 0.0491s/iter; left time: 997.7769s
	iters: 200, epoch: 24 | loss: 33.1183510
	speed: 0.0466s/iter; left time: 940.9445s
Epoch: 24 cost time: 12.667744159698486
Epoch: 24, Steps: 265 Train Loss: 32.6406 (Forecasting Loss:0.1891 + XiCon Loss:3.2451 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.1827164
	speed: 0.0490s/iter; left time: 982.1558s
	iters: 200, epoch: 25 | loss: 33.2785339
	speed: 0.0473s/iter; left time: 943.6778s
Epoch: 25 cost time: 12.7366783618927
Epoch: 25, Steps: 265 Train Loss: 32.8466 (Forecasting Loss:0.1891 + XiCon Loss:3.2658 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.4921532
	speed: 0.0494s/iter; left time: 975.9777s
	iters: 200, epoch: 26 | loss: 32.2850151
	speed: 0.0486s/iter; left time: 956.1664s
Epoch: 26 cost time: 12.906303405761719
Epoch: 26, Steps: 265 Train Loss: 32.5474 (Forecasting Loss:0.1891 + XiCon Loss:3.2358 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039569661021232605, mae:0.1499209851026535, mape:0.11892573535442352, mspe:0.02638360857963562 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4798
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.7466526
	speed: 0.0481s/iter; left time: 1270.3572s
	iters: 200, epoch: 1 | loss: 30.9325581
	speed: 0.0453s/iter; left time: 1191.5726s
Epoch: 1 cost time: 12.334043264389038
Epoch: 1, Steps: 265 Train Loss: 32.1126 (Forecasting Loss:0.2122 + XiCon Loss:3.1900 x Lambda(10.0)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.146731).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.4026642
	speed: 0.0507s/iter; left time: 1324.1002s
	iters: 200, epoch: 2 | loss: 32.0234222
	speed: 0.0480s/iter; left time: 1249.8973s
Epoch: 2 cost time: 12.99557113647461
Epoch: 2, Steps: 265 Train Loss: 33.0410 (Forecasting Loss:0.1980 + XiCon Loss:3.2843 x Lambda(10.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0972
Validation loss decreased (0.146731 --> 0.146319).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8485317
	speed: 0.0500s/iter; left time: 1294.3034s
	iters: 200, epoch: 3 | loss: 33.8330841
	speed: 0.0470s/iter; left time: 1211.2162s
Epoch: 3 cost time: 12.820915937423706
Epoch: 3, Steps: 265 Train Loss: 32.3327 (Forecasting Loss:0.1929 + XiCon Loss:3.2140 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0952
Validation loss decreased (0.146319 --> 0.143743).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7410889
	speed: 0.0496s/iter; left time: 1269.8105s
	iters: 200, epoch: 4 | loss: 32.5877075
	speed: 0.0471s/iter; left time: 1202.3516s
Epoch: 4 cost time: 12.770998477935791
Epoch: 4, Steps: 265 Train Loss: 32.3187 (Forecasting Loss:0.1915 + XiCon Loss:3.2127 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0948
Validation loss decreased (0.143743 --> 0.142177).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.3794060
	speed: 0.0493s/iter; left time: 1249.5280s
	iters: 200, epoch: 5 | loss: 32.3220253
	speed: 0.0473s/iter; left time: 1192.9373s
Epoch: 5 cost time: 12.783547401428223
Epoch: 5, Steps: 265 Train Loss: 32.0793 (Forecasting Loss:0.1902 + XiCon Loss:3.1889 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
Validation loss decreased (0.142177 --> 0.141729).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.3169060
	speed: 0.0498s/iter; left time: 1249.1858s
	iters: 200, epoch: 6 | loss: 31.3215103
	speed: 0.0484s/iter; left time: 1209.0316s
Epoch: 6 cost time: 13.043397665023804
Epoch: 6, Steps: 265 Train Loss: 31.7283 (Forecasting Loss:0.1898 + XiCon Loss:3.1538 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0943203
	speed: 0.0504s/iter; left time: 1249.9496s
	iters: 200, epoch: 7 | loss: 32.4324379
	speed: 0.0483s/iter; left time: 1193.3345s
Epoch: 7 cost time: 12.981969594955444
Epoch: 7, Steps: 265 Train Loss: 31.7726 (Forecasting Loss:0.1896 + XiCon Loss:3.1583 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.141729 --> 0.141553).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.6658077
	speed: 0.0511s/iter; left time: 1253.7667s
	iters: 200, epoch: 8 | loss: 31.8739929
	speed: 0.0479s/iter; left time: 1171.0019s
Epoch: 8 cost time: 13.003489255905151
Epoch: 8, Steps: 265 Train Loss: 32.1739 (Forecasting Loss:0.1894 + XiCon Loss:3.1984 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1820221
	speed: 0.0495s/iter; left time: 1200.7402s
	iters: 200, epoch: 9 | loss: 32.8427048
	speed: 0.0472s/iter; left time: 1141.9938s
Epoch: 9 cost time: 12.727844476699829
Epoch: 9, Steps: 265 Train Loss: 32.1283 (Forecasting Loss:0.1892 + XiCon Loss:3.1939 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.3891563
	speed: 0.0502s/iter; left time: 1206.6744s
	iters: 200, epoch: 10 | loss: 32.7079697
	speed: 0.0474s/iter; left time: 1132.9153s
Epoch: 10 cost time: 12.898025274276733
Epoch: 10, Steps: 265 Train Loss: 32.1114 (Forecasting Loss:0.1891 + XiCon Loss:3.1922 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8823948
	speed: 0.0503s/iter; left time: 1194.1362s
	iters: 200, epoch: 11 | loss: 32.2971840
	speed: 0.0483s/iter; left time: 1142.0863s
Epoch: 11 cost time: 13.005436420440674
Epoch: 11, Steps: 265 Train Loss: 32.1348 (Forecasting Loss:0.1892 + XiCon Loss:3.1946 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.2215824
	speed: 0.0498s/iter; left time: 1169.7310s
	iters: 200, epoch: 12 | loss: 32.0107880
	speed: 0.0475s/iter; left time: 1110.4832s
Epoch: 12 cost time: 12.787243127822876
Epoch: 12, Steps: 265 Train Loss: 32.1315 (Forecasting Loss:0.1892 + XiCon Loss:3.1942 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.6390572
	speed: 0.0501s/iter; left time: 1162.7862s
	iters: 200, epoch: 13 | loss: 32.8406410
	speed: 0.0477s/iter; left time: 1102.7807s
Epoch: 13 cost time: 12.89801836013794
Epoch: 13, Steps: 265 Train Loss: 32.1971 (Forecasting Loss:0.1892 + XiCon Loss:3.2008 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.8787270
	speed: 0.0493s/iter; left time: 1132.7607s
	iters: 200, epoch: 14 | loss: 31.5428009
	speed: 0.0470s/iter; left time: 1073.6768s
Epoch: 14 cost time: 12.706708908081055
Epoch: 14, Steps: 265 Train Loss: 32.1270 (Forecasting Loss:0.1892 + XiCon Loss:3.1938 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.9138680
	speed: 0.0505s/iter; left time: 1146.7855s
	iters: 200, epoch: 15 | loss: 30.2855225
	speed: 0.0475s/iter; left time: 1073.7626s
Epoch: 15 cost time: 12.900447368621826
Epoch: 15, Steps: 265 Train Loss: 32.1619 (Forecasting Loss:0.1891 + XiCon Loss:3.1973 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4189644
	speed: 0.0494s/iter; left time: 1106.8401s
	iters: 200, epoch: 16 | loss: 31.0225201
	speed: 0.0471s/iter; left time: 1052.5545s
Epoch: 16 cost time: 12.75908374786377
Epoch: 16, Steps: 265 Train Loss: 32.1081 (Forecasting Loss:0.1890 + XiCon Loss:3.1919 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.1878090
	speed: 0.0538s/iter; left time: 1192.8690s
	iters: 200, epoch: 17 | loss: 32.4802551
	speed: 0.0476s/iter; left time: 1050.1352s
Epoch: 17 cost time: 16.907200574874878
Epoch: 17, Steps: 265 Train Loss: 32.1677 (Forecasting Loss:0.1891 + XiCon Loss:3.1979 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039395153522491455, mae:0.14978601038455963, mape:0.1192258819937706, mspe:0.026639336720108986 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 34.7541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.2960968
	speed: 0.1152s/iter; left time: 3040.7334s
	iters: 200, epoch: 1 | loss: 31.6317921
	speed: 0.1069s/iter; left time: 2812.8542s
Epoch: 1 cost time: 28.943447589874268
Epoch: 1, Steps: 265 Train Loss: 32.0510 (Forecasting Loss:0.2115 + XiCon Loss:3.1839 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.147882).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 42.4630585
	speed: 0.1124s/iter; left time: 2937.9623s
	iters: 200, epoch: 2 | loss: 35.7428017
	speed: 0.0998s/iter; left time: 2599.2198s
Epoch: 2 cost time: 28.41482424736023
Epoch: 2, Steps: 265 Train Loss: 36.7410 (Forecasting Loss:0.2444 + XiCon Loss:3.6497 x Lambda(10.0)), Vali MSE Loss: 0.1495 Test MSE Loss: 0.1019
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.4230881
	speed: 0.1103s/iter; left time: 2854.5443s
	iters: 200, epoch: 3 | loss: 34.3397179
	speed: 0.1074s/iter; left time: 2768.1570s
Epoch: 3 cost time: 28.975181579589844
Epoch: 3, Steps: 265 Train Loss: 37.2144 (Forecasting Loss:0.1926 + XiCon Loss:3.7022 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0955
Validation loss decreased (0.147882 --> 0.143969).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 36.1262131
	speed: 0.1138s/iter; left time: 2914.2521s
	iters: 200, epoch: 4 | loss: 37.8854027
	speed: 0.1042s/iter; left time: 2657.9195s
Epoch: 4 cost time: 28.75026249885559
Epoch: 4, Steps: 265 Train Loss: 36.8883 (Forecasting Loss:0.1914 + XiCon Loss:3.6697 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0950
Validation loss decreased (0.143969 --> 0.142247).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 35.7766609
	speed: 0.1151s/iter; left time: 2916.1954s
	iters: 200, epoch: 5 | loss: 39.7007294
	speed: 0.1077s/iter; left time: 2718.4381s
Epoch: 5 cost time: 29.448667764663696
Epoch: 5, Steps: 265 Train Loss: 36.7146 (Forecasting Loss:0.1894 + XiCon Loss:3.6525 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 37.2559166
	speed: 0.1126s/iter; left time: 2822.4066s
	iters: 200, epoch: 6 | loss: 36.9549332
	speed: 0.1042s/iter; left time: 2601.3019s
Epoch: 6 cost time: 28.77062225341797
Epoch: 6, Steps: 265 Train Loss: 36.6849 (Forecasting Loss:0.1889 + XiCon Loss:3.6496 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 36.3247910
	speed: 0.1070s/iter; left time: 2653.9777s
	iters: 200, epoch: 7 | loss: 37.6062126
	speed: 0.1011s/iter; left time: 2497.4062s
Epoch: 7 cost time: 27.33423900604248
Epoch: 7, Steps: 265 Train Loss: 36.7616 (Forecasting Loss:0.1886 + XiCon Loss:3.6573 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
Validation loss decreased (0.142247 --> 0.141830).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 36.7406578
	speed: 0.1075s/iter; left time: 2637.7455s
	iters: 200, epoch: 8 | loss: 35.1527596
	speed: 0.0910s/iter; left time: 2225.1496s
Epoch: 8 cost time: 25.67367911338806
Epoch: 8, Steps: 265 Train Loss: 36.6770 (Forecasting Loss:0.1884 + XiCon Loss:3.6489 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 39.6458435
	speed: 0.1013s/iter; left time: 2460.7905s
	iters: 200, epoch: 9 | loss: 37.0029640
	speed: 0.0936s/iter; left time: 2262.8064s
Epoch: 9 cost time: 25.34854531288147
Epoch: 9, Steps: 265 Train Loss: 36.5655 (Forecasting Loss:0.1883 + XiCon Loss:3.6377 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 39.0633163
	speed: 0.0926s/iter; left time: 2223.4946s
	iters: 200, epoch: 10 | loss: 39.3322678
	speed: 0.0861s/iter; left time: 2058.7940s
Epoch: 10 cost time: 23.854790925979614
Epoch: 10, Steps: 265 Train Loss: 36.3632 (Forecasting Loss:0.1882 + XiCon Loss:3.6175 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.2274284
	speed: 0.1046s/iter; left time: 2483.4542s
	iters: 200, epoch: 11 | loss: 34.2157669
	speed: 0.1048s/iter; left time: 2479.0247s
Epoch: 11 cost time: 27.2600359916687
Epoch: 11, Steps: 265 Train Loss: 36.5571 (Forecasting Loss:0.1883 + XiCon Loss:3.6369 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 38.0593338
	speed: 0.1205s/iter; left time: 2829.9768s
	iters: 200, epoch: 12 | loss: 35.6573982
	speed: 0.1152s/iter; left time: 2693.8245s
Epoch: 12 cost time: 31.163098335266113
Epoch: 12, Steps: 265 Train Loss: 36.6330 (Forecasting Loss:0.1881 + XiCon Loss:3.6445 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 35.7294121
	speed: 0.1283s/iter; left time: 2979.3114s
	iters: 200, epoch: 13 | loss: 37.1788597
	speed: 0.1175s/iter; left time: 2716.0198s
Epoch: 13 cost time: 32.26000261306763
Epoch: 13, Steps: 265 Train Loss: 36.6191 (Forecasting Loss:0.1882 + XiCon Loss:3.6431 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 35.8629150
	speed: 0.1239s/iter; left time: 2844.4698s
	iters: 200, epoch: 14 | loss: 38.3578033
	speed: 0.1122s/iter; left time: 2563.5847s
Epoch: 14 cost time: 31.772884130477905
Epoch: 14, Steps: 265 Train Loss: 36.5677 (Forecasting Loss:0.1882 + XiCon Loss:3.6379 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 34.7654877
	speed: 0.1221s/iter; left time: 2771.6467s
	iters: 200, epoch: 15 | loss: 38.3351936
	speed: 0.1141s/iter; left time: 2577.8499s
Epoch: 15 cost time: 31.387567043304443
Epoch: 15, Steps: 265 Train Loss: 36.4781 (Forecasting Loss:0.1883 + XiCon Loss:3.6290 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 37.4781303
	speed: 0.1191s/iter; left time: 2671.2619s
	iters: 200, epoch: 16 | loss: 38.0158119
	speed: 0.1142s/iter; left time: 2549.6343s
Epoch: 16 cost time: 30.698320150375366
Epoch: 16, Steps: 265 Train Loss: 36.4414 (Forecasting Loss:0.1882 + XiCon Loss:3.6253 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.7794838
	speed: 0.1187s/iter; left time: 2631.4217s
	iters: 200, epoch: 17 | loss: 36.5852242
	speed: 0.1107s/iter; left time: 2441.7898s
Epoch: 17 cost time: 29.8065824508667
Epoch: 17, Steps: 265 Train Loss: 36.5128 (Forecasting Loss:0.1883 + XiCon Loss:3.6325 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03922183811664581, mae:0.14944034814834595, mape:0.11906785517930984, mspe:0.026853257790207863 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 27.4470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.8894730
	speed: 0.1091s/iter; left time: 2879.3781s
	iters: 200, epoch: 1 | loss: 31.1656895
	speed: 0.1053s/iter; left time: 2768.6624s
Epoch: 1 cost time: 28.047703742980957
Epoch: 1, Steps: 265 Train Loss: 32.0507 (Forecasting Loss:0.2095 + XiCon Loss:3.1841 x Lambda(10.0)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.0992
Validation loss decreased (inf --> 0.148051).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 36.4516602
	speed: 0.1104s/iter; left time: 2885.9293s
	iters: 200, epoch: 2 | loss: 33.0356178
	speed: 0.1011s/iter; left time: 2632.2565s
Epoch: 2 cost time: 27.206326246261597
Epoch: 2, Steps: 265 Train Loss: 35.3412 (Forecasting Loss:0.2000 + XiCon Loss:3.5141 x Lambda(10.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0969
Validation loss decreased (0.148051 --> 0.145590).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 34.4298363
	speed: 0.1019s/iter; left time: 2637.1706s
	iters: 200, epoch: 3 | loss: 37.2061501
	speed: 0.0955s/iter; left time: 2461.2211s
Epoch: 3 cost time: 26.029674530029297
Epoch: 3, Steps: 265 Train Loss: 36.7221 (Forecasting Loss:0.1938 + XiCon Loss:3.6528 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0956
Validation loss decreased (0.145590 --> 0.143091).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 41.3186111
	speed: 0.0968s/iter; left time: 2479.8211s
	iters: 200, epoch: 4 | loss: 35.0024071
	speed: 0.0946s/iter; left time: 2413.6877s
Epoch: 4 cost time: 25.32196807861328
Epoch: 4, Steps: 265 Train Loss: 41.6631 (Forecasting Loss:5.8964 + XiCon Loss:3.5767 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0954
Validation loss decreased (0.143091 --> 0.142441).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 38.5227623
	speed: 0.1004s/iter; left time: 2544.4778s
	iters: 200, epoch: 5 | loss: 36.1640625
	speed: 0.0994s/iter; left time: 2507.7543s
Epoch: 5 cost time: 26.172434329986572
Epoch: 5, Steps: 265 Train Loss: 36.3540 (Forecasting Loss:0.2687 + XiCon Loss:3.6085 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0952
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 35.8592491
	speed: 0.0890s/iter; left time: 2230.9488s
	iters: 200, epoch: 6 | loss: 36.2654572
	speed: 0.0881s/iter; left time: 2199.9449s
Epoch: 6 cost time: 23.373624324798584
Epoch: 6, Steps: 265 Train Loss: 36.3509 (Forecasting Loss:0.1917 + XiCon Loss:3.6159 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0947
Validation loss decreased (0.142441 --> 0.142162).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 37.4507027
	speed: 0.0897s/iter; left time: 2224.5121s
	iters: 200, epoch: 7 | loss: 34.2739220
	speed: 0.0856s/iter; left time: 2116.3072s
Epoch: 7 cost time: 23.12306237220764
Epoch: 7, Steps: 265 Train Loss: 36.2052 (Forecasting Loss:0.1889 + XiCon Loss:3.6016 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0948
Validation loss decreased (0.142162 --> 0.142052).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 35.8042336
	speed: 0.0907s/iter; left time: 2227.3912s
	iters: 200, epoch: 8 | loss: 34.2739067
	speed: 0.0881s/iter; left time: 2153.8309s
Epoch: 8 cost time: 23.673759937286377
Epoch: 8, Steps: 265 Train Loss: 36.2389 (Forecasting Loss:0.1887 + XiCon Loss:3.6050 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0947
Validation loss decreased (0.142052 --> 0.141999).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 36.9408455
	speed: 0.0926s/iter; left time: 2248.5453s
	iters: 200, epoch: 9 | loss: 35.9597931
	speed: 0.0822s/iter; left time: 1987.1260s
Epoch: 9 cost time: 22.66323447227478
Epoch: 9, Steps: 265 Train Loss: 36.2770 (Forecasting Loss:0.1887 + XiCon Loss:3.6088 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
Validation loss decreased (0.141999 --> 0.141848).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 37.6452446
	speed: 0.0825s/iter; left time: 1981.4252s
	iters: 200, epoch: 10 | loss: 37.7262726
	speed: 0.0778s/iter; left time: 1860.2584s
Epoch: 10 cost time: 21.16567897796631
Epoch: 10, Steps: 265 Train Loss: 36.4459 (Forecasting Loss:0.1886 + XiCon Loss:3.6257 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0951
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.9596043
	speed: 0.0820s/iter; left time: 1946.9511s
	iters: 200, epoch: 11 | loss: 34.9369926
	speed: 0.0762s/iter; left time: 1802.0368s
Epoch: 11 cost time: 21.051038026809692
Epoch: 11, Steps: 265 Train Loss: 36.3703 (Forecasting Loss:0.1886 + XiCon Loss:3.6182 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 37.5294800
	speed: 0.0827s/iter; left time: 1942.0669s
	iters: 200, epoch: 12 | loss: 35.5172958
	speed: 0.0771s/iter; left time: 1803.8251s
Epoch: 12 cost time: 21.210225582122803
Epoch: 12, Steps: 265 Train Loss: 36.4435 (Forecasting Loss:0.1886 + XiCon Loss:3.6255 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
Validation loss decreased (0.141848 --> 0.141780).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 36.4534264
	speed: 0.0796s/iter; left time: 1848.1754s
	iters: 200, epoch: 13 | loss: 37.3990326
	speed: 0.0554s/iter; left time: 1281.2311s
Epoch: 13 cost time: 17.58186912536621
Epoch: 13, Steps: 265 Train Loss: 36.3067 (Forecasting Loss:0.1885 + XiCon Loss:3.6118 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 38.4649925
	speed: 0.0669s/iter; left time: 1534.6635s
	iters: 200, epoch: 14 | loss: 35.7586136
	speed: 0.0534s/iter; left time: 1219.8196s
Epoch: 14 cost time: 15.45093297958374
Epoch: 14, Steps: 265 Train Loss: 36.2263 (Forecasting Loss:0.1886 + XiCon Loss:3.6038 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 35.9686279
	speed: 0.0579s/iter; left time: 1314.8992s
	iters: 200, epoch: 15 | loss: 35.3308105
	speed: 0.0536s/iter; left time: 1210.7032s
Epoch: 15 cost time: 14.699264526367188
Epoch: 15, Steps: 265 Train Loss: 36.4163 (Forecasting Loss:0.1886 + XiCon Loss:3.6228 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 36.7634201
	speed: 0.0570s/iter; left time: 1277.2640s
	iters: 200, epoch: 16 | loss: 37.4519424
	speed: 0.0583s/iter; left time: 1301.1534s
Epoch: 16 cost time: 15.530073642730713
Epoch: 16, Steps: 265 Train Loss: 36.2770 (Forecasting Loss:0.1886 + XiCon Loss:3.6088 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0950
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 34.1960182
	speed: 0.0624s/iter; left time: 1383.5025s
	iters: 200, epoch: 17 | loss: 36.5207291
	speed: 0.0550s/iter; left time: 1213.9935s
Epoch: 17 cost time: 15.319484233856201
Epoch: 17, Steps: 265 Train Loss: 36.3209 (Forecasting Loss:0.1886 + XiCon Loss:3.6132 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 41.5180244
	speed: 0.0495s/iter; left time: 1084.2811s
	iters: 200, epoch: 18 | loss: 35.1711464
	speed: 0.0487s/iter; left time: 1060.8214s
Epoch: 18 cost time: 12.789284706115723
Epoch: 18, Steps: 265 Train Loss: 36.4644 (Forecasting Loss:0.1895 + XiCon Loss:3.6275 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 35.8917961
	speed: 0.0531s/iter; left time: 1148.6887s
	iters: 200, epoch: 19 | loss: 35.7856712
	speed: 0.0479s/iter; left time: 1031.3045s
Epoch: 19 cost time: 13.139238595962524
Epoch: 19, Steps: 265 Train Loss: 36.3964 (Forecasting Loss:0.1886 + XiCon Loss:3.6208 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 35.1997795
	speed: 0.0505s/iter; left time: 1078.9196s
	iters: 200, epoch: 20 | loss: 34.5530891
	speed: 0.0454s/iter; left time: 965.5535s
Epoch: 20 cost time: 12.587724924087524
Epoch: 20, Steps: 265 Train Loss: 36.2961 (Forecasting Loss:0.1885 + XiCon Loss:3.6108 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 39.9866524
	speed: 0.0520s/iter; left time: 1097.4821s
	iters: 200, epoch: 21 | loss: 33.5813522
	speed: 0.0483s/iter; left time: 1014.1928s
Epoch: 21 cost time: 13.118674755096436
Epoch: 21, Steps: 265 Train Loss: 36.3398 (Forecasting Loss:0.1886 + XiCon Loss:3.6151 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0950
Validation loss decreased (0.141780 --> 0.141725).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 36.5935326
	speed: 0.0506s/iter; left time: 1055.1846s
	iters: 200, epoch: 22 | loss: 40.6459084
	speed: 0.0471s/iter; left time: 976.6195s
Epoch: 22 cost time: 12.747300148010254
Epoch: 22, Steps: 265 Train Loss: 36.2892 (Forecasting Loss:0.1887 + XiCon Loss:3.6100 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 37.0882912
	speed: 0.0496s/iter; left time: 1021.1922s
	iters: 200, epoch: 23 | loss: 33.3765488
	speed: 0.0456s/iter; left time: 933.5895s
Epoch: 23 cost time: 12.585854291915894
Epoch: 23, Steps: 265 Train Loss: 36.4133 (Forecasting Loss:0.1928 + XiCon Loss:3.6221 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 35.4106331
	speed: 0.0484s/iter; left time: 983.5154s
	iters: 200, epoch: 24 | loss: 34.8936996
	speed: 0.0459s/iter; left time: 928.0732s
Epoch: 24 cost time: 12.507518291473389
Epoch: 24, Steps: 265 Train Loss: 36.3204 (Forecasting Loss:0.1951 + XiCon Loss:3.6125 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 36.3198090
	speed: 0.0493s/iter; left time: 987.7493s
	iters: 200, epoch: 25 | loss: 33.5905952
	speed: 0.0459s/iter; left time: 914.6343s
Epoch: 25 cost time: 12.530112743377686
Epoch: 25, Steps: 265 Train Loss: 36.2990 (Forecasting Loss:0.1887 + XiCon Loss:3.6110 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 37.4652443
	speed: 0.0491s/iter; left time: 970.3046s
	iters: 200, epoch: 26 | loss: 37.6298370
	speed: 0.0456s/iter; left time: 896.8897s
Epoch: 26 cost time: 12.551228761672974
Epoch: 26, Steps: 265 Train Loss: 36.4292 (Forecasting Loss:0.1887 + XiCon Loss:3.6241 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 35.3927155
	speed: 0.0484s/iter; left time: 943.9253s
	iters: 200, epoch: 27 | loss: 36.2000313
	speed: 0.0459s/iter; left time: 890.8459s
Epoch: 27 cost time: 12.468279123306274
Epoch: 27, Steps: 265 Train Loss: 36.2772 (Forecasting Loss:0.1886 + XiCon Loss:3.6089 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 36.3791580
	speed: 0.0480s/iter; left time: 924.4573s
	iters: 200, epoch: 28 | loss: 35.1682053
	speed: 0.0461s/iter; left time: 881.8849s
Epoch: 28 cost time: 12.48551344871521
Epoch: 28, Steps: 265 Train Loss: 36.4917 (Forecasting Loss:0.1885 + XiCon Loss:3.6303 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 37.9872360
	speed: 0.0496s/iter; left time: 940.8158s
	iters: 200, epoch: 29 | loss: 36.0245018
	speed: 0.0460s/iter; left time: 867.8520s
Epoch: 29 cost time: 12.626219987869263
Epoch: 29, Steps: 265 Train Loss: 36.3161 (Forecasting Loss:0.1886 + XiCon Loss:3.6128 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 36.6366081
	speed: 0.0491s/iter; left time: 918.3419s
	iters: 200, epoch: 30 | loss: 37.9599266
	speed: 0.0462s/iter; left time: 860.3698s
Epoch: 30 cost time: 12.594256162643433
Epoch: 30, Steps: 265 Train Loss: 36.2116 (Forecasting Loss:0.1887 + XiCon Loss:3.6023 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 34.6167297
	speed: 0.0492s/iter; left time: 907.8418s
	iters: 200, epoch: 31 | loss: 35.9096298
	speed: 0.0472s/iter; left time: 865.5553s
Epoch: 31 cost time: 12.68920087814331
Epoch: 31, Steps: 265 Train Loss: 36.5065 (Forecasting Loss:0.1887 + XiCon Loss:3.6318 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0399431474506855, mae:0.1501164436340332, mape:0.11948063224554062, mspe:0.027077633887529373 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.4138
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.9019489
	speed: 0.0478s/iter; left time: 1262.0885s
	iters: 200, epoch: 1 | loss: 31.6953812
	speed: 0.0441s/iter; left time: 1158.6328s
Epoch: 1 cost time: 12.151525497436523
Epoch: 1, Steps: 265 Train Loss: 32.1196 (Forecasting Loss:0.2125 + XiCon Loss:3.1907 x Lambda(10.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.148206).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.5186768
	speed: 0.0486s/iter; left time: 1271.1364s
	iters: 200, epoch: 2 | loss: 32.7016945
	speed: 0.0471s/iter; left time: 1225.6128s
Epoch: 2 cost time: 12.626200437545776
Epoch: 2, Steps: 265 Train Loss: 33.4033 (Forecasting Loss:0.1988 + XiCon Loss:3.3204 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.0967
Validation loss decreased (0.148206 --> 0.146010).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.9064503
	speed: 0.0490s/iter; left time: 1267.4394s
	iters: 200, epoch: 3 | loss: 31.8010235
	speed: 0.0465s/iter; left time: 1197.6740s
Epoch: 3 cost time: 12.564764976501465
Epoch: 3, Steps: 265 Train Loss: 31.5321 (Forecasting Loss:0.1928 + XiCon Loss:3.1339 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0965
Validation loss decreased (0.146010 --> 0.143238).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7040215
	speed: 0.0488s/iter; left time: 1249.6760s
	iters: 200, epoch: 4 | loss: 31.0421562
	speed: 0.0464s/iter; left time: 1184.2265s
Epoch: 4 cost time: 12.551950216293335
Epoch: 4, Steps: 265 Train Loss: 31.2616 (Forecasting Loss:0.1910 + XiCon Loss:3.1071 x Lambda(10.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0962
Validation loss decreased (0.143238 --> 0.142986).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.0257111
	speed: 0.0483s/iter; left time: 1224.4070s
	iters: 200, epoch: 5 | loss: 31.1015854
	speed: 0.0467s/iter; left time: 1179.1961s
Epoch: 5 cost time: 12.621896505355835
Epoch: 5, Steps: 265 Train Loss: 31.1816 (Forecasting Loss:0.1897 + XiCon Loss:3.0992 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0963
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.8591957
	speed: 0.0488s/iter; left time: 1223.4344s
	iters: 200, epoch: 6 | loss: 31.3888321
	speed: 0.0461s/iter; left time: 1150.4635s
Epoch: 6 cost time: 12.620686054229736
Epoch: 6, Steps: 265 Train Loss: 31.2625 (Forecasting Loss:0.1894 + XiCon Loss:3.1073 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0957
Validation loss decreased (0.142986 --> 0.142246).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.9497280
	speed: 0.0487s/iter; left time: 1207.9285s
	iters: 200, epoch: 7 | loss: 30.8049965
	speed: 0.0460s/iter; left time: 1136.7285s
Epoch: 7 cost time: 12.515811204910278
Epoch: 7, Steps: 265 Train Loss: 31.2223 (Forecasting Loss:0.1891 + XiCon Loss:3.1033 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0957
Validation loss decreased (0.142246 --> 0.142203).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.4485435
	speed: 0.0485s/iter; left time: 1191.5867s
	iters: 200, epoch: 8 | loss: 31.7472458
	speed: 0.0459s/iter; left time: 1122.7739s
Epoch: 8 cost time: 12.471747398376465
Epoch: 8, Steps: 265 Train Loss: 31.2636 (Forecasting Loss:0.1889 + XiCon Loss:3.1075 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0955
Validation loss decreased (0.142203 --> 0.141945).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4793720
	speed: 0.0485s/iter; left time: 1177.2338s
	iters: 200, epoch: 9 | loss: 31.2782650
	speed: 0.0466s/iter; left time: 1125.6921s
Epoch: 9 cost time: 12.487498044967651
Epoch: 9, Steps: 265 Train Loss: 31.1786 (Forecasting Loss:0.1888 + XiCon Loss:3.0990 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0955
Validation loss decreased (0.141945 --> 0.141780).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1259422
	speed: 0.0494s/iter; left time: 1185.8419s
	iters: 200, epoch: 10 | loss: 30.8264561
	speed: 0.0461s/iter; left time: 1101.8191s
Epoch: 10 cost time: 12.582995653152466
Epoch: 10, Steps: 265 Train Loss: 31.1872 (Forecasting Loss:0.1888 + XiCon Loss:3.0998 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8239670
	speed: 0.0486s/iter; left time: 1153.6950s
	iters: 200, epoch: 11 | loss: 31.9110470
	speed: 0.0458s/iter; left time: 1082.3939s
Epoch: 11 cost time: 12.463624954223633
Epoch: 11, Steps: 265 Train Loss: 31.1741 (Forecasting Loss:0.1888 + XiCon Loss:3.0985 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0956
Validation loss decreased (0.141780 --> 0.141773).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6478767
	speed: 0.0487s/iter; left time: 1144.7248s
	iters: 200, epoch: 12 | loss: 31.2807465
	speed: 0.0466s/iter; left time: 1090.4719s
Epoch: 12 cost time: 12.572201490402222
Epoch: 12, Steps: 265 Train Loss: 31.1714 (Forecasting Loss:0.1888 + XiCon Loss:3.0983 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7758007
	speed: 0.0495s/iter; left time: 1148.7780s
	iters: 200, epoch: 13 | loss: 31.4486961
	speed: 0.0457s/iter; left time: 1057.2330s
Epoch: 13 cost time: 12.543086767196655
Epoch: 13, Steps: 265 Train Loss: 31.2219 (Forecasting Loss:0.1888 + XiCon Loss:3.1033 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.0166092
	speed: 0.0492s/iter; left time: 1128.3003s
	iters: 200, epoch: 14 | loss: 31.5268993
	speed: 0.0461s/iter; left time: 1053.7978s
Epoch: 14 cost time: 12.582188129425049
Epoch: 14, Steps: 265 Train Loss: 31.1839 (Forecasting Loss:0.1887 + XiCon Loss:3.0995 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9586124
	speed: 0.0490s/iter; left time: 1111.4884s
	iters: 200, epoch: 15 | loss: 30.6574554
	speed: 0.0463s/iter; left time: 1047.0434s
Epoch: 15 cost time: 12.620771884918213
Epoch: 15, Steps: 265 Train Loss: 31.2239 (Forecasting Loss:0.1887 + XiCon Loss:3.1035 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8239307
	speed: 0.0483s/iter; left time: 1083.1283s
	iters: 200, epoch: 16 | loss: 30.6815853
	speed: 0.0465s/iter; left time: 1037.2419s
Epoch: 16 cost time: 12.50291109085083
Epoch: 16, Steps: 265 Train Loss: 31.2325 (Forecasting Loss:0.1887 + XiCon Loss:3.1044 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.7122650
	speed: 0.0485s/iter; left time: 1075.0576s
	iters: 200, epoch: 17 | loss: 31.9407635
	speed: 0.0455s/iter; left time: 1004.7526s
Epoch: 17 cost time: 12.519967555999756
Epoch: 17, Steps: 265 Train Loss: 31.2008 (Forecasting Loss:0.1888 + XiCon Loss:3.1012 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.9451580
	speed: 0.0483s/iter; left time: 1057.7425s
	iters: 200, epoch: 18 | loss: 31.5148525
	speed: 0.0464s/iter; left time: 1011.4201s
Epoch: 18 cost time: 12.48790717124939
Epoch: 18, Steps: 265 Train Loss: 31.1848 (Forecasting Loss:0.1887 + XiCon Loss:3.0996 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7142315
	speed: 0.0489s/iter; left time: 1056.8307s
	iters: 200, epoch: 19 | loss: 31.3220196
	speed: 0.0457s/iter; left time: 983.7744s
Epoch: 19 cost time: 12.561069011688232
Epoch: 19, Steps: 265 Train Loss: 31.1590 (Forecasting Loss:0.1888 + XiCon Loss:3.0970 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5769844
	speed: 0.0491s/iter; left time: 1048.2778s
	iters: 200, epoch: 20 | loss: 31.1444683
	speed: 0.0461s/iter; left time: 980.5453s
Epoch: 20 cost time: 12.594619035720825
Epoch: 20, Steps: 265 Train Loss: 31.2005 (Forecasting Loss:0.1887 + XiCon Loss:3.1012 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5561161
	speed: 0.0483s/iter; left time: 1019.6524s
	iters: 200, epoch: 21 | loss: 31.0242271
	speed: 0.0462s/iter; left time: 969.4764s
Epoch: 21 cost time: 12.529231548309326
Epoch: 21, Steps: 265 Train Loss: 31.2351 (Forecasting Loss:0.1888 + XiCon Loss:3.1046 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039978474378585815, mae:0.15114426612854004, mape:0.11988969147205353, mspe:0.026635069400072098 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0396+-0.00041, MAE:0.1501+-0.00080, MAPE:0.1193+-0.00047, MSPE:0.0267+-0.00032, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4609
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5681621
	speed: 0.0393s/iter; left time: 1034.5425s
	iters: 200, epoch: 1 | loss: 0.5847746
	speed: 0.0345s/iter; left time: 902.8172s
Epoch: 1 cost time: 9.595656394958496
Epoch: 1, Steps: 264 Train Loss: 0.5606 (Forecasting Loss:0.2365 + XiCon Loss:3.2416 x Lambda(0.1)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1154
Validation loss decreased (inf --> 0.172851).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5759571
	speed: 0.0430s/iter; left time: 1120.2522s
	iters: 200, epoch: 2 | loss: 0.5732949
	speed: 0.0377s/iter; left time: 978.7958s
Epoch: 2 cost time: 10.496260166168213
Epoch: 2, Steps: 264 Train Loss: 0.5559 (Forecasting Loss:0.2425 + XiCon Loss:3.1338 x Lambda(0.1)), Vali MSE Loss: 0.1790 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5334884
	speed: 0.0395s/iter; left time: 1017.2727s
	iters: 200, epoch: 3 | loss: 0.5006571
	speed: 0.0369s/iter; left time: 948.2161s
Epoch: 3 cost time: 10.04571008682251
Epoch: 3, Steps: 264 Train Loss: 0.5399 (Forecasting Loss:0.2339 + XiCon Loss:3.0595 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1153
Validation loss decreased (0.172851 --> 0.172430).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5162573
	speed: 0.0400s/iter; left time: 1021.0933s
	iters: 200, epoch: 4 | loss: 0.5552881
	speed: 0.0371s/iter; left time: 941.8131s
Epoch: 4 cost time: 10.139957189559937
Epoch: 4, Steps: 264 Train Loss: 0.5342 (Forecasting Loss:0.2292 + XiCon Loss:3.0499 x Lambda(0.1)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1170
Validation loss decreased (0.172430 --> 0.171877).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5323033
	speed: 0.0399s/iter; left time: 1006.2898s
	iters: 200, epoch: 5 | loss: 0.5102751
	speed: 0.0369s/iter; left time: 927.3122s
Epoch: 5 cost time: 10.11130666732788
Epoch: 5, Steps: 264 Train Loss: 0.5315 (Forecasting Loss:0.2274 + XiCon Loss:3.0410 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1147
Validation loss decreased (0.171877 --> 0.171187).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5276744
	speed: 0.0403s/iter; left time: 1007.9815s
	iters: 200, epoch: 6 | loss: 0.5174385
	speed: 0.0372s/iter; left time: 926.1350s
Epoch: 6 cost time: 10.151584148406982
Epoch: 6, Steps: 264 Train Loss: 0.5306 (Forecasting Loss:0.2264 + XiCon Loss:3.0419 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1147
Validation loss decreased (0.171187 --> 0.170378).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5369141
	speed: 0.0406s/iter; left time: 1003.8460s
	iters: 200, epoch: 7 | loss: 0.5194851
	speed: 0.0375s/iter; left time: 922.8079s
Epoch: 7 cost time: 10.234822034835815
Epoch: 7, Steps: 264 Train Loss: 0.5299 (Forecasting Loss:0.2258 + XiCon Loss:3.0410 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5165483
	speed: 0.0406s/iter; left time: 991.6436s
	iters: 200, epoch: 8 | loss: 0.5380092
	speed: 0.0367s/iter; left time: 893.4242s
Epoch: 8 cost time: 10.112119913101196
Epoch: 8, Steps: 264 Train Loss: 0.5294 (Forecasting Loss:0.2255 + XiCon Loss:3.0395 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1149
Validation loss decreased (0.170378 --> 0.170154).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5139297
	speed: 0.0400s/iter; left time: 968.7597s
	iters: 200, epoch: 9 | loss: 0.5259066
	speed: 0.0377s/iter; left time: 908.5056s
Epoch: 9 cost time: 10.239609956741333
Epoch: 9, Steps: 264 Train Loss: 0.5290 (Forecasting Loss:0.2253 + XiCon Loss:3.0370 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5554355
	speed: 0.0392s/iter; left time: 938.0341s
	iters: 200, epoch: 10 | loss: 0.5448388
	speed: 0.0373s/iter; left time: 889.4449s
Epoch: 10 cost time: 10.083203315734863
Epoch: 10, Steps: 264 Train Loss: 0.5291 (Forecasting Loss:0.2253 + XiCon Loss:3.0375 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1148
Validation loss decreased (0.170154 --> 0.170053).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5225434
	speed: 0.0396s/iter; left time: 936.9479s
	iters: 200, epoch: 11 | loss: 0.5191296
	speed: 0.0377s/iter; left time: 887.1145s
Epoch: 11 cost time: 10.140724182128906
Epoch: 11, Steps: 264 Train Loss: 0.5288 (Forecasting Loss:0.2251 + XiCon Loss:3.0362 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5495717
	speed: 0.0398s/iter; left time: 930.9188s
	iters: 200, epoch: 12 | loss: 0.5220836
	speed: 0.0383s/iter; left time: 893.3436s
Epoch: 12 cost time: 10.263187170028687
Epoch: 12, Steps: 264 Train Loss: 0.5292 (Forecasting Loss:0.2252 + XiCon Loss:3.0404 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5186990
	speed: 0.0403s/iter; left time: 931.6582s
	iters: 200, epoch: 13 | loss: 0.5142147
	speed: 0.0373s/iter; left time: 860.1277s
Epoch: 13 cost time: 10.205796957015991
Epoch: 13, Steps: 264 Train Loss: 0.5289 (Forecasting Loss:0.2252 + XiCon Loss:3.0366 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5463869
	speed: 0.0392s/iter; left time: 897.1882s
	iters: 200, epoch: 14 | loss: 0.5235602
	speed: 0.0373s/iter; left time: 849.4012s
Epoch: 14 cost time: 10.049389839172363
Epoch: 14, Steps: 264 Train Loss: 0.5289 (Forecasting Loss:0.2251 + XiCon Loss:3.0372 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5352871
	speed: 0.0398s/iter; left time: 898.6717s
	iters: 200, epoch: 15 | loss: 0.5360419
	speed: 0.0379s/iter; left time: 853.5057s
Epoch: 15 cost time: 10.168766021728516
Epoch: 15, Steps: 264 Train Loss: 0.5290 (Forecasting Loss:0.2251 + XiCon Loss:3.0389 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5144864
	speed: 0.0397s/iter; left time: 888.0270s
	iters: 200, epoch: 16 | loss: 0.5286883
	speed: 0.0373s/iter; left time: 829.6035s
Epoch: 16 cost time: 10.106761455535889
Epoch: 16, Steps: 264 Train Loss: 0.5288 (Forecasting Loss:0.2251 + XiCon Loss:3.0371 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5333995
	speed: 0.0392s/iter; left time: 866.3388s
	iters: 200, epoch: 17 | loss: 0.5261844
	speed: 0.0371s/iter; left time: 815.7025s
Epoch: 17 cost time: 10.050230026245117
Epoch: 17, Steps: 264 Train Loss: 0.5293 (Forecasting Loss:0.2252 + XiCon Loss:3.0415 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5348822
	speed: 0.0397s/iter; left time: 865.2211s
	iters: 200, epoch: 18 | loss: 0.5197363
	speed: 0.0379s/iter; left time: 822.8076s
Epoch: 18 cost time: 10.189661741256714
Epoch: 18, Steps: 264 Train Loss: 0.5288 (Forecasting Loss:0.2252 + XiCon Loss:3.0364 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5186059
	speed: 0.0394s/iter; left time: 848.3550s
	iters: 200, epoch: 19 | loss: 0.5477858
	speed: 0.0380s/iter; left time: 815.1524s
Epoch: 19 cost time: 10.133548498153687
Epoch: 19, Steps: 264 Train Loss: 0.5289 (Forecasting Loss:0.2251 + XiCon Loss:3.0379 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5423356
	speed: 0.0391s/iter; left time: 831.2758s
	iters: 200, epoch: 20 | loss: 0.5233688
	speed: 0.0384s/iter; left time: 813.5111s
Epoch: 20 cost time: 10.163801431655884
Epoch: 20, Steps: 264 Train Loss: 0.5287 (Forecasting Loss:0.2252 + XiCon Loss:3.0355 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05494779348373413, mae:0.17471718788146973, mape:0.135943204164505, mspe:0.03316611051559448 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9582
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5568020
	speed: 0.0375s/iter; left time: 985.1310s
	iters: 200, epoch: 1 | loss: 0.5522731
	speed: 0.0341s/iter; left time: 893.8554s
Epoch: 1 cost time: 9.360126495361328
Epoch: 1, Steps: 264 Train Loss: 0.5642 (Forecasting Loss:0.2380 + XiCon Loss:3.2620 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1144
Validation loss decreased (inf --> 0.172402).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5759486
	speed: 0.0419s/iter; left time: 1091.8489s
	iters: 200, epoch: 2 | loss: 0.5246338
	speed: 0.0381s/iter; left time: 988.4944s
Epoch: 2 cost time: 10.45679521560669
Epoch: 2, Steps: 264 Train Loss: 0.5567 (Forecasting Loss:0.2416 + XiCon Loss:3.1502 x Lambda(0.1)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5102252
	speed: 0.0396s/iter; left time: 1020.5075s
	iters: 200, epoch: 3 | loss: 0.5566541
	speed: 0.0379s/iter; left time: 973.3289s
Epoch: 3 cost time: 10.20699667930603
Epoch: 3, Steps: 264 Train Loss: 0.5397 (Forecasting Loss:0.2341 + XiCon Loss:3.0560 x Lambda(0.1)), Vali MSE Loss: 0.1750 Test MSE Loss: 0.1156
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5296286
	speed: 0.0399s/iter; left time: 1018.2920s
	iters: 200, epoch: 4 | loss: 0.5611262
	speed: 0.0373s/iter; left time: 948.1953s
Epoch: 4 cost time: 10.185032367706299
Epoch: 4, Steps: 264 Train Loss: 0.5353 (Forecasting Loss:0.2310 + XiCon Loss:3.0426 x Lambda(0.1)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1131
Validation loss decreased (0.172402 --> 0.171055).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5409111
	speed: 0.0396s/iter; left time: 1000.7440s
	iters: 200, epoch: 5 | loss: 0.5529613
	speed: 0.0374s/iter; left time: 941.1264s
Epoch: 5 cost time: 10.10269546508789
Epoch: 5, Steps: 264 Train Loss: 0.5318 (Forecasting Loss:0.2284 + XiCon Loss:3.0344 x Lambda(0.1)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1136
Validation loss decreased (0.171055 --> 0.170966).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5404348
	speed: 0.0399s/iter; left time: 995.5029s
	iters: 200, epoch: 6 | loss: 0.5307964
	speed: 0.0380s/iter; left time: 945.7629s
Epoch: 6 cost time: 10.190131187438965
Epoch: 6, Steps: 264 Train Loss: 0.5307 (Forecasting Loss:0.2274 + XiCon Loss:3.0330 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
Validation loss decreased (0.170966 --> 0.170228).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5208184
	speed: 0.0406s/iter; left time: 1004.7294s
	iters: 200, epoch: 7 | loss: 0.5439299
	speed: 0.0382s/iter; left time: 939.5831s
Epoch: 7 cost time: 10.313724994659424
Epoch: 7, Steps: 264 Train Loss: 0.5300 (Forecasting Loss:0.2268 + XiCon Loss:3.0326 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170228 --> 0.169984).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5261214
	speed: 0.0395s/iter; left time: 966.6406s
	iters: 200, epoch: 8 | loss: 0.5357912
	speed: 0.0379s/iter; left time: 924.0818s
Epoch: 8 cost time: 10.146233081817627
Epoch: 8, Steps: 264 Train Loss: 0.5296 (Forecasting Loss:0.2263 + XiCon Loss:3.0326 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1127
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5321429
	speed: 0.0398s/iter; left time: 961.8897s
	iters: 200, epoch: 9 | loss: 0.4993329
	speed: 0.0384s/iter; left time: 924.3078s
Epoch: 9 cost time: 10.244679927825928
Epoch: 9, Steps: 264 Train Loss: 0.5293 (Forecasting Loss:0.2265 + XiCon Loss:3.0287 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5222008
	speed: 0.0398s/iter; left time: 951.3205s
	iters: 200, epoch: 10 | loss: 0.5465917
	speed: 0.0374s/iter; left time: 891.4047s
Epoch: 10 cost time: 10.090221643447876
Epoch: 10, Steps: 264 Train Loss: 0.5293 (Forecasting Loss:0.2264 + XiCon Loss:3.0297 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5244272
	speed: 0.0399s/iter; left time: 944.5870s
	iters: 200, epoch: 11 | loss: 0.5235180
	speed: 0.0370s/iter; left time: 872.1579s
Epoch: 11 cost time: 10.088544845581055
Epoch: 11, Steps: 264 Train Loss: 0.5293 (Forecasting Loss:0.2263 + XiCon Loss:3.0306 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5404915
	speed: 0.0400s/iter; left time: 935.2305s
	iters: 200, epoch: 12 | loss: 0.5121555
	speed: 0.0378s/iter; left time: 881.6593s
Epoch: 12 cost time: 10.229077339172363
Epoch: 12, Steps: 264 Train Loss: 0.5294 (Forecasting Loss:0.2262 + XiCon Loss:3.0315 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1122
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5212382
	speed: 0.0396s/iter; left time: 915.9152s
	iters: 200, epoch: 13 | loss: 0.5251474
	speed: 0.0375s/iter; left time: 863.5380s
Epoch: 13 cost time: 10.18295407295227
Epoch: 13, Steps: 264 Train Loss: 0.5291 (Forecasting Loss:0.2262 + XiCon Loss:3.0291 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1122
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5157081
	speed: 0.0398s/iter; left time: 910.5733s
	iters: 200, epoch: 14 | loss: 0.5328754
	speed: 0.0382s/iter; left time: 869.8478s
Epoch: 14 cost time: 10.254898309707642
Epoch: 14, Steps: 264 Train Loss: 0.5293 (Forecasting Loss:0.2261 + XiCon Loss:3.0317 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1122
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5442660
	speed: 0.0395s/iter; left time: 892.6059s
	iters: 200, epoch: 15 | loss: 0.5297012
	speed: 0.0365s/iter; left time: 820.3444s
Epoch: 15 cost time: 10.042566537857056
Epoch: 15, Steps: 264 Train Loss: 0.5291 (Forecasting Loss:0.2262 + XiCon Loss:3.0293 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1122
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5258875
	speed: 0.0397s/iter; left time: 886.4942s
	iters: 200, epoch: 16 | loss: 0.5185623
	speed: 0.0379s/iter; left time: 842.7505s
Epoch: 16 cost time: 10.223576307296753
Epoch: 16, Steps: 264 Train Loss: 0.5295 (Forecasting Loss:0.2261 + XiCon Loss:3.0336 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1122
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5108005
	speed: 0.0397s/iter; left time: 876.3166s
	iters: 200, epoch: 17 | loss: 0.5560365
	speed: 0.0370s/iter; left time: 812.7724s
Epoch: 17 cost time: 10.087602138519287
Epoch: 17, Steps: 264 Train Loss: 0.5289 (Forecasting Loss:0.2261 + XiCon Loss:3.0281 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1122
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.052488841116428375, mae:0.1724279373884201, mape:0.13474686443805695, mspe:0.03242446482181549 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1635
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5868602
	speed: 0.0377s/iter; left time: 990.4120s
	iters: 200, epoch: 1 | loss: 0.5643753
	speed: 0.0343s/iter; left time: 897.8627s
Epoch: 1 cost time: 9.428393125534058
Epoch: 1, Steps: 264 Train Loss: 0.5596 (Forecasting Loss:0.2364 + XiCon Loss:3.2319 x Lambda(0.1)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1175
Validation loss decreased (inf --> 0.177404).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5642858
	speed: 0.0404s/iter; left time: 1051.6777s
	iters: 200, epoch: 2 | loss: 0.5517137
	speed: 0.0388s/iter; left time: 1007.3739s
Epoch: 2 cost time: 10.372556686401367
Epoch: 2, Steps: 264 Train Loss: 0.5632 (Forecasting Loss:0.2413 + XiCon Loss:3.2192 x Lambda(0.1)), Vali MSE Loss: 0.1773 Test MSE Loss: 0.1166
Validation loss decreased (0.177404 --> 0.177264).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5522028
	speed: 0.0396s/iter; left time: 1021.0933s
	iters: 200, epoch: 3 | loss: 0.5725269
	speed: 0.0381s/iter; left time: 977.9939s
Epoch: 3 cost time: 10.116214752197266
Epoch: 3, Steps: 264 Train Loss: 0.5481 (Forecasting Loss:0.2337 + XiCon Loss:3.1444 x Lambda(0.1)), Vali MSE Loss: 0.1762 Test MSE Loss: 0.1168
Validation loss decreased (0.177264 --> 0.176219).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5442468
	speed: 0.0404s/iter; left time: 1031.7322s
	iters: 200, epoch: 4 | loss: 0.5424339
	speed: 0.0375s/iter; left time: 953.2379s
Epoch: 4 cost time: 10.220184564590454
Epoch: 4, Steps: 264 Train Loss: 0.5426 (Forecasting Loss:0.2302 + XiCon Loss:3.1244 x Lambda(0.1)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1132
Validation loss decreased (0.176219 --> 0.171399).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5417793
	speed: 0.0399s/iter; left time: 1006.2738s
	iters: 200, epoch: 5 | loss: 0.5263857
	speed: 0.0376s/iter; left time: 945.0121s
Epoch: 5 cost time: 10.134273529052734
Epoch: 5, Steps: 264 Train Loss: 0.5413 (Forecasting Loss:0.2283 + XiCon Loss:3.1297 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1125
Validation loss decreased (0.171399 --> 0.170511).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5314903
	speed: 0.0399s/iter; left time: 996.6527s
	iters: 200, epoch: 6 | loss: 0.5466236
	speed: 0.0382s/iter; left time: 951.0896s
Epoch: 6 cost time: 10.233376502990723
Epoch: 6, Steps: 264 Train Loss: 0.5393 (Forecasting Loss:0.2274 + XiCon Loss:3.1186 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5589966
	speed: 0.0399s/iter; left time: 986.5819s
	iters: 200, epoch: 7 | loss: 0.5360777
	speed: 0.0371s/iter; left time: 914.5059s
Epoch: 7 cost time: 10.113402366638184
Epoch: 7, Steps: 264 Train Loss: 0.5384 (Forecasting Loss:0.2268 + XiCon Loss:3.1152 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1128
Validation loss decreased (0.170511 --> 0.170318).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5240847
	speed: 0.0403s/iter; left time: 985.6010s
	iters: 200, epoch: 8 | loss: 0.5294652
	speed: 0.0384s/iter; left time: 935.9752s
Epoch: 8 cost time: 10.328675508499146
Epoch: 8, Steps: 264 Train Loss: 0.5379 (Forecasting Loss:0.2263 + XiCon Loss:3.1157 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170318 --> 0.169996).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5683471
	speed: 0.0399s/iter; left time: 964.5223s
	iters: 200, epoch: 9 | loss: 0.5463697
	speed: 0.0374s/iter; left time: 901.4743s
Epoch: 9 cost time: 10.222185850143433
Epoch: 9, Steps: 264 Train Loss: 0.5372 (Forecasting Loss:0.2261 + XiCon Loss:3.1110 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5181681
	speed: 0.0399s/iter; left time: 954.9925s
	iters: 200, epoch: 10 | loss: 0.5478349
	speed: 0.0382s/iter; left time: 909.2986s
Epoch: 10 cost time: 10.292934894561768
Epoch: 10, Steps: 264 Train Loss: 0.5376 (Forecasting Loss:0.2261 + XiCon Loss:3.1149 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169996 --> 0.169890).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5416867
	speed: 0.0401s/iter; left time: 947.6549s
	iters: 200, epoch: 11 | loss: 0.5293478
	speed: 0.0385s/iter; left time: 906.3478s
Epoch: 11 cost time: 10.259742021560669
Epoch: 11, Steps: 264 Train Loss: 0.5374 (Forecasting Loss:0.2259 + XiCon Loss:3.1150 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169890 --> 0.169873).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5445104
	speed: 0.0406s/iter; left time: 951.0099s
	iters: 200, epoch: 12 | loss: 0.5526088
	speed: 0.0377s/iter; left time: 877.6837s
Epoch: 12 cost time: 10.295477151870728
Epoch: 12, Steps: 264 Train Loss: 0.5372 (Forecasting Loss:0.2260 + XiCon Loss:3.1123 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5280520
	speed: 0.0404s/iter; left time: 933.9502s
	iters: 200, epoch: 13 | loss: 0.5312004
	speed: 0.0378s/iter; left time: 870.3170s
Epoch: 13 cost time: 10.28926968574524
Epoch: 13, Steps: 264 Train Loss: 0.5372 (Forecasting Loss:0.2259 + XiCon Loss:3.1123 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5306565
	speed: 0.0407s/iter; left time: 930.7681s
	iters: 200, epoch: 14 | loss: 0.5415725
	speed: 0.0372s/iter; left time: 846.9355s
Epoch: 14 cost time: 10.29950737953186
Epoch: 14, Steps: 264 Train Loss: 0.5370 (Forecasting Loss:0.2259 + XiCon Loss:3.1110 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4933859
	speed: 0.0411s/iter; left time: 928.9573s
	iters: 200, epoch: 15 | loss: 0.5255920
	speed: 0.0389s/iter; left time: 874.5496s
Epoch: 15 cost time: 10.416674852371216
Epoch: 15, Steps: 264 Train Loss: 0.5375 (Forecasting Loss:0.2259 + XiCon Loss:3.1155 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5452054
	speed: 0.0401s/iter; left time: 895.6530s
	iters: 200, epoch: 16 | loss: 0.5301046
	speed: 0.0373s/iter; left time: 830.4088s
Epoch: 16 cost time: 10.176878690719604
Epoch: 16, Steps: 264 Train Loss: 0.5376 (Forecasting Loss:0.2258 + XiCon Loss:3.1179 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5213627
	speed: 0.0407s/iter; left time: 897.5830s
	iters: 200, epoch: 17 | loss: 0.5262153
	speed: 0.0381s/iter; left time: 836.8185s
Epoch: 17 cost time: 10.339797019958496
Epoch: 17, Steps: 264 Train Loss: 0.5371 (Forecasting Loss:0.2260 + XiCon Loss:3.1116 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5289389
	speed: 0.0399s/iter; left time: 870.9859s
	iters: 200, epoch: 18 | loss: 0.5350960
	speed: 0.0386s/iter; left time: 837.3167s
Epoch: 18 cost time: 10.31463623046875
Epoch: 18, Steps: 264 Train Loss: 0.5372 (Forecasting Loss:0.2259 + XiCon Loss:3.1124 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5530916
	speed: 0.0400s/iter; left time: 861.3268s
	iters: 200, epoch: 19 | loss: 0.5395943
	speed: 0.0383s/iter; left time: 821.4114s
Epoch: 19 cost time: 10.283786058425903
Epoch: 19, Steps: 264 Train Loss: 0.5368 (Forecasting Loss:0.2259 + XiCon Loss:3.1091 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5570087
	speed: 0.0405s/iter; left time: 861.2396s
	iters: 200, epoch: 20 | loss: 0.5391505
	speed: 0.0371s/iter; left time: 785.3734s
Epoch: 20 cost time: 10.13864016532898
Epoch: 20, Steps: 264 Train Loss: 0.5375 (Forecasting Loss:0.2259 + XiCon Loss:3.1152 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1125
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5587384
	speed: 0.0404s/iter; left time: 849.5288s
	iters: 200, epoch: 21 | loss: 0.5455439
	speed: 0.0370s/iter; left time: 774.9015s
Epoch: 21 cost time: 10.175949096679688
Epoch: 21, Steps: 264 Train Loss: 0.5374 (Forecasting Loss:0.2259 + XiCon Loss:3.1148 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05250794440507889, mae:0.17233838140964508, mape:0.13447216153144836, mspe:0.03220266476273537 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.2593
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5710555
	speed: 0.0380s/iter; left time: 999.4978s
	iters: 200, epoch: 1 | loss: 0.5540891
	speed: 0.0342s/iter; left time: 896.7118s
Epoch: 1 cost time: 9.471487045288086
Epoch: 1, Steps: 264 Train Loss: 0.5642 (Forecasting Loss:0.2382 + XiCon Loss:3.2602 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1137
Validation loss decreased (inf --> 0.173538).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5876561
	speed: 0.0429s/iter; left time: 1116.4640s
	iters: 200, epoch: 2 | loss: 0.5507370
	speed: 0.0383s/iter; left time: 994.3803s
Epoch: 2 cost time: 10.525815725326538
Epoch: 2, Steps: 264 Train Loss: 0.5600 (Forecasting Loss:0.2426 + XiCon Loss:3.1739 x Lambda(0.1)), Vali MSE Loss: 0.1759 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5524737
	speed: 0.0402s/iter; left time: 1034.8916s
	iters: 200, epoch: 3 | loss: 0.5196988
	speed: 0.0385s/iter; left time: 987.9427s
Epoch: 3 cost time: 10.318603992462158
Epoch: 3, Steps: 264 Train Loss: 0.5427 (Forecasting Loss:0.2333 + XiCon Loss:3.0945 x Lambda(0.1)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5356365
	speed: 0.0392s/iter; left time: 999.6457s
	iters: 200, epoch: 4 | loss: 0.5586854
	speed: 0.0371s/iter; left time: 942.8583s
Epoch: 4 cost time: 10.036908149719238
Epoch: 4, Steps: 264 Train Loss: 0.5346 (Forecasting Loss:0.2302 + XiCon Loss:3.0441 x Lambda(0.1)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5162916
	speed: 0.0402s/iter; left time: 1015.8440s
	iters: 200, epoch: 5 | loss: 0.5171106
	speed: 0.0370s/iter; left time: 929.3757s
Epoch: 5 cost time: 10.18561577796936
Epoch: 5, Steps: 264 Train Loss: 0.5303 (Forecasting Loss:0.2271 + XiCon Loss:3.0318 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1170
Validation loss decreased (0.173538 --> 0.170566).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5131599
	speed: 0.0403s/iter; left time: 1007.1724s
	iters: 200, epoch: 6 | loss: 0.5418586
	speed: 0.0376s/iter; left time: 934.6546s
Epoch: 6 cost time: 10.25842833518982
Epoch: 6, Steps: 264 Train Loss: 0.5277 (Forecasting Loss:0.2253 + XiCon Loss:3.0238 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5336419
	speed: 0.0399s/iter; left time: 986.3071s
	iters: 200, epoch: 7 | loss: 0.5061763
	speed: 0.0379s/iter; left time: 931.8885s
Epoch: 7 cost time: 10.262797117233276
Epoch: 7, Steps: 264 Train Loss: 0.5268 (Forecasting Loss:0.2247 + XiCon Loss:3.0213 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5076824
	speed: 0.0394s/iter; left time: 964.2788s
	iters: 200, epoch: 8 | loss: 0.5291885
	speed: 0.0373s/iter; left time: 908.4440s
Epoch: 8 cost time: 10.05257534980774
Epoch: 8, Steps: 264 Train Loss: 0.5259 (Forecasting Loss:0.2240 + XiCon Loss:3.0198 x Lambda(0.1)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1168
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5179472
	speed: 0.0395s/iter; left time: 954.4282s
	iters: 200, epoch: 9 | loss: 0.5062891
	speed: 0.0383s/iter; left time: 922.2686s
Epoch: 9 cost time: 10.170090913772583
Epoch: 9, Steps: 264 Train Loss: 0.5254 (Forecasting Loss:0.2237 + XiCon Loss:3.0170 x Lambda(0.1)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1171
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5065646
	speed: 0.0402s/iter; left time: 960.6421s
	iters: 200, epoch: 10 | loss: 0.5422888
	speed: 0.0376s/iter; left time: 896.8521s
Epoch: 10 cost time: 10.194669961929321
Epoch: 10, Steps: 264 Train Loss: 0.5247 (Forecasting Loss:0.2235 + XiCon Loss:3.0126 x Lambda(0.1)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1172
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5085496
	speed: 0.0400s/iter; left time: 945.7510s
	iters: 200, epoch: 11 | loss: 0.5028837
	speed: 0.0380s/iter; left time: 896.1085s
Epoch: 11 cost time: 10.237092733383179
Epoch: 11, Steps: 264 Train Loss: 0.5252 (Forecasting Loss:0.2235 + XiCon Loss:3.0175 x Lambda(0.1)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1171
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5111765
	speed: 0.0390s/iter; left time: 912.0701s
	iters: 200, epoch: 12 | loss: 0.5112394
	speed: 0.0373s/iter; left time: 868.1308s
Epoch: 12 cost time: 10.090456247329712
Epoch: 12, Steps: 264 Train Loss: 0.5253 (Forecasting Loss:0.2234 + XiCon Loss:3.0190 x Lambda(0.1)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1171
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5471487
	speed: 0.0404s/iter; left time: 934.0431s
	iters: 200, epoch: 13 | loss: 0.5318265
	speed: 0.0373s/iter; left time: 859.4413s
Epoch: 13 cost time: 10.20706057548523
Epoch: 13, Steps: 264 Train Loss: 0.5251 (Forecasting Loss:0.2234 + XiCon Loss:3.0176 x Lambda(0.1)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1171
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5191117
	speed: 0.0403s/iter; left time: 922.4737s
	iters: 200, epoch: 14 | loss: 0.5238572
	speed: 0.0369s/iter; left time: 840.5808s
Epoch: 14 cost time: 10.156020164489746
Epoch: 14, Steps: 264 Train Loss: 0.5250 (Forecasting Loss:0.2234 + XiCon Loss:3.0166 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1171
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5180951
	speed: 0.0401s/iter; left time: 907.5133s
	iters: 200, epoch: 15 | loss: 0.5183359
	speed: 0.0374s/iter; left time: 841.9122s
Epoch: 15 cost time: 10.164732933044434
Epoch: 15, Steps: 264 Train Loss: 0.5251 (Forecasting Loss:0.2234 + XiCon Loss:3.0168 x Lambda(0.1)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1171
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.0567096583545208, mae:0.17731283605098724, mape:0.1397332400083542, mspe:0.03651993349194527 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.7631
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6005495
	speed: 0.0383s/iter; left time: 1006.2041s
	iters: 200, epoch: 1 | loss: 0.5358295
	speed: 0.0352s/iter; left time: 922.7445s
Epoch: 1 cost time: 9.608375072479248
Epoch: 1, Steps: 264 Train Loss: 0.5647 (Forecasting Loss:0.2382 + XiCon Loss:3.2652 x Lambda(0.1)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1142
Validation loss decreased (inf --> 0.171888).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6172869
	speed: 0.0410s/iter; left time: 1066.9139s
	iters: 200, epoch: 2 | loss: 0.5514774
	speed: 0.0372s/iter; left time: 963.6084s
Epoch: 2 cost time: 10.252387762069702
Epoch: 2, Steps: 264 Train Loss: 0.5633 (Forecasting Loss:0.2411 + XiCon Loss:3.2221 x Lambda(0.1)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1182
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5327128
	speed: 0.0408s/iter; left time: 1051.0946s
	iters: 200, epoch: 3 | loss: 0.5540801
	speed: 0.0393s/iter; left time: 1008.0499s
Epoch: 3 cost time: 10.5429527759552
Epoch: 3, Steps: 264 Train Loss: 0.5501 (Forecasting Loss:0.2330 + XiCon Loss:3.1707 x Lambda(0.1)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1164
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5236993
	speed: 0.0403s/iter; left time: 1027.1865s
	iters: 200, epoch: 4 | loss: 0.5727029
	speed: 0.0381s/iter; left time: 968.1374s
Epoch: 4 cost time: 10.297015190124512
Epoch: 4, Steps: 264 Train Loss: 0.5453 (Forecasting Loss:0.2289 + XiCon Loss:3.1635 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1161
Validation loss decreased (0.171888 --> 0.165790).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5169663
	speed: 0.0403s/iter; left time: 1017.2284s
	iters: 200, epoch: 5 | loss: 0.5361854
	speed: 0.0373s/iter; left time: 938.0342s
Epoch: 5 cost time: 10.200627326965332
Epoch: 5, Steps: 264 Train Loss: 0.5384 (Forecasting Loss:0.2233 + XiCon Loss:3.1506 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1218
Validation loss decreased (0.165790 --> 0.164188).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5724496
	speed: 0.0403s/iter; left time: 1005.7444s
	iters: 200, epoch: 6 | loss: 0.5418380
	speed: 0.0372s/iter; left time: 924.3433s
Epoch: 6 cost time: 10.128309965133667
Epoch: 6, Steps: 264 Train Loss: 0.5364 (Forecasting Loss:0.2204 + XiCon Loss:3.1597 x Lambda(0.1)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1231
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5217232
	speed: 0.0398s/iter; left time: 984.6559s
	iters: 200, epoch: 7 | loss: 0.4983743
	speed: 0.0379s/iter; left time: 933.3765s
Epoch: 7 cost time: 10.200844049453735
Epoch: 7, Steps: 264 Train Loss: 0.5345 (Forecasting Loss:0.2194 + XiCon Loss:3.1515 x Lambda(0.1)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5632665
	speed: 0.0389s/iter; left time: 950.3728s
	iters: 200, epoch: 8 | loss: 0.5379974
	speed: 0.0378s/iter; left time: 920.2444s
Epoch: 8 cost time: 10.110180854797363
Epoch: 8, Steps: 264 Train Loss: 0.5335 (Forecasting Loss:0.2186 + XiCon Loss:3.1490 x Lambda(0.1)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1240
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5264645
	speed: 0.0405s/iter; left time: 979.3507s
	iters: 200, epoch: 9 | loss: 0.5304582
	speed: 0.0384s/iter; left time: 923.8960s
Epoch: 9 cost time: 10.369544506072998
Epoch: 9, Steps: 264 Train Loss: 0.5329 (Forecasting Loss:0.2180 + XiCon Loss:3.1481 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1252
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5524623
	speed: 0.0403s/iter; left time: 963.1312s
	iters: 200, epoch: 10 | loss: 0.5374193
	speed: 0.0378s/iter; left time: 900.2379s
Epoch: 10 cost time: 10.226205348968506
Epoch: 10, Steps: 264 Train Loss: 0.5330 (Forecasting Loss:0.2178 + XiCon Loss:3.1523 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1258
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5702736
	speed: 0.0400s/iter; left time: 945.7817s
	iters: 200, epoch: 11 | loss: 0.5405552
	speed: 0.0371s/iter; left time: 874.2399s
Epoch: 11 cost time: 10.138333082199097
Epoch: 11, Steps: 264 Train Loss: 0.5327 (Forecasting Loss:0.2176 + XiCon Loss:3.1508 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1255
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5440530
	speed: 0.0406s/iter; left time: 949.8006s
	iters: 200, epoch: 12 | loss: 0.5345515
	speed: 0.0372s/iter; left time: 867.3340s
Epoch: 12 cost time: 10.25818157196045
Epoch: 12, Steps: 264 Train Loss: 0.5329 (Forecasting Loss:0.2175 + XiCon Loss:3.1536 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1257
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5322998
	speed: 0.0393s/iter; left time: 910.0055s
	iters: 200, epoch: 13 | loss: 0.5372447
	speed: 0.0369s/iter; left time: 850.8736s
Epoch: 13 cost time: 10.091246366500854
Epoch: 13, Steps: 264 Train Loss: 0.5326 (Forecasting Loss:0.2178 + XiCon Loss:3.1477 x Lambda(0.1)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1256
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5615625
	speed: 0.0399s/iter; left time: 911.4483s
	iters: 200, epoch: 14 | loss: 0.5256422
	speed: 0.0372s/iter; left time: 846.8899s
Epoch: 14 cost time: 10.13204836845398
Epoch: 14, Steps: 264 Train Loss: 0.5332 (Forecasting Loss:0.2177 + XiCon Loss:3.1546 x Lambda(0.1)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1257
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5206528
	speed: 0.0400s/iter; left time: 903.0992s
	iters: 200, epoch: 15 | loss: 0.5296883
	speed: 0.0378s/iter; left time: 851.6874s
Epoch: 15 cost time: 10.124846935272217
Epoch: 15, Steps: 264 Train Loss: 0.5325 (Forecasting Loss:0.2178 + XiCon Loss:3.1469 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1257
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05839373543858528, mae:0.18510937690734863, mape:0.14503103494644165, mspe:0.03717528283596039 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0550+-0.00322, MAE:0.1764+-0.00656, MAPE:0.1380+-0.00554, MSPE:0.0343+-0.00294, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.7685
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.2084541
	speed: 0.0401s/iter; left time: 1042.8203s
	iters: 200, epoch: 1 | loss: 33.8580208
	speed: 0.0349s/iter; left time: 903.5114s
Epoch: 1 cost time: 9.633122205734253
Epoch: 1, Steps: 261 Train Loss: 34.0008 (Forecasting Loss:0.2771 + XiCon Loss:3.3724 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
Validation loss decreased (inf --> 0.200729).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.9674950
	speed: 0.0415s/iter; left time: 1067.4703s
	iters: 200, epoch: 2 | loss: 31.4901180
	speed: 0.0403s/iter; left time: 1033.8517s
Epoch: 2 cost time: 10.572286128997803
Epoch: 2, Steps: 261 Train Loss: 31.3524 (Forecasting Loss:0.2752 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1425
Validation loss decreased (0.200729 --> 0.199938).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8635216
	speed: 0.0416s/iter; left time: 1059.7201s
	iters: 200, epoch: 3 | loss: 30.6614132
	speed: 0.0393s/iter; left time: 998.1500s
Epoch: 3 cost time: 10.49842357635498
Epoch: 3, Steps: 261 Train Loss: 30.6503 (Forecasting Loss:0.2690 + XiCon Loss:3.0381 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.3118153
	speed: 0.0415s/iter; left time: 1045.8863s
	iters: 200, epoch: 4 | loss: 30.4278545
	speed: 0.0393s/iter; left time: 987.2622s
Epoch: 4 cost time: 10.452724695205688
Epoch: 4, Steps: 261 Train Loss: 30.4869 (Forecasting Loss:0.2665 + XiCon Loss:3.0220 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1470
Validation loss decreased (0.199938 --> 0.199114).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5285339
	speed: 0.0420s/iter; left time: 1048.6015s
	iters: 200, epoch: 5 | loss: 30.3843403
	speed: 0.0394s/iter; left time: 979.7575s
Epoch: 5 cost time: 10.579400062561035
Epoch: 5, Steps: 261 Train Loss: 30.3917 (Forecasting Loss:0.2653 + XiCon Loss:3.0126 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1466
Validation loss decreased (0.199114 --> 0.198827).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5489807
	speed: 0.0420s/iter; left time: 1036.8376s
	iters: 200, epoch: 6 | loss: 30.3395519
	speed: 0.0396s/iter; left time: 973.8499s
Epoch: 6 cost time: 10.648649215698242
Epoch: 6, Steps: 261 Train Loss: 30.3682 (Forecasting Loss:0.2643 + XiCon Loss:3.0104 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1445
Validation loss decreased (0.198827 --> 0.198477).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1595898
	speed: 0.0422s/iter; left time: 1031.9291s
	iters: 200, epoch: 7 | loss: 30.5570793
	speed: 0.0401s/iter; left time: 975.1420s
Epoch: 7 cost time: 10.69664478302002
Epoch: 7, Steps: 261 Train Loss: 30.3302 (Forecasting Loss:0.2642 + XiCon Loss:3.0066 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1450
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4029484
	speed: 0.0419s/iter; left time: 1013.0652s
	iters: 200, epoch: 8 | loss: 30.0697594
	speed: 0.0405s/iter; left time: 974.7768s
Epoch: 8 cost time: 10.697428941726685
Epoch: 8, Steps: 261 Train Loss: 30.3422 (Forecasting Loss:0.2640 + XiCon Loss:3.0078 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1444
Validation loss decreased (0.198477 --> 0.198264).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5594139
	speed: 0.0432s/iter; left time: 1032.1089s
	iters: 200, epoch: 9 | loss: 30.4512253
	speed: 0.0397s/iter; left time: 944.9531s
Epoch: 9 cost time: 10.767717838287354
Epoch: 9, Steps: 261 Train Loss: 30.3337 (Forecasting Loss:0.2638 + XiCon Loss:3.0070 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1451
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3983631
	speed: 0.0424s/iter; left time: 1002.4044s
	iters: 200, epoch: 10 | loss: 30.5466328
	speed: 0.0403s/iter; left time: 948.7210s
Epoch: 10 cost time: 10.72493028640747
Epoch: 10, Steps: 261 Train Loss: 30.3174 (Forecasting Loss:0.2637 + XiCon Loss:3.0054 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1452
Validation loss decreased (0.198264 --> 0.198244).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3722839
	speed: 0.0426s/iter; left time: 996.6180s
	iters: 200, epoch: 11 | loss: 30.0707550
	speed: 0.0399s/iter; left time: 930.4098s
Epoch: 11 cost time: 10.734469413757324
Epoch: 11, Steps: 261 Train Loss: 30.3265 (Forecasting Loss:0.2636 + XiCon Loss:3.0063 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1449
Validation loss decreased (0.198244 --> 0.198157).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4314766
	speed: 0.0422s/iter; left time: 976.8479s
	iters: 200, epoch: 12 | loss: 30.5937462
	speed: 0.0405s/iter; left time: 932.6929s
Epoch: 12 cost time: 10.808090448379517
Epoch: 12, Steps: 261 Train Loss: 30.3389 (Forecasting Loss:0.2637 + XiCon Loss:3.0075 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1451
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7363148
	speed: 0.0429s/iter; left time: 981.6601s
	iters: 200, epoch: 13 | loss: 30.1028461
	speed: 0.0408s/iter; left time: 929.2841s
Epoch: 13 cost time: 10.84079360961914
Epoch: 13, Steps: 261 Train Loss: 30.3325 (Forecasting Loss:0.2638 + XiCon Loss:3.0069 x Lambda(10.0)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1450
Validation loss decreased (0.198157 --> 0.198091).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5501366
	speed: 0.0415s/iter; left time: 938.2362s
	iters: 200, epoch: 14 | loss: 30.3241196
	speed: 0.0403s/iter; left time: 906.5238s
Epoch: 14 cost time: 10.66029143333435
Epoch: 14, Steps: 261 Train Loss: 30.3222 (Forecasting Loss:0.2636 + XiCon Loss:3.0059 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1450
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2656593
	speed: 0.0426s/iter; left time: 951.3572s
	iters: 200, epoch: 15 | loss: 30.2373486
	speed: 0.0402s/iter; left time: 893.2279s
Epoch: 15 cost time: 10.72494888305664
Epoch: 15, Steps: 261 Train Loss: 30.3071 (Forecasting Loss:0.2638 + XiCon Loss:3.0043 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1073685
	speed: 0.0425s/iter; left time: 938.2021s
	iters: 200, epoch: 16 | loss: 30.3469353
	speed: 0.0397s/iter; left time: 873.8645s
Epoch: 16 cost time: 10.6999990940094
Epoch: 16, Steps: 261 Train Loss: 30.3259 (Forecasting Loss:0.2636 + XiCon Loss:3.0062 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.2048359
	speed: 0.0423s/iter; left time: 922.9218s
	iters: 200, epoch: 17 | loss: 30.3824596
	speed: 0.0402s/iter; left time: 873.7781s
Epoch: 17 cost time: 10.758017778396606
Epoch: 17, Steps: 261 Train Loss: 30.3469 (Forecasting Loss:0.2638 + XiCon Loss:3.0083 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.5717316
	speed: 0.0419s/iter; left time: 903.9224s
	iters: 200, epoch: 18 | loss: 30.4541302
	speed: 0.0405s/iter; left time: 868.4769s
Epoch: 18 cost time: 10.739640474319458
Epoch: 18, Steps: 261 Train Loss: 30.3404 (Forecasting Loss:0.2637 + XiCon Loss:3.0077 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1450
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4861584
	speed: 0.0423s/iter; left time: 901.3063s
	iters: 200, epoch: 19 | loss: 30.3497448
	speed: 0.0398s/iter; left time: 844.6271s
Epoch: 19 cost time: 10.683189392089844
Epoch: 19, Steps: 261 Train Loss: 30.3435 (Forecasting Loss:0.2637 + XiCon Loss:3.0080 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5394249
	speed: 0.0421s/iter; left time: 886.7150s
	iters: 200, epoch: 20 | loss: 30.7110844
	speed: 0.0409s/iter; left time: 855.6024s
Epoch: 20 cost time: 10.741020441055298
Epoch: 20, Steps: 261 Train Loss: 30.3399 (Forecasting Loss:0.2637 + XiCon Loss:3.0076 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1450
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.4694157
	speed: 0.0428s/iter; left time: 888.9089s
	iters: 200, epoch: 21 | loss: 30.1602669
	speed: 0.0400s/iter; left time: 826.7368s
Epoch: 21 cost time: 10.778306722640991
Epoch: 21, Steps: 261 Train Loss: 30.3284 (Forecasting Loss:0.2638 + XiCon Loss:3.0065 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.4354992
	speed: 0.0427s/iter; left time: 877.0682s
	iters: 200, epoch: 22 | loss: 30.5761299
	speed: 0.0404s/iter; left time: 824.9356s
Epoch: 22 cost time: 10.742093801498413
Epoch: 22, Steps: 261 Train Loss: 30.3187 (Forecasting Loss:0.2636 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1450
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.7019501
	speed: 0.0422s/iter; left time: 854.1416s
	iters: 200, epoch: 23 | loss: 30.6455498
	speed: 0.0403s/iter; left time: 811.6235s
Epoch: 23 cost time: 10.676501512527466
Epoch: 23, Steps: 261 Train Loss: 30.3433 (Forecasting Loss:0.2636 + XiCon Loss:3.0080 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1450
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07940725237131119, mae:0.21063266694545746, mape:0.15746259689331055, mspe:0.04179280251264572 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6587
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 33.7513885
	speed: 0.0341s/iter; left time: 885.4986s
	iters: 200, epoch: 1 | loss: 33.6786079
	speed: 0.0303s/iter; left time: 785.3525s
Epoch: 1 cost time: 8.266893863677979
Epoch: 1, Steps: 261 Train Loss: 33.8129 (Forecasting Loss:0.2758 + XiCon Loss:3.3537 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1411
Validation loss decreased (inf --> 0.197625).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.6098404
	speed: 0.0368s/iter; left time: 948.2474s
	iters: 200, epoch: 2 | loss: 31.5315247
	speed: 0.0343s/iter; left time: 879.2878s
Epoch: 2 cost time: 9.217761993408203
Epoch: 2, Steps: 261 Train Loss: 31.6258 (Forecasting Loss:0.2747 + XiCon Loss:3.1351 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1419
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5010052
	speed: 0.0369s/iter; left time: 940.9576s
	iters: 200, epoch: 3 | loss: 29.4940434
	speed: 0.0335s/iter; left time: 849.0544s
Epoch: 3 cost time: 9.139206171035767
Epoch: 3, Steps: 261 Train Loss: 30.2372 (Forecasting Loss:0.2696 + XiCon Loss:2.9968 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1404
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.5540009
	speed: 0.0378s/iter; left time: 952.0300s
	iters: 200, epoch: 4 | loss: 30.0087452
	speed: 0.0343s/iter; left time: 862.6808s
Epoch: 4 cost time: 9.299968242645264
Epoch: 4, Steps: 261 Train Loss: 29.7559 (Forecasting Loss:0.2670 + XiCon Loss:2.9489 x Lambda(10.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1392
Validation loss decreased (0.197625 --> 0.196401).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8274879
	speed: 0.0376s/iter; left time: 937.5439s
	iters: 200, epoch: 5 | loss: 29.7726460
	speed: 0.0345s/iter; left time: 858.4562s
Epoch: 5 cost time: 9.314066410064697
Epoch: 5, Steps: 261 Train Loss: 29.8261 (Forecasting Loss:0.2660 + XiCon Loss:2.9560 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1398
Validation loss decreased (0.196401 --> 0.196223).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6468658
	speed: 0.0378s/iter; left time: 933.3994s
	iters: 200, epoch: 6 | loss: 30.1041298
	speed: 0.0350s/iter; left time: 859.7845s
Epoch: 6 cost time: 9.389198541641235
Epoch: 6, Steps: 261 Train Loss: 29.7548 (Forecasting Loss:0.2652 + XiCon Loss:2.9490 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1395
Validation loss decreased (0.196223 --> 0.195869).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9630413
	speed: 0.0368s/iter; left time: 898.0094s
	iters: 200, epoch: 7 | loss: 30.0721664
	speed: 0.0342s/iter; left time: 832.2242s
Epoch: 7 cost time: 9.210335731506348
Epoch: 7, Steps: 261 Train Loss: 29.7046 (Forecasting Loss:0.2648 + XiCon Loss:2.9440 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7103291
	speed: 0.0371s/iter; left time: 898.0576s
	iters: 200, epoch: 8 | loss: 29.6583939
	speed: 0.0341s/iter; left time: 819.7841s
Epoch: 8 cost time: 9.23608946800232
Epoch: 8, Steps: 261 Train Loss: 29.7061 (Forecasting Loss:0.2645 + XiCon Loss:2.9442 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1396
Validation loss decreased (0.195869 --> 0.195333).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.6237659
	speed: 0.0384s/iter; left time: 917.8122s
	iters: 200, epoch: 9 | loss: 29.6786613
	speed: 0.0348s/iter; left time: 828.8141s
Epoch: 9 cost time: 9.439728736877441
Epoch: 9, Steps: 261 Train Loss: 29.6719 (Forecasting Loss:0.2646 + XiCon Loss:2.9407 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1398
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8235931
	speed: 0.0374s/iter; left time: 883.8513s
	iters: 200, epoch: 10 | loss: 29.6125584
	speed: 0.0340s/iter; left time: 800.7877s
Epoch: 10 cost time: 9.226972579956055
Epoch: 10, Steps: 261 Train Loss: 29.6861 (Forecasting Loss:0.2646 + XiCon Loss:2.9422 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1398
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8062134
	speed: 0.0371s/iter; left time: 868.8795s
	iters: 200, epoch: 11 | loss: 29.9637165
	speed: 0.0347s/iter; left time: 808.9494s
Epoch: 11 cost time: 9.287445783615112
Epoch: 11, Steps: 261 Train Loss: 29.6861 (Forecasting Loss:0.2645 + XiCon Loss:2.9422 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1398
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.7762966
	speed: 0.0380s/iter; left time: 879.3555s
	iters: 200, epoch: 12 | loss: 30.1966705
	speed: 0.0347s/iter; left time: 799.5968s
Epoch: 12 cost time: 9.404033184051514
Epoch: 12, Steps: 261 Train Loss: 29.6832 (Forecasting Loss:0.2645 + XiCon Loss:2.9419 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3913689
	speed: 0.0381s/iter; left time: 870.9219s
	iters: 200, epoch: 13 | loss: 29.6517029
	speed: 0.0345s/iter; left time: 784.5285s
Epoch: 13 cost time: 9.37522578239441
Epoch: 13, Steps: 261 Train Loss: 29.6779 (Forecasting Loss:0.2645 + XiCon Loss:2.9413 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.7462101
	speed: 0.0383s/iter; left time: 865.3569s
	iters: 200, epoch: 14 | loss: 29.6517830
	speed: 0.0345s/iter; left time: 775.5610s
Epoch: 14 cost time: 9.368789434432983
Epoch: 14, Steps: 261 Train Loss: 29.6894 (Forecasting Loss:0.2645 + XiCon Loss:2.9425 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1399
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5558147
	speed: 0.0384s/iter; left time: 858.4868s
	iters: 200, epoch: 15 | loss: 29.4841557
	speed: 0.0351s/iter; left time: 780.5744s
Epoch: 15 cost time: 9.457170486450195
Epoch: 15, Steps: 261 Train Loss: 29.6759 (Forecasting Loss:0.2645 + XiCon Loss:2.9411 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1399
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8288574
	speed: 0.0380s/iter; left time: 839.1180s
	iters: 200, epoch: 16 | loss: 29.8278713
	speed: 0.0343s/iter; left time: 753.8058s
Epoch: 16 cost time: 9.340950012207031
Epoch: 16, Steps: 261 Train Loss: 29.6809 (Forecasting Loss:0.2645 + XiCon Loss:2.9416 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1399
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6482658
	speed: 0.0375s/iter; left time: 819.3772s
	iters: 200, epoch: 17 | loss: 29.8454857
	speed: 0.0349s/iter; left time: 759.1380s
Epoch: 17 cost time: 9.33081841468811
Epoch: 17, Steps: 261 Train Loss: 29.6658 (Forecasting Loss:0.2645 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1399
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.5503063
	speed: 0.0376s/iter; left time: 811.2901s
	iters: 200, epoch: 18 | loss: 29.4796638
	speed: 0.0356s/iter; left time: 764.5575s
Epoch: 18 cost time: 9.423876762390137
Epoch: 18, Steps: 261 Train Loss: 29.6663 (Forecasting Loss:0.2645 + XiCon Loss:2.9402 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07350930571556091, mae:0.2057386338710785, mape:0.15450303256511688, mspe:0.039566125720739365 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.7310
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.0854149
	speed: 0.0387s/iter; left time: 1006.1815s
	iters: 200, epoch: 1 | loss: 33.5033302
	speed: 0.0349s/iter; left time: 902.7833s
Epoch: 1 cost time: 9.499268531799316
Epoch: 1, Steps: 261 Train Loss: 33.8819 (Forecasting Loss:0.2768 + XiCon Loss:3.3605 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1415
Validation loss decreased (inf --> 0.199732).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.3705711
	speed: 0.0416s/iter; left time: 1069.9701s
	iters: 200, epoch: 2 | loss: 31.3988533
	speed: 0.0395s/iter; left time: 1012.0453s
Epoch: 2 cost time: 10.550797939300537
Epoch: 2, Steps: 261 Train Loss: 31.5120 (Forecasting Loss:0.2743 + XiCon Loss:3.1238 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1416
Validation loss decreased (0.199732 --> 0.198488).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.2273674
	speed: 0.0427s/iter; left time: 1087.4515s
	iters: 200, epoch: 3 | loss: 32.3258095
	speed: 0.0380s/iter; left time: 964.1512s
Epoch: 3 cost time: 10.400351285934448
Epoch: 3, Steps: 261 Train Loss: 31.9150 (Forecasting Loss:0.2696 + XiCon Loss:3.1645 x Lambda(10.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1411
Validation loss decreased (0.198488 --> 0.198043).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1497288
	speed: 0.0413s/iter; left time: 1041.1945s
	iters: 200, epoch: 4 | loss: 31.4655724
	speed: 0.0388s/iter; left time: 975.1894s
Epoch: 4 cost time: 10.384523391723633
Epoch: 4, Steps: 261 Train Loss: 31.5369 (Forecasting Loss:0.2671 + XiCon Loss:3.1270 x Lambda(10.0)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1401
Validation loss decreased (0.198043 --> 0.197229).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.4772015
	speed: 0.0416s/iter; left time: 1038.9226s
	iters: 200, epoch: 5 | loss: 31.9102325
	speed: 0.0389s/iter; left time: 967.6689s
Epoch: 5 cost time: 10.406672954559326
Epoch: 5, Steps: 261 Train Loss: 31.2582 (Forecasting Loss:0.2664 + XiCon Loss:3.0992 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1403
Validation loss decreased (0.197229 --> 0.195991).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.2424088
	speed: 0.0410s/iter; left time: 1012.0974s
	iters: 200, epoch: 6 | loss: 30.9252052
	speed: 0.0385s/iter; left time: 947.1277s
Epoch: 6 cost time: 10.308197259902954
Epoch: 6, Steps: 261 Train Loss: 31.1585 (Forecasting Loss:0.2655 + XiCon Loss:3.0893 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1148434
	speed: 0.0408s/iter; left time: 997.2681s
	iters: 200, epoch: 7 | loss: 31.2410450
	speed: 0.0389s/iter; left time: 947.7243s
Epoch: 7 cost time: 10.362788438796997
Epoch: 7, Steps: 261 Train Loss: 31.1141 (Forecasting Loss:0.2651 + XiCon Loss:3.0849 x Lambda(10.0)), Vali MSE Loss: 0.1963 Test MSE Loss: 0.1403
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0998650
	speed: 0.0414s/iter; left time: 1000.2385s
	iters: 200, epoch: 8 | loss: 30.8416920
	speed: 0.0387s/iter; left time: 932.7758s
Epoch: 8 cost time: 10.378365993499756
Epoch: 8, Steps: 261 Train Loss: 31.1025 (Forecasting Loss:0.2649 + XiCon Loss:3.0838 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.3196144
	speed: 0.0409s/iter; left time: 977.0822s
	iters: 200, epoch: 9 | loss: 31.1748352
	speed: 0.0380s/iter; left time: 905.6813s
Epoch: 9 cost time: 10.259705781936646
Epoch: 9, Steps: 261 Train Loss: 31.0961 (Forecasting Loss:0.2647 + XiCon Loss:3.0831 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
Validation loss decreased (0.195991 --> 0.195947).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.7811165
	speed: 0.0412s/iter; left time: 974.8467s
	iters: 200, epoch: 10 | loss: 30.8794861
	speed: 0.0387s/iter; left time: 910.6652s
Epoch: 10 cost time: 10.36373519897461
Epoch: 10, Steps: 261 Train Loss: 31.0724 (Forecasting Loss:0.2646 + XiCon Loss:3.0808 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1400
Validation loss decreased (0.195947 --> 0.195900).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2553596
	speed: 0.0409s/iter; left time: 956.1992s
	iters: 200, epoch: 11 | loss: 30.9114704
	speed: 0.0386s/iter; left time: 898.1585s
Epoch: 11 cost time: 10.319565534591675
Epoch: 11, Steps: 261 Train Loss: 31.0937 (Forecasting Loss:0.2646 + XiCon Loss:3.0829 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.3832626
	speed: 0.0408s/iter; left time: 943.9070s
	iters: 200, epoch: 12 | loss: 31.3149185
	speed: 0.0386s/iter; left time: 888.7074s
Epoch: 12 cost time: 10.340422868728638
Epoch: 12, Steps: 261 Train Loss: 31.0876 (Forecasting Loss:0.2646 + XiCon Loss:3.0823 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.1514893
	speed: 0.0410s/iter; left time: 937.9569s
	iters: 200, epoch: 13 | loss: 31.1160088
	speed: 0.0397s/iter; left time: 903.2123s
Epoch: 13 cost time: 10.464971780776978
Epoch: 13, Steps: 261 Train Loss: 31.0969 (Forecasting Loss:0.2646 + XiCon Loss:3.0832 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4417000
	speed: 0.0412s/iter; left time: 930.6890s
	iters: 200, epoch: 14 | loss: 30.9853516
	speed: 0.0379s/iter; left time: 853.8213s
Epoch: 14 cost time: 10.221771240234375
Epoch: 14, Steps: 261 Train Loss: 31.1121 (Forecasting Loss:0.2646 + XiCon Loss:3.0847 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.4654808
	speed: 0.0409s/iter; left time: 913.3508s
	iters: 200, epoch: 15 | loss: 31.1429920
	speed: 0.0394s/iter; left time: 875.9082s
Epoch: 15 cost time: 10.390061378479004
Epoch: 15, Steps: 261 Train Loss: 31.0940 (Forecasting Loss:0.2646 + XiCon Loss:3.0829 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.0248127
	speed: 0.0406s/iter; left time: 897.5015s
	iters: 200, epoch: 16 | loss: 31.2972870
	speed: 0.0385s/iter; left time: 847.0314s
Epoch: 16 cost time: 10.361933946609497
Epoch: 16, Steps: 261 Train Loss: 31.1000 (Forecasting Loss:0.2646 + XiCon Loss:3.0835 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.2189770
	speed: 0.0412s/iter; left time: 898.4241s
	iters: 200, epoch: 17 | loss: 31.2851810
	speed: 0.0385s/iter; left time: 836.0018s
Epoch: 17 cost time: 10.333477973937988
Epoch: 17, Steps: 261 Train Loss: 31.1037 (Forecasting Loss:0.2645 + XiCon Loss:3.0839 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.7437592
	speed: 0.0407s/iter; left time: 877.7135s
	iters: 200, epoch: 18 | loss: 31.1063404
	speed: 0.0395s/iter; left time: 847.3459s
Epoch: 18 cost time: 10.40169095993042
Epoch: 18, Steps: 261 Train Loss: 31.0638 (Forecasting Loss:0.2645 + XiCon Loss:3.0799 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.4661770
	speed: 0.0415s/iter; left time: 883.0249s
	iters: 200, epoch: 19 | loss: 31.1583557
	speed: 0.0382s/iter; left time: 810.6948s
Epoch: 19 cost time: 10.357943773269653
Epoch: 19, Steps: 261 Train Loss: 31.0771 (Forecasting Loss:0.2645 + XiCon Loss:3.0813 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.1700039
	speed: 0.0403s/iter; left time: 847.9064s
	iters: 200, epoch: 20 | loss: 30.6870842
	speed: 0.0392s/iter; left time: 821.5378s
Epoch: 20 cost time: 10.335572957992554
Epoch: 20, Steps: 261 Train Loss: 31.0994 (Forecasting Loss:0.2645 + XiCon Loss:3.0835 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07374290376901627, mae:0.20620021224021912, mape:0.15467551350593567, mspe:0.03955087810754776 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.1845
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.1369629
	speed: 0.0382s/iter; left time: 993.2876s
	iters: 200, epoch: 1 | loss: 33.5462990
	speed: 0.0358s/iter; left time: 926.2039s
Epoch: 1 cost time: 9.518313884735107
Epoch: 1, Steps: 261 Train Loss: 33.7696 (Forecasting Loss:0.2776 + XiCon Loss:3.3492 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1423
Validation loss decreased (inf --> 0.201056).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.4347229
	speed: 0.0418s/iter; left time: 1076.1103s
	iters: 200, epoch: 2 | loss: 31.3658810
	speed: 0.0400s/iter; left time: 1026.6316s
Epoch: 2 cost time: 10.619408130645752
Epoch: 2, Steps: 261 Train Loss: 31.4292 (Forecasting Loss:0.2738 + XiCon Loss:3.1155 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1616
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.8204498
	speed: 0.0415s/iter; left time: 1056.8664s
	iters: 200, epoch: 3 | loss: 29.4166107
	speed: 0.0397s/iter; left time: 1006.3317s
Epoch: 3 cost time: 10.558359861373901
Epoch: 3, Steps: 261 Train Loss: 29.5120 (Forecasting Loss:0.2689 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1491
Validation loss decreased (0.201056 --> 0.197525).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3147850
	speed: 0.0417s/iter; left time: 1051.9805s
	iters: 200, epoch: 4 | loss: 29.4717331
	speed: 0.0404s/iter; left time: 1015.6866s
Epoch: 4 cost time: 10.630738019943237
Epoch: 4, Steps: 261 Train Loss: 29.5145 (Forecasting Loss:0.2668 + XiCon Loss:2.9248 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1452
Validation loss decreased (0.197525 --> 0.196199).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7224579
	speed: 0.0419s/iter; left time: 1046.6871s
	iters: 200, epoch: 5 | loss: 30.3253574
	speed: 0.0394s/iter; left time: 978.1600s
Epoch: 5 cost time: 10.552551031112671
Epoch: 5, Steps: 261 Train Loss: 29.9859 (Forecasting Loss:0.2655 + XiCon Loss:2.9720 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1412
Validation loss decreased (0.196199 --> 0.195258).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4264450
	speed: 0.0417s/iter; left time: 1030.8032s
	iters: 200, epoch: 6 | loss: 30.3990479
	speed: 0.0390s/iter; left time: 959.3985s
Epoch: 6 cost time: 10.47643256187439
Epoch: 6, Steps: 261 Train Loss: 30.1720 (Forecasting Loss:0.2642 + XiCon Loss:2.9908 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1412
Validation loss decreased (0.195258 --> 0.194547).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.2064781
	speed: 0.0411s/iter; left time: 1003.6119s
	iters: 200, epoch: 7 | loss: 29.7263927
	speed: 0.0396s/iter; left time: 964.4420s
Epoch: 7 cost time: 10.446007490158081
Epoch: 7, Steps: 261 Train Loss: 30.1389 (Forecasting Loss:0.2637 + XiCon Loss:2.9875 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.1409
Validation loss decreased (0.194547 --> 0.194303).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9396000
	speed: 0.0414s/iter; left time: 1001.3376s
	iters: 200, epoch: 8 | loss: 30.2610264
	speed: 0.0396s/iter; left time: 952.9566s
Epoch: 8 cost time: 10.432724475860596
Epoch: 8, Steps: 261 Train Loss: 30.1074 (Forecasting Loss:0.2635 + XiCon Loss:2.9844 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1411
Validation loss decreased (0.194303 --> 0.194140).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1378670
	speed: 0.0410s/iter; left time: 981.3609s
	iters: 200, epoch: 9 | loss: 30.2138119
	speed: 0.0389s/iter; left time: 925.2912s
Epoch: 9 cost time: 10.416189670562744
Epoch: 9, Steps: 261 Train Loss: 30.1044 (Forecasting Loss:0.2635 + XiCon Loss:2.9841 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1411
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.0152435
	speed: 0.0413s/iter; left time: 976.6233s
	iters: 200, epoch: 10 | loss: 30.0544262
	speed: 0.0395s/iter; left time: 930.9382s
Epoch: 10 cost time: 10.449702262878418
Epoch: 10, Steps: 261 Train Loss: 30.1053 (Forecasting Loss:0.2633 + XiCon Loss:2.9842 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2274723
	speed: 0.0419s/iter; left time: 979.6502s
	iters: 200, epoch: 11 | loss: 29.8373909
	speed: 0.0382s/iter; left time: 889.7007s
Epoch: 11 cost time: 10.430500745773315
Epoch: 11, Steps: 261 Train Loss: 30.1141 (Forecasting Loss:0.2633 + XiCon Loss:2.9851 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.1410
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0741024
	speed: 0.0406s/iter; left time: 939.0279s
	iters: 200, epoch: 12 | loss: 29.8553200
	speed: 0.0386s/iter; left time: 888.2721s
Epoch: 12 cost time: 10.33351731300354
Epoch: 12, Steps: 261 Train Loss: 30.1105 (Forecasting Loss:0.2633 + XiCon Loss:2.9847 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1410
Validation loss decreased (0.194140 --> 0.194070).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.0100498
	speed: 0.0414s/iter; left time: 945.8712s
	iters: 200, epoch: 13 | loss: 30.0659447
	speed: 0.0388s/iter; left time: 884.3915s
Epoch: 13 cost time: 10.363687753677368
Epoch: 13, Steps: 261 Train Loss: 30.0891 (Forecasting Loss:0.2633 + XiCon Loss:2.9826 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1545563
	speed: 0.0413s/iter; left time: 934.6705s
	iters: 200, epoch: 14 | loss: 29.8388157
	speed: 0.0389s/iter; left time: 874.8927s
Epoch: 14 cost time: 10.433503866195679
Epoch: 14, Steps: 261 Train Loss: 30.1017 (Forecasting Loss:0.2633 + XiCon Loss:2.9838 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1410
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2032719
	speed: 0.0409s/iter; left time: 914.9924s
	iters: 200, epoch: 15 | loss: 29.7165012
	speed: 0.0392s/iter; left time: 873.1395s
Epoch: 15 cost time: 10.435943841934204
Epoch: 15, Steps: 261 Train Loss: 30.1138 (Forecasting Loss:0.2633 + XiCon Loss:2.9851 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0356941
	speed: 0.0407s/iter; left time: 899.7559s
	iters: 200, epoch: 16 | loss: 29.9955235
	speed: 0.0397s/iter; left time: 871.8339s
Epoch: 16 cost time: 10.438555002212524
Epoch: 16, Steps: 261 Train Loss: 30.0973 (Forecasting Loss:0.2634 + XiCon Loss:2.9834 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.8902206
	speed: 0.0417s/iter; left time: 909.8024s
	iters: 200, epoch: 17 | loss: 30.0789394
	speed: 0.0399s/iter; left time: 865.9673s
Epoch: 17 cost time: 10.59122085571289
Epoch: 17, Steps: 261 Train Loss: 30.0944 (Forecasting Loss:0.2633 + XiCon Loss:2.9831 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0177078
	speed: 0.0414s/iter; left time: 892.7703s
	iters: 200, epoch: 18 | loss: 30.1588669
	speed: 0.0389s/iter; left time: 834.4537s
Epoch: 18 cost time: 10.428964853286743
Epoch: 18, Steps: 261 Train Loss: 30.1195 (Forecasting Loss:0.2633 + XiCon Loss:2.9856 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4144306
	speed: 0.0410s/iter; left time: 874.4004s
	iters: 200, epoch: 19 | loss: 29.9840813
	speed: 0.0395s/iter; left time: 838.0740s
Epoch: 19 cost time: 10.48900318145752
Epoch: 19, Steps: 261 Train Loss: 30.1099 (Forecasting Loss:0.2633 + XiCon Loss:2.9847 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1410
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.0047340
	speed: 0.0409s/iter; left time: 861.6489s
	iters: 200, epoch: 20 | loss: 29.9378815
	speed: 0.0391s/iter; left time: 818.3178s
Epoch: 20 cost time: 10.396977186203003
Epoch: 20, Steps: 261 Train Loss: 30.1011 (Forecasting Loss:0.2634 + XiCon Loss:2.9838 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.3063412
	speed: 0.0416s/iter; left time: 865.4169s
	iters: 200, epoch: 21 | loss: 29.7932835
	speed: 0.0385s/iter; left time: 795.7786s
Epoch: 21 cost time: 10.400150060653687
Epoch: 21, Steps: 261 Train Loss: 30.1013 (Forecasting Loss:0.2632 + XiCon Loss:2.9838 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1410
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.0021973
	speed: 0.0407s/iter; left time: 835.8932s
	iters: 200, epoch: 22 | loss: 30.1538200
	speed: 0.0390s/iter; left time: 796.5706s
Epoch: 22 cost time: 10.390343427658081
Epoch: 22, Steps: 261 Train Loss: 30.1034 (Forecasting Loss:0.2632 + XiCon Loss:2.9840 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0745028555393219, mae:0.20750993490219116, mape:0.15560659766197205, mspe:0.03997204452753067 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.5929
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.1311913
	speed: 0.0384s/iter; left time: 999.0708s
	iters: 200, epoch: 1 | loss: 33.4725304
	speed: 0.0351s/iter; left time: 908.8220s
Epoch: 1 cost time: 9.516120433807373
Epoch: 1, Steps: 261 Train Loss: 33.8522 (Forecasting Loss:0.2766 + XiCon Loss:3.3576 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1421
Validation loss decreased (inf --> 0.198267).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1812248
	speed: 0.0412s/iter; left time: 1061.7321s
	iters: 200, epoch: 2 | loss: 31.7644386
	speed: 0.0398s/iter; left time: 1020.5278s
Epoch: 2 cost time: 10.50734281539917
Epoch: 2, Steps: 261 Train Loss: 31.5174 (Forecasting Loss:0.2736 + XiCon Loss:3.1244 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1426
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.4952011
	speed: 0.0422s/iter; left time: 1076.4339s
	iters: 200, epoch: 3 | loss: 29.5993233
	speed: 0.0404s/iter; left time: 1026.2941s
Epoch: 3 cost time: 10.699321269989014
Epoch: 3, Steps: 261 Train Loss: 30.1127 (Forecasting Loss:0.2690 + XiCon Loss:2.9844 x Lambda(10.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1393
Validation loss decreased (0.198267 --> 0.196377).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7755070
	speed: 0.0426s/iter; left time: 1073.9370s
	iters: 200, epoch: 4 | loss: 29.3236008
	speed: 0.0405s/iter; left time: 1016.2261s
Epoch: 4 cost time: 10.801265716552734
Epoch: 4, Steps: 261 Train Loss: 29.4509 (Forecasting Loss:0.2661 + XiCon Loss:2.9185 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1451
Validation loss decreased (0.196377 --> 0.195476).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2672844
	speed: 0.0423s/iter; left time: 1054.6427s
	iters: 200, epoch: 5 | loss: 30.0067329
	speed: 0.0400s/iter; left time: 994.2824s
Epoch: 5 cost time: 10.618653059005737
Epoch: 5, Steps: 261 Train Loss: 29.8085 (Forecasting Loss:0.2651 + XiCon Loss:2.9543 x Lambda(10.0)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1393
Validation loss decreased (0.195476 --> 0.194851).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.7544842
	speed: 0.0432s/iter; left time: 1066.7306s
	iters: 200, epoch: 6 | loss: 29.6989403
	speed: 0.0399s/iter; left time: 981.2710s
Epoch: 6 cost time: 10.778932094573975
Epoch: 6, Steps: 261 Train Loss: 30.0879 (Forecasting Loss:0.2642 + XiCon Loss:2.9824 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1383
Validation loss decreased (0.194851 --> 0.194195).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0616570
	speed: 0.0427s/iter; left time: 1044.5148s
	iters: 200, epoch: 7 | loss: 29.8980846
	speed: 0.0404s/iter; left time: 982.7569s
Epoch: 7 cost time: 10.808420181274414
Epoch: 7, Steps: 261 Train Loss: 30.0935 (Forecasting Loss:0.2637 + XiCon Loss:2.9830 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1381
Validation loss decreased (0.194195 --> 0.193420).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.0530624
	speed: 0.0420s/iter; left time: 1014.8181s
	iters: 200, epoch: 8 | loss: 29.5795574
	speed: 0.0394s/iter; left time: 947.8714s
Epoch: 8 cost time: 10.580806970596313
Epoch: 8, Steps: 261 Train Loss: 30.2355 (Forecasting Loss:0.2634 + XiCon Loss:2.9972 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1383
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1109581
	speed: 0.0423s/iter; left time: 1012.3896s
	iters: 200, epoch: 9 | loss: 30.2194557
	speed: 0.0406s/iter; left time: 967.8407s
Epoch: 9 cost time: 10.803190231323242
Epoch: 9, Steps: 261 Train Loss: 30.3032 (Forecasting Loss:0.2633 + XiCon Loss:3.0040 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1379
Validation loss decreased (0.193420 --> 0.193350).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2757397
	speed: 0.0424s/iter; left time: 1002.7277s
	iters: 200, epoch: 10 | loss: 30.6211243
	speed: 0.0402s/iter; left time: 947.2653s
Epoch: 10 cost time: 10.685740947723389
Epoch: 10, Steps: 261 Train Loss: 30.3099 (Forecasting Loss:0.2633 + XiCon Loss:3.0047 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.1378
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5764294
	speed: 0.0422s/iter; left time: 987.7909s
	iters: 200, epoch: 11 | loss: 30.5981140
	speed: 0.0400s/iter; left time: 932.3475s
Epoch: 11 cost time: 10.730175733566284
Epoch: 11, Steps: 261 Train Loss: 30.3214 (Forecasting Loss:0.2634 + XiCon Loss:3.0058 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1378
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5422306
	speed: 0.0431s/iter; left time: 995.8205s
	iters: 200, epoch: 12 | loss: 30.0131550
	speed: 0.0408s/iter; left time: 939.1852s
Epoch: 12 cost time: 10.847163677215576
Epoch: 12, Steps: 261 Train Loss: 30.3214 (Forecasting Loss:0.2632 + XiCon Loss:3.0058 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1378
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4893494
	speed: 0.0425s/iter; left time: 971.2507s
	iters: 200, epoch: 13 | loss: 30.3387356
	speed: 0.0400s/iter; left time: 909.8457s
Epoch: 13 cost time: 10.759464979171753
Epoch: 13, Steps: 261 Train Loss: 30.3622 (Forecasting Loss:0.2632 + XiCon Loss:3.0099 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2978325
	speed: 0.0428s/iter; left time: 968.4171s
	iters: 200, epoch: 14 | loss: 30.0435562
	speed: 0.0402s/iter; left time: 904.6321s
Epoch: 14 cost time: 10.759620428085327
Epoch: 14, Steps: 261 Train Loss: 30.3359 (Forecasting Loss:0.2632 + XiCon Loss:3.0073 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3044720
	speed: 0.0422s/iter; left time: 943.6523s
	iters: 200, epoch: 15 | loss: 30.3771286
	speed: 0.0398s/iter; left time: 886.4848s
Epoch: 15 cost time: 10.654623746871948
Epoch: 15, Steps: 261 Train Loss: 30.3424 (Forecasting Loss:0.2633 + XiCon Loss:3.0079 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.1379
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6238708
	speed: 0.0419s/iter; left time: 925.3960s
	iters: 200, epoch: 16 | loss: 30.1237965
	speed: 0.0399s/iter; left time: 878.0531s
Epoch: 16 cost time: 10.66223955154419
Epoch: 16, Steps: 261 Train Loss: 30.3507 (Forecasting Loss:0.2633 + XiCon Loss:3.0087 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.6265068
	speed: 0.0430s/iter; left time: 937.7633s
	iters: 200, epoch: 17 | loss: 30.1253223
	speed: 0.0407s/iter; left time: 883.6961s
Epoch: 17 cost time: 10.816588878631592
Epoch: 17, Steps: 261 Train Loss: 30.3203 (Forecasting Loss:0.2633 + XiCon Loss:3.0057 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1379
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.8681564
	speed: 0.0420s/iter; left time: 905.7337s
	iters: 200, epoch: 18 | loss: 30.1434689
	speed: 0.0409s/iter; left time: 878.2582s
Epoch: 18 cost time: 10.724778175354004
Epoch: 18, Steps: 261 Train Loss: 30.3314 (Forecasting Loss:0.2632 + XiCon Loss:3.0068 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1379
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7019024
	speed: 0.0422s/iter; left time: 898.7792s
	iters: 200, epoch: 19 | loss: 30.4347115
	speed: 0.0399s/iter; left time: 846.9984s
Epoch: 19 cost time: 10.700548887252808
Epoch: 19, Steps: 261 Train Loss: 30.3151 (Forecasting Loss:0.2633 + XiCon Loss:3.0052 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1379
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07215764373540878, mae:0.20360210537910461, mape:0.15335695445537567, mspe:0.039252880960702896 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0747+-0.00346, MAE:0.2067+-0.00322, MAPE:0.1551+-0.00190, MSPE:0.0400+-0.00127, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5294
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.0973320
	speed: 0.0349s/iter; left time: 924.0815s
	iters: 200, epoch: 1 | loss: 32.2473106
	speed: 0.0304s/iter; left time: 803.2591s
Epoch: 1 cost time: 8.530452251434326
Epoch: 1, Steps: 266 Train Loss: 32.7990 (Forecasting Loss:0.1871 + XiCon Loss:3.2612 x Lambda(10.0)), Vali MSE Loss: 0.1583 Test MSE Loss: 0.1380
Validation loss decreased (inf --> 0.158313).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.0126991
	speed: 0.0301s/iter; left time: 790.2008s
	iters: 200, epoch: 2 | loss: 31.4337769
	speed: 0.0275s/iter; left time: 719.9393s
Epoch: 2 cost time: 7.623086214065552
Epoch: 2, Steps: 266 Train Loss: 31.4664 (Forecasting Loss:0.1588 + XiCon Loss:3.1308 x Lambda(10.0)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.1330
Validation loss decreased (0.158313 --> 0.156907).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1909275
	speed: 0.0291s/iter; left time: 756.5021s
	iters: 200, epoch: 3 | loss: 30.4545975
	speed: 0.0292s/iter; left time: 756.2614s
Epoch: 3 cost time: 7.741976499557495
Epoch: 3, Steps: 266 Train Loss: 30.7441 (Forecasting Loss:0.1522 + XiCon Loss:3.0592 x Lambda(10.0)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.1297
Validation loss decreased (0.156907 --> 0.148479).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2016945
	speed: 0.0299s/iter; left time: 769.3632s
	iters: 200, epoch: 4 | loss: 30.4137306
	speed: 0.0283s/iter; left time: 724.4134s
Epoch: 4 cost time: 7.694194316864014
Epoch: 4, Steps: 266 Train Loss: 30.6926 (Forecasting Loss:0.1497 + XiCon Loss:3.0543 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1278
Validation loss decreased (0.148479 --> 0.146008).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7416821
	speed: 0.0307s/iter; left time: 781.1560s
	iters: 200, epoch: 5 | loss: 30.6444626
	speed: 0.0282s/iter; left time: 714.8885s
Epoch: 5 cost time: 7.725543260574341
Epoch: 5, Steps: 266 Train Loss: 30.6271 (Forecasting Loss:0.1481 + XiCon Loss:3.0479 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.1259
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5348473
	speed: 0.0302s/iter; left time: 760.6571s
	iters: 200, epoch: 6 | loss: 30.5408669
	speed: 0.0276s/iter; left time: 692.5218s
Epoch: 6 cost time: 7.647238492965698
Epoch: 6, Steps: 266 Train Loss: 30.6351 (Forecasting Loss:0.1475 + XiCon Loss:3.0488 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1246
Validation loss decreased (0.146008 --> 0.144558).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4311390
	speed: 0.0304s/iter; left time: 757.8109s
	iters: 200, epoch: 7 | loss: 30.2602444
	speed: 0.0284s/iter; left time: 705.1568s
Epoch: 7 cost time: 7.84192967414856
Epoch: 7, Steps: 266 Train Loss: 30.6115 (Forecasting Loss:0.1472 + XiCon Loss:3.0464 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144558 --> 0.144401).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3759594
	speed: 0.0303s/iter; left time: 747.4851s
	iters: 200, epoch: 8 | loss: 30.4967747
	speed: 0.0280s/iter; left time: 688.0880s
Epoch: 8 cost time: 7.735433578491211
Epoch: 8, Steps: 266 Train Loss: 30.5862 (Forecasting Loss:0.1470 + XiCon Loss:3.0439 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
Validation loss decreased (0.144401 --> 0.144161).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.8663483
	speed: 0.0305s/iter; left time: 743.1379s
	iters: 200, epoch: 9 | loss: 30.6982365
	speed: 0.0272s/iter; left time: 661.1849s
Epoch: 9 cost time: 7.558854579925537
Epoch: 9, Steps: 266 Train Loss: 30.6302 (Forecasting Loss:0.1470 + XiCon Loss:3.0483 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3949890
	speed: 0.0303s/iter; left time: 730.1274s
	iters: 200, epoch: 10 | loss: 30.8983917
	speed: 0.0288s/iter; left time: 690.9744s
Epoch: 10 cost time: 7.895406723022461
Epoch: 10, Steps: 266 Train Loss: 30.6230 (Forecasting Loss:0.1469 + XiCon Loss:3.0476 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5876179
	speed: 0.0308s/iter; left time: 734.0014s
	iters: 200, epoch: 11 | loss: 30.4670315
	speed: 0.0281s/iter; left time: 668.2652s
Epoch: 11 cost time: 7.792602300643921
Epoch: 11, Steps: 266 Train Loss: 30.6186 (Forecasting Loss:0.1469 + XiCon Loss:3.0472 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1475277
	speed: 0.0302s/iter; left time: 712.2915s
	iters: 200, epoch: 12 | loss: 30.7102222
	speed: 0.0279s/iter; left time: 654.7716s
Epoch: 12 cost time: 7.668337106704712
Epoch: 12, Steps: 266 Train Loss: 30.6177 (Forecasting Loss:0.1469 + XiCon Loss:3.0471 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.0774765
	speed: 0.0303s/iter; left time: 705.4663s
	iters: 200, epoch: 13 | loss: 31.2487068
	speed: 0.0279s/iter; left time: 647.3606s
Epoch: 13 cost time: 7.69695520401001
Epoch: 13, Steps: 266 Train Loss: 30.5727 (Forecasting Loss:0.1468 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
Validation loss decreased (0.144161 --> 0.143994).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8457355
	speed: 0.0307s/iter; left time: 706.9140s
	iters: 200, epoch: 14 | loss: 30.2023277
	speed: 0.0277s/iter; left time: 636.0263s
Epoch: 14 cost time: 7.686569929122925
Epoch: 14, Steps: 266 Train Loss: 30.6285 (Forecasting Loss:0.1468 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.0532837
	speed: 0.0309s/iter; left time: 702.9160s
	iters: 200, epoch: 15 | loss: 30.2263145
	speed: 0.0282s/iter; left time: 638.6975s
Epoch: 15 cost time: 7.821285963058472
Epoch: 15, Steps: 266 Train Loss: 30.6060 (Forecasting Loss:0.1468 + XiCon Loss:3.0459 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.7565346
	speed: 0.0305s/iter; left time: 685.6628s
	iters: 200, epoch: 16 | loss: 30.3606129
	speed: 0.0289s/iter; left time: 646.7055s
Epoch: 16 cost time: 7.785510540008545
Epoch: 16, Steps: 266 Train Loss: 30.6030 (Forecasting Loss:0.1468 + XiCon Loss:3.0456 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.8910999
	speed: 0.0299s/iter; left time: 665.7764s
	iters: 200, epoch: 17 | loss: 30.2698345
	speed: 0.0279s/iter; left time: 618.7731s
Epoch: 17 cost time: 7.601606845855713
Epoch: 17, Steps: 266 Train Loss: 30.6060 (Forecasting Loss:0.1468 + XiCon Loss:3.0459 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8963337
	speed: 0.0304s/iter; left time: 668.1561s
	iters: 200, epoch: 18 | loss: 30.2655125
	speed: 0.0272s/iter; left time: 594.5289s
Epoch: 18 cost time: 7.594601154327393
Epoch: 18, Steps: 266 Train Loss: 30.5855 (Forecasting Loss:0.1468 + XiCon Loss:3.0439 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5759563
	speed: 0.0302s/iter; left time: 656.5412s
	iters: 200, epoch: 19 | loss: 30.3455963
	speed: 0.0283s/iter; left time: 610.9307s
Epoch: 19 cost time: 7.738982677459717
Epoch: 19, Steps: 266 Train Loss: 30.6187 (Forecasting Loss:0.1469 + XiCon Loss:3.0472 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.7046986
	speed: 0.0306s/iter; left time: 656.7297s
	iters: 200, epoch: 20 | loss: 30.4378796
	speed: 0.0284s/iter; left time: 605.5730s
Epoch: 20 cost time: 7.8145599365234375
Epoch: 20, Steps: 266 Train Loss: 30.6141 (Forecasting Loss:0.1468 + XiCon Loss:3.0467 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.0762177
	speed: 0.0302s/iter; left time: 640.0954s
	iters: 200, epoch: 21 | loss: 30.3874722
	speed: 0.0283s/iter; left time: 597.5645s
Epoch: 21 cost time: 7.700873136520386
Epoch: 21, Steps: 266 Train Loss: 30.6001 (Forecasting Loss:0.1468 + XiCon Loss:3.0453 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.1281834
	speed: 0.0302s/iter; left time: 631.3756s
	iters: 200, epoch: 22 | loss: 30.7641239
	speed: 0.0283s/iter; left time: 589.2264s
Epoch: 22 cost time: 7.793367624282837
Epoch: 22, Steps: 266 Train Loss: 30.6013 (Forecasting Loss:0.1469 + XiCon Loss:3.0454 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.4578876
	speed: 0.0301s/iter; left time: 620.9571s
	iters: 200, epoch: 23 | loss: 30.6010723
	speed: 0.0277s/iter; left time: 569.9515s
Epoch: 23 cost time: 7.694150924682617
Epoch: 23, Steps: 266 Train Loss: 30.6281 (Forecasting Loss:0.1468 + XiCon Loss:3.0481 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0646427795290947, mae:0.18431982398033142, mape:0.44841697812080383, mspe:8.117908477783203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.7671
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.0921249
	speed: 0.0329s/iter; left time: 870.7738s
	iters: 200, epoch: 1 | loss: 32.2241745
	speed: 0.0301s/iter; left time: 794.3333s
Epoch: 1 cost time: 8.31772494316101
Epoch: 1, Steps: 266 Train Loss: 32.8978 (Forecasting Loss:0.1857 + XiCon Loss:3.2712 x Lambda(10.0)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1357
Validation loss decreased (inf --> 0.158581).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.5973873
	speed: 0.0307s/iter; left time: 806.5112s
	iters: 200, epoch: 2 | loss: 32.1042442
	speed: 0.0287s/iter; left time: 749.2717s
Epoch: 2 cost time: 7.856201171875
Epoch: 2, Steps: 266 Train Loss: 32.0335 (Forecasting Loss:0.1586 + XiCon Loss:3.1875 x Lambda(10.0)), Vali MSE Loss: 0.1533 Test MSE Loss: 0.1323
Validation loss decreased (0.158581 --> 0.153291).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.9936771
	speed: 0.0301s/iter; left time: 782.6975s
	iters: 200, epoch: 3 | loss: 31.8185387
	speed: 0.0278s/iter; left time: 719.0564s
Epoch: 3 cost time: 7.660992383956909
Epoch: 3, Steps: 266 Train Loss: 31.4148 (Forecasting Loss:0.1517 + XiCon Loss:3.1263 x Lambda(10.0)), Vali MSE Loss: 0.1489 Test MSE Loss: 0.1282
Validation loss decreased (0.153291 --> 0.148870).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1750145
	speed: 0.0305s/iter; left time: 784.4399s
	iters: 200, epoch: 4 | loss: 31.2567806
	speed: 0.0281s/iter; left time: 720.5521s
Epoch: 4 cost time: 7.718858003616333
Epoch: 4, Steps: 266 Train Loss: 31.2837 (Forecasting Loss:0.1496 + XiCon Loss:3.1134 x Lambda(10.0)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.1256
Validation loss decreased (0.148870 --> 0.147204).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.6287460
	speed: 0.0305s/iter; left time: 776.8922s
	iters: 200, epoch: 5 | loss: 30.8363781
	speed: 0.0281s/iter; left time: 710.9061s
Epoch: 5 cost time: 7.728338241577148
Epoch: 5, Steps: 266 Train Loss: 31.2317 (Forecasting Loss:0.1480 + XiCon Loss:3.1084 x Lambda(10.0)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.1253
Validation loss decreased (0.147204 --> 0.145085).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9910564
	speed: 0.0300s/iter; left time: 755.5706s
	iters: 200, epoch: 6 | loss: 30.3451557
	speed: 0.0278s/iter; left time: 697.5216s
Epoch: 6 cost time: 7.7492356300354
Epoch: 6, Steps: 266 Train Loss: 31.1812 (Forecasting Loss:0.1474 + XiCon Loss:3.1034 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1247
Validation loss decreased (0.145085 --> 0.144860).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.8083878
	speed: 0.0304s/iter; left time: 756.8654s
	iters: 200, epoch: 7 | loss: 30.5534000
	speed: 0.0283s/iter; left time: 700.8054s
Epoch: 7 cost time: 7.739633560180664
Epoch: 7, Steps: 266 Train Loss: 31.1225 (Forecasting Loss:0.1472 + XiCon Loss:3.0975 x Lambda(10.0)), Vali MSE Loss: 0.1452 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1254272
	speed: 0.0301s/iter; left time: 740.4393s
	iters: 200, epoch: 8 | loss: 31.0017509
	speed: 0.0282s/iter; left time: 692.3182s
Epoch: 8 cost time: 7.791780233383179
Epoch: 8, Steps: 266 Train Loss: 31.1777 (Forecasting Loss:0.1470 + XiCon Loss:3.1031 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1246
Validation loss decreased (0.144860 --> 0.144656).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7791672
	speed: 0.0304s/iter; left time: 741.9840s
	iters: 200, epoch: 9 | loss: 30.7903366
	speed: 0.0277s/iter; left time: 672.0271s
Epoch: 9 cost time: 7.631100177764893
Epoch: 9, Steps: 266 Train Loss: 31.1357 (Forecasting Loss:0.1469 + XiCon Loss:3.0989 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
Validation loss decreased (0.144656 --> 0.144500).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1299400
	speed: 0.0304s/iter; left time: 732.5644s
	iters: 200, epoch: 10 | loss: 30.7795277
	speed: 0.0285s/iter; left time: 685.1642s
Epoch: 10 cost time: 7.731648921966553
Epoch: 10, Steps: 266 Train Loss: 31.1526 (Forecasting Loss:0.1469 + XiCon Loss:3.1006 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
Validation loss decreased (0.144500 --> 0.144499).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.9877720
	speed: 0.0311s/iter; left time: 741.4421s
	iters: 200, epoch: 11 | loss: 31.0177860
	speed: 0.0298s/iter; left time: 708.3027s
Epoch: 11 cost time: 8.129202127456665
Epoch: 11, Steps: 266 Train Loss: 31.1934 (Forecasting Loss:0.1469 + XiCon Loss:3.1047 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0763683
	speed: 0.0312s/iter; left time: 734.7869s
	iters: 200, epoch: 12 | loss: 30.5463715
	speed: 0.0286s/iter; left time: 670.6850s
Epoch: 12 cost time: 7.818729877471924
Epoch: 12, Steps: 266 Train Loss: 31.1457 (Forecasting Loss:0.1468 + XiCon Loss:3.0999 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
Validation loss decreased (0.144499 --> 0.144373).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8737717
	speed: 0.0306s/iter; left time: 713.5894s
	iters: 200, epoch: 13 | loss: 30.5377827
	speed: 0.0280s/iter; left time: 649.7092s
Epoch: 13 cost time: 7.856238603591919
Epoch: 13, Steps: 266 Train Loss: 31.1445 (Forecasting Loss:0.1467 + XiCon Loss:3.0998 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2130852
	speed: 0.0302s/iter; left time: 694.7983s
	iters: 200, epoch: 14 | loss: 31.1081886
	speed: 0.0278s/iter; left time: 637.6409s
Epoch: 14 cost time: 7.669107913970947
Epoch: 14, Steps: 266 Train Loss: 31.1979 (Forecasting Loss:0.1468 + XiCon Loss:3.1051 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.1414604
	speed: 0.0311s/iter; left time: 709.0657s
	iters: 200, epoch: 15 | loss: 30.9519863
	speed: 0.0288s/iter; left time: 653.2300s
Epoch: 15 cost time: 7.835384845733643
Epoch: 15, Steps: 266 Train Loss: 31.1464 (Forecasting Loss:0.1468 + XiCon Loss:3.1000 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.1207066
	speed: 0.0303s/iter; left time: 681.7558s
	iters: 200, epoch: 16 | loss: 31.0419025
	speed: 0.0282s/iter; left time: 632.4942s
Epoch: 16 cost time: 7.873312711715698
Epoch: 16, Steps: 266 Train Loss: 31.0923 (Forecasting Loss:0.1467 + XiCon Loss:3.0946 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
Validation loss decreased (0.144373 --> 0.144340).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.8034859
	speed: 0.0311s/iter; left time: 691.6866s
	iters: 200, epoch: 17 | loss: 30.4509201
	speed: 0.0277s/iter; left time: 614.4873s
Epoch: 17 cost time: 7.768397092819214
Epoch: 17, Steps: 266 Train Loss: 31.1442 (Forecasting Loss:0.1468 + XiCon Loss:3.0997 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2412109
	speed: 0.0303s/iter; left time: 666.8336s
	iters: 200, epoch: 18 | loss: 31.3077469
	speed: 0.0287s/iter; left time: 627.6949s
Epoch: 18 cost time: 7.866789102554321
Epoch: 18, Steps: 266 Train Loss: 31.1401 (Forecasting Loss:0.1467 + XiCon Loss:3.0993 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
Validation loss decreased (0.144340 --> 0.144280).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.1292763
	speed: 0.0303s/iter; left time: 657.3050s
	iters: 200, epoch: 19 | loss: 31.2610340
	speed: 0.0289s/iter; left time: 625.1093s
Epoch: 19 cost time: 7.804474115371704
Epoch: 19, Steps: 266 Train Loss: 31.1826 (Forecasting Loss:0.1467 + XiCon Loss:3.1036 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3760490
	speed: 0.0300s/iter; left time: 642.5188s
	iters: 200, epoch: 20 | loss: 30.7711010
	speed: 0.0281s/iter; left time: 600.3807s
Epoch: 20 cost time: 7.612797021865845
Epoch: 20, Steps: 266 Train Loss: 31.1593 (Forecasting Loss:0.1468 + XiCon Loss:3.1012 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5634232
	speed: 0.0298s/iter; left time: 630.3677s
	iters: 200, epoch: 21 | loss: 30.7246761
	speed: 0.0279s/iter; left time: 588.0591s
Epoch: 21 cost time: 7.653580188751221
Epoch: 21, Steps: 266 Train Loss: 31.1382 (Forecasting Loss:0.1468 + XiCon Loss:3.0991 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.5450115
	speed: 0.0302s/iter; left time: 631.9350s
	iters: 200, epoch: 22 | loss: 31.6572380
	speed: 0.0278s/iter; left time: 579.2769s
Epoch: 22 cost time: 7.707033157348633
Epoch: 22, Steps: 266 Train Loss: 31.1351 (Forecasting Loss:0.1468 + XiCon Loss:3.0988 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.8811817
	speed: 0.0308s/iter; left time: 636.8126s
	iters: 200, epoch: 23 | loss: 30.7448769
	speed: 0.0290s/iter; left time: 596.8988s
Epoch: 23 cost time: 7.87425422668457
Epoch: 23, Steps: 266 Train Loss: 31.1057 (Forecasting Loss:0.1468 + XiCon Loss:3.0959 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6130199
	speed: 0.0297s/iter; left time: 605.4857s
	iters: 200, epoch: 24 | loss: 30.7595406
	speed: 0.0281s/iter; left time: 570.4101s
Epoch: 24 cost time: 7.655310153961182
Epoch: 24, Steps: 266 Train Loss: 31.1551 (Forecasting Loss:0.1468 + XiCon Loss:3.1008 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.4145489
	speed: 0.0318s/iter; left time: 639.7584s
	iters: 200, epoch: 25 | loss: 30.6483269
	speed: 0.0285s/iter; left time: 569.5314s
Epoch: 25 cost time: 7.93521785736084
Epoch: 25, Steps: 266 Train Loss: 31.1227 (Forecasting Loss:0.1467 + XiCon Loss:3.0976 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.0641346
	speed: 0.0303s/iter; left time: 601.6948s
	iters: 200, epoch: 26 | loss: 30.7433090
	speed: 0.0286s/iter; left time: 565.6861s
Epoch: 26 cost time: 7.813035011291504
Epoch: 26, Steps: 266 Train Loss: 31.1549 (Forecasting Loss:0.1469 + XiCon Loss:3.1008 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.9000034
	speed: 0.0304s/iter; left time: 594.4075s
	iters: 200, epoch: 27 | loss: 31.5418224
	speed: 0.0289s/iter; left time: 562.9943s
Epoch: 27 cost time: 7.780474662780762
Epoch: 27, Steps: 266 Train Loss: 31.1499 (Forecasting Loss:0.1468 + XiCon Loss:3.1003 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.9937553
	speed: 0.0305s/iter; left time: 589.8545s
	iters: 200, epoch: 28 | loss: 31.3282413
	speed: 0.0279s/iter; left time: 536.0611s
Epoch: 28 cost time: 7.760716676712036
Epoch: 28, Steps: 266 Train Loss: 31.1168 (Forecasting Loss:0.1467 + XiCon Loss:3.0970 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06446767598390579, mae:0.18427160382270813, mape:0.44882455468177795, mspe:8.17718505859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.1115
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.8708878
	speed: 0.0302s/iter; left time: 801.2335s
	iters: 200, epoch: 1 | loss: 32.2039032
	speed: 0.0277s/iter; left time: 730.3889s
Epoch: 1 cost time: 7.633417844772339
Epoch: 1, Steps: 266 Train Loss: 32.7533 (Forecasting Loss:0.1832 + XiCon Loss:3.2570 x Lambda(10.0)), Vali MSE Loss: 0.1580 Test MSE Loss: 0.1364
Validation loss decreased (inf --> 0.158046).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.5003815
	speed: 0.0318s/iter; left time: 834.0806s
	iters: 200, epoch: 2 | loss: 31.1720333
	speed: 0.0316s/iter; left time: 825.6836s
Epoch: 2 cost time: 8.421144247055054
Epoch: 2, Steps: 266 Train Loss: 31.8053 (Forecasting Loss:0.1595 + XiCon Loss:3.1646 x Lambda(10.0)), Vali MSE Loss: 0.1504 Test MSE Loss: 0.1302
Validation loss decreased (0.158046 --> 0.150420).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6655445
	speed: 0.0308s/iter; left time: 800.3059s
	iters: 200, epoch: 3 | loss: 30.5374565
	speed: 0.0284s/iter; left time: 734.5539s
Epoch: 3 cost time: 7.756424427032471
Epoch: 3, Steps: 266 Train Loss: 30.9853 (Forecasting Loss:0.1511 + XiCon Loss:3.0834 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1301
Validation loss decreased (0.150420 --> 0.148645).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4991550
	speed: 0.0318s/iter; left time: 817.0109s
	iters: 200, epoch: 4 | loss: 30.0792789
	speed: 0.0289s/iter; left time: 739.7445s
Epoch: 4 cost time: 7.961820125579834
Epoch: 4, Steps: 266 Train Loss: 30.6375 (Forecasting Loss:0.1493 + XiCon Loss:3.0488 x Lambda(10.0)), Vali MSE Loss: 0.1454 Test MSE Loss: 0.1258
Validation loss decreased (0.148645 --> 0.145379).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2405243
	speed: 0.0302s/iter; left time: 769.2156s
	iters: 200, epoch: 5 | loss: 30.7520008
	speed: 0.0285s/iter; left time: 722.4677s
Epoch: 5 cost time: 7.770085096359253
Epoch: 5, Steps: 266 Train Loss: 30.4622 (Forecasting Loss:0.1480 + XiCon Loss:3.0314 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1607933
	speed: 0.0310s/iter; left time: 779.1495s
	iters: 200, epoch: 6 | loss: 30.3330517
	speed: 0.0291s/iter; left time: 730.2899s
Epoch: 6 cost time: 7.938544511795044
Epoch: 6, Steps: 266 Train Loss: 30.4403 (Forecasting Loss:0.1473 + XiCon Loss:3.0293 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1246
Validation loss decreased (0.145379 --> 0.144932).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4417629
	speed: 0.0306s/iter; left time: 761.3018s
	iters: 200, epoch: 7 | loss: 30.2120132
	speed: 0.0280s/iter; left time: 694.2373s
Epoch: 7 cost time: 7.7855448722839355
Epoch: 7, Steps: 266 Train Loss: 30.3869 (Forecasting Loss:0.1469 + XiCon Loss:3.0240 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
Validation loss decreased (0.144932 --> 0.144223).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4652882
	speed: 0.0309s/iter; left time: 760.2404s
	iters: 200, epoch: 8 | loss: 30.7754841
	speed: 0.0275s/iter; left time: 675.5414s
Epoch: 8 cost time: 7.702075958251953
Epoch: 8, Steps: 266 Train Loss: 30.3961 (Forecasting Loss:0.1467 + XiCon Loss:3.0249 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9919338
	speed: 0.0300s/iter; left time: 731.9996s
	iters: 200, epoch: 9 | loss: 30.7635441
	speed: 0.0279s/iter; left time: 678.1937s
Epoch: 9 cost time: 7.6916184425354
Epoch: 9, Steps: 266 Train Loss: 30.4252 (Forecasting Loss:0.1467 + XiCon Loss:3.0278 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1242
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4621773
	speed: 0.0294s/iter; left time: 707.6771s
	iters: 200, epoch: 10 | loss: 30.5823059
	speed: 0.0285s/iter; left time: 683.8492s
Epoch: 10 cost time: 7.718145132064819
Epoch: 10, Steps: 266 Train Loss: 30.4049 (Forecasting Loss:0.1467 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1241
Validation loss decreased (0.144223 --> 0.144051).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8846264
	speed: 0.0313s/iter; left time: 746.0704s
	iters: 200, epoch: 11 | loss: 30.6949043
	speed: 0.0283s/iter; left time: 672.8251s
Epoch: 11 cost time: 7.9215617179870605
Epoch: 11, Steps: 266 Train Loss: 30.4099 (Forecasting Loss:0.1466 + XiCon Loss:3.0263 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1241
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7379227
	speed: 0.0311s/iter; left time: 733.7551s
	iters: 200, epoch: 12 | loss: 30.1325054
	speed: 0.0278s/iter; left time: 652.4271s
Epoch: 12 cost time: 7.750550746917725
Epoch: 12, Steps: 266 Train Loss: 30.4270 (Forecasting Loss:0.1466 + XiCon Loss:3.0280 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7557983
	speed: 0.0306s/iter; left time: 713.5971s
	iters: 200, epoch: 13 | loss: 31.1314144
	speed: 0.0283s/iter; left time: 656.7943s
Epoch: 13 cost time: 7.785714626312256
Epoch: 13, Steps: 266 Train Loss: 30.4203 (Forecasting Loss:0.1465 + XiCon Loss:3.0274 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3376427
	speed: 0.0303s/iter; left time: 698.8981s
	iters: 200, epoch: 14 | loss: 30.1460457
	speed: 0.0280s/iter; left time: 642.1179s
Epoch: 14 cost time: 7.729418754577637
Epoch: 14, Steps: 266 Train Loss: 30.3986 (Forecasting Loss:0.1466 + XiCon Loss:3.0252 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.8186569
	speed: 0.0311s/iter; left time: 708.3008s
	iters: 200, epoch: 15 | loss: 30.5255413
	speed: 0.0276s/iter; left time: 625.2905s
Epoch: 15 cost time: 7.736204385757446
Epoch: 15, Steps: 266 Train Loss: 30.4256 (Forecasting Loss:0.1466 + XiCon Loss:3.0279 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4795494
	speed: 0.0321s/iter; left time: 722.3351s
	iters: 200, epoch: 16 | loss: 30.9096146
	speed: 0.0293s/iter; left time: 657.6949s
Epoch: 16 cost time: 8.00499677658081
Epoch: 16, Steps: 266 Train Loss: 30.4071 (Forecasting Loss:0.1465 + XiCon Loss:3.0261 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1241
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4774570
	speed: 0.0315s/iter; left time: 699.9464s
	iters: 200, epoch: 17 | loss: 30.3470478
	speed: 0.0288s/iter; left time: 637.6603s
Epoch: 17 cost time: 7.92940092086792
Epoch: 17, Steps: 266 Train Loss: 30.4071 (Forecasting Loss:0.1466 + XiCon Loss:3.0261 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1241
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0959320
	speed: 0.0313s/iter; left time: 688.6094s
	iters: 200, epoch: 18 | loss: 30.3875980
	speed: 0.0286s/iter; left time: 625.8561s
Epoch: 18 cost time: 7.883243083953857
Epoch: 18, Steps: 266 Train Loss: 30.3837 (Forecasting Loss:0.1466 + XiCon Loss:3.0237 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3813477
	speed: 0.0303s/iter; left time: 657.9837s
	iters: 200, epoch: 19 | loss: 30.0399418
	speed: 0.0281s/iter; left time: 607.5085s
Epoch: 19 cost time: 7.722409725189209
Epoch: 19, Steps: 266 Train Loss: 30.4144 (Forecasting Loss:0.1465 + XiCon Loss:3.0268 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3682861
	speed: 0.0302s/iter; left time: 647.9882s
	iters: 200, epoch: 20 | loss: 30.0996819
	speed: 0.0283s/iter; left time: 603.4160s
Epoch: 20 cost time: 7.7419373989105225
Epoch: 20, Steps: 266 Train Loss: 30.4082 (Forecasting Loss:0.1464 + XiCon Loss:3.0262 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1241
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06424181163311005, mae:0.18401983380317688, mape:0.4480624496936798, mspe:8.131896018981934 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3729
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.8537254
	speed: 0.0339s/iter; left time: 898.3047s
	iters: 200, epoch: 1 | loss: 32.1024666
	speed: 0.0306s/iter; left time: 808.6421s
Epoch: 1 cost time: 8.493420839309692
Epoch: 1, Steps: 266 Train Loss: 32.7032 (Forecasting Loss:0.1865 + XiCon Loss:3.2517 x Lambda(10.0)), Vali MSE Loss: 0.1565 Test MSE Loss: 0.1366
Validation loss decreased (inf --> 0.156544).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.6395226
	speed: 0.0312s/iter; left time: 818.1624s
	iters: 200, epoch: 2 | loss: 31.4631329
	speed: 0.0285s/iter; left time: 743.9752s
Epoch: 2 cost time: 7.840741872787476
Epoch: 2, Steps: 266 Train Loss: 31.7023 (Forecasting Loss:0.1598 + XiCon Loss:3.1543 x Lambda(10.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1385
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2922745
	speed: 0.0302s/iter; left time: 783.6151s
	iters: 200, epoch: 3 | loss: 30.6772861
	speed: 0.0282s/iter; left time: 729.0615s
Epoch: 3 cost time: 7.699570417404175
Epoch: 3, Steps: 266 Train Loss: 31.1208 (Forecasting Loss:0.1523 + XiCon Loss:3.0968 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.1278
Validation loss decreased (0.156544 --> 0.148287).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9193573
	speed: 0.0304s/iter; left time: 782.0243s
	iters: 200, epoch: 4 | loss: 30.7421303
	speed: 0.0285s/iter; left time: 730.9470s
Epoch: 4 cost time: 7.75470495223999
Epoch: 4, Steps: 266 Train Loss: 30.9445 (Forecasting Loss:0.1495 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.1274
Validation loss decreased (0.148287 --> 0.147540).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0628681
	speed: 0.0309s/iter; left time: 784.8103s
	iters: 200, epoch: 5 | loss: 31.2495365
	speed: 0.0281s/iter; left time: 712.4862s
Epoch: 5 cost time: 7.750317096710205
Epoch: 5, Steps: 266 Train Loss: 30.9297 (Forecasting Loss:0.1481 + XiCon Loss:3.0782 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1253
Validation loss decreased (0.147540 --> 0.144289).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7229538
	speed: 0.0306s/iter; left time: 770.2919s
	iters: 200, epoch: 6 | loss: 30.8400211
	speed: 0.0271s/iter; left time: 678.9834s
Epoch: 6 cost time: 7.583710432052612
Epoch: 6, Steps: 266 Train Loss: 30.9107 (Forecasting Loss:0.1475 + XiCon Loss:3.0763 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1713867
	speed: 0.0307s/iter; left time: 764.7812s
	iters: 200, epoch: 7 | loss: 30.6929684
	speed: 0.0286s/iter; left time: 710.1423s
Epoch: 7 cost time: 7.849780321121216
Epoch: 7, Steps: 266 Train Loss: 30.8748 (Forecasting Loss:0.1471 + XiCon Loss:3.0728 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1250
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.5725708
	speed: 0.0304s/iter; left time: 747.9493s
	iters: 200, epoch: 8 | loss: 30.8635597
	speed: 0.0280s/iter; left time: 688.0620s
Epoch: 8 cost time: 7.70837926864624
Epoch: 8, Steps: 266 Train Loss: 30.8685 (Forecasting Loss:0.1470 + XiCon Loss:3.0721 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0216408
	speed: 0.0299s/iter; left time: 728.9605s
	iters: 200, epoch: 9 | loss: 30.6979237
	speed: 0.0281s/iter; left time: 682.1537s
Epoch: 9 cost time: 7.697835206985474
Epoch: 9, Steps: 266 Train Loss: 30.8813 (Forecasting Loss:0.1470 + XiCon Loss:3.0734 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
Validation loss decreased (0.144289 --> 0.144169).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1205826
	speed: 0.0303s/iter; left time: 729.5725s
	iters: 200, epoch: 10 | loss: 30.4316368
	speed: 0.0271s/iter; left time: 649.8507s
Epoch: 10 cost time: 7.641651630401611
Epoch: 10, Steps: 266 Train Loss: 30.9030 (Forecasting Loss:0.1468 + XiCon Loss:3.0756 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8262939
	speed: 0.0304s/iter; left time: 725.0509s
	iters: 200, epoch: 11 | loss: 30.3886662
	speed: 0.0285s/iter; left time: 677.4882s
Epoch: 11 cost time: 7.75112247467041
Epoch: 11, Steps: 266 Train Loss: 30.8927 (Forecasting Loss:0.1468 + XiCon Loss:3.0746 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9393406
	speed: 0.0309s/iter; left time: 728.6028s
	iters: 200, epoch: 12 | loss: 31.4035091
	speed: 0.0284s/iter; left time: 666.2856s
Epoch: 12 cost time: 7.775758266448975
Epoch: 12, Steps: 266 Train Loss: 30.8680 (Forecasting Loss:0.1469 + XiCon Loss:3.0721 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.9435368
	speed: 0.0312s/iter; left time: 727.5907s
	iters: 200, epoch: 13 | loss: 30.4707279
	speed: 0.0287s/iter; left time: 666.2315s
Epoch: 13 cost time: 7.921697616577148
Epoch: 13, Steps: 266 Train Loss: 30.8571 (Forecasting Loss:0.1468 + XiCon Loss:3.0710 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.1696606
	speed: 0.0308s/iter; left time: 710.1861s
	iters: 200, epoch: 14 | loss: 30.9142151
	speed: 0.0278s/iter; left time: 636.9250s
Epoch: 14 cost time: 7.751248598098755
Epoch: 14, Steps: 266 Train Loss: 30.8829 (Forecasting Loss:0.1468 + XiCon Loss:3.0736 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
Validation loss decreased (0.144169 --> 0.144140).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9244556
	speed: 0.0297s/iter; left time: 676.4549s
	iters: 200, epoch: 15 | loss: 30.6408100
	speed: 0.0287s/iter; left time: 651.7857s
Epoch: 15 cost time: 7.7051100730896
Epoch: 15, Steps: 266 Train Loss: 30.8503 (Forecasting Loss:0.1468 + XiCon Loss:3.0704 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9113674
	speed: 0.0303s/iter; left time: 682.5527s
	iters: 200, epoch: 16 | loss: 31.6228409
	speed: 0.0273s/iter; left time: 610.9596s
Epoch: 16 cost time: 7.642455101013184
Epoch: 16, Steps: 266 Train Loss: 30.8693 (Forecasting Loss:0.1468 + XiCon Loss:3.0722 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5671329
	speed: 0.0310s/iter; left time: 690.1231s
	iters: 200, epoch: 17 | loss: 31.0930672
	speed: 0.0273s/iter; left time: 604.4543s
Epoch: 17 cost time: 7.7052857875823975
Epoch: 17, Steps: 266 Train Loss: 30.8795 (Forecasting Loss:0.1468 + XiCon Loss:3.0733 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.5524139
	speed: 0.0301s/iter; left time: 662.6619s
	iters: 200, epoch: 18 | loss: 30.6845417
	speed: 0.0285s/iter; left time: 623.7443s
Epoch: 18 cost time: 7.74501895904541
Epoch: 18, Steps: 266 Train Loss: 30.8925 (Forecasting Loss:0.1468 + XiCon Loss:3.0746 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5657349
	speed: 0.0303s/iter; left time: 657.1432s
	iters: 200, epoch: 19 | loss: 30.7886448
	speed: 0.0290s/iter; left time: 627.5857s
Epoch: 19 cost time: 7.785126686096191
Epoch: 19, Steps: 266 Train Loss: 30.8551 (Forecasting Loss:0.1468 + XiCon Loss:3.0708 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
Validation loss decreased (0.144140 --> 0.144114).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.9796619
	speed: 0.0317s/iter; left time: 678.9448s
	iters: 200, epoch: 20 | loss: 30.5137978
	speed: 0.0281s/iter; left time: 600.4837s
Epoch: 20 cost time: 7.847714424133301
Epoch: 20, Steps: 266 Train Loss: 30.8821 (Forecasting Loss:0.1468 + XiCon Loss:3.0735 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
Validation loss decreased (0.144114 --> 0.144079).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.4182358
	speed: 0.0311s/iter; left time: 659.1194s
	iters: 200, epoch: 21 | loss: 30.8402519
	speed: 0.0281s/iter; left time: 592.0828s
Epoch: 21 cost time: 7.854485988616943
Epoch: 21, Steps: 266 Train Loss: 30.8711 (Forecasting Loss:0.1468 + XiCon Loss:3.0724 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.9995956
	speed: 0.0304s/iter; left time: 635.7482s
	iters: 200, epoch: 22 | loss: 31.1740379
	speed: 0.0280s/iter; left time: 582.7404s
Epoch: 22 cost time: 7.716644525527954
Epoch: 22, Steps: 266 Train Loss: 30.8418 (Forecasting Loss:0.1468 + XiCon Loss:3.0695 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
Validation loss decreased (0.144079 --> 0.144062).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.6337166
	speed: 0.0301s/iter; left time: 621.1783s
	iters: 200, epoch: 23 | loss: 30.5864449
	speed: 0.0286s/iter; left time: 588.5095s
Epoch: 23 cost time: 7.804956436157227
Epoch: 23, Steps: 266 Train Loss: 30.8714 (Forecasting Loss:0.1467 + XiCon Loss:3.0725 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6579285
	speed: 0.0310s/iter; left time: 632.6317s
	iters: 200, epoch: 24 | loss: 31.0976067
	speed: 0.0287s/iter; left time: 581.3208s
Epoch: 24 cost time: 7.81243896484375
Epoch: 24, Steps: 266 Train Loss: 30.8769 (Forecasting Loss:0.1468 + XiCon Loss:3.0730 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.9597683
	speed: 0.0303s/iter; left time: 609.8756s
	iters: 200, epoch: 25 | loss: 30.8314266
	speed: 0.0281s/iter; left time: 563.1499s
Epoch: 25 cost time: 7.705928564071655
Epoch: 25, Steps: 266 Train Loss: 30.8737 (Forecasting Loss:0.1469 + XiCon Loss:3.0727 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.5771370
	speed: 0.0304s/iter; left time: 603.3620s
	iters: 200, epoch: 26 | loss: 31.4980240
	speed: 0.0281s/iter; left time: 555.3961s
Epoch: 26 cost time: 7.667435169219971
Epoch: 26, Steps: 266 Train Loss: 30.8585 (Forecasting Loss:0.1468 + XiCon Loss:3.0712 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.7147026
	speed: 0.0306s/iter; left time: 598.7087s
	iters: 200, epoch: 27 | loss: 31.1899433
	speed: 0.0279s/iter; left time: 543.2918s
Epoch: 27 cost time: 7.733509302139282
Epoch: 27, Steps: 266 Train Loss: 30.8756 (Forecasting Loss:0.1468 + XiCon Loss:3.0729 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.5251503
	speed: 0.0301s/iter; left time: 580.7077s
	iters: 200, epoch: 28 | loss: 31.0055523
	speed: 0.0278s/iter; left time: 534.6944s
Epoch: 28 cost time: 7.650152921676636
Epoch: 28, Steps: 266 Train Loss: 30.8407 (Forecasting Loss:0.1468 + XiCon Loss:3.0694 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.9566727
	speed: 0.0303s/iter; left time: 577.8828s
	iters: 200, epoch: 29 | loss: 30.6096783
	speed: 0.0290s/iter; left time: 549.0232s
Epoch: 29 cost time: 7.829315423965454
Epoch: 29, Steps: 266 Train Loss: 30.8627 (Forecasting Loss:0.1468 + XiCon Loss:3.0716 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.7236004
	speed: 0.0306s/iter; left time: 574.5819s
	iters: 200, epoch: 30 | loss: 31.1186886
	speed: 0.0281s/iter; left time: 525.1433s
Epoch: 30 cost time: 7.70465350151062
Epoch: 30, Steps: 266 Train Loss: 30.8495 (Forecasting Loss:0.1469 + XiCon Loss:3.0703 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 31.2012444
	speed: 0.0300s/iter; left time: 556.4663s
	iters: 200, epoch: 31 | loss: 30.5707226
	speed: 0.0293s/iter; left time: 538.9013s
Epoch: 31 cost time: 7.818553686141968
Epoch: 31, Steps: 266 Train Loss: 30.8889 (Forecasting Loss:0.1467 + XiCon Loss:3.0742 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.0413246
	speed: 0.0308s/iter; left time: 562.2823s
	iters: 200, epoch: 32 | loss: 31.4421501
	speed: 0.0285s/iter; left time: 518.2079s
Epoch: 32 cost time: 7.8558385372161865
Epoch: 32, Steps: 266 Train Loss: 30.8827 (Forecasting Loss:0.1468 + XiCon Loss:3.0736 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06474676728248596, mae:0.18448898196220398, mape:0.44936469197273254, mspe:8.166556358337402 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6710
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.3479424
	speed: 0.0306s/iter; left time: 812.2359s
	iters: 200, epoch: 1 | loss: 32.4784508
	speed: 0.0281s/iter; left time: 741.6174s
Epoch: 1 cost time: 7.791759252548218
Epoch: 1, Steps: 266 Train Loss: 32.9578 (Forecasting Loss:0.1900 + XiCon Loss:3.2768 x Lambda(10.0)), Vali MSE Loss: 0.1611 Test MSE Loss: 0.1377
Validation loss decreased (inf --> 0.161123).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.9048576
	speed: 0.0304s/iter; left time: 798.6958s
	iters: 200, epoch: 2 | loss: 31.2079525
	speed: 0.0281s/iter; left time: 733.6001s
Epoch: 2 cost time: 7.7531609535217285
Epoch: 2, Steps: 266 Train Loss: 31.4843 (Forecasting Loss:0.1588 + XiCon Loss:3.1326 x Lambda(10.0)), Vali MSE Loss: 0.1502 Test MSE Loss: 0.1322
Validation loss decreased (0.161123 --> 0.150171).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0739174
	speed: 0.0318s/iter; left time: 826.1760s
	iters: 200, epoch: 3 | loss: 30.2320137
	speed: 0.0283s/iter; left time: 732.6686s
Epoch: 3 cost time: 7.901822328567505
Epoch: 3, Steps: 266 Train Loss: 30.7011 (Forecasting Loss:0.1522 + XiCon Loss:3.0549 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1271
Validation loss decreased (0.150171 --> 0.147889).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.5608749
	speed: 0.0303s/iter; left time: 778.4756s
	iters: 200, epoch: 4 | loss: 30.6912708
	speed: 0.0288s/iter; left time: 738.4142s
Epoch: 4 cost time: 7.769269943237305
Epoch: 4, Steps: 266 Train Loss: 30.6327 (Forecasting Loss:0.1494 + XiCon Loss:3.0483 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1269
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5898361
	speed: 0.0304s/iter; left time: 772.3822s
	iters: 200, epoch: 5 | loss: 30.1317749
	speed: 0.0283s/iter; left time: 716.3187s
Epoch: 5 cost time: 7.822917938232422
Epoch: 5, Steps: 266 Train Loss: 30.5984 (Forecasting Loss:0.1480 + XiCon Loss:3.0450 x Lambda(10.0)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.1256
Validation loss decreased (0.147889 --> 0.146554).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.2751961
	speed: 0.0306s/iter; left time: 770.2053s
	iters: 200, epoch: 6 | loss: 31.1461411
	speed: 0.0278s/iter; left time: 697.8181s
Epoch: 6 cost time: 7.741103410720825
Epoch: 6, Steps: 266 Train Loss: 30.5483 (Forecasting Loss:0.1476 + XiCon Loss:3.0401 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1255
Validation loss decreased (0.146554 --> 0.143991).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5192299
	speed: 0.0300s/iter; left time: 747.0217s
	iters: 200, epoch: 7 | loss: 30.9407024
	speed: 0.0281s/iter; left time: 697.9759s
Epoch: 7 cost time: 7.7122368812561035
Epoch: 7, Steps: 266 Train Loss: 30.5721 (Forecasting Loss:0.1472 + XiCon Loss:3.0425 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8482304
	speed: 0.0297s/iter; left time: 732.6467s
	iters: 200, epoch: 8 | loss: 30.5687943
	speed: 0.0277s/iter; left time: 680.3866s
Epoch: 8 cost time: 7.634361505508423
Epoch: 8, Steps: 266 Train Loss: 30.6127 (Forecasting Loss:0.1470 + XiCon Loss:3.0466 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1251
Validation loss decreased (0.143991 --> 0.143982).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3993187
	speed: 0.0301s/iter; left time: 734.1039s
	iters: 200, epoch: 9 | loss: 31.3043785
	speed: 0.0286s/iter; left time: 693.5851s
Epoch: 9 cost time: 7.737577199935913
Epoch: 9, Steps: 266 Train Loss: 30.5892 (Forecasting Loss:0.1469 + XiCon Loss:3.0442 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1250
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1028824
	speed: 0.0313s/iter; left time: 755.1422s
	iters: 200, epoch: 10 | loss: 30.2235184
	speed: 0.0276s/iter; left time: 662.5340s
Epoch: 10 cost time: 7.823540210723877
Epoch: 10, Steps: 266 Train Loss: 30.5760 (Forecasting Loss:0.1468 + XiCon Loss:3.0429 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1250
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4796982
	speed: 0.0296s/iter; left time: 705.2955s
	iters: 200, epoch: 11 | loss: 30.3255119
	speed: 0.0280s/iter; left time: 665.8369s
Epoch: 11 cost time: 7.605418920516968
Epoch: 11, Steps: 266 Train Loss: 30.5631 (Forecasting Loss:0.1468 + XiCon Loss:3.0416 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9981403
	speed: 0.0302s/iter; left time: 713.0905s
	iters: 200, epoch: 12 | loss: 30.4210987
	speed: 0.0293s/iter; left time: 686.9132s
Epoch: 12 cost time: 7.954255819320679
Epoch: 12, Steps: 266 Train Loss: 30.5658 (Forecasting Loss:0.1469 + XiCon Loss:3.0419 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8848724
	speed: 0.0297s/iter; left time: 692.9133s
	iters: 200, epoch: 13 | loss: 30.3839359
	speed: 0.0280s/iter; left time: 650.7967s
Epoch: 13 cost time: 7.672325372695923
Epoch: 13, Steps: 266 Train Loss: 30.5639 (Forecasting Loss:0.1468 + XiCon Loss:3.0417 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1249
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0724373
	speed: 0.0307s/iter; left time: 706.5663s
	iters: 200, epoch: 14 | loss: 30.4693298
	speed: 0.0281s/iter; left time: 644.8861s
Epoch: 14 cost time: 7.770091533660889
Epoch: 14, Steps: 266 Train Loss: 30.5899 (Forecasting Loss:0.1468 + XiCon Loss:3.0443 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1249
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9406815
	speed: 0.0303s/iter; left time: 690.3373s
	iters: 200, epoch: 15 | loss: 30.0900497
	speed: 0.0282s/iter; left time: 640.3678s
Epoch: 15 cost time: 7.839309215545654
Epoch: 15, Steps: 266 Train Loss: 30.5761 (Forecasting Loss:0.1468 + XiCon Loss:3.0429 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.7569046
	speed: 0.0308s/iter; left time: 692.7855s
	iters: 200, epoch: 16 | loss: 30.7181110
	speed: 0.0279s/iter; left time: 626.1779s
Epoch: 16 cost time: 7.699836730957031
Epoch: 16, Steps: 266 Train Loss: 30.6023 (Forecasting Loss:0.1468 + XiCon Loss:3.0455 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.8192005
	speed: 0.0300s/iter; left time: 668.4092s
	iters: 200, epoch: 17 | loss: 30.3500328
	speed: 0.0282s/iter; left time: 624.3789s
Epoch: 17 cost time: 7.802755832672119
Epoch: 17, Steps: 266 Train Loss: 30.5730 (Forecasting Loss:0.1468 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.0295353
	speed: 0.0310s/iter; left time: 682.3646s
	iters: 200, epoch: 18 | loss: 30.0819569
	speed: 0.0273s/iter; left time: 596.9786s
Epoch: 18 cost time: 7.736603498458862
Epoch: 18, Steps: 266 Train Loss: 30.6103 (Forecasting Loss:0.1468 + XiCon Loss:3.0464 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1249
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06516749411821365, mae:0.18508502840995789, mape:0.4533626437187195, mspe:8.237655639648438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0647+-0.00043, MAE:0.1844+-0.00050, MAPE:0.4496+-0.00268, MSPE:8.1662+-0.05803, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9544
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.7366276
	speed: 0.0341s/iter; left time: 901.1907s
	iters: 200, epoch: 1 | loss: 3.7334139
	speed: 0.0286s/iter; left time: 753.2695s
Epoch: 1 cost time: 8.198559761047363
Epoch: 1, Steps: 265 Train Loss: 3.7229 (Forecasting Loss:0.3531 + XiCon Loss:3.3698 x Lambda(1.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2776
Validation loss decreased (inf --> 0.336489).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5363801
	speed: 0.0316s/iter; left time: 826.6395s
	iters: 200, epoch: 2 | loss: 3.5361955
	speed: 0.0292s/iter; left time: 759.6142s
Epoch: 2 cost time: 8.05995512008667
Epoch: 2, Steps: 265 Train Loss: 3.5475 (Forecasting Loss:0.2415 + XiCon Loss:3.3060 x Lambda(1.0)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1739
Validation loss decreased (0.336489 --> 0.216739).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3868406
	speed: 0.0321s/iter; left time: 830.1619s
	iters: 200, epoch: 3 | loss: 3.3961248
	speed: 0.0300s/iter; left time: 773.7859s
Epoch: 3 cost time: 8.197031736373901
Epoch: 3, Steps: 265 Train Loss: 3.4179 (Forecasting Loss:0.2144 + XiCon Loss:3.2034 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1709
Validation loss decreased (0.216739 --> 0.211849).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3509171
	speed: 0.0316s/iter; left time: 809.8244s
	iters: 200, epoch: 4 | loss: 3.3856041
	speed: 0.0299s/iter; left time: 762.2056s
Epoch: 4 cost time: 8.114839553833008
Epoch: 4, Steps: 265 Train Loss: 3.3814 (Forecasting Loss:0.2111 + XiCon Loss:3.1703 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1700
Validation loss decreased (0.211849 --> 0.210562).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3690681
	speed: 0.0309s/iter; left time: 783.7627s
	iters: 200, epoch: 5 | loss: 3.3805537
	speed: 0.0290s/iter; left time: 733.0361s
Epoch: 5 cost time: 7.888726234436035
Epoch: 5, Steps: 265 Train Loss: 3.3678 (Forecasting Loss:0.2098 + XiCon Loss:3.1580 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1696
Validation loss decreased (0.210562 --> 0.209850).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3956037
	speed: 0.0314s/iter; left time: 786.7606s
	iters: 200, epoch: 6 | loss: 3.3300297
	speed: 0.0298s/iter; left time: 743.1603s
Epoch: 6 cost time: 8.046497583389282
Epoch: 6, Steps: 265 Train Loss: 3.3641 (Forecasting Loss:0.2093 + XiCon Loss:3.1548 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1694
Validation loss decreased (0.209850 --> 0.209745).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3663838
	speed: 0.0312s/iter; left time: 774.2091s
	iters: 200, epoch: 7 | loss: 3.3967385
	speed: 0.0303s/iter; left time: 747.6452s
Epoch: 7 cost time: 8.135692358016968
Epoch: 7, Steps: 265 Train Loss: 3.3616 (Forecasting Loss:0.2092 + XiCon Loss:3.1524 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3785071
	speed: 0.0308s/iter; left time: 755.3102s
	iters: 200, epoch: 8 | loss: 3.3808270
	speed: 0.0289s/iter; left time: 706.5689s
Epoch: 8 cost time: 7.921300649642944
Epoch: 8, Steps: 265 Train Loss: 3.3596 (Forecasting Loss:0.2090 + XiCon Loss:3.1506 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
Validation loss decreased (0.209745 --> 0.209661).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3694468
	speed: 0.0316s/iter; left time: 767.3834s
	iters: 200, epoch: 9 | loss: 3.3510818
	speed: 0.0288s/iter; left time: 697.0390s
Epoch: 9 cost time: 8.030693292617798
Epoch: 9, Steps: 265 Train Loss: 3.3599 (Forecasting Loss:0.2088 + XiCon Loss:3.1511 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3769746
	speed: 0.0318s/iter; left time: 763.8984s
	iters: 200, epoch: 10 | loss: 3.3564878
	speed: 0.0290s/iter; left time: 694.5500s
Epoch: 10 cost time: 7.9827775955200195
Epoch: 10, Steps: 265 Train Loss: 3.3574 (Forecasting Loss:0.2089 + XiCon Loss:3.1485 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1692
Validation loss decreased (0.209661 --> 0.209502).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3538613
	speed: 0.0319s/iter; left time: 756.9316s
	iters: 200, epoch: 11 | loss: 3.3316803
	speed: 0.0290s/iter; left time: 686.5860s
Epoch: 11 cost time: 7.99581503868103
Epoch: 11, Steps: 265 Train Loss: 3.3598 (Forecasting Loss:0.2089 + XiCon Loss:3.1509 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3707299
	speed: 0.0325s/iter; left time: 762.7973s
	iters: 200, epoch: 12 | loss: 3.3618405
	speed: 0.0310s/iter; left time: 725.3286s
Epoch: 12 cost time: 8.385998249053955
Epoch: 12, Steps: 265 Train Loss: 3.3597 (Forecasting Loss:0.2088 + XiCon Loss:3.1509 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3691218
	speed: 0.0316s/iter; left time: 732.9407s
	iters: 200, epoch: 13 | loss: 3.3363428
	speed: 0.0293s/iter; left time: 677.8105s
Epoch: 13 cost time: 7.95724892616272
Epoch: 13, Steps: 265 Train Loss: 3.3583 (Forecasting Loss:0.2088 + XiCon Loss:3.1495 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3479867
	speed: 0.0318s/iter; left time: 728.8861s
	iters: 200, epoch: 14 | loss: 3.3680029
	speed: 0.0290s/iter; left time: 662.6378s
Epoch: 14 cost time: 7.972940921783447
Epoch: 14, Steps: 265 Train Loss: 3.3581 (Forecasting Loss:0.2088 + XiCon Loss:3.1493 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3741271
	speed: 0.0306s/iter; left time: 694.5814s
	iters: 200, epoch: 15 | loss: 3.3571088
	speed: 0.0293s/iter; left time: 661.0930s
Epoch: 15 cost time: 7.85808253288269
Epoch: 15, Steps: 265 Train Loss: 3.3583 (Forecasting Loss:0.2087 + XiCon Loss:3.1496 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3870564
	speed: 0.0317s/iter; left time: 710.7481s
	iters: 200, epoch: 16 | loss: 3.3734319
	speed: 0.0291s/iter; left time: 648.6558s
Epoch: 16 cost time: 8.035259246826172
Epoch: 16, Steps: 265 Train Loss: 3.3594 (Forecasting Loss:0.2088 + XiCon Loss:3.1507 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1692
Validation loss decreased (0.209502 --> 0.209442).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3829153
	speed: 0.0317s/iter; left time: 701.6397s
	iters: 200, epoch: 17 | loss: 3.3996770
	speed: 0.0305s/iter; left time: 673.3197s
Epoch: 17 cost time: 8.185975790023804
Epoch: 17, Steps: 265 Train Loss: 3.3585 (Forecasting Loss:0.2088 + XiCon Loss:3.1497 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3823586
	speed: 0.0311s/iter; left time: 680.7833s
	iters: 200, epoch: 18 | loss: 3.3917043
	speed: 0.0290s/iter; left time: 632.7062s
Epoch: 18 cost time: 7.907452821731567
Epoch: 18, Steps: 265 Train Loss: 3.3575 (Forecasting Loss:0.2088 + XiCon Loss:3.1487 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3495731
	speed: 0.0323s/iter; left time: 698.5993s
	iters: 200, epoch: 19 | loss: 3.3547142
	speed: 0.0296s/iter; left time: 637.4251s
Epoch: 19 cost time: 8.12474274635315
Epoch: 19, Steps: 265 Train Loss: 3.3585 (Forecasting Loss:0.2088 + XiCon Loss:3.1497 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3223939
	speed: 0.0325s/iter; left time: 694.9264s
	iters: 200, epoch: 20 | loss: 3.3601553
	speed: 0.0298s/iter; left time: 634.0850s
Epoch: 20 cost time: 8.168931245803833
Epoch: 20, Steps: 265 Train Loss: 3.3577 (Forecasting Loss:0.2088 + XiCon Loss:3.1490 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.3687778
	speed: 0.0315s/iter; left time: 665.3315s
	iters: 200, epoch: 21 | loss: 3.3381686
	speed: 0.0285s/iter; left time: 598.9805s
Epoch: 21 cost time: 7.918673515319824
Epoch: 21, Steps: 265 Train Loss: 3.3583 (Forecasting Loss:0.2087 + XiCon Loss:3.1496 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3821754
	speed: 0.0321s/iter; left time: 669.5775s
	iters: 200, epoch: 22 | loss: 3.3611307
	speed: 0.0303s/iter; left time: 628.4950s
Epoch: 22 cost time: 8.257879495620728
Epoch: 22, Steps: 265 Train Loss: 3.3579 (Forecasting Loss:0.2087 + XiCon Loss:3.1492 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3823295
	speed: 0.0312s/iter; left time: 642.2656s
	iters: 200, epoch: 23 | loss: 3.3367918
	speed: 0.0295s/iter; left time: 604.7075s
Epoch: 23 cost time: 7.953225612640381
Epoch: 23, Steps: 265 Train Loss: 3.3577 (Forecasting Loss:0.2088 + XiCon Loss:3.1489 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3632648
	speed: 0.0311s/iter; left time: 631.6163s
	iters: 200, epoch: 24 | loss: 3.3610635
	speed: 0.0293s/iter; left time: 591.2877s
Epoch: 24 cost time: 7.972540378570557
Epoch: 24, Steps: 265 Train Loss: 3.3579 (Forecasting Loss:0.2089 + XiCon Loss:3.1490 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3609471
	speed: 0.0310s/iter; left time: 621.1900s
	iters: 200, epoch: 25 | loss: 3.3465247
	speed: 0.0282s/iter; left time: 561.7379s
Epoch: 25 cost time: 7.777448654174805
Epoch: 25, Steps: 265 Train Loss: 3.3603 (Forecasting Loss:0.2088 + XiCon Loss:3.1515 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1692
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3533180
	speed: 0.0321s/iter; left time: 634.7851s
	iters: 200, epoch: 26 | loss: 3.3668773
	speed: 0.0288s/iter; left time: 566.0708s
Epoch: 26 cost time: 8.006804704666138
Epoch: 26, Steps: 265 Train Loss: 3.3588 (Forecasting Loss:0.2088 + XiCon Loss:3.1500 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09881289303302765, mae:0.23957529664039612, mape:0.5692863464355469, mspe:11.826334953308105 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3283
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.7038097
	speed: 0.0339s/iter; left time: 893.7586s
	iters: 200, epoch: 1 | loss: 3.7588489
	speed: 0.0319s/iter; left time: 839.0639s
Epoch: 1 cost time: 8.647427797317505
Epoch: 1, Steps: 265 Train Loss: 3.7468 (Forecasting Loss:0.3608 + XiCon Loss:3.3860 x Lambda(1.0)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2830
Validation loss decreased (inf --> 0.335581).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5457129
	speed: 0.0315s/iter; left time: 823.2976s
	iters: 200, epoch: 2 | loss: 3.4987013
	speed: 0.0289s/iter; left time: 751.4496s
Epoch: 2 cost time: 7.94962739944458
Epoch: 2, Steps: 265 Train Loss: 3.5521 (Forecasting Loss:0.2416 + XiCon Loss:3.3106 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1723
Validation loss decreased (0.335581 --> 0.219104).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3987491
	speed: 0.0320s/iter; left time: 829.1081s
	iters: 200, epoch: 3 | loss: 3.3850234
	speed: 0.0292s/iter; left time: 752.9398s
Epoch: 3 cost time: 8.059966564178467
Epoch: 3, Steps: 265 Train Loss: 3.4110 (Forecasting Loss:0.2134 + XiCon Loss:3.1976 x Lambda(1.0)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1689
Validation loss decreased (0.219104 --> 0.214491).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3707740
	speed: 0.0308s/iter; left time: 788.7288s
	iters: 200, epoch: 4 | loss: 3.3686283
	speed: 0.0288s/iter; left time: 735.1891s
Epoch: 4 cost time: 7.808454513549805
Epoch: 4, Steps: 265 Train Loss: 3.3780 (Forecasting Loss:0.2102 + XiCon Loss:3.1678 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1674
Validation loss decreased (0.214491 --> 0.211527).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3415351
	speed: 0.0310s/iter; left time: 785.1225s
	iters: 200, epoch: 5 | loss: 3.3632572
	speed: 0.0285s/iter; left time: 720.1642s
Epoch: 5 cost time: 7.904557228088379
Epoch: 5, Steps: 265 Train Loss: 3.3649 (Forecasting Loss:0.2090 + XiCon Loss:3.1559 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1672
Validation loss decreased (0.211527 --> 0.210541).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3768592
	speed: 0.0318s/iter; left time: 797.8766s
	iters: 200, epoch: 6 | loss: 3.3400123
	speed: 0.0296s/iter; left time: 738.8106s
Epoch: 6 cost time: 8.070169925689697
Epoch: 6, Steps: 265 Train Loss: 3.3585 (Forecasting Loss:0.2083 + XiCon Loss:3.1502 x Lambda(1.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1668
Validation loss decreased (0.210541 --> 0.209914).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3512290
	speed: 0.0320s/iter; left time: 792.9437s
	iters: 200, epoch: 7 | loss: 3.3361480
	speed: 0.0295s/iter; left time: 728.3599s
Epoch: 7 cost time: 8.078591346740723
Epoch: 7, Steps: 265 Train Loss: 3.3554 (Forecasting Loss:0.2081 + XiCon Loss:3.1474 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1666
Validation loss decreased (0.209914 --> 0.209408).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3926404
	speed: 0.0316s/iter; left time: 776.4358s
	iters: 200, epoch: 8 | loss: 3.3506107
	speed: 0.0294s/iter; left time: 718.0554s
Epoch: 8 cost time: 7.982945919036865
Epoch: 8, Steps: 265 Train Loss: 3.3532 (Forecasting Loss:0.2079 + XiCon Loss:3.1453 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1666
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3356369
	speed: 0.0309s/iter; left time: 750.2435s
	iters: 200, epoch: 9 | loss: 3.3292789
	speed: 0.0287s/iter; left time: 693.1511s
Epoch: 9 cost time: 7.897831439971924
Epoch: 9, Steps: 265 Train Loss: 3.3520 (Forecasting Loss:0.2077 + XiCon Loss:3.1443 x Lambda(1.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1666
Validation loss decreased (0.209408 --> 0.209317).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3236394
	speed: 0.0318s/iter; left time: 764.0479s
	iters: 200, epoch: 10 | loss: 3.3372090
	speed: 0.0289s/iter; left time: 690.3383s
Epoch: 10 cost time: 7.983752965927124
Epoch: 10, Steps: 265 Train Loss: 3.3518 (Forecasting Loss:0.2078 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1666
Validation loss decreased (0.209317 --> 0.209033).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3356643
	speed: 0.0310s/iter; left time: 737.0623s
	iters: 200, epoch: 11 | loss: 3.3276505
	speed: 0.0284s/iter; left time: 671.1820s
Epoch: 11 cost time: 7.889459133148193
Epoch: 11, Steps: 265 Train Loss: 3.3523 (Forecasting Loss:0.2076 + XiCon Loss:3.1447 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3246403
	speed: 0.0313s/iter; left time: 734.4984s
	iters: 200, epoch: 12 | loss: 3.3256962
	speed: 0.0292s/iter; left time: 682.9280s
Epoch: 12 cost time: 7.9751877784729
Epoch: 12, Steps: 265 Train Loss: 3.3510 (Forecasting Loss:0.2078 + XiCon Loss:3.1432 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1665
Validation loss decreased (0.209033 --> 0.208967).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3690529
	speed: 0.0318s/iter; left time: 739.2429s
	iters: 200, epoch: 13 | loss: 3.3476660
	speed: 0.0296s/iter; left time: 683.5417s
Epoch: 13 cost time: 8.080904483795166
Epoch: 13, Steps: 265 Train Loss: 3.3518 (Forecasting Loss:0.2078 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3672030
	speed: 0.0314s/iter; left time: 720.1346s
	iters: 200, epoch: 14 | loss: 3.3481452
	speed: 0.0292s/iter; left time: 668.1274s
Epoch: 14 cost time: 8.00119924545288
Epoch: 14, Steps: 265 Train Loss: 3.3521 (Forecasting Loss:0.2077 + XiCon Loss:3.1445 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3664069
	speed: 0.0315s/iter; left time: 714.2713s
	iters: 200, epoch: 15 | loss: 3.3568423
	speed: 0.0289s/iter; left time: 653.9637s
Epoch: 15 cost time: 7.9416985511779785
Epoch: 15, Steps: 265 Train Loss: 3.3517 (Forecasting Loss:0.2077 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3408549
	speed: 0.0316s/iter; left time: 709.0832s
	iters: 200, epoch: 16 | loss: 3.3402317
	speed: 0.0291s/iter; left time: 648.5807s
Epoch: 16 cost time: 7.967166423797607
Epoch: 16, Steps: 265 Train Loss: 3.3505 (Forecasting Loss:0.2077 + XiCon Loss:3.1428 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1665
Validation loss decreased (0.208967 --> 0.208929).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3538320
	speed: 0.0311s/iter; left time: 689.8378s
	iters: 200, epoch: 17 | loss: 3.3754225
	speed: 0.0290s/iter; left time: 639.7348s
Epoch: 17 cost time: 7.919015169143677
Epoch: 17, Steps: 265 Train Loss: 3.3522 (Forecasting Loss:0.2078 + XiCon Loss:3.1444 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3643336
	speed: 0.0309s/iter; left time: 677.0954s
	iters: 200, epoch: 18 | loss: 3.3387637
	speed: 0.0286s/iter; left time: 622.6534s
Epoch: 18 cost time: 7.842611789703369
Epoch: 18, Steps: 265 Train Loss: 3.3505 (Forecasting Loss:0.2077 + XiCon Loss:3.1428 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3717844
	speed: 0.0318s/iter; left time: 688.2954s
	iters: 200, epoch: 19 | loss: 3.3530595
	speed: 0.0291s/iter; left time: 627.4118s
Epoch: 19 cost time: 8.056922197341919
Epoch: 19, Steps: 265 Train Loss: 3.3514 (Forecasting Loss:0.2078 + XiCon Loss:3.1437 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3694892
	speed: 0.0321s/iter; left time: 686.6249s
	iters: 200, epoch: 20 | loss: 3.3140981
	speed: 0.0294s/iter; left time: 625.3089s
Epoch: 20 cost time: 8.132561445236206
Epoch: 20, Steps: 265 Train Loss: 3.3519 (Forecasting Loss:0.2077 + XiCon Loss:3.1442 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1665
Validation loss decreased (0.208929 --> 0.208889).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.3400595
	speed: 0.0326s/iter; left time: 688.8115s
	iters: 200, epoch: 21 | loss: 3.3543725
	speed: 0.0299s/iter; left time: 627.9822s
Epoch: 21 cost time: 8.189681768417358
Epoch: 21, Steps: 265 Train Loss: 3.3512 (Forecasting Loss:0.2077 + XiCon Loss:3.1435 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3991277
	speed: 0.0310s/iter; left time: 646.5899s
	iters: 200, epoch: 22 | loss: 3.3321531
	speed: 0.0293s/iter; left time: 607.2099s
Epoch: 22 cost time: 7.910083293914795
Epoch: 22, Steps: 265 Train Loss: 3.3517 (Forecasting Loss:0.2077 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3862913
	speed: 0.0317s/iter; left time: 652.7370s
	iters: 200, epoch: 23 | loss: 3.3596895
	speed: 0.0296s/iter; left time: 605.6993s
Epoch: 23 cost time: 8.016458511352539
Epoch: 23, Steps: 265 Train Loss: 3.3501 (Forecasting Loss:0.2076 + XiCon Loss:3.1425 x Lambda(1.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3729947
	speed: 0.0308s/iter; left time: 625.1364s
	iters: 200, epoch: 24 | loss: 3.3353837
	speed: 0.0286s/iter; left time: 578.7493s
Epoch: 24 cost time: 7.843734264373779
Epoch: 24, Steps: 265 Train Loss: 3.3527 (Forecasting Loss:0.2078 + XiCon Loss:3.1449 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3780248
	speed: 0.0313s/iter; left time: 626.7347s
	iters: 200, epoch: 25 | loss: 3.3538413
	speed: 0.0295s/iter; left time: 588.3030s
Epoch: 25 cost time: 8.103673458099365
Epoch: 25, Steps: 265 Train Loss: 3.3515 (Forecasting Loss:0.2076 + XiCon Loss:3.1439 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1665
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3446877
	speed: 0.0319s/iter; left time: 631.1081s
	iters: 200, epoch: 26 | loss: 3.3627317
	speed: 0.0293s/iter; left time: 576.5249s
Epoch: 26 cost time: 8.080764293670654
Epoch: 26, Steps: 265 Train Loss: 3.3524 (Forecasting Loss:0.2077 + XiCon Loss:3.1447 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1665
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.3610723
	speed: 0.0316s/iter; left time: 616.6057s
	iters: 200, epoch: 27 | loss: 3.3440418
	speed: 0.0287s/iter; left time: 557.1194s
Epoch: 27 cost time: 7.952977180480957
Epoch: 27, Steps: 265 Train Loss: 3.3521 (Forecasting Loss:0.2077 + XiCon Loss:3.1444 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1665
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.3484530
	speed: 0.0312s/iter; left time: 601.1084s
	iters: 200, epoch: 28 | loss: 3.3212664
	speed: 0.0291s/iter; left time: 557.5008s
Epoch: 28 cost time: 7.987370252609253
Epoch: 28, Steps: 265 Train Loss: 3.3507 (Forecasting Loss:0.2077 + XiCon Loss:3.1430 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1665
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.3585353
	speed: 0.0310s/iter; left time: 587.4817s
	iters: 200, epoch: 29 | loss: 3.3184493
	speed: 0.0292s/iter; left time: 550.6260s
Epoch: 29 cost time: 7.906501293182373
Epoch: 29, Steps: 265 Train Loss: 3.3499 (Forecasting Loss:0.2077 + XiCon Loss:3.1422 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1665
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.3431895
	speed: 0.0328s/iter; left time: 614.4543s
	iters: 200, epoch: 30 | loss: 3.3550253
	speed: 0.0303s/iter; left time: 564.9458s
Epoch: 30 cost time: 8.284745454788208
Epoch: 30, Steps: 265 Train Loss: 3.3516 (Forecasting Loss:0.2075 + XiCon Loss:3.1441 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09657146036624908, mae:0.23650261759757996, mape:0.5706225037574768, mspe:12.210332870483398 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.7429
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.6828055
	speed: 0.0326s/iter; left time: 861.8814s
	iters: 200, epoch: 1 | loss: 3.6584582
	speed: 0.0299s/iter; left time: 786.5359s
Epoch: 1 cost time: 8.156500101089478
Epoch: 1, Steps: 265 Train Loss: 3.7134 (Forecasting Loss:0.3468 + XiCon Loss:3.3666 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2714
Validation loss decreased (inf --> 0.325128).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5109055
	speed: 0.0313s/iter; left time: 817.5538s
	iters: 200, epoch: 2 | loss: 3.4609692
	speed: 0.0286s/iter; left time: 744.9169s
Epoch: 2 cost time: 7.857516288757324
Epoch: 2, Steps: 265 Train Loss: 3.5241 (Forecasting Loss:0.2398 + XiCon Loss:3.2843 x Lambda(1.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1734
Validation loss decreased (0.325128 --> 0.220678).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.4435072
	speed: 0.0305s/iter; left time: 790.0183s
	iters: 200, epoch: 3 | loss: 3.3838203
	speed: 0.0305s/iter; left time: 786.0387s
Epoch: 3 cost time: 8.157600164413452
Epoch: 3, Steps: 265 Train Loss: 3.3995 (Forecasting Loss:0.2145 + XiCon Loss:3.1850 x Lambda(1.0)), Vali MSE Loss: 0.2160 Test MSE Loss: 0.1706
Validation loss decreased (0.220678 --> 0.215961).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3631299
	speed: 0.0318s/iter; left time: 814.2746s
	iters: 200, epoch: 4 | loss: 3.3442950
	speed: 0.0290s/iter; left time: 738.5030s
Epoch: 4 cost time: 8.065247774124146
Epoch: 4, Steps: 265 Train Loss: 3.3755 (Forecasting Loss:0.2113 + XiCon Loss:3.1643 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1699
Validation loss decreased (0.215961 --> 0.213581).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3454194
	speed: 0.0316s/iter; left time: 799.6483s
	iters: 200, epoch: 5 | loss: 3.3740499
	speed: 0.0302s/iter; left time: 761.0268s
Epoch: 5 cost time: 8.017348766326904
Epoch: 5, Steps: 265 Train Loss: 3.3661 (Forecasting Loss:0.2100 + XiCon Loss:3.1560 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1695
Validation loss decreased (0.213581 --> 0.212885).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4065604
	speed: 0.0319s/iter; left time: 799.1705s
	iters: 200, epoch: 6 | loss: 3.3858230
	speed: 0.0297s/iter; left time: 740.8675s
Epoch: 6 cost time: 8.122591495513916
Epoch: 6, Steps: 265 Train Loss: 3.3635 (Forecasting Loss:0.2093 + XiCon Loss:3.1543 x Lambda(1.0)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1694
Validation loss decreased (0.212885 --> 0.212245).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3999014
	speed: 0.0315s/iter; left time: 781.9836s
	iters: 200, epoch: 7 | loss: 3.3723450
	speed: 0.0291s/iter; left time: 719.7331s
Epoch: 7 cost time: 8.013797998428345
Epoch: 7, Steps: 265 Train Loss: 3.3664 (Forecasting Loss:0.2089 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1693
Validation loss decreased (0.212245 --> 0.211864).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3533857
	speed: 0.0314s/iter; left time: 771.0600s
	iters: 200, epoch: 8 | loss: 3.3408871
	speed: 0.0305s/iter; left time: 745.2959s
Epoch: 8 cost time: 8.239521980285645
Epoch: 8, Steps: 265 Train Loss: 3.3658 (Forecasting Loss:0.2088 + XiCon Loss:3.1571 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1693
Validation loss decreased (0.211864 --> 0.211774).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3849134
	speed: 0.0306s/iter; left time: 743.2148s
	iters: 200, epoch: 9 | loss: 3.3646307
	speed: 0.0293s/iter; left time: 708.4766s
Epoch: 9 cost time: 7.872008323669434
Epoch: 9, Steps: 265 Train Loss: 3.3670 (Forecasting Loss:0.2088 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1693
Validation loss decreased (0.211774 --> 0.211740).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3516047
	speed: 0.0312s/iter; left time: 749.9665s
	iters: 200, epoch: 10 | loss: 3.3368707
	speed: 0.0291s/iter; left time: 696.9667s
Epoch: 10 cost time: 7.944682598114014
Epoch: 10, Steps: 265 Train Loss: 3.3669 (Forecasting Loss:0.2087 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3995991
	speed: 0.0320s/iter; left time: 760.6525s
	iters: 200, epoch: 11 | loss: 3.3475416
	speed: 0.0287s/iter; left time: 679.2153s
Epoch: 11 cost time: 7.986338138580322
Epoch: 11, Steps: 265 Train Loss: 3.3662 (Forecasting Loss:0.2087 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1693
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3227682
	speed: 0.0322s/iter; left time: 756.0444s
	iters: 200, epoch: 12 | loss: 3.3664153
	speed: 0.0287s/iter; left time: 670.3870s
Epoch: 12 cost time: 8.018851518630981
Epoch: 12, Steps: 265 Train Loss: 3.3677 (Forecasting Loss:0.2087 + XiCon Loss:3.1590 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
Validation loss decreased (0.211740 --> 0.211578).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3548224
	speed: 0.0310s/iter; left time: 720.6544s
	iters: 200, epoch: 13 | loss: 3.3674474
	speed: 0.0298s/iter; left time: 689.2504s
Epoch: 13 cost time: 8.14584231376648
Epoch: 13, Steps: 265 Train Loss: 3.3662 (Forecasting Loss:0.2087 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3352354
	speed: 0.0316s/iter; left time: 725.1790s
	iters: 200, epoch: 14 | loss: 3.3432477
	speed: 0.0282s/iter; left time: 645.2892s
Epoch: 14 cost time: 7.877727508544922
Epoch: 14, Steps: 265 Train Loss: 3.3662 (Forecasting Loss:0.2086 + XiCon Loss:3.1576 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1693
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3544679
	speed: 0.0313s/iter; left time: 711.1452s
	iters: 200, epoch: 15 | loss: 3.3729072
	speed: 0.0292s/iter; left time: 659.5369s
Epoch: 15 cost time: 7.949803590774536
Epoch: 15, Steps: 265 Train Loss: 3.3673 (Forecasting Loss:0.2087 + XiCon Loss:3.1586 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1693
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3799438
	speed: 0.0309s/iter; left time: 693.2083s
	iters: 200, epoch: 16 | loss: 3.3669391
	speed: 0.0296s/iter; left time: 660.2236s
Epoch: 16 cost time: 7.9785826206207275
Epoch: 16, Steps: 265 Train Loss: 3.3667 (Forecasting Loss:0.2086 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1693
Validation loss decreased (0.211578 --> 0.211288).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3454022
	speed: 0.0314s/iter; left time: 695.1965s
	iters: 200, epoch: 17 | loss: 3.3693717
	speed: 0.0292s/iter; left time: 644.6639s
Epoch: 17 cost time: 7.93088698387146
Epoch: 17, Steps: 265 Train Loss: 3.3668 (Forecasting Loss:0.2087 + XiCon Loss:3.1582 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3377173
	speed: 0.0329s/iter; left time: 719.6807s
	iters: 200, epoch: 18 | loss: 3.4042811
	speed: 0.0311s/iter; left time: 676.9270s
Epoch: 18 cost time: 8.487752914428711
Epoch: 18, Steps: 265 Train Loss: 3.3658 (Forecasting Loss:0.2086 + XiCon Loss:3.1571 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3941889
	speed: 0.0315s/iter; left time: 681.0559s
	iters: 200, epoch: 19 | loss: 3.3736620
	speed: 0.0295s/iter; left time: 635.6708s
Epoch: 19 cost time: 8.03916072845459
Epoch: 19, Steps: 265 Train Loss: 3.3684 (Forecasting Loss:0.2086 + XiCon Loss:3.1598 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1693
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3566160
	speed: 0.0311s/iter; left time: 664.5308s
	iters: 200, epoch: 20 | loss: 3.3343551
	speed: 0.0292s/iter; left time: 621.5339s
Epoch: 20 cost time: 7.925296306610107
Epoch: 20, Steps: 265 Train Loss: 3.3653 (Forecasting Loss:0.2085 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1693
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.3566937
	speed: 0.0312s/iter; left time: 657.9302s
	iters: 200, epoch: 21 | loss: 3.3777144
	speed: 0.0288s/iter; left time: 603.8368s
Epoch: 21 cost time: 7.908251762390137
Epoch: 21, Steps: 265 Train Loss: 3.3669 (Forecasting Loss:0.2087 + XiCon Loss:3.1582 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3650324
	speed: 0.0312s/iter; left time: 649.5528s
	iters: 200, epoch: 22 | loss: 3.3377068
	speed: 0.0294s/iter; left time: 610.4539s
Epoch: 22 cost time: 7.9913330078125
Epoch: 22, Steps: 265 Train Loss: 3.3677 (Forecasting Loss:0.2087 + XiCon Loss:3.1590 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3304977
	speed: 0.0312s/iter; left time: 641.5633s
	iters: 200, epoch: 23 | loss: 3.3030617
	speed: 0.0307s/iter; left time: 628.0340s
Epoch: 23 cost time: 8.270434141159058
Epoch: 23, Steps: 265 Train Loss: 3.3669 (Forecasting Loss:0.2086 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3403344
	speed: 0.0322s/iter; left time: 654.6770s
	iters: 200, epoch: 24 | loss: 3.3373668
	speed: 0.0293s/iter; left time: 591.7147s
Epoch: 24 cost time: 8.141218423843384
Epoch: 24, Steps: 265 Train Loss: 3.3676 (Forecasting Loss:0.2087 + XiCon Loss:3.1589 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1693
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3888779
	speed: 0.0319s/iter; left time: 640.1888s
	iters: 200, epoch: 25 | loss: 3.3845751
	speed: 0.0293s/iter; left time: 584.0671s
Epoch: 25 cost time: 8.051992177963257
Epoch: 25, Steps: 265 Train Loss: 3.3664 (Forecasting Loss:0.2087 + XiCon Loss:3.1578 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1693
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3502924
	speed: 0.0317s/iter; left time: 627.3392s
	iters: 200, epoch: 26 | loss: 3.3620520
	speed: 0.0302s/iter; left time: 593.6099s
Epoch: 26 cost time: 8.144410610198975
Epoch: 26, Steps: 265 Train Loss: 3.3661 (Forecasting Loss:0.2087 + XiCon Loss:3.1574 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1693
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09936080127954483, mae:0.23916397988796234, mape:0.5735132694244385, mspe:12.080901145935059 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.8639
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.7483115
	speed: 0.0348s/iter; left time: 918.7820s
	iters: 200, epoch: 1 | loss: 3.7217548
	speed: 0.0307s/iter; left time: 806.1745s
Epoch: 1 cost time: 8.530085802078247
Epoch: 1, Steps: 265 Train Loss: 3.7396 (Forecasting Loss:0.3611 + XiCon Loss:3.3785 x Lambda(1.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2837
Validation loss decreased (inf --> 0.331493).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5602295
	speed: 0.0311s/iter; left time: 812.9813s
	iters: 200, epoch: 2 | loss: 3.4379082
	speed: 0.0288s/iter; left time: 749.4880s
Epoch: 2 cost time: 7.944355249404907
Epoch: 2, Steps: 265 Train Loss: 3.5297 (Forecasting Loss:0.2384 + XiCon Loss:3.2913 x Lambda(1.0)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1737
Validation loss decreased (0.331493 --> 0.222563).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3591638
	speed: 0.0315s/iter; left time: 815.7736s
	iters: 200, epoch: 3 | loss: 3.4079807
	speed: 0.0293s/iter; left time: 755.5968s
Epoch: 3 cost time: 7.968148708343506
Epoch: 3, Steps: 265 Train Loss: 3.3943 (Forecasting Loss:0.2125 + XiCon Loss:3.1819 x Lambda(1.0)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1702
Validation loss decreased (0.222563 --> 0.214705).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3708293
	speed: 0.0323s/iter; left time: 825.8225s
	iters: 200, epoch: 4 | loss: 3.3157151
	speed: 0.0297s/iter; left time: 758.0082s
Epoch: 4 cost time: 8.171547174453735
Epoch: 4, Steps: 265 Train Loss: 3.3652 (Forecasting Loss:0.2100 + XiCon Loss:3.1552 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
Validation loss decreased (0.214705 --> 0.212650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3632820
	speed: 0.0309s/iter; left time: 782.6198s
	iters: 200, epoch: 5 | loss: 3.3524652
	speed: 0.0286s/iter; left time: 722.5355s
Epoch: 5 cost time: 7.934461355209351
Epoch: 5, Steps: 265 Train Loss: 3.3559 (Forecasting Loss:0.2090 + XiCon Loss:3.1469 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1685
Validation loss decreased (0.212650 --> 0.211416).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3328319
	speed: 0.0306s/iter; left time: 768.4325s
	iters: 200, epoch: 6 | loss: 3.3458307
	speed: 0.0296s/iter; left time: 739.8471s
Epoch: 6 cost time: 7.8853912353515625
Epoch: 6, Steps: 265 Train Loss: 3.3506 (Forecasting Loss:0.2083 + XiCon Loss:3.1423 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1689
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3424118
	speed: 0.0307s/iter; left time: 761.4510s
	iters: 200, epoch: 7 | loss: 3.3671668
	speed: 0.0287s/iter; left time: 708.7943s
Epoch: 7 cost time: 7.840517282485962
Epoch: 7, Steps: 265 Train Loss: 3.3482 (Forecasting Loss:0.2080 + XiCon Loss:3.1402 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1687
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3289702
	speed: 0.0312s/iter; left time: 765.0496s
	iters: 200, epoch: 8 | loss: 3.3443375
	speed: 0.0289s/iter; left time: 706.8412s
Epoch: 8 cost time: 7.91623854637146
Epoch: 8, Steps: 265 Train Loss: 3.3472 (Forecasting Loss:0.2081 + XiCon Loss:3.1391 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1688
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3398328
	speed: 0.0319s/iter; left time: 773.5153s
	iters: 200, epoch: 9 | loss: 3.3541365
	speed: 0.0296s/iter; left time: 715.4225s
Epoch: 9 cost time: 8.044166803359985
Epoch: 9, Steps: 265 Train Loss: 3.3469 (Forecasting Loss:0.2078 + XiCon Loss:3.1391 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1688
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3519661
	speed: 0.0321s/iter; left time: 770.3679s
	iters: 200, epoch: 10 | loss: 3.3268223
	speed: 0.0288s/iter; left time: 689.1584s
Epoch: 10 cost time: 8.031362056732178
Epoch: 10, Steps: 265 Train Loss: 3.3464 (Forecasting Loss:0.2077 + XiCon Loss:3.1387 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1687
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3389490
	speed: 0.0314s/iter; left time: 745.2633s
	iters: 200, epoch: 11 | loss: 3.3508384
	speed: 0.0291s/iter; left time: 688.2893s
Epoch: 11 cost time: 8.029884815216064
Epoch: 11, Steps: 265 Train Loss: 3.3457 (Forecasting Loss:0.2078 + XiCon Loss:3.1379 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1687
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3549087
	speed: 0.0313s/iter; left time: 734.5322s
	iters: 200, epoch: 12 | loss: 3.3732746
	speed: 0.0282s/iter; left time: 660.2624s
Epoch: 12 cost time: 7.854114055633545
Epoch: 12, Steps: 265 Train Loss: 3.3473 (Forecasting Loss:0.2079 + XiCon Loss:3.1394 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1687
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3823335
	speed: 0.0314s/iter; left time: 729.5813s
	iters: 200, epoch: 13 | loss: 3.3688674
	speed: 0.0297s/iter; left time: 685.9131s
Epoch: 13 cost time: 8.044870615005493
Epoch: 13, Steps: 265 Train Loss: 3.3454 (Forecasting Loss:0.2078 + XiCon Loss:3.1376 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1687
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3321447
	speed: 0.0318s/iter; left time: 729.7536s
	iters: 200, epoch: 14 | loss: 3.3301146
	speed: 0.0297s/iter; left time: 678.4303s
Epoch: 14 cost time: 8.100250482559204
Epoch: 14, Steps: 265 Train Loss: 3.3449 (Forecasting Loss:0.2076 + XiCon Loss:3.1373 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1687
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3682671
	speed: 0.0320s/iter; left time: 727.1139s
	iters: 200, epoch: 15 | loss: 3.3353114
	speed: 0.0300s/iter; left time: 678.8184s
Epoch: 15 cost time: 8.267282247543335
Epoch: 15, Steps: 265 Train Loss: 3.3445 (Forecasting Loss:0.2077 + XiCon Loss:3.1368 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1687
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09883740544319153, mae:0.2382604479789734, mape:0.5729283094406128, mspe:11.735037803649902 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.4244
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.7692106
	speed: 0.0316s/iter; left time: 834.3857s
	iters: 200, epoch: 1 | loss: 3.6781600
	speed: 0.0296s/iter; left time: 777.7118s
Epoch: 1 cost time: 8.063978433609009
Epoch: 1, Steps: 265 Train Loss: 3.7219 (Forecasting Loss:0.3534 + XiCon Loss:3.3685 x Lambda(1.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2800
Validation loss decreased (inf --> 0.338274).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5427504
	speed: 0.0313s/iter; left time: 818.7237s
	iters: 200, epoch: 2 | loss: 3.4659128
	speed: 0.0287s/iter; left time: 747.9858s
Epoch: 2 cost time: 7.922020673751831
Epoch: 2, Steps: 265 Train Loss: 3.5614 (Forecasting Loss:0.2419 + XiCon Loss:3.3195 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1733
Validation loss decreased (0.338274 --> 0.219849).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.4501674
	speed: 0.0315s/iter; left time: 815.3848s
	iters: 200, epoch: 3 | loss: 3.3584063
	speed: 0.0305s/iter; left time: 784.7892s
Epoch: 3 cost time: 8.273607730865479
Epoch: 3, Steps: 265 Train Loss: 3.4229 (Forecasting Loss:0.2145 + XiCon Loss:3.2084 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.1696
Validation loss decreased (0.219849 --> 0.214955).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3875127
	speed: 0.0317s/iter; left time: 811.3744s
	iters: 200, epoch: 4 | loss: 3.3598871
	speed: 0.0289s/iter; left time: 736.5701s
Epoch: 4 cost time: 8.03589153289795
Epoch: 4, Steps: 265 Train Loss: 3.3871 (Forecasting Loss:0.2110 + XiCon Loss:3.1761 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1685
Validation loss decreased (0.214955 --> 0.212506).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3689737
	speed: 0.0311s/iter; left time: 788.2135s
	iters: 200, epoch: 5 | loss: 3.4008942
	speed: 0.0290s/iter; left time: 731.8522s
Epoch: 5 cost time: 7.936712980270386
Epoch: 5, Steps: 265 Train Loss: 3.3773 (Forecasting Loss:0.2097 + XiCon Loss:3.1676 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1681
Validation loss decreased (0.212506 --> 0.211409).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3745909
	speed: 0.0315s/iter; left time: 790.9159s
	iters: 200, epoch: 6 | loss: 3.3814993
	speed: 0.0291s/iter; left time: 726.9854s
Epoch: 6 cost time: 8.001767873764038
Epoch: 6, Steps: 265 Train Loss: 3.3731 (Forecasting Loss:0.2090 + XiCon Loss:3.1642 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1679
Validation loss decreased (0.211409 --> 0.211221).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3719299
	speed: 0.0315s/iter; left time: 781.3214s
	iters: 200, epoch: 7 | loss: 3.3558712
	speed: 0.0293s/iter; left time: 725.1291s
Epoch: 7 cost time: 8.0559401512146
Epoch: 7, Steps: 265 Train Loss: 3.3712 (Forecasting Loss:0.2086 + XiCon Loss:3.1627 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1679
Validation loss decreased (0.211221 --> 0.210868).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3433084
	speed: 0.0321s/iter; left time: 787.3046s
	iters: 200, epoch: 8 | loss: 3.3813162
	speed: 0.0314s/iter; left time: 768.7032s
Epoch: 8 cost time: 8.470685958862305
Epoch: 8, Steps: 265 Train Loss: 3.3682 (Forecasting Loss:0.2086 + XiCon Loss:3.1596 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1678
Validation loss decreased (0.210868 --> 0.210752).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3630066
	speed: 0.0317s/iter; left time: 770.5802s
	iters: 200, epoch: 9 | loss: 3.3831255
	speed: 0.0287s/iter; left time: 693.2171s
Epoch: 9 cost time: 7.972568511962891
Epoch: 9, Steps: 265 Train Loss: 3.3681 (Forecasting Loss:0.2084 + XiCon Loss:3.1597 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
Validation loss decreased (0.210752 --> 0.210586).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3613455
	speed: 0.0313s/iter; left time: 750.6688s
	iters: 200, epoch: 10 | loss: 3.3832521
	speed: 0.0292s/iter; left time: 698.4071s
Epoch: 10 cost time: 7.944406747817993
Epoch: 10, Steps: 265 Train Loss: 3.3675 (Forecasting Loss:0.2084 + XiCon Loss:3.1592 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3314605
	speed: 0.0311s/iter; left time: 737.8880s
	iters: 200, epoch: 11 | loss: 3.3597488
	speed: 0.0294s/iter; left time: 695.5801s
Epoch: 11 cost time: 8.074254035949707
Epoch: 11, Steps: 265 Train Loss: 3.3675 (Forecasting Loss:0.2083 + XiCon Loss:3.1592 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1678
Validation loss decreased (0.210586 --> 0.210447).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3884788
	speed: 0.0320s/iter; left time: 752.4059s
	iters: 200, epoch: 12 | loss: 3.3549337
	speed: 0.0289s/iter; left time: 676.7123s
Epoch: 12 cost time: 8.05471682548523
Epoch: 12, Steps: 265 Train Loss: 3.3666 (Forecasting Loss:0.2083 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3769577
	speed: 0.0320s/iter; left time: 743.0305s
	iters: 200, epoch: 13 | loss: 3.3979125
	speed: 0.0310s/iter; left time: 717.5618s
Epoch: 13 cost time: 8.29260516166687
Epoch: 13, Steps: 265 Train Loss: 3.3683 (Forecasting Loss:0.2084 + XiCon Loss:3.1599 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1678
Validation loss decreased (0.210447 --> 0.210058).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3563824
	speed: 0.0312s/iter; left time: 717.1058s
	iters: 200, epoch: 14 | loss: 3.3352501
	speed: 0.0298s/iter; left time: 681.0427s
Epoch: 14 cost time: 7.992128372192383
Epoch: 14, Steps: 265 Train Loss: 3.3668 (Forecasting Loss:0.2082 + XiCon Loss:3.1586 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3672459
	speed: 0.0318s/iter; left time: 721.0889s
	iters: 200, epoch: 15 | loss: 3.3519776
	speed: 0.0291s/iter; left time: 658.2835s
Epoch: 15 cost time: 7.950606107711792
Epoch: 15, Steps: 265 Train Loss: 3.3667 (Forecasting Loss:0.2084 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1678
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3743646
	speed: 0.0321s/iter; left time: 718.9850s
	iters: 200, epoch: 16 | loss: 3.3635776
	speed: 0.0292s/iter; left time: 652.1128s
Epoch: 16 cost time: 8.057336568832397
Epoch: 16, Steps: 265 Train Loss: 3.3668 (Forecasting Loss:0.2083 + XiCon Loss:3.1585 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3626943
	speed: 0.0315s/iter; left time: 698.4250s
	iters: 200, epoch: 17 | loss: 3.3705101
	speed: 0.0293s/iter; left time: 646.3899s
Epoch: 17 cost time: 8.020312786102295
Epoch: 17, Steps: 265 Train Loss: 3.3675 (Forecasting Loss:0.2083 + XiCon Loss:3.1593 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3766384
	speed: 0.0315s/iter; left time: 690.4730s
	iters: 200, epoch: 18 | loss: 3.3582430
	speed: 0.0307s/iter; left time: 669.9663s
Epoch: 18 cost time: 8.243499040603638
Epoch: 18, Steps: 265 Train Loss: 3.3696 (Forecasting Loss:0.2082 + XiCon Loss:3.1615 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3528535
	speed: 0.0323s/iter; left time: 698.6757s
	iters: 200, epoch: 19 | loss: 3.3742085
	speed: 0.0298s/iter; left time: 641.3005s
Epoch: 19 cost time: 8.121119499206543
Epoch: 19, Steps: 265 Train Loss: 3.3666 (Forecasting Loss:0.2083 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3824606
	speed: 0.0320s/iter; left time: 684.4075s
	iters: 200, epoch: 20 | loss: 3.3644414
	speed: 0.0293s/iter; left time: 622.5491s
Epoch: 20 cost time: 8.089752197265625
Epoch: 20, Steps: 265 Train Loss: 3.3680 (Forecasting Loss:0.2083 + XiCon Loss:3.1597 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.3964472
	speed: 0.0321s/iter; left time: 676.9221s
	iters: 200, epoch: 21 | loss: 3.3619878
	speed: 0.0291s/iter; left time: 610.8505s
Epoch: 21 cost time: 7.978570222854614
Epoch: 21, Steps: 265 Train Loss: 3.3684 (Forecasting Loss:0.2083 + XiCon Loss:3.1602 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3504181
	speed: 0.0315s/iter; left time: 655.6203s
	iters: 200, epoch: 22 | loss: 3.3686895
	speed: 0.0289s/iter; left time: 599.9990s
Epoch: 22 cost time: 7.9622642993927
Epoch: 22, Steps: 265 Train Loss: 3.3681 (Forecasting Loss:0.2084 + XiCon Loss:3.1597 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3861389
	speed: 0.0315s/iter; left time: 648.4082s
	iters: 200, epoch: 23 | loss: 3.3422432
	speed: 0.0307s/iter; left time: 628.6904s
Epoch: 23 cost time: 8.206576585769653
Epoch: 23, Steps: 265 Train Loss: 3.3676 (Forecasting Loss:0.2082 + XiCon Loss:3.1594 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09792809188365936, mae:0.23763741552829742, mape:0.5658396482467651, mspe:11.819132804870605 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0983+-0.00136, MAE:0.2382+-0.00152, MAPE:0.5704+-0.00384, MSPE:11.9343+-0.25012, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.2598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.7260571
	speed: 0.0371s/iter; left time: 975.6324s
	iters: 200, epoch: 1 | loss: 3.6438410
	speed: 0.0323s/iter; left time: 845.8447s
Epoch: 1 cost time: 8.956110000610352
Epoch: 1, Steps: 264 Train Loss: 3.6949 (Forecasting Loss:0.3356 + XiCon Loss:3.3593 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2336
Validation loss decreased (inf --> 0.296801).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3767791
	speed: 0.0347s/iter; left time: 902.2007s
	iters: 200, epoch: 2 | loss: 3.5096397
	speed: 0.0321s/iter; left time: 832.3798s
Epoch: 2 cost time: 8.800250053405762
Epoch: 2, Steps: 264 Train Loss: 3.4594 (Forecasting Loss:0.2532 + XiCon Loss:3.2062 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1934
Validation loss decreased (0.296801 --> 0.249659).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4795041
	speed: 0.0355s/iter; left time: 915.8668s
	iters: 200, epoch: 3 | loss: 3.3857718
	speed: 0.0317s/iter; left time: 813.5401s
Epoch: 3 cost time: 8.724797487258911
Epoch: 3, Steps: 264 Train Loss: 3.4431 (Forecasting Loss:0.2449 + XiCon Loss:3.1982 x Lambda(1.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1920
Validation loss decreased (0.249659 --> 0.247869).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4297493
	speed: 0.0348s/iter; left time: 887.5859s
	iters: 200, epoch: 4 | loss: 3.4446261
	speed: 0.0319s/iter; left time: 810.2827s
Epoch: 4 cost time: 8.689390182495117
Epoch: 4, Steps: 264 Train Loss: 3.4216 (Forecasting Loss:0.2426 + XiCon Loss:3.1791 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1927
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4181993
	speed: 0.0342s/iter; left time: 862.8343s
	iters: 200, epoch: 5 | loss: 3.3569181
	speed: 0.0325s/iter; left time: 816.0447s
Epoch: 5 cost time: 8.719761371612549
Epoch: 5, Steps: 264 Train Loss: 3.4112 (Forecasting Loss:0.2415 + XiCon Loss:3.1696 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1923
Validation loss decreased (0.247869 --> 0.246146).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4460068
	speed: 0.0336s/iter; left time: 839.2945s
	iters: 200, epoch: 6 | loss: 3.3890066
	speed: 0.0318s/iter; left time: 790.3289s
Epoch: 6 cost time: 8.565850973129272
Epoch: 6, Steps: 264 Train Loss: 3.4016 (Forecasting Loss:0.2410 + XiCon Loss:3.1607 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1922
Validation loss decreased (0.246146 --> 0.245811).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3945129
	speed: 0.0338s/iter; left time: 835.8611s
	iters: 200, epoch: 7 | loss: 3.3669162
	speed: 0.0314s/iter; left time: 773.5740s
Epoch: 7 cost time: 8.581313371658325
Epoch: 7, Steps: 264 Train Loss: 3.4015 (Forecasting Loss:0.2408 + XiCon Loss:3.1606 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1923
Validation loss decreased (0.245811 --> 0.245638).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3802228
	speed: 0.0340s/iter; left time: 831.0142s
	iters: 200, epoch: 8 | loss: 3.3529379
	speed: 0.0320s/iter; left time: 780.2740s
Epoch: 8 cost time: 8.611268043518066
Epoch: 8, Steps: 264 Train Loss: 3.3982 (Forecasting Loss:0.2406 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1924
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3868730
	speed: 0.0336s/iter; left time: 812.5182s
	iters: 200, epoch: 9 | loss: 3.4282560
	speed: 0.0318s/iter; left time: 766.0559s
Epoch: 9 cost time: 8.614812850952148
Epoch: 9, Steps: 264 Train Loss: 3.4008 (Forecasting Loss:0.2408 + XiCon Loss:3.1601 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1924
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4339023
	speed: 0.0336s/iter; left time: 802.8894s
	iters: 200, epoch: 10 | loss: 3.4178228
	speed: 0.0322s/iter; left time: 766.9094s
Epoch: 10 cost time: 8.61818528175354
Epoch: 10, Steps: 264 Train Loss: 3.3974 (Forecasting Loss:0.2408 + XiCon Loss:3.1566 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1924
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4259241
	speed: 0.0343s/iter; left time: 811.2578s
	iters: 200, epoch: 11 | loss: 3.3496504
	speed: 0.0318s/iter; left time: 748.2241s
Epoch: 11 cost time: 8.681747913360596
Epoch: 11, Steps: 264 Train Loss: 3.3998 (Forecasting Loss:0.2408 + XiCon Loss:3.1590 x Lambda(1.0)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.1924
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4058831
	speed: 0.0338s/iter; left time: 790.0052s
	iters: 200, epoch: 12 | loss: 3.3693404
	speed: 0.0321s/iter; left time: 748.4221s
Epoch: 12 cost time: 8.639329433441162
Epoch: 12, Steps: 264 Train Loss: 3.3967 (Forecasting Loss:0.2404 + XiCon Loss:3.1563 x Lambda(1.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1924
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4133086
	speed: 0.0373s/iter; left time: 861.8728s
	iters: 200, epoch: 13 | loss: 3.3859708
	speed: 0.0315s/iter; left time: 725.4382s
Epoch: 13 cost time: 8.964659690856934
Epoch: 13, Steps: 264 Train Loss: 3.3981 (Forecasting Loss:0.2405 + XiCon Loss:3.1576 x Lambda(1.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1924
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4533725
	speed: 0.0344s/iter; left time: 787.4524s
	iters: 200, epoch: 14 | loss: 3.3832967
	speed: 0.0321s/iter; left time: 730.3845s
Epoch: 14 cost time: 8.714775562286377
Epoch: 14, Steps: 264 Train Loss: 3.3964 (Forecasting Loss:0.2405 + XiCon Loss:3.1559 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1924
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3942456
	speed: 0.0347s/iter; left time: 784.6181s
	iters: 200, epoch: 15 | loss: 3.3525782
	speed: 0.0320s/iter; left time: 720.7856s
Epoch: 15 cost time: 8.735586404800415
Epoch: 15, Steps: 264 Train Loss: 3.3987 (Forecasting Loss:0.2406 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1924
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3658302
	speed: 0.0345s/iter; left time: 771.5075s
	iters: 200, epoch: 16 | loss: 3.4221902
	speed: 0.0319s/iter; left time: 709.2628s
Epoch: 16 cost time: 8.6950843334198
Epoch: 16, Steps: 264 Train Loss: 3.3975 (Forecasting Loss:0.2407 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1924
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4117939
	speed: 0.0341s/iter; left time: 753.5525s
	iters: 200, epoch: 17 | loss: 3.4766912
	speed: 0.0322s/iter; left time: 707.7610s
Epoch: 17 cost time: 8.629864692687988
Epoch: 17, Steps: 264 Train Loss: 3.3983 (Forecasting Loss:0.2408 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1924
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12110450863838196, mae:0.2635140120983124, mape:0.6315354704856873, mspe:14.509747505187988 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.9363
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.7703369
	speed: 0.0364s/iter; left time: 956.4809s
	iters: 200, epoch: 1 | loss: 3.6788676
	speed: 0.0339s/iter; left time: 888.8896s
Epoch: 1 cost time: 9.183976650238037
Epoch: 1, Steps: 264 Train Loss: 3.7084 (Forecasting Loss:0.3346 + XiCon Loss:3.3738 x Lambda(1.0)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.2320
Validation loss decreased (inf --> 0.293991).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4033906
	speed: 0.0340s/iter; left time: 885.4490s
	iters: 200, epoch: 2 | loss: 3.3925872
	speed: 0.0345s/iter; left time: 895.6967s
Epoch: 2 cost time: 9.095225811004639
Epoch: 2, Steps: 264 Train Loss: 3.4618 (Forecasting Loss:0.2526 + XiCon Loss:3.2092 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1950
Validation loss decreased (0.293991 --> 0.250861).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5237362
	speed: 0.0380s/iter; left time: 980.5948s
	iters: 200, epoch: 3 | loss: 3.6358526
	speed: 0.0353s/iter; left time: 906.6913s
Epoch: 3 cost time: 9.623946905136108
Epoch: 3, Steps: 264 Train Loss: 3.5486 (Forecasting Loss:0.2440 + XiCon Loss:3.3046 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1947
Validation loss decreased (0.250861 --> 0.249151).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6984677
	speed: 0.0372s/iter; left time: 948.4158s
	iters: 200, epoch: 4 | loss: 3.6663728
	speed: 0.0356s/iter; left time: 903.3373s
Epoch: 4 cost time: 9.479703187942505
Epoch: 4, Steps: 264 Train Loss: 3.6036 (Forecasting Loss:0.2422 + XiCon Loss:3.3614 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1939
Validation loss decreased (0.249151 --> 0.248574).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6791973
	speed: 0.0379s/iter; left time: 957.3276s
	iters: 200, epoch: 5 | loss: 3.5317290
	speed: 0.0359s/iter; left time: 902.4580s
Epoch: 5 cost time: 9.624809980392456
Epoch: 5, Steps: 264 Train Loss: 3.6207 (Forecasting Loss:0.2412 + XiCon Loss:3.3795 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1933
Validation loss decreased (0.248574 --> 0.248530).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5626249
	speed: 0.0379s/iter; left time: 947.5243s
	iters: 200, epoch: 6 | loss: 3.6090145
	speed: 0.0346s/iter; left time: 861.1299s
Epoch: 6 cost time: 9.465014457702637
Epoch: 6, Steps: 264 Train Loss: 3.6321 (Forecasting Loss:0.2407 + XiCon Loss:3.3914 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1932
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6347051
	speed: 0.0375s/iter; left time: 926.1021s
	iters: 200, epoch: 7 | loss: 3.6207795
	speed: 0.0359s/iter; left time: 883.4891s
Epoch: 7 cost time: 9.567856550216675
Epoch: 7, Steps: 264 Train Loss: 3.6256 (Forecasting Loss:0.2405 + XiCon Loss:3.3851 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
Validation loss decreased (0.248530 --> 0.248455).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5652919
	speed: 0.0375s/iter; left time: 917.9878s
	iters: 200, epoch: 8 | loss: 3.6795957
	speed: 0.0347s/iter; left time: 844.6362s
Epoch: 8 cost time: 9.484426021575928
Epoch: 8, Steps: 264 Train Loss: 3.6237 (Forecasting Loss:0.2403 + XiCon Loss:3.3834 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1934
Validation loss decreased (0.248455 --> 0.248432).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6422288
	speed: 0.0376s/iter; left time: 908.5568s
	iters: 200, epoch: 9 | loss: 3.5670362
	speed: 0.0356s/iter; left time: 856.5169s
Epoch: 9 cost time: 9.660020351409912
Epoch: 9, Steps: 264 Train Loss: 3.6284 (Forecasting Loss:0.2402 + XiCon Loss:3.3883 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6924334
	speed: 0.0383s/iter; left time: 917.2698s
	iters: 200, epoch: 10 | loss: 3.6272302
	speed: 0.0341s/iter; left time: 813.0075s
Epoch: 10 cost time: 9.539533615112305
Epoch: 10, Steps: 264 Train Loss: 3.6304 (Forecasting Loss:0.2404 + XiCon Loss:3.3900 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5749383
	speed: 0.0373s/iter; left time: 882.6678s
	iters: 200, epoch: 11 | loss: 3.6090860
	speed: 0.0351s/iter; left time: 826.5833s
Epoch: 11 cost time: 9.448532104492188
Epoch: 11, Steps: 264 Train Loss: 3.6315 (Forecasting Loss:0.2402 + XiCon Loss:3.3913 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5410194
	speed: 0.0371s/iter; left time: 868.7562s
	iters: 200, epoch: 12 | loss: 3.6467516
	speed: 0.0345s/iter; left time: 804.0765s
Epoch: 12 cost time: 9.444831371307373
Epoch: 12, Steps: 264 Train Loss: 3.6309 (Forecasting Loss:0.2400 + XiCon Loss:3.3908 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5946107
	speed: 0.0379s/iter; left time: 877.7935s
	iters: 200, epoch: 13 | loss: 3.6459339
	speed: 0.0360s/iter; left time: 828.5114s
Epoch: 13 cost time: 9.711548328399658
Epoch: 13, Steps: 264 Train Loss: 3.6331 (Forecasting Loss:0.2402 + XiCon Loss:3.3929 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1934
Validation loss decreased (0.248432 --> 0.248423).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5055180
	speed: 0.0372s/iter; left time: 851.3936s
	iters: 200, epoch: 14 | loss: 3.6279216
	speed: 0.0345s/iter; left time: 784.4141s
Epoch: 14 cost time: 9.416916847229004
Epoch: 14, Steps: 264 Train Loss: 3.6305 (Forecasting Loss:0.2401 + XiCon Loss:3.3904 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6413131
	speed: 0.0377s/iter; left time: 851.9964s
	iters: 200, epoch: 15 | loss: 3.6940114
	speed: 0.0353s/iter; left time: 794.9135s
Epoch: 15 cost time: 9.613160610198975
Epoch: 15, Steps: 264 Train Loss: 3.6292 (Forecasting Loss:0.2400 + XiCon Loss:3.3892 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6687927
	speed: 0.0380s/iter; left time: 849.7141s
	iters: 200, epoch: 16 | loss: 3.6399863
	speed: 0.0347s/iter; left time: 772.6718s
Epoch: 16 cost time: 9.508121252059937
Epoch: 16, Steps: 264 Train Loss: 3.6249 (Forecasting Loss:0.2401 + XiCon Loss:3.3847 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6224575
	speed: 0.0375s/iter; left time: 828.2888s
	iters: 200, epoch: 17 | loss: 3.7051275
	speed: 0.0357s/iter; left time: 785.2477s
Epoch: 17 cost time: 9.58420467376709
Epoch: 17, Steps: 264 Train Loss: 3.6279 (Forecasting Loss:0.2403 + XiCon Loss:3.3876 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.7995915
	speed: 0.0376s/iter; left time: 821.2327s
	iters: 200, epoch: 18 | loss: 3.5869799
	speed: 0.0351s/iter; left time: 761.9918s
Epoch: 18 cost time: 9.554538488388062
Epoch: 18, Steps: 264 Train Loss: 3.6296 (Forecasting Loss:0.2401 + XiCon Loss:3.3895 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6508110
	speed: 0.0372s/iter; left time: 802.1866s
	iters: 200, epoch: 19 | loss: 3.6775343
	speed: 0.0347s/iter; left time: 745.0000s
Epoch: 19 cost time: 9.466611385345459
Epoch: 19, Steps: 264 Train Loss: 3.6298 (Forecasting Loss:0.2401 + XiCon Loss:3.3896 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6263552
	speed: 0.0375s/iter; left time: 798.7039s
	iters: 200, epoch: 20 | loss: 3.5092442
	speed: 0.0349s/iter; left time: 738.9466s
Epoch: 20 cost time: 9.523597478866577
Epoch: 20, Steps: 264 Train Loss: 3.6266 (Forecasting Loss:0.2402 + XiCon Loss:3.3864 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6610177
	speed: 0.0374s/iter; left time: 785.7548s
	iters: 200, epoch: 21 | loss: 3.6661122
	speed: 0.0352s/iter; left time: 737.1837s
Epoch: 21 cost time: 9.541015148162842
Epoch: 21, Steps: 264 Train Loss: 3.6269 (Forecasting Loss:0.2402 + XiCon Loss:3.3868 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.1934
Validation loss decreased (0.248423 --> 0.248339).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.5434523
	speed: 0.0371s/iter; left time: 769.8866s
	iters: 200, epoch: 22 | loss: 3.5569913
	speed: 0.0352s/iter; left time: 726.6434s
Epoch: 22 cost time: 9.45024585723877
Epoch: 22, Steps: 264 Train Loss: 3.6268 (Forecasting Loss:0.2401 + XiCon Loss:3.3866 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.5569656
	speed: 0.0378s/iter; left time: 773.7529s
	iters: 200, epoch: 23 | loss: 3.5278540
	speed: 0.0360s/iter; left time: 734.4255s
Epoch: 23 cost time: 9.599265813827515
Epoch: 23, Steps: 264 Train Loss: 3.6337 (Forecasting Loss:0.2404 + XiCon Loss:3.3932 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1934
Validation loss decreased (0.248339 --> 0.248149).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.6574807
	speed: 0.0376s/iter; left time: 759.6596s
	iters: 200, epoch: 24 | loss: 3.5963528
	speed: 0.0348s/iter; left time: 700.7190s
Epoch: 24 cost time: 9.523722887039185
Epoch: 24, Steps: 264 Train Loss: 3.6341 (Forecasting Loss:0.2401 + XiCon Loss:3.3939 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1934
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.6115203
	speed: 0.0380s/iter; left time: 758.4800s
	iters: 200, epoch: 25 | loss: 3.5885930
	speed: 0.0354s/iter; left time: 702.2835s
Epoch: 25 cost time: 9.584625959396362
Epoch: 25, Steps: 264 Train Loss: 3.6290 (Forecasting Loss:0.2403 + XiCon Loss:3.3887 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.6192296
	speed: 0.0371s/iter; left time: 730.0371s
	iters: 200, epoch: 26 | loss: 3.5573943
	speed: 0.0357s/iter; left time: 700.2146s
Epoch: 26 cost time: 9.598498821258545
Epoch: 26, Steps: 264 Train Loss: 3.6269 (Forecasting Loss:0.2402 + XiCon Loss:3.3868 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.7108276
	speed: 0.0385s/iter; left time: 747.5330s
	iters: 200, epoch: 27 | loss: 3.7082803
	speed: 0.0344s/iter; left time: 665.7684s
Epoch: 27 cost time: 9.558244705200195
Epoch: 27, Steps: 264 Train Loss: 3.6295 (Forecasting Loss:0.2404 + XiCon Loss:3.3892 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.6379576
	speed: 0.0371s/iter; left time: 710.6542s
	iters: 200, epoch: 28 | loss: 3.6517432
	speed: 0.0349s/iter; left time: 666.4220s
Epoch: 28 cost time: 9.448131322860718
Epoch: 28, Steps: 264 Train Loss: 3.6282 (Forecasting Loss:0.2402 + XiCon Loss:3.3880 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1934
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.6330018
	speed: 0.0377s/iter; left time: 712.2475s
	iters: 200, epoch: 29 | loss: 3.5747089
	speed: 0.0357s/iter; left time: 671.6819s
Epoch: 29 cost time: 9.647485256195068
Epoch: 29, Steps: 264 Train Loss: 3.6344 (Forecasting Loss:0.2401 + XiCon Loss:3.3943 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.6740665
	speed: 0.0377s/iter; left time: 702.8192s
	iters: 200, epoch: 30 | loss: 3.6550953
	speed: 0.0350s/iter; left time: 649.7047s
Epoch: 30 cost time: 9.509855031967163
Epoch: 30, Steps: 264 Train Loss: 3.6302 (Forecasting Loss:0.2402 + XiCon Loss:3.3900 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1934
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.6531458
	speed: 0.0375s/iter; left time: 689.0429s
	iters: 200, epoch: 31 | loss: 3.5867550
	speed: 0.0338s/iter; left time: 618.6394s
Epoch: 31 cost time: 9.406222105026245
Epoch: 31, Steps: 264 Train Loss: 3.6324 (Forecasting Loss:0.2402 + XiCon Loss:3.3922 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1934
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.6051838
	speed: 0.0378s/iter; left time: 684.8880s
	iters: 200, epoch: 32 | loss: 3.5286682
	speed: 0.0351s/iter; left time: 632.9856s
Epoch: 32 cost time: 9.548434972763062
Epoch: 32, Steps: 264 Train Loss: 3.6259 (Forecasting Loss:0.2403 + XiCon Loss:3.3856 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1934
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.6231623
	speed: 0.0373s/iter; left time: 665.6734s
	iters: 200, epoch: 33 | loss: 3.7458467
	speed: 0.0355s/iter; left time: 630.3305s
Epoch: 33 cost time: 9.522827863693237
Epoch: 33, Steps: 264 Train Loss: 3.6360 (Forecasting Loss:0.2402 + XiCon Loss:3.3958 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1934
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12181615829467773, mae:0.26498445868492126, mape:0.6183834671974182, mspe:13.730587005615234 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.2291
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.6995394
	speed: 0.0355s/iter; left time: 934.9157s
	iters: 200, epoch: 1 | loss: 3.6617393
	speed: 0.0330s/iter; left time: 863.7449s
Epoch: 1 cost time: 8.984440088272095
Epoch: 1, Steps: 264 Train Loss: 3.6962 (Forecasting Loss:0.3340 + XiCon Loss:3.3623 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.296843).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4000432
	speed: 0.0343s/iter; left time: 892.9478s
	iters: 200, epoch: 2 | loss: 3.4193757
	speed: 0.0315s/iter; left time: 817.1936s
Epoch: 2 cost time: 8.663522005081177
Epoch: 2, Steps: 264 Train Loss: 3.4418 (Forecasting Loss:0.2529 + XiCon Loss:3.1889 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1941
Validation loss decreased (0.296843 --> 0.250694).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3746929
	speed: 0.0340s/iter; left time: 876.5681s
	iters: 200, epoch: 3 | loss: 3.4462528
	speed: 0.0318s/iter; left time: 817.0766s
Epoch: 3 cost time: 8.661982536315918
Epoch: 3, Steps: 264 Train Loss: 3.4198 (Forecasting Loss:0.2451 + XiCon Loss:3.1747 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1938
Validation loss decreased (0.250694 --> 0.249825).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3446248
	speed: 0.0344s/iter; left time: 876.7077s
	iters: 200, epoch: 4 | loss: 3.4047432
	speed: 0.0325s/iter; left time: 825.2610s
Epoch: 4 cost time: 8.777373552322388
Epoch: 4, Steps: 264 Train Loss: 3.3937 (Forecasting Loss:0.2436 + XiCon Loss:3.1501 x Lambda(1.0)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.1930
Validation loss decreased (0.249825 --> 0.246405).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3655617
	speed: 0.0335s/iter; left time: 845.6014s
	iters: 200, epoch: 5 | loss: 3.3795087
	speed: 0.0316s/iter; left time: 794.3876s
Epoch: 5 cost time: 8.56827688217163
Epoch: 5, Steps: 264 Train Loss: 3.3852 (Forecasting Loss:0.2430 + XiCon Loss:3.1422 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1926
Validation loss decreased (0.246405 --> 0.245728).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4288023
	speed: 0.0345s/iter; left time: 861.1473s
	iters: 200, epoch: 6 | loss: 3.3923252
	speed: 0.0324s/iter; left time: 805.1007s
Epoch: 6 cost time: 8.74107551574707
Epoch: 6, Steps: 264 Train Loss: 3.3786 (Forecasting Loss:0.2424 + XiCon Loss:3.1362 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1927
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3200655
	speed: 0.0347s/iter; left time: 856.7041s
	iters: 200, epoch: 7 | loss: 3.3906839
	speed: 0.0321s/iter; left time: 791.0127s
Epoch: 7 cost time: 8.759645223617554
Epoch: 7, Steps: 264 Train Loss: 3.3749 (Forecasting Loss:0.2421 + XiCon Loss:3.1328 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1929
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3729904
	speed: 0.0348s/iter; left time: 851.6481s
	iters: 200, epoch: 8 | loss: 3.3617635
	speed: 0.0325s/iter; left time: 790.7861s
Epoch: 8 cost time: 8.800437927246094
Epoch: 8, Steps: 264 Train Loss: 3.3768 (Forecasting Loss:0.2416 + XiCon Loss:3.1351 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1929
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3935809
	speed: 0.0341s/iter; left time: 825.3455s
	iters: 200, epoch: 9 | loss: 3.4145687
	speed: 0.0315s/iter; left time: 758.7409s
Epoch: 9 cost time: 8.627526760101318
Epoch: 9, Steps: 264 Train Loss: 3.3737 (Forecasting Loss:0.2418 + XiCon Loss:3.1319 x Lambda(1.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1929
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3984764
	speed: 0.0346s/iter; left time: 826.9677s
	iters: 200, epoch: 10 | loss: 3.3930767
	speed: 0.0318s/iter; left time: 758.3038s
Epoch: 10 cost time: 8.710827350616455
Epoch: 10, Steps: 264 Train Loss: 3.3752 (Forecasting Loss:0.2416 + XiCon Loss:3.1336 x Lambda(1.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1929
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3151135
	speed: 0.0344s/iter; left time: 814.5734s
	iters: 200, epoch: 11 | loss: 3.3712561
	speed: 0.0323s/iter; left time: 760.7824s
Epoch: 11 cost time: 8.728959083557129
Epoch: 11, Steps: 264 Train Loss: 3.3757 (Forecasting Loss:0.2417 + XiCon Loss:3.1340 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1929
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3490605
	speed: 0.0344s/iter; left time: 804.8652s
	iters: 200, epoch: 12 | loss: 3.3558397
	speed: 0.0316s/iter; left time: 735.7909s
Epoch: 12 cost time: 8.691905975341797
Epoch: 12, Steps: 264 Train Loss: 3.3745 (Forecasting Loss:0.2417 + XiCon Loss:3.1329 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1929
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3018444
	speed: 0.0339s/iter; left time: 784.9183s
	iters: 200, epoch: 13 | loss: 3.3239985
	speed: 0.0316s/iter; left time: 727.5636s
Epoch: 13 cost time: 8.677517414093018
Epoch: 13, Steps: 264 Train Loss: 3.3733 (Forecasting Loss:0.2418 + XiCon Loss:3.1316 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1929
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4423084
	speed: 0.0343s/iter; left time: 784.7840s
	iters: 200, epoch: 14 | loss: 3.3553321
	speed: 0.0327s/iter; left time: 743.7894s
Epoch: 14 cost time: 8.837078094482422
Epoch: 14, Steps: 264 Train Loss: 3.3715 (Forecasting Loss:0.2418 + XiCon Loss:3.1297 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1929
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3534803
	speed: 0.0344s/iter; left time: 777.9989s
	iters: 200, epoch: 15 | loss: 3.3687391
	speed: 0.0312s/iter; left time: 701.8713s
Epoch: 15 cost time: 8.559632778167725
Epoch: 15, Steps: 264 Train Loss: 3.3750 (Forecasting Loss:0.2418 + XiCon Loss:3.1332 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1929
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12087802588939667, mae:0.2643585801124573, mape:0.6371358633041382, mspe:14.78547191619873 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.3781
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.7073009
	speed: 0.0364s/iter; left time: 956.3480s
	iters: 200, epoch: 1 | loss: 3.7063394
	speed: 0.0329s/iter; left time: 863.1256s
Epoch: 1 cost time: 9.060463428497314
Epoch: 1, Steps: 264 Train Loss: 3.7135 (Forecasting Loss:0.3354 + XiCon Loss:3.3780 x Lambda(1.0)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2351
Validation loss decreased (inf --> 0.300024).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4260652
	speed: 0.0332s/iter; left time: 864.1441s
	iters: 200, epoch: 2 | loss: 3.3221037
	speed: 0.0317s/iter; left time: 821.9438s
Epoch: 2 cost time: 8.474576950073242
Epoch: 2, Steps: 264 Train Loss: 3.4418 (Forecasting Loss:0.2519 + XiCon Loss:3.1899 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1948
Validation loss decreased (0.300024 --> 0.249685).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5307803
	speed: 0.0347s/iter; left time: 893.3796s
	iters: 200, epoch: 3 | loss: 3.4129021
	speed: 0.0317s/iter; left time: 814.4414s
Epoch: 3 cost time: 8.711119413375854
Epoch: 3, Steps: 264 Train Loss: 3.4558 (Forecasting Loss:0.2437 + XiCon Loss:3.2121 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4871628
	speed: 0.0349s/iter; left time: 889.2896s
	iters: 200, epoch: 4 | loss: 3.4412167
	speed: 0.0321s/iter; left time: 814.5481s
Epoch: 4 cost time: 8.76435399055481
Epoch: 4, Steps: 264 Train Loss: 3.4447 (Forecasting Loss:0.2418 + XiCon Loss:3.2029 x Lambda(1.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1945
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4202394
	speed: 0.0344s/iter; left time: 868.9514s
	iters: 200, epoch: 5 | loss: 3.4338899
	speed: 0.0327s/iter; left time: 822.2812s
Epoch: 5 cost time: 8.776759386062622
Epoch: 5, Steps: 264 Train Loss: 3.4311 (Forecasting Loss:0.2408 + XiCon Loss:3.1903 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.1934
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4007025
	speed: 0.0339s/iter; left time: 847.4201s
	iters: 200, epoch: 6 | loss: 3.3970280
	speed: 0.0321s/iter; left time: 798.5194s
Epoch: 6 cost time: 8.72934079170227
Epoch: 6, Steps: 264 Train Loss: 3.4259 (Forecasting Loss:0.2400 + XiCon Loss:3.1859 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1935
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4579585
	speed: 0.0342s/iter; left time: 845.5972s
	iters: 200, epoch: 7 | loss: 3.4397628
	speed: 0.0322s/iter; left time: 793.2091s
Epoch: 7 cost time: 8.695165872573853
Epoch: 7, Steps: 264 Train Loss: 3.4235 (Forecasting Loss:0.2400 + XiCon Loss:3.1836 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1934
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4157341
	speed: 0.0337s/iter; left time: 824.8521s
	iters: 200, epoch: 8 | loss: 3.5089924
	speed: 0.0324s/iter; left time: 788.8969s
Epoch: 8 cost time: 8.59615969657898
Epoch: 8, Steps: 264 Train Loss: 3.4194 (Forecasting Loss:0.2398 + XiCon Loss:3.1796 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1934
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3816798
	speed: 0.0342s/iter; left time: 827.6044s
	iters: 200, epoch: 9 | loss: 3.4320817
	speed: 0.0317s/iter; left time: 764.1768s
Epoch: 9 cost time: 8.659112930297852
Epoch: 9, Steps: 264 Train Loss: 3.4223 (Forecasting Loss:0.2396 + XiCon Loss:3.1827 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1935
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4269283
	speed: 0.0344s/iter; left time: 823.7621s
	iters: 200, epoch: 10 | loss: 3.4611912
	speed: 0.0320s/iter; left time: 761.5406s
Epoch: 10 cost time: 8.720308303833008
Epoch: 10, Steps: 264 Train Loss: 3.4209 (Forecasting Loss:0.2395 + XiCon Loss:3.1814 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1935
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4384232
	speed: 0.0343s/iter; left time: 811.7931s
	iters: 200, epoch: 11 | loss: 3.4053283
	speed: 0.0318s/iter; left time: 748.9700s
Epoch: 11 cost time: 8.634918451309204
Epoch: 11, Steps: 264 Train Loss: 3.4201 (Forecasting Loss:0.2396 + XiCon Loss:3.1806 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1935
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3738587
	speed: 0.0348s/iter; left time: 814.0728s
	iters: 200, epoch: 12 | loss: 3.4321871
	speed: 0.0318s/iter; left time: 741.9763s
Epoch: 12 cost time: 8.693611860275269
Epoch: 12, Steps: 264 Train Loss: 3.4194 (Forecasting Loss:0.2397 + XiCon Loss:3.1797 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1935
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12235873937606812, mae:0.26731669902801514, mape:0.6444586515426636, mspe:14.816831588745117 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.4592
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.6812179
	speed: 0.0374s/iter; left time: 983.3058s
	iters: 200, epoch: 1 | loss: 3.6978087
	speed: 0.0324s/iter; left time: 848.4348s
Epoch: 1 cost time: 9.012535810470581
Epoch: 1, Steps: 264 Train Loss: 3.6933 (Forecasting Loss:0.3334 + XiCon Loss:3.3599 x Lambda(1.0)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2321
Validation loss decreased (inf --> 0.294888).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4741457
	speed: 0.0343s/iter; left time: 892.2499s
	iters: 200, epoch: 2 | loss: 3.3030448
	speed: 0.0319s/iter; left time: 827.3846s
Epoch: 2 cost time: 8.692835092544556
Epoch: 2, Steps: 264 Train Loss: 3.4228 (Forecasting Loss:0.2507 + XiCon Loss:3.1721 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1960
Validation loss decreased (0.294888 --> 0.247075).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4267523
	speed: 0.0343s/iter; left time: 884.8773s
	iters: 200, epoch: 3 | loss: 3.4503272
	speed: 0.0319s/iter; left time: 819.7164s
Epoch: 3 cost time: 8.702725410461426
Epoch: 3, Steps: 264 Train Loss: 3.4404 (Forecasting Loss:0.2445 + XiCon Loss:3.1959 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1940
Validation loss decreased (0.247075 --> 0.245839).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3865120
	speed: 0.0356s/iter; left time: 907.2730s
	iters: 200, epoch: 4 | loss: 3.5125599
	speed: 0.0332s/iter; left time: 843.8578s
Epoch: 4 cost time: 9.030211687088013
Epoch: 4, Steps: 264 Train Loss: 3.4221 (Forecasting Loss:0.2430 + XiCon Loss:3.1791 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1930
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3904300
	speed: 0.0364s/iter; left time: 919.4403s
	iters: 200, epoch: 5 | loss: 3.4317324
	speed: 0.0339s/iter; left time: 851.9072s
Epoch: 5 cost time: 9.184458255767822
Epoch: 5, Steps: 264 Train Loss: 3.4101 (Forecasting Loss:0.2425 + XiCon Loss:3.1676 x Lambda(1.0)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1929
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4560068
	speed: 0.0358s/iter; left time: 893.7425s
	iters: 200, epoch: 6 | loss: 3.4489002
	speed: 0.0333s/iter; left time: 827.9650s
Epoch: 6 cost time: 9.06027340888977
Epoch: 6, Steps: 264 Train Loss: 3.4017 (Forecasting Loss:0.2423 + XiCon Loss:3.1594 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1929
Validation loss decreased (0.245839 --> 0.245539).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3792713
	speed: 0.0359s/iter; left time: 886.7033s
	iters: 200, epoch: 7 | loss: 3.4498239
	speed: 0.0336s/iter; left time: 827.6373s
Epoch: 7 cost time: 9.146678447723389
Epoch: 7, Steps: 264 Train Loss: 3.4014 (Forecasting Loss:0.2422 + XiCon Loss:3.1592 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1927
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4383028
	speed: 0.0359s/iter; left time: 878.4729s
	iters: 200, epoch: 8 | loss: 3.4471145
	speed: 0.0336s/iter; left time: 818.1084s
Epoch: 8 cost time: 9.112844705581665
Epoch: 8, Steps: 264 Train Loss: 3.3959 (Forecasting Loss:0.2418 + XiCon Loss:3.1541 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1926
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3846536
	speed: 0.0356s/iter; left time: 861.6069s
	iters: 200, epoch: 9 | loss: 3.3819544
	speed: 0.0334s/iter; left time: 803.6111s
Epoch: 9 cost time: 9.08906626701355
Epoch: 9, Steps: 264 Train Loss: 3.4006 (Forecasting Loss:0.2420 + XiCon Loss:3.1586 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4038274
	speed: 0.0366s/iter; left time: 876.4740s
	iters: 200, epoch: 10 | loss: 3.3927267
	speed: 0.0337s/iter; left time: 803.3871s
Epoch: 10 cost time: 9.25934624671936
Epoch: 10, Steps: 264 Train Loss: 3.3985 (Forecasting Loss:0.2420 + XiCon Loss:3.1565 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
Validation loss decreased (0.245539 --> 0.245529).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4245908
	speed: 0.0356s/iter; left time: 842.5877s
	iters: 200, epoch: 11 | loss: 3.4095500
	speed: 0.0332s/iter; left time: 781.0957s
Epoch: 11 cost time: 9.079333305358887
Epoch: 11, Steps: 264 Train Loss: 3.3992 (Forecasting Loss:0.2419 + XiCon Loss:3.1574 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
Validation loss decreased (0.245529 --> 0.245381).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4056456
	speed: 0.0358s/iter; left time: 838.1717s
	iters: 200, epoch: 12 | loss: 3.3941500
	speed: 0.0339s/iter; left time: 788.9986s
Epoch: 12 cost time: 9.156236410140991
Epoch: 12, Steps: 264 Train Loss: 3.3962 (Forecasting Loss:0.2419 + XiCon Loss:3.1543 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4244993
	speed: 0.0358s/iter; left time: 828.8557s
	iters: 200, epoch: 13 | loss: 3.3864737
	speed: 0.0330s/iter; left time: 760.4597s
Epoch: 13 cost time: 9.032365322113037
Epoch: 13, Steps: 264 Train Loss: 3.3963 (Forecasting Loss:0.2421 + XiCon Loss:3.1541 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
Validation loss decreased (0.245381 --> 0.245352).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3362381
	speed: 0.0351s/iter; left time: 803.1192s
	iters: 200, epoch: 14 | loss: 3.4267039
	speed: 0.0338s/iter; left time: 768.5004s
Epoch: 14 cost time: 9.088143587112427
Epoch: 14, Steps: 264 Train Loss: 3.3963 (Forecasting Loss:0.2420 + XiCon Loss:3.1543 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4491322
	speed: 0.0365s/iter; left time: 825.6827s
	iters: 200, epoch: 15 | loss: 3.4055140
	speed: 0.0331s/iter; left time: 746.0057s
Epoch: 15 cost time: 9.139383316040039
Epoch: 15, Steps: 264 Train Loss: 3.3963 (Forecasting Loss:0.2419 + XiCon Loss:3.1544 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3964069
	speed: 0.0368s/iter; left time: 821.9350s
	iters: 200, epoch: 16 | loss: 3.3732085
	speed: 0.0345s/iter; left time: 767.1494s
Epoch: 16 cost time: 9.32996916770935
Epoch: 16, Steps: 264 Train Loss: 3.3980 (Forecasting Loss:0.2419 + XiCon Loss:3.1560 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4088390
	speed: 0.0359s/iter; left time: 793.5479s
	iters: 200, epoch: 17 | loss: 3.3910661
	speed: 0.0329s/iter; left time: 722.9698s
Epoch: 17 cost time: 9.03849720954895
Epoch: 17, Steps: 264 Train Loss: 3.3980 (Forecasting Loss:0.2419 + XiCon Loss:3.1561 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.4580872
	speed: 0.0364s/iter; left time: 794.2201s
	iters: 200, epoch: 18 | loss: 3.3750489
	speed: 0.0338s/iter; left time: 734.2172s
Epoch: 18 cost time: 9.228547811508179
Epoch: 18, Steps: 264 Train Loss: 3.3964 (Forecasting Loss:0.2420 + XiCon Loss:3.1544 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1926
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.3407121
	speed: 0.0356s/iter; left time: 767.8547s
	iters: 200, epoch: 19 | loss: 3.4051216
	speed: 0.0330s/iter; left time: 707.5015s
Epoch: 19 cost time: 9.044715881347656
Epoch: 19, Steps: 264 Train Loss: 3.3973 (Forecasting Loss:0.2419 + XiCon Loss:3.1555 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1926
Validation loss decreased (0.245352 --> 0.245327).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4196463
	speed: 0.0359s/iter; left time: 764.0043s
	iters: 200, epoch: 20 | loss: 3.4491310
	speed: 0.0340s/iter; left time: 719.7251s
Epoch: 20 cost time: 9.258397102355957
Epoch: 20, Steps: 264 Train Loss: 3.3976 (Forecasting Loss:0.2420 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.4032063
	speed: 0.0366s/iter; left time: 769.3368s
	iters: 200, epoch: 21 | loss: 3.4205527
	speed: 0.0337s/iter; left time: 704.1581s
Epoch: 21 cost time: 9.2162024974823
Epoch: 21, Steps: 264 Train Loss: 3.3990 (Forecasting Loss:0.2420 + XiCon Loss:3.1570 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.4045746
	speed: 0.0354s/iter; left time: 735.2771s
	iters: 200, epoch: 22 | loss: 3.3581991
	speed: 0.0340s/iter; left time: 702.2195s
Epoch: 22 cost time: 9.13660740852356
Epoch: 22, Steps: 264 Train Loss: 3.3986 (Forecasting Loss:0.2419 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.4017923
	speed: 0.0368s/iter; left time: 753.9827s
	iters: 200, epoch: 23 | loss: 3.3659146
	speed: 0.0333s/iter; left time: 678.4421s
Epoch: 23 cost time: 9.237392902374268
Epoch: 23, Steps: 264 Train Loss: 3.3993 (Forecasting Loss:0.2419 + XiCon Loss:3.1574 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1926
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.3860681
	speed: 0.0358s/iter; left time: 723.9119s
	iters: 200, epoch: 24 | loss: 3.4121180
	speed: 0.0342s/iter; left time: 688.5878s
Epoch: 24 cost time: 9.212249517440796
Epoch: 24, Steps: 264 Train Loss: 3.3962 (Forecasting Loss:0.2420 + XiCon Loss:3.1542 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.3632481
	speed: 0.0364s/iter; left time: 726.1705s
	iters: 200, epoch: 25 | loss: 3.3885126
	speed: 0.0336s/iter; left time: 667.1289s
Epoch: 25 cost time: 9.163254499435425
Epoch: 25, Steps: 264 Train Loss: 3.3988 (Forecasting Loss:0.2420 + XiCon Loss:3.1568 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1926
Validation loss decreased (0.245327 --> 0.245252).  Saving model ...
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.3828294
	speed: 0.0363s/iter; left time: 714.7319s
	iters: 200, epoch: 26 | loss: 3.4238443
	speed: 0.0333s/iter; left time: 652.9705s
Epoch: 26 cost time: 9.087806463241577
Epoch: 26, Steps: 264 Train Loss: 3.3959 (Forecasting Loss:0.2420 + XiCon Loss:3.1539 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1926
Validation loss decreased (0.245252 --> 0.245186).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.3403118
	speed: 0.0362s/iter; left time: 704.3109s
	iters: 200, epoch: 27 | loss: 3.3635826
	speed: 0.0337s/iter; left time: 651.3453s
Epoch: 27 cost time: 9.154510259628296
Epoch: 27, Steps: 264 Train Loss: 3.3941 (Forecasting Loss:0.2419 + XiCon Loss:3.1522 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.4028618
	speed: 0.0361s/iter; left time: 692.4523s
	iters: 200, epoch: 28 | loss: 3.3956740
	speed: 0.0333s/iter; left time: 635.1987s
Epoch: 28 cost time: 9.14719271659851
Epoch: 28, Steps: 264 Train Loss: 3.3959 (Forecasting Loss:0.2422 + XiCon Loss:3.1538 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1926
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.4112351
	speed: 0.0360s/iter; left time: 680.3608s
	iters: 200, epoch: 29 | loss: 3.3168025
	speed: 0.0334s/iter; left time: 629.0344s
Epoch: 29 cost time: 9.14291000366211
Epoch: 29, Steps: 264 Train Loss: 3.3960 (Forecasting Loss:0.2420 + XiCon Loss:3.1540 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1926
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.4290648
	speed: 0.0357s/iter; left time: 666.2112s
	iters: 200, epoch: 30 | loss: 3.4336700
	speed: 0.0333s/iter; left time: 618.0532s
Epoch: 30 cost time: 9.120133399963379
Epoch: 30, Steps: 264 Train Loss: 3.3981 (Forecasting Loss:0.2419 + XiCon Loss:3.1561 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.3767676
	speed: 0.0359s/iter; left time: 659.2679s
	iters: 200, epoch: 31 | loss: 3.4230187
	speed: 0.0337s/iter; left time: 616.5452s
Epoch: 31 cost time: 9.146270275115967
Epoch: 31, Steps: 264 Train Loss: 3.3956 (Forecasting Loss:0.2419 + XiCon Loss:3.1538 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.3329153
	speed: 0.0363s/iter; left time: 657.2140s
	iters: 200, epoch: 32 | loss: 3.3987238
	speed: 0.0334s/iter; left time: 602.0905s
Epoch: 32 cost time: 9.157379150390625
Epoch: 32, Steps: 264 Train Loss: 3.3965 (Forecasting Loss:0.2420 + XiCon Loss:3.1545 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1926
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.4249973
	speed: 0.0364s/iter; left time: 650.1147s
	iters: 200, epoch: 33 | loss: 3.4233963
	speed: 0.0339s/iter; left time: 602.0645s
Epoch: 33 cost time: 9.24459171295166
Epoch: 33, Steps: 264 Train Loss: 3.3988 (Forecasting Loss:0.2421 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 3.3804505
	speed: 0.0356s/iter; left time: 626.7393s
	iters: 200, epoch: 34 | loss: 3.4136453
	speed: 0.0338s/iter; left time: 590.6686s
Epoch: 34 cost time: 9.12337040901184
Epoch: 34, Steps: 264 Train Loss: 3.3972 (Forecasting Loss:0.2418 + XiCon Loss:3.1554 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 35 | loss: 3.4457512
	speed: 0.0361s/iter; left time: 625.1204s
	iters: 200, epoch: 35 | loss: 3.4252923
	speed: 0.0334s/iter; left time: 576.0873s
Epoch: 35 cost time: 9.158827781677246
Epoch: 35, Steps: 264 Train Loss: 3.3965 (Forecasting Loss:0.2420 + XiCon Loss:3.1545 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1926
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 36 | loss: 3.3340795
	speed: 0.0369s/iter; left time: 629.7746s
	iters: 200, epoch: 36 | loss: 3.4489689
	speed: 0.0335s/iter; left time: 568.2228s
Epoch: 36 cost time: 9.173792839050293
Epoch: 36, Steps: 264 Train Loss: 3.3978 (Forecasting Loss:0.2420 + XiCon Loss:3.1559 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1926
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12149380147457123, mae:0.26367703080177307, mape:0.6228083968162537, mspe:13.970178604125977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1215+-0.00073, MAE:0.2648+-0.00191, MAPE:0.6309+-0.01310, MSPE:14.3626+-0.60836, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5608
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.7384217
	speed: 0.0512s/iter; left time: 1330.4879s
	iters: 200, epoch: 1 | loss: 3.6742847
	speed: 0.0453s/iter; left time: 1173.2872s
Epoch: 1 cost time: 12.479138135910034
Epoch: 1, Steps: 261 Train Loss: 3.7355 (Forecasting Loss:0.3721 + XiCon Loss:3.3633 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.324146).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4583147
	speed: 0.0484s/iter; left time: 1245.4363s
	iters: 200, epoch: 2 | loss: 3.4371746
	speed: 0.0454s/iter; left time: 1164.0067s
Epoch: 2 cost time: 12.101398229598999
Epoch: 2, Steps: 261 Train Loss: 3.4984 (Forecasting Loss:0.3001 + XiCon Loss:3.1982 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2480
Validation loss decreased (0.324146 --> 0.290684).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4696312
	speed: 0.0474s/iter; left time: 1207.5129s
	iters: 200, epoch: 3 | loss: 3.5392752
	speed: 0.0448s/iter; left time: 1135.7592s
Epoch: 3 cost time: 12.023934364318848
Epoch: 3, Steps: 261 Train Loss: 3.4877 (Forecasting Loss:0.2928 + XiCon Loss:3.1950 x Lambda(1.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2455
Validation loss decreased (0.290684 --> 0.280062).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4248164
	speed: 0.0479s/iter; left time: 1207.7144s
	iters: 200, epoch: 4 | loss: 3.4586947
	speed: 0.0447s/iter; left time: 1121.6214s
Epoch: 4 cost time: 12.14039921760559
Epoch: 4, Steps: 261 Train Loss: 3.4705 (Forecasting Loss:0.2901 + XiCon Loss:3.1804 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2455
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5130963
	speed: 0.0475s/iter; left time: 1185.4179s
	iters: 200, epoch: 5 | loss: 3.4668303
	speed: 0.0452s/iter; left time: 1123.4557s
Epoch: 5 cost time: 12.079479932785034
Epoch: 5, Steps: 261 Train Loss: 3.4599 (Forecasting Loss:0.2894 + XiCon Loss:3.1705 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2453
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4947045
	speed: 0.0477s/iter; left time: 1177.7813s
	iters: 200, epoch: 6 | loss: 3.4315767
	speed: 0.0451s/iter; left time: 1108.2682s
Epoch: 6 cost time: 12.105807781219482
Epoch: 6, Steps: 261 Train Loss: 3.4562 (Forecasting Loss:0.2884 + XiCon Loss:3.1678 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2448
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4416103
	speed: 0.0483s/iter; left time: 1179.7835s
	iters: 200, epoch: 7 | loss: 3.4070349
	speed: 0.0454s/iter; left time: 1105.2616s
Epoch: 7 cost time: 12.173448324203491
Epoch: 7, Steps: 261 Train Loss: 3.4520 (Forecasting Loss:0.2885 + XiCon Loss:3.1635 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2450
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4749703
	speed: 0.0472s/iter; left time: 1140.9298s
	iters: 200, epoch: 8 | loss: 3.5186424
	speed: 0.0455s/iter; left time: 1095.7607s
Epoch: 8 cost time: 11.992758989334106
Epoch: 8, Steps: 261 Train Loss: 3.4509 (Forecasting Loss:0.2885 + XiCon Loss:3.1624 x Lambda(1.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.2452
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3925676
	speed: 0.0473s/iter; left time: 1130.9626s
	iters: 200, epoch: 9 | loss: 3.4282060
	speed: 0.0454s/iter; left time: 1081.2671s
Epoch: 9 cost time: 12.07616925239563
Epoch: 9, Steps: 261 Train Loss: 3.4546 (Forecasting Loss:0.2885 + XiCon Loss:3.1661 x Lambda(1.0)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.2453
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4851124
	speed: 0.0475s/iter; left time: 1122.3160s
	iters: 200, epoch: 10 | loss: 3.4546003
	speed: 0.0457s/iter; left time: 1077.3755s
Epoch: 10 cost time: 12.141988277435303
Epoch: 10, Steps: 261 Train Loss: 3.4502 (Forecasting Loss:0.2883 + XiCon Loss:3.1619 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2452
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4736865
	speed: 0.0485s/iter; left time: 1135.5895s
	iters: 200, epoch: 11 | loss: 3.4213457
	speed: 0.0458s/iter; left time: 1067.3943s
Epoch: 11 cost time: 12.243110418319702
Epoch: 11, Steps: 261 Train Loss: 3.4507 (Forecasting Loss:0.2884 + XiCon Loss:3.1623 x Lambda(1.0)), Vali MSE Loss: 0.2823 Test MSE Loss: 0.2452
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4539948
	speed: 0.0477s/iter; left time: 1102.7613s
	iters: 200, epoch: 12 | loss: 3.4351149
	speed: 0.0456s/iter; left time: 1049.2268s
Epoch: 12 cost time: 12.171209812164307
Epoch: 12, Steps: 261 Train Loss: 3.4528 (Forecasting Loss:0.2883 + XiCon Loss:3.1645 x Lambda(1.0)), Vali MSE Loss: 0.2825 Test MSE Loss: 0.2453
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4911575
	speed: 0.0475s/iter; left time: 1087.2006s
	iters: 200, epoch: 13 | loss: 3.4411187
	speed: 0.0452s/iter; left time: 1029.0808s
Epoch: 13 cost time: 12.073511362075806
Epoch: 13, Steps: 261 Train Loss: 3.4530 (Forecasting Loss:0.2884 + XiCon Loss:3.1645 x Lambda(1.0)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.2453
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17060266435146332, mae:0.320328950881958, mape:0.7294715642929077, mspe:20.646394729614258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.2974
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.7692342
	speed: 0.0496s/iter; left time: 1289.6723s
	iters: 200, epoch: 1 | loss: 3.7064538
	speed: 0.0452s/iter; left time: 1171.8353s
Epoch: 1 cost time: 12.243040323257446
Epoch: 1, Steps: 261 Train Loss: 3.7508 (Forecasting Loss:0.3712 + XiCon Loss:3.3796 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2809
Validation loss decreased (inf --> 0.323930).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4660876
	speed: 0.0476s/iter; left time: 1225.7343s
	iters: 200, epoch: 2 | loss: 3.4411695
	speed: 0.0438s/iter; left time: 1122.8852s
Epoch: 2 cost time: 11.887790441513062
Epoch: 2, Steps: 261 Train Loss: 3.4870 (Forecasting Loss:0.2991 + XiCon Loss:3.1879 x Lambda(1.0)), Vali MSE Loss: 0.2844 Test MSE Loss: 0.2535
Validation loss decreased (0.323930 --> 0.284417).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4989288
	speed: 0.0504s/iter; left time: 1284.0352s
	iters: 200, epoch: 3 | loss: 3.5412354
	speed: 0.0475s/iter; left time: 1206.4174s
Epoch: 3 cost time: 12.814139366149902
Epoch: 3, Steps: 261 Train Loss: 3.5032 (Forecasting Loss:0.2912 + XiCon Loss:3.2120 x Lambda(1.0)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.2494
Validation loss decreased (0.284417 --> 0.274921).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4917085
	speed: 0.0495s/iter; left time: 1249.1341s
	iters: 200, epoch: 4 | loss: 3.4289782
	speed: 0.0458s/iter; left time: 1149.2760s
Epoch: 4 cost time: 12.350202322006226
Epoch: 4, Steps: 261 Train Loss: 3.4714 (Forecasting Loss:0.2900 + XiCon Loss:3.1814 x Lambda(1.0)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.2471
Validation loss decreased (0.274921 --> 0.272688).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4639933
	speed: 0.0476s/iter; left time: 1187.6546s
	iters: 200, epoch: 5 | loss: 3.4712336
	speed: 0.0456s/iter; left time: 1132.5246s
Epoch: 5 cost time: 12.152501344680786
Epoch: 5, Steps: 261 Train Loss: 3.4586 (Forecasting Loss:0.2889 + XiCon Loss:3.1698 x Lambda(1.0)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.2458
Validation loss decreased (0.272688 --> 0.271710).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4178174
	speed: 0.0477s/iter; left time: 1177.1070s
	iters: 200, epoch: 6 | loss: 3.4354839
	speed: 0.0459s/iter; left time: 1128.7798s
Epoch: 6 cost time: 12.125174522399902
Epoch: 6, Steps: 261 Train Loss: 3.4533 (Forecasting Loss:0.2884 + XiCon Loss:3.1649 x Lambda(1.0)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.2461
Validation loss decreased (0.271710 --> 0.271074).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4856498
	speed: 0.0477s/iter; left time: 1166.0275s
	iters: 200, epoch: 7 | loss: 3.4884925
	speed: 0.0459s/iter; left time: 1116.9581s
Epoch: 7 cost time: 12.171394348144531
Epoch: 7, Steps: 261 Train Loss: 3.4484 (Forecasting Loss:0.2880 + XiCon Loss:3.1604 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2458
Validation loss decreased (0.271074 --> 0.270576).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4337375
	speed: 0.0484s/iter; left time: 1171.0262s
	iters: 200, epoch: 8 | loss: 3.4339020
	speed: 0.0463s/iter; left time: 1114.0520s
Epoch: 8 cost time: 12.320880889892578
Epoch: 8, Steps: 261 Train Loss: 3.4460 (Forecasting Loss:0.2879 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4658036
	speed: 0.0480s/iter; left time: 1146.7789s
	iters: 200, epoch: 9 | loss: 3.4331417
	speed: 0.0462s/iter; left time: 1101.1240s
Epoch: 9 cost time: 12.23000693321228
Epoch: 9, Steps: 261 Train Loss: 3.4447 (Forecasting Loss:0.2878 + XiCon Loss:3.1569 x Lambda(1.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.2457
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4333467
	speed: 0.0477s/iter; left time: 1128.7081s
	iters: 200, epoch: 10 | loss: 3.4692726
	speed: 0.0461s/iter; left time: 1086.3825s
Epoch: 10 cost time: 12.238486766815186
Epoch: 10, Steps: 261 Train Loss: 3.4487 (Forecasting Loss:0.2879 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2457
Validation loss decreased (0.270576 --> 0.270474).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4552388
	speed: 0.0485s/iter; left time: 1134.6766s
	iters: 200, epoch: 11 | loss: 3.5137901
	speed: 0.0459s/iter; left time: 1069.1649s
Epoch: 11 cost time: 12.276948928833008
Epoch: 11, Steps: 261 Train Loss: 3.4446 (Forecasting Loss:0.2879 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4462538
	speed: 0.0483s/iter; left time: 1116.4186s
	iters: 200, epoch: 12 | loss: 3.4744296
	speed: 0.0453s/iter; left time: 1042.8932s
Epoch: 12 cost time: 12.171367406845093
Epoch: 12, Steps: 261 Train Loss: 3.4483 (Forecasting Loss:0.2880 + XiCon Loss:3.1603 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4336510
	speed: 0.0479s/iter; left time: 1096.2144s
	iters: 200, epoch: 13 | loss: 3.4217813
	speed: 0.0470s/iter; left time: 1071.0324s
Epoch: 13 cost time: 12.3025643825531
Epoch: 13, Steps: 261 Train Loss: 3.4452 (Forecasting Loss:0.2878 + XiCon Loss:3.1574 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4168568
	speed: 0.0485s/iter; left time: 1097.3546s
	iters: 200, epoch: 14 | loss: 3.4744887
	speed: 0.0458s/iter; left time: 1030.6186s
Epoch: 14 cost time: 12.305056810379028
Epoch: 14, Steps: 261 Train Loss: 3.4443 (Forecasting Loss:0.2876 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
Validation loss decreased (0.270474 --> 0.270458).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4716437
	speed: 0.0481s/iter; left time: 1074.0730s
	iters: 200, epoch: 15 | loss: 3.4141011
	speed: 0.0458s/iter; left time: 1018.2547s
Epoch: 15 cost time: 12.219585657119751
Epoch: 15, Steps: 261 Train Loss: 3.4484 (Forecasting Loss:0.2879 + XiCon Loss:3.1605 x Lambda(1.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.2456
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4783602
	speed: 0.0479s/iter; left time: 1058.4061s
	iters: 200, epoch: 16 | loss: 3.4685049
	speed: 0.0461s/iter; left time: 1012.5093s
Epoch: 16 cost time: 12.21197247505188
Epoch: 16, Steps: 261 Train Loss: 3.4462 (Forecasting Loss:0.2879 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5078285
	speed: 0.0476s/iter; left time: 1039.5214s
	iters: 200, epoch: 17 | loss: 3.4361093
	speed: 0.0460s/iter; left time: 998.8899s
Epoch: 17 cost time: 12.173420667648315
Epoch: 17, Steps: 261 Train Loss: 3.4463 (Forecasting Loss:0.2879 + XiCon Loss:3.1584 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.4519150
	speed: 0.0482s/iter; left time: 1038.8244s
	iters: 200, epoch: 18 | loss: 3.4862874
	speed: 0.0465s/iter; left time: 997.0949s
Epoch: 18 cost time: 12.304040431976318
Epoch: 18, Steps: 261 Train Loss: 3.4486 (Forecasting Loss:0.2878 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.2456
Validation loss decreased (0.270458 --> 0.270376).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4406922
	speed: 0.0488s/iter; left time: 1040.3604s
	iters: 200, epoch: 19 | loss: 3.4972835
	speed: 0.0454s/iter; left time: 962.2227s
Epoch: 19 cost time: 12.250588417053223
Epoch: 19, Steps: 261 Train Loss: 3.4458 (Forecasting Loss:0.2877 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.2456
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4733045
	speed: 0.0475s/iter; left time: 1000.0165s
	iters: 200, epoch: 20 | loss: 3.4192133
	speed: 0.0459s/iter; left time: 960.6726s
Epoch: 20 cost time: 12.182641506195068
Epoch: 20, Steps: 261 Train Loss: 3.4460 (Forecasting Loss:0.2879 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.2456
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.4324365
	speed: 0.0480s/iter; left time: 997.5374s
	iters: 200, epoch: 21 | loss: 3.3857784
	speed: 0.0469s/iter; left time: 969.9890s
Epoch: 21 cost time: 12.380386590957642
Epoch: 21, Steps: 261 Train Loss: 3.4467 (Forecasting Loss:0.2877 + XiCon Loss:3.1590 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.4516711
	speed: 0.0487s/iter; left time: 1000.2188s
	iters: 200, epoch: 22 | loss: 3.5033967
	speed: 0.0462s/iter; left time: 942.4710s
Epoch: 22 cost time: 12.328193664550781
Epoch: 22, Steps: 261 Train Loss: 3.4462 (Forecasting Loss:0.2879 + XiCon Loss:3.1584 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.4127243
	speed: 0.0488s/iter; left time: 989.2154s
	iters: 200, epoch: 23 | loss: 3.3883102
	speed: 0.0458s/iter; left time: 924.0291s
Epoch: 23 cost time: 12.34188175201416
Epoch: 23, Steps: 261 Train Loss: 3.4463 (Forecasting Loss:0.2880 + XiCon Loss:3.1584 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.4639730
	speed: 0.0497s/iter; left time: 992.9394s
	iters: 200, epoch: 24 | loss: 3.4517815
	speed: 0.0450s/iter; left time: 894.5602s
Epoch: 24 cost time: 12.217811107635498
Epoch: 24, Steps: 261 Train Loss: 3.4463 (Forecasting Loss:0.2878 + XiCon Loss:3.1585 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.4671006
	speed: 0.0472s/iter; left time: 932.3466s
	iters: 200, epoch: 25 | loss: 3.4894524
	speed: 0.0462s/iter; left time: 907.3922s
Epoch: 25 cost time: 12.20388388633728
Epoch: 25, Steps: 261 Train Loss: 3.4456 (Forecasting Loss:0.2878 + XiCon Loss:3.1579 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.4820530
	speed: 0.0476s/iter; left time: 926.7169s
	iters: 200, epoch: 26 | loss: 3.5153997
	speed: 0.0457s/iter; left time: 884.9415s
Epoch: 26 cost time: 12.166544198989868
Epoch: 26, Steps: 261 Train Loss: 3.4460 (Forecasting Loss:0.2877 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.4247439
	speed: 0.0481s/iter; left time: 924.6549s
	iters: 200, epoch: 27 | loss: 3.4662709
	speed: 0.0461s/iter; left time: 881.3842s
Epoch: 27 cost time: 12.228021621704102
Epoch: 27, Steps: 261 Train Loss: 3.4457 (Forecasting Loss:0.2878 + XiCon Loss:3.1579 x Lambda(1.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.2456
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.4629064
	speed: 0.0492s/iter; left time: 932.8235s
	iters: 200, epoch: 28 | loss: 3.3723891
	speed: 0.0454s/iter; left time: 856.1402s
Epoch: 28 cost time: 12.323395490646362
Epoch: 28, Steps: 261 Train Loss: 3.4484 (Forecasting Loss:0.2879 + XiCon Loss:3.1605 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2456
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17156687378883362, mae:0.31967979669570923, mape:0.703098475933075, mspe:18.886241912841797 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9882
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.7183187
	speed: 0.0488s/iter; left time: 1269.2041s
	iters: 200, epoch: 1 | loss: 3.6998320
	speed: 0.0453s/iter; left time: 1173.2335s
Epoch: 1 cost time: 12.215681314468384
Epoch: 1, Steps: 261 Train Loss: 3.7350 (Forecasting Loss:0.3723 + XiCon Loss:3.3627 x Lambda(1.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.319393).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5172718
	speed: 0.0479s/iter; left time: 1233.2317s
	iters: 200, epoch: 2 | loss: 3.4839439
	speed: 0.0447s/iter; left time: 1145.5194s
Epoch: 2 cost time: 12.064723253250122
Epoch: 2, Steps: 261 Train Loss: 3.5597 (Forecasting Loss:0.3000 + XiCon Loss:3.2598 x Lambda(1.0)), Vali MSE Loss: 0.2866 Test MSE Loss: 0.2472
Validation loss decreased (0.319393 --> 0.286617).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6683278
	speed: 0.0486s/iter; left time: 1237.4030s
	iters: 200, epoch: 3 | loss: 3.5699348
	speed: 0.0450s/iter; left time: 1142.3284s
Epoch: 3 cost time: 12.150758504867554
Epoch: 3, Steps: 261 Train Loss: 3.5864 (Forecasting Loss:0.2897 + XiCon Loss:3.2967 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2508
Validation loss decreased (0.286617 --> 0.283839).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5004740
	speed: 0.0476s/iter; left time: 1199.5764s
	iters: 200, epoch: 4 | loss: 3.5223083
	speed: 0.0455s/iter; left time: 1142.8083s
Epoch: 4 cost time: 12.092341661453247
Epoch: 4, Steps: 261 Train Loss: 3.5698 (Forecasting Loss:0.2866 + XiCon Loss:3.2832 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2529
Validation loss decreased (0.283839 --> 0.281404).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5377722
	speed: 0.0494s/iter; left time: 1232.7707s
	iters: 200, epoch: 5 | loss: 3.5206659
	speed: 0.0456s/iter; left time: 1132.4104s
Epoch: 5 cost time: 12.360125303268433
Epoch: 5, Steps: 261 Train Loss: 3.5601 (Forecasting Loss:0.2851 + XiCon Loss:3.2750 x Lambda(1.0)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.2523
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6241155
	speed: 0.0486s/iter; left time: 1201.3479s
	iters: 200, epoch: 6 | loss: 3.5393004
	speed: 0.0459s/iter; left time: 1128.7329s
Epoch: 6 cost time: 12.269577980041504
Epoch: 6, Steps: 261 Train Loss: 3.5542 (Forecasting Loss:0.2847 + XiCon Loss:3.2695 x Lambda(1.0)), Vali MSE Loss: 0.2822 Test MSE Loss: 0.2522
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4920375
	speed: 0.0490s/iter; left time: 1196.8191s
	iters: 200, epoch: 7 | loss: 3.5513442
	speed: 0.0457s/iter; left time: 1112.1107s
Epoch: 7 cost time: 12.326166868209839
Epoch: 7, Steps: 261 Train Loss: 3.5530 (Forecasting Loss:0.2847 + XiCon Loss:3.2683 x Lambda(1.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.2525
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6245654
	speed: 0.0493s/iter; left time: 1192.9206s
	iters: 200, epoch: 8 | loss: 3.5986974
	speed: 0.0462s/iter; left time: 1111.5789s
Epoch: 8 cost time: 12.413899660110474
Epoch: 8, Steps: 261 Train Loss: 3.5526 (Forecasting Loss:0.2844 + XiCon Loss:3.2681 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2526
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5363939
	speed: 0.0490s/iter; left time: 1170.9386s
	iters: 200, epoch: 9 | loss: 3.5679224
	speed: 0.0464s/iter; left time: 1105.7466s
Epoch: 9 cost time: 12.389833688735962
Epoch: 9, Steps: 261 Train Loss: 3.5554 (Forecasting Loss:0.2842 + XiCon Loss:3.2711 x Lambda(1.0)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.2526
Validation loss decreased (0.281404 --> 0.281341).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5632384
	speed: 0.0483s/iter; left time: 1142.7252s
	iters: 200, epoch: 10 | loss: 3.5624032
	speed: 0.0459s/iter; left time: 1079.8616s
Epoch: 10 cost time: 12.330046892166138
Epoch: 10, Steps: 261 Train Loss: 3.5542 (Forecasting Loss:0.2843 + XiCon Loss:3.2699 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5898228
	speed: 0.0489s/iter; left time: 1142.7361s
	iters: 200, epoch: 11 | loss: 3.5398338
	speed: 0.0461s/iter; left time: 1073.2611s
Epoch: 11 cost time: 12.360611915588379
Epoch: 11, Steps: 261 Train Loss: 3.5549 (Forecasting Loss:0.2844 + XiCon Loss:3.2705 x Lambda(1.0)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.2526
Validation loss decreased (0.281341 --> 0.281260).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5795579
	speed: 0.0489s/iter; left time: 1130.3251s
	iters: 200, epoch: 12 | loss: 3.5834887
	speed: 0.0468s/iter; left time: 1076.9019s
Epoch: 12 cost time: 12.496155023574829
Epoch: 12, Steps: 261 Train Loss: 3.5553 (Forecasting Loss:0.2842 + XiCon Loss:3.2712 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2526
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4270098
	speed: 0.0493s/iter; left time: 1128.3523s
	iters: 200, epoch: 13 | loss: 3.5705721
	speed: 0.0467s/iter; left time: 1064.2934s
Epoch: 13 cost time: 12.53106141090393
Epoch: 13, Steps: 261 Train Loss: 3.5517 (Forecasting Loss:0.2841 + XiCon Loss:3.2675 x Lambda(1.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2526
Validation loss decreased (0.281260 --> 0.281217).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5215127
	speed: 0.0490s/iter; left time: 1108.3570s
	iters: 200, epoch: 14 | loss: 3.5269914
	speed: 0.0470s/iter; left time: 1058.9192s
Epoch: 14 cost time: 12.52179503440857
Epoch: 14, Steps: 261 Train Loss: 3.5541 (Forecasting Loss:0.2842 + XiCon Loss:3.2699 x Lambda(1.0)), Vali MSE Loss: 0.2811 Test MSE Loss: 0.2526
Validation loss decreased (0.281217 --> 0.281139).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5024998
	speed: 0.0490s/iter; left time: 1094.2978s
	iters: 200, epoch: 15 | loss: 3.6165044
	speed: 0.0468s/iter; left time: 1041.7295s
Epoch: 15 cost time: 12.504577159881592
Epoch: 15, Steps: 261 Train Loss: 3.5549 (Forecasting Loss:0.2841 + XiCon Loss:3.2708 x Lambda(1.0)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.2526
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6200409
	speed: 0.0489s/iter; left time: 1080.8491s
	iters: 200, epoch: 16 | loss: 3.6350217
	speed: 0.0463s/iter; left time: 1016.9434s
Epoch: 16 cost time: 12.379255294799805
Epoch: 16, Steps: 261 Train Loss: 3.5539 (Forecasting Loss:0.2843 + XiCon Loss:3.2695 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5933447
	speed: 0.0491s/iter; left time: 1071.5669s
	iters: 200, epoch: 17 | loss: 3.6251850
	speed: 0.0469s/iter; left time: 1017.9123s
Epoch: 17 cost time: 12.514954805374146
Epoch: 17, Steps: 261 Train Loss: 3.5557 (Forecasting Loss:0.2841 + XiCon Loss:3.2716 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.4854040
	speed: 0.0496s/iter; left time: 1068.8930s
	iters: 200, epoch: 18 | loss: 3.4959710
	speed: 0.0469s/iter; left time: 1007.1482s
Epoch: 18 cost time: 12.544575452804565
Epoch: 18, Steps: 261 Train Loss: 3.5533 (Forecasting Loss:0.2843 + XiCon Loss:3.2690 x Lambda(1.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2526
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.5246294
	speed: 0.0485s/iter; left time: 1032.3169s
	iters: 200, epoch: 19 | loss: 3.5132413
	speed: 0.0457s/iter; left time: 968.0922s
Epoch: 19 cost time: 12.239205121994019
Epoch: 19, Steps: 261 Train Loss: 3.5512 (Forecasting Loss:0.2840 + XiCon Loss:3.2672 x Lambda(1.0)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.2526
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5495493
	speed: 0.0491s/iter; left time: 1033.7852s
	iters: 200, epoch: 20 | loss: 3.6027446
	speed: 0.0468s/iter; left time: 979.2472s
Epoch: 20 cost time: 12.54183030128479
Epoch: 20, Steps: 261 Train Loss: 3.5518 (Forecasting Loss:0.2841 + XiCon Loss:3.2677 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.4579659
	speed: 0.0487s/iter; left time: 1012.0173s
	iters: 200, epoch: 21 | loss: 3.4648273
	speed: 0.0464s/iter; left time: 959.4684s
Epoch: 21 cost time: 12.417967081069946
Epoch: 21, Steps: 261 Train Loss: 3.5504 (Forecasting Loss:0.2843 + XiCon Loss:3.2661 x Lambda(1.0)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.2526
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.5132697
	speed: 0.0489s/iter; left time: 1003.6416s
	iters: 200, epoch: 22 | loss: 3.5550401
	speed: 0.0466s/iter; left time: 952.3091s
Epoch: 22 cost time: 12.468175411224365
Epoch: 22, Steps: 261 Train Loss: 3.5505 (Forecasting Loss:0.2845 + XiCon Loss:3.2660 x Lambda(1.0)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.2526
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.6401162
	speed: 0.0487s/iter; left time: 987.4777s
	iters: 200, epoch: 23 | loss: 3.5164554
	speed: 0.0475s/iter; left time: 958.4961s
Epoch: 23 cost time: 12.54645586013794
Epoch: 23, Steps: 261 Train Loss: 3.5488 (Forecasting Loss:0.2841 + XiCon Loss:3.2646 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.4848933
	speed: 0.0493s/iter; left time: 985.3897s
	iters: 200, epoch: 24 | loss: 3.6548402
	speed: 0.0468s/iter; left time: 931.7230s
Epoch: 24 cost time: 12.574698448181152
Epoch: 24, Steps: 261 Train Loss: 3.5504 (Forecasting Loss:0.2843 + XiCon Loss:3.2661 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2526
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17754212021827698, mae:0.32773369550704956, mape:0.730255663394928, mspe:19.77358627319336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.0499
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.8005774
	speed: 0.0484s/iter; left time: 1258.1277s
	iters: 200, epoch: 1 | loss: 3.7011776
	speed: 0.0447s/iter; left time: 1157.0670s
Epoch: 1 cost time: 12.121406316757202
Epoch: 1, Steps: 261 Train Loss: 3.7554 (Forecasting Loss:0.3726 + XiCon Loss:3.3828 x Lambda(1.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2812
Validation loss decreased (inf --> 0.319674).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4648695
	speed: 0.0473s/iter; left time: 1216.4197s
	iters: 200, epoch: 2 | loss: 3.4996426
	speed: 0.0448s/iter; left time: 1149.1478s
Epoch: 2 cost time: 12.001737356185913
Epoch: 2, Steps: 261 Train Loss: 3.5105 (Forecasting Loss:0.2999 + XiCon Loss:3.2105 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2476
Validation loss decreased (0.319674 --> 0.281559).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4909050
	speed: 0.0474s/iter; left time: 1208.8485s
	iters: 200, epoch: 3 | loss: 3.5684285
	speed: 0.0448s/iter; left time: 1135.9592s
Epoch: 3 cost time: 12.009192943572998
Epoch: 3, Steps: 261 Train Loss: 3.5192 (Forecasting Loss:0.2938 + XiCon Loss:3.2254 x Lambda(1.0)), Vali MSE Loss: 0.2825 Test MSE Loss: 0.2487
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4363487
	speed: 0.0481s/iter; left time: 1212.7302s
	iters: 200, epoch: 4 | loss: 3.4603090
	speed: 0.0452s/iter; left time: 1134.2709s
Epoch: 4 cost time: 12.106922149658203
Epoch: 4, Steps: 261 Train Loss: 3.5063 (Forecasting Loss:0.2915 + XiCon Loss:3.2149 x Lambda(1.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2482
Validation loss decreased (0.281559 --> 0.280187).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4984384
	speed: 0.0478s/iter; left time: 1192.0910s
	iters: 200, epoch: 5 | loss: 3.4918895
	speed: 0.0457s/iter; left time: 1135.7460s
Epoch: 5 cost time: 12.141209125518799
Epoch: 5, Steps: 261 Train Loss: 3.5014 (Forecasting Loss:0.2907 + XiCon Loss:3.2106 x Lambda(1.0)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.2491
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5309279
	speed: 0.0477s/iter; left time: 1178.2096s
	iters: 200, epoch: 6 | loss: 3.5568211
	speed: 0.0448s/iter; left time: 1102.1253s
Epoch: 6 cost time: 12.041530847549438
Epoch: 6, Steps: 261 Train Loss: 3.5003 (Forecasting Loss:0.2905 + XiCon Loss:3.2098 x Lambda(1.0)), Vali MSE Loss: 0.2805 Test MSE Loss: 0.2489
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4194722
	speed: 0.0483s/iter; left time: 1179.1547s
	iters: 200, epoch: 7 | loss: 3.5848708
	speed: 0.0463s/iter; left time: 1125.8538s
Epoch: 7 cost time: 12.239673614501953
Epoch: 7, Steps: 261 Train Loss: 3.4913 (Forecasting Loss:0.2898 + XiCon Loss:3.2015 x Lambda(1.0)), Vali MSE Loss: 0.2793 Test MSE Loss: 0.2481
Validation loss decreased (0.280187 --> 0.279342).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4858401
	speed: 0.0476s/iter; left time: 1151.2151s
	iters: 200, epoch: 8 | loss: 3.5929341
	speed: 0.0455s/iter; left time: 1094.3923s
Epoch: 8 cost time: 12.10800313949585
Epoch: 8, Steps: 261 Train Loss: 3.4893 (Forecasting Loss:0.2899 + XiCon Loss:3.1993 x Lambda(1.0)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2478
Validation loss decreased (0.279342 --> 0.278232).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4818225
	speed: 0.0480s/iter; left time: 1147.5954s
	iters: 200, epoch: 9 | loss: 3.5483646
	speed: 0.0462s/iter; left time: 1099.2571s
Epoch: 9 cost time: 12.238519668579102
Epoch: 9, Steps: 261 Train Loss: 3.4938 (Forecasting Loss:0.2901 + XiCon Loss:3.2037 x Lambda(1.0)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2481
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4820428
	speed: 0.0481s/iter; left time: 1137.5926s
	iters: 200, epoch: 10 | loss: 3.4800854
	speed: 0.0457s/iter; left time: 1076.9333s
Epoch: 10 cost time: 12.197392463684082
Epoch: 10, Steps: 261 Train Loss: 3.4939 (Forecasting Loss:0.2897 + XiCon Loss:3.2043 x Lambda(1.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2481
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4793050
	speed: 0.0479s/iter; left time: 1119.8007s
	iters: 200, epoch: 11 | loss: 3.5580161
	speed: 0.0452s/iter; left time: 1053.8223s
Epoch: 11 cost time: 12.081993103027344
Epoch: 11, Steps: 261 Train Loss: 3.4917 (Forecasting Loss:0.2893 + XiCon Loss:3.2025 x Lambda(1.0)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2482
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5410929
	speed: 0.0478s/iter; left time: 1105.9054s
	iters: 200, epoch: 12 | loss: 3.4443023
	speed: 0.0462s/iter; left time: 1064.5224s
Epoch: 12 cost time: 12.241336822509766
Epoch: 12, Steps: 261 Train Loss: 3.4937 (Forecasting Loss:0.2897 + XiCon Loss:3.2039 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2482
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4570503
	speed: 0.0484s/iter; left time: 1106.9029s
	iters: 200, epoch: 13 | loss: 3.5004358
	speed: 0.0455s/iter; left time: 1035.0043s
Epoch: 13 cost time: 12.174708366394043
Epoch: 13, Steps: 261 Train Loss: 3.4947 (Forecasting Loss:0.2897 + XiCon Loss:3.2050 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2482
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4800801
	speed: 0.0488s/iter; left time: 1104.3652s
	iters: 200, epoch: 14 | loss: 3.4016516
	speed: 0.0461s/iter; left time: 1037.4804s
Epoch: 14 cost time: 12.274905681610107
Epoch: 14, Steps: 261 Train Loss: 3.4955 (Forecasting Loss:0.2898 + XiCon Loss:3.2056 x Lambda(1.0)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2482
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5175109
	speed: 0.0480s/iter; left time: 1072.0230s
	iters: 200, epoch: 15 | loss: 3.4906521
	speed: 0.0453s/iter; left time: 1008.8149s
Epoch: 15 cost time: 12.154250144958496
Epoch: 15, Steps: 261 Train Loss: 3.4869 (Forecasting Loss:0.2896 + XiCon Loss:3.1972 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2482
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4749148
	speed: 0.0481s/iter; left time: 1062.0087s
	iters: 200, epoch: 16 | loss: 3.5369120
	speed: 0.0455s/iter; left time: 1000.2692s
Epoch: 16 cost time: 12.158671855926514
Epoch: 16, Steps: 261 Train Loss: 3.4907 (Forecasting Loss:0.2898 + XiCon Loss:3.2009 x Lambda(1.0)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2482
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4921107
	speed: 0.0477s/iter; left time: 1041.3090s
	iters: 200, epoch: 17 | loss: 3.5584822
	speed: 0.0448s/iter; left time: 972.5642s
Epoch: 17 cost time: 12.085236072540283
Epoch: 17, Steps: 261 Train Loss: 3.4925 (Forecasting Loss:0.2898 + XiCon Loss:3.2026 x Lambda(1.0)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2482
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.4108291
	speed: 0.0479s/iter; left time: 1032.8290s
	iters: 200, epoch: 18 | loss: 3.4997616
	speed: 0.0449s/iter; left time: 963.9621s
Epoch: 18 cost time: 12.097106456756592
Epoch: 18, Steps: 261 Train Loss: 3.4886 (Forecasting Loss:0.2897 + XiCon Loss:3.1989 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2482
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17341135442256927, mae:0.3222249448299408, mape:0.7165150046348572, mspe:20.000585556030273 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3217
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.7611098
	speed: 0.0481s/iter; left time: 1251.7032s
	iters: 200, epoch: 1 | loss: 3.7456813
	speed: 0.0450s/iter; left time: 1165.5722s
Epoch: 1 cost time: 12.090002536773682
Epoch: 1, Steps: 261 Train Loss: 3.7549 (Forecasting Loss:0.3749 + XiCon Loss:3.3800 x Lambda(1.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2819
Validation loss decreased (inf --> 0.319743).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4994242
	speed: 0.0479s/iter; left time: 1232.7904s
	iters: 200, epoch: 2 | loss: 3.5069604
	speed: 0.0451s/iter; left time: 1155.5801s
Epoch: 2 cost time: 12.076341152191162
Epoch: 2, Steps: 261 Train Loss: 3.5354 (Forecasting Loss:0.2995 + XiCon Loss:3.2359 x Lambda(1.0)), Vali MSE Loss: 0.2860 Test MSE Loss: 0.2476
Validation loss decreased (0.319743 --> 0.286007).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5621343
	speed: 0.0474s/iter; left time: 1207.8086s
	iters: 200, epoch: 3 | loss: 3.4842963
	speed: 0.0443s/iter; left time: 1125.4513s
Epoch: 3 cost time: 12.002433776855469
Epoch: 3, Steps: 261 Train Loss: 3.5394 (Forecasting Loss:0.2955 + XiCon Loss:3.2438 x Lambda(1.0)), Vali MSE Loss: 0.2868 Test MSE Loss: 0.2482
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4628191
	speed: 0.0465s/iter; left time: 1172.3210s
	iters: 200, epoch: 4 | loss: 3.4745955
	speed: 0.0456s/iter; left time: 1145.1524s
Epoch: 4 cost time: 12.01279330253601
Epoch: 4, Steps: 261 Train Loss: 3.5054 (Forecasting Loss:0.2931 + XiCon Loss:3.2123 x Lambda(1.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2470
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4196739
	speed: 0.0476s/iter; left time: 1188.7628s
	iters: 200, epoch: 5 | loss: 3.4785247
	speed: 0.0449s/iter; left time: 1116.2346s
Epoch: 5 cost time: 12.039353370666504
Epoch: 5, Steps: 261 Train Loss: 3.4769 (Forecasting Loss:0.2907 + XiCon Loss:3.1862 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2472
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5038860
	speed: 0.0483s/iter; left time: 1192.4152s
	iters: 200, epoch: 6 | loss: 3.4010930
	speed: 0.0454s/iter; left time: 1115.5951s
Epoch: 6 cost time: 12.134741067886353
Epoch: 6, Steps: 261 Train Loss: 3.4676 (Forecasting Loss:0.2898 + XiCon Loss:3.1778 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2472
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5145314
	speed: 0.0486s/iter; left time: 1188.1577s
	iters: 200, epoch: 7 | loss: 3.4163435
	speed: 0.0460s/iter; left time: 1118.4916s
Epoch: 7 cost time: 12.260826349258423
Epoch: 7, Steps: 261 Train Loss: 3.4614 (Forecasting Loss:0.2894 + XiCon Loss:3.1720 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2473
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4249098
	speed: 0.0481s/iter; left time: 1162.2237s
	iters: 200, epoch: 8 | loss: 3.4260073
	speed: 0.0451s/iter; left time: 1086.6366s
Epoch: 8 cost time: 12.138075113296509
Epoch: 8, Steps: 261 Train Loss: 3.4598 (Forecasting Loss:0.2894 + XiCon Loss:3.1704 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2473
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4960253
	speed: 0.0474s/iter; left time: 1134.5060s
	iters: 200, epoch: 9 | loss: 3.5123150
	speed: 0.0459s/iter; left time: 1093.0634s
Epoch: 9 cost time: 12.143752813339233
Epoch: 9, Steps: 261 Train Loss: 3.4636 (Forecasting Loss:0.2892 + XiCon Loss:3.1744 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2473
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4579310
	speed: 0.0480s/iter; left time: 1135.7675s
	iters: 200, epoch: 10 | loss: 3.4364893
	speed: 0.0454s/iter; left time: 1070.3280s
Epoch: 10 cost time: 12.114474296569824
Epoch: 10, Steps: 261 Train Loss: 3.4608 (Forecasting Loss:0.2893 + XiCon Loss:3.1715 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2473
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4262929
	speed: 0.0472s/iter; left time: 1105.1211s
	iters: 200, epoch: 11 | loss: 3.4591181
	speed: 0.0452s/iter; left time: 1051.9957s
Epoch: 11 cost time: 12.023634672164917
Epoch: 11, Steps: 261 Train Loss: 3.4576 (Forecasting Loss:0.2892 + XiCon Loss:3.1684 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2473
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4209883
	speed: 0.0475s/iter; left time: 1099.4575s
	iters: 200, epoch: 12 | loss: 3.4454637
	speed: 0.0454s/iter; left time: 1045.0645s
Epoch: 12 cost time: 12.098702430725098
Epoch: 12, Steps: 261 Train Loss: 3.4578 (Forecasting Loss:0.2892 + XiCon Loss:3.1687 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2473
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1727282851934433, mae:0.3223901689052582, mape:0.7079139947891235, mspe:19.149715423583984 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1732+-0.00332, MAE:0.3225+-0.00393, MAPE:0.7175+-0.01529, MSPE:19.6913+-0.86829, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
