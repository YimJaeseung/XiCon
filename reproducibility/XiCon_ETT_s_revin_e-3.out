Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3811
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2456698
	speed: 0.0164s/iter; left time: 208.1508s
Epoch: 1 cost time: 1.9886832237243652
Epoch: 1, Steps: 128 Train Loss: 0.2470 (Forecasting Loss:0.2439 + XiCon Loss:3.1093 x Lambda(0.001)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1209
Validation loss decreased (inf --> 0.173761).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2493072
	speed: 0.0142s/iter; left time: 178.2287s
Epoch: 2 cost time: 1.7547097206115723
Epoch: 2, Steps: 128 Train Loss: 0.2366 (Forecasting Loss:0.2335 + XiCon Loss:3.0981 x Lambda(0.001)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1390
Validation loss decreased (0.173761 --> 0.173607).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1679367
	speed: 0.0146s/iter; left time: 182.0492s
Epoch: 3 cost time: 1.8083419799804688
Epoch: 3, Steps: 128 Train Loss: 0.1939 (Forecasting Loss:0.1908 + XiCon Loss:3.1113 x Lambda(0.001)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1532
Validation loss decreased (0.173607 --> 0.171527).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1411889
	speed: 0.0130s/iter; left time: 160.7036s
Epoch: 4 cost time: 1.6279690265655518
Epoch: 4, Steps: 128 Train Loss: 0.1586 (Forecasting Loss:0.1555 + XiCon Loss:3.1114 x Lambda(0.001)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1711
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1324531
	speed: 0.0134s/iter; left time: 162.7513s
Epoch: 5 cost time: 1.6609282493591309
Epoch: 5, Steps: 128 Train Loss: 0.1422 (Forecasting Loss:0.1391 + XiCon Loss:3.1075 x Lambda(0.001)), Vali MSE Loss: 0.1791 Test MSE Loss: 0.1749
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1301263
	speed: 0.0130s/iter; left time: 156.2124s
Epoch: 6 cost time: 1.6271264553070068
Epoch: 6, Steps: 128 Train Loss: 0.1358 (Forecasting Loss:0.1327 + XiCon Loss:3.1064 x Lambda(0.001)), Vali MSE Loss: 0.1768 Test MSE Loss: 0.1787
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1233523
	speed: 0.0135s/iter; left time: 160.7957s
Epoch: 7 cost time: 1.676919937133789
Epoch: 7, Steps: 128 Train Loss: 0.1332 (Forecasting Loss:0.1301 + XiCon Loss:3.1070 x Lambda(0.001)), Vali MSE Loss: 0.1801 Test MSE Loss: 0.1776
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1354900
	speed: 0.0140s/iter; left time: 164.9602s
Epoch: 8 cost time: 1.7955305576324463
Epoch: 8, Steps: 128 Train Loss: 0.1315 (Forecasting Loss:0.1284 + XiCon Loss:3.1073 x Lambda(0.001)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1801
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1430963
	speed: 0.0132s/iter; left time: 154.5082s
Epoch: 9 cost time: 1.6552150249481201
Epoch: 9, Steps: 128 Train Loss: 0.1307 (Forecasting Loss:0.1276 + XiCon Loss:3.1064 x Lambda(0.001)), Vali MSE Loss: 0.1784 Test MSE Loss: 0.1781
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1380803
	speed: 0.0135s/iter; left time: 156.0077s
Epoch: 10 cost time: 1.6821191310882568
Epoch: 10, Steps: 128 Train Loss: 0.1304 (Forecasting Loss:0.1273 + XiCon Loss:3.1058 x Lambda(0.001)), Vali MSE Loss: 0.1780 Test MSE Loss: 0.1796
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1329812
	speed: 0.0135s/iter; left time: 154.0839s
Epoch: 11 cost time: 1.6917665004730225
Epoch: 11, Steps: 128 Train Loss: 0.1299 (Forecasting Loss:0.1268 + XiCon Loss:3.1067 x Lambda(0.001)), Vali MSE Loss: 0.1778 Test MSE Loss: 0.1794
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1352514
	speed: 0.0136s/iter; left time: 153.4091s
Epoch: 12 cost time: 1.693366289138794
Epoch: 12, Steps: 128 Train Loss: 0.1301 (Forecasting Loss:0.1270 + XiCon Loss:3.1070 x Lambda(0.001)), Vali MSE Loss: 0.1784 Test MSE Loss: 0.1796
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1334045
	speed: 0.0137s/iter; left time: 153.2099s
Epoch: 13 cost time: 1.705939531326294
Epoch: 13, Steps: 128 Train Loss: 0.1299 (Forecasting Loss:0.1268 + XiCon Loss:3.1072 x Lambda(0.001)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1798
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.08260656893253326, mae:0.223885178565979, mape:0.18461130559444427, mspe:0.0729871392250061 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2907
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2382320
	speed: 0.0132s/iter; left time: 167.8799s
Epoch: 1 cost time: 1.6494333744049072
Epoch: 1, Steps: 128 Train Loss: 0.2454 (Forecasting Loss:0.2423 + XiCon Loss:3.0999 x Lambda(0.001)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1241
Validation loss decreased (inf --> 0.182332).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2898459
	speed: 0.0140s/iter; left time: 176.2342s
Epoch: 2 cost time: 1.8035566806793213
Epoch: 2, Steps: 128 Train Loss: 0.2516 (Forecasting Loss:0.2485 + XiCon Loss:3.1457 x Lambda(0.001)), Vali MSE Loss: 0.1810 Test MSE Loss: 0.1298
Validation loss decreased (0.182332 --> 0.181006).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2351982
	speed: 0.0143s/iter; left time: 178.0875s
Epoch: 3 cost time: 1.8047139644622803
Epoch: 3, Steps: 128 Train Loss: 0.2276 (Forecasting Loss:0.2245 + XiCon Loss:3.1471 x Lambda(0.001)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1200
Validation loss decreased (0.181006 --> 0.172357).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2376554
	speed: 0.0134s/iter; left time: 165.3984s
Epoch: 4 cost time: 1.726527214050293
Epoch: 4, Steps: 128 Train Loss: 0.2114 (Forecasting Loss:0.2083 + XiCon Loss:3.1062 x Lambda(0.001)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1299
Validation loss decreased (0.172357 --> 0.171028).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2023271
	speed: 0.0135s/iter; left time: 164.4917s
Epoch: 5 cost time: 1.718827247619629
Epoch: 5, Steps: 128 Train Loss: 0.2010 (Forecasting Loss:0.1979 + XiCon Loss:3.0960 x Lambda(0.001)), Vali MSE Loss: 0.1713 Test MSE Loss: 0.1262
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2238837
	speed: 0.0133s/iter; left time: 159.9338s
Epoch: 6 cost time: 1.6656925678253174
Epoch: 6, Steps: 128 Train Loss: 0.1917 (Forecasting Loss:0.1886 + XiCon Loss:3.0892 x Lambda(0.001)), Vali MSE Loss: 0.1806 Test MSE Loss: 0.1278
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1885540
	speed: 0.0137s/iter; left time: 163.7505s
Epoch: 7 cost time: 1.7357959747314453
Epoch: 7, Steps: 128 Train Loss: 0.1864 (Forecasting Loss:0.1834 + XiCon Loss:3.0868 x Lambda(0.001)), Vali MSE Loss: 0.1789 Test MSE Loss: 0.1298
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1590272
	speed: 0.0128s/iter; left time: 151.0876s
Epoch: 8 cost time: 1.61722993850708
Epoch: 8, Steps: 128 Train Loss: 0.1834 (Forecasting Loss:0.1803 + XiCon Loss:3.0893 x Lambda(0.001)), Vali MSE Loss: 0.1811 Test MSE Loss: 0.1319
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1871697
	speed: 0.0144s/iter; left time: 167.6614s
Epoch: 9 cost time: 1.778461217880249
Epoch: 9, Steps: 128 Train Loss: 0.1823 (Forecasting Loss:0.1792 + XiCon Loss:3.0903 x Lambda(0.001)), Vali MSE Loss: 0.1807 Test MSE Loss: 0.1329
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1720479
	speed: 0.0148s/iter; left time: 171.2382s
Epoch: 10 cost time: 1.8737337589263916
Epoch: 10, Steps: 128 Train Loss: 0.1818 (Forecasting Loss:0.1787 + XiCon Loss:3.0910 x Lambda(0.001)), Vali MSE Loss: 0.1809 Test MSE Loss: 0.1330
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1782422
	speed: 0.0135s/iter; left time: 154.3785s
Epoch: 11 cost time: 1.7253870964050293
Epoch: 11, Steps: 128 Train Loss: 0.1812 (Forecasting Loss:0.1781 + XiCon Loss:3.0895 x Lambda(0.001)), Vali MSE Loss: 0.1814 Test MSE Loss: 0.1329
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1934638
	speed: 0.0136s/iter; left time: 153.7274s
Epoch: 12 cost time: 1.7098777294158936
Epoch: 12, Steps: 128 Train Loss: 0.1807 (Forecasting Loss:0.1777 + XiCon Loss:3.0894 x Lambda(0.001)), Vali MSE Loss: 0.1815 Test MSE Loss: 0.1331
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1793726
	speed: 0.0131s/iter; left time: 146.1233s
Epoch: 13 cost time: 1.681410312652588
Epoch: 13, Steps: 128 Train Loss: 0.1808 (Forecasting Loss:0.1777 + XiCon Loss:3.0898 x Lambda(0.001)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1331
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1582310
	speed: 0.0148s/iter; left time: 163.7402s
Epoch: 14 cost time: 1.8130109310150146
Epoch: 14, Steps: 128 Train Loss: 0.1804 (Forecasting Loss:0.1773 + XiCon Loss:3.0882 x Lambda(0.001)), Vali MSE Loss: 0.1812 Test MSE Loss: 0.1331
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0645081028342247, mae:0.19529369473457336, mape:0.15626788139343262, mspe:0.050205934792757034 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3375
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2245251
	speed: 0.0133s/iter; left time: 168.9800s
Epoch: 1 cost time: 1.658168077468872
Epoch: 1, Steps: 128 Train Loss: 0.2467 (Forecasting Loss:0.2436 + XiCon Loss:3.1185 x Lambda(0.001)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1199
Validation loss decreased (inf --> 0.171968).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2433796
	speed: 0.0140s/iter; left time: 175.8877s
Epoch: 2 cost time: 1.7346117496490479
Epoch: 2, Steps: 128 Train Loss: 0.2419 (Forecasting Loss:0.2387 + XiCon Loss:3.1411 x Lambda(0.001)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1354
Validation loss decreased (0.171968 --> 0.171229).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2327550
	speed: 0.0134s/iter; left time: 166.8010s
Epoch: 3 cost time: 1.6866977214813232
Epoch: 3, Steps: 128 Train Loss: 0.2122 (Forecasting Loss:0.2090 + XiCon Loss:3.1137 x Lambda(0.001)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1361
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1638151
	speed: 0.0143s/iter; left time: 176.6095s
Epoch: 4 cost time: 1.7707583904266357
Epoch: 4, Steps: 128 Train Loss: 0.1836 (Forecasting Loss:0.1805 + XiCon Loss:3.1126 x Lambda(0.001)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1548
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1718946
	speed: 0.0137s/iter; left time: 167.0431s
Epoch: 5 cost time: 1.7072243690490723
Epoch: 5, Steps: 128 Train Loss: 0.1652 (Forecasting Loss:0.1621 + XiCon Loss:3.1137 x Lambda(0.001)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1667
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1537532
	speed: 0.0140s/iter; left time: 168.4521s
Epoch: 6 cost time: 1.7293741703033447
Epoch: 6, Steps: 128 Train Loss: 0.1549 (Forecasting Loss:0.1518 + XiCon Loss:3.1112 x Lambda(0.001)), Vali MSE Loss: 0.1821 Test MSE Loss: 0.1728
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1543972
	speed: 0.0140s/iter; left time: 166.7523s
Epoch: 7 cost time: 1.7324490547180176
Epoch: 7, Steps: 128 Train Loss: 0.1496 (Forecasting Loss:0.1464 + XiCon Loss:3.1139 x Lambda(0.001)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.1788
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1649290
	speed: 0.0131s/iter; left time: 154.2829s
Epoch: 8 cost time: 1.6418430805206299
Epoch: 8, Steps: 128 Train Loss: 0.1467 (Forecasting Loss:0.1436 + XiCon Loss:3.1110 x Lambda(0.001)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1799
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1617526
	speed: 0.0136s/iter; left time: 158.8152s
Epoch: 9 cost time: 1.6970314979553223
Epoch: 9, Steps: 128 Train Loss: 0.1456 (Forecasting Loss:0.1425 + XiCon Loss:3.1118 x Lambda(0.001)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1805
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1433196
	speed: 0.0134s/iter; left time: 154.9558s
Epoch: 10 cost time: 1.7211756706237793
Epoch: 10, Steps: 128 Train Loss: 0.1450 (Forecasting Loss:0.1419 + XiCon Loss:3.1118 x Lambda(0.001)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1813
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1474786
	speed: 0.0130s/iter; left time: 148.5656s
Epoch: 11 cost time: 1.6896915435791016
Epoch: 11, Steps: 128 Train Loss: 0.1445 (Forecasting Loss:0.1414 + XiCon Loss:3.1118 x Lambda(0.001)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1815
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1418202
	speed: 0.0132s/iter; left time: 148.7846s
Epoch: 12 cost time: 1.6467046737670898
Epoch: 12, Steps: 128 Train Loss: 0.1444 (Forecasting Loss:0.1413 + XiCon Loss:3.1109 x Lambda(0.001)), Vali MSE Loss: 0.1855 Test MSE Loss: 0.1814
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0683261901140213, mae:0.2024168074131012, mape:0.1667580008506775, mspe:0.059091974049806595 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3265
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2206362
	speed: 0.0136s/iter; left time: 173.3578s
Epoch: 1 cost time: 1.7097713947296143
Epoch: 1, Steps: 128 Train Loss: 0.2477 (Forecasting Loss:0.2446 + XiCon Loss:3.1081 x Lambda(0.001)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1224
Validation loss decreased (inf --> 0.173317).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2470290
	speed: 0.0133s/iter; left time: 167.7914s
Epoch: 2 cost time: 1.6854803562164307
Epoch: 2, Steps: 128 Train Loss: 0.2496 (Forecasting Loss:0.2464 + XiCon Loss:3.1812 x Lambda(0.001)), Vali MSE Loss: 0.1786 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2331553
	speed: 0.0135s/iter; left time: 167.4518s
Epoch: 3 cost time: 1.7032856941223145
Epoch: 3, Steps: 128 Train Loss: 0.2288 (Forecasting Loss:0.2256 + XiCon Loss:3.1933 x Lambda(0.001)), Vali MSE Loss: 0.1796 Test MSE Loss: 0.1275
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2173492
	speed: 0.0135s/iter; left time: 166.7538s
Epoch: 4 cost time: 1.6841936111450195
Epoch: 4, Steps: 128 Train Loss: 0.2095 (Forecasting Loss:0.2063 + XiCon Loss:3.1901 x Lambda(0.001)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1256
Validation loss decreased (0.173317 --> 0.172490).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1769180
	speed: 0.0135s/iter; left time: 164.8111s
Epoch: 5 cost time: 1.6812903881072998
Epoch: 5, Steps: 128 Train Loss: 0.1916 (Forecasting Loss:0.1884 + XiCon Loss:3.1869 x Lambda(0.001)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1269
Validation loss decreased (0.172490 --> 0.170915).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1848936
	speed: 0.0143s/iter; left time: 172.1411s
Epoch: 6 cost time: 1.7875087261199951
Epoch: 6, Steps: 128 Train Loss: 0.1814 (Forecasting Loss:0.1783 + XiCon Loss:3.1835 x Lambda(0.001)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1323
Validation loss decreased (0.170915 --> 0.170228).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1671916
	speed: 0.0140s/iter; left time: 167.4968s
Epoch: 7 cost time: 1.7734012603759766
Epoch: 7, Steps: 128 Train Loss: 0.1751 (Forecasting Loss:0.1719 + XiCon Loss:3.1832 x Lambda(0.001)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1334
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1649888
	speed: 0.0139s/iter; left time: 163.5680s
Epoch: 8 cost time: 1.7261476516723633
Epoch: 8, Steps: 128 Train Loss: 0.1721 (Forecasting Loss:0.1690 + XiCon Loss:3.1823 x Lambda(0.001)), Vali MSE Loss: 0.1721 Test MSE Loss: 0.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1806240
	speed: 0.0133s/iter; left time: 155.7876s
Epoch: 9 cost time: 1.6676881313323975
Epoch: 9, Steps: 128 Train Loss: 0.1706 (Forecasting Loss:0.1674 + XiCon Loss:3.1805 x Lambda(0.001)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1359
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1705524
	speed: 0.0136s/iter; left time: 156.8127s
Epoch: 10 cost time: 1.6887385845184326
Epoch: 10, Steps: 128 Train Loss: 0.1693 (Forecasting Loss:0.1661 + XiCon Loss:3.1826 x Lambda(0.001)), Vali MSE Loss: 0.1713 Test MSE Loss: 0.1364
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1957101
	speed: 0.0144s/iter; left time: 164.8503s
Epoch: 11 cost time: 1.791602373123169
Epoch: 11, Steps: 128 Train Loss: 0.1690 (Forecasting Loss:0.1658 + XiCon Loss:3.1820 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1703238
	speed: 0.0130s/iter; left time: 146.6414s
Epoch: 12 cost time: 1.6300592422485352
Epoch: 12, Steps: 128 Train Loss: 0.1690 (Forecasting Loss:0.1659 + XiCon Loss:3.1808 x Lambda(0.001)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1773235
	speed: 0.0130s/iter; left time: 144.8913s
Epoch: 13 cost time: 1.6491246223449707
Epoch: 13, Steps: 128 Train Loss: 0.1694 (Forecasting Loss:0.1662 + XiCon Loss:3.1805 x Lambda(0.001)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1367
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1813047
	speed: 0.0133s/iter; left time: 147.0476s
Epoch: 14 cost time: 1.6587021350860596
Epoch: 14, Steps: 128 Train Loss: 0.1691 (Forecasting Loss:0.1659 + XiCon Loss:3.1834 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1367
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.1742647
	speed: 0.0139s/iter; left time: 151.4454s
Epoch: 15 cost time: 1.7580673694610596
Epoch: 15, Steps: 128 Train Loss: 0.1690 (Forecasting Loss:0.1658 + XiCon Loss:3.1824 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1367
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.1771903
	speed: 0.0139s/iter; left time: 149.5377s
Epoch: 16 cost time: 1.7081866264343262
Epoch: 16, Steps: 128 Train Loss: 0.1689 (Forecasting Loss:0.1658 + XiCon Loss:3.1808 x Lambda(0.001)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1367
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0653814747929573, mae:0.19928722083568573, mape:0.16795453429222107, mspe:0.06172190606594086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3706
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2293856
	speed: 0.0129s/iter; left time: 163.3428s
Epoch: 1 cost time: 1.6169376373291016
Epoch: 1, Steps: 128 Train Loss: 0.2460 (Forecasting Loss:0.2428 + XiCon Loss:3.1079 x Lambda(0.001)), Vali MSE Loss: 0.1804 Test MSE Loss: 0.1253
Validation loss decreased (inf --> 0.180418).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2105763
	speed: 0.0130s/iter; left time: 163.2798s
Epoch: 2 cost time: 1.6266157627105713
Epoch: 2, Steps: 128 Train Loss: 0.2351 (Forecasting Loss:0.2320 + XiCon Loss:3.1341 x Lambda(0.001)), Vali MSE Loss: 0.1829 Test MSE Loss: 0.1405
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1756011
	speed: 0.0128s/iter; left time: 159.2541s
Epoch: 3 cost time: 1.6168856620788574
Epoch: 3, Steps: 128 Train Loss: 0.1897 (Forecasting Loss:0.1866 + XiCon Loss:3.0841 x Lambda(0.001)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1667
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1577553
	speed: 0.0137s/iter; left time: 168.4623s
Epoch: 4 cost time: 1.6994996070861816
Epoch: 4, Steps: 128 Train Loss: 0.1577 (Forecasting Loss:0.1546 + XiCon Loss:3.0774 x Lambda(0.001)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.1573
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1474368
	speed: 0.0145s/iter; left time: 176.6729s
Epoch: 5 cost time: 1.8007707595825195
Epoch: 5, Steps: 128 Train Loss: 0.1443 (Forecasting Loss:0.1412 + XiCon Loss:3.0783 x Lambda(0.001)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.1577
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1496916
	speed: 0.0134s/iter; left time: 161.5941s
Epoch: 6 cost time: 1.6711750030517578
Epoch: 6, Steps: 128 Train Loss: 0.1379 (Forecasting Loss:0.1349 + XiCon Loss:3.0747 x Lambda(0.001)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1648
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1326539
	speed: 0.0139s/iter; left time: 165.4274s
Epoch: 7 cost time: 1.727342128753662
Epoch: 7, Steps: 128 Train Loss: 0.1350 (Forecasting Loss:0.1320 + XiCon Loss:3.0707 x Lambda(0.001)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1653
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1309631
	speed: 0.0128s/iter; left time: 150.8436s
Epoch: 8 cost time: 1.6055004596710205
Epoch: 8, Steps: 128 Train Loss: 0.1334 (Forecasting Loss:0.1304 + XiCon Loss:3.0691 x Lambda(0.001)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1657
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1371837
	speed: 0.0138s/iter; left time: 161.6167s
Epoch: 9 cost time: 1.717820405960083
Epoch: 9, Steps: 128 Train Loss: 0.1326 (Forecasting Loss:0.1295 + XiCon Loss:3.0693 x Lambda(0.001)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1677
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1287790
	speed: 0.0138s/iter; left time: 159.0061s
Epoch: 10 cost time: 1.7260191440582275
Epoch: 10, Steps: 128 Train Loss: 0.1324 (Forecasting Loss:0.1293 + XiCon Loss:3.0662 x Lambda(0.001)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1673
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1272310
	speed: 0.0139s/iter; left time: 158.5493s
Epoch: 11 cost time: 1.7259042263031006
Epoch: 11, Steps: 128 Train Loss: 0.1326 (Forecasting Loss:0.1295 + XiCon Loss:3.0684 x Lambda(0.001)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1671
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.060339853167533875, mae:0.19027230143547058, mape:0.15192317962646484, mspe:0.04341975972056389 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0682+-0.01059, MAE:0.2022+-0.01605, MAPE:0.1655+-0.01574, MSPE:0.0575+-0.01404, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3646
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2336644
	speed: 0.0172s/iter; left time: 215.5250s
Epoch: 1 cost time: 2.0692458152770996
Epoch: 1, Steps: 126 Train Loss: 0.2795 (Forecasting Loss:0.2764 + XiCon Loss:3.0861 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1435
Validation loss decreased (inf --> 0.196827).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2529458
	speed: 0.0145s/iter; left time: 179.1715s
Epoch: 2 cost time: 1.8457410335540771
Epoch: 2, Steps: 126 Train Loss: 0.2542 (Forecasting Loss:0.2511 + XiCon Loss:3.0761 x Lambda(0.001)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.1494
Validation loss decreased (0.196827 --> 0.194443).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1994901
	speed: 0.0170s/iter; left time: 207.6431s
Epoch: 3 cost time: 2.100409507751465
Epoch: 3, Steps: 126 Train Loss: 0.2095 (Forecasting Loss:0.2065 + XiCon Loss:3.0668 x Lambda(0.001)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1718
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1826867
	speed: 0.0160s/iter; left time: 194.5102s
Epoch: 4 cost time: 1.989485263824463
Epoch: 4, Steps: 126 Train Loss: 0.1913 (Forecasting Loss:0.1882 + XiCon Loss:3.0550 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1714
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1688513
	speed: 0.0164s/iter; left time: 196.6408s
Epoch: 5 cost time: 2.0246546268463135
Epoch: 5, Steps: 126 Train Loss: 0.1854 (Forecasting Loss:0.1823 + XiCon Loss:3.0531 x Lambda(0.001)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1751
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1620256
	speed: 0.0162s/iter; left time: 192.6255s
Epoch: 6 cost time: 2.0220277309417725
Epoch: 6, Steps: 126 Train Loss: 0.1828 (Forecasting Loss:0.1797 + XiCon Loss:3.0490 x Lambda(0.001)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1743
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1758648
	speed: 0.0169s/iter; left time: 198.3313s
Epoch: 7 cost time: 2.0723977088928223
Epoch: 7, Steps: 126 Train Loss: 0.1818 (Forecasting Loss:0.1787 + XiCon Loss:3.0480 x Lambda(0.001)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1752
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1960639
	speed: 0.0168s/iter; left time: 194.7782s
Epoch: 8 cost time: 2.094597339630127
Epoch: 8, Steps: 126 Train Loss: 0.1810 (Forecasting Loss:0.1780 + XiCon Loss:3.0478 x Lambda(0.001)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1758
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1753111
	speed: 0.0166s/iter; left time: 190.6933s
Epoch: 9 cost time: 2.0313100814819336
Epoch: 9, Steps: 126 Train Loss: 0.1806 (Forecasting Loss:0.1775 + XiCon Loss:3.0488 x Lambda(0.001)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1760
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1875471
	speed: 0.0161s/iter; left time: 183.1168s
Epoch: 10 cost time: 2.0163681507110596
Epoch: 10, Steps: 126 Train Loss: 0.1804 (Forecasting Loss:0.1774 + XiCon Loss:3.0492 x Lambda(0.001)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1764
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1783156
	speed: 0.0161s/iter; left time: 181.2418s
Epoch: 11 cost time: 2.008845329284668
Epoch: 11, Steps: 126 Train Loss: 0.1801 (Forecasting Loss:0.1771 + XiCon Loss:3.0466 x Lambda(0.001)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1762
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1782805
	speed: 0.0546s/iter; left time: 607.3720s
Epoch: 12 cost time: 6.751904726028442
Epoch: 12, Steps: 126 Train Loss: 0.1803 (Forecasting Loss:0.1773 + XiCon Loss:3.0472 x Lambda(0.001)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1764
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.08021188527345657, mae:0.21851204335689545, mape:0.17564743757247925, mspe:0.06491713970899582 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.2901
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2523004
	speed: 0.0509s/iter; left time: 635.9484s
Epoch: 1 cost time: 6.453577041625977
Epoch: 1, Steps: 126 Train Loss: 0.2805 (Forecasting Loss:0.2774 + XiCon Loss:3.0708 x Lambda(0.001)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1439
Validation loss decreased (inf --> 0.196044).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2363087
	speed: 0.0636s/iter; left time: 787.3441s
Epoch: 2 cost time: 7.83965539932251
Epoch: 2, Steps: 126 Train Loss: 0.2504 (Forecasting Loss:0.2473 + XiCon Loss:3.0588 x Lambda(0.001)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1494
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1912574
	speed: 0.0589s/iter; left time: 721.6568s
Epoch: 3 cost time: 7.564967393875122
Epoch: 3, Steps: 126 Train Loss: 0.2108 (Forecasting Loss:0.2078 + XiCon Loss:3.0228 x Lambda(0.001)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1518
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2009705
	speed: 0.0576s/iter; left time: 698.0089s
Epoch: 4 cost time: 7.153903484344482
Epoch: 4, Steps: 126 Train Loss: 0.1957 (Forecasting Loss:0.1927 + XiCon Loss:3.0172 x Lambda(0.001)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1634
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1890551
	speed: 0.0510s/iter; left time: 611.9008s
Epoch: 5 cost time: 6.4463372230529785
Epoch: 5, Steps: 126 Train Loss: 0.1887 (Forecasting Loss:0.1857 + XiCon Loss:3.0165 x Lambda(0.001)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.1681
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1950112
	speed: 0.0466s/iter; left time: 552.6687s
Epoch: 6 cost time: 5.8792338371276855
Epoch: 6, Steps: 126 Train Loss: 0.1861 (Forecasting Loss:0.1831 + XiCon Loss:3.0114 x Lambda(0.001)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1678
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1790692
	speed: 0.0437s/iter; left time: 513.6685s
Epoch: 7 cost time: 5.4583728313446045
Epoch: 7, Steps: 126 Train Loss: 0.1846 (Forecasting Loss:0.1816 + XiCon Loss:3.0106 x Lambda(0.001)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1930825
	speed: 0.0212s/iter; left time: 246.1363s
Epoch: 8 cost time: 2.562596559524536
Epoch: 8, Steps: 126 Train Loss: 0.1840 (Forecasting Loss:0.1810 + XiCon Loss:3.0129 x Lambda(0.001)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.1706
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1716471
	speed: 0.0225s/iter; left time: 258.3945s
Epoch: 9 cost time: 2.6922786235809326
Epoch: 9, Steps: 126 Train Loss: 0.1837 (Forecasting Loss:0.1806 + XiCon Loss:3.0118 x Lambda(0.001)), Vali MSE Loss: 0.2228 Test MSE Loss: 0.1716
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1763544
	speed: 0.0189s/iter; left time: 215.0081s
Epoch: 10 cost time: 2.3377695083618164
Epoch: 10, Steps: 126 Train Loss: 0.1835 (Forecasting Loss:0.1805 + XiCon Loss:3.0110 x Lambda(0.001)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1717
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1690705
	speed: 0.0188s/iter; left time: 211.3396s
Epoch: 11 cost time: 2.3212807178497314
Epoch: 11, Steps: 126 Train Loss: 0.1835 (Forecasting Loss:0.1805 + XiCon Loss:3.0111 x Lambda(0.001)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.0749407708644867, mae:0.21289698779582977, mape:0.16306036710739136, mspe:0.04568025469779968 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5004
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2551533
	speed: 0.0163s/iter; left time: 204.1493s
Epoch: 1 cost time: 2.0388259887695312
Epoch: 1, Steps: 126 Train Loss: 0.2792 (Forecasting Loss:0.2761 + XiCon Loss:3.0612 x Lambda(0.001)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1435
Validation loss decreased (inf --> 0.196511).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2474277
	speed: 0.0157s/iter; left time: 193.8404s
Epoch: 2 cost time: 2.0082919597625732
Epoch: 2, Steps: 126 Train Loss: 0.2580 (Forecasting Loss:0.2549 + XiCon Loss:3.0520 x Lambda(0.001)), Vali MSE Loss: 0.1910 Test MSE Loss: 0.1470
Validation loss decreased (0.196511 --> 0.191018).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2251933
	speed: 0.0175s/iter; left time: 214.1389s
Epoch: 3 cost time: 2.160590410232544
Epoch: 3, Steps: 126 Train Loss: 0.2180 (Forecasting Loss:0.2150 + XiCon Loss:3.0138 x Lambda(0.001)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1514
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1827916
	speed: 0.0176s/iter; left time: 213.5063s
Epoch: 4 cost time: 2.187013626098633
Epoch: 4, Steps: 126 Train Loss: 0.2004 (Forecasting Loss:0.1974 + XiCon Loss:3.0188 x Lambda(0.001)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1582
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1887244
	speed: 0.0172s/iter; left time: 206.2639s
Epoch: 5 cost time: 2.1406948566436768
Epoch: 5, Steps: 126 Train Loss: 0.1929 (Forecasting Loss:0.1899 + XiCon Loss:3.0186 x Lambda(0.001)), Vali MSE Loss: 0.2331 Test MSE Loss: 0.1640
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1847646
	speed: 0.0173s/iter; left time: 205.6161s
Epoch: 6 cost time: 2.149425506591797
Epoch: 6, Steps: 126 Train Loss: 0.1897 (Forecasting Loss:0.1866 + XiCon Loss:3.0185 x Lambda(0.001)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.1641
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1787389
	speed: 0.0167s/iter; left time: 196.4733s
Epoch: 7 cost time: 2.087724208831787
Epoch: 7, Steps: 126 Train Loss: 0.1874 (Forecasting Loss:0.1844 + XiCon Loss:3.0186 x Lambda(0.001)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1666
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2065065
	speed: 0.0167s/iter; left time: 194.4615s
Epoch: 8 cost time: 2.0877466201782227
Epoch: 8, Steps: 126 Train Loss: 0.1867 (Forecasting Loss:0.1837 + XiCon Loss:3.0207 x Lambda(0.001)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1685
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1960961
	speed: 0.0162s/iter; left time: 185.7715s
Epoch: 9 cost time: 2.0162391662597656
Epoch: 9, Steps: 126 Train Loss: 0.1860 (Forecasting Loss:0.1829 + XiCon Loss:3.0209 x Lambda(0.001)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1688
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1852551
	speed: 0.0158s/iter; left time: 180.0345s
Epoch: 10 cost time: 1.9697725772857666
Epoch: 10, Steps: 126 Train Loss: 0.1860 (Forecasting Loss:0.1830 + XiCon Loss:3.0210 x Lambda(0.001)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1684
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1659260
	speed: 0.0160s/iter; left time: 180.3768s
Epoch: 11 cost time: 1.9952678680419922
Epoch: 11, Steps: 126 Train Loss: 0.1856 (Forecasting Loss:0.1826 + XiCon Loss:3.0198 x Lambda(0.001)), Vali MSE Loss: 0.2361 Test MSE Loss: 0.1684
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1759545
	speed: 0.0159s/iter; left time: 176.7520s
Epoch: 12 cost time: 1.9803998470306396
Epoch: 12, Steps: 126 Train Loss: 0.1857 (Forecasting Loss:0.1827 + XiCon Loss:3.0204 x Lambda(0.001)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1685
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07824905961751938, mae:0.21575592458248138, mape:0.16964301466941833, mspe:0.05516599118709564 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2727518
	speed: 0.0141s/iter; left time: 175.7224s
Epoch: 1 cost time: 1.7429108619689941
Epoch: 1, Steps: 126 Train Loss: 0.2773 (Forecasting Loss:0.2742 + XiCon Loss:3.0703 x Lambda(0.001)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1437
Validation loss decreased (inf --> 0.195874).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2205735
	speed: 0.0135s/iter; left time: 167.2266s
Epoch: 2 cost time: 1.6869733333587646
Epoch: 2, Steps: 126 Train Loss: 0.2610 (Forecasting Loss:0.2580 + XiCon Loss:3.0646 x Lambda(0.001)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1357
Validation loss decreased (0.195874 --> 0.183970).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2332364
	speed: 0.0154s/iter; left time: 188.3303s
Epoch: 3 cost time: 1.9116103649139404
Epoch: 3, Steps: 126 Train Loss: 0.2290 (Forecasting Loss:0.2259 + XiCon Loss:3.0421 x Lambda(0.001)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1475
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1993645
	speed: 0.0156s/iter; left time: 188.5256s
Epoch: 4 cost time: 1.9311625957489014
Epoch: 4, Steps: 126 Train Loss: 0.2070 (Forecasting Loss:0.2040 + XiCon Loss:3.0404 x Lambda(0.001)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1554
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1871261
	speed: 0.0173s/iter; left time: 207.9207s
Epoch: 5 cost time: 2.1383562088012695
Epoch: 5, Steps: 126 Train Loss: 0.1970 (Forecasting Loss:0.1939 + XiCon Loss:3.0427 x Lambda(0.001)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1617
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1858872
	speed: 0.0171s/iter; left time: 202.5444s
Epoch: 6 cost time: 2.126169443130493
Epoch: 6, Steps: 126 Train Loss: 0.1926 (Forecasting Loss:0.1896 + XiCon Loss:3.0401 x Lambda(0.001)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1598
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1912288
	speed: 0.0178s/iter; left time: 208.5320s
Epoch: 7 cost time: 2.1935911178588867
Epoch: 7, Steps: 126 Train Loss: 0.1906 (Forecasting Loss:0.1876 + XiCon Loss:3.0370 x Lambda(0.001)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1619
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1883166
	speed: 0.0180s/iter; left time: 208.8471s
Epoch: 8 cost time: 2.208845615386963
Epoch: 8, Steps: 126 Train Loss: 0.1894 (Forecasting Loss:0.1863 + XiCon Loss:3.0383 x Lambda(0.001)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1630
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1725403
	speed: 0.0176s/iter; left time: 202.6554s
Epoch: 9 cost time: 2.176669120788574
Epoch: 9, Steps: 126 Train Loss: 0.1890 (Forecasting Loss:0.1860 + XiCon Loss:3.0364 x Lambda(0.001)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1637
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1865780
	speed: 0.0174s/iter; left time: 197.8956s
Epoch: 10 cost time: 2.177184820175171
Epoch: 10, Steps: 126 Train Loss: 0.1886 (Forecasting Loss:0.1856 + XiCon Loss:3.0358 x Lambda(0.001)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1636
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1764735
	speed: 0.0169s/iter; left time: 190.4981s
Epoch: 11 cost time: 2.1150872707366943
Epoch: 11, Steps: 126 Train Loss: 0.1885 (Forecasting Loss:0.1854 + XiCon Loss:3.0392 x Lambda(0.001)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1635
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1907819
	speed: 0.0179s/iter; left time: 199.4027s
Epoch: 12 cost time: 2.194779634475708
Epoch: 12, Steps: 126 Train Loss: 0.1882 (Forecasting Loss:0.1852 + XiCon Loss:3.0343 x Lambda(0.001)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1635
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06947176158428192, mae:0.20197640359401703, mape:0.1555784046649933, mspe:0.045150358229875565 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3203
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2756340
	speed: 0.0157s/iter; left time: 196.5358s
Epoch: 1 cost time: 1.959202527999878
Epoch: 1, Steps: 126 Train Loss: 0.2804 (Forecasting Loss:0.2773 + XiCon Loss:3.0641 x Lambda(0.001)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1438
Validation loss decreased (inf --> 0.195878).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2588241
	speed: 0.0160s/iter; left time: 198.0700s
Epoch: 2 cost time: 1.9471919536590576
Epoch: 2, Steps: 126 Train Loss: 0.2554 (Forecasting Loss:0.2524 + XiCon Loss:3.0505 x Lambda(0.001)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1468
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2380275
	speed: 0.0160s/iter; left time: 196.0000s
Epoch: 3 cost time: 2.000453233718872
Epoch: 3, Steps: 126 Train Loss: 0.2217 (Forecasting Loss:0.2187 + XiCon Loss:3.0252 x Lambda(0.001)), Vali MSE Loss: 0.1907 Test MSE Loss: 0.1382
Validation loss decreased (0.195878 --> 0.190699).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1870540
	speed: 0.0158s/iter; left time: 191.6697s
Epoch: 4 cost time: 1.9697761535644531
Epoch: 4, Steps: 126 Train Loss: 0.1993 (Forecasting Loss:0.1963 + XiCon Loss:3.0234 x Lambda(0.001)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1436
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1938938
	speed: 0.0160s/iter; left time: 191.7101s
Epoch: 5 cost time: 1.9711005687713623
Epoch: 5, Steps: 126 Train Loss: 0.1905 (Forecasting Loss:0.1875 + XiCon Loss:3.0270 x Lambda(0.001)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1462
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1868915
	speed: 0.0161s/iter; left time: 191.3122s
Epoch: 6 cost time: 2.013023853302002
Epoch: 6, Steps: 126 Train Loss: 0.1866 (Forecasting Loss:0.1836 + XiCon Loss:3.0287 x Lambda(0.001)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1464
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1857306
	speed: 0.0153s/iter; left time: 179.3399s
Epoch: 7 cost time: 1.9373576641082764
Epoch: 7, Steps: 126 Train Loss: 0.1851 (Forecasting Loss:0.1821 + XiCon Loss:3.0287 x Lambda(0.001)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1453
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1553661
	speed: 0.0155s/iter; left time: 180.3972s
Epoch: 8 cost time: 1.9406161308288574
Epoch: 8, Steps: 126 Train Loss: 0.1843 (Forecasting Loss:0.1812 + XiCon Loss:3.0279 x Lambda(0.001)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1451
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1771041
	speed: 0.0170s/iter; left time: 195.7035s
Epoch: 9 cost time: 2.0788331031799316
Epoch: 9, Steps: 126 Train Loss: 0.1839 (Forecasting Loss:0.1809 + XiCon Loss:3.0252 x Lambda(0.001)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1458
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1928257
	speed: 0.0157s/iter; left time: 178.8895s
Epoch: 10 cost time: 1.9355332851409912
Epoch: 10, Steps: 126 Train Loss: 0.1834 (Forecasting Loss:0.1804 + XiCon Loss:3.0276 x Lambda(0.001)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1459
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1950661
	speed: 0.0163s/iter; left time: 183.1274s
Epoch: 11 cost time: 2.06081485748291
Epoch: 11, Steps: 126 Train Loss: 0.1835 (Forecasting Loss:0.1805 + XiCon Loss:3.0262 x Lambda(0.001)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1457
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1745881
	speed: 0.0163s/iter; left time: 181.0876s
Epoch: 12 cost time: 2.042978048324585
Epoch: 12, Steps: 126 Train Loss: 0.1835 (Forecasting Loss:0.1804 + XiCon Loss:3.0273 x Lambda(0.001)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1456
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2002358
	speed: 0.0157s/iter; left time: 172.9275s
Epoch: 13 cost time: 1.943120002746582
Epoch: 13, Steps: 126 Train Loss: 0.1835 (Forecasting Loss:0.1805 + XiCon Loss:3.0251 x Lambda(0.001)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1455
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.0708366110920906, mae:0.2055162489414215, mape:0.16640356183052063, mspe:0.06098414957523346 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0747+-0.00573, MAE:0.2109+-0.00865, MAPE:0.1661+-0.00929, MSPE:0.0544+-0.01104, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3407
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2804646
	speed: 0.0227s/iter; left time: 279.5195s
Epoch: 1 cost time: 2.706569194793701
Epoch: 1, Steps: 124 Train Loss: 0.2948 (Forecasting Loss:0.2918 + XiCon Loss:3.0684 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1573
Validation loss decreased (inf --> 0.216235).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2790504
	speed: 0.0197s/iter; left time: 239.4426s
Epoch: 2 cost time: 2.4086544513702393
Epoch: 2, Steps: 124 Train Loss: 0.2761 (Forecasting Loss:0.2731 + XiCon Loss:3.0682 x Lambda(0.001)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1683
Validation loss decreased (0.216235 --> 0.197824).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2360228
	speed: 0.0195s/iter; left time: 234.8211s
Epoch: 3 cost time: 2.3859333992004395
Epoch: 3, Steps: 124 Train Loss: 0.2498 (Forecasting Loss:0.2467 + XiCon Loss:3.0667 x Lambda(0.001)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2389616
	speed: 0.0197s/iter; left time: 235.2392s
Epoch: 4 cost time: 2.38991379737854
Epoch: 4, Steps: 124 Train Loss: 0.2349 (Forecasting Loss:0.2318 + XiCon Loss:3.0613 x Lambda(0.001)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1527
Validation loss decreased (0.197824 --> 0.196722).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2160228
	speed: 0.0199s/iter; left time: 235.2060s
Epoch: 5 cost time: 2.404283285140991
Epoch: 5, Steps: 124 Train Loss: 0.2236 (Forecasting Loss:0.2205 + XiCon Loss:3.0591 x Lambda(0.001)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1488
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2178860
	speed: 0.0197s/iter; left time: 230.6904s
Epoch: 6 cost time: 2.395927906036377
Epoch: 6, Steps: 124 Train Loss: 0.2181 (Forecasting Loss:0.2150 + XiCon Loss:3.0586 x Lambda(0.001)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1466
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2001993
	speed: 0.0193s/iter; left time: 222.8841s
Epoch: 7 cost time: 2.3832075595855713
Epoch: 7, Steps: 124 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.0590 x Lambda(0.001)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1474
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2173557
	speed: 0.0197s/iter; left time: 225.6478s
Epoch: 8 cost time: 2.3986594676971436
Epoch: 8, Steps: 124 Train Loss: 0.2142 (Forecasting Loss:0.2112 + XiCon Loss:3.0579 x Lambda(0.001)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1470
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2101582
	speed: 0.0199s/iter; left time: 225.2633s
Epoch: 9 cost time: 2.437669515609741
Epoch: 9, Steps: 124 Train Loss: 0.2140 (Forecasting Loss:0.2109 + XiCon Loss:3.0595 x Lambda(0.001)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1471
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2054340
	speed: 0.0192s/iter; left time: 214.7284s
Epoch: 10 cost time: 2.382338047027588
Epoch: 10, Steps: 124 Train Loss: 0.2139 (Forecasting Loss:0.2108 + XiCon Loss:3.0580 x Lambda(0.001)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1461
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2027904
	speed: 0.0194s/iter; left time: 214.2041s
Epoch: 11 cost time: 2.369088888168335
Epoch: 11, Steps: 124 Train Loss: 0.2137 (Forecasting Loss:0.2107 + XiCon Loss:3.0585 x Lambda(0.001)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1463
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2106420
	speed: 0.0195s/iter; left time: 213.8060s
Epoch: 12 cost time: 2.3815994262695312
Epoch: 12, Steps: 124 Train Loss: 0.2136 (Forecasting Loss:0.2105 + XiCon Loss:3.0579 x Lambda(0.001)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1464
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2075984
	speed: 0.0196s/iter; left time: 211.9587s
Epoch: 13 cost time: 2.4521329402923584
Epoch: 13, Steps: 124 Train Loss: 0.2133 (Forecasting Loss:0.2102 + XiCon Loss:3.0589 x Lambda(0.001)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1464
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2025183
	speed: 0.0191s/iter; left time: 203.8155s
Epoch: 14 cost time: 2.349475383758545
Epoch: 14, Steps: 124 Train Loss: 0.2133 (Forecasting Loss:0.2103 + XiCon Loss:3.0569 x Lambda(0.001)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1464
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08032037317752838, mae:0.22500908374786377, mape:0.17697805166244507, mspe:0.05838967114686966 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3589
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2778620
	speed: 0.0193s/iter; left time: 236.9806s
Epoch: 1 cost time: 2.3581626415252686
Epoch: 1, Steps: 124 Train Loss: 0.2988 (Forecasting Loss:0.2957 + XiCon Loss:3.0616 x Lambda(0.001)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1611
Validation loss decreased (inf --> 0.215866).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2588850
	speed: 0.0245s/iter; left time: 298.1005s
Epoch: 2 cost time: 3.0652809143066406
Epoch: 2, Steps: 124 Train Loss: 0.2626 (Forecasting Loss:0.2595 + XiCon Loss:3.0767 x Lambda(0.001)), Vali MSE Loss: 0.2675 Test MSE Loss: 0.1518
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2044207
	speed: 0.0266s/iter; left time: 320.0328s
Epoch: 3 cost time: 3.244776487350464
Epoch: 3, Steps: 124 Train Loss: 0.2235 (Forecasting Loss:0.2204 + XiCon Loss:3.0783 x Lambda(0.001)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.1629
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2129268
	speed: 0.0269s/iter; left time: 320.8684s
Epoch: 4 cost time: 3.273948907852173
Epoch: 4, Steps: 124 Train Loss: 0.2109 (Forecasting Loss:0.2078 + XiCon Loss:3.0747 x Lambda(0.001)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.1595
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1846671
	speed: 0.0266s/iter; left time: 314.5986s
Epoch: 5 cost time: 3.2419354915618896
Epoch: 5, Steps: 124 Train Loss: 0.2068 (Forecasting Loss:0.2037 + XiCon Loss:3.0749 x Lambda(0.001)), Vali MSE Loss: 0.3040 Test MSE Loss: 0.1598
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2012497
	speed: 0.0259s/iter; left time: 302.0555s
Epoch: 6 cost time: 3.1982531547546387
Epoch: 6, Steps: 124 Train Loss: 0.2043 (Forecasting Loss:0.2012 + XiCon Loss:3.0724 x Lambda(0.001)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.1585
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2018214
	speed: 0.0259s/iter; left time: 299.8699s
Epoch: 7 cost time: 3.164618492126465
Epoch: 7, Steps: 124 Train Loss: 0.2032 (Forecasting Loss:0.2001 + XiCon Loss:3.0743 x Lambda(0.001)), Vali MSE Loss: 0.3056 Test MSE Loss: 0.1597
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2117793
	speed: 0.0264s/iter; left time: 301.4437s
Epoch: 8 cost time: 3.239149332046509
Epoch: 8, Steps: 124 Train Loss: 0.2027 (Forecasting Loss:0.1996 + XiCon Loss:3.0743 x Lambda(0.001)), Vali MSE Loss: 0.3044 Test MSE Loss: 0.1598
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2070940
	speed: 0.0270s/iter; left time: 305.4633s
Epoch: 9 cost time: 3.3215107917785645
Epoch: 9, Steps: 124 Train Loss: 0.2024 (Forecasting Loss:0.1994 + XiCon Loss:3.0747 x Lambda(0.001)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.1600
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2186186
	speed: 0.0256s/iter; left time: 286.3962s
Epoch: 10 cost time: 3.1535441875457764
Epoch: 10, Steps: 124 Train Loss: 0.2024 (Forecasting Loss:0.1993 + XiCon Loss:3.0761 x Lambda(0.001)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.1597
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1966593
	speed: 0.0264s/iter; left time: 291.6065s
Epoch: 11 cost time: 3.2283308506011963
Epoch: 11, Steps: 124 Train Loss: 0.2023 (Forecasting Loss:0.1992 + XiCon Loss:3.0759 x Lambda(0.001)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.1598
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08673180639743805, mae:0.23546892404556274, mape:0.17665939033031464, mspe:0.05045633763074875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2964
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2687654
	speed: 0.0197s/iter; left time: 242.8732s
Epoch: 1 cost time: 2.3987314701080322
Epoch: 1, Steps: 124 Train Loss: 0.2974 (Forecasting Loss:0.2943 + XiCon Loss:3.0802 x Lambda(0.001)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1597
Validation loss decreased (inf --> 0.214854).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2399803
	speed: 0.0216s/iter; left time: 263.3549s
Epoch: 2 cost time: 2.8008251190185547
Epoch: 2, Steps: 124 Train Loss: 0.2720 (Forecasting Loss:0.2689 + XiCon Loss:3.0622 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1478
Validation loss decreased (0.214854 --> 0.209614).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2374444
	speed: 0.0285s/iter; left time: 343.3704s
Epoch: 3 cost time: 3.529782772064209
Epoch: 3, Steps: 124 Train Loss: 0.2417 (Forecasting Loss:0.2386 + XiCon Loss:3.0522 x Lambda(0.001)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1583
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2277775
	speed: 0.0283s/iter; left time: 338.0063s
Epoch: 4 cost time: 3.5072717666625977
Epoch: 4, Steps: 124 Train Loss: 0.2274 (Forecasting Loss:0.2243 + XiCon Loss:3.0555 x Lambda(0.001)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1578
Validation loss decreased (0.209614 --> 0.206166).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2070110
	speed: 0.0295s/iter; left time: 347.8714s
Epoch: 5 cost time: 3.6081511974334717
Epoch: 5, Steps: 124 Train Loss: 0.2192 (Forecasting Loss:0.2161 + XiCon Loss:3.0505 x Lambda(0.001)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2138697
	speed: 0.0290s/iter; left time: 338.6069s
Epoch: 6 cost time: 3.593304395675659
Epoch: 6, Steps: 124 Train Loss: 0.2159 (Forecasting Loss:0.2129 + XiCon Loss:3.0479 x Lambda(0.001)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1624
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2106502
	speed: 0.0298s/iter; left time: 344.4131s
Epoch: 7 cost time: 3.6483519077301025
Epoch: 7, Steps: 124 Train Loss: 0.2143 (Forecasting Loss:0.2112 + XiCon Loss:3.0501 x Lambda(0.001)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1605
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1936794
	speed: 0.0297s/iter; left time: 339.9184s
Epoch: 8 cost time: 3.624110221862793
Epoch: 8, Steps: 124 Train Loss: 0.2136 (Forecasting Loss:0.2105 + XiCon Loss:3.0492 x Lambda(0.001)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1613
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2192400
	speed: 0.0296s/iter; left time: 334.2499s
Epoch: 9 cost time: 3.6529247760772705
Epoch: 9, Steps: 124 Train Loss: 0.2132 (Forecasting Loss:0.2102 + XiCon Loss:3.0482 x Lambda(0.001)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1624
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2259309
	speed: 0.0297s/iter; left time: 332.0825s
Epoch: 10 cost time: 3.652893543243408
Epoch: 10, Steps: 124 Train Loss: 0.2131 (Forecasting Loss:0.2100 + XiCon Loss:3.0501 x Lambda(0.001)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1620
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2086049
	speed: 0.0292s/iter; left time: 322.6024s
Epoch: 11 cost time: 3.5880634784698486
Epoch: 11, Steps: 124 Train Loss: 0.2128 (Forecasting Loss:0.2097 + XiCon Loss:3.0468 x Lambda(0.001)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1620
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1965356
	speed: 0.0290s/iter; left time: 317.0535s
Epoch: 12 cost time: 3.5679678916931152
Epoch: 12, Steps: 124 Train Loss: 0.2128 (Forecasting Loss:0.2098 + XiCon Loss:3.0498 x Lambda(0.001)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1621
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2068486
	speed: 0.0291s/iter; left time: 315.0919s
Epoch: 13 cost time: 3.6059892177581787
Epoch: 13, Steps: 124 Train Loss: 0.2127 (Forecasting Loss:0.2096 + XiCon Loss:3.0509 x Lambda(0.001)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1620
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2225328
	speed: 0.0295s/iter; left time: 314.9974s
Epoch: 14 cost time: 3.6372087001800537
Epoch: 14, Steps: 124 Train Loss: 0.2127 (Forecasting Loss:0.2097 + XiCon Loss:3.0488 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1621
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08340837061405182, mae:0.23225916922092438, mape:0.18385577201843262, mspe:0.06530474126338959 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3287
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2870662
	speed: 0.0195s/iter; left time: 240.4264s
Epoch: 1 cost time: 2.3991055488586426
Epoch: 1, Steps: 124 Train Loss: 0.2975 (Forecasting Loss:0.2944 + XiCon Loss:3.0652 x Lambda(0.001)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1634
Validation loss decreased (inf --> 0.215814).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2465119
	speed: 0.0210s/iter; left time: 255.8196s
Epoch: 2 cost time: 2.6287810802459717
Epoch: 2, Steps: 124 Train Loss: 0.2630 (Forecasting Loss:0.2599 + XiCon Loss:3.0739 x Lambda(0.001)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.1491
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2322780
	speed: 0.0232s/iter; left time: 279.2903s
Epoch: 3 cost time: 2.841435670852661
Epoch: 3, Steps: 124 Train Loss: 0.2255 (Forecasting Loss:0.2225 + XiCon Loss:3.0586 x Lambda(0.001)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1477
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2181612
	speed: 0.0224s/iter; left time: 266.7781s
Epoch: 4 cost time: 2.7665774822235107
Epoch: 4, Steps: 124 Train Loss: 0.2140 (Forecasting Loss:0.2109 + XiCon Loss:3.0595 x Lambda(0.001)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1486
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2051431
	speed: 0.0228s/iter; left time: 269.2676s
Epoch: 5 cost time: 2.8256306648254395
Epoch: 5, Steps: 124 Train Loss: 0.2088 (Forecasting Loss:0.2057 + XiCon Loss:3.0591 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1490
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2015114
	speed: 0.0237s/iter; left time: 276.4505s
Epoch: 6 cost time: 2.891951322555542
Epoch: 6, Steps: 124 Train Loss: 0.2066 (Forecasting Loss:0.2036 + XiCon Loss:3.0594 x Lambda(0.001)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1495
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1990675
	speed: 0.0236s/iter; left time: 272.9828s
Epoch: 7 cost time: 2.877241373062134
Epoch: 7, Steps: 124 Train Loss: 0.2053 (Forecasting Loss:0.2022 + XiCon Loss:3.0595 x Lambda(0.001)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.1493
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2016572
	speed: 0.0237s/iter; left time: 270.5350s
Epoch: 8 cost time: 2.903465986251831
Epoch: 8, Steps: 124 Train Loss: 0.2045 (Forecasting Loss:0.2014 + XiCon Loss:3.0592 x Lambda(0.001)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1491
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2016610
	speed: 0.0230s/iter; left time: 260.3143s
Epoch: 9 cost time: 2.808028221130371
Epoch: 9, Steps: 124 Train Loss: 0.2045 (Forecasting Loss:0.2015 + XiCon Loss:3.0594 x Lambda(0.001)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.1488
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1896942
	speed: 0.0232s/iter; left time: 259.6795s
Epoch: 10 cost time: 2.8610944747924805
Epoch: 10, Steps: 124 Train Loss: 0.2041 (Forecasting Loss:0.2011 + XiCon Loss:3.0604 x Lambda(0.001)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.1488
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2043224
	speed: 0.0231s/iter; left time: 255.0182s
Epoch: 11 cost time: 2.835402488708496
Epoch: 11, Steps: 124 Train Loss: 0.2043 (Forecasting Loss:0.2012 + XiCon Loss:3.0582 x Lambda(0.001)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1489
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08874914050102234, mae:0.2380010187625885, mape:0.1779916137456894, mspe:0.050851695239543915 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3306
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2758740
	speed: 0.0196s/iter; left time: 240.9533s
Epoch: 1 cost time: 2.3857879638671875
Epoch: 1, Steps: 124 Train Loss: 0.2972 (Forecasting Loss:0.2941 + XiCon Loss:3.0742 x Lambda(0.001)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1587
Validation loss decreased (inf --> 0.214586).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2556570
	speed: 0.0196s/iter; left time: 239.1062s
Epoch: 2 cost time: 2.4192490577697754
Epoch: 2, Steps: 124 Train Loss: 0.2757 (Forecasting Loss:0.2727 + XiCon Loss:3.0740 x Lambda(0.001)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1631
Validation loss decreased (0.214586 --> 0.199208).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2366156
	speed: 0.0195s/iter; left time: 235.2370s
Epoch: 3 cost time: 2.3898277282714844
Epoch: 3, Steps: 124 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.0624 x Lambda(0.001)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1552
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2448266
	speed: 0.0198s/iter; left time: 236.2123s
Epoch: 4 cost time: 2.4222426414489746
Epoch: 4, Steps: 124 Train Loss: 0.2313 (Forecasting Loss:0.2282 + XiCon Loss:3.0676 x Lambda(0.001)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1543
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2105755
	speed: 0.0197s/iter; left time: 232.1255s
Epoch: 5 cost time: 2.4211952686309814
Epoch: 5, Steps: 124 Train Loss: 0.2208 (Forecasting Loss:0.2177 + XiCon Loss:3.0635 x Lambda(0.001)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1530
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2138650
	speed: 0.0195s/iter; left time: 228.1908s
Epoch: 6 cost time: 2.3960087299346924
Epoch: 6, Steps: 124 Train Loss: 0.2164 (Forecasting Loss:0.2133 + XiCon Loss:3.0621 x Lambda(0.001)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1557
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1915719
	speed: 0.0198s/iter; left time: 228.9395s
Epoch: 7 cost time: 2.407200336456299
Epoch: 7, Steps: 124 Train Loss: 0.2134 (Forecasting Loss:0.2103 + XiCon Loss:3.0623 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1559
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2164659
	speed: 0.0197s/iter; left time: 224.9033s
Epoch: 8 cost time: 2.390697479248047
Epoch: 8, Steps: 124 Train Loss: 0.2123 (Forecasting Loss:0.2092 + XiCon Loss:3.0636 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1556
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2244293
	speed: 0.0199s/iter; left time: 224.8554s
Epoch: 9 cost time: 2.450032949447632
Epoch: 9, Steps: 124 Train Loss: 0.2117 (Forecasting Loss:0.2087 + XiCon Loss:3.0636 x Lambda(0.001)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1561
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2038371
	speed: 0.0198s/iter; left time: 221.3279s
Epoch: 10 cost time: 2.416377305984497
Epoch: 10, Steps: 124 Train Loss: 0.2111 (Forecasting Loss:0.2080 + XiCon Loss:3.0626 x Lambda(0.001)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1558
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2233466
	speed: 0.0205s/iter; left time: 226.7558s
Epoch: 11 cost time: 2.488713264465332
Epoch: 11, Steps: 124 Train Loss: 0.2111 (Forecasting Loss:0.2080 + XiCon Loss:3.0629 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1562
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2175019
	speed: 0.0195s/iter; left time: 213.7251s
Epoch: 12 cost time: 2.4294610023498535
Epoch: 12, Steps: 124 Train Loss: 0.2111 (Forecasting Loss:0.2080 + XiCon Loss:3.0630 x Lambda(0.001)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1561
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.09117002785205841, mae:0.23493452370166779, mape:0.17899014055728912, mspe:0.05577234551310539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0861+-0.00533, MAE:0.2331+-0.00618, MAPE:0.1789+-0.00363, MSPE:0.0562+-0.00759, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3864
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3705418
	speed: 0.0479s/iter; left time: 560.7721s
Epoch: 1 cost time: 5.559199810028076
Epoch: 1, Steps: 118 Train Loss: 0.3626 (Forecasting Loss:0.3594 + XiCon Loss:3.1828 x Lambda(0.001)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.258898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2762342
	speed: 0.0480s/iter; left time: 555.6300s
Epoch: 2 cost time: 5.806478261947632
Epoch: 2, Steps: 118 Train Loss: 0.2995 (Forecasting Loss:0.2964 + XiCon Loss:3.1766 x Lambda(0.001)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1500
Validation loss decreased (0.258898 --> 0.251229).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2398003
	speed: 0.0621s/iter; left time: 712.5263s
Epoch: 3 cost time: 7.249639987945557
Epoch: 3, Steps: 118 Train Loss: 0.2371 (Forecasting Loss:0.2340 + XiCon Loss:3.1531 x Lambda(0.001)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1442
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2133794
	speed: 0.0601s/iter; left time: 681.9716s
Epoch: 4 cost time: 7.101479530334473
Epoch: 4, Steps: 118 Train Loss: 0.2225 (Forecasting Loss:0.2194 + XiCon Loss:3.1449 x Lambda(0.001)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.1473
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2093326
	speed: 0.0587s/iter; left time: 658.9764s
Epoch: 5 cost time: 6.943619251251221
Epoch: 5, Steps: 118 Train Loss: 0.2168 (Forecasting Loss:0.2137 + XiCon Loss:3.1429 x Lambda(0.001)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1465
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2190698
	speed: 0.0674s/iter; left time: 749.3792s
Epoch: 6 cost time: 7.93160343170166
Epoch: 6, Steps: 118 Train Loss: 0.2142 (Forecasting Loss:0.2110 + XiCon Loss:3.1407 x Lambda(0.001)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.1477
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2127023
	speed: 0.0627s/iter; left time: 689.7107s
Epoch: 7 cost time: 7.369937896728516
Epoch: 7, Steps: 118 Train Loss: 0.2128 (Forecasting Loss:0.2097 + XiCon Loss:3.1391 x Lambda(0.001)), Vali MSE Loss: 0.2576 Test MSE Loss: 0.1487
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2140494
	speed: 0.0655s/iter; left time: 712.6845s
Epoch: 8 cost time: 7.701492786407471
Epoch: 8, Steps: 118 Train Loss: 0.2122 (Forecasting Loss:0.2090 + XiCon Loss:3.1379 x Lambda(0.001)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.1472
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2036131
	speed: 0.0601s/iter; left time: 646.9982s
Epoch: 9 cost time: 7.129053831100464
Epoch: 9, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2082 + XiCon Loss:3.1381 x Lambda(0.001)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1477
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2220140
	speed: 0.0664s/iter; left time: 705.9254s
Epoch: 10 cost time: 7.803011417388916
Epoch: 10, Steps: 118 Train Loss: 0.2116 (Forecasting Loss:0.2085 + XiCon Loss:3.1380 x Lambda(0.001)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1479
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2222872
	speed: 0.0610s/iter; left time: 641.9858s
Epoch: 11 cost time: 7.197111368179321
Epoch: 11, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2082 + XiCon Loss:3.1386 x Lambda(0.001)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1476
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2061370
	speed: 0.0638s/iter; left time: 664.0826s
Epoch: 12 cost time: 7.461071491241455
Epoch: 12, Steps: 118 Train Loss: 0.2113 (Forecasting Loss:0.2081 + XiCon Loss:3.1375 x Lambda(0.001)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.1477
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07775268703699112, mae:0.22227807343006134, mape:0.16739284992218018, mspe:0.04888422414660454 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3665
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3102270
	speed: 0.0451s/iter; left time: 527.2144s
Epoch: 1 cost time: 5.330052137374878
Epoch: 1, Steps: 118 Train Loss: 0.3566 (Forecasting Loss:0.3535 + XiCon Loss:3.1769 x Lambda(0.001)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.1627
Validation loss decreased (inf --> 0.256374).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2835161
	speed: 0.0487s/iter; left time: 564.5943s
Epoch: 2 cost time: 5.680884838104248
Epoch: 2, Steps: 118 Train Loss: 0.3036 (Forecasting Loss:0.3004 + XiCon Loss:3.1673 x Lambda(0.001)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1480
Validation loss decreased (0.256374 --> 0.218338).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2456269
	speed: 0.0485s/iter; left time: 556.5639s
Epoch: 3 cost time: 5.704436540603638
Epoch: 3, Steps: 118 Train Loss: 0.2590 (Forecasting Loss:0.2558 + XiCon Loss:3.1589 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1472
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2383144
	speed: 0.0489s/iter; left time: 555.1493s
Epoch: 4 cost time: 5.664900302886963
Epoch: 4, Steps: 118 Train Loss: 0.2407 (Forecasting Loss:0.2376 + XiCon Loss:3.1589 x Lambda(0.001)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1457
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2279705
	speed: 0.0452s/iter; left time: 507.4842s
Epoch: 5 cost time: 5.327350378036499
Epoch: 5, Steps: 118 Train Loss: 0.2318 (Forecasting Loss:0.2287 + XiCon Loss:3.1581 x Lambda(0.001)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.1447
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2349164
	speed: 0.0459s/iter; left time: 509.8213s
Epoch: 6 cost time: 5.478365659713745
Epoch: 6, Steps: 118 Train Loss: 0.2282 (Forecasting Loss:0.2250 + XiCon Loss:3.1583 x Lambda(0.001)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1450
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2346423
	speed: 0.0474s/iter; left time: 521.2595s
Epoch: 7 cost time: 5.5518693923950195
Epoch: 7, Steps: 118 Train Loss: 0.2266 (Forecasting Loss:0.2235 + XiCon Loss:3.1582 x Lambda(0.001)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1451
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2385695
	speed: 0.0451s/iter; left time: 490.7852s
Epoch: 8 cost time: 5.310701131820679
Epoch: 8, Steps: 118 Train Loss: 0.2254 (Forecasting Loss:0.2222 + XiCon Loss:3.1579 x Lambda(0.001)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2215125
	speed: 0.0482s/iter; left time: 518.7916s
Epoch: 9 cost time: 5.619075298309326
Epoch: 9, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.1585 x Lambda(0.001)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.1445
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2342062
	speed: 0.0494s/iter; left time: 525.3095s
Epoch: 10 cost time: 5.721930265426636
Epoch: 10, Steps: 118 Train Loss: 0.2248 (Forecasting Loss:0.2217 + XiCon Loss:3.1571 x Lambda(0.001)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2324456
	speed: 0.0469s/iter; left time: 493.3711s
Epoch: 11 cost time: 5.5563414096832275
Epoch: 11, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2219 + XiCon Loss:3.1585 x Lambda(0.001)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1448
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2194704
	speed: 0.0481s/iter; left time: 500.4518s
Epoch: 12 cost time: 5.672427177429199
Epoch: 12, Steps: 118 Train Loss: 0.2249 (Forecasting Loss:0.2218 + XiCon Loss:3.1577 x Lambda(0.001)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07559357583522797, mae:0.22041693329811096, mape:0.1664663404226303, mspe:0.04627635329961777 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2884
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3267493
	speed: 0.0459s/iter; left time: 537.5852s
Epoch: 1 cost time: 5.43816876411438
Epoch: 1, Steps: 118 Train Loss: 0.3577 (Forecasting Loss:0.3545 + XiCon Loss:3.1764 x Lambda(0.001)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1640
Validation loss decreased (inf --> 0.253625).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2705109
	speed: 0.0475s/iter; left time: 549.9781s
Epoch: 2 cost time: 5.642709732055664
Epoch: 2, Steps: 118 Train Loss: 0.3042 (Forecasting Loss:0.3011 + XiCon Loss:3.1425 x Lambda(0.001)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1453
Validation loss decreased (0.253625 --> 0.250933).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2400580
	speed: 0.0569s/iter; left time: 651.7889s
Epoch: 3 cost time: 6.630502223968506
Epoch: 3, Steps: 118 Train Loss: 0.2418 (Forecasting Loss:0.2387 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1538
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2145527
	speed: 0.0545s/iter; left time: 618.5456s
Epoch: 4 cost time: 6.515247344970703
Epoch: 4, Steps: 118 Train Loss: 0.2233 (Forecasting Loss:0.2202 + XiCon Loss:3.1018 x Lambda(0.001)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1477
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2179527
	speed: 0.0586s/iter; left time: 658.4142s
Epoch: 5 cost time: 6.883873224258423
Epoch: 5, Steps: 118 Train Loss: 0.2166 (Forecasting Loss:0.2135 + XiCon Loss:3.0998 x Lambda(0.001)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1512
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2182606
	speed: 0.0609s/iter; left time: 676.7842s
Epoch: 6 cost time: 7.111776828765869
Epoch: 6, Steps: 118 Train Loss: 0.2132 (Forecasting Loss:0.2101 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.2636 Test MSE Loss: 0.1492
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2170444
	speed: 0.0617s/iter; left time: 677.7291s
Epoch: 7 cost time: 7.225748062133789
Epoch: 7, Steps: 118 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1000 x Lambda(0.001)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.1511
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2066161
	speed: 0.0585s/iter; left time: 636.3863s
Epoch: 8 cost time: 6.900627136230469
Epoch: 8, Steps: 118 Train Loss: 0.2110 (Forecasting Loss:0.2079 + XiCon Loss:3.1001 x Lambda(0.001)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1500
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2124444
	speed: 0.0645s/iter; left time: 693.5697s
Epoch: 9 cost time: 7.484161138534546
Epoch: 9, Steps: 118 Train Loss: 0.2106 (Forecasting Loss:0.2075 + XiCon Loss:3.0979 x Lambda(0.001)), Vali MSE Loss: 0.2634 Test MSE Loss: 0.1501
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2049582
	speed: 0.0619s/iter; left time: 658.4612s
Epoch: 10 cost time: 7.265658617019653
Epoch: 10, Steps: 118 Train Loss: 0.2104 (Forecasting Loss:0.2073 + XiCon Loss:3.0987 x Lambda(0.001)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1502
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2244769
	speed: 0.0563s/iter; left time: 591.9257s
Epoch: 11 cost time: 6.6500067710876465
Epoch: 11, Steps: 118 Train Loss: 0.2102 (Forecasting Loss:0.2071 + XiCon Loss:3.0983 x Lambda(0.001)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1506
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2157263
	speed: 0.0615s/iter; left time: 639.4121s
Epoch: 12 cost time: 7.168533086776733
Epoch: 12, Steps: 118 Train Loss: 0.2103 (Forecasting Loss:0.2072 + XiCon Loss:3.0993 x Lambda(0.001)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1503
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0746346041560173, mae:0.21590672433376312, mape:0.1629609912633896, mspe:0.04814989119768143 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2628
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3242696
	speed: 0.0449s/iter; left time: 525.8861s
Epoch: 1 cost time: 5.313159465789795
Epoch: 1, Steps: 118 Train Loss: 0.3553 (Forecasting Loss:0.3521 + XiCon Loss:3.1777 x Lambda(0.001)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1590
Validation loss decreased (inf --> 0.255510).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2623523
	speed: 0.0459s/iter; left time: 532.1972s
Epoch: 2 cost time: 5.421744108200073
Epoch: 2, Steps: 118 Train Loss: 0.3165 (Forecasting Loss:0.3133 + XiCon Loss:3.1657 x Lambda(0.001)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.1384
Validation loss decreased (0.255510 --> 0.229176).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2459767
	speed: 0.0561s/iter; left time: 643.5198s
Epoch: 3 cost time: 6.635817527770996
Epoch: 3, Steps: 118 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.1348 x Lambda(0.001)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2253923
	speed: 0.0520s/iter; left time: 589.9288s
Epoch: 4 cost time: 6.262020587921143
Epoch: 4, Steps: 118 Train Loss: 0.2282 (Forecasting Loss:0.2251 + XiCon Loss:3.1220 x Lambda(0.001)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1405
Validation loss decreased (0.229176 --> 0.228874).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2325196
	speed: 0.0566s/iter; left time: 635.3021s
Epoch: 5 cost time: 6.581234455108643
Epoch: 5, Steps: 118 Train Loss: 0.2223 (Forecasting Loss:0.2191 + XiCon Loss:3.1204 x Lambda(0.001)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2100114
	speed: 0.0531s/iter; left time: 589.6257s
Epoch: 6 cost time: 6.235941410064697
Epoch: 6, Steps: 118 Train Loss: 0.2190 (Forecasting Loss:0.2159 + XiCon Loss:3.1195 x Lambda(0.001)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1365
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2155675
	speed: 0.0582s/iter; left time: 640.3231s
Epoch: 7 cost time: 6.772774696350098
Epoch: 7, Steps: 118 Train Loss: 0.2178 (Forecasting Loss:0.2147 + XiCon Loss:3.1207 x Lambda(0.001)), Vali MSE Loss: 0.2386 Test MSE Loss: 0.1370
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2235000
	speed: 0.0564s/iter; left time: 612.8803s
Epoch: 8 cost time: 6.609958171844482
Epoch: 8, Steps: 118 Train Loss: 0.2170 (Forecasting Loss:0.2139 + XiCon Loss:3.1196 x Lambda(0.001)), Vali MSE Loss: 0.2378 Test MSE Loss: 0.1375
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2228020
	speed: 0.0539s/iter; left time: 579.8169s
Epoch: 9 cost time: 6.335503101348877
Epoch: 9, Steps: 118 Train Loss: 0.2167 (Forecasting Loss:0.2136 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.2387 Test MSE Loss: 0.1369
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2220400
	speed: 0.0575s/iter; left time: 611.3234s
Epoch: 10 cost time: 6.656954050064087
Epoch: 10, Steps: 118 Train Loss: 0.2166 (Forecasting Loss:0.2135 + XiCon Loss:3.1184 x Lambda(0.001)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2202023
	speed: 0.0571s/iter; left time: 600.8196s
Epoch: 11 cost time: 6.638756036758423
Epoch: 11, Steps: 118 Train Loss: 0.2164 (Forecasting Loss:0.2132 + XiCon Loss:3.1201 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1368
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2130013
	speed: 0.0572s/iter; left time: 595.1315s
Epoch: 12 cost time: 6.687626838684082
Epoch: 12, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2130 + XiCon Loss:3.1214 x Lambda(0.001)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1367
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2263949
	speed: 0.0560s/iter; left time: 575.7295s
Epoch: 13 cost time: 6.61715030670166
Epoch: 13, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2131 + XiCon Loss:3.1206 x Lambda(0.001)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1368
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2031743
	speed: 0.0544s/iter; left time: 553.4716s
Epoch: 14 cost time: 6.3980302810668945
Epoch: 14, Steps: 118 Train Loss: 0.2163 (Forecasting Loss:0.2132 + XiCon Loss:3.1208 x Lambda(0.001)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07018648833036423, mae:0.21080194413661957, mape:0.15734724700450897, mspe:0.04249102622270584 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2498
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3341178
	speed: 0.0453s/iter; left time: 530.3982s
Epoch: 1 cost time: 5.424518585205078
Epoch: 1, Steps: 118 Train Loss: 0.3567 (Forecasting Loss:0.3535 + XiCon Loss:3.1774 x Lambda(0.001)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1621
Validation loss decreased (inf --> 0.255394).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2742794
	speed: 0.0463s/iter; left time: 536.7623s
Epoch: 2 cost time: 5.529507875442505
Epoch: 2, Steps: 118 Train Loss: 0.3057 (Forecasting Loss:0.3025 + XiCon Loss:3.1634 x Lambda(0.001)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1483
Validation loss decreased (0.255394 --> 0.226973).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2416171
	speed: 0.0479s/iter; left time: 548.8283s
Epoch: 3 cost time: 5.698068618774414
Epoch: 3, Steps: 118 Train Loss: 0.2494 (Forecasting Loss:0.2463 + XiCon Loss:3.1385 x Lambda(0.001)), Vali MSE Loss: 0.2232 Test MSE Loss: 0.1344
Validation loss decreased (0.226973 --> 0.223153).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2246460
	speed: 0.0501s/iter; left time: 567.9573s
Epoch: 4 cost time: 5.958550930023193
Epoch: 4, Steps: 118 Train Loss: 0.2280 (Forecasting Loss:0.2249 + XiCon Loss:3.1128 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1376
Validation loss decreased (0.223153 --> 0.216173).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2109078
	speed: 0.0486s/iter; left time: 545.6132s
Epoch: 5 cost time: 5.690839529037476
Epoch: 5, Steps: 118 Train Loss: 0.2212 (Forecasting Loss:0.2181 + XiCon Loss:3.1094 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2097467
	speed: 0.0478s/iter; left time: 531.6519s
Epoch: 6 cost time: 5.586402893066406
Epoch: 6, Steps: 118 Train Loss: 0.2185 (Forecasting Loss:0.2154 + XiCon Loss:3.1074 x Lambda(0.001)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1389
Validation loss decreased (0.216173 --> 0.215558).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2097901
	speed: 0.0498s/iter; left time: 547.2278s
Epoch: 7 cost time: 5.8777992725372314
Epoch: 7, Steps: 118 Train Loss: 0.2172 (Forecasting Loss:0.2141 + XiCon Loss:3.1069 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1387
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2056282
	speed: 0.0492s/iter; left time: 534.8270s
Epoch: 8 cost time: 5.878639221191406
Epoch: 8, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2130 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1368
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2093196
	speed: 0.0476s/iter; left time: 512.3749s
Epoch: 9 cost time: 5.592542409896851
Epoch: 9, Steps: 118 Train Loss: 0.2159 (Forecasting Loss:0.2128 + XiCon Loss:3.1075 x Lambda(0.001)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2005154
	speed: 0.0525s/iter; left time: 558.9155s
Epoch: 10 cost time: 6.092742681503296
Epoch: 10, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.1056 x Lambda(0.001)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1382
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2243007
	speed: 0.0500s/iter; left time: 526.4514s
Epoch: 11 cost time: 5.837594985961914
Epoch: 11, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.1065 x Lambda(0.001)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1383
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2166481
	speed: 0.0484s/iter; left time: 503.0343s
Epoch: 12 cost time: 5.69424843788147
Epoch: 12, Steps: 118 Train Loss: 0.2157 (Forecasting Loss:0.2125 + XiCon Loss:3.1060 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1383
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2122058
	speed: 0.0512s/iter; left time: 526.2463s
Epoch: 13 cost time: 5.963015556335449
Epoch: 13, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2125 + XiCon Loss:3.1062 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1383
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2156212
	speed: 0.0494s/iter; left time: 502.6206s
Epoch: 14 cost time: 5.757350921630859
Epoch: 14, Steps: 118 Train Loss: 0.2151 (Forecasting Loss:0.2120 + XiCon Loss:3.1062 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1383
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2302009
	speed: 0.0494s/iter; left time: 496.4927s
Epoch: 15 cost time: 5.758569717407227
Epoch: 15, Steps: 118 Train Loss: 0.2152 (Forecasting Loss:0.2121 + XiCon Loss:3.1055 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1383
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2179538
	speed: 0.0482s/iter; left time: 478.7144s
Epoch: 16 cost time: 5.661351680755615
Epoch: 16, Steps: 118 Train Loss: 0.2153 (Forecasting Loss:0.2122 + XiCon Loss:3.1063 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1384
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.06813675910234451, mae:0.20960365235805511, mape:0.15839529037475586, mspe:0.04325753077864647 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0733+-0.00494, MAE:0.2158+-0.00699, MAPE:0.1625+-0.00567, MSPE:0.0458+-0.00355, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4703
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2366662
	speed: 0.0166s/iter; left time: 211.2189s
Epoch: 1 cost time: 2.0143535137176514
Epoch: 1, Steps: 128 Train Loss: 0.2953 (Forecasting Loss:0.2922 + XiCon Loss:3.0930 x Lambda(0.001)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.2307
Validation loss decreased (inf --> 0.274658).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2198806
	speed: 0.0135s/iter; left time: 170.1636s
Epoch: 2 cost time: 1.6895930767059326
Epoch: 2, Steps: 128 Train Loss: 0.2393 (Forecasting Loss:0.2362 + XiCon Loss:3.0955 x Lambda(0.001)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2581
Validation loss decreased (0.274658 --> 0.251543).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1879907
	speed: 0.0144s/iter; left time: 178.5969s
Epoch: 3 cost time: 1.8205649852752686
Epoch: 3, Steps: 128 Train Loss: 0.1878 (Forecasting Loss:0.1848 + XiCon Loss:3.0647 x Lambda(0.001)), Vali MSE Loss: 0.2778 Test MSE Loss: 0.3093
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1547608
	speed: 0.0134s/iter; left time: 165.3319s
Epoch: 4 cost time: 1.721529245376587
Epoch: 4, Steps: 128 Train Loss: 0.1627 (Forecasting Loss:0.1597 + XiCon Loss:3.0495 x Lambda(0.001)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.3211
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1608573
	speed: 0.0137s/iter; left time: 166.7698s
Epoch: 5 cost time: 1.7287774085998535
Epoch: 5, Steps: 128 Train Loss: 0.1515 (Forecasting Loss:0.1484 + XiCon Loss:3.0421 x Lambda(0.001)), Vali MSE Loss: 0.2980 Test MSE Loss: 0.3333
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1599012
	speed: 0.0135s/iter; left time: 163.3391s
Epoch: 6 cost time: 1.7104196548461914
Epoch: 6, Steps: 128 Train Loss: 0.1472 (Forecasting Loss:0.1441 + XiCon Loss:3.0374 x Lambda(0.001)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.3323
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1558686
	speed: 0.0145s/iter; left time: 173.5249s
Epoch: 7 cost time: 1.8479375839233398
Epoch: 7, Steps: 128 Train Loss: 0.1445 (Forecasting Loss:0.1415 + XiCon Loss:3.0366 x Lambda(0.001)), Vali MSE Loss: 0.2986 Test MSE Loss: 0.3361
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1519427
	speed: 0.0140s/iter; left time: 164.8617s
Epoch: 8 cost time: 1.7896032333374023
Epoch: 8, Steps: 128 Train Loss: 0.1437 (Forecasting Loss:0.1407 + XiCon Loss:3.0348 x Lambda(0.001)), Vali MSE Loss: 0.2963 Test MSE Loss: 0.3337
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1405389
	speed: 0.0139s/iter; left time: 162.1603s
Epoch: 9 cost time: 1.7401478290557861
Epoch: 9, Steps: 128 Train Loss: 0.1432 (Forecasting Loss:0.1402 + XiCon Loss:3.0366 x Lambda(0.001)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.3338
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1343799
	speed: 0.0137s/iter; left time: 158.2180s
Epoch: 10 cost time: 1.700875997543335
Epoch: 10, Steps: 128 Train Loss: 0.1426 (Forecasting Loss:0.1396 + XiCon Loss:3.0370 x Lambda(0.001)), Vali MSE Loss: 0.2994 Test MSE Loss: 0.3330
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1460453
	speed: 0.0140s/iter; left time: 159.4976s
Epoch: 11 cost time: 1.7657291889190674
Epoch: 11, Steps: 128 Train Loss: 0.1427 (Forecasting Loss:0.1397 + XiCon Loss:3.0358 x Lambda(0.001)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.3333
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1205478
	speed: 0.0144s/iter; left time: 162.8723s
Epoch: 12 cost time: 1.8111772537231445
Epoch: 12, Steps: 128 Train Loss: 0.1427 (Forecasting Loss:0.1397 + XiCon Loss:3.0357 x Lambda(0.001)), Vali MSE Loss: 0.2996 Test MSE Loss: 0.3337
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.18538285791873932, mae:0.3307499587535858, mape:0.7364158034324646, mspe:21.113752365112305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3737
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2411063
	speed: 0.0136s/iter; left time: 172.7693s
Epoch: 1 cost time: 1.7187352180480957
Epoch: 1, Steps: 128 Train Loss: 0.2983 (Forecasting Loss:0.2952 + XiCon Loss:3.0931 x Lambda(0.001)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.2281
Validation loss decreased (inf --> 0.274058).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2194855
	speed: 0.0141s/iter; left time: 177.2507s
Epoch: 2 cost time: 1.7592356204986572
Epoch: 2, Steps: 128 Train Loss: 0.2393 (Forecasting Loss:0.2362 + XiCon Loss:3.1288 x Lambda(0.001)), Vali MSE Loss: 0.2723 Test MSE Loss: 0.2539
Validation loss decreased (0.274058 --> 0.272267).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1683445
	speed: 0.0136s/iter; left time: 168.8616s
Epoch: 3 cost time: 1.7125895023345947
Epoch: 3, Steps: 128 Train Loss: 0.1946 (Forecasting Loss:0.1915 + XiCon Loss:3.1144 x Lambda(0.001)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2782
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1745696
	speed: 0.0151s/iter; left time: 185.5235s
Epoch: 4 cost time: 1.8563408851623535
Epoch: 4, Steps: 128 Train Loss: 0.1649 (Forecasting Loss:0.1618 + XiCon Loss:3.0993 x Lambda(0.001)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.2732
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1421836
	speed: 0.0145s/iter; left time: 177.3444s
Epoch: 5 cost time: 1.813105821609497
Epoch: 5, Steps: 128 Train Loss: 0.1535 (Forecasting Loss:0.1504 + XiCon Loss:3.0957 x Lambda(0.001)), Vali MSE Loss: 0.3101 Test MSE Loss: 0.2872
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1439744
	speed: 0.0133s/iter; left time: 160.9538s
Epoch: 6 cost time: 1.6854894161224365
Epoch: 6, Steps: 128 Train Loss: 0.1486 (Forecasting Loss:0.1456 + XiCon Loss:3.0956 x Lambda(0.001)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.2743
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1540008
	speed: 0.0138s/iter; left time: 164.2403s
Epoch: 7 cost time: 1.733142614364624
Epoch: 7, Steps: 128 Train Loss: 0.1466 (Forecasting Loss:0.1436 + XiCon Loss:3.0951 x Lambda(0.001)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.2733
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1472301
	speed: 0.0144s/iter; left time: 169.7523s
Epoch: 8 cost time: 1.872281789779663
Epoch: 8, Steps: 128 Train Loss: 0.1456 (Forecasting Loss:0.1425 + XiCon Loss:3.0954 x Lambda(0.001)), Vali MSE Loss: 0.3148 Test MSE Loss: 0.2746
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1352299
	speed: 0.0141s/iter; left time: 164.3954s
Epoch: 9 cost time: 1.8136582374572754
Epoch: 9, Steps: 128 Train Loss: 0.1453 (Forecasting Loss:0.1422 + XiCon Loss:3.0970 x Lambda(0.001)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.2751
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1348738
	speed: 0.0147s/iter; left time: 169.4144s
Epoch: 10 cost time: 1.8245739936828613
Epoch: 10, Steps: 128 Train Loss: 0.1451 (Forecasting Loss:0.1420 + XiCon Loss:3.0953 x Lambda(0.001)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2768
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1504925
	speed: 0.0140s/iter; left time: 160.1705s
Epoch: 11 cost time: 1.7440409660339355
Epoch: 11, Steps: 128 Train Loss: 0.1449 (Forecasting Loss:0.1418 + XiCon Loss:3.0963 x Lambda(0.001)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.2768
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1486168
	speed: 0.0143s/iter; left time: 161.4489s
Epoch: 12 cost time: 1.7718379497528076
Epoch: 12, Steps: 128 Train Loss: 0.1446 (Forecasting Loss:0.1415 + XiCon Loss:3.0971 x Lambda(0.001)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.2771
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.18112975358963013, mae:0.32661789655685425, mape:0.770320475101471, mspe:23.03458595275879 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3222
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2308860
	speed: 0.0138s/iter; left time: 175.2929s
Epoch: 1 cost time: 1.7742419242858887
Epoch: 1, Steps: 128 Train Loss: 0.2967 (Forecasting Loss:0.2936 + XiCon Loss:3.1180 x Lambda(0.001)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.2250
Validation loss decreased (inf --> 0.271664).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1930838
	speed: 0.0141s/iter; left time: 176.9988s
Epoch: 2 cost time: 1.7746381759643555
Epoch: 2, Steps: 128 Train Loss: 0.2405 (Forecasting Loss:0.2375 + XiCon Loss:3.0721 x Lambda(0.001)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.2833
Validation loss decreased (0.271664 --> 0.269586).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1991187
	speed: 0.0145s/iter; left time: 180.5734s
Epoch: 3 cost time: 1.8646221160888672
Epoch: 3, Steps: 128 Train Loss: 0.1895 (Forecasting Loss:0.1865 + XiCon Loss:3.0462 x Lambda(0.001)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1581912
	speed: 0.0140s/iter; left time: 171.9397s
Epoch: 4 cost time: 1.7383952140808105
Epoch: 4, Steps: 128 Train Loss: 0.1622 (Forecasting Loss:0.1592 + XiCon Loss:3.0435 x Lambda(0.001)), Vali MSE Loss: 0.2768 Test MSE Loss: 0.2910
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1412113
	speed: 0.0149s/iter; left time: 181.4758s
Epoch: 5 cost time: 1.8887550830841064
Epoch: 5, Steps: 128 Train Loss: 0.1495 (Forecasting Loss:0.1465 + XiCon Loss:3.0408 x Lambda(0.001)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.2815
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1422641
	speed: 0.0139s/iter; left time: 167.2432s
Epoch: 6 cost time: 1.7357580661773682
Epoch: 6, Steps: 128 Train Loss: 0.1445 (Forecasting Loss:0.1415 + XiCon Loss:3.0450 x Lambda(0.001)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2710
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1487605
	speed: 0.0141s/iter; left time: 167.7656s
Epoch: 7 cost time: 1.7568528652191162
Epoch: 7, Steps: 128 Train Loss: 0.1421 (Forecasting Loss:0.1391 + XiCon Loss:3.0458 x Lambda(0.001)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2748
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1435829
	speed: 0.0140s/iter; left time: 165.0494s
Epoch: 8 cost time: 1.7573497295379639
Epoch: 8, Steps: 128 Train Loss: 0.1413 (Forecasting Loss:0.1383 + XiCon Loss:3.0442 x Lambda(0.001)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.2760
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1372211
	speed: 0.0144s/iter; left time: 168.5670s
Epoch: 9 cost time: 1.843273639678955
Epoch: 9, Steps: 128 Train Loss: 0.1409 (Forecasting Loss:0.1379 + XiCon Loss:3.0450 x Lambda(0.001)), Vali MSE Loss: 0.2880 Test MSE Loss: 0.2756
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1460299
	speed: 0.0140s/iter; left time: 161.3832s
Epoch: 10 cost time: 1.7631947994232178
Epoch: 10, Steps: 128 Train Loss: 0.1406 (Forecasting Loss:0.1375 + XiCon Loss:3.0461 x Lambda(0.001)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2780
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1470682
	speed: 0.0144s/iter; left time: 164.3082s
Epoch: 11 cost time: 1.7921295166015625
Epoch: 11, Steps: 128 Train Loss: 0.1405 (Forecasting Loss:0.1374 + XiCon Loss:3.0454 x Lambda(0.001)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2776
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1466973
	speed: 0.0143s/iter; left time: 161.3778s
Epoch: 12 cost time: 1.7905762195587158
Epoch: 12, Steps: 128 Train Loss: 0.1404 (Forecasting Loss:0.1374 + XiCon Loss:3.0464 x Lambda(0.001)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2778
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.21460527181625366, mae:0.3520353436470032, mape:0.8119157552719116, mspe:22.923608779907227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3895
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2697541
	speed: 0.0133s/iter; left time: 168.8542s
Epoch: 1 cost time: 1.680891513824463
Epoch: 1, Steps: 128 Train Loss: 0.2955 (Forecasting Loss:0.2924 + XiCon Loss:3.0913 x Lambda(0.001)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.2275
Validation loss decreased (inf --> 0.273607).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2495494
	speed: 0.0141s/iter; left time: 177.6961s
Epoch: 2 cost time: 1.760033130645752
Epoch: 2, Steps: 128 Train Loss: 0.2440 (Forecasting Loss:0.2409 + XiCon Loss:3.0834 x Lambda(0.001)), Vali MSE Loss: 0.2648 Test MSE Loss: 0.2185
Validation loss decreased (0.273607 --> 0.264772).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2001917
	speed: 0.0137s/iter; left time: 170.5371s
Epoch: 3 cost time: 1.7088491916656494
Epoch: 3, Steps: 128 Train Loss: 0.2102 (Forecasting Loss:0.2071 + XiCon Loss:3.0812 x Lambda(0.001)), Vali MSE Loss: 0.2563 Test MSE Loss: 0.2542
Validation loss decreased (0.264772 --> 0.256323).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1741485
	speed: 0.0145s/iter; left time: 178.2326s
Epoch: 4 cost time: 1.8014090061187744
Epoch: 4, Steps: 128 Train Loss: 0.1847 (Forecasting Loss:0.1816 + XiCon Loss:3.0748 x Lambda(0.001)), Vali MSE Loss: 0.2767 Test MSE Loss: 0.3174
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1664860
	speed: 0.0140s/iter; left time: 170.9535s
Epoch: 5 cost time: 1.729886531829834
Epoch: 5, Steps: 128 Train Loss: 0.1690 (Forecasting Loss:0.1659 + XiCon Loss:3.0652 x Lambda(0.001)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.3312
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1721646
	speed: 0.0141s/iter; left time: 169.5049s
Epoch: 6 cost time: 1.7793948650360107
Epoch: 6, Steps: 128 Train Loss: 0.1627 (Forecasting Loss:0.1597 + XiCon Loss:3.0622 x Lambda(0.001)), Vali MSE Loss: 0.2831 Test MSE Loss: 0.3199
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1650086
	speed: 0.0135s/iter; left time: 161.4793s
Epoch: 7 cost time: 1.6715624332427979
Epoch: 7, Steps: 128 Train Loss: 0.1595 (Forecasting Loss:0.1565 + XiCon Loss:3.0615 x Lambda(0.001)), Vali MSE Loss: 0.2866 Test MSE Loss: 0.3324
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1693127
	speed: 0.0144s/iter; left time: 170.2160s
Epoch: 8 cost time: 1.7881066799163818
Epoch: 8, Steps: 128 Train Loss: 0.1582 (Forecasting Loss:0.1552 + XiCon Loss:3.0610 x Lambda(0.001)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.3270
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1545845
	speed: 0.0139s/iter; left time: 162.4331s
Epoch: 9 cost time: 1.7428441047668457
Epoch: 9, Steps: 128 Train Loss: 0.1573 (Forecasting Loss:0.1542 + XiCon Loss:3.0584 x Lambda(0.001)), Vali MSE Loss: 0.2865 Test MSE Loss: 0.3295
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1520916
	speed: 0.0148s/iter; left time: 170.7177s
Epoch: 10 cost time: 1.8103888034820557
Epoch: 10, Steps: 128 Train Loss: 0.1571 (Forecasting Loss:0.1541 + XiCon Loss:3.0593 x Lambda(0.001)), Vali MSE Loss: 0.2858 Test MSE Loss: 0.3274
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1432918
	speed: 0.0151s/iter; left time: 172.8327s
Epoch: 11 cost time: 1.8664953708648682
Epoch: 11, Steps: 128 Train Loss: 0.1569 (Forecasting Loss:0.1539 + XiCon Loss:3.0587 x Lambda(0.001)), Vali MSE Loss: 0.2861 Test MSE Loss: 0.3290
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1579026
	speed: 0.0139s/iter; left time: 157.1935s
Epoch: 12 cost time: 1.7512297630310059
Epoch: 12, Steps: 128 Train Loss: 0.1568 (Forecasting Loss:0.1538 + XiCon Loss:3.0573 x Lambda(0.001)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.3295
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.1477188
	speed: 0.0140s/iter; left time: 156.3864s
Epoch: 13 cost time: 1.737612009048462
Epoch: 13, Steps: 128 Train Loss: 0.1568 (Forecasting Loss:0.1537 + XiCon Loss:3.0581 x Lambda(0.001)), Vali MSE Loss: 0.2861 Test MSE Loss: 0.3290
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.18332676589488983, mae:0.3251475393772125, mape:0.8117689490318298, mspe:28.855487823486328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3247
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2400779
	speed: 0.0142s/iter; left time: 180.6534s
Epoch: 1 cost time: 1.773263931274414
Epoch: 1, Steps: 128 Train Loss: 0.2945 (Forecasting Loss:0.2915 + XiCon Loss:3.0798 x Lambda(0.001)), Vali MSE Loss: 0.2728 Test MSE Loss: 0.2320
Validation loss decreased (inf --> 0.272809).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2336368
	speed: 0.0144s/iter; left time: 180.9918s
Epoch: 2 cost time: 1.8112313747406006
Epoch: 2, Steps: 128 Train Loss: 0.2400 (Forecasting Loss:0.2369 + XiCon Loss:3.0759 x Lambda(0.001)), Vali MSE Loss: 0.2679 Test MSE Loss: 0.2529
Validation loss decreased (0.272809 --> 0.267857).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1841383
	speed: 0.0136s/iter; left time: 169.7092s
Epoch: 3 cost time: 1.7190742492675781
Epoch: 3, Steps: 128 Train Loss: 0.1920 (Forecasting Loss:0.1889 + XiCon Loss:3.0860 x Lambda(0.001)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.3097
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1666627
	speed: 0.0139s/iter; left time: 170.9019s
Epoch: 4 cost time: 1.737135887145996
Epoch: 4, Steps: 128 Train Loss: 0.1678 (Forecasting Loss:0.1647 + XiCon Loss:3.0853 x Lambda(0.001)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.3302
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1506677
	speed: 0.0145s/iter; left time: 177.3030s
Epoch: 5 cost time: 1.8423445224761963
Epoch: 5, Steps: 128 Train Loss: 0.1573 (Forecasting Loss:0.1542 + XiCon Loss:3.0847 x Lambda(0.001)), Vali MSE Loss: 0.3371 Test MSE Loss: 0.3384
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1514256
	speed: 0.0136s/iter; left time: 163.5863s
Epoch: 6 cost time: 1.7693872451782227
Epoch: 6, Steps: 128 Train Loss: 0.1532 (Forecasting Loss:0.1501 + XiCon Loss:3.0802 x Lambda(0.001)), Vali MSE Loss: 0.3410 Test MSE Loss: 0.3414
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1496586
	speed: 0.0136s/iter; left time: 162.7577s
Epoch: 7 cost time: 1.7185025215148926
Epoch: 7, Steps: 128 Train Loss: 0.1512 (Forecasting Loss:0.1482 + XiCon Loss:3.0807 x Lambda(0.001)), Vali MSE Loss: 0.3403 Test MSE Loss: 0.3403
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1453715
	speed: 0.0152s/iter; left time: 179.4555s
Epoch: 8 cost time: 1.8522312641143799
Epoch: 8, Steps: 128 Train Loss: 0.1503 (Forecasting Loss:0.1472 + XiCon Loss:3.0821 x Lambda(0.001)), Vali MSE Loss: 0.3426 Test MSE Loss: 0.3417
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1511554
	speed: 0.0148s/iter; left time: 172.3764s
Epoch: 9 cost time: 1.8491792678833008
Epoch: 9, Steps: 128 Train Loss: 0.1499 (Forecasting Loss:0.1468 + XiCon Loss:3.0808 x Lambda(0.001)), Vali MSE Loss: 0.3436 Test MSE Loss: 0.3417
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1421112
	speed: 0.0136s/iter; left time: 157.5679s
Epoch: 10 cost time: 1.7167582511901855
Epoch: 10, Steps: 128 Train Loss: 0.1499 (Forecasting Loss:0.1468 + XiCon Loss:3.0822 x Lambda(0.001)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.3413
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1398742
	speed: 0.0136s/iter; left time: 155.2622s
Epoch: 11 cost time: 1.7288484573364258
Epoch: 11, Steps: 128 Train Loss: 0.1498 (Forecasting Loss:0.1467 + XiCon Loss:3.0809 x Lambda(0.001)), Vali MSE Loss: 0.3426 Test MSE Loss: 0.3415
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1714414
	speed: 0.0140s/iter; left time: 158.6202s
Epoch: 12 cost time: 1.7387418746948242
Epoch: 12, Steps: 128 Train Loss: 0.1494 (Forecasting Loss:0.1464 + XiCon Loss:3.0809 x Lambda(0.001)), Vali MSE Loss: 0.3427 Test MSE Loss: 0.3413
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.17510709166526794, mae:0.33070051670074463, mape:0.8349887132644653, mspe:27.46134376525879 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1879+-0.01913, MAE:0.3331+-0.01353, MAPE:0.7931+-0.04884, MSPE:24.6778+-4.10318, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4040
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3157971
	speed: 0.0176s/iter; left time: 220.4301s
Epoch: 1 cost time: 2.1162068843841553
Epoch: 1, Steps: 126 Train Loss: 0.3232 (Forecasting Loss:0.3201 + XiCon Loss:3.0903 x Lambda(0.001)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2655
Validation loss decreased (inf --> 0.306617).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2627673
	speed: 0.0163s/iter; left time: 201.3701s
Epoch: 2 cost time: 2.0447471141815186
Epoch: 2, Steps: 126 Train Loss: 0.2724 (Forecasting Loss:0.2693 + XiCon Loss:3.1069 x Lambda(0.001)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.2990
Validation loss decreased (0.306617 --> 0.302948).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2067906
	speed: 0.0176s/iter; left time: 216.1517s
Epoch: 3 cost time: 2.2075159549713135
Epoch: 3, Steps: 126 Train Loss: 0.2268 (Forecasting Loss:0.2237 + XiCon Loss:3.1045 x Lambda(0.001)), Vali MSE Loss: 0.3584 Test MSE Loss: 0.3399
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1989268
	speed: 0.0177s/iter; left time: 215.1369s
Epoch: 4 cost time: 2.199028730392456
Epoch: 4, Steps: 126 Train Loss: 0.2085 (Forecasting Loss:0.2054 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.3606
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2021970
	speed: 0.0173s/iter; left time: 207.9277s
Epoch: 5 cost time: 2.167126178741455
Epoch: 5, Steps: 126 Train Loss: 0.2023 (Forecasting Loss:0.1992 + XiCon Loss:3.1007 x Lambda(0.001)), Vali MSE Loss: 0.3343 Test MSE Loss: 0.3532
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1852994
	speed: 0.0174s/iter; left time: 206.3930s
Epoch: 6 cost time: 2.180500030517578
Epoch: 6, Steps: 126 Train Loss: 0.1996 (Forecasting Loss:0.1965 + XiCon Loss:3.0976 x Lambda(0.001)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.3582
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1864134
	speed: 0.0175s/iter; left time: 205.8118s
Epoch: 7 cost time: 2.182342529296875
Epoch: 7, Steps: 126 Train Loss: 0.1983 (Forecasting Loss:0.1952 + XiCon Loss:3.0989 x Lambda(0.001)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.3621
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2002159
	speed: 0.0177s/iter; left time: 205.1422s
Epoch: 8 cost time: 2.1729648113250732
Epoch: 8, Steps: 126 Train Loss: 0.1976 (Forecasting Loss:0.1945 + XiCon Loss:3.0984 x Lambda(0.001)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.3598
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2126824
	speed: 0.0180s/iter; left time: 206.3630s
Epoch: 9 cost time: 2.247723340988159
Epoch: 9, Steps: 126 Train Loss: 0.1974 (Forecasting Loss:0.1943 + XiCon Loss:3.0984 x Lambda(0.001)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3609
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1990974
	speed: 0.0175s/iter; left time: 198.7807s
Epoch: 10 cost time: 2.155667304992676
Epoch: 10, Steps: 126 Train Loss: 0.1969 (Forecasting Loss:0.1938 + XiCon Loss:3.0990 x Lambda(0.001)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3598
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2078855
	speed: 0.0178s/iter; left time: 199.8246s
Epoch: 11 cost time: 2.1931827068328857
Epoch: 11, Steps: 126 Train Loss: 0.1974 (Forecasting Loss:0.1943 + XiCon Loss:3.0978 x Lambda(0.001)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3605
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1903210
	speed: 0.0178s/iter; left time: 198.3216s
Epoch: 12 cost time: 2.2089946269989014
Epoch: 12, Steps: 126 Train Loss: 0.1970 (Forecasting Loss:0.1939 + XiCon Loss:3.0987 x Lambda(0.001)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3608
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.21851427853107452, mae:0.37952616810798645, mape:0.7955158948898315, mspe:22.99964714050293 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3617
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2918280
	speed: 0.0159s/iter; left time: 199.2290s
Epoch: 1 cost time: 1.9722893238067627
Epoch: 1, Steps: 126 Train Loss: 0.3208 (Forecasting Loss:0.3177 + XiCon Loss:3.1053 x Lambda(0.001)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.2666
Validation loss decreased (inf --> 0.306965).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2852499
	speed: 0.0167s/iter; left time: 206.3125s
Epoch: 2 cost time: 2.0888869762420654
Epoch: 2, Steps: 126 Train Loss: 0.2778 (Forecasting Loss:0.2747 + XiCon Loss:3.0867 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2169090
	speed: 0.0180s/iter; left time: 220.3198s
Epoch: 3 cost time: 2.257838487625122
Epoch: 3, Steps: 126 Train Loss: 0.2278 (Forecasting Loss:0.2247 + XiCon Loss:3.0833 x Lambda(0.001)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.3027
Validation loss decreased (0.306965 --> 0.306798).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1985141
	speed: 0.0178s/iter; left time: 215.6151s
Epoch: 4 cost time: 2.1778390407562256
Epoch: 4, Steps: 126 Train Loss: 0.2089 (Forecasting Loss:0.2058 + XiCon Loss:3.0839 x Lambda(0.001)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.3076
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1980362
	speed: 0.0171s/iter; left time: 205.4699s
Epoch: 5 cost time: 2.1301889419555664
Epoch: 5, Steps: 126 Train Loss: 0.2027 (Forecasting Loss:0.1996 + XiCon Loss:3.0893 x Lambda(0.001)), Vali MSE Loss: 0.3104 Test MSE Loss: 0.3021
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2031975
	speed: 0.0172s/iter; left time: 204.6933s
Epoch: 6 cost time: 2.145327091217041
Epoch: 6, Steps: 126 Train Loss: 0.1998 (Forecasting Loss:0.1967 + XiCon Loss:3.0897 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.3086
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2096415
	speed: 0.0176s/iter; left time: 206.1707s
Epoch: 7 cost time: 2.1871023178100586
Epoch: 7, Steps: 126 Train Loss: 0.1985 (Forecasting Loss:0.1954 + XiCon Loss:3.0889 x Lambda(0.001)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.3062
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1993230
	speed: 0.0171s/iter; left time: 198.5202s
Epoch: 8 cost time: 2.109084129333496
Epoch: 8, Steps: 126 Train Loss: 0.1977 (Forecasting Loss:0.1946 + XiCon Loss:3.0881 x Lambda(0.001)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.3063
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1838377
	speed: 0.0175s/iter; left time: 200.9490s
Epoch: 9 cost time: 2.163696050643921
Epoch: 9, Steps: 126 Train Loss: 0.1974 (Forecasting Loss:0.1943 + XiCon Loss:3.0899 x Lambda(0.001)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.3054
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2124910
	speed: 0.0176s/iter; left time: 200.3711s
Epoch: 10 cost time: 2.216904640197754
Epoch: 10, Steps: 126 Train Loss: 0.1968 (Forecasting Loss:0.1937 + XiCon Loss:3.0881 x Lambda(0.001)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.3063
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1824960
	speed: 0.0176s/iter; left time: 197.6454s
Epoch: 11 cost time: 2.1597118377685547
Epoch: 11, Steps: 126 Train Loss: 0.1968 (Forecasting Loss:0.1937 + XiCon Loss:3.0877 x Lambda(0.001)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.3065
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1830796
	speed: 0.0172s/iter; left time: 191.4151s
Epoch: 12 cost time: 2.1538565158843994
Epoch: 12, Steps: 126 Train Loss: 0.1968 (Forecasting Loss:0.1937 + XiCon Loss:3.0877 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.3064
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.1816849
	speed: 0.0169s/iter; left time: 185.4750s
Epoch: 13 cost time: 2.1145687103271484
Epoch: 13, Steps: 126 Train Loss: 0.1967 (Forecasting Loss:0.1936 + XiCon Loss:3.0898 x Lambda(0.001)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.3064
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.2253716140985489, mae:0.3799450695514679, mape:0.8271433115005493, mspe:24.562742233276367 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2908
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2836935
	speed: 0.0156s/iter; left time: 195.1262s
Epoch: 1 cost time: 1.9641125202178955
Epoch: 1, Steps: 126 Train Loss: 0.3211 (Forecasting Loss:0.3180 + XiCon Loss:3.0870 x Lambda(0.001)), Vali MSE Loss: 0.3078 Test MSE Loss: 0.2645
Validation loss decreased (inf --> 0.307839).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2302810
	speed: 0.0159s/iter; left time: 196.2992s
Epoch: 2 cost time: 1.9841632843017578
Epoch: 2, Steps: 126 Train Loss: 0.2629 (Forecasting Loss:0.2599 + XiCon Loss:3.0855 x Lambda(0.001)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2666
Validation loss decreased (0.307839 --> 0.305993).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2270426
	speed: 0.0168s/iter; left time: 205.5823s
Epoch: 3 cost time: 2.0960230827331543
Epoch: 3, Steps: 126 Train Loss: 0.2199 (Forecasting Loss:0.2168 + XiCon Loss:3.0781 x Lambda(0.001)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.2739
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1820721
	speed: 0.0168s/iter; left time: 203.9766s
Epoch: 4 cost time: 2.086271047592163
Epoch: 4, Steps: 126 Train Loss: 0.2056 (Forecasting Loss:0.2025 + XiCon Loss:3.0737 x Lambda(0.001)), Vali MSE Loss: 0.3110 Test MSE Loss: 0.2811
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1924509
	speed: 0.0171s/iter; left time: 204.7136s
Epoch: 5 cost time: 2.132695436477661
Epoch: 5, Steps: 126 Train Loss: 0.2000 (Forecasting Loss:0.1970 + XiCon Loss:3.0699 x Lambda(0.001)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.2696
Validation loss decreased (0.305993 --> 0.302905).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1857833
	speed: 0.0168s/iter; left time: 198.9329s
Epoch: 6 cost time: 2.133768320083618
Epoch: 6, Steps: 126 Train Loss: 0.1975 (Forecasting Loss:0.1944 + XiCon Loss:3.0707 x Lambda(0.001)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2677
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1771661
	speed: 0.0176s/iter; left time: 206.4685s
Epoch: 7 cost time: 2.1821634769439697
Epoch: 7, Steps: 126 Train Loss: 0.1964 (Forecasting Loss:0.1933 + XiCon Loss:3.0705 x Lambda(0.001)), Vali MSE Loss: 0.3033 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1893880
	speed: 0.0173s/iter; left time: 201.3104s
Epoch: 8 cost time: 2.141028881072998
Epoch: 8, Steps: 126 Train Loss: 0.1958 (Forecasting Loss:0.1927 + XiCon Loss:3.0699 x Lambda(0.001)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.2703
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1930425
	speed: 0.0169s/iter; left time: 194.4252s
Epoch: 9 cost time: 2.117995262145996
Epoch: 9, Steps: 126 Train Loss: 0.1955 (Forecasting Loss:0.1924 + XiCon Loss:3.0708 x Lambda(0.001)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.2677
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1912530
	speed: 0.0172s/iter; left time: 195.7159s
Epoch: 10 cost time: 2.1293272972106934
Epoch: 10, Steps: 126 Train Loss: 0.1951 (Forecasting Loss:0.1921 + XiCon Loss:3.0692 x Lambda(0.001)), Vali MSE Loss: 0.3043 Test MSE Loss: 0.2683
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1877887
	speed: 0.0174s/iter; left time: 196.0108s
Epoch: 11 cost time: 2.195120334625244
Epoch: 11, Steps: 126 Train Loss: 0.1951 (Forecasting Loss:0.1920 + XiCon Loss:3.0714 x Lambda(0.001)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.2680
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1905565
	speed: 0.0178s/iter; left time: 198.0432s
Epoch: 12 cost time: 2.1983256340026855
Epoch: 12, Steps: 126 Train Loss: 0.1951 (Forecasting Loss:0.1921 + XiCon Loss:3.0703 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2679
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.1914037
	speed: 0.0172s/iter; left time: 188.7215s
Epoch: 13 cost time: 2.1251516342163086
Epoch: 13, Steps: 126 Train Loss: 0.1948 (Forecasting Loss:0.1917 + XiCon Loss:3.0709 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2679
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.1886822
	speed: 0.0174s/iter; left time: 189.0644s
Epoch: 14 cost time: 2.1365106105804443
Epoch: 14, Steps: 126 Train Loss: 0.1951 (Forecasting Loss:0.1920 + XiCon Loss:3.0694 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2679
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.1931553
	speed: 0.0172s/iter; left time: 185.0411s
Epoch: 15 cost time: 2.121018171310425
Epoch: 15, Steps: 126 Train Loss: 0.1949 (Forecasting Loss:0.1918 + XiCon Loss:3.0693 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2679
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.18794730305671692, mae:0.3512401878833771, mape:0.7020720839500427, mspe:16.388864517211914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3599
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2895552
	speed: 0.0152s/iter; left time: 189.8963s
Epoch: 1 cost time: 1.878016710281372
Epoch: 1, Steps: 126 Train Loss: 0.3206 (Forecasting Loss:0.3175 + XiCon Loss:3.1010 x Lambda(0.001)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2621
Validation loss decreased (inf --> 0.308262).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2907986
	speed: 0.0156s/iter; left time: 192.4371s
Epoch: 2 cost time: 1.9272541999816895
Epoch: 2, Steps: 126 Train Loss: 0.2797 (Forecasting Loss:0.2766 + XiCon Loss:3.0838 x Lambda(0.001)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.2936
Validation loss decreased (0.308262 --> 0.300556).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2262399
	speed: 0.0154s/iter; left time: 188.9621s
Epoch: 3 cost time: 1.9119229316711426
Epoch: 3, Steps: 126 Train Loss: 0.2432 (Forecasting Loss:0.2401 + XiCon Loss:3.0658 x Lambda(0.001)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.3465
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2070865
	speed: 0.0159s/iter; left time: 192.8596s
Epoch: 4 cost time: 1.9669411182403564
Epoch: 4, Steps: 126 Train Loss: 0.2182 (Forecasting Loss:0.2151 + XiCon Loss:3.0606 x Lambda(0.001)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.3767
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2289356
	speed: 0.0158s/iter; left time: 190.1115s
Epoch: 5 cost time: 1.961395025253296
Epoch: 5, Steps: 126 Train Loss: 0.2076 (Forecasting Loss:0.2045 + XiCon Loss:3.0553 x Lambda(0.001)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.3864
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1933194
	speed: 0.0153s/iter; left time: 181.8098s
Epoch: 6 cost time: 1.935448408126831
Epoch: 6, Steps: 126 Train Loss: 0.2037 (Forecasting Loss:0.2007 + XiCon Loss:3.0563 x Lambda(0.001)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.3920
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2084713
	speed: 0.0162s/iter; left time: 189.7696s
Epoch: 7 cost time: 1.9719955921173096
Epoch: 7, Steps: 126 Train Loss: 0.2015 (Forecasting Loss:0.1984 + XiCon Loss:3.0534 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.3946
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2122179
	speed: 0.0162s/iter; left time: 188.4857s
Epoch: 8 cost time: 1.9910166263580322
Epoch: 8, Steps: 126 Train Loss: 0.2003 (Forecasting Loss:0.1972 + XiCon Loss:3.0556 x Lambda(0.001)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.4012
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2090389
	speed: 0.0151s/iter; left time: 173.5328s
Epoch: 9 cost time: 1.8678629398345947
Epoch: 9, Steps: 126 Train Loss: 0.1998 (Forecasting Loss:0.1968 + XiCon Loss:3.0564 x Lambda(0.001)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.3994
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2013135
	speed: 0.0154s/iter; left time: 174.8947s
Epoch: 10 cost time: 1.9112439155578613
Epoch: 10, Steps: 126 Train Loss: 0.1994 (Forecasting Loss:0.1963 + XiCon Loss:3.0537 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.3973
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1884931
	speed: 0.0161s/iter; left time: 180.8618s
Epoch: 11 cost time: 1.9750659465789795
Epoch: 11, Steps: 126 Train Loss: 0.1991 (Forecasting Loss:0.1960 + XiCon Loss:3.0520 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.4000
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2076323
	speed: 0.0154s/iter; left time: 171.2087s
Epoch: 12 cost time: 1.9399666786193848
Epoch: 12, Steps: 126 Train Loss: 0.1993 (Forecasting Loss:0.1962 + XiCon Loss:3.0540 x Lambda(0.001)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.3994
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.217426136136055, mae:0.36985117197036743, mape:0.7266894578933716, mspe:16.782203674316406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3150
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2978310
	speed: 0.0166s/iter; left time: 207.1657s
Epoch: 1 cost time: 2.0456435680389404
Epoch: 1, Steps: 126 Train Loss: 0.3239 (Forecasting Loss:0.3208 + XiCon Loss:3.0810 x Lambda(0.001)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.2609
Validation loss decreased (inf --> 0.304202).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2891064
	speed: 0.0157s/iter; left time: 194.1849s
Epoch: 2 cost time: 1.971444845199585
Epoch: 2, Steps: 126 Train Loss: 0.2828 (Forecasting Loss:0.2797 + XiCon Loss:3.0721 x Lambda(0.001)), Vali MSE Loss: 0.2866 Test MSE Loss: 0.2962
Validation loss decreased (0.304202 --> 0.286642).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2201947
	speed: 0.0166s/iter; left time: 203.3024s
Epoch: 3 cost time: 2.0536680221557617
Epoch: 3, Steps: 126 Train Loss: 0.2485 (Forecasting Loss:0.2454 + XiCon Loss:3.0716 x Lambda(0.001)), Vali MSE Loss: 0.3323 Test MSE Loss: 0.3445
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1995886
	speed: 0.0166s/iter; left time: 201.4599s
Epoch: 4 cost time: 2.073455333709717
Epoch: 4, Steps: 126 Train Loss: 0.2288 (Forecasting Loss:0.2257 + XiCon Loss:3.0767 x Lambda(0.001)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.3527
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2071505
	speed: 0.0169s/iter; left time: 202.4547s
Epoch: 5 cost time: 2.099240779876709
Epoch: 5, Steps: 126 Train Loss: 0.2152 (Forecasting Loss:0.2121 + XiCon Loss:3.0816 x Lambda(0.001)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.3473
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2176104
	speed: 0.0181s/iter; left time: 214.6376s
Epoch: 6 cost time: 2.2207024097442627
Epoch: 6, Steps: 126 Train Loss: 0.2098 (Forecasting Loss:0.2067 + XiCon Loss:3.0799 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.3382
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2047040
	speed: 0.0169s/iter; left time: 197.9290s
Epoch: 7 cost time: 2.0764293670654297
Epoch: 7, Steps: 126 Train Loss: 0.2073 (Forecasting Loss:0.2042 + XiCon Loss:3.0771 x Lambda(0.001)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.3403
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2119486
	speed: 0.0172s/iter; left time: 199.3207s
Epoch: 8 cost time: 2.126349687576294
Epoch: 8, Steps: 126 Train Loss: 0.2060 (Forecasting Loss:0.2029 + XiCon Loss:3.0771 x Lambda(0.001)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.3430
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2195991
	speed: 0.0166s/iter; left time: 190.2601s
Epoch: 9 cost time: 2.1101980209350586
Epoch: 9, Steps: 126 Train Loss: 0.2054 (Forecasting Loss:0.2024 + XiCon Loss:3.0774 x Lambda(0.001)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.3439
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2093344
	speed: 0.0170s/iter; left time: 193.6058s
Epoch: 10 cost time: 2.1291611194610596
Epoch: 10, Steps: 126 Train Loss: 0.2052 (Forecasting Loss:0.2021 + XiCon Loss:3.0770 x Lambda(0.001)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.3428
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2080265
	speed: 0.0178s/iter; left time: 200.4861s
Epoch: 11 cost time: 2.2064318656921387
Epoch: 11, Steps: 126 Train Loss: 0.2054 (Forecasting Loss:0.2023 + XiCon Loss:3.0768 x Lambda(0.001)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.3433
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1955958
	speed: 0.0172s/iter; left time: 190.7825s
Epoch: 12 cost time: 2.1299540996551514
Epoch: 12, Steps: 126 Train Loss: 0.2048 (Forecasting Loss:0.2017 + XiCon Loss:3.0772 x Lambda(0.001)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.3426
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.21833668649196625, mae:0.37406793236732483, mape:0.8205609917640686, mspe:22.086057662963867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2135+-0.01818, MAE:0.3709+-0.01461, MAPE:0.7744+-0.07042, MSPE:20.5639+-4.64475, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3963
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3109092
	speed: 0.0204s/iter; left time: 251.2169s
Epoch: 1 cost time: 2.4028983116149902
Epoch: 1, Steps: 124 Train Loss: 0.3426 (Forecasting Loss:0.3396 + XiCon Loss:3.0711 x Lambda(0.001)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2846
Validation loss decreased (inf --> 0.340531).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2482916
	speed: 0.0211s/iter; left time: 256.5156s
Epoch: 2 cost time: 2.595367193222046
Epoch: 2, Steps: 124 Train Loss: 0.2790 (Forecasting Loss:0.2759 + XiCon Loss:3.1034 x Lambda(0.001)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.2939
Validation loss decreased (0.340531 --> 0.297552).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2287757
	speed: 0.0216s/iter; left time: 260.0697s
Epoch: 3 cost time: 2.6337013244628906
Epoch: 3, Steps: 124 Train Loss: 0.2384 (Forecasting Loss:0.2353 + XiCon Loss:3.0840 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.3162
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2355272
	speed: 0.0219s/iter; left time: 261.5592s
Epoch: 4 cost time: 2.674851179122925
Epoch: 4, Steps: 124 Train Loss: 0.2259 (Forecasting Loss:0.2228 + XiCon Loss:3.0750 x Lambda(0.001)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.3119
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2234097
	speed: 0.0214s/iter; left time: 253.1214s
Epoch: 5 cost time: 2.619002342224121
Epoch: 5, Steps: 124 Train Loss: 0.2186 (Forecasting Loss:0.2155 + XiCon Loss:3.0694 x Lambda(0.001)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.3141
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2107681
	speed: 0.0216s/iter; left time: 252.7314s
Epoch: 6 cost time: 2.6404027938842773
Epoch: 6, Steps: 124 Train Loss: 0.2165 (Forecasting Loss:0.2134 + XiCon Loss:3.0672 x Lambda(0.001)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.3158
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2103157
	speed: 0.0217s/iter; left time: 250.2240s
Epoch: 7 cost time: 2.6276590824127197
Epoch: 7, Steps: 124 Train Loss: 0.2151 (Forecasting Loss:0.2120 + XiCon Loss:3.0636 x Lambda(0.001)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.3121
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1956574
	speed: 0.0220s/iter; left time: 252.0284s
Epoch: 8 cost time: 2.7069268226623535
Epoch: 8, Steps: 124 Train Loss: 0.2144 (Forecasting Loss:0.2113 + XiCon Loss:3.0653 x Lambda(0.001)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.3110
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2010012
	speed: 0.0217s/iter; left time: 244.8870s
Epoch: 9 cost time: 2.6724812984466553
Epoch: 9, Steps: 124 Train Loss: 0.2140 (Forecasting Loss:0.2109 + XiCon Loss:3.0650 x Lambda(0.001)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.3116
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2281671
	speed: 0.0215s/iter; left time: 239.9404s
Epoch: 10 cost time: 2.637744665145874
Epoch: 10, Steps: 124 Train Loss: 0.2138 (Forecasting Loss:0.2108 + XiCon Loss:3.0636 x Lambda(0.001)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.3122
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2226529
	speed: 0.0211s/iter; left time: 233.7548s
Epoch: 11 cost time: 2.591463804244995
Epoch: 11, Steps: 124 Train Loss: 0.2135 (Forecasting Loss:0.2104 + XiCon Loss:3.0626 x Lambda(0.001)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.3114
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2052780
	speed: 0.0215s/iter; left time: 235.6007s
Epoch: 12 cost time: 2.639770746231079
Epoch: 12, Steps: 124 Train Loss: 0.2137 (Forecasting Loss:0.2106 + XiCon Loss:3.0664 x Lambda(0.001)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.3121
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.21463237702846527, mae:0.3732292056083679, mape:0.8456659317016602, mspe:26.53569984436035 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3145
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3317086
	speed: 0.0172s/iter; left time: 211.3452s
Epoch: 1 cost time: 2.117068290710449
Epoch: 1, Steps: 124 Train Loss: 0.3380 (Forecasting Loss:0.3349 + XiCon Loss:3.0706 x Lambda(0.001)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2716
Validation loss decreased (inf --> 0.329524).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2718383
	speed: 0.0171s/iter; left time: 208.4375s
Epoch: 2 cost time: 2.0793235301971436
Epoch: 2, Steps: 124 Train Loss: 0.3046 (Forecasting Loss:0.3015 + XiCon Loss:3.0556 x Lambda(0.001)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.2952
Validation loss decreased (0.329524 --> 0.318765).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2280848
	speed: 0.0170s/iter; left time: 204.5069s
Epoch: 3 cost time: 2.0688886642456055
Epoch: 3, Steps: 124 Train Loss: 0.2712 (Forecasting Loss:0.2681 + XiCon Loss:3.0330 x Lambda(0.001)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2622
Validation loss decreased (0.318765 --> 0.304913).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2256883
	speed: 0.0166s/iter; left time: 197.8025s
Epoch: 4 cost time: 2.032362699508667
Epoch: 4, Steps: 124 Train Loss: 0.2449 (Forecasting Loss:0.2418 + XiCon Loss:3.0223 x Lambda(0.001)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2883
Validation loss decreased (0.304913 --> 0.280091).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2194053
	speed: 0.0169s/iter; left time: 200.0113s
Epoch: 5 cost time: 2.085212230682373
Epoch: 5, Steps: 124 Train Loss: 0.2310 (Forecasting Loss:0.2280 + XiCon Loss:3.0168 x Lambda(0.001)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.3105
Validation loss decreased (0.280091 --> 0.274541).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2215903
	speed: 0.0172s/iter; left time: 200.4259s
Epoch: 6 cost time: 2.0903520584106445
Epoch: 6, Steps: 124 Train Loss: 0.2256 (Forecasting Loss:0.2226 + XiCon Loss:3.0139 x Lambda(0.001)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.3284
Validation loss decreased (0.274541 --> 0.274512).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2266463
	speed: 0.0176s/iter; left time: 202.9864s
Epoch: 7 cost time: 2.135218858718872
Epoch: 7, Steps: 124 Train Loss: 0.2231 (Forecasting Loss:0.2201 + XiCon Loss:3.0143 x Lambda(0.001)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.3268
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2148126
	speed: 0.0173s/iter; left time: 197.5224s
Epoch: 8 cost time: 2.0916812419891357
Epoch: 8, Steps: 124 Train Loss: 0.2220 (Forecasting Loss:0.2189 + XiCon Loss:3.0120 x Lambda(0.001)), Vali MSE Loss: 0.2778 Test MSE Loss: 0.3324
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2205479
	speed: 0.0168s/iter; left time: 190.2984s
Epoch: 9 cost time: 2.060169219970703
Epoch: 9, Steps: 124 Train Loss: 0.2215 (Forecasting Loss:0.2185 + XiCon Loss:3.0141 x Lambda(0.001)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.3324
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2118523
	speed: 0.0169s/iter; left time: 189.0090s
Epoch: 10 cost time: 2.098449945449829
Epoch: 10, Steps: 124 Train Loss: 0.2208 (Forecasting Loss:0.2178 + XiCon Loss:3.0143 x Lambda(0.001)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.3360
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2549954
	speed: 0.0176s/iter; left time: 194.6287s
Epoch: 11 cost time: 2.1543612480163574
Epoch: 11, Steps: 124 Train Loss: 0.2210 (Forecasting Loss:0.2180 + XiCon Loss:3.0127 x Lambda(0.001)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.3351
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2301829
	speed: 0.0170s/iter; left time: 185.9101s
Epoch: 12 cost time: 2.066382646560669
Epoch: 12, Steps: 124 Train Loss: 0.2210 (Forecasting Loss:0.2180 + XiCon Loss:3.0150 x Lambda(0.001)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.3361
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2467550
	speed: 0.0164s/iter; left time: 176.9676s
Epoch: 13 cost time: 2.016293525695801
Epoch: 13, Steps: 124 Train Loss: 0.2208 (Forecasting Loss:0.2178 + XiCon Loss:3.0126 x Lambda(0.001)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.3353
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2144077
	speed: 0.0171s/iter; left time: 183.3153s
Epoch: 14 cost time: 2.1088504791259766
Epoch: 14, Steps: 124 Train Loss: 0.2206 (Forecasting Loss:0.2175 + XiCon Loss:3.0130 x Lambda(0.001)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.3354
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2139994
	speed: 0.0168s/iter; left time: 177.5330s
Epoch: 15 cost time: 2.0775249004364014
Epoch: 15, Steps: 124 Train Loss: 0.2207 (Forecasting Loss:0.2177 + XiCon Loss:3.0147 x Lambda(0.001)), Vali MSE Loss: 0.2776 Test MSE Loss: 0.3356
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2352206
	speed: 0.0166s/iter; left time: 173.1945s
Epoch: 16 cost time: 2.0355141162872314
Epoch: 16, Steps: 124 Train Loss: 0.2207 (Forecasting Loss:0.2177 + XiCon Loss:3.0121 x Lambda(0.001)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.3355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.2493942528963089, mae:0.40744584798812866, mape:0.7802561521530151, mspe:17.660717010498047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4029
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2974708
	speed: 0.0174s/iter; left time: 213.4525s
Epoch: 1 cost time: 2.1171622276306152
Epoch: 1, Steps: 124 Train Loss: 0.3407 (Forecasting Loss:0.3377 + XiCon Loss:3.0686 x Lambda(0.001)), Vali MSE Loss: 0.3438 Test MSE Loss: 0.2881
Validation loss decreased (inf --> 0.343819).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2661519
	speed: 0.0170s/iter; left time: 207.3358s
Epoch: 2 cost time: 2.116856575012207
Epoch: 2, Steps: 124 Train Loss: 0.2944 (Forecasting Loss:0.2913 + XiCon Loss:3.0767 x Lambda(0.001)), Vali MSE Loss: 0.3002 Test MSE Loss: 0.2913
Validation loss decreased (0.343819 --> 0.300151).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2352661
	speed: 0.0192s/iter; left time: 231.9248s
Epoch: 3 cost time: 2.375563144683838
Epoch: 3, Steps: 124 Train Loss: 0.2464 (Forecasting Loss:0.2434 + XiCon Loss:3.0637 x Lambda(0.001)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.2784
Validation loss decreased (0.300151 --> 0.292756).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2193899
	speed: 0.0197s/iter; left time: 235.5865s
Epoch: 4 cost time: 2.4330785274505615
Epoch: 4, Steps: 124 Train Loss: 0.2264 (Forecasting Loss:0.2233 + XiCon Loss:3.0542 x Lambda(0.001)), Vali MSE Loss: 0.3010 Test MSE Loss: 0.2694
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2044524
	speed: 0.0204s/iter; left time: 240.5778s
Epoch: 5 cost time: 2.480435609817505
Epoch: 5, Steps: 124 Train Loss: 0.2184 (Forecasting Loss:0.2153 + XiCon Loss:3.0501 x Lambda(0.001)), Vali MSE Loss: 0.2962 Test MSE Loss: 0.2782
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2127919
	speed: 0.0204s/iter; left time: 238.6361s
Epoch: 6 cost time: 2.4853434562683105
Epoch: 6, Steps: 124 Train Loss: 0.2146 (Forecasting Loss:0.2115 + XiCon Loss:3.0505 x Lambda(0.001)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.2817
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2241728
	speed: 0.0208s/iter; left time: 239.8593s
Epoch: 7 cost time: 2.5487284660339355
Epoch: 7, Steps: 124 Train Loss: 0.2127 (Forecasting Loss:0.2097 + XiCon Loss:3.0515 x Lambda(0.001)), Vali MSE Loss: 0.3012 Test MSE Loss: 0.2816
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2224154
	speed: 0.0212s/iter; left time: 241.8515s
Epoch: 8 cost time: 2.5698442459106445
Epoch: 8, Steps: 124 Train Loss: 0.2119 (Forecasting Loss:0.2089 + XiCon Loss:3.0503 x Lambda(0.001)), Vali MSE Loss: 0.3012 Test MSE Loss: 0.2836
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2105811
	speed: 0.0213s/iter; left time: 240.5295s
Epoch: 9 cost time: 2.598778009414673
Epoch: 9, Steps: 124 Train Loss: 0.2115 (Forecasting Loss:0.2085 + XiCon Loss:3.0483 x Lambda(0.001)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.2824
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2101384
	speed: 0.0208s/iter; left time: 232.6147s
Epoch: 10 cost time: 2.5310983657836914
Epoch: 10, Steps: 124 Train Loss: 0.2110 (Forecasting Loss:0.2080 + XiCon Loss:3.0498 x Lambda(0.001)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2829
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2113041
	speed: 0.0210s/iter; left time: 231.8403s
Epoch: 11 cost time: 2.5430474281311035
Epoch: 11, Steps: 124 Train Loss: 0.2111 (Forecasting Loss:0.2080 + XiCon Loss:3.0497 x Lambda(0.001)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.2823
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2021606
	speed: 0.0210s/iter; left time: 229.4262s
Epoch: 12 cost time: 2.5584356784820557
Epoch: 12, Steps: 124 Train Loss: 0.2109 (Forecasting Loss:0.2078 + XiCon Loss:3.0506 x Lambda(0.001)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.2823
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2177689
	speed: 0.0202s/iter; left time: 218.2804s
Epoch: 13 cost time: 2.5143978595733643
Epoch: 13, Steps: 124 Train Loss: 0.2109 (Forecasting Loss:0.2079 + XiCon Loss:3.0472 x Lambda(0.001)), Vali MSE Loss: 0.2986 Test MSE Loss: 0.2826
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19534575939178467, mae:0.3615209460258484, mape:0.8710139393806458, mspe:28.47648811340332 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3363
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3238989
	speed: 0.0182s/iter; left time: 224.4857s
Epoch: 1 cost time: 2.2308876514434814
Epoch: 1, Steps: 124 Train Loss: 0.3374 (Forecasting Loss:0.3344 + XiCon Loss:3.0572 x Lambda(0.001)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.2752
Validation loss decreased (inf --> 0.330555).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3155858
	speed: 0.0178s/iter; left time: 216.2418s
Epoch: 2 cost time: 2.1516761779785156
Epoch: 2, Steps: 124 Train Loss: 0.2947 (Forecasting Loss:0.2916 + XiCon Loss:3.0616 x Lambda(0.001)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.3011
Validation loss decreased (0.330555 --> 0.322333).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2521653
	speed: 0.0168s/iter; left time: 202.6605s
Epoch: 3 cost time: 2.044389247894287
Epoch: 3, Steps: 124 Train Loss: 0.2550 (Forecasting Loss:0.2520 + XiCon Loss:3.0461 x Lambda(0.001)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2783
Validation loss decreased (0.322333 --> 0.280100).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2203319
	speed: 0.0171s/iter; left time: 203.7471s
Epoch: 4 cost time: 2.1125993728637695
Epoch: 4, Steps: 124 Train Loss: 0.2329 (Forecasting Loss:0.2299 + XiCon Loss:3.0267 x Lambda(0.001)), Vali MSE Loss: 0.2691 Test MSE Loss: 0.2868
Validation loss decreased (0.280100 --> 0.269107).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2026743
	speed: 0.0170s/iter; left time: 200.8065s
Epoch: 5 cost time: 2.094395875930786
Epoch: 5, Steps: 124 Train Loss: 0.2258 (Forecasting Loss:0.2227 + XiCon Loss:3.0230 x Lambda(0.001)), Vali MSE Loss: 0.2760 Test MSE Loss: 0.2932
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1958975
	speed: 0.0166s/iter; left time: 194.1198s
Epoch: 6 cost time: 2.05204701423645
Epoch: 6, Steps: 124 Train Loss: 0.2216 (Forecasting Loss:0.2186 + XiCon Loss:3.0212 x Lambda(0.001)), Vali MSE Loss: 0.2714 Test MSE Loss: 0.2873
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2196227
	speed: 0.0174s/iter; left time: 200.6755s
Epoch: 7 cost time: 2.10597562789917
Epoch: 7, Steps: 124 Train Loss: 0.2198 (Forecasting Loss:0.2167 + XiCon Loss:3.0217 x Lambda(0.001)), Vali MSE Loss: 0.2729 Test MSE Loss: 0.2834
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2364516
	speed: 0.0167s/iter; left time: 190.4733s
Epoch: 8 cost time: 2.059302806854248
Epoch: 8, Steps: 124 Train Loss: 0.2186 (Forecasting Loss:0.2156 + XiCon Loss:3.0196 x Lambda(0.001)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2859
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2374150
	speed: 0.0169s/iter; left time: 191.6407s
Epoch: 9 cost time: 2.0963199138641357
Epoch: 9, Steps: 124 Train Loss: 0.2182 (Forecasting Loss:0.2152 + XiCon Loss:3.0211 x Lambda(0.001)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.2884
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2254899
	speed: 0.0165s/iter; left time: 184.4952s
Epoch: 10 cost time: 2.0173439979553223
Epoch: 10, Steps: 124 Train Loss: 0.2179 (Forecasting Loss:0.2149 + XiCon Loss:3.0195 x Lambda(0.001)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.2887
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2127425
	speed: 0.0173s/iter; left time: 191.5597s
Epoch: 11 cost time: 2.103693723678589
Epoch: 11, Steps: 124 Train Loss: 0.2179 (Forecasting Loss:0.2149 + XiCon Loss:3.0188 x Lambda(0.001)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.2896
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2223464
	speed: 0.0169s/iter; left time: 184.4497s
Epoch: 12 cost time: 2.0540263652801514
Epoch: 12, Steps: 124 Train Loss: 0.2176 (Forecasting Loss:0.2146 + XiCon Loss:3.0197 x Lambda(0.001)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2885
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2143023
	speed: 0.0176s/iter; left time: 189.8019s
Epoch: 13 cost time: 2.1316440105438232
Epoch: 13, Steps: 124 Train Loss: 0.2176 (Forecasting Loss:0.2146 + XiCon Loss:3.0183 x Lambda(0.001)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2888
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2072931
	speed: 0.0175s/iter; left time: 186.6641s
Epoch: 14 cost time: 2.1153879165649414
Epoch: 14, Steps: 124 Train Loss: 0.2177 (Forecasting Loss:0.2147 + XiCon Loss:3.0199 x Lambda(0.001)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.2888
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.20546063780784607, mae:0.3681958019733429, mape:0.7122289538383484, mspe:15.479300498962402 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3231
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2923203
	speed: 0.0177s/iter; left time: 217.3902s
Epoch: 1 cost time: 2.147564172744751
Epoch: 1, Steps: 124 Train Loss: 0.3383 (Forecasting Loss:0.3352 + XiCon Loss:3.0682 x Lambda(0.001)), Vali MSE Loss: 0.3432 Test MSE Loss: 0.2834
Validation loss decreased (inf --> 0.343218).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2704711
	speed: 0.0197s/iter; left time: 240.2859s
Epoch: 2 cost time: 2.4536969661712646
Epoch: 2, Steps: 124 Train Loss: 0.2820 (Forecasting Loss:0.2789 + XiCon Loss:3.0650 x Lambda(0.001)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.3356
Validation loss decreased (0.343218 --> 0.281485).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2423324
	speed: 0.0212s/iter; left time: 256.1000s
Epoch: 3 cost time: 2.5858476161956787
Epoch: 3, Steps: 124 Train Loss: 0.2393 (Forecasting Loss:0.2363 + XiCon Loss:3.0509 x Lambda(0.001)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.3666
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2243969
	speed: 0.0210s/iter; left time: 250.0510s
Epoch: 4 cost time: 2.5712883472442627
Epoch: 4, Steps: 124 Train Loss: 0.2235 (Forecasting Loss:0.2205 + XiCon Loss:3.0491 x Lambda(0.001)), Vali MSE Loss: 0.3510 Test MSE Loss: 0.3525
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2033421
	speed: 0.0212s/iter; left time: 249.9167s
Epoch: 5 cost time: 2.577399730682373
Epoch: 5, Steps: 124 Train Loss: 0.2177 (Forecasting Loss:0.2146 + XiCon Loss:3.0474 x Lambda(0.001)), Vali MSE Loss: 0.3478 Test MSE Loss: 0.3622
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2121862
	speed: 0.0209s/iter; left time: 243.8468s
Epoch: 6 cost time: 2.585066318511963
Epoch: 6, Steps: 124 Train Loss: 0.2148 (Forecasting Loss:0.2117 + XiCon Loss:3.0495 x Lambda(0.001)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.3706
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2108706
	speed: 0.0210s/iter; left time: 242.3445s
Epoch: 7 cost time: 2.582031011581421
Epoch: 7, Steps: 124 Train Loss: 0.2133 (Forecasting Loss:0.2102 + XiCon Loss:3.0488 x Lambda(0.001)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.3619
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2009304
	speed: 0.0210s/iter; left time: 240.4846s
Epoch: 8 cost time: 2.5486948490142822
Epoch: 8, Steps: 124 Train Loss: 0.2127 (Forecasting Loss:0.2096 + XiCon Loss:3.0477 x Lambda(0.001)), Vali MSE Loss: 0.3595 Test MSE Loss: 0.3682
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2204459
	speed: 0.0211s/iter; left time: 238.2439s
Epoch: 9 cost time: 2.598214626312256
Epoch: 9, Steps: 124 Train Loss: 0.2122 (Forecasting Loss:0.2091 + XiCon Loss:3.0479 x Lambda(0.001)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.3680
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2096149
	speed: 0.0209s/iter; left time: 234.0609s
Epoch: 10 cost time: 2.552274703979492
Epoch: 10, Steps: 124 Train Loss: 0.2122 (Forecasting Loss:0.2091 + XiCon Loss:3.0497 x Lambda(0.001)), Vali MSE Loss: 0.3594 Test MSE Loss: 0.3657
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2198205
	speed: 0.0202s/iter; left time: 223.8114s
Epoch: 11 cost time: 2.488736629486084
Epoch: 11, Steps: 124 Train Loss: 0.2119 (Forecasting Loss:0.2089 + XiCon Loss:3.0498 x Lambda(0.001)), Vali MSE Loss: 0.3597 Test MSE Loss: 0.3679
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2171025
	speed: 0.0203s/iter; left time: 222.2014s
Epoch: 12 cost time: 2.4706366062164307
Epoch: 12, Steps: 124 Train Loss: 0.2119 (Forecasting Loss:0.2089 + XiCon Loss:3.0506 x Lambda(0.001)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.3673
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.2675122320652008, mae:0.40360137820243835, mape:0.8253010511398315, mspe:23.76166343688965 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2265+-0.03807, MAE:0.3828+-0.02632, MAPE:0.8069+-0.07760, MSPE:22.3828+-6.97538, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3879
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4554065
	speed: 0.0207s/iter; left time: 242.7064s
Epoch: 1 cost time: 2.3495655059814453
Epoch: 1, Steps: 118 Train Loss: 0.4767 (Forecasting Loss:0.4736 + XiCon Loss:3.1504 x Lambda(0.001)), Vali MSE Loss: 0.4757 Test MSE Loss: 0.3612
Validation loss decreased (inf --> 0.475684).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3712719
	speed: 0.0170s/iter; left time: 197.0978s
Epoch: 2 cost time: 1.9891939163208008
Epoch: 2, Steps: 118 Train Loss: 0.3498 (Forecasting Loss:0.3466 + XiCon Loss:3.1494 x Lambda(0.001)), Vali MSE Loss: 0.3779 Test MSE Loss: 0.2872
Validation loss decreased (0.475684 --> 0.377945).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3064533
	speed: 0.0175s/iter; left time: 201.1391s
Epoch: 3 cost time: 2.0489935874938965
Epoch: 3, Steps: 118 Train Loss: 0.3136 (Forecasting Loss:0.3104 + XiCon Loss:3.1476 x Lambda(0.001)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.2778
Validation loss decreased (0.377945 --> 0.373654).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3192959
	speed: 0.0175s/iter; left time: 198.8890s
Epoch: 4 cost time: 2.0522520542144775
Epoch: 4, Steps: 118 Train Loss: 0.3087 (Forecasting Loss:0.3056 + XiCon Loss:3.1442 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2798
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3113033
	speed: 0.0173s/iter; left time: 193.7589s
Epoch: 5 cost time: 2.027881145477295
Epoch: 5, Steps: 118 Train Loss: 0.3066 (Forecasting Loss:0.3034 + XiCon Loss:3.1429 x Lambda(0.001)), Vali MSE Loss: 0.3832 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2907207
	speed: 0.0183s/iter; left time: 202.9530s
Epoch: 6 cost time: 2.137000322341919
Epoch: 6, Steps: 118 Train Loss: 0.3055 (Forecasting Loss:0.3023 + XiCon Loss:3.1451 x Lambda(0.001)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.2802
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3088582
	speed: 0.0171s/iter; left time: 187.6178s
Epoch: 7 cost time: 1.99853515625
Epoch: 7, Steps: 118 Train Loss: 0.3056 (Forecasting Loss:0.3025 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2805
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2895609
	speed: 0.0176s/iter; left time: 190.8965s
Epoch: 8 cost time: 2.0558393001556396
Epoch: 8, Steps: 118 Train Loss: 0.3046 (Forecasting Loss:0.3015 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.3755 Test MSE Loss: 0.2807
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3028466
	speed: 0.0179s/iter; left time: 192.6946s
Epoch: 9 cost time: 2.0947744846343994
Epoch: 9, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.1447 x Lambda(0.001)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.2808
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3064210
	speed: 0.0176s/iter; left time: 186.9179s
Epoch: 10 cost time: 2.0429248809814453
Epoch: 10, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.1450 x Lambda(0.001)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.2808
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2957939
	speed: 0.0172s/iter; left time: 181.1802s
Epoch: 11 cost time: 2.0332281589508057
Epoch: 11, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.1453 x Lambda(0.001)), Vali MSE Loss: 0.3765 Test MSE Loss: 0.2808
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3164936
	speed: 0.0178s/iter; left time: 185.3742s
Epoch: 12 cost time: 2.0746219158172607
Epoch: 12, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.1465 x Lambda(0.001)), Vali MSE Loss: 0.3770 Test MSE Loss: 0.2808
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2932846
	speed: 0.0173s/iter; left time: 177.9289s
Epoch: 13 cost time: 2.029726266860962
Epoch: 13, Steps: 118 Train Loss: 0.3046 (Forecasting Loss:0.3014 + XiCon Loss:3.1432 x Lambda(0.001)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2808
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19793017208576202, mae:0.3575896918773651, mape:0.6932328939437866, mspe:23.380695343017578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3204
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4365933
	speed: 0.0177s/iter; left time: 206.9947s
Epoch: 1 cost time: 2.05294132232666
Epoch: 1, Steps: 118 Train Loss: 0.4717 (Forecasting Loss:0.4685 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.4889 Test MSE Loss: 0.3764
Validation loss decreased (inf --> 0.488925).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3001639
	speed: 0.0172s/iter; left time: 199.4099s
Epoch: 2 cost time: 2.014683246612549
Epoch: 2, Steps: 118 Train Loss: 0.3484 (Forecasting Loss:0.3453 + XiCon Loss:3.1622 x Lambda(0.001)), Vali MSE Loss: 0.3579 Test MSE Loss: 0.2695
Validation loss decreased (0.488925 --> 0.357851).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2869036
	speed: 0.0186s/iter; left time: 213.0801s
Epoch: 3 cost time: 2.1867923736572266
Epoch: 3, Steps: 118 Train Loss: 0.2813 (Forecasting Loss:0.2782 + XiCon Loss:3.1625 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2673
Validation loss decreased (0.357851 --> 0.315689).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2612299
	speed: 0.0181s/iter; left time: 204.9024s
Epoch: 4 cost time: 2.1236555576324463
Epoch: 4, Steps: 118 Train Loss: 0.2714 (Forecasting Loss:0.2682 + XiCon Loss:3.1564 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2658
Validation loss decreased (0.315689 --> 0.311984).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2670114
	speed: 0.0184s/iter; left time: 206.1643s
Epoch: 5 cost time: 2.1432924270629883
Epoch: 5, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2652 + XiCon Loss:3.1518 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2559900
	speed: 0.0188s/iter; left time: 209.2466s
Epoch: 6 cost time: 2.1918442249298096
Epoch: 6, Steps: 118 Train Loss: 0.2669 (Forecasting Loss:0.2637 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2678
Validation loss decreased (0.311984 --> 0.311331).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2712147
	speed: 0.0191s/iter; left time: 209.6336s
Epoch: 7 cost time: 2.2182209491729736
Epoch: 7, Steps: 118 Train Loss: 0.2661 (Forecasting Loss:0.2629 + XiCon Loss:3.1481 x Lambda(0.001)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2566866
	speed: 0.0191s/iter; left time: 208.1868s
Epoch: 8 cost time: 2.2198967933654785
Epoch: 8, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1482 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2516559
	speed: 0.0189s/iter; left time: 202.8267s
Epoch: 9 cost time: 2.188626766204834
Epoch: 9, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2626 + XiCon Loss:3.1480 x Lambda(0.001)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2676
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2709889
	speed: 0.0192s/iter; left time: 204.2926s
Epoch: 10 cost time: 2.246145725250244
Epoch: 10, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1470 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2758247
	speed: 0.0190s/iter; left time: 199.7743s
Epoch: 11 cost time: 2.204193115234375
Epoch: 11, Steps: 118 Train Loss: 0.2654 (Forecasting Loss:0.2623 + XiCon Loss:3.1477 x Lambda(0.001)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2581068
	speed: 0.0191s/iter; left time: 198.5507s
Epoch: 12 cost time: 2.2349207401275635
Epoch: 12, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1493 x Lambda(0.001)), Vali MSE Loss: 0.3137 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2824830
	speed: 0.0196s/iter; left time: 201.4638s
Epoch: 13 cost time: 2.277316093444824
Epoch: 13, Steps: 118 Train Loss: 0.2653 (Forecasting Loss:0.2622 + XiCon Loss:3.1487 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.2680
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2551371
	speed: 0.0194s/iter; left time: 196.7337s
Epoch: 14 cost time: 2.2606542110443115
Epoch: 14, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1476 x Lambda(0.001)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.2680
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2687682
	speed: 0.0187s/iter; left time: 188.1976s
Epoch: 15 cost time: 2.2077434062957764
Epoch: 15, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2623 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2608399
	speed: 0.0186s/iter; left time: 184.4117s
Epoch: 16 cost time: 2.18564772605896
Epoch: 16, Steps: 118 Train Loss: 0.2652 (Forecasting Loss:0.2621 + XiCon Loss:3.1475 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.186104416847229, mae:0.34956371784210205, mape:0.6736178994178772, mspe:18.202117919921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3464
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4507805
	speed: 0.0184s/iter; left time: 215.1645s
Epoch: 1 cost time: 2.1621408462524414
Epoch: 1, Steps: 118 Train Loss: 0.4724 (Forecasting Loss:0.4693 + XiCon Loss:3.1462 x Lambda(0.001)), Vali MSE Loss: 0.4768 Test MSE Loss: 0.3596
Validation loss decreased (inf --> 0.476795).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.2846947
	speed: 0.0176s/iter; left time: 203.7386s
Epoch: 2 cost time: 2.0888924598693848
Epoch: 2, Steps: 118 Train Loss: 0.3436 (Forecasting Loss:0.3404 + XiCon Loss:3.1175 x Lambda(0.001)), Vali MSE Loss: 0.3618 Test MSE Loss: 0.2610
Validation loss decreased (0.476795 --> 0.361822).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2800852
	speed: 0.0204s/iter; left time: 233.7827s
Epoch: 3 cost time: 2.3814094066619873
Epoch: 3, Steps: 118 Train Loss: 0.2830 (Forecasting Loss:0.2799 + XiCon Loss:3.0888 x Lambda(0.001)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2590
Validation loss decreased (0.361822 --> 0.338566).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2749482
	speed: 0.0206s/iter; left time: 233.4982s
Epoch: 4 cost time: 2.4081294536590576
Epoch: 4, Steps: 118 Train Loss: 0.2753 (Forecasting Loss:0.2722 + XiCon Loss:3.0826 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2585
Validation loss decreased (0.338566 --> 0.318332).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2665918
	speed: 0.0206s/iter; left time: 231.7113s
Epoch: 5 cost time: 2.4202089309692383
Epoch: 5, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.0781 x Lambda(0.001)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.2578
Validation loss decreased (0.318332 --> 0.314897).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2838763
	speed: 0.0203s/iter; left time: 225.9636s
Epoch: 6 cost time: 2.3837058544158936
Epoch: 6, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2673 + XiCon Loss:3.0759 x Lambda(0.001)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.2593
Validation loss decreased (0.314897 --> 0.313393).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2653637
	speed: 0.0210s/iter; left time: 231.2775s
Epoch: 7 cost time: 2.4428915977478027
Epoch: 7, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2665 + XiCon Loss:3.0756 x Lambda(0.001)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2586
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2600766
	speed: 0.0200s/iter; left time: 217.6889s
Epoch: 8 cost time: 2.4077961444854736
Epoch: 8, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2661 + XiCon Loss:3.0728 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2757599
	speed: 0.0199s/iter; left time: 213.9881s
Epoch: 9 cost time: 2.3359568119049072
Epoch: 9, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2662 + XiCon Loss:3.0741 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2676319
	speed: 0.0207s/iter; left time: 220.0146s
Epoch: 10 cost time: 2.4311089515686035
Epoch: 10, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2658 + XiCon Loss:3.0739 x Lambda(0.001)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2594
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2744607
	speed: 0.0208s/iter; left time: 219.2189s
Epoch: 11 cost time: 2.4249539375305176
Epoch: 11, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2660 + XiCon Loss:3.0730 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2594
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2780262
	speed: 0.0206s/iter; left time: 213.8311s
Epoch: 12 cost time: 2.419724464416504
Epoch: 12, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2657 + XiCon Loss:3.0713 x Lambda(0.001)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2594
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3100964
	speed: 0.0209s/iter; left time: 214.7400s
Epoch: 13 cost time: 2.4595041275024414
Epoch: 13, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2659 + XiCon Loss:3.0729 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2594
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2490345
	speed: 0.0203s/iter; left time: 206.2236s
Epoch: 14 cost time: 2.370028018951416
Epoch: 14, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0735 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2732109
	speed: 0.0203s/iter; left time: 204.0039s
Epoch: 15 cost time: 2.3908615112304688
Epoch: 15, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0747 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2890851
	speed: 0.0202s/iter; left time: 200.4047s
Epoch: 16 cost time: 2.3672399520874023
Epoch: 16, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0744 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17643332481384277, mae:0.34208643436431885, mape:0.6958777904510498, mspe:21.348543167114258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3193
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4674888
	speed: 0.0183s/iter; left time: 214.2988s
Epoch: 1 cost time: 2.123453378677368
Epoch: 1, Steps: 118 Train Loss: 0.4995 (Forecasting Loss:0.4964 + XiCon Loss:3.1492 x Lambda(0.001)), Vali MSE Loss: 0.5422 Test MSE Loss: 0.4452
Validation loss decreased (inf --> 0.542249).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3096410
	speed: 0.0179s/iter; left time: 207.7473s
Epoch: 2 cost time: 2.0851926803588867
Epoch: 2, Steps: 118 Train Loss: 0.3703 (Forecasting Loss:0.3671 + XiCon Loss:3.1499 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2744
Validation loss decreased (0.542249 --> 0.358910).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2780795
	speed: 0.0196s/iter; left time: 225.2691s
Epoch: 3 cost time: 2.296396255493164
Epoch: 3, Steps: 118 Train Loss: 0.2913 (Forecasting Loss:0.2882 + XiCon Loss:3.1609 x Lambda(0.001)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2682
Validation loss decreased (0.358910 --> 0.326726).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2773181
	speed: 0.0199s/iter; left time: 225.6284s
Epoch: 4 cost time: 2.3238959312438965
Epoch: 4, Steps: 118 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.1638 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2660
Validation loss decreased (0.326726 --> 0.322232).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2734492
	speed: 0.0197s/iter; left time: 220.7714s
Epoch: 5 cost time: 2.32768177986145
Epoch: 5, Steps: 118 Train Loss: 0.2715 (Forecasting Loss:0.2683 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.3174 Test MSE Loss: 0.2655
Validation loss decreased (0.322232 --> 0.317377).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2611406
	speed: 0.0199s/iter; left time: 221.5657s
Epoch: 6 cost time: 2.3394739627838135
Epoch: 6, Steps: 118 Train Loss: 0.2699 (Forecasting Loss:0.2667 + XiCon Loss:3.1579 x Lambda(0.001)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2836235
	speed: 0.0201s/iter; left time: 221.1811s
Epoch: 7 cost time: 2.3513705730438232
Epoch: 7, Steps: 118 Train Loss: 0.2686 (Forecasting Loss:0.2655 + XiCon Loss:3.1599 x Lambda(0.001)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2651
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2594902
	speed: 0.0199s/iter; left time: 216.5671s
Epoch: 8 cost time: 2.3555421829223633
Epoch: 8, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2651 + XiCon Loss:3.1600 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2582529
	speed: 0.0205s/iter; left time: 220.7837s
Epoch: 9 cost time: 2.402754783630371
Epoch: 9, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2648 + XiCon Loss:3.1585 x Lambda(0.001)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2525959
	speed: 0.0204s/iter; left time: 216.8948s
Epoch: 10 cost time: 2.4073870182037354
Epoch: 10, Steps: 118 Train Loss: 0.2678 (Forecasting Loss:0.2646 + XiCon Loss:3.1591 x Lambda(0.001)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2807141
	speed: 0.0204s/iter; left time: 215.0247s
Epoch: 11 cost time: 2.3803017139434814
Epoch: 11, Steps: 118 Train Loss: 0.2677 (Forecasting Loss:0.2645 + XiCon Loss:3.1570 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2637901
	speed: 0.0200s/iter; left time: 207.9711s
Epoch: 12 cost time: 2.3576881885528564
Epoch: 12, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2649 + XiCon Loss:3.1576 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2652276
	speed: 0.0195s/iter; left time: 200.8135s
Epoch: 13 cost time: 2.2899234294891357
Epoch: 13, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2647 + XiCon Loss:3.1572 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2664698
	speed: 0.0202s/iter; left time: 204.9333s
Epoch: 14 cost time: 2.3836116790771484
Epoch: 14, Steps: 118 Train Loss: 0.2681 (Forecasting Loss:0.2650 + XiCon Loss:3.1566 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2561431
	speed: 0.0203s/iter; left time: 203.5790s
Epoch: 15 cost time: 2.363919973373413
Epoch: 15, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2648 + XiCon Loss:3.1596 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18284490704536438, mae:0.34813329577445984, mape:0.7116622924804688, mspe:20.31229019165039 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4438057
	speed: 0.0182s/iter; left time: 212.5338s
Epoch: 1 cost time: 2.1282944679260254
Epoch: 1, Steps: 118 Train Loss: 0.4780 (Forecasting Loss:0.4748 + XiCon Loss:3.1799 x Lambda(0.001)), Vali MSE Loss: 0.5074 Test MSE Loss: 0.4006
Validation loss decreased (inf --> 0.507354).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3169235
	speed: 0.0173s/iter; left time: 200.3360s
Epoch: 2 cost time: 2.036515712738037
Epoch: 2, Steps: 118 Train Loss: 0.3506 (Forecasting Loss:0.3475 + XiCon Loss:3.1635 x Lambda(0.001)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.2702
Validation loss decreased (0.507354 --> 0.351474).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2703553
	speed: 0.0175s/iter; left time: 200.9447s
Epoch: 3 cost time: 2.075622081756592
Epoch: 3, Steps: 118 Train Loss: 0.2854 (Forecasting Loss:0.2822 + XiCon Loss:3.1208 x Lambda(0.001)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2723
Validation loss decreased (0.351474 --> 0.327559).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2672113
	speed: 0.0171s/iter; left time: 194.3608s
Epoch: 4 cost time: 2.0024256706237793
Epoch: 4, Steps: 118 Train Loss: 0.2774 (Forecasting Loss:0.2743 + XiCon Loss:3.1168 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2662
Validation loss decreased (0.327559 --> 0.319456).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2879466
	speed: 0.0181s/iter; left time: 202.6984s
Epoch: 5 cost time: 2.098933696746826
Epoch: 5, Steps: 118 Train Loss: 0.2744 (Forecasting Loss:0.2713 + XiCon Loss:3.1155 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.2611
Validation loss decreased (0.319456 --> 0.317553).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2724699
	speed: 0.0182s/iter; left time: 202.0304s
Epoch: 6 cost time: 2.1106700897216797
Epoch: 6, Steps: 118 Train Loss: 0.2734 (Forecasting Loss:0.2703 + XiCon Loss:3.1161 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2617
Validation loss decreased (0.317553 --> 0.316888).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2807164
	speed: 0.0173s/iter; left time: 189.7481s
Epoch: 7 cost time: 2.011423110961914
Epoch: 7, Steps: 118 Train Loss: 0.2726 (Forecasting Loss:0.2694 + XiCon Loss:3.1147 x Lambda(0.001)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2604
Validation loss decreased (0.316888 --> 0.316681).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2458611
	speed: 0.0182s/iter; left time: 198.1837s
Epoch: 8 cost time: 2.117344617843628
Epoch: 8, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1145 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2596
Validation loss decreased (0.316681 --> 0.315233).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2666704
	speed: 0.0175s/iter; left time: 188.2790s
Epoch: 9 cost time: 2.037371873855591
Epoch: 9, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1144 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2599
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2874802
	speed: 0.0178s/iter; left time: 188.8836s
Epoch: 10 cost time: 2.1158502101898193
Epoch: 10, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1159 x Lambda(0.001)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2599
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2521877
	speed: 0.0179s/iter; left time: 187.9691s
Epoch: 11 cost time: 2.0843870639801025
Epoch: 11, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2690 + XiCon Loss:3.1159 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2598
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2675732
	speed: 0.0179s/iter; left time: 185.8895s
Epoch: 12 cost time: 2.075972080230713
Epoch: 12, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.1147 x Lambda(0.001)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2598
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2423994
	speed: 0.0179s/iter; left time: 183.6654s
Epoch: 13 cost time: 2.0846002101898193
Epoch: 13, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.1154 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2774287
	speed: 0.0174s/iter; left time: 177.2616s
Epoch: 14 cost time: 2.035147190093994
Epoch: 14, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.1130 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2598
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2705584
	speed: 0.0180s/iter; left time: 181.1750s
Epoch: 15 cost time: 2.108107089996338
Epoch: 15, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1161 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.2598
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2600011
	speed: 0.0176s/iter; left time: 175.1446s
Epoch: 16 cost time: 2.0499320030212402
Epoch: 16, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1145 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2598
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2623484
	speed: 0.0174s/iter; left time: 170.8259s
Epoch: 17 cost time: 2.031759262084961
Epoch: 17, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1172 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2893268
	speed: 0.0173s/iter; left time: 167.8824s
Epoch: 18 cost time: 2.0323915481567383
Epoch: 18, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.1142 x Lambda(0.001)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.2598
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17702071368694305, mae:0.3422482907772064, mape:0.7658515572547913, mspe:23.96337127685547 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1841+-0.01086, MAE:0.3479+-0.00791, MAPE:0.7080+-0.04349, MSPE:21.4414+-2.90518, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5440
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1588914
	speed: 0.0426s/iter; left time: 1129.0161s
	iters: 200, epoch: 1 | loss: 0.1437905
	speed: 0.0366s/iter; left time: 966.4729s
Epoch: 1 cost time: 10.34729266166687
Epoch: 1, Steps: 266 Train Loss: 0.1677 (Forecasting Loss:0.1643 + XiCon Loss:3.3670 x Lambda(0.001)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0779
Validation loss decreased (inf --> 0.115162).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1492434
	speed: 0.0390s/iter; left time: 1021.9026s
	iters: 200, epoch: 2 | loss: 0.1370208
	speed: 0.0368s/iter; left time: 961.3425s
Epoch: 2 cost time: 10.013827562332153
Epoch: 2, Steps: 266 Train Loss: 0.1495 (Forecasting Loss:0.1461 + XiCon Loss:3.3600 x Lambda(0.001)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.0789
Validation loss decreased (0.115162 --> 0.113861).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1252748
	speed: 0.0395s/iter; left time: 1027.0622s
	iters: 200, epoch: 3 | loss: 0.1320394
	speed: 0.0375s/iter; left time: 970.7048s
Epoch: 3 cost time: 10.228590488433838
Epoch: 3, Steps: 266 Train Loss: 0.1301 (Forecasting Loss:0.1268 + XiCon Loss:3.3357 x Lambda(0.001)), Vali MSE Loss: 0.1168 Test MSE Loss: 0.0881
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.0956852
	speed: 0.0401s/iter; left time: 1029.9201s
	iters: 200, epoch: 4 | loss: 0.1077003
	speed: 0.0381s/iter; left time: 974.2609s
Epoch: 4 cost time: 10.298836469650269
Epoch: 4, Steps: 266 Train Loss: 0.1085 (Forecasting Loss:0.1052 + XiCon Loss:3.3251 x Lambda(0.001)), Vali MSE Loss: 0.1265 Test MSE Loss: 0.0969
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0986914
	speed: 0.0399s/iter; left time: 1014.5128s
	iters: 200, epoch: 5 | loss: 0.0917522
	speed: 0.0385s/iter; left time: 974.7869s
Epoch: 5 cost time: 10.345506191253662
Epoch: 5, Steps: 266 Train Loss: 0.0958 (Forecasting Loss:0.0925 + XiCon Loss:3.3233 x Lambda(0.001)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.1004
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0997913
	speed: 0.0404s/iter; left time: 1017.9812s
	iters: 200, epoch: 6 | loss: 0.0921254
	speed: 0.0386s/iter; left time: 968.7121s
Epoch: 6 cost time: 10.400989770889282
Epoch: 6, Steps: 266 Train Loss: 0.0902 (Forecasting Loss:0.0869 + XiCon Loss:3.3212 x Lambda(0.001)), Vali MSE Loss: 0.1299 Test MSE Loss: 0.1011
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0906238
	speed: 0.0407s/iter; left time: 1013.0873s
	iters: 200, epoch: 7 | loss: 0.0842307
	speed: 0.0380s/iter; left time: 941.7999s
Epoch: 7 cost time: 10.433812856674194
Epoch: 7, Steps: 266 Train Loss: 0.0878 (Forecasting Loss:0.0845 + XiCon Loss:3.3199 x Lambda(0.001)), Vali MSE Loss: 0.1314 Test MSE Loss: 0.1023
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0886996
	speed: 0.0395s/iter; left time: 973.4434s
	iters: 200, epoch: 8 | loss: 0.0895775
	speed: 0.0381s/iter; left time: 935.3773s
Epoch: 8 cost time: 10.345076322555542
Epoch: 8, Steps: 266 Train Loss: 0.0866 (Forecasting Loss:0.0833 + XiCon Loss:3.3210 x Lambda(0.001)), Vali MSE Loss: 0.1313 Test MSE Loss: 0.1024
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0821705
	speed: 0.0404s/iter; left time: 985.3648s
	iters: 200, epoch: 9 | loss: 0.0872634
	speed: 0.0390s/iter; left time: 945.9157s
Epoch: 9 cost time: 10.46619725227356
Epoch: 9, Steps: 266 Train Loss: 0.0860 (Forecasting Loss:0.0827 + XiCon Loss:3.3199 x Lambda(0.001)), Vali MSE Loss: 0.1320 Test MSE Loss: 0.1028
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0771963
	speed: 0.0405s/iter; left time: 975.9461s
	iters: 200, epoch: 10 | loss: 0.0864812
	speed: 0.0375s/iter; left time: 900.7279s
Epoch: 10 cost time: 10.275243043899536
Epoch: 10, Steps: 266 Train Loss: 0.0858 (Forecasting Loss:0.0825 + XiCon Loss:3.3215 x Lambda(0.001)), Vali MSE Loss: 0.1323 Test MSE Loss: 0.1027
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0859421
	speed: 0.0406s/iter; left time: 967.0764s
	iters: 200, epoch: 11 | loss: 0.0870605
	speed: 0.0381s/iter; left time: 905.6850s
Epoch: 11 cost time: 10.389814615249634
Epoch: 11, Steps: 266 Train Loss: 0.0856 (Forecasting Loss:0.0823 + XiCon Loss:3.3193 x Lambda(0.001)), Vali MSE Loss: 0.1326 Test MSE Loss: 0.1030
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.0825816
	speed: 0.0406s/iter; left time: 957.8353s
	iters: 200, epoch: 12 | loss: 0.0849819
	speed: 0.0389s/iter; left time: 913.1266s
Epoch: 12 cost time: 10.486718654632568
Epoch: 12, Steps: 266 Train Loss: 0.0855 (Forecasting Loss:0.0822 + XiCon Loss:3.3195 x Lambda(0.001)), Vali MSE Loss: 0.1323 Test MSE Loss: 0.1030
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02862796001136303, mae:0.1291089653968811, mape:0.10596712678670883, mspe:0.022527163848280907 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5016
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1518492
	speed: 0.0401s/iter; left time: 1063.4720s
	iters: 200, epoch: 1 | loss: 0.1533334
	speed: 0.0378s/iter; left time: 997.3399s
Epoch: 1 cost time: 10.165601968765259
Epoch: 1, Steps: 266 Train Loss: 0.1699 (Forecasting Loss:0.1665 + XiCon Loss:3.3760 x Lambda(0.001)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.0785
Validation loss decreased (inf --> 0.115746).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1379518
	speed: 0.0385s/iter; left time: 1011.1889s
	iters: 200, epoch: 2 | loss: 0.1330411
	speed: 0.0370s/iter; left time: 967.6811s
Epoch: 2 cost time: 10.043323278427124
Epoch: 2, Steps: 266 Train Loss: 0.1501 (Forecasting Loss:0.1468 + XiCon Loss:3.3527 x Lambda(0.001)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.0789
Validation loss decreased (0.115746 --> 0.112895).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1413466
	speed: 0.0388s/iter; left time: 1007.5663s
	iters: 200, epoch: 3 | loss: 0.1317546
	speed: 0.0369s/iter; left time: 953.5776s
Epoch: 3 cost time: 10.023799657821655
Epoch: 3, Steps: 266 Train Loss: 0.1339 (Forecasting Loss:0.1306 + XiCon Loss:3.3315 x Lambda(0.001)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.0839
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1145122
	speed: 0.0391s/iter; left time: 1005.3677s
	iters: 200, epoch: 4 | loss: 0.1132878
	speed: 0.0374s/iter; left time: 958.7130s
Epoch: 4 cost time: 10.122685194015503
Epoch: 4, Steps: 266 Train Loss: 0.1154 (Forecasting Loss:0.1121 + XiCon Loss:3.3291 x Lambda(0.001)), Vali MSE Loss: 0.1248 Test MSE Loss: 0.0956
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0967439
	speed: 0.0391s/iter; left time: 995.8316s
	iters: 200, epoch: 5 | loss: 0.1020683
	speed: 0.0377s/iter; left time: 955.4534s
Epoch: 5 cost time: 10.183802604675293
Epoch: 5, Steps: 266 Train Loss: 0.1034 (Forecasting Loss:0.1000 + XiCon Loss:3.3291 x Lambda(0.001)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.0987
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1030896
	speed: 0.0389s/iter; left time: 977.9301s
	iters: 200, epoch: 6 | loss: 0.0952786
	speed: 0.0383s/iter; left time: 959.4377s
Epoch: 6 cost time: 10.203420877456665
Epoch: 6, Steps: 266 Train Loss: 0.0973 (Forecasting Loss:0.0940 + XiCon Loss:3.3312 x Lambda(0.001)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.1021
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1034928
	speed: 0.0397s/iter; left time: 989.9737s
	iters: 200, epoch: 7 | loss: 0.0926795
	speed: 0.0376s/iter; left time: 931.4604s
Epoch: 7 cost time: 10.195749759674072
Epoch: 7, Steps: 266 Train Loss: 0.0946 (Forecasting Loss:0.0912 + XiCon Loss:3.3307 x Lambda(0.001)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.1019
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0978102
	speed: 0.0395s/iter; left time: 972.3986s
	iters: 200, epoch: 8 | loss: 0.0915350
	speed: 0.0377s/iter; left time: 924.8391s
Epoch: 8 cost time: 10.249987840652466
Epoch: 8, Steps: 266 Train Loss: 0.0934 (Forecasting Loss:0.0901 + XiCon Loss:3.3314 x Lambda(0.001)), Vali MSE Loss: 0.1323 Test MSE Loss: 0.1027
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0890985
	speed: 0.0400s/iter; left time: 973.7113s
	iters: 200, epoch: 9 | loss: 0.0863719
	speed: 0.0388s/iter; left time: 942.8661s
Epoch: 9 cost time: 10.407918691635132
Epoch: 9, Steps: 266 Train Loss: 0.0928 (Forecasting Loss:0.0895 + XiCon Loss:3.3318 x Lambda(0.001)), Vali MSE Loss: 0.1326 Test MSE Loss: 0.1032
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0865084
	speed: 0.0391s/iter; left time: 943.7319s
	iters: 200, epoch: 10 | loss: 0.0909164
	speed: 0.0387s/iter; left time: 929.1623s
Epoch: 10 cost time: 10.254008293151855
Epoch: 10, Steps: 266 Train Loss: 0.0925 (Forecasting Loss:0.0892 + XiCon Loss:3.3310 x Lambda(0.001)), Vali MSE Loss: 0.1321 Test MSE Loss: 0.1027
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0966672
	speed: 0.0403s/iter; left time: 961.9415s
	iters: 200, epoch: 11 | loss: 0.0888626
	speed: 0.0372s/iter; left time: 883.1951s
Epoch: 11 cost time: 10.302121639251709
Epoch: 11, Steps: 266 Train Loss: 0.0923 (Forecasting Loss:0.0890 + XiCon Loss:3.3322 x Lambda(0.001)), Vali MSE Loss: 0.1325 Test MSE Loss: 0.1027
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.0875760
	speed: 0.0387s/iter; left time: 911.1990s
	iters: 200, epoch: 12 | loss: 0.0905376
	speed: 0.0376s/iter; left time: 881.6879s
Epoch: 12 cost time: 10.137211799621582
Epoch: 12, Steps: 266 Train Loss: 0.0922 (Forecasting Loss:0.0889 + XiCon Loss:3.3295 x Lambda(0.001)), Vali MSE Loss: 0.1322 Test MSE Loss: 0.1029
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.029026197269558907, mae:0.12868112325668335, mape:0.10422392189502716, mspe:0.021845437586307526 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5207
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1780607
	speed: 0.0395s/iter; left time: 1046.8373s
	iters: 200, epoch: 1 | loss: 0.1458618
	speed: 0.0364s/iter; left time: 960.9855s
Epoch: 1 cost time: 10.003906726837158
Epoch: 1, Steps: 266 Train Loss: 0.1684 (Forecasting Loss:0.1650 + XiCon Loss:3.3778 x Lambda(0.001)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.0766
Validation loss decreased (inf --> 0.113868).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1553845
	speed: 0.0393s/iter; left time: 1030.2665s
	iters: 200, epoch: 2 | loss: 0.1539647
	speed: 0.0380s/iter; left time: 993.2362s
Epoch: 2 cost time: 10.264142513275146
Epoch: 2, Steps: 266 Train Loss: 0.1482 (Forecasting Loss:0.1448 + XiCon Loss:3.4167 x Lambda(0.001)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.0786
Validation loss decreased (0.113868 --> 0.111569).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1187993
	speed: 0.0405s/iter; left time: 1052.9258s
	iters: 200, epoch: 3 | loss: 0.1372249
	speed: 0.0383s/iter; left time: 990.6807s
Epoch: 3 cost time: 10.433529376983643
Epoch: 3, Steps: 266 Train Loss: 0.1288 (Forecasting Loss:0.1254 + XiCon Loss:3.3885 x Lambda(0.001)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.0883
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1150533
	speed: 0.0405s/iter; left time: 1040.0102s
	iters: 200, epoch: 4 | loss: 0.1101425
	speed: 0.0385s/iter; left time: 986.8792s
Epoch: 4 cost time: 10.413625240325928
Epoch: 4, Steps: 266 Train Loss: 0.1074 (Forecasting Loss:0.1040 + XiCon Loss:3.3768 x Lambda(0.001)), Vali MSE Loss: 0.1222 Test MSE Loss: 0.0978
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0902455
	speed: 0.0398s/iter; left time: 1012.3668s
	iters: 200, epoch: 5 | loss: 0.0916519
	speed: 0.0383s/iter; left time: 970.4128s
Epoch: 5 cost time: 10.331488609313965
Epoch: 5, Steps: 266 Train Loss: 0.0957 (Forecasting Loss:0.0923 + XiCon Loss:3.3676 x Lambda(0.001)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.1024
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0880147
	speed: 0.0405s/iter; left time: 1018.8057s
	iters: 200, epoch: 6 | loss: 0.0874136
	speed: 0.0386s/iter; left time: 968.0435s
Epoch: 6 cost time: 10.426663160324097
Epoch: 6, Steps: 266 Train Loss: 0.0909 (Forecasting Loss:0.0875 + XiCon Loss:3.3647 x Lambda(0.001)), Vali MSE Loss: 0.1283 Test MSE Loss: 0.1039
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0894524
	speed: 0.0404s/iter; left time: 1007.1774s
	iters: 200, epoch: 7 | loss: 0.0849092
	speed: 0.0393s/iter; left time: 974.6960s
Epoch: 7 cost time: 10.5144522190094
Epoch: 7, Steps: 266 Train Loss: 0.0888 (Forecasting Loss:0.0855 + XiCon Loss:3.3630 x Lambda(0.001)), Vali MSE Loss: 0.1289 Test MSE Loss: 0.1043
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0930773
	speed: 0.0409s/iter; left time: 1007.3381s
	iters: 200, epoch: 8 | loss: 0.0827057
	speed: 0.0384s/iter; left time: 941.6199s
Epoch: 8 cost time: 10.504760026931763
Epoch: 8, Steps: 266 Train Loss: 0.0878 (Forecasting Loss:0.0844 + XiCon Loss:3.3621 x Lambda(0.001)), Vali MSE Loss: 0.1291 Test MSE Loss: 0.1048
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0850965
	speed: 0.0401s/iter; left time: 977.5854s
	iters: 200, epoch: 9 | loss: 0.0849769
	speed: 0.0389s/iter; left time: 945.1334s
Epoch: 9 cost time: 10.458621501922607
Epoch: 9, Steps: 266 Train Loss: 0.0873 (Forecasting Loss:0.0839 + XiCon Loss:3.3630 x Lambda(0.001)), Vali MSE Loss: 0.1293 Test MSE Loss: 0.1047
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0816538
	speed: 0.0400s/iter; left time: 965.0361s
	iters: 200, epoch: 10 | loss: 0.0828187
	speed: 0.0382s/iter; left time: 916.7023s
Epoch: 10 cost time: 10.428828477859497
Epoch: 10, Steps: 266 Train Loss: 0.0871 (Forecasting Loss:0.0837 + XiCon Loss:3.3633 x Lambda(0.001)), Vali MSE Loss: 0.1292 Test MSE Loss: 0.1047
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0872085
	speed: 0.0414s/iter; left time: 986.2962s
	iters: 200, epoch: 11 | loss: 0.0977863
	speed: 0.0389s/iter; left time: 924.4594s
Epoch: 11 cost time: 10.569721698760986
Epoch: 11, Steps: 266 Train Loss: 0.0870 (Forecasting Loss:0.0836 + XiCon Loss:3.3596 x Lambda(0.001)), Vali MSE Loss: 0.1293 Test MSE Loss: 0.1048
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.0873021
	speed: 0.0404s/iter; left time: 952.1992s
	iters: 200, epoch: 12 | loss: 0.0908961
	speed: 0.0381s/iter; left time: 894.9891s
Epoch: 12 cost time: 10.406044960021973
Epoch: 12, Steps: 266 Train Loss: 0.0869 (Forecasting Loss:0.0835 + XiCon Loss:3.3624 x Lambda(0.001)), Vali MSE Loss: 0.1296 Test MSE Loss: 0.1049
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.028647761791944504, mae:0.12847422063350677, mape:0.10367170721292496, mspe:0.02101677842438221 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4853
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1626874
	speed: 0.0393s/iter; left time: 1040.2877s
	iters: 200, epoch: 1 | loss: 0.1658802
	speed: 0.0369s/iter; left time: 975.3931s
Epoch: 1 cost time: 10.044129133224487
Epoch: 1, Steps: 266 Train Loss: 0.1662 (Forecasting Loss:0.1628 + XiCon Loss:3.3722 x Lambda(0.001)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.0776
Validation loss decreased (inf --> 0.114685).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1580908
	speed: 0.0401s/iter; left time: 1051.9392s
	iters: 200, epoch: 2 | loss: 0.1358592
	speed: 0.0375s/iter; left time: 981.2245s
Epoch: 2 cost time: 10.224079370498657
Epoch: 2, Steps: 266 Train Loss: 0.1494 (Forecasting Loss:0.1460 + XiCon Loss:3.4002 x Lambda(0.001)), Vali MSE Loss: 0.1206 Test MSE Loss: 0.0836
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1195571
	speed: 0.0404s/iter; left time: 1049.6873s
	iters: 200, epoch: 3 | loss: 0.1265560
	speed: 0.0387s/iter; left time: 1002.0657s
Epoch: 3 cost time: 10.455434083938599
Epoch: 3, Steps: 266 Train Loss: 0.1273 (Forecasting Loss:0.1239 + XiCon Loss:3.3633 x Lambda(0.001)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.0849
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1066756
	speed: 0.0406s/iter; left time: 1044.3037s
	iters: 200, epoch: 4 | loss: 0.1138638
	speed: 0.0396s/iter; left time: 1013.4244s
Epoch: 4 cost time: 10.544904232025146
Epoch: 4, Steps: 266 Train Loss: 0.1051 (Forecasting Loss:0.1017 + XiCon Loss:3.3497 x Lambda(0.001)), Vali MSE Loss: 0.1223 Test MSE Loss: 0.0921
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1014115
	speed: 0.0402s/iter; left time: 1022.6080s
	iters: 200, epoch: 5 | loss: 0.0855307
	speed: 0.0391s/iter; left time: 990.0313s
Epoch: 5 cost time: 10.417970180511475
Epoch: 5, Steps: 266 Train Loss: 0.0940 (Forecasting Loss:0.0906 + XiCon Loss:3.3472 x Lambda(0.001)), Vali MSE Loss: 0.1245 Test MSE Loss: 0.0960
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0890502
	speed: 0.0401s/iter; left time: 1010.4349s
	iters: 200, epoch: 6 | loss: 0.0886998
	speed: 0.0391s/iter; left time: 980.0889s
Epoch: 6 cost time: 10.459583759307861
Epoch: 6, Steps: 266 Train Loss: 0.0893 (Forecasting Loss:0.0859 + XiCon Loss:3.3455 x Lambda(0.001)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.0987
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0926608
	speed: 0.0401s/iter; left time: 998.2499s
	iters: 200, epoch: 7 | loss: 0.0852962
	speed: 0.0382s/iter; left time: 948.3292s
Epoch: 7 cost time: 10.368619680404663
Epoch: 7, Steps: 266 Train Loss: 0.0874 (Forecasting Loss:0.0841 + XiCon Loss:3.3461 x Lambda(0.001)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.0987
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0846814
	speed: 0.0401s/iter; left time: 987.0356s
	iters: 200, epoch: 8 | loss: 0.0790012
	speed: 0.0386s/iter; left time: 947.0313s
Epoch: 8 cost time: 10.40622615814209
Epoch: 8, Steps: 266 Train Loss: 0.0865 (Forecasting Loss:0.0832 + XiCon Loss:3.3475 x Lambda(0.001)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.0991
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0900639
	speed: 0.0400s/iter; left time: 974.4951s
	iters: 200, epoch: 9 | loss: 0.0883224
	speed: 0.0386s/iter; left time: 937.3531s
Epoch: 9 cost time: 10.389116048812866
Epoch: 9, Steps: 266 Train Loss: 0.0861 (Forecasting Loss:0.0827 + XiCon Loss:3.3451 x Lambda(0.001)), Vali MSE Loss: 0.1266 Test MSE Loss: 0.0989
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0815201
	speed: 0.0415s/iter; left time: 999.8870s
	iters: 200, epoch: 10 | loss: 0.0848128
	speed: 0.0388s/iter; left time: 931.9970s
Epoch: 10 cost time: 10.613693714141846
Epoch: 10, Steps: 266 Train Loss: 0.0858 (Forecasting Loss:0.0825 + XiCon Loss:3.3471 x Lambda(0.001)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.0989
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0858663
	speed: 0.0414s/iter; left time: 987.1365s
	iters: 200, epoch: 11 | loss: 0.0847831
	speed: 0.0398s/iter; left time: 944.8293s
Epoch: 11 cost time: 10.722994804382324
Epoch: 11, Steps: 266 Train Loss: 0.0858 (Forecasting Loss:0.0824 + XiCon Loss:3.3472 x Lambda(0.001)), Vali MSE Loss: 0.1270 Test MSE Loss: 0.0991
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02792399190366268, mae:0.12723059952259064, mape:0.10248047113418579, mspe:0.020423265174031258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3524
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1574762
	speed: 0.0391s/iter; left time: 1035.8881s
	iters: 200, epoch: 1 | loss: 0.1570823
	speed: 0.0376s/iter; left time: 993.0837s
Epoch: 1 cost time: 10.156954765319824
Epoch: 1, Steps: 266 Train Loss: 0.1694 (Forecasting Loss:0.1661 + XiCon Loss:3.3769 x Lambda(0.001)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.0782
Validation loss decreased (inf --> 0.114386).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1500711
	speed: 0.0395s/iter; left time: 1037.4056s
	iters: 200, epoch: 2 | loss: 0.1599079
	speed: 0.0366s/iter; left time: 957.6216s
Epoch: 2 cost time: 10.079294681549072
Epoch: 2, Steps: 266 Train Loss: 0.1470 (Forecasting Loss:0.1437 + XiCon Loss:3.3710 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.0825
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1389869
	speed: 0.0398s/iter; left time: 1032.4229s
	iters: 200, epoch: 3 | loss: 0.1210372
	speed: 0.0382s/iter; left time: 988.1914s
Epoch: 3 cost time: 10.275166988372803
Epoch: 3, Steps: 266 Train Loss: 0.1254 (Forecasting Loss:0.1221 + XiCon Loss:3.3390 x Lambda(0.001)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.0919
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1039637
	speed: 0.0390s/iter; left time: 1001.1730s
	iters: 200, epoch: 4 | loss: 0.1098964
	speed: 0.0377s/iter; left time: 965.6446s
Epoch: 4 cost time: 10.1992027759552
Epoch: 4, Steps: 266 Train Loss: 0.1029 (Forecasting Loss:0.0995 + XiCon Loss:3.3268 x Lambda(0.001)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.0997
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0896118
	speed: 0.0402s/iter; left time: 1023.0654s
	iters: 200, epoch: 5 | loss: 0.1008977
	speed: 0.0373s/iter; left time: 944.6470s
Epoch: 5 cost time: 10.2409188747406
Epoch: 5, Steps: 266 Train Loss: 0.0915 (Forecasting Loss:0.0881 + XiCon Loss:3.3236 x Lambda(0.001)), Vali MSE Loss: 0.1295 Test MSE Loss: 0.0996
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0784195
	speed: 0.0396s/iter; left time: 996.2902s
	iters: 200, epoch: 6 | loss: 0.0944344
	speed: 0.0370s/iter; left time: 927.0295s
Epoch: 6 cost time: 10.226089715957642
Epoch: 6, Steps: 266 Train Loss: 0.0871 (Forecasting Loss:0.0838 + XiCon Loss:3.3229 x Lambda(0.001)), Vali MSE Loss: 0.1288 Test MSE Loss: 0.1025
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0902753
	speed: 0.0412s/iter; left time: 1025.3588s
	iters: 200, epoch: 7 | loss: 0.0841056
	speed: 0.0383s/iter; left time: 950.6280s
Epoch: 7 cost time: 10.565677642822266
Epoch: 7, Steps: 266 Train Loss: 0.0851 (Forecasting Loss:0.0818 + XiCon Loss:3.3216 x Lambda(0.001)), Vali MSE Loss: 0.1298 Test MSE Loss: 0.1025
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0870589
	speed: 0.0411s/iter; left time: 1011.8567s
	iters: 200, epoch: 8 | loss: 0.0832321
	speed: 0.0387s/iter; left time: 949.4358s
Epoch: 8 cost time: 10.581532001495361
Epoch: 8, Steps: 266 Train Loss: 0.0843 (Forecasting Loss:0.0809 + XiCon Loss:3.3207 x Lambda(0.001)), Vali MSE Loss: 0.1302 Test MSE Loss: 0.1019
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0796701
	speed: 0.0413s/iter; left time: 1006.9372s
	iters: 200, epoch: 9 | loss: 0.0933516
	speed: 0.0381s/iter; left time: 923.8241s
Epoch: 9 cost time: 10.50451946258545
Epoch: 9, Steps: 266 Train Loss: 0.0838 (Forecasting Loss:0.0804 + XiCon Loss:3.3214 x Lambda(0.001)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.1028
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0831521
	speed: 0.0406s/iter; left time: 977.8918s
	iters: 200, epoch: 10 | loss: 0.0756988
	speed: 0.0381s/iter; left time: 913.4931s
Epoch: 10 cost time: 10.41288447380066
Epoch: 10, Steps: 266 Train Loss: 0.0836 (Forecasting Loss:0.0803 + XiCon Loss:3.3207 x Lambda(0.001)), Vali MSE Loss: 0.1305 Test MSE Loss: 0.1024
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0858800
	speed: 0.0406s/iter; left time: 969.0635s
	iters: 200, epoch: 11 | loss: 0.0754883
	speed: 0.0388s/iter; left time: 921.9051s
Epoch: 11 cost time: 10.495725631713867
Epoch: 11, Steps: 266 Train Loss: 0.0834 (Forecasting Loss:0.0801 + XiCon Loss:3.3200 x Lambda(0.001)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.1026
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02818794548511505, mae:0.12811817228794098, mape:0.10377436876296997, mspe:0.02129249833524227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0285+-0.00054, MAE:0.1283+-0.00088, MAPE:0.1040+-0.00157, MSPE:0.0214+-0.00100, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3439
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2084382
	speed: 0.0521s/iter; left time: 1374.9801s
	iters: 200, epoch: 1 | loss: 0.1956535
	speed: 0.0470s/iter; left time: 1236.0472s
Epoch: 1 cost time: 13.011224269866943
Epoch: 1, Steps: 265 Train Loss: 0.2099 (Forecasting Loss:0.2066 + XiCon Loss:3.2959 x Lambda(0.001)), Vali MSE Loss: 0.1462 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.146194).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1959358
	speed: 0.0525s/iter; left time: 1372.2905s
	iters: 200, epoch: 2 | loss: 0.1989102
	speed: 0.0510s/iter; left time: 1326.9497s
Epoch: 2 cost time: 13.67023229598999
Epoch: 2, Steps: 265 Train Loss: 0.1860 (Forecasting Loss:0.1827 + XiCon Loss:3.3154 x Lambda(0.001)), Vali MSE Loss: 0.1609 Test MSE Loss: 0.1119
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1320706
	speed: 0.0490s/iter; left time: 1268.4265s
	iters: 200, epoch: 3 | loss: 0.1227646
	speed: 0.0511s/iter; left time: 1316.5512s
Epoch: 3 cost time: 13.367474555969238
Epoch: 3, Steps: 265 Train Loss: 0.1331 (Forecasting Loss:0.1298 + XiCon Loss:3.2855 x Lambda(0.001)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1263
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1142915
	speed: 0.0535s/iter; left time: 1371.1556s
	iters: 200, epoch: 4 | loss: 0.1201623
	speed: 0.0532s/iter; left time: 1356.5444s
Epoch: 4 cost time: 14.127847671508789
Epoch: 4, Steps: 265 Train Loss: 0.1094 (Forecasting Loss:0.1062 + XiCon Loss:3.2736 x Lambda(0.001)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1317
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0967325
	speed: 0.0541s/iter; left time: 1371.4957s
	iters: 200, epoch: 5 | loss: 0.1005278
	speed: 0.0511s/iter; left time: 1289.0941s
Epoch: 5 cost time: 13.997475624084473
Epoch: 5, Steps: 265 Train Loss: 0.1018 (Forecasting Loss:0.0985 + XiCon Loss:3.2715 x Lambda(0.001)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1303
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1073196
	speed: 0.0537s/iter; left time: 1345.5137s
	iters: 200, epoch: 6 | loss: 0.1000436
	speed: 0.0534s/iter; left time: 1333.7711s
Epoch: 6 cost time: 14.075430870056152
Epoch: 6, Steps: 265 Train Loss: 0.0989 (Forecasting Loss:0.0956 + XiCon Loss:3.2715 x Lambda(0.001)), Vali MSE Loss: 0.1722 Test MSE Loss: 0.1317
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0929634
	speed: 0.0542s/iter; left time: 1344.2915s
	iters: 200, epoch: 7 | loss: 0.0976127
	speed: 0.0527s/iter; left time: 1302.7632s
Epoch: 7 cost time: 14.065221309661865
Epoch: 7, Steps: 265 Train Loss: 0.0974 (Forecasting Loss:0.0942 + XiCon Loss:3.2731 x Lambda(0.001)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1325
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1020154
	speed: 0.0543s/iter; left time: 1332.4483s
	iters: 200, epoch: 8 | loss: 0.0971649
	speed: 0.0527s/iter; left time: 1288.6299s
Epoch: 8 cost time: 14.201477527618408
Epoch: 8, Steps: 265 Train Loss: 0.0967 (Forecasting Loss:0.0935 + XiCon Loss:3.2701 x Lambda(0.001)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1318
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0912056
	speed: 0.0537s/iter; left time: 1304.8312s
	iters: 200, epoch: 9 | loss: 0.0919455
	speed: 0.0514s/iter; left time: 1242.1299s
Epoch: 9 cost time: 14.001611232757568
Epoch: 9, Steps: 265 Train Loss: 0.0964 (Forecasting Loss:0.0931 + XiCon Loss:3.2706 x Lambda(0.001)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1321
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0916161
	speed: 0.0541s/iter; left time: 1298.7681s
	iters: 200, epoch: 10 | loss: 0.1011789
	speed: 0.0482s/iter; left time: 1153.6521s
Epoch: 10 cost time: 13.302082538604736
Epoch: 10, Steps: 265 Train Loss: 0.0962 (Forecasting Loss:0.0929 + XiCon Loss:3.2696 x Lambda(0.001)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1325
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0953328
	speed: 0.0548s/iter; left time: 1301.9459s
	iters: 200, epoch: 11 | loss: 0.0943540
	speed: 0.0527s/iter; left time: 1245.5939s
Epoch: 11 cost time: 14.11204743385315
Epoch: 11, Steps: 265 Train Loss: 0.0961 (Forecasting Loss:0.0928 + XiCon Loss:3.2705 x Lambda(0.001)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1326
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04091712459921837, mae:0.15565137565135956, mape:0.12514923512935638, mspe:0.029140057042241096 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3716
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2093115
	speed: 0.0497s/iter; left time: 1312.3838s
	iters: 200, epoch: 1 | loss: 0.1991851
	speed: 0.0470s/iter; left time: 1235.3530s
Epoch: 1 cost time: 12.798055410385132
Epoch: 1, Steps: 265 Train Loss: 0.2080 (Forecasting Loss:0.2047 + XiCon Loss:3.2945 x Lambda(0.001)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.0995
Validation loss decreased (inf --> 0.147657).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1816753
	speed: 0.0515s/iter; left time: 1345.1647s
	iters: 200, epoch: 2 | loss: 0.1576411
	speed: 0.0532s/iter; left time: 1384.8012s
Epoch: 2 cost time: 13.867217540740967
Epoch: 2, Steps: 265 Train Loss: 0.1901 (Forecasting Loss:0.1867 + XiCon Loss:3.3230 x Lambda(0.001)), Vali MSE Loss: 0.1508 Test MSE Loss: 0.1088
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1408196
	speed: 0.0558s/iter; left time: 1443.2752s
	iters: 200, epoch: 3 | loss: 0.1420499
	speed: 0.0534s/iter; left time: 1376.8737s
Epoch: 3 cost time: 14.440269947052002
Epoch: 3, Steps: 265 Train Loss: 0.1446 (Forecasting Loss:0.1413 + XiCon Loss:3.2927 x Lambda(0.001)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1232
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1173582
	speed: 0.0546s/iter; left time: 1398.0613s
	iters: 200, epoch: 4 | loss: 0.1056764
	speed: 0.0525s/iter; left time: 1339.7374s
Epoch: 4 cost time: 14.18882942199707
Epoch: 4, Steps: 265 Train Loss: 0.1157 (Forecasting Loss:0.1125 + XiCon Loss:3.2874 x Lambda(0.001)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1215
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1009008
	speed: 0.0571s/iter; left time: 1446.0239s
	iters: 200, epoch: 5 | loss: 0.1003926
	speed: 0.0550s/iter; left time: 1387.2860s
Epoch: 5 cost time: 14.803414106369019
Epoch: 5, Steps: 265 Train Loss: 0.1067 (Forecasting Loss:0.1034 + XiCon Loss:3.2866 x Lambda(0.001)), Vali MSE Loss: 0.1752 Test MSE Loss: 0.1212
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1044006
	speed: 0.0533s/iter; left time: 1335.6920s
	iters: 200, epoch: 6 | loss: 0.0976369
	speed: 0.0488s/iter; left time: 1218.0700s
Epoch: 6 cost time: 13.697594165802002
Epoch: 6, Steps: 265 Train Loss: 0.1038 (Forecasting Loss:0.1005 + XiCon Loss:3.2880 x Lambda(0.001)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1228
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1021436
	speed: 0.0544s/iter; left time: 1348.8390s
	iters: 200, epoch: 7 | loss: 0.1050645
	speed: 0.0546s/iter; left time: 1349.1354s
Epoch: 7 cost time: 14.428423881530762
Epoch: 7, Steps: 265 Train Loss: 0.1024 (Forecasting Loss:0.0991 + XiCon Loss:3.2909 x Lambda(0.001)), Vali MSE Loss: 0.1722 Test MSE Loss: 0.1230
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1010449
	speed: 0.0554s/iter; left time: 1359.0860s
	iters: 200, epoch: 8 | loss: 0.0955784
	speed: 0.0527s/iter; left time: 1288.3615s
Epoch: 8 cost time: 14.240031480789185
Epoch: 8, Steps: 265 Train Loss: 0.1017 (Forecasting Loss:0.0984 + XiCon Loss:3.2883 x Lambda(0.001)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1224
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1013487
	speed: 0.0541s/iter; left time: 1314.3093s
	iters: 200, epoch: 9 | loss: 0.0984410
	speed: 0.0556s/iter; left time: 1343.7526s
Epoch: 9 cost time: 14.458070278167725
Epoch: 9, Steps: 265 Train Loss: 0.1013 (Forecasting Loss:0.0981 + XiCon Loss:3.2886 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1231
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1023836
	speed: 0.0548s/iter; left time: 1315.5418s
	iters: 200, epoch: 10 | loss: 0.0986206
	speed: 0.0532s/iter; left time: 1271.2331s
Epoch: 10 cost time: 14.33769178390503
Epoch: 10, Steps: 265 Train Loss: 0.1012 (Forecasting Loss:0.0979 + XiCon Loss:3.2879 x Lambda(0.001)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1229
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0988956
	speed: 0.0550s/iter; left time: 1306.2664s
	iters: 200, epoch: 11 | loss: 0.1002336
	speed: 0.0537s/iter; left time: 1269.1254s
Epoch: 11 cost time: 14.349631547927856
Epoch: 11, Steps: 265 Train Loss: 0.1011 (Forecasting Loss:0.0978 + XiCon Loss:3.2897 x Lambda(0.001)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1230
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.041947610676288605, mae:0.1571040153503418, mape:0.12536552548408508, mspe:0.029006291180849075 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2734
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2053022
	speed: 0.0490s/iter; left time: 1292.6609s
	iters: 200, epoch: 1 | loss: 0.1926838
	speed: 0.0466s/iter; left time: 1225.6471s
Epoch: 1 cost time: 12.574129343032837
Epoch: 1, Steps: 265 Train Loss: 0.2122 (Forecasting Loss:0.2089 + XiCon Loss:3.3022 x Lambda(0.001)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.0991
Validation loss decreased (inf --> 0.147641).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1797973
	speed: 0.0510s/iter; left time: 1332.4189s
	iters: 200, epoch: 2 | loss: 0.1854673
	speed: 0.0493s/iter; left time: 1284.7297s
Epoch: 2 cost time: 13.353594541549683
Epoch: 2, Steps: 265 Train Loss: 0.1948 (Forecasting Loss:0.1914 + XiCon Loss:3.3525 x Lambda(0.001)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.1001
Validation loss decreased (0.147641 --> 0.147233).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1614746
	speed: 0.0547s/iter; left time: 1416.4054s
	iters: 200, epoch: 3 | loss: 0.1481108
	speed: 0.0527s/iter; left time: 1358.8624s
Epoch: 3 cost time: 14.16515064239502
Epoch: 3, Steps: 265 Train Loss: 0.1645 (Forecasting Loss:0.1612 + XiCon Loss:3.3283 x Lambda(0.001)), Vali MSE Loss: 0.1589 Test MSE Loss: 0.1199
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1343936
	speed: 0.0543s/iter; left time: 1390.5247s
	iters: 200, epoch: 4 | loss: 0.1234664
	speed: 0.0532s/iter; left time: 1355.9767s
Epoch: 4 cost time: 14.219524621963501
Epoch: 4, Steps: 265 Train Loss: 0.1318 (Forecasting Loss:0.1285 + XiCon Loss:3.3186 x Lambda(0.001)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1211
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1115100
	speed: 0.0536s/iter; left time: 1359.2265s
	iters: 200, epoch: 5 | loss: 0.1124164
	speed: 0.0530s/iter; left time: 1337.3221s
Epoch: 5 cost time: 14.082475662231445
Epoch: 5, Steps: 265 Train Loss: 0.1148 (Forecasting Loss:0.1115 + XiCon Loss:3.3146 x Lambda(0.001)), Vali MSE Loss: 0.1691 Test MSE Loss: 0.1287
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1102014
	speed: 0.0553s/iter; left time: 1385.5858s
	iters: 200, epoch: 6 | loss: 0.1035046
	speed: 0.0536s/iter; left time: 1337.9856s
Epoch: 6 cost time: 14.289289474487305
Epoch: 6, Steps: 265 Train Loss: 0.1078 (Forecasting Loss:0.1045 + XiCon Loss:3.3144 x Lambda(0.001)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1289
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1080218
	speed: 0.0554s/iter; left time: 1374.6301s
	iters: 200, epoch: 7 | loss: 0.1011386
	speed: 0.0519s/iter; left time: 1282.2423s
Epoch: 7 cost time: 14.232498407363892
Epoch: 7, Steps: 265 Train Loss: 0.1052 (Forecasting Loss:0.1019 + XiCon Loss:3.3129 x Lambda(0.001)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1288
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1054711
	speed: 0.0532s/iter; left time: 1304.9790s
	iters: 200, epoch: 8 | loss: 0.1167445
	speed: 0.0529s/iter; left time: 1292.5149s
Epoch: 8 cost time: 14.02768063545227
Epoch: 8, Steps: 265 Train Loss: 0.1040 (Forecasting Loss:0.1007 + XiCon Loss:3.3107 x Lambda(0.001)), Vali MSE Loss: 0.1695 Test MSE Loss: 0.1284
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1079228
	speed: 0.0503s/iter; left time: 1220.7694s
	iters: 200, epoch: 9 | loss: 0.0968905
	speed: 0.0464s/iter; left time: 1122.8762s
Epoch: 9 cost time: 13.054625034332275
Epoch: 9, Steps: 265 Train Loss: 0.1033 (Forecasting Loss:0.1000 + XiCon Loss:3.3109 x Lambda(0.001)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1286
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1069450
	speed: 0.0553s/iter; left time: 1327.7817s
	iters: 200, epoch: 10 | loss: 0.1029477
	speed: 0.0521s/iter; left time: 1246.7973s
Epoch: 10 cost time: 14.202213764190674
Epoch: 10, Steps: 265 Train Loss: 0.1031 (Forecasting Loss:0.0998 + XiCon Loss:3.3096 x Lambda(0.001)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1282
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1003974
	speed: 0.0536s/iter; left time: 1272.7985s
	iters: 200, epoch: 11 | loss: 0.1021394
	speed: 0.0539s/iter; left time: 1275.2352s
Epoch: 11 cost time: 14.182595491409302
Epoch: 11, Steps: 265 Train Loss: 0.1029 (Forecasting Loss:0.0996 + XiCon Loss:3.3099 x Lambda(0.001)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1286
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1060588
	speed: 0.0527s/iter; left time: 1236.6120s
	iters: 200, epoch: 12 | loss: 0.1093926
	speed: 0.0532s/iter; left time: 1244.8830s
Epoch: 12 cost time: 14.025312185287476
Epoch: 12, Steps: 265 Train Loss: 0.1029 (Forecasting Loss:0.0996 + XiCon Loss:3.3109 x Lambda(0.001)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1287
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04189290478825569, mae:0.15823708474636078, mape:0.12936833500862122, mspe:0.032579097896814346 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1014
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.1863578
	speed: 0.0496s/iter; left time: 1308.6684s
	iters: 200, epoch: 1 | loss: 0.1934551
	speed: 0.0472s/iter; left time: 1242.2046s
Epoch: 1 cost time: 12.785979747772217
Epoch: 1, Steps: 265 Train Loss: 0.2086 (Forecasting Loss:0.2053 + XiCon Loss:3.2985 x Lambda(0.001)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0974
Validation loss decreased (inf --> 0.146395).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1925293
	speed: 0.0528s/iter; left time: 1381.2189s
	iters: 200, epoch: 2 | loss: 0.1888623
	speed: 0.0517s/iter; left time: 1346.2587s
Epoch: 2 cost time: 13.782969236373901
Epoch: 2, Steps: 265 Train Loss: 0.1886 (Forecasting Loss:0.1852 + XiCon Loss:3.3330 x Lambda(0.001)), Vali MSE Loss: 0.1595 Test MSE Loss: 0.1238
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1397256
	speed: 0.0531s/iter; left time: 1373.9407s
	iters: 200, epoch: 3 | loss: 0.1221162
	speed: 0.0522s/iter; left time: 1345.1246s
Epoch: 3 cost time: 13.845565557479858
Epoch: 3, Steps: 265 Train Loss: 0.1407 (Forecasting Loss:0.1374 + XiCon Loss:3.3126 x Lambda(0.001)), Vali MSE Loss: 0.1615 Test MSE Loss: 0.1198
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1143604
	speed: 0.0488s/iter; left time: 1248.6354s
	iters: 200, epoch: 4 | loss: 0.1076686
	speed: 0.0530s/iter; left time: 1352.6749s
Epoch: 4 cost time: 13.624354839324951
Epoch: 4, Steps: 265 Train Loss: 0.1138 (Forecasting Loss:0.1105 + XiCon Loss:3.2995 x Lambda(0.001)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1264
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1075573
	speed: 0.0547s/iter; left time: 1386.2361s
	iters: 200, epoch: 5 | loss: 0.0965056
	speed: 0.0524s/iter; left time: 1322.2791s
Epoch: 5 cost time: 14.031346321105957
Epoch: 5, Steps: 265 Train Loss: 0.1064 (Forecasting Loss:0.1031 + XiCon Loss:3.2942 x Lambda(0.001)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1288
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1028981
	speed: 0.0554s/iter; left time: 1388.5513s
	iters: 200, epoch: 6 | loss: 0.1035685
	speed: 0.0526s/iter; left time: 1312.8310s
Epoch: 6 cost time: 14.265110492706299
Epoch: 6, Steps: 265 Train Loss: 0.1034 (Forecasting Loss:0.1001 + XiCon Loss:3.2902 x Lambda(0.001)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1307
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0996393
	speed: 0.0552s/iter; left time: 1369.9164s
	iters: 200, epoch: 7 | loss: 0.0994600
	speed: 0.0545s/iter; left time: 1345.7004s
Epoch: 7 cost time: 14.418687582015991
Epoch: 7, Steps: 265 Train Loss: 0.1021 (Forecasting Loss:0.0988 + XiCon Loss:3.2887 x Lambda(0.001)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1306
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0961109
	speed: 0.0545s/iter; left time: 1336.5331s
	iters: 200, epoch: 8 | loss: 0.0999061
	speed: 0.0537s/iter; left time: 1313.6521s
Epoch: 8 cost time: 14.351048469543457
Epoch: 8, Steps: 265 Train Loss: 0.1014 (Forecasting Loss:0.0981 + XiCon Loss:3.2897 x Lambda(0.001)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1321
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1006166
	speed: 0.0539s/iter; left time: 1308.3770s
	iters: 200, epoch: 9 | loss: 0.1035981
	speed: 0.0537s/iter; left time: 1297.6087s
Epoch: 9 cost time: 14.111956357955933
Epoch: 9, Steps: 265 Train Loss: 0.1010 (Forecasting Loss:0.0977 + XiCon Loss:3.2877 x Lambda(0.001)), Vali MSE Loss: 0.1676 Test MSE Loss: 0.1324
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1067191
	speed: 0.0544s/iter; left time: 1307.1579s
	iters: 200, epoch: 10 | loss: 0.1046558
	speed: 0.0509s/iter; left time: 1217.0524s
Epoch: 10 cost time: 14.193178653717041
Epoch: 10, Steps: 265 Train Loss: 0.1008 (Forecasting Loss:0.0975 + XiCon Loss:3.2901 x Lambda(0.001)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1324
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0979822
	speed: 0.0514s/iter; left time: 1221.2474s
	iters: 200, epoch: 11 | loss: 0.1007109
	speed: 0.0469s/iter; left time: 1109.6764s
Epoch: 11 cost time: 12.975008726119995
Epoch: 11, Steps: 265 Train Loss: 0.1007 (Forecasting Loss:0.0974 + XiCon Loss:3.2871 x Lambda(0.001)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1325
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04074515029788017, mae:0.15414047241210938, mape:0.12231166660785675, mspe:0.027440395206212997 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.0205
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2069753
	speed: 0.0493s/iter; left time: 1301.4731s
	iters: 200, epoch: 1 | loss: 0.1899237
	speed: 0.0482s/iter; left time: 1267.8132s
Epoch: 1 cost time: 12.850854396820068
Epoch: 1, Steps: 265 Train Loss: 0.2093 (Forecasting Loss:0.2059 + XiCon Loss:3.3213 x Lambda(0.001)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.1004
Validation loss decreased (inf --> 0.147212).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1927821
	speed: 0.0497s/iter; left time: 1299.8958s
	iters: 200, epoch: 2 | loss: 0.1850353
	speed: 0.0502s/iter; left time: 1305.8944s
Epoch: 2 cost time: 13.33104395866394
Epoch: 2, Steps: 265 Train Loss: 0.1898 (Forecasting Loss:0.1865 + XiCon Loss:3.3048 x Lambda(0.001)), Vali MSE Loss: 0.1517 Test MSE Loss: 0.1081
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1330685
	speed: 0.0535s/iter; left time: 1384.9296s
	iters: 200, epoch: 3 | loss: 0.1187172
	speed: 0.0518s/iter; left time: 1334.8194s
Epoch: 3 cost time: 13.836942672729492
Epoch: 3, Steps: 265 Train Loss: 0.1309 (Forecasting Loss:0.1276 + XiCon Loss:3.2714 x Lambda(0.001)), Vali MSE Loss: 0.1674 Test MSE Loss: 0.1222
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1043527
	speed: 0.0532s/iter; left time: 1363.2087s
	iters: 200, epoch: 4 | loss: 0.1092341
	speed: 0.0525s/iter; left time: 1338.1145s
Epoch: 4 cost time: 13.92861819267273
Epoch: 4, Steps: 265 Train Loss: 0.1066 (Forecasting Loss:0.1034 + XiCon Loss:3.2625 x Lambda(0.001)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1216
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1057392
	speed: 0.0553s/iter; left time: 1400.9936s
	iters: 200, epoch: 5 | loss: 0.0954840
	speed: 0.0512s/iter; left time: 1291.1499s
Epoch: 5 cost time: 14.008409261703491
Epoch: 5, Steps: 265 Train Loss: 0.1015 (Forecasting Loss:0.0982 + XiCon Loss:3.2661 x Lambda(0.001)), Vali MSE Loss: 0.1664 Test MSE Loss: 0.1249
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0961868
	speed: 0.0547s/iter; left time: 1371.5517s
	iters: 200, epoch: 6 | loss: 0.0991041
	speed: 0.0531s/iter; left time: 1327.2691s
Epoch: 6 cost time: 14.088462352752686
Epoch: 6, Steps: 265 Train Loss: 0.0993 (Forecasting Loss:0.0960 + XiCon Loss:3.2636 x Lambda(0.001)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1258
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0961370
	speed: 0.0483s/iter; left time: 1198.1812s
	iters: 200, epoch: 7 | loss: 0.0969860
	speed: 0.0464s/iter; left time: 1147.6243s
Epoch: 7 cost time: 12.719367265701294
Epoch: 7, Steps: 265 Train Loss: 0.0982 (Forecasting Loss:0.0949 + XiCon Loss:3.2628 x Lambda(0.001)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1270
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0875453
	speed: 0.1059s/iter; left time: 2599.0670s
	iters: 200, epoch: 8 | loss: 0.1024936
	speed: 0.1024s/iter; left time: 2504.1062s
Epoch: 8 cost time: 28.43929409980774
Epoch: 8, Steps: 265 Train Loss: 0.0975 (Forecasting Loss:0.0943 + XiCon Loss:3.2621 x Lambda(0.001)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1258
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0915202
	speed: 0.1065s/iter; left time: 2586.8817s
	iters: 200, epoch: 9 | loss: 0.0927533
	speed: 0.0936s/iter; left time: 2263.4647s
Epoch: 9 cost time: 25.66927671432495
Epoch: 9, Steps: 265 Train Loss: 0.0972 (Forecasting Loss:0.0940 + XiCon Loss:3.2632 x Lambda(0.001)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1269
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0941536
	speed: 0.0810s/iter; left time: 1946.0449s
	iters: 200, epoch: 10 | loss: 0.0943457
	speed: 0.0558s/iter; left time: 1335.0625s
Epoch: 10 cost time: 16.814121961593628
Epoch: 10, Steps: 265 Train Loss: 0.0970 (Forecasting Loss:0.0938 + XiCon Loss:3.2608 x Lambda(0.001)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1269
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0935374
	speed: 0.0497s/iter; left time: 1180.7363s
	iters: 200, epoch: 11 | loss: 0.1025608
	speed: 0.0482s/iter; left time: 1139.1167s
Epoch: 11 cost time: 12.976057529449463
Epoch: 11, Steps: 265 Train Loss: 0.0969 (Forecasting Loss:0.0937 + XiCon Loss:3.2620 x Lambda(0.001)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1266
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.042481616139411926, mae:0.15828698873519897, mape:0.1267251968383789, mspe:0.029930660501122475 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0416+-0.00092, MAE:0.1567+-0.00221, MAPE:0.1258+-0.00319, MSPE:0.0296+-0.00234, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1417
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2423432
	speed: 0.0401s/iter; left time: 1054.3791s
	iters: 200, epoch: 1 | loss: 0.2688616
	speed: 0.0338s/iter; left time: 886.8326s
Epoch: 1 cost time: 9.57073712348938
Epoch: 1, Steps: 264 Train Loss: 0.2390 (Forecasting Loss:0.2358 + XiCon Loss:3.2157 x Lambda(0.001)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1158
Validation loss decreased (inf --> 0.173193).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2559037
	speed: 0.0388s/iter; left time: 1010.6530s
	iters: 200, epoch: 2 | loss: 0.2316412
	speed: 0.0412s/iter; left time: 1069.7538s
Epoch: 2 cost time: 10.808395624160767
Epoch: 2, Steps: 264 Train Loss: 0.2283 (Forecasting Loss:0.2251 + XiCon Loss:3.2125 x Lambda(0.001)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1821562
	speed: 0.0448s/iter; left time: 1155.7858s
	iters: 200, epoch: 3 | loss: 0.1664119
	speed: 0.0422s/iter; left time: 1082.1906s
Epoch: 3 cost time: 11.468414545059204
Epoch: 3, Steps: 264 Train Loss: 0.1844 (Forecasting Loss:0.1812 + XiCon Loss:3.1977 x Lambda(0.001)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1551
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1533255
	speed: 0.0443s/iter; left time: 1130.5888s
	iters: 200, epoch: 4 | loss: 0.1582572
	speed: 0.0432s/iter; left time: 1098.6066s
Epoch: 4 cost time: 11.479750156402588
Epoch: 4, Steps: 264 Train Loss: 0.1592 (Forecasting Loss:0.1560 + XiCon Loss:3.1940 x Lambda(0.001)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1609
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1424579
	speed: 0.0446s/iter; left time: 1126.8620s
	iters: 200, epoch: 5 | loss: 0.1420971
	speed: 0.0428s/iter; left time: 1075.7405s
Epoch: 5 cost time: 11.51819396018982
Epoch: 5, Steps: 264 Train Loss: 0.1490 (Forecasting Loss:0.1458 + XiCon Loss:3.1903 x Lambda(0.001)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1638
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1445630
	speed: 0.0445s/iter; left time: 1111.5194s
	iters: 200, epoch: 6 | loss: 0.1424915
	speed: 0.0426s/iter; left time: 1060.8101s
Epoch: 6 cost time: 11.44498872756958
Epoch: 6, Steps: 264 Train Loss: 0.1449 (Forecasting Loss:0.1417 + XiCon Loss:3.1903 x Lambda(0.001)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1688
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1485985
	speed: 0.0446s/iter; left time: 1103.2550s
	iters: 200, epoch: 7 | loss: 0.1391188
	speed: 0.0431s/iter; left time: 1061.2768s
Epoch: 7 cost time: 11.49973177909851
Epoch: 7, Steps: 264 Train Loss: 0.1427 (Forecasting Loss:0.1395 + XiCon Loss:3.1925 x Lambda(0.001)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1680
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1411400
	speed: 0.0453s/iter; left time: 1106.9204s
	iters: 200, epoch: 8 | loss: 0.1507927
	speed: 0.0436s/iter; left time: 1062.8342s
Epoch: 8 cost time: 11.658248662948608
Epoch: 8, Steps: 264 Train Loss: 0.1415 (Forecasting Loss:0.1383 + XiCon Loss:3.1911 x Lambda(0.001)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1682
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1362212
	speed: 0.0449s/iter; left time: 1086.5220s
	iters: 200, epoch: 9 | loss: 0.1445627
	speed: 0.0428s/iter; left time: 1030.1124s
Epoch: 9 cost time: 11.593114376068115
Epoch: 9, Steps: 264 Train Loss: 0.1411 (Forecasting Loss:0.1379 + XiCon Loss:3.1905 x Lambda(0.001)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1694
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1421237
	speed: 0.0457s/iter; left time: 1092.9767s
	iters: 200, epoch: 10 | loss: 0.1470487
	speed: 0.0436s/iter; left time: 1038.9890s
Epoch: 10 cost time: 11.704711675643921
Epoch: 10, Steps: 264 Train Loss: 0.1409 (Forecasting Loss:0.1378 + XiCon Loss:3.1909 x Lambda(0.001)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1696
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1450950
	speed: 0.0444s/iter; left time: 1051.4471s
	iters: 200, epoch: 11 | loss: 0.1390507
	speed: 0.0429s/iter; left time: 1011.0614s
Epoch: 11 cost time: 11.440966844558716
Epoch: 11, Steps: 264 Train Loss: 0.1407 (Forecasting Loss:0.1375 + XiCon Loss:3.1902 x Lambda(0.001)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05451710522174835, mae:0.1770460605621338, mape:0.1380663365125656, mspe:0.03353925421833992 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4339
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2196530
	speed: 0.0396s/iter; left time: 1042.3964s
	iters: 200, epoch: 1 | loss: 0.2153191
	speed: 0.0364s/iter; left time: 952.5655s
Epoch: 1 cost time: 9.958611249923706
Epoch: 1, Steps: 264 Train Loss: 0.2385 (Forecasting Loss:0.2353 + XiCon Loss:3.2094 x Lambda(0.001)), Vali MSE Loss: 0.1775 Test MSE Loss: 0.1177
Validation loss decreased (inf --> 0.177535).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2148601
	speed: 0.0390s/iter; left time: 1015.9506s
	iters: 200, epoch: 2 | loss: 0.2347509
	speed: 0.0379s/iter; left time: 982.9176s
Epoch: 2 cost time: 10.299064636230469
Epoch: 2, Steps: 264 Train Loss: 0.2328 (Forecasting Loss:0.2296 + XiCon Loss:3.2172 x Lambda(0.001)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1875132
	speed: 0.0449s/iter; left time: 1156.5508s
	iters: 200, epoch: 3 | loss: 0.1889521
	speed: 0.0426s/iter; left time: 1094.6591s
Epoch: 3 cost time: 11.559456825256348
Epoch: 3, Steps: 264 Train Loss: 0.1985 (Forecasting Loss:0.1953 + XiCon Loss:3.2073 x Lambda(0.001)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1483
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1661416
	speed: 0.0465s/iter; left time: 1186.7555s
	iters: 200, epoch: 4 | loss: 0.1786084
	speed: 0.0438s/iter; left time: 1112.9284s
Epoch: 4 cost time: 11.846083164215088
Epoch: 4, Steps: 264 Train Loss: 0.1721 (Forecasting Loss:0.1689 + XiCon Loss:3.1917 x Lambda(0.001)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1632
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1511196
	speed: 0.0462s/iter; left time: 1165.5282s
	iters: 200, epoch: 5 | loss: 0.1678829
	speed: 0.0437s/iter; left time: 1098.7612s
Epoch: 5 cost time: 11.817563533782959
Epoch: 5, Steps: 264 Train Loss: 0.1589 (Forecasting Loss:0.1557 + XiCon Loss:3.1870 x Lambda(0.001)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1750
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1498323
	speed: 0.0461s/iter; left time: 1152.1019s
	iters: 200, epoch: 6 | loss: 0.1689629
	speed: 0.0447s/iter; left time: 1112.9753s
Epoch: 6 cost time: 11.863492250442505
Epoch: 6, Steps: 264 Train Loss: 0.1534 (Forecasting Loss:0.1502 + XiCon Loss:3.1888 x Lambda(0.001)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1729
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1516663
	speed: 0.0467s/iter; left time: 1154.2385s
	iters: 200, epoch: 7 | loss: 0.1444498
	speed: 0.0445s/iter; left time: 1096.6352s
Epoch: 7 cost time: 11.997917413711548
Epoch: 7, Steps: 264 Train Loss: 0.1508 (Forecasting Loss:0.1476 + XiCon Loss:3.1906 x Lambda(0.001)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1756
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1621541
	speed: 0.0457s/iter; left time: 1116.8317s
	iters: 200, epoch: 8 | loss: 0.1454567
	speed: 0.0435s/iter; left time: 1060.3489s
Epoch: 8 cost time: 11.774064302444458
Epoch: 8, Steps: 264 Train Loss: 0.1495 (Forecasting Loss:0.1463 + XiCon Loss:3.1888 x Lambda(0.001)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1761
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1479530
	speed: 0.0471s/iter; left time: 1138.1537s
	iters: 200, epoch: 9 | loss: 0.1575307
	speed: 0.0437s/iter; left time: 1052.7126s
Epoch: 9 cost time: 11.85258436203003
Epoch: 9, Steps: 264 Train Loss: 0.1489 (Forecasting Loss:0.1457 + XiCon Loss:3.1886 x Lambda(0.001)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1760
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1480427
	speed: 0.0464s/iter; left time: 1110.8453s
	iters: 200, epoch: 10 | loss: 0.1520590
	speed: 0.0442s/iter; left time: 1052.2323s
Epoch: 10 cost time: 11.890215873718262
Epoch: 10, Steps: 264 Train Loss: 0.1485 (Forecasting Loss:0.1453 + XiCon Loss:3.1916 x Lambda(0.001)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1765
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1560338
	speed: 0.0468s/iter; left time: 1108.1860s
	iters: 200, epoch: 11 | loss: 0.1493749
	speed: 0.0446s/iter; left time: 1050.1441s
Epoch: 11 cost time: 11.903663158416748
Epoch: 11, Steps: 264 Train Loss: 0.1485 (Forecasting Loss:0.1453 + XiCon Loss:3.1912 x Lambda(0.001)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1758
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.055814653635025024, mae:0.17951637506484985, mape:0.139798104763031, mspe:0.03405819460749626 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8219
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2469142
	speed: 0.0392s/iter; left time: 1030.6021s
	iters: 200, epoch: 1 | loss: 0.2199152
	speed: 0.0368s/iter; left time: 964.0389s
Epoch: 1 cost time: 9.894634485244751
Epoch: 1, Steps: 264 Train Loss: 0.2368 (Forecasting Loss:0.2336 + XiCon Loss:3.2011 x Lambda(0.001)), Vali MSE Loss: 0.1787 Test MSE Loss: 0.1210
Validation loss decreased (inf --> 0.178715).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2214375
	speed: 0.0381s/iter; left time: 993.2235s
	iters: 200, epoch: 2 | loss: 0.2199927
	speed: 0.0374s/iter; left time: 970.6009s
Epoch: 2 cost time: 9.97926926612854
Epoch: 2, Steps: 264 Train Loss: 0.2324 (Forecasting Loss:0.2292 + XiCon Loss:3.2181 x Lambda(0.001)), Vali MSE Loss: 0.1811 Test MSE Loss: 0.1308
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2018292
	speed: 0.0392s/iter; left time: 1010.9888s
	iters: 200, epoch: 3 | loss: 0.1888707
	speed: 0.0373s/iter; left time: 956.6371s
Epoch: 3 cost time: 10.059188842773438
Epoch: 3, Steps: 264 Train Loss: 0.1946 (Forecasting Loss:0.1914 + XiCon Loss:3.1945 x Lambda(0.001)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.1568
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1653905
	speed: 0.0398s/iter; left time: 1015.2596s
	iters: 200, epoch: 4 | loss: 0.1658888
	speed: 0.0375s/iter; left time: 953.6064s
Epoch: 4 cost time: 10.097580909729004
Epoch: 4, Steps: 264 Train Loss: 0.1697 (Forecasting Loss:0.1665 + XiCon Loss:3.1826 x Lambda(0.001)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1419520
	speed: 0.0389s/iter; left time: 981.3753s
	iters: 200, epoch: 5 | loss: 0.1523880
	speed: 0.0379s/iter; left time: 953.6129s
Epoch: 5 cost time: 10.053908109664917
Epoch: 5, Steps: 264 Train Loss: 0.1568 (Forecasting Loss:0.1536 + XiCon Loss:3.1863 x Lambda(0.001)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1704
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1585325
	speed: 0.0395s/iter; left time: 987.6546s
	iters: 200, epoch: 6 | loss: 0.1503948
	speed: 0.0372s/iter; left time: 924.9122s
Epoch: 6 cost time: 10.093456983566284
Epoch: 6, Steps: 264 Train Loss: 0.1501 (Forecasting Loss:0.1469 + XiCon Loss:3.1871 x Lambda(0.001)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1718
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1441017
	speed: 0.0399s/iter; left time: 986.2671s
	iters: 200, epoch: 7 | loss: 0.1466917
	speed: 0.0366s/iter; left time: 901.2332s
Epoch: 7 cost time: 10.051135778427124
Epoch: 7, Steps: 264 Train Loss: 0.1469 (Forecasting Loss:0.1437 + XiCon Loss:3.1933 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1744
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1510379
	speed: 0.0397s/iter; left time: 970.3965s
	iters: 200, epoch: 8 | loss: 0.1446399
	speed: 0.0373s/iter; left time: 907.8201s
Epoch: 8 cost time: 10.15523910522461
Epoch: 8, Steps: 264 Train Loss: 0.1456 (Forecasting Loss:0.1424 + XiCon Loss:3.1913 x Lambda(0.001)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1750
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1466687
	speed: 0.0397s/iter; left time: 959.1921s
	iters: 200, epoch: 9 | loss: 0.1418733
	speed: 0.0365s/iter; left time: 879.4939s
Epoch: 9 cost time: 10.03735899925232
Epoch: 9, Steps: 264 Train Loss: 0.1448 (Forecasting Loss:0.1416 + XiCon Loss:3.1914 x Lambda(0.001)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1757
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1307477
	speed: 0.0389s/iter; left time: 929.7589s
	iters: 200, epoch: 10 | loss: 0.1382885
	speed: 0.0376s/iter; left time: 894.8382s
Epoch: 10 cost time: 10.026678800582886
Epoch: 10, Steps: 264 Train Loss: 0.1444 (Forecasting Loss:0.1412 + XiCon Loss:3.1909 x Lambda(0.001)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1754
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1358113
	speed: 0.0391s/iter; left time: 925.8476s
	iters: 200, epoch: 11 | loss: 0.1419613
	speed: 0.0373s/iter; left time: 877.9030s
Epoch: 11 cost time: 9.97398042678833
Epoch: 11, Steps: 264 Train Loss: 0.1443 (Forecasting Loss:0.1411 + XiCon Loss:3.1907 x Lambda(0.001)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1752
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.057978831231594086, mae:0.18395103514194489, mape:0.14445188641548157, mspe:0.03676368296146393 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3597
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2360404
	speed: 0.0400s/iter; left time: 1052.3041s
	iters: 200, epoch: 1 | loss: 0.2289910
	speed: 0.0376s/iter; left time: 984.7655s
Epoch: 1 cost time: 10.08678150177002
Epoch: 1, Steps: 264 Train Loss: 0.2398 (Forecasting Loss:0.2366 + XiCon Loss:3.2023 x Lambda(0.001)), Vali MSE Loss: 0.1759 Test MSE Loss: 0.1176
Validation loss decreased (inf --> 0.175855).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2156510
	speed: 0.0463s/iter; left time: 1205.9714s
	iters: 200, epoch: 2 | loss: 0.2253660
	speed: 0.0426s/iter; left time: 1103.7302s
Epoch: 2 cost time: 11.667301416397095
Epoch: 2, Steps: 264 Train Loss: 0.2300 (Forecasting Loss:0.2268 + XiCon Loss:3.2080 x Lambda(0.001)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1341
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1956231
	speed: 0.0448s/iter; left time: 1155.6514s
	iters: 200, epoch: 3 | loss: 0.1823855
	speed: 0.0427s/iter; left time: 1095.3980s
Epoch: 3 cost time: 11.450968265533447
Epoch: 3, Steps: 264 Train Loss: 0.1806 (Forecasting Loss:0.1774 + XiCon Loss:3.1973 x Lambda(0.001)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1574
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1512755
	speed: 0.0451s/iter; left time: 1151.5313s
	iters: 200, epoch: 4 | loss: 0.1541531
	speed: 0.0422s/iter; left time: 1073.5102s
Epoch: 4 cost time: 11.556729793548584
Epoch: 4, Steps: 264 Train Loss: 0.1537 (Forecasting Loss:0.1505 + XiCon Loss:3.1912 x Lambda(0.001)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1635
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1473708
	speed: 0.0446s/iter; left time: 1126.2247s
	iters: 200, epoch: 5 | loss: 0.1494110
	speed: 0.0425s/iter; left time: 1069.7198s
Epoch: 5 cost time: 11.47409176826477
Epoch: 5, Steps: 264 Train Loss: 0.1460 (Forecasting Loss:0.1428 + XiCon Loss:3.1923 x Lambda(0.001)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1751
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1383578
	speed: 0.0450s/iter; left time: 1123.8062s
	iters: 200, epoch: 6 | loss: 0.1367697
	speed: 0.0435s/iter; left time: 1081.9144s
Epoch: 6 cost time: 11.677810430526733
Epoch: 6, Steps: 264 Train Loss: 0.1421 (Forecasting Loss:0.1389 + XiCon Loss:3.1889 x Lambda(0.001)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1805
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1432458
	speed: 0.0456s/iter; left time: 1127.2121s
	iters: 200, epoch: 7 | loss: 0.1409248
	speed: 0.0437s/iter; left time: 1075.6450s
Epoch: 7 cost time: 11.74235224723816
Epoch: 7, Steps: 264 Train Loss: 0.1401 (Forecasting Loss:0.1370 + XiCon Loss:3.1892 x Lambda(0.001)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1784
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1375741
	speed: 0.0450s/iter; left time: 1101.0570s
	iters: 200, epoch: 8 | loss: 0.1328699
	speed: 0.0437s/iter; left time: 1064.5184s
Epoch: 8 cost time: 11.670098543167114
Epoch: 8, Steps: 264 Train Loss: 0.1396 (Forecasting Loss:0.1364 + XiCon Loss:3.1892 x Lambda(0.001)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1800
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1354958
	speed: 0.0453s/iter; left time: 1096.6878s
	iters: 200, epoch: 9 | loss: 0.1349971
	speed: 0.0423s/iter; left time: 1019.1417s
Epoch: 9 cost time: 11.489360094070435
Epoch: 9, Steps: 264 Train Loss: 0.1390 (Forecasting Loss:0.1359 + XiCon Loss:3.1854 x Lambda(0.001)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1798
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1405521
	speed: 0.0461s/iter; left time: 1103.2759s
	iters: 200, epoch: 10 | loss: 0.1267831
	speed: 0.0436s/iter; left time: 1037.8586s
Epoch: 10 cost time: 11.744994163513184
Epoch: 10, Steps: 264 Train Loss: 0.1390 (Forecasting Loss:0.1358 + XiCon Loss:3.1886 x Lambda(0.001)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1801
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1400243
	speed: 0.0451s/iter; left time: 1066.1489s
	iters: 200, epoch: 11 | loss: 0.1327709
	speed: 0.0424s/iter; left time: 998.1436s
Epoch: 11 cost time: 11.468285322189331
Epoch: 11, Steps: 264 Train Loss: 0.1387 (Forecasting Loss:0.1355 + XiCon Loss:3.1874 x Lambda(0.001)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1809
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05574076250195503, mae:0.17942240834236145, mape:0.13921590149402618, mspe:0.03396795317530632 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6242
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2458863
	speed: 0.0398s/iter; left time: 1045.9886s
	iters: 200, epoch: 1 | loss: 0.2439787
	speed: 0.0369s/iter; left time: 967.8184s
Epoch: 1 cost time: 10.031737089157104
Epoch: 1, Steps: 264 Train Loss: 0.2394 (Forecasting Loss:0.2362 + XiCon Loss:3.2114 x Lambda(0.001)), Vali MSE Loss: 0.1797 Test MSE Loss: 0.1204
Validation loss decreased (inf --> 0.179658).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2663648
	speed: 0.0437s/iter; left time: 1137.1826s
	iters: 200, epoch: 2 | loss: 0.2711769
	speed: 0.0413s/iter; left time: 1070.7000s
Epoch: 2 cost time: 11.059006929397583
Epoch: 2, Steps: 264 Train Loss: 0.2480 (Forecasting Loss:0.2447 + XiCon Loss:3.3016 x Lambda(0.001)), Vali MSE Loss: 0.1815 Test MSE Loss: 0.1202
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2425523
	speed: 0.0424s/iter; left time: 1091.8937s
	iters: 200, epoch: 3 | loss: 0.2242971
	speed: 0.0406s/iter; left time: 1041.5641s
Epoch: 3 cost time: 10.964929819107056
Epoch: 3, Steps: 264 Train Loss: 0.2364 (Forecasting Loss:0.2331 + XiCon Loss:3.3029 x Lambda(0.001)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1157
Validation loss decreased (0.179658 --> 0.175312).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2141230
	speed: 0.0436s/iter; left time: 1112.5712s
	iters: 200, epoch: 4 | loss: 0.2336926
	speed: 0.0402s/iter; left time: 1021.3438s
Epoch: 4 cost time: 11.061180830001831
Epoch: 4, Steps: 264 Train Loss: 0.2333 (Forecasting Loss:0.2300 + XiCon Loss:3.2986 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1132
Validation loss decreased (0.175312 --> 0.171415).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2491445
	speed: 0.0436s/iter; left time: 1100.7995s
	iters: 200, epoch: 5 | loss: 0.2378760
	speed: 0.0411s/iter; left time: 1034.4492s
Epoch: 5 cost time: 11.20541000366211
Epoch: 5, Steps: 264 Train Loss: 0.2318 (Forecasting Loss:0.2285 + XiCon Loss:3.3004 x Lambda(0.001)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1131
Validation loss decreased (0.171415 --> 0.170792).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2524068
	speed: 0.0430s/iter; left time: 1073.8259s
	iters: 200, epoch: 6 | loss: 0.2210063
	speed: 0.0414s/iter; left time: 1030.2045s
Epoch: 6 cost time: 11.081419229507446
Epoch: 6, Steps: 264 Train Loss: 0.2306 (Forecasting Loss:0.2273 + XiCon Loss:3.3004 x Lambda(0.001)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1126
Validation loss decreased (0.170792 --> 0.170260).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2198485
	speed: 0.0424s/iter; left time: 1048.9952s
	iters: 200, epoch: 7 | loss: 0.2178217
	speed: 0.0406s/iter; left time: 999.2046s
Epoch: 7 cost time: 10.941180229187012
Epoch: 7, Steps: 264 Train Loss: 0.2302 (Forecasting Loss:0.2269 + XiCon Loss:3.3007 x Lambda(0.001)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
Validation loss decreased (0.170260 --> 0.170177).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2246560
	speed: 0.0435s/iter; left time: 1064.3854s
	iters: 200, epoch: 8 | loss: 0.2247276
	speed: 0.0404s/iter; left time: 984.6213s
Epoch: 8 cost time: 11.06285834312439
Epoch: 8, Steps: 264 Train Loss: 0.2301 (Forecasting Loss:0.2268 + XiCon Loss:3.3011 x Lambda(0.001)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2365438
	speed: 0.0433s/iter; left time: 1048.0670s
	iters: 200, epoch: 9 | loss: 0.2275127
	speed: 0.0411s/iter; left time: 989.6852s
Epoch: 9 cost time: 11.047993183135986
Epoch: 9, Steps: 264 Train Loss: 0.2299 (Forecasting Loss:0.2266 + XiCon Loss:3.2993 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170177 --> 0.170012).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2032364
	speed: 0.0425s/iter; left time: 1016.2407s
	iters: 200, epoch: 10 | loss: 0.2410694
	speed: 0.0418s/iter; left time: 995.5327s
Epoch: 10 cost time: 11.055291652679443
Epoch: 10, Steps: 264 Train Loss: 0.2298 (Forecasting Loss:0.2265 + XiCon Loss:3.2988 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170012 --> 0.169974).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2691785
	speed: 0.0431s/iter; left time: 1020.1245s
	iters: 200, epoch: 11 | loss: 0.2178285
	speed: 0.0399s/iter; left time: 938.9834s
Epoch: 11 cost time: 10.981305837631226
Epoch: 11, Steps: 264 Train Loss: 0.2296 (Forecasting Loss:0.2263 + XiCon Loss:3.2979 x Lambda(0.001)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169974 --> 0.169904).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.2287336
	speed: 0.0428s/iter; left time: 1002.3949s
	iters: 200, epoch: 12 | loss: 0.2735321
	speed: 0.0404s/iter; left time: 941.8782s
Epoch: 12 cost time: 10.901957511901855
Epoch: 12, Steps: 264 Train Loss: 0.2297 (Forecasting Loss:0.2264 + XiCon Loss:3.2998 x Lambda(0.001)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.2299536
	speed: 0.0432s/iter; left time: 998.4237s
	iters: 200, epoch: 13 | loss: 0.2299610
	speed: 0.0408s/iter; left time: 940.0411s
Epoch: 13 cost time: 10.987469911575317
Epoch: 13, Steps: 264 Train Loss: 0.2296 (Forecasting Loss:0.2263 + XiCon Loss:3.2959 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.2369828
	speed: 0.0424s/iter; left time: 969.3518s
	iters: 200, epoch: 14 | loss: 0.2649218
	speed: 0.0409s/iter; left time: 930.9298s
Epoch: 14 cost time: 10.953438997268677
Epoch: 14, Steps: 264 Train Loss: 0.2296 (Forecasting Loss:0.2263 + XiCon Loss:3.2955 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.2340337
	speed: 0.0439s/iter; left time: 991.3522s
	iters: 200, epoch: 15 | loss: 0.2320628
	speed: 0.0414s/iter; left time: 931.5707s
Epoch: 15 cost time: 11.106770277023315
Epoch: 15, Steps: 264 Train Loss: 0.2296 (Forecasting Loss:0.2263 + XiCon Loss:3.2967 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.2373079
	speed: 0.0428s/iter; left time: 956.6557s
	iters: 200, epoch: 16 | loss: 0.2035556
	speed: 0.0402s/iter; left time: 893.8994s
Epoch: 16 cost time: 10.977171421051025
Epoch: 16, Steps: 264 Train Loss: 0.2295 (Forecasting Loss:0.2262 + XiCon Loss:3.2973 x Lambda(0.001)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.2260757
	speed: 0.0417s/iter; left time: 921.1282s
	iters: 200, epoch: 17 | loss: 0.2285023
	speed: 0.0406s/iter; left time: 892.1956s
Epoch: 17 cost time: 10.818169116973877
Epoch: 17, Steps: 264 Train Loss: 0.2297 (Forecasting Loss:0.2264 + XiCon Loss:3.3001 x Lambda(0.001)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.2326184
	speed: 0.0432s/iter; left time: 942.8361s
	iters: 200, epoch: 18 | loss: 0.2485887
	speed: 0.0405s/iter; left time: 880.0137s
Epoch: 18 cost time: 11.006813049316406
Epoch: 18, Steps: 264 Train Loss: 0.2296 (Forecasting Loss:0.2263 + XiCon Loss:3.2970 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.2207177
	speed: 0.0428s/iter; left time: 922.7799s
	iters: 200, epoch: 19 | loss: 0.2123736
	speed: 0.0418s/iter; left time: 897.4380s
Epoch: 19 cost time: 11.056889057159424
Epoch: 19, Steps: 264 Train Loss: 0.2298 (Forecasting Loss:0.2265 + XiCon Loss:3.2989 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.2322686
	speed: 0.0436s/iter; left time: 928.0564s
	iters: 200, epoch: 20 | loss: 0.2406117
	speed: 0.0412s/iter; left time: 873.4674s
Epoch: 20 cost time: 11.135056495666504
Epoch: 20, Steps: 264 Train Loss: 0.2297 (Forecasting Loss:0.2264 + XiCon Loss:3.2971 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.2214318
	speed: 0.0426s/iter; left time: 894.6644s
	iters: 200, epoch: 21 | loss: 0.2424530
	speed: 0.0409s/iter; left time: 854.9634s
Epoch: 21 cost time: 10.898004055023193
Epoch: 21, Steps: 264 Train Loss: 0.2297 (Forecasting Loss:0.2264 + XiCon Loss:3.2974 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05250673368573189, mae:0.1723288893699646, mape:0.1343747228384018, mspe:0.03214319050312042 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0553+-0.00249, MAE:0.1785+-0.00526, MAPE:0.1392+-0.00450, MSPE:0.0341+-0.00208, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9056
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2814813
	speed: 0.0429s/iter; left time: 1116.5500s
	iters: 200, epoch: 1 | loss: 0.3079841
	speed: 0.0378s/iter; left time: 979.5118s
Epoch: 1 cost time: 10.320077180862427
Epoch: 1, Steps: 261 Train Loss: 0.2804 (Forecasting Loss:0.2770 + XiCon Loss:3.4050 x Lambda(0.001)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.199483).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2615881
	speed: 0.0405s/iter; left time: 1042.5735s
	iters: 200, epoch: 2 | loss: 0.2639790
	speed: 0.0376s/iter; left time: 963.9449s
Epoch: 2 cost time: 10.136405229568481
Epoch: 2, Steps: 261 Train Loss: 0.2671 (Forecasting Loss:0.2637 + XiCon Loss:3.3979 x Lambda(0.001)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1408
Validation loss decreased (0.199483 --> 0.190314).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2494341
	speed: 0.0392s/iter; left time: 998.6410s
	iters: 200, epoch: 3 | loss: 0.2464182
	speed: 0.0382s/iter; left time: 970.5214s
Epoch: 3 cost time: 10.019412755966187
Epoch: 3, Steps: 261 Train Loss: 0.2475 (Forecasting Loss:0.2441 + XiCon Loss:3.3722 x Lambda(0.001)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.1453
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2507574
	speed: 0.0391s/iter; left time: 986.8013s
	iters: 200, epoch: 4 | loss: 0.2303079
	speed: 0.0374s/iter; left time: 938.9628s
Epoch: 4 cost time: 9.870036125183105
Epoch: 4, Steps: 261 Train Loss: 0.2331 (Forecasting Loss:0.2297 + XiCon Loss:3.3733 x Lambda(0.001)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1477
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2337210
	speed: 0.0384s/iter; left time: 957.8415s
	iters: 200, epoch: 5 | loss: 0.2329347
	speed: 0.0377s/iter; left time: 938.3123s
Epoch: 5 cost time: 9.854891777038574
Epoch: 5, Steps: 261 Train Loss: 0.2260 (Forecasting Loss:0.2227 + XiCon Loss:3.3750 x Lambda(0.001)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1513
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2417792
	speed: 0.0397s/iter; left time: 979.6167s
	iters: 200, epoch: 6 | loss: 0.2074952
	speed: 0.0381s/iter; left time: 936.8059s
Epoch: 6 cost time: 10.0896155834198
Epoch: 6, Steps: 261 Train Loss: 0.2229 (Forecasting Loss:0.2195 + XiCon Loss:3.3775 x Lambda(0.001)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1502
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2148510
	speed: 0.0401s/iter; left time: 979.9333s
	iters: 200, epoch: 7 | loss: 0.2209623
	speed: 0.0369s/iter; left time: 898.5705s
Epoch: 7 cost time: 9.988274574279785
Epoch: 7, Steps: 261 Train Loss: 0.2212 (Forecasting Loss:0.2179 + XiCon Loss:3.3763 x Lambda(0.001)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1488
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2280937
	speed: 0.0389s/iter; left time: 940.5727s
	iters: 200, epoch: 8 | loss: 0.2244074
	speed: 0.0374s/iter; left time: 901.5004s
Epoch: 8 cost time: 9.841361045837402
Epoch: 8, Steps: 261 Train Loss: 0.2205 (Forecasting Loss:0.2171 + XiCon Loss:3.3787 x Lambda(0.001)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2160729
	speed: 0.0402s/iter; left time: 961.4472s
	iters: 200, epoch: 9 | loss: 0.2295233
	speed: 0.0380s/iter; left time: 905.5384s
Epoch: 9 cost time: 10.127143621444702
Epoch: 9, Steps: 261 Train Loss: 0.2200 (Forecasting Loss:0.2166 + XiCon Loss:3.3787 x Lambda(0.001)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.1500
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2120309
	speed: 0.0396s/iter; left time: 935.4519s
	iters: 200, epoch: 10 | loss: 0.2210568
	speed: 0.0375s/iter; left time: 883.5442s
Epoch: 10 cost time: 10.04819917678833
Epoch: 10, Steps: 261 Train Loss: 0.2198 (Forecasting Loss:0.2165 + XiCon Loss:3.3780 x Lambda(0.001)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2264099
	speed: 0.0400s/iter; left time: 934.6741s
	iters: 200, epoch: 11 | loss: 0.2188119
	speed: 0.0371s/iter; left time: 863.8094s
Epoch: 11 cost time: 10.007350206375122
Epoch: 11, Steps: 261 Train Loss: 0.2197 (Forecasting Loss:0.2163 + XiCon Loss:3.3773 x Lambda(0.001)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1499
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2444685
	speed: 0.0423s/iter; left time: 978.8105s
	iters: 200, epoch: 12 | loss: 0.2116594
	speed: 0.0371s/iter; left time: 853.6866s
Epoch: 12 cost time: 10.213613510131836
Epoch: 12, Steps: 261 Train Loss: 0.2198 (Forecasting Loss:0.2164 + XiCon Loss:3.3781 x Lambda(0.001)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07464218884706497, mae:0.20696140825748444, mape:0.15826600790023804, mspe:0.04330456629395485 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7109
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2715686
	speed: 0.0362s/iter; left time: 941.3896s
	iters: 200, epoch: 1 | loss: 0.2543913
	speed: 0.0331s/iter; left time: 856.3400s
Epoch: 1 cost time: 8.96870756149292
Epoch: 1, Steps: 261 Train Loss: 0.2786 (Forecasting Loss:0.2751 + XiCon Loss:3.4134 x Lambda(0.001)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1409
Validation loss decreased (inf --> 0.199737).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2770538
	speed: 0.0357s/iter; left time: 918.1433s
	iters: 200, epoch: 2 | loss: 0.2483008
	speed: 0.0348s/iter; left time: 891.2803s
Epoch: 2 cost time: 9.136977672576904
Epoch: 2, Steps: 261 Train Loss: 0.2674 (Forecasting Loss:0.2641 + XiCon Loss:3.3969 x Lambda(0.001)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2675765
	speed: 0.0382s/iter; left time: 973.5939s
	iters: 200, epoch: 3 | loss: 0.2558357
	speed: 0.0354s/iter; left time: 898.3358s
Epoch: 3 cost time: 9.443758726119995
Epoch: 3, Steps: 261 Train Loss: 0.2435 (Forecasting Loss:0.2401 + XiCon Loss:3.3650 x Lambda(0.001)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1545
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2173661
	speed: 0.0385s/iter; left time: 971.0676s
	iters: 200, epoch: 4 | loss: 0.2273399
	speed: 0.0356s/iter; left time: 893.6798s
Epoch: 4 cost time: 9.612796783447266
Epoch: 4, Steps: 261 Train Loss: 0.2286 (Forecasting Loss:0.2252 + XiCon Loss:3.3550 x Lambda(0.001)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1605
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2234689
	speed: 0.0390s/iter; left time: 974.5209s
	iters: 200, epoch: 5 | loss: 0.2504612
	speed: 0.0365s/iter; left time: 907.9305s
Epoch: 5 cost time: 9.760149955749512
Epoch: 5, Steps: 261 Train Loss: 0.2204 (Forecasting Loss:0.2171 + XiCon Loss:3.3589 x Lambda(0.001)), Vali MSE Loss: 0.2268 Test MSE Loss: 0.1637
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2204890
	speed: 0.0395s/iter; left time: 975.2876s
	iters: 200, epoch: 6 | loss: 0.1978714
	speed: 0.0367s/iter; left time: 902.4289s
Epoch: 6 cost time: 9.797181844711304
Epoch: 6, Steps: 261 Train Loss: 0.2165 (Forecasting Loss:0.2132 + XiCon Loss:3.3581 x Lambda(0.001)), Vali MSE Loss: 0.2246 Test MSE Loss: 0.1640
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2080892
	speed: 0.0391s/iter; left time: 955.1236s
	iters: 200, epoch: 7 | loss: 0.2012325
	speed: 0.0367s/iter; left time: 892.8769s
Epoch: 7 cost time: 9.806382656097412
Epoch: 7, Steps: 261 Train Loss: 0.2144 (Forecasting Loss:0.2110 + XiCon Loss:3.3603 x Lambda(0.001)), Vali MSE Loss: 0.2257 Test MSE Loss: 0.1648
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2173362
	speed: 0.0391s/iter; left time: 945.1813s
	iters: 200, epoch: 8 | loss: 0.2223379
	speed: 0.0373s/iter; left time: 897.4739s
Epoch: 8 cost time: 9.844147205352783
Epoch: 8, Steps: 261 Train Loss: 0.2136 (Forecasting Loss:0.2103 + XiCon Loss:3.3586 x Lambda(0.001)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1655
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1981084
	speed: 0.0400s/iter; left time: 955.3451s
	iters: 200, epoch: 9 | loss: 0.2073712
	speed: 0.0366s/iter; left time: 870.7193s
Epoch: 9 cost time: 9.977387428283691
Epoch: 9, Steps: 261 Train Loss: 0.2134 (Forecasting Loss:0.2100 + XiCon Loss:3.3588 x Lambda(0.001)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1660
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2169307
	speed: 0.0402s/iter; left time: 950.8271s
	iters: 200, epoch: 10 | loss: 0.2041233
	speed: 0.0363s/iter; left time: 855.0705s
Epoch: 10 cost time: 9.871937274932861
Epoch: 10, Steps: 261 Train Loss: 0.2130 (Forecasting Loss:0.2097 + XiCon Loss:3.3596 x Lambda(0.001)), Vali MSE Loss: 0.2286 Test MSE Loss: 0.1662
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1971517
	speed: 0.0391s/iter; left time: 913.5147s
	iters: 200, epoch: 11 | loss: 0.2087046
	speed: 0.0362s/iter; left time: 844.2468s
Epoch: 11 cost time: 9.802554607391357
Epoch: 11, Steps: 261 Train Loss: 0.2130 (Forecasting Loss:0.2096 + XiCon Loss:3.3587 x Lambda(0.001)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1661
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07424198091030121, mae:0.20757749676704407, mape:0.1562958061695099, mspe:0.04043235257267952 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5881
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2744967
	speed: 0.0398s/iter; left time: 1034.2668s
	iters: 200, epoch: 1 | loss: 0.2886009
	speed: 0.0375s/iter; left time: 971.6166s
Epoch: 1 cost time: 9.975330114364624
Epoch: 1, Steps: 261 Train Loss: 0.2795 (Forecasting Loss:0.2761 + XiCon Loss:3.3989 x Lambda(0.001)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1406
Validation loss decreased (inf --> 0.199586).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2651324
	speed: 0.0395s/iter; left time: 1017.0547s
	iters: 200, epoch: 2 | loss: 0.2580989
	speed: 0.0375s/iter; left time: 961.5377s
Epoch: 2 cost time: 9.989887714385986
Epoch: 2, Steps: 261 Train Loss: 0.2671 (Forecasting Loss:0.2637 + XiCon Loss:3.3922 x Lambda(0.001)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1416
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2499720
	speed: 0.0398s/iter; left time: 1015.2140s
	iters: 200, epoch: 3 | loss: 0.2380043
	speed: 0.0380s/iter; left time: 964.9840s
Epoch: 3 cost time: 10.11012864112854
Epoch: 3, Steps: 261 Train Loss: 0.2370 (Forecasting Loss:0.2337 + XiCon Loss:3.3867 x Lambda(0.001)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1470
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2048271
	speed: 0.0403s/iter; left time: 1015.2962s
	iters: 200, epoch: 4 | loss: 0.2157269
	speed: 0.0383s/iter; left time: 962.7188s
Epoch: 4 cost time: 10.209497690200806
Epoch: 4, Steps: 261 Train Loss: 0.2206 (Forecasting Loss:0.2172 + XiCon Loss:3.3924 x Lambda(0.001)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1542
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2126268
	speed: 0.0403s/iter; left time: 1007.0060s
	iters: 200, epoch: 5 | loss: 0.1990033
	speed: 0.0393s/iter; left time: 977.2291s
Epoch: 5 cost time: 10.320301055908203
Epoch: 5, Steps: 261 Train Loss: 0.2129 (Forecasting Loss:0.2095 + XiCon Loss:3.3935 x Lambda(0.001)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1563
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2060745
	speed: 0.0410s/iter; left time: 1012.9768s
	iters: 200, epoch: 6 | loss: 0.2107486
	speed: 0.0383s/iter; left time: 942.4236s
Epoch: 6 cost time: 10.292931318283081
Epoch: 6, Steps: 261 Train Loss: 0.2089 (Forecasting Loss:0.2055 + XiCon Loss:3.3928 x Lambda(0.001)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.1579
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2003214
	speed: 0.0411s/iter; left time: 1004.9956s
	iters: 200, epoch: 7 | loss: 0.1992387
	speed: 0.0387s/iter; left time: 941.3347s
Epoch: 7 cost time: 10.33348274230957
Epoch: 7, Steps: 261 Train Loss: 0.2072 (Forecasting Loss:0.2038 + XiCon Loss:3.3916 x Lambda(0.001)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.1577
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2021659
	speed: 0.0405s/iter; left time: 979.3787s
	iters: 200, epoch: 8 | loss: 0.2037420
	speed: 0.0386s/iter; left time: 929.8318s
Epoch: 8 cost time: 10.26102352142334
Epoch: 8, Steps: 261 Train Loss: 0.2064 (Forecasting Loss:0.2030 + XiCon Loss:3.3929 x Lambda(0.001)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2002027
	speed: 0.0404s/iter; left time: 966.2036s
	iters: 200, epoch: 9 | loss: 0.2191950
	speed: 0.0378s/iter; left time: 899.9229s
Epoch: 9 cost time: 10.141976356506348
Epoch: 9, Steps: 261 Train Loss: 0.2060 (Forecasting Loss:0.2026 + XiCon Loss:3.3926 x Lambda(0.001)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1589
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2086093
	speed: 0.0413s/iter; left time: 977.4413s
	iters: 200, epoch: 10 | loss: 0.2000883
	speed: 0.0379s/iter; left time: 893.1168s
Epoch: 10 cost time: 10.169164180755615
Epoch: 10, Steps: 261 Train Loss: 0.2061 (Forecasting Loss:0.2027 + XiCon Loss:3.3935 x Lambda(0.001)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1589
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2042007
	speed: 0.0403s/iter; left time: 942.8339s
	iters: 200, epoch: 11 | loss: 0.2087363
	speed: 0.0374s/iter; left time: 870.0365s
Epoch: 11 cost time: 10.038065195083618
Epoch: 11, Steps: 261 Train Loss: 0.2055 (Forecasting Loss:0.2021 + XiCon Loss:3.3928 x Lambda(0.001)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1588
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07388538122177124, mae:0.2072938233613968, mape:0.15643763542175293, mspe:0.040805671364068985 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2761
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2850195
	speed: 0.0385s/iter; left time: 1000.8914s
	iters: 200, epoch: 1 | loss: 0.2859588
	speed: 0.0347s/iter; left time: 898.0896s
Epoch: 1 cost time: 9.471240043640137
Epoch: 1, Steps: 261 Train Loss: 0.2799 (Forecasting Loss:0.2765 + XiCon Loss:3.3983 x Lambda(0.001)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1426
Validation loss decreased (inf --> 0.198878).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2790151
	speed: 0.0373s/iter; left time: 959.3694s
	iters: 200, epoch: 2 | loss: 0.2722006
	speed: 0.0357s/iter; left time: 915.7110s
Epoch: 2 cost time: 9.352010250091553
Epoch: 2, Steps: 261 Train Loss: 0.2653 (Forecasting Loss:0.2619 + XiCon Loss:3.3710 x Lambda(0.001)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1443
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2374610
	speed: 0.0374s/iter; left time: 951.9346s
	iters: 200, epoch: 3 | loss: 0.2404454
	speed: 0.0349s/iter; left time: 884.9174s
Epoch: 3 cost time: 9.2878897190094
Epoch: 3, Steps: 261 Train Loss: 0.2341 (Forecasting Loss:0.2308 + XiCon Loss:3.3504 x Lambda(0.001)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1507
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2168268
	speed: 0.0366s/iter; left time: 923.5137s
	iters: 200, epoch: 4 | loss: 0.2094733
	speed: 0.0343s/iter; left time: 860.5776s
Epoch: 4 cost time: 9.233227491378784
Epoch: 4, Steps: 261 Train Loss: 0.2175 (Forecasting Loss:0.2141 + XiCon Loss:3.3569 x Lambda(0.001)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1438
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2021128
	speed: 0.0373s/iter; left time: 930.4365s
	iters: 200, epoch: 5 | loss: 0.2182629
	speed: 0.0345s/iter; left time: 857.9433s
Epoch: 5 cost time: 9.224154472351074
Epoch: 5, Steps: 261 Train Loss: 0.2108 (Forecasting Loss:0.2074 + XiCon Loss:3.3581 x Lambda(0.001)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1472
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2009110
	speed: 0.0376s/iter; left time: 927.9192s
	iters: 200, epoch: 6 | loss: 0.1991146
	speed: 0.0344s/iter; left time: 844.9222s
Epoch: 6 cost time: 9.265002727508545
Epoch: 6, Steps: 261 Train Loss: 0.2075 (Forecasting Loss:0.2042 + XiCon Loss:3.3581 x Lambda(0.001)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1493
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2203693
	speed: 0.0376s/iter; left time: 918.6697s
	iters: 200, epoch: 7 | loss: 0.2123437
	speed: 0.0350s/iter; left time: 852.3833s
Epoch: 7 cost time: 9.295752048492432
Epoch: 7, Steps: 261 Train Loss: 0.2065 (Forecasting Loss:0.2031 + XiCon Loss:3.3572 x Lambda(0.001)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1497
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2120965
	speed: 0.0363s/iter; left time: 877.5408s
	iters: 200, epoch: 8 | loss: 0.2206755
	speed: 0.0367s/iter; left time: 883.9531s
Epoch: 8 cost time: 9.459718704223633
Epoch: 8, Steps: 261 Train Loss: 0.2051 (Forecasting Loss:0.2018 + XiCon Loss:3.3564 x Lambda(0.001)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1483
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2041663
	speed: 0.0382s/iter; left time: 913.3716s
	iters: 200, epoch: 9 | loss: 0.1951561
	speed: 0.0350s/iter; left time: 834.1589s
Epoch: 9 cost time: 9.451502561569214
Epoch: 9, Steps: 261 Train Loss: 0.2052 (Forecasting Loss:0.2019 + XiCon Loss:3.3574 x Lambda(0.001)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1487
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2074896
	speed: 0.0373s/iter; left time: 883.3724s
	iters: 200, epoch: 10 | loss: 0.1918918
	speed: 0.0343s/iter; left time: 808.3398s
Epoch: 10 cost time: 9.323557615280151
Epoch: 10, Steps: 261 Train Loss: 0.2047 (Forecasting Loss:0.2014 + XiCon Loss:3.3585 x Lambda(0.001)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1492
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2114811
	speed: 0.0375s/iter; left time: 877.0830s
	iters: 200, epoch: 11 | loss: 0.1980883
	speed: 0.0354s/iter; left time: 824.5084s
Epoch: 11 cost time: 9.4037446975708
Epoch: 11, Steps: 261 Train Loss: 0.2049 (Forecasting Loss:0.2015 + XiCon Loss:3.3582 x Lambda(0.001)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1490
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07557852566242218, mae:0.20969977974891663, mape:0.15727439522743225, mspe:0.04063894972205162 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4827
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2668579
	speed: 0.0385s/iter; left time: 1001.5991s
	iters: 200, epoch: 1 | loss: 0.2630674
	speed: 0.0346s/iter; left time: 895.5846s
Epoch: 1 cost time: 9.445128917694092
Epoch: 1, Steps: 261 Train Loss: 0.2806 (Forecasting Loss:0.2772 + XiCon Loss:3.4297 x Lambda(0.001)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1405
Validation loss decreased (inf --> 0.196699).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2619495
	speed: 0.0373s/iter; left time: 960.7480s
	iters: 200, epoch: 2 | loss: 0.2409820
	speed: 0.0352s/iter; left time: 902.9477s
Epoch: 2 cost time: 9.331407308578491
Epoch: 2, Steps: 261 Train Loss: 0.2687 (Forecasting Loss:0.2653 + XiCon Loss:3.4026 x Lambda(0.001)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1433
Validation loss decreased (0.196699 --> 0.186968).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2134571
	speed: 0.0384s/iter; left time: 977.2032s
	iters: 200, epoch: 3 | loss: 0.2252159
	speed: 0.0351s/iter; left time: 891.4136s
Epoch: 3 cost time: 9.477129459381104
Epoch: 3, Steps: 261 Train Loss: 0.2451 (Forecasting Loss:0.2417 + XiCon Loss:3.3888 x Lambda(0.001)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1513
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2377547
	speed: 0.0383s/iter; left time: 965.3786s
	iters: 200, epoch: 4 | loss: 0.2330862
	speed: 0.0362s/iter; left time: 908.0191s
Epoch: 4 cost time: 9.651475429534912
Epoch: 4, Steps: 261 Train Loss: 0.2297 (Forecasting Loss:0.2263 + XiCon Loss:3.3743 x Lambda(0.001)), Vali MSE Loss: 0.2148 Test MSE Loss: 0.1566
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2185641
	speed: 0.0386s/iter; left time: 962.4150s
	iters: 200, epoch: 5 | loss: 0.2075921
	speed: 0.0370s/iter; left time: 919.9071s
Epoch: 5 cost time: 9.769112825393677
Epoch: 5, Steps: 261 Train Loss: 0.2231 (Forecasting Loss:0.2198 + XiCon Loss:3.3704 x Lambda(0.001)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1602
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2205285
	speed: 0.0379s/iter; left time: 936.9215s
	iters: 200, epoch: 6 | loss: 0.2131280
	speed: 0.0358s/iter; left time: 880.8205s
Epoch: 6 cost time: 9.544740200042725
Epoch: 6, Steps: 261 Train Loss: 0.2200 (Forecasting Loss:0.2167 + XiCon Loss:3.3696 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1599
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2132770
	speed: 0.0397s/iter; left time: 968.8531s
	iters: 200, epoch: 7 | loss: 0.2257928
	speed: 0.0351s/iter; left time: 853.5545s
Epoch: 7 cost time: 9.639286756515503
Epoch: 7, Steps: 261 Train Loss: 0.2185 (Forecasting Loss:0.2151 + XiCon Loss:3.3680 x Lambda(0.001)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1600
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2208488
	speed: 0.0392s/iter; left time: 947.8980s
	iters: 200, epoch: 8 | loss: 0.2042936
	speed: 0.0360s/iter; left time: 867.4528s
Epoch: 8 cost time: 9.682453632354736
Epoch: 8, Steps: 261 Train Loss: 0.2175 (Forecasting Loss:0.2142 + XiCon Loss:3.3697 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1603
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2156244
	speed: 0.0385s/iter; left time: 921.7303s
	iters: 200, epoch: 9 | loss: 0.2037062
	speed: 0.0361s/iter; left time: 860.1277s
Epoch: 9 cost time: 9.657222747802734
Epoch: 9, Steps: 261 Train Loss: 0.2174 (Forecasting Loss:0.2141 + XiCon Loss:3.3706 x Lambda(0.001)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1600
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2358181
	speed: 0.0384s/iter; left time: 907.1425s
	iters: 200, epoch: 10 | loss: 0.2173727
	speed: 0.0363s/iter; left time: 854.3856s
Epoch: 10 cost time: 9.648120164871216
Epoch: 10, Steps: 261 Train Loss: 0.2172 (Forecasting Loss:0.2139 + XiCon Loss:3.3701 x Lambda(0.001)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1601
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2259941
	speed: 0.0390s/iter; left time: 912.8988s
	iters: 200, epoch: 11 | loss: 0.2184208
	speed: 0.0371s/iter; left time: 864.4998s
Epoch: 11 cost time: 9.79794192314148
Epoch: 11, Steps: 261 Train Loss: 0.2172 (Forecasting Loss:0.2138 + XiCon Loss:3.3693 x Lambda(0.001)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1601
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2191835
	speed: 0.0392s/iter; left time: 907.3387s
	iters: 200, epoch: 12 | loss: 0.2115346
	speed: 0.0361s/iter; left time: 830.4221s
Epoch: 12 cost time: 9.700133085250854
Epoch: 12, Steps: 261 Train Loss: 0.2168 (Forecasting Loss:0.2135 + XiCon Loss:3.3694 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1601
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07604897022247314, mae:0.21057599782943726, mape:0.16325902938842773, mspe:0.04696189984679222 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0749+-0.00113, MAE:0.2084+-0.00200, MAPE:0.1583+-0.00357, MSPE:0.0424+-0.00346, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2533
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1685199
	speed: 0.0386s/iter; left time: 1023.5120s
	iters: 200, epoch: 1 | loss: 0.1815518
	speed: 0.0306s/iter; left time: 807.2875s
Epoch: 1 cost time: 9.096431732177734
Epoch: 1, Steps: 266 Train Loss: 0.1875 (Forecasting Loss:0.1841 + XiCon Loss:3.3720 x Lambda(0.001)), Vali MSE Loss: 0.1543 Test MSE Loss: 0.1359
Validation loss decreased (inf --> 0.154278).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1620524
	speed: 0.0332s/iter; left time: 872.0583s
	iters: 200, epoch: 2 | loss: 0.1649652
	speed: 0.0296s/iter; left time: 772.8149s
Epoch: 2 cost time: 8.288376092910767
Epoch: 2, Steps: 266 Train Loss: 0.1578 (Forecasting Loss:0.1545 + XiCon Loss:3.3339 x Lambda(0.001)), Vali MSE Loss: 0.1516 Test MSE Loss: 0.1335
Validation loss decreased (0.154278 --> 0.151573).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1354450
	speed: 0.0323s/iter; left time: 839.0708s
	iters: 200, epoch: 3 | loss: 0.1287936
	speed: 0.0305s/iter; left time: 787.7962s
Epoch: 3 cost time: 8.298685312271118
Epoch: 3, Steps: 266 Train Loss: 0.1435 (Forecasting Loss:0.1402 + XiCon Loss:3.3123 x Lambda(0.001)), Vali MSE Loss: 0.1540 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1226833
	speed: 0.0332s/iter; left time: 852.3294s
	iters: 200, epoch: 4 | loss: 0.1262595
	speed: 0.0303s/iter; left time: 775.5887s
Epoch: 4 cost time: 8.400181531906128
Epoch: 4, Steps: 266 Train Loss: 0.1306 (Forecasting Loss:0.1273 + XiCon Loss:3.3210 x Lambda(0.001)), Vali MSE Loss: 0.1611 Test MSE Loss: 0.1431
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1264851
	speed: 0.0318s/iter; left time: 808.9034s
	iters: 200, epoch: 5 | loss: 0.1189039
	speed: 0.0306s/iter; left time: 775.2377s
Epoch: 5 cost time: 8.37822699546814
Epoch: 5, Steps: 266 Train Loss: 0.1196 (Forecasting Loss:0.1163 + XiCon Loss:3.3248 x Lambda(0.001)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1489
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1144127
	speed: 0.0331s/iter; left time: 832.4467s
	iters: 200, epoch: 6 | loss: 0.1071909
	speed: 0.0316s/iter; left time: 791.4690s
Epoch: 6 cost time: 8.527825355529785
Epoch: 6, Steps: 266 Train Loss: 0.1142 (Forecasting Loss:0.1109 + XiCon Loss:3.3283 x Lambda(0.001)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1520
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1170650
	speed: 0.0333s/iter; left time: 828.1986s
	iters: 200, epoch: 7 | loss: 0.1169124
	speed: 0.0309s/iter; left time: 767.5320s
Epoch: 7 cost time: 8.495224714279175
Epoch: 7, Steps: 266 Train Loss: 0.1118 (Forecasting Loss:0.1085 + XiCon Loss:3.3282 x Lambda(0.001)), Vali MSE Loss: 0.1616 Test MSE Loss: 0.1530
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1059870
	speed: 0.0327s/iter; left time: 806.5796s
	iters: 200, epoch: 8 | loss: 0.1198097
	speed: 0.0302s/iter; left time: 741.5292s
Epoch: 8 cost time: 8.334145784378052
Epoch: 8, Steps: 266 Train Loss: 0.1106 (Forecasting Loss:0.1072 + XiCon Loss:3.3285 x Lambda(0.001)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1552
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1084681
	speed: 0.0325s/iter; left time: 791.7884s
	iters: 200, epoch: 9 | loss: 0.1067199
	speed: 0.0311s/iter; left time: 755.5650s
Epoch: 9 cost time: 8.380716562271118
Epoch: 9, Steps: 266 Train Loss: 0.1098 (Forecasting Loss:0.1065 + XiCon Loss:3.3287 x Lambda(0.001)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1552
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1168329
	speed: 0.0335s/iter; left time: 807.7987s
	iters: 200, epoch: 10 | loss: 0.1027582
	speed: 0.0321s/iter; left time: 770.2062s
Epoch: 10 cost time: 8.683628559112549
Epoch: 10, Steps: 266 Train Loss: 0.1096 (Forecasting Loss:0.1063 + XiCon Loss:3.3290 x Lambda(0.001)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1555
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1048929
	speed: 0.0337s/iter; left time: 803.6021s
	iters: 200, epoch: 11 | loss: 0.1236480
	speed: 0.0327s/iter; left time: 775.8358s
Epoch: 11 cost time: 8.7642662525177
Epoch: 11, Steps: 266 Train Loss: 0.1094 (Forecasting Loss:0.1061 + XiCon Loss:3.3305 x Lambda(0.001)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1555
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1172425
	speed: 0.0335s/iter; left time: 789.2204s
	iters: 200, epoch: 12 | loss: 0.1050804
	speed: 0.0312s/iter; left time: 732.0091s
Epoch: 12 cost time: 8.5238516330719
Epoch: 12, Steps: 266 Train Loss: 0.1093 (Forecasting Loss:0.1059 + XiCon Loss:3.3311 x Lambda(0.001)), Vali MSE Loss: 0.1627 Test MSE Loss: 0.1554
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07053528726100922, mae:0.19645114243030548, mape:0.49127906560897827, mspe:9.519149780273438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6809
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1804111
	speed: 0.0321s/iter; left time: 850.8516s
	iters: 200, epoch: 1 | loss: 0.1340332
	speed: 0.0310s/iter; left time: 819.7270s
Epoch: 1 cost time: 8.44201946258545
Epoch: 1, Steps: 266 Train Loss: 0.1892 (Forecasting Loss:0.1858 + XiCon Loss:3.3981 x Lambda(0.001)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.1355
Validation loss decreased (inf --> 0.157920).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1568359
	speed: 0.0330s/iter; left time: 866.1963s
	iters: 200, epoch: 2 | loss: 0.1388012
	speed: 0.0314s/iter; left time: 821.4321s
Epoch: 2 cost time: 8.585927963256836
Epoch: 2, Steps: 266 Train Loss: 0.1534 (Forecasting Loss:0.1500 + XiCon Loss:3.3939 x Lambda(0.001)), Vali MSE Loss: 0.1583 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1321006
	speed: 0.0343s/iter; left time: 890.4050s
	iters: 200, epoch: 3 | loss: 0.1270617
	speed: 0.0305s/iter; left time: 789.3160s
Epoch: 3 cost time: 8.596080780029297
Epoch: 3, Steps: 266 Train Loss: 0.1320 (Forecasting Loss:0.1286 + XiCon Loss:3.3781 x Lambda(0.001)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1451
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1228453
	speed: 0.0342s/iter; left time: 879.8876s
	iters: 200, epoch: 4 | loss: 0.1162143
	speed: 0.0319s/iter; left time: 818.0158s
Epoch: 4 cost time: 8.755367517471313
Epoch: 4, Steps: 266 Train Loss: 0.1164 (Forecasting Loss:0.1131 + XiCon Loss:3.3771 x Lambda(0.001)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1510
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.0996620
	speed: 0.0336s/iter; left time: 855.9344s
	iters: 200, epoch: 5 | loss: 0.1007982
	speed: 0.0324s/iter; left time: 821.0089s
Epoch: 5 cost time: 8.755722522735596
Epoch: 5, Steps: 266 Train Loss: 0.1084 (Forecasting Loss:0.1050 + XiCon Loss:3.3752 x Lambda(0.001)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1534
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1013766
	speed: 0.0341s/iter; left time: 858.1265s
	iters: 200, epoch: 6 | loss: 0.1117744
	speed: 0.0321s/iter; left time: 804.1503s
Epoch: 6 cost time: 8.703613996505737
Epoch: 6, Steps: 266 Train Loss: 0.1047 (Forecasting Loss:0.1014 + XiCon Loss:3.3758 x Lambda(0.001)), Vali MSE Loss: 0.1745 Test MSE Loss: 0.1534
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1115851
	speed: 0.0339s/iter; left time: 845.2430s
	iters: 200, epoch: 7 | loss: 0.1010224
	speed: 0.0323s/iter; left time: 799.9959s
Epoch: 7 cost time: 8.757323503494263
Epoch: 7, Steps: 266 Train Loss: 0.1028 (Forecasting Loss:0.0994 + XiCon Loss:3.3722 x Lambda(0.001)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1542
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0999136
	speed: 0.0335s/iter; left time: 824.5600s
	iters: 200, epoch: 8 | loss: 0.1018734
	speed: 0.0310s/iter; left time: 759.5503s
Epoch: 8 cost time: 8.55414605140686
Epoch: 8, Steps: 266 Train Loss: 0.1021 (Forecasting Loss:0.0987 + XiCon Loss:3.3718 x Lambda(0.001)), Vali MSE Loss: 0.1746 Test MSE Loss: 0.1554
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1004273
	speed: 0.0335s/iter; left time: 817.0074s
	iters: 200, epoch: 9 | loss: 0.0924165
	speed: 0.0317s/iter; left time: 770.0246s
Epoch: 9 cost time: 8.646395206451416
Epoch: 9, Steps: 266 Train Loss: 0.1014 (Forecasting Loss:0.0980 + XiCon Loss:3.3735 x Lambda(0.001)), Vali MSE Loss: 0.1747 Test MSE Loss: 0.1544
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0943210
	speed: 0.0343s/iter; left time: 825.9571s
	iters: 200, epoch: 10 | loss: 0.0961872
	speed: 0.0319s/iter; left time: 765.3092s
Epoch: 10 cost time: 8.775475978851318
Epoch: 10, Steps: 266 Train Loss: 0.1012 (Forecasting Loss:0.0979 + XiCon Loss:3.3743 x Lambda(0.001)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1546
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.0952989
	speed: 0.0334s/iter; left time: 796.4675s
	iters: 200, epoch: 11 | loss: 0.1022442
	speed: 0.0317s/iter; left time: 751.4132s
Epoch: 11 cost time: 8.575412034988403
Epoch: 11, Steps: 266 Train Loss: 0.1012 (Forecasting Loss:0.0978 + XiCon Loss:3.3720 x Lambda(0.001)), Vali MSE Loss: 0.1751 Test MSE Loss: 0.1552
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07150708138942719, mae:0.1994568407535553, mape:0.48715564608573914, mspe:8.938703536987305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5830
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1659093
	speed: 0.0329s/iter; left time: 871.5431s
	iters: 200, epoch: 1 | loss: 0.1740926
	speed: 0.0301s/iter; left time: 794.5706s
Epoch: 1 cost time: 8.359061241149902
Epoch: 1, Steps: 266 Train Loss: 0.1853 (Forecasting Loss:0.1819 + XiCon Loss:3.3703 x Lambda(0.001)), Vali MSE Loss: 0.1568 Test MSE Loss: 0.1364
Validation loss decreased (inf --> 0.156808).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1539994
	speed: 0.0333s/iter; left time: 873.2753s
	iters: 200, epoch: 2 | loss: 0.1568878
	speed: 0.0307s/iter; left time: 801.9776s
Epoch: 2 cost time: 8.481958627700806
Epoch: 2, Steps: 266 Train Loss: 0.1585 (Forecasting Loss:0.1552 + XiCon Loss:3.3314 x Lambda(0.001)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.1374
Validation loss decreased (0.156808 --> 0.147593).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1330800
	speed: 0.0334s/iter; left time: 866.9586s
	iters: 200, epoch: 3 | loss: 0.1645007
	speed: 0.0313s/iter; left time: 810.3857s
Epoch: 3 cost time: 8.56234860420227
Epoch: 3, Steps: 266 Train Loss: 0.1406 (Forecasting Loss:0.1373 + XiCon Loss:3.3057 x Lambda(0.001)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.1375
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1296476
	speed: 0.0334s/iter; left time: 858.3895s
	iters: 200, epoch: 4 | loss: 0.1117052
	speed: 0.0305s/iter; left time: 780.5022s
Epoch: 4 cost time: 8.455527544021606
Epoch: 4, Steps: 266 Train Loss: 0.1232 (Forecasting Loss:0.1199 + XiCon Loss:3.2959 x Lambda(0.001)), Vali MSE Loss: 0.1581 Test MSE Loss: 0.1486
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1176792
	speed: 0.0333s/iter; left time: 847.7721s
	iters: 200, epoch: 5 | loss: 0.1192372
	speed: 0.0307s/iter; left time: 777.2270s
Epoch: 5 cost time: 8.414897441864014
Epoch: 5, Steps: 266 Train Loss: 0.1121 (Forecasting Loss:0.1088 + XiCon Loss:3.2985 x Lambda(0.001)), Vali MSE Loss: 0.1605 Test MSE Loss: 0.1582
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1004087
	speed: 0.0329s/iter; left time: 827.6254s
	iters: 200, epoch: 6 | loss: 0.1023130
	speed: 0.0316s/iter; left time: 792.4174s
Epoch: 6 cost time: 8.60347294807434
Epoch: 6, Steps: 266 Train Loss: 0.1071 (Forecasting Loss:0.1038 + XiCon Loss:3.2976 x Lambda(0.001)), Vali MSE Loss: 0.1597 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1041226
	speed: 0.0329s/iter; left time: 818.8971s
	iters: 200, epoch: 7 | loss: 0.0975028
	speed: 0.0310s/iter; left time: 770.1048s
Epoch: 7 cost time: 8.49795150756836
Epoch: 7, Steps: 266 Train Loss: 0.1044 (Forecasting Loss:0.1011 + XiCon Loss:3.2983 x Lambda(0.001)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.1606
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0960913
	speed: 0.0333s/iter; left time: 821.4689s
	iters: 200, epoch: 8 | loss: 0.0960925
	speed: 0.0309s/iter; left time: 757.5544s
Epoch: 8 cost time: 8.439192771911621
Epoch: 8, Steps: 266 Train Loss: 0.1031 (Forecasting Loss:0.0998 + XiCon Loss:3.2996 x Lambda(0.001)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1622
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1033128
	speed: 0.0341s/iter; left time: 831.3846s
	iters: 200, epoch: 9 | loss: 0.0914902
	speed: 0.0307s/iter; left time: 745.9890s
Epoch: 9 cost time: 8.507180213928223
Epoch: 9, Steps: 266 Train Loss: 0.1026 (Forecasting Loss:0.0993 + XiCon Loss:3.3003 x Lambda(0.001)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.1622
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1070095
	speed: 0.0335s/iter; left time: 806.8196s
	iters: 200, epoch: 10 | loss: 0.1047461
	speed: 0.0300s/iter; left time: 720.3260s
Epoch: 10 cost time: 8.364072561264038
Epoch: 10, Steps: 266 Train Loss: 0.1024 (Forecasting Loss:0.0991 + XiCon Loss:3.3009 x Lambda(0.001)), Vali MSE Loss: 0.1614 Test MSE Loss: 0.1622
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1026255
	speed: 0.0325s/iter; left time: 775.0974s
	iters: 200, epoch: 11 | loss: 0.1024891
	speed: 0.0307s/iter; left time: 728.0944s
Epoch: 11 cost time: 8.392176628112793
Epoch: 11, Steps: 266 Train Loss: 0.1024 (Forecasting Loss:0.0991 + XiCon Loss:3.2995 x Lambda(0.001)), Vali MSE Loss: 0.1613 Test MSE Loss: 0.1619
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1009986
	speed: 0.0323s/iter; left time: 760.7250s
	iters: 200, epoch: 12 | loss: 0.1084880
	speed: 0.0308s/iter; left time: 723.5886s
Epoch: 12 cost time: 8.300156354904175
Epoch: 12, Steps: 266 Train Loss: 0.1021 (Forecasting Loss:0.0988 + XiCon Loss:3.3008 x Lambda(0.001)), Vali MSE Loss: 0.1615 Test MSE Loss: 0.1621
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07338057458400726, mae:0.20143184065818787, mape:0.5053915977478027, mspe:9.790507316589355 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9827
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1637316
	speed: 0.0328s/iter; left time: 868.6813s
	iters: 200, epoch: 1 | loss: 0.1604800
	speed: 0.0299s/iter; left time: 789.3028s
Epoch: 1 cost time: 8.29621171951294
Epoch: 1, Steps: 266 Train Loss: 0.1833 (Forecasting Loss:0.1799 + XiCon Loss:3.3755 x Lambda(0.001)), Vali MSE Loss: 0.1558 Test MSE Loss: 0.1337
Validation loss decreased (inf --> 0.155823).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1645683
	speed: 0.0330s/iter; left time: 865.0050s
	iters: 200, epoch: 2 | loss: 0.1520672
	speed: 0.0320s/iter; left time: 837.5247s
Epoch: 2 cost time: 8.654097080230713
Epoch: 2, Steps: 266 Train Loss: 0.1548 (Forecasting Loss:0.1514 + XiCon Loss:3.3462 x Lambda(0.001)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1507893
	speed: 0.0336s/iter; left time: 871.7648s
	iters: 200, epoch: 3 | loss: 0.1299749
	speed: 0.0318s/iter; left time: 823.6824s
Epoch: 3 cost time: 8.528384685516357
Epoch: 3, Steps: 266 Train Loss: 0.1338 (Forecasting Loss:0.1305 + XiCon Loss:3.3296 x Lambda(0.001)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1131482
	speed: 0.0331s/iter; left time: 849.5113s
	iters: 200, epoch: 4 | loss: 0.1112706
	speed: 0.0310s/iter; left time: 794.5271s
Epoch: 4 cost time: 8.435269594192505
Epoch: 4, Steps: 266 Train Loss: 0.1161 (Forecasting Loss:0.1128 + XiCon Loss:3.3281 x Lambda(0.001)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1524
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1098964
	speed: 0.0342s/iter; left time: 871.2026s
	iters: 200, epoch: 5 | loss: 0.0999326
	speed: 0.0307s/iter; left time: 778.4962s
Epoch: 5 cost time: 8.530560493469238
Epoch: 5, Steps: 266 Train Loss: 0.1071 (Forecasting Loss:0.1037 + XiCon Loss:3.3228 x Lambda(0.001)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1535
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1094222
	speed: 0.0330s/iter; left time: 829.5116s
	iters: 200, epoch: 6 | loss: 0.1020325
	speed: 0.0303s/iter; left time: 760.1686s
Epoch: 6 cost time: 8.373717784881592
Epoch: 6, Steps: 266 Train Loss: 0.1027 (Forecasting Loss:0.0994 + XiCon Loss:3.3231 x Lambda(0.001)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1557
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.0930427
	speed: 0.0330s/iter; left time: 822.6631s
	iters: 200, epoch: 7 | loss: 0.0975703
	speed: 0.0323s/iter; left time: 801.7310s
Epoch: 7 cost time: 8.7387375831604
Epoch: 7, Steps: 266 Train Loss: 0.1004 (Forecasting Loss:0.0971 + XiCon Loss:3.3222 x Lambda(0.001)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1554
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1097287
	speed: 0.0324s/iter; left time: 798.6834s
	iters: 200, epoch: 8 | loss: 0.1044915
	speed: 0.0307s/iter; left time: 754.0101s
Epoch: 8 cost time: 8.335727214813232
Epoch: 8, Steps: 266 Train Loss: 0.0995 (Forecasting Loss:0.0962 + XiCon Loss:3.3218 x Lambda(0.001)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1555
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1016065
	speed: 0.0332s/iter; left time: 809.4838s
	iters: 200, epoch: 9 | loss: 0.1003041
	speed: 0.0307s/iter; left time: 745.7166s
Epoch: 9 cost time: 8.382242202758789
Epoch: 9, Steps: 266 Train Loss: 0.0991 (Forecasting Loss:0.0958 + XiCon Loss:3.3216 x Lambda(0.001)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1551
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0940272
	speed: 0.0327s/iter; left time: 787.3828s
	iters: 200, epoch: 10 | loss: 0.0933861
	speed: 0.0295s/iter; left time: 709.4015s
Epoch: 10 cost time: 8.225597858428955
Epoch: 10, Steps: 266 Train Loss: 0.0987 (Forecasting Loss:0.0953 + XiCon Loss:3.3214 x Lambda(0.001)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1555
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1009536
	speed: 0.0331s/iter; left time: 789.0965s
	iters: 200, epoch: 11 | loss: 0.0992287
	speed: 0.0303s/iter; left time: 718.8985s
Epoch: 11 cost time: 8.317545413970947
Epoch: 11, Steps: 266 Train Loss: 0.0985 (Forecasting Loss:0.0952 + XiCon Loss:3.3212 x Lambda(0.001)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1557
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06969955563545227, mae:0.1976485252380371, mape:0.4794650375843048, mspe:8.906566619873047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3894
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1672934
	speed: 0.0345s/iter; left time: 914.1343s
	iters: 200, epoch: 1 | loss: 0.1615424
	speed: 0.0320s/iter; left time: 844.8311s
Epoch: 1 cost time: 8.779146194458008
Epoch: 1, Steps: 266 Train Loss: 0.1908 (Forecasting Loss:0.1874 + XiCon Loss:3.3691 x Lambda(0.001)), Vali MSE Loss: 0.1578 Test MSE Loss: 0.1357
Validation loss decreased (inf --> 0.157817).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1520314
	speed: 0.0334s/iter; left time: 876.2756s
	iters: 200, epoch: 2 | loss: 0.1418220
	speed: 0.0327s/iter; left time: 854.2543s
Epoch: 2 cost time: 8.7148756980896
Epoch: 2, Steps: 266 Train Loss: 0.1550 (Forecasting Loss:0.1516 + XiCon Loss:3.3872 x Lambda(0.001)), Vali MSE Loss: 0.1577 Test MSE Loss: 0.1377
Validation loss decreased (0.157817 --> 0.157661).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1247257
	speed: 0.0327s/iter; left time: 850.4099s
	iters: 200, epoch: 3 | loss: 0.1227674
	speed: 0.0315s/iter; left time: 814.2573s
Epoch: 3 cost time: 8.510213136672974
Epoch: 3, Steps: 266 Train Loss: 0.1320 (Forecasting Loss:0.1286 + XiCon Loss:3.3724 x Lambda(0.001)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1524
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1187332
	speed: 0.0334s/iter; left time: 858.5980s
	iters: 200, epoch: 4 | loss: 0.1036658
	speed: 0.0316s/iter; left time: 808.4961s
Epoch: 4 cost time: 8.571068048477173
Epoch: 4, Steps: 266 Train Loss: 0.1142 (Forecasting Loss:0.1108 + XiCon Loss:3.3575 x Lambda(0.001)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1574
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1078632
	speed: 0.0332s/iter; left time: 844.8811s
	iters: 200, epoch: 5 | loss: 0.1166203
	speed: 0.0323s/iter; left time: 818.4346s
Epoch: 5 cost time: 8.748593807220459
Epoch: 5, Steps: 266 Train Loss: 0.1058 (Forecasting Loss:0.1025 + XiCon Loss:3.3570 x Lambda(0.001)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1576
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1106984
	speed: 0.0347s/iter; left time: 874.3020s
	iters: 200, epoch: 6 | loss: 0.1037852
	speed: 0.0315s/iter; left time: 790.2408s
Epoch: 6 cost time: 8.684574604034424
Epoch: 6, Steps: 266 Train Loss: 0.1022 (Forecasting Loss:0.0988 + XiCon Loss:3.3557 x Lambda(0.001)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1016351
	speed: 0.0327s/iter; left time: 814.0657s
	iters: 200, epoch: 7 | loss: 0.1042187
	speed: 0.0315s/iter; left time: 782.5752s
Epoch: 7 cost time: 8.490914344787598
Epoch: 7, Steps: 266 Train Loss: 0.1004 (Forecasting Loss:0.0970 + XiCon Loss:3.3553 x Lambda(0.001)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1594
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0987436
	speed: 0.0332s/iter; left time: 816.7995s
	iters: 200, epoch: 8 | loss: 0.0888380
	speed: 0.0311s/iter; left time: 762.3281s
Epoch: 8 cost time: 8.442597389221191
Epoch: 8, Steps: 266 Train Loss: 0.0994 (Forecasting Loss:0.0961 + XiCon Loss:3.3534 x Lambda(0.001)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1608
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0936081
	speed: 0.0327s/iter; left time: 797.3176s
	iters: 200, epoch: 9 | loss: 0.0962667
	speed: 0.0312s/iter; left time: 756.8603s
Epoch: 9 cost time: 8.347604513168335
Epoch: 9, Steps: 266 Train Loss: 0.0989 (Forecasting Loss:0.0955 + XiCon Loss:3.3536 x Lambda(0.001)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1611
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0954384
	speed: 0.0316s/iter; left time: 762.6799s
	iters: 200, epoch: 10 | loss: 0.0997471
	speed: 0.0321s/iter; left time: 771.0011s
Epoch: 10 cost time: 8.563321113586426
Epoch: 10, Steps: 266 Train Loss: 0.0988 (Forecasting Loss:0.0955 + XiCon Loss:3.3535 x Lambda(0.001)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1611
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1136229
	speed: 0.0345s/iter; left time: 821.7398s
	iters: 200, epoch: 11 | loss: 0.0931265
	speed: 0.0329s/iter; left time: 781.5890s
Epoch: 11 cost time: 8.812914609909058
Epoch: 11, Steps: 266 Train Loss: 0.0988 (Forecasting Loss:0.0954 + XiCon Loss:3.3534 x Lambda(0.001)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1611
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.0980774
	speed: 0.0337s/iter; left time: 795.1380s
	iters: 200, epoch: 12 | loss: 0.0939492
	speed: 0.0310s/iter; left time: 726.8576s
Epoch: 12 cost time: 8.539469480514526
Epoch: 12, Steps: 266 Train Loss: 0.0988 (Forecasting Loss:0.0954 + XiCon Loss:3.3548 x Lambda(0.001)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1612
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07335008680820465, mae:0.2019810825586319, mape:0.5222014784812927, mspe:10.709460258483887 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0717+-0.00205, MAE:0.1994+-0.00295, MAPE:0.4971+-0.02099, MSPE:9.5729+-0.91837, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1203
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3699119
	speed: 0.0395s/iter; left time: 1041.9092s
	iters: 200, epoch: 1 | loss: 0.3575006
	speed: 0.0340s/iter; left time: 894.6601s
Epoch: 1 cost time: 9.51367449760437
Epoch: 1, Steps: 265 Train Loss: 0.3562 (Forecasting Loss:0.3530 + XiCon Loss:3.2320 x Lambda(0.001)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.2773
Validation loss decreased (inf --> 0.335985).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2191677
	speed: 0.0334s/iter; left time: 874.0016s
	iters: 200, epoch: 2 | loss: 0.2462245
	speed: 0.0314s/iter; left time: 818.7244s
Epoch: 2 cost time: 8.555076122283936
Epoch: 2, Steps: 265 Train Loss: 0.2400 (Forecasting Loss:0.2368 + XiCon Loss:3.2343 x Lambda(0.001)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1726
Validation loss decreased (0.335985 --> 0.213177).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1955504
	speed: 0.0342s/iter; left time: 883.7874s
	iters: 200, epoch: 3 | loss: 0.2095059
	speed: 0.0313s/iter; left time: 807.7978s
Epoch: 3 cost time: 8.630782127380371
Epoch: 3, Steps: 265 Train Loss: 0.2135 (Forecasting Loss:0.2103 + XiCon Loss:3.2366 x Lambda(0.001)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1695
Validation loss decreased (0.213177 --> 0.209720).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1874672
	speed: 0.0335s/iter; left time: 858.5013s
	iters: 200, epoch: 4 | loss: 0.2088090
	speed: 0.0314s/iter; left time: 799.7469s
Epoch: 4 cost time: 8.548151016235352
Epoch: 4, Steps: 265 Train Loss: 0.2105 (Forecasting Loss:0.2072 + XiCon Loss:3.2379 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1683
Validation loss decreased (0.209720 --> 0.208460).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2152387
	speed: 0.0344s/iter; left time: 871.0653s
	iters: 200, epoch: 5 | loss: 0.2063695
	speed: 0.0325s/iter; left time: 821.2839s
Epoch: 5 cost time: 8.9238760471344
Epoch: 5, Steps: 265 Train Loss: 0.2092 (Forecasting Loss:0.2059 + XiCon Loss:3.2358 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1681
Validation loss decreased (0.208460 --> 0.208395).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2356025
	speed: 0.0342s/iter; left time: 858.1946s
	iters: 200, epoch: 6 | loss: 0.1966750
	speed: 0.0315s/iter; left time: 785.9042s
Epoch: 6 cost time: 8.642424821853638
Epoch: 6, Steps: 265 Train Loss: 0.2087 (Forecasting Loss:0.2055 + XiCon Loss:3.2385 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1679
Validation loss decreased (0.208395 --> 0.208354).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1991292
	speed: 0.0325s/iter; left time: 807.5619s
	iters: 200, epoch: 7 | loss: 0.2399654
	speed: 0.0292s/iter; left time: 722.6343s
Epoch: 7 cost time: 8.216202735900879
Epoch: 7, Steps: 265 Train Loss: 0.2087 (Forecasting Loss:0.2055 + XiCon Loss:3.2390 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2209982
	speed: 0.0336s/iter; left time: 823.6029s
	iters: 200, epoch: 8 | loss: 0.2446234
	speed: 0.0318s/iter; left time: 776.2444s
Epoch: 8 cost time: 8.534191131591797
Epoch: 8, Steps: 265 Train Loss: 0.2084 (Forecasting Loss:0.2051 + XiCon Loss:3.2383 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1679
Validation loss decreased (0.208354 --> 0.208324).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2117339
	speed: 0.0331s/iter; left time: 803.3453s
	iters: 200, epoch: 9 | loss: 0.1837238
	speed: 0.0322s/iter; left time: 778.5753s
Epoch: 9 cost time: 8.649436712265015
Epoch: 9, Steps: 265 Train Loss: 0.2083 (Forecasting Loss:0.2050 + XiCon Loss:3.2395 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1679
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2237732
	speed: 0.0335s/iter; left time: 804.9731s
	iters: 200, epoch: 10 | loss: 0.1960402
	speed: 0.0321s/iter; left time: 767.8452s
Epoch: 10 cost time: 8.713448762893677
Epoch: 10, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2049 + XiCon Loss:3.2362 x Lambda(0.001)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1679
Validation loss decreased (0.208324 --> 0.208195).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2114861
	speed: 0.0345s/iter; left time: 818.7397s
	iters: 200, epoch: 11 | loss: 0.1817839
	speed: 0.0317s/iter; left time: 750.7675s
Epoch: 11 cost time: 8.687134265899658
Epoch: 11, Steps: 265 Train Loss: 0.2083 (Forecasting Loss:0.2051 + XiCon Loss:3.2397 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2194293
	speed: 0.0334s/iter; left time: 785.3405s
	iters: 200, epoch: 12 | loss: 0.1972015
	speed: 0.0309s/iter; left time: 723.0022s
Epoch: 12 cost time: 8.52891492843628
Epoch: 12, Steps: 265 Train Loss: 0.2084 (Forecasting Loss:0.2051 + XiCon Loss:3.2388 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2225497
	speed: 0.0339s/iter; left time: 786.0608s
	iters: 200, epoch: 13 | loss: 0.1774416
	speed: 0.0315s/iter; left time: 728.3600s
Epoch: 13 cost time: 8.553472518920898
Epoch: 13, Steps: 265 Train Loss: 0.2081 (Forecasting Loss:0.2049 + XiCon Loss:3.2377 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2037381
	speed: 0.0341s/iter; left time: 782.1738s
	iters: 200, epoch: 14 | loss: 0.2001947
	speed: 0.0316s/iter; left time: 722.5912s
Epoch: 14 cost time: 8.63442587852478
Epoch: 14, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2049 + XiCon Loss:3.2376 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1678
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2398931
	speed: 0.0341s/iter; left time: 774.7707s
	iters: 200, epoch: 15 | loss: 0.1840002
	speed: 0.0320s/iter; left time: 722.5749s
Epoch: 15 cost time: 8.741777896881104
Epoch: 15, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2050 + XiCon Loss:3.2380 x Lambda(0.001)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1678
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2204368
	speed: 0.0340s/iter; left time: 762.6313s
	iters: 200, epoch: 16 | loss: 0.2142854
	speed: 0.0313s/iter; left time: 698.9566s
Epoch: 16 cost time: 8.671099662780762
Epoch: 16, Steps: 265 Train Loss: 0.2083 (Forecasting Loss:0.2050 + XiCon Loss:3.2400 x Lambda(0.001)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1678
Validation loss decreased (0.208195 --> 0.208120).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2254748
	speed: 0.0337s/iter; left time: 746.6013s
	iters: 200, epoch: 17 | loss: 0.2306873
	speed: 0.0320s/iter; left time: 705.8478s
Epoch: 17 cost time: 8.619203567504883
Epoch: 17, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2049 + XiCon Loss:3.2380 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.1966221
	speed: 0.0336s/iter; left time: 734.8547s
	iters: 200, epoch: 18 | loss: 0.2300802
	speed: 0.0316s/iter; left time: 688.3089s
Epoch: 18 cost time: 8.607908248901367
Epoch: 18, Steps: 265 Train Loss: 0.2081 (Forecasting Loss:0.2048 + XiCon Loss:3.2368 x Lambda(0.001)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1678
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.1984907
	speed: 0.0319s/iter; left time: 690.7282s
	iters: 200, epoch: 19 | loss: 0.2059592
	speed: 0.0307s/iter; left time: 662.0184s
Epoch: 19 cost time: 8.29519510269165
Epoch: 19, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2049 + XiCon Loss:3.2374 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.1814355
	speed: 0.0346s/iter; left time: 738.8216s
	iters: 200, epoch: 20 | loss: 0.2093731
	speed: 0.0321s/iter; left time: 681.7976s
Epoch: 20 cost time: 8.790238380432129
Epoch: 20, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2050 + XiCon Loss:3.2368 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.1932618
	speed: 0.0342s/iter; left time: 721.8346s
	iters: 200, epoch: 21 | loss: 0.1879403
	speed: 0.0314s/iter; left time: 659.5570s
Epoch: 21 cost time: 8.577203512191772
Epoch: 21, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2050 + XiCon Loss:3.2378 x Lambda(0.001)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1678
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2091226
	speed: 0.0341s/iter; left time: 709.5296s
	iters: 200, epoch: 22 | loss: 0.2050312
	speed: 0.0312s/iter; left time: 646.7889s
Epoch: 22 cost time: 8.563081741333008
Epoch: 22, Steps: 265 Train Loss: 0.2081 (Forecasting Loss:0.2049 + XiCon Loss:3.2374 x Lambda(0.001)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1678
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2150915
	speed: 0.0339s/iter; left time: 696.8935s
	iters: 200, epoch: 23 | loss: 0.1929754
	speed: 0.0316s/iter; left time: 647.5288s
Epoch: 23 cost time: 8.553260564804077
Epoch: 23, Steps: 265 Train Loss: 0.2083 (Forecasting Loss:0.2051 + XiCon Loss:3.2375 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2183438
	speed: 0.0334s/iter; left time: 677.6325s
	iters: 200, epoch: 24 | loss: 0.2097780
	speed: 0.0325s/iter; left time: 657.4048s
Epoch: 24 cost time: 8.738006830215454
Epoch: 24, Steps: 265 Train Loss: 0.2083 (Forecasting Loss:0.2051 + XiCon Loss:3.2365 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2139909
	speed: 0.0347s/iter; left time: 695.9823s
	iters: 200, epoch: 25 | loss: 0.2021198
	speed: 0.0324s/iter; left time: 645.7399s
Epoch: 25 cost time: 8.782747983932495
Epoch: 25, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2050 + XiCon Loss:3.2405 x Lambda(0.001)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1678
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2226819
	speed: 0.0344s/iter; left time: 680.8370s
	iters: 200, epoch: 26 | loss: 0.2102667
	speed: 0.0311s/iter; left time: 611.5309s
Epoch: 26 cost time: 8.675362825393677
Epoch: 26, Steps: 265 Train Loss: 0.2082 (Forecasting Loss:0.2049 + XiCon Loss:3.2388 x Lambda(0.001)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1678
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09797237813472748, mae:0.23770125210285187, mape:0.5670388340950012, mspe:11.699861526489258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7004
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3292417
	speed: 0.0362s/iter; left time: 956.3053s
	iters: 200, epoch: 1 | loss: 0.3731835
	speed: 0.0340s/iter; left time: 893.1020s
Epoch: 1 cost time: 9.264702320098877
Epoch: 1, Steps: 265 Train Loss: 0.3638 (Forecasting Loss:0.3606 + XiCon Loss:3.2460 x Lambda(0.001)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.2826
Validation loss decreased (inf --> 0.335376).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2277350
	speed: 0.0351s/iter; left time: 917.2794s
	iters: 200, epoch: 2 | loss: 0.2381242
	speed: 0.0323s/iter; left time: 839.8847s
Epoch: 2 cost time: 8.894333600997925
Epoch: 2, Steps: 265 Train Loss: 0.2406 (Forecasting Loss:0.2374 + XiCon Loss:3.2464 x Lambda(0.001)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1712
Validation loss decreased (0.335376 --> 0.214457).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2130129
	speed: 0.0328s/iter; left time: 849.4145s
	iters: 200, epoch: 3 | loss: 0.1941124
	speed: 0.0308s/iter; left time: 793.7304s
Epoch: 3 cost time: 8.409831047058105
Epoch: 3, Steps: 265 Train Loss: 0.2127 (Forecasting Loss:0.2095 + XiCon Loss:3.2444 x Lambda(0.001)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1675
Validation loss decreased (0.214457 --> 0.210300).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2015375
	speed: 0.0342s/iter; left time: 876.4339s
	iters: 200, epoch: 4 | loss: 0.2056890
	speed: 0.0322s/iter; left time: 820.0442s
Epoch: 4 cost time: 8.690348148345947
Epoch: 4, Steps: 265 Train Loss: 0.2094 (Forecasting Loss:0.2061 + XiCon Loss:3.2448 x Lambda(0.001)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1667
Validation loss decreased (0.210300 --> 0.209035).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2042511
	speed: 0.0346s/iter; left time: 875.5776s
	iters: 200, epoch: 5 | loss: 0.2125896
	speed: 0.0328s/iter; left time: 828.8833s
Epoch: 5 cost time: 8.89937138557434
Epoch: 5, Steps: 265 Train Loss: 0.2081 (Forecasting Loss:0.2049 + XiCon Loss:3.2426 x Lambda(0.001)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1663
Validation loss decreased (0.209035 --> 0.208139).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2270218
	speed: 0.0341s/iter; left time: 854.0218s
	iters: 200, epoch: 6 | loss: 0.1993195
	speed: 0.0324s/iter; left time: 809.0212s
Epoch: 6 cost time: 8.711426734924316
Epoch: 6, Steps: 265 Train Loss: 0.2076 (Forecasting Loss:0.2043 + XiCon Loss:3.2420 x Lambda(0.001)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1660
Validation loss decreased (0.208139 --> 0.207836).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2023360
	speed: 0.0344s/iter; left time: 852.5860s
	iters: 200, epoch: 7 | loss: 0.2097679
	speed: 0.0323s/iter; left time: 799.1488s
Epoch: 7 cost time: 8.751058340072632
Epoch: 7, Steps: 265 Train Loss: 0.2073 (Forecasting Loss:0.2040 + XiCon Loss:3.2423 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1659
Validation loss decreased (0.207836 --> 0.207530).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2327900
	speed: 0.0339s/iter; left time: 833.0312s
	iters: 200, epoch: 8 | loss: 0.2171199
	speed: 0.0316s/iter; left time: 772.4692s
Epoch: 8 cost time: 8.55650019645691
Epoch: 8, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2038 + XiCon Loss:3.2411 x Lambda(0.001)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1659
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2092506
	speed: 0.0337s/iter; left time: 819.1926s
	iters: 200, epoch: 9 | loss: 0.2025879
	speed: 0.0312s/iter; left time: 754.6549s
Epoch: 9 cost time: 8.59664797782898
Epoch: 9, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2038 + XiCon Loss:3.2420 x Lambda(0.001)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1659
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2068263
	speed: 0.0355s/iter; left time: 853.3747s
	iters: 200, epoch: 10 | loss: 0.1980749
	speed: 0.0330s/iter; left time: 789.2858s
Epoch: 10 cost time: 8.971542119979858
Epoch: 10, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2414 x Lambda(0.001)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1659
Validation loss decreased (0.207530 --> 0.207338).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.1775896
	speed: 0.0347s/iter; left time: 824.6289s
	iters: 200, epoch: 11 | loss: 0.1895193
	speed: 0.0320s/iter; left time: 757.4849s
Epoch: 11 cost time: 8.781197547912598
Epoch: 11, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2422 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.1969732
	speed: 0.0336s/iter; left time: 789.3051s
	iters: 200, epoch: 12 | loss: 0.1919378
	speed: 0.0313s/iter; left time: 732.0004s
Epoch: 12 cost time: 8.542057275772095
Epoch: 12, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2406 x Lambda(0.001)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1658
Validation loss decreased (0.207338 --> 0.207251).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2160608
	speed: 0.0337s/iter; left time: 783.0700s
	iters: 200, epoch: 13 | loss: 0.2154012
	speed: 0.0319s/iter; left time: 738.4576s
Epoch: 13 cost time: 8.554529666900635
Epoch: 13, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2418 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2035176
	speed: 0.0352s/iter; left time: 806.9098s
	iters: 200, epoch: 14 | loss: 0.2010365
	speed: 0.0329s/iter; left time: 752.7701s
Epoch: 14 cost time: 8.918495416641235
Epoch: 14, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2428 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2234945
	speed: 0.0337s/iter; left time: 764.0194s
	iters: 200, epoch: 15 | loss: 0.2065045
	speed: 0.0319s/iter; left time: 719.9234s
Epoch: 15 cost time: 8.637040138244629
Epoch: 15, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2414 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.1940821
	speed: 0.0333s/iter; left time: 746.5203s
	iters: 200, epoch: 16 | loss: 0.2024976
	speed: 0.0310s/iter; left time: 691.5080s
Epoch: 16 cost time: 8.445499897003174
Epoch: 16, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2404 x Lambda(0.001)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1658
Validation loss decreased (0.207251 --> 0.207249).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.1938432
	speed: 0.0339s/iter; left time: 751.3330s
	iters: 200, epoch: 17 | loss: 0.2176965
	speed: 0.0321s/iter; left time: 708.0463s
Epoch: 17 cost time: 8.686773538589478
Epoch: 17, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2427 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2179120
	speed: 0.0336s/iter; left time: 736.6514s
	iters: 200, epoch: 18 | loss: 0.1942374
	speed: 0.0313s/iter; left time: 682.0645s
Epoch: 18 cost time: 8.528117895126343
Epoch: 18, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2036 + XiCon Loss:3.2400 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2001892
	speed: 0.0341s/iter; left time: 737.2363s
	iters: 200, epoch: 19 | loss: 0.2022934
	speed: 0.0325s/iter; left time: 700.6843s
Epoch: 19 cost time: 8.779491901397705
Epoch: 19, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2411 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2313671
	speed: 0.0336s/iter; left time: 716.9837s
	iters: 200, epoch: 20 | loss: 0.1828138
	speed: 0.0319s/iter; left time: 679.2077s
Epoch: 20 cost time: 8.608057975769043
Epoch: 20, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2419 x Lambda(0.001)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1658
Validation loss decreased (0.207249 --> 0.207198).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.1949693
	speed: 0.0341s/iter; left time: 719.1414s
	iters: 200, epoch: 21 | loss: 0.2029242
	speed: 0.0322s/iter; left time: 675.8130s
Epoch: 21 cost time: 8.65377688407898
Epoch: 21, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2038 + XiCon Loss:3.2415 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2419356
	speed: 0.0345s/iter; left time: 717.9898s
	iters: 200, epoch: 22 | loss: 0.2085637
	speed: 0.0315s/iter; left time: 652.2736s
Epoch: 22 cost time: 8.633690357208252
Epoch: 22, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2416 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2238551
	speed: 0.0336s/iter; left time: 691.4198s
	iters: 200, epoch: 23 | loss: 0.2215930
	speed: 0.0312s/iter; left time: 638.2546s
Epoch: 23 cost time: 8.57039999961853
Epoch: 23, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2397 x Lambda(0.001)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1658
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2212050
	speed: 0.0338s/iter; left time: 685.8761s
	iters: 200, epoch: 24 | loss: 0.1974496
	speed: 0.0322s/iter; left time: 649.8498s
Epoch: 24 cost time: 8.743108034133911
Epoch: 24, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2428 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2267298
	speed: 0.0340s/iter; left time: 681.1679s
	iters: 200, epoch: 25 | loss: 0.2202083
	speed: 0.0320s/iter; left time: 638.4610s
Epoch: 25 cost time: 8.684423923492432
Epoch: 25, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2413 x Lambda(0.001)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1658
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2002557
	speed: 0.0345s/iter; left time: 682.5667s
	iters: 200, epoch: 26 | loss: 0.1935965
	speed: 0.0299s/iter; left time: 588.2464s
Epoch: 26 cost time: 8.456105470657349
Epoch: 26, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2038 + XiCon Loss:3.2427 x Lambda(0.001)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1658
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.2149090
	speed: 0.0326s/iter; left time: 636.8389s
	iters: 200, epoch: 27 | loss: 0.1904653
	speed: 0.0314s/iter; left time: 609.3195s
Epoch: 27 cost time: 8.474488019943237
Epoch: 27, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2427 x Lambda(0.001)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1658
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.2119458
	speed: 0.0347s/iter; left time: 667.3493s
	iters: 200, epoch: 28 | loss: 0.2101969
	speed: 0.0324s/iter; left time: 620.0569s
Epoch: 28 cost time: 8.909954309463501
Epoch: 28, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2404 x Lambda(0.001)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1658
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.1895219
	speed: 0.0336s/iter; left time: 637.5128s
	iters: 200, epoch: 29 | loss: 0.2105084
	speed: 0.0318s/iter; left time: 600.2824s
Epoch: 29 cost time: 8.621624231338501
Epoch: 29, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2392 x Lambda(0.001)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1658
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.1924300
	speed: 0.0341s/iter; left time: 638.3959s
	iters: 200, epoch: 30 | loss: 0.2049601
	speed: 0.0317s/iter; left time: 589.5958s
Epoch: 30 cost time: 8.635128498077393
Epoch: 30, Steps: 265 Train Loss: 0.2067 (Forecasting Loss:0.2035 + XiCon Loss:3.2425 x Lambda(0.001)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1658
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09601173549890518, mae:0.23565949499607086, mape:0.567179799079895, mspe:11.817036628723145 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9432
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3253262
	speed: 0.0352s/iter; left time: 928.1338s
	iters: 200, epoch: 1 | loss: 0.3018562
	speed: 0.0335s/iter; left time: 880.7324s
Epoch: 1 cost time: 9.013350009918213
Epoch: 1, Steps: 265 Train Loss: 0.3499 (Forecasting Loss:0.3466 + XiCon Loss:3.2291 x Lambda(0.001)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2711
Validation loss decreased (inf --> 0.324665).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2059434
	speed: 0.0341s/iter; left time: 891.6719s
	iters: 200, epoch: 2 | loss: 0.2087877
	speed: 0.0329s/iter; left time: 856.0947s
Epoch: 2 cost time: 8.764746189117432
Epoch: 2, Steps: 265 Train Loss: 0.2373 (Forecasting Loss:0.2340 + XiCon Loss:3.2449 x Lambda(0.001)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1723
Validation loss decreased (0.324665 --> 0.213586).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2258251
	speed: 0.0336s/iter; left time: 869.2795s
	iters: 200, epoch: 3 | loss: 0.2057786
	speed: 0.0317s/iter; left time: 817.3762s
Epoch: 3 cost time: 8.617262840270996
Epoch: 3, Steps: 265 Train Loss: 0.2098 (Forecasting Loss:0.2065 + XiCon Loss:3.2505 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1727
Validation loss decreased (0.213586 --> 0.211658).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2019376
	speed: 0.0340s/iter; left time: 869.8222s
	iters: 200, epoch: 4 | loss: 0.2016330
	speed: 0.0316s/iter; left time: 805.4042s
Epoch: 4 cost time: 8.558892965316772
Epoch: 4, Steps: 265 Train Loss: 0.2061 (Forecasting Loss:0.2029 + XiCon Loss:3.2525 x Lambda(0.001)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1718
Validation loss decreased (0.211658 --> 0.209142).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1928850
	speed: 0.0354s/iter; left time: 896.2062s
	iters: 200, epoch: 5 | loss: 0.2047863
	speed: 0.0330s/iter; left time: 833.3307s
Epoch: 5 cost time: 9.023277282714844
Epoch: 5, Steps: 265 Train Loss: 0.2049 (Forecasting Loss:0.2016 + XiCon Loss:3.2514 x Lambda(0.001)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1718
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2310299
	speed: 0.0331s/iter; left time: 829.3015s
	iters: 200, epoch: 6 | loss: 0.2177206
	speed: 0.0299s/iter; left time: 746.5446s
Epoch: 6 cost time: 8.314965724945068
Epoch: 6, Steps: 265 Train Loss: 0.2041 (Forecasting Loss:0.2009 + XiCon Loss:3.2492 x Lambda(0.001)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1717
Validation loss decreased (0.209142 --> 0.208863).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2206703
	speed: 0.0332s/iter; left time: 822.6331s
	iters: 200, epoch: 7 | loss: 0.2014477
	speed: 0.0317s/iter; left time: 782.7186s
Epoch: 7 cost time: 8.530768632888794
Epoch: 7, Steps: 265 Train Loss: 0.2040 (Forecasting Loss:0.2008 + XiCon Loss:3.2502 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1717
Validation loss decreased (0.208863 --> 0.208676).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2029125
	speed: 0.0334s/iter; left time: 820.1757s
	iters: 200, epoch: 8 | loss: 0.2064278
	speed: 0.0316s/iter; left time: 771.8719s
Epoch: 8 cost time: 8.504661798477173
Epoch: 8, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2497 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1716
Validation loss decreased (0.208676 --> 0.208670).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2140107
	speed: 0.0337s/iter; left time: 818.9513s
	iters: 200, epoch: 9 | loss: 0.2057521
	speed: 0.0323s/iter; left time: 780.8314s
Epoch: 9 cost time: 8.665092706680298
Epoch: 9, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2006 + XiCon Loss:3.2498 x Lambda(0.001)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1716
Validation loss decreased (0.208670 --> 0.208603).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1884086
	speed: 0.0343s/iter; left time: 824.1446s
	iters: 200, epoch: 10 | loss: 0.1927614
	speed: 0.0329s/iter; left time: 787.0896s
Epoch: 10 cost time: 8.958664417266846
Epoch: 10, Steps: 265 Train Loss: 0.2037 (Forecasting Loss:0.2005 + XiCon Loss:3.2487 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1716
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2134724
	speed: 0.0344s/iter; left time: 817.7036s
	iters: 200, epoch: 11 | loss: 0.2092776
	speed: 0.0327s/iter; left time: 774.3779s
Epoch: 11 cost time: 8.790973901748657
Epoch: 11, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2004 + XiCon Loss:3.2490 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1716
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.1972651
	speed: 0.0341s/iter; left time: 801.2962s
	iters: 200, epoch: 12 | loss: 0.2034106
	speed: 0.0319s/iter; left time: 745.3523s
Epoch: 12 cost time: 8.580449342727661
Epoch: 12, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2481 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
Validation loss decreased (0.208603 --> 0.208452).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.1948350
	speed: 0.0335s/iter; left time: 778.7972s
	iters: 200, epoch: 13 | loss: 0.1958988
	speed: 0.0322s/iter; left time: 744.3610s
Epoch: 13 cost time: 8.621625900268555
Epoch: 13, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2004 + XiCon Loss:3.2491 x Lambda(0.001)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1716
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.1761529
	speed: 0.0339s/iter; left time: 778.1267s
	iters: 200, epoch: 14 | loss: 0.1858926
	speed: 0.0317s/iter; left time: 725.5633s
Epoch: 14 cost time: 8.566153287887573
Epoch: 14, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2487 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1716
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2074222
	speed: 0.0340s/iter; left time: 771.8869s
	iters: 200, epoch: 15 | loss: 0.1881766
	speed: 0.0325s/iter; left time: 733.6121s
Epoch: 15 cost time: 8.817754030227661
Epoch: 15, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2004 + XiCon Loss:3.2508 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2080445
	speed: 0.0334s/iter; left time: 748.9723s
	iters: 200, epoch: 16 | loss: 0.1916920
	speed: 0.0325s/iter; left time: 725.3004s
Epoch: 16 cost time: 8.650351524353027
Epoch: 16, Steps: 265 Train Loss: 0.2035 (Forecasting Loss:0.2003 + XiCon Loss:3.2495 x Lambda(0.001)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1716
Validation loss decreased (0.208452 --> 0.208134).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.1994544
	speed: 0.0333s/iter; left time: 737.6764s
	iters: 200, epoch: 17 | loss: 0.1941579
	speed: 0.0316s/iter; left time: 697.9437s
Epoch: 17 cost time: 8.558185577392578
Epoch: 17, Steps: 265 Train Loss: 0.2037 (Forecasting Loss:0.2004 + XiCon Loss:3.2503 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.1881546
	speed: 0.0335s/iter; left time: 733.0077s
	iters: 200, epoch: 18 | loss: 0.1945206
	speed: 0.0308s/iter; left time: 671.7836s
Epoch: 18 cost time: 8.416172742843628
Epoch: 18, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2004 + XiCon Loss:3.2490 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2185764
	speed: 0.0341s/iter; left time: 737.9512s
	iters: 200, epoch: 19 | loss: 0.2178635
	speed: 0.0320s/iter; left time: 689.1609s
Epoch: 19 cost time: 8.732735872268677
Epoch: 19, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2003 + XiCon Loss:3.2522 x Lambda(0.001)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1716
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.1924237
	speed: 0.0349s/iter; left time: 746.6133s
	iters: 200, epoch: 20 | loss: 0.1950290
	speed: 0.0320s/iter; left time: 680.2873s
Epoch: 20 cost time: 8.799919128417969
Epoch: 20, Steps: 265 Train Loss: 0.2036 (Forecasting Loss:0.2003 + XiCon Loss:3.2498 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2095509
	speed: 0.0331s/iter; left time: 697.4460s
	iters: 200, epoch: 21 | loss: 0.2113091
	speed: 0.0322s/iter; left time: 675.5068s
Epoch: 21 cost time: 8.587647199630737
Epoch: 21, Steps: 265 Train Loss: 0.2037 (Forecasting Loss:0.2005 + XiCon Loss:3.2494 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.1956272
	speed: 0.0344s/iter; left time: 716.9962s
	iters: 200, epoch: 22 | loss: 0.2028494
	speed: 0.0314s/iter; left time: 651.0632s
Epoch: 22 cost time: 8.592532873153687
Epoch: 22, Steps: 265 Train Loss: 0.2037 (Forecasting Loss:0.2004 + XiCon Loss:3.2501 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.1881111
	speed: 0.0352s/iter; left time: 723.3814s
	iters: 200, epoch: 23 | loss: 0.1729483
	speed: 0.0314s/iter; left time: 643.4430s
Epoch: 23 cost time: 8.717240571975708
Epoch: 23, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2497 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.1935038
	speed: 0.0339s/iter; left time: 687.5121s
	iters: 200, epoch: 24 | loss: 0.1921163
	speed: 0.0326s/iter; left time: 657.7799s
Epoch: 24 cost time: 8.693114519119263
Epoch: 24, Steps: 265 Train Loss: 0.2037 (Forecasting Loss:0.2005 + XiCon Loss:3.2512 x Lambda(0.001)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1716
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.1989888
	speed: 0.0338s/iter; left time: 678.2059s
	iters: 200, epoch: 25 | loss: 0.2164020
	speed: 0.0317s/iter; left time: 631.9667s
Epoch: 25 cost time: 8.739763259887695
Epoch: 25, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2494 x Lambda(0.001)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1716
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.1874332
	speed: 0.0343s/iter; left time: 678.6993s
	iters: 200, epoch: 26 | loss: 0.1834680
	speed: 0.0320s/iter; left time: 629.8371s
Epoch: 26 cost time: 8.651769638061523
Epoch: 26, Steps: 265 Train Loss: 0.2038 (Forecasting Loss:0.2005 + XiCon Loss:3.2498 x Lambda(0.001)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1716
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10095217078924179, mae:0.24226006865501404, mape:0.5829104781150818, mspe:12.190078735351562 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5369
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3588703
	speed: 0.0355s/iter; left time: 936.2715s
	iters: 200, epoch: 1 | loss: 0.3432868
	speed: 0.0343s/iter; left time: 903.2305s
Epoch: 1 cost time: 9.11858868598938
Epoch: 1, Steps: 265 Train Loss: 0.3643 (Forecasting Loss:0.3610 + XiCon Loss:3.2404 x Lambda(0.001)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.2836
Validation loss decreased (inf --> 0.331414).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2223618
	speed: 0.0337s/iter; left time: 879.9420s
	iters: 200, epoch: 2 | loss: 0.1982970
	speed: 0.0307s/iter; left time: 799.6364s
Epoch: 2 cost time: 8.483254432678223
Epoch: 2, Steps: 265 Train Loss: 0.2376 (Forecasting Loss:0.2343 + XiCon Loss:3.2422 x Lambda(0.001)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1748
Validation loss decreased (0.331414 --> 0.217394).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1968560
	speed: 0.0352s/iter; left time: 909.4927s
	iters: 200, epoch: 3 | loss: 0.2213338
	speed: 0.0315s/iter; left time: 813.0475s
Epoch: 3 cost time: 8.787363767623901
Epoch: 3, Steps: 265 Train Loss: 0.2113 (Forecasting Loss:0.2081 + XiCon Loss:3.2432 x Lambda(0.001)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1712
Validation loss decreased (0.217394 --> 0.213458).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2112153
	speed: 0.0338s/iter; left time: 864.6489s
	iters: 200, epoch: 4 | loss: 0.1873833
	speed: 0.0319s/iter; left time: 814.4889s
Epoch: 4 cost time: 8.650527238845825
Epoch: 4, Steps: 265 Train Loss: 0.2091 (Forecasting Loss:0.2058 + XiCon Loss:3.2397 x Lambda(0.001)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1707
Validation loss decreased (0.213458 --> 0.212886).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2157533
	speed: 0.0341s/iter; left time: 863.7643s
	iters: 200, epoch: 5 | loss: 0.2157922
	speed: 0.0317s/iter; left time: 801.3255s
Epoch: 5 cost time: 8.746417045593262
Epoch: 5, Steps: 265 Train Loss: 0.2080 (Forecasting Loss:0.2047 + XiCon Loss:3.2404 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1702
Validation loss decreased (0.212886 --> 0.212032).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2092263
	speed: 0.0339s/iter; left time: 850.8585s
	iters: 200, epoch: 6 | loss: 0.2074093
	speed: 0.0316s/iter; left time: 790.0543s
Epoch: 6 cost time: 8.597239255905151
Epoch: 6, Steps: 265 Train Loss: 0.2075 (Forecasting Loss:0.2042 + XiCon Loss:3.2392 x Lambda(0.001)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2118304
	speed: 0.0340s/iter; left time: 843.9342s
	iters: 200, epoch: 7 | loss: 0.2029773
	speed: 0.0306s/iter; left time: 755.3043s
Epoch: 7 cost time: 8.595920324325562
Epoch: 7, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2393 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
Validation loss decreased (0.212032 --> 0.211771).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1947008
	speed: 0.0334s/iter; left time: 818.7446s
	iters: 200, epoch: 8 | loss: 0.2242058
	speed: 0.0316s/iter; left time: 773.2382s
Epoch: 8 cost time: 8.517814636230469
Epoch: 8, Steps: 265 Train Loss: 0.2072 (Forecasting Loss:0.2040 + XiCon Loss:3.2389 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1949376
	speed: 0.0332s/iter; left time: 804.9471s
	iters: 200, epoch: 9 | loss: 0.2090104
	speed: 0.0317s/iter; left time: 766.2864s
Epoch: 9 cost time: 8.600571870803833
Epoch: 9, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2395 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2320601
	speed: 0.0341s/iter; left time: 817.9434s
	iters: 200, epoch: 10 | loss: 0.1788458
	speed: 0.0324s/iter; left time: 774.9376s
Epoch: 10 cost time: 8.877854585647583
Epoch: 10, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2402 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2095162
	speed: 0.0348s/iter; left time: 826.3149s
	iters: 200, epoch: 11 | loss: 0.2057862
	speed: 0.0324s/iter; left time: 766.0034s
Epoch: 11 cost time: 8.785346746444702
Epoch: 11, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2392 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2106562
	speed: 0.0349s/iter; left time: 820.7569s
	iters: 200, epoch: 12 | loss: 0.2258231
	speed: 0.0323s/iter; left time: 755.9520s
Epoch: 12 cost time: 8.859945297241211
Epoch: 12, Steps: 265 Train Loss: 0.2072 (Forecasting Loss:0.2040 + XiCon Loss:3.2412 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2141912
	speed: 0.0337s/iter; left time: 781.8704s
	iters: 200, epoch: 13 | loss: 0.2197330
	speed: 0.0319s/iter; left time: 736.9763s
Epoch: 13 cost time: 8.563008546829224
Epoch: 13, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2379 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2008174
	speed: 0.0331s/iter; left time: 759.2992s
	iters: 200, epoch: 14 | loss: 0.1836211
	speed: 0.0303s/iter; left time: 693.1881s
Epoch: 14 cost time: 8.411890506744385
Epoch: 14, Steps: 265 Train Loss: 0.2068 (Forecasting Loss:0.2036 + XiCon Loss:3.2384 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2197196
	speed: 0.0341s/iter; left time: 773.4708s
	iters: 200, epoch: 15 | loss: 0.1872808
	speed: 0.0322s/iter; left time: 726.7467s
Epoch: 15 cost time: 8.735040426254272
Epoch: 15, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2370 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2238356
	speed: 0.0335s/iter; left time: 750.3466s
	iters: 200, epoch: 16 | loss: 0.1954570
	speed: 0.0313s/iter; left time: 698.8451s
Epoch: 16 cost time: 8.532541513442993
Epoch: 16, Steps: 265 Train Loss: 0.2068 (Forecasting Loss:0.2035 + XiCon Loss:3.2399 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2306486
	speed: 0.0338s/iter; left time: 749.1044s
	iters: 200, epoch: 17 | loss: 0.1843972
	speed: 0.0310s/iter; left time: 683.8663s
Epoch: 17 cost time: 8.548566341400146
Epoch: 17, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2363 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
Validation loss decreased (0.211771 --> 0.211745).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2104589
	speed: 0.0331s/iter; left time: 724.3958s
	iters: 200, epoch: 18 | loss: 0.2183923
	speed: 0.0316s/iter; left time: 688.6331s
Epoch: 18 cost time: 8.47629189491272
Epoch: 18, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2038 + XiCon Loss:3.2389 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2071278
	speed: 0.0347s/iter; left time: 751.0105s
	iters: 200, epoch: 19 | loss: 0.2066570
	speed: 0.0309s/iter; left time: 665.8707s
Epoch: 19 cost time: 8.705654859542847
Epoch: 19, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2374 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.1774663
	speed: 0.0341s/iter; left time: 729.3247s
	iters: 200, epoch: 20 | loss: 0.2245568
	speed: 0.0327s/iter; left time: 694.5604s
Epoch: 20 cost time: 8.765748262405396
Epoch: 20, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2393 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2181472
	speed: 0.0344s/iter; left time: 725.0594s
	iters: 200, epoch: 21 | loss: 0.2072285
	speed: 0.0323s/iter; left time: 677.9488s
Epoch: 21 cost time: 8.778421401977539
Epoch: 21, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2390 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.1862008
	speed: 0.0343s/iter; left time: 714.4790s
	iters: 200, epoch: 22 | loss: 0.1876520
	speed: 0.0309s/iter; left time: 640.5438s
Epoch: 22 cost time: 8.594985008239746
Epoch: 22, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2398 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.1967792
	speed: 0.0338s/iter; left time: 694.3853s
	iters: 200, epoch: 23 | loss: 0.2303489
	speed: 0.0326s/iter; left time: 668.0576s
Epoch: 23 cost time: 8.693114757537842
Epoch: 23, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2386 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
Validation loss decreased (0.211745 --> 0.211724).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2044802
	speed: 0.0331s/iter; left time: 671.3268s
	iters: 200, epoch: 24 | loss: 0.2190112
	speed: 0.0327s/iter; left time: 661.4301s
Epoch: 24 cost time: 8.784231185913086
Epoch: 24, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2398 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2340201
	speed: 0.0345s/iter; left time: 692.2937s
	iters: 200, epoch: 25 | loss: 0.2259193
	speed: 0.0316s/iter; left time: 630.1871s
Epoch: 25 cost time: 8.622997522354126
Epoch: 25, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2413 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.1860503
	speed: 0.0331s/iter; left time: 653.9254s
	iters: 200, epoch: 26 | loss: 0.2061581
	speed: 0.0302s/iter; left time: 594.1005s
Epoch: 26 cost time: 8.210700035095215
Epoch: 26, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2397 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.1998295
	speed: 0.0752s/iter; left time: 1467.5277s
	iters: 200, epoch: 27 | loss: 0.2409162
	speed: 0.0784s/iter; left time: 1521.0704s
Epoch: 27 cost time: 20.111584663391113
Epoch: 27, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2403 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.1930092
	speed: 0.1046s/iter; left time: 2013.6052s
	iters: 200, epoch: 28 | loss: 0.2172155
	speed: 0.0898s/iter; left time: 1720.1772s
Epoch: 28 cost time: 25.031160593032837
Epoch: 28, Steps: 265 Train Loss: 0.2071 (Forecasting Loss:0.2039 + XiCon Loss:3.2389 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.1846642
	speed: 0.0768s/iter; left time: 1457.5808s
	iters: 200, epoch: 29 | loss: 0.2108602
	speed: 0.0690s/iter; left time: 1303.6675s
Epoch: 29 cost time: 18.726212739944458
Epoch: 29, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2391 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.2079983
	speed: 0.0460s/iter; left time: 861.6007s
	iters: 200, epoch: 30 | loss: 0.2157243
	speed: 0.0392s/iter; left time: 729.3485s
Epoch: 30 cost time: 10.71983551979065
Epoch: 30, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2410 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.2167913
	speed: 0.0346s/iter; left time: 639.0074s
	iters: 200, epoch: 31 | loss: 0.2378406
	speed: 0.0308s/iter; left time: 565.8560s
Epoch: 31 cost time: 8.625243902206421
Epoch: 31, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2390 x Lambda(0.001)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1699
Validation loss decreased (0.211724 --> 0.211622).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.2149062
	speed: 0.0324s/iter; left time: 588.6290s
	iters: 200, epoch: 32 | loss: 0.1893946
	speed: 0.0298s/iter; left time: 539.6394s
Epoch: 32 cost time: 8.274074792861938
Epoch: 32, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2375 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.2150016
	speed: 0.0328s/iter; left time: 588.5465s
	iters: 200, epoch: 33 | loss: 0.2141702
	speed: 0.0300s/iter; left time: 534.8073s
Epoch: 33 cost time: 8.308497428894043
Epoch: 33, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2384 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.2441763
	speed: 0.0315s/iter; left time: 556.0671s
	iters: 200, epoch: 34 | loss: 0.2204134
	speed: 0.0301s/iter; left time: 528.8652s
Epoch: 34 cost time: 8.119683742523193
Epoch: 34, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2394 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.2261171
	speed: 0.0319s/iter; left time: 555.5982s
	iters: 200, epoch: 35 | loss: 0.2528834
	speed: 0.0286s/iter; left time: 494.9455s
Epoch: 35 cost time: 7.997406244277954
Epoch: 35, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2407 x Lambda(0.001)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.1744455
	speed: 0.0304s/iter; left time: 520.1469s
	iters: 200, epoch: 36 | loss: 0.2182881
	speed: 0.0289s/iter; left time: 491.9671s
Epoch: 36 cost time: 7.862378358840942
Epoch: 36, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2381 x Lambda(0.001)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.2063650
	speed: 0.0342s/iter; left time: 577.3752s
	iters: 200, epoch: 37 | loss: 0.1996462
	speed: 0.0325s/iter; left time: 543.9931s
Epoch: 37 cost time: 8.836942434310913
Epoch: 37, Steps: 265 Train Loss: 0.2068 (Forecasting Loss:0.2035 + XiCon Loss:3.2374 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.1880611
	speed: 0.0350s/iter; left time: 580.6872s
	iters: 200, epoch: 38 | loss: 0.2286732
	speed: 0.0326s/iter; left time: 536.9912s
Epoch: 38 cost time: 8.854878425598145
Epoch: 38, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2375 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.2063949
	speed: 0.0345s/iter; left time: 563.6279s
	iters: 200, epoch: 39 | loss: 0.1789169
	speed: 0.0315s/iter; left time: 511.4176s
Epoch: 39 cost time: 8.616844654083252
Epoch: 39, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2395 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.2159128
	speed: 0.0337s/iter; left time: 541.9518s
	iters: 200, epoch: 40 | loss: 0.1957315
	speed: 0.0320s/iter; left time: 511.0187s
Epoch: 40 cost time: 8.624595642089844
Epoch: 40, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2038 + XiCon Loss:3.2400 x Lambda(0.001)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1699
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.1921470
	speed: 0.0341s/iter; left time: 538.7709s
	iters: 200, epoch: 41 | loss: 0.2237681
	speed: 0.0316s/iter; left time: 496.1828s
Epoch: 41 cost time: 8.644912958145142
Epoch: 41, Steps: 265 Train Loss: 0.2069 (Forecasting Loss:0.2037 + XiCon Loss:3.2388 x Lambda(0.001)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09967583417892456, mae:0.24010008573532104, mape:0.587611198425293, mspe:12.826972961425781 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8803
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3895882
	speed: 0.0354s/iter; left time: 934.5288s
	iters: 200, epoch: 1 | loss: 0.3118410
	speed: 0.0338s/iter; left time: 887.7736s
Epoch: 1 cost time: 9.200079917907715
Epoch: 1, Steps: 265 Train Loss: 0.3500 (Forecasting Loss:0.3468 + XiCon Loss:3.2416 x Lambda(0.001)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.2724
Validation loss decreased (inf --> 0.327718).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2545664
	speed: 0.0351s/iter; left time: 918.3004s
	iters: 200, epoch: 2 | loss: 0.2045086
	speed: 0.0321s/iter; left time: 834.7297s
Epoch: 2 cost time: 8.778856039047241
Epoch: 2, Steps: 265 Train Loss: 0.2391 (Forecasting Loss:0.2359 + XiCon Loss:3.2518 x Lambda(0.001)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1726
Validation loss decreased (0.327718 --> 0.213778).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2101506
	speed: 0.0349s/iter; left time: 903.5866s
	iters: 200, epoch: 3 | loss: 0.2123055
	speed: 0.0324s/iter; left time: 834.2776s
Epoch: 3 cost time: 8.779001235961914
Epoch: 3, Steps: 265 Train Loss: 0.2119 (Forecasting Loss:0.2086 + XiCon Loss:3.2631 x Lambda(0.001)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1695
Validation loss decreased (0.213778 --> 0.211276).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2076952
	speed: 0.0339s/iter; left time: 867.9459s
	iters: 200, epoch: 4 | loss: 0.2241944
	speed: 0.0305s/iter; left time: 778.5847s
Epoch: 4 cost time: 8.510704755783081
Epoch: 4, Steps: 265 Train Loss: 0.2085 (Forecasting Loss:0.2052 + XiCon Loss:3.2615 x Lambda(0.001)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1689
Validation loss decreased (0.211276 --> 0.209837).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2092208
	speed: 0.0331s/iter; left time: 837.9522s
	iters: 200, epoch: 5 | loss: 0.2138989
	speed: 0.0320s/iter; left time: 807.6397s
Epoch: 5 cost time: 8.581055879592896
Epoch: 5, Steps: 265 Train Loss: 0.2074 (Forecasting Loss:0.2041 + XiCon Loss:3.2632 x Lambda(0.001)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1690
Validation loss decreased (0.209837 --> 0.209733).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1930644
	speed: 0.0341s/iter; left time: 854.8476s
	iters: 200, epoch: 6 | loss: 0.2165172
	speed: 0.0323s/iter; left time: 807.8417s
Epoch: 6 cost time: 8.698835611343384
Epoch: 6, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.2037 + XiCon Loss:3.2632 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1689
Validation loss decreased (0.209733 --> 0.209626).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1998108
	speed: 0.0334s/iter; left time: 829.7844s
	iters: 200, epoch: 7 | loss: 0.1781095
	speed: 0.0313s/iter; left time: 773.9695s
Epoch: 7 cost time: 8.589746236801147
Epoch: 7, Steps: 265 Train Loss: 0.2065 (Forecasting Loss:0.2032 + XiCon Loss:3.2613 x Lambda(0.001)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1689
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2288188
	speed: 0.0337s/iter; left time: 828.1546s
	iters: 200, epoch: 8 | loss: 0.2094810
	speed: 0.0313s/iter; left time: 765.4152s
Epoch: 8 cost time: 8.56028962135315
Epoch: 8, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2032 + XiCon Loss:3.2641 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
Validation loss decreased (0.209626 --> 0.209614).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2025751
	speed: 0.0336s/iter; left time: 815.4373s
	iters: 200, epoch: 9 | loss: 0.1899011
	speed: 0.0314s/iter; left time: 760.1604s
Epoch: 9 cost time: 8.560717821121216
Epoch: 9, Steps: 265 Train Loss: 0.2065 (Forecasting Loss:0.2032 + XiCon Loss:3.2645 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
Validation loss decreased (0.209614 --> 0.209569).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2197508
	speed: 0.0342s/iter; left time: 820.7155s
	iters: 200, epoch: 10 | loss: 0.2190924
	speed: 0.0315s/iter; left time: 753.1165s
Epoch: 10 cost time: 8.573825120925903
Epoch: 10, Steps: 265 Train Loss: 0.2065 (Forecasting Loss:0.2032 + XiCon Loss:3.2651 x Lambda(0.001)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1688
Validation loss decreased (0.209569 --> 0.209509).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2143440
	speed: 0.0336s/iter; left time: 796.8820s
	iters: 200, epoch: 11 | loss: 0.2073828
	speed: 0.0316s/iter; left time: 748.2043s
Epoch: 11 cost time: 8.618572473526001
Epoch: 11, Steps: 265 Train Loss: 0.2063 (Forecasting Loss:0.2031 + XiCon Loss:3.2634 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2022099
	speed: 0.0337s/iter; left time: 791.2865s
	iters: 200, epoch: 12 | loss: 0.2091460
	speed: 0.0319s/iter; left time: 746.3915s
Epoch: 12 cost time: 8.637330055236816
Epoch: 12, Steps: 265 Train Loss: 0.2065 (Forecasting Loss:0.2032 + XiCon Loss:3.2666 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2113250
	speed: 0.0343s/iter; left time: 796.1702s
	iters: 200, epoch: 13 | loss: 0.1870176
	speed: 0.0317s/iter; left time: 731.9200s
Epoch: 13 cost time: 8.690716981887817
Epoch: 13, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2031 + XiCon Loss:3.2651 x Lambda(0.001)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1688
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2061309
	speed: 0.0349s/iter; left time: 800.0587s
	iters: 200, epoch: 14 | loss: 0.1984431
	speed: 0.0322s/iter; left time: 736.9035s
Epoch: 14 cost time: 8.854114770889282
Epoch: 14, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2032 + XiCon Loss:3.2638 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2185241
	speed: 0.0340s/iter; left time: 771.3343s
	iters: 200, epoch: 15 | loss: 0.2148351
	speed: 0.0324s/iter; left time: 732.7078s
Epoch: 15 cost time: 8.723123550415039
Epoch: 15, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2031 + XiCon Loss:3.2616 x Lambda(0.001)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1688
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.1970279
	speed: 0.0337s/iter; left time: 756.1963s
	iters: 200, epoch: 16 | loss: 0.1938989
	speed: 0.0318s/iter; left time: 708.9821s
Epoch: 16 cost time: 8.66567611694336
Epoch: 16, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2032 + XiCon Loss:3.2649 x Lambda(0.001)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1688
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2358267
	speed: 0.0329s/iter; left time: 729.5620s
	iters: 200, epoch: 17 | loss: 0.2109405
	speed: 0.0309s/iter; left time: 682.7546s
Epoch: 17 cost time: 8.383603811264038
Epoch: 17, Steps: 265 Train Loss: 0.2062 (Forecasting Loss:0.2030 + XiCon Loss:3.2637 x Lambda(0.001)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1688
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2492646
	speed: 0.0329s/iter; left time: 720.7441s
	iters: 200, epoch: 18 | loss: 0.1793345
	speed: 0.0310s/iter; left time: 676.3437s
Epoch: 18 cost time: 8.42274022102356
Epoch: 18, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2031 + XiCon Loss:3.2632 x Lambda(0.001)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1688
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.1837281
	speed: 0.0356s/iter; left time: 770.3396s
	iters: 200, epoch: 19 | loss: 0.2379330
	speed: 0.0318s/iter; left time: 685.0796s
Epoch: 19 cost time: 8.895551443099976
Epoch: 19, Steps: 265 Train Loss: 0.2064 (Forecasting Loss:0.2032 + XiCon Loss:3.2659 x Lambda(0.001)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1688
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.1659260
	speed: 0.0343s/iter; left time: 733.7629s
	iters: 200, epoch: 20 | loss: 0.1957776
	speed: 0.0322s/iter; left time: 684.9000s
Epoch: 20 cost time: 8.748209953308105
Epoch: 20, Steps: 265 Train Loss: 0.2065 (Forecasting Loss:0.2033 + XiCon Loss:3.2631 x Lambda(0.001)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1688
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0989413633942604, mae:0.23870797455310822, mape:0.5849970579147339, mspe:12.768146514892578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0987+-0.00231, MAE:0.2389+-0.00309, MAPE:0.5779+-0.01246, MSPE:12.2604+-0.64951, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1420
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3579955
	speed: 0.0399s/iter; left time: 1048.8317s
	iters: 200, epoch: 1 | loss: 0.3019823
	speed: 0.0341s/iter; left time: 892.3243s
Epoch: 1 cost time: 9.666971921920776
Epoch: 1, Steps: 264 Train Loss: 0.3387 (Forecasting Loss:0.3354 + XiCon Loss:3.2326 x Lambda(0.001)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2325
Validation loss decreased (inf --> 0.294854).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2527604
	speed: 0.0364s/iter; left time: 948.7405s
	iters: 200, epoch: 2 | loss: 0.2546051
	speed: 0.0347s/iter; left time: 900.6133s
Epoch: 2 cost time: 9.28988766670227
Epoch: 2, Steps: 264 Train Loss: 0.2546 (Forecasting Loss:0.2513 + XiCon Loss:3.2182 x Lambda(0.001)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.1947
Validation loss decreased (0.294854 --> 0.253958).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2358278
	speed: 0.0372s/iter; left time: 958.7969s
	iters: 200, epoch: 3 | loss: 0.2111077
	speed: 0.0347s/iter; left time: 890.5708s
Epoch: 3 cost time: 9.343066453933716
Epoch: 3, Steps: 264 Train Loss: 0.2409 (Forecasting Loss:0.2377 + XiCon Loss:3.1973 x Lambda(0.001)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2036
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2044972
	speed: 0.0375s/iter; left time: 955.5316s
	iters: 200, epoch: 4 | loss: 0.2433126
	speed: 0.0349s/iter; left time: 886.3708s
Epoch: 4 cost time: 9.44187307357788
Epoch: 4, Steps: 264 Train Loss: 0.2334 (Forecasting Loss:0.2302 + XiCon Loss:3.1911 x Lambda(0.001)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.2038
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2013332
	speed: 0.0368s/iter; left time: 928.1625s
	iters: 200, epoch: 5 | loss: 0.2129897
	speed: 0.0343s/iter; left time: 861.5979s
Epoch: 5 cost time: 9.374865055084229
Epoch: 5, Steps: 264 Train Loss: 0.2293 (Forecasting Loss:0.2261 + XiCon Loss:3.1887 x Lambda(0.001)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.2074
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2289715
	speed: 0.0359s/iter; left time: 896.6572s
	iters: 200, epoch: 6 | loss: 0.2187172
	speed: 0.0342s/iter; left time: 851.6206s
Epoch: 6 cost time: 9.189007759094238
Epoch: 6, Steps: 264 Train Loss: 0.2276 (Forecasting Loss:0.2244 + XiCon Loss:3.1861 x Lambda(0.001)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.2089
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2033859
	speed: 0.0365s/iter; left time: 901.6041s
	iters: 200, epoch: 7 | loss: 0.2361570
	speed: 0.0351s/iter; left time: 864.8913s
Epoch: 7 cost time: 9.399648666381836
Epoch: 7, Steps: 264 Train Loss: 0.2269 (Forecasting Loss:0.2237 + XiCon Loss:3.1842 x Lambda(0.001)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.2081
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2258530
	speed: 0.0365s/iter; left time: 892.3523s
	iters: 200, epoch: 8 | loss: 0.2308432
	speed: 0.0336s/iter; left time: 817.7369s
Epoch: 8 cost time: 9.192468881607056
Epoch: 8, Steps: 264 Train Loss: 0.2265 (Forecasting Loss:0.2233 + XiCon Loss:3.1860 x Lambda(0.001)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.2080
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2223411
	speed: 0.0362s/iter; left time: 876.8297s
	iters: 200, epoch: 9 | loss: 0.2349495
	speed: 0.0346s/iter; left time: 833.8812s
Epoch: 9 cost time: 9.31187629699707
Epoch: 9, Steps: 264 Train Loss: 0.2264 (Forecasting Loss:0.2232 + XiCon Loss:3.1868 x Lambda(0.001)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.2087
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2552353
	speed: 0.0365s/iter; left time: 872.2043s
	iters: 200, epoch: 10 | loss: 0.2059972
	speed: 0.0340s/iter; left time: 809.9892s
Epoch: 10 cost time: 9.299753665924072
Epoch: 10, Steps: 264 Train Loss: 0.2265 (Forecasting Loss:0.2233 + XiCon Loss:3.1869 x Lambda(0.001)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.2086
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2079094
	speed: 0.0362s/iter; left time: 855.5254s
	iters: 200, epoch: 11 | loss: 0.2421542
	speed: 0.0344s/iter; left time: 810.4037s
Epoch: 11 cost time: 9.202110052108765
Epoch: 11, Steps: 264 Train Loss: 0.2264 (Forecasting Loss:0.2232 + XiCon Loss:3.1876 x Lambda(0.001)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.2087
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2392596
	speed: 0.0370s/iter; left time: 865.9328s
	iters: 200, epoch: 12 | loss: 0.1941585
	speed: 0.0353s/iter; left time: 822.3658s
Epoch: 12 cost time: 9.501152276992798
Epoch: 12, Steps: 264 Train Loss: 0.2260 (Forecasting Loss:0.2228 + XiCon Loss:3.1867 x Lambda(0.001)), Vali MSE Loss: 0.2652 Test MSE Loss: 0.2087
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12210068106651306, mae:0.2672330141067505, mape:0.6440310478210449, mspe:14.55344295501709 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.4173
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3538996
	speed: 0.0372s/iter; left time: 978.1481s
	iters: 200, epoch: 1 | loss: 0.2912730
	speed: 0.0346s/iter; left time: 906.9878s
Epoch: 1 cost time: 9.416013717651367
Epoch: 1, Steps: 264 Train Loss: 0.3341 (Forecasting Loss:0.3309 + XiCon Loss:3.2403 x Lambda(0.001)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.2293
Validation loss decreased (inf --> 0.292384).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2474352
	speed: 0.0367s/iter; left time: 956.3390s
	iters: 200, epoch: 2 | loss: 0.2165769
	speed: 0.0342s/iter; left time: 887.2291s
Epoch: 2 cost time: 9.29121208190918
Epoch: 2, Steps: 264 Train Loss: 0.2489 (Forecasting Loss:0.2457 + XiCon Loss:3.2493 x Lambda(0.001)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.2033
Validation loss decreased (0.292384 --> 0.261182).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2359019
	speed: 0.0367s/iter; left time: 947.0052s
	iters: 200, epoch: 3 | loss: 0.2393943
	speed: 0.0352s/iter; left time: 903.8509s
Epoch: 3 cost time: 9.40073537826538
Epoch: 3, Steps: 264 Train Loss: 0.2334 (Forecasting Loss:0.2301 + XiCon Loss:3.2540 x Lambda(0.001)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2069
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2136361
	speed: 0.0357s/iter; left time: 910.3941s
	iters: 200, epoch: 4 | loss: 0.2242271
	speed: 0.0327s/iter; left time: 830.9368s
Epoch: 4 cost time: 9.106425523757935
Epoch: 4, Steps: 264 Train Loss: 0.2273 (Forecasting Loss:0.2240 + XiCon Loss:3.2555 x Lambda(0.001)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.2100
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2350968
	speed: 0.0373s/iter; left time: 941.0350s
	iters: 200, epoch: 5 | loss: 0.2207914
	speed: 0.0361s/iter; left time: 908.7738s
Epoch: 5 cost time: 9.633723735809326
Epoch: 5, Steps: 264 Train Loss: 0.2239 (Forecasting Loss:0.2206 + XiCon Loss:3.2547 x Lambda(0.001)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.2125
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2561476
	speed: 0.0372s/iter; left time: 929.2619s
	iters: 200, epoch: 6 | loss: 0.2285875
	speed: 0.0355s/iter; left time: 882.5690s
Epoch: 6 cost time: 9.508500337600708
Epoch: 6, Steps: 264 Train Loss: 0.2224 (Forecasting Loss:0.2192 + XiCon Loss:3.2553 x Lambda(0.001)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2132
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2384366
	speed: 0.0378s/iter; left time: 934.4600s
	iters: 200, epoch: 7 | loss: 0.2056549
	speed: 0.0346s/iter; left time: 852.5804s
Epoch: 7 cost time: 9.521151781082153
Epoch: 7, Steps: 264 Train Loss: 0.2214 (Forecasting Loss:0.2182 + XiCon Loss:3.2540 x Lambda(0.001)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2150
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2159929
	speed: 0.0367s/iter; left time: 898.0601s
	iters: 200, epoch: 8 | loss: 0.2125191
	speed: 0.0350s/iter; left time: 851.6390s
Epoch: 8 cost time: 9.464078187942505
Epoch: 8, Steps: 264 Train Loss: 0.2210 (Forecasting Loss:0.2178 + XiCon Loss:3.2549 x Lambda(0.001)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2154
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2267795
	speed: 0.0370s/iter; left time: 895.4627s
	iters: 200, epoch: 9 | loss: 0.2259625
	speed: 0.0355s/iter; left time: 854.1511s
Epoch: 9 cost time: 9.46424388885498
Epoch: 9, Steps: 264 Train Loss: 0.2209 (Forecasting Loss:0.2177 + XiCon Loss:3.2549 x Lambda(0.001)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2155
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2304975
	speed: 0.0366s/iter; left time: 875.2084s
	iters: 200, epoch: 10 | loss: 0.2092231
	speed: 0.0358s/iter; left time: 853.0880s
Epoch: 10 cost time: 9.526764869689941
Epoch: 10, Steps: 264 Train Loss: 0.2208 (Forecasting Loss:0.2175 + XiCon Loss:3.2543 x Lambda(0.001)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2157
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2229452
	speed: 0.0384s/iter; left time: 908.9717s
	iters: 200, epoch: 11 | loss: 0.2220788
	speed: 0.0355s/iter; left time: 836.8470s
Epoch: 11 cost time: 9.561964988708496
Epoch: 11, Steps: 264 Train Loss: 0.2208 (Forecasting Loss:0.2175 + XiCon Loss:3.2547 x Lambda(0.001)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2157
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2212244
	speed: 0.0375s/iter; left time: 878.3776s
	iters: 200, epoch: 12 | loss: 0.2398168
	speed: 0.0346s/iter; left time: 806.3345s
Epoch: 12 cost time: 9.486669301986694
Epoch: 12, Steps: 264 Train Loss: 0.2207 (Forecasting Loss:0.2174 + XiCon Loss:3.2567 x Lambda(0.001)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2157
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.1295030266046524, mae:0.2771642208099365, mape:0.6641288995742798, mspe:15.687766075134277 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1674
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3326884
	speed: 0.0383s/iter; left time: 1006.2404s
	iters: 200, epoch: 1 | loss: 0.3536400
	speed: 0.0350s/iter; left time: 916.0707s
Epoch: 1 cost time: 9.501719951629639
Epoch: 1, Steps: 264 Train Loss: 0.3379 (Forecasting Loss:0.3347 + XiCon Loss:3.2551 x Lambda(0.001)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.2324
Validation loss decreased (inf --> 0.295958).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2880399
	speed: 0.0362s/iter; left time: 941.4576s
	iters: 200, epoch: 2 | loss: 0.2367456
	speed: 0.0346s/iter; left time: 898.1583s
Epoch: 2 cost time: 9.29118824005127
Epoch: 2, Steps: 264 Train Loss: 0.2494 (Forecasting Loss:0.2461 + XiCon Loss:3.2221 x Lambda(0.001)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.2056
Validation loss decreased (0.295958 --> 0.261357).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2418180
	speed: 0.0372s/iter; left time: 958.1625s
	iters: 200, epoch: 3 | loss: 0.2488328
	speed: 0.0350s/iter; left time: 899.7899s
Epoch: 3 cost time: 9.414402961730957
Epoch: 3, Steps: 264 Train Loss: 0.2332 (Forecasting Loss:0.2300 + XiCon Loss:3.2103 x Lambda(0.001)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.2087
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2363500
	speed: 0.0368s/iter; left time: 937.9725s
	iters: 200, epoch: 4 | loss: 0.2368326
	speed: 0.0350s/iter; left time: 888.7929s
Epoch: 4 cost time: 9.418924570083618
Epoch: 4, Steps: 264 Train Loss: 0.2268 (Forecasting Loss:0.2236 + XiCon Loss:3.2132 x Lambda(0.001)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.2119
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2218687
	speed: 0.0369s/iter; left time: 930.9314s
	iters: 200, epoch: 5 | loss: 0.2131855
	speed: 0.0352s/iter; left time: 885.7540s
Epoch: 5 cost time: 9.529024124145508
Epoch: 5, Steps: 264 Train Loss: 0.2240 (Forecasting Loss:0.2208 + XiCon Loss:3.2110 x Lambda(0.001)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.2126
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2216003
	speed: 0.0373s/iter; left time: 932.8417s
	iters: 200, epoch: 6 | loss: 0.2553542
	speed: 0.0358s/iter; left time: 889.6121s
Epoch: 6 cost time: 9.431110620498657
Epoch: 6, Steps: 264 Train Loss: 0.2227 (Forecasting Loss:0.2195 + XiCon Loss:3.2089 x Lambda(0.001)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.2145
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2435397
	speed: 0.0369s/iter; left time: 911.9605s
	iters: 200, epoch: 7 | loss: 0.2320540
	speed: 0.0348s/iter; left time: 857.1665s
Epoch: 7 cost time: 9.395382642745972
Epoch: 7, Steps: 264 Train Loss: 0.2220 (Forecasting Loss:0.2187 + XiCon Loss:3.2079 x Lambda(0.001)), Vali MSE Loss: 0.2645 Test MSE Loss: 0.2152
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2249478
	speed: 0.0361s/iter; left time: 882.4750s
	iters: 200, epoch: 8 | loss: 0.1964422
	speed: 0.0345s/iter; left time: 840.9945s
Epoch: 8 cost time: 9.310383796691895
Epoch: 8, Steps: 264 Train Loss: 0.2217 (Forecasting Loss:0.2185 + XiCon Loss:3.2096 x Lambda(0.001)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.2160
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2070490
	speed: 0.0364s/iter; left time: 881.1776s
	iters: 200, epoch: 9 | loss: 0.2139890
	speed: 0.0346s/iter; left time: 832.5827s
Epoch: 9 cost time: 9.296396732330322
Epoch: 9, Steps: 264 Train Loss: 0.2216 (Forecasting Loss:0.2184 + XiCon Loss:3.2079 x Lambda(0.001)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.2159
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2130655
	speed: 0.0368s/iter; left time: 880.3615s
	iters: 200, epoch: 10 | loss: 0.2489332
	speed: 0.0345s/iter; left time: 821.8126s
Epoch: 10 cost time: 9.32028079032898
Epoch: 10, Steps: 264 Train Loss: 0.2214 (Forecasting Loss:0.2181 + XiCon Loss:3.2099 x Lambda(0.001)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.2158
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2045944
	speed: 0.0371s/iter; left time: 878.9528s
	iters: 200, epoch: 11 | loss: 0.2159011
	speed: 0.0340s/iter; left time: 801.4527s
Epoch: 11 cost time: 9.376986265182495
Epoch: 11, Steps: 264 Train Loss: 0.2215 (Forecasting Loss:0.2182 + XiCon Loss:3.2083 x Lambda(0.001)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.2159
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2266241
	speed: 0.0353s/iter; left time: 825.0973s
	iters: 200, epoch: 12 | loss: 0.2179290
	speed: 0.0334s/iter; left time: 777.4703s
Epoch: 12 cost time: 8.993351221084595
Epoch: 12, Steps: 264 Train Loss: 0.2212 (Forecasting Loss:0.2180 + XiCon Loss:3.2094 x Lambda(0.001)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.2159
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.1313762664794922, mae:0.27987614274024963, mape:0.6825027465820312, mspe:16.052043914794922 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6007
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3475906
	speed: 0.0377s/iter; left time: 991.4900s
	iters: 200, epoch: 1 | loss: 0.2937684
	speed: 0.0350s/iter; left time: 917.9160s
Epoch: 1 cost time: 9.46760082244873
Epoch: 1, Steps: 264 Train Loss: 0.3394 (Forecasting Loss:0.3362 + XiCon Loss:3.2277 x Lambda(0.001)), Vali MSE Loss: 0.2973 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.297330).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2505983
	speed: 0.0367s/iter; left time: 955.6583s
	iters: 200, epoch: 2 | loss: 0.2393170
	speed: 0.0340s/iter; left time: 882.8696s
Epoch: 2 cost time: 9.300228357315063
Epoch: 2, Steps: 264 Train Loss: 0.2540 (Forecasting Loss:0.2508 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1993
Validation loss decreased (0.297330 --> 0.255027).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2160294
	speed: 0.0363s/iter; left time: 935.5661s
	iters: 200, epoch: 3 | loss: 0.2528769
	speed: 0.0339s/iter; left time: 869.9155s
Epoch: 3 cost time: 9.169143915176392
Epoch: 3, Steps: 264 Train Loss: 0.2373 (Forecasting Loss:0.2341 + XiCon Loss:3.2145 x Lambda(0.001)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.2074
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2303812
	speed: 0.0369s/iter; left time: 941.9988s
	iters: 200, epoch: 4 | loss: 0.2095383
	speed: 0.0343s/iter; left time: 871.9949s
Epoch: 4 cost time: 9.344835996627808
Epoch: 4, Steps: 264 Train Loss: 0.2301 (Forecasting Loss:0.2269 + XiCon Loss:3.2109 x Lambda(0.001)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.2074
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2231129
	speed: 0.0372s/iter; left time: 938.9420s
	iters: 200, epoch: 5 | loss: 0.2366761
	speed: 0.0345s/iter; left time: 866.4888s
Epoch: 5 cost time: 9.41245150566101
Epoch: 5, Steps: 264 Train Loss: 0.2271 (Forecasting Loss:0.2239 + XiCon Loss:3.2061 x Lambda(0.001)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.2087
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2282530
	speed: 0.0363s/iter; left time: 906.0689s
	iters: 200, epoch: 6 | loss: 0.2301976
	speed: 0.0347s/iter; left time: 863.0374s
Epoch: 6 cost time: 9.27527666091919
Epoch: 6, Steps: 264 Train Loss: 0.2257 (Forecasting Loss:0.2225 + XiCon Loss:3.2061 x Lambda(0.001)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.2078
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2450963
	speed: 0.0362s/iter; left time: 895.6551s
	iters: 200, epoch: 7 | loss: 0.2387185
	speed: 0.0347s/iter; left time: 853.0299s
Epoch: 7 cost time: 9.254050493240356
Epoch: 7, Steps: 264 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.2072 x Lambda(0.001)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2082
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2284647
	speed: 0.0370s/iter; left time: 903.5799s
	iters: 200, epoch: 8 | loss: 0.2426190
	speed: 0.0346s/iter; left time: 842.4143s
Epoch: 8 cost time: 9.351317644119263
Epoch: 8, Steps: 264 Train Loss: 0.2243 (Forecasting Loss:0.2211 + XiCon Loss:3.2052 x Lambda(0.001)), Vali MSE Loss: 0.2804 Test MSE Loss: 0.2091
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2183271
	speed: 0.0356s/iter; left time: 862.0862s
	iters: 200, epoch: 9 | loss: 0.2534344
	speed: 0.0347s/iter; left time: 835.5623s
Epoch: 9 cost time: 9.223960876464844
Epoch: 9, Steps: 264 Train Loss: 0.2241 (Forecasting Loss:0.2209 + XiCon Loss:3.2063 x Lambda(0.001)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2080
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2620271
	speed: 0.0355s/iter; left time: 848.7883s
	iters: 200, epoch: 10 | loss: 0.2215102
	speed: 0.0326s/iter; left time: 777.4494s
Epoch: 10 cost time: 9.07373595237732
Epoch: 10, Steps: 264 Train Loss: 0.2243 (Forecasting Loss:0.2211 + XiCon Loss:3.2045 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2086
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2266215
	speed: 0.0375s/iter; left time: 886.5206s
	iters: 200, epoch: 11 | loss: 0.2334830
	speed: 0.0349s/iter; left time: 821.8782s
Epoch: 11 cost time: 9.52978229522705
Epoch: 11, Steps: 264 Train Loss: 0.2243 (Forecasting Loss:0.2211 + XiCon Loss:3.2045 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2085
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2222400
	speed: 0.0367s/iter; left time: 859.7967s
	iters: 200, epoch: 12 | loss: 0.2308839
	speed: 0.0355s/iter; left time: 826.4903s
Epoch: 12 cost time: 9.437139987945557
Epoch: 12, Steps: 264 Train Loss: 0.2243 (Forecasting Loss:0.2211 + XiCon Loss:3.2074 x Lambda(0.001)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.2084
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12621702253818512, mae:0.27243033051490784, mape:0.6899134516716003, mspe:17.1320743560791 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9792
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3443733
	speed: 0.0386s/iter; left time: 1015.6948s
	iters: 200, epoch: 1 | loss: 0.3293853
	speed: 0.0362s/iter; left time: 948.8755s
Epoch: 1 cost time: 9.771971464157104
Epoch: 1, Steps: 264 Train Loss: 0.3376 (Forecasting Loss:0.3343 + XiCon Loss:3.2595 x Lambda(0.001)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2302
Validation loss decreased (inf --> 0.290926).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2183616
	speed: 0.0362s/iter; left time: 942.1294s
	iters: 200, epoch: 2 | loss: 0.2580678
	speed: 0.0347s/iter; left time: 900.2517s
Epoch: 2 cost time: 9.31394362449646
Epoch: 2, Steps: 264 Train Loss: 0.2474 (Forecasting Loss:0.2442 + XiCon Loss:3.2561 x Lambda(0.001)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2041
Validation loss decreased (0.290926 --> 0.250892).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2375765
	speed: 0.0369s/iter; left time: 949.7573s
	iters: 200, epoch: 3 | loss: 0.2259114
	speed: 0.0346s/iter; left time: 889.1294s
Epoch: 3 cost time: 9.425164937973022
Epoch: 3, Steps: 264 Train Loss: 0.2341 (Forecasting Loss:0.2308 + XiCon Loss:3.2361 x Lambda(0.001)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.2160
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2632270
	speed: 0.0366s/iter; left time: 933.6607s
	iters: 200, epoch: 4 | loss: 0.2175189
	speed: 0.0345s/iter; left time: 877.0689s
Epoch: 4 cost time: 9.352421998977661
Epoch: 4, Steps: 264 Train Loss: 0.2280 (Forecasting Loss:0.2247 + XiCon Loss:3.2331 x Lambda(0.001)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.2194
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2273243
	speed: 0.0365s/iter; left time: 921.8673s
	iters: 200, epoch: 5 | loss: 0.2148166
	speed: 0.0351s/iter; left time: 883.3549s
Epoch: 5 cost time: 9.345759153366089
Epoch: 5, Steps: 264 Train Loss: 0.2241 (Forecasting Loss:0.2209 + XiCon Loss:3.2315 x Lambda(0.001)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.2202
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2400700
	speed: 0.0358s/iter; left time: 895.1777s
	iters: 200, epoch: 6 | loss: 0.2079349
	speed: 0.0346s/iter; left time: 860.1972s
Epoch: 6 cost time: 9.320051670074463
Epoch: 6, Steps: 264 Train Loss: 0.2221 (Forecasting Loss:0.2188 + XiCon Loss:3.2325 x Lambda(0.001)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2230
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2292696
	speed: 0.0359s/iter; left time: 887.4537s
	iters: 200, epoch: 7 | loss: 0.2457969
	speed: 0.0339s/iter; left time: 834.2759s
Epoch: 7 cost time: 9.125738382339478
Epoch: 7, Steps: 264 Train Loss: 0.2210 (Forecasting Loss:0.2177 + XiCon Loss:3.2335 x Lambda(0.001)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.2225
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2192179
	speed: 0.0367s/iter; left time: 898.5673s
	iters: 200, epoch: 8 | loss: 0.2099675
	speed: 0.0346s/iter; left time: 843.7489s
Epoch: 8 cost time: 9.401010990142822
Epoch: 8, Steps: 264 Train Loss: 0.2206 (Forecasting Loss:0.2174 + XiCon Loss:3.2344 x Lambda(0.001)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.2228
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2209530
	speed: 0.0375s/iter; left time: 905.9985s
	iters: 200, epoch: 9 | loss: 0.2480582
	speed: 0.0368s/iter; left time: 886.4320s
Epoch: 9 cost time: 9.657399654388428
Epoch: 9, Steps: 264 Train Loss: 0.2203 (Forecasting Loss:0.2171 + XiCon Loss:3.2345 x Lambda(0.001)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.2232
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2077553
	speed: 0.0368s/iter; left time: 880.5089s
	iters: 200, epoch: 10 | loss: 0.1909284
	speed: 0.0347s/iter; left time: 826.1836s
Epoch: 10 cost time: 9.401030540466309
Epoch: 10, Steps: 264 Train Loss: 0.2202 (Forecasting Loss:0.2169 + XiCon Loss:3.2348 x Lambda(0.001)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.2233
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2419425
	speed: 0.0386s/iter; left time: 913.9409s
	iters: 200, epoch: 11 | loss: 0.1986349
	speed: 0.0346s/iter; left time: 815.9040s
Epoch: 11 cost time: 9.607783079147339
Epoch: 11, Steps: 264 Train Loss: 0.2200 (Forecasting Loss:0.2168 + XiCon Loss:3.2325 x Lambda(0.001)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.2234
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2105215
	speed: 0.0369s/iter; left time: 862.5662s
	iters: 200, epoch: 12 | loss: 0.2360885
	speed: 0.0358s/iter; left time: 833.4739s
Epoch: 12 cost time: 9.525806665420532
Epoch: 12, Steps: 264 Train Loss: 0.2200 (Forecasting Loss:0.2167 + XiCon Loss:3.2342 x Lambda(0.001)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.2234
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.1300748586654663, mae:0.27815067768096924, mape:0.662924587726593, mspe:15.240524291992188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1279+-0.00464, MAE:0.2750+-0.00637, MAPE:0.6687+-0.02241, MSPE:15.7332+-1.19341, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9741
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3856410
	speed: 0.0529s/iter; left time: 1376.2309s
	iters: 200, epoch: 1 | loss: 0.3254096
	speed: 0.0477s/iter; left time: 1235.3596s
Epoch: 1 cost time: 13.047357559204102
Epoch: 1, Steps: 261 Train Loss: 0.3748 (Forecasting Loss:0.3716 + XiCon Loss:3.2378 x Lambda(0.001)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2788
Validation loss decreased (inf --> 0.321083).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2753528
	speed: 0.0499s/iter; left time: 1285.0081s
	iters: 200, epoch: 2 | loss: 0.2667370
	speed: 0.0478s/iter; left time: 1225.4872s
Epoch: 2 cost time: 12.70491647720337
Epoch: 2, Steps: 261 Train Loss: 0.2960 (Forecasting Loss:0.2928 + XiCon Loss:3.2175 x Lambda(0.001)), Vali MSE Loss: 0.3053 Test MSE Loss: 0.2529
Validation loss decreased (0.321083 --> 0.305263).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2757649
	speed: 0.0504s/iter; left time: 1283.6769s
	iters: 200, epoch: 3 | loss: 0.2965817
	speed: 0.0442s/iter; left time: 1121.3063s
Epoch: 3 cost time: 12.178708553314209
Epoch: 3, Steps: 261 Train Loss: 0.2800 (Forecasting Loss:0.2768 + XiCon Loss:3.2140 x Lambda(0.001)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2598
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2606141
	speed: 0.0508s/iter; left time: 1282.3195s
	iters: 200, epoch: 4 | loss: 0.2722487
	speed: 0.0484s/iter; left time: 1214.9410s
Epoch: 4 cost time: 12.89767575263977
Epoch: 4, Steps: 261 Train Loss: 0.2733 (Forecasting Loss:0.2701 + XiCon Loss:3.2135 x Lambda(0.001)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2620
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2787212
	speed: 0.0509s/iter; left time: 1269.7022s
	iters: 200, epoch: 5 | loss: 0.2658813
	speed: 0.0486s/iter; left time: 1208.9270s
Epoch: 5 cost time: 12.980561256408691
Epoch: 5, Steps: 261 Train Loss: 0.2705 (Forecasting Loss:0.2673 + XiCon Loss:3.2096 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2967026
	speed: 0.0512s/iter; left time: 1265.4634s
	iters: 200, epoch: 6 | loss: 0.2809984
	speed: 0.0496s/iter; left time: 1220.0631s
Epoch: 6 cost time: 13.0249502658844
Epoch: 6, Steps: 261 Train Loss: 0.2686 (Forecasting Loss:0.2654 + XiCon Loss:3.2093 x Lambda(0.001)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2626
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2519928
	speed: 0.0518s/iter; left time: 1265.5194s
	iters: 200, epoch: 7 | loss: 0.2536335
	speed: 0.0488s/iter; left time: 1187.6873s
Epoch: 7 cost time: 13.02358102798462
Epoch: 7, Steps: 261 Train Loss: 0.2681 (Forecasting Loss:0.2649 + XiCon Loss:3.2080 x Lambda(0.001)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2647478
	speed: 0.0500s/iter; left time: 1207.6117s
	iters: 200, epoch: 8 | loss: 0.2712431
	speed: 0.0489s/iter; left time: 1177.2680s
Epoch: 8 cost time: 12.776280879974365
Epoch: 8, Steps: 261 Train Loss: 0.2678 (Forecasting Loss:0.2646 + XiCon Loss:3.2090 x Lambda(0.001)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2642
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2609934
	speed: 0.0507s/iter; left time: 1211.7416s
	iters: 200, epoch: 9 | loss: 0.2531320
	speed: 0.0502s/iter; left time: 1195.7342s
Epoch: 9 cost time: 13.200902223587036
Epoch: 9, Steps: 261 Train Loss: 0.2675 (Forecasting Loss:0.2643 + XiCon Loss:3.2093 x Lambda(0.001)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.2643
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2891008
	speed: 0.0515s/iter; left time: 1217.9602s
	iters: 200, epoch: 10 | loss: 0.2514498
	speed: 0.0491s/iter; left time: 1155.4199s
Epoch: 10 cost time: 13.07629656791687
Epoch: 10, Steps: 261 Train Loss: 0.2672 (Forecasting Loss:0.2640 + XiCon Loss:3.2080 x Lambda(0.001)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.2643
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2693501
	speed: 0.0487s/iter; left time: 1139.3562s
	iters: 200, epoch: 11 | loss: 0.2541551
	speed: 0.0443s/iter; left time: 1032.9518s
Epoch: 11 cost time: 12.281598806381226
Epoch: 11, Steps: 261 Train Loss: 0.2674 (Forecasting Loss:0.2642 + XiCon Loss:3.2069 x Lambda(0.001)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.2643
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2429500
	speed: 0.0514s/iter; left time: 1188.8182s
	iters: 200, epoch: 12 | loss: 0.2872045
	speed: 0.0495s/iter; left time: 1139.4280s
Epoch: 12 cost time: 13.154794216156006
Epoch: 12, Steps: 261 Train Loss: 0.2673 (Forecasting Loss:0.2641 + XiCon Loss:3.2099 x Lambda(0.001)), Vali MSE Loss: 0.3255 Test MSE Loss: 0.2643
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17900557816028595, mae:0.32686978578567505, mape:0.6966617703437805, mspe:17.46308135986328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7964
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3971222
	speed: 0.0473s/iter; left time: 1228.9133s
	iters: 200, epoch: 1 | loss: 0.3411801
	speed: 0.0449s/iter; left time: 1163.7145s
Epoch: 1 cost time: 11.946267366409302
Epoch: 1, Steps: 261 Train Loss: 0.3760 (Forecasting Loss:0.3728 + XiCon Loss:3.2442 x Lambda(0.001)), Vali MSE Loss: 0.3311 Test MSE Loss: 0.2844
Validation loss decreased (inf --> 0.331142).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3115278
	speed: 0.0465s/iter; left time: 1196.2881s
	iters: 200, epoch: 2 | loss: 0.2938202
	speed: 0.0442s/iter; left time: 1132.1088s
Epoch: 2 cost time: 11.785892009735107
Epoch: 2, Steps: 261 Train Loss: 0.2990 (Forecasting Loss:0.2958 + XiCon Loss:3.2180 x Lambda(0.001)), Vali MSE Loss: 0.2983 Test MSE Loss: 0.2524
Validation loss decreased (0.331142 --> 0.298348).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2863953
	speed: 0.0452s/iter; left time: 1150.9387s
	iters: 200, epoch: 3 | loss: 0.2866266
	speed: 0.0446s/iter; left time: 1132.7873s
Epoch: 3 cost time: 11.72391390800476
Epoch: 3, Steps: 261 Train Loss: 0.2838 (Forecasting Loss:0.2806 + XiCon Loss:3.2032 x Lambda(0.001)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.2529
Validation loss decreased (0.298348 --> 0.293107).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2669179
	speed: 0.0473s/iter; left time: 1192.3790s
	iters: 200, epoch: 4 | loss: 0.2996125
	speed: 0.0439s/iter; left time: 1103.3244s
Epoch: 4 cost time: 11.856751203536987
Epoch: 4, Steps: 261 Train Loss: 0.2793 (Forecasting Loss:0.2761 + XiCon Loss:3.2003 x Lambda(0.001)), Vali MSE Loss: 0.2995 Test MSE Loss: 0.2597
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2983473
	speed: 0.0480s/iter; left time: 1196.9803s
	iters: 200, epoch: 5 | loss: 0.2712156
	speed: 0.0449s/iter; left time: 1115.0203s
Epoch: 5 cost time: 12.031659841537476
Epoch: 5, Steps: 261 Train Loss: 0.2775 (Forecasting Loss:0.2743 + XiCon Loss:3.1991 x Lambda(0.001)), Vali MSE Loss: 0.3005 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2778179
	speed: 0.0477s/iter; left time: 1177.5340s
	iters: 200, epoch: 6 | loss: 0.2659827
	speed: 0.0431s/iter; left time: 1059.5280s
Epoch: 6 cost time: 11.731363534927368
Epoch: 6, Steps: 261 Train Loss: 0.2764 (Forecasting Loss:0.2732 + XiCon Loss:3.2007 x Lambda(0.001)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2609
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2681970
	speed: 0.0500s/iter; left time: 1220.8301s
	iters: 200, epoch: 7 | loss: 0.2498061
	speed: 0.0442s/iter; left time: 1075.0575s
Epoch: 7 cost time: 12.191858768463135
Epoch: 7, Steps: 261 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.1988 x Lambda(0.001)), Vali MSE Loss: 0.2997 Test MSE Loss: 0.2610
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2719211
	speed: 0.0475s/iter; left time: 1147.4718s
	iters: 200, epoch: 8 | loss: 0.2863209
	speed: 0.0438s/iter; left time: 1054.9972s
Epoch: 8 cost time: 11.845582485198975
Epoch: 8, Steps: 261 Train Loss: 0.2756 (Forecasting Loss:0.2724 + XiCon Loss:3.2002 x Lambda(0.001)), Vali MSE Loss: 0.2997 Test MSE Loss: 0.2612
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2486415
	speed: 0.0482s/iter; left time: 1151.4891s
	iters: 200, epoch: 9 | loss: 0.2882240
	speed: 0.0449s/iter; left time: 1068.9777s
Epoch: 9 cost time: 12.027177810668945
Epoch: 9, Steps: 261 Train Loss: 0.2754 (Forecasting Loss:0.2722 + XiCon Loss:3.1963 x Lambda(0.001)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2608
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3030482
	speed: 0.0501s/iter; left time: 1185.8483s
	iters: 200, epoch: 10 | loss: 0.2772221
	speed: 0.0458s/iter; left time: 1079.8318s
Epoch: 10 cost time: 12.539361476898193
Epoch: 10, Steps: 261 Train Loss: 0.2755 (Forecasting Loss:0.2723 + XiCon Loss:3.1972 x Lambda(0.001)), Vali MSE Loss: 0.2996 Test MSE Loss: 0.2612
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2612962
	speed: 0.0499s/iter; left time: 1166.6262s
	iters: 200, epoch: 11 | loss: 0.2711973
	speed: 0.0456s/iter; left time: 1062.3453s
Epoch: 11 cost time: 12.413393259048462
Epoch: 11, Steps: 261 Train Loss: 0.2756 (Forecasting Loss:0.2724 + XiCon Loss:3.1997 x Lambda(0.001)), Vali MSE Loss: 0.2998 Test MSE Loss: 0.2611
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2813165
	speed: 0.0497s/iter; left time: 1149.0457s
	iters: 200, epoch: 12 | loss: 0.3009085
	speed: 0.0462s/iter; left time: 1063.8675s
Epoch: 12 cost time: 12.446506261825562
Epoch: 12, Steps: 261 Train Loss: 0.2755 (Forecasting Loss:0.2723 + XiCon Loss:3.1976 x Lambda(0.001)), Vali MSE Loss: 0.2999 Test MSE Loss: 0.2610
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.2526819
	speed: 0.0492s/iter; left time: 1125.4080s
	iters: 200, epoch: 13 | loss: 0.2725318
	speed: 0.0456s/iter; left time: 1038.7987s
Epoch: 13 cost time: 12.305113077163696
Epoch: 13, Steps: 261 Train Loss: 0.2756 (Forecasting Loss:0.2724 + XiCon Loss:3.1987 x Lambda(0.001)), Vali MSE Loss: 0.2998 Test MSE Loss: 0.2610
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17706987261772156, mae:0.3287248909473419, mape:0.7381336092948914, mspe:20.212749481201172 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5070
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3604692
	speed: 0.0511s/iter; left time: 1328.0639s
	iters: 200, epoch: 1 | loss: 0.3534893
	speed: 0.0481s/iter; left time: 1246.7178s
Epoch: 1 cost time: 12.968025922775269
Epoch: 1, Steps: 261 Train Loss: 0.3708 (Forecasting Loss:0.3676 + XiCon Loss:3.2487 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2775
Validation loss decreased (inf --> 0.320348).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3114915
	speed: 0.0531s/iter; left time: 1367.7161s
	iters: 200, epoch: 2 | loss: 0.2930267
	speed: 0.0497s/iter; left time: 1274.5900s
Epoch: 2 cost time: 13.473077774047852
Epoch: 2, Steps: 261 Train Loss: 0.2966 (Forecasting Loss:0.2933 + XiCon Loss:3.2362 x Lambda(0.001)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2573
Validation loss decreased (0.320348 --> 0.283906).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2909757
	speed: 0.0509s/iter; left time: 1296.1493s
	iters: 200, epoch: 3 | loss: 0.2602778
	speed: 0.0493s/iter; left time: 1250.3019s
Epoch: 3 cost time: 13.135250329971313
Epoch: 3, Steps: 261 Train Loss: 0.2830 (Forecasting Loss:0.2798 + XiCon Loss:3.2229 x Lambda(0.001)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.2621
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2720005
	speed: 0.0511s/iter; left time: 1288.2071s
	iters: 200, epoch: 4 | loss: 0.3096147
	speed: 0.0502s/iter; left time: 1260.0254s
Epoch: 4 cost time: 13.178231477737427
Epoch: 4, Steps: 261 Train Loss: 0.2779 (Forecasting Loss:0.2746 + XiCon Loss:3.2207 x Lambda(0.001)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2673
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2756752
	speed: 0.0525s/iter; left time: 1309.6340s
	iters: 200, epoch: 5 | loss: 0.2814563
	speed: 0.0500s/iter; left time: 1242.0974s
Epoch: 5 cost time: 13.397540092468262
Epoch: 5, Steps: 261 Train Loss: 0.2753 (Forecasting Loss:0.2721 + XiCon Loss:3.2224 x Lambda(0.001)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.2663
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2789607
	speed: 0.0528s/iter; left time: 1304.7439s
	iters: 200, epoch: 6 | loss: 0.2760901
	speed: 0.0503s/iter; left time: 1236.9828s
Epoch: 6 cost time: 13.510954856872559
Epoch: 6, Steps: 261 Train Loss: 0.2742 (Forecasting Loss:0.2710 + XiCon Loss:3.2208 x Lambda(0.001)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.2656
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2795412
	speed: 0.0519s/iter; left time: 1269.3321s
	iters: 200, epoch: 7 | loss: 0.2645484
	speed: 0.0489s/iter; left time: 1188.8051s
Epoch: 7 cost time: 13.07984447479248
Epoch: 7, Steps: 261 Train Loss: 0.2737 (Forecasting Loss:0.2705 + XiCon Loss:3.2233 x Lambda(0.001)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.2658
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2638597
	speed: 0.0522s/iter; left time: 1262.5663s
	iters: 200, epoch: 8 | loss: 0.2579936
	speed: 0.0453s/iter; left time: 1091.0834s
Epoch: 8 cost time: 12.503756761550903
Epoch: 8, Steps: 261 Train Loss: 0.2735 (Forecasting Loss:0.2703 + XiCon Loss:3.2224 x Lambda(0.001)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.2662
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2711610
	speed: 0.0504s/iter; left time: 1204.2577s
	iters: 200, epoch: 9 | loss: 0.2530667
	speed: 0.0508s/iter; left time: 1209.5737s
Epoch: 9 cost time: 13.182350397109985
Epoch: 9, Steps: 261 Train Loss: 0.2736 (Forecasting Loss:0.2703 + XiCon Loss:3.2225 x Lambda(0.001)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.2663
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2643671
	speed: 0.0525s/iter; left time: 1242.4921s
	iters: 200, epoch: 10 | loss: 0.3113207
	speed: 0.0506s/iter; left time: 1192.2061s
Epoch: 10 cost time: 13.483863353729248
Epoch: 10, Steps: 261 Train Loss: 0.2733 (Forecasting Loss:0.2701 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.2665
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2642668
	speed: 0.0517s/iter; left time: 1208.5767s
	iters: 200, epoch: 11 | loss: 0.2658220
	speed: 0.0484s/iter; left time: 1127.0936s
Epoch: 11 cost time: 12.954161643981934
Epoch: 11, Steps: 261 Train Loss: 0.2731 (Forecasting Loss:0.2699 + XiCon Loss:3.2222 x Lambda(0.001)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.2665
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3106026
	speed: 0.0508s/iter; left time: 1174.8160s
	iters: 200, epoch: 12 | loss: 0.2809394
	speed: 0.0490s/iter; left time: 1129.4165s
Epoch: 12 cost time: 13.003710746765137
Epoch: 12, Steps: 261 Train Loss: 0.2731 (Forecasting Loss:0.2699 + XiCon Loss:3.2221 x Lambda(0.001)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.2665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.18041497468948364, mae:0.3342258632183075, mape:0.7704578638076782, mspe:21.888399124145508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9144
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3724297
	speed: 0.0511s/iter; left time: 1329.6964s
	iters: 200, epoch: 1 | loss: 0.3517934
	speed: 0.0487s/iter; left time: 1261.9566s
Epoch: 1 cost time: 12.865011930465698
Epoch: 1, Steps: 261 Train Loss: 0.3734 (Forecasting Loss:0.3702 + XiCon Loss:3.2208 x Lambda(0.001)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2803
Validation loss decreased (inf --> 0.324077).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2897645
	speed: 0.0512s/iter; left time: 1317.6001s
	iters: 200, epoch: 2 | loss: 0.2664436
	speed: 0.0475s/iter; left time: 1216.8545s
Epoch: 2 cost time: 12.761728286743164
Epoch: 2, Steps: 261 Train Loss: 0.2945 (Forecasting Loss:0.2913 + XiCon Loss:3.2263 x Lambda(0.001)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.2502
Validation loss decreased (0.324077 --> 0.287835).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2948115
	speed: 0.0489s/iter; left time: 1245.3703s
	iters: 200, epoch: 3 | loss: 0.2625843
	speed: 0.0446s/iter; left time: 1130.9079s
Epoch: 3 cost time: 12.19715166091919
Epoch: 3, Steps: 261 Train Loss: 0.2831 (Forecasting Loss:0.2798 + XiCon Loss:3.2231 x Lambda(0.001)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.2590
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2909890
	speed: 0.0507s/iter; left time: 1277.9387s
	iters: 200, epoch: 4 | loss: 0.2673518
	speed: 0.0492s/iter; left time: 1235.8336s
Epoch: 4 cost time: 13.03346061706543
Epoch: 4, Steps: 261 Train Loss: 0.2794 (Forecasting Loss:0.2761 + XiCon Loss:3.2296 x Lambda(0.001)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.2592
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3023026
	speed: 0.0509s/iter; left time: 1269.2793s
	iters: 200, epoch: 5 | loss: 0.3017206
	speed: 0.0497s/iter; left time: 1235.8455s
Epoch: 5 cost time: 13.108344554901123
Epoch: 5, Steps: 261 Train Loss: 0.2777 (Forecasting Loss:0.2745 + XiCon Loss:3.2307 x Lambda(0.001)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.2618
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2969094
	speed: 0.0517s/iter; left time: 1277.7447s
	iters: 200, epoch: 6 | loss: 0.2416257
	speed: 0.0482s/iter; left time: 1184.8194s
Epoch: 6 cost time: 12.959871530532837
Epoch: 6, Steps: 261 Train Loss: 0.2768 (Forecasting Loss:0.2736 + XiCon Loss:3.2316 x Lambda(0.001)), Vali MSE Loss: 0.3023 Test MSE Loss: 0.2615
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2491416
	speed: 0.0512s/iter; left time: 1251.2817s
	iters: 200, epoch: 7 | loss: 0.2658893
	speed: 0.0491s/iter; left time: 1193.8466s
Epoch: 7 cost time: 13.04612421989441
Epoch: 7, Steps: 261 Train Loss: 0.2763 (Forecasting Loss:0.2731 + XiCon Loss:3.2292 x Lambda(0.001)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.2622
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2629026
	speed: 0.0511s/iter; left time: 1235.8965s
	iters: 200, epoch: 8 | loss: 0.2607225
	speed: 0.0506s/iter; left time: 1217.1263s
Epoch: 8 cost time: 13.134233951568604
Epoch: 8, Steps: 261 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.2312 x Lambda(0.001)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.2614
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2699526
	speed: 0.0499s/iter; left time: 1192.3367s
	iters: 200, epoch: 9 | loss: 0.2627729
	speed: 0.0489s/iter; left time: 1164.2367s
Epoch: 9 cost time: 12.988244771957397
Epoch: 9, Steps: 261 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.2307 x Lambda(0.001)), Vali MSE Loss: 0.3019 Test MSE Loss: 0.2615
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2713567
	speed: 0.0507s/iter; left time: 1198.0108s
	iters: 200, epoch: 10 | loss: 0.2939322
	speed: 0.0488s/iter; left time: 1149.5737s
Epoch: 10 cost time: 12.886650562286377
Epoch: 10, Steps: 261 Train Loss: 0.2758 (Forecasting Loss:0.2726 + XiCon Loss:3.2301 x Lambda(0.001)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.2616
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2783574
	speed: 0.0475s/iter; left time: 1111.0409s
	iters: 200, epoch: 11 | loss: 0.3122089
	speed: 0.0457s/iter; left time: 1064.2104s
Epoch: 11 cost time: 12.323117733001709
Epoch: 11, Steps: 261 Train Loss: 0.2758 (Forecasting Loss:0.2726 + XiCon Loss:3.2317 x Lambda(0.001)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.2616
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2761939
	speed: 0.0518s/iter; left time: 1197.9754s
	iters: 200, epoch: 12 | loss: 0.2904263
	speed: 0.0509s/iter; left time: 1171.3431s
Epoch: 12 cost time: 13.235463857650757
Epoch: 12, Steps: 261 Train Loss: 0.2759 (Forecasting Loss:0.2727 + XiCon Loss:3.2312 x Lambda(0.001)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.2616
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1739700734615326, mae:0.32645246386528015, mape:0.7308900356292725, mspe:20.294429779052734 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1083
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4316562
	speed: 0.0507s/iter; left time: 1317.3035s
	iters: 200, epoch: 1 | loss: 0.3696150
	speed: 0.0490s/iter; left time: 1268.1694s
Epoch: 1 cost time: 12.914733171463013
Epoch: 1, Steps: 261 Train Loss: 0.3725 (Forecasting Loss:0.3692 + XiCon Loss:3.2389 x Lambda(0.001)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2797
Validation loss decreased (inf --> 0.323011).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2773767
	speed: 0.0513s/iter; left time: 1321.0470s
	iters: 200, epoch: 2 | loss: 0.2626225
	speed: 0.0485s/iter; left time: 1244.1062s
Epoch: 2 cost time: 12.88999056816101
Epoch: 2, Steps: 261 Train Loss: 0.2991 (Forecasting Loss:0.2959 + XiCon Loss:3.2307 x Lambda(0.001)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.2485
Validation loss decreased (0.323011 --> 0.292478).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3019442
	speed: 0.0497s/iter; left time: 1266.5180s
	iters: 200, epoch: 3 | loss: 0.2950886
	speed: 0.0475s/iter; left time: 1204.7122s
Epoch: 3 cost time: 12.689863443374634
Epoch: 3, Steps: 261 Train Loss: 0.2844 (Forecasting Loss:0.2812 + XiCon Loss:3.2085 x Lambda(0.001)), Vali MSE Loss: 0.2937 Test MSE Loss: 0.2572
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2697521
	speed: 0.0511s/iter; left time: 1287.4504s
	iters: 200, epoch: 4 | loss: 0.2855908
	speed: 0.0500s/iter; left time: 1256.4136s
Epoch: 4 cost time: 13.099887609481812
Epoch: 4, Steps: 261 Train Loss: 0.2789 (Forecasting Loss:0.2757 + XiCon Loss:3.2069 x Lambda(0.001)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.2616
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2865381
	speed: 0.0511s/iter; left time: 1276.2877s
	iters: 200, epoch: 5 | loss: 0.2938746
	speed: 0.0479s/iter; left time: 1190.0466s
Epoch: 5 cost time: 12.810168266296387
Epoch: 5, Steps: 261 Train Loss: 0.2755 (Forecasting Loss:0.2723 + XiCon Loss:3.2061 x Lambda(0.001)), Vali MSE Loss: 0.3051 Test MSE Loss: 0.2657
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2677545
	speed: 0.0473s/iter; left time: 1167.0351s
	iters: 200, epoch: 6 | loss: 0.3050458
	speed: 0.0490s/iter; left time: 1205.3695s
Epoch: 6 cost time: 12.592577934265137
Epoch: 6, Steps: 261 Train Loss: 0.2745 (Forecasting Loss:0.2713 + XiCon Loss:3.2054 x Lambda(0.001)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2632
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2691996
	speed: 0.0517s/iter; left time: 1262.3572s
	iters: 200, epoch: 7 | loss: 0.2934221
	speed: 0.0503s/iter; left time: 1223.5509s
Epoch: 7 cost time: 13.18766188621521
Epoch: 7, Steps: 261 Train Loss: 0.2738 (Forecasting Loss:0.2706 + XiCon Loss:3.2045 x Lambda(0.001)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.2639
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2769134
	speed: 0.0512s/iter; left time: 1237.0497s
	iters: 200, epoch: 8 | loss: 0.2726732
	speed: 0.0500s/iter; left time: 1204.5240s
Epoch: 8 cost time: 13.282310485839844
Epoch: 8, Steps: 261 Train Loss: 0.2735 (Forecasting Loss:0.2703 + XiCon Loss:3.2029 x Lambda(0.001)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2638
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2747249
	speed: 0.0500s/iter; left time: 1195.2787s
	iters: 200, epoch: 9 | loss: 0.2815899
	speed: 0.0490s/iter; left time: 1167.8932s
Epoch: 9 cost time: 12.888785600662231
Epoch: 9, Steps: 261 Train Loss: 0.2734 (Forecasting Loss:0.2702 + XiCon Loss:3.2049 x Lambda(0.001)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.2641
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2724202
	speed: 0.0513s/iter; left time: 1214.5122s
	iters: 200, epoch: 10 | loss: 0.2887242
	speed: 0.0488s/iter; left time: 1149.1810s
Epoch: 10 cost time: 13.108087539672852
Epoch: 10, Steps: 261 Train Loss: 0.2736 (Forecasting Loss:0.2704 + XiCon Loss:3.2036 x Lambda(0.001)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2643
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2526332
	speed: 0.0515s/iter; left time: 1203.8148s
	iters: 200, epoch: 11 | loss: 0.2476239
	speed: 0.0496s/iter; left time: 1155.5967s
Epoch: 11 cost time: 13.118743419647217
Epoch: 11, Steps: 261 Train Loss: 0.2734 (Forecasting Loss:0.2702 + XiCon Loss:3.2044 x Lambda(0.001)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.2641
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2634987
	speed: 0.0507s/iter; left time: 1172.1193s
	iters: 200, epoch: 12 | loss: 0.2783774
	speed: 0.0495s/iter; left time: 1139.6235s
Epoch: 12 cost time: 13.002333641052246
Epoch: 12, Steps: 261 Train Loss: 0.2733 (Forecasting Loss:0.2701 + XiCon Loss:3.2047 x Lambda(0.001)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.2642
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17334429919719696, mae:0.323583722114563, mape:0.7163949608802795, mspe:18.957687377929688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1768+-0.00382, MAE:0.3280+-0.00491, MAPE:0.7305+-0.03400, MSPE:19.7633+-2.05346, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
