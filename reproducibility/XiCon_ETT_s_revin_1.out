Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4685
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2829018
	speed: 0.0175s/iter; left time: 222.3878s
Epoch: 1 cost time: 2.157029390335083
Epoch: 1, Steps: 128 Train Loss: 3.3057 (Forecasting Loss:0.2444 + XiCon Loss:3.0613 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173674).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0925283
	speed: 0.0157s/iter; left time: 196.9818s
Epoch: 2 cost time: 2.007214069366455
Epoch: 2, Steps: 128 Train Loss: 3.0846 (Forecasting Loss:0.2466 + XiCon Loss:2.8380 x Lambda(1.0)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0930798
	speed: 0.0144s/iter; left time: 179.7544s
Epoch: 3 cost time: 1.789280652999878
Epoch: 3, Steps: 128 Train Loss: 3.1548 (Forecasting Loss:0.2320 + XiCon Loss:2.9227 x Lambda(1.0)), Vali MSE Loss: 0.1687 Test MSE Loss: 0.1241
Validation loss decreased (0.173674 --> 0.168678).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0474153
	speed: 0.0144s/iter; left time: 177.3507s
Epoch: 4 cost time: 1.8078927993774414
Epoch: 4, Steps: 128 Train Loss: 3.0933 (Forecasting Loss:0.2224 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1164
Validation loss decreased (0.168678 --> 0.167820).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0226445
	speed: 0.0147s/iter; left time: 179.4147s
Epoch: 5 cost time: 1.8379626274108887
Epoch: 5, Steps: 128 Train Loss: 3.0660 (Forecasting Loss:0.2168 + XiCon Loss:2.8492 x Lambda(1.0)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1178
Validation loss decreased (0.167820 --> 0.166661).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 2.9399755
	speed: 0.0143s/iter; left time: 172.8665s
Epoch: 6 cost time: 1.8161206245422363
Epoch: 6, Steps: 128 Train Loss: 3.0373 (Forecasting Loss:0.2143 + XiCon Loss:2.8230 x Lambda(1.0)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1162
Validation loss decreased (0.166661 --> 0.165419).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0419581
	speed: 0.0150s/iter; left time: 178.6554s
Epoch: 7 cost time: 1.878032922744751
Epoch: 7, Steps: 128 Train Loss: 3.0337 (Forecasting Loss:0.2131 + XiCon Loss:2.8206 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1178
Validation loss decreased (0.165419 --> 0.164844).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 2.9887500
	speed: 0.0138s/iter; left time: 163.3745s
Epoch: 8 cost time: 1.7548325061798096
Epoch: 8, Steps: 128 Train Loss: 3.0261 (Forecasting Loss:0.2126 + XiCon Loss:2.8134 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1090264
	speed: 0.0145s/iter; left time: 169.7004s
Epoch: 9 cost time: 1.8603670597076416
Epoch: 9, Steps: 128 Train Loss: 3.0205 (Forecasting Loss:0.2122 + XiCon Loss:2.8083 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1171
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0145473
	speed: 0.0142s/iter; left time: 164.1420s
Epoch: 10 cost time: 1.8021693229675293
Epoch: 10, Steps: 128 Train Loss: 3.0242 (Forecasting Loss:0.2120 + XiCon Loss:2.8122 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1171
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0583255
	speed: 0.0150s/iter; left time: 171.4398s
Epoch: 11 cost time: 1.8617067337036133
Epoch: 11, Steps: 128 Train Loss: 3.0173 (Forecasting Loss:0.2118 + XiCon Loss:2.8055 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1172
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 2.9767156
	speed: 0.0143s/iter; left time: 161.7118s
Epoch: 12 cost time: 1.807253360748291
Epoch: 12, Steps: 128 Train Loss: 3.0168 (Forecasting Loss:0.2115 + XiCon Loss:2.8053 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1171
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1382699
	speed: 0.0137s/iter; left time: 152.6929s
Epoch: 13 cost time: 1.7079694271087646
Epoch: 13, Steps: 128 Train Loss: 3.0190 (Forecasting Loss:0.2115 + XiCon Loss:2.8075 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1171
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1037447
	speed: 0.0145s/iter; left time: 160.0641s
Epoch: 14 cost time: 1.7930212020874023
Epoch: 14, Steps: 128 Train Loss: 3.0233 (Forecasting Loss:0.2117 + XiCon Loss:2.8116 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1171
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0902922
	speed: 0.0141s/iter; left time: 154.1696s
Epoch: 15 cost time: 1.7944941520690918
Epoch: 15, Steps: 128 Train Loss: 3.0235 (Forecasting Loss:0.2117 + XiCon Loss:2.8118 x Lambda(1.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1171
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 2.9388649
	speed: 0.0145s/iter; left time: 156.3213s
Epoch: 16 cost time: 1.8311936855316162
Epoch: 16, Steps: 128 Train Loss: 3.0240 (Forecasting Loss:0.2117 + XiCon Loss:2.8122 x Lambda(1.0)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1171
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 2.9512975
	speed: 0.0142s/iter; left time: 151.0754s
Epoch: 17 cost time: 1.7872679233551025
Epoch: 17, Steps: 128 Train Loss: 3.0190 (Forecasting Loss:0.2118 + XiCon Loss:2.8072 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1171
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05567315220832825, mae:0.179879829287529, mape:0.14446379244327545, mspe:0.041065435856580734 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3660
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2352374
	speed: 0.0152s/iter; left time: 193.2897s
Epoch: 1 cost time: 1.879525899887085
Epoch: 1, Steps: 128 Train Loss: 3.2818 (Forecasting Loss:0.2416 + XiCon Loss:3.0402 x Lambda(1.0)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1214
Validation loss decreased (inf --> 0.173751).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1411171
	speed: 0.0145s/iter; left time: 181.9841s
Epoch: 2 cost time: 1.7980775833129883
Epoch: 2, Steps: 128 Train Loss: 3.1074 (Forecasting Loss:0.2448 + XiCon Loss:2.8627 x Lambda(1.0)), Vali MSE Loss: 0.1795 Test MSE Loss: 0.1217
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2360332
	speed: 0.0151s/iter; left time: 187.4803s
Epoch: 3 cost time: 1.880324125289917
Epoch: 3, Steps: 128 Train Loss: 3.1619 (Forecasting Loss:0.2325 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.1682 Test MSE Loss: 0.1209
Validation loss decreased (0.173751 --> 0.168204).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1473773
	speed: 0.0150s/iter; left time: 184.9713s
Epoch: 4 cost time: 1.865119457244873
Epoch: 4, Steps: 128 Train Loss: 3.1364 (Forecasting Loss:0.2230 + XiCon Loss:2.9133 x Lambda(1.0)), Vali MSE Loss: 0.1668 Test MSE Loss: 0.1200
Validation loss decreased (0.168204 --> 0.166785).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0746493
	speed: 0.0149s/iter; left time: 181.0444s
Epoch: 5 cost time: 1.89213228225708
Epoch: 5, Steps: 128 Train Loss: 3.0786 (Forecasting Loss:0.2181 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1175
Validation loss decreased (0.166785 --> 0.164521).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0473125
	speed: 0.0139s/iter; left time: 167.6691s
Epoch: 6 cost time: 1.7703101634979248
Epoch: 6, Steps: 128 Train Loss: 3.0644 (Forecasting Loss:0.2161 + XiCon Loss:2.8484 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1182
Validation loss decreased (0.164521 --> 0.164142).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0682659
	speed: 0.0145s/iter; left time: 172.8642s
Epoch: 7 cost time: 1.840874433517456
Epoch: 7, Steps: 128 Train Loss: 3.0484 (Forecasting Loss:0.2146 + XiCon Loss:2.8338 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1162
Validation loss decreased (0.164142 --> 0.163508).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1128750
	speed: 0.0146s/iter; left time: 172.3975s
Epoch: 8 cost time: 1.8079729080200195
Epoch: 8, Steps: 128 Train Loss: 3.0497 (Forecasting Loss:0.2138 + XiCon Loss:2.8359 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0919359
	speed: 0.0151s/iter; left time: 176.4073s
Epoch: 9 cost time: 1.87660551071167
Epoch: 9, Steps: 128 Train Loss: 3.0491 (Forecasting Loss:0.2136 + XiCon Loss:2.8355 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1164
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0607541
	speed: 0.0141s/iter; left time: 163.0439s
Epoch: 10 cost time: 1.779994249343872
Epoch: 10, Steps: 128 Train Loss: 3.0458 (Forecasting Loss:0.2134 + XiCon Loss:2.8323 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
Validation loss decreased (0.163508 --> 0.163454).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0854490
	speed: 0.0146s/iter; left time: 166.2250s
Epoch: 11 cost time: 1.8424649238586426
Epoch: 11, Steps: 128 Train Loss: 3.0444 (Forecasting Loss:0.2134 + XiCon Loss:2.8310 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 2.9695609
	speed: 0.0146s/iter; left time: 165.3089s
Epoch: 12 cost time: 1.8384342193603516
Epoch: 12, Steps: 128 Train Loss: 3.0461 (Forecasting Loss:0.2133 + XiCon Loss:2.8329 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1165
Validation loss decreased (0.163454 --> 0.163347).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0142007
	speed: 0.0142s/iter; left time: 158.8877s
Epoch: 13 cost time: 1.7649245262145996
Epoch: 13, Steps: 128 Train Loss: 3.0471 (Forecasting Loss:0.2134 + XiCon Loss:2.8338 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9554610
	speed: 0.0148s/iter; left time: 163.0786s
Epoch: 14 cost time: 1.8312807083129883
Epoch: 14, Steps: 128 Train Loss: 3.0371 (Forecasting Loss:0.2133 + XiCon Loss:2.8238 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1165
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0386152
	speed: 0.0152s/iter; left time: 165.5537s
Epoch: 15 cost time: 1.8679986000061035
Epoch: 15, Steps: 128 Train Loss: 3.0481 (Forecasting Loss:0.2132 + XiCon Loss:2.8350 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0866973
	speed: 0.0140s/iter; left time: 150.9796s
Epoch: 16 cost time: 1.7553269863128662
Epoch: 16, Steps: 128 Train Loss: 3.0454 (Forecasting Loss:0.2133 + XiCon Loss:2.8321 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1165
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0517433
	speed: 0.0154s/iter; left time: 164.1895s
Epoch: 17 cost time: 1.9039859771728516
Epoch: 17, Steps: 128 Train Loss: 3.0528 (Forecasting Loss:0.2132 + XiCon Loss:2.8396 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1165
Validation loss decreased (0.163347 --> 0.163190).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0055940
	speed: 0.0145s/iter; left time: 152.8136s
Epoch: 18 cost time: 1.7998595237731934
Epoch: 18, Steps: 128 Train Loss: 3.0411 (Forecasting Loss:0.2132 + XiCon Loss:2.8279 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0063796
	speed: 0.0140s/iter; left time: 145.6728s
Epoch: 19 cost time: 1.8005189895629883
Epoch: 19, Steps: 128 Train Loss: 3.0434 (Forecasting Loss:0.2133 + XiCon Loss:2.8301 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1165
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1236987
	speed: 0.0148s/iter; left time: 151.9794s
Epoch: 20 cost time: 1.8413100242614746
Epoch: 20, Steps: 128 Train Loss: 3.0399 (Forecasting Loss:0.2133 + XiCon Loss:2.8266 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1165
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0015621
	speed: 0.0153s/iter; left time: 155.5547s
Epoch: 21 cost time: 1.8955135345458984
Epoch: 21, Steps: 128 Train Loss: 3.0473 (Forecasting Loss:0.2133 + XiCon Loss:2.8340 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1332428
	speed: 0.0141s/iter; left time: 141.1467s
Epoch: 22 cost time: 1.792679786682129
Epoch: 22, Steps: 128 Train Loss: 3.0481 (Forecasting Loss:0.2133 + XiCon Loss:2.8348 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0152328
	speed: 0.0148s/iter; left time: 146.4473s
Epoch: 23 cost time: 1.8544583320617676
Epoch: 23, Steps: 128 Train Loss: 3.0469 (Forecasting Loss:0.2133 + XiCon Loss:2.8336 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1165
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0051253
	speed: 0.0147s/iter; left time: 143.1049s
Epoch: 24 cost time: 1.8589777946472168
Epoch: 24, Steps: 128 Train Loss: 3.0382 (Forecasting Loss:0.2133 + XiCon Loss:2.8249 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1165
Validation loss decreased (0.163190 --> 0.163188).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0091166
	speed: 0.0150s/iter; left time: 144.6287s
Epoch: 25 cost time: 1.892090082168579
Epoch: 25, Steps: 128 Train Loss: 3.0496 (Forecasting Loss:0.2133 + XiCon Loss:2.8363 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0202050
	speed: 0.0144s/iter; left time: 137.1134s
Epoch: 26 cost time: 1.841979742050171
Epoch: 26, Steps: 128 Train Loss: 3.0466 (Forecasting Loss:0.2132 + XiCon Loss:2.8334 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0263202
	speed: 0.0151s/iter; left time: 141.3658s
Epoch: 27 cost time: 1.8454105854034424
Epoch: 27, Steps: 128 Train Loss: 3.0458 (Forecasting Loss:0.2133 + XiCon Loss:2.8325 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1165
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0680060
	speed: 0.0148s/iter; left time: 136.7937s
Epoch: 28 cost time: 1.8398470878601074
Epoch: 28, Steps: 128 Train Loss: 3.0474 (Forecasting Loss:0.2134 + XiCon Loss:2.8340 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0269647
	speed: 0.0144s/iter; left time: 131.6616s
Epoch: 29 cost time: 1.8202321529388428
Epoch: 29, Steps: 128 Train Loss: 3.0422 (Forecasting Loss:0.2133 + XiCon Loss:2.8289 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1165
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 2.9869590
	speed: 0.0139s/iter; left time: 124.7234s
Epoch: 30 cost time: 1.727785587310791
Epoch: 30, Steps: 128 Train Loss: 3.0399 (Forecasting Loss:0.2132 + XiCon Loss:2.8267 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0499430
	speed: 0.0144s/iter; left time: 127.6627s
Epoch: 31 cost time: 1.7769839763641357
Epoch: 31, Steps: 128 Train Loss: 3.0475 (Forecasting Loss:0.2134 + XiCon Loss:2.8341 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1165
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0491729
	speed: 0.0141s/iter; left time: 123.3863s
Epoch: 32 cost time: 1.774245262145996
Epoch: 32, Steps: 128 Train Loss: 3.0435 (Forecasting Loss:0.2132 + XiCon Loss:2.8303 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0785227
	speed: 0.0142s/iter; left time: 122.1781s
Epoch: 33 cost time: 1.7997488975524902
Epoch: 33, Steps: 128 Train Loss: 3.0504 (Forecasting Loss:0.2133 + XiCon Loss:2.8371 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1165
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0536463
	speed: 0.0145s/iter; left time: 123.2632s
Epoch: 34 cost time: 1.8747506141662598
Epoch: 34, Steps: 128 Train Loss: 3.0417 (Forecasting Loss:0.2133 + XiCon Loss:2.8284 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054707612842321396, mae:0.1782434731721878, mape:0.1415082812309265, mspe:0.0374029278755188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3942
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2124321
	speed: 0.0149s/iter; left time: 188.9897s
Epoch: 1 cost time: 1.8518726825714111
Epoch: 1, Steps: 128 Train Loss: 3.2637 (Forecasting Loss:0.2446 + XiCon Loss:3.0192 x Lambda(1.0)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1206
Validation loss decreased (inf --> 0.173151).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 2.9662554
	speed: 0.0139s/iter; left time: 174.4236s
Epoch: 2 cost time: 1.7324638366699219
Epoch: 2, Steps: 128 Train Loss: 3.0687 (Forecasting Loss:0.2453 + XiCon Loss:2.8234 x Lambda(1.0)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1268
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2074938
	speed: 0.0141s/iter; left time: 175.0723s
Epoch: 3 cost time: 1.797433853149414
Epoch: 3, Steps: 128 Train Loss: 3.1021 (Forecasting Loss:0.2283 + XiCon Loss:2.8738 x Lambda(1.0)), Vali MSE Loss: 0.1691 Test MSE Loss: 0.1200
Validation loss decreased (0.173151 --> 0.169112).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0754540
	speed: 0.0151s/iter; left time: 186.1125s
Epoch: 4 cost time: 1.874603509902954
Epoch: 4, Steps: 128 Train Loss: 3.1373 (Forecasting Loss:0.2213 + XiCon Loss:2.9160 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1159
Validation loss decreased (0.169112 --> 0.166620).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0929315
	speed: 0.0145s/iter; left time: 177.2309s
Epoch: 5 cost time: 1.8112573623657227
Epoch: 5, Steps: 128 Train Loss: 3.0916 (Forecasting Loss:0.2172 + XiCon Loss:2.8745 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1154
Validation loss decreased (0.166620 --> 0.165233).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0379188
	speed: 0.0148s/iter; left time: 178.8121s
Epoch: 6 cost time: 1.830124855041504
Epoch: 6, Steps: 128 Train Loss: 3.0669 (Forecasting Loss:0.2156 + XiCon Loss:2.8513 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1164
Validation loss decreased (0.165233 --> 0.163519).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0415144
	speed: 0.0146s/iter; left time: 173.9381s
Epoch: 7 cost time: 1.818910837173462
Epoch: 7, Steps: 128 Train Loss: 3.0582 (Forecasting Loss:0.2144 + XiCon Loss:2.8438 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0343506
	speed: 0.0151s/iter; left time: 178.0393s
Epoch: 8 cost time: 1.9209306240081787
Epoch: 8, Steps: 128 Train Loss: 3.0532 (Forecasting Loss:0.2136 + XiCon Loss:2.8396 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0244467
	speed: 0.0146s/iter; left time: 170.2583s
Epoch: 9 cost time: 1.8180267810821533
Epoch: 9, Steps: 128 Train Loss: 3.0582 (Forecasting Loss:0.2134 + XiCon Loss:2.8448 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1167
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0798104
	speed: 0.0152s/iter; left time: 175.1648s
Epoch: 10 cost time: 1.9002859592437744
Epoch: 10, Steps: 128 Train Loss: 3.0526 (Forecasting Loss:0.2132 + XiCon Loss:2.8394 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1169
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1838524
	speed: 0.0143s/iter; left time: 163.5261s
Epoch: 11 cost time: 1.7948060035705566
Epoch: 11, Steps: 128 Train Loss: 3.0539 (Forecasting Loss:0.2130 + XiCon Loss:2.8409 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0047019
	speed: 0.0147s/iter; left time: 166.4288s
Epoch: 12 cost time: 1.8188347816467285
Epoch: 12, Steps: 128 Train Loss: 3.0535 (Forecasting Loss:0.2129 + XiCon Loss:2.8406 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0182462
	speed: 0.0152s/iter; left time: 169.3839s
Epoch: 13 cost time: 1.8479599952697754
Epoch: 13, Steps: 128 Train Loss: 3.0475 (Forecasting Loss:0.2131 + XiCon Loss:2.8345 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9680777
	speed: 0.0148s/iter; left time: 163.4237s
Epoch: 14 cost time: 1.8662707805633545
Epoch: 14, Steps: 128 Train Loss: 3.0482 (Forecasting Loss:0.2132 + XiCon Loss:2.8350 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1168
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0459695
	speed: 0.0143s/iter; left time: 155.6730s
Epoch: 15 cost time: 1.8038442134857178
Epoch: 15, Steps: 128 Train Loss: 3.0586 (Forecasting Loss:0.2131 + XiCon Loss:2.8455 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0704138
	speed: 0.0142s/iter; left time: 152.8600s
Epoch: 16 cost time: 1.7719078063964844
Epoch: 16, Steps: 128 Train Loss: 3.0494 (Forecasting Loss:0.2131 + XiCon Loss:2.8363 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1168
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05464556813240051, mae:0.17807437479496002, mape:0.14195069670677185, mspe:0.038185007870197296 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3402
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2390549
	speed: 0.0158s/iter; left time: 200.4331s
Epoch: 1 cost time: 1.9859189987182617
Epoch: 1, Steps: 128 Train Loss: 3.2843 (Forecasting Loss:0.2453 + XiCon Loss:3.0389 x Lambda(1.0)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1223
Validation loss decreased (inf --> 0.172040).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1570511
	speed: 0.0159s/iter; left time: 199.3234s
Epoch: 2 cost time: 1.9780724048614502
Epoch: 2, Steps: 128 Train Loss: 3.1368 (Forecasting Loss:0.2439 + XiCon Loss:2.8929 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1270
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2098033
	speed: 0.0147s/iter; left time: 182.9976s
Epoch: 3 cost time: 1.8243045806884766
Epoch: 3, Steps: 128 Train Loss: 3.1387 (Forecasting Loss:0.2311 + XiCon Loss:2.9076 x Lambda(1.0)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1185
Validation loss decreased (0.172040 --> 0.167321).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1210265
	speed: 0.0147s/iter; left time: 181.5099s
Epoch: 4 cost time: 1.871795892715454
Epoch: 4, Steps: 128 Train Loss: 3.1458 (Forecasting Loss:0.2216 + XiCon Loss:2.9241 x Lambda(1.0)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1181
Validation loss decreased (0.167321 --> 0.166874).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2545471
	speed: 0.0140s/iter; left time: 170.9840s
Epoch: 5 cost time: 1.73655366897583
Epoch: 5, Steps: 128 Train Loss: 3.1216 (Forecasting Loss:0.2176 + XiCon Loss:2.9040 x Lambda(1.0)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1225
Validation loss decreased (0.166874 --> 0.166505).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0924072
	speed: 0.0151s/iter; left time: 182.6887s
Epoch: 6 cost time: 1.9107282161712646
Epoch: 6, Steps: 128 Train Loss: 3.1030 (Forecasting Loss:0.2154 + XiCon Loss:2.8876 x Lambda(1.0)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0801623
	speed: 0.0155s/iter; left time: 185.4091s
Epoch: 7 cost time: 1.9197816848754883
Epoch: 7, Steps: 128 Train Loss: 3.0975 (Forecasting Loss:0.2145 + XiCon Loss:2.8830 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1158
Validation loss decreased (0.166505 --> 0.164474).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1242139
	speed: 0.0156s/iter; left time: 184.6966s
Epoch: 8 cost time: 1.9238226413726807
Epoch: 8, Steps: 128 Train Loss: 3.0956 (Forecasting Loss:0.2137 + XiCon Loss:2.8819 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1160
Validation loss decreased (0.164474 --> 0.164248).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0658681
	speed: 0.0144s/iter; left time: 168.5110s
Epoch: 9 cost time: 1.77693772315979
Epoch: 9, Steps: 128 Train Loss: 3.0949 (Forecasting Loss:0.2133 + XiCon Loss:2.8815 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1156
Validation loss decreased (0.164248 --> 0.163879).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0813510
	speed: 0.0144s/iter; left time: 166.1882s
Epoch: 10 cost time: 1.795748233795166
Epoch: 10, Steps: 128 Train Loss: 3.0912 (Forecasting Loss:0.2131 + XiCon Loss:2.8780 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
Validation loss decreased (0.163879 --> 0.163814).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0731716
	speed: 0.0144s/iter; left time: 164.4892s
Epoch: 11 cost time: 1.8572478294372559
Epoch: 11, Steps: 128 Train Loss: 3.0867 (Forecasting Loss:0.2130 + XiCon Loss:2.8737 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
Validation loss decreased (0.163814 --> 0.163513).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0841179
	speed: 0.0144s/iter; left time: 162.2965s
Epoch: 12 cost time: 1.8027524948120117
Epoch: 12, Steps: 128 Train Loss: 3.0910 (Forecasting Loss:0.2130 + XiCon Loss:2.8780 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
Validation loss decreased (0.163513 --> 0.163508).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0286789
	speed: 0.0146s/iter; left time: 162.9782s
Epoch: 13 cost time: 1.796548843383789
Epoch: 13, Steps: 128 Train Loss: 3.0914 (Forecasting Loss:0.2129 + XiCon Loss:2.8784 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0651641
	speed: 0.0145s/iter; left time: 159.5140s
Epoch: 14 cost time: 1.828277349472046
Epoch: 14, Steps: 128 Train Loss: 3.0942 (Forecasting Loss:0.2127 + XiCon Loss:2.8815 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0536656
	speed: 0.0151s/iter; left time: 164.6769s
Epoch: 15 cost time: 1.8581116199493408
Epoch: 15, Steps: 128 Train Loss: 3.0886 (Forecasting Loss:0.2129 + XiCon Loss:2.8757 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0684495
	speed: 0.0153s/iter; left time: 164.5015s
Epoch: 16 cost time: 1.8884608745574951
Epoch: 16, Steps: 128 Train Loss: 3.0864 (Forecasting Loss:0.2130 + XiCon Loss:2.8734 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0676856
	speed: 0.0140s/iter; left time: 148.8903s
Epoch: 17 cost time: 1.7588977813720703
Epoch: 17, Steps: 128 Train Loss: 3.0861 (Forecasting Loss:0.2130 + XiCon Loss:2.8731 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0977917
	speed: 0.0152s/iter; left time: 160.2556s
Epoch: 18 cost time: 1.871802568435669
Epoch: 18, Steps: 128 Train Loss: 3.0944 (Forecasting Loss:0.2130 + XiCon Loss:2.8814 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0895462
	speed: 0.0138s/iter; left time: 143.5537s
Epoch: 19 cost time: 1.7368290424346924
Epoch: 19, Steps: 128 Train Loss: 3.0854 (Forecasting Loss:0.2128 + XiCon Loss:2.8726 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.2103159
	speed: 0.0138s/iter; left time: 142.2216s
Epoch: 20 cost time: 1.741011142730713
Epoch: 20, Steps: 128 Train Loss: 3.0851 (Forecasting Loss:0.2129 + XiCon Loss:2.8723 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0827041
	speed: 0.0161s/iter; left time: 163.1997s
Epoch: 21 cost time: 1.9682481288909912
Epoch: 21, Steps: 128 Train Loss: 3.0787 (Forecasting Loss:0.2129 + XiCon Loss:2.8658 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0286481
	speed: 0.0145s/iter; left time: 144.8363s
Epoch: 22 cost time: 1.8055894374847412
Epoch: 22, Steps: 128 Train Loss: 3.0946 (Forecasting Loss:0.2130 + XiCon Loss:2.8816 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
Validation loss decreased (0.163508 --> 0.163483).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0752497
	speed: 0.0146s/iter; left time: 143.9498s
Epoch: 23 cost time: 1.8171279430389404
Epoch: 23, Steps: 128 Train Loss: 3.0861 (Forecasting Loss:0.2129 + XiCon Loss:2.8732 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0543346
	speed: 0.0154s/iter; left time: 150.7428s
Epoch: 24 cost time: 1.9300239086151123
Epoch: 24, Steps: 128 Train Loss: 3.0942 (Forecasting Loss:0.2128 + XiCon Loss:2.8814 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1577415
	speed: 0.0144s/iter; left time: 138.2562s
Epoch: 25 cost time: 1.8113598823547363
Epoch: 25, Steps: 128 Train Loss: 3.0875 (Forecasting Loss:0.2129 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0509572
	speed: 0.0137s/iter; left time: 130.1272s
Epoch: 26 cost time: 1.7277567386627197
Epoch: 26, Steps: 128 Train Loss: 3.0909 (Forecasting Loss:0.2129 + XiCon Loss:2.8780 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0409865
	speed: 0.0142s/iter; left time: 133.3004s
Epoch: 27 cost time: 1.8380341529846191
Epoch: 27, Steps: 128 Train Loss: 3.0888 (Forecasting Loss:0.2131 + XiCon Loss:2.8758 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0998044
	speed: 0.0152s/iter; left time: 140.3928s
Epoch: 28 cost time: 1.8869819641113281
Epoch: 28, Steps: 128 Train Loss: 3.0926 (Forecasting Loss:0.2130 + XiCon Loss:2.8797 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0828609
	speed: 0.0149s/iter; left time: 136.0485s
Epoch: 29 cost time: 1.8497967720031738
Epoch: 29, Steps: 128 Train Loss: 3.0955 (Forecasting Loss:0.2130 + XiCon Loss:2.8826 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1153164
	speed: 0.0152s/iter; left time: 136.5273s
Epoch: 30 cost time: 1.8877537250518799
Epoch: 30, Steps: 128 Train Loss: 3.0874 (Forecasting Loss:0.2128 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1160
Validation loss decreased (0.163483 --> 0.163284).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0645552
	speed: 0.0153s/iter; left time: 135.1395s
Epoch: 31 cost time: 1.8985636234283447
Epoch: 31, Steps: 128 Train Loss: 3.0907 (Forecasting Loss:0.2128 + XiCon Loss:2.8779 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.2571487
	speed: 0.0150s/iter; left time: 131.3198s
Epoch: 32 cost time: 1.8617994785308838
Epoch: 32, Steps: 128 Train Loss: 3.0885 (Forecasting Loss:0.2130 + XiCon Loss:2.8755 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0158339
	speed: 0.0148s/iter; left time: 127.3857s
Epoch: 33 cost time: 1.8317556381225586
Epoch: 33, Steps: 128 Train Loss: 3.0892 (Forecasting Loss:0.2129 + XiCon Loss:2.8763 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0309670
	speed: 0.0154s/iter; left time: 130.2022s
Epoch: 34 cost time: 1.920759916305542
Epoch: 34, Steps: 128 Train Loss: 3.0893 (Forecasting Loss:0.2129 + XiCon Loss:2.8764 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.1294322
	speed: 0.0155s/iter; left time: 129.7713s
Epoch: 35 cost time: 1.9186372756958008
Epoch: 35, Steps: 128 Train Loss: 3.0902 (Forecasting Loss:0.2126 + XiCon Loss:2.8776 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.0754435
	speed: 0.0145s/iter; left time: 119.3840s
Epoch: 36 cost time: 1.809993028640747
Epoch: 36, Steps: 128 Train Loss: 3.0908 (Forecasting Loss:0.2130 + XiCon Loss:2.8777 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.0713553
	speed: 0.0145s/iter; left time: 117.7339s
Epoch: 37 cost time: 1.8496358394622803
Epoch: 37, Steps: 128 Train Loss: 3.0955 (Forecasting Loss:0.2129 + XiCon Loss:2.8827 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.1802247
	speed: 0.0142s/iter; left time: 113.0710s
Epoch: 38 cost time: 1.7849626541137695
Epoch: 38, Steps: 128 Train Loss: 3.0905 (Forecasting Loss:0.2130 + XiCon Loss:2.8774 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 3.2229304
	speed: 0.0151s/iter; left time: 118.5885s
Epoch: 39 cost time: 1.912825345993042
Epoch: 39, Steps: 128 Train Loss: 3.0875 (Forecasting Loss:0.2128 + XiCon Loss:2.8747 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 3.0489790
	speed: 0.0143s/iter; left time: 110.3996s
Epoch: 40 cost time: 1.7832398414611816
Epoch: 40, Steps: 128 Train Loss: 3.0900 (Forecasting Loss:0.2129 + XiCon Loss:2.8772 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05430839955806732, mae:0.1776355803012848, mape:0.14130212366580963, mspe:0.03750483691692352 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3443
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2909255
	speed: 0.0154s/iter; left time: 195.1011s
Epoch: 1 cost time: 1.9039027690887451
Epoch: 1, Steps: 128 Train Loss: 3.2976 (Forecasting Loss:0.2453 + XiCon Loss:3.0523 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1240
Validation loss decreased (inf --> 0.175428).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1220922
	speed: 0.0144s/iter; left time: 181.4624s
Epoch: 2 cost time: 1.7833597660064697
Epoch: 2, Steps: 128 Train Loss: 3.1414 (Forecasting Loss:0.2503 + XiCon Loss:2.8912 x Lambda(1.0)), Vali MSE Loss: 0.1759 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0883875
	speed: 0.0141s/iter; left time: 175.7797s
Epoch: 3 cost time: 1.8132622241973877
Epoch: 3, Steps: 128 Train Loss: 3.1282 (Forecasting Loss:0.2290 + XiCon Loss:2.8992 x Lambda(1.0)), Vali MSE Loss: 0.1681 Test MSE Loss: 0.1201
Validation loss decreased (0.175428 --> 0.168062).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1477911
	speed: 0.0145s/iter; left time: 179.0262s
Epoch: 4 cost time: 1.7844598293304443
Epoch: 4, Steps: 128 Train Loss: 3.1497 (Forecasting Loss:0.2210 + XiCon Loss:2.9287 x Lambda(1.0)), Vali MSE Loss: 0.1681 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0597086
	speed: 0.0151s/iter; left time: 184.2116s
Epoch: 5 cost time: 1.9194343090057373
Epoch: 5, Steps: 128 Train Loss: 3.1040 (Forecasting Loss:0.2172 + XiCon Loss:2.8868 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1184
Validation loss decreased (0.168062 --> 0.165200).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1346626
	speed: 0.0141s/iter; left time: 169.7958s
Epoch: 6 cost time: 1.7482571601867676
Epoch: 6, Steps: 128 Train Loss: 3.0758 (Forecasting Loss:0.2146 + XiCon Loss:2.8612 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
Validation loss decreased (0.165200 --> 0.163516).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1420586
	speed: 0.0145s/iter; left time: 172.5540s
Epoch: 7 cost time: 1.8285157680511475
Epoch: 7, Steps: 128 Train Loss: 3.0697 (Forecasting Loss:0.2135 + XiCon Loss:2.8562 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0542307
	speed: 0.0143s/iter; left time: 168.6466s
Epoch: 8 cost time: 1.833540678024292
Epoch: 8, Steps: 128 Train Loss: 3.0584 (Forecasting Loss:0.2129 + XiCon Loss:2.8455 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
Validation loss decreased (0.163516 --> 0.163433).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0053587
	speed: 0.0152s/iter; left time: 177.9955s
Epoch: 9 cost time: 1.931455373764038
Epoch: 9, Steps: 128 Train Loss: 3.0545 (Forecasting Loss:0.2126 + XiCon Loss:2.8419 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
Validation loss decreased (0.163433 --> 0.163306).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 2.9887440
	speed: 0.0146s/iter; left time: 168.1500s
Epoch: 10 cost time: 1.8382666110992432
Epoch: 10, Steps: 128 Train Loss: 3.0506 (Forecasting Loss:0.2125 + XiCon Loss:2.8381 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 2.9970787
	speed: 0.0149s/iter; left time: 170.5579s
Epoch: 11 cost time: 1.8597426414489746
Epoch: 11, Steps: 128 Train Loss: 3.0551 (Forecasting Loss:0.2125 + XiCon Loss:2.8426 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1151237
	speed: 0.0144s/iter; left time: 162.8969s
Epoch: 12 cost time: 1.8473420143127441
Epoch: 12, Steps: 128 Train Loss: 3.0539 (Forecasting Loss:0.2123 + XiCon Loss:2.8416 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0719421
	speed: 0.0141s/iter; left time: 157.0795s
Epoch: 13 cost time: 1.8182227611541748
Epoch: 13, Steps: 128 Train Loss: 3.0523 (Forecasting Loss:0.2123 + XiCon Loss:2.8400 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0528574
	speed: 0.0138s/iter; left time: 152.6816s
Epoch: 14 cost time: 1.713836431503296
Epoch: 14, Steps: 128 Train Loss: 3.0539 (Forecasting Loss:0.2122 + XiCon Loss:2.8417 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
Validation loss decreased (0.163306 --> 0.163125).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0501742
	speed: 0.0143s/iter; left time: 155.5441s
Epoch: 15 cost time: 1.777299165725708
Epoch: 15, Steps: 128 Train Loss: 3.0525 (Forecasting Loss:0.2123 + XiCon Loss:2.8402 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0193055
	speed: 0.0144s/iter; left time: 155.5177s
Epoch: 16 cost time: 1.847578763961792
Epoch: 16, Steps: 128 Train Loss: 3.0497 (Forecasting Loss:0.2123 + XiCon Loss:2.8374 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1152
Validation loss decreased (0.163125 --> 0.162991).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 2.9690256
	speed: 0.0152s/iter; left time: 162.3775s
Epoch: 17 cost time: 1.8997762203216553
Epoch: 17, Steps: 128 Train Loss: 3.0585 (Forecasting Loss:0.2121 + XiCon Loss:2.8463 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1624489
	speed: 0.0155s/iter; left time: 162.6296s
Epoch: 18 cost time: 1.954967737197876
Epoch: 18, Steps: 128 Train Loss: 3.0505 (Forecasting Loss:0.2124 + XiCon Loss:2.8381 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0496299
	speed: 0.0145s/iter; left time: 150.9219s
Epoch: 19 cost time: 1.8004934787750244
Epoch: 19, Steps: 128 Train Loss: 3.0531 (Forecasting Loss:0.2122 + XiCon Loss:2.8408 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0172188
	speed: 0.0148s/iter; left time: 152.3045s
Epoch: 20 cost time: 1.8393642902374268
Epoch: 20, Steps: 128 Train Loss: 3.0497 (Forecasting Loss:0.2123 + XiCon Loss:2.8374 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 2.9947469
	speed: 0.0148s/iter; left time: 149.8945s
Epoch: 21 cost time: 1.8521349430084229
Epoch: 21, Steps: 128 Train Loss: 3.0546 (Forecasting Loss:0.2124 + XiCon Loss:2.8423 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0001481
	speed: 0.0143s/iter; left time: 143.1674s
Epoch: 22 cost time: 1.7832152843475342
Epoch: 22, Steps: 128 Train Loss: 3.0476 (Forecasting Loss:0.2124 + XiCon Loss:2.8352 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0685399
	speed: 0.0152s/iter; left time: 150.1256s
Epoch: 23 cost time: 1.8838005065917969
Epoch: 23, Steps: 128 Train Loss: 3.0531 (Forecasting Loss:0.2124 + XiCon Loss:2.8407 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1204774
	speed: 0.0145s/iter; left time: 141.5069s
Epoch: 24 cost time: 1.811586618423462
Epoch: 24, Steps: 128 Train Loss: 3.0544 (Forecasting Loss:0.2122 + XiCon Loss:2.8422 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1152
Validation loss decreased (0.162991 --> 0.162901).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0022357
	speed: 0.0151s/iter; left time: 145.0047s
Epoch: 25 cost time: 1.8690555095672607
Epoch: 25, Steps: 128 Train Loss: 3.0455 (Forecasting Loss:0.2123 + XiCon Loss:2.8332 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0836432
	speed: 0.0145s/iter; left time: 137.5625s
Epoch: 26 cost time: 1.832855224609375
Epoch: 26, Steps: 128 Train Loss: 3.0529 (Forecasting Loss:0.2124 + XiCon Loss:2.8405 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0130017
	speed: 0.0143s/iter; left time: 133.7632s
Epoch: 27 cost time: 1.8082199096679688
Epoch: 27, Steps: 128 Train Loss: 3.0544 (Forecasting Loss:0.2123 + XiCon Loss:2.8421 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0655632
	speed: 0.0147s/iter; left time: 136.0721s
Epoch: 28 cost time: 1.8457257747650146
Epoch: 28, Steps: 128 Train Loss: 3.0542 (Forecasting Loss:0.2122 + XiCon Loss:2.8420 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0433729
	speed: 0.0155s/iter; left time: 141.2264s
Epoch: 29 cost time: 1.9546611309051514
Epoch: 29, Steps: 128 Train Loss: 3.0557 (Forecasting Loss:0.2123 + XiCon Loss:2.8434 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0543380
	speed: 0.0149s/iter; left time: 133.5538s
Epoch: 30 cost time: 1.9130668640136719
Epoch: 30, Steps: 128 Train Loss: 3.0594 (Forecasting Loss:0.2122 + XiCon Loss:2.8472 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0571833
	speed: 0.0149s/iter; left time: 132.3709s
Epoch: 31 cost time: 1.8473386764526367
Epoch: 31, Steps: 128 Train Loss: 3.0554 (Forecasting Loss:0.2123 + XiCon Loss:2.8431 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0812149
	speed: 0.0147s/iter; left time: 128.5103s
Epoch: 32 cost time: 1.889632225036621
Epoch: 32, Steps: 128 Train Loss: 3.0539 (Forecasting Loss:0.2121 + XiCon Loss:2.8418 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0613790
	speed: 0.0144s/iter; left time: 123.9874s
Epoch: 33 cost time: 1.788231611251831
Epoch: 33, Steps: 128 Train Loss: 3.0528 (Forecasting Loss:0.2123 + XiCon Loss:2.8405 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1152
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0087137
	speed: 0.0140s/iter; left time: 118.6696s
Epoch: 34 cost time: 1.7617037296295166
Epoch: 34, Steps: 128 Train Loss: 3.0503 (Forecasting Loss:0.2121 + XiCon Loss:2.8382 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054087553173303604, mae:0.17635971307754517, mape:0.1401895433664322, mspe:0.0372982919216156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0547+-0.00075, MAE:0.1780+-0.00157, MAPE:0.1419+-0.00196, MSPE:0.0383+-0.00197, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4236
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2682209
	speed: 0.0179s/iter; left time: 224.2717s
Epoch: 1 cost time: 2.1787524223327637
Epoch: 1, Steps: 126 Train Loss: 3.3284 (Forecasting Loss:0.2773 + XiCon Loss:3.0511 x Lambda(1.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1440
Validation loss decreased (inf --> 0.197610).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0892780
	speed: 0.0161s/iter; left time: 199.3230s
Epoch: 2 cost time: 2.050740957260132
Epoch: 2, Steps: 126 Train Loss: 3.1155 (Forecasting Loss:0.2610 + XiCon Loss:2.8544 x Lambda(1.0)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.1385
Validation loss decreased (0.197610 --> 0.191224).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.9683383
	speed: 0.0169s/iter; left time: 207.0974s
Epoch: 3 cost time: 2.1414175033569336
Epoch: 3, Steps: 126 Train Loss: 3.0051 (Forecasting Loss:0.2456 + XiCon Loss:2.7595 x Lambda(1.0)), Vali MSE Loss: 0.1897 Test MSE Loss: 0.1389
Validation loss decreased (0.191224 --> 0.189734).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1585348
	speed: 0.0164s/iter; left time: 198.9974s
Epoch: 4 cost time: 2.0358707904815674
Epoch: 4, Steps: 126 Train Loss: 3.2092 (Forecasting Loss:0.2401 + XiCon Loss:2.9691 x Lambda(1.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1382
Validation loss decreased (0.189734 --> 0.185311).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1503587
	speed: 0.0171s/iter; left time: 205.6570s
Epoch: 5 cost time: 2.146366834640503
Epoch: 5, Steps: 126 Train Loss: 3.1597 (Forecasting Loss:0.2380 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1360
Validation loss decreased (0.185311 --> 0.181840).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1654501
	speed: 0.0179s/iter; left time: 212.2722s
Epoch: 6 cost time: 2.2313342094421387
Epoch: 6, Steps: 126 Train Loss: 3.1526 (Forecasting Loss:0.2355 + XiCon Loss:2.9172 x Lambda(1.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1363
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1899626
	speed: 0.0163s/iter; left time: 191.2850s
Epoch: 7 cost time: 2.0453145503997803
Epoch: 7, Steps: 126 Train Loss: 3.1641 (Forecasting Loss:0.2339 + XiCon Loss:2.9303 x Lambda(1.0)), Vali MSE Loss: 0.1830 Test MSE Loss: 0.1380
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2922199
	speed: 0.0173s/iter; left time: 200.7642s
Epoch: 8 cost time: 2.1557695865631104
Epoch: 8, Steps: 126 Train Loss: 3.1450 (Forecasting Loss:0.2339 + XiCon Loss:2.9111 x Lambda(1.0)), Vali MSE Loss: 0.1825 Test MSE Loss: 0.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0129390
	speed: 0.0170s/iter; left time: 194.8269s
Epoch: 9 cost time: 2.121483325958252
Epoch: 9, Steps: 126 Train Loss: 3.1562 (Forecasting Loss:0.2326 + XiCon Loss:2.9236 x Lambda(1.0)), Vali MSE Loss: 0.1827 Test MSE Loss: 0.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3093972
	speed: 0.0171s/iter; left time: 193.9536s
Epoch: 10 cost time: 2.103790521621704
Epoch: 10, Steps: 126 Train Loss: 3.1541 (Forecasting Loss:0.2326 + XiCon Loss:2.9215 x Lambda(1.0)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1376
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1444128
	speed: 0.0178s/iter; left time: 199.9087s
Epoch: 11 cost time: 2.194711685180664
Epoch: 11, Steps: 126 Train Loss: 3.1678 (Forecasting Loss:0.2324 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.1824 Test MSE Loss: 0.1375
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2368240
	speed: 0.0166s/iter; left time: 184.5062s
Epoch: 12 cost time: 2.067206859588623
Epoch: 12, Steps: 126 Train Loss: 3.1562 (Forecasting Loss:0.2325 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.1825 Test MSE Loss: 0.1375
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2738957
	speed: 0.0172s/iter; left time: 189.0157s
Epoch: 13 cost time: 2.1271438598632812
Epoch: 13, Steps: 126 Train Loss: 3.1548 (Forecasting Loss:0.2318 + XiCon Loss:2.9230 x Lambda(1.0)), Vali MSE Loss: 0.1825 Test MSE Loss: 0.1375
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.0691864
	speed: 0.0175s/iter; left time: 190.5741s
Epoch: 14 cost time: 2.2120580673217773
Epoch: 14, Steps: 126 Train Loss: 3.1622 (Forecasting Loss:0.2326 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.1825 Test MSE Loss: 0.1375
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1334391
	speed: 0.0174s/iter; left time: 186.8290s
Epoch: 15 cost time: 2.1909756660461426
Epoch: 15, Steps: 126 Train Loss: 3.1568 (Forecasting Loss:0.2322 + XiCon Loss:2.9247 x Lambda(1.0)), Vali MSE Loss: 0.1824 Test MSE Loss: 0.1375
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06947202980518341, mae:0.202523872256279, mape:0.15731309354305267, mspe:0.04458367079496384 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2838743
	speed: 0.0165s/iter; left time: 205.9706s
Epoch: 1 cost time: 2.0469882488250732
Epoch: 1, Steps: 126 Train Loss: 3.3189 (Forecasting Loss:0.2784 + XiCon Loss:3.0405 x Lambda(1.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1440
Validation loss decreased (inf --> 0.197540).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0740604
	speed: 0.0172s/iter; left time: 212.7650s
Epoch: 2 cost time: 2.168705940246582
Epoch: 2, Steps: 126 Train Loss: 3.1138 (Forecasting Loss:0.2634 + XiCon Loss:2.8504 x Lambda(1.0)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1401
Validation loss decreased (0.197540 --> 0.197190).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3455386
	speed: 0.0182s/iter; left time: 223.4627s
Epoch: 3 cost time: 2.224919080734253
Epoch: 3, Steps: 126 Train Loss: 3.1696 (Forecasting Loss:0.2535 + XiCon Loss:2.9162 x Lambda(1.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1385
Validation loss decreased (0.197190 --> 0.189960).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1163566
	speed: 0.0166s/iter; left time: 201.6688s
Epoch: 4 cost time: 2.0666913986206055
Epoch: 4, Steps: 126 Train Loss: 3.1834 (Forecasting Loss:0.2472 + XiCon Loss:2.9361 x Lambda(1.0)), Vali MSE Loss: 0.1890 Test MSE Loss: 0.1380
Validation loss decreased (0.189960 --> 0.188979).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0926836
	speed: 0.0173s/iter; left time: 206.9981s
Epoch: 5 cost time: 2.1182503700256348
Epoch: 5, Steps: 126 Train Loss: 3.1718 (Forecasting Loss:0.2447 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1356
Validation loss decreased (0.188979 --> 0.186344).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1623623
	speed: 0.0164s/iter; left time: 195.0159s
Epoch: 6 cost time: 2.0841972827911377
Epoch: 6, Steps: 126 Train Loss: 3.1504 (Forecasting Loss:0.2432 + XiCon Loss:2.9072 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1375
Validation loss decreased (0.186344 --> 0.185620).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3061271
	speed: 0.0168s/iter; left time: 197.1765s
Epoch: 7 cost time: 2.111901044845581
Epoch: 7, Steps: 126 Train Loss: 3.1561 (Forecasting Loss:0.2424 + XiCon Loss:2.9138 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
Validation loss decreased (0.185620 --> 0.185575).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2253861
	speed: 0.0164s/iter; left time: 190.3794s
Epoch: 8 cost time: 2.0229578018188477
Epoch: 8, Steps: 126 Train Loss: 3.1503 (Forecasting Loss:0.2420 + XiCon Loss:2.9083 x Lambda(1.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1368
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1118214
	speed: 0.0165s/iter; left time: 189.8028s
Epoch: 9 cost time: 2.033759593963623
Epoch: 9, Steps: 126 Train Loss: 3.1370 (Forecasting Loss:0.2417 + XiCon Loss:2.8953 x Lambda(1.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1370
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1089239
	speed: 0.0174s/iter; left time: 197.3159s
Epoch: 10 cost time: 2.1581928730010986
Epoch: 10, Steps: 126 Train Loss: 3.1520 (Forecasting Loss:0.2416 + XiCon Loss:2.9104 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1371
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3114307
	speed: 0.0171s/iter; left time: 191.9127s
Epoch: 11 cost time: 2.096951723098755
Epoch: 11, Steps: 126 Train Loss: 3.1601 (Forecasting Loss:0.2412 + XiCon Loss:2.9189 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2012823
	speed: 0.0172s/iter; left time: 190.9940s
Epoch: 12 cost time: 2.14193058013916
Epoch: 12, Steps: 126 Train Loss: 3.1550 (Forecasting Loss:0.2415 + XiCon Loss:2.9135 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
Validation loss decreased (0.185575 --> 0.185557).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1031172
	speed: 0.0167s/iter; left time: 183.5323s
Epoch: 13 cost time: 2.1144349575042725
Epoch: 13, Steps: 126 Train Loss: 3.1414 (Forecasting Loss:0.2413 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3113794
	speed: 0.0166s/iter; left time: 180.0075s
Epoch: 14 cost time: 2.0356338024139404
Epoch: 14, Steps: 126 Train Loss: 3.1438 (Forecasting Loss:0.2414 + XiCon Loss:2.9024 x Lambda(1.0)), Vali MSE Loss: 0.1855 Test MSE Loss: 0.1372
Validation loss decreased (0.185557 --> 0.185541).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0802813
	speed: 0.0170s/iter; left time: 182.8179s
Epoch: 15 cost time: 2.08628511428833
Epoch: 15, Steps: 126 Train Loss: 3.1443 (Forecasting Loss:0.2412 + XiCon Loss:2.9031 x Lambda(1.0)), Vali MSE Loss: 0.1855 Test MSE Loss: 0.1372
Validation loss decreased (0.185541 --> 0.185512).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1009896
	speed: 0.0161s/iter; left time: 170.9366s
Epoch: 16 cost time: 2.0213892459869385
Epoch: 16, Steps: 126 Train Loss: 3.1486 (Forecasting Loss:0.2412 + XiCon Loss:2.9074 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1103537
	speed: 0.0165s/iter; left time: 172.7971s
Epoch: 17 cost time: 2.0762763023376465
Epoch: 17, Steps: 126 Train Loss: 3.1472 (Forecasting Loss:0.2411 + XiCon Loss:2.9061 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1053395
	speed: 0.0170s/iter; left time: 176.2719s
Epoch: 18 cost time: 2.091610908508301
Epoch: 18, Steps: 126 Train Loss: 3.1508 (Forecasting Loss:0.2411 + XiCon Loss:2.9097 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0235538
	speed: 0.0177s/iter; left time: 181.3844s
Epoch: 19 cost time: 2.240779161453247
Epoch: 19, Steps: 126 Train Loss: 3.1360 (Forecasting Loss:0.2413 + XiCon Loss:2.8947 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1470425
	speed: 0.0172s/iter; left time: 173.9488s
Epoch: 20 cost time: 2.1406757831573486
Epoch: 20, Steps: 126 Train Loss: 3.1452 (Forecasting Loss:0.2416 + XiCon Loss:2.9036 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0388653
	speed: 0.0167s/iter; left time: 166.3515s
Epoch: 21 cost time: 2.1173017024993896
Epoch: 21, Steps: 126 Train Loss: 3.1341 (Forecasting Loss:0.2414 + XiCon Loss:2.8927 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1076441
	speed: 0.0163s/iter; left time: 160.6945s
Epoch: 22 cost time: 2.02480149269104
Epoch: 22, Steps: 126 Train Loss: 3.1494 (Forecasting Loss:0.2414 + XiCon Loss:2.9079 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2169087
	speed: 0.0168s/iter; left time: 163.0584s
Epoch: 23 cost time: 2.0590598583221436
Epoch: 23, Steps: 126 Train Loss: 3.1578 (Forecasting Loss:0.2413 + XiCon Loss:2.9165 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1973958
	speed: 0.0173s/iter; left time: 165.8454s
Epoch: 24 cost time: 2.12658429145813
Epoch: 24, Steps: 126 Train Loss: 3.1402 (Forecasting Loss:0.2413 + XiCon Loss:2.8989 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1359978
	speed: 0.0165s/iter; left time: 156.5776s
Epoch: 25 cost time: 2.0923469066619873
Epoch: 25, Steps: 126 Train Loss: 3.1459 (Forecasting Loss:0.2414 + XiCon Loss:2.9045 x Lambda(1.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07057267427444458, mae:0.20384491980075836, mape:0.15585164725780487, mspe:0.042116910219192505 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3561
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3038406
	speed: 0.0161s/iter; left time: 201.3181s
Epoch: 1 cost time: 2.017735719680786
Epoch: 1, Steps: 126 Train Loss: 3.3130 (Forecasting Loss:0.2758 + XiCon Loss:3.0372 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1462
Validation loss decreased (inf --> 0.197651).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0653315
	speed: 0.0176s/iter; left time: 217.3184s
Epoch: 2 cost time: 2.2276806831359863
Epoch: 2, Steps: 126 Train Loss: 3.1237 (Forecasting Loss:0.2631 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1426
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0818448
	speed: 0.0191s/iter; left time: 233.6529s
Epoch: 3 cost time: 2.3662519454956055
Epoch: 3, Steps: 126 Train Loss: 3.0581 (Forecasting Loss:0.2496 + XiCon Loss:2.8085 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1517
Validation loss decreased (0.197651 --> 0.195752).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2047007
	speed: 0.0171s/iter; left time: 207.5734s
Epoch: 4 cost time: 2.1214518547058105
Epoch: 4, Steps: 126 Train Loss: 3.1039 (Forecasting Loss:0.2432 + XiCon Loss:2.8607 x Lambda(1.0)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.1349
Validation loss decreased (0.195752 --> 0.188305).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1848698
	speed: 0.0176s/iter; left time: 211.1521s
Epoch: 5 cost time: 2.222343921661377
Epoch: 5, Steps: 126 Train Loss: 3.2517 (Forecasting Loss:0.2404 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.1924 Test MSE Loss: 0.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1403451
	speed: 0.0170s/iter; left time: 201.2369s
Epoch: 6 cost time: 2.0919477939605713
Epoch: 6, Steps: 126 Train Loss: 3.2154 (Forecasting Loss:0.2364 + XiCon Loss:2.9790 x Lambda(1.0)), Vali MSE Loss: 0.1918 Test MSE Loss: 0.1360
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2297473
	speed: 0.0169s/iter; left time: 198.2159s
Epoch: 7 cost time: 2.0913963317871094
Epoch: 7, Steps: 126 Train Loss: 3.1924 (Forecasting Loss:0.2339 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1344
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2471545
	speed: 0.0175s/iter; left time: 203.5559s
Epoch: 8 cost time: 2.184875965118408
Epoch: 8, Steps: 126 Train Loss: 3.2017 (Forecasting Loss:0.2325 + XiCon Loss:2.9692 x Lambda(1.0)), Vali MSE Loss: 0.1901 Test MSE Loss: 0.1340
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2864666
	speed: 0.0175s/iter; left time: 201.2809s
Epoch: 9 cost time: 2.1679911613464355
Epoch: 9, Steps: 126 Train Loss: 3.1765 (Forecasting Loss:0.2321 + XiCon Loss:2.9444 x Lambda(1.0)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.1339
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2796590
	speed: 0.0174s/iter; left time: 198.1497s
Epoch: 10 cost time: 2.1513571739196777
Epoch: 10, Steps: 126 Train Loss: 3.1906 (Forecasting Loss:0.2318 + XiCon Loss:2.9588 x Lambda(1.0)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.1339
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1590042
	speed: 0.0173s/iter; left time: 194.5677s
Epoch: 11 cost time: 2.134249687194824
Epoch: 11, Steps: 126 Train Loss: 3.1798 (Forecasting Loss:0.2321 + XiCon Loss:2.9477 x Lambda(1.0)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.1338
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1259422
	speed: 0.0177s/iter; left time: 196.2448s
Epoch: 12 cost time: 2.21838641166687
Epoch: 12, Steps: 126 Train Loss: 3.1864 (Forecasting Loss:0.2317 + XiCon Loss:2.9548 x Lambda(1.0)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1338
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1383715
	speed: 0.0176s/iter; left time: 193.4421s
Epoch: 13 cost time: 2.1758079528808594
Epoch: 13, Steps: 126 Train Loss: 3.1946 (Forecasting Loss:0.2314 + XiCon Loss:2.9632 x Lambda(1.0)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.1338
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3473468
	speed: 0.0174s/iter; left time: 189.0388s
Epoch: 14 cost time: 2.1630942821502686
Epoch: 14, Steps: 126 Train Loss: 3.1989 (Forecasting Loss:0.2316 + XiCon Loss:2.9673 x Lambda(1.0)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.1338
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06818703562021255, mae:0.20158319175243378, mape:0.15678150951862335, mspe:0.045478109270334244 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3514
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2879210
	speed: 0.0155s/iter; left time: 193.3104s
Epoch: 1 cost time: 1.9854416847229004
Epoch: 1, Steps: 126 Train Loss: 3.3182 (Forecasting Loss:0.2766 + XiCon Loss:3.0415 x Lambda(1.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1434
Validation loss decreased (inf --> 0.196616).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1092124
	speed: 0.0174s/iter; left time: 215.2413s
Epoch: 2 cost time: 2.134995698928833
Epoch: 2, Steps: 126 Train Loss: 3.1438 (Forecasting Loss:0.2625 + XiCon Loss:2.8813 x Lambda(1.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1452
Validation loss decreased (0.196616 --> 0.195557).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3254197
	speed: 0.0176s/iter; left time: 215.7290s
Epoch: 3 cost time: 2.2010855674743652
Epoch: 3, Steps: 126 Train Loss: 3.1514 (Forecasting Loss:0.2520 + XiCon Loss:2.8994 x Lambda(1.0)), Vali MSE Loss: 0.1893 Test MSE Loss: 0.1364
Validation loss decreased (0.195557 --> 0.189346).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1022182
	speed: 0.0191s/iter; left time: 231.3568s
Epoch: 4 cost time: 2.3087778091430664
Epoch: 4, Steps: 126 Train Loss: 3.2223 (Forecasting Loss:0.2467 + XiCon Loss:2.9757 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1388
Validation loss decreased (0.189346 --> 0.186376).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1335344
	speed: 0.0174s/iter; left time: 209.0603s
Epoch: 5 cost time: 2.171891927719116
Epoch: 5, Steps: 126 Train Loss: 3.1696 (Forecasting Loss:0.2431 + XiCon Loss:2.9265 x Lambda(1.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1385
Validation loss decreased (0.186376 --> 0.185409).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1210732
	speed: 0.0171s/iter; left time: 203.5607s
Epoch: 6 cost time: 2.144897937774658
Epoch: 6, Steps: 126 Train Loss: 3.1662 (Forecasting Loss:0.2411 + XiCon Loss:2.9251 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1381
Validation loss decreased (0.185409 --> 0.184043).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1375813
	speed: 0.0170s/iter; left time: 200.0430s
Epoch: 7 cost time: 2.0929596424102783
Epoch: 7, Steps: 126 Train Loss: 3.1740 (Forecasting Loss:0.2396 + XiCon Loss:2.9344 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1391
Validation loss decreased (0.184043 --> 0.183977).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3381796
	speed: 0.0174s/iter; left time: 201.7534s
Epoch: 8 cost time: 2.1372036933898926
Epoch: 8, Steps: 126 Train Loss: 3.1578 (Forecasting Loss:0.2391 + XiCon Loss:2.9187 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1378
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0148497
	speed: 0.0174s/iter; left time: 199.5712s
Epoch: 9 cost time: 2.1577229499816895
Epoch: 9, Steps: 126 Train Loss: 3.1852 (Forecasting Loss:0.2387 + XiCon Loss:2.9465 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1378
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2052550
	speed: 0.0168s/iter; left time: 190.8840s
Epoch: 10 cost time: 2.093550682067871
Epoch: 10, Steps: 126 Train Loss: 3.1636 (Forecasting Loss:0.2387 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1378
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1587760
	speed: 0.0165s/iter; left time: 185.9518s
Epoch: 11 cost time: 2.0719122886657715
Epoch: 11, Steps: 126 Train Loss: 3.1682 (Forecasting Loss:0.2387 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.1839 Test MSE Loss: 0.1380
Validation loss decreased (0.183977 --> 0.183934).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0979021
	speed: 0.0172s/iter; left time: 191.4432s
Epoch: 12 cost time: 2.113938808441162
Epoch: 12, Steps: 126 Train Loss: 3.1583 (Forecasting Loss:0.2384 + XiCon Loss:2.9199 x Lambda(1.0)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1524181
	speed: 0.0170s/iter; left time: 186.7847s
Epoch: 13 cost time: 2.1166927814483643
Epoch: 13, Steps: 126 Train Loss: 3.1608 (Forecasting Loss:0.2384 + XiCon Loss:2.9224 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.0769291
	speed: 0.0171s/iter; left time: 185.4302s
Epoch: 14 cost time: 2.131708860397339
Epoch: 14, Steps: 126 Train Loss: 3.1534 (Forecasting Loss:0.2383 + XiCon Loss:2.9151 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0644894
	speed: 0.0170s/iter; left time: 182.6209s
Epoch: 15 cost time: 2.170018196105957
Epoch: 15, Steps: 126 Train Loss: 3.1564 (Forecasting Loss:0.2384 + XiCon Loss:2.9180 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1922929
	speed: 0.0172s/iter; left time: 182.0524s
Epoch: 16 cost time: 2.1413733959198
Epoch: 16, Steps: 126 Train Loss: 3.1627 (Forecasting Loss:0.2384 + XiCon Loss:2.9243 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1517653
	speed: 0.0185s/iter; left time: 193.8904s
Epoch: 17 cost time: 2.23244047164917
Epoch: 17, Steps: 126 Train Loss: 3.1779 (Forecasting Loss:0.2382 + XiCon Loss:2.9397 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1755171
	speed: 0.0170s/iter; left time: 176.1643s
Epoch: 18 cost time: 2.1100378036499023
Epoch: 18, Steps: 126 Train Loss: 3.1805 (Forecasting Loss:0.2385 + XiCon Loss:2.9420 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0439775
	speed: 0.0170s/iter; left time: 173.7576s
Epoch: 19 cost time: 2.110691785812378
Epoch: 19, Steps: 126 Train Loss: 3.1601 (Forecasting Loss:0.2384 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1817865
	speed: 0.0172s/iter; left time: 174.2447s
Epoch: 20 cost time: 2.1269450187683105
Epoch: 20, Steps: 126 Train Loss: 3.1665 (Forecasting Loss:0.2382 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0991266
	speed: 0.0174s/iter; left time: 173.4941s
Epoch: 21 cost time: 2.15512752532959
Epoch: 21, Steps: 126 Train Loss: 3.1648 (Forecasting Loss:0.2385 + XiCon Loss:2.9263 x Lambda(1.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1379
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07083076238632202, mae:0.20512832701206207, mape:0.15826384723186493, mspe:0.044496625661849976 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3585
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2643466
	speed: 0.0160s/iter; left time: 200.2489s
Epoch: 1 cost time: 1.9799749851226807
Epoch: 1, Steps: 126 Train Loss: 3.3193 (Forecasting Loss:0.2769 + XiCon Loss:3.0424 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1453
Validation loss decreased (inf --> 0.197936).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1359766
	speed: 0.0181s/iter; left time: 223.5024s
Epoch: 2 cost time: 2.265857458114624
Epoch: 2, Steps: 126 Train Loss: 3.1729 (Forecasting Loss:0.2609 + XiCon Loss:2.9120 x Lambda(1.0)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1425
Validation loss decreased (0.197936 --> 0.194859).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2671039
	speed: 0.0174s/iter; left time: 213.4653s
Epoch: 3 cost time: 2.1427040100097656
Epoch: 3, Steps: 126 Train Loss: 3.2980 (Forecasting Loss:0.2498 + XiCon Loss:3.0482 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1435
Validation loss decreased (0.194859 --> 0.193945).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4028060
	speed: 0.0183s/iter; left time: 221.6650s
Epoch: 4 cost time: 2.24326229095459
Epoch: 4, Steps: 126 Train Loss: 3.2571 (Forecasting Loss:0.2423 + XiCon Loss:3.0148 x Lambda(1.0)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1393
Validation loss decreased (0.193945 --> 0.192171).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1133709
	speed: 0.0179s/iter; left time: 214.1757s
Epoch: 5 cost time: 2.203535318374634
Epoch: 5, Steps: 126 Train Loss: 3.2082 (Forecasting Loss:0.2380 + XiCon Loss:2.9702 x Lambda(1.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1380
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1076121
	speed: 0.0174s/iter; left time: 206.8164s
Epoch: 6 cost time: 2.182920455932617
Epoch: 6, Steps: 126 Train Loss: 3.2290 (Forecasting Loss:0.2353 + XiCon Loss:2.9937 x Lambda(1.0)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.1383
Validation loss decreased (0.192171 --> 0.191187).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1796749
	speed: 0.0177s/iter; left time: 207.3582s
Epoch: 7 cost time: 2.18119740486145
Epoch: 7, Steps: 126 Train Loss: 3.2135 (Forecasting Loss:0.2344 + XiCon Loss:2.9790 x Lambda(1.0)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1698990
	speed: 0.0175s/iter; left time: 203.3295s
Epoch: 8 cost time: 2.168649435043335
Epoch: 8, Steps: 126 Train Loss: 3.2150 (Forecasting Loss:0.2335 + XiCon Loss:2.9816 x Lambda(1.0)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1362
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0778489
	speed: 0.0176s/iter; left time: 202.7487s
Epoch: 9 cost time: 2.15449857711792
Epoch: 9, Steps: 126 Train Loss: 3.2089 (Forecasting Loss:0.2329 + XiCon Loss:2.9759 x Lambda(1.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1367
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2377787
	speed: 0.0169s/iter; left time: 192.2488s
Epoch: 10 cost time: 2.0984606742858887
Epoch: 10, Steps: 126 Train Loss: 3.2125 (Forecasting Loss:0.2328 + XiCon Loss:2.9798 x Lambda(1.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0378509
	speed: 0.0174s/iter; left time: 195.6201s
Epoch: 11 cost time: 2.186861991882324
Epoch: 11, Steps: 126 Train Loss: 3.2043 (Forecasting Loss:0.2325 + XiCon Loss:2.9718 x Lambda(1.0)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2671912
	speed: 0.0171s/iter; left time: 189.7456s
Epoch: 12 cost time: 2.114274740219116
Epoch: 12, Steps: 126 Train Loss: 3.2027 (Forecasting Loss:0.2328 + XiCon Loss:2.9699 x Lambda(1.0)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1803060
	speed: 0.0171s/iter; left time: 188.3916s
Epoch: 13 cost time: 2.1195030212402344
Epoch: 13, Steps: 126 Train Loss: 3.1958 (Forecasting Loss:0.2329 + XiCon Loss:2.9629 x Lambda(1.0)), Vali MSE Loss: 0.1919 Test MSE Loss: 0.1366
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2917337
	speed: 0.0179s/iter; left time: 194.9859s
Epoch: 14 cost time: 2.20510196685791
Epoch: 14, Steps: 126 Train Loss: 3.1899 (Forecasting Loss:0.2326 + XiCon Loss:2.9573 x Lambda(1.0)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1366
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2758989
	speed: 0.0170s/iter; left time: 182.3987s
Epoch: 15 cost time: 2.1070518493652344
Epoch: 15, Steps: 126 Train Loss: 3.2039 (Forecasting Loss:0.2329 + XiCon Loss:2.9711 x Lambda(1.0)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1366
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1638236
	speed: 0.0173s/iter; left time: 183.1243s
Epoch: 16 cost time: 2.1386919021606445
Epoch: 16, Steps: 126 Train Loss: 3.2017 (Forecasting Loss:0.2327 + XiCon Loss:2.9690 x Lambda(1.0)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1366
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07071388512849808, mae:0.20586808025836945, mape:0.15729466080665588, mspe:0.04299330338835716 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0700+-0.00140, MAE:0.2038+-0.00220, MAPE:0.1571+-0.00109, MSPE:0.0439+-0.00168, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4276
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3281288
	speed: 0.0241s/iter; left time: 296.7159s
Epoch: 1 cost time: 2.8452327251434326
Epoch: 1, Steps: 124 Train Loss: 3.3416 (Forecasting Loss:0.2937 + XiCon Loss:3.0479 x Lambda(1.0)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1619
Validation loss decreased (inf --> 0.216504).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1522236
	speed: 0.0226s/iter; left time: 275.6896s
Epoch: 2 cost time: 2.782991647720337
Epoch: 2, Steps: 124 Train Loss: 3.1713 (Forecasting Loss:0.2815 + XiCon Loss:2.8898 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1562
Validation loss decreased (0.216504 --> 0.212258).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4063120
	speed: 0.0208s/iter; left time: 250.3805s
Epoch: 3 cost time: 2.5384609699249268
Epoch: 3, Steps: 124 Train Loss: 3.2327 (Forecasting Loss:0.2652 + XiCon Loss:2.9675 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1540
Validation loss decreased (0.212258 --> 0.206083).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0598247
	speed: 0.0210s/iter; left time: 250.5845s
Epoch: 4 cost time: 2.560370683670044
Epoch: 4, Steps: 124 Train Loss: 3.1657 (Forecasting Loss:0.2527 + XiCon Loss:2.9130 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1487
Validation loss decreased (0.206083 --> 0.204137).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2936835
	speed: 0.0209s/iter; left time: 246.7634s
Epoch: 5 cost time: 2.5720460414886475
Epoch: 5, Steps: 124 Train Loss: 3.1486 (Forecasting Loss:0.2466 + XiCon Loss:2.9020 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1504
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0412588
	speed: 0.0210s/iter; left time: 245.5891s
Epoch: 6 cost time: 2.5889854431152344
Epoch: 6, Steps: 124 Train Loss: 3.1261 (Forecasting Loss:0.2432 + XiCon Loss:2.8828 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1492
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1577275
	speed: 0.0211s/iter; left time: 244.1246s
Epoch: 7 cost time: 2.607994556427002
Epoch: 7, Steps: 124 Train Loss: 3.1218 (Forecasting Loss:0.2411 + XiCon Loss:2.8807 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1488
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1449051
	speed: 0.0213s/iter; left time: 243.9785s
Epoch: 8 cost time: 2.6200668811798096
Epoch: 8, Steps: 124 Train Loss: 3.1140 (Forecasting Loss:0.2405 + XiCon Loss:2.8735 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1487
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0651622
	speed: 0.0215s/iter; left time: 242.8694s
Epoch: 9 cost time: 2.615577220916748
Epoch: 9, Steps: 124 Train Loss: 3.1234 (Forecasting Loss:0.2399 + XiCon Loss:2.8835 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1496
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0379481
	speed: 0.0211s/iter; left time: 235.6906s
Epoch: 10 cost time: 2.596099376678467
Epoch: 10, Steps: 124 Train Loss: 3.1149 (Forecasting Loss:0.2398 + XiCon Loss:2.8752 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1500
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1116261
	speed: 0.0213s/iter; left time: 235.8222s
Epoch: 11 cost time: 2.6445915699005127
Epoch: 11, Steps: 124 Train Loss: 3.1161 (Forecasting Loss:0.2398 + XiCon Loss:2.8763 x Lambda(1.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1497
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0371125
	speed: 0.0214s/iter; left time: 234.0960s
Epoch: 12 cost time: 2.6363847255706787
Epoch: 12, Steps: 124 Train Loss: 3.1185 (Forecasting Loss:0.2395 + XiCon Loss:2.8790 x Lambda(1.0)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1496
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0741000
	speed: 0.0215s/iter; left time: 231.9971s
Epoch: 13 cost time: 2.641731023788452
Epoch: 13, Steps: 124 Train Loss: 3.1188 (Forecasting Loss:0.2400 + XiCon Loss:2.8788 x Lambda(1.0)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1496
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1401706
	speed: 0.0220s/iter; left time: 235.6408s
Epoch: 14 cost time: 2.687182664871216
Epoch: 14, Steps: 124 Train Loss: 3.1107 (Forecasting Loss:0.2397 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1495
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07779372483491898, mae:0.2196873426437378, mape:0.16606123745441437, mspe:0.04805153235793114 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3589
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3190453
	speed: 0.0206s/iter; left time: 253.4277s
Epoch: 1 cost time: 2.5303096771240234
Epoch: 1, Steps: 124 Train Loss: 3.3323 (Forecasting Loss:0.2965 + XiCon Loss:3.0358 x Lambda(1.0)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1611
Validation loss decreased (inf --> 0.216078).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4166145
	speed: 0.0235s/iter; left time: 285.7683s
Epoch: 2 cost time: 2.9430575370788574
Epoch: 2, Steps: 124 Train Loss: 3.2373 (Forecasting Loss:0.2784 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1555
Validation loss decreased (0.216078 --> 0.208166).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2279880
	speed: 0.0248s/iter; left time: 299.0131s
Epoch: 3 cost time: 3.0936834812164307
Epoch: 3, Steps: 124 Train Loss: 3.2743 (Forecasting Loss:0.2572 + XiCon Loss:3.0171 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1522
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1661828
	speed: 0.0242s/iter; left time: 288.8023s
Epoch: 4 cost time: 3.015761375427246
Epoch: 4, Steps: 124 Train Loss: 3.2438 (Forecasting Loss:0.2491 + XiCon Loss:2.9947 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1453
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2148337
	speed: 0.0253s/iter; left time: 298.7216s
Epoch: 5 cost time: 3.09063720703125
Epoch: 5, Steps: 124 Train Loss: 3.2131 (Forecasting Loss:0.2465 + XiCon Loss:2.9667 x Lambda(1.0)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1448
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1818857
	speed: 0.0252s/iter; left time: 294.0808s
Epoch: 6 cost time: 3.07159161567688
Epoch: 6, Steps: 124 Train Loss: 3.2060 (Forecasting Loss:0.2446 + XiCon Loss:2.9614 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1418
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2669129
	speed: 0.0258s/iter; left time: 298.1049s
Epoch: 7 cost time: 3.1558690071105957
Epoch: 7, Steps: 124 Train Loss: 3.2082 (Forecasting Loss:0.2436 + XiCon Loss:2.9645 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1430
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1618085
	speed: 0.0258s/iter; left time: 294.9842s
Epoch: 8 cost time: 3.160519599914551
Epoch: 8, Steps: 124 Train Loss: 3.1970 (Forecasting Loss:0.2433 + XiCon Loss:2.9537 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1431
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2634926
	speed: 0.0252s/iter; left time: 285.3808s
Epoch: 9 cost time: 3.12515926361084
Epoch: 9, Steps: 124 Train Loss: 3.2103 (Forecasting Loss:0.2427 + XiCon Loss:2.9677 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1430
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1539588
	speed: 0.0252s/iter; left time: 281.7473s
Epoch: 10 cost time: 3.0571911334991455
Epoch: 10, Steps: 124 Train Loss: 3.2003 (Forecasting Loss:0.2427 + XiCon Loss:2.9576 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1430
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1021419
	speed: 0.0251s/iter; left time: 277.6339s
Epoch: 11 cost time: 3.1006736755371094
Epoch: 11, Steps: 124 Train Loss: 3.1943 (Forecasting Loss:0.2429 + XiCon Loss:2.9515 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1431
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3290999
	speed: 0.0255s/iter; left time: 278.7111s
Epoch: 12 cost time: 3.172081232070923
Epoch: 12, Steps: 124 Train Loss: 3.2094 (Forecasting Loss:0.2427 + XiCon Loss:2.9667 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1431
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.0828230232000351, mae:0.22818030416965485, mape:0.17127260565757751, mspe:0.04911068454384804 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3192
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3008034
	speed: 0.0207s/iter; left time: 254.1509s
Epoch: 1 cost time: 2.5484466552734375
Epoch: 1, Steps: 124 Train Loss: 3.3438 (Forecasting Loss:0.2940 + XiCon Loss:3.0498 x Lambda(1.0)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1613
Validation loss decreased (inf --> 0.216891).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0596876
	speed: 0.0228s/iter; left time: 277.8286s
Epoch: 2 cost time: 2.8397653102874756
Epoch: 2, Steps: 124 Train Loss: 3.1592 (Forecasting Loss:0.2784 + XiCon Loss:2.8808 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1552
Validation loss decreased (0.216891 --> 0.208723).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2019036
	speed: 0.0220s/iter; left time: 264.7812s
Epoch: 3 cost time: 2.6534011363983154
Epoch: 3, Steps: 124 Train Loss: 3.2284 (Forecasting Loss:0.2594 + XiCon Loss:2.9690 x Lambda(1.0)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1448
Validation loss decreased (0.208723 --> 0.207850).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1480694
	speed: 0.0203s/iter; left time: 242.3932s
Epoch: 4 cost time: 2.4775803089141846
Epoch: 4, Steps: 124 Train Loss: 3.1950 (Forecasting Loss:0.2484 + XiCon Loss:2.9466 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1420
Validation loss decreased (0.207850 --> 0.202306).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0088208
	speed: 0.0208s/iter; left time: 245.1382s
Epoch: 5 cost time: 2.5247504711151123
Epoch: 5, Steps: 124 Train Loss: 3.1684 (Forecasting Loss:0.2433 + XiCon Loss:2.9251 x Lambda(1.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1403
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0371625
	speed: 0.0207s/iter; left time: 242.3391s
Epoch: 6 cost time: 2.553910970687866
Epoch: 6, Steps: 124 Train Loss: 3.1693 (Forecasting Loss:0.2416 + XiCon Loss:2.9278 x Lambda(1.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1420
Validation loss decreased (0.202306 --> 0.201160).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3347750
	speed: 0.0209s/iter; left time: 241.5724s
Epoch: 7 cost time: 2.5777170658111572
Epoch: 7, Steps: 124 Train Loss: 3.1551 (Forecasting Loss:0.2399 + XiCon Loss:2.9152 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1413
Validation loss decreased (0.201160 --> 0.200491).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2751074
	speed: 0.0212s/iter; left time: 242.5084s
Epoch: 8 cost time: 2.57149076461792
Epoch: 8, Steps: 124 Train Loss: 3.1710 (Forecasting Loss:0.2397 + XiCon Loss:2.9313 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1412
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1097908
	speed: 0.0211s/iter; left time: 238.2955s
Epoch: 9 cost time: 2.588714599609375
Epoch: 9, Steps: 124 Train Loss: 3.1469 (Forecasting Loss:0.2394 + XiCon Loss:2.9075 x Lambda(1.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1415
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1363785
	speed: 0.0210s/iter; left time: 234.7155s
Epoch: 10 cost time: 2.5956430435180664
Epoch: 10, Steps: 124 Train Loss: 3.1569 (Forecasting Loss:0.2396 + XiCon Loss:2.9174 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2788715
	speed: 0.0211s/iter; left time: 233.6840s
Epoch: 11 cost time: 2.5991570949554443
Epoch: 11, Steps: 124 Train Loss: 3.1545 (Forecasting Loss:0.2391 + XiCon Loss:2.9155 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1033843
	speed: 0.0210s/iter; left time: 229.4369s
Epoch: 12 cost time: 2.5515387058258057
Epoch: 12, Steps: 124 Train Loss: 3.1561 (Forecasting Loss:0.2389 + XiCon Loss:2.9172 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1417
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0512719
	speed: 0.0210s/iter; left time: 227.3252s
Epoch: 13 cost time: 2.620525360107422
Epoch: 13, Steps: 124 Train Loss: 3.1506 (Forecasting Loss:0.2391 + XiCon Loss:2.9115 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1417
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.0944698
	speed: 0.0210s/iter; left time: 224.6815s
Epoch: 14 cost time: 2.6105010509490967
Epoch: 14, Steps: 124 Train Loss: 3.1473 (Forecasting Loss:0.2393 + XiCon Loss:2.9080 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1417
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1208186
	speed: 0.0207s/iter; left time: 218.6571s
Epoch: 15 cost time: 2.533205270767212
Epoch: 15, Steps: 124 Train Loss: 3.1491 (Forecasting Loss:0.2392 + XiCon Loss:2.9099 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1417
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 2.9560897
	speed: 0.0211s/iter; left time: 219.9913s
Epoch: 16 cost time: 2.57619571685791
Epoch: 16, Steps: 124 Train Loss: 3.1620 (Forecasting Loss:0.2389 + XiCon Loss:2.9230 x Lambda(1.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1417
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0556085
	speed: 0.0212s/iter; left time: 218.2967s
Epoch: 17 cost time: 2.6083571910858154
Epoch: 17, Steps: 124 Train Loss: 3.1608 (Forecasting Loss:0.2388 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.0714210644364357, mae:0.2112531065940857, mape:0.16175179183483124, mspe:0.046220820397138596 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3098
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3301613
	speed: 0.0208s/iter; left time: 255.3129s
Epoch: 1 cost time: 2.540123224258423
Epoch: 1, Steps: 124 Train Loss: 3.3531 (Forecasting Loss:0.2967 + XiCon Loss:3.0564 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1586
Validation loss decreased (inf --> 0.214182).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1786876
	speed: 0.0237s/iter; left time: 288.5001s
Epoch: 2 cost time: 2.97418475151062
Epoch: 2, Steps: 124 Train Loss: 3.2390 (Forecasting Loss:0.2755 + XiCon Loss:2.9634 x Lambda(1.0)), Vali MSE Loss: 0.2337 Test MSE Loss: 0.1618
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2469025
	speed: 0.0289s/iter; left time: 348.3045s
Epoch: 3 cost time: 3.52266526222229
Epoch: 3, Steps: 124 Train Loss: 3.3094 (Forecasting Loss:0.2613 + XiCon Loss:3.0481 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1510
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2454312
	speed: 0.0275s/iter; left time: 327.9070s
Epoch: 4 cost time: 3.3849985599517822
Epoch: 4, Steps: 124 Train Loss: 3.2428 (Forecasting Loss:0.2489 + XiCon Loss:2.9939 x Lambda(1.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1488
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2619662
	speed: 0.0277s/iter; left time: 326.6607s
Epoch: 5 cost time: 3.380373477935791
Epoch: 5, Steps: 124 Train Loss: 3.2191 (Forecasting Loss:0.2444 + XiCon Loss:2.9747 x Lambda(1.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1442
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2304304
	speed: 0.0273s/iter; left time: 318.4449s
Epoch: 6 cost time: 3.358272075653076
Epoch: 6, Steps: 124 Train Loss: 3.2221 (Forecasting Loss:0.2427 + XiCon Loss:2.9795 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.1447
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1136560
	speed: 0.0279s/iter; left time: 321.9096s
Epoch: 7 cost time: 3.4523839950561523
Epoch: 7, Steps: 124 Train Loss: 3.2069 (Forecasting Loss:0.2412 + XiCon Loss:2.9658 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1441
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1195817
	speed: 0.0273s/iter; left time: 312.2514s
Epoch: 8 cost time: 3.3714966773986816
Epoch: 8, Steps: 124 Train Loss: 3.2103 (Forecasting Loss:0.2410 + XiCon Loss:2.9694 x Lambda(1.0)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1452
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2433066
	speed: 0.0270s/iter; left time: 305.5270s
Epoch: 9 cost time: 3.292174816131592
Epoch: 9, Steps: 124 Train Loss: 3.2140 (Forecasting Loss:0.2400 + XiCon Loss:2.9740 x Lambda(1.0)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1444
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1778977
	speed: 0.0271s/iter; left time: 303.3018s
Epoch: 10 cost time: 3.353991746902466
Epoch: 10, Steps: 124 Train Loss: 3.1989 (Forecasting Loss:0.2395 + XiCon Loss:2.9594 x Lambda(1.0)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1444
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1497824
	speed: 0.0265s/iter; left time: 293.0366s
Epoch: 11 cost time: 3.280285358428955
Epoch: 11, Steps: 124 Train Loss: 3.1967 (Forecasting Loss:0.2397 + XiCon Loss:2.9570 x Lambda(1.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1443
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08472855389118195, mae:0.23246708512306213, mape:0.17459248006343842, mspe:0.049459703266620636 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3338
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3133943
	speed: 0.0204s/iter; left time: 250.6096s
Epoch: 1 cost time: 2.4969069957733154
Epoch: 1, Steps: 124 Train Loss: 3.3467 (Forecasting Loss:0.3015 + XiCon Loss:3.0452 x Lambda(1.0)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1640
Validation loss decreased (inf --> 0.220167).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0680387
	speed: 0.0230s/iter; left time: 280.5283s
Epoch: 2 cost time: 2.9719600677490234
Epoch: 2, Steps: 124 Train Loss: 3.1729 (Forecasting Loss:0.2814 + XiCon Loss:2.8916 x Lambda(1.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.1563
Validation loss decreased (0.220167 --> 0.217992).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2950823
	speed: 0.0235s/iter; left time: 283.6626s
Epoch: 3 cost time: 2.884089946746826
Epoch: 3, Steps: 124 Train Loss: 3.3011 (Forecasting Loss:0.2638 + XiCon Loss:3.0373 x Lambda(1.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1539
Validation loss decreased (0.217992 --> 0.205456).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2520883
	speed: 0.0229s/iter; left time: 273.2156s
Epoch: 4 cost time: 2.8298985958099365
Epoch: 4, Steps: 124 Train Loss: 3.2738 (Forecasting Loss:0.2511 + XiCon Loss:3.0226 x Lambda(1.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1502
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2513800
	speed: 0.0226s/iter; left time: 266.2737s
Epoch: 5 cost time: 2.7577314376831055
Epoch: 5, Steps: 124 Train Loss: 3.2281 (Forecasting Loss:0.2469 + XiCon Loss:2.9812 x Lambda(1.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1492
Validation loss decreased (0.205456 --> 0.203966).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3057301
	speed: 0.0222s/iter; left time: 259.8399s
Epoch: 6 cost time: 2.736393928527832
Epoch: 6, Steps: 124 Train Loss: 3.2151 (Forecasting Loss:0.2443 + XiCon Loss:2.9708 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1501
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1642690
	speed: 0.0220s/iter; left time: 254.5713s
Epoch: 7 cost time: 2.7313709259033203
Epoch: 7, Steps: 124 Train Loss: 3.2064 (Forecasting Loss:0.2435 + XiCon Loss:2.9629 x Lambda(1.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1500
Validation loss decreased (0.203966 --> 0.202580).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1949968
	speed: 0.0226s/iter; left time: 258.8551s
Epoch: 8 cost time: 2.7792532444000244
Epoch: 8, Steps: 124 Train Loss: 3.2190 (Forecasting Loss:0.2430 + XiCon Loss:2.9760 x Lambda(1.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1497
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1618772
	speed: 0.0224s/iter; left time: 253.4353s
Epoch: 9 cost time: 2.763936996459961
Epoch: 9, Steps: 124 Train Loss: 3.2108 (Forecasting Loss:0.2425 + XiCon Loss:2.9683 x Lambda(1.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1494
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1280551
	speed: 0.0232s/iter; left time: 259.8837s
Epoch: 10 cost time: 2.807304620742798
Epoch: 10, Steps: 124 Train Loss: 3.2070 (Forecasting Loss:0.2424 + XiCon Loss:2.9646 x Lambda(1.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1493
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1192813
	speed: 0.0225s/iter; left time: 248.7006s
Epoch: 11 cost time: 2.760868787765503
Epoch: 11, Steps: 124 Train Loss: 3.2104 (Forecasting Loss:0.2424 + XiCon Loss:2.9680 x Lambda(1.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1494
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1961458
	speed: 0.0231s/iter; left time: 253.1885s
Epoch: 12 cost time: 2.8364596366882324
Epoch: 12, Steps: 124 Train Loss: 3.2066 (Forecasting Loss:0.2423 + XiCon Loss:2.9644 x Lambda(1.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1494
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3371985
	speed: 0.0230s/iter; left time: 249.0530s
Epoch: 13 cost time: 2.8379900455474854
Epoch: 13, Steps: 124 Train Loss: 3.2190 (Forecasting Loss:0.2422 + XiCon Loss:2.9768 x Lambda(1.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1494
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.0760317
	speed: 0.0226s/iter; left time: 241.1797s
Epoch: 14 cost time: 2.7769827842712402
Epoch: 14, Steps: 124 Train Loss: 3.2199 (Forecasting Loss:0.2421 + XiCon Loss:2.9779 x Lambda(1.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1495
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2516191
	speed: 0.0224s/iter; left time: 236.5690s
Epoch: 15 cost time: 2.7998104095458984
Epoch: 15, Steps: 124 Train Loss: 3.2134 (Forecasting Loss:0.2424 + XiCon Loss:2.9710 x Lambda(1.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1495
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2256896
	speed: 0.0223s/iter; left time: 232.6799s
Epoch: 16 cost time: 2.7268381118774414
Epoch: 16, Steps: 124 Train Loss: 3.2226 (Forecasting Loss:0.2421 + XiCon Loss:2.9805 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1495
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0821099
	speed: 0.0223s/iter; left time: 229.6975s
Epoch: 17 cost time: 2.730555295944214
Epoch: 17, Steps: 124 Train Loss: 3.2112 (Forecasting Loss:0.2423 + XiCon Loss:2.9689 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1495
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07927554845809937, mae:0.22078783810138702, mape:0.1649191677570343, mspe:0.0452137216925621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0792+-0.00640, MAE:0.2225+-0.01018, MAPE:0.1677+-0.00639, MSPE:0.0476+-0.00228, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4133
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4888010
	speed: 0.0488s/iter; left time: 571.4522s
Epoch: 1 cost time: 5.717514514923096
Epoch: 1, Steps: 118 Train Loss: 3.5136 (Forecasting Loss:0.3608 + XiCon Loss:3.1528 x Lambda(1.0)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1717
Validation loss decreased (inf --> 0.261130).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3991635
	speed: 0.0488s/iter; left time: 565.5972s
Epoch: 2 cost time: 5.759640216827393
Epoch: 2, Steps: 118 Train Loss: 3.3749 (Forecasting Loss:0.3123 + XiCon Loss:3.0626 x Lambda(1.0)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.1574
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.6515620
	speed: 0.0497s/iter; left time: 570.2926s
Epoch: 3 cost time: 5.825925350189209
Epoch: 3, Steps: 118 Train Loss: 3.5055 (Forecasting Loss:0.2817 + XiCon Loss:3.2238 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1526
Validation loss decreased (0.261130 --> 0.248458).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3409808
	speed: 0.0485s/iter; left time: 550.7148s
Epoch: 4 cost time: 5.736258268356323
Epoch: 4, Steps: 118 Train Loss: 3.4484 (Forecasting Loss:0.2748 + XiCon Loss:3.1736 x Lambda(1.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1570
Validation loss decreased (0.248458 --> 0.232094).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3778279
	speed: 0.0489s/iter; left time: 548.9192s
Epoch: 5 cost time: 5.732016324996948
Epoch: 5, Steps: 118 Train Loss: 3.4206 (Forecasting Loss:0.2676 + XiCon Loss:3.1530 x Lambda(1.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.1555
Validation loss decreased (0.232094 --> 0.230944).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3870401
	speed: 0.0483s/iter; left time: 536.9681s
Epoch: 6 cost time: 5.749584674835205
Epoch: 6, Steps: 118 Train Loss: 3.4038 (Forecasting Loss:0.2635 + XiCon Loss:3.1403 x Lambda(1.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1507
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4566920
	speed: 0.0560s/iter; left time: 615.4446s
Epoch: 7 cost time: 6.407122373580933
Epoch: 7, Steps: 118 Train Loss: 3.3849 (Forecasting Loss:0.2613 + XiCon Loss:3.1236 x Lambda(1.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.1511
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4349880
	speed: 0.0834s/iter; left time: 906.8030s
Epoch: 8 cost time: 9.939486742019653
Epoch: 8, Steps: 118 Train Loss: 3.3876 (Forecasting Loss:0.2611 + XiCon Loss:3.1265 x Lambda(1.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1507
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3742974
	speed: 0.0873s/iter; left time: 939.0533s
Epoch: 9 cost time: 10.765706777572632
Epoch: 9, Steps: 118 Train Loss: 3.3877 (Forecasting Loss:0.2602 + XiCon Loss:3.1275 x Lambda(1.0)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1505
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3806551
	speed: 0.1062s/iter; left time: 1129.3717s
Epoch: 10 cost time: 12.478432178497314
Epoch: 10, Steps: 118 Train Loss: 3.3870 (Forecasting Loss:0.2607 + XiCon Loss:3.1263 x Lambda(1.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1503
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4760833
	speed: 0.0911s/iter; left time: 958.9616s
Epoch: 11 cost time: 10.741331338882446
Epoch: 11, Steps: 118 Train Loss: 3.3829 (Forecasting Loss:0.2598 + XiCon Loss:3.1231 x Lambda(1.0)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.1504
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4925103
	speed: 0.0809s/iter; left time: 841.5944s
Epoch: 12 cost time: 9.421268224716187
Epoch: 12, Steps: 118 Train Loss: 3.3703 (Forecasting Loss:0.2601 + XiCon Loss:3.1102 x Lambda(1.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1504
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4209201
	speed: 0.0630s/iter; left time: 648.3330s
Epoch: 13 cost time: 7.298308610916138
Epoch: 13, Steps: 118 Train Loss: 3.3835 (Forecasting Loss:0.2603 + XiCon Loss:3.1231 x Lambda(1.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1504
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4013665
	speed: 0.0496s/iter; left time: 503.7878s
Epoch: 14 cost time: 5.7871716022491455
Epoch: 14, Steps: 118 Train Loss: 3.3818 (Forecasting Loss:0.2600 + XiCon Loss:3.1218 x Lambda(1.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1504
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2507856
	speed: 0.0479s/iter; left time: 481.3515s
Epoch: 15 cost time: 5.6388349533081055
Epoch: 15, Steps: 118 Train Loss: 3.3784 (Forecasting Loss:0.2594 + XiCon Loss:3.1190 x Lambda(1.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08325120806694031, mae:0.2277429699897766, mape:0.16667410731315613, mspe:0.0458245575428009 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4972
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4696014
	speed: 0.0423s/iter; left time: 495.5356s
Epoch: 1 cost time: 5.041179180145264
Epoch: 1, Steps: 118 Train Loss: 3.5101 (Forecasting Loss:0.3604 + XiCon Loss:3.1498 x Lambda(1.0)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1695
Validation loss decreased (inf --> 0.265294).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4337764
	speed: 0.0469s/iter; left time: 543.4037s
Epoch: 2 cost time: 5.597955226898193
Epoch: 2, Steps: 118 Train Loss: 3.4072 (Forecasting Loss:0.3076 + XiCon Loss:3.0995 x Lambda(1.0)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1471
Validation loss decreased (0.265294 --> 0.227629).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5778682
	speed: 0.0555s/iter; left time: 636.4728s
Epoch: 3 cost time: 6.4641101360321045
Epoch: 3, Steps: 118 Train Loss: 3.5377 (Forecasting Loss:0.2762 + XiCon Loss:3.2615 x Lambda(1.0)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4872909
	speed: 0.0485s/iter; left time: 550.1193s
Epoch: 4 cost time: 5.716545581817627
Epoch: 4, Steps: 118 Train Loss: 3.5003 (Forecasting Loss:0.2605 + XiCon Loss:3.2398 x Lambda(1.0)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1364
Validation loss decreased (0.227629 --> 0.214459).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5919881
	speed: 0.0545s/iter; left time: 612.5312s
Epoch: 5 cost time: 6.396177291870117
Epoch: 5, Steps: 118 Train Loss: 3.4713 (Forecasting Loss:0.2527 + XiCon Loss:3.2186 x Lambda(1.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.1365
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3889484
	speed: 0.0490s/iter; left time: 544.2692s
Epoch: 6 cost time: 5.821685314178467
Epoch: 6, Steps: 118 Train Loss: 3.4501 (Forecasting Loss:0.2502 + XiCon Loss:3.1999 x Lambda(1.0)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3498664
	speed: 0.0557s/iter; left time: 612.1218s
Epoch: 7 cost time: 6.513108968734741
Epoch: 7, Steps: 118 Train Loss: 3.4436 (Forecasting Loss:0.2487 + XiCon Loss:3.1949 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1354
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5371337
	speed: 0.0517s/iter; left time: 562.4325s
Epoch: 8 cost time: 6.075924873352051
Epoch: 8, Steps: 118 Train Loss: 3.4336 (Forecasting Loss:0.2479 + XiCon Loss:3.1857 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3806486
	speed: 0.0506s/iter; left time: 544.6050s
Epoch: 9 cost time: 5.938365459442139
Epoch: 9, Steps: 118 Train Loss: 3.4221 (Forecasting Loss:0.2472 + XiCon Loss:3.1749 x Lambda(1.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.1354
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4352744
	speed: 0.0545s/iter; left time: 579.5057s
Epoch: 10 cost time: 6.361704111099243
Epoch: 10, Steps: 118 Train Loss: 3.4272 (Forecasting Loss:0.2474 + XiCon Loss:3.1799 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1354
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4642653
	speed: 0.0515s/iter; left time: 541.6912s
Epoch: 11 cost time: 6.136965036392212
Epoch: 11, Steps: 118 Train Loss: 3.4239 (Forecasting Loss:0.2468 + XiCon Loss:3.1771 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4297776
	speed: 0.0528s/iter; left time: 549.2650s
Epoch: 12 cost time: 6.219336986541748
Epoch: 12, Steps: 118 Train Loss: 3.4343 (Forecasting Loss:0.2471 + XiCon Loss:3.1872 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1357
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.6650276
	speed: 0.0540s/iter; left time: 555.2970s
Epoch: 13 cost time: 6.319717884063721
Epoch: 13, Steps: 118 Train Loss: 3.4404 (Forecasting Loss:0.2469 + XiCon Loss:3.1935 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1356
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3938787
	speed: 0.0504s/iter; left time: 512.6265s
Epoch: 14 cost time: 5.928005695343018
Epoch: 14, Steps: 118 Train Loss: 3.4390 (Forecasting Loss:0.2471 + XiCon Loss:3.1919 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1356
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.06638679653406143, mae:0.206457257270813, mape:0.15478265285491943, mspe:0.04036673530936241 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3745
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.5024145
	speed: 0.0466s/iter; left time: 545.3679s
Epoch: 1 cost time: 5.511063098907471
Epoch: 1, Steps: 118 Train Loss: 3.5120 (Forecasting Loss:0.3565 + XiCon Loss:3.1555 x Lambda(1.0)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.1706
Validation loss decreased (inf --> 0.261499).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2302082
	speed: 0.0736s/iter; left time: 852.6869s
Epoch: 2 cost time: 8.867791414260864
Epoch: 2, Steps: 118 Train Loss: 3.3044 (Forecasting Loss:0.3340 + XiCon Loss:2.9704 x Lambda(1.0)), Vali MSE Loss: 0.3009 Test MSE Loss: 0.1631
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4869704
	speed: 0.0593s/iter; left time: 680.3976s
Epoch: 3 cost time: 7.093106269836426
Epoch: 3, Steps: 118 Train Loss: 3.4042 (Forecasting Loss:0.2854 + XiCon Loss:3.1188 x Lambda(1.0)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.1504
Validation loss decreased (0.261499 --> 0.228011).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4053626
	speed: 0.0609s/iter; left time: 690.8685s
Epoch: 4 cost time: 7.203336238861084
Epoch: 4, Steps: 118 Train Loss: 3.4021 (Forecasting Loss:0.2722 + XiCon Loss:3.1298 x Lambda(1.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1512
Validation loss decreased (0.228011 --> 0.220500).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5123749
	speed: 0.0601s/iter; left time: 674.6695s
Epoch: 5 cost time: 7.129779100418091
Epoch: 5, Steps: 118 Train Loss: 3.3748 (Forecasting Loss:0.2642 + XiCon Loss:3.1106 x Lambda(1.0)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1525
Validation loss decreased (0.220500 --> 0.220185).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2927279
	speed: 0.0676s/iter; left time: 750.6390s
Epoch: 6 cost time: 7.906262159347534
Epoch: 6, Steps: 118 Train Loss: 3.3560 (Forecasting Loss:0.2603 + XiCon Loss:3.0957 x Lambda(1.0)), Vali MSE Loss: 0.2231 Test MSE Loss: 0.1505
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2576358
	speed: 0.0678s/iter; left time: 745.4810s
Epoch: 7 cost time: 7.895398855209351
Epoch: 7, Steps: 118 Train Loss: 3.3540 (Forecasting Loss:0.2582 + XiCon Loss:3.0959 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1510
Validation loss decreased (0.220185 --> 0.219137).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2713213
	speed: 0.0627s/iter; left time: 681.3924s
Epoch: 8 cost time: 7.372692823410034
Epoch: 8, Steps: 118 Train Loss: 3.3417 (Forecasting Loss:0.2569 + XiCon Loss:3.0849 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1502
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2785339
	speed: 0.0619s/iter; left time: 665.7938s
Epoch: 9 cost time: 7.2699432373046875
Epoch: 9, Steps: 118 Train Loss: 3.3399 (Forecasting Loss:0.2561 + XiCon Loss:3.0839 x Lambda(1.0)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1494
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3540926
	speed: 0.0637s/iter; left time: 677.8769s
Epoch: 10 cost time: 7.444688558578491
Epoch: 10, Steps: 118 Train Loss: 3.3287 (Forecasting Loss:0.2559 + XiCon Loss:3.0729 x Lambda(1.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1504
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4656937
	speed: 0.0638s/iter; left time: 670.8557s
Epoch: 11 cost time: 7.451271057128906
Epoch: 11, Steps: 118 Train Loss: 3.3531 (Forecasting Loss:0.2562 + XiCon Loss:3.0969 x Lambda(1.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.1504
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3429675
	speed: 0.0639s/iter; left time: 664.6951s
Epoch: 12 cost time: 7.460658311843872
Epoch: 12, Steps: 118 Train Loss: 3.3424 (Forecasting Loss:0.2559 + XiCon Loss:3.0865 x Lambda(1.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1503
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4844797
	speed: 0.0632s/iter; left time: 649.7755s
Epoch: 13 cost time: 7.463048696517944
Epoch: 13, Steps: 118 Train Loss: 3.3441 (Forecasting Loss:0.2557 + XiCon Loss:3.0884 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1502
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2696173
	speed: 0.0664s/iter; left time: 674.7549s
Epoch: 14 cost time: 7.8265581130981445
Epoch: 14, Steps: 118 Train Loss: 3.3479 (Forecasting Loss:0.2559 + XiCon Loss:3.0919 x Lambda(1.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1502
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2843931
	speed: 0.0634s/iter; left time: 637.5335s
Epoch: 15 cost time: 7.453199625015259
Epoch: 15, Steps: 118 Train Loss: 3.3400 (Forecasting Loss:0.2558 + XiCon Loss:3.0842 x Lambda(1.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.1502
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3566694
	speed: 0.0618s/iter; left time: 613.6220s
Epoch: 16 cost time: 7.342850208282471
Epoch: 16, Steps: 118 Train Loss: 3.3427 (Forecasting Loss:0.2558 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1502
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4108510
	speed: 0.0620s/iter; left time: 608.6810s
Epoch: 17 cost time: 7.279515027999878
Epoch: 17, Steps: 118 Train Loss: 3.3344 (Forecasting Loss:0.2557 + XiCon Loss:3.0786 x Lambda(1.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07829025387763977, mae:0.22361108660697937, mape:0.16667500138282776, mspe:0.04692268744111061 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3799
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4839368
	speed: 0.0464s/iter; left time: 543.1149s
Epoch: 1 cost time: 5.511384010314941
Epoch: 1, Steps: 118 Train Loss: 3.4986 (Forecasting Loss:0.3553 + XiCon Loss:3.1433 x Lambda(1.0)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1688
Validation loss decreased (inf --> 0.259323).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4321887
	speed: 0.0486s/iter; left time: 563.3642s
Epoch: 2 cost time: 5.8439621925354
Epoch: 2, Steps: 118 Train Loss: 3.3711 (Forecasting Loss:0.3201 + XiCon Loss:3.0510 x Lambda(1.0)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1572
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4546728
	speed: 0.0641s/iter; left time: 735.0810s
Epoch: 3 cost time: 7.592485189437866
Epoch: 3, Steps: 118 Train Loss: 3.5139 (Forecasting Loss:0.2847 + XiCon Loss:3.2292 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1538
Validation loss decreased (0.259323 --> 0.249623).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6018584
	speed: 0.0680s/iter; left time: 771.6201s
Epoch: 4 cost time: 8.045963287353516
Epoch: 4, Steps: 118 Train Loss: 3.4442 (Forecasting Loss:0.2737 + XiCon Loss:3.1705 x Lambda(1.0)), Vali MSE Loss: 0.2372 Test MSE Loss: 0.1432
Validation loss decreased (0.249623 --> 0.237233).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3817854
	speed: 0.0679s/iter; left time: 762.2497s
Epoch: 5 cost time: 8.017024517059326
Epoch: 5, Steps: 118 Train Loss: 3.3772 (Forecasting Loss:0.2641 + XiCon Loss:3.1131 x Lambda(1.0)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1432
Validation loss decreased (0.237233 --> 0.229616).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.5305231
	speed: 0.0701s/iter; left time: 778.8087s
Epoch: 6 cost time: 8.262194633483887
Epoch: 6, Steps: 118 Train Loss: 3.3714 (Forecasting Loss:0.2594 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1413
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4770966
	speed: 0.0764s/iter; left time: 839.6815s
Epoch: 7 cost time: 9.08591914176941
Epoch: 7, Steps: 118 Train Loss: 3.3511 (Forecasting Loss:0.2571 + XiCon Loss:3.0941 x Lambda(1.0)), Vali MSE Loss: 0.2333 Test MSE Loss: 0.1410
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3203285
	speed: 0.0739s/iter; left time: 803.9449s
Epoch: 8 cost time: 8.63645315170288
Epoch: 8, Steps: 118 Train Loss: 3.3627 (Forecasting Loss:0.2563 + XiCon Loss:3.1064 x Lambda(1.0)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1412
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3641648
	speed: 0.0704s/iter; left time: 757.5356s
Epoch: 9 cost time: 8.488960981369019
Epoch: 9, Steps: 118 Train Loss: 3.3406 (Forecasting Loss:0.2558 + XiCon Loss:3.0849 x Lambda(1.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.1409
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3069317
	speed: 0.0729s/iter; left time: 775.6604s
Epoch: 10 cost time: 8.590014457702637
Epoch: 10, Steps: 118 Train Loss: 3.3485 (Forecasting Loss:0.2556 + XiCon Loss:3.0929 x Lambda(1.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1409
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5082026
	speed: 0.0707s/iter; left time: 743.9436s
Epoch: 11 cost time: 8.402971744537354
Epoch: 11, Steps: 118 Train Loss: 3.3523 (Forecasting Loss:0.2553 + XiCon Loss:3.0970 x Lambda(1.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2832272
	speed: 0.0704s/iter; left time: 732.6221s
Epoch: 12 cost time: 8.259770631790161
Epoch: 12, Steps: 118 Train Loss: 3.3450 (Forecasting Loss:0.2551 + XiCon Loss:3.0899 x Lambda(1.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1408
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2943969
	speed: 0.0685s/iter; left time: 704.1507s
Epoch: 13 cost time: 8.068389654159546
Epoch: 13, Steps: 118 Train Loss: 3.3476 (Forecasting Loss:0.2553 + XiCon Loss:3.0923 x Lambda(1.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1407
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4770288
	speed: 0.0716s/iter; left time: 727.8839s
Epoch: 14 cost time: 8.409390687942505
Epoch: 14, Steps: 118 Train Loss: 3.3376 (Forecasting Loss:0.2557 + XiCon Loss:3.0818 x Lambda(1.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1407
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3626130
	speed: 0.0742s/iter; left time: 745.5787s
Epoch: 15 cost time: 8.873791217803955
Epoch: 15, Steps: 118 Train Loss: 3.3448 (Forecasting Loss:0.2551 + XiCon Loss:3.0896 x Lambda(1.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1407
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07233956456184387, mae:0.21415133774280548, mape:0.16044464707374573, mspe:0.04391704127192497 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3368
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4793737
	speed: 0.0476s/iter; left time: 557.2375s
Epoch: 1 cost time: 5.589940786361694
Epoch: 1, Steps: 118 Train Loss: 3.5056 (Forecasting Loss:0.3577 + XiCon Loss:3.1479 x Lambda(1.0)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.1677
Validation loss decreased (inf --> 0.259132).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4514153
	speed: 0.0625s/iter; left time: 723.9179s
Epoch: 2 cost time: 7.643216609954834
Epoch: 2, Steps: 118 Train Loss: 3.3928 (Forecasting Loss:0.3037 + XiCon Loss:3.0892 x Lambda(1.0)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.1479
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4516702
	speed: 0.0781s/iter; left time: 895.3860s
Epoch: 3 cost time: 9.17326021194458
Epoch: 3, Steps: 118 Train Loss: 3.5695 (Forecasting Loss:0.2714 + XiCon Loss:3.2981 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1445
Validation loss decreased (0.259132 --> 0.252646).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6445010
	speed: 0.0716s/iter; left time: 812.8184s
Epoch: 4 cost time: 8.649775266647339
Epoch: 4, Steps: 118 Train Loss: 3.5157 (Forecasting Loss:0.2622 + XiCon Loss:3.2535 x Lambda(1.0)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4505746
	speed: 0.0768s/iter; left time: 862.7257s
Epoch: 5 cost time: 8.97021484375
Epoch: 5, Steps: 118 Train Loss: 3.4643 (Forecasting Loss:0.2565 + XiCon Loss:3.2078 x Lambda(1.0)), Vali MSE Loss: 0.2563 Test MSE Loss: 0.1411
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3110330
	speed: 0.0684s/iter; left time: 760.2955s
Epoch: 6 cost time: 8.071154594421387
Epoch: 6, Steps: 118 Train Loss: 3.4317 (Forecasting Loss:0.2541 + XiCon Loss:3.1776 x Lambda(1.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.1403
Validation loss decreased (0.252646 --> 0.252328).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5241606
	speed: 0.0751s/iter; left time: 825.2417s
Epoch: 7 cost time: 8.761196851730347
Epoch: 7, Steps: 118 Train Loss: 3.4307 (Forecasting Loss:0.2517 + XiCon Loss:3.1791 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1410
Validation loss decreased (0.252328 --> 0.251786).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4365790
	speed: 0.0695s/iter; left time: 756.0028s
Epoch: 8 cost time: 8.254939794540405
Epoch: 8, Steps: 118 Train Loss: 3.4287 (Forecasting Loss:0.2512 + XiCon Loss:3.1775 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1419
Validation loss decreased (0.251786 --> 0.249861).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4702108
	speed: 0.0723s/iter; left time: 777.4033s
Epoch: 9 cost time: 8.435762643814087
Epoch: 9, Steps: 118 Train Loss: 3.4117 (Forecasting Loss:0.2505 + XiCon Loss:3.1612 x Lambda(1.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.1412
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2848623
	speed: 0.0695s/iter; left time: 739.8376s
Epoch: 10 cost time: 8.242719650268555
Epoch: 10, Steps: 118 Train Loss: 3.4087 (Forecasting Loss:0.2500 + XiCon Loss:3.1587 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1410
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2970586
	speed: 0.0723s/iter; left time: 760.2086s
Epoch: 11 cost time: 8.614727973937988
Epoch: 11, Steps: 118 Train Loss: 3.4061 (Forecasting Loss:0.2499 + XiCon Loss:3.1563 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.1411
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3914950
	speed: 0.0733s/iter; left time: 762.5750s
Epoch: 12 cost time: 8.645042657852173
Epoch: 12, Steps: 118 Train Loss: 3.4180 (Forecasting Loss:0.2502 + XiCon Loss:3.1678 x Lambda(1.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.1412
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5813696
	speed: 0.0674s/iter; left time: 692.8509s
Epoch: 13 cost time: 7.960225343704224
Epoch: 13, Steps: 118 Train Loss: 3.4143 (Forecasting Loss:0.2499 + XiCon Loss:3.1644 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1412
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4498188
	speed: 0.0738s/iter; left time: 750.0476s
Epoch: 14 cost time: 8.659346103668213
Epoch: 14, Steps: 118 Train Loss: 3.4123 (Forecasting Loss:0.2496 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1413
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4963851
	speed: 0.0689s/iter; left time: 692.0154s
Epoch: 15 cost time: 8.105413913726807
Epoch: 15, Steps: 118 Train Loss: 3.4143 (Forecasting Loss:0.2502 + XiCon Loss:3.1641 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1413
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4056706
	speed: 0.0730s/iter; left time: 725.2551s
Epoch: 16 cost time: 8.56562089920044
Epoch: 16, Steps: 118 Train Loss: 3.4182 (Forecasting Loss:0.2498 + XiCon Loss:3.1684 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1413
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.6392217
	speed: 0.0678s/iter; left time: 665.8118s
Epoch: 17 cost time: 8.045967817306519
Epoch: 17, Steps: 118 Train Loss: 3.4166 (Forecasting Loss:0.2499 + XiCon Loss:3.1668 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1413
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5281899
	speed: 0.0741s/iter; left time: 718.4341s
Epoch: 18 cost time: 8.668434381484985
Epoch: 18, Steps: 118 Train Loss: 3.4130 (Forecasting Loss:0.2504 + XiCon Loss:3.1625 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1413
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07199529558420181, mae:0.21190160512924194, mape:0.15667816996574402, mspe:0.0413052998483181 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0745+-0.00804, MAE:0.2168+-0.01083, MAPE:0.1611+-0.00686, MSPE:0.0437+-0.00350, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3886
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2474489
	speed: 0.0183s/iter; left time: 231.9530s
Epoch: 1 cost time: 2.232297658920288
Epoch: 1, Steps: 128 Train Loss: 3.3352 (Forecasting Loss:0.2930 + XiCon Loss:3.0422 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.277077).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0703812
	speed: 0.0146s/iter; left time: 183.0421s
Epoch: 2 cost time: 1.859665870666504
Epoch: 2, Steps: 128 Train Loss: 3.1159 (Forecasting Loss:0.2572 + XiCon Loss:2.8586 x Lambda(1.0)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.2210
Validation loss decreased (0.277077 --> 0.259237).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2401886
	speed: 0.0151s/iter; left time: 187.7915s
Epoch: 3 cost time: 1.895432949066162
Epoch: 3, Steps: 128 Train Loss: 3.2054 (Forecasting Loss:0.2424 + XiCon Loss:2.9630 x Lambda(1.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2169
Validation loss decreased (0.259237 --> 0.251301).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1405563
	speed: 0.0153s/iter; left time: 188.2336s
Epoch: 4 cost time: 1.897472620010376
Epoch: 4, Steps: 128 Train Loss: 3.2118 (Forecasting Loss:0.2363 + XiCon Loss:2.9754 x Lambda(1.0)), Vali MSE Loss: 0.2553 Test MSE Loss: 0.2055
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1301370
	speed: 0.0152s/iter; left time: 185.0978s
Epoch: 5 cost time: 1.885120153427124
Epoch: 5, Steps: 128 Train Loss: 3.1937 (Forecasting Loss:0.2334 + XiCon Loss:2.9603 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2043
Validation loss decreased (0.251301 --> 0.249406).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1519408
	speed: 0.0152s/iter; left time: 183.3534s
Epoch: 6 cost time: 1.8999030590057373
Epoch: 6, Steps: 128 Train Loss: 3.1701 (Forecasting Loss:0.2316 + XiCon Loss:2.9385 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2025
Validation loss decreased (0.249406 --> 0.248783).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1785648
	speed: 0.0146s/iter; left time: 174.7834s
Epoch: 7 cost time: 1.837982177734375
Epoch: 7, Steps: 128 Train Loss: 3.1517 (Forecasting Loss:0.2304 + XiCon Loss:2.9213 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2031
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0821857
	speed: 0.0147s/iter; left time: 173.6506s
Epoch: 8 cost time: 1.8423867225646973
Epoch: 8, Steps: 128 Train Loss: 3.1503 (Forecasting Loss:0.2302 + XiCon Loss:2.9201 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2025
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0714581
	speed: 0.0147s/iter; left time: 172.0586s
Epoch: 9 cost time: 1.8385465145111084
Epoch: 9, Steps: 128 Train Loss: 3.1466 (Forecasting Loss:0.2302 + XiCon Loss:2.9164 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2018
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1102729
	speed: 0.0150s/iter; left time: 173.5288s
Epoch: 10 cost time: 1.8670618534088135
Epoch: 10, Steps: 128 Train Loss: 3.1542 (Forecasting Loss:0.2300 + XiCon Loss:2.9241 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2020
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0411406
	speed: 0.0149s/iter; left time: 169.9633s
Epoch: 11 cost time: 1.8469350337982178
Epoch: 11, Steps: 128 Train Loss: 3.1534 (Forecasting Loss:0.2300 + XiCon Loss:2.9235 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2020
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2363987
	speed: 0.0158s/iter; left time: 178.7892s
Epoch: 12 cost time: 1.949376106262207
Epoch: 12, Steps: 128 Train Loss: 3.1503 (Forecasting Loss:0.2299 + XiCon Loss:2.9203 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2019
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0983016
	speed: 0.0147s/iter; left time: 163.9278s
Epoch: 13 cost time: 1.869253396987915
Epoch: 13, Steps: 128 Train Loss: 3.1544 (Forecasting Loss:0.2299 + XiCon Loss:2.9245 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2019
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2205927
	speed: 0.0139s/iter; left time: 153.0361s
Epoch: 14 cost time: 1.7412257194519043
Epoch: 14, Steps: 128 Train Loss: 3.1554 (Forecasting Loss:0.2297 + XiCon Loss:2.9257 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2019
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1463060
	speed: 0.0147s/iter; left time: 160.8069s
Epoch: 15 cost time: 1.840029001235962
Epoch: 15, Steps: 128 Train Loss: 3.1519 (Forecasting Loss:0.2297 + XiCon Loss:2.9222 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2019
Validation loss decreased (0.248783 --> 0.248634).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1094031
	speed: 0.0152s/iter; left time: 164.3074s
Epoch: 16 cost time: 1.9202709197998047
Epoch: 16, Steps: 128 Train Loss: 3.1543 (Forecasting Loss:0.2299 + XiCon Loss:2.9245 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2019
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1532555
	speed: 0.0159s/iter; left time: 169.5564s
Epoch: 17 cost time: 1.9923932552337646
Epoch: 17, Steps: 128 Train Loss: 3.1572 (Forecasting Loss:0.2299 + XiCon Loss:2.9273 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2019
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.0773940
	speed: 0.0147s/iter; left time: 155.0820s
Epoch: 18 cost time: 1.9142351150512695
Epoch: 18, Steps: 128 Train Loss: 3.1542 (Forecasting Loss:0.2299 + XiCon Loss:2.9242 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2019
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1393251
	speed: 0.0152s/iter; left time: 158.3230s
Epoch: 19 cost time: 1.8989641666412354
Epoch: 19, Steps: 128 Train Loss: 3.1468 (Forecasting Loss:0.2299 + XiCon Loss:2.9169 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2019
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0834126
	speed: 0.0151s/iter; left time: 154.5891s
Epoch: 20 cost time: 1.9115228652954102
Epoch: 20, Steps: 128 Train Loss: 3.1505 (Forecasting Loss:0.2299 + XiCon Loss:2.9207 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2019
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0706935
	speed: 0.0149s/iter; left time: 151.1921s
Epoch: 21 cost time: 1.8787841796875
Epoch: 21, Steps: 128 Train Loss: 3.1495 (Forecasting Loss:0.2296 + XiCon Loss:2.9199 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2019
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2063403
	speed: 0.0147s/iter; left time: 147.0820s
Epoch: 22 cost time: 1.8810701370239258
Epoch: 22, Steps: 128 Train Loss: 3.1553 (Forecasting Loss:0.2299 + XiCon Loss:2.9254 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2019
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1534686
	speed: 0.0152s/iter; left time: 150.4553s
Epoch: 23 cost time: 1.8990890979766846
Epoch: 23, Steps: 128 Train Loss: 3.1639 (Forecasting Loss:0.2299 + XiCon Loss:2.9340 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2019
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.0869410
	speed: 0.0147s/iter; left time: 143.0044s
Epoch: 24 cost time: 1.8232731819152832
Epoch: 24, Steps: 128 Train Loss: 3.1450 (Forecasting Loss:0.2298 + XiCon Loss:2.9152 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2019
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1324265
	speed: 0.0154s/iter; left time: 148.6623s
Epoch: 25 cost time: 1.9191114902496338
Epoch: 25, Steps: 128 Train Loss: 3.1581 (Forecasting Loss:0.2298 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2019
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.12723976373672485, mae:0.27661585807800293, mape:0.6670562624931335, mspe:19.433576583862305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2746
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2637029
	speed: 0.0151s/iter; left time: 191.7125s
Epoch: 1 cost time: 1.8874356746673584
Epoch: 1, Steps: 128 Train Loss: 3.3361 (Forecasting Loss:0.2935 + XiCon Loss:3.0426 x Lambda(1.0)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.2275
Validation loss decreased (inf --> 0.274910).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1613891
	speed: 0.0145s/iter; left time: 182.3685s
Epoch: 2 cost time: 1.8326349258422852
Epoch: 2, Steps: 128 Train Loss: 3.1573 (Forecasting Loss:0.2545 + XiCon Loss:2.9028 x Lambda(1.0)), Vali MSE Loss: 0.2668 Test MSE Loss: 0.2214
Validation loss decreased (0.274910 --> 0.266755).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1202118
	speed: 0.0162s/iter; left time: 201.2649s
Epoch: 3 cost time: 2.028452157974243
Epoch: 3, Steps: 128 Train Loss: 3.1505 (Forecasting Loss:0.2391 + XiCon Loss:2.9114 x Lambda(1.0)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.2190
Validation loss decreased (0.266755 --> 0.266627).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1083229
	speed: 0.0149s/iter; left time: 183.7065s
Epoch: 4 cost time: 1.9242525100708008
Epoch: 4, Steps: 128 Train Loss: 3.1071 (Forecasting Loss:0.2323 + XiCon Loss:2.8748 x Lambda(1.0)), Vali MSE Loss: 0.2543 Test MSE Loss: 0.2155
Validation loss decreased (0.266627 --> 0.254267).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0844097
	speed: 0.0147s/iter; left time: 179.7732s
Epoch: 5 cost time: 1.8642981052398682
Epoch: 5, Steps: 128 Train Loss: 3.0876 (Forecasting Loss:0.2279 + XiCon Loss:2.8598 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.2107
Validation loss decreased (0.254267 --> 0.245667).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1144378
	speed: 0.0148s/iter; left time: 178.0860s
Epoch: 6 cost time: 1.865112543106079
Epoch: 6, Steps: 128 Train Loss: 3.0755 (Forecasting Loss:0.2251 + XiCon Loss:2.8504 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.2130
Validation loss decreased (0.245667 --> 0.243739).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0334182
	speed: 0.0158s/iter; left time: 188.2926s
Epoch: 7 cost time: 1.9451231956481934
Epoch: 7, Steps: 128 Train Loss: 3.0769 (Forecasting Loss:0.2229 + XiCon Loss:2.8539 x Lambda(1.0)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.2114
Validation loss decreased (0.243739 --> 0.243174).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0226307
	speed: 0.0148s/iter; left time: 174.6727s
Epoch: 8 cost time: 1.8531301021575928
Epoch: 8, Steps: 128 Train Loss: 3.0700 (Forecasting Loss:0.2219 + XiCon Loss:2.8481 x Lambda(1.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.2127
Validation loss decreased (0.243174 --> 0.242804).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1595211
	speed: 0.0147s/iter; left time: 172.0127s
Epoch: 9 cost time: 1.8557326793670654
Epoch: 9, Steps: 128 Train Loss: 3.0688 (Forecasting Loss:0.2218 + XiCon Loss:2.8470 x Lambda(1.0)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.2123
Validation loss decreased (0.242804 --> 0.242372).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0434623
	speed: 0.0150s/iter; left time: 173.6335s
Epoch: 10 cost time: 1.8835151195526123
Epoch: 10, Steps: 128 Train Loss: 3.0635 (Forecasting Loss:0.2216 + XiCon Loss:2.8419 x Lambda(1.0)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.2122
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2217319
	speed: 0.0143s/iter; left time: 163.2209s
Epoch: 11 cost time: 1.8162260055541992
Epoch: 11, Steps: 128 Train Loss: 3.0749 (Forecasting Loss:0.2216 + XiCon Loss:2.8533 x Lambda(1.0)), Vali MSE Loss: 0.2429 Test MSE Loss: 0.2122
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0350552
	speed: 0.0145s/iter; left time: 164.0402s
Epoch: 12 cost time: 1.8364572525024414
Epoch: 12, Steps: 128 Train Loss: 3.0662 (Forecasting Loss:0.2215 + XiCon Loss:2.8447 x Lambda(1.0)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.2122
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1444647
	speed: 0.0157s/iter; left time: 174.8035s
Epoch: 13 cost time: 1.927537441253662
Epoch: 13, Steps: 128 Train Loss: 3.0676 (Forecasting Loss:0.2211 + XiCon Loss:2.8465 x Lambda(1.0)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.2122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1389787
	speed: 0.0147s/iter; left time: 162.6536s
Epoch: 14 cost time: 1.8407323360443115
Epoch: 14, Steps: 128 Train Loss: 3.0655 (Forecasting Loss:0.2213 + XiCon Loss:2.8441 x Lambda(1.0)), Vali MSE Loss: 0.2421 Test MSE Loss: 0.2121
Validation loss decreased (0.242372 --> 0.242090).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0206258
	speed: 0.0159s/iter; left time: 173.0378s
Epoch: 15 cost time: 2.0192437171936035
Epoch: 15, Steps: 128 Train Loss: 3.0701 (Forecasting Loss:0.2208 + XiCon Loss:2.8494 x Lambda(1.0)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.2121
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0544248
	speed: 0.0151s/iter; left time: 162.4689s
Epoch: 16 cost time: 1.8747458457946777
Epoch: 16, Steps: 128 Train Loss: 3.0721 (Forecasting Loss:0.2208 + XiCon Loss:2.8514 x Lambda(1.0)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.2121
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0563633
	speed: 0.0140s/iter; left time: 148.7813s
Epoch: 17 cost time: 1.7970221042633057
Epoch: 17, Steps: 128 Train Loss: 3.0608 (Forecasting Loss:0.2211 + XiCon Loss:2.8397 x Lambda(1.0)), Vali MSE Loss: 0.2430 Test MSE Loss: 0.2121
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.0461304
	speed: 0.0150s/iter; left time: 157.9825s
Epoch: 18 cost time: 1.8830225467681885
Epoch: 18, Steps: 128 Train Loss: 3.0672 (Forecasting Loss:0.2208 + XiCon Loss:2.8463 x Lambda(1.0)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.2121
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0278645
	speed: 0.0151s/iter; left time: 156.5165s
Epoch: 19 cost time: 1.860560655593872
Epoch: 19, Steps: 128 Train Loss: 3.0684 (Forecasting Loss:0.2215 + XiCon Loss:2.8469 x Lambda(1.0)), Vali MSE Loss: 0.2430 Test MSE Loss: 0.2121
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0249634
	speed: 0.0149s/iter; left time: 153.4978s
Epoch: 20 cost time: 1.880478858947754
Epoch: 20, Steps: 128 Train Loss: 3.0622 (Forecasting Loss:0.2210 + XiCon Loss:2.8412 x Lambda(1.0)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.2121
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 2.9694090
	speed: 0.0151s/iter; left time: 153.4206s
Epoch: 21 cost time: 1.9102425575256348
Epoch: 21, Steps: 128 Train Loss: 3.0736 (Forecasting Loss:0.2213 + XiCon Loss:2.8522 x Lambda(1.0)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.2121
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.0347250
	speed: 0.0154s/iter; left time: 154.3172s
Epoch: 22 cost time: 1.9379806518554688
Epoch: 22, Steps: 128 Train Loss: 3.0664 (Forecasting Loss:0.2213 + XiCon Loss:2.8451 x Lambda(1.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.2121
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.0150955
	speed: 0.0148s/iter; left time: 146.0198s
Epoch: 23 cost time: 1.8887712955474854
Epoch: 23, Steps: 128 Train Loss: 3.0698 (Forecasting Loss:0.2209 + XiCon Loss:2.8489 x Lambda(1.0)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.2121
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.0540318
	speed: 0.0154s/iter; left time: 150.2670s
Epoch: 24 cost time: 1.9427905082702637
Epoch: 24, Steps: 128 Train Loss: 3.0671 (Forecasting Loss:0.2212 + XiCon Loss:2.8459 x Lambda(1.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.2121
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13649882376194, mae:0.28777292370796204, mape:0.7121532559394836, mspe:21.46742820739746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3539
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3227482
	speed: 0.0145s/iter; left time: 183.5611s
Epoch: 1 cost time: 1.8164844512939453
Epoch: 1, Steps: 128 Train Loss: 3.3297 (Forecasting Loss:0.2969 + XiCon Loss:3.0328 x Lambda(1.0)), Vali MSE Loss: 0.2754 Test MSE Loss: 0.2282
Validation loss decreased (inf --> 0.275377).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1101055
	speed: 0.0164s/iter; left time: 206.2108s
Epoch: 2 cost time: 2.0423128604888916
Epoch: 2, Steps: 128 Train Loss: 3.1248 (Forecasting Loss:0.2553 + XiCon Loss:2.8695 x Lambda(1.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.2204
Validation loss decreased (0.275377 --> 0.269607).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2497301
	speed: 0.0156s/iter; left time: 193.8972s
Epoch: 3 cost time: 1.927018165588379
Epoch: 3, Steps: 128 Train Loss: 3.2029 (Forecasting Loss:0.2449 + XiCon Loss:2.9580 x Lambda(1.0)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.2013
Validation loss decreased (0.269607 --> 0.259788).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2664373
	speed: 0.0148s/iter; left time: 182.2895s
Epoch: 4 cost time: 1.8497297763824463
Epoch: 4, Steps: 128 Train Loss: 3.2189 (Forecasting Loss:0.2372 + XiCon Loss:2.9816 x Lambda(1.0)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2044
Validation loss decreased (0.259788 --> 0.254430).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2118344
	speed: 0.0150s/iter; left time: 182.7149s
Epoch: 5 cost time: 1.9195060729980469
Epoch: 5, Steps: 128 Train Loss: 3.1920 (Forecasting Loss:0.2339 + XiCon Loss:2.9581 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.2086
Validation loss decreased (0.254430 --> 0.253629).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1715803
	speed: 0.0156s/iter; left time: 187.5752s
Epoch: 6 cost time: 1.9265332221984863
Epoch: 6, Steps: 128 Train Loss: 3.1759 (Forecasting Loss:0.2320 + XiCon Loss:2.9438 x Lambda(1.0)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.2043
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1334984
	speed: 0.0146s/iter; left time: 174.6884s
Epoch: 7 cost time: 1.9143095016479492
Epoch: 7, Steps: 128 Train Loss: 3.1699 (Forecasting Loss:0.2313 + XiCon Loss:2.9386 x Lambda(1.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.2066
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2092109
	speed: 0.0150s/iter; left time: 177.4926s
Epoch: 8 cost time: 1.9470763206481934
Epoch: 8, Steps: 128 Train Loss: 3.1672 (Forecasting Loss:0.2308 + XiCon Loss:2.9365 x Lambda(1.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2044
Validation loss decreased (0.253629 --> 0.253191).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1208963
	speed: 0.0142s/iter; left time: 165.4653s
Epoch: 9 cost time: 1.7784833908081055
Epoch: 9, Steps: 128 Train Loss: 3.1590 (Forecasting Loss:0.2306 + XiCon Loss:2.9285 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.2049
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2702038
	speed: 0.0152s/iter; left time: 175.4200s
Epoch: 10 cost time: 1.875246286392212
Epoch: 10, Steps: 128 Train Loss: 3.1602 (Forecasting Loss:0.2304 + XiCon Loss:2.9298 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2047
Validation loss decreased (0.253191 --> 0.252851).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3059666
	speed: 0.0148s/iter; left time: 169.2873s
Epoch: 11 cost time: 1.8886587619781494
Epoch: 11, Steps: 128 Train Loss: 3.1608 (Forecasting Loss:0.2303 + XiCon Loss:2.9305 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2048
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0753627
	speed: 0.0153s/iter; left time: 172.7817s
Epoch: 12 cost time: 1.92911958694458
Epoch: 12, Steps: 128 Train Loss: 3.1573 (Forecasting Loss:0.2301 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.2049
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0926330
	speed: 0.0156s/iter; left time: 174.1743s
Epoch: 13 cost time: 1.9912219047546387
Epoch: 13, Steps: 128 Train Loss: 3.1610 (Forecasting Loss:0.2304 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.2049
Validation loss decreased (0.252851 --> 0.252846).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2818105
	speed: 0.0143s/iter; left time: 158.1689s
Epoch: 14 cost time: 1.796328067779541
Epoch: 14, Steps: 128 Train Loss: 3.1607 (Forecasting Loss:0.2302 + XiCon Loss:2.9305 x Lambda(1.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2048
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1455262
	speed: 0.0145s/iter; left time: 158.0450s
Epoch: 15 cost time: 1.823439359664917
Epoch: 15, Steps: 128 Train Loss: 3.1613 (Forecasting Loss:0.2304 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2048
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1121905
	speed: 0.0148s/iter; left time: 159.2051s
Epoch: 16 cost time: 1.8202784061431885
Epoch: 16, Steps: 128 Train Loss: 3.1670 (Forecasting Loss:0.2304 + XiCon Loss:2.9366 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.2048
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1189435
	speed: 0.0145s/iter; left time: 154.1223s
Epoch: 17 cost time: 1.8083951473236084
Epoch: 17, Steps: 128 Train Loss: 3.1567 (Forecasting Loss:0.2301 + XiCon Loss:2.9265 x Lambda(1.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2048
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2357562
	speed: 0.0144s/iter; left time: 151.9123s
Epoch: 18 cost time: 1.8535666465759277
Epoch: 18, Steps: 128 Train Loss: 3.1661 (Forecasting Loss:0.2302 + XiCon Loss:2.9360 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2048
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1545768
	speed: 0.0147s/iter; left time: 152.5746s
Epoch: 19 cost time: 1.8369460105895996
Epoch: 19, Steps: 128 Train Loss: 3.1645 (Forecasting Loss:0.2301 + XiCon Loss:2.9344 x Lambda(1.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2048
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1864424
	speed: 0.0151s/iter; left time: 155.3275s
Epoch: 20 cost time: 1.872192621231079
Epoch: 20, Steps: 128 Train Loss: 3.1598 (Forecasting Loss:0.2302 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2048
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1577976
	speed: 0.0154s/iter; left time: 156.4661s
Epoch: 21 cost time: 1.9321765899658203
Epoch: 21, Steps: 128 Train Loss: 3.1604 (Forecasting Loss:0.2305 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.2530 Test MSE Loss: 0.2048
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1673255
	speed: 0.0142s/iter; left time: 142.2995s
Epoch: 22 cost time: 1.8063595294952393
Epoch: 22, Steps: 128 Train Loss: 3.1596 (Forecasting Loss:0.2302 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2048
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1602147
	speed: 0.0154s/iter; left time: 152.5818s
Epoch: 23 cost time: 1.9455602169036865
Epoch: 23, Steps: 128 Train Loss: 3.1558 (Forecasting Loss:0.2303 + XiCon Loss:2.9255 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2048
Validation loss decreased (0.252846 --> 0.252400).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1314249
	speed: 0.0153s/iter; left time: 149.0940s
Epoch: 24 cost time: 1.9267592430114746
Epoch: 24, Steps: 128 Train Loss: 3.1549 (Forecasting Loss:0.2301 + XiCon Loss:2.9248 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.2048
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2132170
	speed: 0.0153s/iter; left time: 146.9587s
Epoch: 25 cost time: 1.8837416172027588
Epoch: 25, Steps: 128 Train Loss: 3.1615 (Forecasting Loss:0.2304 + XiCon Loss:2.9311 x Lambda(1.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2048
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1203372
	speed: 0.0148s/iter; left time: 140.4563s
Epoch: 26 cost time: 1.8792195320129395
Epoch: 26, Steps: 128 Train Loss: 3.1536 (Forecasting Loss:0.2303 + XiCon Loss:2.9234 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.2048
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1484962
	speed: 0.0151s/iter; left time: 141.6852s
Epoch: 27 cost time: 1.9028654098510742
Epoch: 27, Steps: 128 Train Loss: 3.1538 (Forecasting Loss:0.2304 + XiCon Loss:2.9235 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2048
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1055317
	speed: 0.0150s/iter; left time: 138.6517s
Epoch: 28 cost time: 1.895601511001587
Epoch: 28, Steps: 128 Train Loss: 3.1677 (Forecasting Loss:0.2303 + XiCon Loss:2.9374 x Lambda(1.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2048
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1371191
	speed: 0.0149s/iter; left time: 135.3988s
Epoch: 29 cost time: 1.8700950145721436
Epoch: 29, Steps: 128 Train Loss: 3.1600 (Forecasting Loss:0.2303 + XiCon Loss:2.9297 x Lambda(1.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2048
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.0700765
	speed: 0.0147s/iter; left time: 132.2001s
Epoch: 30 cost time: 1.8610360622406006
Epoch: 30, Steps: 128 Train Loss: 3.1614 (Forecasting Loss:0.2303 + XiCon Loss:2.9311 x Lambda(1.0)), Vali MSE Loss: 0.2530 Test MSE Loss: 0.2048
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1738145
	speed: 0.0152s/iter; left time: 134.2720s
Epoch: 31 cost time: 1.9271156787872314
Epoch: 31, Steps: 128 Train Loss: 3.1594 (Forecasting Loss:0.2303 + XiCon Loss:2.9291 x Lambda(1.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2048
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1729648
	speed: 0.0156s/iter; left time: 136.1060s
Epoch: 32 cost time: 1.9408206939697266
Epoch: 32, Steps: 128 Train Loss: 3.1644 (Forecasting Loss:0.2303 + XiCon Loss:2.9341 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2048
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.1372476
	speed: 0.0150s/iter; left time: 128.6746s
Epoch: 33 cost time: 1.877626657485962
Epoch: 33, Steps: 128 Train Loss: 3.1526 (Forecasting Loss:0.2302 + XiCon Loss:2.9223 x Lambda(1.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2048
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.12890522181987762, mae:0.28073740005493164, mape:0.6948382258415222, mspe:20.790002822875977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3278
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2764571
	speed: 0.0147s/iter; left time: 187.1588s
Epoch: 1 cost time: 1.841599941253662
Epoch: 1, Steps: 128 Train Loss: 3.3432 (Forecasting Loss:0.2953 + XiCon Loss:3.0479 x Lambda(1.0)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2309
Validation loss decreased (inf --> 0.273268).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0852714
	speed: 0.0156s/iter; left time: 195.9856s
Epoch: 2 cost time: 1.944735050201416
Epoch: 2, Steps: 128 Train Loss: 3.1476 (Forecasting Loss:0.2553 + XiCon Loss:2.8923 x Lambda(1.0)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.2137
Validation loss decreased (0.273268 --> 0.263197).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1201298
	speed: 0.0155s/iter; left time: 192.2963s
Epoch: 3 cost time: 1.9154152870178223
Epoch: 3, Steps: 128 Train Loss: 3.2070 (Forecasting Loss:0.2424 + XiCon Loss:2.9646 x Lambda(1.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.2085
Validation loss decreased (0.263197 --> 0.254204).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0763125
	speed: 0.0155s/iter; left time: 190.5250s
Epoch: 4 cost time: 1.9483957290649414
Epoch: 4, Steps: 128 Train Loss: 3.1370 (Forecasting Loss:0.2345 + XiCon Loss:2.9025 x Lambda(1.0)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.2092
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1399815
	speed: 0.0160s/iter; left time: 194.9939s
Epoch: 5 cost time: 1.944718837738037
Epoch: 5, Steps: 128 Train Loss: 3.1108 (Forecasting Loss:0.2309 + XiCon Loss:2.8799 x Lambda(1.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2039
Validation loss decreased (0.254204 --> 0.251272).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1913674
	speed: 0.0154s/iter; left time: 185.9693s
Epoch: 6 cost time: 1.9038233757019043
Epoch: 6, Steps: 128 Train Loss: 3.1027 (Forecasting Loss:0.2283 + XiCon Loss:2.8743 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2079
Validation loss decreased (0.251272 --> 0.250231).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0944114
	speed: 0.0158s/iter; left time: 187.9673s
Epoch: 7 cost time: 1.9900050163269043
Epoch: 7, Steps: 128 Train Loss: 3.0893 (Forecasting Loss:0.2264 + XiCon Loss:2.8628 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2063
Validation loss decreased (0.250231 --> 0.249545).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1802466
	speed: 0.0159s/iter; left time: 187.2047s
Epoch: 8 cost time: 2.0032100677490234
Epoch: 8, Steps: 128 Train Loss: 3.0882 (Forecasting Loss:0.2258 + XiCon Loss:2.8624 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2064
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0542009
	speed: 0.0152s/iter; left time: 177.7540s
Epoch: 9 cost time: 1.8864319324493408
Epoch: 9, Steps: 128 Train Loss: 3.1002 (Forecasting Loss:0.2255 + XiCon Loss:2.8747 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2067
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0298362
	speed: 0.0150s/iter; left time: 172.6926s
Epoch: 10 cost time: 1.8536460399627686
Epoch: 10, Steps: 128 Train Loss: 3.0887 (Forecasting Loss:0.2251 + XiCon Loss:2.8635 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2066
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1605761
	speed: 0.0158s/iter; left time: 180.1675s
Epoch: 11 cost time: 1.9901447296142578
Epoch: 11, Steps: 128 Train Loss: 3.0969 (Forecasting Loss:0.2251 + XiCon Loss:2.8718 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2067
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1883776
	speed: 0.0151s/iter; left time: 170.7534s
Epoch: 12 cost time: 1.8948214054107666
Epoch: 12, Steps: 128 Train Loss: 3.0895 (Forecasting Loss:0.2253 + XiCon Loss:2.8643 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2067
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0834436
	speed: 0.0151s/iter; left time: 168.2243s
Epoch: 13 cost time: 1.90928053855896
Epoch: 13, Steps: 128 Train Loss: 3.0855 (Forecasting Loss:0.2252 + XiCon Loss:2.8604 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2067
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1038690
	speed: 0.0149s/iter; left time: 164.1127s
Epoch: 14 cost time: 1.868448257446289
Epoch: 14, Steps: 128 Train Loss: 3.0825 (Forecasting Loss:0.2254 + XiCon Loss:2.8571 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2067
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0415630
	speed: 0.0150s/iter; left time: 163.1940s
Epoch: 15 cost time: 1.8890180587768555
Epoch: 15, Steps: 128 Train Loss: 3.0952 (Forecasting Loss:0.2244 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2067
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0811369
	speed: 0.0139s/iter; left time: 149.6470s
Epoch: 16 cost time: 1.779123306274414
Epoch: 16, Steps: 128 Train Loss: 3.0938 (Forecasting Loss:0.2254 + XiCon Loss:2.8684 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2067
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0197437
	speed: 0.0160s/iter; left time: 170.0711s
Epoch: 17 cost time: 2.0086731910705566
Epoch: 17, Steps: 128 Train Loss: 3.0892 (Forecasting Loss:0.2249 + XiCon Loss:2.8643 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2067
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13201159238815308, mae:0.2805377244949341, mape:0.656840980052948, mspe:19.10843849182129 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3132
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2855575
	speed: 0.0153s/iter; left time: 194.8672s
Epoch: 1 cost time: 1.9154186248779297
Epoch: 1, Steps: 128 Train Loss: 3.3457 (Forecasting Loss:0.2960 + XiCon Loss:3.0497 x Lambda(1.0)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2282
Validation loss decreased (inf --> 0.273092).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1517546
	speed: 0.0153s/iter; left time: 192.9199s
Epoch: 2 cost time: 1.9368760585784912
Epoch: 2, Steps: 128 Train Loss: 3.1628 (Forecasting Loss:0.2543 + XiCon Loss:2.9085 x Lambda(1.0)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2224
Validation loss decreased (0.273092 --> 0.258478).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3186884
	speed: 0.0145s/iter; left time: 180.5831s
Epoch: 3 cost time: 1.8417017459869385
Epoch: 3, Steps: 128 Train Loss: 3.2551 (Forecasting Loss:0.2422 + XiCon Loss:3.0128 x Lambda(1.0)), Vali MSE Loss: 0.2572 Test MSE Loss: 0.2190
Validation loss decreased (0.258478 --> 0.257221).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2173600
	speed: 0.0148s/iter; left time: 182.8771s
Epoch: 4 cost time: 1.8524730205535889
Epoch: 4, Steps: 128 Train Loss: 3.3039 (Forecasting Loss:0.2363 + XiCon Loss:3.0676 x Lambda(1.0)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.2044
Validation loss decreased (0.257221 --> 0.251359).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2859197
	speed: 0.0155s/iter; left time: 188.4229s
Epoch: 5 cost time: 1.9345648288726807
Epoch: 5, Steps: 128 Train Loss: 3.2951 (Forecasting Loss:0.2328 + XiCon Loss:3.0623 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2087
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1364565
	speed: 0.0150s/iter; left time: 181.4181s
Epoch: 6 cost time: 1.8747620582580566
Epoch: 6, Steps: 128 Train Loss: 3.2687 (Forecasting Loss:0.2309 + XiCon Loss:3.0378 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2074
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1804161
	speed: 0.0155s/iter; left time: 184.6069s
Epoch: 7 cost time: 1.9116590023040771
Epoch: 7, Steps: 128 Train Loss: 3.2720 (Forecasting Loss:0.2303 + XiCon Loss:3.0417 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2079
Validation loss decreased (0.251359 --> 0.250938).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1473627
	speed: 0.0144s/iter; left time: 170.4174s
Epoch: 8 cost time: 1.799241304397583
Epoch: 8, Steps: 128 Train Loss: 3.2776 (Forecasting Loss:0.2300 + XiCon Loss:3.0476 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2074
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2569673
	speed: 0.0158s/iter; left time: 184.5605s
Epoch: 9 cost time: 1.9844295978546143
Epoch: 9, Steps: 128 Train Loss: 3.2610 (Forecasting Loss:0.2296 + XiCon Loss:3.0314 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2073
Validation loss decreased (0.250938 --> 0.250751).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1677475
	speed: 0.0140s/iter; left time: 161.3480s
Epoch: 10 cost time: 1.7430756092071533
Epoch: 10, Steps: 128 Train Loss: 3.2689 (Forecasting Loss:0.2296 + XiCon Loss:3.0393 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2071
Validation loss decreased (0.250751 --> 0.250544).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1282203
	speed: 0.0149s/iter; left time: 170.5589s
Epoch: 11 cost time: 1.8416800498962402
Epoch: 11, Steps: 128 Train Loss: 3.2770 (Forecasting Loss:0.2293 + XiCon Loss:3.0477 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2071
Validation loss decreased (0.250544 --> 0.250177).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2166641
	speed: 0.0162s/iter; left time: 182.7171s
Epoch: 12 cost time: 1.9838571548461914
Epoch: 12, Steps: 128 Train Loss: 3.2702 (Forecasting Loss:0.2294 + XiCon Loss:3.0408 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2071
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2105777
	speed: 0.0150s/iter; left time: 167.7727s
Epoch: 13 cost time: 1.9009807109832764
Epoch: 13, Steps: 128 Train Loss: 3.2727 (Forecasting Loss:0.2294 + XiCon Loss:3.0432 x Lambda(1.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.2070
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2141540
	speed: 0.0154s/iter; left time: 170.3930s
Epoch: 14 cost time: 1.951500654220581
Epoch: 14, Steps: 128 Train Loss: 3.2689 (Forecasting Loss:0.2294 + XiCon Loss:3.0395 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2070
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2508636
	speed: 0.0148s/iter; left time: 161.0522s
Epoch: 15 cost time: 1.851900339126587
Epoch: 15, Steps: 128 Train Loss: 3.2716 (Forecasting Loss:0.2294 + XiCon Loss:3.0422 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2070
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2079556
	speed: 0.0153s/iter; left time: 164.9175s
Epoch: 16 cost time: 1.904597520828247
Epoch: 16, Steps: 128 Train Loss: 3.2695 (Forecasting Loss:0.2292 + XiCon Loss:3.0402 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2070
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1905639
	speed: 0.0147s/iter; left time: 156.4891s
Epoch: 17 cost time: 1.8267991542816162
Epoch: 17, Steps: 128 Train Loss: 3.2700 (Forecasting Loss:0.2294 + XiCon Loss:3.0406 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2070
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2955427
	speed: 0.0151s/iter; left time: 158.7052s
Epoch: 18 cost time: 1.8947124481201172
Epoch: 18, Steps: 128 Train Loss: 3.2781 (Forecasting Loss:0.2293 + XiCon Loss:3.0488 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2070
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1078382
	speed: 0.0153s/iter; left time: 158.8368s
Epoch: 19 cost time: 1.9300308227539062
Epoch: 19, Steps: 128 Train Loss: 3.2772 (Forecasting Loss:0.2293 + XiCon Loss:3.0479 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2070
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2459571
	speed: 0.0143s/iter; left time: 146.7581s
Epoch: 20 cost time: 1.7703094482421875
Epoch: 20, Steps: 128 Train Loss: 3.2784 (Forecasting Loss:0.2293 + XiCon Loss:3.0490 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2070
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2069037
	speed: 0.0152s/iter; left time: 153.9469s
Epoch: 21 cost time: 1.8958756923675537
Epoch: 21, Steps: 128 Train Loss: 3.2740 (Forecasting Loss:0.2294 + XiCon Loss:3.0446 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2070
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13241758942604065, mae:0.28175294399261475, mape:0.6613895893096924, mspe:19.713869094848633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1314+-0.00443, MAE:0.2815+-0.00500, MAPE:0.6785+-0.02972, MSPE:20.1027+-1.22955, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4148
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3454857
	speed: 0.0196s/iter; left time: 244.8398s
Epoch: 1 cost time: 2.3333628177642822
Epoch: 1, Steps: 126 Train Loss: 3.3651 (Forecasting Loss:0.3209 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.2701
Validation loss decreased (inf --> 0.310676).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1618805
	speed: 0.0180s/iter; left time: 222.4657s
Epoch: 2 cost time: 2.2387638092041016
Epoch: 2, Steps: 126 Train Loss: 3.1585 (Forecasting Loss:0.2931 + XiCon Loss:2.8654 x Lambda(1.0)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.2548
Validation loss decreased (0.310676 --> 0.301393).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1975546
	speed: 0.0175s/iter; left time: 213.8890s
Epoch: 3 cost time: 2.15761399269104
Epoch: 3, Steps: 126 Train Loss: 3.1168 (Forecasting Loss:0.2799 + XiCon Loss:2.8369 x Lambda(1.0)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.2601
Validation loss decreased (0.301393 --> 0.293605).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2271030
	speed: 0.0181s/iter; left time: 219.0221s
Epoch: 4 cost time: 2.251596212387085
Epoch: 4, Steps: 126 Train Loss: 3.2661 (Forecasting Loss:0.2722 + XiCon Loss:2.9939 x Lambda(1.0)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.2481
Validation loss decreased (0.293605 --> 0.292525).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5200436
	speed: 0.0182s/iter; left time: 218.5524s
Epoch: 5 cost time: 2.2400901317596436
Epoch: 5, Steps: 126 Train Loss: 3.3259 (Forecasting Loss:0.2697 + XiCon Loss:3.0563 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2460
Validation loss decreased (0.292525 --> 0.290154).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3916674
	speed: 0.0181s/iter; left time: 215.2409s
Epoch: 6 cost time: 2.306380033493042
Epoch: 6, Steps: 126 Train Loss: 3.3448 (Forecasting Loss:0.2680 + XiCon Loss:3.0768 x Lambda(1.0)), Vali MSE Loss: 0.2915 Test MSE Loss: 0.2474
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3367143
	speed: 0.0177s/iter; left time: 208.3546s
Epoch: 7 cost time: 2.2097761631011963
Epoch: 7, Steps: 126 Train Loss: 3.3349 (Forecasting Loss:0.2670 + XiCon Loss:3.0679 x Lambda(1.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.2467
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4471698
	speed: 0.0184s/iter; left time: 213.7935s
Epoch: 8 cost time: 2.289116382598877
Epoch: 8, Steps: 126 Train Loss: 3.3448 (Forecasting Loss:0.2666 + XiCon Loss:3.0783 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2458
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3925614
	speed: 0.0184s/iter; left time: 211.0067s
Epoch: 9 cost time: 2.289980173110962
Epoch: 9, Steps: 126 Train Loss: 3.3369 (Forecasting Loss:0.2663 + XiCon Loss:3.0706 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2462
Validation loss decreased (0.290154 --> 0.290104).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2838116
	speed: 0.0191s/iter; left time: 216.8395s
Epoch: 10 cost time: 2.3658559322357178
Epoch: 10, Steps: 126 Train Loss: 3.3329 (Forecasting Loss:0.2660 + XiCon Loss:3.0669 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2462
Validation loss decreased (0.290104 --> 0.289953).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5434377
	speed: 0.0185s/iter; left time: 208.0370s
Epoch: 11 cost time: 2.2890870571136475
Epoch: 11, Steps: 126 Train Loss: 3.3347 (Forecasting Loss:0.2660 + XiCon Loss:3.0687 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2938023
	speed: 0.0180s/iter; left time: 200.1276s
Epoch: 12 cost time: 2.2525508403778076
Epoch: 12, Steps: 126 Train Loss: 3.3476 (Forecasting Loss:0.2659 + XiCon Loss:3.0817 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
Validation loss decreased (0.289953 --> 0.289951).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3902969
	speed: 0.0180s/iter; left time: 198.3330s
Epoch: 13 cost time: 2.259617805480957
Epoch: 13, Steps: 126 Train Loss: 3.3357 (Forecasting Loss:0.2662 + XiCon Loss:3.0696 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2437110
	speed: 0.0180s/iter; left time: 195.5905s
Epoch: 14 cost time: 2.242112398147583
Epoch: 14, Steps: 126 Train Loss: 3.3382 (Forecasting Loss:0.2658 + XiCon Loss:3.0724 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4532435
	speed: 0.0182s/iter; left time: 195.5130s
Epoch: 15 cost time: 2.258634567260742
Epoch: 15, Steps: 126 Train Loss: 3.3207 (Forecasting Loss:0.2659 + XiCon Loss:3.0548 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
Validation loss decreased (0.289951 --> 0.289900).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3083670
	speed: 0.0188s/iter; left time: 199.6538s
Epoch: 16 cost time: 2.3745551109313965
Epoch: 16, Steps: 126 Train Loss: 3.3350 (Forecasting Loss:0.2660 + XiCon Loss:3.0689 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2898164
	speed: 0.0182s/iter; left time: 190.9524s
Epoch: 17 cost time: 2.2680745124816895
Epoch: 17, Steps: 126 Train Loss: 3.3418 (Forecasting Loss:0.2660 + XiCon Loss:3.0758 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2821558
	speed: 0.0181s/iter; left time: 187.0220s
Epoch: 18 cost time: 2.23392915725708
Epoch: 18, Steps: 126 Train Loss: 3.3429 (Forecasting Loss:0.2660 + XiCon Loss:3.0768 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.5071383
	speed: 0.0188s/iter; left time: 192.3546s
Epoch: 19 cost time: 2.330869674682617
Epoch: 19, Steps: 126 Train Loss: 3.3338 (Forecasting Loss:0.2656 + XiCon Loss:3.0682 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2892148
	speed: 0.0180s/iter; left time: 181.9734s
Epoch: 20 cost time: 2.252674102783203
Epoch: 20, Steps: 126 Train Loss: 3.3455 (Forecasting Loss:0.2658 + XiCon Loss:3.0797 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2976596
	speed: 0.0183s/iter; left time: 183.1213s
Epoch: 21 cost time: 2.2704098224639893
Epoch: 21, Steps: 126 Train Loss: 3.3292 (Forecasting Loss:0.2661 + XiCon Loss:3.0631 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4043872
	speed: 0.0186s/iter; left time: 183.4795s
Epoch: 22 cost time: 2.311439275741577
Epoch: 22, Steps: 126 Train Loss: 3.3318 (Forecasting Loss:0.2658 + XiCon Loss:3.0660 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5311172
	speed: 0.0185s/iter; left time: 180.1829s
Epoch: 23 cost time: 2.2933473587036133
Epoch: 23, Steps: 126 Train Loss: 3.3474 (Forecasting Loss:0.2656 + XiCon Loss:3.0818 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4256911
	speed: 0.0183s/iter; left time: 175.5122s
Epoch: 24 cost time: 2.312133550643921
Epoch: 24, Steps: 126 Train Loss: 3.3355 (Forecasting Loss:0.2659 + XiCon Loss:3.0697 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
Validation loss decreased (0.289900 --> 0.289892).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4357631
	speed: 0.0185s/iter; left time: 175.7789s
Epoch: 25 cost time: 2.315798044204712
Epoch: 25, Steps: 126 Train Loss: 3.3309 (Forecasting Loss:0.2659 + XiCon Loss:3.0650 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
Validation loss decreased (0.289892 --> 0.289892).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2009590
	speed: 0.0193s/iter; left time: 180.5147s
Epoch: 26 cost time: 2.353789806365967
Epoch: 26, Steps: 126 Train Loss: 3.3266 (Forecasting Loss:0.2656 + XiCon Loss:3.0610 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3516107
	speed: 0.0190s/iter; left time: 175.4526s
Epoch: 27 cost time: 2.38267183303833
Epoch: 27, Steps: 126 Train Loss: 3.3274 (Forecasting Loss:0.2658 + XiCon Loss:3.0616 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
Validation loss decreased (0.289892 --> 0.289888).  Saving model ...
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.4246202
	speed: 0.0177s/iter; left time: 161.2174s
Epoch: 28 cost time: 2.2437150478363037
Epoch: 28, Steps: 126 Train Loss: 3.3304 (Forecasting Loss:0.2657 + XiCon Loss:3.0647 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.4369025
	speed: 0.0188s/iter; left time: 168.5870s
Epoch: 29 cost time: 2.334005117416382
Epoch: 29, Steps: 126 Train Loss: 3.3381 (Forecasting Loss:0.2660 + XiCon Loss:3.0721 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2461
Validation loss decreased (0.289888 --> 0.289827).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2596645
	speed: 0.0189s/iter; left time: 167.5940s
Epoch: 30 cost time: 2.3705532550811768
Epoch: 30, Steps: 126 Train Loss: 3.3285 (Forecasting Loss:0.2656 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.2447064
	speed: 0.0188s/iter; left time: 163.8764s
Epoch: 31 cost time: 2.294976234436035
Epoch: 31, Steps: 126 Train Loss: 3.3293 (Forecasting Loss:0.2659 + XiCon Loss:3.0634 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.2910991
	speed: 0.0187s/iter; left time: 160.3629s
Epoch: 32 cost time: 2.3126132488250732
Epoch: 32, Steps: 126 Train Loss: 3.3227 (Forecasting Loss:0.2658 + XiCon Loss:3.0570 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.3367698
	speed: 0.0186s/iter; left time: 157.5704s
Epoch: 33 cost time: 2.2713589668273926
Epoch: 33, Steps: 126 Train Loss: 3.3233 (Forecasting Loss:0.2658 + XiCon Loss:3.0575 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.4548798
	speed: 0.0188s/iter; left time: 157.1024s
Epoch: 34 cost time: 2.332402467727661
Epoch: 34, Steps: 126 Train Loss: 3.3385 (Forecasting Loss:0.2662 + XiCon Loss:3.0723 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 3.3909473
	speed: 0.0190s/iter; left time: 155.9233s
Epoch: 35 cost time: 2.3205678462982178
Epoch: 35, Steps: 126 Train Loss: 3.3417 (Forecasting Loss:0.2657 + XiCon Loss:3.0760 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 3.3066289
	speed: 0.0187s/iter; left time: 151.0038s
Epoch: 36 cost time: 2.323587656021118
Epoch: 36, Steps: 126 Train Loss: 3.3402 (Forecasting Loss:0.2656 + XiCon Loss:3.0746 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 3.3733194
	speed: 0.0179s/iter; left time: 142.3086s
Epoch: 37 cost time: 2.2584898471832275
Epoch: 37, Steps: 126 Train Loss: 3.3438 (Forecasting Loss:0.2656 + XiCon Loss:3.0782 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 3.3690851
	speed: 0.0191s/iter; left time: 149.5600s
Epoch: 38 cost time: 2.361593246459961
Epoch: 38, Steps: 126 Train Loss: 3.3381 (Forecasting Loss:0.2658 + XiCon Loss:3.0722 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2461
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 3.4085941
	speed: 0.0185s/iter; left time: 142.4694s
Epoch: 39 cost time: 2.32987117767334
Epoch: 39, Steps: 126 Train Loss: 3.3379 (Forecasting Loss:0.2660 + XiCon Loss:3.0719 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2461
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1684788316488266, mae:0.32365682721138, mape:0.6801600456237793, mspe:20.092763900756836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3520
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3230164
	speed: 0.0162s/iter; left time: 203.0973s
Epoch: 1 cost time: 1.9966511726379395
Epoch: 1, Steps: 126 Train Loss: 3.3643 (Forecasting Loss:0.3201 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.3094 Test MSE Loss: 0.2673
Validation loss decreased (inf --> 0.309354).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1405916
	speed: 0.0181s/iter; left time: 223.9263s
Epoch: 2 cost time: 2.21828293800354
Epoch: 2, Steps: 126 Train Loss: 3.1646 (Forecasting Loss:0.2917 + XiCon Loss:2.8729 x Lambda(1.0)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.2534
Validation loss decreased (0.309354 --> 0.303616).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2866483
	speed: 0.0180s/iter; left time: 220.3659s
Epoch: 3 cost time: 2.244225025177002
Epoch: 3, Steps: 126 Train Loss: 3.1882 (Forecasting Loss:0.2800 + XiCon Loss:2.9082 x Lambda(1.0)), Vali MSE Loss: 0.2962 Test MSE Loss: 0.2693
Validation loss decreased (0.303616 --> 0.296165).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3082530
	speed: 0.0191s/iter; left time: 231.3131s
Epoch: 4 cost time: 2.3330914974212646
Epoch: 4, Steps: 126 Train Loss: 3.2944 (Forecasting Loss:0.2727 + XiCon Loss:3.0217 x Lambda(1.0)), Vali MSE Loss: 0.2972 Test MSE Loss: 0.2478
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2597723
	speed: 0.0186s/iter; left time: 222.5767s
Epoch: 5 cost time: 2.2809815406799316
Epoch: 5, Steps: 126 Train Loss: 3.3397 (Forecasting Loss:0.2698 + XiCon Loss:3.0700 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2419
Validation loss decreased (0.296165 --> 0.290787).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2294385
	speed: 0.0190s/iter; left time: 225.8045s
Epoch: 6 cost time: 2.341949939727783
Epoch: 6, Steps: 126 Train Loss: 3.3440 (Forecasting Loss:0.2683 + XiCon Loss:3.0757 x Lambda(1.0)), Vali MSE Loss: 0.2913 Test MSE Loss: 0.2463
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3133981
	speed: 0.0182s/iter; left time: 214.0296s
Epoch: 7 cost time: 2.25783109664917
Epoch: 7, Steps: 126 Train Loss: 3.3524 (Forecasting Loss:0.2674 + XiCon Loss:3.0850 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2442
Validation loss decreased (0.290787 --> 0.289097).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1872983
	speed: 0.0188s/iter; left time: 218.4627s
Epoch: 8 cost time: 2.331936836242676
Epoch: 8, Steps: 126 Train Loss: 3.3418 (Forecasting Loss:0.2671 + XiCon Loss:3.0747 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2443
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2272959
	speed: 0.0189s/iter; left time: 217.2242s
Epoch: 9 cost time: 2.3199617862701416
Epoch: 9, Steps: 126 Train Loss: 3.3513 (Forecasting Loss:0.2667 + XiCon Loss:3.0846 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2448
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3641307
	speed: 0.0182s/iter; left time: 206.3214s
Epoch: 10 cost time: 2.34028697013855
Epoch: 10, Steps: 126 Train Loss: 3.3487 (Forecasting Loss:0.2669 + XiCon Loss:3.0818 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2445
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4618371
	speed: 0.0182s/iter; left time: 204.3253s
Epoch: 11 cost time: 2.255235195159912
Epoch: 11, Steps: 126 Train Loss: 3.3467 (Forecasting Loss:0.2665 + XiCon Loss:3.0802 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2444
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2752576
	speed: 0.0182s/iter; left time: 202.7036s
Epoch: 12 cost time: 2.2598936557769775
Epoch: 12, Steps: 126 Train Loss: 3.3360 (Forecasting Loss:0.2664 + XiCon Loss:3.0696 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2445
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3605204
	speed: 0.0187s/iter; left time: 205.9796s
Epoch: 13 cost time: 2.3347833156585693
Epoch: 13, Steps: 126 Train Loss: 3.3377 (Forecasting Loss:0.2667 + XiCon Loss:3.0710 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2445
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2620745
	speed: 0.0188s/iter; left time: 204.1073s
Epoch: 14 cost time: 2.311546564102173
Epoch: 14, Steps: 126 Train Loss: 3.3381 (Forecasting Loss:0.2665 + XiCon Loss:3.0716 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2445
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0927627
	speed: 0.0180s/iter; left time: 193.1687s
Epoch: 15 cost time: 2.237420082092285
Epoch: 15, Steps: 126 Train Loss: 3.3465 (Forecasting Loss:0.2664 + XiCon Loss:3.0801 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2445
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3252800
	speed: 0.0182s/iter; left time: 193.5587s
Epoch: 16 cost time: 2.2588846683502197
Epoch: 16, Steps: 126 Train Loss: 3.3375 (Forecasting Loss:0.2664 + XiCon Loss:3.0711 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2445
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2784410
	speed: 0.0188s/iter; left time: 196.6769s
Epoch: 17 cost time: 2.3527371883392334
Epoch: 17, Steps: 126 Train Loss: 3.3424 (Forecasting Loss:0.2666 + XiCon Loss:3.0758 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16707564890384674, mae:0.32141023874282837, mape:0.6792477369308472, mspe:20.303876876831055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3907
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3007052
	speed: 0.0163s/iter; left time: 204.1543s
Epoch: 1 cost time: 2.046570062637329
Epoch: 1, Steps: 126 Train Loss: 3.3576 (Forecasting Loss:0.3156 + XiCon Loss:3.0420 x Lambda(1.0)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.2680
Validation loss decreased (inf --> 0.308501).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1895897
	speed: 0.0177s/iter; left time: 218.4993s
Epoch: 2 cost time: 2.1814794540405273
Epoch: 2, Steps: 126 Train Loss: 3.1889 (Forecasting Loss:0.2904 + XiCon Loss:2.8985 x Lambda(1.0)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.2555
Validation loss decreased (0.308501 --> 0.303748).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2669034
	speed: 0.0179s/iter; left time: 219.1244s
Epoch: 3 cost time: 2.1977438926696777
Epoch: 3, Steps: 126 Train Loss: 3.2555 (Forecasting Loss:0.2808 + XiCon Loss:2.9747 x Lambda(1.0)), Vali MSE Loss: 0.2978 Test MSE Loss: 0.2565
Validation loss decreased (0.303748 --> 0.297795).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3393836
	speed: 0.0177s/iter; left time: 215.1712s
Epoch: 4 cost time: 2.1941821575164795
Epoch: 4, Steps: 126 Train Loss: 3.3012 (Forecasting Loss:0.2726 + XiCon Loss:3.0286 x Lambda(1.0)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.2491
Validation loss decreased (0.297795 --> 0.292428).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3009491
	speed: 0.0187s/iter; left time: 224.0238s
Epoch: 5 cost time: 2.291538953781128
Epoch: 5, Steps: 126 Train Loss: 3.3025 (Forecasting Loss:0.2694 + XiCon Loss:3.0331 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2469
Validation loss decreased (0.292428 --> 0.289060).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3022113
	speed: 0.0182s/iter; left time: 216.1538s
Epoch: 6 cost time: 2.2436091899871826
Epoch: 6, Steps: 126 Train Loss: 3.3010 (Forecasting Loss:0.2673 + XiCon Loss:3.0337 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2451
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3721755
	speed: 0.0186s/iter; left time: 218.0853s
Epoch: 7 cost time: 2.3243002891540527
Epoch: 7, Steps: 126 Train Loss: 3.3000 (Forecasting Loss:0.2661 + XiCon Loss:3.0339 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2480
Validation loss decreased (0.289060 --> 0.288573).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3916564
	speed: 0.0183s/iter; left time: 212.1655s
Epoch: 8 cost time: 2.2807531356811523
Epoch: 8, Steps: 126 Train Loss: 3.3117 (Forecasting Loss:0.2658 + XiCon Loss:3.0459 x Lambda(1.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2812417
	speed: 0.0176s/iter; left time: 201.9308s
Epoch: 9 cost time: 2.2327778339385986
Epoch: 9, Steps: 126 Train Loss: 3.3172 (Forecasting Loss:0.2657 + XiCon Loss:3.0515 x Lambda(1.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3096108
	speed: 0.0191s/iter; left time: 216.5980s
Epoch: 10 cost time: 2.3026912212371826
Epoch: 10, Steps: 126 Train Loss: 3.2970 (Forecasting Loss:0.2651 + XiCon Loss:3.0319 x Lambda(1.0)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.2478
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3161991
	speed: 0.0177s/iter; left time: 198.5017s
Epoch: 11 cost time: 2.2260000705718994
Epoch: 11, Steps: 126 Train Loss: 3.3174 (Forecasting Loss:0.2645 + XiCon Loss:3.0529 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2478
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4304173
	speed: 0.0179s/iter; left time: 199.4578s
Epoch: 12 cost time: 2.238060474395752
Epoch: 12, Steps: 126 Train Loss: 3.3178 (Forecasting Loss:0.2648 + XiCon Loss:3.0530 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2478
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1748378
	speed: 0.0183s/iter; left time: 200.6939s
Epoch: 13 cost time: 2.2695322036743164
Epoch: 13, Steps: 126 Train Loss: 3.3000 (Forecasting Loss:0.2649 + XiCon Loss:3.0351 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2478
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3519092
	speed: 0.0180s/iter; left time: 195.7099s
Epoch: 14 cost time: 2.252744674682617
Epoch: 14, Steps: 126 Train Loss: 3.3098 (Forecasting Loss:0.2647 + XiCon Loss:3.0451 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2478
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4624476
	speed: 0.0178s/iter; left time: 190.9883s
Epoch: 15 cost time: 2.2096943855285645
Epoch: 15, Steps: 126 Train Loss: 3.3036 (Forecasting Loss:0.2649 + XiCon Loss:3.0387 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2478
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2804956
	speed: 0.0185s/iter; left time: 195.9871s
Epoch: 16 cost time: 2.3257670402526855
Epoch: 16, Steps: 126 Train Loss: 3.3161 (Forecasting Loss:0.2648 + XiCon Loss:3.0513 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2478
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2755518
	speed: 0.0182s/iter; left time: 190.7028s
Epoch: 17 cost time: 2.276134729385376
Epoch: 17, Steps: 126 Train Loss: 3.3251 (Forecasting Loss:0.2645 + XiCon Loss:3.0606 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2478
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.17048031091690063, mae:0.3255956470966339, mape:0.6744957566261292, mspe:19.608718872070312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3745
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2943051
	speed: 0.0166s/iter; left time: 208.0643s
Epoch: 1 cost time: 2.064007520675659
Epoch: 1, Steps: 126 Train Loss: 3.3569 (Forecasting Loss:0.3184 + XiCon Loss:3.0385 x Lambda(1.0)), Vali MSE Loss: 0.3057 Test MSE Loss: 0.2642
Validation loss decreased (inf --> 0.305719).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2933335
	speed: 0.0179s/iter; left time: 221.5412s
Epoch: 2 cost time: 2.24519944190979
Epoch: 2, Steps: 126 Train Loss: 3.2123 (Forecasting Loss:0.2903 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.2705
Validation loss decreased (0.305719 --> 0.294392).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1955156
	speed: 0.0185s/iter; left time: 226.6308s
Epoch: 3 cost time: 2.315605401992798
Epoch: 3, Steps: 126 Train Loss: 3.2289 (Forecasting Loss:0.2771 + XiCon Loss:2.9517 x Lambda(1.0)), Vali MSE Loss: 0.2963 Test MSE Loss: 0.2554
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3576176
	speed: 0.0182s/iter; left time: 220.0949s
Epoch: 4 cost time: 2.2240169048309326
Epoch: 4, Steps: 126 Train Loss: 3.1709 (Forecasting Loss:0.2727 + XiCon Loss:2.8982 x Lambda(1.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2503
Validation loss decreased (0.294392 --> 0.289639).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1309054
	speed: 0.0181s/iter; left time: 217.0973s
Epoch: 5 cost time: 2.240499973297119
Epoch: 5, Steps: 126 Train Loss: 3.1511 (Forecasting Loss:0.2684 + XiCon Loss:2.8827 x Lambda(1.0)), Vali MSE Loss: 0.2881 Test MSE Loss: 0.2490
Validation loss decreased (0.289639 --> 0.288069).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0817733
	speed: 0.0182s/iter; left time: 215.7924s
Epoch: 6 cost time: 2.2476274967193604
Epoch: 6, Steps: 126 Train Loss: 3.1509 (Forecasting Loss:0.2665 + XiCon Loss:2.8844 x Lambda(1.0)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.2474
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1556628
	speed: 0.0185s/iter; left time: 217.0861s
Epoch: 7 cost time: 2.3076391220092773
Epoch: 7, Steps: 126 Train Loss: 3.1517 (Forecasting Loss:0.2653 + XiCon Loss:2.8864 x Lambda(1.0)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.2487
Validation loss decreased (0.288069 --> 0.287759).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1488466
	speed: 0.0189s/iter; left time: 219.1917s
Epoch: 8 cost time: 2.326230049133301
Epoch: 8, Steps: 126 Train Loss: 3.1394 (Forecasting Loss:0.2652 + XiCon Loss:2.8741 x Lambda(1.0)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.2488
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0994196
	speed: 0.0183s/iter; left time: 210.7224s
Epoch: 9 cost time: 2.2598929405212402
Epoch: 9, Steps: 126 Train Loss: 3.1394 (Forecasting Loss:0.2648 + XiCon Loss:2.8745 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2487
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0681951
	speed: 0.0184s/iter; left time: 209.5914s
Epoch: 10 cost time: 2.312687873840332
Epoch: 10, Steps: 126 Train Loss: 3.1354 (Forecasting Loss:0.2647 + XiCon Loss:2.8707 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2486
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0454917
	speed: 0.0186s/iter; left time: 209.3530s
Epoch: 11 cost time: 2.301982879638672
Epoch: 11, Steps: 126 Train Loss: 3.1375 (Forecasting Loss:0.2648 + XiCon Loss:2.8727 x Lambda(1.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2486
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1084349
	speed: 0.0184s/iter; left time: 204.7831s
Epoch: 12 cost time: 2.28619384765625
Epoch: 12, Steps: 126 Train Loss: 3.1404 (Forecasting Loss:0.2645 + XiCon Loss:2.8759 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2486
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1318712
	speed: 0.0171s/iter; left time: 188.3659s
Epoch: 13 cost time: 2.2371315956115723
Epoch: 13, Steps: 126 Train Loss: 3.1429 (Forecasting Loss:0.2648 + XiCon Loss:2.8781 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2486
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2475986
	speed: 0.0181s/iter; left time: 196.4397s
Epoch: 14 cost time: 2.2220137119293213
Epoch: 14, Steps: 126 Train Loss: 3.1405 (Forecasting Loss:0.2644 + XiCon Loss:2.8761 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2486
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1606462
	speed: 0.0184s/iter; left time: 197.2416s
Epoch: 15 cost time: 2.298018455505371
Epoch: 15, Steps: 126 Train Loss: 3.1369 (Forecasting Loss:0.2646 + XiCon Loss:2.8724 x Lambda(1.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2487
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0959458
	speed: 0.0178s/iter; left time: 188.5458s
Epoch: 16 cost time: 2.254722833633423
Epoch: 16, Steps: 126 Train Loss: 3.1414 (Forecasting Loss:0.2648 + XiCon Loss:2.8766 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2487
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1898007
	speed: 0.0184s/iter; left time: 193.0541s
Epoch: 17 cost time: 2.3023319244384766
Epoch: 17, Steps: 126 Train Loss: 3.1380 (Forecasting Loss:0.2645 + XiCon Loss:2.8735 x Lambda(1.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2487
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1716679185628891, mae:0.32577377557754517, mape:0.6845678687095642, mspe:21.23137092590332 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3621
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2883997
	speed: 0.0166s/iter; left time: 207.2994s
Epoch: 1 cost time: 2.058568000793457
Epoch: 1, Steps: 126 Train Loss: 3.3704 (Forecasting Loss:0.3181 + XiCon Loss:3.0524 x Lambda(1.0)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2644
Validation loss decreased (inf --> 0.313935).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1004839
	speed: 0.0183s/iter; left time: 225.9477s
Epoch: 2 cost time: 2.2306199073791504
Epoch: 2, Steps: 126 Train Loss: 3.1754 (Forecasting Loss:0.2933 + XiCon Loss:2.8821 x Lambda(1.0)), Vali MSE Loss: 0.2981 Test MSE Loss: 0.2553
Validation loss decreased (0.313935 --> 0.298117).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3816774
	speed: 0.0191s/iter; left time: 233.8059s
Epoch: 3 cost time: 2.3933050632476807
Epoch: 3, Steps: 126 Train Loss: 3.2403 (Forecasting Loss:0.2800 + XiCon Loss:2.9603 x Lambda(1.0)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2591
Validation loss decreased (0.298117 --> 0.294945).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3260474
	speed: 0.0193s/iter; left time: 233.5550s
Epoch: 4 cost time: 2.4073405265808105
Epoch: 4, Steps: 126 Train Loss: 3.2977 (Forecasting Loss:0.2725 + XiCon Loss:3.0252 x Lambda(1.0)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.2563
Validation loss decreased (0.294945 --> 0.293759).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2324464
	speed: 0.0194s/iter; left time: 233.1368s
Epoch: 5 cost time: 2.3944685459136963
Epoch: 5, Steps: 126 Train Loss: 3.2981 (Forecasting Loss:0.2703 + XiCon Loss:3.0278 x Lambda(1.0)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.2506
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3557544
	speed: 0.0189s/iter; left time: 224.5516s
Epoch: 6 cost time: 2.35626482963562
Epoch: 6, Steps: 126 Train Loss: 3.2913 (Forecasting Loss:0.2687 + XiCon Loss:3.0226 x Lambda(1.0)), Vali MSE Loss: 0.2930 Test MSE Loss: 0.2514
Validation loss decreased (0.293759 --> 0.293037).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3270385
	speed: 0.0195s/iter; left time: 228.9491s
Epoch: 7 cost time: 2.4336435794830322
Epoch: 7, Steps: 126 Train Loss: 3.2756 (Forecasting Loss:0.2676 + XiCon Loss:3.0080 x Lambda(1.0)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.2496
Validation loss decreased (0.293037 --> 0.292606).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1114874
	speed: 0.0188s/iter; left time: 218.2649s
Epoch: 8 cost time: 2.320343255996704
Epoch: 8, Steps: 126 Train Loss: 3.2903 (Forecasting Loss:0.2674 + XiCon Loss:3.0229 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2494
Validation loss decreased (0.292606 --> 0.290805).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1347032
	speed: 0.0196s/iter; left time: 224.7800s
Epoch: 9 cost time: 2.4570655822753906
Epoch: 9, Steps: 126 Train Loss: 3.2700 (Forecasting Loss:0.2668 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2496
Validation loss decreased (0.290805 --> 0.290729).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2809839
	speed: 0.0194s/iter; left time: 220.4064s
Epoch: 10 cost time: 2.377119541168213
Epoch: 10, Steps: 126 Train Loss: 3.2882 (Forecasting Loss:0.2669 + XiCon Loss:3.0213 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2494
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2919300
	speed: 0.0196s/iter; left time: 220.0203s
Epoch: 11 cost time: 2.3906967639923096
Epoch: 11, Steps: 126 Train Loss: 3.2888 (Forecasting Loss:0.2664 + XiCon Loss:3.0224 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2493
Validation loss decreased (0.290729 --> 0.290649).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3543320
	speed: 0.0197s/iter; left time: 219.0251s
Epoch: 12 cost time: 2.427110195159912
Epoch: 12, Steps: 126 Train Loss: 3.2868 (Forecasting Loss:0.2669 + XiCon Loss:3.0199 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2493
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3316917
	speed: 0.0192s/iter; left time: 211.4474s
Epoch: 13 cost time: 2.37111759185791
Epoch: 13, Steps: 126 Train Loss: 3.2929 (Forecasting Loss:0.2664 + XiCon Loss:3.0264 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2158957
	speed: 0.0196s/iter; left time: 212.9020s
Epoch: 14 cost time: 2.4391283988952637
Epoch: 14, Steps: 126 Train Loss: 3.2790 (Forecasting Loss:0.2664 + XiCon Loss:3.0125 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3251166
	speed: 0.0195s/iter; left time: 209.1514s
Epoch: 15 cost time: 2.397451162338257
Epoch: 15, Steps: 126 Train Loss: 3.2837 (Forecasting Loss:0.2667 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3967140
	speed: 0.0195s/iter; left time: 206.5606s
Epoch: 16 cost time: 2.4190666675567627
Epoch: 16, Steps: 126 Train Loss: 3.2833 (Forecasting Loss:0.2666 + XiCon Loss:3.0166 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4077122
	speed: 0.0191s/iter; left time: 200.3030s
Epoch: 17 cost time: 2.3740031719207764
Epoch: 17, Steps: 126 Train Loss: 3.2907 (Forecasting Loss:0.2666 + XiCon Loss:3.0241 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2492
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3325841
	speed: 0.0192s/iter; left time: 198.3986s
Epoch: 18 cost time: 2.3479654788970947
Epoch: 18, Steps: 126 Train Loss: 3.3017 (Forecasting Loss:0.2667 + XiCon Loss:3.0350 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2492
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4155402
	speed: 0.0193s/iter; left time: 197.6559s
Epoch: 19 cost time: 2.386932373046875
Epoch: 19, Steps: 126 Train Loss: 3.2814 (Forecasting Loss:0.2666 + XiCon Loss:3.0148 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2492
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4003825
	speed: 0.0189s/iter; left time: 190.7544s
Epoch: 20 cost time: 2.3257970809936523
Epoch: 20, Steps: 126 Train Loss: 3.2970 (Forecasting Loss:0.2667 + XiCon Loss:3.0303 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3176942
	speed: 0.0197s/iter; left time: 196.3712s
Epoch: 21 cost time: 2.4340856075286865
Epoch: 21, Steps: 126 Train Loss: 3.2771 (Forecasting Loss:0.2668 + XiCon Loss:3.0103 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2492
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.17182967066764832, mae:0.3267611563205719, mape:0.6802340149879456, mspe:20.028301239013672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1699+-0.00257, MAE:0.3246+-0.00264, MAPE:0.6797+-0.00445, MSPE:20.2530+-0.74785, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4083
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2916882
	speed: 0.0213s/iter; left time: 261.7667s
Epoch: 1 cost time: 2.513028144836426
Epoch: 1, Steps: 124 Train Loss: 3.3598 (Forecasting Loss:0.3418 + XiCon Loss:3.0180 x Lambda(1.0)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2924
Validation loss decreased (inf --> 0.346305).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1431170
	speed: 0.0214s/iter; left time: 261.1494s
Epoch: 2 cost time: 2.6593332290649414
Epoch: 2, Steps: 124 Train Loss: 3.1614 (Forecasting Loss:0.3140 + XiCon Loss:2.8474 x Lambda(1.0)), Vali MSE Loss: 0.3395 Test MSE Loss: 0.2881
Validation loss decreased (0.346305 --> 0.339474).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1203279
	speed: 0.0215s/iter; left time: 259.1121s
Epoch: 3 cost time: 2.6341185569763184
Epoch: 3, Steps: 124 Train Loss: 3.1360 (Forecasting Loss:0.3027 + XiCon Loss:2.8333 x Lambda(1.0)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.2741
Validation loss decreased (0.339474 --> 0.332697).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2587097
	speed: 0.0220s/iter; left time: 262.8453s
Epoch: 4 cost time: 2.6925151348114014
Epoch: 4, Steps: 124 Train Loss: 3.2759 (Forecasting Loss:0.2956 + XiCon Loss:2.9802 x Lambda(1.0)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2716
Validation loss decreased (0.332697 --> 0.326676).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3966656
	speed: 0.0219s/iter; left time: 258.0166s
Epoch: 5 cost time: 2.7081594467163086
Epoch: 5, Steps: 124 Train Loss: 3.3437 (Forecasting Loss:0.2908 + XiCon Loss:3.0529 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2708
Validation loss decreased (0.326676 --> 0.322914).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3386114
	speed: 0.0214s/iter; left time: 250.4295s
Epoch: 6 cost time: 2.6639528274536133
Epoch: 6, Steps: 124 Train Loss: 3.3577 (Forecasting Loss:0.2890 + XiCon Loss:3.0687 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2707
Validation loss decreased (0.322914 --> 0.322130).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4047229
	speed: 0.0217s/iter; left time: 250.3625s
Epoch: 7 cost time: 2.6809051036834717
Epoch: 7, Steps: 124 Train Loss: 3.3637 (Forecasting Loss:0.2879 + XiCon Loss:3.0757 x Lambda(1.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2699
Validation loss decreased (0.322130 --> 0.319563).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4547894
	speed: 0.0209s/iter; left time: 239.0014s
Epoch: 8 cost time: 2.5965771675109863
Epoch: 8, Steps: 124 Train Loss: 3.3703 (Forecasting Loss:0.2870 + XiCon Loss:3.0833 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2702
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1733341
	speed: 0.0219s/iter; left time: 247.8101s
Epoch: 9 cost time: 2.6735756397247314
Epoch: 9, Steps: 124 Train Loss: 3.3699 (Forecasting Loss:0.2867 + XiCon Loss:3.0832 x Lambda(1.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5717251
	speed: 0.0221s/iter; left time: 247.0829s
Epoch: 10 cost time: 2.6983039379119873
Epoch: 10, Steps: 124 Train Loss: 3.3503 (Forecasting Loss:0.2864 + XiCon Loss:3.0639 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2700
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4336147
	speed: 0.0222s/iter; left time: 246.0203s
Epoch: 11 cost time: 2.738262891769409
Epoch: 11, Steps: 124 Train Loss: 3.3577 (Forecasting Loss:0.2862 + XiCon Loss:3.0715 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2704
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3364494
	speed: 0.0223s/iter; left time: 243.3725s
Epoch: 12 cost time: 2.727869987487793
Epoch: 12, Steps: 124 Train Loss: 3.3592 (Forecasting Loss:0.2865 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2703
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3060560
	speed: 0.0225s/iter; left time: 243.5541s
Epoch: 13 cost time: 2.7627344131469727
Epoch: 13, Steps: 124 Train Loss: 3.3702 (Forecasting Loss:0.2862 + XiCon Loss:3.0841 x Lambda(1.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2703
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2637684
	speed: 0.0222s/iter; left time: 237.7777s
Epoch: 14 cost time: 2.7150728702545166
Epoch: 14, Steps: 124 Train Loss: 3.3542 (Forecasting Loss:0.2862 + XiCon Loss:3.0680 x Lambda(1.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2703
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3599377
	speed: 0.0219s/iter; left time: 231.7619s
Epoch: 15 cost time: 2.698343276977539
Epoch: 15, Steps: 124 Train Loss: 3.3668 (Forecasting Loss:0.2861 + XiCon Loss:3.0807 x Lambda(1.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2703
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4106534
	speed: 0.0223s/iter; left time: 232.3676s
Epoch: 16 cost time: 2.7143495082855225
Epoch: 16, Steps: 124 Train Loss: 3.3827 (Forecasting Loss:0.2862 + XiCon Loss:3.0965 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2703
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2153835
	speed: 0.0220s/iter; left time: 227.1782s
Epoch: 17 cost time: 2.700286626815796
Epoch: 17, Steps: 124 Train Loss: 3.3656 (Forecasting Loss:0.2862 + XiCon Loss:3.0794 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2703
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1892373412847519, mae:0.35063451528549194, mape:0.6703752875328064, mspe:18.016386032104492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4187
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2461379
	speed: 0.0183s/iter; left time: 224.9540s
Epoch: 1 cost time: 2.209527015686035
Epoch: 1, Steps: 124 Train Loss: 3.3267 (Forecasting Loss:0.3377 + XiCon Loss:2.9889 x Lambda(1.0)), Vali MSE Loss: 0.3436 Test MSE Loss: 0.2870
Validation loss decreased (inf --> 0.343558).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1757731
	speed: 0.0227s/iter; left time: 276.4159s
Epoch: 2 cost time: 2.7805936336517334
Epoch: 2, Steps: 124 Train Loss: 3.1640 (Forecasting Loss:0.3146 + XiCon Loss:2.8493 x Lambda(1.0)), Vali MSE Loss: 0.3467 Test MSE Loss: 0.2909
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0578489
	speed: 0.0225s/iter; left time: 271.7260s
Epoch: 3 cost time: 2.7567379474639893
Epoch: 3, Steps: 124 Train Loss: 3.1385 (Forecasting Loss:0.3033 + XiCon Loss:2.8352 x Lambda(1.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.2749
Validation loss decreased (0.343558 --> 0.330564).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3057489
	speed: 0.0227s/iter; left time: 271.1373s
Epoch: 4 cost time: 2.7682642936706543
Epoch: 4, Steps: 124 Train Loss: 3.2268 (Forecasting Loss:0.2958 + XiCon Loss:2.9310 x Lambda(1.0)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.2691
Validation loss decreased (0.330564 --> 0.328551).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3776839
	speed: 0.0232s/iter; left time: 273.7017s
Epoch: 5 cost time: 2.864537239074707
Epoch: 5, Steps: 124 Train Loss: 3.2743 (Forecasting Loss:0.2927 + XiCon Loss:2.9816 x Lambda(1.0)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2718
Validation loss decreased (0.328551 --> 0.326932).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2186761
	speed: 0.0232s/iter; left time: 271.3184s
Epoch: 6 cost time: 2.8609204292297363
Epoch: 6, Steps: 124 Train Loss: 3.2931 (Forecasting Loss:0.2906 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2685
Validation loss decreased (0.326932 --> 0.325230).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2810571
	speed: 0.0232s/iter; left time: 267.9693s
Epoch: 7 cost time: 2.8561599254608154
Epoch: 7, Steps: 124 Train Loss: 3.3066 (Forecasting Loss:0.2896 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2703
Validation loss decreased (0.325230 --> 0.323420).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3454540
	speed: 0.0226s/iter; left time: 258.4343s
Epoch: 8 cost time: 2.817293882369995
Epoch: 8, Steps: 124 Train Loss: 3.3102 (Forecasting Loss:0.2888 + XiCon Loss:3.0213 x Lambda(1.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2680
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3154821
	speed: 0.0228s/iter; left time: 257.7549s
Epoch: 9 cost time: 2.8112096786499023
Epoch: 9, Steps: 124 Train Loss: 3.2962 (Forecasting Loss:0.2885 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2885749
	speed: 0.0235s/iter; left time: 263.2634s
Epoch: 10 cost time: 2.9034547805786133
Epoch: 10, Steps: 124 Train Loss: 3.3112 (Forecasting Loss:0.2884 + XiCon Loss:3.0229 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2680
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2134080
	speed: 0.0226s/iter; left time: 249.5039s
Epoch: 11 cost time: 2.7557690143585205
Epoch: 11, Steps: 124 Train Loss: 3.3025 (Forecasting Loss:0.2882 + XiCon Loss:3.0143 x Lambda(1.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2323279
	speed: 0.0234s/iter; left time: 255.4685s
Epoch: 12 cost time: 2.8914644718170166
Epoch: 12, Steps: 124 Train Loss: 3.3082 (Forecasting Loss:0.2880 + XiCon Loss:3.0202 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3317740
	speed: 0.0225s/iter; left time: 243.6120s
Epoch: 13 cost time: 2.7916080951690674
Epoch: 13, Steps: 124 Train Loss: 3.3078 (Forecasting Loss:0.2882 + XiCon Loss:3.0197 x Lambda(1.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2681
Validation loss decreased (0.323420 --> 0.323393).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3738070
	speed: 0.0227s/iter; left time: 242.2652s
Epoch: 14 cost time: 2.815986156463623
Epoch: 14, Steps: 124 Train Loss: 3.3038 (Forecasting Loss:0.2882 + XiCon Loss:3.0156 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5794179
	speed: 0.0228s/iter; left time: 241.0594s
Epoch: 15 cost time: 2.815178155899048
Epoch: 15, Steps: 124 Train Loss: 3.3163 (Forecasting Loss:0.2880 + XiCon Loss:3.0283 x Lambda(1.0)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2055588
	speed: 0.0227s/iter; left time: 236.5305s
Epoch: 16 cost time: 2.8372411727905273
Epoch: 16, Steps: 124 Train Loss: 3.2993 (Forecasting Loss:0.2878 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2095182
	speed: 0.0221s/iter; left time: 228.4477s
Epoch: 17 cost time: 2.7374632358551025
Epoch: 17, Steps: 124 Train Loss: 3.3193 (Forecasting Loss:0.2880 + XiCon Loss:3.0312 x Lambda(1.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5000787
	speed: 0.0227s/iter; left time: 230.9940s
Epoch: 18 cost time: 2.8073654174804688
Epoch: 18, Steps: 124 Train Loss: 3.2932 (Forecasting Loss:0.2882 + XiCon Loss:3.0050 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1544449
	speed: 0.0228s/iter; left time: 229.3778s
Epoch: 19 cost time: 2.789787530899048
Epoch: 19, Steps: 124 Train Loss: 3.2919 (Forecasting Loss:0.2881 + XiCon Loss:3.0038 x Lambda(1.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2791967
	speed: 0.0233s/iter; left time: 231.5981s
Epoch: 20 cost time: 2.8458471298217773
Epoch: 20, Steps: 124 Train Loss: 3.3029 (Forecasting Loss:0.2882 + XiCon Loss:3.0147 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2681
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2794542
	speed: 0.0232s/iter; left time: 228.1802s
Epoch: 21 cost time: 2.8413190841674805
Epoch: 21, Steps: 124 Train Loss: 3.3015 (Forecasting Loss:0.2882 + XiCon Loss:3.0134 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2681
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2324133
	speed: 0.0227s/iter; left time: 219.8720s
Epoch: 22 cost time: 2.7592670917510986
Epoch: 22, Steps: 124 Train Loss: 3.3023 (Forecasting Loss:0.2882 + XiCon Loss:3.0141 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2681
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3571260
	speed: 0.0228s/iter; left time: 218.5682s
Epoch: 23 cost time: 2.786926507949829
Epoch: 23, Steps: 124 Train Loss: 3.3052 (Forecasting Loss:0.2881 + XiCon Loss:3.0171 x Lambda(1.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2681
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.187179833650589, mae:0.34900495409965515, mape:0.6711465120315552, mspe:17.888015747070312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3513
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2832992
	speed: 0.0182s/iter; left time: 224.1373s
Epoch: 1 cost time: 2.246497631072998
Epoch: 1, Steps: 124 Train Loss: 3.3376 (Forecasting Loss:0.3413 + XiCon Loss:2.9962 x Lambda(1.0)), Vali MSE Loss: 0.3409 Test MSE Loss: 0.2855
Validation loss decreased (inf --> 0.340937).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0918908
	speed: 0.0208s/iter; left time: 253.5401s
Epoch: 2 cost time: 2.589169979095459
Epoch: 2, Steps: 124 Train Loss: 3.1600 (Forecasting Loss:0.3150 + XiCon Loss:2.8450 x Lambda(1.0)), Vali MSE Loss: 0.3371 Test MSE Loss: 0.2842
Validation loss decreased (0.340937 --> 0.337088).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1590750
	speed: 0.0217s/iter; left time: 261.7453s
Epoch: 3 cost time: 2.698988437652588
Epoch: 3, Steps: 124 Train Loss: 3.1301 (Forecasting Loss:0.3031 + XiCon Loss:2.8270 x Lambda(1.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.2723
Validation loss decreased (0.337088 --> 0.330850).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2885447
	speed: 0.0222s/iter; left time: 264.9967s
Epoch: 4 cost time: 2.7062788009643555
Epoch: 4, Steps: 124 Train Loss: 3.2298 (Forecasting Loss:0.2964 + XiCon Loss:2.9335 x Lambda(1.0)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2773
Validation loss decreased (0.330850 --> 0.325759).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3421533
	speed: 0.0221s/iter; left time: 261.2285s
Epoch: 5 cost time: 2.738187313079834
Epoch: 5, Steps: 124 Train Loss: 3.2998 (Forecasting Loss:0.2917 + XiCon Loss:3.0081 x Lambda(1.0)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2669
Validation loss decreased (0.325759 --> 0.324687).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2555480
	speed: 0.0218s/iter; left time: 254.2558s
Epoch: 6 cost time: 2.676651954650879
Epoch: 6, Steps: 124 Train Loss: 3.3331 (Forecasting Loss:0.2890 + XiCon Loss:3.0441 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2695
Validation loss decreased (0.324687 --> 0.322939).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2853203
	speed: 0.0214s/iter; left time: 247.7447s
Epoch: 7 cost time: 2.6392390727996826
Epoch: 7, Steps: 124 Train Loss: 3.3306 (Forecasting Loss:0.2872 + XiCon Loss:3.0434 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2679
Validation loss decreased (0.322939 --> 0.321539).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2801826
	speed: 0.0220s/iter; left time: 251.4717s
Epoch: 8 cost time: 2.702274799346924
Epoch: 8, Steps: 124 Train Loss: 3.3329 (Forecasting Loss:0.2869 + XiCon Loss:3.0460 x Lambda(1.0)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2670
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2322769
	speed: 0.0218s/iter; left time: 246.0200s
Epoch: 9 cost time: 2.7072582244873047
Epoch: 9, Steps: 124 Train Loss: 3.3297 (Forecasting Loss:0.2867 + XiCon Loss:3.0430 x Lambda(1.0)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2660
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2697325
	speed: 0.0214s/iter; left time: 239.1640s
Epoch: 10 cost time: 2.6436755657196045
Epoch: 10, Steps: 124 Train Loss: 3.3295 (Forecasting Loss:0.2867 + XiCon Loss:3.0428 x Lambda(1.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2665
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3726788
	speed: 0.0213s/iter; left time: 235.2538s
Epoch: 11 cost time: 2.6065211296081543
Epoch: 11, Steps: 124 Train Loss: 3.3242 (Forecasting Loss:0.2862 + XiCon Loss:3.0381 x Lambda(1.0)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2665
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3665559
	speed: 0.0217s/iter; left time: 237.1488s
Epoch: 12 cost time: 2.6443982124328613
Epoch: 12, Steps: 124 Train Loss: 3.3372 (Forecasting Loss:0.2863 + XiCon Loss:3.0509 x Lambda(1.0)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2664
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2464709
	speed: 0.0214s/iter; left time: 231.3924s
Epoch: 13 cost time: 2.6473731994628906
Epoch: 13, Steps: 124 Train Loss: 3.3162 (Forecasting Loss:0.2863 + XiCon Loss:3.0299 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2665
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3268998
	speed: 0.0218s/iter; left time: 233.5509s
Epoch: 14 cost time: 2.6864404678344727
Epoch: 14, Steps: 124 Train Loss: 3.3341 (Forecasting Loss:0.2866 + XiCon Loss:3.0475 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2665
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4212434
	speed: 0.0217s/iter; left time: 229.4534s
Epoch: 15 cost time: 2.6775381565093994
Epoch: 15, Steps: 124 Train Loss: 3.3220 (Forecasting Loss:0.2864 + XiCon Loss:3.0356 x Lambda(1.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2665
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3320475
	speed: 0.0219s/iter; left time: 228.8307s
Epoch: 16 cost time: 2.7210981845855713
Epoch: 16, Steps: 124 Train Loss: 3.3271 (Forecasting Loss:0.2865 + XiCon Loss:3.0406 x Lambda(1.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2665
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3498158
	speed: 0.0213s/iter; left time: 219.6439s
Epoch: 17 cost time: 2.6036570072174072
Epoch: 17, Steps: 124 Train Loss: 3.3221 (Forecasting Loss:0.2865 + XiCon Loss:3.0356 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18725982308387756, mae:0.3485342264175415, mape:0.6806739568710327, mspe:18.65799331665039 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3886
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2846363
	speed: 0.0184s/iter; left time: 225.9088s
Epoch: 1 cost time: 2.2376599311828613
Epoch: 1, Steps: 124 Train Loss: 3.3537 (Forecasting Loss:0.3367 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.3428 Test MSE Loss: 0.2794
Validation loss decreased (inf --> 0.342807).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2261026
	speed: 0.0185s/iter; left time: 225.3694s
Epoch: 2 cost time: 2.234562873840332
Epoch: 2, Steps: 124 Train Loss: 3.2014 (Forecasting Loss:0.2997 + XiCon Loss:2.9018 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.3054
Validation loss decreased (0.342807 --> 0.313208).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2155831
	speed: 0.0191s/iter; left time: 230.0682s
Epoch: 3 cost time: 2.3553335666656494
Epoch: 3, Steps: 124 Train Loss: 3.3217 (Forecasting Loss:0.2849 + XiCon Loss:3.0368 x Lambda(1.0)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2850
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4116623
	speed: 0.0201s/iter; left time: 239.5075s
Epoch: 4 cost time: 2.4527459144592285
Epoch: 4, Steps: 124 Train Loss: 3.2410 (Forecasting Loss:0.2699 + XiCon Loss:2.9711 x Lambda(1.0)), Vali MSE Loss: 0.2988 Test MSE Loss: 0.2818
Validation loss decreased (0.313208 --> 0.298764).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3156693
	speed: 0.0208s/iter; left time: 245.5437s
Epoch: 5 cost time: 2.5517356395721436
Epoch: 5, Steps: 124 Train Loss: 3.2145 (Forecasting Loss:0.2631 + XiCon Loss:2.9514 x Lambda(1.0)), Vali MSE Loss: 0.2969 Test MSE Loss: 0.2911
Validation loss decreased (0.298764 --> 0.296884).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3443017
	speed: 0.0197s/iter; left time: 229.7960s
Epoch: 6 cost time: 2.422494649887085
Epoch: 6, Steps: 124 Train Loss: 3.2186 (Forecasting Loss:0.2597 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.2806
Validation loss decreased (0.296884 --> 0.295257).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3495522
	speed: 0.0202s/iter; left time: 233.5540s
Epoch: 7 cost time: 2.4805727005004883
Epoch: 7, Steps: 124 Train Loss: 3.2016 (Forecasting Loss:0.2591 + XiCon Loss:2.9425 x Lambda(1.0)), Vali MSE Loss: 0.2913 Test MSE Loss: 0.2815
Validation loss decreased (0.295257 --> 0.291308).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3139758
	speed: 0.0202s/iter; left time: 230.3952s
Epoch: 8 cost time: 2.476832866668701
Epoch: 8, Steps: 124 Train Loss: 3.2056 (Forecasting Loss:0.2573 + XiCon Loss:2.9484 x Lambda(1.0)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.2784
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4049578
	speed: 0.0203s/iter; left time: 229.8532s
Epoch: 9 cost time: 2.482185125350952
Epoch: 9, Steps: 124 Train Loss: 3.2137 (Forecasting Loss:0.2570 + XiCon Loss:2.9567 x Lambda(1.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2801
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2122428
	speed: 0.0207s/iter; left time: 231.6273s
Epoch: 10 cost time: 2.527505874633789
Epoch: 10, Steps: 124 Train Loss: 3.2018 (Forecasting Loss:0.2560 + XiCon Loss:2.9457 x Lambda(1.0)), Vali MSE Loss: 0.2917 Test MSE Loss: 0.2815
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0461047
	speed: 0.0203s/iter; left time: 224.4447s
Epoch: 11 cost time: 2.4567408561706543
Epoch: 11, Steps: 124 Train Loss: 3.2036 (Forecasting Loss:0.2565 + XiCon Loss:2.9471 x Lambda(1.0)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.2807
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2896907
	speed: 0.0203s/iter; left time: 222.5175s
Epoch: 12 cost time: 2.4947469234466553
Epoch: 12, Steps: 124 Train Loss: 3.1931 (Forecasting Loss:0.2561 + XiCon Loss:2.9370 x Lambda(1.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2808
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2271149
	speed: 0.0204s/iter; left time: 220.4572s
Epoch: 13 cost time: 2.4965953826904297
Epoch: 13, Steps: 124 Train Loss: 3.2122 (Forecasting Loss:0.2559 + XiCon Loss:2.9563 x Lambda(1.0)), Vali MSE Loss: 0.2917 Test MSE Loss: 0.2804
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4525161
	speed: 0.0201s/iter; left time: 214.6558s
Epoch: 14 cost time: 2.464751720428467
Epoch: 14, Steps: 124 Train Loss: 3.2108 (Forecasting Loss:0.2562 + XiCon Loss:2.9546 x Lambda(1.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2806
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1819520
	speed: 0.0206s/iter; left time: 217.4204s
Epoch: 15 cost time: 2.506601333618164
Epoch: 15, Steps: 124 Train Loss: 3.1964 (Forecasting Loss:0.2559 + XiCon Loss:2.9406 x Lambda(1.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2806
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1833031
	speed: 0.0201s/iter; left time: 209.9602s
Epoch: 16 cost time: 2.447042465209961
Epoch: 16, Steps: 124 Train Loss: 3.2130 (Forecasting Loss:0.2559 + XiCon Loss:2.9571 x Lambda(1.0)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.2806
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2158399
	speed: 0.0206s/iter; left time: 212.9598s
Epoch: 17 cost time: 2.5182626247406006
Epoch: 17, Steps: 124 Train Loss: 3.2064 (Forecasting Loss:0.2562 + XiCon Loss:2.9502 x Lambda(1.0)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.2806
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19729244709014893, mae:0.3657884895801544, mape:0.7758989334106445, mspe:19.500438690185547 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3473
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3112183
	speed: 0.0181s/iter; left time: 223.0085s
Epoch: 1 cost time: 2.220536708831787
Epoch: 1, Steps: 124 Train Loss: 3.3539 (Forecasting Loss:0.3388 + XiCon Loss:3.0151 x Lambda(1.0)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2897
Validation loss decreased (inf --> 0.344789).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1499202
	speed: 0.0219s/iter; left time: 266.6250s
Epoch: 2 cost time: 2.6685519218444824
Epoch: 2, Steps: 124 Train Loss: 3.1671 (Forecasting Loss:0.3154 + XiCon Loss:2.8517 x Lambda(1.0)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2800
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1792591
	speed: 0.0222s/iter; left time: 267.2974s
Epoch: 3 cost time: 2.702831506729126
Epoch: 3, Steps: 124 Train Loss: 3.1090 (Forecasting Loss:0.3029 + XiCon Loss:2.8061 x Lambda(1.0)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.2808
Validation loss decreased (0.344789 --> 0.337336).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0962081
	speed: 0.0217s/iter; left time: 259.4024s
Epoch: 4 cost time: 2.7125155925750732
Epoch: 4, Steps: 124 Train Loss: 3.1201 (Forecasting Loss:0.2976 + XiCon Loss:2.8225 x Lambda(1.0)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2828
Validation loss decreased (0.337336 --> 0.329367).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1890295
	speed: 0.0227s/iter; left time: 267.7797s
Epoch: 5 cost time: 2.78509783744812
Epoch: 5, Steps: 124 Train Loss: 3.1432 (Forecasting Loss:0.2945 + XiCon Loss:2.8488 x Lambda(1.0)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.2744
Validation loss decreased (0.329367 --> 0.328460).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3357587
	speed: 0.0232s/iter; left time: 271.2708s
Epoch: 6 cost time: 2.8450214862823486
Epoch: 6, Steps: 124 Train Loss: 3.1583 (Forecasting Loss:0.2927 + XiCon Loss:2.8656 x Lambda(1.0)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.2735
Validation loss decreased (0.328460 --> 0.327099).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1033549
	speed: 0.0225s/iter; left time: 259.9316s
Epoch: 7 cost time: 2.7523348331451416
Epoch: 7, Steps: 124 Train Loss: 3.1749 (Forecasting Loss:0.2915 + XiCon Loss:2.8834 x Lambda(1.0)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1914554
	speed: 0.0223s/iter; left time: 255.0021s
Epoch: 8 cost time: 2.7674572467803955
Epoch: 8, Steps: 124 Train Loss: 3.1850 (Forecasting Loss:0.2912 + XiCon Loss:2.8937 x Lambda(1.0)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2723
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0937181
	speed: 0.0228s/iter; left time: 257.8437s
Epoch: 9 cost time: 2.7678253650665283
Epoch: 9, Steps: 124 Train Loss: 3.1752 (Forecasting Loss:0.2909 + XiCon Loss:2.8843 x Lambda(1.0)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2730
Validation loss decreased (0.327099 --> 0.326955).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2644567
	speed: 0.0224s/iter; left time: 250.9485s
Epoch: 10 cost time: 2.762913227081299
Epoch: 10, Steps: 124 Train Loss: 3.1735 (Forecasting Loss:0.2909 + XiCon Loss:2.8826 x Lambda(1.0)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2730
Validation loss decreased (0.326955 --> 0.326195).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2224383
	speed: 0.0222s/iter; left time: 245.4152s
Epoch: 11 cost time: 2.723820447921753
Epoch: 11, Steps: 124 Train Loss: 3.1839 (Forecasting Loss:0.2907 + XiCon Loss:2.8932 x Lambda(1.0)), Vali MSE Loss: 0.3268 Test MSE Loss: 0.2730
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1457777
	speed: 0.0230s/iter; left time: 251.1957s
Epoch: 12 cost time: 2.8234236240386963
Epoch: 12, Steps: 124 Train Loss: 3.1790 (Forecasting Loss:0.2908 + XiCon Loss:2.8881 x Lambda(1.0)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.2730
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2810500
	speed: 0.0224s/iter; left time: 242.0992s
Epoch: 13 cost time: 2.7611846923828125
Epoch: 13, Steps: 124 Train Loss: 3.1789 (Forecasting Loss:0.2907 + XiCon Loss:2.8882 x Lambda(1.0)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2730
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1193545
	speed: 0.0232s/iter; left time: 247.5708s
Epoch: 14 cost time: 2.817312002182007
Epoch: 14, Steps: 124 Train Loss: 3.1824 (Forecasting Loss:0.2907 + XiCon Loss:2.8917 x Lambda(1.0)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2730
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0874789
	speed: 0.0224s/iter; left time: 236.5028s
Epoch: 15 cost time: 2.7445716857910156
Epoch: 15, Steps: 124 Train Loss: 3.1841 (Forecasting Loss:0.2907 + XiCon Loss:2.8934 x Lambda(1.0)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2730
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2278895
	speed: 0.0225s/iter; left time: 235.2194s
Epoch: 16 cost time: 2.7532708644866943
Epoch: 16, Steps: 124 Train Loss: 3.1839 (Forecasting Loss:0.2906 + XiCon Loss:2.8933 x Lambda(1.0)), Vali MSE Loss: 0.3265 Test MSE Loss: 0.2730
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1400919
	speed: 0.0222s/iter; left time: 229.2732s
Epoch: 17 cost time: 2.7350845336914062
Epoch: 17, Steps: 124 Train Loss: 3.1890 (Forecasting Loss:0.2908 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.2730
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2241774
	speed: 0.0227s/iter; left time: 231.2434s
Epoch: 18 cost time: 2.7923314571380615
Epoch: 18, Steps: 124 Train Loss: 3.1756 (Forecasting Loss:0.2906 + XiCon Loss:2.8850 x Lambda(1.0)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2730
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1683974
	speed: 0.0220s/iter; left time: 221.2631s
Epoch: 19 cost time: 2.713165283203125
Epoch: 19, Steps: 124 Train Loss: 3.1775 (Forecasting Loss:0.2906 + XiCon Loss:2.8868 x Lambda(1.0)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.2730
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2118640
	speed: 0.0224s/iter; left time: 222.4889s
Epoch: 20 cost time: 2.7124032974243164
Epoch: 20, Steps: 124 Train Loss: 3.1849 (Forecasting Loss:0.2910 + XiCon Loss:2.8940 x Lambda(1.0)), Vali MSE Loss: 0.3263 Test MSE Loss: 0.2730
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19238920509815216, mae:0.35364577174186707, mape:0.6775233745574951, mspe:18.049636840820312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1907+-0.00529, MAE:0.3535+-0.00887, MAPE:0.6951+-0.05632, MSPE:18.4225+-0.83456, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.6045885
	speed: 0.0218s/iter; left time: 254.8680s
Epoch: 1 cost time: 2.4995596408843994
Epoch: 1, Steps: 118 Train Loss: 3.6213 (Forecasting Loss:0.4746 + XiCon Loss:3.1467 x Lambda(1.0)), Vali MSE Loss: 0.4856 Test MSE Loss: 0.3741
Validation loss decreased (inf --> 0.485624).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4224977
	speed: 0.0190s/iter; left time: 220.2362s
Epoch: 2 cost time: 2.195068836212158
Epoch: 2, Steps: 118 Train Loss: 3.4273 (Forecasting Loss:0.3678 + XiCon Loss:3.0595 x Lambda(1.0)), Vali MSE Loss: 0.3880 Test MSE Loss: 0.2711
Validation loss decreased (0.485624 --> 0.388038).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2657468
	speed: 0.0189s/iter; left time: 217.2538s
Epoch: 3 cost time: 2.2082560062408447
Epoch: 3, Steps: 118 Train Loss: 3.2928 (Forecasting Loss:0.3201 + XiCon Loss:2.9727 x Lambda(1.0)), Vali MSE Loss: 0.3801 Test MSE Loss: 0.2849
Validation loss decreased (0.388038 --> 0.380061).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2518611
	speed: 0.0178s/iter; left time: 202.0300s
Epoch: 4 cost time: 2.134296417236328
Epoch: 4, Steps: 118 Train Loss: 3.2614 (Forecasting Loss:0.3100 + XiCon Loss:2.9514 x Lambda(1.0)), Vali MSE Loss: 0.3912 Test MSE Loss: 0.2852
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2437224
	speed: 0.0181s/iter; left time: 203.4174s
Epoch: 5 cost time: 2.1291604042053223
Epoch: 5, Steps: 118 Train Loss: 3.2496 (Forecasting Loss:0.3067 + XiCon Loss:2.9430 x Lambda(1.0)), Vali MSE Loss: 0.3826 Test MSE Loss: 0.2868
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2287893
	speed: 0.0183s/iter; left time: 203.5042s
Epoch: 6 cost time: 2.1418087482452393
Epoch: 6, Steps: 118 Train Loss: 3.2461 (Forecasting Loss:0.3054 + XiCon Loss:2.9407 x Lambda(1.0)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2853
Validation loss decreased (0.380061 --> 0.375214).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2432358
	speed: 0.0188s/iter; left time: 206.9422s
Epoch: 7 cost time: 2.1846046447753906
Epoch: 7, Steps: 118 Train Loss: 3.2412 (Forecasting Loss:0.3053 + XiCon Loss:2.9359 x Lambda(1.0)), Vali MSE Loss: 0.3726 Test MSE Loss: 0.2862
Validation loss decreased (0.375214 --> 0.372635).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2233601
	speed: 0.0184s/iter; left time: 200.0883s
Epoch: 8 cost time: 2.144747734069824
Epoch: 8, Steps: 118 Train Loss: 3.2409 (Forecasting Loss:0.3043 + XiCon Loss:2.9366 x Lambda(1.0)), Vali MSE Loss: 0.3743 Test MSE Loss: 0.2858
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2300031
	speed: 0.0178s/iter; left time: 191.6723s
Epoch: 9 cost time: 2.0979604721069336
Epoch: 9, Steps: 118 Train Loss: 3.2416 (Forecasting Loss:0.3049 + XiCon Loss:2.9367 x Lambda(1.0)), Vali MSE Loss: 0.3766 Test MSE Loss: 0.2857
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2282205
	speed: 0.0187s/iter; left time: 198.9196s
Epoch: 10 cost time: 2.182955265045166
Epoch: 10, Steps: 118 Train Loss: 3.2402 (Forecasting Loss:0.3045 + XiCon Loss:2.9358 x Lambda(1.0)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.2858
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2260802
	speed: 0.0181s/iter; left time: 190.9086s
Epoch: 11 cost time: 2.1447269916534424
Epoch: 11, Steps: 118 Train Loss: 3.2407 (Forecasting Loss:0.3045 + XiCon Loss:2.9362 x Lambda(1.0)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.2858
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2356310
	speed: 0.0178s/iter; left time: 185.1865s
Epoch: 12 cost time: 2.072765827178955
Epoch: 12, Steps: 118 Train Loss: 3.2415 (Forecasting Loss:0.3047 + XiCon Loss:2.9368 x Lambda(1.0)), Vali MSE Loss: 0.3761 Test MSE Loss: 0.2858
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2445381
	speed: 0.0188s/iter; left time: 193.7363s
Epoch: 13 cost time: 2.1985247135162354
Epoch: 13, Steps: 118 Train Loss: 3.2396 (Forecasting Loss:0.3048 + XiCon Loss:2.9348 x Lambda(1.0)), Vali MSE Loss: 0.3761 Test MSE Loss: 0.2858
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2330327
	speed: 0.0178s/iter; left time: 181.1556s
Epoch: 14 cost time: 2.1085195541381836
Epoch: 14, Steps: 118 Train Loss: 3.2403 (Forecasting Loss:0.3041 + XiCon Loss:2.9362 x Lambda(1.0)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2858
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2365797
	speed: 0.0189s/iter; left time: 189.8131s
Epoch: 15 cost time: 2.202397346496582
Epoch: 15, Steps: 118 Train Loss: 3.2402 (Forecasting Loss:0.3045 + XiCon Loss:2.9357 x Lambda(1.0)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2858
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2080727
	speed: 0.0190s/iter; left time: 188.8246s
Epoch: 16 cost time: 2.2273201942443848
Epoch: 16, Steps: 118 Train Loss: 3.2395 (Forecasting Loss:0.3043 + XiCon Loss:2.9352 x Lambda(1.0)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2858
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2300789
	speed: 0.0181s/iter; left time: 177.2606s
Epoch: 17 cost time: 2.1405370235443115
Epoch: 17, Steps: 118 Train Loss: 3.2409 (Forecasting Loss:0.3047 + XiCon Loss:2.9362 x Lambda(1.0)), Vali MSE Loss: 0.3757 Test MSE Loss: 0.2858
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2068459391593933, mae:0.36546754837036133, mape:0.7086694836616516, mspe:23.99365234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3954
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.5711107
	speed: 0.0182s/iter; left time: 212.9875s
Epoch: 1 cost time: 2.13004994392395
Epoch: 1, Steps: 118 Train Loss: 3.5903 (Forecasting Loss:0.4695 + XiCon Loss:3.1208 x Lambda(1.0)), Vali MSE Loss: 0.4569 Test MSE Loss: 0.3360
Validation loss decreased (inf --> 0.456917).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3639603
	speed: 0.0183s/iter; left time: 211.4048s
Epoch: 2 cost time: 2.1313211917877197
Epoch: 2, Steps: 118 Train Loss: 3.4246 (Forecasting Loss:0.3804 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.4136 Test MSE Loss: 0.3028
Validation loss decreased (0.456917 --> 0.413557).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2887988
	speed: 0.0192s/iter; left time: 219.7663s
Epoch: 3 cost time: 2.2346255779266357
Epoch: 3, Steps: 118 Train Loss: 3.3227 (Forecasting Loss:0.3635 + XiCon Loss:2.9592 x Lambda(1.0)), Vali MSE Loss: 0.4126 Test MSE Loss: 0.3039
Validation loss decreased (0.413557 --> 0.412620).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3042784
	speed: 0.0186s/iter; left time: 211.2818s
Epoch: 4 cost time: 2.2003376483917236
Epoch: 4, Steps: 118 Train Loss: 3.3019 (Forecasting Loss:0.3590 + XiCon Loss:2.9428 x Lambda(1.0)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3054
Validation loss decreased (0.412620 --> 0.411503).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2952511
	speed: 0.0185s/iter; left time: 207.3390s
Epoch: 5 cost time: 2.159167528152466
Epoch: 5, Steps: 118 Train Loss: 3.2938 (Forecasting Loss:0.3568 + XiCon Loss:2.9370 x Lambda(1.0)), Vali MSE Loss: 0.4113 Test MSE Loss: 0.3047
Validation loss decreased (0.411503 --> 0.411323).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2740064
	speed: 0.0190s/iter; left time: 210.7797s
Epoch: 6 cost time: 2.2653398513793945
Epoch: 6, Steps: 118 Train Loss: 3.2903 (Forecasting Loss:0.3556 + XiCon Loss:2.9348 x Lambda(1.0)), Vali MSE Loss: 0.4134 Test MSE Loss: 0.3077
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2870817
	speed: 0.0182s/iter; left time: 199.7582s
Epoch: 7 cost time: 2.1669232845306396
Epoch: 7, Steps: 118 Train Loss: 3.2904 (Forecasting Loss:0.3547 + XiCon Loss:2.9357 x Lambda(1.0)), Vali MSE Loss: 0.4103 Test MSE Loss: 0.3050
Validation loss decreased (0.411323 --> 0.410344).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2753544
	speed: 0.0181s/iter; left time: 197.1478s
Epoch: 8 cost time: 2.1312670707702637
Epoch: 8, Steps: 118 Train Loss: 3.2893 (Forecasting Loss:0.3539 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
Validation loss decreased (0.410344 --> 0.409776).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3120291
	speed: 0.0187s/iter; left time: 200.7596s
Epoch: 9 cost time: 2.179381847381592
Epoch: 9, Steps: 118 Train Loss: 3.2872 (Forecasting Loss:0.3535 + XiCon Loss:2.9336 x Lambda(1.0)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3041
Validation loss decreased (0.409776 --> 0.409583).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2531927
	speed: 0.0184s/iter; left time: 195.5956s
Epoch: 10 cost time: 2.152031660079956
Epoch: 10, Steps: 118 Train Loss: 3.2857 (Forecasting Loss:0.3534 + XiCon Loss:2.9322 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3040
Validation loss decreased (0.409583 --> 0.409031).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2961094
	speed: 0.0191s/iter; left time: 201.3195s
Epoch: 11 cost time: 2.228647470474243
Epoch: 11, Steps: 118 Train Loss: 3.2889 (Forecasting Loss:0.3533 + XiCon Loss:2.9356 x Lambda(1.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3041
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2698367
	speed: 0.0186s/iter; left time: 193.4608s
Epoch: 12 cost time: 2.160813808441162
Epoch: 12, Steps: 118 Train Loss: 3.2872 (Forecasting Loss:0.3533 + XiCon Loss:2.9339 x Lambda(1.0)), Vali MSE Loss: 0.4094 Test MSE Loss: 0.3041
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2509921
	speed: 0.0191s/iter; left time: 196.8338s
Epoch: 13 cost time: 2.2449986934661865
Epoch: 13, Steps: 118 Train Loss: 3.2870 (Forecasting Loss:0.3533 + XiCon Loss:2.9337 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2805853
	speed: 0.0188s/iter; left time: 191.3274s
Epoch: 14 cost time: 2.1907975673675537
Epoch: 14, Steps: 118 Train Loss: 3.2871 (Forecasting Loss:0.3530 + XiCon Loss:2.9341 x Lambda(1.0)), Vali MSE Loss: 0.4099 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.3101850
	speed: 0.0183s/iter; left time: 184.3380s
Epoch: 15 cost time: 2.18847393989563
Epoch: 15, Steps: 118 Train Loss: 3.2878 (Forecasting Loss:0.3531 + XiCon Loss:2.9347 x Lambda(1.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 0.3041
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.3490646
	speed: 0.0198s/iter; left time: 196.6068s
Epoch: 16 cost time: 2.299950361251831
Epoch: 16, Steps: 118 Train Loss: 3.2886 (Forecasting Loss:0.3535 + XiCon Loss:2.9351 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3041
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2928147
	speed: 0.0183s/iter; left time: 179.6729s
Epoch: 17 cost time: 2.19614577293396
Epoch: 17, Steps: 118 Train Loss: 3.2876 (Forecasting Loss:0.3529 + XiCon Loss:2.9346 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3041
Validation loss decreased (0.409031 --> 0.408967).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.3022158
	speed: 0.0190s/iter; left time: 183.9759s
Epoch: 18 cost time: 2.217372179031372
Epoch: 18, Steps: 118 Train Loss: 3.2870 (Forecasting Loss:0.3534 + XiCon Loss:2.9336 x Lambda(1.0)), Vali MSE Loss: 0.4101 Test MSE Loss: 0.3041
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2619946
	speed: 0.0201s/iter; left time: 192.7799s
Epoch: 19 cost time: 2.359994649887085
Epoch: 19, Steps: 118 Train Loss: 3.2879 (Forecasting Loss:0.3532 + XiCon Loss:2.9346 x Lambda(1.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 0.3041
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2562926
	speed: 0.0177s/iter; left time: 167.6749s
Epoch: 20 cost time: 2.079840898513794
Epoch: 20, Steps: 118 Train Loss: 3.2871 (Forecasting Loss:0.3531 + XiCon Loss:2.9340 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.3480492
	speed: 0.0188s/iter; left time: 176.0112s
Epoch: 21 cost time: 2.2068350315093994
Epoch: 21, Steps: 118 Train Loss: 3.2893 (Forecasting Loss:0.3536 + XiCon Loss:2.9356 x Lambda(1.0)), Vali MSE Loss: 0.4099 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.2413239
	speed: 0.0183s/iter; left time: 168.5520s
Epoch: 22 cost time: 2.1649439334869385
Epoch: 22, Steps: 118 Train Loss: 3.2884 (Forecasting Loss:0.3534 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.4088 Test MSE Loss: 0.3041
Validation loss decreased (0.408967 --> 0.408847).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.2663858
	speed: 0.0183s/iter; left time: 166.6869s
Epoch: 23 cost time: 2.131620407104492
Epoch: 23, Steps: 118 Train Loss: 3.2869 (Forecasting Loss:0.3536 + XiCon Loss:2.9333 x Lambda(1.0)), Vali MSE Loss: 0.4099 Test MSE Loss: 0.3041
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.2971656
	speed: 0.0185s/iter; left time: 166.5576s
Epoch: 24 cost time: 2.149231195449829
Epoch: 24, Steps: 118 Train Loss: 3.2892 (Forecasting Loss:0.3535 + XiCon Loss:2.9357 x Lambda(1.0)), Vali MSE Loss: 0.4094 Test MSE Loss: 0.3041
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.3298063
	speed: 0.0185s/iter; left time: 164.3581s
Epoch: 25 cost time: 2.1960723400115967
Epoch: 25, Steps: 118 Train Loss: 3.2873 (Forecasting Loss:0.3532 + XiCon Loss:2.9341 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.2491155
	speed: 0.0184s/iter; left time: 161.0087s
Epoch: 26 cost time: 2.1926896572113037
Epoch: 26, Steps: 118 Train Loss: 3.2864 (Forecasting Loss:0.3536 + XiCon Loss:2.9329 x Lambda(1.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 3.2789197
	speed: 0.0190s/iter; left time: 164.4350s
Epoch: 27 cost time: 2.2616405487060547
Epoch: 27, Steps: 118 Train Loss: 3.2896 (Forecasting Loss:0.3539 + XiCon Loss:2.9357 x Lambda(1.0)), Vali MSE Loss: 0.4102 Test MSE Loss: 0.3041
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 3.2679305
	speed: 0.0187s/iter; left time: 158.8213s
Epoch: 28 cost time: 2.164915084838867
Epoch: 28, Steps: 118 Train Loss: 3.2881 (Forecasting Loss:0.3527 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3041
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 3.3500454
	speed: 0.0181s/iter; left time: 151.9975s
Epoch: 29 cost time: 2.135288715362549
Epoch: 29, Steps: 118 Train Loss: 3.2889 (Forecasting Loss:0.3534 + XiCon Loss:2.9355 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 3.2950475
	speed: 0.0187s/iter; left time: 154.4108s
Epoch: 30 cost time: 2.163914918899536
Epoch: 30, Steps: 118 Train Loss: 3.2881 (Forecasting Loss:0.3532 + XiCon Loss:2.9349 x Lambda(1.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3041
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 3.3026662
	speed: 0.0185s/iter; left time: 150.7355s
Epoch: 31 cost time: 2.1787242889404297
Epoch: 31, Steps: 118 Train Loss: 3.2888 (Forecasting Loss:0.3533 + XiCon Loss:2.9355 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3041
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 3.2952893
	speed: 0.0185s/iter; left time: 148.8132s
Epoch: 32 cost time: 2.15474534034729
Epoch: 32, Steps: 118 Train Loss: 3.2862 (Forecasting Loss:0.3533 + XiCon Loss:2.9329 x Lambda(1.0)), Vali MSE Loss: 0.4088 Test MSE Loss: 0.3041
Validation loss decreased (0.408847 --> 0.408818).  Saving model ...
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 3.2676573
	speed: 0.0183s/iter; left time: 145.2064s
Epoch: 33 cost time: 2.1438143253326416
Epoch: 33, Steps: 118 Train Loss: 3.2891 (Forecasting Loss:0.3537 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.4092 Test MSE Loss: 0.3041
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 3.3147452
	speed: 0.0188s/iter; left time: 146.8733s
Epoch: 34 cost time: 2.1910154819488525
Epoch: 34, Steps: 118 Train Loss: 3.2871 (Forecasting Loss:0.3529 + XiCon Loss:2.9342 x Lambda(1.0)), Vali MSE Loss: 0.4099 Test MSE Loss: 0.3041
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 3.3273168
	speed: 0.0183s/iter; left time: 140.3508s
Epoch: 35 cost time: 2.1689085960388184
Epoch: 35, Steps: 118 Train Loss: 3.2885 (Forecasting Loss:0.3535 + XiCon Loss:2.9349 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 3.2457333
	speed: 0.0193s/iter; left time: 146.1289s
Epoch: 36 cost time: 2.2714688777923584
Epoch: 36, Steps: 118 Train Loss: 3.2856 (Forecasting Loss:0.3530 + XiCon Loss:2.9325 x Lambda(1.0)), Vali MSE Loss: 0.4100 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 3.2511489
	speed: 0.0188s/iter; left time: 140.2104s
Epoch: 37 cost time: 2.1908435821533203
Epoch: 37, Steps: 118 Train Loss: 3.2871 (Forecasting Loss:0.3534 + XiCon Loss:2.9337 x Lambda(1.0)), Vali MSE Loss: 0.4092 Test MSE Loss: 0.3041
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 3.3066881
	speed: 0.0183s/iter; left time: 134.2255s
Epoch: 38 cost time: 2.147599697113037
Epoch: 38, Steps: 118 Train Loss: 3.2881 (Forecasting Loss:0.3535 + XiCon Loss:2.9346 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3041
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 3.2718747
	speed: 0.0189s/iter; left time: 136.1023s
Epoch: 39 cost time: 2.1886258125305176
Epoch: 39, Steps: 118 Train Loss: 3.2876 (Forecasting Loss:0.3537 + XiCon Loss:2.9339 x Lambda(1.0)), Vali MSE Loss: 0.4092 Test MSE Loss: 0.3041
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-15
	iters: 100, epoch: 40 | loss: 3.2900972
	speed: 0.0188s/iter; left time: 133.7291s
Epoch: 40 cost time: 2.216465473175049
Epoch: 40, Steps: 118 Train Loss: 3.2875 (Forecasting Loss:0.3524 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3041
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-15
	iters: 100, epoch: 41 | loss: 3.2516541
	speed: 0.0188s/iter; left time: 131.3634s
Epoch: 41 cost time: 2.2104597091674805
Epoch: 41, Steps: 118 Train Loss: 3.2890 (Forecasting Loss:0.3534 + XiCon Loss:2.9355 x Lambda(1.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 0.3041
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-16
	iters: 100, epoch: 42 | loss: 3.3191102
	speed: 0.0186s/iter; left time: 127.4708s
Epoch: 42 cost time: 2.1531472206115723
Epoch: 42, Steps: 118 Train Loss: 3.2882 (Forecasting Loss:0.3532 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3041
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2254744917154312, mae:0.3827701807022095, mape:0.6441506743431091, mspe:14.774088859558105 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3498
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.5647516
	speed: 0.0188s/iter; left time: 220.2609s
Epoch: 1 cost time: 2.2127864360809326
Epoch: 1, Steps: 118 Train Loss: 3.6069 (Forecasting Loss:0.4703 + XiCon Loss:3.1366 x Lambda(1.0)), Vali MSE Loss: 0.4902 Test MSE Loss: 0.3806
Validation loss decreased (inf --> 0.490168).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3567686
	speed: 0.0182s/iter; left time: 210.2379s
Epoch: 2 cost time: 2.150805711746216
Epoch: 2, Steps: 118 Train Loss: 3.4287 (Forecasting Loss:0.3788 + XiCon Loss:3.0500 x Lambda(1.0)), Vali MSE Loss: 0.4185 Test MSE Loss: 0.2967
Validation loss decreased (0.490168 --> 0.418460).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3382983
	speed: 0.0194s/iter; left time: 222.7030s
Epoch: 3 cost time: 2.2593815326690674
Epoch: 3, Steps: 118 Train Loss: 3.3160 (Forecasting Loss:0.3594 + XiCon Loss:2.9566 x Lambda(1.0)), Vali MSE Loss: 0.4041 Test MSE Loss: 0.2916
Validation loss decreased (0.418460 --> 0.404084).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3017089
	speed: 0.0184s/iter; left time: 208.4460s
Epoch: 4 cost time: 2.1770458221435547
Epoch: 4, Steps: 118 Train Loss: 3.2863 (Forecasting Loss:0.3506 + XiCon Loss:2.9357 x Lambda(1.0)), Vali MSE Loss: 0.3955 Test MSE Loss: 0.2797
Validation loss decreased (0.404084 --> 0.395529).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2951622
	speed: 0.0187s/iter; left time: 209.8210s
Epoch: 5 cost time: 2.20979380607605
Epoch: 5, Steps: 118 Train Loss: 3.2766 (Forecasting Loss:0.3422 + XiCon Loss:2.9344 x Lambda(1.0)), Vali MSE Loss: 0.3817 Test MSE Loss: 0.2665
Validation loss decreased (0.395529 --> 0.381664).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3273520
	speed: 0.0184s/iter; left time: 204.6942s
Epoch: 6 cost time: 2.1954383850097656
Epoch: 6, Steps: 118 Train Loss: 3.2683 (Forecasting Loss:0.3377 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.3816 Test MSE Loss: 0.2659
Validation loss decreased (0.381664 --> 0.381562).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2419698
	speed: 0.0189s/iter; left time: 208.1948s
Epoch: 7 cost time: 2.1913342475891113
Epoch: 7, Steps: 118 Train Loss: 3.2643 (Forecasting Loss:0.3345 + XiCon Loss:2.9298 x Lambda(1.0)), Vali MSE Loss: 0.3804 Test MSE Loss: 0.2652
Validation loss decreased (0.381562 --> 0.380384).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2815382
	speed: 0.0184s/iter; left time: 199.8641s
Epoch: 8 cost time: 2.1638314723968506
Epoch: 8, Steps: 118 Train Loss: 3.2626 (Forecasting Loss:0.3331 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.3809 Test MSE Loss: 0.2658
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2504041
	speed: 0.0188s/iter; left time: 202.1911s
Epoch: 9 cost time: 2.183976173400879
Epoch: 9, Steps: 118 Train Loss: 3.2641 (Forecasting Loss:0.3328 + XiCon Loss:2.9313 x Lambda(1.0)), Vali MSE Loss: 0.3802 Test MSE Loss: 0.2653
Validation loss decreased (0.380384 --> 0.380176).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2502632
	speed: 0.0192s/iter; left time: 204.1585s
Epoch: 10 cost time: 2.240997314453125
Epoch: 10, Steps: 118 Train Loss: 3.2634 (Forecasting Loss:0.3326 + XiCon Loss:2.9308 x Lambda(1.0)), Vali MSE Loss: 0.3794 Test MSE Loss: 0.2652
Validation loss decreased (0.380176 --> 0.379374).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2500575
	speed: 0.0186s/iter; left time: 195.3577s
Epoch: 11 cost time: 2.1528799533843994
Epoch: 11, Steps: 118 Train Loss: 3.2600 (Forecasting Loss:0.3323 + XiCon Loss:2.9277 x Lambda(1.0)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.2653
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2393949
	speed: 0.0185s/iter; left time: 191.9606s
Epoch: 12 cost time: 2.1383306980133057
Epoch: 12, Steps: 118 Train Loss: 3.2631 (Forecasting Loss:0.3323 + XiCon Loss:2.9308 x Lambda(1.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.2652
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2625394
	speed: 0.0187s/iter; left time: 191.9521s
Epoch: 13 cost time: 2.1886696815490723
Epoch: 13, Steps: 118 Train Loss: 3.2623 (Forecasting Loss:0.3322 + XiCon Loss:2.9301 x Lambda(1.0)), Vali MSE Loss: 0.3797 Test MSE Loss: 0.2652
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2868683
	speed: 0.0187s/iter; left time: 189.8042s
Epoch: 14 cost time: 2.1790096759796143
Epoch: 14, Steps: 118 Train Loss: 3.2622 (Forecasting Loss:0.3323 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.3804 Test MSE Loss: 0.2652
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2575924
	speed: 0.0185s/iter; left time: 185.5606s
Epoch: 15 cost time: 2.145136833190918
Epoch: 15, Steps: 118 Train Loss: 3.2617 (Forecasting Loss:0.3319 + XiCon Loss:2.9298 x Lambda(1.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.2652
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2343261
	speed: 0.0188s/iter; left time: 186.3541s
Epoch: 16 cost time: 2.191819906234741
Epoch: 16, Steps: 118 Train Loss: 3.2606 (Forecasting Loss:0.3319 + XiCon Loss:2.9287 x Lambda(1.0)), Vali MSE Loss: 0.3803 Test MSE Loss: 0.2652
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2353766
	speed: 0.0186s/iter; left time: 182.6674s
Epoch: 17 cost time: 2.1611733436584473
Epoch: 17, Steps: 118 Train Loss: 3.2606 (Forecasting Loss:0.3324 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.3789 Test MSE Loss: 0.2652
Validation loss decreased (0.379374 --> 0.378921).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.2541404
	speed: 0.0186s/iter; left time: 180.3355s
Epoch: 18 cost time: 2.173318386077881
Epoch: 18, Steps: 118 Train Loss: 3.2629 (Forecasting Loss:0.3320 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.3800 Test MSE Loss: 0.2652
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2902298
	speed: 0.0186s/iter; left time: 178.1349s
Epoch: 19 cost time: 2.2250795364379883
Epoch: 19, Steps: 118 Train Loss: 3.2624 (Forecasting Loss:0.3317 + XiCon Loss:2.9307 x Lambda(1.0)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.2652
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2229428
	speed: 0.0186s/iter; left time: 175.9382s
Epoch: 20 cost time: 2.1651837825775146
Epoch: 20, Steps: 118 Train Loss: 3.2625 (Forecasting Loss:0.3321 + XiCon Loss:2.9304 x Lambda(1.0)), Vali MSE Loss: 0.3810 Test MSE Loss: 0.2652
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.2738161
	speed: 0.0193s/iter; left time: 179.8483s
Epoch: 21 cost time: 2.2478256225585938
Epoch: 21, Steps: 118 Train Loss: 3.2617 (Forecasting Loss:0.3321 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.3800 Test MSE Loss: 0.2652
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.2969699
	speed: 0.0196s/iter; left time: 180.3328s
Epoch: 22 cost time: 2.282684564590454
Epoch: 22, Steps: 118 Train Loss: 3.2613 (Forecasting Loss:0.3320 + XiCon Loss:2.9293 x Lambda(1.0)), Vali MSE Loss: 0.3800 Test MSE Loss: 0.2652
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.2631934
	speed: 0.0179s/iter; left time: 163.2809s
Epoch: 23 cost time: 2.113633871078491
Epoch: 23, Steps: 118 Train Loss: 3.2621 (Forecasting Loss:0.3322 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.3791 Test MSE Loss: 0.2652
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.2512434
	speed: 0.0188s/iter; left time: 168.8179s
Epoch: 24 cost time: 2.1887669563293457
Epoch: 24, Steps: 118 Train Loss: 3.2610 (Forecasting Loss:0.3318 + XiCon Loss:2.9292 x Lambda(1.0)), Vali MSE Loss: 0.3796 Test MSE Loss: 0.2652
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.2381172
	speed: 0.0184s/iter; left time: 163.3523s
Epoch: 25 cost time: 2.2065093517303467
Epoch: 25, Steps: 118 Train Loss: 3.2639 (Forecasting Loss:0.3325 + XiCon Loss:2.9315 x Lambda(1.0)), Vali MSE Loss: 0.3793 Test MSE Loss: 0.2652
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.2563872
	speed: 0.0192s/iter; left time: 168.1991s
Epoch: 26 cost time: 2.242208480834961
Epoch: 26, Steps: 118 Train Loss: 3.2627 (Forecasting Loss:0.3320 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.2652
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 3.2755957
	speed: 0.0185s/iter; left time: 159.3473s
Epoch: 27 cost time: 2.157109022140503
Epoch: 27, Steps: 118 Train Loss: 3.2618 (Forecasting Loss:0.3320 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.3804 Test MSE Loss: 0.2652
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18307353556156158, mae:0.34724485874176025, mape:0.6399232745170593, mspe:18.736299514770508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.5673037
	speed: 0.0188s/iter; left time: 219.7194s
Epoch: 1 cost time: 2.206713914871216
Epoch: 1, Steps: 118 Train Loss: 3.6219 (Forecasting Loss:0.4785 + XiCon Loss:3.1435 x Lambda(1.0)), Vali MSE Loss: 0.4954 Test MSE Loss: 0.3862
Validation loss decreased (inf --> 0.495420).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3970850
	speed: 0.0195s/iter; left time: 225.9937s
Epoch: 2 cost time: 2.266096353530884
Epoch: 2, Steps: 118 Train Loss: 3.4295 (Forecasting Loss:0.3667 + XiCon Loss:3.0628 x Lambda(1.0)), Vali MSE Loss: 0.3793 Test MSE Loss: 0.2740
Validation loss decreased (0.495420 --> 0.379293).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3021920
	speed: 0.0190s/iter; left time: 217.4665s
Epoch: 3 cost time: 2.258176326751709
Epoch: 3, Steps: 118 Train Loss: 3.3085 (Forecasting Loss:0.3129 + XiCon Loss:2.9956 x Lambda(1.0)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.2816
Validation loss decreased (0.379293 --> 0.359991).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2973676
	speed: 0.0187s/iter; left time: 212.5516s
Epoch: 4 cost time: 2.202089309692383
Epoch: 4, Steps: 118 Train Loss: 3.2785 (Forecasting Loss:0.3046 + XiCon Loss:2.9739 x Lambda(1.0)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.2834
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2864103
	speed: 0.0181s/iter; left time: 203.5794s
Epoch: 5 cost time: 2.1155810356140137
Epoch: 5, Steps: 118 Train Loss: 3.2691 (Forecasting Loss:0.3018 + XiCon Loss:2.9673 x Lambda(1.0)), Vali MSE Loss: 0.3554 Test MSE Loss: 0.2858
Validation loss decreased (0.359991 --> 0.355390).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2738423
	speed: 0.0185s/iter; left time: 205.4555s
Epoch: 6 cost time: 2.198500156402588
Epoch: 6, Steps: 118 Train Loss: 3.2633 (Forecasting Loss:0.3002 + XiCon Loss:2.9631 x Lambda(1.0)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.2838
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2484732
	speed: 0.0189s/iter; left time: 207.2746s
Epoch: 7 cost time: 2.1912472248077393
Epoch: 7, Steps: 118 Train Loss: 3.2601 (Forecasting Loss:0.2989 + XiCon Loss:2.9611 x Lambda(1.0)), Vali MSE Loss: 0.3636 Test MSE Loss: 0.2827
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2281809
	speed: 0.0181s/iter; left time: 196.9923s
Epoch: 8 cost time: 2.11723256111145
Epoch: 8, Steps: 118 Train Loss: 3.2592 (Forecasting Loss:0.2992 + XiCon Loss:2.9600 x Lambda(1.0)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.2829
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2642250
	speed: 0.0186s/iter; left time: 199.6493s
Epoch: 9 cost time: 2.1525423526763916
Epoch: 9, Steps: 118 Train Loss: 3.2582 (Forecasting Loss:0.2985 + XiCon Loss:2.9597 x Lambda(1.0)), Vali MSE Loss: 0.3593 Test MSE Loss: 0.2830
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2893963
	speed: 0.0187s/iter; left time: 198.8100s
Epoch: 10 cost time: 2.18546462059021
Epoch: 10, Steps: 118 Train Loss: 3.2567 (Forecasting Loss:0.2983 + XiCon Loss:2.9584 x Lambda(1.0)), Vali MSE Loss: 0.3596 Test MSE Loss: 0.2830
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2726300
	speed: 0.0190s/iter; left time: 200.2425s
Epoch: 11 cost time: 2.235724925994873
Epoch: 11, Steps: 118 Train Loss: 3.2573 (Forecasting Loss:0.2988 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.3595 Test MSE Loss: 0.2831
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2429845
	speed: 0.0187s/iter; left time: 194.0560s
Epoch: 12 cost time: 2.2290871143341064
Epoch: 12, Steps: 118 Train Loss: 3.2566 (Forecasting Loss:0.2986 + XiCon Loss:2.9580 x Lambda(1.0)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.2830
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2410455
	speed: 0.0185s/iter; left time: 190.3127s
Epoch: 13 cost time: 2.1707966327667236
Epoch: 13, Steps: 118 Train Loss: 3.2564 (Forecasting Loss:0.2983 + XiCon Loss:2.9581 x Lambda(1.0)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.2830
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2828555
	speed: 0.0191s/iter; left time: 194.6286s
Epoch: 14 cost time: 2.2383289337158203
Epoch: 14, Steps: 118 Train Loss: 3.2580 (Forecasting Loss:0.2985 + XiCon Loss:2.9595 x Lambda(1.0)), Vali MSE Loss: 0.3591 Test MSE Loss: 0.2830
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2525692
	speed: 0.0183s/iter; left time: 184.1765s
Epoch: 15 cost time: 2.172668933868408
Epoch: 15, Steps: 118 Train Loss: 3.2595 (Forecasting Loss:0.2989 + XiCon Loss:2.9606 x Lambda(1.0)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2830
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20679469406604767, mae:0.36478015780448914, mape:0.7179035544395447, mspe:24.72658920288086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3675
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.5904145
	speed: 0.0185s/iter; left time: 216.6806s
Epoch: 1 cost time: 2.153148889541626
Epoch: 1, Steps: 118 Train Loss: 3.6440 (Forecasting Loss:0.4780 + XiCon Loss:3.1660 x Lambda(1.0)), Vali MSE Loss: 0.4584 Test MSE Loss: 0.3299
Validation loss decreased (inf --> 0.458378).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3352289
	speed: 0.0183s/iter; left time: 211.5451s
Epoch: 2 cost time: 2.1780779361724854
Epoch: 2, Steps: 118 Train Loss: 3.4308 (Forecasting Loss:0.3829 + XiCon Loss:3.0480 x Lambda(1.0)), Vali MSE Loss: 0.4180 Test MSE Loss: 0.3104
Validation loss decreased (0.458378 --> 0.418035).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2776556
	speed: 0.0187s/iter; left time: 214.6557s
Epoch: 3 cost time: 2.16926646232605
Epoch: 3, Steps: 118 Train Loss: 3.3232 (Forecasting Loss:0.3643 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.4172 Test MSE Loss: 0.3103
Validation loss decreased (0.418035 --> 0.417173).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3271339
	speed: 0.0176s/iter; left time: 199.5270s
Epoch: 4 cost time: 2.055382013320923
Epoch: 4, Steps: 118 Train Loss: 3.3003 (Forecasting Loss:0.3608 + XiCon Loss:2.9395 x Lambda(1.0)), Vali MSE Loss: 0.4170 Test MSE Loss: 0.3079
Validation loss decreased (0.417173 --> 0.417024).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2528532
	speed: 0.0190s/iter; left time: 212.9323s
Epoch: 5 cost time: 2.208711624145508
Epoch: 5, Steps: 118 Train Loss: 3.2925 (Forecasting Loss:0.3591 + XiCon Loss:2.9334 x Lambda(1.0)), Vali MSE Loss: 0.4155 Test MSE Loss: 0.3072
Validation loss decreased (0.417024 --> 0.415463).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2171776
	speed: 0.0194s/iter; left time: 215.1763s
Epoch: 6 cost time: 2.2419252395629883
Epoch: 6, Steps: 118 Train Loss: 3.2875 (Forecasting Loss:0.3579 + XiCon Loss:2.9295 x Lambda(1.0)), Vali MSE Loss: 0.4145 Test MSE Loss: 0.3071
Validation loss decreased (0.415463 --> 0.414550).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2626402
	speed: 0.0182s/iter; left time: 200.6111s
Epoch: 7 cost time: 2.132216215133667
Epoch: 7, Steps: 118 Train Loss: 3.2857 (Forecasting Loss:0.3573 + XiCon Loss:2.9284 x Lambda(1.0)), Vali MSE Loss: 0.4158 Test MSE Loss: 0.3079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3223739
	speed: 0.0193s/iter; left time: 209.4076s
Epoch: 8 cost time: 2.241384267807007
Epoch: 8, Steps: 118 Train Loss: 3.2850 (Forecasting Loss:0.3575 + XiCon Loss:2.9275 x Lambda(1.0)), Vali MSE Loss: 0.4144 Test MSE Loss: 0.3077
Validation loss decreased (0.414550 --> 0.414353).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2989051
	speed: 0.0188s/iter; left time: 201.7687s
Epoch: 9 cost time: 2.1967415809631348
Epoch: 9, Steps: 118 Train Loss: 3.2833 (Forecasting Loss:0.3575 + XiCon Loss:2.9259 x Lambda(1.0)), Vali MSE Loss: 0.4149 Test MSE Loss: 0.3076
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2222688
	speed: 0.0184s/iter; left time: 195.6600s
Epoch: 10 cost time: 2.1631295680999756
Epoch: 10, Steps: 118 Train Loss: 3.2856 (Forecasting Loss:0.3566 + XiCon Loss:2.9290 x Lambda(1.0)), Vali MSE Loss: 0.4150 Test MSE Loss: 0.3075
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2750885
	speed: 0.0183s/iter; left time: 192.0734s
Epoch: 11 cost time: 2.15271258354187
Epoch: 11, Steps: 118 Train Loss: 3.2868 (Forecasting Loss:0.3571 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.4160 Test MSE Loss: 0.3075
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2573464
	speed: 0.0195s/iter; left time: 203.1693s
Epoch: 12 cost time: 2.280127763748169
Epoch: 12, Steps: 118 Train Loss: 3.2867 (Forecasting Loss:0.3572 + XiCon Loss:2.9295 x Lambda(1.0)), Vali MSE Loss: 0.4157 Test MSE Loss: 0.3076
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.3042071
	speed: 0.0187s/iter; left time: 191.8355s
Epoch: 13 cost time: 2.16270112991333
Epoch: 13, Steps: 118 Train Loss: 3.2854 (Forecasting Loss:0.3566 + XiCon Loss:2.9288 x Lambda(1.0)), Vali MSE Loss: 0.4156 Test MSE Loss: 0.3076
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.3565993
	speed: 0.0189s/iter; left time: 192.3504s
Epoch: 14 cost time: 2.208965539932251
Epoch: 14, Steps: 118 Train Loss: 3.2861 (Forecasting Loss:0.3569 + XiCon Loss:2.9292 x Lambda(1.0)), Vali MSE Loss: 0.4159 Test MSE Loss: 0.3076
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2821538
	speed: 0.0183s/iter; left time: 184.3499s
Epoch: 15 cost time: 2.129546642303467
Epoch: 15, Steps: 118 Train Loss: 3.2841 (Forecasting Loss:0.3567 + XiCon Loss:2.9273 x Lambda(1.0)), Vali MSE Loss: 0.4149 Test MSE Loss: 0.3076
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2909753
	speed: 0.0189s/iter; left time: 187.5794s
Epoch: 16 cost time: 2.211843490600586
Epoch: 16, Steps: 118 Train Loss: 3.2839 (Forecasting Loss:0.3565 + XiCon Loss:2.9274 x Lambda(1.0)), Vali MSE Loss: 0.4156 Test MSE Loss: 0.3076
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2885885
	speed: 0.0184s/iter; left time: 180.6990s
Epoch: 17 cost time: 2.1349570751190186
Epoch: 17, Steps: 118 Train Loss: 3.2834 (Forecasting Loss:0.3565 + XiCon Loss:2.9270 x Lambda(1.0)), Vali MSE Loss: 0.4160 Test MSE Loss: 0.3076
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.2774982
	speed: 0.0184s/iter; left time: 178.0033s
Epoch: 18 cost time: 2.146416425704956
Epoch: 18, Steps: 118 Train Loss: 3.2844 (Forecasting Loss:0.3567 + XiCon Loss:2.9277 x Lambda(1.0)), Vali MSE Loss: 0.4157 Test MSE Loss: 0.3076
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2299126535654068, mae:0.385405033826828, mape:0.6547887921333313, mspe:15.629804611206055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2104+-0.02307, MAE:0.3691+-0.01926, MAPE:0.6731+-0.04624, MSPE:19.5721+-5.73657, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9203
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3711743
	speed: 0.0435s/iter; left time: 1151.5440s
	iters: 200, epoch: 1 | loss: 3.2982383
	speed: 0.0370s/iter; left time: 977.2924s
Epoch: 1 cost time: 10.478865146636963
Epoch: 1, Steps: 266 Train Loss: 3.3804 (Forecasting Loss:0.1679 + XiCon Loss:3.2126 x Lambda(1.0)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.0790
Validation loss decreased (inf --> 0.115010).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3191791
	speed: 0.0413s/iter; left time: 1084.1551s
	iters: 200, epoch: 2 | loss: 3.2907712
	speed: 0.0388s/iter; left time: 1014.6883s
Epoch: 2 cost time: 10.540612936019897
Epoch: 2, Steps: 266 Train Loss: 3.3393 (Forecasting Loss:0.1503 + XiCon Loss:3.1890 x Lambda(1.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.0762
Validation loss decreased (0.115010 --> 0.111697).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3505950
	speed: 0.0414s/iter; left time: 1073.9419s
	iters: 200, epoch: 3 | loss: 3.1871562
	speed: 0.0383s/iter; left time: 990.3250s
Epoch: 3 cost time: 10.535339593887329
Epoch: 3, Steps: 266 Train Loss: 3.2397 (Forecasting Loss:0.1451 + XiCon Loss:3.0945 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.0764
Validation loss decreased (0.111697 --> 0.109631).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1592295
	speed: 0.0416s/iter; left time: 1069.7714s
	iters: 200, epoch: 4 | loss: 3.1973403
	speed: 0.0388s/iter; left time: 992.4112s
Epoch: 4 cost time: 10.566052198410034
Epoch: 4, Steps: 266 Train Loss: 3.2212 (Forecasting Loss:0.1432 + XiCon Loss:3.0779 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0753
Validation loss decreased (0.109631 --> 0.108572).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1886487
	speed: 0.0412s/iter; left time: 1048.5763s
	iters: 200, epoch: 5 | loss: 3.1945710
	speed: 0.0390s/iter; left time: 987.2326s
Epoch: 5 cost time: 10.648374795913696
Epoch: 5, Steps: 266 Train Loss: 3.2150 (Forecasting Loss:0.1424 + XiCon Loss:3.0726 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0748
Validation loss decreased (0.108572 --> 0.107790).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1921315
	speed: 0.0406s/iter; left time: 1022.3541s
	iters: 200, epoch: 6 | loss: 3.1854351
	speed: 0.0383s/iter; left time: 960.8561s
Epoch: 6 cost time: 10.450116634368896
Epoch: 6, Steps: 266 Train Loss: 3.2073 (Forecasting Loss:0.1420 + XiCon Loss:3.0652 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0746
Validation loss decreased (0.107790 --> 0.107679).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1274824
	speed: 0.0415s/iter; left time: 1034.3152s
	iters: 200, epoch: 7 | loss: 3.1546884
	speed: 0.0389s/iter; left time: 963.6794s
Epoch: 7 cost time: 10.665817260742188
Epoch: 7, Steps: 266 Train Loss: 3.2049 (Forecasting Loss:0.1417 + XiCon Loss:3.0631 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
Validation loss decreased (0.107679 --> 0.107454).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2656410
	speed: 0.0406s/iter; left time: 1000.3426s
	iters: 200, epoch: 8 | loss: 3.1972384
	speed: 0.0382s/iter; left time: 936.1782s
Epoch: 8 cost time: 10.23835563659668
Epoch: 8, Steps: 266 Train Loss: 3.2056 (Forecasting Loss:0.1416 + XiCon Loss:3.0640 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0746
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1726074
	speed: 0.0375s/iter; left time: 912.8068s
	iters: 200, epoch: 9 | loss: 3.1778693
	speed: 0.0387s/iter; left time: 939.0325s
Epoch: 9 cost time: 10.224962711334229
Epoch: 9, Steps: 266 Train Loss: 3.2040 (Forecasting Loss:0.1415 + XiCon Loss:3.0625 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0746
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1926408
	speed: 0.0401s/iter; left time: 967.7980s
	iters: 200, epoch: 10 | loss: 3.1748514
	speed: 0.0383s/iter; left time: 918.8463s
Epoch: 10 cost time: 10.458282709121704
Epoch: 10, Steps: 266 Train Loss: 3.2060 (Forecasting Loss:0.1415 + XiCon Loss:3.0645 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2401731
	speed: 0.0401s/iter; left time: 956.0267s
	iters: 200, epoch: 11 | loss: 3.2148714
	speed: 0.0391s/iter; left time: 927.6320s
Epoch: 11 cost time: 10.44175386428833
Epoch: 11, Steps: 266 Train Loss: 3.1997 (Forecasting Loss:0.1415 + XiCon Loss:3.0583 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
Validation loss decreased (0.107454 --> 0.107451).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1532500
	speed: 0.0404s/iter; left time: 951.9061s
	iters: 200, epoch: 12 | loss: 3.2264066
	speed: 0.0386s/iter; left time: 906.4047s
Epoch: 12 cost time: 10.470343112945557
Epoch: 12, Steps: 266 Train Loss: 3.2042 (Forecasting Loss:0.1415 + XiCon Loss:3.0628 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
Validation loss decreased (0.107451 --> 0.107438).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1822360
	speed: 0.0405s/iter; left time: 943.7888s
	iters: 200, epoch: 13 | loss: 3.2063682
	speed: 0.0383s/iter; left time: 889.5811s
Epoch: 13 cost time: 10.499008178710938
Epoch: 13, Steps: 266 Train Loss: 3.2083 (Forecasting Loss:0.1415 + XiCon Loss:3.0668 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1377835
	speed: 0.0411s/iter; left time: 946.3307s
	iters: 200, epoch: 14 | loss: 3.2374165
	speed: 0.0395s/iter; left time: 905.1458s
Epoch: 14 cost time: 10.67982029914856
Epoch: 14, Steps: 266 Train Loss: 3.2030 (Forecasting Loss:0.1415 + XiCon Loss:3.0615 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
Validation loss decreased (0.107438 --> 0.107381).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2386642
	speed: 0.0405s/iter; left time: 922.4494s
	iters: 200, epoch: 15 | loss: 3.1267922
	speed: 0.0381s/iter; left time: 864.0065s
Epoch: 15 cost time: 10.380527257919312
Epoch: 15, Steps: 266 Train Loss: 3.2044 (Forecasting Loss:0.1415 + XiCon Loss:3.0629 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2993937
	speed: 0.0414s/iter; left time: 932.1793s
	iters: 200, epoch: 16 | loss: 3.2658617
	speed: 0.0377s/iter; left time: 845.7614s
Epoch: 16 cost time: 10.42743706703186
Epoch: 16, Steps: 266 Train Loss: 3.2018 (Forecasting Loss:0.1414 + XiCon Loss:3.0603 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1731322
	speed: 0.0406s/iter; left time: 902.4180s
	iters: 200, epoch: 17 | loss: 3.2458072
	speed: 0.0391s/iter; left time: 865.5883s
Epoch: 17 cost time: 10.513797998428345
Epoch: 17, Steps: 266 Train Loss: 3.2029 (Forecasting Loss:0.1414 + XiCon Loss:3.0614 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2098329
	speed: 0.0409s/iter; left time: 899.1120s
	iters: 200, epoch: 18 | loss: 3.1717124
	speed: 0.0353s/iter; left time: 771.7552s
Epoch: 18 cost time: 9.930838823318481
Epoch: 18, Steps: 266 Train Loss: 3.1991 (Forecasting Loss:0.1415 + XiCon Loss:3.0576 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2385459
	speed: 0.0402s/iter; left time: 873.2395s
	iters: 200, epoch: 19 | loss: 3.1297846
	speed: 0.0384s/iter; left time: 830.3655s
Epoch: 19 cost time: 10.423504114151001
Epoch: 19, Steps: 266 Train Loss: 3.2033 (Forecasting Loss:0.1415 + XiCon Loss:3.0618 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1857607
	speed: 0.0417s/iter; left time: 894.2022s
	iters: 200, epoch: 20 | loss: 3.1493435
	speed: 0.0391s/iter; left time: 835.6881s
Epoch: 20 cost time: 10.667971134185791
Epoch: 20, Steps: 266 Train Loss: 3.2018 (Forecasting Loss:0.1414 + XiCon Loss:3.0603 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1563945
	speed: 0.0406s/iter; left time: 860.2509s
	iters: 200, epoch: 21 | loss: 3.2400000
	speed: 0.0380s/iter; left time: 801.3428s
Epoch: 21 cost time: 10.447230100631714
Epoch: 21, Steps: 266 Train Loss: 3.2017 (Forecasting Loss:0.1414 + XiCon Loss:3.0602 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3335850
	speed: 0.0413s/iter; left time: 863.4648s
	iters: 200, epoch: 22 | loss: 3.1995487
	speed: 0.0403s/iter; left time: 838.3722s
Epoch: 22 cost time: 10.683490753173828
Epoch: 22, Steps: 266 Train Loss: 3.2049 (Forecasting Loss:0.1414 + XiCon Loss:3.0635 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
Validation loss decreased (0.107381 --> 0.107363).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1400502
	speed: 0.0407s/iter; left time: 840.5767s
	iters: 200, epoch: 23 | loss: 3.2014034
	speed: 0.0376s/iter; left time: 772.4332s
Epoch: 23 cost time: 10.3654305934906
Epoch: 23, Steps: 266 Train Loss: 3.2059 (Forecasting Loss:0.1415 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1817508
	speed: 0.0410s/iter; left time: 835.3710s
	iters: 200, epoch: 24 | loss: 3.1977754
	speed: 0.0387s/iter; left time: 784.2381s
Epoch: 24 cost time: 10.582560539245605
Epoch: 24, Steps: 266 Train Loss: 3.2022 (Forecasting Loss:0.1414 + XiCon Loss:3.0608 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2517562
	speed: 0.0414s/iter; left time: 833.3670s
	iters: 200, epoch: 25 | loss: 3.1230969
	speed: 0.0386s/iter; left time: 771.8835s
Epoch: 25 cost time: 10.558552742004395
Epoch: 25, Steps: 266 Train Loss: 3.2050 (Forecasting Loss:0.1414 + XiCon Loss:3.0636 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1735234
	speed: 0.0419s/iter; left time: 832.4098s
	iters: 200, epoch: 26 | loss: 3.1591384
	speed: 0.0386s/iter; left time: 761.7524s
Epoch: 26 cost time: 10.617904424667358
Epoch: 26, Steps: 266 Train Loss: 3.2049 (Forecasting Loss:0.1414 + XiCon Loss:3.0635 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2660861
	speed: 0.0403s/iter; left time: 789.8214s
	iters: 200, epoch: 27 | loss: 3.1446052
	speed: 0.0388s/iter; left time: 756.5467s
Epoch: 27 cost time: 10.53049373626709
Epoch: 27, Steps: 266 Train Loss: 3.2037 (Forecasting Loss:0.1415 + XiCon Loss:3.0622 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1270120
	speed: 0.0372s/iter; left time: 719.1311s
	iters: 200, epoch: 28 | loss: 3.2539961
	speed: 0.0373s/iter; left time: 717.7214s
Epoch: 28 cost time: 10.065130710601807
Epoch: 28, Steps: 266 Train Loss: 3.1996 (Forecasting Loss:0.1415 + XiCon Loss:3.0581 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2134688
	speed: 0.0409s/iter; left time: 778.3986s
	iters: 200, epoch: 29 | loss: 3.2785001
	speed: 0.0392s/iter; left time: 743.0755s
Epoch: 29 cost time: 10.60364055633545
Epoch: 29, Steps: 266 Train Loss: 3.2045 (Forecasting Loss:0.1415 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0745
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2137611
	speed: 0.0409s/iter; left time: 767.9420s
	iters: 200, epoch: 30 | loss: 3.1547215
	speed: 0.0390s/iter; left time: 727.9543s
Epoch: 30 cost time: 10.573893785476685
Epoch: 30, Steps: 266 Train Loss: 3.2055 (Forecasting Loss:0.1414 + XiCon Loss:3.0641 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1651633
	speed: 0.0401s/iter; left time: 743.4991s
	iters: 200, epoch: 31 | loss: 3.1612749
	speed: 0.0391s/iter; left time: 720.5306s
Epoch: 31 cost time: 10.468101739883423
Epoch: 31, Steps: 266 Train Loss: 3.2057 (Forecasting Loss:0.1415 + XiCon Loss:3.0643 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1739833
	speed: 0.0407s/iter; left time: 742.7972s
	iters: 200, epoch: 32 | loss: 3.3135912
	speed: 0.0392s/iter; left time: 711.9249s
Epoch: 32 cost time: 10.558488368988037
Epoch: 32, Steps: 266 Train Loss: 3.2026 (Forecasting Loss:0.1414 + XiCon Loss:3.0612 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0745
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026663517579436302, mae:0.12234494090080261, mape:0.09904054552316666, mspe:0.019916554912924767 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9225
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3686705
	speed: 0.0407s/iter; left time: 1077.6922s
	iters: 200, epoch: 1 | loss: 3.3231037
	speed: 0.0379s/iter; left time: 1000.4100s
Epoch: 1 cost time: 10.35460901260376
Epoch: 1, Steps: 266 Train Loss: 3.3896 (Forecasting Loss:0.1670 + XiCon Loss:3.2227 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0778
Validation loss decreased (inf --> 0.115225).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4583943
	speed: 0.0408s/iter; left time: 1069.8953s
	iters: 200, epoch: 2 | loss: 3.4012425
	speed: 0.0382s/iter; left time: 999.1268s
Epoch: 2 cost time: 10.456629276275635
Epoch: 2, Steps: 266 Train Loss: 3.4827 (Forecasting Loss:0.1507 + XiCon Loss:3.3320 x Lambda(1.0)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.0761
Validation loss decreased (0.115225 --> 0.110891).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3792651
	speed: 0.0404s/iter; left time: 1048.7161s
	iters: 200, epoch: 3 | loss: 3.2732935
	speed: 0.0387s/iter; left time: 1001.1996s
Epoch: 3 cost time: 10.444737672805786
Epoch: 3, Steps: 266 Train Loss: 3.4000 (Forecasting Loss:0.1454 + XiCon Loss:3.2546 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.0752
Validation loss decreased (0.110891 --> 0.108837).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6623063
	speed: 0.0380s/iter; left time: 975.4358s
	iters: 200, epoch: 4 | loss: 3.3091943
	speed: 0.0345s/iter; left time: 882.8507s
Epoch: 4 cost time: 9.746464729309082
Epoch: 4, Steps: 266 Train Loss: 3.3792 (Forecasting Loss:0.1433 + XiCon Loss:3.2359 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0749
Validation loss decreased (0.108837 --> 0.108391).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4045072
	speed: 0.0407s/iter; left time: 1034.7518s
	iters: 200, epoch: 5 | loss: 3.5400414
	speed: 0.0388s/iter; left time: 983.0682s
Epoch: 5 cost time: 10.464552879333496
Epoch: 5, Steps: 266 Train Loss: 3.3900 (Forecasting Loss:0.1426 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0747
Validation loss decreased (0.108391 --> 0.107993).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4575012
	speed: 0.0409s/iter; left time: 1030.1476s
	iters: 200, epoch: 6 | loss: 3.5383048
	speed: 0.0388s/iter; left time: 973.4870s
Epoch: 6 cost time: 10.543641805648804
Epoch: 6, Steps: 266 Train Loss: 3.4010 (Forecasting Loss:0.1421 + XiCon Loss:3.2589 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107993 --> 0.107721).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4285023
	speed: 0.0406s/iter; left time: 1011.0966s
	iters: 200, epoch: 7 | loss: 3.3160810
	speed: 0.0379s/iter; left time: 940.2250s
Epoch: 7 cost time: 10.3970046043396
Epoch: 7, Steps: 266 Train Loss: 3.3827 (Forecasting Loss:0.1418 + XiCon Loss:3.2410 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0739
Validation loss decreased (0.107721 --> 0.107368).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2890022
	speed: 0.0409s/iter; left time: 1007.9182s
	iters: 200, epoch: 8 | loss: 3.2370009
	speed: 0.0379s/iter; left time: 930.0938s
Epoch: 8 cost time: 10.43138575553894
Epoch: 8, Steps: 266 Train Loss: 3.3699 (Forecasting Loss:0.1416 + XiCon Loss:3.2283 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
Validation loss decreased (0.107368 --> 0.107298).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4379499
	speed: 0.0405s/iter; left time: 988.1057s
	iters: 200, epoch: 9 | loss: 3.6015565
	speed: 0.0385s/iter; left time: 935.5551s
Epoch: 9 cost time: 10.452074527740479
Epoch: 9, Steps: 266 Train Loss: 3.3788 (Forecasting Loss:0.1416 + XiCon Loss:3.2372 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2545447
	speed: 0.0415s/iter; left time: 999.3180s
	iters: 200, epoch: 10 | loss: 3.3502350
	speed: 0.0383s/iter; left time: 918.6915s
Epoch: 10 cost time: 10.528239488601685
Epoch: 10, Steps: 266 Train Loss: 3.3860 (Forecasting Loss:0.1416 + XiCon Loss:3.2444 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0739
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3910568
	speed: 0.0409s/iter; left time: 974.4328s
	iters: 200, epoch: 11 | loss: 3.3129635
	speed: 0.0384s/iter; left time: 912.7422s
Epoch: 11 cost time: 10.546231269836426
Epoch: 11, Steps: 266 Train Loss: 3.3628 (Forecasting Loss:0.1415 + XiCon Loss:3.2214 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5295243
	speed: 0.0407s/iter; left time: 960.0973s
	iters: 200, epoch: 12 | loss: 3.3873510
	speed: 0.0387s/iter; left time: 908.1329s
Epoch: 12 cost time: 10.495792388916016
Epoch: 12, Steps: 266 Train Loss: 3.3778 (Forecasting Loss:0.1414 + XiCon Loss:3.2364 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
Validation loss decreased (0.107298 --> 0.107290).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4504251
	speed: 0.0409s/iter; left time: 953.8810s
	iters: 200, epoch: 13 | loss: 3.4672129
	speed: 0.0392s/iter; left time: 909.6710s
Epoch: 13 cost time: 10.44618821144104
Epoch: 13, Steps: 266 Train Loss: 3.3746 (Forecasting Loss:0.1414 + XiCon Loss:3.2331 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
Validation loss decreased (0.107290 --> 0.107276).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3019543
	speed: 0.0377s/iter; left time: 869.6591s
	iters: 200, epoch: 14 | loss: 3.3014104
	speed: 0.0383s/iter; left time: 877.9808s
Epoch: 14 cost time: 10.109537839889526
Epoch: 14, Steps: 266 Train Loss: 3.3618 (Forecasting Loss:0.1414 + XiCon Loss:3.2204 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1645544
	speed: 0.0405s/iter; left time: 921.4956s
	iters: 200, epoch: 15 | loss: 3.3561831
	speed: 0.0377s/iter; left time: 855.6040s
Epoch: 15 cost time: 10.394766569137573
Epoch: 15, Steps: 266 Train Loss: 3.3717 (Forecasting Loss:0.1415 + XiCon Loss:3.2302 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4267392
	speed: 0.0406s/iter; left time: 914.5262s
	iters: 200, epoch: 16 | loss: 3.4404778
	speed: 0.0381s/iter; left time: 852.9176s
Epoch: 16 cost time: 10.377586603164673
Epoch: 16, Steps: 266 Train Loss: 3.3713 (Forecasting Loss:0.1414 + XiCon Loss:3.2298 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0739
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3375008
	speed: 0.0414s/iter; left time: 921.9766s
	iters: 200, epoch: 17 | loss: 3.4557238
	speed: 0.0391s/iter; left time: 866.5906s
Epoch: 17 cost time: 10.584006309509277
Epoch: 17, Steps: 266 Train Loss: 3.3884 (Forecasting Loss:0.1415 + XiCon Loss:3.2470 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
Validation loss decreased (0.107276 --> 0.107266).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4060061
	speed: 0.0404s/iter; left time: 887.5540s
	iters: 200, epoch: 18 | loss: 3.4707723
	speed: 0.0391s/iter; left time: 855.6627s
Epoch: 18 cost time: 10.537442684173584
Epoch: 18, Steps: 266 Train Loss: 3.3747 (Forecasting Loss:0.1415 + XiCon Loss:3.2332 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
Validation loss decreased (0.107266 --> 0.107208).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3985670
	speed: 0.0405s/iter; left time: 879.4516s
	iters: 200, epoch: 19 | loss: 3.4256785
	speed: 0.0388s/iter; left time: 837.7532s
Epoch: 19 cost time: 10.482512950897217
Epoch: 19, Steps: 266 Train Loss: 3.3691 (Forecasting Loss:0.1414 + XiCon Loss:3.2278 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4745810
	speed: 0.0412s/iter; left time: 884.6856s
	iters: 200, epoch: 20 | loss: 3.2443442
	speed: 0.0380s/iter; left time: 810.5031s
Epoch: 20 cost time: 10.486109733581543
Epoch: 20, Steps: 266 Train Loss: 3.3902 (Forecasting Loss:0.1414 + XiCon Loss:3.2488 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
Validation loss decreased (0.107208 --> 0.107198).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3273053
	speed: 0.0408s/iter; left time: 863.3151s
	iters: 200, epoch: 21 | loss: 3.4237678
	speed: 0.0388s/iter; left time: 818.2162s
Epoch: 21 cost time: 10.532394886016846
Epoch: 21, Steps: 266 Train Loss: 3.3786 (Forecasting Loss:0.1415 + XiCon Loss:3.2372 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5300210
	speed: 0.0414s/iter; left time: 865.4978s
	iters: 200, epoch: 22 | loss: 3.4654458
	speed: 0.0385s/iter; left time: 802.1971s
Epoch: 22 cost time: 10.519075632095337
Epoch: 22, Steps: 266 Train Loss: 3.3659 (Forecasting Loss:0.1414 + XiCon Loss:3.2245 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3386452
	speed: 0.0400s/iter; left time: 826.0574s
	iters: 200, epoch: 23 | loss: 3.1874962
	speed: 0.0362s/iter; left time: 743.3610s
Epoch: 23 cost time: 9.986717700958252
Epoch: 23, Steps: 266 Train Loss: 3.3771 (Forecasting Loss:0.1414 + XiCon Loss:3.2357 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2064424
	speed: 0.0405s/iter; left time: 826.0961s
	iters: 200, epoch: 24 | loss: 3.4218500
	speed: 0.0384s/iter; left time: 779.3683s
Epoch: 24 cost time: 10.447993993759155
Epoch: 24, Steps: 266 Train Loss: 3.3761 (Forecasting Loss:0.1415 + XiCon Loss:3.2347 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1854179
	speed: 0.0403s/iter; left time: 810.4257s
	iters: 200, epoch: 25 | loss: 3.2293363
	speed: 0.0384s/iter; left time: 768.6243s
Epoch: 25 cost time: 10.426279067993164
Epoch: 25, Steps: 266 Train Loss: 3.3694 (Forecasting Loss:0.1415 + XiCon Loss:3.2279 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3093121
	speed: 0.0408s/iter; left time: 810.4236s
	iters: 200, epoch: 26 | loss: 3.3144293
	speed: 0.0393s/iter; left time: 775.7695s
Epoch: 26 cost time: 10.507201910018921
Epoch: 26, Steps: 266 Train Loss: 3.3764 (Forecasting Loss:0.1414 + XiCon Loss:3.2350 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4441638
	speed: 0.0403s/iter; left time: 790.0044s
	iters: 200, epoch: 27 | loss: 3.3362949
	speed: 0.0379s/iter; left time: 737.5251s
Epoch: 27 cost time: 10.357831716537476
Epoch: 27, Steps: 266 Train Loss: 3.3754 (Forecasting Loss:0.1414 + XiCon Loss:3.2340 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2649364
	speed: 0.0399s/iter; left time: 770.6922s
	iters: 200, epoch: 28 | loss: 3.3416746
	speed: 0.0386s/iter; left time: 741.1661s
Epoch: 28 cost time: 10.435198307037354
Epoch: 28, Steps: 266 Train Loss: 3.3686 (Forecasting Loss:0.1414 + XiCon Loss:3.2272 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3570962
	speed: 0.0415s/iter; left time: 790.6560s
	iters: 200, epoch: 29 | loss: 3.3879335
	speed: 0.0388s/iter; left time: 734.5785s
Epoch: 29 cost time: 10.601483345031738
Epoch: 29, Steps: 266 Train Loss: 3.3672 (Forecasting Loss:0.1415 + XiCon Loss:3.2258 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.3070719
	speed: 0.0407s/iter; left time: 764.6162s
	iters: 200, epoch: 30 | loss: 3.5441344
	speed: 0.0382s/iter; left time: 713.6131s
Epoch: 30 cost time: 10.437908172607422
Epoch: 30, Steps: 266 Train Loss: 3.3808 (Forecasting Loss:0.1415 + XiCon Loss:3.2393 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02625824324786663, mae:0.12153834104537964, mape:0.09828774631023407, mspe:0.01955348439514637 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6585
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3536656
	speed: 0.0410s/iter; left time: 1087.0155s
	iters: 200, epoch: 1 | loss: 3.3020289
	speed: 0.0378s/iter; left time: 999.0015s
Epoch: 1 cost time: 10.385615110397339
Epoch: 1, Steps: 266 Train Loss: 3.3582 (Forecasting Loss:0.1687 + XiCon Loss:3.1895 x Lambda(1.0)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.0807
Validation loss decreased (inf --> 0.117768).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5833623
	speed: 0.0377s/iter; left time: 989.9333s
	iters: 200, epoch: 2 | loss: 3.3797970
	speed: 0.0383s/iter; left time: 1000.1126s
Epoch: 2 cost time: 10.181376934051514
Epoch: 2, Steps: 266 Train Loss: 3.4733 (Forecasting Loss:0.1510 + XiCon Loss:3.3223 x Lambda(1.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.0784
Validation loss decreased (0.117768 --> 0.113727).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2512054
	speed: 0.0400s/iter; left time: 1038.5529s
	iters: 200, epoch: 3 | loss: 3.4201739
	speed: 0.0385s/iter; left time: 995.3990s
Epoch: 3 cost time: 10.385837078094482
Epoch: 3, Steps: 266 Train Loss: 3.3653 (Forecasting Loss:0.1456 + XiCon Loss:3.2197 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0754
Validation loss decreased (0.113727 --> 0.109694).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3144751
	speed: 0.0404s/iter; left time: 1037.3744s
	iters: 200, epoch: 4 | loss: 3.4143105
	speed: 0.0383s/iter; left time: 980.0403s
Epoch: 4 cost time: 10.396846771240234
Epoch: 4, Steps: 266 Train Loss: 3.3655 (Forecasting Loss:0.1435 + XiCon Loss:3.2220 x Lambda(1.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.0748
Validation loss decreased (0.109694 --> 0.108300).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4003718
	speed: 0.0404s/iter; left time: 1026.6711s
	iters: 200, epoch: 5 | loss: 3.3701143
	speed: 0.0383s/iter; left time: 969.8672s
Epoch: 5 cost time: 10.469964504241943
Epoch: 5, Steps: 266 Train Loss: 3.3402 (Forecasting Loss:0.1425 + XiCon Loss:3.1978 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0741
Validation loss decreased (0.108300 --> 0.107780).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3427892
	speed: 0.0403s/iter; left time: 1015.3500s
	iters: 200, epoch: 6 | loss: 3.4828813
	speed: 0.0386s/iter; left time: 967.4404s
Epoch: 6 cost time: 10.428269863128662
Epoch: 6, Steps: 266 Train Loss: 3.3422 (Forecasting Loss:0.1420 + XiCon Loss:3.2002 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107780 --> 0.107357).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3964286
	speed: 0.0400s/iter; left time: 995.0485s
	iters: 200, epoch: 7 | loss: 3.4426904
	speed: 0.0385s/iter; left time: 956.2027s
Epoch: 7 cost time: 10.429443120956421
Epoch: 7, Steps: 266 Train Loss: 3.3324 (Forecasting Loss:0.1417 + XiCon Loss:3.1908 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3097303
	speed: 0.0410s/iter; left time: 1010.4963s
	iters: 200, epoch: 8 | loss: 3.3028839
	speed: 0.0388s/iter; left time: 950.9064s
Epoch: 8 cost time: 10.53649091720581
Epoch: 8, Steps: 266 Train Loss: 3.3290 (Forecasting Loss:0.1416 + XiCon Loss:3.1875 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
Validation loss decreased (0.107357 --> 0.107203).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1718116
	speed: 0.0401s/iter; left time: 977.0891s
	iters: 200, epoch: 9 | loss: 3.2242713
	speed: 0.0382s/iter; left time: 927.8834s
Epoch: 9 cost time: 10.381014585494995
Epoch: 9, Steps: 266 Train Loss: 3.3215 (Forecasting Loss:0.1415 + XiCon Loss:3.1800 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0740
Validation loss decreased (0.107203 --> 0.107201).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2993596
	speed: 0.0403s/iter; left time: 970.6826s
	iters: 200, epoch: 10 | loss: 3.4240084
	speed: 0.0385s/iter; left time: 923.1135s
Epoch: 10 cost time: 10.46178674697876
Epoch: 10, Steps: 266 Train Loss: 3.3334 (Forecasting Loss:0.1415 + XiCon Loss:3.1919 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0740
Validation loss decreased (0.107201 --> 0.107159).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4460320
	speed: 0.0407s/iter; left time: 970.7984s
	iters: 200, epoch: 11 | loss: 3.2828372
	speed: 0.0364s/iter; left time: 863.9028s
Epoch: 11 cost time: 10.097998142242432
Epoch: 11, Steps: 266 Train Loss: 3.3333 (Forecasting Loss:0.1415 + XiCon Loss:3.1918 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3211565
	speed: 0.0402s/iter; left time: 947.2358s
	iters: 200, epoch: 12 | loss: 3.3859475
	speed: 0.0387s/iter; left time: 907.3555s
Epoch: 12 cost time: 10.426450252532959
Epoch: 12, Steps: 266 Train Loss: 3.3287 (Forecasting Loss:0.1414 + XiCon Loss:3.1873 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2660530
	speed: 0.0408s/iter; left time: 950.0392s
	iters: 200, epoch: 13 | loss: 3.4388206
	speed: 0.0385s/iter; left time: 893.5144s
Epoch: 13 cost time: 10.44261622428894
Epoch: 13, Steps: 266 Train Loss: 3.3270 (Forecasting Loss:0.1414 + XiCon Loss:3.1856 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2928202
	speed: 0.0412s/iter; left time: 948.8411s
	iters: 200, epoch: 14 | loss: 3.2476737
	speed: 0.0388s/iter; left time: 890.8793s
Epoch: 14 cost time: 10.494961023330688
Epoch: 14, Steps: 266 Train Loss: 3.3256 (Forecasting Loss:0.1415 + XiCon Loss:3.1841 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3290255
	speed: 0.0408s/iter; left time: 929.6417s
	iters: 200, epoch: 15 | loss: 3.4734814
	speed: 0.0378s/iter; left time: 858.1388s
Epoch: 15 cost time: 10.397079706192017
Epoch: 15, Steps: 266 Train Loss: 3.3396 (Forecasting Loss:0.1414 + XiCon Loss:3.1982 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2470901
	speed: 0.0410s/iter; left time: 923.8502s
	iters: 200, epoch: 16 | loss: 3.3002896
	speed: 0.0380s/iter; left time: 852.7365s
Epoch: 16 cost time: 10.381672859191895
Epoch: 16, Steps: 266 Train Loss: 3.3315 (Forecasting Loss:0.1415 + XiCon Loss:3.1900 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4340584
	speed: 0.0402s/iter; left time: 893.3562s
	iters: 200, epoch: 17 | loss: 3.3229852
	speed: 0.0381s/iter; left time: 844.7033s
Epoch: 17 cost time: 10.342542886734009
Epoch: 17, Steps: 266 Train Loss: 3.3360 (Forecasting Loss:0.1414 + XiCon Loss:3.1946 x Lambda(1.0)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.0739
Validation loss decreased (0.107159 --> 0.107150).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2721310
	speed: 0.0405s/iter; left time: 889.2920s
	iters: 200, epoch: 18 | loss: 3.3614397
	speed: 0.0386s/iter; left time: 843.9257s
Epoch: 18 cost time: 10.468968629837036
Epoch: 18, Steps: 266 Train Loss: 3.3413 (Forecasting Loss:0.1414 + XiCon Loss:3.2000 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3713031
	speed: 0.0407s/iter; left time: 882.7169s
	iters: 200, epoch: 19 | loss: 3.4433696
	speed: 0.0376s/iter; left time: 812.2201s
Epoch: 19 cost time: 10.360516786575317
Epoch: 19, Steps: 266 Train Loss: 3.3324 (Forecasting Loss:0.1414 + XiCon Loss:3.1910 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3103657
	speed: 0.0413s/iter; left time: 886.4847s
	iters: 200, epoch: 20 | loss: 3.3119118
	speed: 0.0387s/iter; left time: 825.5696s
Epoch: 20 cost time: 10.569905281066895
Epoch: 20, Steps: 266 Train Loss: 3.3277 (Forecasting Loss:0.1415 + XiCon Loss:3.1862 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3869238
	speed: 0.0399s/iter; left time: 845.0419s
	iters: 200, epoch: 21 | loss: 3.3307061
	speed: 0.0351s/iter; left time: 739.7704s
Epoch: 21 cost time: 9.92207932472229
Epoch: 21, Steps: 266 Train Loss: 3.3264 (Forecasting Loss:0.1415 + XiCon Loss:3.1849 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5082142
	speed: 0.0412s/iter; left time: 862.5463s
	iters: 200, epoch: 22 | loss: 3.2220814
	speed: 0.0380s/iter; left time: 790.8529s
Epoch: 22 cost time: 10.498542547225952
Epoch: 22, Steps: 266 Train Loss: 3.3297 (Forecasting Loss:0.1414 + XiCon Loss:3.1883 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0739
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2739570
	speed: 0.0414s/iter; left time: 854.1653s
	iters: 200, epoch: 23 | loss: 3.3014498
	speed: 0.0383s/iter; left time: 786.2795s
Epoch: 23 cost time: 10.523082494735718
Epoch: 23, Steps: 266 Train Loss: 3.3250 (Forecasting Loss:0.1415 + XiCon Loss:3.1835 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3136122
	speed: 0.0408s/iter; left time: 832.2610s
	iters: 200, epoch: 24 | loss: 3.3459079
	speed: 0.0381s/iter; left time: 773.6291s
Epoch: 24 cost time: 10.512815475463867
Epoch: 24, Steps: 266 Train Loss: 3.3276 (Forecasting Loss:0.1414 + XiCon Loss:3.1862 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3283350
	speed: 0.0413s/iter; left time: 830.1609s
	iters: 200, epoch: 25 | loss: 3.4372845
	speed: 0.0384s/iter; left time: 769.6401s
Epoch: 25 cost time: 10.518960237503052
Epoch: 25, Steps: 266 Train Loss: 3.3294 (Forecasting Loss:0.1415 + XiCon Loss:3.1879 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.4875822
	speed: 0.0405s/iter; left time: 803.7658s
	iters: 200, epoch: 26 | loss: 3.1967318
	speed: 0.0392s/iter; left time: 774.8964s
Epoch: 26 cost time: 10.55780291557312
Epoch: 26, Steps: 266 Train Loss: 3.3388 (Forecasting Loss:0.1415 + XiCon Loss:3.1974 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2989631
	speed: 0.0412s/iter; left time: 806.6293s
	iters: 200, epoch: 27 | loss: 3.5831594
	speed: 0.0391s/iter; left time: 761.8913s
Epoch: 27 cost time: 10.56163501739502
Epoch: 27, Steps: 266 Train Loss: 3.3213 (Forecasting Loss:0.1414 + XiCon Loss:3.1798 x Lambda(1.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0739
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026279227808117867, mae:0.1216086894273758, mape:0.09839529544115067, mspe:0.019620979204773903 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1177
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4339643
	speed: 0.0408s/iter; left time: 1081.9786s
	iters: 200, epoch: 1 | loss: 3.2768934
	speed: 0.0373s/iter; left time: 985.0339s
Epoch: 1 cost time: 10.307775259017944
Epoch: 1, Steps: 266 Train Loss: 3.3874 (Forecasting Loss:0.1668 + XiCon Loss:3.2206 x Lambda(1.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.0787
Validation loss decreased (inf --> 0.113976).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4964979
	speed: 0.0404s/iter; left time: 1060.3159s
	iters: 200, epoch: 2 | loss: 3.7517715
	speed: 0.0364s/iter; left time: 951.2137s
Epoch: 2 cost time: 10.025885105133057
Epoch: 2, Steps: 266 Train Loss: 3.6169 (Forecasting Loss:0.1509 + XiCon Loss:3.4660 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.0766
Validation loss decreased (0.113976 --> 0.110469).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4911599
	speed: 0.0419s/iter; left time: 1089.2829s
	iters: 200, epoch: 3 | loss: 3.5822079
	speed: 0.0388s/iter; left time: 1002.5917s
Epoch: 3 cost time: 10.60340166091919
Epoch: 3, Steps: 266 Train Loss: 3.5365 (Forecasting Loss:0.1453 + XiCon Loss:3.3912 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.0752
Validation loss decreased (0.110469 --> 0.109108).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2517347
	speed: 0.0408s/iter; left time: 1047.9922s
	iters: 200, epoch: 4 | loss: 3.3757396
	speed: 0.0379s/iter; left time: 969.6567s
Epoch: 4 cost time: 10.431205034255981
Epoch: 4, Steps: 266 Train Loss: 3.4084 (Forecasting Loss:0.1437 + XiCon Loss:3.2647 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0746
Validation loss decreased (0.109108 --> 0.108074).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4449553
	speed: 0.0409s/iter; left time: 1039.9583s
	iters: 200, epoch: 5 | loss: 3.3797255
	speed: 0.0389s/iter; left time: 985.0227s
Epoch: 5 cost time: 10.544292211532593
Epoch: 5, Steps: 266 Train Loss: 3.3838 (Forecasting Loss:0.1425 + XiCon Loss:3.2413 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0741
Validation loss decreased (0.108074 --> 0.107793).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4265103
	speed: 0.0406s/iter; left time: 1022.6303s
	iters: 200, epoch: 6 | loss: 3.3130820
	speed: 0.0377s/iter; left time: 944.4598s
Epoch: 6 cost time: 10.428115367889404
Epoch: 6, Steps: 266 Train Loss: 3.3650 (Forecasting Loss:0.1421 + XiCon Loss:3.2229 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107793 --> 0.107658).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2539914
	speed: 0.0411s/iter; left time: 1023.7403s
	iters: 200, epoch: 7 | loss: 3.3142745
	speed: 0.0386s/iter; left time: 957.9439s
Epoch: 7 cost time: 10.518478393554688
Epoch: 7, Steps: 266 Train Loss: 3.3594 (Forecasting Loss:0.1419 + XiCon Loss:3.2176 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107658 --> 0.107514).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3897786
	speed: 0.0400s/iter; left time: 985.0484s
	iters: 200, epoch: 8 | loss: 3.3095589
	speed: 0.0389s/iter; left time: 954.5888s
Epoch: 8 cost time: 10.456470727920532
Epoch: 8, Steps: 266 Train Loss: 3.3509 (Forecasting Loss:0.1417 + XiCon Loss:3.2092 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2037487
	speed: 0.0419s/iter; left time: 1021.0045s
	iters: 200, epoch: 9 | loss: 3.3661063
	speed: 0.0384s/iter; left time: 931.5987s
Epoch: 9 cost time: 10.507030487060547
Epoch: 9, Steps: 266 Train Loss: 3.3381 (Forecasting Loss:0.1416 + XiCon Loss:3.1965 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107514 --> 0.107511).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3591180
	speed: 0.0402s/iter; left time: 967.9619s
	iters: 200, epoch: 10 | loss: 3.3310680
	speed: 0.0380s/iter; left time: 911.6348s
Epoch: 10 cost time: 10.39819073677063
Epoch: 10, Steps: 266 Train Loss: 3.3498 (Forecasting Loss:0.1416 + XiCon Loss:3.2082 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107511 --> 0.107483).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2878759
	speed: 0.0416s/iter; left time: 990.7585s
	iters: 200, epoch: 11 | loss: 3.4482596
	speed: 0.0385s/iter; left time: 914.9734s
Epoch: 11 cost time: 10.522236347198486
Epoch: 11, Steps: 266 Train Loss: 3.3463 (Forecasting Loss:0.1415 + XiCon Loss:3.2048 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107483 --> 0.107407).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5838084
	speed: 0.0387s/iter; left time: 912.6353s
	iters: 200, epoch: 12 | loss: 3.4684353
	speed: 0.0348s/iter; left time: 817.2079s
Epoch: 12 cost time: 9.90691590309143
Epoch: 12, Steps: 266 Train Loss: 3.3457 (Forecasting Loss:0.1416 + XiCon Loss:3.2041 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1656876
	speed: 0.0411s/iter; left time: 957.8113s
	iters: 200, epoch: 13 | loss: 3.3014674
	speed: 0.0380s/iter; left time: 881.5218s
Epoch: 13 cost time: 10.390939474105835
Epoch: 13, Steps: 266 Train Loss: 3.3395 (Forecasting Loss:0.1416 + XiCon Loss:3.1979 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2615740
	speed: 0.0405s/iter; left time: 932.9981s
	iters: 200, epoch: 14 | loss: 3.2996113
	speed: 0.0383s/iter; left time: 878.6869s
Epoch: 14 cost time: 10.439708232879639
Epoch: 14, Steps: 266 Train Loss: 3.3487 (Forecasting Loss:0.1415 + XiCon Loss:3.2072 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3841090
	speed: 0.0404s/iter; left time: 920.2472s
	iters: 200, epoch: 15 | loss: 3.2519484
	speed: 0.0390s/iter; left time: 884.7527s
Epoch: 15 cost time: 10.494954824447632
Epoch: 15, Steps: 266 Train Loss: 3.3496 (Forecasting Loss:0.1416 + XiCon Loss:3.2081 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3511746
	speed: 0.0410s/iter; left time: 922.4867s
	iters: 200, epoch: 16 | loss: 3.2852862
	speed: 0.0380s/iter; left time: 851.7475s
Epoch: 16 cost time: 10.46604299545288
Epoch: 16, Steps: 266 Train Loss: 3.3356 (Forecasting Loss:0.1415 + XiCon Loss:3.1941 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4661996
	speed: 0.0410s/iter; left time: 912.8878s
	iters: 200, epoch: 17 | loss: 3.4419236
	speed: 0.0389s/iter; left time: 862.4315s
Epoch: 17 cost time: 10.524854183197021
Epoch: 17, Steps: 266 Train Loss: 3.3473 (Forecasting Loss:0.1415 + XiCon Loss:3.2057 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3560297
	speed: 0.0409s/iter; left time: 899.5337s
	iters: 200, epoch: 18 | loss: 3.4265845
	speed: 0.0383s/iter; left time: 838.3874s
Epoch: 18 cost time: 10.4910569190979
Epoch: 18, Steps: 266 Train Loss: 3.3468 (Forecasting Loss:0.1415 + XiCon Loss:3.2053 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3656976
	speed: 0.0407s/iter; left time: 884.6659s
	iters: 200, epoch: 19 | loss: 3.3023386
	speed: 0.0387s/iter; left time: 837.4639s
Epoch: 19 cost time: 10.492699146270752
Epoch: 19, Steps: 266 Train Loss: 3.3458 (Forecasting Loss:0.1416 + XiCon Loss:3.2042 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3157749
	speed: 0.0410s/iter; left time: 879.1365s
	iters: 200, epoch: 20 | loss: 3.2375238
	speed: 0.0388s/iter; left time: 827.9343s
Epoch: 20 cost time: 10.48447561264038
Epoch: 20, Steps: 266 Train Loss: 3.3530 (Forecasting Loss:0.1415 + XiCon Loss:3.2115 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.5116174
	speed: 0.0408s/iter; left time: 864.1276s
	iters: 200, epoch: 21 | loss: 3.3448267
	speed: 0.0382s/iter; left time: 805.8336s
Epoch: 21 cost time: 10.448785305023193
Epoch: 21, Steps: 266 Train Loss: 3.3506 (Forecasting Loss:0.1416 + XiCon Loss:3.2091 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02635614387691021, mae:0.12174943834543228, mape:0.09840410947799683, mspe:0.019587645307183266 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 21.8648
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.3781896
	speed: 0.0918s/iter; left time: 2433.3797s
	iters: 200, epoch: 1 | loss: 3.2814345
	speed: 0.0988s/iter; left time: 2607.8000s
Epoch: 1 cost time: 25.99475598335266
Epoch: 1, Steps: 266 Train Loss: 3.3961 (Forecasting Loss:0.1692 + XiCon Loss:3.2269 x Lambda(1.0)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.0799
Validation loss decreased (inf --> 0.115752).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4173629
	speed: 0.0981s/iter; left time: 2573.6173s
	iters: 200, epoch: 2 | loss: 3.4260182
	speed: 0.0861s/iter; left time: 2250.1284s
Epoch: 2 cost time: 23.53463578224182
Epoch: 2, Steps: 266 Train Loss: 3.4775 (Forecasting Loss:0.1505 + XiCon Loss:3.3270 x Lambda(1.0)), Vali MSE Loss: 0.1113 Test MSE Loss: 0.0761
Validation loss decreased (0.115752 --> 0.111338).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2779508
	speed: 0.0751s/iter; left time: 1949.1448s
	iters: 200, epoch: 3 | loss: 3.3826110
	speed: 0.0541s/iter; left time: 1399.0386s
Epoch: 3 cost time: 16.22902250289917
Epoch: 3, Steps: 266 Train Loss: 3.3241 (Forecasting Loss:0.1452 + XiCon Loss:3.1789 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.0756
Validation loss decreased (0.111338 --> 0.109953).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3507342
	speed: 0.0406s/iter; left time: 1043.5116s
	iters: 200, epoch: 4 | loss: 3.3060806
	speed: 0.0371s/iter; left time: 948.9582s
Epoch: 4 cost time: 10.15811800956726
Epoch: 4, Steps: 266 Train Loss: 3.2950 (Forecasting Loss:0.1435 + XiCon Loss:3.1515 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.0749
Validation loss decreased (0.109953 --> 0.108222).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2544811
	speed: 0.0384s/iter; left time: 975.7117s
	iters: 200, epoch: 5 | loss: 3.3207669
	speed: 0.0354s/iter; left time: 897.5620s
Epoch: 5 cost time: 9.841137647628784
Epoch: 5, Steps: 266 Train Loss: 3.2635 (Forecasting Loss:0.1427 + XiCon Loss:3.1208 x Lambda(1.0)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.0742
Validation loss decreased (0.108222 --> 0.107937).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3003504
	speed: 0.0385s/iter; left time: 969.6103s
	iters: 200, epoch: 6 | loss: 3.3609693
	speed: 0.0361s/iter; left time: 904.6847s
Epoch: 6 cost time: 9.811996221542358
Epoch: 6, Steps: 266 Train Loss: 3.2522 (Forecasting Loss:0.1420 + XiCon Loss:3.1102 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0743
Validation loss decreased (0.107937 --> 0.107691).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3178561
	speed: 0.0386s/iter; left time: 961.3143s
	iters: 200, epoch: 7 | loss: 3.3014221
	speed: 0.0359s/iter; left time: 891.0695s
Epoch: 7 cost time: 9.853283405303955
Epoch: 7, Steps: 266 Train Loss: 3.2479 (Forecasting Loss:0.1418 + XiCon Loss:3.1061 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
Validation loss decreased (0.107691 --> 0.107528).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2996254
	speed: 0.0377s/iter; left time: 929.1578s
	iters: 200, epoch: 8 | loss: 3.1903448
	speed: 0.0350s/iter; left time: 858.2683s
Epoch: 8 cost time: 9.587396383285522
Epoch: 8, Steps: 266 Train Loss: 3.2454 (Forecasting Loss:0.1416 + XiCon Loss:3.1037 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2641885
	speed: 0.0385s/iter; left time: 939.1769s
	iters: 200, epoch: 9 | loss: 3.2844450
	speed: 0.0385s/iter; left time: 934.7120s
Epoch: 9 cost time: 10.222617387771606
Epoch: 9, Steps: 266 Train Loss: 3.2442 (Forecasting Loss:0.1416 + XiCon Loss:3.1026 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107528 --> 0.107467).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2133205
	speed: 0.0413s/iter; left time: 994.5823s
	iters: 200, epoch: 10 | loss: 3.3321347
	speed: 0.0378s/iter; left time: 907.9928s
Epoch: 10 cost time: 10.424773216247559
Epoch: 10, Steps: 266 Train Loss: 3.2384 (Forecasting Loss:0.1415 + XiCon Loss:3.0969 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107467 --> 0.107430).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2786613
	speed: 0.0412s/iter; left time: 982.4922s
	iters: 200, epoch: 11 | loss: 3.2011514
	speed: 0.0387s/iter; left time: 919.9574s
Epoch: 11 cost time: 10.578303813934326
Epoch: 11, Steps: 266 Train Loss: 3.2446 (Forecasting Loss:0.1415 + XiCon Loss:3.1031 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107430 --> 0.107426).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2650704
	speed: 0.0396s/iter; left time: 934.2028s
	iters: 200, epoch: 12 | loss: 3.1978300
	speed: 0.0401s/iter; left time: 940.4983s
Epoch: 12 cost time: 10.652488470077515
Epoch: 12, Steps: 266 Train Loss: 3.2448 (Forecasting Loss:0.1415 + XiCon Loss:3.1033 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107426 --> 0.107405).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3163080
	speed: 0.0410s/iter; left time: 955.4384s
	iters: 200, epoch: 13 | loss: 3.1955996
	speed: 0.0384s/iter; left time: 890.3710s
Epoch: 13 cost time: 10.500596523284912
Epoch: 13, Steps: 266 Train Loss: 3.2432 (Forecasting Loss:0.1415 + XiCon Loss:3.1016 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107405 --> 0.107393).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3641684
	speed: 0.0404s/iter; left time: 931.2748s
	iters: 200, epoch: 14 | loss: 3.1914673
	speed: 0.0378s/iter; left time: 867.5431s
Epoch: 14 cost time: 10.392566680908203
Epoch: 14, Steps: 266 Train Loss: 3.2447 (Forecasting Loss:0.1415 + XiCon Loss:3.1032 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2586887
	speed: 0.0405s/iter; left time: 921.4967s
	iters: 200, epoch: 15 | loss: 3.1962841
	speed: 0.0387s/iter; left time: 878.3763s
Epoch: 15 cost time: 10.45792293548584
Epoch: 15, Steps: 266 Train Loss: 3.2459 (Forecasting Loss:0.1416 + XiCon Loss:3.1043 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1975057
	speed: 0.0413s/iter; left time: 929.1785s
	iters: 200, epoch: 16 | loss: 3.2124877
	speed: 0.0385s/iter; left time: 863.3536s
Epoch: 16 cost time: 10.508196353912354
Epoch: 16, Steps: 266 Train Loss: 3.2431 (Forecasting Loss:0.1415 + XiCon Loss:3.1016 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3251150
	speed: 0.0405s/iter; left time: 901.3229s
	iters: 200, epoch: 17 | loss: 3.2612731
	speed: 0.0384s/iter; left time: 849.8800s
Epoch: 17 cost time: 10.41797137260437
Epoch: 17, Steps: 266 Train Loss: 3.2456 (Forecasting Loss:0.1416 + XiCon Loss:3.1040 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2909484
	speed: 0.0405s/iter; left time: 890.4088s
	iters: 200, epoch: 18 | loss: 3.1863341
	speed: 0.0354s/iter; left time: 774.3677s
Epoch: 18 cost time: 9.89937686920166
Epoch: 18, Steps: 266 Train Loss: 3.2456 (Forecasting Loss:0.1416 + XiCon Loss:3.1041 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2861593
	speed: 0.0410s/iter; left time: 889.9072s
	iters: 200, epoch: 19 | loss: 3.2721975
	speed: 0.0395s/iter; left time: 854.5829s
Epoch: 19 cost time: 10.592076063156128
Epoch: 19, Steps: 266 Train Loss: 3.2429 (Forecasting Loss:0.1416 + XiCon Loss:3.1013 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107393 --> 0.107360).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2294002
	speed: 0.0402s/iter; left time: 863.0148s
	iters: 200, epoch: 20 | loss: 3.1706450
	speed: 0.0393s/iter; left time: 838.9751s
Epoch: 20 cost time: 10.504924774169922
Epoch: 20, Steps: 266 Train Loss: 3.2459 (Forecasting Loss:0.1416 + XiCon Loss:3.1043 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1862907
	speed: 0.0402s/iter; left time: 850.6374s
	iters: 200, epoch: 21 | loss: 3.1660881
	speed: 0.0382s/iter; left time: 805.1882s
Epoch: 21 cost time: 10.365240097045898
Epoch: 21, Steps: 266 Train Loss: 3.2465 (Forecasting Loss:0.1416 + XiCon Loss:3.1049 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2072973
	speed: 0.0409s/iter; left time: 854.5902s
	iters: 200, epoch: 22 | loss: 3.1870167
	speed: 0.0387s/iter; left time: 804.6465s
Epoch: 22 cost time: 10.449112892150879
Epoch: 22, Steps: 266 Train Loss: 3.2410 (Forecasting Loss:0.1415 + XiCon Loss:3.0995 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2233083
	speed: 0.0411s/iter; left time: 847.8894s
	iters: 200, epoch: 23 | loss: 3.2074161
	speed: 0.0378s/iter; left time: 777.0137s
Epoch: 23 cost time: 10.460357666015625
Epoch: 23, Steps: 266 Train Loss: 3.2445 (Forecasting Loss:0.1416 + XiCon Loss:3.1029 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1905584
	speed: 0.0409s/iter; left time: 833.2955s
	iters: 200, epoch: 24 | loss: 3.3048635
	speed: 0.0396s/iter; left time: 802.4195s
Epoch: 24 cost time: 10.5799400806427
Epoch: 24, Steps: 266 Train Loss: 3.2436 (Forecasting Loss:0.1415 + XiCon Loss:3.1021 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1605563
	speed: 0.0405s/iter; left time: 815.1845s
	iters: 200, epoch: 25 | loss: 3.2616022
	speed: 0.0397s/iter; left time: 795.5293s
Epoch: 25 cost time: 10.59966778755188
Epoch: 25, Steps: 266 Train Loss: 3.2486 (Forecasting Loss:0.1416 + XiCon Loss:3.1070 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2933087
	speed: 0.0399s/iter; left time: 792.6649s
	iters: 200, epoch: 26 | loss: 3.2258244
	speed: 0.0393s/iter; left time: 776.5299s
Epoch: 26 cost time: 10.489630699157715
Epoch: 26, Steps: 266 Train Loss: 3.2465 (Forecasting Loss:0.1416 + XiCon Loss:3.1049 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2108455
	speed: 0.0412s/iter; left time: 806.6172s
	iters: 200, epoch: 27 | loss: 3.2519026
	speed: 0.0393s/iter; left time: 765.1532s
Epoch: 27 cost time: 10.626158475875854
Epoch: 27, Steps: 266 Train Loss: 3.2461 (Forecasting Loss:0.1416 + XiCon Loss:3.1046 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2369137
	speed: 0.0376s/iter; left time: 727.2205s
	iters: 200, epoch: 28 | loss: 3.2819409
	speed: 0.0353s/iter; left time: 679.3131s
Epoch: 28 cost time: 9.88253140449524
Epoch: 28, Steps: 266 Train Loss: 3.2432 (Forecasting Loss:0.1415 + XiCon Loss:3.1016 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3110948
	speed: 0.0408s/iter; left time: 777.5897s
	iters: 200, epoch: 29 | loss: 3.2875292
	speed: 0.0383s/iter; left time: 726.0530s
Epoch: 29 cost time: 10.499508380889893
Epoch: 29, Steps: 266 Train Loss: 3.2448 (Forecasting Loss:0.1415 + XiCon Loss:3.1033 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026341740041971207, mae:0.12178828567266464, mape:0.09840928018093109, mspe:0.019534308463335037 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0264+-0.00020, MAE:0.1218+-0.00039, MAPE:0.0985+-0.00038, MSPE:0.0196+-0.00019, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2852
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3410864
	speed: 0.0524s/iter; left time: 1383.4491s
	iters: 200, epoch: 1 | loss: 3.2413843
	speed: 0.0480s/iter; left time: 1262.8294s
Epoch: 1 cost time: 13.184022665023804
Epoch: 1, Steps: 265 Train Loss: 3.3354 (Forecasting Loss:0.2093 + XiCon Loss:3.1260 x Lambda(1.0)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.0985
Validation loss decreased (inf --> 0.147480).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4517803
	speed: 0.0539s/iter; left time: 1408.4430s
	iters: 200, epoch: 2 | loss: 3.4390745
	speed: 0.0496s/iter; left time: 1292.0049s
Epoch: 2 cost time: 13.562390327453613
Epoch: 2, Steps: 265 Train Loss: 3.4694 (Forecasting Loss:0.1985 + XiCon Loss:3.2709 x Lambda(1.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0963
Validation loss decreased (0.147480 --> 0.145690).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3276072
	speed: 0.0514s/iter; left time: 1329.2439s
	iters: 200, epoch: 3 | loss: 3.3534670
	speed: 0.0499s/iter; left time: 1287.0607s
Epoch: 3 cost time: 13.43306565284729
Epoch: 3, Steps: 265 Train Loss: 3.4007 (Forecasting Loss:0.1931 + XiCon Loss:3.2077 x Lambda(1.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0956
Validation loss decreased (0.145690 --> 0.143522).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4366417
	speed: 0.0514s/iter; left time: 1315.3108s
	iters: 200, epoch: 4 | loss: 3.3253102
	speed: 0.0496s/iter; left time: 1264.5976s
Epoch: 4 cost time: 13.373953819274902
Epoch: 4, Steps: 265 Train Loss: 3.3337 (Forecasting Loss:0.1913 + XiCon Loss:3.1424 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3252311
	speed: 0.0515s/iter; left time: 1305.8859s
	iters: 200, epoch: 5 | loss: 3.4597425
	speed: 0.0498s/iter; left time: 1256.2744s
Epoch: 5 cost time: 13.29581093788147
Epoch: 5, Steps: 265 Train Loss: 3.3402 (Forecasting Loss:0.1906 + XiCon Loss:3.1496 x Lambda(1.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0952
Validation loss decreased (0.143522 --> 0.142645).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3573656
	speed: 0.0513s/iter; left time: 1286.5619s
	iters: 200, epoch: 6 | loss: 3.2320895
	speed: 0.0510s/iter; left time: 1274.3144s
Epoch: 6 cost time: 13.488935708999634
Epoch: 6, Steps: 265 Train Loss: 3.3338 (Forecasting Loss:0.1898 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
Validation loss decreased (0.142645 --> 0.141866).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2944517
	speed: 0.0528s/iter; left time: 1309.5371s
	iters: 200, epoch: 7 | loss: 3.3029075
	speed: 0.0494s/iter; left time: 1219.8551s
Epoch: 7 cost time: 13.441651344299316
Epoch: 7, Steps: 265 Train Loss: 3.3185 (Forecasting Loss:0.1895 + XiCon Loss:3.1290 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3461821
	speed: 0.0529s/iter; left time: 1298.9604s
	iters: 200, epoch: 8 | loss: 3.3653593
	speed: 0.0497s/iter; left time: 1215.1084s
Epoch: 8 cost time: 13.578869581222534
Epoch: 8, Steps: 265 Train Loss: 3.3091 (Forecasting Loss:0.1895 + XiCon Loss:3.1197 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.141866 --> 0.141855).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.5200925
	speed: 0.0515s/iter; left time: 1251.2343s
	iters: 200, epoch: 9 | loss: 3.2660964
	speed: 0.0512s/iter; left time: 1238.4892s
Epoch: 9 cost time: 13.640634298324585
Epoch: 9, Steps: 265 Train Loss: 3.3159 (Forecasting Loss:0.1893 + XiCon Loss:3.1267 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141855 --> 0.141815).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2370958
	speed: 0.0535s/iter; left time: 1284.5857s
	iters: 200, epoch: 10 | loss: 3.2224460
	speed: 0.0518s/iter; left time: 1238.5605s
Epoch: 10 cost time: 13.793146848678589
Epoch: 10, Steps: 265 Train Loss: 3.3091 (Forecasting Loss:0.1892 + XiCon Loss:3.1198 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141815 --> 0.141680).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2514460
	speed: 0.0525s/iter; left time: 1246.3278s
	iters: 200, epoch: 11 | loss: 3.3019829
	speed: 0.0500s/iter; left time: 1182.9107s
Epoch: 11 cost time: 13.54296875
Epoch: 11, Steps: 265 Train Loss: 3.3160 (Forecasting Loss:0.1893 + XiCon Loss:3.1267 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3131409
	speed: 0.0525s/iter; left time: 1233.1351s
	iters: 200, epoch: 12 | loss: 3.2572839
	speed: 0.0504s/iter; left time: 1178.8828s
Epoch: 12 cost time: 13.609357118606567
Epoch: 12, Steps: 265 Train Loss: 3.3078 (Forecasting Loss:0.1892 + XiCon Loss:3.1186 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141680 --> 0.141654).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3256876
	speed: 0.0517s/iter; left time: 1200.0707s
	iters: 200, epoch: 13 | loss: 3.1867247
	speed: 0.0490s/iter; left time: 1132.4157s
Epoch: 13 cost time: 13.338616132736206
Epoch: 13, Steps: 265 Train Loss: 3.3131 (Forecasting Loss:0.1892 + XiCon Loss:3.1239 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3638651
	speed: 0.0518s/iter; left time: 1188.1739s
	iters: 200, epoch: 14 | loss: 3.3624208
	speed: 0.0501s/iter; left time: 1144.0078s
Epoch: 14 cost time: 13.576078414916992
Epoch: 14, Steps: 265 Train Loss: 3.3139 (Forecasting Loss:0.1893 + XiCon Loss:3.1246 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3513529
	speed: 0.0513s/iter; left time: 1164.7811s
	iters: 200, epoch: 15 | loss: 3.1680086
	speed: 0.0495s/iter; left time: 1118.2980s
Epoch: 15 cost time: 13.417577266693115
Epoch: 15, Steps: 265 Train Loss: 3.3152 (Forecasting Loss:0.1890 + XiCon Loss:3.1261 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2558949
	speed: 0.0517s/iter; left time: 1158.4746s
	iters: 200, epoch: 16 | loss: 3.4127867
	speed: 0.0514s/iter; left time: 1147.3168s
Epoch: 16 cost time: 13.667057752609253
Epoch: 16, Steps: 265 Train Loss: 3.3152 (Forecasting Loss:0.1892 + XiCon Loss:3.1260 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141654 --> 0.141601).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2853246
	speed: 0.0513s/iter; left time: 1136.5489s
	iters: 200, epoch: 17 | loss: 3.2930017
	speed: 0.0511s/iter; left time: 1127.7995s
Epoch: 17 cost time: 13.50894021987915
Epoch: 17, Steps: 265 Train Loss: 3.3117 (Forecasting Loss:0.1892 + XiCon Loss:3.1226 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3160312
	speed: 0.0516s/iter; left time: 1128.7909s
	iters: 200, epoch: 18 | loss: 3.2629366
	speed: 0.0501s/iter; left time: 1091.3141s
Epoch: 18 cost time: 13.43755292892456
Epoch: 18, Steps: 265 Train Loss: 3.3029 (Forecasting Loss:0.1891 + XiCon Loss:3.1138 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3860064
	speed: 0.0517s/iter; left time: 1117.7691s
	iters: 200, epoch: 19 | loss: 3.3434219
	speed: 0.0511s/iter; left time: 1099.3863s
Epoch: 19 cost time: 13.535517692565918
Epoch: 19, Steps: 265 Train Loss: 3.3187 (Forecasting Loss:0.1892 + XiCon Loss:3.1295 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2922177
	speed: 0.0520s/iter; left time: 1111.8238s
	iters: 200, epoch: 20 | loss: 3.4780469
	speed: 0.0502s/iter; left time: 1068.5359s
Epoch: 20 cost time: 13.56434440612793
Epoch: 20, Steps: 265 Train Loss: 3.3134 (Forecasting Loss:0.1892 + XiCon Loss:3.1242 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4074206
	speed: 0.0498s/iter; left time: 1051.1789s
	iters: 200, epoch: 21 | loss: 3.4436626
	speed: 0.0514s/iter; left time: 1079.3130s
Epoch: 21 cost time: 13.432735204696655
Epoch: 21, Steps: 265 Train Loss: 3.3155 (Forecasting Loss:0.1891 + XiCon Loss:3.1264 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3524485
	speed: 0.0521s/iter; left time: 1084.7399s
	iters: 200, epoch: 22 | loss: 3.2613344
	speed: 0.0503s/iter; left time: 1042.5171s
Epoch: 22 cost time: 13.525325775146484
Epoch: 22, Steps: 265 Train Loss: 3.3091 (Forecasting Loss:0.1891 + XiCon Loss:3.1200 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.4102848
	speed: 0.0518s/iter; left time: 1065.1833s
	iters: 200, epoch: 23 | loss: 3.3845282
	speed: 0.0499s/iter; left time: 1021.7598s
Epoch: 23 cost time: 13.41880989074707
Epoch: 23, Steps: 265 Train Loss: 3.3156 (Forecasting Loss:0.1893 + XiCon Loss:3.1263 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4780698
	speed: 0.0529s/iter; left time: 1074.3489s
	iters: 200, epoch: 24 | loss: 3.3180816
	speed: 0.0500s/iter; left time: 1010.2017s
Epoch: 24 cost time: 13.587126970291138
Epoch: 24, Steps: 265 Train Loss: 3.3112 (Forecasting Loss:0.1892 + XiCon Loss:3.1220 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4278593
	speed: 0.0519s/iter; left time: 1040.8699s
	iters: 200, epoch: 25 | loss: 3.1426635
	speed: 0.0507s/iter; left time: 1011.1798s
Epoch: 25 cost time: 13.508115768432617
Epoch: 25, Steps: 265 Train Loss: 3.3118 (Forecasting Loss:0.1892 + XiCon Loss:3.1226 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3011470
	speed: 0.0519s/iter; left time: 1027.1307s
	iters: 200, epoch: 26 | loss: 3.2698803
	speed: 0.0498s/iter; left time: 978.9441s
Epoch: 26 cost time: 13.52121877670288
Epoch: 26, Steps: 265 Train Loss: 3.3136 (Forecasting Loss:0.1892 + XiCon Loss:3.1244 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03931811451911926, mae:0.14940227568149567, mape:0.11857562512159348, mspe:0.02630791999399662 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8966
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.2818198
	speed: 0.0502s/iter; left time: 1325.1821s
	iters: 200, epoch: 1 | loss: 3.1940641
	speed: 0.0448s/iter; left time: 1178.7029s
Epoch: 1 cost time: 12.452000856399536
Epoch: 1, Steps: 265 Train Loss: 3.3240 (Forecasting Loss:0.2120 + XiCon Loss:3.1119 x Lambda(1.0)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.146662).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2759759
	speed: 0.0524s/iter; left time: 1368.2904s
	iters: 200, epoch: 2 | loss: 3.2563453
	speed: 0.0499s/iter; left time: 1300.4888s
Epoch: 2 cost time: 13.432402610778809
Epoch: 2, Steps: 265 Train Loss: 3.5197 (Forecasting Loss:0.1987 + XiCon Loss:3.3210 x Lambda(1.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0973
Validation loss decreased (0.146662 --> 0.146392).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4201486
	speed: 0.0517s/iter; left time: 1337.3790s
	iters: 200, epoch: 3 | loss: 3.4399834
	speed: 0.0492s/iter; left time: 1268.6686s
Epoch: 3 cost time: 13.305391311645508
Epoch: 3, Steps: 265 Train Loss: 3.4119 (Forecasting Loss:0.1929 + XiCon Loss:3.2191 x Lambda(1.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0952
Validation loss decreased (0.146392 --> 0.143730).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3458424
	speed: 0.0512s/iter; left time: 1311.0719s
	iters: 200, epoch: 4 | loss: 3.3011448
	speed: 0.0495s/iter; left time: 1263.5121s
Epoch: 4 cost time: 13.372996807098389
Epoch: 4, Steps: 265 Train Loss: 3.3869 (Forecasting Loss:0.1915 + XiCon Loss:3.1954 x Lambda(1.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0948
Validation loss decreased (0.143730 --> 0.142167).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4122925
	speed: 0.0520s/iter; left time: 1316.5412s
	iters: 200, epoch: 5 | loss: 3.3571644
	speed: 0.0493s/iter; left time: 1244.9083s
Epoch: 5 cost time: 13.38218355178833
Epoch: 5, Steps: 265 Train Loss: 3.3803 (Forecasting Loss:0.1903 + XiCon Loss:3.1900 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.142167 --> 0.141722).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3531148
	speed: 0.0514s/iter; left time: 1288.6037s
	iters: 200, epoch: 6 | loss: 3.3672619
	speed: 0.0505s/iter; left time: 1261.9686s
Epoch: 6 cost time: 13.52415132522583
Epoch: 6, Steps: 265 Train Loss: 3.3736 (Forecasting Loss:0.1899 + XiCon Loss:3.1836 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4321756
	speed: 0.0520s/iter; left time: 1289.8527s
	iters: 200, epoch: 7 | loss: 3.3835304
	speed: 0.0507s/iter; left time: 1252.0299s
Epoch: 7 cost time: 13.627223253250122
Epoch: 7, Steps: 265 Train Loss: 3.3730 (Forecasting Loss:0.1896 + XiCon Loss:3.1834 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
Validation loss decreased (0.141722 --> 0.141524).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3974884
	speed: 0.0526s/iter; left time: 1290.6623s
	iters: 200, epoch: 8 | loss: 3.2066076
	speed: 0.0506s/iter; left time: 1236.9545s
Epoch: 8 cost time: 13.55027461051941
Epoch: 8, Steps: 265 Train Loss: 3.3677 (Forecasting Loss:0.1894 + XiCon Loss:3.1784 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2671275
	speed: 0.0498s/iter; left time: 1209.1465s
	iters: 200, epoch: 9 | loss: 3.5003033
	speed: 0.0494s/iter; left time: 1193.3804s
Epoch: 9 cost time: 13.157294988632202
Epoch: 9, Steps: 265 Train Loss: 3.3673 (Forecasting Loss:0.1892 + XiCon Loss:3.1780 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3283660
	speed: 0.0523s/iter; left time: 1256.6520s
	iters: 200, epoch: 10 | loss: 3.5300450
	speed: 0.0504s/iter; left time: 1206.1019s
Epoch: 10 cost time: 13.508726358413696
Epoch: 10, Steps: 265 Train Loss: 3.3562 (Forecasting Loss:0.1892 + XiCon Loss:3.1670 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4210911
	speed: 0.0520s/iter; left time: 1234.8373s
	iters: 200, epoch: 11 | loss: 3.3546729
	speed: 0.0501s/iter; left time: 1185.0260s
Epoch: 11 cost time: 13.532896757125854
Epoch: 11, Steps: 265 Train Loss: 3.3646 (Forecasting Loss:0.1893 + XiCon Loss:3.1753 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2979047
	speed: 0.0518s/iter; left time: 1216.6640s
	iters: 200, epoch: 12 | loss: 3.3308518
	speed: 0.0502s/iter; left time: 1173.8923s
Epoch: 12 cost time: 13.463037967681885
Epoch: 12, Steps: 265 Train Loss: 3.3542 (Forecasting Loss:0.1892 + XiCon Loss:3.1650 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5520864
	speed: 0.0528s/iter; left time: 1225.1487s
	iters: 200, epoch: 13 | loss: 3.2763898
	speed: 0.0502s/iter; left time: 1160.5617s
Epoch: 13 cost time: 13.560622453689575
Epoch: 13, Steps: 265 Train Loss: 3.3648 (Forecasting Loss:0.1892 + XiCon Loss:3.1756 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3058455
	speed: 0.0526s/iter; left time: 1207.7640s
	iters: 200, epoch: 14 | loss: 3.4405167
	speed: 0.0503s/iter; left time: 1148.9644s
Epoch: 14 cost time: 13.5335111618042
Epoch: 14, Steps: 265 Train Loss: 3.3603 (Forecasting Loss:0.1893 + XiCon Loss:3.1710 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2768910
	speed: 0.0524s/iter; left time: 1189.7919s
	iters: 200, epoch: 15 | loss: 3.2364898
	speed: 0.0496s/iter; left time: 1119.7926s
Epoch: 15 cost time: 13.502769708633423
Epoch: 15, Steps: 265 Train Loss: 3.3637 (Forecasting Loss:0.1892 + XiCon Loss:3.1746 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2928622
	speed: 0.0522s/iter; left time: 1171.6612s
	iters: 200, epoch: 16 | loss: 3.3410175
	speed: 0.0498s/iter; left time: 1110.9260s
Epoch: 16 cost time: 13.574951648712158
Epoch: 16, Steps: 265 Train Loss: 3.3674 (Forecasting Loss:0.1891 + XiCon Loss:3.1784 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2581561
	speed: 0.0515s/iter; left time: 1142.2280s
	iters: 200, epoch: 17 | loss: 3.4799674
	speed: 0.0502s/iter; left time: 1107.4338s
Epoch: 17 cost time: 13.56743597984314
Epoch: 17, Steps: 265 Train Loss: 3.3594 (Forecasting Loss:0.1891 + XiCon Loss:3.1703 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03932990878820419, mae:0.14963948726654053, mape:0.1190587729215622, mspe:0.02656819298863411 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7408
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3796084
	speed: 0.0501s/iter; left time: 1322.7862s
	iters: 200, epoch: 1 | loss: 3.2827697
	speed: 0.0481s/iter; left time: 1264.0867s
Epoch: 1 cost time: 12.878944158554077
Epoch: 1, Steps: 265 Train Loss: 3.3204 (Forecasting Loss:0.2102 + XiCon Loss:3.1102 x Lambda(1.0)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.147273).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5666089
	speed: 0.0523s/iter; left time: 1366.7935s
	iters: 200, epoch: 2 | loss: 3.4317598
	speed: 0.0503s/iter; left time: 1309.0771s
Epoch: 2 cost time: 13.474546432495117
Epoch: 2, Steps: 265 Train Loss: 3.4767 (Forecasting Loss:0.1994 + XiCon Loss:3.2773 x Lambda(1.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0977
Validation loss decreased (0.147273 --> 0.146396).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2924604
	speed: 0.0514s/iter; left time: 1330.2294s
	iters: 200, epoch: 3 | loss: 3.2055175
	speed: 0.0483s/iter; left time: 1244.5699s
Epoch: 3 cost time: 13.158291816711426
Epoch: 3, Steps: 265 Train Loss: 3.2756 (Forecasting Loss:0.1928 + XiCon Loss:3.0828 x Lambda(1.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0953
Validation loss decreased (0.146396 --> 0.143043).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2208767
	speed: 0.0506s/iter; left time: 1296.3996s
	iters: 200, epoch: 4 | loss: 3.2050495
	speed: 0.0500s/iter; left time: 1274.6594s
Epoch: 4 cost time: 13.325128078460693
Epoch: 4, Steps: 265 Train Loss: 3.2256 (Forecasting Loss:0.1911 + XiCon Loss:3.0344 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0950
Validation loss decreased (0.143043 --> 0.142007).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1944647
	speed: 0.0519s/iter; left time: 1315.0819s
	iters: 200, epoch: 5 | loss: 3.2324176
	speed: 0.0489s/iter; left time: 1233.4205s
Epoch: 5 cost time: 13.414021730422974
Epoch: 5, Steps: 265 Train Loss: 3.2081 (Forecasting Loss:0.1903 + XiCon Loss:3.0178 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2599914
	speed: 0.0515s/iter; left time: 1291.8427s
	iters: 200, epoch: 6 | loss: 3.2079422
	speed: 0.0485s/iter; left time: 1211.1842s
Epoch: 6 cost time: 13.294667482376099
Epoch: 6, Steps: 265 Train Loss: 3.2037 (Forecasting Loss:0.1899 + XiCon Loss:3.0139 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.142007 --> 0.141930).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2639287
	speed: 0.0511s/iter; left time: 1268.6240s
	iters: 200, epoch: 7 | loss: 3.2644615
	speed: 0.0497s/iter; left time: 1227.3843s
Epoch: 7 cost time: 13.446462154388428
Epoch: 7, Steps: 265 Train Loss: 3.2059 (Forecasting Loss:0.1896 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
Validation loss decreased (0.141930 --> 0.141690).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1584718
	speed: 0.0526s/iter; left time: 1290.4507s
	iters: 200, epoch: 8 | loss: 3.1702592
	speed: 0.0499s/iter; left time: 1219.4469s
Epoch: 8 cost time: 13.513070106506348
Epoch: 8, Steps: 265 Train Loss: 3.2057 (Forecasting Loss:0.1894 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1395097
	speed: 0.0527s/iter; left time: 1278.4287s
	iters: 200, epoch: 9 | loss: 3.1370800
	speed: 0.0505s/iter; left time: 1220.6342s
Epoch: 9 cost time: 13.60049033164978
Epoch: 9, Steps: 265 Train Loss: 3.2048 (Forecasting Loss:0.1893 + XiCon Loss:3.0155 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2606311
	speed: 0.0518s/iter; left time: 1243.3719s
	iters: 200, epoch: 10 | loss: 3.1401613
	speed: 0.0498s/iter; left time: 1191.2898s
Epoch: 10 cost time: 13.447366714477539
Epoch: 10, Steps: 265 Train Loss: 3.2025 (Forecasting Loss:0.1893 + XiCon Loss:3.0133 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
Validation loss decreased (0.141690 --> 0.141651).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1323359
	speed: 0.0519s/iter; left time: 1231.8744s
	iters: 200, epoch: 11 | loss: 3.1945572
	speed: 0.0505s/iter; left time: 1193.7261s
Epoch: 11 cost time: 13.522251605987549
Epoch: 11, Steps: 265 Train Loss: 3.2032 (Forecasting Loss:0.1893 + XiCon Loss:3.0139 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2394021
	speed: 0.0532s/iter; left time: 1250.3360s
	iters: 200, epoch: 12 | loss: 3.2014101
	speed: 0.0508s/iter; left time: 1187.6778s
Epoch: 12 cost time: 13.606724262237549
Epoch: 12, Steps: 265 Train Loss: 3.2023 (Forecasting Loss:0.1891 + XiCon Loss:3.0131 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2028246
	speed: 0.0540s/iter; left time: 1253.9452s
	iters: 200, epoch: 13 | loss: 3.1754622
	speed: 0.0501s/iter; left time: 1158.9794s
Epoch: 13 cost time: 13.644278526306152
Epoch: 13, Steps: 265 Train Loss: 3.2020 (Forecasting Loss:0.1892 + XiCon Loss:3.0128 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2398705
	speed: 0.0506s/iter; left time: 1161.4048s
	iters: 200, epoch: 14 | loss: 3.1771407
	speed: 0.0499s/iter; left time: 1141.2928s
Epoch: 14 cost time: 13.348313331604004
Epoch: 14, Steps: 265 Train Loss: 3.2010 (Forecasting Loss:0.1893 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1275024
	speed: 0.0515s/iter; left time: 1168.0796s
	iters: 200, epoch: 15 | loss: 3.1596284
	speed: 0.0509s/iter; left time: 1149.7059s
Epoch: 15 cost time: 13.458850145339966
Epoch: 15, Steps: 265 Train Loss: 3.1987 (Forecasting Loss:0.1892 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0943
Validation loss decreased (0.141651 --> 0.141601).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2473269
	speed: 0.0514s/iter; left time: 1152.9900s
	iters: 200, epoch: 16 | loss: 3.2501774
	speed: 0.0502s/iter; left time: 1119.8847s
Epoch: 16 cost time: 13.407679557800293
Epoch: 16, Steps: 265 Train Loss: 3.2009 (Forecasting Loss:0.1893 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1715233
	speed: 0.0527s/iter; left time: 1166.9566s
	iters: 200, epoch: 17 | loss: 3.1424599
	speed: 0.0488s/iter; left time: 1076.6653s
Epoch: 17 cost time: 13.360288381576538
Epoch: 17, Steps: 265 Train Loss: 3.2000 (Forecasting Loss:0.1893 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1247208
	speed: 0.0520s/iter; left time: 1139.4271s
	iters: 200, epoch: 18 | loss: 3.1732993
	speed: 0.0501s/iter; left time: 1091.7993s
Epoch: 18 cost time: 13.44119668006897
Epoch: 18, Steps: 265 Train Loss: 3.2020 (Forecasting Loss:0.1893 + XiCon Loss:3.0126 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1768832
	speed: 0.0522s/iter; left time: 1129.2663s
	iters: 200, epoch: 19 | loss: 3.2586408
	speed: 0.0511s/iter; left time: 1100.8925s
Epoch: 19 cost time: 13.640950918197632
Epoch: 19, Steps: 265 Train Loss: 3.2005 (Forecasting Loss:0.1892 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2495897
	speed: 0.0517s/iter; left time: 1105.2175s
	iters: 200, epoch: 20 | loss: 3.1477494
	speed: 0.0499s/iter; left time: 1061.1100s
Epoch: 20 cost time: 13.51194429397583
Epoch: 20, Steps: 265 Train Loss: 3.2007 (Forecasting Loss:0.1893 + XiCon Loss:3.0114 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0943
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1502938
	speed: 0.0512s/iter; left time: 1079.4080s
	iters: 200, epoch: 21 | loss: 3.1420150
	speed: 0.0496s/iter; left time: 1042.2025s
Epoch: 21 cost time: 13.229240894317627
Epoch: 21, Steps: 265 Train Loss: 3.2066 (Forecasting Loss:0.1892 + XiCon Loss:3.0173 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1220281
	speed: 0.0518s/iter; left time: 1079.3080s
	iters: 200, epoch: 22 | loss: 3.2242906
	speed: 0.0506s/iter; left time: 1049.0557s
Epoch: 22 cost time: 13.465552568435669
Epoch: 22, Steps: 265 Train Loss: 3.2011 (Forecasting Loss:0.1892 + XiCon Loss:3.0119 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1541407
	speed: 0.0525s/iter; left time: 1080.4502s
	iters: 200, epoch: 23 | loss: 3.2338555
	speed: 0.0497s/iter; left time: 1018.1460s
Epoch: 23 cost time: 13.607359647750854
Epoch: 23, Steps: 265 Train Loss: 3.2038 (Forecasting Loss:0.1891 + XiCon Loss:3.0147 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2435236
	speed: 0.0521s/iter; left time: 1056.9890s
	iters: 200, epoch: 24 | loss: 3.2808018
	speed: 0.0492s/iter; left time: 993.1846s
Epoch: 24 cost time: 13.545814990997314
Epoch: 24, Steps: 265 Train Loss: 3.2026 (Forecasting Loss:0.1892 + XiCon Loss:3.0135 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0943
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1792469
	speed: 0.0530s/iter; left time: 1062.0010s
	iters: 200, epoch: 25 | loss: 3.2211685
	speed: 0.0493s/iter; left time: 984.0221s
Epoch: 25 cost time: 13.524089336395264
Epoch: 25, Steps: 265 Train Loss: 3.2011 (Forecasting Loss:0.1893 + XiCon Loss:3.0119 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039289440959692, mae:0.1494024395942688, mape:0.11861934512853622, mspe:0.026311233639717102 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7783
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3287852
	speed: 0.0499s/iter; left time: 1317.4100s
	iters: 200, epoch: 1 | loss: 3.2711303
	speed: 0.0482s/iter; left time: 1267.1246s
Epoch: 1 cost time: 12.935541152954102
Epoch: 1, Steps: 265 Train Loss: 3.3112 (Forecasting Loss:0.2074 + XiCon Loss:3.1038 x Lambda(1.0)), Vali MSE Loss: 0.1474 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.147421).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.7932172
	speed: 0.0522s/iter; left time: 1364.4651s
	iters: 200, epoch: 2 | loss: 3.4379215
	speed: 0.0491s/iter; left time: 1278.4699s
Epoch: 2 cost time: 13.364068508148193
Epoch: 2, Steps: 265 Train Loss: 3.5700 (Forecasting Loss:0.1971 + XiCon Loss:3.3729 x Lambda(1.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0970
Validation loss decreased (0.147421 --> 0.146103).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3532095
	speed: 0.0500s/iter; left time: 1293.2473s
	iters: 200, epoch: 3 | loss: 3.5348113
	speed: 0.0488s/iter; left time: 1257.7566s
Epoch: 3 cost time: 13.14570951461792
Epoch: 3, Steps: 265 Train Loss: 3.4666 (Forecasting Loss:0.1934 + XiCon Loss:3.2732 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0972
Validation loss decreased (0.146103 --> 0.145568).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.5281720
	speed: 0.0513s/iter; left time: 1313.8925s
	iters: 200, epoch: 4 | loss: 3.7442133
	speed: 0.0496s/iter; left time: 1264.3865s
Epoch: 4 cost time: 13.50391173362732
Epoch: 4, Steps: 265 Train Loss: 3.4430 (Forecasting Loss:0.1915 + XiCon Loss:3.2515 x Lambda(1.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0953
Validation loss decreased (0.145568 --> 0.142473).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3631556
	speed: 0.0525s/iter; left time: 1331.6380s
	iters: 200, epoch: 5 | loss: 3.3557305
	speed: 0.0501s/iter; left time: 1264.5010s
Epoch: 5 cost time: 13.56553339958191
Epoch: 5, Steps: 265 Train Loss: 3.3758 (Forecasting Loss:0.1902 + XiCon Loss:3.1856 x Lambda(1.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0956
Validation loss decreased (0.142473 --> 0.142347).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3988514
	speed: 0.0518s/iter; left time: 1299.9366s
	iters: 200, epoch: 6 | loss: 3.4386439
	speed: 0.0501s/iter; left time: 1250.1556s
Epoch: 6 cost time: 13.462355613708496
Epoch: 6, Steps: 265 Train Loss: 3.3517 (Forecasting Loss:0.1897 + XiCon Loss:3.1620 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0951
Validation loss decreased (0.142347 --> 0.141920).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5430562
	speed: 0.0519s/iter; left time: 1288.0379s
	iters: 200, epoch: 7 | loss: 3.2708609
	speed: 0.0514s/iter; left time: 1270.3848s
Epoch: 7 cost time: 13.637639045715332
Epoch: 7, Steps: 265 Train Loss: 3.3419 (Forecasting Loss:0.1895 + XiCon Loss:3.1525 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0951
Validation loss decreased (0.141920 --> 0.141917).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3155141
	speed: 0.0525s/iter; left time: 1288.4482s
	iters: 200, epoch: 8 | loss: 3.5285995
	speed: 0.0497s/iter; left time: 1216.1498s
Epoch: 8 cost time: 13.551449060440063
Epoch: 8, Steps: 265 Train Loss: 3.3433 (Forecasting Loss:0.1894 + XiCon Loss:3.1539 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3905373
	speed: 0.0526s/iter; left time: 1276.2137s
	iters: 200, epoch: 9 | loss: 3.2710204
	speed: 0.0493s/iter; left time: 1193.1857s
Epoch: 9 cost time: 13.482454061508179
Epoch: 9, Steps: 265 Train Loss: 3.3420 (Forecasting Loss:0.1892 + XiCon Loss:3.1528 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
Validation loss decreased (0.141917 --> 0.141748).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3365741
	speed: 0.0527s/iter; left time: 1264.4499s
	iters: 200, epoch: 10 | loss: 3.3064160
	speed: 0.0495s/iter; left time: 1183.0635s
Epoch: 10 cost time: 13.359025716781616
Epoch: 10, Steps: 265 Train Loss: 3.3430 (Forecasting Loss:0.1891 + XiCon Loss:3.1538 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1745143
	speed: 0.0505s/iter; left time: 1200.1586s
	iters: 200, epoch: 11 | loss: 3.4156411
	speed: 0.0498s/iter; left time: 1177.2026s
Epoch: 11 cost time: 13.32938289642334
Epoch: 11, Steps: 265 Train Loss: 3.3358 (Forecasting Loss:0.1892 + XiCon Loss:3.1466 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2846053
	speed: 0.0534s/iter; left time: 1254.2270s
	iters: 200, epoch: 12 | loss: 3.5195627
	speed: 0.0504s/iter; left time: 1179.7802s
Epoch: 12 cost time: 13.714311122894287
Epoch: 12, Steps: 265 Train Loss: 3.3443 (Forecasting Loss:0.1891 + XiCon Loss:3.1552 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
Validation loss decreased (0.141748 --> 0.141722).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2691050
	speed: 0.0531s/iter; left time: 1232.5050s
	iters: 200, epoch: 13 | loss: 3.3319421
	speed: 0.0508s/iter; left time: 1173.4472s
Epoch: 13 cost time: 13.717739343643188
Epoch: 13, Steps: 265 Train Loss: 3.3486 (Forecasting Loss:0.1891 + XiCon Loss:3.1594 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
Validation loss decreased (0.141722 --> 0.141586).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2637472
	speed: 0.0529s/iter; left time: 1214.9730s
	iters: 200, epoch: 14 | loss: 3.5418146
	speed: 0.0513s/iter; left time: 1172.9390s
Epoch: 14 cost time: 13.709638595581055
Epoch: 14, Steps: 265 Train Loss: 3.3428 (Forecasting Loss:0.1892 + XiCon Loss:3.1536 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2161682
	speed: 0.0518s/iter; left time: 1176.2325s
	iters: 200, epoch: 15 | loss: 3.3947451
	speed: 0.0502s/iter; left time: 1134.5069s
Epoch: 15 cost time: 13.584412574768066
Epoch: 15, Steps: 265 Train Loss: 3.3393 (Forecasting Loss:0.1891 + XiCon Loss:3.1501 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2413001
	speed: 0.0519s/iter; left time: 1164.1160s
	iters: 200, epoch: 16 | loss: 3.3745406
	speed: 0.0503s/iter; left time: 1123.2733s
Epoch: 16 cost time: 13.520116329193115
Epoch: 16, Steps: 265 Train Loss: 3.3420 (Forecasting Loss:0.1893 + XiCon Loss:3.1528 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4373925
	speed: 0.0513s/iter; left time: 1136.8998s
	iters: 200, epoch: 17 | loss: 3.3629994
	speed: 0.0499s/iter; left time: 1101.1380s
Epoch: 17 cost time: 13.458469867706299
Epoch: 17, Steps: 265 Train Loss: 3.3436 (Forecasting Loss:0.1892 + XiCon Loss:3.1543 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3481374
	speed: 0.0510s/iter; left time: 1117.6802s
	iters: 200, epoch: 18 | loss: 3.3014297
	speed: 0.0489s/iter; left time: 1064.9992s
Epoch: 18 cost time: 13.290795803070068
Epoch: 18, Steps: 265 Train Loss: 3.3475 (Forecasting Loss:0.1892 + XiCon Loss:3.1583 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2712762
	speed: 0.0521s/iter; left time: 1127.7114s
	iters: 200, epoch: 19 | loss: 3.3106852
	speed: 0.0506s/iter; left time: 1089.8039s
Epoch: 19 cost time: 13.541661262512207
Epoch: 19, Steps: 265 Train Loss: 3.3364 (Forecasting Loss:0.1892 + XiCon Loss:3.1472 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3309698
	speed: 0.0536s/iter; left time: 1144.9096s
	iters: 200, epoch: 20 | loss: 3.3928359
	speed: 0.0503s/iter; left time: 1069.1899s
Epoch: 20 cost time: 13.727075099945068
Epoch: 20, Steps: 265 Train Loss: 3.3413 (Forecasting Loss:0.1891 + XiCon Loss:3.1522 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3174813
	speed: 0.0521s/iter; left time: 1099.9805s
	iters: 200, epoch: 21 | loss: 3.3470645
	speed: 0.0498s/iter; left time: 1046.2406s
Epoch: 21 cost time: 13.49653172492981
Epoch: 21, Steps: 265 Train Loss: 3.3476 (Forecasting Loss:0.1891 + XiCon Loss:3.1585 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3733375
	speed: 0.0526s/iter; left time: 1096.0711s
	iters: 200, epoch: 22 | loss: 3.4247713
	speed: 0.0499s/iter; left time: 1034.7456s
Epoch: 22 cost time: 13.62881875038147
Epoch: 22, Steps: 265 Train Loss: 3.3433 (Forecasting Loss:0.1893 + XiCon Loss:3.1540 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2290385
	speed: 0.0526s/iter; left time: 1081.6376s
	iters: 200, epoch: 23 | loss: 3.3971162
	speed: 0.0504s/iter; left time: 1030.8935s
Epoch: 23 cost time: 13.572332382202148
Epoch: 23, Steps: 265 Train Loss: 3.3521 (Forecasting Loss:0.1893 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039654411375522614, mae:0.150032639503479, mape:0.11902402341365814, mspe:0.02643708884716034 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7332
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3056202
	speed: 0.0493s/iter; left time: 1300.3809s
	iters: 200, epoch: 1 | loss: 3.3068027
	speed: 0.0470s/iter; left time: 1237.0384s
Epoch: 1 cost time: 12.703816175460815
Epoch: 1, Steps: 265 Train Loss: 3.3287 (Forecasting Loss:0.2119 + XiCon Loss:3.1168 x Lambda(1.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.148199).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.7149358
	speed: 0.0492s/iter; left time: 1285.1646s
	iters: 200, epoch: 2 | loss: 3.4893715
	speed: 0.0489s/iter; left time: 1273.8860s
Epoch: 2 cost time: 12.932996988296509
Epoch: 2, Steps: 265 Train Loss: 3.5769 (Forecasting Loss:0.2025 + XiCon Loss:3.3745 x Lambda(1.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0962
Validation loss decreased (0.148199 --> 0.146109).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3169587
	speed: 0.0500s/iter; left time: 1294.3059s
	iters: 200, epoch: 3 | loss: 3.3472695
	speed: 0.0485s/iter; left time: 1248.9698s
Epoch: 3 cost time: 13.057451725006104
Epoch: 3, Steps: 265 Train Loss: 3.3520 (Forecasting Loss:0.1928 + XiCon Loss:3.1592 x Lambda(1.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0952
Validation loss decreased (0.146109 --> 0.143311).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3184450
	speed: 0.0508s/iter; left time: 1300.6295s
	iters: 200, epoch: 4 | loss: 3.2457130
	speed: 0.0494s/iter; left time: 1260.7648s
Epoch: 4 cost time: 13.311877727508545
Epoch: 4, Steps: 265 Train Loss: 3.3091 (Forecasting Loss:0.1912 + XiCon Loss:3.1180 x Lambda(1.0)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.0948
Validation loss decreased (0.143311 --> 0.142934).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2709429
	speed: 0.0498s/iter; left time: 1262.4244s
	iters: 200, epoch: 5 | loss: 3.3589909
	speed: 0.0500s/iter; left time: 1262.5225s
Epoch: 5 cost time: 13.193902730941772
Epoch: 5, Steps: 265 Train Loss: 3.2705 (Forecasting Loss:0.1901 + XiCon Loss:3.0804 x Lambda(1.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0951
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2142954
	speed: 0.0515s/iter; left time: 1290.3555s
	iters: 200, epoch: 6 | loss: 3.2791963
	speed: 0.0500s/iter; left time: 1249.5751s
Epoch: 6 cost time: 13.455445289611816
Epoch: 6, Steps: 265 Train Loss: 3.2600 (Forecasting Loss:0.1899 + XiCon Loss:3.0701 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0943
Validation loss decreased (0.142934 --> 0.142116).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1897402
	speed: 0.0518s/iter; left time: 1285.5951s
	iters: 200, epoch: 7 | loss: 3.2263155
	speed: 0.0496s/iter; left time: 1224.9019s
Epoch: 7 cost time: 13.385440349578857
Epoch: 7, Steps: 265 Train Loss: 3.2560 (Forecasting Loss:0.1895 + XiCon Loss:3.0665 x Lambda(1.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2163622
	speed: 0.0515s/iter; left time: 1264.2464s
	iters: 200, epoch: 8 | loss: 3.1809640
	speed: 0.0507s/iter; left time: 1239.6140s
Epoch: 8 cost time: 13.45048713684082
Epoch: 8, Steps: 265 Train Loss: 3.2494 (Forecasting Loss:0.1892 + XiCon Loss:3.0601 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
Validation loss decreased (0.142116 --> 0.141862).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1858609
	speed: 0.0513s/iter; left time: 1245.9778s
	iters: 200, epoch: 9 | loss: 3.3149602
	speed: 0.0485s/iter; left time: 1172.2751s
Epoch: 9 cost time: 13.108844518661499
Epoch: 9, Steps: 265 Train Loss: 3.2508 (Forecasting Loss:0.1892 + XiCon Loss:3.0616 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0942
Validation loss decreased (0.141862 --> 0.141736).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2085989
	speed: 0.0517s/iter; left time: 1241.8081s
	iters: 200, epoch: 10 | loss: 3.3444319
	speed: 0.0481s/iter; left time: 1149.9094s
Epoch: 10 cost time: 13.154234170913696
Epoch: 10, Steps: 265 Train Loss: 3.2542 (Forecasting Loss:0.1891 + XiCon Loss:3.0651 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1885395
	speed: 0.0516s/iter; left time: 1225.0935s
	iters: 200, epoch: 11 | loss: 3.2582955
	speed: 0.0475s/iter; left time: 1122.9287s
Epoch: 11 cost time: 13.135249137878418
Epoch: 11, Steps: 265 Train Loss: 3.2493 (Forecasting Loss:0.1891 + XiCon Loss:3.0602 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0942
Validation loss decreased (0.141736 --> 0.141736).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2072484
	speed: 0.0520s/iter; left time: 1222.1571s
	iters: 200, epoch: 12 | loss: 3.1917095
	speed: 0.0488s/iter; left time: 1141.5568s
Epoch: 12 cost time: 13.36848521232605
Epoch: 12, Steps: 265 Train Loss: 3.2470 (Forecasting Loss:0.1891 + XiCon Loss:3.0579 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2257495
	speed: 0.0512s/iter; left time: 1188.7796s
	iters: 200, epoch: 13 | loss: 3.3665667
	speed: 0.0506s/iter; left time: 1169.1625s
Epoch: 13 cost time: 13.44170355796814
Epoch: 13, Steps: 265 Train Loss: 3.2497 (Forecasting Loss:0.1891 + XiCon Loss:3.0606 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1785891
	speed: 0.0518s/iter; left time: 1188.9157s
	iters: 200, epoch: 14 | loss: 3.3437691
	speed: 0.0488s/iter; left time: 1116.1570s
Epoch: 14 cost time: 13.3099946975708
Epoch: 14, Steps: 265 Train Loss: 3.2509 (Forecasting Loss:0.1891 + XiCon Loss:3.0619 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2016394
	speed: 0.0509s/iter; left time: 1154.1811s
	iters: 200, epoch: 15 | loss: 3.2444763
	speed: 0.0500s/iter; left time: 1128.5914s
Epoch: 15 cost time: 13.301979541778564
Epoch: 15, Steps: 265 Train Loss: 3.2483 (Forecasting Loss:0.1890 + XiCon Loss:3.0593 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2117281
	speed: 0.0514s/iter; left time: 1152.4553s
	iters: 200, epoch: 16 | loss: 3.1783576
	speed: 0.0503s/iter; left time: 1122.8672s
Epoch: 16 cost time: 13.3309907913208
Epoch: 16, Steps: 265 Train Loss: 3.2479 (Forecasting Loss:0.1890 + XiCon Loss:3.0589 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2453749
	speed: 0.0503s/iter; left time: 1115.0699s
	iters: 200, epoch: 17 | loss: 3.2704256
	speed: 0.0475s/iter; left time: 1047.6785s
Epoch: 17 cost time: 13.04936695098877
Epoch: 17, Steps: 265 Train Loss: 3.2490 (Forecasting Loss:0.1891 + XiCon Loss:3.0598 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3853211
	speed: 0.0506s/iter; left time: 1108.5280s
	iters: 200, epoch: 18 | loss: 3.2394321
	speed: 0.0500s/iter; left time: 1088.7424s
Epoch: 18 cost time: 13.256601333618164
Epoch: 18, Steps: 265 Train Loss: 3.2554 (Forecasting Loss:0.1890 + XiCon Loss:3.0663 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2680469
	speed: 0.0512s/iter; left time: 1106.5453s
	iters: 200, epoch: 19 | loss: 3.1828518
	speed: 0.0498s/iter; left time: 1072.2741s
Epoch: 19 cost time: 13.436852931976318
Epoch: 19, Steps: 265 Train Loss: 3.2484 (Forecasting Loss:0.1891 + XiCon Loss:3.0593 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1454117
	speed: 0.0526s/iter; left time: 1123.9524s
	iters: 200, epoch: 20 | loss: 3.1982160
	speed: 0.0493s/iter; left time: 1048.9213s
Epoch: 20 cost time: 13.490220069885254
Epoch: 20, Steps: 265 Train Loss: 3.2509 (Forecasting Loss:0.1891 + XiCon Loss:3.0619 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3049703
	speed: 0.0518s/iter; left time: 1092.8262s
	iters: 200, epoch: 21 | loss: 3.2435541
	speed: 0.0485s/iter; left time: 1018.2924s
Epoch: 21 cost time: 13.292428255081177
Epoch: 21, Steps: 265 Train Loss: 3.2488 (Forecasting Loss:0.1891 + XiCon Loss:3.0597 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03914201259613037, mae:0.14930091798305511, mape:0.11872155219316483, mspe:0.026442281901836395 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0393+-0.00023, MAE:0.1496+-0.00037, MAPE:0.1188+-0.00028, MSPE:0.0264+-0.00013, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7165
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.3238003
	speed: 0.0430s/iter; left time: 1132.1296s
	iters: 200, epoch: 1 | loss: 3.2879872
	speed: 0.0374s/iter; left time: 980.4233s
Epoch: 1 cost time: 10.426675081253052
Epoch: 1, Steps: 264 Train Loss: 3.3002 (Forecasting Loss:0.2377 + XiCon Loss:3.0625 x Lambda(1.0)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1134
Validation loss decreased (inf --> 0.174140).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2681899
	speed: 0.0440s/iter; left time: 1146.6899s
	iters: 200, epoch: 2 | loss: 3.3061349
	speed: 0.0383s/iter; left time: 992.4522s
Epoch: 2 cost time: 10.637681722640991
Epoch: 2, Steps: 264 Train Loss: 3.2157 (Forecasting Loss:0.2438 + XiCon Loss:2.9719 x Lambda(1.0)), Vali MSE Loss: 0.1786 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1206493
	speed: 0.0415s/iter; left time: 1069.7595s
	iters: 200, epoch: 3 | loss: 3.1740432
	speed: 0.0392s/iter; left time: 1006.5452s
Epoch: 3 cost time: 10.690661668777466
Epoch: 3, Steps: 264 Train Loss: 3.1745 (Forecasting Loss:0.2340 + XiCon Loss:2.9405 x Lambda(1.0)), Vali MSE Loss: 0.1721 Test MSE Loss: 0.1133
Validation loss decreased (0.174140 --> 0.172104).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1641755
	speed: 0.0418s/iter; left time: 1067.0067s
	iters: 200, epoch: 4 | loss: 3.1504230
	speed: 0.0398s/iter; left time: 1012.0678s
Epoch: 4 cost time: 10.73393177986145
Epoch: 4, Steps: 264 Train Loss: 3.1404 (Forecasting Loss:0.2298 + XiCon Loss:2.9106 x Lambda(1.0)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1140
Validation loss decreased (0.172104 --> 0.171719).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1617656
	speed: 0.0420s/iter; left time: 1059.7498s
	iters: 200, epoch: 5 | loss: 3.0598760
	speed: 0.0406s/iter; left time: 1022.0914s
Epoch: 5 cost time: 10.812421798706055
Epoch: 5, Steps: 264 Train Loss: 3.1135 (Forecasting Loss:0.2284 + XiCon Loss:2.8851 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1123
Validation loss decreased (0.171719 --> 0.171095).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1048462
	speed: 0.0418s/iter; left time: 1043.5121s
	iters: 200, epoch: 6 | loss: 3.0071034
	speed: 0.0401s/iter; left time: 997.7941s
Epoch: 6 cost time: 10.696774005889893
Epoch: 6, Steps: 264 Train Loss: 3.0807 (Forecasting Loss:0.2274 + XiCon Loss:2.8533 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1136
Validation loss decreased (0.171095 --> 0.170146).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1043856
	speed: 0.0416s/iter; left time: 1027.4381s
	iters: 200, epoch: 7 | loss: 3.0468016
	speed: 0.0406s/iter; left time: 1000.1235s
Epoch: 7 cost time: 10.823657035827637
Epoch: 7, Steps: 264 Train Loss: 3.0755 (Forecasting Loss:0.2264 + XiCon Loss:2.8491 x Lambda(1.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1197014
	speed: 0.0426s/iter; left time: 1041.9761s
	iters: 200, epoch: 8 | loss: 3.0673075
	speed: 0.0404s/iter; left time: 985.0768s
Epoch: 8 cost time: 10.877817153930664
Epoch: 8, Steps: 264 Train Loss: 3.0649 (Forecasting Loss:0.2259 + XiCon Loss:2.8390 x Lambda(1.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0476882
	speed: 0.0412s/iter; left time: 997.4431s
	iters: 200, epoch: 9 | loss: 3.0769510
	speed: 0.0405s/iter; left time: 974.7231s
Epoch: 9 cost time: 10.752303123474121
Epoch: 9, Steps: 264 Train Loss: 3.0647 (Forecasting Loss:0.2255 + XiCon Loss:2.8392 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1140
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1148977
	speed: 0.0421s/iter; left time: 1006.1486s
	iters: 200, epoch: 10 | loss: 3.1099555
	speed: 0.0403s/iter; left time: 959.3936s
Epoch: 10 cost time: 10.775898456573486
Epoch: 10, Steps: 264 Train Loss: 3.0645 (Forecasting Loss:0.2254 + XiCon Loss:2.8391 x Lambda(1.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1142
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0187235
	speed: 0.0425s/iter; left time: 1006.4463s
	iters: 200, epoch: 11 | loss: 3.0332994
	speed: 0.0411s/iter; left time: 969.2575s
Epoch: 11 cost time: 10.736594438552856
Epoch: 11, Steps: 264 Train Loss: 3.0625 (Forecasting Loss:0.2252 + XiCon Loss:2.8374 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1145
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0509024
	speed: 0.0400s/iter; left time: 936.5762s
	iters: 200, epoch: 12 | loss: 3.0765362
	speed: 0.0404s/iter; left time: 941.8428s
Epoch: 12 cost time: 10.603906631469727
Epoch: 12, Steps: 264 Train Loss: 3.0674 (Forecasting Loss:0.2252 + XiCon Loss:2.8422 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1147
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0130069
	speed: 0.0422s/iter; left time: 975.1020s
	iters: 200, epoch: 13 | loss: 3.0646193
	speed: 0.0401s/iter; left time: 922.9734s
Epoch: 13 cost time: 10.807762861251831
Epoch: 13, Steps: 264 Train Loss: 3.0618 (Forecasting Loss:0.2252 + XiCon Loss:2.8366 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1145
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0993173
	speed: 0.0422s/iter; left time: 965.6507s
	iters: 200, epoch: 14 | loss: 3.0725498
	speed: 0.0397s/iter; left time: 904.4236s
Epoch: 14 cost time: 10.746699333190918
Epoch: 14, Steps: 264 Train Loss: 3.0611 (Forecasting Loss:0.2251 + XiCon Loss:2.8360 x Lambda(1.0)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1145
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0869379
	speed: 0.0414s/iter; left time: 936.3239s
	iters: 200, epoch: 15 | loss: 3.0543406
	speed: 0.0406s/iter; left time: 914.1303s
Epoch: 15 cost time: 10.815465688705444
Epoch: 15, Steps: 264 Train Loss: 3.0651 (Forecasting Loss:0.2250 + XiCon Loss:2.8401 x Lambda(1.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1146
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0462081
	speed: 0.0417s/iter; left time: 930.9267s
	iters: 200, epoch: 16 | loss: 3.0637913
	speed: 0.0402s/iter; left time: 894.1044s
Epoch: 16 cost time: 10.751331567764282
Epoch: 16, Steps: 264 Train Loss: 3.0616 (Forecasting Loss:0.2251 + XiCon Loss:2.8365 x Lambda(1.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1146
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05333104357123375, mae:0.17384138703346252, mape:0.1361396461725235, mspe:0.03365664556622505 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3774
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.3354871
	speed: 0.0404s/iter; left time: 1061.4786s
	iters: 200, epoch: 1 | loss: 3.2367947
	speed: 0.0369s/iter; left time: 967.6372s
Epoch: 1 cost time: 10.157021045684814
Epoch: 1, Steps: 264 Train Loss: 3.3119 (Forecasting Loss:0.2379 + XiCon Loss:3.0739 x Lambda(1.0)), Vali MSE Loss: 0.1745 Test MSE Loss: 0.1147
Validation loss decreased (inf --> 0.174543).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2972057
	speed: 0.0452s/iter; left time: 1176.9761s
	iters: 200, epoch: 2 | loss: 3.1717944
	speed: 0.0397s/iter; left time: 1030.9772s
Epoch: 2 cost time: 11.086687803268433
Epoch: 2, Steps: 264 Train Loss: 3.2490 (Forecasting Loss:0.2412 + XiCon Loss:3.0077 x Lambda(1.0)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1173
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1190443
	speed: 0.0416s/iter; left time: 1073.2851s
	iters: 200, epoch: 3 | loss: 3.0910897
	speed: 0.0387s/iter; left time: 992.2964s
Epoch: 3 cost time: 10.375612258911133
Epoch: 3, Steps: 264 Train Loss: 3.1421 (Forecasting Loss:0.2348 + XiCon Loss:2.9073 x Lambda(1.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1148
Validation loss decreased (0.174543 --> 0.172680).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1001883
	speed: 0.0413s/iter; left time: 1054.0693s
	iters: 200, epoch: 4 | loss: 3.1377692
	speed: 0.0400s/iter; left time: 1017.3885s
Epoch: 4 cost time: 10.733968257904053
Epoch: 4, Steps: 264 Train Loss: 3.1213 (Forecasting Loss:0.2301 + XiCon Loss:2.8913 x Lambda(1.0)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1124
Validation loss decreased (0.172680 --> 0.170643).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1445804
	speed: 0.0420s/iter; left time: 1060.2568s
	iters: 200, epoch: 5 | loss: 3.0912912
	speed: 0.0399s/iter; left time: 1003.6834s
Epoch: 5 cost time: 10.723193407058716
Epoch: 5, Steps: 264 Train Loss: 3.1146 (Forecasting Loss:0.2280 + XiCon Loss:2.8866 x Lambda(1.0)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1131
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1057806
	speed: 0.0427s/iter; left time: 1067.5285s
	iters: 200, epoch: 6 | loss: 3.1276102
	speed: 0.0405s/iter; left time: 1008.0168s
Epoch: 6 cost time: 10.88273549079895
Epoch: 6, Steps: 264 Train Loss: 3.1137 (Forecasting Loss:0.2275 + XiCon Loss:2.8862 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
Validation loss decreased (0.170643 --> 0.170192).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0644317
	speed: 0.0411s/iter; left time: 1016.7001s
	iters: 200, epoch: 7 | loss: 3.0964448
	speed: 0.0392s/iter; left time: 964.3696s
Epoch: 7 cost time: 10.622041702270508
Epoch: 7, Steps: 264 Train Loss: 3.1105 (Forecasting Loss:0.2268 + XiCon Loss:2.8837 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
Validation loss decreased (0.170192 --> 0.170068).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0763662
	speed: 0.0413s/iter; left time: 1009.6932s
	iters: 200, epoch: 8 | loss: 3.1549804
	speed: 0.0398s/iter; left time: 969.3009s
Epoch: 8 cost time: 10.674409866333008
Epoch: 8, Steps: 264 Train Loss: 3.1065 (Forecasting Loss:0.2266 + XiCon Loss:2.8799 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1122
Validation loss decreased (0.170068 --> 0.169881).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1286731
	speed: 0.0423s/iter; left time: 1022.8988s
	iters: 200, epoch: 9 | loss: 3.0925465
	speed: 0.0400s/iter; left time: 964.4545s
Epoch: 9 cost time: 10.79383635520935
Epoch: 9, Steps: 264 Train Loss: 3.1052 (Forecasting Loss:0.2265 + XiCon Loss:2.8787 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
Validation loss decreased (0.169881 --> 0.169815).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1124239
	speed: 0.0413s/iter; left time: 989.1883s
	iters: 200, epoch: 10 | loss: 3.1116073
	speed: 0.0407s/iter; left time: 970.3267s
Epoch: 10 cost time: 10.729106903076172
Epoch: 10, Steps: 264 Train Loss: 3.1131 (Forecasting Loss:0.2264 + XiCon Loss:2.8866 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169815 --> 0.169804).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1064644
	speed: 0.0417s/iter; left time: 985.6376s
	iters: 200, epoch: 11 | loss: 3.1509597
	speed: 0.0384s/iter; left time: 904.7706s
Epoch: 11 cost time: 10.547211170196533
Epoch: 11, Steps: 264 Train Loss: 3.1083 (Forecasting Loss:0.2263 + XiCon Loss:2.8820 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
Validation loss decreased (0.169804 --> 0.169763).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1121464
	speed: 0.0425s/iter; left time: 994.1862s
	iters: 200, epoch: 12 | loss: 3.1538949
	speed: 0.0399s/iter; left time: 930.0666s
Epoch: 12 cost time: 10.635481357574463
Epoch: 12, Steps: 264 Train Loss: 3.1082 (Forecasting Loss:0.2261 + XiCon Loss:2.8821 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0576024
	speed: 0.0399s/iter; left time: 922.4930s
	iters: 200, epoch: 13 | loss: 3.0427933
	speed: 0.0394s/iter; left time: 906.7088s
Epoch: 13 cost time: 10.39378571510315
Epoch: 13, Steps: 264 Train Loss: 3.1064 (Forecasting Loss:0.2264 + XiCon Loss:2.8800 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1181195
	speed: 0.0422s/iter; left time: 964.0487s
	iters: 200, epoch: 14 | loss: 3.1044044
	speed: 0.0397s/iter; left time: 904.8516s
Epoch: 14 cost time: 10.741029977798462
Epoch: 14, Steps: 264 Train Loss: 3.1057 (Forecasting Loss:0.2264 + XiCon Loss:2.8793 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1229570
	speed: 0.0429s/iter; left time: 968.8576s
	iters: 200, epoch: 15 | loss: 3.1084797
	speed: 0.0409s/iter; left time: 921.4830s
Epoch: 15 cost time: 10.918814897537231
Epoch: 15, Steps: 264 Train Loss: 3.1090 (Forecasting Loss:0.2263 + XiCon Loss:2.8827 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1482773
	speed: 0.0413s/iter; left time: 922.3065s
	iters: 200, epoch: 16 | loss: 3.1372075
	speed: 0.0396s/iter; left time: 880.4248s
Epoch: 16 cost time: 10.626219987869263
Epoch: 16, Steps: 264 Train Loss: 3.1059 (Forecasting Loss:0.2263 + XiCon Loss:2.8795 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0913477
	speed: 0.0425s/iter; left time: 937.7401s
	iters: 200, epoch: 17 | loss: 3.0518320
	speed: 0.0394s/iter; left time: 866.6660s
Epoch: 17 cost time: 10.710049867630005
Epoch: 17, Steps: 264 Train Loss: 3.1071 (Forecasting Loss:0.2262 + XiCon Loss:2.8808 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1600955
	speed: 0.0423s/iter; left time: 923.5961s
	iters: 200, epoch: 18 | loss: 3.1141696
	speed: 0.0393s/iter; left time: 853.5670s
Epoch: 18 cost time: 10.81821346282959
Epoch: 18, Steps: 264 Train Loss: 3.1083 (Forecasting Loss:0.2262 + XiCon Loss:2.8820 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1406348
	speed: 0.0425s/iter; left time: 916.1029s
	iters: 200, epoch: 19 | loss: 3.0528643
	speed: 0.0401s/iter; left time: 859.9827s
Epoch: 19 cost time: 10.834836721420288
Epoch: 19, Steps: 264 Train Loss: 3.1095 (Forecasting Loss:0.2263 + XiCon Loss:2.8832 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1236668
	speed: 0.0430s/iter; left time: 914.5344s
	iters: 200, epoch: 20 | loss: 3.0331573
	speed: 0.0404s/iter; left time: 855.5504s
Epoch: 20 cost time: 10.838675737380981
Epoch: 20, Steps: 264 Train Loss: 3.1057 (Forecasting Loss:0.2263 + XiCon Loss:2.8794 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
Validation loss decreased (0.169763 --> 0.169753).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0511055
	speed: 0.0425s/iter; left time: 893.6242s
	iters: 200, epoch: 21 | loss: 3.1463482
	speed: 0.0403s/iter; left time: 843.4887s
Epoch: 21 cost time: 10.885558605194092
Epoch: 21, Steps: 264 Train Loss: 3.1099 (Forecasting Loss:0.2262 + XiCon Loss:2.8837 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
Validation loss decreased (0.169753 --> 0.169751).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0619926
	speed: 0.0401s/iter; left time: 832.4004s
	iters: 200, epoch: 22 | loss: 3.1227293
	speed: 0.0404s/iter; left time: 834.4702s
Epoch: 22 cost time: 10.587267875671387
Epoch: 22, Steps: 264 Train Loss: 3.1083 (Forecasting Loss:0.2263 + XiCon Loss:2.8821 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1107321
	speed: 0.0415s/iter; left time: 850.9271s
	iters: 200, epoch: 23 | loss: 3.1006329
	speed: 0.0398s/iter; left time: 811.6819s
Epoch: 23 cost time: 10.714118719100952
Epoch: 23, Steps: 264 Train Loss: 3.1061 (Forecasting Loss:0.2263 + XiCon Loss:2.8798 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0945518
	speed: 0.0409s/iter; left time: 826.8134s
	iters: 200, epoch: 24 | loss: 3.0762746
	speed: 0.0395s/iter; left time: 795.1589s
Epoch: 24 cost time: 10.57085108757019
Epoch: 24, Steps: 264 Train Loss: 3.1082 (Forecasting Loss:0.2262 + XiCon Loss:2.8820 x Lambda(1.0)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1123
Validation loss decreased (0.169751 --> 0.169645).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1603696
	speed: 0.0422s/iter; left time: 842.9589s
	iters: 200, epoch: 25 | loss: 3.1201570
	speed: 0.0401s/iter; left time: 796.0920s
Epoch: 25 cost time: 10.782342195510864
Epoch: 25, Steps: 264 Train Loss: 3.1057 (Forecasting Loss:0.2264 + XiCon Loss:2.8793 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1310096
	speed: 0.0414s/iter; left time: 815.9708s
	iters: 200, epoch: 26 | loss: 3.1082828
	speed: 0.0402s/iter; left time: 787.0794s
Epoch: 26 cost time: 10.662752628326416
Epoch: 26, Steps: 264 Train Loss: 3.0997 (Forecasting Loss:0.2264 + XiCon Loss:2.8734 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0584779
	speed: 0.0421s/iter; left time: 818.8519s
	iters: 200, epoch: 27 | loss: 3.1063232
	speed: 0.0394s/iter; left time: 762.4902s
Epoch: 27 cost time: 10.656072616577148
Epoch: 27, Steps: 264 Train Loss: 3.1078 (Forecasting Loss:0.2263 + XiCon Loss:2.8815 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0615869
	speed: 0.0424s/iter; left time: 812.3284s
	iters: 200, epoch: 28 | loss: 3.1827121
	speed: 0.0394s/iter; left time: 752.2268s
Epoch: 28 cost time: 10.72907042503357
Epoch: 28, Steps: 264 Train Loss: 3.1081 (Forecasting Loss:0.2262 + XiCon Loss:2.8818 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0965488
	speed: 0.0424s/iter; left time: 801.7772s
	iters: 200, epoch: 29 | loss: 3.0587978
	speed: 0.0397s/iter; left time: 747.0574s
Epoch: 29 cost time: 10.744518280029297
Epoch: 29, Steps: 264 Train Loss: 3.1079 (Forecasting Loss:0.2263 + XiCon Loss:2.8816 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1611407
	speed: 0.0411s/iter; left time: 765.5785s
	iters: 200, epoch: 30 | loss: 3.1780820
	speed: 0.0397s/iter; left time: 736.7321s
Epoch: 30 cost time: 10.590762853622437
Epoch: 30, Steps: 264 Train Loss: 3.1082 (Forecasting Loss:0.2263 + XiCon Loss:2.8819 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0946608
	speed: 0.0382s/iter; left time: 702.3264s
	iters: 200, epoch: 31 | loss: 3.0507631
	speed: 0.0364s/iter; left time: 665.2505s
Epoch: 31 cost time: 10.049973011016846
Epoch: 31, Steps: 264 Train Loss: 3.1075 (Forecasting Loss:0.2264 + XiCon Loss:2.8811 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0954444
	speed: 0.0417s/iter; left time: 754.6330s
	iters: 200, epoch: 32 | loss: 3.0910194
	speed: 0.0399s/iter; left time: 719.6841s
Epoch: 32 cost time: 10.809586763381958
Epoch: 32, Steps: 264 Train Loss: 3.1052 (Forecasting Loss:0.2262 + XiCon Loss:2.8789 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0967977
	speed: 0.0412s/iter; left time: 736.3118s
	iters: 200, epoch: 33 | loss: 3.1408253
	speed: 0.0396s/iter; left time: 702.9017s
Epoch: 33 cost time: 10.6512610912323
Epoch: 33, Steps: 264 Train Loss: 3.1047 (Forecasting Loss:0.2263 + XiCon Loss:2.8783 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0464602
	speed: 0.0418s/iter; left time: 736.0252s
	iters: 200, epoch: 34 | loss: 3.1060538
	speed: 0.0401s/iter; left time: 701.7130s
Epoch: 34 cost time: 10.787202835083008
Epoch: 34, Steps: 264 Train Loss: 3.1042 (Forecasting Loss:0.2264 + XiCon Loss:2.8778 x Lambda(1.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05243385210633278, mae:0.1722271740436554, mape:0.13428567349910736, mspe:0.03210655227303505 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3793
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.2954648
	speed: 0.0405s/iter; left time: 1064.5831s
	iters: 200, epoch: 1 | loss: 3.2389362
	speed: 0.0376s/iter; left time: 985.5843s
Epoch: 1 cost time: 10.184393405914307
Epoch: 1, Steps: 264 Train Loss: 3.3040 (Forecasting Loss:0.2376 + XiCon Loss:3.0664 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1147
Validation loss decreased (inf --> 0.173661).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1115456
	speed: 0.0441s/iter; left time: 1147.9720s
	iters: 200, epoch: 2 | loss: 3.1551108
	speed: 0.0408s/iter; left time: 1057.0207s
Epoch: 2 cost time: 11.054453611373901
Epoch: 2, Steps: 264 Train Loss: 3.2140 (Forecasting Loss:0.2441 + XiCon Loss:2.9699 x Lambda(1.0)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2470789
	speed: 0.0429s/iter; left time: 1105.3755s
	iters: 200, epoch: 3 | loss: 3.1683662
	speed: 0.0406s/iter; left time: 1042.5864s
Epoch: 3 cost time: 10.865772485733032
Epoch: 3, Steps: 264 Train Loss: 3.2335 (Forecasting Loss:0.2326 + XiCon Loss:3.0009 x Lambda(1.0)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1153
Validation loss decreased (0.173661 --> 0.172942).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2276483
	speed: 0.0421s/iter; left time: 1074.0623s
	iters: 200, epoch: 4 | loss: 3.0694127
	speed: 0.0404s/iter; left time: 1026.7010s
Epoch: 4 cost time: 10.807937383651733
Epoch: 4, Steps: 264 Train Loss: 3.2052 (Forecasting Loss:0.2301 + XiCon Loss:2.9751 x Lambda(1.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1134
Validation loss decreased (0.172942 --> 0.171165).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1266117
	speed: 0.0390s/iter; left time: 983.5699s
	iters: 200, epoch: 5 | loss: 3.2069635
	speed: 0.0374s/iter; left time: 940.4407s
Epoch: 5 cost time: 10.266431331634521
Epoch: 5, Steps: 264 Train Loss: 3.1823 (Forecasting Loss:0.2283 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1508465
	speed: 0.0424s/iter; left time: 1060.2298s
	iters: 200, epoch: 6 | loss: 3.2375209
	speed: 0.0401s/iter; left time: 997.5221s
Epoch: 6 cost time: 10.86234450340271
Epoch: 6, Steps: 264 Train Loss: 3.1692 (Forecasting Loss:0.2274 + XiCon Loss:2.9418 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1123
Validation loss decreased (0.171165 --> 0.170289).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2124972
	speed: 0.0431s/iter; left time: 1066.1172s
	iters: 200, epoch: 7 | loss: 3.1189520
	speed: 0.0408s/iter; left time: 1003.2594s
Epoch: 7 cost time: 10.957899332046509
Epoch: 7, Steps: 264 Train Loss: 3.1671 (Forecasting Loss:0.2269 + XiCon Loss:2.9403 x Lambda(1.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2116830
	speed: 0.0437s/iter; left time: 1067.7446s
	iters: 200, epoch: 8 | loss: 3.2049854
	speed: 0.0405s/iter; left time: 986.9334s
Epoch: 8 cost time: 10.998801708221436
Epoch: 8, Steps: 264 Train Loss: 3.1603 (Forecasting Loss:0.2267 + XiCon Loss:2.9336 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170289 --> 0.169998).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1349018
	speed: 0.0433s/iter; left time: 1047.4979s
	iters: 200, epoch: 9 | loss: 3.1039140
	speed: 0.0404s/iter; left time: 972.6647s
Epoch: 9 cost time: 10.88605523109436
Epoch: 9, Steps: 264 Train Loss: 3.1632 (Forecasting Loss:0.2264 + XiCon Loss:2.9368 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169998 --> 0.169948).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1264510
	speed: 0.0425s/iter; left time: 1016.9084s
	iters: 200, epoch: 10 | loss: 3.1352971
	speed: 0.0411s/iter; left time: 980.3886s
Epoch: 10 cost time: 10.943498849868774
Epoch: 10, Steps: 264 Train Loss: 3.1596 (Forecasting Loss:0.2263 + XiCon Loss:2.9333 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1078999
	speed: 0.0429s/iter; left time: 1015.9630s
	iters: 200, epoch: 11 | loss: 3.1718993
	speed: 0.0400s/iter; left time: 942.7509s
Epoch: 11 cost time: 10.898728370666504
Epoch: 11, Steps: 264 Train Loss: 3.1629 (Forecasting Loss:0.2262 + XiCon Loss:2.9367 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169948 --> 0.169918).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1677122
	speed: 0.0424s/iter; left time: 991.7643s
	iters: 200, epoch: 12 | loss: 3.1520667
	speed: 0.0397s/iter; left time: 923.8106s
Epoch: 12 cost time: 10.748634576797485
Epoch: 12, Steps: 264 Train Loss: 3.1605 (Forecasting Loss:0.2263 + XiCon Loss:2.9342 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0675979
	speed: 0.0419s/iter; left time: 970.3462s
	iters: 200, epoch: 13 | loss: 3.2122440
	speed: 0.0410s/iter; left time: 945.1308s
Epoch: 13 cost time: 10.976249694824219
Epoch: 13, Steps: 264 Train Loss: 3.1576 (Forecasting Loss:0.2262 + XiCon Loss:2.9314 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1060936
	speed: 0.0394s/iter; left time: 901.8774s
	iters: 200, epoch: 14 | loss: 3.1769881
	speed: 0.0378s/iter; left time: 859.9957s
Epoch: 14 cost time: 10.320080995559692
Epoch: 14, Steps: 264 Train Loss: 3.1579 (Forecasting Loss:0.2262 + XiCon Loss:2.9318 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.2021108
	speed: 0.0417s/iter; left time: 942.3086s
	iters: 200, epoch: 15 | loss: 3.1291144
	speed: 0.0401s/iter; left time: 903.5105s
Epoch: 15 cost time: 10.738301992416382
Epoch: 15, Steps: 264 Train Loss: 3.1592 (Forecasting Loss:0.2261 + XiCon Loss:2.9330 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169918 --> 0.169901).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2052436
	speed: 0.0422s/iter; left time: 941.9823s
	iters: 200, epoch: 16 | loss: 3.0926929
	speed: 0.0406s/iter; left time: 902.7535s
Epoch: 16 cost time: 10.964268207550049
Epoch: 16, Steps: 264 Train Loss: 3.1604 (Forecasting Loss:0.2262 + XiCon Loss:2.9342 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169901 --> 0.169857).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1320524
	speed: 0.0429s/iter; left time: 947.8701s
	iters: 200, epoch: 17 | loss: 3.1596832
	speed: 0.0406s/iter; left time: 891.2770s
Epoch: 17 cost time: 10.916175603866577
Epoch: 17, Steps: 264 Train Loss: 3.1568 (Forecasting Loss:0.2262 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169857 --> 0.169834).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1380053
	speed: 0.0428s/iter; left time: 932.6530s
	iters: 200, epoch: 18 | loss: 3.0241714
	speed: 0.0402s/iter; left time: 873.9020s
Epoch: 18 cost time: 10.883776903152466
Epoch: 18, Steps: 264 Train Loss: 3.1582 (Forecasting Loss:0.2262 + XiCon Loss:2.9320 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1500885
	speed: 0.0426s/iter; left time: 917.7103s
	iters: 200, epoch: 19 | loss: 3.1483510
	speed: 0.0405s/iter; left time: 868.8305s
Epoch: 19 cost time: 10.949223518371582
Epoch: 19, Steps: 264 Train Loss: 3.1528 (Forecasting Loss:0.2262 + XiCon Loss:2.9267 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1108894
	speed: 0.0422s/iter; left time: 897.8318s
	iters: 200, epoch: 20 | loss: 3.1543467
	speed: 0.0405s/iter; left time: 857.2117s
Epoch: 20 cost time: 10.8961341381073
Epoch: 20, Steps: 264 Train Loss: 3.1569 (Forecasting Loss:0.2262 + XiCon Loss:2.9307 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1420343
	speed: 0.0426s/iter; left time: 895.8421s
	iters: 200, epoch: 21 | loss: 3.2052188
	speed: 0.0402s/iter; left time: 841.7950s
Epoch: 21 cost time: 10.808347225189209
Epoch: 21, Steps: 264 Train Loss: 3.1635 (Forecasting Loss:0.2262 + XiCon Loss:2.9373 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1490777
	speed: 0.0429s/iter; left time: 889.7165s
	iters: 200, epoch: 22 | loss: 3.2164888
	speed: 0.0409s/iter; left time: 845.4279s
Epoch: 22 cost time: 10.910653591156006
Epoch: 22, Steps: 264 Train Loss: 3.1543 (Forecasting Loss:0.2262 + XiCon Loss:2.9281 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2191348
	speed: 0.0396s/iter; left time: 811.8959s
	iters: 200, epoch: 23 | loss: 3.1370416
	speed: 0.0369s/iter; left time: 752.0969s
Epoch: 23 cost time: 10.07993197441101
Epoch: 23, Steps: 264 Train Loss: 3.1623 (Forecasting Loss:0.2262 + XiCon Loss:2.9362 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1791999
	speed: 0.0418s/iter; left time: 844.9549s
	iters: 200, epoch: 24 | loss: 3.1226356
	speed: 0.0398s/iter; left time: 802.0815s
Epoch: 24 cost time: 10.803546667098999
Epoch: 24, Steps: 264 Train Loss: 3.1590 (Forecasting Loss:0.2262 + XiCon Loss:2.9328 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1351423
	speed: 0.0424s/iter; left time: 845.6380s
	iters: 200, epoch: 25 | loss: 3.1480126
	speed: 0.0398s/iter; left time: 790.3544s
Epoch: 25 cost time: 10.779890298843384
Epoch: 25, Steps: 264 Train Loss: 3.1615 (Forecasting Loss:0.2262 + XiCon Loss:2.9353 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2262802
	speed: 0.0430s/iter; left time: 846.8647s
	iters: 200, epoch: 26 | loss: 3.1327920
	speed: 0.0405s/iter; left time: 794.8168s
Epoch: 26 cost time: 10.93730115890503
Epoch: 26, Steps: 264 Train Loss: 3.1549 (Forecasting Loss:0.2262 + XiCon Loss:2.9288 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1019635
	speed: 0.0433s/iter; left time: 840.9823s
	iters: 200, epoch: 27 | loss: 3.1532872
	speed: 0.0402s/iter; left time: 776.9575s
Epoch: 27 cost time: 10.893435001373291
Epoch: 27, Steps: 264 Train Loss: 3.1612 (Forecasting Loss:0.2261 + XiCon Loss:2.9351 x Lambda(1.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169834 --> 0.169830).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1238356
	speed: 0.0431s/iter; left time: 825.5803s
	iters: 200, epoch: 28 | loss: 3.1222274
	speed: 0.0399s/iter; left time: 761.9613s
Epoch: 28 cost time: 10.865538120269775
Epoch: 28, Steps: 264 Train Loss: 3.1573 (Forecasting Loss:0.2261 + XiCon Loss:2.9312 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0644832
	speed: 0.0425s/iter; left time: 802.8065s
	iters: 200, epoch: 29 | loss: 3.1735628
	speed: 0.0400s/iter; left time: 751.5133s
Epoch: 29 cost time: 10.80204439163208
Epoch: 29, Steps: 264 Train Loss: 3.1669 (Forecasting Loss:0.2262 + XiCon Loss:2.9407 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1546528
	speed: 0.0425s/iter; left time: 792.1855s
	iters: 200, epoch: 30 | loss: 3.1730909
	speed: 0.0398s/iter; left time: 738.1644s
Epoch: 30 cost time: 10.812381744384766
Epoch: 30, Steps: 264 Train Loss: 3.1613 (Forecasting Loss:0.2262 + XiCon Loss:2.9351 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1671417
	speed: 0.0421s/iter; left time: 773.9047s
	iters: 200, epoch: 31 | loss: 3.1744730
	speed: 0.0401s/iter; left time: 732.8202s
Epoch: 31 cost time: 10.819072008132935
Epoch: 31, Steps: 264 Train Loss: 3.1593 (Forecasting Loss:0.2262 + XiCon Loss:2.9332 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0787098
	speed: 0.0424s/iter; left time: 768.3888s
	iters: 200, epoch: 32 | loss: 3.0779111
	speed: 0.0363s/iter; left time: 653.5130s
Epoch: 32 cost time: 10.295397758483887
Epoch: 32, Steps: 264 Train Loss: 3.1568 (Forecasting Loss:0.2262 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2088177
	speed: 0.0425s/iter; left time: 759.4819s
	iters: 200, epoch: 33 | loss: 3.1289761
	speed: 0.0403s/iter; left time: 715.1385s
Epoch: 33 cost time: 10.860692501068115
Epoch: 33, Steps: 264 Train Loss: 3.1573 (Forecasting Loss:0.2262 + XiCon Loss:2.9311 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1393116
	speed: 0.0421s/iter; left time: 740.6695s
	iters: 200, epoch: 34 | loss: 3.2085073
	speed: 0.0406s/iter; left time: 709.5103s
Epoch: 34 cost time: 10.913146257400513
Epoch: 34, Steps: 264 Train Loss: 3.1575 (Forecasting Loss:0.2261 + XiCon Loss:2.9314 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.1564660
	speed: 0.0419s/iter; left time: 725.7705s
	iters: 200, epoch: 35 | loss: 3.1440015
	speed: 0.0412s/iter; left time: 710.1048s
Epoch: 35 cost time: 10.963397741317749
Epoch: 35, Steps: 264 Train Loss: 3.1627 (Forecasting Loss:0.2262 + XiCon Loss:2.9365 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.1081047
	speed: 0.0425s/iter; left time: 724.3502s
	iters: 200, epoch: 36 | loss: 3.1537454
	speed: 0.0405s/iter; left time: 687.4617s
Epoch: 36 cost time: 10.919673204421997
Epoch: 36, Steps: 264 Train Loss: 3.1622 (Forecasting Loss:0.2261 + XiCon Loss:2.9361 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.1285872
	speed: 0.0433s/iter; left time: 726.9333s
	iters: 200, epoch: 37 | loss: 3.1899273
	speed: 0.0398s/iter; left time: 663.8380s
Epoch: 37 cost time: 10.899222373962402
Epoch: 37, Steps: 264 Train Loss: 3.1535 (Forecasting Loss:0.2262 + XiCon Loss:2.9273 x Lambda(1.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05247122049331665, mae:0.17227548360824585, mape:0.1343197226524353, mspe:0.03211047127842903 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6385
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.3336606
	speed: 0.0400s/iter; left time: 1051.8978s
	iters: 200, epoch: 1 | loss: 3.2225740
	speed: 0.0371s/iter; left time: 971.4262s
Epoch: 1 cost time: 10.041572093963623
Epoch: 1, Steps: 264 Train Loss: 3.3099 (Forecasting Loss:0.2388 + XiCon Loss:3.0711 x Lambda(1.0)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1149
Validation loss decreased (inf --> 0.173648).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1941657
	speed: 0.0437s/iter; left time: 1137.6607s
	iters: 200, epoch: 2 | loss: 3.1578658
	speed: 0.0409s/iter; left time: 1059.5433s
Epoch: 2 cost time: 11.038341522216797
Epoch: 2, Steps: 264 Train Loss: 3.1618 (Forecasting Loss:0.2421 + XiCon Loss:2.9197 x Lambda(1.0)), Vali MSE Loss: 0.1778 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0583575
	speed: 0.0404s/iter; left time: 1040.3397s
	iters: 200, epoch: 3 | loss: 3.0463102
	speed: 0.0369s/iter; left time: 948.2105s
Epoch: 3 cost time: 10.319433450698853
Epoch: 3, Steps: 264 Train Loss: 3.0726 (Forecasting Loss:0.2344 + XiCon Loss:2.8382 x Lambda(1.0)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1153
Validation loss decreased (0.173648 --> 0.173210).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0103922
	speed: 0.0416s/iter; left time: 1061.9109s
	iters: 200, epoch: 4 | loss: 2.9864342
	speed: 0.0405s/iter; left time: 1028.6555s
Epoch: 4 cost time: 10.854830980300903
Epoch: 4, Steps: 264 Train Loss: 3.0561 (Forecasting Loss:0.2298 + XiCon Loss:2.8263 x Lambda(1.0)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1141
Validation loss decreased (0.173210 --> 0.171910).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0070930
	speed: 0.0431s/iter; left time: 1088.3066s
	iters: 200, epoch: 5 | loss: 3.0058603
	speed: 0.0405s/iter; left time: 1018.7980s
Epoch: 5 cost time: 10.943976640701294
Epoch: 5, Steps: 264 Train Loss: 3.0517 (Forecasting Loss:0.2278 + XiCon Loss:2.8239 x Lambda(1.0)), Vali MSE Loss: 0.1756 Test MSE Loss: 0.1151
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0561492
	speed: 0.0421s/iter; left time: 1052.6587s
	iters: 200, epoch: 6 | loss: 3.0638509
	speed: 0.0398s/iter; left time: 991.2723s
Epoch: 6 cost time: 10.754190921783447
Epoch: 6, Steps: 264 Train Loss: 3.0462 (Forecasting Loss:0.2264 + XiCon Loss:2.8197 x Lambda(1.0)), Vali MSE Loss: 0.1758 Test MSE Loss: 0.1135
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1225457
	speed: 0.0433s/iter; left time: 1070.0429s
	iters: 200, epoch: 7 | loss: 2.9706063
	speed: 0.0414s/iter; left time: 1018.6555s
Epoch: 7 cost time: 11.016406059265137
Epoch: 7, Steps: 264 Train Loss: 3.0459 (Forecasting Loss:0.2260 + XiCon Loss:2.8199 x Lambda(1.0)), Vali MSE Loss: 0.1752 Test MSE Loss: 0.1135
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0276108
	speed: 0.0434s/iter; left time: 1060.7164s
	iters: 200, epoch: 8 | loss: 2.9846284
	speed: 0.0407s/iter; left time: 992.1746s
Epoch: 8 cost time: 10.944283485412598
Epoch: 8, Steps: 264 Train Loss: 3.0442 (Forecasting Loss:0.2255 + XiCon Loss:2.8187 x Lambda(1.0)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1133
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0552955
	speed: 0.0428s/iter; left time: 1034.3774s
	iters: 200, epoch: 9 | loss: 3.0689037
	speed: 0.0411s/iter; left time: 989.1657s
Epoch: 9 cost time: 11.005112409591675
Epoch: 9, Steps: 264 Train Loss: 3.0428 (Forecasting Loss:0.2254 + XiCon Loss:2.8174 x Lambda(1.0)), Vali MSE Loss: 0.1740 Test MSE Loss: 0.1130
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0490754
	speed: 0.0426s/iter; left time: 1020.1949s
	iters: 200, epoch: 10 | loss: 3.0451379
	speed: 0.0401s/iter; left time: 954.7786s
Epoch: 10 cost time: 10.862607717514038
Epoch: 10, Steps: 264 Train Loss: 3.0443 (Forecasting Loss:0.2251 + XiCon Loss:2.8192 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1133
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0434585
	speed: 0.0427s/iter; left time: 1011.0366s
	iters: 200, epoch: 11 | loss: 3.0221546
	speed: 0.0396s/iter; left time: 933.1711s
Epoch: 11 cost time: 10.775592803955078
Epoch: 11, Steps: 264 Train Loss: 3.0438 (Forecasting Loss:0.2251 + XiCon Loss:2.8187 x Lambda(1.0)), Vali MSE Loss: 0.1758 Test MSE Loss: 0.1133
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0079403
	speed: 0.0422s/iter; left time: 987.1162s
	iters: 200, epoch: 12 | loss: 3.0173204
	speed: 0.0366s/iter; left time: 851.9596s
Epoch: 12 cost time: 10.263365745544434
Epoch: 12, Steps: 264 Train Loss: 3.0424 (Forecasting Loss:0.2251 + XiCon Loss:2.8172 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1132
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 2.9893603
	speed: 0.0649s/iter; left time: 1500.2896s
	iters: 200, epoch: 13 | loss: 2.9705105
	speed: 0.0997s/iter; left time: 2295.7514s
Epoch: 13 cost time: 22.66696548461914
Epoch: 13, Steps: 264 Train Loss: 3.0429 (Forecasting Loss:0.2251 + XiCon Loss:2.8178 x Lambda(1.0)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1132
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0386095
	speed: 0.1156s/iter; left time: 2643.5884s
	iters: 200, epoch: 14 | loss: 2.9645145
	speed: 0.1015s/iter; left time: 2310.6539s
Epoch: 14 cost time: 27.69821310043335
Epoch: 14, Steps: 264 Train Loss: 3.0406 (Forecasting Loss:0.2251 + XiCon Loss:2.8156 x Lambda(1.0)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1132
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.053645651787519455, mae:0.17452125251293182, mape:0.13610684871673584, mspe:0.03311973065137863 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.6313
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.2469575
	speed: 0.0376s/iter; left time: 989.9565s
	iters: 200, epoch: 1 | loss: 3.1752694
	speed: 0.0344s/iter; left time: 901.0153s
Epoch: 1 cost time: 9.43045711517334
Epoch: 1, Steps: 264 Train Loss: 3.2842 (Forecasting Loss:0.2381 + XiCon Loss:3.0461 x Lambda(1.0)), Vali MSE Loss: 0.1743 Test MSE Loss: 0.1151
Validation loss decreased (inf --> 0.174312).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2819023
	speed: 0.0429s/iter; left time: 1117.4489s
	iters: 200, epoch: 2 | loss: 3.2726579
	speed: 0.0382s/iter; left time: 991.3789s
Epoch: 2 cost time: 10.593848943710327
Epoch: 2, Steps: 264 Train Loss: 3.2179 (Forecasting Loss:0.2403 + XiCon Loss:2.9777 x Lambda(1.0)), Vali MSE Loss: 0.1759 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1711020
	speed: 0.0414s/iter; left time: 1067.1640s
	iters: 200, epoch: 3 | loss: 3.1888978
	speed: 0.0390s/iter; left time: 1001.1237s
Epoch: 3 cost time: 10.455451965332031
Epoch: 3, Steps: 264 Train Loss: 3.1576 (Forecasting Loss:0.2330 + XiCon Loss:2.9246 x Lambda(1.0)), Vali MSE Loss: 0.1744 Test MSE Loss: 0.1150
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0785811
	speed: 0.0406s/iter; left time: 1034.6577s
	iters: 200, epoch: 4 | loss: 3.1386468
	speed: 0.0383s/iter; left time: 972.6254s
Epoch: 4 cost time: 10.399392127990723
Epoch: 4, Steps: 264 Train Loss: 3.1315 (Forecasting Loss:0.2296 + XiCon Loss:2.9019 x Lambda(1.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1143
Validation loss decreased (0.174312 --> 0.172458).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1056137
	speed: 0.0385s/iter; left time: 973.0839s
	iters: 200, epoch: 5 | loss: 3.0814626
	speed: 0.0370s/iter; left time: 931.2066s
Epoch: 5 cost time: 9.986627101898193
Epoch: 5, Steps: 264 Train Loss: 3.1108 (Forecasting Loss:0.2282 + XiCon Loss:2.8826 x Lambda(1.0)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1128
Validation loss decreased (0.172458 --> 0.170756).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1107111
	speed: 0.0423s/iter; left time: 1057.6375s
	iters: 200, epoch: 6 | loss: 3.1060255
	speed: 0.0397s/iter; left time: 987.8331s
Epoch: 6 cost time: 10.76528000831604
Epoch: 6, Steps: 264 Train Loss: 3.1072 (Forecasting Loss:0.2272 + XiCon Loss:2.8800 x Lambda(1.0)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1129
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0835309
	speed: 0.0418s/iter; left time: 1033.3812s
	iters: 200, epoch: 7 | loss: 3.1589355
	speed: 0.0405s/iter; left time: 996.6620s
Epoch: 7 cost time: 10.775170087814331
Epoch: 7, Steps: 264 Train Loss: 3.1010 (Forecasting Loss:0.2266 + XiCon Loss:2.8744 x Lambda(1.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1129
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0861173
	speed: 0.0428s/iter; left time: 1047.2586s
	iters: 200, epoch: 8 | loss: 3.1179724
	speed: 0.0406s/iter; left time: 988.4537s
Epoch: 8 cost time: 10.914853811264038
Epoch: 8, Steps: 264 Train Loss: 3.1008 (Forecasting Loss:0.2263 + XiCon Loss:2.8745 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1128
Validation loss decreased (0.170756 --> 0.170333).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1636858
	speed: 0.0427s/iter; left time: 1033.2979s
	iters: 200, epoch: 9 | loss: 3.0923047
	speed: 0.0401s/iter; left time: 966.6933s
Epoch: 9 cost time: 10.889452934265137
Epoch: 9, Steps: 264 Train Loss: 3.0999 (Forecasting Loss:0.2261 + XiCon Loss:2.8739 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1128
Validation loss decreased (0.170333 --> 0.170293).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1045504
	speed: 0.0434s/iter; left time: 1037.4014s
	iters: 200, epoch: 10 | loss: 3.1198883
	speed: 0.0403s/iter; left time: 961.1325s
Epoch: 10 cost time: 10.89863133430481
Epoch: 10, Steps: 264 Train Loss: 3.0997 (Forecasting Loss:0.2260 + XiCon Loss:2.8737 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0613339
	speed: 0.0429s/iter; left time: 1015.2485s
	iters: 200, epoch: 11 | loss: 3.1260729
	speed: 0.0401s/iter; left time: 943.8144s
Epoch: 11 cost time: 10.893435001373291
Epoch: 11, Steps: 264 Train Loss: 3.0980 (Forecasting Loss:0.2259 + XiCon Loss:2.8720 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1126
Validation loss decreased (0.170293 --> 0.170288).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0638921
	speed: 0.0425s/iter; left time: 993.5640s
	iters: 200, epoch: 12 | loss: 3.1894765
	speed: 0.0409s/iter; left time: 953.6102s
Epoch: 12 cost time: 10.89095163345337
Epoch: 12, Steps: 264 Train Loss: 3.0986 (Forecasting Loss:0.2258 + XiCon Loss:2.8728 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
Validation loss decreased (0.170288 --> 0.170171).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0914288
	speed: 0.0427s/iter; left time: 988.4762s
	iters: 200, epoch: 13 | loss: 3.0847929
	speed: 0.0403s/iter; left time: 928.8548s
Epoch: 13 cost time: 10.890233755111694
Epoch: 13, Steps: 264 Train Loss: 3.0973 (Forecasting Loss:0.2259 + XiCon Loss:2.8714 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0654035
	speed: 0.0426s/iter; left time: 973.8022s
	iters: 200, epoch: 14 | loss: 3.0678356
	speed: 0.0368s/iter; left time: 838.3064s
Epoch: 14 cost time: 10.3440420627594
Epoch: 14, Steps: 264 Train Loss: 3.0974 (Forecasting Loss:0.2259 + XiCon Loss:2.8716 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
Validation loss decreased (0.170171 --> 0.170150).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0939550
	speed: 0.0422s/iter; left time: 953.7868s
	iters: 200, epoch: 15 | loss: 3.0699315
	speed: 0.0404s/iter; left time: 908.5587s
Epoch: 15 cost time: 10.841940641403198
Epoch: 15, Steps: 264 Train Loss: 3.0981 (Forecasting Loss:0.2259 + XiCon Loss:2.8722 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0273478
	speed: 0.0425s/iter; left time: 948.8208s
	iters: 200, epoch: 16 | loss: 3.0948274
	speed: 0.0404s/iter; left time: 898.7865s
Epoch: 16 cost time: 10.865853786468506
Epoch: 16, Steps: 264 Train Loss: 3.0960 (Forecasting Loss:0.2258 + XiCon Loss:2.8701 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0411818
	speed: 0.0421s/iter; left time: 930.2174s
	iters: 200, epoch: 17 | loss: 3.0503583
	speed: 0.0409s/iter; left time: 898.4392s
Epoch: 17 cost time: 10.893343210220337
Epoch: 17, Steps: 264 Train Loss: 3.1002 (Forecasting Loss:0.2258 + XiCon Loss:2.8744 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
Validation loss decreased (0.170150 --> 0.170131).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1513169
	speed: 0.0417s/iter; left time: 910.1663s
	iters: 200, epoch: 18 | loss: 3.0330985
	speed: 0.0402s/iter; left time: 873.7571s
Epoch: 18 cost time: 10.80810546875
Epoch: 18, Steps: 264 Train Loss: 3.0995 (Forecasting Loss:0.2258 + XiCon Loss:2.8736 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0554519
	speed: 0.0427s/iter; left time: 920.7415s
	iters: 200, epoch: 19 | loss: 3.0573776
	speed: 0.0401s/iter; left time: 860.8517s
Epoch: 19 cost time: 10.857696294784546
Epoch: 19, Steps: 264 Train Loss: 3.0996 (Forecasting Loss:0.2258 + XiCon Loss:2.8738 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
Validation loss decreased (0.170131 --> 0.170103).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0775032
	speed: 0.0420s/iter; left time: 893.9723s
	iters: 200, epoch: 20 | loss: 3.0920379
	speed: 0.0402s/iter; left time: 852.5444s
Epoch: 20 cost time: 10.765190601348877
Epoch: 20, Steps: 264 Train Loss: 3.0980 (Forecasting Loss:0.2259 + XiCon Loss:2.8721 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0675659
	speed: 0.0419s/iter; left time: 880.8723s
	iters: 200, epoch: 21 | loss: 3.1282365
	speed: 0.0404s/iter; left time: 845.1510s
Epoch: 21 cost time: 10.829773902893066
Epoch: 21, Steps: 264 Train Loss: 3.1012 (Forecasting Loss:0.2258 + XiCon Loss:2.8753 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0743148
	speed: 0.0423s/iter; left time: 877.1235s
	iters: 200, epoch: 22 | loss: 3.1227036
	speed: 0.0394s/iter; left time: 813.7247s
Epoch: 22 cost time: 10.722852230072021
Epoch: 22, Steps: 264 Train Loss: 3.0974 (Forecasting Loss:0.2259 + XiCon Loss:2.8715 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1340048
	speed: 0.0422s/iter; left time: 864.9654s
	iters: 200, epoch: 23 | loss: 3.0896556
	speed: 0.0384s/iter; left time: 782.6544s
Epoch: 23 cost time: 10.446040391921997
Epoch: 23, Steps: 264 Train Loss: 3.0977 (Forecasting Loss:0.2259 + XiCon Loss:2.8718 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0805793
	speed: 0.0416s/iter; left time: 840.5671s
	iters: 200, epoch: 24 | loss: 3.1037567
	speed: 0.0402s/iter; left time: 809.7884s
Epoch: 24 cost time: 10.691497087478638
Epoch: 24, Steps: 264 Train Loss: 3.0964 (Forecasting Loss:0.2259 + XiCon Loss:2.8706 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1403506
	speed: 0.0424s/iter; left time: 846.2661s
	iters: 200, epoch: 25 | loss: 3.0742521
	speed: 0.0400s/iter; left time: 795.0878s
Epoch: 25 cost time: 10.848520994186401
Epoch: 25, Steps: 264 Train Loss: 3.0983 (Forecasting Loss:0.2258 + XiCon Loss:2.8726 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1093657
	speed: 0.0418s/iter; left time: 823.5211s
	iters: 200, epoch: 26 | loss: 3.1837463
	speed: 0.0407s/iter; left time: 797.3775s
Epoch: 26 cost time: 10.882991075515747
Epoch: 26, Steps: 264 Train Loss: 3.0968 (Forecasting Loss:0.2259 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1125
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1291418
	speed: 0.0419s/iter; left time: 813.8338s
	iters: 200, epoch: 27 | loss: 3.1564989
	speed: 0.0400s/iter; left time: 773.4841s
Epoch: 27 cost time: 10.822936296463013
Epoch: 27, Steps: 264 Train Loss: 3.1007 (Forecasting Loss:0.2259 + XiCon Loss:2.8748 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0591226
	speed: 0.0416s/iter; left time: 797.6135s
	iters: 200, epoch: 28 | loss: 3.1378691
	speed: 0.0398s/iter; left time: 758.7399s
Epoch: 28 cost time: 10.716801166534424
Epoch: 28, Steps: 264 Train Loss: 3.0998 (Forecasting Loss:0.2257 + XiCon Loss:2.8741 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1100338
	speed: 0.0416s/iter; left time: 786.7411s
	iters: 200, epoch: 29 | loss: 3.1014953
	speed: 0.0398s/iter; left time: 749.3681s
Epoch: 29 cost time: 10.649130821228027
Epoch: 29, Steps: 264 Train Loss: 3.0952 (Forecasting Loss:0.2258 + XiCon Loss:2.8694 x Lambda(1.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05253152921795845, mae:0.1725255697965622, mape:0.13457542657852173, mspe:0.03218168020248413 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0529+-0.00070, MAE:0.1731+-0.00129, MAPE:0.1351+-0.00118, MSPE:0.0326+-0.00089, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9479
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6708405
	speed: 0.0429s/iter; left time: 1115.3730s
	iters: 200, epoch: 1 | loss: 3.6601164
	speed: 0.0374s/iter; left time: 968.9791s
Epoch: 1 cost time: 10.295365333557129
Epoch: 1, Steps: 261 Train Loss: 3.6495 (Forecasting Loss:0.2771 + XiCon Loss:3.3725 x Lambda(1.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.200628).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3953385
	speed: 0.0421s/iter; left time: 1082.6498s
	iters: 200, epoch: 2 | loss: 3.3875995
	speed: 0.0395s/iter; left time: 1013.7192s
Epoch: 2 cost time: 10.687814474105835
Epoch: 2, Steps: 261 Train Loss: 3.4096 (Forecasting Loss:0.2746 + XiCon Loss:3.1349 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1423
Validation loss decreased (0.200628 --> 0.200008).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3621132
	speed: 0.0454s/iter; left time: 1157.1892s
	iters: 200, epoch: 3 | loss: 3.4449124
	speed: 0.0437s/iter; left time: 1109.4509s
Epoch: 3 cost time: 11.529946088790894
Epoch: 3, Steps: 261 Train Loss: 3.3693 (Forecasting Loss:0.2692 + XiCon Loss:3.1002 x Lambda(1.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1418
Validation loss decreased (0.200008 --> 0.197520).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3438907
	speed: 0.0463s/iter; left time: 1166.6853s
	iters: 200, epoch: 4 | loss: 3.3381557
	speed: 0.0437s/iter; left time: 1098.6028s
Epoch: 4 cost time: 11.636719465255737
Epoch: 4, Steps: 261 Train Loss: 3.3360 (Forecasting Loss:0.2648 + XiCon Loss:3.0712 x Lambda(1.0)), Vali MSE Loss: 0.1889 Test MSE Loss: 0.1413
Validation loss decreased (0.197520 --> 0.188867).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3424103
	speed: 0.0465s/iter; left time: 1160.0305s
	iters: 200, epoch: 5 | loss: 3.3319168
	speed: 0.0422s/iter; left time: 1049.6127s
Epoch: 5 cost time: 11.457769870758057
Epoch: 5, Steps: 261 Train Loss: 3.3061 (Forecasting Loss:0.2616 + XiCon Loss:3.0445 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1386
Validation loss decreased (0.188867 --> 0.186417).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3181617
	speed: 0.0443s/iter; left time: 1094.7651s
	iters: 200, epoch: 6 | loss: 3.2939432
	speed: 0.0423s/iter; left time: 1041.3458s
Epoch: 6 cost time: 11.311283588409424
Epoch: 6, Steps: 261 Train Loss: 3.2925 (Forecasting Loss:0.2604 + XiCon Loss:3.0322 x Lambda(1.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2659192
	speed: 0.0443s/iter; left time: 1081.2749s
	iters: 200, epoch: 7 | loss: 3.3204687
	speed: 0.0437s/iter; left time: 1063.6039s
Epoch: 7 cost time: 11.415156126022339
Epoch: 7, Steps: 261 Train Loss: 3.2881 (Forecasting Loss:0.2600 + XiCon Loss:3.0282 x Lambda(1.0)), Vali MSE Loss: 0.1868 Test MSE Loss: 0.1388
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3002422
	speed: 0.0432s/iter; left time: 1043.9508s
	iters: 200, epoch: 8 | loss: 3.2879660
	speed: 0.0432s/iter; left time: 1040.9152s
Epoch: 8 cost time: 11.231309413909912
Epoch: 8, Steps: 261 Train Loss: 3.2873 (Forecasting Loss:0.2596 + XiCon Loss:3.0277 x Lambda(1.0)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1403
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3044438
	speed: 0.0444s/iter; left time: 1062.2000s
	iters: 200, epoch: 9 | loss: 3.3105459
	speed: 0.0426s/iter; left time: 1015.4909s
Epoch: 9 cost time: 11.360593318939209
Epoch: 9, Steps: 261 Train Loss: 3.2860 (Forecasting Loss:0.2593 + XiCon Loss:3.0267 x Lambda(1.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2925863
	speed: 0.0446s/iter; left time: 1054.1180s
	iters: 200, epoch: 10 | loss: 3.2960181
	speed: 0.0421s/iter; left time: 990.5069s
Epoch: 10 cost time: 11.267466306686401
Epoch: 10, Steps: 261 Train Loss: 3.2832 (Forecasting Loss:0.2592 + XiCon Loss:3.0239 x Lambda(1.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1394
Validation loss decreased (0.186417 --> 0.186292).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2991459
	speed: 0.0414s/iter; left time: 967.9766s
	iters: 200, epoch: 11 | loss: 3.2907224
	speed: 0.0423s/iter; left time: 985.4500s
Epoch: 11 cost time: 10.941927433013916
Epoch: 11, Steps: 261 Train Loss: 3.2826 (Forecasting Loss:0.2594 + XiCon Loss:3.0232 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2936146
	speed: 0.0446s/iter; left time: 1032.1950s
	iters: 200, epoch: 12 | loss: 3.3010993
	speed: 0.0421s/iter; left time: 969.3026s
Epoch: 12 cost time: 11.265279769897461
Epoch: 12, Steps: 261 Train Loss: 3.2845 (Forecasting Loss:0.2592 + XiCon Loss:3.0253 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1397
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3271589
	speed: 0.0438s/iter; left time: 1002.6319s
	iters: 200, epoch: 13 | loss: 3.2841020
	speed: 0.0425s/iter; left time: 968.1530s
Epoch: 13 cost time: 11.259541034698486
Epoch: 13, Steps: 261 Train Loss: 3.2835 (Forecasting Loss:0.2593 + XiCon Loss:3.0242 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1397
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3391788
	speed: 0.0434s/iter; left time: 982.1542s
	iters: 200, epoch: 14 | loss: 3.2615583
	speed: 0.0434s/iter; left time: 977.2016s
Epoch: 14 cost time: 11.336299419403076
Epoch: 14, Steps: 261 Train Loss: 3.2833 (Forecasting Loss:0.2592 + XiCon Loss:3.0240 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2563410
	speed: 0.0452s/iter; left time: 1010.4655s
	iters: 200, epoch: 15 | loss: 3.2525716
	speed: 0.0422s/iter; left time: 939.4803s
Epoch: 15 cost time: 11.343205690383911
Epoch: 15, Steps: 261 Train Loss: 3.2829 (Forecasting Loss:0.2593 + XiCon Loss:3.0236 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1396
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2869897
	speed: 0.0445s/iter; left time: 983.7147s
	iters: 200, epoch: 16 | loss: 3.3129001
	speed: 0.0420s/iter; left time: 923.4733s
Epoch: 16 cost time: 11.26588225364685
Epoch: 16, Steps: 261 Train Loss: 3.2831 (Forecasting Loss:0.2593 + XiCon Loss:3.0238 x Lambda(1.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2685506
	speed: 0.0441s/iter; left time: 963.2053s
	iters: 200, epoch: 17 | loss: 3.2926157
	speed: 0.0423s/iter; left time: 918.1122s
Epoch: 17 cost time: 11.295617818832397
Epoch: 17, Steps: 261 Train Loss: 3.2859 (Forecasting Loss:0.2593 + XiCon Loss:3.0266 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2792234
	speed: 0.0447s/iter; left time: 963.0214s
	iters: 200, epoch: 18 | loss: 3.3276777
	speed: 0.0420s/iter; left time: 901.0110s
Epoch: 18 cost time: 11.242677688598633
Epoch: 18, Steps: 261 Train Loss: 3.2845 (Forecasting Loss:0.2592 + XiCon Loss:3.0254 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2933939
	speed: 0.0444s/iter; left time: 945.7534s
	iters: 200, epoch: 19 | loss: 3.3120539
	speed: 0.0422s/iter; left time: 893.7908s
Epoch: 19 cost time: 11.078829526901245
Epoch: 19, Steps: 261 Train Loss: 3.2842 (Forecasting Loss:0.2592 + XiCon Loss:3.0250 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2995217
	speed: 0.0427s/iter; left time: 898.0337s
	iters: 200, epoch: 20 | loss: 3.2492862
	speed: 0.0425s/iter; left time: 890.0631s
Epoch: 20 cost time: 11.053568840026855
Epoch: 20, Steps: 261 Train Loss: 3.2865 (Forecasting Loss:0.2593 + XiCon Loss:3.0271 x Lambda(1.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07367690652608871, mae:0.20510336756706238, mape:0.15390115976333618, mspe:0.03944484516978264 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3486
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6389506
	speed: 0.0367s/iter; left time: 954.3688s
	iters: 200, epoch: 1 | loss: 3.5656161
	speed: 0.0337s/iter; left time: 874.0572s
Epoch: 1 cost time: 9.108806133270264
Epoch: 1, Steps: 261 Train Loss: 3.6241 (Forecasting Loss:0.2774 + XiCon Loss:3.3467 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1422
Validation loss decreased (inf --> 0.199937).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4273744
	speed: 0.0412s/iter; left time: 1061.2372s
	iters: 200, epoch: 2 | loss: 3.3807943
	speed: 0.0402s/iter; left time: 1030.5227s
Epoch: 2 cost time: 10.452773809432983
Epoch: 2, Steps: 261 Train Loss: 3.3950 (Forecasting Loss:0.2756 + XiCon Loss:3.1195 x Lambda(1.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1444
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2935817
	speed: 0.0402s/iter; left time: 1023.4275s
	iters: 200, epoch: 3 | loss: 3.2976213
	speed: 0.0380s/iter; left time: 963.9265s
Epoch: 3 cost time: 10.0440993309021
Epoch: 3, Steps: 261 Train Loss: 3.3204 (Forecasting Loss:0.2696 + XiCon Loss:3.0508 x Lambda(1.0)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1411
Validation loss decreased (0.199937 --> 0.196992).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2653749
	speed: 0.0397s/iter; left time: 1000.5198s
	iters: 200, epoch: 4 | loss: 3.3296378
	speed: 0.0364s/iter; left time: 913.1721s
Epoch: 4 cost time: 9.836293458938599
Epoch: 4, Steps: 261 Train Loss: 3.2920 (Forecasting Loss:0.2632 + XiCon Loss:3.0287 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1405
Validation loss decreased (0.196992 --> 0.194955).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2799602
	speed: 0.0399s/iter; left time: 996.1655s
	iters: 200, epoch: 5 | loss: 3.3201103
	speed: 0.0359s/iter; left time: 892.8454s
Epoch: 5 cost time: 9.83904218673706
Epoch: 5, Steps: 261 Train Loss: 3.2806 (Forecasting Loss:0.2613 + XiCon Loss:3.0193 x Lambda(1.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.1415
Validation loss decreased (0.194955 --> 0.194816).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2757914
	speed: 0.0412s/iter; left time: 1017.6937s
	iters: 200, epoch: 6 | loss: 3.2661746
	speed: 0.0372s/iter; left time: 915.7911s
Epoch: 6 cost time: 10.088528156280518
Epoch: 6, Steps: 261 Train Loss: 3.2750 (Forecasting Loss:0.2605 + XiCon Loss:3.0145 x Lambda(1.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1410
Validation loss decreased (0.194816 --> 0.194229).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2788706
	speed: 0.0403s/iter; left time: 985.8672s
	iters: 200, epoch: 7 | loss: 3.2624137
	speed: 0.0378s/iter; left time: 920.5796s
Epoch: 7 cost time: 10.094574213027954
Epoch: 7, Steps: 261 Train Loss: 3.2730 (Forecasting Loss:0.2593 + XiCon Loss:3.0137 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1408
Validation loss decreased (0.194229 --> 0.194102).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2798877
	speed: 0.0360s/iter; left time: 869.8045s
	iters: 200, epoch: 8 | loss: 3.2750189
	speed: 0.0354s/iter; left time: 852.4360s
Epoch: 8 cost time: 9.337042093276978
Epoch: 8, Steps: 261 Train Loss: 3.2701 (Forecasting Loss:0.2591 + XiCon Loss:3.0110 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1406
Validation loss decreased (0.194102 --> 0.193958).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2822702
	speed: 0.0400s/iter; left time: 957.7003s
	iters: 200, epoch: 9 | loss: 3.3202827
	speed: 0.0377s/iter; left time: 897.2101s
Epoch: 9 cost time: 10.024683713912964
Epoch: 9, Steps: 261 Train Loss: 3.2704 (Forecasting Loss:0.2591 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1406
Validation loss decreased (0.193958 --> 0.193949).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2702944
	speed: 0.0409s/iter; left time: 966.3797s
	iters: 200, epoch: 10 | loss: 3.2728076
	speed: 0.0373s/iter; left time: 878.0651s
Epoch: 10 cost time: 10.075239181518555
Epoch: 10, Steps: 261 Train Loss: 3.2691 (Forecasting Loss:0.2590 + XiCon Loss:3.0101 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1406
Validation loss decreased (0.193949 --> 0.193935).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2692294
	speed: 0.0407s/iter; left time: 951.9015s
	iters: 200, epoch: 11 | loss: 3.3261244
	speed: 0.0378s/iter; left time: 879.3966s
Epoch: 11 cost time: 10.17025637626648
Epoch: 11, Steps: 261 Train Loss: 3.2695 (Forecasting Loss:0.2589 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
Validation loss decreased (0.193935 --> 0.193896).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2511888
	speed: 0.0403s/iter; left time: 932.9864s
	iters: 200, epoch: 12 | loss: 3.2730138
	speed: 0.0378s/iter; left time: 871.4949s
Epoch: 12 cost time: 10.090169191360474
Epoch: 12, Steps: 261 Train Loss: 3.2695 (Forecasting Loss:0.2589 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2453785
	speed: 0.0406s/iter; left time: 927.3545s
	iters: 200, epoch: 13 | loss: 3.2877111
	speed: 0.0374s/iter; left time: 851.7026s
Epoch: 13 cost time: 10.066220998764038
Epoch: 13, Steps: 261 Train Loss: 3.2708 (Forecasting Loss:0.2590 + XiCon Loss:3.0118 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2661231
	speed: 0.0396s/iter; left time: 895.7514s
	iters: 200, epoch: 14 | loss: 3.3095465
	speed: 0.0375s/iter; left time: 845.0315s
Epoch: 14 cost time: 9.940872192382812
Epoch: 14, Steps: 261 Train Loss: 3.2713 (Forecasting Loss:0.2590 + XiCon Loss:3.0123 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2817121
	speed: 0.0404s/iter; left time: 903.6063s
	iters: 200, epoch: 15 | loss: 3.2886958
	speed: 0.0377s/iter; left time: 838.9951s
Epoch: 15 cost time: 10.122618436813354
Epoch: 15, Steps: 261 Train Loss: 3.2707 (Forecasting Loss:0.2591 + XiCon Loss:3.0116 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2784982
	speed: 0.0408s/iter; left time: 901.7884s
	iters: 200, epoch: 16 | loss: 3.2848287
	speed: 0.0366s/iter; left time: 803.8122s
Epoch: 16 cost time: 10.024899959564209
Epoch: 16, Steps: 261 Train Loss: 3.2704 (Forecasting Loss:0.2590 + XiCon Loss:3.0114 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
Validation loss decreased (0.193896 --> 0.193878).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2646489
	speed: 0.0400s/iter; left time: 874.0168s
	iters: 200, epoch: 17 | loss: 3.2467637
	speed: 0.0379s/iter; left time: 822.7850s
Epoch: 17 cost time: 9.902837753295898
Epoch: 17, Steps: 261 Train Loss: 3.2711 (Forecasting Loss:0.2590 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2503662
	speed: 0.0377s/iter; left time: 812.9830s
	iters: 200, epoch: 18 | loss: 3.2236938
	speed: 0.0368s/iter; left time: 790.1343s
Epoch: 18 cost time: 9.635303735733032
Epoch: 18, Steps: 261 Train Loss: 3.2700 (Forecasting Loss:0.2590 + XiCon Loss:3.0110 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2996840
	speed: 0.0405s/iter; left time: 862.5021s
	iters: 200, epoch: 19 | loss: 3.2526546
	speed: 0.0372s/iter; left time: 788.6636s
Epoch: 19 cost time: 9.997037649154663
Epoch: 19, Steps: 261 Train Loss: 3.2702 (Forecasting Loss:0.2589 + XiCon Loss:3.0112 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2620583
	speed: 0.0402s/iter; left time: 845.9324s
	iters: 200, epoch: 20 | loss: 3.2339935
	speed: 0.0379s/iter; left time: 793.8074s
Epoch: 20 cost time: 10.076490879058838
Epoch: 20, Steps: 261 Train Loss: 3.2699 (Forecasting Loss:0.2589 + XiCon Loss:3.0110 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2984576
	speed: 0.0403s/iter; left time: 836.5582s
	iters: 200, epoch: 21 | loss: 3.2544794
	speed: 0.0378s/iter; left time: 781.3114s
Epoch: 21 cost time: 10.117416620254517
Epoch: 21, Steps: 261 Train Loss: 3.2686 (Forecasting Loss:0.2590 + XiCon Loss:3.0096 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2897921
	speed: 0.0403s/iter; left time: 827.1381s
	iters: 200, epoch: 22 | loss: 3.2381430
	speed: 0.0377s/iter; left time: 770.0388s
Epoch: 22 cost time: 10.046542882919312
Epoch: 22, Steps: 261 Train Loss: 3.2705 (Forecasting Loss:0.2591 + XiCon Loss:3.0114 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2553184
	speed: 0.0400s/iter; left time: 809.3650s
	iters: 200, epoch: 23 | loss: 3.2504921
	speed: 0.0378s/iter; left time: 762.7581s
Epoch: 23 cost time: 10.000604629516602
Epoch: 23, Steps: 261 Train Loss: 3.2711 (Forecasting Loss:0.2590 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2896919
	speed: 0.0398s/iter; left time: 796.2559s
	iters: 200, epoch: 24 | loss: 3.3023467
	speed: 0.0375s/iter; left time: 746.1965s
Epoch: 24 cost time: 10.034978866577148
Epoch: 24, Steps: 261 Train Loss: 3.2696 (Forecasting Loss:0.2589 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1407
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2541552
	speed: 0.0393s/iter; left time: 776.2912s
	iters: 200, epoch: 25 | loss: 3.2633469
	speed: 0.0380s/iter; left time: 745.6107s
Epoch: 25 cost time: 10.004982471466064
Epoch: 25, Steps: 261 Train Loss: 3.2705 (Forecasting Loss:0.2588 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
Validation loss decreased (0.193878 --> 0.193874).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2839320
	speed: 0.0412s/iter; left time: 802.0390s
	iters: 200, epoch: 26 | loss: 3.2822497
	speed: 0.0372s/iter; left time: 720.1765s
Epoch: 26 cost time: 10.10134220123291
Epoch: 26, Steps: 261 Train Loss: 3.2694 (Forecasting Loss:0.2589 + XiCon Loss:3.0105 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3009911
	speed: 0.0396s/iter; left time: 761.1209s
	iters: 200, epoch: 27 | loss: 3.2965083
	speed: 0.0341s/iter; left time: 651.7953s
Epoch: 27 cost time: 9.444129705429077
Epoch: 27, Steps: 261 Train Loss: 3.2703 (Forecasting Loss:0.2587 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2367575
	speed: 0.0400s/iter; left time: 758.9487s
	iters: 200, epoch: 28 | loss: 3.2594943
	speed: 0.0381s/iter; left time: 719.0135s
Epoch: 28 cost time: 10.050685167312622
Epoch: 28, Steps: 261 Train Loss: 3.2693 (Forecasting Loss:0.2590 + XiCon Loss:3.0103 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
Validation loss decreased (0.193874 --> 0.193861).  Saving model ...
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3055716
	speed: 0.0400s/iter; left time: 748.5631s
	iters: 200, epoch: 29 | loss: 3.2618594
	speed: 0.0378s/iter; left time: 703.5883s
Epoch: 29 cost time: 10.036515712738037
Epoch: 29, Steps: 261 Train Loss: 3.2709 (Forecasting Loss:0.2590 + XiCon Loss:3.0119 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2808194
	speed: 0.0402s/iter; left time: 740.5695s
	iters: 200, epoch: 30 | loss: 3.2646105
	speed: 0.0368s/iter; left time: 674.6737s
Epoch: 30 cost time: 9.953101873397827
Epoch: 30, Steps: 261 Train Loss: 3.2695 (Forecasting Loss:0.2589 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.2553570
	speed: 0.0398s/iter; left time: 724.0889s
	iters: 200, epoch: 31 | loss: 3.2776072
	speed: 0.0372s/iter; left time: 671.6452s
Epoch: 31 cost time: 9.989946842193604
Epoch: 31, Steps: 261 Train Loss: 3.2690 (Forecasting Loss:0.2588 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.2978745
	speed: 0.0403s/iter; left time: 720.9866s
	iters: 200, epoch: 32 | loss: 3.2807500
	speed: 0.0371s/iter; left time: 661.5375s
Epoch: 32 cost time: 9.98417043685913
Epoch: 32, Steps: 261 Train Loss: 3.2686 (Forecasting Loss:0.2589 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.3051753
	speed: 0.0411s/iter; left time: 725.9307s
	iters: 200, epoch: 33 | loss: 3.2821620
	speed: 0.0366s/iter; left time: 643.1252s
Epoch: 33 cost time: 10.075799226760864
Epoch: 33, Steps: 261 Train Loss: 3.2700 (Forecasting Loss:0.2591 + XiCon Loss:3.0109 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.2958395
	speed: 0.0407s/iter; left time: 708.4158s
	iters: 200, epoch: 34 | loss: 3.2915461
	speed: 0.0378s/iter; left time: 652.9924s
Epoch: 34 cost time: 10.107922792434692
Epoch: 34, Steps: 261 Train Loss: 3.2717 (Forecasting Loss:0.2589 + XiCon Loss:3.0128 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 3.2620945
	speed: 0.0408s/iter; left time: 699.5761s
	iters: 200, epoch: 35 | loss: 3.3155849
	speed: 0.0379s/iter; left time: 645.4012s
Epoch: 35 cost time: 10.17826247215271
Epoch: 35, Steps: 261 Train Loss: 3.2682 (Forecasting Loss:0.2590 + XiCon Loss:3.0092 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1407
Validation loss decreased (0.193861 --> 0.193839).  Saving model ...
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 3.2692711
	speed: 0.0409s/iter; left time: 690.3777s
	iters: 200, epoch: 36 | loss: 3.2805643
	speed: 0.0377s/iter; left time: 631.6881s
Epoch: 36 cost time: 10.139511108398438
Epoch: 36, Steps: 261 Train Loss: 3.2708 (Forecasting Loss:0.2590 + XiCon Loss:3.0118 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 3.3071072
	speed: 0.0368s/iter; left time: 611.1178s
	iters: 200, epoch: 37 | loss: 3.2722154
	speed: 0.0339s/iter; left time: 558.8055s
Epoch: 37 cost time: 9.428837537765503
Epoch: 37, Steps: 261 Train Loss: 3.2694 (Forecasting Loss:0.2587 + XiCon Loss:3.0108 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1407
Validation loss decreased (0.193839 --> 0.193799).  Saving model ...
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 3.2857893
	speed: 0.0398s/iter; left time: 650.9700s
	iters: 200, epoch: 38 | loss: 3.2726650
	speed: 0.0370s/iter; left time: 600.5188s
Epoch: 38 cost time: 10.02190089225769
Epoch: 38, Steps: 261 Train Loss: 3.2691 (Forecasting Loss:0.2588 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 3.2310414
	speed: 0.0403s/iter; left time: 647.8488s
	iters: 200, epoch: 39 | loss: 3.2961831
	speed: 0.0368s/iter; left time: 587.7947s
Epoch: 39 cost time: 9.965821981430054
Epoch: 39, Steps: 261 Train Loss: 3.2688 (Forecasting Loss:0.2589 + XiCon Loss:3.0100 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 3.2768164
	speed: 0.0402s/iter; left time: 635.3786s
	iters: 200, epoch: 40 | loss: 3.2741733
	speed: 0.0378s/iter; left time: 594.0008s
Epoch: 40 cost time: 10.096165180206299
Epoch: 40, Steps: 261 Train Loss: 3.2704 (Forecasting Loss:0.2588 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 3.3071523
	speed: 0.0404s/iter; left time: 628.3373s
	iters: 200, epoch: 41 | loss: 3.2578006
	speed: 0.0373s/iter; left time: 576.1706s
Epoch: 41 cost time: 9.98821473121643
Epoch: 41, Steps: 261 Train Loss: 3.2724 (Forecasting Loss:0.2589 + XiCon Loss:3.0135 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1407
Validation loss decreased (0.193799 --> 0.193789).  Saving model ...
Updating learning rate to 4.547473508864641e-15
	iters: 100, epoch: 42 | loss: 3.2485867
	speed: 0.0415s/iter; left time: 635.5540s
	iters: 200, epoch: 42 | loss: 3.2928073
	speed: 0.0379s/iter; left time: 576.8200s
Epoch: 42 cost time: 10.206968069076538
Epoch: 42, Steps: 261 Train Loss: 3.2713 (Forecasting Loss:0.2589 + XiCon Loss:3.0124 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.2737367544323206e-15
	iters: 100, epoch: 43 | loss: 3.2764311
	speed: 0.0399s/iter; left time: 599.4129s
	iters: 200, epoch: 43 | loss: 3.2286713
	speed: 0.0380s/iter; left time: 567.1807s
Epoch: 43 cost time: 10.077704668045044
Epoch: 43, Steps: 261 Train Loss: 3.2705 (Forecasting Loss:0.2589 + XiCon Loss:3.0116 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1368683772161603e-15
	iters: 100, epoch: 44 | loss: 3.2727818
	speed: 0.0400s/iter; left time: 591.0013s
	iters: 200, epoch: 44 | loss: 3.2877355
	speed: 0.0364s/iter; left time: 533.9099s
Epoch: 44 cost time: 9.903068780899048
Epoch: 44, Steps: 261 Train Loss: 3.2696 (Forecasting Loss:0.2589 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.684341886080802e-16
	iters: 100, epoch: 45 | loss: 3.2763703
	speed: 0.0401s/iter; left time: 581.6875s
	iters: 200, epoch: 45 | loss: 3.2753592
	speed: 0.0377s/iter; left time: 544.2380s
Epoch: 45 cost time: 10.083853244781494
Epoch: 45, Steps: 261 Train Loss: 3.2690 (Forecasting Loss:0.2590 + XiCon Loss:3.0100 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.842170943040401e-16
	iters: 100, epoch: 46 | loss: 3.2355709
	speed: 0.0413s/iter; left time: 588.2641s
	iters: 200, epoch: 46 | loss: 3.2764964
	speed: 0.0371s/iter; left time: 524.9957s
Epoch: 46 cost time: 10.01264500617981
Epoch: 46, Steps: 261 Train Loss: 3.2696 (Forecasting Loss:0.2589 + XiCon Loss:3.0108 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4210854715202004e-16
	iters: 100, epoch: 47 | loss: 3.2641544
	speed: 0.0371s/iter; left time: 519.7287s
	iters: 200, epoch: 47 | loss: 3.2373028
	speed: 0.0382s/iter; left time: 530.9331s
Epoch: 47 cost time: 9.794283628463745
Epoch: 47, Steps: 261 Train Loss: 3.2700 (Forecasting Loss:0.2590 + XiCon Loss:3.0109 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.105427357601002e-17
	iters: 100, epoch: 48 | loss: 3.2369227
	speed: 0.0406s/iter; left time: 557.1327s
	iters: 200, epoch: 48 | loss: 3.2663953
	speed: 0.0376s/iter; left time: 511.9772s
Epoch: 48 cost time: 10.101802587509155
Epoch: 48, Steps: 261 Train Loss: 3.2684 (Forecasting Loss:0.2589 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1407
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.552713678800501e-17
	iters: 100, epoch: 49 | loss: 3.3030467
	speed: 0.0405s/iter; left time: 545.6363s
	iters: 200, epoch: 49 | loss: 3.2912104
	speed: 0.0368s/iter; left time: 492.2347s
Epoch: 49 cost time: 10.013934135437012
Epoch: 49, Steps: 261 Train Loss: 3.2711 (Forecasting Loss:0.2589 + XiCon Loss:3.0122 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.7763568394002505e-17
	iters: 100, epoch: 50 | loss: 3.2972534
	speed: 0.0404s/iter; left time: 533.4446s
	iters: 200, epoch: 50 | loss: 3.3094835
	speed: 0.0379s/iter; left time: 496.4840s
Epoch: 50 cost time: 10.133071184158325
Epoch: 50, Steps: 261 Train Loss: 3.2714 (Forecasting Loss:0.2591 + XiCon Loss:3.0123 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1407
EarlyStopping counter: 9 out of 10
Updating learning rate to 8.881784197001253e-18
	iters: 100, epoch: 51 | loss: 3.3021779
	speed: 0.0395s/iter; left time: 511.1268s
	iters: 200, epoch: 51 | loss: 3.2592535
	speed: 0.0378s/iter; left time: 486.3930s
Epoch: 51 cost time: 9.941435813903809
Epoch: 51, Steps: 261 Train Loss: 3.2704 (Forecasting Loss:0.2588 + XiCon Loss:3.0116 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1407
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07437467575073242, mae:0.20700711011886597, mape:0.1558072417974472, mspe:0.04041678458452225 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4981
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6296599
	speed: 0.0372s/iter; left time: 966.6493s
	iters: 200, epoch: 1 | loss: 3.5595875
	speed: 0.0335s/iter; left time: 868.5985s
Epoch: 1 cost time: 9.082524061203003
Epoch: 1, Steps: 261 Train Loss: 3.6182 (Forecasting Loss:0.2804 + XiCon Loss:3.3378 x Lambda(1.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1419
Validation loss decreased (inf --> 0.199571).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3815336
	speed: 0.0417s/iter; left time: 1073.8062s
	iters: 200, epoch: 2 | loss: 3.3850698
	speed: 0.0400s/iter; left time: 1025.9476s
Epoch: 2 cost time: 10.594846487045288
Epoch: 2, Steps: 261 Train Loss: 3.3776 (Forecasting Loss:0.2750 + XiCon Loss:3.1026 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2891836
	speed: 0.0400s/iter; left time: 1019.3562s
	iters: 200, epoch: 3 | loss: 3.3239968
	speed: 0.0377s/iter; left time: 956.7544s
Epoch: 3 cost time: 10.045236825942993
Epoch: 3, Steps: 261 Train Loss: 3.3178 (Forecasting Loss:0.2698 + XiCon Loss:3.0481 x Lambda(1.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1439
Validation loss decreased (0.199571 --> 0.199551).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3371134
	speed: 0.0394s/iter; left time: 994.5698s
	iters: 200, epoch: 4 | loss: 3.2822127
	speed: 0.0348s/iter; left time: 872.8592s
Epoch: 4 cost time: 9.69582200050354
Epoch: 4, Steps: 261 Train Loss: 3.3082 (Forecasting Loss:0.2673 + XiCon Loss:3.0409 x Lambda(1.0)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1401
Validation loss decreased (0.199551 --> 0.196661).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2958646
	speed: 0.0419s/iter; left time: 1046.8880s
	iters: 200, epoch: 5 | loss: 3.3050365
	speed: 0.0384s/iter; left time: 953.8790s
Epoch: 5 cost time: 10.305329322814941
Epoch: 5, Steps: 261 Train Loss: 3.3013 (Forecasting Loss:0.2660 + XiCon Loss:3.0353 x Lambda(1.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1403
Validation loss decreased (0.196661 --> 0.196410).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3192861
	speed: 0.0417s/iter; left time: 1030.5182s
	iters: 200, epoch: 6 | loss: 3.2612798
	speed: 0.0379s/iter; left time: 932.5733s
Epoch: 6 cost time: 10.243507623672485
Epoch: 6, Steps: 261 Train Loss: 3.2934 (Forecasting Loss:0.2654 + XiCon Loss:3.0280 x Lambda(1.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1406
Validation loss decreased (0.196410 --> 0.195957).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2496593
	speed: 0.0424s/iter; left time: 1036.9155s
	iters: 200, epoch: 7 | loss: 3.2779558
	speed: 0.0378s/iter; left time: 918.9433s
Epoch: 7 cost time: 10.348516464233398
Epoch: 7, Steps: 261 Train Loss: 3.2915 (Forecasting Loss:0.2653 + XiCon Loss:3.0262 x Lambda(1.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1405
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3095436
	speed: 0.0423s/iter; left time: 1022.2168s
	iters: 200, epoch: 8 | loss: 3.2772307
	speed: 0.0381s/iter; left time: 916.6863s
Epoch: 8 cost time: 10.331301927566528
Epoch: 8, Steps: 261 Train Loss: 3.2915 (Forecasting Loss:0.2650 + XiCon Loss:3.0265 x Lambda(1.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1402
Validation loss decreased (0.195957 --> 0.195732).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2881553
	speed: 0.0418s/iter; left time: 998.9408s
	iters: 200, epoch: 9 | loss: 3.3067431
	speed: 0.0386s/iter; left time: 918.2451s
Epoch: 9 cost time: 10.401037454605103
Epoch: 9, Steps: 261 Train Loss: 3.2910 (Forecasting Loss:0.2650 + XiCon Loss:3.0260 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2587910
	speed: 0.0414s/iter; left time: 979.8492s
	iters: 200, epoch: 10 | loss: 3.3109741
	speed: 0.0384s/iter; left time: 903.5674s
Epoch: 10 cost time: 10.27508544921875
Epoch: 10, Steps: 261 Train Loss: 3.2923 (Forecasting Loss:0.2648 + XiCon Loss:3.0275 x Lambda(1.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195732 --> 0.195707).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2777767
	speed: 0.0418s/iter; left time: 978.6291s
	iters: 200, epoch: 11 | loss: 3.2874665
	speed: 0.0394s/iter; left time: 916.7253s
Epoch: 11 cost time: 10.45808458328247
Epoch: 11, Steps: 261 Train Loss: 3.2911 (Forecasting Loss:0.2648 + XiCon Loss:3.0263 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2865043
	speed: 0.0424s/iter; left time: 980.4019s
	iters: 200, epoch: 12 | loss: 3.3286707
	speed: 0.0386s/iter; left time: 889.8243s
Epoch: 12 cost time: 10.465261459350586
Epoch: 12, Steps: 261 Train Loss: 3.2910 (Forecasting Loss:0.2649 + XiCon Loss:3.0262 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2970798
	speed: 0.0413s/iter; left time: 944.3651s
	iters: 200, epoch: 13 | loss: 3.2731953
	speed: 0.0388s/iter; left time: 883.8513s
Epoch: 13 cost time: 10.08607292175293
Epoch: 13, Steps: 261 Train Loss: 3.2926 (Forecasting Loss:0.2647 + XiCon Loss:3.0279 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3190320
	speed: 0.0390s/iter; left time: 882.2626s
	iters: 200, epoch: 14 | loss: 3.2924228
	speed: 0.0383s/iter; left time: 861.1741s
Epoch: 14 cost time: 10.019057035446167
Epoch: 14, Steps: 261 Train Loss: 3.2894 (Forecasting Loss:0.2648 + XiCon Loss:3.0247 x Lambda(1.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3000286
	speed: 0.0426s/iter; left time: 952.7950s
	iters: 200, epoch: 15 | loss: 3.3259318
	speed: 0.0387s/iter; left time: 861.7902s
Epoch: 15 cost time: 10.51470947265625
Epoch: 15, Steps: 261 Train Loss: 3.2906 (Forecasting Loss:0.2648 + XiCon Loss:3.0258 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2785327
	speed: 0.0425s/iter; left time: 939.3028s
	iters: 200, epoch: 16 | loss: 3.3141937
	speed: 0.0394s/iter; left time: 865.6753s
Epoch: 16 cost time: 10.514031171798706
Epoch: 16, Steps: 261 Train Loss: 3.2902 (Forecasting Loss:0.2648 + XiCon Loss:3.0254 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3069170
	speed: 0.0426s/iter; left time: 929.4631s
	iters: 200, epoch: 17 | loss: 3.2795503
	speed: 0.0382s/iter; left time: 830.8636s
Epoch: 17 cost time: 10.400392055511475
Epoch: 17, Steps: 261 Train Loss: 3.2904 (Forecasting Loss:0.2648 + XiCon Loss:3.0255 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3073997
	speed: 0.0420s/iter; left time: 905.5476s
	iters: 200, epoch: 18 | loss: 3.2634039
	speed: 0.0382s/iter; left time: 820.9388s
Epoch: 18 cost time: 10.341585159301758
Epoch: 18, Steps: 261 Train Loss: 3.2906 (Forecasting Loss:0.2648 + XiCon Loss:3.0258 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3106210
	speed: 0.0416s/iter; left time: 886.1250s
	iters: 200, epoch: 19 | loss: 3.2728071
	speed: 0.0393s/iter; left time: 832.9794s
Epoch: 19 cost time: 10.398902177810669
Epoch: 19, Steps: 261 Train Loss: 3.2902 (Forecasting Loss:0.2648 + XiCon Loss:3.0254 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2575810
	speed: 0.0427s/iter; left time: 898.3622s
	iters: 200, epoch: 20 | loss: 3.2848713
	speed: 0.0385s/iter; left time: 806.4253s
Epoch: 20 cost time: 10.479437589645386
Epoch: 20, Steps: 261 Train Loss: 3.2909 (Forecasting Loss:0.2648 + XiCon Loss:3.0262 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07381582260131836, mae:0.20629669725894928, mape:0.1547718644142151, mspe:0.039600104093551636 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4435
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6258702
	speed: 0.0404s/iter; left time: 1050.5453s
	iters: 200, epoch: 1 | loss: 3.5819173
	speed: 0.0379s/iter; left time: 981.8224s
Epoch: 1 cost time: 10.107067823410034
Epoch: 1, Steps: 261 Train Loss: 3.6400 (Forecasting Loss:0.2766 + XiCon Loss:3.3634 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1412
Validation loss decreased (inf --> 0.199023).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4187150
	speed: 0.0424s/iter; left time: 1092.3513s
	iters: 200, epoch: 2 | loss: 3.3860908
	speed: 0.0453s/iter; left time: 1161.8305s
Epoch: 2 cost time: 11.370344400405884
Epoch: 2, Steps: 261 Train Loss: 3.3870 (Forecasting Loss:0.2750 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1419
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3561611
	speed: 0.0448s/iter; left time: 1141.4447s
	iters: 200, epoch: 3 | loss: 3.4047692
	speed: 0.0426s/iter; left time: 1080.4197s
Epoch: 3 cost time: 11.433194875717163
Epoch: 3, Steps: 261 Train Loss: 3.3572 (Forecasting Loss:0.2680 + XiCon Loss:3.0891 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1412
Validation loss decreased (0.199023 --> 0.193763).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3253012
	speed: 0.0453s/iter; left time: 1143.6084s
	iters: 200, epoch: 4 | loss: 3.3239992
	speed: 0.0429s/iter; left time: 1077.8549s
Epoch: 4 cost time: 11.546552658081055
Epoch: 4, Steps: 261 Train Loss: 3.3105 (Forecasting Loss:0.2613 + XiCon Loss:3.0493 x Lambda(1.0)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.1405
Validation loss decreased (0.193763 --> 0.188785).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3421059
	speed: 0.0451s/iter; left time: 1124.7903s
	iters: 200, epoch: 5 | loss: 3.3050349
	speed: 0.0436s/iter; left time: 1084.4301s
Epoch: 5 cost time: 11.497678756713867
Epoch: 5, Steps: 261 Train Loss: 3.2933 (Forecasting Loss:0.2583 + XiCon Loss:3.0350 x Lambda(1.0)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.1409
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2806137
	speed: 0.0470s/iter; left time: 1161.7989s
	iters: 200, epoch: 6 | loss: 3.2936993
	speed: 0.0437s/iter; left time: 1075.9256s
Epoch: 6 cost time: 11.655535221099854
Epoch: 6, Steps: 261 Train Loss: 3.2842 (Forecasting Loss:0.2568 + XiCon Loss:3.0274 x Lambda(1.0)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.1403
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3111148
	speed: 0.0453s/iter; left time: 1106.6909s
	iters: 200, epoch: 7 | loss: 3.3292389
	speed: 0.0433s/iter; left time: 1053.5138s
Epoch: 7 cost time: 11.50488805770874
Epoch: 7, Steps: 261 Train Loss: 3.2769 (Forecasting Loss:0.2552 + XiCon Loss:3.0218 x Lambda(1.0)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.1405
Validation loss decreased (0.188785 --> 0.188782).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2931004
	speed: 0.0460s/iter; left time: 1112.1602s
	iters: 200, epoch: 8 | loss: 3.2390327
	speed: 0.0422s/iter; left time: 1015.0105s
Epoch: 8 cost time: 11.408616781234741
Epoch: 8, Steps: 261 Train Loss: 3.2751 (Forecasting Loss:0.2536 + XiCon Loss:3.0215 x Lambda(1.0)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2716203
	speed: 0.0459s/iter; left time: 1098.6784s
	iters: 200, epoch: 9 | loss: 3.2212276
	speed: 0.0428s/iter; left time: 1020.0344s
Epoch: 9 cost time: 11.496087551116943
Epoch: 9, Steps: 261 Train Loss: 3.2738 (Forecasting Loss:0.2533 + XiCon Loss:3.0205 x Lambda(1.0)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2788777
	speed: 0.0454s/iter; left time: 1074.4819s
	iters: 200, epoch: 10 | loss: 3.2865698
	speed: 0.0401s/iter; left time: 944.4112s
Epoch: 10 cost time: 11.043514728546143
Epoch: 10, Steps: 261 Train Loss: 3.2765 (Forecasting Loss:0.2534 + XiCon Loss:3.0231 x Lambda(1.0)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2551289
	speed: 0.0456s/iter; left time: 1066.0987s
	iters: 200, epoch: 11 | loss: 3.2600744
	speed: 0.0428s/iter; left time: 996.2982s
Epoch: 11 cost time: 11.479818105697632
Epoch: 11, Steps: 261 Train Loss: 3.2731 (Forecasting Loss:0.2535 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.1402
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3027239
	speed: 0.0452s/iter; left time: 1044.8944s
	iters: 200, epoch: 12 | loss: 3.2733345
	speed: 0.0439s/iter; left time: 1011.7270s
Epoch: 12 cost time: 11.537839651107788
Epoch: 12, Steps: 261 Train Loss: 3.2753 (Forecasting Loss:0.2530 + XiCon Loss:3.0223 x Lambda(1.0)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.1402
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2518876
	speed: 0.0464s/iter; left time: 1060.9348s
	iters: 200, epoch: 13 | loss: 3.3021460
	speed: 0.0427s/iter; left time: 972.9770s
Epoch: 13 cost time: 11.552416801452637
Epoch: 13, Steps: 261 Train Loss: 3.2732 (Forecasting Loss:0.2534 + XiCon Loss:3.0198 x Lambda(1.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1402
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2669516
	speed: 0.0455s/iter; left time: 1029.3612s
	iters: 200, epoch: 14 | loss: 3.2677865
	speed: 0.0442s/iter; left time: 994.1004s
Epoch: 14 cost time: 11.547659873962402
Epoch: 14, Steps: 261 Train Loss: 3.2740 (Forecasting Loss:0.2531 + XiCon Loss:3.0209 x Lambda(1.0)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1402
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2477291
	speed: 0.0453s/iter; left time: 1011.9627s
	iters: 200, epoch: 15 | loss: 3.3112979
	speed: 0.0439s/iter; left time: 976.6955s
Epoch: 15 cost time: 11.53242826461792
Epoch: 15, Steps: 261 Train Loss: 3.2729 (Forecasting Loss:0.2533 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1402
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2427697
	speed: 0.0458s/iter; left time: 1012.1863s
	iters: 200, epoch: 16 | loss: 3.3190830
	speed: 0.0422s/iter; left time: 927.7673s
Epoch: 16 cost time: 11.375645637512207
Epoch: 16, Steps: 261 Train Loss: 3.2742 (Forecasting Loss:0.2530 + XiCon Loss:3.0213 x Lambda(1.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1402
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2241144
	speed: 0.0451s/iter; left time: 985.0306s
	iters: 200, epoch: 17 | loss: 3.3099024
	speed: 0.0429s/iter; left time: 930.9927s
Epoch: 17 cost time: 11.510379552841187
Epoch: 17, Steps: 261 Train Loss: 3.2728 (Forecasting Loss:0.2531 + XiCon Loss:3.0198 x Lambda(1.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1402
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0734235942363739, mae:0.20760464668273926, mape:0.15705789625644684, mspe:0.04086519405245781 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6925
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6616261
	speed: 0.0382s/iter; left time: 993.8235s
	iters: 200, epoch: 1 | loss: 3.6515992
	speed: 0.0379s/iter; left time: 982.5215s
Epoch: 1 cost time: 9.931612968444824
Epoch: 1, Steps: 261 Train Loss: 3.6479 (Forecasting Loss:0.2762 + XiCon Loss:3.3717 x Lambda(1.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.199537).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4038799
	speed: 0.0438s/iter; left time: 1128.0423s
	iters: 200, epoch: 2 | loss: 3.3799005
	speed: 0.0412s/iter; left time: 1055.5741s
Epoch: 2 cost time: 11.018296480178833
Epoch: 2, Steps: 261 Train Loss: 3.4042 (Forecasting Loss:0.2745 + XiCon Loss:3.1297 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1446
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4133348
	speed: 0.0444s/iter; left time: 1130.9533s
	iters: 200, epoch: 3 | loss: 3.3708646
	speed: 0.0426s/iter; left time: 1080.1768s
Epoch: 3 cost time: 11.302929162979126
Epoch: 3, Steps: 261 Train Loss: 3.3824 (Forecasting Loss:0.2694 + XiCon Loss:3.1130 x Lambda(1.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1407
Validation loss decreased (0.199537 --> 0.196248).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3690283
	speed: 0.0441s/iter; left time: 1112.9467s
	iters: 200, epoch: 4 | loss: 3.3473878
	speed: 0.0423s/iter; left time: 1061.7348s
Epoch: 4 cost time: 11.208336591720581
Epoch: 4, Steps: 261 Train Loss: 3.3482 (Forecasting Loss:0.2665 + XiCon Loss:3.0817 x Lambda(1.0)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1406
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2946506
	speed: 0.0436s/iter; left time: 1087.8606s
	iters: 200, epoch: 5 | loss: 3.3279843
	speed: 0.0413s/iter; left time: 1027.0612s
Epoch: 5 cost time: 10.996214151382446
Epoch: 5, Steps: 261 Train Loss: 3.3359 (Forecasting Loss:0.2633 + XiCon Loss:3.0726 x Lambda(1.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.1404
Validation loss decreased (0.196248 --> 0.194834).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2967851
	speed: 0.0430s/iter; left time: 1061.3912s
	iters: 200, epoch: 6 | loss: 3.3024974
	speed: 0.0405s/iter; left time: 995.2520s
Epoch: 6 cost time: 10.892000436782837
Epoch: 6, Steps: 261 Train Loss: 3.3099 (Forecasting Loss:0.2591 + XiCon Loss:3.0508 x Lambda(1.0)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1397
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3194261
	speed: 0.0437s/iter; left time: 1066.8783s
	iters: 200, epoch: 7 | loss: 3.3435574
	speed: 0.0406s/iter; left time: 988.5992s
Epoch: 7 cost time: 11.07505178451538
Epoch: 7, Steps: 261 Train Loss: 3.3015 (Forecasting Loss:0.2572 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1402
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2644351
	speed: 0.0436s/iter; left time: 1054.6596s
	iters: 200, epoch: 8 | loss: 3.3121428
	speed: 0.0413s/iter; left time: 995.3658s
Epoch: 8 cost time: 10.988541603088379
Epoch: 8, Steps: 261 Train Loss: 3.3023 (Forecasting Loss:0.2564 + XiCon Loss:3.0458 x Lambda(1.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1400
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2859201
	speed: 0.0438s/iter; left time: 1048.1323s
	iters: 200, epoch: 9 | loss: 3.2402186
	speed: 0.0412s/iter; left time: 980.0938s
Epoch: 9 cost time: 10.877983331680298
Epoch: 9, Steps: 261 Train Loss: 3.2995 (Forecasting Loss:0.2559 + XiCon Loss:3.0436 x Lambda(1.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1398
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2930346
	speed: 0.0416s/iter; left time: 983.2779s
	iters: 200, epoch: 10 | loss: 3.2948115
	speed: 0.0420s/iter; left time: 989.5696s
Epoch: 10 cost time: 10.857677221298218
Epoch: 10, Steps: 261 Train Loss: 3.2987 (Forecasting Loss:0.2557 + XiCon Loss:3.0430 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1400
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3023090
	speed: 0.0448s/iter; left time: 1047.3520s
	iters: 200, epoch: 11 | loss: 3.2735763
	speed: 0.0407s/iter; left time: 948.8318s
Epoch: 11 cost time: 11.032364845275879
Epoch: 11, Steps: 261 Train Loss: 3.2961 (Forecasting Loss:0.2554 + XiCon Loss:3.0406 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1400
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2914598
	speed: 0.0439s/iter; left time: 1015.5919s
	iters: 200, epoch: 12 | loss: 3.2892976
	speed: 0.0415s/iter; left time: 956.6179s
Epoch: 12 cost time: 11.091481685638428
Epoch: 12, Steps: 261 Train Loss: 3.2965 (Forecasting Loss:0.2554 + XiCon Loss:3.0411 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1400
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3134098
	speed: 0.0442s/iter; left time: 1011.4896s
	iters: 200, epoch: 13 | loss: 3.2528949
	speed: 0.0410s/iter; left time: 933.7528s
Epoch: 13 cost time: 10.98600697517395
Epoch: 13, Steps: 261 Train Loss: 3.2987 (Forecasting Loss:0.2557 + XiCon Loss:3.0430 x Lambda(1.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1400
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3058476
	speed: 0.0430s/iter; left time: 972.6409s
	iters: 200, epoch: 14 | loss: 3.2861204
	speed: 0.0417s/iter; left time: 937.7493s
Epoch: 14 cost time: 11.082179546356201
Epoch: 14, Steps: 261 Train Loss: 3.2959 (Forecasting Loss:0.2556 + XiCon Loss:3.0403 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1400
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3076279
	speed: 0.0433s/iter; left time: 967.7040s
	iters: 200, epoch: 15 | loss: 3.3333206
	speed: 0.0412s/iter; left time: 917.0688s
Epoch: 15 cost time: 11.012194871902466
Epoch: 15, Steps: 261 Train Loss: 3.2978 (Forecasting Loss:0.2554 + XiCon Loss:3.0424 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1400
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07413441687822342, mae:0.20664319396018982, mape:0.15499043464660645, mspe:0.03976880759000778 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0739+-0.00047, MAE:0.2065+-0.00116, MAPE:0.1553+-0.00148, MSPE:0.0400+-0.00075, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0830
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4625394
	speed: 0.0369s/iter; left time: 978.5629s
	iters: 200, epoch: 1 | loss: 3.3909764
	speed: 0.0326s/iter; left time: 861.7002s
Epoch: 1 cost time: 9.02800965309143
Epoch: 1, Steps: 266 Train Loss: 3.4491 (Forecasting Loss:0.1867 + XiCon Loss:3.2624 x Lambda(1.0)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.1382
Validation loss decreased (inf --> 0.157856).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3406451
	speed: 0.0326s/iter; left time: 856.4290s
	iters: 200, epoch: 2 | loss: 3.2750769
	speed: 0.0312s/iter; left time: 814.9277s
Epoch: 2 cost time: 8.504217386245728
Epoch: 2, Steps: 266 Train Loss: 3.2993 (Forecasting Loss:0.1587 + XiCon Loss:3.1405 x Lambda(1.0)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.1331
Validation loss decreased (0.157856 --> 0.156932).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1380589
	speed: 0.0337s/iter; left time: 876.1019s
	iters: 200, epoch: 3 | loss: 3.1458831
	speed: 0.0308s/iter; left time: 797.2715s
Epoch: 3 cost time: 8.500416994094849
Epoch: 3, Steps: 266 Train Loss: 3.1983 (Forecasting Loss:0.1521 + XiCon Loss:3.0462 x Lambda(1.0)), Vali MSE Loss: 0.1484 Test MSE Loss: 0.1298
Validation loss decreased (0.156932 --> 0.148409).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1123662
	speed: 0.0323s/iter; left time: 830.8018s
	iters: 200, epoch: 4 | loss: 3.1604526
	speed: 0.0307s/iter; left time: 785.0892s
Epoch: 4 cost time: 8.272816181182861
Epoch: 4, Steps: 266 Train Loss: 3.1795 (Forecasting Loss:0.1496 + XiCon Loss:3.0299 x Lambda(1.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1283
Validation loss decreased (0.148409 --> 0.145980).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1781716
	speed: 0.0337s/iter; left time: 857.7224s
	iters: 200, epoch: 5 | loss: 3.1853905
	speed: 0.0330s/iter; left time: 836.2253s
Epoch: 5 cost time: 8.77381443977356
Epoch: 5, Steps: 266 Train Loss: 3.1616 (Forecasting Loss:0.1480 + XiCon Loss:3.0136 x Lambda(1.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.1263
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1635818
	speed: 0.0345s/iter; left time: 867.3596s
	iters: 200, epoch: 6 | loss: 3.1745088
	speed: 0.0313s/iter; left time: 785.8787s
Epoch: 6 cost time: 8.716533422470093
Epoch: 6, Steps: 266 Train Loss: 3.1594 (Forecasting Loss:0.1473 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
Validation loss decreased (0.145980 --> 0.144535).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1498139
	speed: 0.0334s/iter; left time: 830.8563s
	iters: 200, epoch: 7 | loss: 3.1619482
	speed: 0.0319s/iter; left time: 792.4374s
Epoch: 7 cost time: 8.611881017684937
Epoch: 7, Steps: 266 Train Loss: 3.1573 (Forecasting Loss:0.1471 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1251
Validation loss decreased (0.144535 --> 0.144378).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1832113
	speed: 0.0334s/iter; left time: 823.4173s
	iters: 200, epoch: 8 | loss: 3.1525512
	speed: 0.0312s/iter; left time: 766.8271s
Epoch: 8 cost time: 8.498304843902588
Epoch: 8, Steps: 266 Train Loss: 3.1547 (Forecasting Loss:0.1469 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1252
Validation loss decreased (0.144378 --> 0.144163).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1397491
	speed: 0.0337s/iter; left time: 820.5452s
	iters: 200, epoch: 9 | loss: 3.1773982
	speed: 0.0306s/iter; left time: 742.4453s
Epoch: 9 cost time: 8.48901104927063
Epoch: 9, Steps: 266 Train Loss: 3.1561 (Forecasting Loss:0.1468 + XiCon Loss:3.0093 x Lambda(1.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1250
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1890481
	speed: 0.0339s/iter; left time: 817.8417s
	iters: 200, epoch: 10 | loss: 3.1308179
	speed: 0.0324s/iter; left time: 777.3975s
Epoch: 10 cost time: 8.749923706054688
Epoch: 10, Steps: 266 Train Loss: 3.1574 (Forecasting Loss:0.1468 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1248
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1857803
	speed: 0.0350s/iter; left time: 834.6375s
	iters: 200, epoch: 11 | loss: 3.1734524
	speed: 0.0329s/iter; left time: 780.7898s
Epoch: 11 cost time: 8.994023084640503
Epoch: 11, Steps: 266 Train Loss: 3.1562 (Forecasting Loss:0.1467 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2047665
	speed: 0.0339s/iter; left time: 799.8555s
	iters: 200, epoch: 12 | loss: 3.1133018
	speed: 0.0317s/iter; left time: 743.1899s
Epoch: 12 cost time: 8.641494035720825
Epoch: 12, Steps: 266 Train Loss: 3.1581 (Forecasting Loss:0.1467 + XiCon Loss:3.0114 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1234701
	speed: 0.0341s/iter; left time: 795.5398s
	iters: 200, epoch: 13 | loss: 3.1555977
	speed: 0.0312s/iter; left time: 723.4355s
Epoch: 13 cost time: 8.67120361328125
Epoch: 13, Steps: 266 Train Loss: 3.1541 (Forecasting Loss:0.1467 + XiCon Loss:3.0075 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
Validation loss decreased (0.144163 --> 0.143991).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1041994
	speed: 0.0334s/iter; left time: 768.5759s
	iters: 200, epoch: 14 | loss: 3.1070108
	speed: 0.0317s/iter; left time: 727.9886s
Epoch: 14 cost time: 8.58802342414856
Epoch: 14, Steps: 266 Train Loss: 3.1562 (Forecasting Loss:0.1467 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2423384
	speed: 0.0346s/iter; left time: 788.6618s
	iters: 200, epoch: 15 | loss: 3.1131160
	speed: 0.0333s/iter; left time: 754.0744s
Epoch: 15 cost time: 8.922468662261963
Epoch: 15, Steps: 266 Train Loss: 3.1547 (Forecasting Loss:0.1466 + XiCon Loss:3.0080 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1506028
	speed: 0.0331s/iter; left time: 744.9658s
	iters: 200, epoch: 16 | loss: 3.1306448
	speed: 0.0312s/iter; left time: 699.8135s
Epoch: 16 cost time: 8.510315656661987
Epoch: 16, Steps: 266 Train Loss: 3.1563 (Forecasting Loss:0.1467 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1654434
	speed: 0.0333s/iter; left time: 741.7715s
	iters: 200, epoch: 17 | loss: 3.1543927
	speed: 0.0310s/iter; left time: 686.7358s
Epoch: 17 cost time: 8.48391056060791
Epoch: 17, Steps: 266 Train Loss: 3.1564 (Forecasting Loss:0.1466 + XiCon Loss:3.0098 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1617358
	speed: 0.0331s/iter; left time: 726.5567s
	iters: 200, epoch: 18 | loss: 3.1239479
	speed: 0.0311s/iter; left time: 679.3766s
Epoch: 18 cost time: 8.435055255889893
Epoch: 18, Steps: 266 Train Loss: 3.1542 (Forecasting Loss:0.1467 + XiCon Loss:3.0075 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1247
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1204669
	speed: 0.0341s/iter; left time: 740.7602s
	iters: 200, epoch: 19 | loss: 3.1415944
	speed: 0.0309s/iter; left time: 667.5467s
Epoch: 19 cost time: 8.588308811187744
Epoch: 19, Steps: 266 Train Loss: 3.1551 (Forecasting Loss:0.1467 + XiCon Loss:3.0084 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2026427
	speed: 0.0334s/iter; left time: 717.0329s
	iters: 200, epoch: 20 | loss: 3.1970613
	speed: 0.0305s/iter; left time: 650.8357s
Epoch: 20 cost time: 8.496852159500122
Epoch: 20, Steps: 266 Train Loss: 3.1560 (Forecasting Loss:0.1466 + XiCon Loss:3.0094 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1247
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2148633
	speed: 0.0336s/iter; left time: 710.6290s
	iters: 200, epoch: 21 | loss: 3.1289732
	speed: 0.0308s/iter; left time: 649.8807s
Epoch: 21 cost time: 8.470015287399292
Epoch: 21, Steps: 266 Train Loss: 3.1568 (Forecasting Loss:0.1466 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1693249
	speed: 0.0327s/iter; left time: 683.9889s
	iters: 200, epoch: 22 | loss: 3.1304772
	speed: 0.0310s/iter; left time: 646.0633s
Epoch: 22 cost time: 8.440057039260864
Epoch: 22, Steps: 266 Train Loss: 3.1546 (Forecasting Loss:0.1467 + XiCon Loss:3.0079 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1471927
	speed: 0.0330s/iter; left time: 680.9963s
	iters: 200, epoch: 23 | loss: 3.1613352
	speed: 0.0316s/iter; left time: 649.8066s
Epoch: 23 cost time: 8.474887132644653
Epoch: 23, Steps: 266 Train Loss: 3.1544 (Forecasting Loss:0.1466 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06496600806713104, mae:0.18434752523899078, mape:0.44939371943473816, mspe:8.292464256286621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7600
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4461570
	speed: 0.0347s/iter; left time: 919.5807s
	iters: 200, epoch: 1 | loss: 3.3855367
	speed: 0.0322s/iter; left time: 849.7411s
Epoch: 1 cost time: 8.743992567062378
Epoch: 1, Steps: 266 Train Loss: 3.4569 (Forecasting Loss:0.1854 + XiCon Loss:3.2715 x Lambda(1.0)), Vali MSE Loss: 0.1583 Test MSE Loss: 0.1355
Validation loss decreased (inf --> 0.158294).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4113982
	speed: 0.0332s/iter; left time: 871.2292s
	iters: 200, epoch: 2 | loss: 3.3092577
	speed: 0.0303s/iter; left time: 792.8989s
Epoch: 2 cost time: 8.341723918914795
Epoch: 2, Steps: 266 Train Loss: 3.3395 (Forecasting Loss:0.1587 + XiCon Loss:3.1809 x Lambda(1.0)), Vali MSE Loss: 0.1531 Test MSE Loss: 0.1323
Validation loss decreased (0.158294 --> 0.153106).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2697952
	speed: 0.0334s/iter; left time: 866.2597s
	iters: 200, epoch: 3 | loss: 3.3089883
	speed: 0.0301s/iter; left time: 778.7360s
Epoch: 3 cost time: 8.342534303665161
Epoch: 3, Steps: 266 Train Loss: 3.2817 (Forecasting Loss:0.1516 + XiCon Loss:3.1301 x Lambda(1.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1281
Validation loss decreased (0.153106 --> 0.148577).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3617465
	speed: 0.0330s/iter; left time: 846.9780s
	iters: 200, epoch: 4 | loss: 3.3017437
	speed: 0.0312s/iter; left time: 799.1903s
Epoch: 4 cost time: 8.45076870918274
Epoch: 4, Steps: 266 Train Loss: 3.2722 (Forecasting Loss:0.1494 + XiCon Loss:3.1228 x Lambda(1.0)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.1261
Validation loss decreased (0.148577 --> 0.147310).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2163386
	speed: 0.0333s/iter; left time: 847.7096s
	iters: 200, epoch: 5 | loss: 3.2713878
	speed: 0.0309s/iter; left time: 783.7604s
Epoch: 5 cost time: 8.666482925415039
Epoch: 5, Steps: 266 Train Loss: 3.2567 (Forecasting Loss:0.1478 + XiCon Loss:3.1089 x Lambda(1.0)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.1257
Validation loss decreased (0.147310 --> 0.145089).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2637997
	speed: 0.0329s/iter; left time: 828.0162s
	iters: 200, epoch: 6 | loss: 3.2005286
	speed: 0.0303s/iter; left time: 760.6987s
Epoch: 6 cost time: 8.37525463104248
Epoch: 6, Steps: 266 Train Loss: 3.2590 (Forecasting Loss:0.1470 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1256
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2003796
	speed: 0.0344s/iter; left time: 855.8339s
	iters: 200, epoch: 7 | loss: 3.2420905
	speed: 0.0311s/iter; left time: 772.3068s
Epoch: 7 cost time: 8.599624872207642
Epoch: 7, Steps: 266 Train Loss: 3.2510 (Forecasting Loss:0.1466 + XiCon Loss:3.1044 x Lambda(1.0)), Vali MSE Loss: 0.1458 Test MSE Loss: 0.1257
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1948690
	speed: 0.0327s/iter; left time: 805.0143s
	iters: 200, epoch: 8 | loss: 3.2069225
	speed: 0.0311s/iter; left time: 764.0951s
Epoch: 8 cost time: 8.454496383666992
Epoch: 8, Steps: 266 Train Loss: 3.2535 (Forecasting Loss:0.1463 + XiCon Loss:3.1073 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1257
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1929009
	speed: 0.0333s/iter; left time: 811.9221s
	iters: 200, epoch: 9 | loss: 3.2059159
	speed: 0.0314s/iter; left time: 762.2986s
Epoch: 9 cost time: 8.52558183670044
Epoch: 9, Steps: 266 Train Loss: 3.2514 (Forecasting Loss:0.1462 + XiCon Loss:3.1052 x Lambda(1.0)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.1257
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2027056
	speed: 0.0333s/iter; left time: 802.8470s
	iters: 200, epoch: 10 | loss: 3.2709551
	speed: 0.0319s/iter; left time: 766.4559s
Epoch: 10 cost time: 8.667996883392334
Epoch: 10, Steps: 266 Train Loss: 3.2543 (Forecasting Loss:0.1461 + XiCon Loss:3.1082 x Lambda(1.0)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.1256
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2640467
	speed: 0.0331s/iter; left time: 789.4963s
	iters: 200, epoch: 11 | loss: 3.2726526
	speed: 0.0313s/iter; left time: 743.9874s
Epoch: 11 cost time: 8.512768507003784
Epoch: 11, Steps: 266 Train Loss: 3.2540 (Forecasting Loss:0.1461 + XiCon Loss:3.1078 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1255
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2390187
	speed: 0.0336s/iter; left time: 792.7326s
	iters: 200, epoch: 12 | loss: 3.1790304
	speed: 0.0311s/iter; left time: 731.1820s
Epoch: 12 cost time: 8.537416219711304
Epoch: 12, Steps: 266 Train Loss: 3.2518 (Forecasting Loss:0.1460 + XiCon Loss:3.1057 x Lambda(1.0)), Vali MSE Loss: 0.1454 Test MSE Loss: 0.1256
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2065184
	speed: 0.0333s/iter; left time: 776.6377s
	iters: 200, epoch: 13 | loss: 3.2634788
	speed: 0.0311s/iter; left time: 720.9874s
Epoch: 13 cost time: 8.494101524353027
Epoch: 13, Steps: 266 Train Loss: 3.2504 (Forecasting Loss:0.1460 + XiCon Loss:3.1044 x Lambda(1.0)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.1256
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2231643
	speed: 0.0339s/iter; left time: 780.7284s
	iters: 200, epoch: 14 | loss: 3.2769184
	speed: 0.0309s/iter; left time: 710.0431s
Epoch: 14 cost time: 8.543245792388916
Epoch: 14, Steps: 266 Train Loss: 3.2563 (Forecasting Loss:0.1460 + XiCon Loss:3.1103 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1256
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1903567
	speed: 0.0338s/iter; left time: 769.2250s
	iters: 200, epoch: 15 | loss: 3.2571409
	speed: 0.0329s/iter; left time: 745.6554s
Epoch: 15 cost time: 8.790370225906372
Epoch: 15, Steps: 266 Train Loss: 3.2540 (Forecasting Loss:0.1460 + XiCon Loss:3.1080 x Lambda(1.0)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.1256
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06523110717535019, mae:0.18626317381858826, mape:0.4522705674171448, mspe:8.353545188903809 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6600
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4239135
	speed: 0.0334s/iter; left time: 885.0839s
	iters: 200, epoch: 1 | loss: 3.3628395
	speed: 0.0304s/iter; left time: 801.8738s
Epoch: 1 cost time: 8.391921281814575
Epoch: 1, Steps: 266 Train Loss: 3.4405 (Forecasting Loss:0.1878 + XiCon Loss:3.2526 x Lambda(1.0)), Vali MSE Loss: 0.1596 Test MSE Loss: 0.1366
Validation loss decreased (inf --> 0.159625).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5625148
	speed: 0.0325s/iter; left time: 852.1178s
	iters: 200, epoch: 2 | loss: 3.4581637
	speed: 0.0313s/iter; left time: 816.9920s
Epoch: 2 cost time: 8.372097969055176
Epoch: 2, Steps: 266 Train Loss: 3.5006 (Forecasting Loss:0.1589 + XiCon Loss:3.3417 x Lambda(1.0)), Vali MSE Loss: 0.1546 Test MSE Loss: 0.1320
Validation loss decreased (0.159625 --> 0.154572).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5414300
	speed: 0.0331s/iter; left time: 859.1755s
	iters: 200, epoch: 3 | loss: 3.4861233
	speed: 0.0330s/iter; left time: 852.7066s
Epoch: 3 cost time: 8.724164485931396
Epoch: 3, Steps: 266 Train Loss: 3.5356 (Forecasting Loss:0.1523 + XiCon Loss:3.3833 x Lambda(1.0)), Vali MSE Loss: 0.1490 Test MSE Loss: 0.1287
Validation loss decreased (0.154572 --> 0.149001).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.5456736
	speed: 0.0337s/iter; left time: 865.4819s
	iters: 200, epoch: 4 | loss: 3.5763433
	speed: 0.0303s/iter; left time: 775.5421s
Epoch: 4 cost time: 8.52442193031311
Epoch: 4, Steps: 266 Train Loss: 3.5023 (Forecasting Loss:0.1497 + XiCon Loss:3.3526 x Lambda(1.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1289
Validation loss decreased (0.149001 --> 0.148613).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4863818
	speed: 0.0334s/iter; left time: 849.6862s
	iters: 200, epoch: 5 | loss: 3.3107176
	speed: 0.0314s/iter; left time: 795.6609s
Epoch: 5 cost time: 8.565041542053223
Epoch: 5, Steps: 266 Train Loss: 3.4799 (Forecasting Loss:0.1483 + XiCon Loss:3.3315 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1253
Validation loss decreased (0.148613 --> 0.144371).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4444447
	speed: 0.0333s/iter; left time: 838.4067s
	iters: 200, epoch: 6 | loss: 3.4260333
	speed: 0.0316s/iter; left time: 793.2539s
Epoch: 6 cost time: 8.589381456375122
Epoch: 6, Steps: 266 Train Loss: 3.4635 (Forecasting Loss:0.1475 + XiCon Loss:3.3160 x Lambda(1.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4316828
	speed: 0.0337s/iter; left time: 839.0535s
	iters: 200, epoch: 7 | loss: 3.5159073
	speed: 0.0312s/iter; left time: 773.6345s
Epoch: 7 cost time: 8.517749071121216
Epoch: 7, Steps: 266 Train Loss: 3.4802 (Forecasting Loss:0.1472 + XiCon Loss:3.3331 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1248
Validation loss decreased (0.144371 --> 0.144270).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5495403
	speed: 0.0340s/iter; left time: 837.8751s
	iters: 200, epoch: 8 | loss: 3.5287809
	speed: 0.0323s/iter; left time: 792.0850s
Epoch: 8 cost time: 8.810144901275635
Epoch: 8, Steps: 266 Train Loss: 3.4685 (Forecasting Loss:0.1471 + XiCon Loss:3.3214 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1248
Validation loss decreased (0.144270 --> 0.144243).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.5133224
	speed: 0.0347s/iter; left time: 844.9866s
	iters: 200, epoch: 9 | loss: 3.4114997
	speed: 0.0324s/iter; left time: 785.8181s
Epoch: 9 cost time: 8.77246356010437
Epoch: 9, Steps: 266 Train Loss: 3.4664 (Forecasting Loss:0.1469 + XiCon Loss:3.3194 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1248
Validation loss decreased (0.144243 --> 0.144211).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5285077
	speed: 0.0329s/iter; left time: 794.1992s
	iters: 200, epoch: 10 | loss: 3.4685500
	speed: 0.0314s/iter; left time: 754.0362s
Epoch: 10 cost time: 8.478110790252686
Epoch: 10, Steps: 266 Train Loss: 3.4600 (Forecasting Loss:0.1469 + XiCon Loss:3.3131 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
Validation loss decreased (0.144211 --> 0.143955).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4309819
	speed: 0.0327s/iter; left time: 779.2410s
	iters: 200, epoch: 11 | loss: 3.3965948
	speed: 0.0302s/iter; left time: 716.1279s
Epoch: 11 cost time: 8.394049167633057
Epoch: 11, Steps: 266 Train Loss: 3.4630 (Forecasting Loss:0.1468 + XiCon Loss:3.3161 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3408334
	speed: 0.0342s/iter; left time: 805.7568s
	iters: 200, epoch: 12 | loss: 3.4465632
	speed: 0.0308s/iter; left time: 723.7818s
Epoch: 12 cost time: 8.571381568908691
Epoch: 12, Steps: 266 Train Loss: 3.4700 (Forecasting Loss:0.1468 + XiCon Loss:3.3232 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5127921
	speed: 0.0341s/iter; left time: 795.1800s
	iters: 200, epoch: 13 | loss: 3.5388117
	speed: 0.0334s/iter; left time: 776.1265s
Epoch: 13 cost time: 8.898821592330933
Epoch: 13, Steps: 266 Train Loss: 3.4615 (Forecasting Loss:0.1468 + XiCon Loss:3.3148 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4823885
	speed: 0.0344s/iter; left time: 793.0593s
	iters: 200, epoch: 14 | loss: 3.4088686
	speed: 0.0319s/iter; left time: 731.8690s
Epoch: 14 cost time: 8.797162532806396
Epoch: 14, Steps: 266 Train Loss: 3.4617 (Forecasting Loss:0.1468 + XiCon Loss:3.3150 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3413017
	speed: 0.0342s/iter; left time: 778.1017s
	iters: 200, epoch: 15 | loss: 3.3750527
	speed: 0.0316s/iter; left time: 717.2564s
Epoch: 15 cost time: 8.665499925613403
Epoch: 15, Steps: 266 Train Loss: 3.4651 (Forecasting Loss:0.1468 + XiCon Loss:3.3183 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4407737
	speed: 0.0334s/iter; left time: 750.9809s
	iters: 200, epoch: 16 | loss: 3.3943856
	speed: 0.0313s/iter; left time: 700.3958s
Epoch: 16 cost time: 8.572947025299072
Epoch: 16, Steps: 266 Train Loss: 3.4633 (Forecasting Loss:0.1468 + XiCon Loss:3.3165 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4920328
	speed: 0.0332s/iter; left time: 738.9954s
	iters: 200, epoch: 17 | loss: 3.3387804
	speed: 0.0314s/iter; left time: 695.9587s
Epoch: 17 cost time: 8.558473348617554
Epoch: 17, Steps: 266 Train Loss: 3.4608 (Forecasting Loss:0.1468 + XiCon Loss:3.3140 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2677042
	speed: 0.0337s/iter; left time: 741.4228s
	iters: 200, epoch: 18 | loss: 3.4827232
	speed: 0.0320s/iter; left time: 699.5465s
Epoch: 18 cost time: 8.728384017944336
Epoch: 18, Steps: 266 Train Loss: 3.4581 (Forecasting Loss:0.1468 + XiCon Loss:3.3113 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4023883
	speed: 0.0333s/iter; left time: 724.0416s
	iters: 200, epoch: 19 | loss: 3.4427438
	speed: 0.0315s/iter; left time: 680.9412s
Epoch: 19 cost time: 8.594332456588745
Epoch: 19, Steps: 266 Train Loss: 3.4652 (Forecasting Loss:0.1468 + XiCon Loss:3.3183 x Lambda(1.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1247
Validation loss decreased (0.143955 --> 0.143907).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4358079
	speed: 0.0326s/iter; left time: 698.8921s
	iters: 200, epoch: 20 | loss: 3.4955411
	speed: 0.0321s/iter; left time: 684.4637s
Epoch: 20 cost time: 8.575639009475708
Epoch: 20, Steps: 266 Train Loss: 3.4599 (Forecasting Loss:0.1468 + XiCon Loss:3.3131 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4452257
	speed: 0.0327s/iter; left time: 692.9876s
	iters: 200, epoch: 21 | loss: 3.3309393
	speed: 0.0317s/iter; left time: 667.2408s
Epoch: 21 cost time: 8.521742105484009
Epoch: 21, Steps: 266 Train Loss: 3.4645 (Forecasting Loss:0.1467 + XiCon Loss:3.3178 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3618290
	speed: 0.0344s/iter; left time: 720.5105s
	iters: 200, epoch: 22 | loss: 3.4053817
	speed: 0.0324s/iter; left time: 674.6800s
Epoch: 22 cost time: 8.782663106918335
Epoch: 22, Steps: 266 Train Loss: 3.4668 (Forecasting Loss:0.1468 + XiCon Loss:3.3200 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5236802
	speed: 0.0347s/iter; left time: 717.3582s
	iters: 200, epoch: 23 | loss: 3.5238454
	speed: 0.0321s/iter; left time: 659.6221s
Epoch: 23 cost time: 8.798523902893066
Epoch: 23, Steps: 266 Train Loss: 3.4684 (Forecasting Loss:0.1468 + XiCon Loss:3.3216 x Lambda(1.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1247
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4825745
	speed: 0.0337s/iter; left time: 686.9909s
	iters: 200, epoch: 24 | loss: 3.3671808
	speed: 0.0313s/iter; left time: 635.7845s
Epoch: 24 cost time: 8.532784461975098
Epoch: 24, Steps: 266 Train Loss: 3.4597 (Forecasting Loss:0.1468 + XiCon Loss:3.3129 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4279494
	speed: 0.0338s/iter; left time: 679.0987s
	iters: 200, epoch: 25 | loss: 3.4585428
	speed: 0.0311s/iter; left time: 622.2169s
Epoch: 25 cost time: 8.55771517753601
Epoch: 25, Steps: 266 Train Loss: 3.4673 (Forecasting Loss:0.1468 + XiCon Loss:3.3205 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.4178846
	speed: 0.0331s/iter; left time: 657.1556s
	iters: 200, epoch: 26 | loss: 3.5859604
	speed: 0.0313s/iter; left time: 618.3329s
Epoch: 26 cost time: 8.584895849227905
Epoch: 26, Steps: 266 Train Loss: 3.4644 (Forecasting Loss:0.1468 + XiCon Loss:3.3176 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.6099901
	speed: 0.0339s/iter; left time: 663.0757s
	iters: 200, epoch: 27 | loss: 3.6194735
	speed: 0.0317s/iter; left time: 618.3564s
Epoch: 27 cost time: 8.68605923652649
Epoch: 27, Steps: 266 Train Loss: 3.4609 (Forecasting Loss:0.1469 + XiCon Loss:3.3140 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.4745235
	speed: 0.0332s/iter; left time: 640.9555s
	iters: 200, epoch: 28 | loss: 3.5297093
	speed: 0.0312s/iter; left time: 600.5887s
Epoch: 28 cost time: 8.491698980331421
Epoch: 28, Steps: 266 Train Loss: 3.4617 (Forecasting Loss:0.1468 + XiCon Loss:3.3149 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.4973478
	speed: 0.0339s/iter; left time: 645.0790s
	iters: 200, epoch: 29 | loss: 3.4333470
	speed: 0.0314s/iter; left time: 594.9247s
Epoch: 29 cost time: 8.647164583206177
Epoch: 29, Steps: 266 Train Loss: 3.4627 (Forecasting Loss:0.1467 + XiCon Loss:3.3160 x Lambda(1.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1247
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06478296220302582, mae:0.1846350133419037, mape:0.44860970973968506, mspe:8.125765800476074 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4488
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4838970
	speed: 0.0344s/iter; left time: 911.8956s
	iters: 200, epoch: 1 | loss: 3.4126589
	speed: 0.0329s/iter; left time: 868.3895s
Epoch: 1 cost time: 8.857908487319946
Epoch: 1, Steps: 266 Train Loss: 3.4551 (Forecasting Loss:0.1872 + XiCon Loss:3.2679 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1373
Validation loss decreased (inf --> 0.162001).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3765242
	speed: 0.0343s/iter; left time: 899.0833s
	iters: 200, epoch: 2 | loss: 3.3861072
	speed: 0.0316s/iter; left time: 824.9988s
Epoch: 2 cost time: 8.698680877685547
Epoch: 2, Steps: 266 Train Loss: 3.3739 (Forecasting Loss:0.1598 + XiCon Loss:3.2142 x Lambda(1.0)), Vali MSE Loss: 0.1535 Test MSE Loss: 0.1326
Validation loss decreased (0.162001 --> 0.153462).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3072674
	speed: 0.0322s/iter; left time: 836.3076s
	iters: 200, epoch: 3 | loss: 3.2498901
	speed: 0.0316s/iter; left time: 817.3351s
Epoch: 3 cost time: 8.44162106513977
Epoch: 3, Steps: 266 Train Loss: 3.2922 (Forecasting Loss:0.1519 + XiCon Loss:3.1403 x Lambda(1.0)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.1291
Validation loss decreased (0.153462 --> 0.147299).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2025371
	speed: 0.0326s/iter; left time: 838.9800s
	iters: 200, epoch: 4 | loss: 3.2346265
	speed: 0.0305s/iter; left time: 779.8701s
Epoch: 4 cost time: 8.405900478363037
Epoch: 4, Steps: 266 Train Loss: 3.2659 (Forecasting Loss:0.1490 + XiCon Loss:3.1169 x Lambda(1.0)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.1268
Validation loss decreased (0.147299 --> 0.146705).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1627035
	speed: 0.0337s/iter; left time: 856.6382s
	iters: 200, epoch: 5 | loss: 3.2803173
	speed: 0.0321s/iter; left time: 814.2815s
Epoch: 5 cost time: 8.761668682098389
Epoch: 5, Steps: 266 Train Loss: 3.2328 (Forecasting Loss:0.1480 + XiCon Loss:3.0849 x Lambda(1.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1262
Validation loss decreased (0.146705 --> 0.144758).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2352808
	speed: 0.0334s/iter; left time: 839.7437s
	iters: 200, epoch: 6 | loss: 3.1758931
	speed: 0.0312s/iter; left time: 782.3742s
Epoch: 6 cost time: 8.501044750213623
Epoch: 6, Steps: 266 Train Loss: 3.2218 (Forecasting Loss:0.1475 + XiCon Loss:3.0742 x Lambda(1.0)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.1250
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2283061
	speed: 0.0341s/iter; left time: 848.2737s
	iters: 200, epoch: 7 | loss: 3.2090995
	speed: 0.0319s/iter; left time: 790.3022s
Epoch: 7 cost time: 8.634337663650513
Epoch: 7, Steps: 266 Train Loss: 3.2216 (Forecasting Loss:0.1472 + XiCon Loss:3.0744 x Lambda(1.0)), Vali MSE Loss: 0.1450 Test MSE Loss: 0.1247
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1615522
	speed: 0.0344s/iter; left time: 847.3723s
	iters: 200, epoch: 8 | loss: 3.1950774
	speed: 0.0310s/iter; left time: 760.5270s
Epoch: 8 cost time: 8.659484624862671
Epoch: 8, Steps: 266 Train Loss: 3.2113 (Forecasting Loss:0.1471 + XiCon Loss:3.0642 x Lambda(1.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1248
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2527244
	speed: 0.0331s/iter; left time: 806.8555s
	iters: 200, epoch: 9 | loss: 3.2879672
	speed: 0.0315s/iter; left time: 765.4883s
Epoch: 9 cost time: 8.582847595214844
Epoch: 9, Steps: 266 Train Loss: 3.2186 (Forecasting Loss:0.1469 + XiCon Loss:3.0717 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144758 --> 0.144427).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2187560
	speed: 0.0343s/iter; left time: 827.6813s
	iters: 200, epoch: 10 | loss: 3.2520018
	speed: 0.0326s/iter; left time: 782.1046s
Epoch: 10 cost time: 8.778163433074951
Epoch: 10, Steps: 266 Train Loss: 3.2170 (Forecasting Loss:0.1469 + XiCon Loss:3.0701 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1578777
	speed: 0.0337s/iter; left time: 803.2871s
	iters: 200, epoch: 11 | loss: 3.2134795
	speed: 0.0317s/iter; left time: 753.1274s
Epoch: 11 cost time: 8.675242185592651
Epoch: 11, Steps: 266 Train Loss: 3.2078 (Forecasting Loss:0.1468 + XiCon Loss:3.0610 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144427 --> 0.144384).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1589034
	speed: 0.0338s/iter; left time: 795.8629s
	iters: 200, epoch: 12 | loss: 3.1514537
	speed: 0.0314s/iter; left time: 737.3488s
Epoch: 12 cost time: 8.619026899337769
Epoch: 12, Steps: 266 Train Loss: 3.2076 (Forecasting Loss:0.1468 + XiCon Loss:3.0608 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1895003
	speed: 0.0332s/iter; left time: 773.7675s
	iters: 200, epoch: 13 | loss: 3.2168989
	speed: 0.0307s/iter; left time: 711.3864s
Epoch: 13 cost time: 8.43783688545227
Epoch: 13, Steps: 266 Train Loss: 3.2087 (Forecasting Loss:0.1469 + XiCon Loss:3.0617 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2128811
	speed: 0.0340s/iter; left time: 782.4257s
	iters: 200, epoch: 14 | loss: 3.2063713
	speed: 0.0322s/iter; left time: 737.8927s
Epoch: 14 cost time: 8.710142850875854
Epoch: 14, Steps: 266 Train Loss: 3.2108 (Forecasting Loss:0.1468 + XiCon Loss:3.0639 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144384 --> 0.144380).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2507272
	speed: 0.0338s/iter; left time: 770.1758s
	iters: 200, epoch: 15 | loss: 3.2102144
	speed: 0.0323s/iter; left time: 733.0623s
Epoch: 15 cost time: 8.772837400436401
Epoch: 15, Steps: 266 Train Loss: 3.2130 (Forecasting Loss:0.1468 + XiCon Loss:3.0661 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2263060
	speed: 0.0335s/iter; left time: 755.0354s
	iters: 200, epoch: 16 | loss: 3.2019067
	speed: 0.0310s/iter; left time: 694.7882s
Epoch: 16 cost time: 8.500710010528564
Epoch: 16, Steps: 266 Train Loss: 3.2077 (Forecasting Loss:0.1469 + XiCon Loss:3.0609 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2534072
	speed: 0.0331s/iter; left time: 736.1418s
	iters: 200, epoch: 17 | loss: 3.2013309
	speed: 0.0306s/iter; left time: 677.8652s
Epoch: 17 cost time: 8.451438426971436
Epoch: 17, Steps: 266 Train Loss: 3.2079 (Forecasting Loss:0.1468 + XiCon Loss:3.0611 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2332702
	speed: 0.0326s/iter; left time: 716.6356s
	iters: 200, epoch: 18 | loss: 3.2560260
	speed: 0.0308s/iter; left time: 673.9723s
Epoch: 18 cost time: 8.406545162200928
Epoch: 18, Steps: 266 Train Loss: 3.2106 (Forecasting Loss:0.1469 + XiCon Loss:3.0637 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
Validation loss decreased (0.144380 --> 0.144335).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2369690
	speed: 0.0332s/iter; left time: 720.7610s
	iters: 200, epoch: 19 | loss: 3.1646826
	speed: 0.0327s/iter; left time: 707.0964s
Epoch: 19 cost time: 8.781586408615112
Epoch: 19, Steps: 266 Train Loss: 3.2084 (Forecasting Loss:0.1468 + XiCon Loss:3.0615 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1763625
	speed: 0.0342s/iter; left time: 732.4306s
	iters: 200, epoch: 20 | loss: 3.2809763
	speed: 0.0323s/iter; left time: 689.7737s
Epoch: 20 cost time: 8.707401275634766
Epoch: 20, Steps: 266 Train Loss: 3.2125 (Forecasting Loss:0.1468 + XiCon Loss:3.0656 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1448143
	speed: 0.0330s/iter; left time: 699.2301s
	iters: 200, epoch: 21 | loss: 3.1952758
	speed: 0.0319s/iter; left time: 672.3735s
Epoch: 21 cost time: 8.568500280380249
Epoch: 21, Steps: 266 Train Loss: 3.2112 (Forecasting Loss:0.1468 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2124219
	speed: 0.0347s/iter; left time: 726.2512s
	iters: 200, epoch: 22 | loss: 3.1718123
	speed: 0.0323s/iter; left time: 672.4002s
Epoch: 22 cost time: 8.749890089035034
Epoch: 22, Steps: 266 Train Loss: 3.2127 (Forecasting Loss:0.1468 + XiCon Loss:3.0659 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2274950
	speed: 0.0325s/iter; left time: 671.4306s
	iters: 200, epoch: 23 | loss: 3.1734655
	speed: 0.0309s/iter; left time: 633.9485s
Epoch: 23 cost time: 8.413973331451416
Epoch: 23, Steps: 266 Train Loss: 3.2106 (Forecasting Loss:0.1468 + XiCon Loss:3.0637 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
Validation loss decreased (0.144335 --> 0.144312).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2388134
	speed: 0.0334s/iter; left time: 680.5524s
	iters: 200, epoch: 24 | loss: 3.2553885
	speed: 0.0334s/iter; left time: 677.6927s
Epoch: 24 cost time: 8.793949604034424
Epoch: 24, Steps: 266 Train Loss: 3.2105 (Forecasting Loss:0.1468 + XiCon Loss:3.0637 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
Validation loss decreased (0.144312 --> 0.144275).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2546947
	speed: 0.0334s/iter; left time: 671.3240s
	iters: 200, epoch: 25 | loss: 3.2010920
	speed: 0.0322s/iter; left time: 644.4365s
Epoch: 25 cost time: 8.64561915397644
Epoch: 25, Steps: 266 Train Loss: 3.2087 (Forecasting Loss:0.1468 + XiCon Loss:3.0618 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2112892
	speed: 0.0332s/iter; left time: 659.2730s
	iters: 200, epoch: 26 | loss: 3.2207785
	speed: 0.0314s/iter; left time: 620.7804s
Epoch: 26 cost time: 8.545180559158325
Epoch: 26, Steps: 266 Train Loss: 3.2090 (Forecasting Loss:0.1468 + XiCon Loss:3.0621 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
Validation loss decreased (0.144275 --> 0.144261).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1458781
	speed: 0.0337s/iter; left time: 659.5586s
	iters: 200, epoch: 27 | loss: 3.1910415
	speed: 0.0301s/iter; left time: 587.2506s
Epoch: 27 cost time: 8.427744626998901
Epoch: 27, Steps: 266 Train Loss: 3.2090 (Forecasting Loss:0.1467 + XiCon Loss:3.0623 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1518216
	speed: 0.0336s/iter; left time: 648.8282s
	iters: 200, epoch: 28 | loss: 3.1737239
	speed: 0.0315s/iter; left time: 604.5084s
Epoch: 28 cost time: 8.584685802459717
Epoch: 28, Steps: 266 Train Loss: 3.2089 (Forecasting Loss:0.1468 + XiCon Loss:3.0620 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2426383
	speed: 0.0336s/iter; left time: 639.7942s
	iters: 200, epoch: 29 | loss: 3.2032826
	speed: 0.0320s/iter; left time: 605.7922s
Epoch: 29 cost time: 8.653603792190552
Epoch: 29, Steps: 266 Train Loss: 3.2119 (Forecasting Loss:0.1469 + XiCon Loss:3.0650 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2209136
	speed: 0.0331s/iter; left time: 621.4286s
	iters: 200, epoch: 30 | loss: 3.2032087
	speed: 0.0310s/iter; left time: 580.0536s
Epoch: 30 cost time: 8.430950164794922
Epoch: 30, Steps: 266 Train Loss: 3.2097 (Forecasting Loss:0.1468 + XiCon Loss:3.0629 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1825318
	speed: 0.0328s/iter; left time: 607.4220s
	iters: 200, epoch: 31 | loss: 3.2001517
	speed: 0.0306s/iter; left time: 564.4160s
Epoch: 31 cost time: 8.420092582702637
Epoch: 31, Steps: 266 Train Loss: 3.2108 (Forecasting Loss:0.1468 + XiCon Loss:3.0640 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1682966
	speed: 0.0336s/iter; left time: 613.3451s
	iters: 200, epoch: 32 | loss: 3.2646687
	speed: 0.0311s/iter; left time: 563.9859s
Epoch: 32 cost time: 8.582973957061768
Epoch: 32, Steps: 266 Train Loss: 3.2099 (Forecasting Loss:0.1468 + XiCon Loss:3.0631 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.2064655
	speed: 0.0339s/iter; left time: 609.8303s
	iters: 200, epoch: 33 | loss: 3.2408383
	speed: 0.0321s/iter; left time: 574.2253s
Epoch: 33 cost time: 8.717260837554932
Epoch: 33, Steps: 266 Train Loss: 3.2091 (Forecasting Loss:0.1468 + XiCon Loss:3.0623 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.2227769
	speed: 0.0341s/iter; left time: 604.1702s
	iters: 200, epoch: 34 | loss: 3.1990900
	speed: 0.0318s/iter; left time: 559.8928s
Epoch: 34 cost time: 8.675443410873413
Epoch: 34, Steps: 266 Train Loss: 3.2071 (Forecasting Loss:0.1469 + XiCon Loss:3.0602 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 3.2309175
	speed: 0.0336s/iter; left time: 586.5929s
	iters: 200, epoch: 35 | loss: 3.1768062
	speed: 0.0316s/iter; left time: 549.0820s
Epoch: 35 cost time: 8.554338216781616
Epoch: 35, Steps: 266 Train Loss: 3.2151 (Forecasting Loss:0.1468 + XiCon Loss:3.0683 x Lambda(1.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 3.1870856
	speed: 0.0339s/iter; left time: 582.7805s
	iters: 200, epoch: 36 | loss: 3.2306480
	speed: 0.0321s/iter; left time: 547.8360s
Epoch: 36 cost time: 8.686392068862915
Epoch: 36, Steps: 266 Train Loss: 3.2122 (Forecasting Loss:0.1469 + XiCon Loss:3.0653 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06467822939157486, mae:0.18430908024311066, mape:0.4488115906715393, mspe:8.150145530700684 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5079
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.4880075
	speed: 0.0351s/iter; left time: 929.9482s
	iters: 200, epoch: 1 | loss: 3.3963544
	speed: 0.0314s/iter; left time: 828.1364s
Epoch: 1 cost time: 8.742172479629517
Epoch: 1, Steps: 266 Train Loss: 3.4665 (Forecasting Loss:0.1899 + XiCon Loss:3.2766 x Lambda(1.0)), Vali MSE Loss: 0.1609 Test MSE Loss: 0.1376
Validation loss decreased (inf --> 0.160949).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3143103
	speed: 0.0334s/iter; left time: 875.9782s
	iters: 200, epoch: 2 | loss: 3.2765796
	speed: 0.0313s/iter; left time: 818.1246s
Epoch: 2 cost time: 8.532430648803711
Epoch: 2, Steps: 266 Train Loss: 3.2930 (Forecasting Loss:0.1588 + XiCon Loss:3.1341 x Lambda(1.0)), Vali MSE Loss: 0.1500 Test MSE Loss: 0.1315
Validation loss decreased (0.160949 --> 0.150049).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1902430
	speed: 0.0337s/iter; left time: 874.1864s
	iters: 200, epoch: 3 | loss: 3.1670575
	speed: 0.0314s/iter; left time: 813.3998s
Epoch: 3 cost time: 8.557602882385254
Epoch: 3, Steps: 266 Train Loss: 3.2010 (Forecasting Loss:0.1522 + XiCon Loss:3.0489 x Lambda(1.0)), Vali MSE Loss: 0.1478 Test MSE Loss: 0.1263
Validation loss decreased (0.150049 --> 0.147756).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2102153
	speed: 0.0330s/iter; left time: 849.3952s
	iters: 200, epoch: 4 | loss: 3.1492105
	speed: 0.0304s/iter; left time: 777.5751s
Epoch: 4 cost time: 8.350987195968628
Epoch: 4, Steps: 266 Train Loss: 3.1927 (Forecasting Loss:0.1494 + XiCon Loss:3.0433 x Lambda(1.0)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.1265
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2611661
	speed: 0.0327s/iter; left time: 830.5766s
	iters: 200, epoch: 5 | loss: 3.1578262
	speed: 0.0315s/iter; left time: 799.3248s
Epoch: 5 cost time: 8.576722860336304
Epoch: 5, Steps: 266 Train Loss: 3.1883 (Forecasting Loss:0.1480 + XiCon Loss:3.0404 x Lambda(1.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.1249
Validation loss decreased (0.147756 --> 0.146463).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2034631
	speed: 0.0342s/iter; left time: 859.8886s
	iters: 200, epoch: 6 | loss: 3.2358263
	speed: 0.0328s/iter; left time: 823.4506s
Epoch: 6 cost time: 8.912676095962524
Epoch: 6, Steps: 266 Train Loss: 3.1851 (Forecasting Loss:0.1476 + XiCon Loss:3.0374 x Lambda(1.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1250
Validation loss decreased (0.146463 --> 0.144059).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2042947
	speed: 0.0336s/iter; left time: 836.3756s
	iters: 200, epoch: 7 | loss: 3.2109330
	speed: 0.0313s/iter; left time: 775.5226s
Epoch: 7 cost time: 8.597190856933594
Epoch: 7, Steps: 266 Train Loss: 3.1890 (Forecasting Loss:0.1472 + XiCon Loss:3.0418 x Lambda(1.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1671422
	speed: 0.0337s/iter; left time: 830.7673s
	iters: 200, epoch: 8 | loss: 3.1937044
	speed: 0.0316s/iter; left time: 774.8492s
Epoch: 8 cost time: 8.57522964477539
Epoch: 8, Steps: 266 Train Loss: 3.1890 (Forecasting Loss:0.1470 + XiCon Loss:3.0419 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1246
Validation loss decreased (0.144059 --> 0.143986).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1482236
	speed: 0.0341s/iter; left time: 831.5295s
	iters: 200, epoch: 9 | loss: 3.2706840
	speed: 0.0314s/iter; left time: 761.1419s
Epoch: 9 cost time: 8.64812159538269
Epoch: 9, Steps: 266 Train Loss: 3.1861 (Forecasting Loss:0.1470 + XiCon Loss:3.0391 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1991303
	speed: 0.0337s/iter; left time: 811.7498s
	iters: 200, epoch: 10 | loss: 3.1919014
	speed: 0.0320s/iter; left time: 769.0012s
Epoch: 10 cost time: 8.69317102432251
Epoch: 10, Steps: 266 Train Loss: 3.1854 (Forecasting Loss:0.1469 + XiCon Loss:3.0385 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1948407
	speed: 0.0343s/iter; left time: 817.4691s
	iters: 200, epoch: 11 | loss: 3.1758966
	speed: 0.0317s/iter; left time: 753.2397s
Epoch: 11 cost time: 8.698015689849854
Epoch: 11, Steps: 266 Train Loss: 3.1847 (Forecasting Loss:0.1469 + XiCon Loss:3.0378 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1958714
	speed: 0.0338s/iter; left time: 796.2498s
	iters: 200, epoch: 12 | loss: 3.2150764
	speed: 0.0313s/iter; left time: 735.1671s
Epoch: 12 cost time: 8.621687889099121
Epoch: 12, Steps: 266 Train Loss: 3.1867 (Forecasting Loss:0.1469 + XiCon Loss:3.0398 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2168839
	speed: 0.0326s/iter; left time: 760.0186s
	iters: 200, epoch: 13 | loss: 3.1709855
	speed: 0.0302s/iter; left time: 700.9090s
Epoch: 13 cost time: 8.259482383728027
Epoch: 13, Steps: 266 Train Loss: 3.1833 (Forecasting Loss:0.1468 + XiCon Loss:3.0364 x Lambda(1.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2132621
	speed: 0.0330s/iter; left time: 760.8649s
	iters: 200, epoch: 14 | loss: 3.1830192
	speed: 0.0321s/iter; left time: 735.5092s
Epoch: 14 cost time: 8.579181671142578
Epoch: 14, Steps: 266 Train Loss: 3.1846 (Forecasting Loss:0.1469 + XiCon Loss:3.0378 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2542181
	speed: 0.0344s/iter; left time: 784.0515s
	iters: 200, epoch: 15 | loss: 3.1560545
	speed: 0.0333s/iter; left time: 755.3951s
Epoch: 15 cost time: 8.930378675460815
Epoch: 15, Steps: 266 Train Loss: 3.1855 (Forecasting Loss:0.1468 + XiCon Loss:3.0386 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1897175
	speed: 0.0335s/iter; left time: 754.9205s
	iters: 200, epoch: 16 | loss: 3.2156413
	speed: 0.0319s/iter; left time: 715.8634s
Epoch: 16 cost time: 8.580631017684937
Epoch: 16, Steps: 266 Train Loss: 3.1868 (Forecasting Loss:0.1469 + XiCon Loss:3.0399 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1689670
	speed: 0.0334s/iter; left time: 743.4172s
	iters: 200, epoch: 17 | loss: 3.1611614
	speed: 0.0314s/iter; left time: 694.4778s
Epoch: 17 cost time: 8.492215633392334
Epoch: 17, Steps: 266 Train Loss: 3.1868 (Forecasting Loss:0.1469 + XiCon Loss:3.0399 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2146425
	speed: 0.0323s/iter; left time: 709.7721s
	iters: 200, epoch: 18 | loss: 3.1357830
	speed: 0.0308s/iter; left time: 673.6186s
Epoch: 18 cost time: 8.282230854034424
Epoch: 18, Steps: 266 Train Loss: 3.1889 (Forecasting Loss:0.1468 + XiCon Loss:3.0420 x Lambda(1.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06465455144643784, mae:0.1845128834247589, mape:0.4487544894218445, mspe:8.087915420532227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0649+-0.00030, MAE:0.1848+-0.00102, MAPE:0.4496+-0.00191, MSPE:8.2020+-0.14247, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7464
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5879288
	speed: 0.0377s/iter; left time: 994.2786s
	iters: 200, epoch: 1 | loss: 3.5931535
	speed: 0.0334s/iter; left time: 878.4233s
Epoch: 1 cost time: 9.33874773979187
Epoch: 1, Steps: 265 Train Loss: 3.5816 (Forecasting Loss:0.3531 + XiCon Loss:3.2284 x Lambda(1.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2776
Validation loss decreased (inf --> 0.336487).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3889594
	speed: 0.0345s/iter; left time: 900.5749s
	iters: 200, epoch: 2 | loss: 3.3900828
	speed: 0.0318s/iter; left time: 827.3667s
Epoch: 2 cost time: 8.71119999885559
Epoch: 2, Steps: 265 Train Loss: 3.4049 (Forecasting Loss:0.2415 + XiCon Loss:3.1635 x Lambda(1.0)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1739
Validation loss decreased (0.336487 --> 0.216745).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2280600
	speed: 0.0335s/iter; left time: 866.9697s
	iters: 200, epoch: 3 | loss: 3.2531981
	speed: 0.0312s/iter; left time: 804.2606s
Epoch: 3 cost time: 8.583746671676636
Epoch: 3, Steps: 265 Train Loss: 3.2749 (Forecasting Loss:0.2144 + XiCon Loss:3.0606 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1708
Validation loss decreased (0.216745 --> 0.211693).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2035558
	speed: 0.0333s/iter; left time: 852.9546s
	iters: 200, epoch: 4 | loss: 3.2551472
	speed: 0.0311s/iter; left time: 794.1761s
Epoch: 4 cost time: 8.531439781188965
Epoch: 4, Steps: 265 Train Loss: 3.2393 (Forecasting Loss:0.2110 + XiCon Loss:3.0283 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1699
Validation loss decreased (0.211693 --> 0.210096).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2233000
	speed: 0.0347s/iter; left time: 878.3894s
	iters: 200, epoch: 5 | loss: 3.2548788
	speed: 0.0329s/iter; left time: 831.2352s
Epoch: 5 cost time: 8.831492185592651
Epoch: 5, Steps: 265 Train Loss: 3.2260 (Forecasting Loss:0.2097 + XiCon Loss:3.0163 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1696
Validation loss decreased (0.210096 --> 0.209200).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2657638
	speed: 0.0332s/iter; left time: 833.5124s
	iters: 200, epoch: 6 | loss: 3.1724527
	speed: 0.0317s/iter; left time: 792.0560s
Epoch: 6 cost time: 8.621687173843384
Epoch: 6, Steps: 265 Train Loss: 3.2239 (Forecasting Loss:0.2091 + XiCon Loss:3.0147 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1694
Validation loss decreased (0.209200 --> 0.209054).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2323933
	speed: 0.0339s/iter; left time: 841.8677s
	iters: 200, epoch: 7 | loss: 3.2647378
	speed: 0.0316s/iter; left time: 781.8747s
Epoch: 7 cost time: 8.61377477645874
Epoch: 7, Steps: 265 Train Loss: 3.2222 (Forecasting Loss:0.2090 + XiCon Loss:3.0132 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1693
Validation loss decreased (0.209054 --> 0.209003).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2404413
	speed: 0.0331s/iter; left time: 812.8645s
	iters: 200, epoch: 8 | loss: 3.2396619
	speed: 0.0310s/iter; left time: 758.8137s
Epoch: 8 cost time: 8.531864166259766
Epoch: 8, Steps: 265 Train Loss: 3.2205 (Forecasting Loss:0.2088 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
Validation loss decreased (0.209003 --> 0.208849).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2187564
	speed: 0.0339s/iter; left time: 822.1230s
	iters: 200, epoch: 9 | loss: 3.2240150
	speed: 0.0317s/iter; left time: 765.3503s
Epoch: 9 cost time: 8.690826654434204
Epoch: 9, Steps: 265 Train Loss: 3.2212 (Forecasting Loss:0.2087 + XiCon Loss:3.0126 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2469931
	speed: 0.0342s/iter; left time: 820.5234s
	iters: 200, epoch: 10 | loss: 3.2171321
	speed: 0.0317s/iter; left time: 757.2609s
Epoch: 10 cost time: 8.62724256515503
Epoch: 10, Steps: 265 Train Loss: 3.2178 (Forecasting Loss:0.2087 + XiCon Loss:3.0091 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1692
Validation loss decreased (0.208849 --> 0.208698).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2169123
	speed: 0.0336s/iter; left time: 798.9885s
	iters: 200, epoch: 11 | loss: 3.1911726
	speed: 0.0323s/iter; left time: 762.8627s
Epoch: 11 cost time: 8.725717067718506
Epoch: 11, Steps: 265 Train Loss: 3.2214 (Forecasting Loss:0.2086 + XiCon Loss:3.0127 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2312133
	speed: 0.0338s/iter; left time: 794.6954s
	iters: 200, epoch: 12 | loss: 3.2275798
	speed: 0.0316s/iter; left time: 738.7665s
Epoch: 12 cost time: 8.592413425445557
Epoch: 12, Steps: 265 Train Loss: 3.2207 (Forecasting Loss:0.2086 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2257619
	speed: 0.0335s/iter; left time: 778.5256s
	iters: 200, epoch: 13 | loss: 3.2032180
	speed: 0.0328s/iter; left time: 757.5079s
Epoch: 13 cost time: 8.690685749053955
Epoch: 13, Steps: 265 Train Loss: 3.2191 (Forecasting Loss:0.2086 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2146742
	speed: 0.0364s/iter; left time: 835.9601s
	iters: 200, epoch: 14 | loss: 3.2411585
	speed: 0.0332s/iter; left time: 759.1142s
Epoch: 14 cost time: 9.103304147720337
Epoch: 14, Steps: 265 Train Loss: 3.2191 (Forecasting Loss:0.2086 + XiCon Loss:3.0104 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2192147
	speed: 0.0346s/iter; left time: 785.6492s
	iters: 200, epoch: 15 | loss: 3.2253757
	speed: 0.0321s/iter; left time: 725.9296s
Epoch: 15 cost time: 8.713761806488037
Epoch: 15, Steps: 265 Train Loss: 3.2190 (Forecasting Loss:0.2085 + XiCon Loss:3.0105 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2487133
	speed: 0.0347s/iter; left time: 778.8912s
	iters: 200, epoch: 16 | loss: 3.2404106
	speed: 0.0323s/iter; left time: 722.0794s
Epoch: 16 cost time: 8.75562858581543
Epoch: 16, Steps: 265 Train Loss: 3.2211 (Forecasting Loss:0.2086 + XiCon Loss:3.0125 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1692
Validation loss decreased (0.208698 --> 0.208629).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2559299
	speed: 0.0337s/iter; left time: 746.2852s
	iters: 200, epoch: 17 | loss: 3.2627504
	speed: 0.0317s/iter; left time: 698.6880s
Epoch: 17 cost time: 8.587867736816406
Epoch: 17, Steps: 265 Train Loss: 3.2194 (Forecasting Loss:0.2086 + XiCon Loss:3.0108 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2597659
	speed: 0.0340s/iter; left time: 744.4678s
	iters: 200, epoch: 18 | loss: 3.2539299
	speed: 0.0314s/iter; left time: 685.1146s
Epoch: 18 cost time: 8.57473373413086
Epoch: 18, Steps: 265 Train Loss: 3.2178 (Forecasting Loss:0.2086 + XiCon Loss:3.0093 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2098467
	speed: 0.0331s/iter; left time: 715.0914s
	iters: 200, epoch: 19 | loss: 3.2204335
	speed: 0.0318s/iter; left time: 684.9872s
Epoch: 19 cost time: 8.663291931152344
Epoch: 19, Steps: 265 Train Loss: 3.2190 (Forecasting Loss:0.2086 + XiCon Loss:3.0105 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.1682558
	speed: 0.0333s/iter; left time: 710.7282s
	iters: 200, epoch: 20 | loss: 3.2226658
	speed: 0.0320s/iter; left time: 680.6032s
Epoch: 20 cost time: 8.601205587387085
Epoch: 20, Steps: 265 Train Loss: 3.2183 (Forecasting Loss:0.2086 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2441392
	speed: 0.0335s/iter; left time: 707.0841s
	iters: 200, epoch: 21 | loss: 3.1989563
	speed: 0.0318s/iter; left time: 667.3411s
Epoch: 21 cost time: 8.647475242614746
Epoch: 21, Steps: 265 Train Loss: 3.2191 (Forecasting Loss:0.2085 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2420311
	speed: 0.0334s/iter; left time: 696.6140s
	iters: 200, epoch: 22 | loss: 3.2279210
	speed: 0.0321s/iter; left time: 665.6602s
Epoch: 22 cost time: 8.578436374664307
Epoch: 22, Steps: 265 Train Loss: 3.2187 (Forecasting Loss:0.2084 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2500598
	speed: 0.0330s/iter; left time: 679.3047s
	iters: 200, epoch: 23 | loss: 3.1988604
	speed: 0.0312s/iter; left time: 637.7062s
Epoch: 23 cost time: 8.505722045898438
Epoch: 23, Steps: 265 Train Loss: 3.2188 (Forecasting Loss:0.2086 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2220955
	speed: 0.0339s/iter; left time: 687.9533s
	iters: 200, epoch: 24 | loss: 3.2282705
	speed: 0.0335s/iter; left time: 677.3221s
Epoch: 24 cost time: 8.936938524246216
Epoch: 24, Steps: 265 Train Loss: 3.2182 (Forecasting Loss:0.2087 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2257712
	speed: 0.0337s/iter; left time: 676.2086s
	iters: 200, epoch: 25 | loss: 3.2037048
	speed: 0.0314s/iter; left time: 625.7879s
Epoch: 25 cost time: 8.582369565963745
Epoch: 25, Steps: 265 Train Loss: 3.2218 (Forecasting Loss:0.2086 + XiCon Loss:3.0131 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2107356
	speed: 0.0340s/iter; left time: 673.2819s
	iters: 200, epoch: 26 | loss: 3.2290399
	speed: 0.0318s/iter; left time: 626.4933s
Epoch: 26 cost time: 8.672155141830444
Epoch: 26, Steps: 265 Train Loss: 3.2201 (Forecasting Loss:0.2086 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09877974539995193, mae:0.23957210779190063, mape:0.568809986114502, mspe:11.793777465820312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7346
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5639777
	speed: 0.0363s/iter; left time: 958.9903s
	iters: 200, epoch: 1 | loss: 3.6198504
	speed: 0.0332s/iter; left time: 872.2560s
Epoch: 1 cost time: 9.109646558761597
Epoch: 1, Steps: 265 Train Loss: 3.6042 (Forecasting Loss:0.3608 + XiCon Loss:3.2434 x Lambda(1.0)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2830
Validation loss decreased (inf --> 0.335581).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3991249
	speed: 0.0346s/iter; left time: 904.4202s
	iters: 200, epoch: 2 | loss: 3.3584447
	speed: 0.0323s/iter; left time: 841.3679s
Epoch: 2 cost time: 8.772838115692139
Epoch: 2, Steps: 265 Train Loss: 3.4098 (Forecasting Loss:0.2416 + XiCon Loss:3.1682 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1723
Validation loss decreased (0.335581 --> 0.219110).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2474830
	speed: 0.0337s/iter; left time: 872.3605s
	iters: 200, epoch: 3 | loss: 3.2460911
	speed: 0.0317s/iter; left time: 815.7036s
Epoch: 3 cost time: 8.68049168586731
Epoch: 3, Steps: 265 Train Loss: 3.2679 (Forecasting Loss:0.2135 + XiCon Loss:3.0544 x Lambda(1.0)), Vali MSE Loss: 0.2148 Test MSE Loss: 0.1691
Validation loss decreased (0.219110 --> 0.214801).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2217555
	speed: 0.0328s/iter; left time: 840.1800s
	iters: 200, epoch: 4 | loss: 3.2275357
	speed: 0.0659s/iter; left time: 1681.4350s
Epoch: 4 cost time: 15.433658123016357
Epoch: 4, Steps: 265 Train Loss: 3.2378 (Forecasting Loss:0.2103 + XiCon Loss:3.0275 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1676
Validation loss decreased (0.214801 --> 0.211940).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1852503
	speed: 0.0959s/iter; left time: 2429.7281s
	iters: 200, epoch: 5 | loss: 3.2229471
	speed: 0.0966s/iter; left time: 2439.2883s
Epoch: 5 cost time: 25.222652196884155
Epoch: 5, Steps: 265 Train Loss: 3.2261 (Forecasting Loss:0.2093 + XiCon Loss:3.0168 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1675
Validation loss decreased (0.211940 --> 0.211355).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2375603
	speed: 0.0840s/iter; left time: 2105.5525s
	iters: 200, epoch: 6 | loss: 3.1956384
	speed: 0.0707s/iter; left time: 1765.7523s
Epoch: 6 cost time: 19.94236159324646
Epoch: 6, Steps: 265 Train Loss: 3.2216 (Forecasting Loss:0.2087 + XiCon Loss:3.0129 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1671
Validation loss decreased (0.211355 --> 0.210833).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2136340
	speed: 0.0622s/iter; left time: 1542.4551s
	iters: 200, epoch: 7 | loss: 3.1923604
	speed: 0.0395s/iter; left time: 975.9835s
Epoch: 7 cost time: 12.727385759353638
Epoch: 7, Steps: 265 Train Loss: 3.2202 (Forecasting Loss:0.2085 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
Validation loss decreased (0.210833 --> 0.210441).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2635183
	speed: 0.0342s/iter; left time: 839.8258s
	iters: 200, epoch: 8 | loss: 3.2118216
	speed: 0.0312s/iter; left time: 762.8341s
Epoch: 8 cost time: 8.607878684997559
Epoch: 8, Steps: 265 Train Loss: 3.2180 (Forecasting Loss:0.2084 + XiCon Loss:3.0096 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1942980
	speed: 0.0319s/iter; left time: 775.4615s
	iters: 200, epoch: 9 | loss: 3.1781552
	speed: 0.0303s/iter; left time: 732.0925s
Epoch: 9 cost time: 8.230810403823853
Epoch: 9, Steps: 265 Train Loss: 3.2180 (Forecasting Loss:0.2082 + XiCon Loss:3.0099 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1669
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1748025
	speed: 0.0331s/iter; left time: 793.7866s
	iters: 200, epoch: 10 | loss: 3.1993842
	speed: 0.0299s/iter; left time: 715.1057s
Epoch: 10 cost time: 8.287575721740723
Epoch: 10, Steps: 265 Train Loss: 3.2178 (Forecasting Loss:0.2082 + XiCon Loss:3.0095 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1669
Validation loss decreased (0.210441 --> 0.210179).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2033553
	speed: 0.0330s/iter; left time: 784.6012s
	iters: 200, epoch: 11 | loss: 3.1917136
	speed: 0.0302s/iter; left time: 714.7967s
Epoch: 11 cost time: 8.353356122970581
Epoch: 11, Steps: 265 Train Loss: 3.2186 (Forecasting Loss:0.2080 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1828184
	speed: 0.0307s/iter; left time: 721.2476s
	iters: 200, epoch: 12 | loss: 3.1862276
	speed: 0.0281s/iter; left time: 658.1391s
Epoch: 12 cost time: 7.821179389953613
Epoch: 12, Steps: 265 Train Loss: 3.2167 (Forecasting Loss:0.2082 + XiCon Loss:3.0085 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1669
Validation loss decreased (0.210179 --> 0.210116).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2310703
	speed: 0.0312s/iter; left time: 723.3589s
	iters: 200, epoch: 13 | loss: 3.2088468
	speed: 0.0279s/iter; left time: 644.9407s
Epoch: 13 cost time: 7.782594203948975
Epoch: 13, Steps: 265 Train Loss: 3.2179 (Forecasting Loss:0.2082 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2365468
	speed: 0.0336s/iter; left time: 771.0176s
	iters: 200, epoch: 14 | loss: 3.2256765
	speed: 0.0316s/iter; left time: 721.5615s
Epoch: 14 cost time: 8.509528636932373
Epoch: 14, Steps: 265 Train Loss: 3.2187 (Forecasting Loss:0.2081 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2370949
	speed: 0.0335s/iter; left time: 760.1812s
	iters: 200, epoch: 15 | loss: 3.2182114
	speed: 0.0315s/iter; left time: 711.9966s
Epoch: 15 cost time: 8.55834150314331
Epoch: 15, Steps: 265 Train Loss: 3.2175 (Forecasting Loss:0.2082 + XiCon Loss:3.0093 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2064123
	speed: 0.0338s/iter; left time: 758.9599s
	iters: 200, epoch: 16 | loss: 3.2045624
	speed: 0.0330s/iter; left time: 737.4838s
Epoch: 16 cost time: 8.898720502853394
Epoch: 16, Steps: 265 Train Loss: 3.2163 (Forecasting Loss:0.2081 + XiCon Loss:3.0082 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1669
Validation loss decreased (0.210116 --> 0.210076).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2316637
	speed: 0.0345s/iter; left time: 764.5856s
	iters: 200, epoch: 17 | loss: 3.2417362
	speed: 0.0313s/iter; left time: 690.0080s
Epoch: 17 cost time: 8.588364124298096
Epoch: 17, Steps: 265 Train Loss: 3.2189 (Forecasting Loss:0.2082 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2251434
	speed: 0.0341s/iter; left time: 745.9762s
	iters: 200, epoch: 18 | loss: 3.2169566
	speed: 0.0319s/iter; left time: 694.9830s
Epoch: 18 cost time: 8.679852724075317
Epoch: 18, Steps: 265 Train Loss: 3.2162 (Forecasting Loss:0.2082 + XiCon Loss:3.0079 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2467973
	speed: 0.0342s/iter; left time: 739.0492s
	iters: 200, epoch: 19 | loss: 3.2260175
	speed: 0.0312s/iter; left time: 672.2535s
Epoch: 19 cost time: 8.613093614578247
Epoch: 19, Steps: 265 Train Loss: 3.2173 (Forecasting Loss:0.2082 + XiCon Loss:3.0091 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1669
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2395258
	speed: 0.0334s/iter; left time: 714.3963s
	iters: 200, epoch: 20 | loss: 3.1711237
	speed: 0.0319s/iter; left time: 678.4471s
Epoch: 20 cost time: 8.563799619674683
Epoch: 20, Steps: 265 Train Loss: 3.2178 (Forecasting Loss:0.2081 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1669
Validation loss decreased (0.210076 --> 0.210034).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2094915
	speed: 0.0342s/iter; left time: 721.8727s
	iters: 200, epoch: 21 | loss: 3.2227812
	speed: 0.0334s/iter; left time: 701.3114s
Epoch: 21 cost time: 8.856984853744507
Epoch: 21, Steps: 265 Train Loss: 3.2177 (Forecasting Loss:0.2081 + XiCon Loss:3.0096 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2666054
	speed: 0.0348s/iter; left time: 724.1896s
	iters: 200, epoch: 22 | loss: 3.1832867
	speed: 0.0315s/iter; left time: 653.3569s
Epoch: 22 cost time: 8.700206518173218
Epoch: 22, Steps: 265 Train Loss: 3.2178 (Forecasting Loss:0.2081 + XiCon Loss:3.0097 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1669
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2704716
	speed: 0.0329s/iter; left time: 677.4500s
	iters: 200, epoch: 23 | loss: 3.2307985
	speed: 0.0317s/iter; left time: 648.3371s
Epoch: 23 cost time: 8.542050123214722
Epoch: 23, Steps: 265 Train Loss: 3.2158 (Forecasting Loss:0.2081 + XiCon Loss:3.0077 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1669
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2430789
	speed: 0.0337s/iter; left time: 684.1523s
	iters: 200, epoch: 24 | loss: 3.1996775
	speed: 0.0322s/iter; left time: 650.3470s
Epoch: 24 cost time: 8.706008911132812
Epoch: 24, Steps: 265 Train Loss: 3.2189 (Forecasting Loss:0.2082 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1669
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2389510
	speed: 0.0344s/iter; left time: 689.3637s
	iters: 200, epoch: 25 | loss: 3.2021732
	speed: 0.0324s/iter; left time: 647.0403s
Epoch: 25 cost time: 8.818929433822632
Epoch: 25, Steps: 265 Train Loss: 3.2176 (Forecasting Loss:0.2080 + XiCon Loss:3.0096 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2196202
	speed: 0.0344s/iter; left time: 680.1628s
	iters: 200, epoch: 26 | loss: 3.2273986
	speed: 0.0323s/iter; left time: 634.6572s
Epoch: 26 cost time: 8.802871704101562
Epoch: 26, Steps: 265 Train Loss: 3.2191 (Forecasting Loss:0.2082 + XiCon Loss:3.0109 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1669
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.2264736
	speed: 0.0335s/iter; left time: 653.8950s
	iters: 200, epoch: 27 | loss: 3.2238295
	speed: 0.0320s/iter; left time: 620.6216s
Epoch: 27 cost time: 8.560950756072998
Epoch: 27, Steps: 265 Train Loss: 3.2190 (Forecasting Loss:0.2082 + XiCon Loss:3.0109 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1669
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.2129750
	speed: 0.0335s/iter; left time: 644.3299s
	iters: 200, epoch: 28 | loss: 3.1864321
	speed: 0.0320s/iter; left time: 612.1051s
Epoch: 28 cost time: 8.574540138244629
Epoch: 28, Steps: 265 Train Loss: 3.2169 (Forecasting Loss:0.2081 + XiCon Loss:3.0088 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1669
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.2420304
	speed: 0.0335s/iter; left time: 636.7985s
	iters: 200, epoch: 29 | loss: 3.1689231
	speed: 0.0316s/iter; left time: 596.8510s
Epoch: 29 cost time: 8.546927452087402
Epoch: 29, Steps: 265 Train Loss: 3.2154 (Forecasting Loss:0.2082 + XiCon Loss:3.0072 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1669
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.2103958
	speed: 0.0339s/iter; left time: 634.7764s
	iters: 200, epoch: 30 | loss: 3.2212379
	speed: 0.0325s/iter; left time: 604.6484s
Epoch: 30 cost time: 8.891862869262695
Epoch: 30, Steps: 265 Train Loss: 3.2179 (Forecasting Loss:0.2079 + XiCon Loss:3.0099 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1669
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09694953262805939, mae:0.23685820400714874, mape:0.5692375302314758, mspe:12.117971420288086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.4700
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5473130
	speed: 0.0346s/iter; left time: 912.4728s
	iters: 200, epoch: 1 | loss: 3.5147676
	speed: 0.0320s/iter; left time: 840.3435s
Epoch: 1 cost time: 8.791067123413086
Epoch: 1, Steps: 265 Train Loss: 3.5726 (Forecasting Loss:0.3468 + XiCon Loss:3.2257 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2714
Validation loss decreased (inf --> 0.325132).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3824995
	speed: 0.0340s/iter; left time: 888.4846s
	iters: 200, epoch: 2 | loss: 3.3276494
	speed: 0.0313s/iter; left time: 814.2383s
Epoch: 2 cost time: 8.59580135345459
Epoch: 2, Steps: 265 Train Loss: 3.3834 (Forecasting Loss:0.2398 + XiCon Loss:3.1436 x Lambda(1.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1733
Validation loss decreased (0.325132 --> 0.220720).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3152316
	speed: 0.0343s/iter; left time: 888.4676s
	iters: 200, epoch: 3 | loss: 3.2459199
	speed: 0.0332s/iter; left time: 856.0360s
Epoch: 3 cost time: 8.936275720596313
Epoch: 3, Steps: 265 Train Loss: 3.2604 (Forecasting Loss:0.2145 + XiCon Loss:3.0459 x Lambda(1.0)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1704
Validation loss decreased (0.220720 --> 0.216062).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2349803
	speed: 0.0345s/iter; left time: 882.9259s
	iters: 200, epoch: 4 | loss: 3.2104652
	speed: 0.0322s/iter; left time: 822.3208s
Epoch: 4 cost time: 8.743062019348145
Epoch: 4, Steps: 265 Train Loss: 3.2432 (Forecasting Loss:0.2111 + XiCon Loss:3.0321 x Lambda(1.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1696
Validation loss decreased (0.216062 --> 0.213980).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2273374
	speed: 0.0341s/iter; left time: 865.3451s
	iters: 200, epoch: 5 | loss: 3.2419348
	speed: 0.0313s/iter; left time: 791.0948s
Epoch: 5 cost time: 8.655137062072754
Epoch: 5, Steps: 265 Train Loss: 3.2349 (Forecasting Loss:0.2098 + XiCon Loss:3.0251 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1692
Validation loss decreased (0.213980 --> 0.213495).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2871332
	speed: 0.0329s/iter; left time: 825.4857s
	iters: 200, epoch: 6 | loss: 3.2560344
	speed: 0.0310s/iter; left time: 774.3659s
Epoch: 6 cost time: 8.406384944915771
Epoch: 6, Steps: 265 Train Loss: 3.2280 (Forecasting Loss:0.2091 + XiCon Loss:3.0189 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1691
Validation loss decreased (0.213495 --> 0.212947).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2898817
	speed: 0.0341s/iter; left time: 846.8870s
	iters: 200, epoch: 7 | loss: 3.2384837
	speed: 0.0317s/iter; left time: 783.2767s
Epoch: 7 cost time: 8.705472946166992
Epoch: 7, Steps: 265 Train Loss: 3.2281 (Forecasting Loss:0.2087 + XiCon Loss:3.0194 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
Validation loss decreased (0.212947 --> 0.212605).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2057061
	speed: 0.0347s/iter; left time: 850.8652s
	iters: 200, epoch: 8 | loss: 3.1949253
	speed: 0.0321s/iter; left time: 785.8406s
Epoch: 8 cost time: 8.775312662124634
Epoch: 8, Steps: 265 Train Loss: 3.2263 (Forecasting Loss:0.2086 + XiCon Loss:3.0177 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1690
Validation loss decreased (0.212605 --> 0.212542).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2481847
	speed: 0.0338s/iter; left time: 820.5990s
	iters: 200, epoch: 9 | loss: 3.2079329
	speed: 0.0313s/iter; left time: 757.2568s
Epoch: 9 cost time: 8.562774896621704
Epoch: 9, Steps: 265 Train Loss: 3.2260 (Forecasting Loss:0.2086 + XiCon Loss:3.0174 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1690
Validation loss decreased (0.212542 --> 0.212504).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2275238
	speed: 0.0331s/iter; left time: 795.5289s
	iters: 200, epoch: 10 | loss: 3.1986561
	speed: 0.0317s/iter; left time: 758.5620s
Epoch: 10 cost time: 8.651386737823486
Epoch: 10, Steps: 265 Train Loss: 3.2252 (Forecasting Loss:0.2086 + XiCon Loss:3.0166 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2422500
	speed: 0.0335s/iter; left time: 794.5375s
	iters: 200, epoch: 11 | loss: 3.2020338
	speed: 0.0321s/iter; left time: 759.7455s
Epoch: 11 cost time: 8.541438579559326
Epoch: 11, Steps: 265 Train Loss: 3.2247 (Forecasting Loss:0.2085 + XiCon Loss:3.0161 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1657708
	speed: 0.0334s/iter; left time: 784.9043s
	iters: 200, epoch: 12 | loss: 3.2187994
	speed: 0.0322s/iter; left time: 752.0438s
Epoch: 12 cost time: 8.738609075546265
Epoch: 12, Steps: 265 Train Loss: 3.2246 (Forecasting Loss:0.2085 + XiCon Loss:3.0161 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1690
Validation loss decreased (0.212504 --> 0.212343).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2050281
	speed: 0.0339s/iter; left time: 787.3474s
	iters: 200, epoch: 13 | loss: 3.2498047
	speed: 0.0313s/iter; left time: 723.7990s
Epoch: 13 cost time: 8.638388633728027
Epoch: 13, Steps: 265 Train Loss: 3.2248 (Forecasting Loss:0.2086 + XiCon Loss:3.0163 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1809874
	speed: 0.0352s/iter; left time: 807.7860s
	iters: 200, epoch: 14 | loss: 3.1905034
	speed: 0.0319s/iter; left time: 730.1559s
Epoch: 14 cost time: 8.739415884017944
Epoch: 14, Steps: 265 Train Loss: 3.2245 (Forecasting Loss:0.2085 + XiCon Loss:3.0160 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2138278
	speed: 0.0337s/iter; left time: 764.8248s
	iters: 200, epoch: 15 | loss: 3.2512395
	speed: 0.0323s/iter; left time: 730.6476s
Epoch: 15 cost time: 8.676143407821655
Epoch: 15, Steps: 265 Train Loss: 3.2260 (Forecasting Loss:0.2085 + XiCon Loss:3.0174 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1690
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2194541
	speed: 0.0345s/iter; left time: 772.8972s
	iters: 200, epoch: 16 | loss: 3.2354431
	speed: 0.0325s/iter; left time: 726.6886s
Epoch: 16 cost time: 8.862490177154541
Epoch: 16, Steps: 265 Train Loss: 3.2254 (Forecasting Loss:0.2085 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1690
Validation loss decreased (0.212343 --> 0.212049).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2036068
	speed: 0.0343s/iter; left time: 759.3831s
	iters: 200, epoch: 17 | loss: 3.2129154
	speed: 0.0319s/iter; left time: 702.9733s
Epoch: 17 cost time: 8.734524726867676
Epoch: 17, Steps: 265 Train Loss: 3.2267 (Forecasting Loss:0.2085 + XiCon Loss:3.0182 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1914229
	speed: 0.0336s/iter; left time: 735.3175s
	iters: 200, epoch: 18 | loss: 3.2586277
	speed: 0.0321s/iter; left time: 699.1869s
Epoch: 18 cost time: 8.703373908996582
Epoch: 18, Steps: 265 Train Loss: 3.2247 (Forecasting Loss:0.2085 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2366533
	speed: 0.0337s/iter; left time: 728.0111s
	iters: 200, epoch: 19 | loss: 3.2269886
	speed: 0.0315s/iter; left time: 678.4552s
Epoch: 19 cost time: 8.62470555305481
Epoch: 19, Steps: 265 Train Loss: 3.2282 (Forecasting Loss:0.2085 + XiCon Loss:3.0197 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2436650
	speed: 0.0339s/iter; left time: 725.0461s
	iters: 200, epoch: 20 | loss: 3.2173052
	speed: 0.0315s/iter; left time: 669.5839s
Epoch: 20 cost time: 8.59425687789917
Epoch: 20, Steps: 265 Train Loss: 3.2250 (Forecasting Loss:0.2084 + XiCon Loss:3.0166 x Lambda(1.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1690
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2091305
	speed: 0.0347s/iter; left time: 731.3478s
	iters: 200, epoch: 21 | loss: 3.2310696
	speed: 0.0331s/iter; left time: 694.8612s
Epoch: 21 cost time: 8.92898964881897
Epoch: 21, Steps: 265 Train Loss: 3.2252 (Forecasting Loss:0.2085 + XiCon Loss:3.0167 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1690
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2521203
	speed: 0.0351s/iter; left time: 732.3847s
	iters: 200, epoch: 22 | loss: 3.1954086
	speed: 0.0320s/iter; left time: 663.6973s
Epoch: 22 cost time: 8.789666652679443
Epoch: 22, Steps: 265 Train Loss: 3.2260 (Forecasting Loss:0.2085 + XiCon Loss:3.0175 x Lambda(1.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1690
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.1920815
	speed: 0.0342s/iter; left time: 704.2272s
	iters: 200, epoch: 23 | loss: 3.1737607
	speed: 0.0317s/iter; left time: 649.8973s
Epoch: 23 cost time: 8.665618658065796
Epoch: 23, Steps: 265 Train Loss: 3.2254 (Forecasting Loss:0.2085 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1690
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2306783
	speed: 0.0339s/iter; left time: 687.5097s
	iters: 200, epoch: 24 | loss: 3.1856694
	speed: 0.0314s/iter; left time: 634.5635s
Epoch: 24 cost time: 8.557313442230225
Epoch: 24, Steps: 265 Train Loss: 3.2272 (Forecasting Loss:0.2085 + XiCon Loss:3.0187 x Lambda(1.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1690
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2267618
	speed: 0.0339s/iter; left time: 678.8909s
	iters: 200, epoch: 25 | loss: 3.2507300
	speed: 0.0311s/iter; left time: 619.2804s
Epoch: 25 cost time: 8.518556833267212
Epoch: 25, Steps: 265 Train Loss: 3.2254 (Forecasting Loss:0.2085 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1690
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2087321
	speed: 0.0339s/iter; left time: 671.1729s
	iters: 200, epoch: 26 | loss: 3.2297459
	speed: 0.0309s/iter; left time: 607.4190s
Epoch: 26 cost time: 8.541802644729614
Epoch: 26, Steps: 265 Train Loss: 3.2259 (Forecasting Loss:0.2085 + XiCon Loss:3.0174 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09920205920934677, mae:0.23869898915290833, mape:0.5713648796081543, mspe:11.975092887878418 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.7995
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.6194038
	speed: 0.0335s/iter; left time: 885.4846s
	iters: 200, epoch: 1 | loss: 3.5770023
	speed: 0.0320s/iter; left time: 841.4675s
Epoch: 1 cost time: 8.611772298812866
Epoch: 1, Steps: 265 Train Loss: 3.5990 (Forecasting Loss:0.3611 + XiCon Loss:3.2378 x Lambda(1.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2837
Validation loss decreased (inf --> 0.331493).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4206376
	speed: 0.0346s/iter; left time: 903.9068s
	iters: 200, epoch: 2 | loss: 3.2986152
	speed: 0.0333s/iter; left time: 866.1124s
Epoch: 2 cost time: 8.931105613708496
Epoch: 2, Steps: 265 Train Loss: 3.3874 (Forecasting Loss:0.2384 + XiCon Loss:3.1490 x Lambda(1.0)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1732
Validation loss decreased (0.331493 --> 0.221976).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.1980917
	speed: 0.0346s/iter; left time: 896.0215s
	iters: 200, epoch: 3 | loss: 3.2689321
	speed: 0.0317s/iter; left time: 818.1615s
Epoch: 3 cost time: 8.759114742279053
Epoch: 3, Steps: 265 Train Loss: 3.2536 (Forecasting Loss:0.2124 + XiCon Loss:3.0412 x Lambda(1.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1700
Validation loss decreased (0.221976 --> 0.214291).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2203002
	speed: 0.0338s/iter; left time: 866.3804s
	iters: 200, epoch: 4 | loss: 3.1678250
	speed: 0.0320s/iter; left time: 816.7825s
Epoch: 4 cost time: 8.610950946807861
Epoch: 4, Steps: 265 Train Loss: 3.2242 (Forecasting Loss:0.2100 + XiCon Loss:3.0142 x Lambda(1.0)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1686
Validation loss decreased (0.214291 --> 0.212065).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2205510
	speed: 0.0332s/iter; left time: 840.6068s
	iters: 200, epoch: 5 | loss: 3.2161198
	speed: 0.0318s/iter; left time: 803.4390s
Epoch: 5 cost time: 8.49110746383667
Epoch: 5, Steps: 265 Train Loss: 3.2165 (Forecasting Loss:0.2089 + XiCon Loss:3.0077 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
Validation loss decreased (0.212065 --> 0.210956).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1866195
	speed: 0.0343s/iter; left time: 860.8442s
	iters: 200, epoch: 6 | loss: 3.2137141
	speed: 0.0311s/iter; left time: 777.4369s
Epoch: 6 cost time: 8.546666622161865
Epoch: 6, Steps: 265 Train Loss: 3.2124 (Forecasting Loss:0.2081 + XiCon Loss:3.0043 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1686
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2068646
	speed: 0.0337s/iter; left time: 837.2311s
	iters: 200, epoch: 7 | loss: 3.2399974
	speed: 0.0332s/iter; left time: 821.0936s
Epoch: 7 cost time: 8.792324304580688
Epoch: 7, Steps: 265 Train Loss: 3.2107 (Forecasting Loss:0.2078 + XiCon Loss:3.0029 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
Validation loss decreased (0.210956 --> 0.210936).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1906371
	speed: 0.0352s/iter; left time: 863.1371s
	iters: 200, epoch: 8 | loss: 3.2003722
	speed: 0.0325s/iter; left time: 794.4059s
Epoch: 8 cost time: 8.896934270858765
Epoch: 8, Steps: 265 Train Loss: 3.2101 (Forecasting Loss:0.2079 + XiCon Loss:3.0022 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2073526
	speed: 0.0336s/iter; left time: 814.8280s
	iters: 200, epoch: 9 | loss: 3.2156460
	speed: 0.0314s/iter; left time: 758.9737s
Epoch: 9 cost time: 8.599952697753906
Epoch: 9, Steps: 265 Train Loss: 3.2101 (Forecasting Loss:0.2076 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2142704
	speed: 0.0337s/iter; left time: 809.8538s
	iters: 200, epoch: 10 | loss: 3.1927552
	speed: 0.0316s/iter; left time: 755.3350s
Epoch: 10 cost time: 8.623400926589966
Epoch: 10, Steps: 265 Train Loss: 3.2104 (Forecasting Loss:0.2076 + XiCon Loss:3.0028 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1888292
	speed: 0.0347s/iter; left time: 824.5651s
	iters: 200, epoch: 11 | loss: 3.2152708
	speed: 0.0309s/iter; left time: 730.4880s
Epoch: 11 cost time: 8.623097658157349
Epoch: 11, Steps: 265 Train Loss: 3.2091 (Forecasting Loss:0.2076 + XiCon Loss:3.0015 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2234142
	speed: 0.0343s/iter; left time: 804.6582s
	iters: 200, epoch: 12 | loss: 3.2459636
	speed: 0.0323s/iter; left time: 754.4104s
Epoch: 12 cost time: 8.714975595474243
Epoch: 12, Steps: 265 Train Loss: 3.2113 (Forecasting Loss:0.2077 + XiCon Loss:3.0036 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2632632
	speed: 0.0339s/iter; left time: 787.4574s
	iters: 200, epoch: 13 | loss: 3.2291436
	speed: 0.0324s/iter; left time: 749.2648s
Epoch: 13 cost time: 8.697894811630249
Epoch: 13, Steps: 265 Train Loss: 3.2082 (Forecasting Loss:0.2077 + XiCon Loss:3.0005 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1882966
	speed: 0.0336s/iter; left time: 770.7860s
	iters: 200, epoch: 14 | loss: 3.1959243
	speed: 0.0315s/iter; left time: 719.5966s
Epoch: 14 cost time: 8.516631841659546
Epoch: 14, Steps: 265 Train Loss: 3.2085 (Forecasting Loss:0.2074 + XiCon Loss:3.0010 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2286644
	speed: 0.0343s/iter; left time: 778.4318s
	iters: 200, epoch: 15 | loss: 3.2002635
	speed: 0.0310s/iter; left time: 699.3442s
Epoch: 15 cost time: 8.500241041183472
Epoch: 15, Steps: 265 Train Loss: 3.2071 (Forecasting Loss:0.2075 + XiCon Loss:2.9996 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2245097
	speed: 0.0336s/iter; left time: 754.3916s
	iters: 200, epoch: 16 | loss: 3.2406347
	speed: 0.0331s/iter; left time: 739.8175s
Epoch: 16 cost time: 8.926111698150635
Epoch: 16, Steps: 265 Train Loss: 3.2102 (Forecasting Loss:0.2075 + XiCon Loss:3.0026 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2100425
	speed: 0.0332s/iter; left time: 734.7553s
	iters: 200, epoch: 17 | loss: 3.1872590
	speed: 0.0314s/iter; left time: 692.8538s
Epoch: 17 cost time: 8.60585880279541
Epoch: 17, Steps: 265 Train Loss: 3.2066 (Forecasting Loss:0.2076 + XiCon Loss:2.9990 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
Validation loss decreased (0.210936 --> 0.210899).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1947384
	speed: 0.0344s/iter; left time: 752.2051s
	iters: 200, epoch: 18 | loss: 3.1958630
	speed: 0.0316s/iter; left time: 689.3270s
Epoch: 18 cost time: 8.639428853988647
Epoch: 18, Steps: 265 Train Loss: 3.2093 (Forecasting Loss:0.2077 + XiCon Loss:3.0016 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1965261
	speed: 0.0344s/iter; left time: 743.4907s
	iters: 200, epoch: 19 | loss: 3.1437588
	speed: 0.0315s/iter; left time: 677.7321s
Epoch: 19 cost time: 8.677112817764282
Epoch: 19, Steps: 265 Train Loss: 3.2074 (Forecasting Loss:0.2075 + XiCon Loss:2.9999 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.1973855
	speed: 0.0342s/iter; left time: 730.0698s
	iters: 200, epoch: 20 | loss: 3.1971471
	speed: 0.0311s/iter; left time: 660.7518s
Epoch: 20 cost time: 8.60174012184143
Epoch: 20, Steps: 265 Train Loss: 3.2095 (Forecasting Loss:0.2077 + XiCon Loss:3.0018 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1914792
	speed: 0.0348s/iter; left time: 734.8811s
	iters: 200, epoch: 21 | loss: 3.1754870
	speed: 0.0329s/iter; left time: 691.0116s
Epoch: 21 cost time: 8.94920301437378
Epoch: 21, Steps: 265 Train Loss: 3.2095 (Forecasting Loss:0.2078 + XiCon Loss:3.0017 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.1822104
	speed: 0.0342s/iter; left time: 713.0036s
	iters: 200, epoch: 22 | loss: 3.2239566
	speed: 0.0323s/iter; left time: 669.7320s
Epoch: 22 cost time: 8.77843165397644
Epoch: 22, Steps: 265 Train Loss: 3.2101 (Forecasting Loss:0.2075 + XiCon Loss:3.0026 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.1894209
	speed: 0.0343s/iter; left time: 705.9386s
	iters: 200, epoch: 23 | loss: 3.2222769
	speed: 0.0316s/iter; left time: 646.2554s
Epoch: 23 cost time: 8.665432691574097
Epoch: 23, Steps: 265 Train Loss: 3.2086 (Forecasting Loss:0.2076 + XiCon Loss:3.0011 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
Validation loss decreased (0.210899 --> 0.210856).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2298629
	speed: 0.0331s/iter; left time: 672.8468s
	iters: 200, epoch: 24 | loss: 3.2049978
	speed: 0.0323s/iter; left time: 652.1263s
Epoch: 24 cost time: 8.584561586380005
Epoch: 24, Steps: 265 Train Loss: 3.2097 (Forecasting Loss:0.2076 + XiCon Loss:3.0021 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2447035
	speed: 0.0343s/iter; left time: 688.2482s
	iters: 200, epoch: 25 | loss: 3.2491007
	speed: 0.0322s/iter; left time: 643.0070s
Epoch: 25 cost time: 8.671348571777344
Epoch: 25, Steps: 265 Train Loss: 3.2116 (Forecasting Loss:0.2076 + XiCon Loss:3.0041 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2150831
	speed: 0.0339s/iter; left time: 670.6783s
	iters: 200, epoch: 26 | loss: 3.1669819
	speed: 0.0340s/iter; left time: 668.1237s
Epoch: 26 cost time: 8.950645685195923
Epoch: 26, Steps: 265 Train Loss: 3.2096 (Forecasting Loss:0.2076 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.1716998
	speed: 0.0337s/iter; left time: 657.0526s
	iters: 200, epoch: 27 | loss: 3.2264185
	speed: 0.0315s/iter; left time: 612.0501s
Epoch: 27 cost time: 8.571259260177612
Epoch: 27, Steps: 265 Train Loss: 3.2105 (Forecasting Loss:0.2077 + XiCon Loss:3.0028 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1683
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.1937761
	speed: 0.0333s/iter; left time: 640.5679s
	iters: 200, epoch: 28 | loss: 3.2450194
	speed: 0.0313s/iter; left time: 598.8357s
Epoch: 28 cost time: 8.495396375656128
Epoch: 28, Steps: 265 Train Loss: 3.2091 (Forecasting Loss:0.2077 + XiCon Loss:3.0014 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.2077382
	speed: 0.0338s/iter; left time: 642.3605s
	iters: 200, epoch: 29 | loss: 3.1776445
	speed: 0.0325s/iter; left time: 613.4699s
Epoch: 29 cost time: 8.697348594665527
Epoch: 29, Steps: 265 Train Loss: 3.2093 (Forecasting Loss:0.2076 + XiCon Loss:3.0017 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.2172680
	speed: 0.0335s/iter; left time: 627.9189s
	iters: 200, epoch: 30 | loss: 3.2355988
	speed: 0.0317s/iter; left time: 590.5650s
Epoch: 30 cost time: 8.56873869895935
Epoch: 30, Steps: 265 Train Loss: 3.2111 (Forecasting Loss:0.2076 + XiCon Loss:3.0035 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.2046726
	speed: 0.0339s/iter; left time: 624.8771s
	iters: 200, epoch: 31 | loss: 3.2154222
	speed: 0.0330s/iter; left time: 605.8416s
Epoch: 31 cost time: 8.956846475601196
Epoch: 31, Steps: 265 Train Loss: 3.2092 (Forecasting Loss:0.2075 + XiCon Loss:3.0018 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1683
Validation loss decreased (0.210856 --> 0.210759).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 3.2542059
	speed: 0.0349s/iter; left time: 634.9909s
	iters: 200, epoch: 32 | loss: 3.2064159
	speed: 0.0324s/iter; left time: 586.2558s
Epoch: 32 cost time: 8.878446340560913
Epoch: 32, Steps: 265 Train Loss: 3.2079 (Forecasting Loss:0.2075 + XiCon Loss:3.0004 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 3.2163351
	speed: 0.0337s/iter; left time: 604.1624s
	iters: 200, epoch: 33 | loss: 3.1762416
	speed: 0.0328s/iter; left time: 585.2408s
Epoch: 33 cost time: 8.74936294555664
Epoch: 33, Steps: 265 Train Loss: 3.2083 (Forecasting Loss:0.2075 + XiCon Loss:3.0008 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 3.2326782
	speed: 0.0345s/iter; left time: 608.4597s
	iters: 200, epoch: 34 | loss: 3.2009037
	speed: 0.0321s/iter; left time: 563.8397s
Epoch: 34 cost time: 8.734020471572876
Epoch: 34, Steps: 265 Train Loss: 3.2095 (Forecasting Loss:0.2076 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 3.1994655
	speed: 0.0341s/iter; left time: 593.8269s
	iters: 200, epoch: 35 | loss: 3.2265811
	speed: 0.0319s/iter; left time: 551.9127s
Epoch: 35 cost time: 8.694162368774414
Epoch: 35, Steps: 265 Train Loss: 3.2106 (Forecasting Loss:0.2077 + XiCon Loss:3.0029 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1683
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 3.1720970
	speed: 0.0345s/iter; left time: 591.6003s
	iters: 200, epoch: 36 | loss: 3.2179906
	speed: 0.0322s/iter; left time: 547.6043s
Epoch: 36 cost time: 8.87708568572998
Epoch: 36, Steps: 265 Train Loss: 3.2086 (Forecasting Loss:0.2077 + XiCon Loss:3.0009 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 3.2199543
	speed: 0.0339s/iter; left time: 571.4743s
	iters: 200, epoch: 37 | loss: 3.1861281
	speed: 0.0306s/iter; left time: 512.8960s
Epoch: 37 cost time: 8.534402132034302
Epoch: 37, Steps: 265 Train Loss: 3.2076 (Forecasting Loss:0.2074 + XiCon Loss:3.0002 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 3.1946869
	speed: 0.0346s/iter; left time: 573.5549s
	iters: 200, epoch: 38 | loss: 3.2451260
	speed: 0.0319s/iter; left time: 526.3845s
Epoch: 38 cost time: 8.716423273086548
Epoch: 38, Steps: 265 Train Loss: 3.2078 (Forecasting Loss:0.2076 + XiCon Loss:3.0002 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 3.1828928
	speed: 0.0347s/iter; left time: 566.8425s
	iters: 200, epoch: 39 | loss: 3.2096035
	speed: 0.0305s/iter; left time: 495.0790s
Epoch: 39 cost time: 8.621914625167847
Epoch: 39, Steps: 265 Train Loss: 3.2097 (Forecasting Loss:0.2075 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 3.2056515
	speed: 0.0337s/iter; left time: 540.9288s
	iters: 200, epoch: 40 | loss: 3.1949289
	speed: 0.0319s/iter; left time: 509.4175s
Epoch: 40 cost time: 8.61667537689209
Epoch: 40, Steps: 265 Train Loss: 3.2105 (Forecasting Loss:0.2076 + XiCon Loss:3.0029 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 3.2186997
	speed: 0.0331s/iter; left time: 523.0149s
	iters: 200, epoch: 41 | loss: 3.2462397
	speed: 0.0325s/iter; left time: 509.5976s
Epoch: 41 cost time: 8.676141500473022
Epoch: 41, Steps: 265 Train Loss: 3.2087 (Forecasting Loss:0.2077 + XiCon Loss:3.0010 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09867458790540695, mae:0.2379748523235321, mape:0.5733357071876526, mspe:11.754464149475098 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8346
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.6314280
	speed: 0.0332s/iter; left time: 877.2495s
	iters: 200, epoch: 1 | loss: 3.5362093
	speed: 0.0316s/iter; left time: 832.0569s
Epoch: 1 cost time: 8.555196046829224
Epoch: 1, Steps: 265 Train Loss: 3.5864 (Forecasting Loss:0.3468 + XiCon Loss:3.2396 x Lambda(1.0)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.2725
Validation loss decreased (inf --> 0.327908).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4408453
	speed: 0.0341s/iter; left time: 891.8057s
	iters: 200, epoch: 2 | loss: 3.3727841
	speed: 0.0312s/iter; left time: 812.0983s
Epoch: 2 cost time: 8.614903211593628
Epoch: 2, Steps: 265 Train Loss: 3.4255 (Forecasting Loss:0.2409 + XiCon Loss:3.1847 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1724
Validation loss decreased (0.327908 --> 0.219463).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3032322
	speed: 0.0345s/iter; left time: 892.2965s
	iters: 200, epoch: 3 | loss: 3.3170795
	speed: 0.0327s/iter; left time: 843.6714s
Epoch: 3 cost time: 8.87696886062622
Epoch: 3, Steps: 265 Train Loss: 3.2935 (Forecasting Loss:0.2143 + XiCon Loss:3.0792 x Lambda(1.0)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1698
Validation loss decreased (0.219463 --> 0.214633).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2299948
	speed: 0.0342s/iter; left time: 875.7584s
	iters: 200, epoch: 4 | loss: 3.2882600
	speed: 0.0314s/iter; left time: 801.4114s
Epoch: 4 cost time: 8.63250470161438
Epoch: 4, Steps: 265 Train Loss: 3.2531 (Forecasting Loss:0.2108 + XiCon Loss:3.0422 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1691
Validation loss decreased (0.214633 --> 0.213000).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2094440
	speed: 0.0340s/iter; left time: 861.6967s
	iters: 200, epoch: 5 | loss: 3.2619138
	speed: 0.0329s/iter; left time: 829.9662s
Epoch: 5 cost time: 8.776483535766602
Epoch: 5, Steps: 265 Train Loss: 3.2432 (Forecasting Loss:0.2097 + XiCon Loss:3.0335 x Lambda(1.0)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1687
Validation loss decreased (0.213000 --> 0.212125).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2185950
	speed: 0.0335s/iter; left time: 838.9678s
	iters: 200, epoch: 6 | loss: 3.2711406
	speed: 0.0318s/iter; left time: 794.3317s
Epoch: 6 cost time: 8.480826377868652
Epoch: 6, Steps: 265 Train Loss: 3.2380 (Forecasting Loss:0.2091 + XiCon Loss:3.0290 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1685
Validation loss decreased (0.212125 --> 0.211750).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2046208
	speed: 0.0340s/iter; left time: 843.3059s
	iters: 200, epoch: 7 | loss: 3.2163670
	speed: 0.0316s/iter; left time: 781.8983s
Epoch: 7 cost time: 8.74848985671997
Epoch: 7, Steps: 265 Train Loss: 3.2339 (Forecasting Loss:0.2087 + XiCon Loss:3.0251 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1685
Validation loss decreased (0.211750 --> 0.211692).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2683895
	speed: 0.0333s/iter; left time: 818.2238s
	iters: 200, epoch: 8 | loss: 3.2416372
	speed: 0.0315s/iter; left time: 770.1160s
Epoch: 8 cost time: 8.463542699813843
Epoch: 8, Steps: 265 Train Loss: 3.2351 (Forecasting Loss:0.2086 + XiCon Loss:3.0265 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1684
Validation loss decreased (0.211692 --> 0.211558).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2326617
	speed: 0.0345s/iter; left time: 836.9503s
	iters: 200, epoch: 9 | loss: 3.2189257
	speed: 0.0324s/iter; left time: 782.7292s
Epoch: 9 cost time: 8.771253108978271
Epoch: 9, Steps: 265 Train Loss: 3.2360 (Forecasting Loss:0.2086 + XiCon Loss:3.0274 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1684
Validation loss decreased (0.211558 --> 0.211431).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2544863
	speed: 0.0335s/iter; left time: 805.3177s
	iters: 200, epoch: 10 | loss: 3.2363498
	speed: 0.0316s/iter; left time: 756.4712s
Epoch: 10 cost time: 8.593365907669067
Epoch: 10, Steps: 265 Train Loss: 3.2358 (Forecasting Loss:0.2087 + XiCon Loss:3.0271 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1684
Validation loss decreased (0.211431 --> 0.211368).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2275817
	speed: 0.0341s/iter; left time: 810.1997s
	iters: 200, epoch: 11 | loss: 3.2632596
	speed: 0.0315s/iter; left time: 745.0150s
Epoch: 11 cost time: 8.652601480484009
Epoch: 11, Steps: 265 Train Loss: 3.2340 (Forecasting Loss:0.2084 + XiCon Loss:3.0256 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2516682
	speed: 0.0345s/iter; left time: 809.4505s
	iters: 200, epoch: 12 | loss: 3.2562838
	speed: 0.0316s/iter; left time: 738.3491s
Epoch: 12 cost time: 8.715888738632202
Epoch: 12, Steps: 265 Train Loss: 3.2370 (Forecasting Loss:0.2085 + XiCon Loss:3.0285 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2556975
	speed: 0.0342s/iter; left time: 793.1920s
	iters: 200, epoch: 13 | loss: 3.2334800
	speed: 0.0315s/iter; left time: 727.5858s
Epoch: 13 cost time: 8.627239465713501
Epoch: 13, Steps: 265 Train Loss: 3.2361 (Forecasting Loss:0.2084 + XiCon Loss:3.0276 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1684
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2140911
	speed: 0.0336s/iter; left time: 771.0663s
	iters: 200, epoch: 14 | loss: 3.2038057
	speed: 0.0321s/iter; left time: 733.3055s
Epoch: 14 cost time: 8.614890575408936
Epoch: 14, Steps: 265 Train Loss: 3.2341 (Forecasting Loss:0.2085 + XiCon Loss:3.0256 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1684
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2304962
	speed: 0.0340s/iter; left time: 772.1890s
	iters: 200, epoch: 15 | loss: 3.2946849
	speed: 0.0320s/iter; left time: 723.7646s
Epoch: 15 cost time: 8.751838207244873
Epoch: 15, Steps: 265 Train Loss: 3.2320 (Forecasting Loss:0.2084 + XiCon Loss:3.0236 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1684
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2303178
	speed: 0.0339s/iter; left time: 761.1262s
	iters: 200, epoch: 16 | loss: 3.2452734
	speed: 0.0326s/iter; left time: 728.2489s
Epoch: 16 cost time: 8.780706405639648
Epoch: 16, Steps: 265 Train Loss: 3.2352 (Forecasting Loss:0.2084 + XiCon Loss:3.0267 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1684
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2798481
	speed: 0.0339s/iter; left time: 750.8018s
	iters: 200, epoch: 17 | loss: 3.2372463
	speed: 0.0321s/iter; left time: 707.5220s
Epoch: 17 cost time: 8.68531060218811
Epoch: 17, Steps: 265 Train Loss: 3.2339 (Forecasting Loss:0.2084 + XiCon Loss:3.0255 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1684
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2709122
	speed: 0.0340s/iter; left time: 743.4401s
	iters: 200, epoch: 18 | loss: 3.2076623
	speed: 0.0317s/iter; left time: 691.3869s
Epoch: 18 cost time: 8.58446717262268
Epoch: 18, Steps: 265 Train Loss: 3.2338 (Forecasting Loss:0.2084 + XiCon Loss:3.0255 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1684
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1969657
	speed: 0.0344s/iter; left time: 745.1124s
	iters: 200, epoch: 19 | loss: 3.2662606
	speed: 0.0312s/iter; left time: 670.9414s
Epoch: 19 cost time: 8.583774089813232
Epoch: 19, Steps: 265 Train Loss: 3.2364 (Forecasting Loss:0.2085 + XiCon Loss:3.0279 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1684
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2071180
	speed: 0.0340s/iter; left time: 726.6132s
	iters: 200, epoch: 20 | loss: 3.2255259
	speed: 0.0317s/iter; left time: 674.1781s
Epoch: 20 cost time: 8.68191385269165
Epoch: 20, Steps: 265 Train Loss: 3.2337 (Forecasting Loss:0.2086 + XiCon Loss:3.0251 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09847580641508102, mae:0.23829106986522675, mape:0.567967414855957, mspe:11.69747543334961 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0984+-0.00107, MAE:0.2383+-0.00124, MAPE:0.5701+-0.00271, MSPE:11.8678+-0.21634, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5795
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5924904
	speed: 0.0406s/iter; left time: 1067.3105s
	iters: 200, epoch: 1 | loss: 3.5017891
	speed: 0.0357s/iter; left time: 936.1132s
Epoch: 1 cost time: 9.975433826446533
Epoch: 1, Steps: 264 Train Loss: 3.5536 (Forecasting Loss:0.3356 + XiCon Loss:3.2180 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2336
Validation loss decreased (inf --> 0.296763).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2167230
	speed: 0.0356s/iter; left time: 926.7701s
	iters: 200, epoch: 2 | loss: 3.2178955
	speed: 0.0345s/iter; left time: 894.0310s
Epoch: 2 cost time: 9.17228102684021
Epoch: 2, Steps: 264 Train Loss: 3.2892 (Forecasting Loss:0.2525 + XiCon Loss:3.0368 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1952
Validation loss decreased (0.296763 --> 0.253584).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3269427
	speed: 0.0363s/iter; left time: 935.5977s
	iters: 200, epoch: 3 | loss: 3.2539239
	speed: 0.0345s/iter; left time: 884.8706s
Epoch: 3 cost time: 9.210793018341064
Epoch: 3, Steps: 264 Train Loss: 3.3394 (Forecasting Loss:0.2453 + XiCon Loss:3.0942 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1931
Validation loss decreased (0.253584 --> 0.248781).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3133008
	speed: 0.0374s/iter; left time: 953.6334s
	iters: 200, epoch: 4 | loss: 3.3829129
	speed: 0.0346s/iter; left time: 878.7802s
Epoch: 4 cost time: 9.407055377960205
Epoch: 4, Steps: 264 Train Loss: 3.3589 (Forecasting Loss:0.2433 + XiCon Loss:3.1155 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1929
Validation loss decreased (0.248781 --> 0.247726).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3690519
	speed: 0.0371s/iter; left time: 937.1524s
	iters: 200, epoch: 5 | loss: 3.4443593
	speed: 0.0347s/iter; left time: 872.7536s
Epoch: 5 cost time: 9.350382566452026
Epoch: 5, Steps: 264 Train Loss: 3.3564 (Forecasting Loss:0.2422 + XiCon Loss:3.1142 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1928
Validation loss decreased (0.247726 --> 0.246722).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3753932
	speed: 0.0374s/iter; left time: 935.3495s
	iters: 200, epoch: 6 | loss: 3.4082599
	speed: 0.0335s/iter; left time: 833.4695s
Epoch: 6 cost time: 9.265402793884277
Epoch: 6, Steps: 264 Train Loss: 3.3490 (Forecasting Loss:0.2420 + XiCon Loss:3.1070 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1923
Validation loss decreased (0.246722 --> 0.245664).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3688693
	speed: 0.0369s/iter; left time: 911.4889s
	iters: 200, epoch: 7 | loss: 3.3795848
	speed: 0.0345s/iter; left time: 848.6647s
Epoch: 7 cost time: 9.419523000717163
Epoch: 7, Steps: 264 Train Loss: 3.3490 (Forecasting Loss:0.2416 + XiCon Loss:3.1073 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1923
Validation loss decreased (0.245664 --> 0.245462).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.2861080
	speed: 0.0358s/iter; left time: 874.8114s
	iters: 200, epoch: 8 | loss: 3.2721584
	speed: 0.0337s/iter; left time: 820.5863s
Epoch: 8 cost time: 9.188750267028809
Epoch: 8, Steps: 264 Train Loss: 3.3476 (Forecasting Loss:0.2416 + XiCon Loss:3.1060 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1923
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3153203
	speed: 0.0354s/iter; left time: 856.5137s
	iters: 200, epoch: 9 | loss: 3.3989942
	speed: 0.0350s/iter; left time: 843.6437s
Epoch: 9 cost time: 9.270502090454102
Epoch: 9, Steps: 264 Train Loss: 3.3483 (Forecasting Loss:0.2415 + XiCon Loss:3.1068 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1923
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3748343
	speed: 0.0356s/iter; left time: 852.7005s
	iters: 200, epoch: 10 | loss: 3.2909999
	speed: 0.0346s/iter; left time: 823.8583s
Epoch: 10 cost time: 9.228452444076538
Epoch: 10, Steps: 264 Train Loss: 3.3442 (Forecasting Loss:0.2417 + XiCon Loss:3.1025 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1923
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.2962346
	speed: 0.0369s/iter; left time: 872.7932s
	iters: 200, epoch: 11 | loss: 3.2861013
	speed: 0.0338s/iter; left time: 796.3258s
Epoch: 11 cost time: 9.320913076400757
Epoch: 11, Steps: 264 Train Loss: 3.3480 (Forecasting Loss:0.2416 + XiCon Loss:3.1064 x Lambda(1.0)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1923
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4397597
	speed: 0.0361s/iter; left time: 844.0704s
	iters: 200, epoch: 12 | loss: 3.3217812
	speed: 0.0333s/iter; left time: 776.9046s
Epoch: 12 cost time: 9.131990194320679
Epoch: 12, Steps: 264 Train Loss: 3.3446 (Forecasting Loss:0.2413 + XiCon Loss:3.1033 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1923
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3813272
	speed: 0.0399s/iter; left time: 922.1429s
	iters: 200, epoch: 13 | loss: 3.4194667
	speed: 0.0343s/iter; left time: 789.5572s
Epoch: 13 cost time: 9.583563804626465
Epoch: 13, Steps: 264 Train Loss: 3.3475 (Forecasting Loss:0.2413 + XiCon Loss:3.1062 x Lambda(1.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1923
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4392970
	speed: 0.0369s/iter; left time: 843.9700s
	iters: 200, epoch: 14 | loss: 3.2855818
	speed: 0.0351s/iter; left time: 799.3075s
Epoch: 14 cost time: 9.442660093307495
Epoch: 14, Steps: 264 Train Loss: 3.3468 (Forecasting Loss:0.2413 + XiCon Loss:3.1055 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1923
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3706756
	speed: 0.0363s/iter; left time: 821.0344s
	iters: 200, epoch: 15 | loss: 3.2437387
	speed: 0.0348s/iter; left time: 783.4830s
Epoch: 15 cost time: 9.36067509651184
Epoch: 15, Steps: 264 Train Loss: 3.3432 (Forecasting Loss:0.2415 + XiCon Loss:3.1017 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1923
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3249447
	speed: 0.0376s/iter; left time: 840.7821s
	iters: 200, epoch: 16 | loss: 3.3524954
	speed: 0.0345s/iter; left time: 766.5139s
Epoch: 16 cost time: 9.409646034240723
Epoch: 16, Steps: 264 Train Loss: 3.3497 (Forecasting Loss:0.2414 + XiCon Loss:3.1083 x Lambda(1.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1923
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.3883064
	speed: 0.0371s/iter; left time: 819.3114s
	iters: 200, epoch: 17 | loss: 3.4175568
	speed: 0.0344s/iter; left time: 755.8540s
Epoch: 17 cost time: 9.39636516571045
Epoch: 17, Steps: 264 Train Loss: 3.3538 (Forecasting Loss:0.2415 + XiCon Loss:3.1122 x Lambda(1.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1923
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12098487466573715, mae:0.263606995344162, mape:0.6322755217552185, mspe:14.546646118164062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5738
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.6316683
	speed: 0.0381s/iter; left time: 1002.8001s
	iters: 200, epoch: 1 | loss: 3.5392461
	speed: 0.0356s/iter; left time: 932.6280s
Epoch: 1 cost time: 9.673472881317139
Epoch: 1, Steps: 264 Train Loss: 3.5674 (Forecasting Loss:0.3346 + XiCon Loss:3.2327 x Lambda(1.0)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.2320
Validation loss decreased (inf --> 0.293981).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2569606
	speed: 0.0378s/iter; left time: 983.2874s
	iters: 200, epoch: 2 | loss: 3.2484219
	speed: 0.0369s/iter; left time: 957.5670s
Epoch: 2 cost time: 9.906002283096313
Epoch: 2, Steps: 264 Train Loss: 3.3167 (Forecasting Loss:0.2526 + XiCon Loss:3.0642 x Lambda(1.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.1954
Validation loss decreased (0.293981 --> 0.251952).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3643942
	speed: 0.0398s/iter; left time: 1024.4829s
	iters: 200, epoch: 3 | loss: 3.4538167
	speed: 0.0380s/iter; left time: 976.2511s
Epoch: 3 cost time: 10.1471848487854
Epoch: 3, Steps: 264 Train Loss: 3.3849 (Forecasting Loss:0.2441 + XiCon Loss:3.1407 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1954
Validation loss decreased (0.251952 --> 0.249025).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5170782
	speed: 0.0373s/iter; left time: 952.5470s
	iters: 200, epoch: 4 | loss: 3.5128381
	speed: 0.0344s/iter; left time: 874.2684s
Epoch: 4 cost time: 9.64052939414978
Epoch: 4, Steps: 264 Train Loss: 3.4310 (Forecasting Loss:0.2424 + XiCon Loss:3.1886 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1946
Validation loss decreased (0.249025 --> 0.248648).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4864647
	speed: 0.0395s/iter; left time: 997.4317s
	iters: 200, epoch: 5 | loss: 3.3906209
	speed: 0.0374s/iter; left time: 940.2958s
Epoch: 5 cost time: 10.107423305511475
Epoch: 5, Steps: 264 Train Loss: 3.4478 (Forecasting Loss:0.2413 + XiCon Loss:3.2065 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1939
Validation loss decreased (0.248648 --> 0.248498).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3786728
	speed: 0.0404s/iter; left time: 1008.8079s
	iters: 200, epoch: 6 | loss: 3.4389884
	speed: 0.0376s/iter; left time: 936.1978s
Epoch: 6 cost time: 10.278697490692139
Epoch: 6, Steps: 264 Train Loss: 3.4609 (Forecasting Loss:0.2408 + XiCon Loss:3.2201 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1940
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4509153
	speed: 0.0405s/iter; left time: 1001.1673s
	iters: 200, epoch: 7 | loss: 3.4494555
	speed: 0.0379s/iter; left time: 934.0486s
Epoch: 7 cost time: 10.265160083770752
Epoch: 7, Steps: 264 Train Loss: 3.4576 (Forecasting Loss:0.2408 + XiCon Loss:3.2169 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1942
Validation loss decreased (0.248498 --> 0.248445).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3911984
	speed: 0.0401s/iter; left time: 979.3773s
	iters: 200, epoch: 8 | loss: 3.5928407
	speed: 0.0386s/iter; left time: 939.4058s
Epoch: 8 cost time: 10.254775524139404
Epoch: 8, Steps: 264 Train Loss: 3.4591 (Forecasting Loss:0.2405 + XiCon Loss:3.2186 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1943
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4794562
	speed: 0.0394s/iter; left time: 952.3171s
	iters: 200, epoch: 9 | loss: 3.3735743
	speed: 0.0380s/iter; left time: 915.7209s
Epoch: 9 cost time: 10.111138105392456
Epoch: 9, Steps: 264 Train Loss: 3.4619 (Forecasting Loss:0.2404 + XiCon Loss:3.2214 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1942
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5098634
	speed: 0.0395s/iter; left time: 945.6546s
	iters: 200, epoch: 10 | loss: 3.4796894
	speed: 0.0379s/iter; left time: 903.1324s
Epoch: 10 cost time: 10.150065183639526
Epoch: 10, Steps: 264 Train Loss: 3.4622 (Forecasting Loss:0.2406 + XiCon Loss:3.2217 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1943
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4211955
	speed: 0.0403s/iter; left time: 952.9167s
	iters: 200, epoch: 11 | loss: 3.4604297
	speed: 0.0372s/iter; left time: 876.5678s
Epoch: 11 cost time: 10.133172988891602
Epoch: 11, Steps: 264 Train Loss: 3.4618 (Forecasting Loss:0.2403 + XiCon Loss:3.2214 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1942
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4057148
	speed: 0.0401s/iter; left time: 937.8841s
	iters: 200, epoch: 12 | loss: 3.4899566
	speed: 0.0370s/iter; left time: 862.5190s
Epoch: 12 cost time: 10.157716512680054
Epoch: 12, Steps: 264 Train Loss: 3.4645 (Forecasting Loss:0.2403 + XiCon Loss:3.2243 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1943
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4148693
	speed: 0.0394s/iter; left time: 912.2784s
	iters: 200, epoch: 13 | loss: 3.4588060
	speed: 0.0378s/iter; left time: 871.5701s
Epoch: 13 cost time: 10.030588150024414
Epoch: 13, Steps: 264 Train Loss: 3.4629 (Forecasting Loss:0.2403 + XiCon Loss:3.2226 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1943
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4161441
	speed: 0.0372s/iter; left time: 850.5674s
	iters: 200, epoch: 14 | loss: 3.4568217
	speed: 0.0376s/iter; left time: 855.9930s
Epoch: 14 cost time: 9.890364646911621
Epoch: 14, Steps: 264 Train Loss: 3.4630 (Forecasting Loss:0.2403 + XiCon Loss:3.2227 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1943
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4905529
	speed: 0.0403s/iter; left time: 910.9357s
	iters: 200, epoch: 15 | loss: 3.4971354
	speed: 0.0375s/iter; left time: 844.9332s
Epoch: 15 cost time: 10.164966344833374
Epoch: 15, Steps: 264 Train Loss: 3.4620 (Forecasting Loss:0.2403 + XiCon Loss:3.2218 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1943
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4681118
	speed: 0.0403s/iter; left time: 900.6062s
	iters: 200, epoch: 16 | loss: 3.4352517
	speed: 0.0377s/iter; left time: 838.6920s
Epoch: 16 cost time: 10.268628120422363
Epoch: 16, Steps: 264 Train Loss: 3.4592 (Forecasting Loss:0.2403 + XiCon Loss:3.2189 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1943
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4486539
	speed: 0.0400s/iter; left time: 883.2271s
	iters: 200, epoch: 17 | loss: 3.5469260
	speed: 0.0388s/iter; left time: 851.7713s
Epoch: 17 cost time: 10.255186080932617
Epoch: 17, Steps: 264 Train Loss: 3.4609 (Forecasting Loss:0.2405 + XiCon Loss:3.2204 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1943
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12254635989665985, mae:0.26591211557388306, mape:0.6181716322898865, mspe:13.67434024810791 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6159
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5576258
	speed: 0.0396s/iter; left time: 1042.4729s
	iters: 200, epoch: 1 | loss: 3.5247753
	speed: 0.0369s/iter; left time: 965.6366s
Epoch: 1 cost time: 9.936123132705688
Epoch: 1, Steps: 264 Train Loss: 3.5603 (Forecasting Loss:0.3306 + XiCon Loss:3.2297 x Lambda(1.0)), Vali MSE Loss: 0.2881 Test MSE Loss: 0.2287
Validation loss decreased (inf --> 0.288078).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2614734
	speed: 0.0367s/iter; left time: 956.6478s
	iters: 200, epoch: 2 | loss: 3.2172163
	speed: 0.0341s/iter; left time: 884.1575s
Epoch: 2 cost time: 9.299869775772095
Epoch: 2, Steps: 264 Train Loss: 3.2881 (Forecasting Loss:0.2519 + XiCon Loss:3.0362 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1935
Validation loss decreased (0.288078 --> 0.251619).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3243589
	speed: 0.0368s/iter; left time: 949.5883s
	iters: 200, epoch: 3 | loss: 3.3133540
	speed: 0.0347s/iter; left time: 890.2318s
Epoch: 3 cost time: 9.33298397064209
Epoch: 3, Steps: 264 Train Loss: 3.3210 (Forecasting Loss:0.2435 + XiCon Loss:3.0775 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1916
Validation loss decreased (0.251619 --> 0.247656).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3419671
	speed: 0.0364s/iter; left time: 927.9806s
	iters: 200, epoch: 4 | loss: 3.4010947
	speed: 0.0344s/iter; left time: 874.0667s
Epoch: 4 cost time: 9.282957553863525
Epoch: 4, Steps: 264 Train Loss: 3.3611 (Forecasting Loss:0.2413 + XiCon Loss:3.1198 x Lambda(1.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1926
Validation loss decreased (0.247656 --> 0.243907).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3298748
	speed: 0.0369s/iter; left time: 931.3262s
	iters: 200, epoch: 5 | loss: 3.3264787
	speed: 0.0341s/iter; left time: 856.6333s
Epoch: 5 cost time: 9.238527059555054
Epoch: 5, Steps: 264 Train Loss: 3.3494 (Forecasting Loss:0.2385 + XiCon Loss:3.1109 x Lambda(1.0)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.1962
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4678080
	speed: 0.0368s/iter; left time: 919.2562s
	iters: 200, epoch: 6 | loss: 3.3176095
	speed: 0.0337s/iter; left time: 839.3132s
Epoch: 6 cost time: 9.28883147239685
Epoch: 6, Steps: 264 Train Loss: 3.3417 (Forecasting Loss:0.2374 + XiCon Loss:3.1043 x Lambda(1.0)), Vali MSE Loss: 0.2442 Test MSE Loss: 0.1965
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3206000
	speed: 0.0374s/iter; left time: 923.5971s
	iters: 200, epoch: 7 | loss: 3.4972451
	speed: 0.0342s/iter; left time: 841.0681s
Epoch: 7 cost time: 9.38249659538269
Epoch: 7, Steps: 264 Train Loss: 3.3421 (Forecasting Loss:0.2369 + XiCon Loss:3.1053 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1967
Validation loss decreased (0.243907 --> 0.243511).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3708010
	speed: 0.0368s/iter; left time: 899.4678s
	iters: 200, epoch: 8 | loss: 3.3736417
	speed: 0.0346s/iter; left time: 843.7248s
Epoch: 8 cost time: 9.377357959747314
Epoch: 8, Steps: 264 Train Loss: 3.3461 (Forecasting Loss:0.2364 + XiCon Loss:3.1097 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1974
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.2386045
	speed: 0.0365s/iter; left time: 883.1826s
	iters: 200, epoch: 9 | loss: 3.3015254
	speed: 0.0342s/iter; left time: 823.9532s
Epoch: 9 cost time: 9.33823537826538
Epoch: 9, Steps: 264 Train Loss: 3.3429 (Forecasting Loss:0.2367 + XiCon Loss:3.1062 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4093325
	speed: 0.0372s/iter; left time: 890.5867s
	iters: 200, epoch: 10 | loss: 3.3460145
	speed: 0.0358s/iter; left time: 853.0723s
Epoch: 10 cost time: 9.553287506103516
Epoch: 10, Steps: 264 Train Loss: 3.3416 (Forecasting Loss:0.2366 + XiCon Loss:3.1050 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1975
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3878224
	speed: 0.0378s/iter; left time: 893.5255s
	iters: 200, epoch: 11 | loss: 3.3013163
	speed: 0.0346s/iter; left time: 814.9264s
Epoch: 11 cost time: 9.415302038192749
Epoch: 11, Steps: 264 Train Loss: 3.3405 (Forecasting Loss:0.2366 + XiCon Loss:3.1039 x Lambda(1.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1975
Validation loss decreased (0.243511 --> 0.243394).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3289521
	speed: 0.0374s/iter; left time: 875.8368s
	iters: 200, epoch: 12 | loss: 3.3353672
	speed: 0.0337s/iter; left time: 785.4614s
Epoch: 12 cost time: 9.371119976043701
Epoch: 12, Steps: 264 Train Loss: 3.3389 (Forecasting Loss:0.2363 + XiCon Loss:3.1026 x Lambda(1.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1976
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3586082
	speed: 0.0375s/iter; left time: 868.6298s
	iters: 200, epoch: 13 | loss: 3.4211900
	speed: 0.0341s/iter; left time: 784.8568s
Epoch: 13 cost time: 9.386790037155151
Epoch: 13, Steps: 264 Train Loss: 3.3449 (Forecasting Loss:0.2366 + XiCon Loss:3.1083 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1976
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.2788675
	speed: 0.0367s/iter; left time: 838.4561s
	iters: 200, epoch: 14 | loss: 3.3390849
	speed: 0.0352s/iter; left time: 801.5828s
Epoch: 14 cost time: 9.400165557861328
Epoch: 14, Steps: 264 Train Loss: 3.3383 (Forecasting Loss:0.2366 + XiCon Loss:3.1018 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.2925239
	speed: 0.0360s/iter; left time: 813.7441s
	iters: 200, epoch: 15 | loss: 3.4321432
	speed: 0.0347s/iter; left time: 780.6676s
Epoch: 15 cost time: 9.208469152450562
Epoch: 15, Steps: 264 Train Loss: 3.3391 (Forecasting Loss:0.2366 + XiCon Loss:3.1025 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3758435
	speed: 0.0362s/iter; left time: 808.3085s
	iters: 200, epoch: 16 | loss: 3.3432441
	speed: 0.0360s/iter; left time: 799.9868s
Epoch: 16 cost time: 9.448134660720825
Epoch: 16, Steps: 264 Train Loss: 3.3389 (Forecasting Loss:0.2365 + XiCon Loss:3.1024 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.3824174
	speed: 0.0367s/iter; left time: 811.2911s
	iters: 200, epoch: 17 | loss: 3.2473288
	speed: 0.0351s/iter; left time: 771.7482s
Epoch: 17 cost time: 9.431006669998169
Epoch: 17, Steps: 264 Train Loss: 3.3368 (Forecasting Loss:0.2365 + XiCon Loss:3.1004 x Lambda(1.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1976
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.2949483
	speed: 0.0368s/iter; left time: 802.1071s
	iters: 200, epoch: 18 | loss: 3.3225195
	speed: 0.0348s/iter; left time: 754.6487s
Epoch: 18 cost time: 9.411273956298828
Epoch: 18, Steps: 264 Train Loss: 3.3376 (Forecasting Loss:0.2364 + XiCon Loss:3.1012 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1976
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.2872367
	speed: 0.0365s/iter; left time: 785.6113s
	iters: 200, epoch: 19 | loss: 3.4206176
	speed: 0.0346s/iter; left time: 742.2838s
Epoch: 19 cost time: 9.299707651138306
Epoch: 19, Steps: 264 Train Loss: 3.3401 (Forecasting Loss:0.2366 + XiCon Loss:3.1035 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1976
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4216621
	speed: 0.0369s/iter; left time: 784.7305s
	iters: 200, epoch: 20 | loss: 3.3967531
	speed: 0.0349s/iter; left time: 738.5147s
Epoch: 20 cost time: 9.330215692520142
Epoch: 20, Steps: 264 Train Loss: 3.3449 (Forecasting Loss:0.2365 + XiCon Loss:3.1085 x Lambda(1.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1976
Validation loss decreased (0.243394 --> 0.243358).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.3215938
	speed: 0.0370s/iter; left time: 778.4973s
	iters: 200, epoch: 21 | loss: 3.4331279
	speed: 0.0345s/iter; left time: 722.4878s
Epoch: 21 cost time: 9.352708578109741
Epoch: 21, Steps: 264 Train Loss: 3.3462 (Forecasting Loss:0.2364 + XiCon Loss:3.1099 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1976
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.3510771
	speed: 0.0371s/iter; left time: 769.1516s
	iters: 200, epoch: 22 | loss: 3.3053672
	speed: 0.0339s/iter; left time: 701.2812s
Epoch: 22 cost time: 9.297741413116455
Epoch: 22, Steps: 264 Train Loss: 3.3406 (Forecasting Loss:0.2365 + XiCon Loss:3.1042 x Lambda(1.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1976
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.2808425
	speed: 0.0382s/iter; left time: 782.0783s
	iters: 200, epoch: 23 | loss: 3.3646340
	speed: 0.0348s/iter; left time: 709.2227s
Epoch: 23 cost time: 9.470059871673584
Epoch: 23, Steps: 264 Train Loss: 3.3444 (Forecasting Loss:0.2365 + XiCon Loss:3.1079 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1976
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.3470502
	speed: 0.0366s/iter; left time: 741.0207s
	iters: 200, epoch: 24 | loss: 3.3663816
	speed: 0.0344s/iter; left time: 691.6805s
Epoch: 24 cost time: 9.33673620223999
Epoch: 24, Steps: 264 Train Loss: 3.3407 (Forecasting Loss:0.2362 + XiCon Loss:3.1045 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1976
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.3117201
	speed: 0.0367s/iter; left time: 732.6388s
	iters: 200, epoch: 25 | loss: 3.3787560
	speed: 0.0342s/iter; left time: 679.7894s
Epoch: 25 cost time: 9.346232414245605
Epoch: 25, Steps: 264 Train Loss: 3.3374 (Forecasting Loss:0.2363 + XiCon Loss:3.1011 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.3978040
	speed: 0.0358s/iter; left time: 705.2020s
	iters: 200, epoch: 26 | loss: 3.3699508
	speed: 0.0337s/iter; left time: 661.1875s
Epoch: 26 cost time: 9.185343503952026
Epoch: 26, Steps: 264 Train Loss: 3.3431 (Forecasting Loss:0.2364 + XiCon Loss:3.1067 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1976
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.2607238
	speed: 0.0372s/iter; left time: 723.1285s
	iters: 200, epoch: 27 | loss: 3.3479257
	speed: 0.0358s/iter; left time: 691.4383s
Epoch: 27 cost time: 9.461044549942017
Epoch: 27, Steps: 264 Train Loss: 3.3370 (Forecasting Loss:0.2366 + XiCon Loss:3.1004 x Lambda(1.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1976
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.3606339
	speed: 0.0368s/iter; left time: 706.0289s
	iters: 200, epoch: 28 | loss: 3.3432379
	speed: 0.0339s/iter; left time: 646.2351s
Epoch: 28 cost time: 9.315004348754883
Epoch: 28, Steps: 264 Train Loss: 3.3434 (Forecasting Loss:0.2364 + XiCon Loss:3.1070 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.2505622
	speed: 0.0370s/iter; left time: 698.9641s
	iters: 200, epoch: 29 | loss: 3.3961122
	speed: 0.0345s/iter; left time: 648.3416s
Epoch: 29 cost time: 9.350785970687866
Epoch: 29, Steps: 264 Train Loss: 3.3448 (Forecasting Loss:0.2365 + XiCon Loss:3.1083 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1976
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.4309697
	speed: 0.0368s/iter; left time: 686.4020s
	iters: 200, epoch: 30 | loss: 3.2977867
	speed: 0.0352s/iter; left time: 652.8771s
Epoch: 30 cost time: 9.47001838684082
Epoch: 30, Steps: 264 Train Loss: 3.3360 (Forecasting Loss:0.2363 + XiCon Loss:3.0997 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1976
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12524157762527466, mae:0.2699951231479645, mape:0.6522676348686218, mspe:15.066267013549805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.4374
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5772595
	speed: 0.0391s/iter; left time: 1027.9468s
	iters: 200, epoch: 1 | loss: 3.4984636
	speed: 0.0358s/iter; left time: 936.7347s
Epoch: 1 cost time: 9.786212682723999
Epoch: 1, Steps: 264 Train Loss: 3.5591 (Forecasting Loss:0.3361 + XiCon Loss:3.2230 x Lambda(1.0)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.2323
Validation loss decreased (inf --> 0.291593).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2697375
	speed: 0.0368s/iter; left time: 958.9820s
	iters: 200, epoch: 2 | loss: 3.2654526
	speed: 0.0349s/iter; left time: 903.9972s
Epoch: 2 cost time: 9.414050340652466
Epoch: 2, Steps: 264 Train Loss: 3.2977 (Forecasting Loss:0.2524 + XiCon Loss:3.0453 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1982
Validation loss decreased (0.291593 --> 0.251470).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2766910
	speed: 0.0369s/iter; left time: 950.6986s
	iters: 200, epoch: 3 | loss: 3.2592926
	speed: 0.0365s/iter; left time: 936.0044s
Epoch: 3 cost time: 9.624473810195923
Epoch: 3, Steps: 264 Train Loss: 3.2816 (Forecasting Loss:0.2422 + XiCon Loss:3.0394 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.1969
Validation loss decreased (0.251470 --> 0.250998).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3404131
	speed: 0.0394s/iter; left time: 1004.7106s
	iters: 200, epoch: 4 | loss: 3.2548485
	speed: 0.0373s/iter; left time: 948.4004s
Epoch: 4 cost time: 10.0359628200531
Epoch: 4, Steps: 264 Train Loss: 3.3270 (Forecasting Loss:0.2408 + XiCon Loss:3.0862 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1970
Validation loss decreased (0.250998 --> 0.250395).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3090844
	speed: 0.0367s/iter; left time: 926.3779s
	iters: 200, epoch: 5 | loss: 3.3830810
	speed: 0.0366s/iter; left time: 920.9527s
Epoch: 5 cost time: 9.73766827583313
Epoch: 5, Steps: 264 Train Loss: 3.3431 (Forecasting Loss:0.2397 + XiCon Loss:3.1034 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1967
Validation loss decreased (0.250395 --> 0.249783).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4500680
	speed: 0.0387s/iter; left time: 967.2933s
	iters: 200, epoch: 6 | loss: 3.4388590
	speed: 0.0373s/iter; left time: 928.6898s
Epoch: 6 cost time: 10.030481100082397
Epoch: 6, Steps: 264 Train Loss: 3.3682 (Forecasting Loss:0.2393 + XiCon Loss:3.1288 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1963
Validation loss decreased (0.249783 --> 0.249495).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3062811
	speed: 0.0391s/iter; left time: 965.3885s
	iters: 200, epoch: 7 | loss: 3.3667510
	speed: 0.0374s/iter; left time: 921.8165s
Epoch: 7 cost time: 10.011189460754395
Epoch: 7, Steps: 264 Train Loss: 3.3731 (Forecasting Loss:0.2390 + XiCon Loss:3.1341 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1965
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3795691
	speed: 0.0385s/iter; left time: 941.7454s
	iters: 200, epoch: 8 | loss: 3.4268622
	speed: 0.0367s/iter; left time: 892.8661s
Epoch: 8 cost time: 9.785757303237915
Epoch: 8, Steps: 264 Train Loss: 3.3798 (Forecasting Loss:0.2391 + XiCon Loss:3.1407 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4625478
	speed: 0.0386s/iter; left time: 932.5760s
	iters: 200, epoch: 9 | loss: 3.3655977
	speed: 0.0365s/iter; left time: 879.7902s
Epoch: 9 cost time: 9.811128854751587
Epoch: 9, Steps: 264 Train Loss: 3.3791 (Forecasting Loss:0.2390 + XiCon Loss:3.1401 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1965
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3947988
	speed: 0.0397s/iter; left time: 949.3223s
	iters: 200, epoch: 10 | loss: 3.4335480
	speed: 0.0367s/iter; left time: 875.0785s
Epoch: 10 cost time: 10.088578939437866
Epoch: 10, Steps: 264 Train Loss: 3.3789 (Forecasting Loss:0.2389 + XiCon Loss:3.1400 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1965
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3921030
	speed: 0.0383s/iter; left time: 905.3543s
	iters: 200, epoch: 11 | loss: 3.3697243
	speed: 0.0370s/iter; left time: 872.1710s
Epoch: 11 cost time: 9.87398076057434
Epoch: 11, Steps: 264 Train Loss: 3.3786 (Forecasting Loss:0.2390 + XiCon Loss:3.1396 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1965
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4385524
	speed: 0.0392s/iter; left time: 916.2217s
	iters: 200, epoch: 12 | loss: 3.3429999
	speed: 0.0372s/iter; left time: 866.3621s
Epoch: 12 cost time: 10.0369131565094
Epoch: 12, Steps: 264 Train Loss: 3.3792 (Forecasting Loss:0.2389 + XiCon Loss:3.1403 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1965
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3781257
	speed: 0.0397s/iter; left time: 919.0624s
	iters: 200, epoch: 13 | loss: 3.3899302
	speed: 0.0368s/iter; left time: 847.7004s
Epoch: 13 cost time: 10.02322268486023
Epoch: 13, Steps: 264 Train Loss: 3.3810 (Forecasting Loss:0.2390 + XiCon Loss:3.1420 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1965
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3696232
	speed: 0.0377s/iter; left time: 862.5991s
	iters: 200, epoch: 14 | loss: 3.3664105
	speed: 0.0379s/iter; left time: 862.6534s
Epoch: 14 cost time: 9.815754652023315
Epoch: 14, Steps: 264 Train Loss: 3.3829 (Forecasting Loss:0.2389 + XiCon Loss:3.1440 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1965
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4156251
	speed: 0.0370s/iter; left time: 835.2990s
	iters: 200, epoch: 15 | loss: 3.4075716
	speed: 0.0368s/iter; left time: 828.3901s
Epoch: 15 cost time: 9.75180435180664
Epoch: 15, Steps: 264 Train Loss: 3.3826 (Forecasting Loss:0.2390 + XiCon Loss:3.1436 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1965
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3463609
	speed: 0.0391s/iter; left time: 872.8408s
	iters: 200, epoch: 16 | loss: 3.3964252
	speed: 0.0368s/iter; left time: 817.5640s
Epoch: 16 cost time: 9.869021654129028
Epoch: 16, Steps: 264 Train Loss: 3.3834 (Forecasting Loss:0.2390 + XiCon Loss:3.1444 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1965
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12425775080919266, mae:0.2683154046535492, mape:0.6278741359710693, mspe:13.985445976257324 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1463
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5453544
	speed: 0.0382s/iter; left time: 1004.8840s
	iters: 200, epoch: 1 | loss: 3.5716238
	speed: 0.0350s/iter; left time: 916.9467s
Epoch: 1 cost time: 9.55879545211792
Epoch: 1, Steps: 264 Train Loss: 3.5516 (Forecasting Loss:0.3381 + XiCon Loss:3.2136 x Lambda(1.0)), Vali MSE Loss: 0.3053 Test MSE Loss: 0.2386
Validation loss decreased (inf --> 0.305309).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2572920
	speed: 0.0370s/iter; left time: 962.3282s
	iters: 200, epoch: 2 | loss: 3.3346763
	speed: 0.0345s/iter; left time: 895.5401s
Epoch: 2 cost time: 9.364500999450684
Epoch: 2, Steps: 264 Train Loss: 3.3337 (Forecasting Loss:0.2508 + XiCon Loss:3.0828 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1982
Validation loss decreased (0.305309 --> 0.252739).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4500339
	speed: 0.0366s/iter; left time: 943.3265s
	iters: 200, epoch: 3 | loss: 3.4180655
	speed: 0.0347s/iter; left time: 889.7744s
Epoch: 3 cost time: 9.380518913269043
Epoch: 3, Steps: 264 Train Loss: 3.4101 (Forecasting Loss:0.2443 + XiCon Loss:3.1658 x Lambda(1.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1938
Validation loss decreased (0.252739 --> 0.251676).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3864453
	speed: 0.0360s/iter; left time: 918.7083s
	iters: 200, epoch: 4 | loss: 3.4850831
	speed: 0.0345s/iter; left time: 877.7424s
Epoch: 4 cost time: 9.267876863479614
Epoch: 4, Steps: 264 Train Loss: 3.4333 (Forecasting Loss:0.2429 + XiCon Loss:3.1903 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1924
Validation loss decreased (0.251676 --> 0.247429).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4127791
	speed: 0.0370s/iter; left time: 933.8441s
	iters: 200, epoch: 5 | loss: 3.4244409
	speed: 0.0344s/iter; left time: 864.4006s
Epoch: 5 cost time: 9.313177347183228
Epoch: 5, Steps: 264 Train Loss: 3.4265 (Forecasting Loss:0.2420 + XiCon Loss:3.1845 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
Validation loss decreased (0.247429 --> 0.246861).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3585324
	speed: 0.0363s/iter; left time: 907.4445s
	iters: 200, epoch: 6 | loss: 3.3899128
	speed: 0.0342s/iter; left time: 850.3834s
Epoch: 6 cost time: 9.314698696136475
Epoch: 6, Steps: 264 Train Loss: 3.4242 (Forecasting Loss:0.2417 + XiCon Loss:3.1825 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1921
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4145756
	speed: 0.0368s/iter; left time: 908.9119s
	iters: 200, epoch: 7 | loss: 3.3739994
	speed: 0.0342s/iter; left time: 841.5777s
Epoch: 7 cost time: 9.280427694320679
Epoch: 7, Steps: 264 Train Loss: 3.4322 (Forecasting Loss:0.2415 + XiCon Loss:3.1907 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1921
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5058446
	speed: 0.0370s/iter; left time: 904.2852s
	iters: 200, epoch: 8 | loss: 3.4867625
	speed: 0.0349s/iter; left time: 851.0975s
Epoch: 8 cost time: 9.38862133026123
Epoch: 8, Steps: 264 Train Loss: 3.4323 (Forecasting Loss:0.2412 + XiCon Loss:3.1911 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3746338
	speed: 0.0364s/iter; left time: 879.4538s
	iters: 200, epoch: 9 | loss: 3.3253777
	speed: 0.0338s/iter; left time: 813.1793s
Epoch: 9 cost time: 9.26877212524414
Epoch: 9, Steps: 264 Train Loss: 3.4247 (Forecasting Loss:0.2412 + XiCon Loss:3.1835 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3774462
	speed: 0.0366s/iter; left time: 876.3990s
	iters: 200, epoch: 10 | loss: 3.3632987
	speed: 0.0348s/iter; left time: 830.0324s
Epoch: 10 cost time: 9.351543188095093
Epoch: 10, Steps: 264 Train Loss: 3.4263 (Forecasting Loss:0.2414 + XiCon Loss:3.1848 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1921
Validation loss decreased (0.246861 --> 0.246840).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3822312
	speed: 0.0365s/iter; left time: 864.3276s
	iters: 200, epoch: 11 | loss: 3.4928274
	speed: 0.0342s/iter; left time: 806.3950s
Epoch: 11 cost time: 9.329403162002563
Epoch: 11, Steps: 264 Train Loss: 3.4276 (Forecasting Loss:0.2413 + XiCon Loss:3.1864 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1921
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4835300
	speed: 0.0368s/iter; left time: 859.9926s
	iters: 200, epoch: 12 | loss: 3.5549345
	speed: 0.0343s/iter; left time: 799.3707s
Epoch: 12 cost time: 9.330429553985596
Epoch: 12, Steps: 264 Train Loss: 3.4318 (Forecasting Loss:0.2411 + XiCon Loss:3.1907 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4233134
	speed: 0.0369s/iter; left time: 854.3528s
	iters: 200, epoch: 13 | loss: 3.5306330
	speed: 0.0347s/iter; left time: 799.9593s
Epoch: 13 cost time: 9.40758991241455
Epoch: 13, Steps: 264 Train Loss: 3.4280 (Forecasting Loss:0.2411 + XiCon Loss:3.1869 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3947940
	speed: 0.0376s/iter; left time: 859.6835s
	iters: 200, epoch: 14 | loss: 3.3480718
	speed: 0.0338s/iter; left time: 770.1954s
Epoch: 14 cost time: 9.440125942230225
Epoch: 14, Steps: 264 Train Loss: 3.4288 (Forecasting Loss:0.2412 + XiCon Loss:3.1876 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3934147
	speed: 0.0371s/iter; left time: 837.8612s
	iters: 200, epoch: 15 | loss: 3.3298976
	speed: 0.0352s/iter; left time: 792.6707s
Epoch: 15 cost time: 9.401085138320923
Epoch: 15, Steps: 264 Train Loss: 3.4295 (Forecasting Loss:0.2412 + XiCon Loss:3.1882 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3595023
	speed: 0.0362s/iter; left time: 808.8804s
	iters: 200, epoch: 16 | loss: 3.5282409
	speed: 0.0349s/iter; left time: 776.5729s
Epoch: 16 cost time: 9.292158126831055
Epoch: 16, Steps: 264 Train Loss: 3.4295 (Forecasting Loss:0.2413 + XiCon Loss:3.1883 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1922
Validation loss decreased (0.246840 --> 0.246798).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4611287
	speed: 0.0369s/iter; left time: 815.0288s
	iters: 200, epoch: 17 | loss: 3.4294066
	speed: 0.0341s/iter; left time: 750.3702s
Epoch: 17 cost time: 9.292197704315186
Epoch: 17, Steps: 264 Train Loss: 3.4239 (Forecasting Loss:0.2411 + XiCon Loss:3.1828 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.3598373
	speed: 0.0355s/iter; left time: 773.3468s
	iters: 200, epoch: 18 | loss: 3.4070053
	speed: 0.0344s/iter; left time: 747.8817s
Epoch: 18 cost time: 9.241809844970703
Epoch: 18, Steps: 264 Train Loss: 3.4315 (Forecasting Loss:0.2412 + XiCon Loss:3.1904 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4137821
	speed: 0.0369s/iter; left time: 795.4308s
	iters: 200, epoch: 19 | loss: 3.5189092
	speed: 0.0346s/iter; left time: 741.4955s
Epoch: 19 cost time: 9.37089228630066
Epoch: 19, Steps: 264 Train Loss: 3.4325 (Forecasting Loss:0.2412 + XiCon Loss:3.1913 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.3871901
	speed: 0.0379s/iter; left time: 807.3320s
	iters: 200, epoch: 20 | loss: 3.3962898
	speed: 0.0351s/iter; left time: 743.5766s
Epoch: 20 cost time: 9.498263835906982
Epoch: 20, Steps: 264 Train Loss: 3.4282 (Forecasting Loss:0.2412 + XiCon Loss:3.1870 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1922
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6109624
	speed: 0.0366s/iter; left time: 769.3261s
	iters: 200, epoch: 21 | loss: 3.4893639
	speed: 0.0343s/iter; left time: 718.5050s
Epoch: 21 cost time: 9.29381775856018
Epoch: 21, Steps: 264 Train Loss: 3.4296 (Forecasting Loss:0.2413 + XiCon Loss:3.1884 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.3457839
	speed: 0.0367s/iter; left time: 762.2579s
	iters: 200, epoch: 22 | loss: 3.3918178
	speed: 0.0349s/iter; left time: 720.0660s
Epoch: 22 cost time: 9.42962646484375
Epoch: 22, Steps: 264 Train Loss: 3.4273 (Forecasting Loss:0.2413 + XiCon Loss:3.1860 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1922
Validation loss decreased (0.246798 --> 0.246742).  Saving model ...
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.3817766
	speed: 0.0370s/iter; left time: 757.5149s
	iters: 200, epoch: 23 | loss: 3.3531394
	speed: 0.0344s/iter; left time: 701.7274s
Epoch: 23 cost time: 9.393994569778442
Epoch: 23, Steps: 264 Train Loss: 3.4262 (Forecasting Loss:0.2411 + XiCon Loss:3.1851 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1922
Validation loss decreased (0.246742 --> 0.246696).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.3751578
	speed: 0.0367s/iter; left time: 741.6425s
	iters: 200, epoch: 24 | loss: 3.4242435
	speed: 0.0347s/iter; left time: 698.2081s
Epoch: 24 cost time: 9.363271713256836
Epoch: 24, Steps: 264 Train Loss: 3.4284 (Forecasting Loss:0.2412 + XiCon Loss:3.1872 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.4012070
	speed: 0.0371s/iter; left time: 740.9257s
	iters: 200, epoch: 25 | loss: 3.3605356
	speed: 0.0348s/iter; left time: 691.6636s
Epoch: 25 cost time: 9.397388696670532
Epoch: 25, Steps: 264 Train Loss: 3.4236 (Forecasting Loss:0.2412 + XiCon Loss:3.1823 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1922
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.4027591
	speed: 0.0374s/iter; left time: 736.6907s
	iters: 200, epoch: 26 | loss: 3.4179878
	speed: 0.0349s/iter; left time: 683.7783s
Epoch: 26 cost time: 9.494396686553955
Epoch: 26, Steps: 264 Train Loss: 3.4254 (Forecasting Loss:0.2413 + XiCon Loss:3.1842 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1922
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.4612868
	speed: 0.0378s/iter; left time: 735.5432s
	iters: 200, epoch: 27 | loss: 3.4134846
	speed: 0.0354s/iter; left time: 685.2883s
Epoch: 27 cost time: 9.522779941558838
Epoch: 27, Steps: 264 Train Loss: 3.4270 (Forecasting Loss:0.2413 + XiCon Loss:3.1858 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.4367905
	speed: 0.0370s/iter; left time: 710.2822s
	iters: 200, epoch: 28 | loss: 3.4711137
	speed: 0.0334s/iter; left time: 637.5684s
Epoch: 28 cost time: 9.22066330909729
Epoch: 28, Steps: 264 Train Loss: 3.4247 (Forecasting Loss:0.2411 + XiCon Loss:3.1837 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.4210653
	speed: 0.0364s/iter; left time: 688.5468s
	iters: 200, epoch: 29 | loss: 3.4636822
	speed: 0.0353s/iter; left time: 663.2989s
Epoch: 29 cost time: 9.302069664001465
Epoch: 29, Steps: 264 Train Loss: 3.4339 (Forecasting Loss:0.2412 + XiCon Loss:3.1926 x Lambda(1.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.1922
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.3215115
	speed: 0.0372s/iter; left time: 693.4882s
	iters: 200, epoch: 30 | loss: 3.4408844
	speed: 0.0351s/iter; left time: 650.8531s
Epoch: 30 cost time: 9.389732599258423
Epoch: 30, Steps: 264 Train Loss: 3.4277 (Forecasting Loss:0.2412 + XiCon Loss:3.1865 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.3776257
	speed: 0.0370s/iter; left time: 680.8141s
	iters: 200, epoch: 31 | loss: 3.4629250
	speed: 0.0354s/iter; left time: 646.8526s
Epoch: 31 cost time: 9.464331150054932
Epoch: 31, Steps: 264 Train Loss: 3.4312 (Forecasting Loss:0.2412 + XiCon Loss:3.1900 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.4306576
	speed: 0.0370s/iter; left time: 669.8887s
	iters: 200, epoch: 32 | loss: 3.5181646
	speed: 0.0343s/iter; left time: 617.2426s
Epoch: 32 cost time: 9.318620681762695
Epoch: 32, Steps: 264 Train Loss: 3.4277 (Forecasting Loss:0.2412 + XiCon Loss:3.1865 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1922
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.3555236
	speed: 0.0362s/iter; left time: 646.4853s
	iters: 200, epoch: 33 | loss: 3.4167752
	speed: 0.0346s/iter; left time: 613.5906s
Epoch: 33 cost time: 9.282671689987183
Epoch: 33, Steps: 264 Train Loss: 3.4280 (Forecasting Loss:0.2411 + XiCon Loss:3.1869 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1922
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12023426592350006, mae:0.2640707194805145, mape:0.6324478387832642, mspe:14.214191436767578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1227+-0.00263, MAE:0.2664+-0.00340, MAPE:0.6326+-0.01543, MSPE:14.2974+-0.66453, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0288
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5941241
	speed: 0.0536s/iter; left time: 1392.6821s
	iters: 200, epoch: 1 | loss: 3.5263679
	speed: 0.0473s/iter; left time: 1225.0741s
Epoch: 1 cost time: 12.973082065582275
Epoch: 1, Steps: 261 Train Loss: 3.5952 (Forecasting Loss:0.3721 + XiCon Loss:3.2230 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.324121).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3264034
	speed: 0.0511s/iter; left time: 1315.9553s
	iters: 200, epoch: 2 | loss: 3.2800524
	speed: 0.0482s/iter; left time: 1234.7410s
Epoch: 2 cost time: 12.798201560974121
Epoch: 2, Steps: 261 Train Loss: 3.3364 (Forecasting Loss:0.2983 + XiCon Loss:3.0381 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2447
Validation loss decreased (0.324121 --> 0.290815).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3877859
	speed: 0.0492s/iter; left time: 1253.4988s
	iters: 200, epoch: 3 | loss: 3.6138830
	speed: 0.0482s/iter; left time: 1222.7551s
Epoch: 3 cost time: 12.656603813171387
Epoch: 3, Steps: 261 Train Loss: 3.3742 (Forecasting Loss:0.2944 + XiCon Loss:3.0798 x Lambda(1.0)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2437
Validation loss decreased (0.290815 --> 0.282948).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4214203
	speed: 0.0500s/iter; left time: 1259.9446s
	iters: 200, epoch: 4 | loss: 3.4000669
	speed: 0.0483s/iter; left time: 1213.6342s
Epoch: 4 cost time: 12.8184072971344
Epoch: 4, Steps: 261 Train Loss: 3.4187 (Forecasting Loss:0.2914 + XiCon Loss:3.1273 x Lambda(1.0)), Vali MSE Loss: 0.2858 Test MSE Loss: 0.2442
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5480146
	speed: 0.0503s/iter; left time: 1255.8721s
	iters: 200, epoch: 5 | loss: 3.4515853
	speed: 0.0483s/iter; left time: 1201.5798s
Epoch: 5 cost time: 12.820981502532959
Epoch: 5, Steps: 261 Train Loss: 3.4025 (Forecasting Loss:0.2909 + XiCon Loss:3.1117 x Lambda(1.0)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.2440
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4474587
	speed: 0.0494s/iter; left time: 1219.3847s
	iters: 200, epoch: 6 | loss: 3.3173656
	speed: 0.0486s/iter; left time: 1196.2668s
Epoch: 6 cost time: 12.812477827072144
Epoch: 6, Steps: 261 Train Loss: 3.3986 (Forecasting Loss:0.2901 + XiCon Loss:3.1085 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2430
Validation loss decreased (0.282948 --> 0.281635).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3335509
	speed: 0.0508s/iter; left time: 1241.7002s
	iters: 200, epoch: 7 | loss: 3.3766551
	speed: 0.0480s/iter; left time: 1169.0875s
Epoch: 7 cost time: 12.8138108253479
Epoch: 7, Steps: 261 Train Loss: 3.3992 (Forecasting Loss:0.2898 + XiCon Loss:3.1094 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2431
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3908391
	speed: 0.0511s/iter; left time: 1235.5793s
	iters: 200, epoch: 8 | loss: 3.4168508
	speed: 0.0484s/iter; left time: 1165.9560s
Epoch: 8 cost time: 12.903470993041992
Epoch: 8, Steps: 261 Train Loss: 3.3962 (Forecasting Loss:0.2900 + XiCon Loss:3.1062 x Lambda(1.0)), Vali MSE Loss: 0.2823 Test MSE Loss: 0.2433
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3396597
	speed: 0.0503s/iter; left time: 1202.3124s
	iters: 200, epoch: 9 | loss: 3.3486376
	speed: 0.0488s/iter; left time: 1160.9228s
Epoch: 9 cost time: 12.867327451705933
Epoch: 9, Steps: 261 Train Loss: 3.4078 (Forecasting Loss:0.2897 + XiCon Loss:3.1181 x Lambda(1.0)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2434
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4204383
	speed: 0.0504s/iter; left time: 1191.0337s
	iters: 200, epoch: 10 | loss: 3.3559051
	speed: 0.0500s/iter; left time: 1177.0014s
Epoch: 10 cost time: 12.90728497505188
Epoch: 10, Steps: 261 Train Loss: 3.4010 (Forecasting Loss:0.2897 + XiCon Loss:3.1113 x Lambda(1.0)), Vali MSE Loss: 0.2825 Test MSE Loss: 0.2434
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3690183
	speed: 0.0504s/iter; left time: 1179.6356s
	iters: 200, epoch: 11 | loss: 3.3753579
	speed: 0.0484s/iter; left time: 1128.1031s
Epoch: 11 cost time: 12.898600339889526
Epoch: 11, Steps: 261 Train Loss: 3.4023 (Forecasting Loss:0.2897 + XiCon Loss:3.1126 x Lambda(1.0)), Vali MSE Loss: 0.2826 Test MSE Loss: 0.2434
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4299657
	speed: 0.0504s/iter; left time: 1164.9676s
	iters: 200, epoch: 12 | loss: 3.4282703
	speed: 0.0478s/iter; left time: 1100.7090s
Epoch: 12 cost time: 12.730326890945435
Epoch: 12, Steps: 261 Train Loss: 3.4041 (Forecasting Loss:0.2896 + XiCon Loss:3.1145 x Lambda(1.0)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.2434
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4065299
	speed: 0.0515s/iter; left time: 1178.5870s
	iters: 200, epoch: 13 | loss: 3.3776448
	speed: 0.0483s/iter; left time: 1100.2419s
Epoch: 13 cost time: 12.993463516235352
Epoch: 13, Steps: 261 Train Loss: 3.3984 (Forecasting Loss:0.2897 + XiCon Loss:3.1087 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.2434
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4091637
	speed: 0.0525s/iter; left time: 1187.6679s
	iters: 200, epoch: 14 | loss: 3.2964168
	speed: 0.0484s/iter; left time: 1090.2805s
Epoch: 14 cost time: 13.11711597442627
Epoch: 14, Steps: 261 Train Loss: 3.4010 (Forecasting Loss:0.2896 + XiCon Loss:3.1114 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.2434
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4042642
	speed: 0.0514s/iter; left time: 1149.5882s
	iters: 200, epoch: 15 | loss: 3.4061999
	speed: 0.0484s/iter; left time: 1077.7815s
Epoch: 15 cost time: 13.024377822875977
Epoch: 15, Steps: 261 Train Loss: 3.4018 (Forecasting Loss:0.2898 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.2826 Test MSE Loss: 0.2434
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4097505
	speed: 0.0505s/iter; left time: 1114.9281s
	iters: 200, epoch: 16 | loss: 3.3724692
	speed: 0.0482s/iter; left time: 1058.8048s
Epoch: 16 cost time: 12.87034010887146
Epoch: 16, Steps: 261 Train Loss: 3.3996 (Forecasting Loss:0.2898 + XiCon Loss:3.1098 x Lambda(1.0)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2434
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.16847282648086548, mae:0.31749144196510315, mape:0.7126543521881104, mspe:19.71269416809082 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6163
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6324282
	speed: 0.0459s/iter; left time: 1192.2209s
	iters: 200, epoch: 1 | loss: 3.5415342
	speed: 0.0423s/iter; left time: 1096.7203s
Epoch: 1 cost time: 11.49441123008728
Epoch: 1, Steps: 261 Train Loss: 3.5901 (Forecasting Loss:0.3729 + XiCon Loss:3.2172 x Lambda(1.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2803
Validation loss decreased (inf --> 0.319528).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3575475
	speed: 0.0460s/iter; left time: 1184.4340s
	iters: 200, epoch: 2 | loss: 3.3125648
	speed: 0.0447s/iter; left time: 1145.8069s
Epoch: 2 cost time: 11.710746049880981
Epoch: 2, Steps: 261 Train Loss: 3.3393 (Forecasting Loss:0.2992 + XiCon Loss:3.0401 x Lambda(1.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.2528
Validation loss decreased (0.319528 --> 0.290512).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2617650
	speed: 0.0466s/iter; left time: 1188.2144s
	iters: 200, epoch: 3 | loss: 3.2190168
	speed: 0.0448s/iter; left time: 1137.3723s
Epoch: 3 cost time: 11.886428117752075
Epoch: 3, Steps: 261 Train Loss: 3.2658 (Forecasting Loss:0.2904 + XiCon Loss:2.9754 x Lambda(1.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.2484
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2375777
	speed: 0.0477s/iter; left time: 1202.8499s
	iters: 200, epoch: 4 | loss: 3.3602772
	speed: 0.0446s/iter; left time: 1120.9504s
Epoch: 4 cost time: 12.054847240447998
Epoch: 4, Steps: 261 Train Loss: 3.3063 (Forecasting Loss:0.2892 + XiCon Loss:3.0171 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2489
Validation loss decreased (0.290512 --> 0.289029).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4142885
	speed: 0.0483s/iter; left time: 1205.6895s
	iters: 200, epoch: 5 | loss: 3.4118533
	speed: 0.0450s/iter; left time: 1117.8625s
Epoch: 5 cost time: 12.090120315551758
Epoch: 5, Steps: 261 Train Loss: 3.3788 (Forecasting Loss:0.2885 + XiCon Loss:3.0903 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2494
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4036767
	speed: 0.0482s/iter; left time: 1189.4129s
	iters: 200, epoch: 6 | loss: 3.4005611
	speed: 0.0459s/iter; left time: 1129.1395s
Epoch: 6 cost time: 12.204389333724976
Epoch: 6, Steps: 261 Train Loss: 3.4135 (Forecasting Loss:0.2877 + XiCon Loss:3.1258 x Lambda(1.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2494
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4021564
	speed: 0.0476s/iter; left time: 1161.9993s
	iters: 200, epoch: 7 | loss: 3.4749777
	speed: 0.0459s/iter; left time: 1117.2735s
Epoch: 7 cost time: 12.076679944992065
Epoch: 7, Steps: 261 Train Loss: 3.4308 (Forecasting Loss:0.2875 + XiCon Loss:3.1433 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2496
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3838911
	speed: 0.0474s/iter; left time: 1146.0542s
	iters: 200, epoch: 8 | loss: 3.4712052
	speed: 0.0462s/iter; left time: 1111.4508s
Epoch: 8 cost time: 12.12360405921936
Epoch: 8, Steps: 261 Train Loss: 3.4302 (Forecasting Loss:0.2871 + XiCon Loss:3.1430 x Lambda(1.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2496
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4424589
	speed: 0.0464s/iter; left time: 1108.5459s
	iters: 200, epoch: 9 | loss: 3.4487178
	speed: 0.0446s/iter; left time: 1062.7256s
Epoch: 9 cost time: 11.86513900756836
Epoch: 9, Steps: 261 Train Loss: 3.4336 (Forecasting Loss:0.2871 + XiCon Loss:3.1464 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2496
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4608693
	speed: 0.0466s/iter; left time: 1102.8945s
	iters: 200, epoch: 10 | loss: 3.3982451
	speed: 0.0461s/iter; left time: 1084.6232s
Epoch: 10 cost time: 11.99618673324585
Epoch: 10, Steps: 261 Train Loss: 3.4419 (Forecasting Loss:0.2869 + XiCon Loss:3.1550 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2496
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4510148
	speed: 0.0483s/iter; left time: 1129.5869s
	iters: 200, epoch: 11 | loss: 3.5138297
	speed: 0.0454s/iter; left time: 1057.1769s
Epoch: 11 cost time: 12.06498122215271
Epoch: 11, Steps: 261 Train Loss: 3.4357 (Forecasting Loss:0.2870 + XiCon Loss:3.1488 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2497
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4862444
	speed: 0.0470s/iter; left time: 1087.8328s
	iters: 200, epoch: 12 | loss: 3.3247933
	speed: 0.0461s/iter; left time: 1061.4971s
Epoch: 12 cost time: 11.986930847167969
Epoch: 12, Steps: 261 Train Loss: 3.4371 (Forecasting Loss:0.2870 + XiCon Loss:3.1501 x Lambda(1.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2497
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5570927
	speed: 0.0475s/iter; left time: 1087.1321s
	iters: 200, epoch: 13 | loss: 3.4180126
	speed: 0.0440s/iter; left time: 1001.3764s
Epoch: 13 cost time: 11.875739336013794
Epoch: 13, Steps: 261 Train Loss: 3.4396 (Forecasting Loss:0.2870 + XiCon Loss:3.1526 x Lambda(1.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2497
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4763124
	speed: 0.0481s/iter; left time: 1086.9557s
	iters: 200, epoch: 14 | loss: 3.3183966
	speed: 0.0450s/iter; left time: 1012.6036s
Epoch: 14 cost time: 12.042340755462646
Epoch: 14, Steps: 261 Train Loss: 3.4396 (Forecasting Loss:0.2870 + XiCon Loss:3.1526 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2497
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17372819781303406, mae:0.32398879528045654, mape:0.7003894448280334, mspe:18.389368057250977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6972
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6419797
	speed: 0.0478s/iter; left time: 1241.9926s
	iters: 200, epoch: 1 | loss: 3.5707335
	speed: 0.0448s/iter; left time: 1160.8638s
Epoch: 1 cost time: 11.978940725326538
Epoch: 1, Steps: 261 Train Loss: 3.6009 (Forecasting Loss:0.3728 + XiCon Loss:3.2281 x Lambda(1.0)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2817
Validation loss decreased (inf --> 0.324921).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3221297
	speed: 0.0463s/iter; left time: 1193.0474s
	iters: 200, epoch: 2 | loss: 3.2713082
	speed: 0.0416s/iter; left time: 1065.9988s
Epoch: 2 cost time: 11.526494026184082
Epoch: 2, Steps: 261 Train Loss: 3.3566 (Forecasting Loss:0.2989 + XiCon Loss:3.0577 x Lambda(1.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.2495
Validation loss decreased (0.324921 --> 0.290458).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2590125
	speed: 0.0464s/iter; left time: 1182.1987s
	iters: 200, epoch: 3 | loss: 3.2713451
	speed: 0.0436s/iter; left time: 1107.3244s
Epoch: 3 cost time: 11.674121379852295
Epoch: 3, Steps: 261 Train Loss: 3.2782 (Forecasting Loss:0.2880 + XiCon Loss:2.9902 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2470
Validation loss decreased (0.290458 --> 0.289813).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2455232
	speed: 0.0465s/iter; left time: 1173.7629s
	iters: 200, epoch: 4 | loss: 3.2504413
	speed: 0.0446s/iter; left time: 1120.5558s
Epoch: 4 cost time: 11.885798215866089
Epoch: 4, Steps: 261 Train Loss: 3.2715 (Forecasting Loss:0.2885 + XiCon Loss:2.9831 x Lambda(1.0)), Vali MSE Loss: 0.2880 Test MSE Loss: 0.2448
Validation loss decreased (0.289813 --> 0.287960).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3489020
	speed: 0.0465s/iter; left time: 1159.3903s
	iters: 200, epoch: 5 | loss: 3.4842668
	speed: 0.0461s/iter; left time: 1145.8837s
Epoch: 5 cost time: 12.092951774597168
Epoch: 5, Steps: 261 Train Loss: 3.3849 (Forecasting Loss:0.2942 + XiCon Loss:3.0908 x Lambda(1.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.2506
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4432864
	speed: 0.0475s/iter; left time: 1172.2057s
	iters: 200, epoch: 6 | loss: 3.3885534
	speed: 0.0446s/iter; left time: 1097.1961s
Epoch: 6 cost time: 11.953352928161621
Epoch: 6, Steps: 261 Train Loss: 3.4302 (Forecasting Loss:0.2942 + XiCon Loss:3.1360 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2520
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4710615
	speed: 0.0478s/iter; left time: 1167.1350s
	iters: 200, epoch: 7 | loss: 3.3769035
	speed: 0.0462s/iter; left time: 1124.6398s
Epoch: 7 cost time: 12.176712989807129
Epoch: 7, Steps: 261 Train Loss: 3.4430 (Forecasting Loss:0.2932 + XiCon Loss:3.1498 x Lambda(1.0)), Vali MSE Loss: 0.2865 Test MSE Loss: 0.2518
Validation loss decreased (0.287960 --> 0.286509).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4491220
	speed: 0.0472s/iter; left time: 1140.3121s
	iters: 200, epoch: 8 | loss: 3.4983773
	speed: 0.0449s/iter; left time: 1080.7327s
Epoch: 8 cost time: 12.166711568832397
Epoch: 8, Steps: 261 Train Loss: 3.4552 (Forecasting Loss:0.2928 + XiCon Loss:3.1624 x Lambda(1.0)), Vali MSE Loss: 0.2859 Test MSE Loss: 0.2517
Validation loss decreased (0.286509 --> 0.285861).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4377742
	speed: 0.0483s/iter; left time: 1154.8894s
	iters: 200, epoch: 9 | loss: 3.5597281
	speed: 0.0451s/iter; left time: 1074.5690s
Epoch: 9 cost time: 12.124459505081177
Epoch: 9, Steps: 261 Train Loss: 3.4527 (Forecasting Loss:0.2926 + XiCon Loss:3.1601 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
Validation loss decreased (0.285861 --> 0.285188).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4149041
	speed: 0.0478s/iter; left time: 1131.4604s
	iters: 200, epoch: 10 | loss: 3.4246101
	speed: 0.0426s/iter; left time: 1002.8991s
Epoch: 10 cost time: 11.724987983703613
Epoch: 10, Steps: 261 Train Loss: 3.4528 (Forecasting Loss:0.2924 + XiCon Loss:3.1604 x Lambda(1.0)), Vali MSE Loss: 0.2856 Test MSE Loss: 0.2515
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4971321
	speed: 0.0440s/iter; left time: 1029.2624s
	iters: 200, epoch: 11 | loss: 3.4938970
	speed: 0.0823s/iter; left time: 1916.4016s
Epoch: 11 cost time: 18.945379495620728
Epoch: 11, Steps: 261 Train Loss: 3.4499 (Forecasting Loss:0.2925 + XiCon Loss:3.1574 x Lambda(1.0)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2514
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5342450
	speed: 0.1256s/iter; left time: 2904.0134s
	iters: 200, epoch: 12 | loss: 3.4085913
	speed: 0.1110s/iter; left time: 2557.4497s
Epoch: 12 cost time: 29.833890438079834
Epoch: 12, Steps: 261 Train Loss: 3.4533 (Forecasting Loss:0.2924 + XiCon Loss:3.1609 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2514
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4790154
	speed: 0.0889s/iter; left time: 2033.9780s
	iters: 200, epoch: 13 | loss: 3.4176962
	speed: 0.0521s/iter; left time: 1186.8362s
Epoch: 13 cost time: 17.1107234954834
Epoch: 13, Steps: 261 Train Loss: 3.4491 (Forecasting Loss:0.2924 + XiCon Loss:3.1567 x Lambda(1.0)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2514
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4305825
	speed: 0.0446s/iter; left time: 1007.6739s
	iters: 200, epoch: 14 | loss: 3.4837143
	speed: 0.0408s/iter; left time: 919.1037s
Epoch: 14 cost time: 11.107098579406738
Epoch: 14, Steps: 261 Train Loss: 3.4505 (Forecasting Loss:0.2922 + XiCon Loss:3.1584 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4253120
	speed: 0.0432s/iter; left time: 964.8141s
	iters: 200, epoch: 15 | loss: 3.4781158
	speed: 0.0405s/iter; left time: 900.0649s
Epoch: 15 cost time: 10.895217657089233
Epoch: 15, Steps: 261 Train Loss: 3.4499 (Forecasting Loss:0.2924 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4502642
	speed: 0.0434s/iter; left time: 959.5730s
	iters: 200, epoch: 16 | loss: 3.4178505
	speed: 0.0407s/iter; left time: 894.3077s
Epoch: 16 cost time: 10.955204010009766
Epoch: 16, Steps: 261 Train Loss: 3.4536 (Forecasting Loss:0.2921 + XiCon Loss:3.1615 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4350781
	speed: 0.0433s/iter; left time: 944.5501s
	iters: 200, epoch: 17 | loss: 3.3717241
	speed: 0.0401s/iter; left time: 871.9299s
Epoch: 17 cost time: 10.852173328399658
Epoch: 17, Steps: 261 Train Loss: 3.4528 (Forecasting Loss:0.2924 + XiCon Loss:3.1603 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.4857259
	speed: 0.0430s/iter; left time: 927.9728s
	iters: 200, epoch: 18 | loss: 3.4248867
	speed: 0.0440s/iter; left time: 943.8059s
Epoch: 18 cost time: 11.387449741363525
Epoch: 18, Steps: 261 Train Loss: 3.4535 (Forecasting Loss:0.2922 + XiCon Loss:3.1613 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2514
Validation loss decreased (0.285188 --> 0.285139).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4494722
	speed: 0.0479s/iter; left time: 1021.1266s
	iters: 200, epoch: 19 | loss: 3.4734211
	speed: 0.0449s/iter; left time: 951.0165s
Epoch: 19 cost time: 11.990885496139526
Epoch: 19, Steps: 261 Train Loss: 3.4524 (Forecasting Loss:0.2924 + XiCon Loss:3.1600 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2514
Validation loss decreased (0.285139 --> 0.285116).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4665020
	speed: 0.0461s/iter; left time: 970.1185s
	iters: 200, epoch: 20 | loss: 3.4309399
	speed: 0.0447s/iter; left time: 935.1849s
Epoch: 20 cost time: 11.836547613143921
Epoch: 20, Steps: 261 Train Loss: 3.4511 (Forecasting Loss:0.2923 + XiCon Loss:3.1588 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2514
Validation loss decreased (0.285116 --> 0.285081).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.4275312
	speed: 0.0459s/iter; left time: 953.6293s
	iters: 200, epoch: 21 | loss: 3.4102311
	speed: 0.0450s/iter; left time: 930.2076s
Epoch: 21 cost time: 11.801494359970093
Epoch: 21, Steps: 261 Train Loss: 3.4535 (Forecasting Loss:0.2925 + XiCon Loss:3.1611 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.4944100
	speed: 0.0484s/iter; left time: 993.6786s
	iters: 200, epoch: 22 | loss: 3.5291946
	speed: 0.0444s/iter; left time: 907.2415s
Epoch: 22 cost time: 12.004648208618164
Epoch: 22, Steps: 261 Train Loss: 3.4500 (Forecasting Loss:0.2924 + XiCon Loss:3.1577 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.4747484
	speed: 0.0473s/iter; left time: 957.6139s
	iters: 200, epoch: 23 | loss: 3.4239707
	speed: 0.0451s/iter; left time: 908.5910s
Epoch: 23 cost time: 11.95628023147583
Epoch: 23, Steps: 261 Train Loss: 3.4543 (Forecasting Loss:0.2922 + XiCon Loss:3.1621 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2514
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.4285126
	speed: 0.0473s/iter; left time: 946.6125s
	iters: 200, epoch: 24 | loss: 3.4359763
	speed: 0.0445s/iter; left time: 885.0979s
Epoch: 24 cost time: 11.938550472259521
Epoch: 24, Steps: 261 Train Loss: 3.4525 (Forecasting Loss:0.2923 + XiCon Loss:3.1603 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2514
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.4890671
	speed: 0.0478s/iter; left time: 942.9223s
	iters: 200, epoch: 25 | loss: 3.5191572
	speed: 0.0447s/iter; left time: 878.6251s
Epoch: 25 cost time: 12.029614448547363
Epoch: 25, Steps: 261 Train Loss: 3.4582 (Forecasting Loss:0.2924 + XiCon Loss:3.1659 x Lambda(1.0)), Vali MSE Loss: 0.2850 Test MSE Loss: 0.2514
Validation loss decreased (0.285081 --> 0.285015).  Saving model ...
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.3979454
	speed: 0.0445s/iter; left time: 867.4065s
	iters: 200, epoch: 26 | loss: 3.4657273
	speed: 0.0410s/iter; left time: 793.8857s
Epoch: 26 cost time: 11.194252490997314
Epoch: 26, Steps: 261 Train Loss: 3.4510 (Forecasting Loss:0.2923 + XiCon Loss:3.1588 x Lambda(1.0)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2514
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.3826036
	speed: 0.0475s/iter; left time: 911.7696s
	iters: 200, epoch: 27 | loss: 3.4493241
	speed: 0.0442s/iter; left time: 845.5893s
Epoch: 27 cost time: 11.934711217880249
Epoch: 27, Steps: 261 Train Loss: 3.4511 (Forecasting Loss:0.2924 + XiCon Loss:3.1587 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.4818840
	speed: 0.0463s/iter; left time: 877.8581s
	iters: 200, epoch: 28 | loss: 3.5128899
	speed: 0.0447s/iter; left time: 843.5952s
Epoch: 28 cost time: 11.800875902175903
Epoch: 28, Steps: 261 Train Loss: 3.4519 (Forecasting Loss:0.2923 + XiCon Loss:3.1596 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.4443915
	speed: 0.0470s/iter; left time: 879.2864s
	iters: 200, epoch: 29 | loss: 3.3893526
	speed: 0.0450s/iter; left time: 836.1090s
Epoch: 29 cost time: 12.034934759140015
Epoch: 29, Steps: 261 Train Loss: 3.4542 (Forecasting Loss:0.2924 + XiCon Loss:3.1619 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.2514
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.4862251
	speed: 0.0473s/iter; left time: 871.4725s
	iters: 200, epoch: 30 | loss: 3.4364910
	speed: 0.0442s/iter; left time: 811.0812s
Epoch: 30 cost time: 11.922343492507935
Epoch: 30, Steps: 261 Train Loss: 3.4539 (Forecasting Loss:0.2923 + XiCon Loss:3.1616 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.4548190
	speed: 0.0469s/iter; left time: 852.3357s
	iters: 200, epoch: 31 | loss: 3.5119305
	speed: 0.0443s/iter; left time: 799.9681s
Epoch: 31 cost time: 11.85410737991333
Epoch: 31, Steps: 261 Train Loss: 3.4510 (Forecasting Loss:0.2924 + XiCon Loss:3.1585 x Lambda(1.0)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2514
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.3529339
	speed: 0.0468s/iter; left time: 837.5904s
	iters: 200, epoch: 32 | loss: 3.4008541
	speed: 0.0446s/iter; left time: 794.2173s
Epoch: 32 cost time: 11.879470109939575
Epoch: 32, Steps: 261 Train Loss: 3.4527 (Forecasting Loss:0.2923 + XiCon Loss:3.1604 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.3788669
	speed: 0.0477s/iter; left time: 842.2534s
	iters: 200, epoch: 33 | loss: 3.3872752
	speed: 0.0440s/iter; left time: 772.1411s
Epoch: 33 cost time: 11.96570897102356
Epoch: 33, Steps: 261 Train Loss: 3.4506 (Forecasting Loss:0.2924 + XiCon Loss:3.1582 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 3.5194969
	speed: 0.0480s/iter; left time: 835.2065s
	iters: 200, epoch: 34 | loss: 3.5202167
	speed: 0.0407s/iter; left time: 703.3257s
Epoch: 34 cost time: 11.398802518844604
Epoch: 34, Steps: 261 Train Loss: 3.4534 (Forecasting Loss:0.2924 + XiCon Loss:3.1610 x Lambda(1.0)), Vali MSE Loss: 0.2853 Test MSE Loss: 0.2514
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 35 | loss: 3.3141606
	speed: 0.0467s/iter; left time: 800.1156s
	iters: 200, epoch: 35 | loss: 3.3897624
	speed: 0.0452s/iter; left time: 769.7466s
Epoch: 35 cost time: 11.92147421836853
Epoch: 35, Steps: 261 Train Loss: 3.4520 (Forecasting Loss:0.2923 + XiCon Loss:3.1597 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2514
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1774948388338089, mae:0.3252708911895752, mape:0.6932507753372192, mspe:17.504549026489258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1167
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6654263
	speed: 0.0438s/iter; left time: 1139.2646s
	iters: 200, epoch: 1 | loss: 3.5575881
	speed: 0.0406s/iter; left time: 1052.7460s
Epoch: 1 cost time: 10.968079090118408
Epoch: 1, Steps: 261 Train Loss: 3.6136 (Forecasting Loss:0.3726 + XiCon Loss:3.2410 x Lambda(1.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2812
Validation loss decreased (inf --> 0.319654).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3223624
	speed: 0.0441s/iter; left time: 1135.6921s
	iters: 200, epoch: 2 | loss: 3.2858636
	speed: 0.0413s/iter; left time: 1057.7142s
Epoch: 2 cost time: 11.059198141098022
Epoch: 2, Steps: 261 Train Loss: 3.3594 (Forecasting Loss:0.2991 + XiCon Loss:3.0603 x Lambda(1.0)), Vali MSE Loss: 0.2921 Test MSE Loss: 0.2519
Validation loss decreased (0.319654 --> 0.292071).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3920941
	speed: 0.0445s/iter; left time: 1133.8931s
	iters: 200, epoch: 3 | loss: 3.3548467
	speed: 0.0405s/iter; left time: 1026.8510s
Epoch: 3 cost time: 11.006701469421387
Epoch: 3, Steps: 261 Train Loss: 3.3709 (Forecasting Loss:0.2937 + XiCon Loss:3.0772 x Lambda(1.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2499
Validation loss decreased (0.292071 --> 0.280166).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2855916
	speed: 0.0431s/iter; left time: 1087.4331s
	iters: 200, epoch: 4 | loss: 3.2896729
	speed: 0.0421s/iter; left time: 1057.1305s
Epoch: 4 cost time: 11.060220956802368
Epoch: 4, Steps: 261 Train Loss: 3.3670 (Forecasting Loss:0.2915 + XiCon Loss:3.0755 x Lambda(1.0)), Vali MSE Loss: 0.2767 Test MSE Loss: 0.2476
Validation loss decreased (0.280166 --> 0.276680).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3848503
	speed: 0.0445s/iter; left time: 1109.4875s
	iters: 200, epoch: 5 | loss: 3.4366536
	speed: 0.0424s/iter; left time: 1052.8669s
Epoch: 5 cost time: 11.327041625976562
Epoch: 5, Steps: 261 Train Loss: 3.3671 (Forecasting Loss:0.2906 + XiCon Loss:3.0766 x Lambda(1.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2501
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3902569
	speed: 0.0452s/iter; left time: 1115.7775s
	iters: 200, epoch: 6 | loss: 3.4250989
	speed: 0.0410s/iter; left time: 1008.1999s
Epoch: 6 cost time: 11.169436693191528
Epoch: 6, Steps: 261 Train Loss: 3.3670 (Forecasting Loss:0.2904 + XiCon Loss:3.0766 x Lambda(1.0)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.2507
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.2888017
	speed: 0.0407s/iter; left time: 995.4707s
	iters: 200, epoch: 7 | loss: 3.4184902
	speed: 0.0414s/iter; left time: 1007.0986s
Epoch: 7 cost time: 10.758544206619263
Epoch: 7, Steps: 261 Train Loss: 3.3608 (Forecasting Loss:0.2899 + XiCon Loss:3.0709 x Lambda(1.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2496
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4266696
	speed: 0.0464s/iter; left time: 1121.7086s
	iters: 200, epoch: 8 | loss: 3.3872931
	speed: 0.0415s/iter; left time: 999.6634s
Epoch: 8 cost time: 11.367721557617188
Epoch: 8, Steps: 261 Train Loss: 3.3618 (Forecasting Loss:0.2898 + XiCon Loss:3.0720 x Lambda(1.0)), Vali MSE Loss: 0.2774 Test MSE Loss: 0.2492
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3871558
	speed: 0.0430s/iter; left time: 1027.5294s
	iters: 200, epoch: 9 | loss: 3.3654411
	speed: 0.0422s/iter; left time: 1004.2374s
Epoch: 9 cost time: 11.02038025856018
Epoch: 9, Steps: 261 Train Loss: 3.3664 (Forecasting Loss:0.2901 + XiCon Loss:3.0763 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2494
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4114759
	speed: 0.0452s/iter; left time: 1068.4651s
	iters: 200, epoch: 10 | loss: 3.3982975
	speed: 0.0409s/iter; left time: 962.2387s
Epoch: 10 cost time: 11.335855484008789
Epoch: 10, Steps: 261 Train Loss: 3.3632 (Forecasting Loss:0.2899 + XiCon Loss:3.0733 x Lambda(1.0)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.2494
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3424382
	speed: 0.0443s/iter; left time: 1035.4752s
	iters: 200, epoch: 11 | loss: 3.4671822
	speed: 0.0413s/iter; left time: 960.9674s
Epoch: 11 cost time: 11.028427839279175
Epoch: 11, Steps: 261 Train Loss: 3.3678 (Forecasting Loss:0.2896 + XiCon Loss:3.0782 x Lambda(1.0)), Vali MSE Loss: 0.2783 Test MSE Loss: 0.2494
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3475108
	speed: 0.0445s/iter; left time: 1029.0708s
	iters: 200, epoch: 12 | loss: 3.3898654
	speed: 0.0412s/iter; left time: 949.4910s
Epoch: 12 cost time: 11.061450481414795
Epoch: 12, Steps: 261 Train Loss: 3.3661 (Forecasting Loss:0.2899 + XiCon Loss:3.0762 x Lambda(1.0)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.2494
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3156958
	speed: 0.0448s/iter; left time: 1023.8275s
	iters: 200, epoch: 13 | loss: 3.3847733
	speed: 0.0411s/iter; left time: 935.8783s
Epoch: 13 cost time: 11.181408643722534
Epoch: 13, Steps: 261 Train Loss: 3.3632 (Forecasting Loss:0.2898 + XiCon Loss:3.0733 x Lambda(1.0)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2494
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3172195
	speed: 0.0441s/iter; left time: 997.5404s
	iters: 200, epoch: 14 | loss: 3.3161154
	speed: 0.0433s/iter; left time: 974.1301s
Epoch: 14 cost time: 11.347455978393555
Epoch: 14, Steps: 261 Train Loss: 3.3636 (Forecasting Loss:0.2899 + XiCon Loss:3.0737 x Lambda(1.0)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.2494
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17291225492954254, mae:0.3222409784793854, mape:0.7278090119361877, mspe:20.67629051208496 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8482
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5767341
	speed: 0.0509s/iter; left time: 1323.7672s
	iters: 200, epoch: 1 | loss: 3.5401525
	speed: 0.0485s/iter; left time: 1256.5021s
Epoch: 1 cost time: 12.922398567199707
Epoch: 1, Steps: 261 Train Loss: 3.5911 (Forecasting Loss:0.3713 + XiCon Loss:3.2198 x Lambda(1.0)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2805
Validation loss decreased (inf --> 0.318436).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2689705
	speed: 0.0506s/iter; left time: 1302.6298s
	iters: 200, epoch: 2 | loss: 3.2441700
	speed: 0.0485s/iter; left time: 1244.5153s
Epoch: 2 cost time: 12.931242942810059
Epoch: 2, Steps: 261 Train Loss: 3.3275 (Forecasting Loss:0.3006 + XiCon Loss:3.0269 x Lambda(1.0)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.2472
Validation loss decreased (0.318436 --> 0.292269).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2751057
	speed: 0.0506s/iter; left time: 1289.7553s
	iters: 200, epoch: 3 | loss: 3.2891626
	speed: 0.0484s/iter; left time: 1227.7103s
Epoch: 3 cost time: 12.839489936828613
Epoch: 3, Steps: 261 Train Loss: 3.2677 (Forecasting Loss:0.2916 + XiCon Loss:2.9761 x Lambda(1.0)), Vali MSE Loss: 0.2864 Test MSE Loss: 0.2473
Validation loss decreased (0.292269 --> 0.286382).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3290200
	speed: 0.0511s/iter; left time: 1288.9992s
	iters: 200, epoch: 4 | loss: 3.3239226
	speed: 0.0483s/iter; left time: 1212.3533s
Epoch: 4 cost time: 12.864824056625366
Epoch: 4, Steps: 261 Train Loss: 3.3360 (Forecasting Loss:0.2911 + XiCon Loss:3.0449 x Lambda(1.0)), Vali MSE Loss: 0.2710 Test MSE Loss: 0.2425
Validation loss decreased (0.286382 --> 0.270992).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4735281
	speed: 0.0507s/iter; left time: 1266.2754s
	iters: 200, epoch: 5 | loss: 3.4522588
	speed: 0.0480s/iter; left time: 1192.6072s
Epoch: 5 cost time: 12.858546733856201
Epoch: 5, Steps: 261 Train Loss: 3.3832 (Forecasting Loss:0.2905 + XiCon Loss:3.0926 x Lambda(1.0)), Vali MSE Loss: 0.2762 Test MSE Loss: 0.2427
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4216325
	speed: 0.0516s/iter; left time: 1273.3976s
	iters: 200, epoch: 6 | loss: 3.3939972
	speed: 0.0482s/iter; left time: 1185.7726s
Epoch: 6 cost time: 13.019920587539673
Epoch: 6, Steps: 261 Train Loss: 3.3877 (Forecasting Loss:0.2900 + XiCon Loss:3.0976 x Lambda(1.0)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.2427
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4319692
	speed: 0.0506s/iter; left time: 1235.9188s
	iters: 200, epoch: 7 | loss: 3.3322558
	speed: 0.0491s/iter; left time: 1193.6566s
Epoch: 7 cost time: 13.062403678894043
Epoch: 7, Steps: 261 Train Loss: 3.3889 (Forecasting Loss:0.2898 + XiCon Loss:3.0992 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2431
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4326274
	speed: 0.0490s/iter; left time: 1185.2213s
	iters: 200, epoch: 8 | loss: 3.3891091
	speed: 0.0483s/iter; left time: 1162.6336s
Epoch: 8 cost time: 12.707814931869507
Epoch: 8, Steps: 261 Train Loss: 3.3862 (Forecasting Loss:0.2894 + XiCon Loss:3.0968 x Lambda(1.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2434
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3369193
	speed: 0.0510s/iter; left time: 1218.6062s
	iters: 200, epoch: 9 | loss: 3.3668940
	speed: 0.0484s/iter; left time: 1152.7101s
Epoch: 9 cost time: 13.00620698928833
Epoch: 9, Steps: 261 Train Loss: 3.3893 (Forecasting Loss:0.2896 + XiCon Loss:3.0997 x Lambda(1.0)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.2433
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4494586
	speed: 0.0509s/iter; left time: 1203.5348s
	iters: 200, epoch: 10 | loss: 3.4095674
	speed: 0.0485s/iter; left time: 1142.3441s
Epoch: 10 cost time: 12.954010725021362
Epoch: 10, Steps: 261 Train Loss: 3.3874 (Forecasting Loss:0.2893 + XiCon Loss:3.0981 x Lambda(1.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2435
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3834381
	speed: 0.0508s/iter; left time: 1187.8520s
	iters: 200, epoch: 11 | loss: 3.3546824
	speed: 0.0483s/iter; left time: 1124.5421s
Epoch: 11 cost time: 12.89226746559143
Epoch: 11, Steps: 261 Train Loss: 3.3846 (Forecasting Loss:0.2896 + XiCon Loss:3.0950 x Lambda(1.0)), Vali MSE Loss: 0.2793 Test MSE Loss: 0.2436
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3770156
	speed: 0.0515s/iter; left time: 1190.5794s
	iters: 200, epoch: 12 | loss: 3.4495203
	speed: 0.0493s/iter; left time: 1136.0032s
Epoch: 12 cost time: 13.075648546218872
Epoch: 12, Steps: 261 Train Loss: 3.3831 (Forecasting Loss:0.2894 + XiCon Loss:3.0937 x Lambda(1.0)), Vali MSE Loss: 0.2793 Test MSE Loss: 0.2435
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4225049
	speed: 0.0523s/iter; left time: 1195.0055s
	iters: 200, epoch: 13 | loss: 3.3838763
	speed: 0.0474s/iter; left time: 1080.0774s
Epoch: 13 cost time: 12.992896795272827
Epoch: 13, Steps: 261 Train Loss: 3.3861 (Forecasting Loss:0.2891 + XiCon Loss:3.0971 x Lambda(1.0)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.2435
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3224447
	speed: 0.0514s/iter; left time: 1161.8163s
	iters: 200, epoch: 14 | loss: 3.3607495
	speed: 0.0491s/iter; left time: 1104.2113s
Epoch: 14 cost time: 13.0286386013031
Epoch: 14, Steps: 261 Train Loss: 3.3880 (Forecasting Loss:0.2893 + XiCon Loss:3.0988 x Lambda(1.0)), Vali MSE Loss: 0.2793 Test MSE Loss: 0.2436
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.16782565414905548, mae:0.3170943856239319, mape:0.7096689343452454, mspe:19.551916122436523 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1721+-0.00496, MAE:0.3212+-0.00465, MAPE:0.7088+-0.01630, MSPE:19.1670+-1.53238, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
