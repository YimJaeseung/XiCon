Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5909
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2457037
	speed: 0.0419s/iter; left time: 532.2917s
Epoch: 1 cost time: 5.255277633666992
Epoch: 1, Steps: 128 Train Loss: 0.2470 (Forecasting Loss:0.2439 + XiCon Loss:3.1438 x Lambda(0.001)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1209
Validation loss decreased (inf --> 0.173761).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2584884
	speed: 0.0366s/iter; left time: 460.3462s
Epoch: 2 cost time: 4.471815824508667
Epoch: 2, Steps: 128 Train Loss: 0.2370 (Forecasting Loss:0.2338 + XiCon Loss:3.1294 x Lambda(0.001)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1343
Validation loss decreased (0.173761 --> 0.170326).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1745424
	speed: 0.0365s/iter; left time: 454.0496s
Epoch: 3 cost time: 4.688533306121826
Epoch: 3, Steps: 128 Train Loss: 0.1920 (Forecasting Loss:0.1889 + XiCon Loss:3.1367 x Lambda(0.001)), Vali MSE Loss: 0.1695 Test MSE Loss: 0.1585
Validation loss decreased (0.170326 --> 0.169505).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1468585
	speed: 0.0411s/iter; left time: 506.6360s
Epoch: 4 cost time: 5.227683067321777
Epoch: 4, Steps: 128 Train Loss: 0.1573 (Forecasting Loss:0.1542 + XiCon Loss:3.1389 x Lambda(0.001)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1559
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1363499
	speed: 0.0398s/iter; left time: 485.0772s
Epoch: 5 cost time: 5.076351642608643
Epoch: 5, Steps: 128 Train Loss: 0.1424 (Forecasting Loss:0.1393 + XiCon Loss:3.1380 x Lambda(0.001)), Vali MSE Loss: 0.1791 Test MSE Loss: 0.1599
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1314246
	speed: 0.0383s/iter; left time: 461.6845s
Epoch: 6 cost time: 4.79890251159668
Epoch: 6, Steps: 128 Train Loss: 0.1358 (Forecasting Loss:0.1327 + XiCon Loss:3.1371 x Lambda(0.001)), Vali MSE Loss: 0.1820 Test MSE Loss: 0.1594
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1216722
	speed: 0.0404s/iter; left time: 481.5968s
Epoch: 7 cost time: 4.9772021770477295
Epoch: 7, Steps: 128 Train Loss: 0.1327 (Forecasting Loss:0.1295 + XiCon Loss:3.1380 x Lambda(0.001)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.1622
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1295936
	speed: 0.0398s/iter; left time: 469.4912s
Epoch: 8 cost time: 5.088609457015991
Epoch: 8, Steps: 128 Train Loss: 0.1312 (Forecasting Loss:0.1281 + XiCon Loss:3.1388 x Lambda(0.001)), Vali MSE Loss: 0.1839 Test MSE Loss: 0.1624
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1477380
	speed: 0.0359s/iter; left time: 418.9571s
Epoch: 9 cost time: 4.7189717292785645
Epoch: 9, Steps: 128 Train Loss: 0.1305 (Forecasting Loss:0.1273 + XiCon Loss:3.1379 x Lambda(0.001)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1621
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1361139
	speed: 0.0391s/iter; left time: 451.8912s
Epoch: 10 cost time: 4.633756160736084
Epoch: 10, Steps: 128 Train Loss: 0.1301 (Forecasting Loss:0.1270 + XiCon Loss:3.1372 x Lambda(0.001)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1623
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1359991
	speed: 0.0401s/iter; left time: 458.5031s
Epoch: 11 cost time: 5.061619520187378
Epoch: 11, Steps: 128 Train Loss: 0.1298 (Forecasting Loss:0.1266 + XiCon Loss:3.1381 x Lambda(0.001)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1623
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1347399
	speed: 0.0400s/iter; left time: 451.8392s
Epoch: 12 cost time: 4.9782469272613525
Epoch: 12, Steps: 128 Train Loss: 0.1297 (Forecasting Loss:0.1265 + XiCon Loss:3.1384 x Lambda(0.001)), Vali MSE Loss: 0.1850 Test MSE Loss: 0.1625
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1350919
	speed: 0.0405s/iter; left time: 452.5604s
Epoch: 13 cost time: 5.125970840454102
Epoch: 13, Steps: 128 Train Loss: 0.1300 (Forecasting Loss:0.1269 + XiCon Loss:3.1382 x Lambda(0.001)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1626
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.08644942194223404, mae:0.2304832637310028, mape:0.1943870633840561, mspe:0.08499476313591003 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7034
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2382571
	speed: 0.0378s/iter; left time: 480.7072s
Epoch: 1 cost time: 4.926692485809326
Epoch: 1, Steps: 128 Train Loss: 0.2454 (Forecasting Loss:0.2423 + XiCon Loss:3.1347 x Lambda(0.001)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1241
Validation loss decreased (inf --> 0.182341).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2912696
	speed: 0.0390s/iter; left time: 490.3238s
Epoch: 2 cost time: 4.859074592590332
Epoch: 2, Steps: 128 Train Loss: 0.2520 (Forecasting Loss:0.2489 + XiCon Loss:3.1313 x Lambda(0.001)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1304
Validation loss decreased (0.182341 --> 0.181344).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2447407
	speed: 0.0351s/iter; left time: 437.3302s
Epoch: 3 cost time: 4.354763746261597
Epoch: 3, Steps: 128 Train Loss: 0.2319 (Forecasting Loss:0.2288 + XiCon Loss:3.1213 x Lambda(0.001)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1193
Validation loss decreased (0.181344 --> 0.168266).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2548403
	speed: 0.0332s/iter; left time: 408.7426s
Epoch: 4 cost time: 4.449921131134033
Epoch: 4, Steps: 128 Train Loss: 0.2233 (Forecasting Loss:0.2202 + XiCon Loss:3.1187 x Lambda(0.001)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1197
Validation loss decreased (0.168266 --> 0.166674).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2118483
	speed: 0.0383s/iter; left time: 467.0707s
Epoch: 5 cost time: 4.738708972930908
Epoch: 5, Steps: 128 Train Loss: 0.2188 (Forecasting Loss:0.2157 + XiCon Loss:3.1166 x Lambda(0.001)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1154
Validation loss decreased (0.166674 --> 0.166197).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2643960
	speed: 0.0410s/iter; left time: 494.9838s
Epoch: 6 cost time: 5.154576539993286
Epoch: 6, Steps: 128 Train Loss: 0.2158 (Forecasting Loss:0.2127 + XiCon Loss:3.1149 x Lambda(0.001)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1157
Validation loss decreased (0.166197 --> 0.165606).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2119096
	speed: 0.0405s/iter; left time: 482.7218s
Epoch: 7 cost time: 5.22300124168396
Epoch: 7, Steps: 128 Train Loss: 0.2144 (Forecasting Loss:0.2113 + XiCon Loss:3.1096 x Lambda(0.001)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1913231
	speed: 0.0407s/iter; left time: 480.8174s
Epoch: 8 cost time: 5.2624382972717285
Epoch: 8, Steps: 128 Train Loss: 0.2131 (Forecasting Loss:0.2100 + XiCon Loss:3.1095 x Lambda(0.001)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1165
Validation loss decreased (0.165606 --> 0.165517).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2179249
	speed: 0.0384s/iter; left time: 448.2875s
Epoch: 9 cost time: 4.609626770019531
Epoch: 9, Steps: 128 Train Loss: 0.2124 (Forecasting Loss:0.2093 + XiCon Loss:3.1079 x Lambda(0.001)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2036809
	speed: 0.0348s/iter; left time: 402.4083s
Epoch: 10 cost time: 4.361830949783325
Epoch: 10, Steps: 128 Train Loss: 0.2121 (Forecasting Loss:0.2090 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1993421
	speed: 0.0392s/iter; left time: 447.8485s
Epoch: 11 cost time: 4.904553413391113
Epoch: 11, Steps: 128 Train Loss: 0.2120 (Forecasting Loss:0.2089 + XiCon Loss:3.1066 x Lambda(0.001)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1168
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.2296047
	speed: 0.0371s/iter; left time: 418.7863s
Epoch: 12 cost time: 4.717448711395264
Epoch: 12, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1065 x Lambda(0.001)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1168
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1996913
	speed: 0.0426s/iter; left time: 476.0155s
Epoch: 13 cost time: 5.43408203125
Epoch: 13, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1078 x Lambda(0.001)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1169
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1841599
	speed: 0.0402s/iter; left time: 443.5782s
Epoch: 14 cost time: 5.219053506851196
Epoch: 14, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1053 x Lambda(0.001)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1169
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.2112799
	speed: 0.0423s/iter; left time: 461.9665s
Epoch: 15 cost time: 5.2831151485443115
Epoch: 15, Steps: 128 Train Loss: 0.2118 (Forecasting Loss:0.2087 + XiCon Loss:3.1082 x Lambda(0.001)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1169
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.2045757
	speed: 0.0360s/iter; left time: 388.3806s
Epoch: 16 cost time: 4.52062726020813
Epoch: 16, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1082 x Lambda(0.001)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1169
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.1774525
	speed: 0.0334s/iter; left time: 355.6850s
Epoch: 17 cost time: 4.485926389694214
Epoch: 17, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1077 x Lambda(0.001)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1169
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.1777197
	speed: 0.0396s/iter; left time: 417.2963s
Epoch: 18 cost time: 5.084784030914307
Epoch: 18, Steps: 128 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1058 x Lambda(0.001)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1169
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05458042025566101, mae:0.17849144339561462, mape:0.1422487050294876, mspe:0.03814806044101715 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6978
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2498353
	speed: 0.0385s/iter; left time: 489.4682s
Epoch: 1 cost time: 5.048757553100586
Epoch: 1, Steps: 128 Train Loss: 0.2500 (Forecasting Loss:0.2469 + XiCon Loss:3.1354 x Lambda(0.001)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1205
Validation loss decreased (inf --> 0.173795).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2244497
	speed: 0.0374s/iter; left time: 469.8103s
Epoch: 2 cost time: 4.9389729499816895
Epoch: 2, Steps: 128 Train Loss: 0.2488 (Forecasting Loss:0.2457 + XiCon Loss:3.1433 x Lambda(0.001)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1416
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2052571
	speed: 0.0397s/iter; left time: 494.5153s
Epoch: 3 cost time: 4.982604742050171
Epoch: 3, Steps: 128 Train Loss: 0.2091 (Forecasting Loss:0.2060 + XiCon Loss:3.0887 x Lambda(0.001)), Vali MSE Loss: 0.1906 Test MSE Loss: 0.1383
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2018772
	speed: 0.0375s/iter; left time: 461.3419s
Epoch: 4 cost time: 4.838783264160156
Epoch: 4, Steps: 128 Train Loss: 0.1812 (Forecasting Loss:0.1781 + XiCon Loss:3.0868 x Lambda(0.001)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1529
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1853777
	speed: 0.0320s/iter; left time: 390.3969s
Epoch: 5 cost time: 4.317324876785278
Epoch: 5, Steps: 128 Train Loss: 0.1674 (Forecasting Loss:0.1643 + XiCon Loss:3.0851 x Lambda(0.001)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1514
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1702760
	speed: 0.0384s/iter; left time: 463.4363s
Epoch: 6 cost time: 4.585202217102051
Epoch: 6, Steps: 128 Train Loss: 0.1610 (Forecasting Loss:0.1579 + XiCon Loss:3.0826 x Lambda(0.001)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1518
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1685741
	speed: 0.0405s/iter; left time: 482.8509s
Epoch: 7 cost time: 5.217909097671509
Epoch: 7, Steps: 128 Train Loss: 0.1578 (Forecasting Loss:0.1547 + XiCon Loss:3.0842 x Lambda(0.001)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1568
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1510479
	speed: 0.0382s/iter; left time: 451.4031s
Epoch: 8 cost time: 4.9258482456207275
Epoch: 8, Steps: 128 Train Loss: 0.1563 (Forecasting Loss:0.1533 + XiCon Loss:3.0825 x Lambda(0.001)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1555
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1478951
	speed: 0.0402s/iter; left time: 469.7736s
Epoch: 9 cost time: 5.0761377811431885
Epoch: 9, Steps: 128 Train Loss: 0.1555 (Forecasting Loss:0.1524 + XiCon Loss:3.0804 x Lambda(0.001)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1547
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1579737
	speed: 0.0375s/iter; left time: 433.1750s
Epoch: 10 cost time: 4.5663440227508545
Epoch: 10, Steps: 128 Train Loss: 0.1550 (Forecasting Loss:0.1519 + XiCon Loss:3.0814 x Lambda(0.001)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1557
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1487799
	speed: 0.0393s/iter; left time: 448.7361s
Epoch: 11 cost time: 5.163255929946899
Epoch: 11, Steps: 128 Train Loss: 0.1548 (Forecasting Loss:0.1517 + XiCon Loss:3.0813 x Lambda(0.001)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1557
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.057113878428936005, mae:0.18388456106185913, mape:0.14685481786727905, mspe:0.04061392694711685 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8001
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2491753
	speed: 0.0403s/iter; left time: 511.4511s
Epoch: 1 cost time: 4.976580619812012
Epoch: 1, Steps: 128 Train Loss: 0.2478 (Forecasting Loss:0.2447 + XiCon Loss:3.1294 x Lambda(0.001)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1233
Validation loss decreased (inf --> 0.174220).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2226663
	speed: 0.0393s/iter; left time: 494.4545s
Epoch: 2 cost time: 5.102824449539185
Epoch: 2, Steps: 128 Train Loss: 0.2489 (Forecasting Loss:0.2457 + XiCon Loss:3.2252 x Lambda(0.001)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2523438
	speed: 0.0385s/iter; left time: 478.5667s
Epoch: 3 cost time: 4.915278673171997
Epoch: 3, Steps: 128 Train Loss: 0.2353 (Forecasting Loss:0.2320 + XiCon Loss:3.2353 x Lambda(0.001)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1209
Validation loss decreased (0.174220 --> 0.170042).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2126349
	speed: 0.0426s/iter; left time: 525.2874s
Epoch: 4 cost time: 5.345611333847046
Epoch: 4, Steps: 128 Train Loss: 0.2255 (Forecasting Loss:0.2223 + XiCon Loss:3.2371 x Lambda(0.001)), Vali MSE Loss: 0.1668 Test MSE Loss: 0.1203
Validation loss decreased (0.170042 --> 0.166752).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2071142
	speed: 0.0419s/iter; left time: 511.2035s
Epoch: 5 cost time: 5.165729284286499
Epoch: 5, Steps: 128 Train Loss: 0.2211 (Forecasting Loss:0.2179 + XiCon Loss:3.2363 x Lambda(0.001)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1155
Validation loss decreased (0.166752 --> 0.164951).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2324479
	speed: 0.0412s/iter; left time: 496.9600s
Epoch: 6 cost time: 5.302077293395996
Epoch: 6, Steps: 128 Train Loss: 0.2188 (Forecasting Loss:0.2156 + XiCon Loss:3.2349 x Lambda(0.001)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1170
Validation loss decreased (0.164951 --> 0.163931).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2010644
	speed: 0.0342s/iter; left time: 407.8248s
Epoch: 7 cost time: 4.500204086303711
Epoch: 7, Steps: 128 Train Loss: 0.2176 (Forecasting Loss:0.2144 + XiCon Loss:3.2369 x Lambda(0.001)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
Validation loss decreased (0.163931 --> 0.163359).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2465943
	speed: 0.0394s/iter; left time: 465.5600s
Epoch: 8 cost time: 4.787227392196655
Epoch: 8, Steps: 128 Train Loss: 0.2170 (Forecasting Loss:0.2138 + XiCon Loss:3.2360 x Lambda(0.001)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2234862
	speed: 0.0440s/iter; left time: 514.2866s
Epoch: 9 cost time: 5.553181886672974
Epoch: 9, Steps: 128 Train Loss: 0.2168 (Forecasting Loss:0.2136 + XiCon Loss:3.2353 x Lambda(0.001)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2327540
	speed: 0.0433s/iter; left time: 500.5675s
Epoch: 10 cost time: 5.472134113311768
Epoch: 10, Steps: 128 Train Loss: 0.2168 (Forecasting Loss:0.2135 + XiCon Loss:3.2352 x Lambda(0.001)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1161
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2254502
	speed: 0.0381s/iter; left time: 435.6204s
Epoch: 11 cost time: 4.943172216415405
Epoch: 11, Steps: 128 Train Loss: 0.2165 (Forecasting Loss:0.2132 + XiCon Loss:3.2376 x Lambda(0.001)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.2149092
	speed: 0.0384s/iter; left time: 433.5956s
Epoch: 12 cost time: 4.975542068481445
Epoch: 12, Steps: 128 Train Loss: 0.2167 (Forecasting Loss:0.2134 + XiCon Loss:3.2364 x Lambda(0.001)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.2547075
	speed: 0.0391s/iter; left time: 436.0329s
Epoch: 13 cost time: 4.6580822467803955
Epoch: 13, Steps: 128 Train Loss: 0.2166 (Forecasting Loss:0.2133 + XiCon Loss:3.2354 x Lambda(0.001)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.2178506
	speed: 0.0349s/iter; left time: 384.9084s
Epoch: 14 cost time: 4.435362100601196
Epoch: 14, Steps: 128 Train Loss: 0.2165 (Forecasting Loss:0.2133 + XiCon Loss:3.2347 x Lambda(0.001)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.2357454
	speed: 0.0393s/iter; left time: 428.6953s
Epoch: 15 cost time: 4.487210750579834
Epoch: 15, Steps: 128 Train Loss: 0.2164 (Forecasting Loss:0.2132 + XiCon Loss:3.2360 x Lambda(0.001)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.2155865
	speed: 0.0412s/iter; left time: 443.8984s
Epoch: 16 cost time: 5.129517316818237
Epoch: 16, Steps: 128 Train Loss: 0.2164 (Forecasting Loss:0.2132 + XiCon Loss:3.2357 x Lambda(0.001)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.2036439
	speed: 0.0391s/iter; left time: 416.0103s
Epoch: 17 cost time: 4.9802141189575195
Epoch: 17, Steps: 128 Train Loss: 0.2165 (Forecasting Loss:0.2133 + XiCon Loss:3.2344 x Lambda(0.001)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0544009692966938, mae:0.17748409509658813, mape:0.14105695486068726, mspe:0.037406157702207565 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7222
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2339595
	speed: 0.0389s/iter; left time: 494.6395s
Epoch: 1 cost time: 4.891152620315552
Epoch: 1, Steps: 128 Train Loss: 0.2454 (Forecasting Loss:0.2423 + XiCon Loss:3.1337 x Lambda(0.001)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1210
Validation loss decreased (inf --> 0.171495).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2778114
	speed: 0.0374s/iter; left time: 470.1637s
Epoch: 2 cost time: 4.867997169494629
Epoch: 2, Steps: 128 Train Loss: 0.2454 (Forecasting Loss:0.2422 + XiCon Loss:3.1926 x Lambda(0.001)), Vali MSE Loss: 0.1784 Test MSE Loss: 0.1267
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2413218
	speed: 0.0396s/iter; left time: 492.5953s
Epoch: 3 cost time: 4.9752068519592285
Epoch: 3, Steps: 128 Train Loss: 0.2203 (Forecasting Loss:0.2171 + XiCon Loss:3.2006 x Lambda(0.001)), Vali MSE Loss: 0.1750 Test MSE Loss: 0.1291
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1856241
	speed: 0.0365s/iter; left time: 449.4507s
Epoch: 4 cost time: 4.655060052871704
Epoch: 4, Steps: 128 Train Loss: 0.1940 (Forecasting Loss:0.1908 + XiCon Loss:3.1953 x Lambda(0.001)), Vali MSE Loss: 0.1792 Test MSE Loss: 0.1304
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1645656
	speed: 0.0342s/iter; left time: 417.3659s
Epoch: 5 cost time: 4.386031866073608
Epoch: 5, Steps: 128 Train Loss: 0.1790 (Forecasting Loss:0.1758 + XiCon Loss:3.1907 x Lambda(0.001)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1336
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1699623
	speed: 0.0401s/iter; left time: 483.8713s
Epoch: 6 cost time: 5.185080289840698
Epoch: 6, Steps: 128 Train Loss: 0.1699 (Forecasting Loss:0.1667 + XiCon Loss:3.1857 x Lambda(0.001)), Vali MSE Loss: 0.1799 Test MSE Loss: 0.1329
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1623334
	speed: 0.0392s/iter; left time: 467.7039s
Epoch: 7 cost time: 4.907891035079956
Epoch: 7, Steps: 128 Train Loss: 0.1653 (Forecasting Loss:0.1622 + XiCon Loss:3.1846 x Lambda(0.001)), Vali MSE Loss: 0.1867 Test MSE Loss: 0.1330
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1653811
	speed: 0.0401s/iter; left time: 473.8945s
Epoch: 8 cost time: 5.3357391357421875
Epoch: 8, Steps: 128 Train Loss: 0.1626 (Forecasting Loss:0.1594 + XiCon Loss:3.1833 x Lambda(0.001)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1341
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1855860
	speed: 0.0430s/iter; left time: 501.9801s
Epoch: 9 cost time: 5.191141843795776
Epoch: 9, Steps: 128 Train Loss: 0.1619 (Forecasting Loss:0.1587 + XiCon Loss:3.1839 x Lambda(0.001)), Vali MSE Loss: 0.1871 Test MSE Loss: 0.1347
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1556732
	speed: 0.0361s/iter; left time: 417.0363s
Epoch: 10 cost time: 4.802714586257935
Epoch: 10, Steps: 128 Train Loss: 0.1611 (Forecasting Loss:0.1580 + XiCon Loss:3.1825 x Lambda(0.001)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1344
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1415716
	speed: 0.0327s/iter; left time: 373.2369s
Epoch: 11 cost time: 4.390396595001221
Epoch: 11, Steps: 128 Train Loss: 0.1607 (Forecasting Loss:0.1575 + XiCon Loss:3.1835 x Lambda(0.001)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1348
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.057395584881305695, mae:0.18458527326583862, mape:0.14677336812019348, mspe:0.040201496332883835 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0620+-0.01707, MAE:0.1910+-0.02769, MAPE:0.1543+-0.02804, MSPE:0.0483+-0.02554, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4723
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3347161
	speed: 0.0631s/iter; left time: 738.3379s
Epoch: 1 cost time: 7.361523151397705
Epoch: 1, Steps: 118 Train Loss: 0.3700 (Forecasting Loss:0.3669 + XiCon Loss:3.1546 x Lambda(0.001)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1731
Validation loss decreased (inf --> 0.266063).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2491042
	speed: 0.0678s/iter; left time: 785.1730s
Epoch: 2 cost time: 8.082418203353882
Epoch: 2, Steps: 118 Train Loss: 0.2761 (Forecasting Loss:0.2729 + XiCon Loss:3.1399 x Lambda(0.001)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.1562
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2327281
	speed: 0.0719s/iter; left time: 824.2993s
Epoch: 3 cost time: 8.40703797340393
Epoch: 3, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2289 + XiCon Loss:3.1234 x Lambda(0.001)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2139628
	speed: 0.0680s/iter; left time: 771.7490s
Epoch: 4 cost time: 7.843840599060059
Epoch: 4, Steps: 118 Train Loss: 0.2210 (Forecasting Loss:0.2179 + XiCon Loss:3.1189 x Lambda(0.001)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.1410
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2184582
	speed: 0.0667s/iter; left time: 748.5900s
Epoch: 5 cost time: 7.9608542919158936
Epoch: 5, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.1130 x Lambda(0.001)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1398
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2199354
	speed: 0.0668s/iter; left time: 742.7602s
Epoch: 6 cost time: 7.944497108459473
Epoch: 6, Steps: 118 Train Loss: 0.2135 (Forecasting Loss:0.2104 + XiCon Loss:3.1119 x Lambda(0.001)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.1392
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2208778
	speed: 0.0705s/iter; left time: 775.3872s
Epoch: 7 cost time: 8.35295844078064
Epoch: 7, Steps: 118 Train Loss: 0.2122 (Forecasting Loss:0.2091 + XiCon Loss:3.1130 x Lambda(0.001)), Vali MSE Loss: 0.2974 Test MSE Loss: 0.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2096273
	speed: 0.0662s/iter; left time: 720.1561s
Epoch: 8 cost time: 7.7354350090026855
Epoch: 8, Steps: 118 Train Loss: 0.2117 (Forecasting Loss:0.2086 + XiCon Loss:3.1121 x Lambda(0.001)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.1393
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2164735
	speed: 0.0564s/iter; left time: 607.2251s
Epoch: 9 cost time: 6.713149309158325
Epoch: 9, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2083 + XiCon Loss:3.1113 x Lambda(0.001)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.1397
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2330888
	speed: 0.0692s/iter; left time: 736.5783s
Epoch: 10 cost time: 8.535147666931152
Epoch: 10, Steps: 118 Train Loss: 0.2112 (Forecasting Loss:0.2081 + XiCon Loss:3.1103 x Lambda(0.001)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1398
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2088326
	speed: 0.0679s/iter; left time: 713.9759s
Epoch: 11 cost time: 7.445270538330078
Epoch: 11, Steps: 118 Train Loss: 0.2110 (Forecasting Loss:0.2079 + XiCon Loss:3.1120 x Lambda(0.001)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.1397
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09868037700653076, mae:0.24750502407550812, mape:0.17990420758724213, mspe:0.05168655887246132 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5209
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3196078
	speed: 0.0441s/iter; left time: 515.6359s
Epoch: 1 cost time: 5.343017578125
Epoch: 1, Steps: 118 Train Loss: 0.3719 (Forecasting Loss:0.3687 + XiCon Loss:3.1579 x Lambda(0.001)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1671
Validation loss decreased (inf --> 0.257845).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2658276
	speed: 0.0640s/iter; left time: 740.7514s
Epoch: 2 cost time: 7.551793575286865
Epoch: 2, Steps: 118 Train Loss: 0.2796 (Forecasting Loss:0.2764 + XiCon Loss:3.1460 x Lambda(0.001)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2344815
	speed: 0.0661s/iter; left time: 757.6028s
Epoch: 3 cost time: 7.906087160110474
Epoch: 3, Steps: 118 Train Loss: 0.2334 (Forecasting Loss:0.2303 + XiCon Loss:3.1375 x Lambda(0.001)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.1378
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2161087
	speed: 0.0676s/iter; left time: 767.0772s
Epoch: 4 cost time: 8.003726720809937
Epoch: 4, Steps: 118 Train Loss: 0.2231 (Forecasting Loss:0.2200 + XiCon Loss:3.1388 x Lambda(0.001)), Vali MSE Loss: 0.2973 Test MSE Loss: 0.1384
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2262475
	speed: 0.0618s/iter; left time: 694.3028s
Epoch: 5 cost time: 7.304379940032959
Epoch: 5, Steps: 118 Train Loss: 0.2187 (Forecasting Loss:0.2155 + XiCon Loss:3.1374 x Lambda(0.001)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2099685
	speed: 0.0311s/iter; left time: 345.4971s
Epoch: 6 cost time: 3.652754545211792
Epoch: 6, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2125 + XiCon Loss:3.1367 x Lambda(0.001)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2260113
	speed: 0.0624s/iter; left time: 685.7303s
Epoch: 7 cost time: 7.536054372787476
Epoch: 7, Steps: 118 Train Loss: 0.2142 (Forecasting Loss:0.2110 + XiCon Loss:3.1351 x Lambda(0.001)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.1365
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2217491
	speed: 0.0681s/iter; left time: 740.6822s
Epoch: 8 cost time: 7.866245985031128
Epoch: 8, Steps: 118 Train Loss: 0.2133 (Forecasting Loss:0.2102 + XiCon Loss:3.1330 x Lambda(0.001)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.1367
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2080388
	speed: 0.0684s/iter; left time: 736.2289s
Epoch: 9 cost time: 8.038849115371704
Epoch: 9, Steps: 118 Train Loss: 0.2130 (Forecasting Loss:0.2098 + XiCon Loss:3.1338 x Lambda(0.001)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.1368
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2054798
	speed: 0.0672s/iter; left time: 714.4661s
Epoch: 10 cost time: 7.838289022445679
Epoch: 10, Steps: 118 Train Loss: 0.2128 (Forecasting Loss:0.2097 + XiCon Loss:3.1342 x Lambda(0.001)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.1369
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2250933
	speed: 0.0594s/iter; left time: 624.4239s
Epoch: 11 cost time: 6.492204189300537
Epoch: 11, Steps: 118 Train Loss: 0.2126 (Forecasting Loss:0.2094 + XiCon Loss:3.1345 x Lambda(0.001)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.1369
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09307640045881271, mae:0.2412029504776001, mape:0.17679038643836975, mspe:0.050458699464797974 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3906
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3349776
	speed: 0.0395s/iter; left time: 461.6610s
Epoch: 1 cost time: 4.989677906036377
Epoch: 1, Steps: 118 Train Loss: 0.3539 (Forecasting Loss:0.3508 + XiCon Loss:3.1549 x Lambda(0.001)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1573
Validation loss decreased (inf --> 0.246947).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2850944
	speed: 0.0581s/iter; left time: 672.8301s
Epoch: 2 cost time: 6.800518274307251
Epoch: 2, Steps: 118 Train Loss: 0.3010 (Forecasting Loss:0.2979 + XiCon Loss:3.1324 x Lambda(0.001)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1518
Validation loss decreased (0.246947 --> 0.220773).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2350012
	speed: 0.0577s/iter; left time: 661.0917s
Epoch: 3 cost time: 6.7971906661987305
Epoch: 3, Steps: 118 Train Loss: 0.2450 (Forecasting Loss:0.2419 + XiCon Loss:3.1133 x Lambda(0.001)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1485
Validation loss decreased (0.220773 --> 0.219126).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2245657
	speed: 0.0575s/iter; left time: 652.2424s
Epoch: 4 cost time: 6.781773328781128
Epoch: 4, Steps: 118 Train Loss: 0.2268 (Forecasting Loss:0.2237 + XiCon Loss:3.1055 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1416
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2270054
	speed: 0.0578s/iter; left time: 649.4899s
Epoch: 5 cost time: 6.7044358253479
Epoch: 5, Steps: 118 Train Loss: 0.2208 (Forecasting Loss:0.2177 + XiCon Loss:3.1042 x Lambda(0.001)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.1424
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2193774
	speed: 0.0519s/iter; left time: 576.8400s
Epoch: 6 cost time: 5.7284979820251465
Epoch: 6, Steps: 118 Train Loss: 0.2181 (Forecasting Loss:0.2150 + XiCon Loss:3.1051 x Lambda(0.001)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1427
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2321375
	speed: 0.0270s/iter; left time: 296.4331s
Epoch: 7 cost time: 3.2015676498413086
Epoch: 7, Steps: 118 Train Loss: 0.2171 (Forecasting Loss:0.2140 + XiCon Loss:3.1029 x Lambda(0.001)), Vali MSE Loss: 0.2247 Test MSE Loss: 0.1431
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2288956
	speed: 0.0616s/iter; left time: 670.2436s
Epoch: 8 cost time: 7.249207973480225
Epoch: 8, Steps: 118 Train Loss: 0.2165 (Forecasting Loss:0.2134 + XiCon Loss:3.1017 x Lambda(0.001)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1429
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2171055
	speed: 0.0601s/iter; left time: 646.1530s
Epoch: 9 cost time: 6.968592643737793
Epoch: 9, Steps: 118 Train Loss: 0.2160 (Forecasting Loss:0.2129 + XiCon Loss:3.1012 x Lambda(0.001)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1424
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2269012
	speed: 0.0578s/iter; left time: 614.4723s
Epoch: 10 cost time: 6.757086515426636
Epoch: 10, Steps: 118 Train Loss: 0.2159 (Forecasting Loss:0.2128 + XiCon Loss:3.1023 x Lambda(0.001)), Vali MSE Loss: 0.2245 Test MSE Loss: 0.1424
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2132622
	speed: 0.0570s/iter; left time: 599.3161s
Epoch: 11 cost time: 6.762222528457642
Epoch: 11, Steps: 118 Train Loss: 0.2158 (Forecasting Loss:0.2127 + XiCon Loss:3.1020 x Lambda(0.001)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1426
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2189422
	speed: 0.0531s/iter; left time: 552.4359s
Epoch: 12 cost time: 6.222934722900391
Epoch: 12, Steps: 118 Train Loss: 0.2157 (Forecasting Loss:0.2126 + XiCon Loss:3.1026 x Lambda(0.001)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.1426
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2202094
	speed: 0.0286s/iter; left time: 294.4561s
Epoch: 13 cost time: 3.333805799484253
Epoch: 13, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.1011 x Lambda(0.001)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.1427
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07594993710517883, mae:0.22111840546131134, mape:0.1687038391828537, mspe:0.04962633550167084 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6727
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3328031
	speed: 0.0562s/iter; left time: 657.9407s
Epoch: 1 cost time: 6.597947359085083
Epoch: 1, Steps: 118 Train Loss: 0.3543 (Forecasting Loss:0.3512 + XiCon Loss:3.1546 x Lambda(0.001)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.1660
Validation loss decreased (inf --> 0.253506).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2801814
	speed: 0.0625s/iter; left time: 723.8971s
Epoch: 2 cost time: 7.361287832260132
Epoch: 2, Steps: 118 Train Loss: 0.3152 (Forecasting Loss:0.3120 + XiCon Loss:3.1693 x Lambda(0.001)), Vali MSE Loss: 0.2697 Test MSE Loss: 0.1635
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2177864
	speed: 0.0604s/iter; left time: 692.3342s
Epoch: 3 cost time: 7.3081090450286865
Epoch: 3, Steps: 118 Train Loss: 0.2419 (Forecasting Loss:0.2387 + XiCon Loss:3.1474 x Lambda(0.001)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.1450
Validation loss decreased (0.253506 --> 0.231940).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2445812
	speed: 0.0624s/iter; left time: 707.5951s
Epoch: 4 cost time: 7.410251140594482
Epoch: 4, Steps: 118 Train Loss: 0.2236 (Forecasting Loss:0.2205 + XiCon Loss:3.1408 x Lambda(0.001)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1437
Validation loss decreased (0.231940 --> 0.217357).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2009106
	speed: 0.0605s/iter; left time: 678.9217s
Epoch: 5 cost time: 7.108764886856079
Epoch: 5, Steps: 118 Train Loss: 0.2179 (Forecasting Loss:0.2147 + XiCon Loss:3.1425 x Lambda(0.001)), Vali MSE Loss: 0.2251 Test MSE Loss: 0.1449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2107602
	speed: 0.0287s/iter; left time: 318.8388s
Epoch: 6 cost time: 3.4249680042266846
Epoch: 6, Steps: 118 Train Loss: 0.2151 (Forecasting Loss:0.2119 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.2240 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2096016
	speed: 0.0629s/iter; left time: 691.9867s
Epoch: 7 cost time: 7.469719886779785
Epoch: 7, Steps: 118 Train Loss: 0.2138 (Forecasting Loss:0.2106 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.2213 Test MSE Loss: 0.1423
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2174545
	speed: 0.0644s/iter; left time: 700.8348s
Epoch: 8 cost time: 7.600203990936279
Epoch: 8, Steps: 118 Train Loss: 0.2130 (Forecasting Loss:0.2098 + XiCon Loss:3.1424 x Lambda(0.001)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1435
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2011261
	speed: 0.0635s/iter; left time: 683.1519s
Epoch: 9 cost time: 7.584450721740723
Epoch: 9, Steps: 118 Train Loss: 0.2126 (Forecasting Loss:0.2094 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.2230 Test MSE Loss: 0.1431
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2074120
	speed: 0.0628s/iter; left time: 668.6221s
Epoch: 10 cost time: 7.484015226364136
Epoch: 10, Steps: 118 Train Loss: 0.2124 (Forecasting Loss:0.2093 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1430
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2075677
	speed: 0.0572s/iter; left time: 601.2864s
Epoch: 11 cost time: 6.766466379165649
Epoch: 11, Steps: 118 Train Loss: 0.2123 (Forecasting Loss:0.2091 + XiCon Loss:3.1433 x Lambda(0.001)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1431
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2098309
	speed: 0.0286s/iter; left time: 297.8754s
Epoch: 12 cost time: 3.3617711067199707
Epoch: 12, Steps: 118 Train Loss: 0.2121 (Forecasting Loss:0.2090 + XiCon Loss:3.1439 x Lambda(0.001)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1430
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2171866
	speed: 0.0631s/iter; left time: 649.2057s
Epoch: 13 cost time: 7.446516036987305
Epoch: 13, Steps: 118 Train Loss: 0.2124 (Forecasting Loss:0.2092 + XiCon Loss:3.1445 x Lambda(0.001)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1430
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2132963
	speed: 0.0643s/iter; left time: 653.3435s
Epoch: 14 cost time: 7.654386520385742
Epoch: 14, Steps: 118 Train Loss: 0.2124 (Forecasting Loss:0.2092 + XiCon Loss:3.1440 x Lambda(0.001)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1430
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07245349138975143, mae:0.21494482457637787, mape:0.1619136929512024, mspe:0.04524010419845581 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7365
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3250501
	speed: 0.0609s/iter; left time: 712.3971s
Epoch: 1 cost time: 7.1007702350616455
Epoch: 1, Steps: 118 Train Loss: 0.3625 (Forecasting Loss:0.3594 + XiCon Loss:3.1300 x Lambda(0.001)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1637
Validation loss decreased (inf --> 0.252238).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2579744
	speed: 0.0590s/iter; left time: 682.8389s
Epoch: 2 cost time: 6.745394229888916
Epoch: 2, Steps: 118 Train Loss: 0.2980 (Forecasting Loss:0.2949 + XiCon Loss:3.0975 x Lambda(0.001)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.1510
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2396381
	speed: 0.0583s/iter; left time: 668.9538s
Epoch: 3 cost time: 6.395703077316284
Epoch: 3, Steps: 118 Train Loss: 0.2371 (Forecasting Loss:0.2340 + XiCon Loss:3.0585 x Lambda(0.001)), Vali MSE Loss: 0.2846 Test MSE Loss: 0.1493
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2254091
	speed: 0.0315s/iter; left time: 357.3348s
Epoch: 4 cost time: 4.1074182987213135
Epoch: 4, Steps: 118 Train Loss: 0.2227 (Forecasting Loss:0.2197 + XiCon Loss:3.0442 x Lambda(0.001)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.1496
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2168219
	speed: 0.0676s/iter; left time: 758.7453s
Epoch: 5 cost time: 8.016180753707886
Epoch: 5, Steps: 118 Train Loss: 0.2173 (Forecasting Loss:0.2143 + XiCon Loss:3.0434 x Lambda(0.001)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.1534
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2153394
	speed: 0.0705s/iter; left time: 783.7663s
Epoch: 6 cost time: 8.379197597503662
Epoch: 6, Steps: 118 Train Loss: 0.2148 (Forecasting Loss:0.2118 + XiCon Loss:3.0438 x Lambda(0.001)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.1528
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2216995
	speed: 0.0710s/iter; left time: 780.3252s
Epoch: 7 cost time: 8.411335945129395
Epoch: 7, Steps: 118 Train Loss: 0.2136 (Forecasting Loss:0.2105 + XiCon Loss:3.0409 x Lambda(0.001)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1540
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2208651
	speed: 0.0652s/iter; left time: 709.0464s
Epoch: 8 cost time: 7.7942469120025635
Epoch: 8, Steps: 118 Train Loss: 0.2129 (Forecasting Loss:0.2099 + XiCon Loss:3.0398 x Lambda(0.001)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.1539
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2077242
	speed: 0.0674s/iter; left time: 725.5263s
Epoch: 9 cost time: 8.069218873977661
Epoch: 9, Steps: 118 Train Loss: 0.2126 (Forecasting Loss:0.2095 + XiCon Loss:3.0415 x Lambda(0.001)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.1532
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2025927
	speed: 0.0702s/iter; left time: 746.3553s
Epoch: 10 cost time: 8.343874454498291
Epoch: 10, Steps: 118 Train Loss: 0.2123 (Forecasting Loss:0.2092 + XiCon Loss:3.0427 x Lambda(0.001)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.1538
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2250294
	speed: 0.0693s/iter; left time: 729.1860s
Epoch: 11 cost time: 8.193318367004395
Epoch: 11, Steps: 118 Train Loss: 0.2126 (Forecasting Loss:0.2095 + XiCon Loss:3.0417 x Lambda(0.001)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.1535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08990505337715149, mae:0.23751229047775269, mape:0.17405715584754944, mspe:0.04852095991373062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0860+-0.01403, MAE:0.2325+-0.01716, MAPE:0.1723+-0.00882, MSPE:0.0491+-0.00304, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8569
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.4890929
	speed: 0.0902s/iter; left time: 956.4037s
Epoch: 1 cost time: 9.672298192977905
Epoch: 1, Steps: 107 Train Loss: 0.5312 (Forecasting Loss:0.5281 + XiCon Loss:3.1543 x Lambda(0.001)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.1928
Validation loss decreased (inf --> 0.338555).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2961254
	speed: 0.0967s/iter; left time: 1014.5160s
Epoch: 2 cost time: 10.413922309875488
Epoch: 2, Steps: 107 Train Loss: 0.3898 (Forecasting Loss:0.3867 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.1417
Validation loss decreased (0.338555 --> 0.239111).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2697932
	speed: 0.0980s/iter; left time: 1017.9428s
Epoch: 3 cost time: 10.626879930496216
Epoch: 3, Steps: 107 Train Loss: 0.2775 (Forecasting Loss:0.2744 + XiCon Loss:3.1406 x Lambda(0.001)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1450
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2622134
	speed: 0.0933s/iter; left time: 959.0763s
Epoch: 4 cost time: 10.07780122756958
Epoch: 4, Steps: 107 Train Loss: 0.2599 (Forecasting Loss:0.2568 + XiCon Loss:3.1371 x Lambda(0.001)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1403
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2483847
	speed: 0.0959s/iter; left time: 976.0278s
Epoch: 5 cost time: 10.332584142684937
Epoch: 5, Steps: 107 Train Loss: 0.2510 (Forecasting Loss:0.2479 + XiCon Loss:3.1318 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1399
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2476541
	speed: 0.0920s/iter; left time: 926.1594s
Epoch: 6 cost time: 9.962743759155273
Epoch: 6, Steps: 107 Train Loss: 0.2477 (Forecasting Loss:0.2446 + XiCon Loss:3.1300 x Lambda(0.001)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1398
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2236090
	speed: 0.0964s/iter; left time: 959.6635s
Epoch: 7 cost time: 10.259145021438599
Epoch: 7, Steps: 107 Train Loss: 0.2464 (Forecasting Loss:0.2432 + XiCon Loss:3.1296 x Lambda(0.001)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1382
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2504229
	speed: 0.0878s/iter; left time: 865.4260s
Epoch: 8 cost time: 9.498104810714722
Epoch: 8, Steps: 107 Train Loss: 0.2453 (Forecasting Loss:0.2422 + XiCon Loss:3.1281 x Lambda(0.001)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1405
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2556925
	speed: 0.0929s/iter; left time: 905.6265s
Epoch: 9 cost time: 9.966367483139038
Epoch: 9, Steps: 107 Train Loss: 0.2448 (Forecasting Loss:0.2416 + XiCon Loss:3.1289 x Lambda(0.001)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.1405
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2556009
	speed: 0.0965s/iter; left time: 930.5013s
Epoch: 10 cost time: 10.33354926109314
Epoch: 10, Steps: 107 Train Loss: 0.2444 (Forecasting Loss:0.2413 + XiCon Loss:3.1286 x Lambda(0.001)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1403
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2441512
	speed: 0.0981s/iter; left time: 934.5350s
Epoch: 11 cost time: 10.615957498550415
Epoch: 11, Steps: 107 Train Loss: 0.2442 (Forecasting Loss:0.2411 + XiCon Loss:3.1294 x Lambda(0.001)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.1400
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2481957
	speed: 0.0891s/iter; left time: 839.6847s
Epoch: 12 cost time: 9.449958801269531
Epoch: 12, Steps: 107 Train Loss: 0.2443 (Forecasting Loss:0.2411 + XiCon Loss:3.1293 x Lambda(0.001)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07123728096485138, mae:0.21225804090499878, mape:0.15602324903011322, mspe:0.040107060223817825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5176107
	speed: 0.0976s/iter; left time: 1034.2905s
Epoch: 1 cost time: 10.478060722351074
Epoch: 1, Steps: 107 Train Loss: 0.5520 (Forecasting Loss:0.5488 + XiCon Loss:3.1582 x Lambda(0.001)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2244
Validation loss decreased (inf --> 0.363721).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3132074
	speed: 0.1009s/iter; left time: 1058.7205s
Epoch: 2 cost time: 10.909746885299683
Epoch: 2, Steps: 107 Train Loss: 0.4102 (Forecasting Loss:0.4071 + XiCon Loss:3.1602 x Lambda(0.001)), Vali MSE Loss: 0.2683 Test MSE Loss: 0.1715
Validation loss decreased (0.363721 --> 0.268264).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2586024
	speed: 0.1083s/iter; left time: 1125.3353s
Epoch: 3 cost time: 11.638068437576294
Epoch: 3, Steps: 107 Train Loss: 0.2704 (Forecasting Loss:0.2673 + XiCon Loss:3.1603 x Lambda(0.001)), Vali MSE Loss: 0.2660 Test MSE Loss: 0.1640
Validation loss decreased (0.268264 --> 0.265970).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2644740
	speed: 0.1044s/iter; left time: 1072.7801s
Epoch: 4 cost time: 11.177791833877563
Epoch: 4, Steps: 107 Train Loss: 0.2539 (Forecasting Loss:0.2508 + XiCon Loss:3.1576 x Lambda(0.001)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2494184
	speed: 0.1099s/iter; left time: 1118.2114s
Epoch: 5 cost time: 11.81606912612915
Epoch: 5, Steps: 107 Train Loss: 0.2456 (Forecasting Loss:0.2425 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.1618
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2489634
	speed: 0.1076s/iter; left time: 1083.2719s
Epoch: 6 cost time: 11.529056787490845
Epoch: 6, Steps: 107 Train Loss: 0.2421 (Forecasting Loss:0.2389 + XiCon Loss:3.1595 x Lambda(0.001)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.1602
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2322302
	speed: 0.1001s/iter; left time: 996.4338s
Epoch: 7 cost time: 10.798073768615723
Epoch: 7, Steps: 107 Train Loss: 0.2406 (Forecasting Loss:0.2374 + XiCon Loss:3.1624 x Lambda(0.001)), Vali MSE Loss: 0.2831 Test MSE Loss: 0.1610
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2331658
	speed: 0.1083s/iter; left time: 1066.4814s
Epoch: 8 cost time: 11.633426904678345
Epoch: 8, Steps: 107 Train Loss: 0.2397 (Forecasting Loss:0.2365 + XiCon Loss:3.1629 x Lambda(0.001)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.1619
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2302993
	speed: 0.1095s/iter; left time: 1067.1914s
Epoch: 9 cost time: 11.827364921569824
Epoch: 9, Steps: 107 Train Loss: 0.2389 (Forecasting Loss:0.2358 + XiCon Loss:3.1625 x Lambda(0.001)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.1620
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2251121
	speed: 0.1083s/iter; left time: 1044.0700s
Epoch: 10 cost time: 11.649869441986084
Epoch: 10, Steps: 107 Train Loss: 0.2385 (Forecasting Loss:0.2353 + XiCon Loss:3.1621 x Lambda(0.001)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.1628
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2324721
	speed: 0.1040s/iter; left time: 991.3024s
Epoch: 11 cost time: 11.183881998062134
Epoch: 11, Steps: 107 Train Loss: 0.2386 (Forecasting Loss:0.2354 + XiCon Loss:3.1627 x Lambda(0.001)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.1619
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2415107
	speed: 0.1069s/iter; left time: 1007.8814s
Epoch: 12 cost time: 11.535816192626953
Epoch: 12, Steps: 107 Train Loss: 0.2384 (Forecasting Loss:0.2352 + XiCon Loss:3.1638 x Lambda(0.001)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.1621
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2281224
	speed: 0.1096s/iter; left time: 1020.8769s
Epoch: 13 cost time: 11.786470890045166
Epoch: 13, Steps: 107 Train Loss: 0.2382 (Forecasting Loss:0.2351 + XiCon Loss:3.1643 x Lambda(0.001)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.1624
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09050656110048294, mae:0.2375394105911255, mape:0.16893552243709564, mspe:0.04486268386244774 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8243
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5089705
	speed: 0.0862s/iter; left time: 914.2122s
Epoch: 1 cost time: 9.396341800689697
Epoch: 1, Steps: 107 Train Loss: 0.5433 (Forecasting Loss:0.5402 + XiCon Loss:3.1496 x Lambda(0.001)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.2031
Validation loss decreased (inf --> 0.333615).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3001132
	speed: 0.0951s/iter; left time: 998.1083s
Epoch: 2 cost time: 10.267652988433838
Epoch: 2, Steps: 107 Train Loss: 0.3995 (Forecasting Loss:0.3964 + XiCon Loss:3.1247 x Lambda(0.001)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.1555
Validation loss decreased (0.333615 --> 0.276403).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2782002
	speed: 0.0927s/iter; left time: 963.1018s
Epoch: 3 cost time: 9.964259386062622
Epoch: 3, Steps: 107 Train Loss: 0.2747 (Forecasting Loss:0.2716 + XiCon Loss:3.1109 x Lambda(0.001)), Vali MSE Loss: 0.2572 Test MSE Loss: 0.1356
Validation loss decreased (0.276403 --> 0.257198).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2574954
	speed: 0.0934s/iter; left time: 960.1134s
Epoch: 4 cost time: 9.968251943588257
Epoch: 4, Steps: 107 Train Loss: 0.2539 (Forecasting Loss:0.2508 + XiCon Loss:3.0978 x Lambda(0.001)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1316
Validation loss decreased (0.257198 --> 0.250051).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2538353
	speed: 0.0954s/iter; left time: 970.7128s
Epoch: 5 cost time: 10.231827735900879
Epoch: 5, Steps: 107 Train Loss: 0.2474 (Forecasting Loss:0.2443 + XiCon Loss:3.0940 x Lambda(0.001)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1311
Validation loss decreased (0.250051 --> 0.248126).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2460716
	speed: 0.0971s/iter; left time: 977.0849s
Epoch: 6 cost time: 10.379347085952759
Epoch: 6, Steps: 107 Train Loss: 0.2445 (Forecasting Loss:0.2415 + XiCon Loss:3.0909 x Lambda(0.001)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1302
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2395303
	speed: 0.0989s/iter; left time: 985.1780s
Epoch: 7 cost time: 10.782771825790405
Epoch: 7, Steps: 107 Train Loss: 0.2426 (Forecasting Loss:0.2395 + XiCon Loss:3.0904 x Lambda(0.001)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.1302
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2423213
	speed: 0.0976s/iter; left time: 961.6928s
Epoch: 8 cost time: 10.446913003921509
Epoch: 8, Steps: 107 Train Loss: 0.2415 (Forecasting Loss:0.2384 + XiCon Loss:3.0882 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1312
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2331230
	speed: 0.0958s/iter; left time: 933.8136s
Epoch: 9 cost time: 10.346161842346191
Epoch: 9, Steps: 107 Train Loss: 0.2411 (Forecasting Loss:0.2380 + XiCon Loss:3.0890 x Lambda(0.001)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1311
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2452822
	speed: 0.0983s/iter; left time: 947.8174s
Epoch: 10 cost time: 10.553989171981812
Epoch: 10, Steps: 107 Train Loss: 0.2408 (Forecasting Loss:0.2377 + XiCon Loss:3.0897 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1308
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2435491
	speed: 0.1004s/iter; left time: 956.4800s
Epoch: 11 cost time: 10.739327430725098
Epoch: 11, Steps: 107 Train Loss: 0.2407 (Forecasting Loss:0.2376 + XiCon Loss:3.0878 x Lambda(0.001)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.1311
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2386532
	speed: 0.0957s/iter; left time: 901.6881s
Epoch: 12 cost time: 10.437347650527954
Epoch: 12, Steps: 107 Train Loss: 0.2404 (Forecasting Loss:0.2374 + XiCon Loss:3.0882 x Lambda(0.001)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1308
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2429746
	speed: 0.0650s/iter; left time: 605.2982s
Epoch: 13 cost time: 7.297720909118652
Epoch: 13, Steps: 107 Train Loss: 0.2406 (Forecasting Loss:0.2375 + XiCon Loss:3.0886 x Lambda(0.001)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1308
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2321195
	speed: 0.0998s/iter; left time: 918.9836s
Epoch: 14 cost time: 10.82231092453003
Epoch: 14, Steps: 107 Train Loss: 0.2406 (Forecasting Loss:0.2376 + XiCon Loss:3.0889 x Lambda(0.001)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1308
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2343954
	speed: 0.0981s/iter; left time: 893.4014s
Epoch: 15 cost time: 10.608699321746826
Epoch: 15, Steps: 107 Train Loss: 0.2403 (Forecasting Loss:0.2372 + XiCon Loss:3.0889 x Lambda(0.001)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1308
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06364193558692932, mae:0.19847312569618225, mape:0.14629894495010376, mspe:0.03713003545999527 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8146
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5135615
	speed: 0.0949s/iter; left time: 1005.5602s
Epoch: 1 cost time: 10.163729190826416
Epoch: 1, Steps: 107 Train Loss: 0.5411 (Forecasting Loss:0.5379 + XiCon Loss:3.1516 x Lambda(0.001)), Vali MSE Loss: 0.3430 Test MSE Loss: 0.2048
Validation loss decreased (inf --> 0.342961).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3330484
	speed: 0.0950s/iter; left time: 997.3179s
Epoch: 2 cost time: 10.209174871444702
Epoch: 2, Steps: 107 Train Loss: 0.4040 (Forecasting Loss:0.4009 + XiCon Loss:3.1322 x Lambda(0.001)), Vali MSE Loss: 0.2712 Test MSE Loss: 0.1426
Validation loss decreased (0.342961 --> 0.271214).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2910134
	speed: 0.1022s/iter; left time: 1061.9950s
Epoch: 3 cost time: 10.961141109466553
Epoch: 3, Steps: 107 Train Loss: 0.2996 (Forecasting Loss:0.2965 + XiCon Loss:3.1150 x Lambda(0.001)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1359
Validation loss decreased (0.271214 --> 0.242459).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2886629
	speed: 0.0991s/iter; left time: 1018.3671s
Epoch: 4 cost time: 10.62683391571045
Epoch: 4, Steps: 107 Train Loss: 0.2732 (Forecasting Loss:0.2701 + XiCon Loss:3.1119 x Lambda(0.001)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1365
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2585615
	speed: 0.0924s/iter; left time: 940.4641s
Epoch: 5 cost time: 9.929389953613281
Epoch: 5, Steps: 107 Train Loss: 0.2630 (Forecasting Loss:0.2599 + XiCon Loss:3.1106 x Lambda(0.001)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.1349
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2540294
	speed: 0.0970s/iter; left time: 976.6348s
Epoch: 6 cost time: 10.514429569244385
Epoch: 6, Steps: 107 Train Loss: 0.2579 (Forecasting Loss:0.2548 + XiCon Loss:3.1113 x Lambda(0.001)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2488076
	speed: 0.1016s/iter; left time: 1012.3081s
Epoch: 7 cost time: 10.901538372039795
Epoch: 7, Steps: 107 Train Loss: 0.2547 (Forecasting Loss:0.2516 + XiCon Loss:3.1120 x Lambda(0.001)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1334
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2605130
	speed: 0.1037s/iter; left time: 1021.3856s
Epoch: 8 cost time: 11.239797115325928
Epoch: 8, Steps: 107 Train Loss: 0.2533 (Forecasting Loss:0.2502 + XiCon Loss:3.1122 x Lambda(0.001)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1325
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2488630
	speed: 0.0856s/iter; left time: 834.3608s
Epoch: 9 cost time: 9.1661536693573
Epoch: 9, Steps: 107 Train Loss: 0.2530 (Forecasting Loss:0.2499 + XiCon Loss:3.1122 x Lambda(0.001)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1329
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2659885
	speed: 0.0953s/iter; left time: 918.0204s
Epoch: 10 cost time: 10.262752532958984
Epoch: 10, Steps: 107 Train Loss: 0.2528 (Forecasting Loss:0.2497 + XiCon Loss:3.1107 x Lambda(0.001)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1327
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2674812
	speed: 0.0961s/iter; left time: 915.5363s
Epoch: 11 cost time: 10.323652505874634
Epoch: 11, Steps: 107 Train Loss: 0.2531 (Forecasting Loss:0.2500 + XiCon Loss:3.1118 x Lambda(0.001)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1328
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2505057
	speed: 0.0946s/iter; left time: 891.2063s
Epoch: 12 cost time: 10.146362781524658
Epoch: 12, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2493 + XiCon Loss:3.1132 x Lambda(0.001)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1327
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2588910
	speed: 0.0905s/iter; left time: 842.9605s
Epoch: 13 cost time: 9.783231735229492
Epoch: 13, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2492 + XiCon Loss:3.1124 x Lambda(0.001)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1327
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.0665542334318161, mae:0.20519843697547913, mape:0.1519121527671814, mspe:0.0390055850148201 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6680
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5254365
	speed: 0.0947s/iter; left time: 1003.5352s
Epoch: 1 cost time: 10.290529727935791
Epoch: 1, Steps: 107 Train Loss: 0.5307 (Forecasting Loss:0.5275 + XiCon Loss:3.1511 x Lambda(0.001)), Vali MSE Loss: 0.3527 Test MSE Loss: 0.2056
Validation loss decreased (inf --> 0.352733).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2688313
	speed: 0.1117s/iter; left time: 1172.3225s
Epoch: 2 cost time: 12.224122762680054
Epoch: 2, Steps: 107 Train Loss: 0.3182 (Forecasting Loss:0.3151 + XiCon Loss:3.1405 x Lambda(0.001)), Vali MSE Loss: 0.4949 Test MSE Loss: 0.1501
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2372329
	speed: 0.1224s/iter; left time: 1271.5705s
Epoch: 3 cost time: 13.152915477752686
Epoch: 3, Steps: 107 Train Loss: 0.2495 (Forecasting Loss:0.2463 + XiCon Loss:3.1340 x Lambda(0.001)), Vali MSE Loss: 0.5099 Test MSE Loss: 0.1504
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2450775
	speed: 0.1266s/iter; left time: 1301.6621s
Epoch: 4 cost time: 13.811472177505493
Epoch: 4, Steps: 107 Train Loss: 0.2408 (Forecasting Loss:0.2376 + XiCon Loss:3.1315 x Lambda(0.001)), Vali MSE Loss: 0.4759 Test MSE Loss: 0.1493
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2372830
	speed: 0.1312s/iter; left time: 1335.0212s
Epoch: 5 cost time: 14.20776653289795
Epoch: 5, Steps: 107 Train Loss: 0.2359 (Forecasting Loss:0.2328 + XiCon Loss:3.1289 x Lambda(0.001)), Vali MSE Loss: 0.4690 Test MSE Loss: 0.1473
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2361385
	speed: 0.1233s/iter; left time: 1240.7347s
Epoch: 6 cost time: 13.288876056671143
Epoch: 6, Steps: 107 Train Loss: 0.2337 (Forecasting Loss:0.2306 + XiCon Loss:3.1256 x Lambda(0.001)), Vali MSE Loss: 0.4655 Test MSE Loss: 0.1498
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2428137
	speed: 0.1300s/iter; left time: 1294.9341s
Epoch: 7 cost time: 14.015936851501465
Epoch: 7, Steps: 107 Train Loss: 0.2327 (Forecasting Loss:0.2296 + XiCon Loss:3.1244 x Lambda(0.001)), Vali MSE Loss: 0.4769 Test MSE Loss: 0.1478
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2359494
	speed: 0.1265s/iter; left time: 1246.5912s
Epoch: 8 cost time: 13.572244644165039
Epoch: 8, Steps: 107 Train Loss: 0.2320 (Forecasting Loss:0.2289 + XiCon Loss:3.1255 x Lambda(0.001)), Vali MSE Loss: 0.4590 Test MSE Loss: 0.1480
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2262520
	speed: 0.1226s/iter; left time: 1195.1798s
Epoch: 9 cost time: 13.091656684875488
Epoch: 9, Steps: 107 Train Loss: 0.2314 (Forecasting Loss:0.2283 + XiCon Loss:3.1228 x Lambda(0.001)), Vali MSE Loss: 0.4601 Test MSE Loss: 0.1480
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2314849
	speed: 0.1299s/iter; left time: 1252.1084s
Epoch: 10 cost time: 13.93069314956665
Epoch: 10, Steps: 107 Train Loss: 0.2317 (Forecasting Loss:0.2286 + XiCon Loss:3.1240 x Lambda(0.001)), Vali MSE Loss: 0.4619 Test MSE Loss: 0.1480
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2402133
	speed: 0.1306s/iter; left time: 1244.4903s
Epoch: 11 cost time: 14.224608421325684
Epoch: 11, Steps: 107 Train Loss: 0.2313 (Forecasting Loss:0.2281 + XiCon Loss:3.1228 x Lambda(0.001)), Vali MSE Loss: 0.4661 Test MSE Loss: 0.1480
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.12725678086280823, mae:0.283992737531662, mape:0.2030768096446991, mspe:0.06364373862743378 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0838+-0.03282, MAE:0.2275+-0.04330, MAPE:0.1652+-0.02822, MSPE:0.0449+-0.01345, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8507
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.71832847595215
Epoch: 1, Steps: 96 Train Loss: 0.7456 (Forecasting Loss:0.7425 + XiCon Loss:3.1662 x Lambda(0.001)), Vali MSE Loss: 0.4344 Test MSE Loss: 0.2913
Validation loss decreased (inf --> 0.434382).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.55436110496521
Epoch: 2, Steps: 96 Train Loss: 0.5429 (Forecasting Loss:0.5398 + XiCon Loss:3.1615 x Lambda(0.001)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.2496
Validation loss decreased (0.434382 --> 0.261430).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.80099081993103
Epoch: 3, Steps: 96 Train Loss: 0.2896 (Forecasting Loss:0.2864 + XiCon Loss:3.1548 x Lambda(0.001)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1711
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 17.111560583114624
Epoch: 4, Steps: 96 Train Loss: 0.2619 (Forecasting Loss:0.2588 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.1719
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.667298793792725
Epoch: 5, Steps: 96 Train Loss: 0.2547 (Forecasting Loss:0.2516 + XiCon Loss:3.1609 x Lambda(0.001)), Vali MSE Loss: 0.3051 Test MSE Loss: 0.1706
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.291998624801636
Epoch: 6, Steps: 96 Train Loss: 0.2514 (Forecasting Loss:0.2483 + XiCon Loss:3.1591 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.1633
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.766921758651733
Epoch: 7, Steps: 96 Train Loss: 0.2498 (Forecasting Loss:0.2467 + XiCon Loss:3.1608 x Lambda(0.001)), Vali MSE Loss: 0.3033 Test MSE Loss: 0.1716
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 17.12669587135315
Epoch: 8, Steps: 96 Train Loss: 0.2488 (Forecasting Loss:0.2457 + XiCon Loss:3.1599 x Lambda(0.001)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1661
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 17.11530637741089
Epoch: 9, Steps: 96 Train Loss: 0.2484 (Forecasting Loss:0.2452 + XiCon Loss:3.1608 x Lambda(0.001)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.1681
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 16.69142436981201
Epoch: 10, Steps: 96 Train Loss: 0.2478 (Forecasting Loss:0.2447 + XiCon Loss:3.1603 x Lambda(0.001)), Vali MSE Loss: 0.3089 Test MSE Loss: 0.1676
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.973457098007202
Epoch: 11, Steps: 96 Train Loss: 0.2481 (Forecasting Loss:0.2449 + XiCon Loss:3.1597 x Lambda(0.001)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.1676
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 16.424278497695923
Epoch: 12, Steps: 96 Train Loss: 0.2478 (Forecasting Loss:0.2446 + XiCon Loss:3.1583 x Lambda(0.001)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.1675
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.1658436805009842, mae:0.33328333497047424, mape:0.2279556691646576, mspe:0.07007050514221191 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.9067
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 17.04645872116089
Epoch: 1, Steps: 96 Train Loss: 0.7243 (Forecasting Loss:0.7211 + XiCon Loss:3.1586 x Lambda(0.001)), Vali MSE Loss: 0.4319 Test MSE Loss: 0.2624
Validation loss decreased (inf --> 0.431880).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.54157066345215
Epoch: 2, Steps: 96 Train Loss: 0.4946 (Forecasting Loss:0.4915 + XiCon Loss:3.1303 x Lambda(0.001)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.1527
Validation loss decreased (0.431880 --> 0.295740).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.49772596359253
Epoch: 3, Steps: 96 Train Loss: 0.2836 (Forecasting Loss:0.2805 + XiCon Loss:3.1110 x Lambda(0.001)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.1414
Validation loss decreased (0.295740 --> 0.294664).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 16.703877210617065
Epoch: 4, Steps: 96 Train Loss: 0.2611 (Forecasting Loss:0.2580 + XiCon Loss:3.1070 x Lambda(0.001)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.1413
Validation loss decreased (0.294664 --> 0.291948).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.974409103393555
Epoch: 5, Steps: 96 Train Loss: 0.2536 (Forecasting Loss:0.2505 + XiCon Loss:3.1063 x Lambda(0.001)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.1413
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.737730026245117
Epoch: 6, Steps: 96 Train Loss: 0.2500 (Forecasting Loss:0.2469 + XiCon Loss:3.1032 x Lambda(0.001)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.1412
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.674790382385254
Epoch: 7, Steps: 96 Train Loss: 0.2481 (Forecasting Loss:0.2450 + XiCon Loss:3.1016 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.1409
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.84467053413391
Epoch: 8, Steps: 96 Train Loss: 0.2471 (Forecasting Loss:0.2440 + XiCon Loss:3.1023 x Lambda(0.001)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.1414
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.453243017196655
Epoch: 9, Steps: 96 Train Loss: 0.2467 (Forecasting Loss:0.2436 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.1415
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 16.48833394050598
Epoch: 10, Steps: 96 Train Loss: 0.2463 (Forecasting Loss:0.2431 + XiCon Loss:3.1014 x Lambda(0.001)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.1414
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.49553346633911
Epoch: 11, Steps: 96 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.1016 x Lambda(0.001)), Vali MSE Loss: 0.3055 Test MSE Loss: 0.1413
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 17.481674909591675
Epoch: 12, Steps: 96 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.1413
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 16.896451234817505
Epoch: 13, Steps: 96 Train Loss: 0.2462 (Forecasting Loss:0.2431 + XiCon Loss:3.0997 x Lambda(0.001)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.1413
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 16.638697385787964
Epoch: 14, Steps: 96 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1004 x Lambda(0.001)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.1413
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07136557251214981, mae:0.2111416757106781, mape:0.15779374539852142, mspe:0.04303474724292755 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7086
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.83199906349182
Epoch: 1, Steps: 96 Train Loss: 0.7928 (Forecasting Loss:0.7897 + XiCon Loss:3.1661 x Lambda(0.001)), Vali MSE Loss: 0.5215 Test MSE Loss: 0.3299
Validation loss decreased (inf --> 0.521506).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 18.401577949523926
Epoch: 2, Steps: 96 Train Loss: 0.5258 (Forecasting Loss:0.5226 + XiCon Loss:3.1386 x Lambda(0.001)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.1611
Validation loss decreased (0.521506 --> 0.289077).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 19.297515869140625
Epoch: 3, Steps: 96 Train Loss: 0.2945 (Forecasting Loss:0.2914 + XiCon Loss:3.1016 x Lambda(0.001)), Vali MSE Loss: 0.3101 Test MSE Loss: 0.1783
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 18.428996801376343
Epoch: 4, Steps: 96 Train Loss: 0.2668 (Forecasting Loss:0.2637 + XiCon Loss:3.0952 x Lambda(0.001)), Vali MSE Loss: 0.3017 Test MSE Loss: 0.1807
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 18.09212040901184
Epoch: 5, Steps: 96 Train Loss: 0.2546 (Forecasting Loss:0.2515 + XiCon Loss:3.0945 x Lambda(0.001)), Vali MSE Loss: 0.2972 Test MSE Loss: 0.1753
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.691027402877808
Epoch: 6, Steps: 96 Train Loss: 0.2499 (Forecasting Loss:0.2468 + XiCon Loss:3.0938 x Lambda(0.001)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.1812
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.993210077285767
Epoch: 7, Steps: 96 Train Loss: 0.2474 (Forecasting Loss:0.2443 + XiCon Loss:3.0950 x Lambda(0.001)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1839
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 20.517815113067627
Epoch: 8, Steps: 96 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.0934 x Lambda(0.001)), Vali MSE Loss: 0.2966 Test MSE Loss: 0.1815
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 20.719456672668457
Epoch: 9, Steps: 96 Train Loss: 0.2453 (Forecasting Loss:0.2422 + XiCon Loss:3.0924 x Lambda(0.001)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.1785
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.012547969818115
Epoch: 10, Steps: 96 Train Loss: 0.2450 (Forecasting Loss:0.2419 + XiCon Loss:3.0937 x Lambda(0.001)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.1788
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 21.043472290039062
Epoch: 11, Steps: 96 Train Loss: 0.2450 (Forecasting Loss:0.2419 + XiCon Loss:3.0933 x Lambda(0.001)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.1794
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 20.94305396080017
Epoch: 12, Steps: 96 Train Loss: 0.2449 (Forecasting Loss:0.2418 + XiCon Loss:3.0928 x Lambda(0.001)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.1796
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08705677837133408, mae:0.23522503674030304, mape:0.17284883558750153, mspe:0.04901467636227608 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6562
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.824240684509277
Epoch: 1, Steps: 96 Train Loss: 0.7190 (Forecasting Loss:0.7158 + XiCon Loss:3.1568 x Lambda(0.001)), Vali MSE Loss: 0.4405 Test MSE Loss: 0.2847
Validation loss decreased (inf --> 0.440541).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.235087633132935
Epoch: 2, Steps: 96 Train Loss: 0.4877 (Forecasting Loss:0.4845 + XiCon Loss:3.1496 x Lambda(0.001)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.1429
Validation loss decreased (0.440541 --> 0.335773).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 19.320836544036865
Epoch: 3, Steps: 96 Train Loss: 0.3226 (Forecasting Loss:0.3195 + XiCon Loss:3.1312 x Lambda(0.001)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.1494
Validation loss decreased (0.335773 --> 0.263261).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 18.740962505340576
Epoch: 4, Steps: 96 Train Loss: 0.2812 (Forecasting Loss:0.2781 + XiCon Loss:3.1231 x Lambda(0.001)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1449
Validation loss decreased (0.263261 --> 0.252600).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.859183073043823
Epoch: 5, Steps: 96 Train Loss: 0.2665 (Forecasting Loss:0.2634 + XiCon Loss:3.1177 x Lambda(0.001)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1483
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 19.140965461730957
Epoch: 6, Steps: 96 Train Loss: 0.2610 (Forecasting Loss:0.2579 + XiCon Loss:3.1160 x Lambda(0.001)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1396
Validation loss decreased (0.252600 --> 0.246468).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 18.80838108062744
Epoch: 7, Steps: 96 Train Loss: 0.2579 (Forecasting Loss:0.2548 + XiCon Loss:3.1147 x Lambda(0.001)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1404
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 18.142762899398804
Epoch: 8, Steps: 96 Train Loss: 0.2562 (Forecasting Loss:0.2530 + XiCon Loss:3.1154 x Lambda(0.001)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1405
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 11.989661455154419
Epoch: 9, Steps: 96 Train Loss: 0.2555 (Forecasting Loss:0.2524 + XiCon Loss:3.1144 x Lambda(0.001)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.1400
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 19.209131002426147
Epoch: 10, Steps: 96 Train Loss: 0.2554 (Forecasting Loss:0.2523 + XiCon Loss:3.1141 x Lambda(0.001)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 19.085965633392334
Epoch: 11, Steps: 96 Train Loss: 0.2556 (Forecasting Loss:0.2525 + XiCon Loss:3.1135 x Lambda(0.001)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1400
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 18.3372745513916
Epoch: 12, Steps: 96 Train Loss: 0.2555 (Forecasting Loss:0.2523 + XiCon Loss:3.1148 x Lambda(0.001)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1404
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 14.986303329467773
Epoch: 13, Steps: 96 Train Loss: 0.2554 (Forecasting Loss:0.2523 + XiCon Loss:3.1146 x Lambda(0.001)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1402
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 19.285640239715576
Epoch: 14, Steps: 96 Train Loss: 0.2554 (Forecasting Loss:0.2523 + XiCon Loss:3.1138 x Lambda(0.001)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1402
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 19.597811222076416
Epoch: 15, Steps: 96 Train Loss: 0.2553 (Forecasting Loss:0.2522 + XiCon Loss:3.1164 x Lambda(0.001)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1402
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 18.7656672000885
Epoch: 16, Steps: 96 Train Loss: 0.2556 (Forecasting Loss:0.2525 + XiCon Loss:3.1150 x Lambda(0.001)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1402
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07017021626234055, mae:0.20903967320919037, mape:0.1543133407831192, mspe:0.0399223156273365 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6324
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 18.81846809387207
Epoch: 1, Steps: 96 Train Loss: 0.7144 (Forecasting Loss:0.7112 + XiCon Loss:3.1505 x Lambda(0.001)), Vali MSE Loss: 0.4269 Test MSE Loss: 0.2673
Validation loss decreased (inf --> 0.426948).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 19.085934162139893
Epoch: 2, Steps: 96 Train Loss: 0.5085 (Forecasting Loss:0.5054 + XiCon Loss:3.1300 x Lambda(0.001)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.1560
Validation loss decreased (0.426948 --> 0.305350).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 18.86412215232849
Epoch: 3, Steps: 96 Train Loss: 0.3004 (Forecasting Loss:0.2973 + XiCon Loss:3.1123 x Lambda(0.001)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.1518
Validation loss decreased (0.305350 --> 0.283315).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 18.683834552764893
Epoch: 4, Steps: 96 Train Loss: 0.2684 (Forecasting Loss:0.2653 + XiCon Loss:3.1117 x Lambda(0.001)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.1415
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 19.301995992660522
Epoch: 5, Steps: 96 Train Loss: 0.2586 (Forecasting Loss:0.2554 + XiCon Loss:3.1106 x Lambda(0.001)), Vali MSE Loss: 0.2979 Test MSE Loss: 0.1361
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 18.61790132522583
Epoch: 6, Steps: 96 Train Loss: 0.2539 (Forecasting Loss:0.2508 + XiCon Loss:3.1090 x Lambda(0.001)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.1363
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 19.053646564483643
Epoch: 7, Steps: 96 Train Loss: 0.2521 (Forecasting Loss:0.2490 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.1364
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 18.935564279556274
Epoch: 8, Steps: 96 Train Loss: 0.2507 (Forecasting Loss:0.2476 + XiCon Loss:3.1085 x Lambda(0.001)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 18.717205286026
Epoch: 9, Steps: 96 Train Loss: 0.2506 (Forecasting Loss:0.2474 + XiCon Loss:3.1085 x Lambda(0.001)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.1366
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 19.068811655044556
Epoch: 10, Steps: 96 Train Loss: 0.2502 (Forecasting Loss:0.2471 + XiCon Loss:3.1098 x Lambda(0.001)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1362
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 19.175621032714844
Epoch: 11, Steps: 96 Train Loss: 0.2501 (Forecasting Loss:0.2470 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.1363
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 18.350141763687134
Epoch: 12, Steps: 96 Train Loss: 0.2502 (Forecasting Loss:0.2471 + XiCon Loss:3.1104 x Lambda(0.001)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.1363
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 19.1446373462677
Epoch: 13, Steps: 96 Train Loss: 0.2500 (Forecasting Loss:0.2469 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.1363
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08070589601993561, mae:0.22279810905456543, mape:0.15933656692504883, mspe:0.0401797853410244 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0950+-0.04990, MAE:0.2423+-0.06448, MAPE:0.1744+-0.03815, MSPE:0.0484+-0.01568, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6442
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2366969
	speed: 0.0458s/iter; left time: 581.5229s
Epoch: 1 cost time: 5.714049577713013
Epoch: 1, Steps: 128 Train Loss: 0.2953 (Forecasting Loss:0.2922 + XiCon Loss:3.1254 x Lambda(0.001)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.2307
Validation loss decreased (inf --> 0.274659).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2261203
	speed: 0.0372s/iter; left time: 467.5296s
Epoch: 2 cost time: 5.053222417831421
Epoch: 2, Steps: 128 Train Loss: 0.2386 (Forecasting Loss:0.2355 + XiCon Loss:3.1269 x Lambda(0.001)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.2333
Validation loss decreased (0.274659 --> 0.266368).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1865513
	speed: 0.0439s/iter; left time: 545.7735s
Epoch: 3 cost time: 5.633963108062744
Epoch: 3, Steps: 128 Train Loss: 0.1882 (Forecasting Loss:0.1851 + XiCon Loss:3.0953 x Lambda(0.001)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.3082
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1545025
	speed: 0.0439s/iter; left time: 540.6171s
Epoch: 4 cost time: 5.430526971817017
Epoch: 4, Steps: 128 Train Loss: 0.1616 (Forecasting Loss:0.1585 + XiCon Loss:3.0923 x Lambda(0.001)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.3209
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1655338
	speed: 0.0451s/iter; left time: 550.0649s
Epoch: 5 cost time: 5.599017143249512
Epoch: 5, Steps: 128 Train Loss: 0.1518 (Forecasting Loss:0.1487 + XiCon Loss:3.0918 x Lambda(0.001)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.3420
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1612006
	speed: 0.0464s/iter; left time: 560.0272s
Epoch: 6 cost time: 5.953107833862305
Epoch: 6, Steps: 128 Train Loss: 0.1477 (Forecasting Loss:0.1446 + XiCon Loss:3.0906 x Lambda(0.001)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.3470
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1535143
	speed: 0.0464s/iter; left time: 553.3689s
Epoch: 7 cost time: 5.678327798843384
Epoch: 7, Steps: 128 Train Loss: 0.1453 (Forecasting Loss:0.1423 + XiCon Loss:3.0901 x Lambda(0.001)), Vali MSE Loss: 0.2966 Test MSE Loss: 0.3528
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1513059
	speed: 0.0445s/iter; left time: 525.0025s
Epoch: 8 cost time: 5.715790510177612
Epoch: 8, Steps: 128 Train Loss: 0.1446 (Forecasting Loss:0.1415 + XiCon Loss:3.0891 x Lambda(0.001)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.3553
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1414812
	speed: 0.0417s/iter; left time: 487.0106s
Epoch: 9 cost time: 5.318964958190918
Epoch: 9, Steps: 128 Train Loss: 0.1441 (Forecasting Loss:0.1410 + XiCon Loss:3.0902 x Lambda(0.001)), Vali MSE Loss: 0.2956 Test MSE Loss: 0.3559
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1349272
	speed: 0.0452s/iter; left time: 522.5033s
Epoch: 10 cost time: 5.918329477310181
Epoch: 10, Steps: 128 Train Loss: 0.1436 (Forecasting Loss:0.1405 + XiCon Loss:3.0912 x Lambda(0.001)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.3556
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1444597
	speed: 0.0451s/iter; left time: 515.3289s
Epoch: 11 cost time: 5.608535528182983
Epoch: 11, Steps: 128 Train Loss: 0.1438 (Forecasting Loss:0.1407 + XiCon Loss:3.0906 x Lambda(0.001)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.3559
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1237347
	speed: 0.0457s/iter; left time: 516.3925s
Epoch: 12 cost time: 5.978971004486084
Epoch: 12, Steps: 128 Train Loss: 0.1436 (Forecasting Loss:0.1405 + XiCon Loss:3.0903 x Lambda(0.001)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.3560
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15783368051052094, mae:0.3086838126182556, mape:0.7358143925666809, mspe:20.839048385620117 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8196
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2411399
	speed: 0.0427s/iter; left time: 542.7725s
Epoch: 1 cost time: 5.492229223251343
Epoch: 1, Steps: 128 Train Loss: 0.2983 (Forecasting Loss:0.2952 + XiCon Loss:3.1254 x Lambda(0.001)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.2281
Validation loss decreased (inf --> 0.274059).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2141465
	speed: 0.0409s/iter; left time: 513.6990s
Epoch: 2 cost time: 5.31553316116333
Epoch: 2, Steps: 128 Train Loss: 0.2368 (Forecasting Loss:0.2337 + XiCon Loss:3.1664 x Lambda(0.001)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.2502
Validation loss decreased (0.274059 --> 0.262719).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1707271
	speed: 0.0426s/iter; left time: 530.0297s
Epoch: 3 cost time: 5.522435426712036
Epoch: 3, Steps: 128 Train Loss: 0.1924 (Forecasting Loss:0.1892 + XiCon Loss:3.1577 x Lambda(0.001)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.2851
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1738701
	speed: 0.0423s/iter; left time: 520.7239s
Epoch: 4 cost time: 5.309145927429199
Epoch: 4, Steps: 128 Train Loss: 0.1653 (Forecasting Loss:0.1621 + XiCon Loss:3.1448 x Lambda(0.001)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.3079
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1411051
	speed: 0.0400s/iter; left time: 487.0495s
Epoch: 5 cost time: 4.992770671844482
Epoch: 5, Steps: 128 Train Loss: 0.1538 (Forecasting Loss:0.1507 + XiCon Loss:3.1442 x Lambda(0.001)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.3050
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1408032
	speed: 0.0452s/iter; left time: 545.5790s
Epoch: 6 cost time: 5.71243143081665
Epoch: 6, Steps: 128 Train Loss: 0.1487 (Forecasting Loss:0.1455 + XiCon Loss:3.1440 x Lambda(0.001)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.3026
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1558335
	speed: 0.0456s/iter; left time: 544.5769s
Epoch: 7 cost time: 5.821897983551025
Epoch: 7, Steps: 128 Train Loss: 0.1467 (Forecasting Loss:0.1435 + XiCon Loss:3.1434 x Lambda(0.001)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.3053
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1496260
	speed: 0.0479s/iter; left time: 565.3065s
Epoch: 8 cost time: 6.077387094497681
Epoch: 8, Steps: 128 Train Loss: 0.1453 (Forecasting Loss:0.1422 + XiCon Loss:3.1430 x Lambda(0.001)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.3092
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1379750
	speed: 0.0451s/iter; left time: 526.4030s
Epoch: 9 cost time: 5.859386205673218
Epoch: 9, Steps: 128 Train Loss: 0.1450 (Forecasting Loss:0.1419 + XiCon Loss:3.1454 x Lambda(0.001)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.3076
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1356416
	speed: 0.0443s/iter; left time: 511.1040s
Epoch: 10 cost time: 5.659883737564087
Epoch: 10, Steps: 128 Train Loss: 0.1447 (Forecasting Loss:0.1416 + XiCon Loss:3.1432 x Lambda(0.001)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.3074
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1467791
	speed: 0.0412s/iter; left time: 471.0150s
Epoch: 11 cost time: 5.145813226699829
Epoch: 11, Steps: 128 Train Loss: 0.1445 (Forecasting Loss:0.1414 + XiCon Loss:3.1445 x Lambda(0.001)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.3079
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1487235
	speed: 0.0436s/iter; left time: 492.7183s
Epoch: 12 cost time: 5.672427654266357
Epoch: 12, Steps: 128 Train Loss: 0.1445 (Forecasting Loss:0.1413 + XiCon Loss:3.1450 x Lambda(0.001)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.3071
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.17729425430297852, mae:0.32301512360572815, mape:0.7961909174919128, mspe:26.003210067749023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7633
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2309157
	speed: 0.0423s/iter; left time: 537.8042s
Epoch: 1 cost time: 5.3796069622039795
Epoch: 1, Steps: 128 Train Loss: 0.2968 (Forecasting Loss:0.2936 + XiCon Loss:3.1500 x Lambda(0.001)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.2250
Validation loss decreased (inf --> 0.271664).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1964893
	speed: 0.0458s/iter; left time: 575.3607s
Epoch: 2 cost time: 5.882829666137695
Epoch: 2, Steps: 128 Train Loss: 0.2401 (Forecasting Loss:0.2370 + XiCon Loss:3.1028 x Lambda(0.001)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.2675
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1932565
	speed: 0.0477s/iter; left time: 593.3103s
Epoch: 3 cost time: 5.879422426223755
Epoch: 3, Steps: 128 Train Loss: 0.1897 (Forecasting Loss:0.1866 + XiCon Loss:3.0776 x Lambda(0.001)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.2643
Validation loss decreased (0.271664 --> 0.271082).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1562390
	speed: 0.0470s/iter; left time: 578.8101s
Epoch: 4 cost time: 5.7259368896484375
Epoch: 4, Steps: 128 Train Loss: 0.1622 (Forecasting Loss:0.1592 + XiCon Loss:3.0689 x Lambda(0.001)), Vali MSE Loss: 0.2904 Test MSE Loss: 0.2855
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1421564
	speed: 0.0413s/iter; left time: 502.9374s
Epoch: 5 cost time: 5.4164721965789795
Epoch: 5, Steps: 128 Train Loss: 0.1504 (Forecasting Loss:0.1473 + XiCon Loss:3.0656 x Lambda(0.001)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.2736
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1418756
	speed: 0.0402s/iter; left time: 485.2660s
Epoch: 6 cost time: 5.24641489982605
Epoch: 6, Steps: 128 Train Loss: 0.1453 (Forecasting Loss:0.1422 + XiCon Loss:3.0678 x Lambda(0.001)), Vali MSE Loss: 0.3018 Test MSE Loss: 0.2727
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1497533
	speed: 0.0451s/iter; left time: 538.4376s
Epoch: 7 cost time: 5.250895023345947
Epoch: 7, Steps: 128 Train Loss: 0.1433 (Forecasting Loss:0.1402 + XiCon Loss:3.0686 x Lambda(0.001)), Vali MSE Loss: 0.3103 Test MSE Loss: 0.2765
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1463431
	speed: 0.0446s/iter; left time: 527.0564s
Epoch: 8 cost time: 5.659609079360962
Epoch: 8, Steps: 128 Train Loss: 0.1424 (Forecasting Loss:0.1394 + XiCon Loss:3.0669 x Lambda(0.001)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.2802
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1383284
	speed: 0.0439s/iter; left time: 512.4373s
Epoch: 9 cost time: 5.766702175140381
Epoch: 9, Steps: 128 Train Loss: 0.1420 (Forecasting Loss:0.1389 + XiCon Loss:3.0678 x Lambda(0.001)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.2764
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1444227
	speed: 0.0438s/iter; left time: 506.0028s
Epoch: 10 cost time: 5.513887882232666
Epoch: 10, Steps: 128 Train Loss: 0.1417 (Forecasting Loss:0.1386 + XiCon Loss:3.0681 x Lambda(0.001)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.2794
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1461288
	speed: 0.0458s/iter; left time: 523.5474s
Epoch: 11 cost time: 5.7926108837127686
Epoch: 11, Steps: 128 Train Loss: 0.1415 (Forecasting Loss:0.1384 + XiCon Loss:3.0677 x Lambda(0.001)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.2792
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1490619
	speed: 0.0434s/iter; left time: 490.3484s
Epoch: 12 cost time: 5.513685464859009
Epoch: 12, Steps: 128 Train Loss: 0.1414 (Forecasting Loss:0.1383 + XiCon Loss:3.0684 x Lambda(0.001)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.2787
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.1396938
	speed: 0.0405s/iter; left time: 452.0184s
Epoch: 13 cost time: 5.385143518447876
Epoch: 13, Steps: 128 Train Loss: 0.1413 (Forecasting Loss:0.1382 + XiCon Loss:3.0676 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2792
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1902291476726532, mae:0.3383428752422333, mape:0.815626323223114, mspe:25.88153076171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7700
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3023583
	speed: 0.0375s/iter; left time: 476.6939s
Epoch: 1 cost time: 4.833741188049316
Epoch: 1, Steps: 128 Train Loss: 0.2944 (Forecasting Loss:0.2913 + XiCon Loss:3.1098 x Lambda(0.001)), Vali MSE Loss: 0.2724 Test MSE Loss: 0.2284
Validation loss decreased (inf --> 0.272406).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2382528
	speed: 0.0472s/iter; left time: 593.1531s
Epoch: 2 cost time: 6.088029623031616
Epoch: 2, Steps: 128 Train Loss: 0.2499 (Forecasting Loss:0.2467 + XiCon Loss:3.1761 x Lambda(0.001)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.2220
Validation loss decreased (0.272406 --> 0.244035).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1784850
	speed: 0.0451s/iter; left time: 560.8877s
Epoch: 3 cost time: 5.771398305892944
Epoch: 3, Steps: 128 Train Loss: 0.2076 (Forecasting Loss:0.2044 + XiCon Loss:3.1600 x Lambda(0.001)), Vali MSE Loss: 0.2430 Test MSE Loss: 0.2601
Validation loss decreased (0.244035 --> 0.242997).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1659244
	speed: 0.0455s/iter; left time: 560.4318s
Epoch: 4 cost time: 5.801797389984131
Epoch: 4, Steps: 128 Train Loss: 0.1825 (Forecasting Loss:0.1793 + XiCon Loss:3.1603 x Lambda(0.001)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.2885
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1762748
	speed: 0.0433s/iter; left time: 527.5074s
Epoch: 5 cost time: 5.6482017040252686
Epoch: 5, Steps: 128 Train Loss: 0.1698 (Forecasting Loss:0.1666 + XiCon Loss:3.1604 x Lambda(0.001)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.2958
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1721696
	speed: 0.0428s/iter; left time: 516.6642s
Epoch: 6 cost time: 5.475163698196411
Epoch: 6, Steps: 128 Train Loss: 0.1627 (Forecasting Loss:0.1596 + XiCon Loss:3.1627 x Lambda(0.001)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.3055
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1719007
	speed: 0.0395s/iter; left time: 471.7312s
Epoch: 7 cost time: 5.226827144622803
Epoch: 7, Steps: 128 Train Loss: 0.1597 (Forecasting Loss:0.1566 + XiCon Loss:3.1630 x Lambda(0.001)), Vali MSE Loss: 0.2718 Test MSE Loss: 0.3066
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1571226
	speed: 0.0411s/iter; left time: 485.2775s
Epoch: 8 cost time: 5.144647836685181
Epoch: 8, Steps: 128 Train Loss: 0.1582 (Forecasting Loss:0.1550 + XiCon Loss:3.1622 x Lambda(0.001)), Vali MSE Loss: 0.2739 Test MSE Loss: 0.3096
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1491870
	speed: 0.0419s/iter; left time: 489.2053s
Epoch: 9 cost time: 5.432621240615845
Epoch: 9, Steps: 128 Train Loss: 0.1575 (Forecasting Loss:0.1543 + XiCon Loss:3.1630 x Lambda(0.001)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.3103
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1496269
	speed: 0.0437s/iter; left time: 504.5740s
Epoch: 10 cost time: 5.497917652130127
Epoch: 10, Steps: 128 Train Loss: 0.1573 (Forecasting Loss:0.1541 + XiCon Loss:3.1619 x Lambda(0.001)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.3107
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1601607
	speed: 0.0427s/iter; left time: 487.4412s
Epoch: 11 cost time: 5.279244422912598
Epoch: 11, Steps: 128 Train Loss: 0.1570 (Forecasting Loss:0.1538 + XiCon Loss:3.1612 x Lambda(0.001)), Vali MSE Loss: 0.2739 Test MSE Loss: 0.3108
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1447473
	speed: 0.0457s/iter; left time: 516.3949s
Epoch: 12 cost time: 5.784020900726318
Epoch: 12, Steps: 128 Train Loss: 0.1568 (Forecasting Loss:0.1536 + XiCon Loss:3.1611 x Lambda(0.001)), Vali MSE Loss: 0.2743 Test MSE Loss: 0.3111
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.1426976
	speed: 0.0431s/iter; left time: 481.7497s
Epoch: 13 cost time: 5.57327675819397
Epoch: 13, Steps: 128 Train Loss: 0.1568 (Forecasting Loss:0.1536 + XiCon Loss:3.1617 x Lambda(0.001)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.3114
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.18200424313545227, mae:0.33817052841186523, mape:0.9457144737243652, mspe:35.51637268066406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7178
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2931849
	speed: 0.0398s/iter; left time: 505.6295s
Epoch: 1 cost time: 5.264611482620239
Epoch: 1, Steps: 128 Train Loss: 0.2938 (Forecasting Loss:0.2906 + XiCon Loss:3.1328 x Lambda(0.001)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2285
Validation loss decreased (inf --> 0.273260).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2288633
	speed: 0.0445s/iter; left time: 559.0240s
Epoch: 2 cost time: 5.578835487365723
Epoch: 2, Steps: 128 Train Loss: 0.2355 (Forecasting Loss:0.2324 + XiCon Loss:3.1090 x Lambda(0.001)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.2758
Validation loss decreased (0.273260 --> 0.253805).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1799269
	speed: 0.0460s/iter; left time: 571.9409s
Epoch: 3 cost time: 5.8393449783325195
Epoch: 3, Steps: 128 Train Loss: 0.1870 (Forecasting Loss:0.1839 + XiCon Loss:3.0931 x Lambda(0.001)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.3124
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1502583
	speed: 0.0445s/iter; left time: 548.1087s
Epoch: 4 cost time: 5.619584798812866
Epoch: 4, Steps: 128 Train Loss: 0.1604 (Forecasting Loss:0.1573 + XiCon Loss:3.0748 x Lambda(0.001)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.3249
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1479367
	speed: 0.0463s/iter; left time: 563.7489s
Epoch: 5 cost time: 5.786984920501709
Epoch: 5, Steps: 128 Train Loss: 0.1495 (Forecasting Loss:0.1465 + XiCon Loss:3.0675 x Lambda(0.001)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.3120
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1446093
	speed: 0.0435s/iter; left time: 524.6527s
Epoch: 6 cost time: 5.7376978397369385
Epoch: 6, Steps: 128 Train Loss: 0.1451 (Forecasting Loss:0.1420 + XiCon Loss:3.0658 x Lambda(0.001)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.3303
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1381893
	speed: 0.0432s/iter; left time: 515.8241s
Epoch: 7 cost time: 5.4747583866119385
Epoch: 7, Steps: 128 Train Loss: 0.1428 (Forecasting Loss:0.1397 + XiCon Loss:3.0684 x Lambda(0.001)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.3315
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1437614
	speed: 0.0445s/iter; left time: 525.0461s
Epoch: 8 cost time: 5.693434238433838
Epoch: 8, Steps: 128 Train Loss: 0.1419 (Forecasting Loss:0.1389 + XiCon Loss:3.0655 x Lambda(0.001)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.3273
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1346928
	speed: 0.0420s/iter; left time: 489.8596s
Epoch: 9 cost time: 5.087759017944336
Epoch: 9, Steps: 128 Train Loss: 0.1412 (Forecasting Loss:0.1381 + XiCon Loss:3.0653 x Lambda(0.001)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.3281
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1402422
	speed: 0.0436s/iter; left time: 503.9766s
Epoch: 10 cost time: 5.464617967605591
Epoch: 10, Steps: 128 Train Loss: 0.1408 (Forecasting Loss:0.1378 + XiCon Loss:3.0653 x Lambda(0.001)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.3295
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1617835
	speed: 0.0440s/iter; left time: 502.0398s
Epoch: 11 cost time: 5.692278623580933
Epoch: 11, Steps: 128 Train Loss: 0.1406 (Forecasting Loss:0.1375 + XiCon Loss:3.0648 x Lambda(0.001)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.3296
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1344423
	speed: 0.0448s/iter; left time: 505.7483s
Epoch: 12 cost time: 5.649302959442139
Epoch: 12, Steps: 128 Train Loss: 0.1407 (Forecasting Loss:0.1376 + XiCon Loss:3.0654 x Lambda(0.001)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.3293
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.19998008012771606, mae:0.35154595971107483, mape:0.8364927172660828, mspe:28.549692153930664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1815+-0.01959, MAE:0.3320+-0.02045, MAPE:0.8260+-0.09532, MSPE:27.3580+-6.64294, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7010
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4127474
	speed: 0.0650s/iter; left time: 760.5306s
Epoch: 1 cost time: 7.588088512420654
Epoch: 1, Steps: 118 Train Loss: 0.4173 (Forecasting Loss:0.4142 + XiCon Loss:3.1344 x Lambda(0.001)), Vali MSE Loss: 0.4295 Test MSE Loss: 0.3234
Validation loss decreased (inf --> 0.429472).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2645519
	speed: 0.0658s/iter; left time: 762.6913s
Epoch: 2 cost time: 7.707225322723389
Epoch: 2, Steps: 118 Train Loss: 0.2985 (Forecasting Loss:0.2954 + XiCon Loss:3.1705 x Lambda(0.001)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.2920
Validation loss decreased (0.429472 --> 0.311580).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2737227
	speed: 0.0691s/iter; left time: 792.7073s
Epoch: 3 cost time: 8.215277910232544
Epoch: 3, Steps: 118 Train Loss: 0.2597 (Forecasting Loss:0.2566 + XiCon Loss:3.1369 x Lambda(0.001)), Vali MSE Loss: 0.3581 Test MSE Loss: 0.2839
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2652281
	speed: 0.0693s/iter; left time: 786.7809s
Epoch: 4 cost time: 8.146471500396729
Epoch: 4, Steps: 118 Train Loss: 0.2472 (Forecasting Loss:0.2441 + XiCon Loss:3.1212 x Lambda(0.001)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.2544
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2280030
	speed: 0.0721s/iter; left time: 809.8428s
Epoch: 5 cost time: 8.384514093399048
Epoch: 5, Steps: 118 Train Loss: 0.2403 (Forecasting Loss:0.2372 + XiCon Loss:3.1146 x Lambda(0.001)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.2598
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2259639
	speed: 0.0713s/iter; left time: 792.4404s
Epoch: 6 cost time: 8.32049560546875
Epoch: 6, Steps: 118 Train Loss: 0.2373 (Forecasting Loss:0.2341 + XiCon Loss:3.1133 x Lambda(0.001)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.2577
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2411486
	speed: 0.0636s/iter; left time: 698.7690s
Epoch: 7 cost time: 7.672226905822754
Epoch: 7, Steps: 118 Train Loss: 0.2356 (Forecasting Loss:0.2325 + XiCon Loss:3.1129 x Lambda(0.001)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.2560
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2152513
	speed: 0.0662s/iter; left time: 720.1419s
Epoch: 8 cost time: 7.879331588745117
Epoch: 8, Steps: 118 Train Loss: 0.2349 (Forecasting Loss:0.2318 + XiCon Loss:3.1118 x Lambda(0.001)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2575
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2289190
	speed: 0.0682s/iter; left time: 734.0350s
Epoch: 9 cost time: 8.128755807876587
Epoch: 9, Steps: 118 Train Loss: 0.2344 (Forecasting Loss:0.2313 + XiCon Loss:3.1124 x Lambda(0.001)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2578
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2306720
	speed: 0.0685s/iter; left time: 729.2128s
Epoch: 10 cost time: 8.073577404022217
Epoch: 10, Steps: 118 Train Loss: 0.2342 (Forecasting Loss:0.2311 + XiCon Loss:3.1120 x Lambda(0.001)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2571
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2327772
	speed: 0.0690s/iter; left time: 725.9091s
Epoch: 11 cost time: 8.183884143829346
Epoch: 11, Steps: 118 Train Loss: 0.2340 (Forecasting Loss:0.2309 + XiCon Loss:3.1116 x Lambda(0.001)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.2571
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2334372
	speed: 0.0692s/iter; left time: 719.9586s
Epoch: 12 cost time: 8.140556812286377
Epoch: 12, Steps: 118 Train Loss: 0.2339 (Forecasting Loss:0.2308 + XiCon Loss:3.1133 x Lambda(0.001)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.2572
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.21052956581115723, mae:0.3735041320323944, mape:0.6695505380630493, mspe:18.050729751586914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6857
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3766964
	speed: 0.0603s/iter; left time: 705.9826s
Epoch: 1 cost time: 7.1266889572143555
Epoch: 1, Steps: 118 Train Loss: 0.4118 (Forecasting Loss:0.4087 + XiCon Loss:3.1312 x Lambda(0.001)), Vali MSE Loss: 0.4270 Test MSE Loss: 0.3212
Validation loss decreased (inf --> 0.426990).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2485002
	speed: 0.0644s/iter; left time: 746.4009s
Epoch: 2 cost time: 7.7431206703186035
Epoch: 2, Steps: 118 Train Loss: 0.3042 (Forecasting Loss:0.3011 + XiCon Loss:3.1100 x Lambda(0.001)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.2857
Validation loss decreased (0.426990 --> 0.346649).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2476826
	speed: 0.0682s/iter; left time: 782.1155s
Epoch: 3 cost time: 8.077707052230835
Epoch: 3, Steps: 118 Train Loss: 0.2555 (Forecasting Loss:0.2524 + XiCon Loss:3.1040 x Lambda(0.001)), Vali MSE Loss: 0.3475 Test MSE Loss: 0.2687
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2689967
	speed: 0.0668s/iter; left time: 758.1087s
Epoch: 4 cost time: 7.86037802696228
Epoch: 4, Steps: 118 Train Loss: 0.2433 (Forecasting Loss:0.2402 + XiCon Loss:3.1014 x Lambda(0.001)), Vali MSE Loss: 0.3440 Test MSE Loss: 0.2788
Validation loss decreased (0.346649 --> 0.344043).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2347783
	speed: 0.0690s/iter; left time: 775.1187s
Epoch: 5 cost time: 8.059788942337036
Epoch: 5, Steps: 118 Train Loss: 0.2372 (Forecasting Loss:0.2341 + XiCon Loss:3.1017 x Lambda(0.001)), Vali MSE Loss: 0.3371 Test MSE Loss: 0.2826
Validation loss decreased (0.344043 --> 0.337127).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2334417
	speed: 0.0656s/iter; left time: 728.4385s
Epoch: 6 cost time: 7.861806869506836
Epoch: 6, Steps: 118 Train Loss: 0.2347 (Forecasting Loss:0.2316 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.2834
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2226357
	speed: 0.0655s/iter; left time: 720.2847s
Epoch: 7 cost time: 7.812418460845947
Epoch: 7, Steps: 118 Train Loss: 0.2335 (Forecasting Loss:0.2304 + XiCon Loss:3.1000 x Lambda(0.001)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2863
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2226729
	speed: 0.0707s/iter; left time: 768.4515s
Epoch: 8 cost time: 8.250614881515503
Epoch: 8, Steps: 118 Train Loss: 0.2328 (Forecasting Loss:0.2297 + XiCon Loss:3.1024 x Lambda(0.001)), Vali MSE Loss: 0.3375 Test MSE Loss: 0.2864
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2381290
	speed: 0.0684s/iter; left time: 735.9122s
Epoch: 9 cost time: 8.085713863372803
Epoch: 9, Steps: 118 Train Loss: 0.2326 (Forecasting Loss:0.2295 + XiCon Loss:3.1002 x Lambda(0.001)), Vali MSE Loss: 0.3377 Test MSE Loss: 0.2865
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2607518
	speed: 0.0729s/iter; left time: 775.4928s
Epoch: 10 cost time: 8.478620767593384
Epoch: 10, Steps: 118 Train Loss: 0.2323 (Forecasting Loss:0.2292 + XiCon Loss:3.1017 x Lambda(0.001)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.2862
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2305120
	speed: 0.0688s/iter; left time: 723.4519s
Epoch: 11 cost time: 8.096396446228027
Epoch: 11, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2291 + XiCon Loss:3.0996 x Lambda(0.001)), Vali MSE Loss: 0.3376 Test MSE Loss: 0.2871
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2287369
	speed: 0.0676s/iter; left time: 702.8490s
Epoch: 12 cost time: 7.737408876419067
Epoch: 12, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2291 + XiCon Loss:3.0997 x Lambda(0.001)), Vali MSE Loss: 0.3377 Test MSE Loss: 0.2868
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2328199
	speed: 0.0704s/iter; left time: 724.5321s
Epoch: 13 cost time: 8.280009746551514
Epoch: 13, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2291 + XiCon Loss:3.1002 x Lambda(0.001)), Vali MSE Loss: 0.3376 Test MSE Loss: 0.2868
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2364478
	speed: 0.0712s/iter; left time: 723.6471s
Epoch: 14 cost time: 8.413859367370605
Epoch: 14, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.1002 x Lambda(0.001)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2868
Validation loss decreased (0.337127 --> 0.337012).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2383765
	speed: 0.0701s/iter; left time: 704.8493s
Epoch: 15 cost time: 8.30234432220459
Epoch: 15, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.1028 x Lambda(0.001)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2869
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2319790
	speed: 0.0702s/iter; left time: 697.0845s
Epoch: 16 cost time: 8.216499328613281
Epoch: 16, Steps: 118 Train Loss: 0.2320 (Forecasting Loss:0.2289 + XiCon Loss:3.1001 x Lambda(0.001)), Vali MSE Loss: 0.3366 Test MSE Loss: 0.2869
Validation loss decreased (0.337012 --> 0.336606).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2422344
	speed: 0.0651s/iter; left time: 638.3393s
Epoch: 17 cost time: 7.641668319702148
Epoch: 17, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.1009 x Lambda(0.001)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2869
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2315291
	speed: 0.0560s/iter; left time: 543.3523s
Epoch: 18 cost time: 6.21763801574707
Epoch: 18, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.0994 x Lambda(0.001)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.2869
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2469154
	speed: 0.0873s/iter; left time: 836.2662s
Epoch: 19 cost time: 10.391648292541504
Epoch: 19, Steps: 118 Train Loss: 0.2320 (Forecasting Loss:0.2289 + XiCon Loss:3.1001 x Lambda(0.001)), Vali MSE Loss: 0.3377 Test MSE Loss: 0.2869
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.2471039
	speed: 0.0514s/iter; left time: 485.7892s
Epoch: 20 cost time: 5.722752332687378
Epoch: 20, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2291 + XiCon Loss:3.1005 x Lambda(0.001)), Vali MSE Loss: 0.3377 Test MSE Loss: 0.2869
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.2518182
	speed: 0.0477s/iter; left time: 445.8871s
Epoch: 21 cost time: 6.143114328384399
Epoch: 21, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.1009 x Lambda(0.001)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2869
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.2322492
	speed: 0.0699s/iter; left time: 644.2958s
Epoch: 22 cost time: 8.334027528762817
Epoch: 22, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2290 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.2869
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.2446523
	speed: 0.0738s/iter; left time: 672.0449s
Epoch: 23 cost time: 8.51756238937378
Epoch: 23, Steps: 118 Train Loss: 0.2320 (Forecasting Loss:0.2289 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.2869
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.2270839
	speed: 0.0726s/iter; left time: 652.6022s
Epoch: 24 cost time: 8.509877443313599
Epoch: 24, Steps: 118 Train Loss: 0.2322 (Forecasting Loss:0.2291 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.2869
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.2375177
	speed: 0.0640s/iter; left time: 567.2602s
Epoch: 25 cost time: 7.637322187423706
Epoch: 25, Steps: 118 Train Loss: 0.2321 (Forecasting Loss:0.2290 + XiCon Loss:3.1015 x Lambda(0.001)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.2869
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.2085792
	speed: 0.0570s/iter; left time: 499.0520s
Epoch: 26 cost time: 6.247255802154541
Epoch: 26, Steps: 118 Train Loss: 0.2319 (Forecasting Loss:0.2288 + XiCon Loss:3.0997 x Lambda(0.001)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.2869
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20785321295261383, mae:0.36589688062667847, mape:0.7684673070907593, mspe:24.305688858032227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4895
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3817890
	speed: 0.0463s/iter; left time: 541.7618s
Epoch: 1 cost time: 5.72180700302124
Epoch: 1, Steps: 118 Train Loss: 0.3961 (Forecasting Loss:0.3929 + XiCon Loss:3.1189 x Lambda(0.001)), Vali MSE Loss: 0.4081 Test MSE Loss: 0.2880
Validation loss decreased (inf --> 0.408126).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2891963
	speed: 0.0629s/iter; left time: 729.0883s
Epoch: 2 cost time: 7.422360420227051
Epoch: 2, Steps: 118 Train Loss: 0.3296 (Forecasting Loss:0.3265 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.3556 Test MSE Loss: 0.2762
Validation loss decreased (0.408126 --> 0.355585).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2778069
	speed: 0.0582s/iter; left time: 667.0890s
Epoch: 3 cost time: 7.023319959640503
Epoch: 3, Steps: 118 Train Loss: 0.2797 (Forecasting Loss:0.2766 + XiCon Loss:3.0807 x Lambda(0.001)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2596
Validation loss decreased (0.355585 --> 0.321737).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2540001
	speed: 0.0619s/iter; left time: 702.0826s
Epoch: 4 cost time: 7.322798490524292
Epoch: 4, Steps: 118 Train Loss: 0.2618 (Forecasting Loss:0.2587 + XiCon Loss:3.0739 x Lambda(0.001)), Vali MSE Loss: 0.3110 Test MSE Loss: 0.2497
Validation loss decreased (0.321737 --> 0.311046).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2483327
	speed: 0.0630s/iter; left time: 707.0805s
Epoch: 5 cost time: 7.313403129577637
Epoch: 5, Steps: 118 Train Loss: 0.2537 (Forecasting Loss:0.2506 + XiCon Loss:3.0682 x Lambda(0.001)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2582
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2454743
	speed: 0.0589s/iter; left time: 654.9243s
Epoch: 6 cost time: 6.964118719100952
Epoch: 6, Steps: 118 Train Loss: 0.2500 (Forecasting Loss:0.2470 + XiCon Loss:3.0657 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2529
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2389182
	speed: 0.0289s/iter; left time: 317.7254s
Epoch: 7 cost time: 3.362586259841919
Epoch: 7, Steps: 118 Train Loss: 0.2478 (Forecasting Loss:0.2447 + XiCon Loss:3.0627 x Lambda(0.001)), Vali MSE Loss: 0.3108 Test MSE Loss: 0.2504
Validation loss decreased (0.311046 --> 0.310820).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2509861
	speed: 0.0452s/iter; left time: 491.9600s
Epoch: 8 cost time: 5.643130779266357
Epoch: 8, Steps: 118 Train Loss: 0.2471 (Forecasting Loss:0.2440 + XiCon Loss:3.0630 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2535
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2440897
	speed: 0.0603s/iter; left time: 648.3884s
Epoch: 9 cost time: 7.189759731292725
Epoch: 9, Steps: 118 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.0618 x Lambda(0.001)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2561
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2332321
	speed: 0.0608s/iter; left time: 646.4020s
Epoch: 10 cost time: 7.138439893722534
Epoch: 10, Steps: 118 Train Loss: 0.2459 (Forecasting Loss:0.2429 + XiCon Loss:3.0609 x Lambda(0.001)), Vali MSE Loss: 0.3124 Test MSE Loss: 0.2570
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2512021
	speed: 0.0627s/iter; left time: 659.8879s
Epoch: 11 cost time: 7.386871337890625
Epoch: 11, Steps: 118 Train Loss: 0.2459 (Forecasting Loss:0.2428 + XiCon Loss:3.0613 x Lambda(0.001)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.2568
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2555413
	speed: 0.0636s/iter; left time: 661.7394s
Epoch: 12 cost time: 7.3953680992126465
Epoch: 12, Steps: 118 Train Loss: 0.2460 (Forecasting Loss:0.2429 + XiCon Loss:3.0620 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2566
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2480834
	speed: 0.0572s/iter; left time: 588.4785s
Epoch: 13 cost time: 6.8287353515625
Epoch: 13, Steps: 118 Train Loss: 0.2456 (Forecasting Loss:0.2426 + XiCon Loss:3.0614 x Lambda(0.001)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2562
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2521864
	speed: 0.0284s/iter; left time: 288.3180s
Epoch: 14 cost time: 3.3608267307281494
Epoch: 14, Steps: 118 Train Loss: 0.2459 (Forecasting Loss:0.2428 + XiCon Loss:3.0612 x Lambda(0.001)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.2564
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2580598
	speed: 0.0395s/iter; left time: 397.3826s
Epoch: 15 cost time: 5.076165437698364
Epoch: 15, Steps: 118 Train Loss: 0.2457 (Forecasting Loss:0.2427 + XiCon Loss:3.0625 x Lambda(0.001)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.2565
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2380480
	speed: 0.0636s/iter; left time: 631.1287s
Epoch: 16 cost time: 7.582747220993042
Epoch: 16, Steps: 118 Train Loss: 0.2457 (Forecasting Loss:0.2427 + XiCon Loss:3.0612 x Lambda(0.001)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.2564
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2392435
	speed: 0.0655s/iter; left time: 642.4032s
Epoch: 17 cost time: 7.686662912368774
Epoch: 17, Steps: 118 Train Loss: 0.2457 (Forecasting Loss:0.2426 + XiCon Loss:3.0604 x Lambda(0.001)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.2564
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.16908913850784302, mae:0.3316543996334076, mape:0.6293310523033142, mspe:16.447858810424805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7345
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3383943
	speed: 0.0636s/iter; left time: 743.7823s
Epoch: 1 cost time: 7.508418321609497
Epoch: 1, Steps: 118 Train Loss: 0.4003 (Forecasting Loss:0.3972 + XiCon Loss:3.1318 x Lambda(0.001)), Vali MSE Loss: 0.3999 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.399933).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3328795
	speed: 0.0584s/iter; left time: 676.3465s
Epoch: 2 cost time: 6.880200386047363
Epoch: 2, Steps: 118 Train Loss: 0.3629 (Forecasting Loss:0.3598 + XiCon Loss:3.1095 x Lambda(0.001)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.2763
Validation loss decreased (0.399933 --> 0.331271).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2653590
	speed: 0.0581s/iter; left time: 666.6877s
Epoch: 3 cost time: 6.391639232635498
Epoch: 3, Steps: 118 Train Loss: 0.2834 (Forecasting Loss:0.2803 + XiCon Loss:3.0828 x Lambda(0.001)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2660
Validation loss decreased (0.331271 --> 0.304123).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2561837
	speed: 0.0318s/iter; left time: 360.9597s
Epoch: 4 cost time: 4.367113828659058
Epoch: 4, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2657 + XiCon Loss:3.0768 x Lambda(0.001)), Vali MSE Loss: 0.2956 Test MSE Loss: 0.2608
Validation loss decreased (0.304123 --> 0.295607).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2571581
	speed: 0.0704s/iter; left time: 791.0250s
Epoch: 5 cost time: 8.336930274963379
Epoch: 5, Steps: 118 Train Loss: 0.2623 (Forecasting Loss:0.2592 + XiCon Loss:3.0794 x Lambda(0.001)), Vali MSE Loss: 0.3058 Test MSE Loss: 0.2641
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2542064
	speed: 0.0732s/iter; left time: 813.6238s
Epoch: 6 cost time: 8.659977674484253
Epoch: 6, Steps: 118 Train Loss: 0.2584 (Forecasting Loss:0.2553 + XiCon Loss:3.0778 x Lambda(0.001)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2666
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2625485
	speed: 0.0711s/iter; left time: 781.2089s
Epoch: 7 cost time: 8.54442024230957
Epoch: 7, Steps: 118 Train Loss: 0.2567 (Forecasting Loss:0.2536 + XiCon Loss:3.0806 x Lambda(0.001)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2644
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2709633
	speed: 0.0731s/iter; left time: 795.1418s
Epoch: 8 cost time: 8.435487747192383
Epoch: 8, Steps: 118 Train Loss: 0.2556 (Forecasting Loss:0.2525 + XiCon Loss:3.0800 x Lambda(0.001)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.2644
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2505699
	speed: 0.0671s/iter; left time: 721.7435s
Epoch: 9 cost time: 7.336608409881592
Epoch: 9, Steps: 118 Train Loss: 0.2550 (Forecasting Loss:0.2519 + XiCon Loss:3.0809 x Lambda(0.001)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.2633
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2383545
	speed: 0.0316s/iter; left time: 336.0433s
Epoch: 10 cost time: 3.726746082305908
Epoch: 10, Steps: 118 Train Loss: 0.2547 (Forecasting Loss:0.2516 + XiCon Loss:3.0783 x Lambda(0.001)), Vali MSE Loss: 0.3025 Test MSE Loss: 0.2632
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2366992
	speed: 0.0745s/iter; left time: 783.7300s
Epoch: 11 cost time: 8.818213701248169
Epoch: 11, Steps: 118 Train Loss: 0.2549 (Forecasting Loss:0.2518 + XiCon Loss:3.0799 x Lambda(0.001)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.2636
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2655047
	speed: 0.0752s/iter; left time: 782.3746s
Epoch: 12 cost time: 8.961628198623657
Epoch: 12, Steps: 118 Train Loss: 0.2547 (Forecasting Loss:0.2516 + XiCon Loss:3.0800 x Lambda(0.001)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.2635
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2572103
	speed: 0.0704s/iter; left time: 724.4759s
Epoch: 13 cost time: 8.292819499969482
Epoch: 13, Steps: 118 Train Loss: 0.2546 (Forecasting Loss:0.2515 + XiCon Loss:3.0809 x Lambda(0.001)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.2635
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2456918
	speed: 0.0725s/iter; left time: 737.3755s
Epoch: 14 cost time: 8.673429489135742
Epoch: 14, Steps: 118 Train Loss: 0.2546 (Forecasting Loss:0.2515 + XiCon Loss:3.0804 x Lambda(0.001)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.2634
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1794179528951645, mae:0.3422336280345917, mape:0.705438494682312, mspe:20.481740951538086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7069
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3739308
	speed: 0.0559s/iter; left time: 654.2015s
Epoch: 1 cost time: 6.139812231063843
Epoch: 1, Steps: 118 Train Loss: 0.4143 (Forecasting Loss:0.4112 + XiCon Loss:3.1155 x Lambda(0.001)), Vali MSE Loss: 0.4347 Test MSE Loss: 0.3246
Validation loss decreased (inf --> 0.434660).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2565978
	speed: 0.0311s/iter; left time: 360.3022s
Epoch: 2 cost time: 3.6711995601654053
Epoch: 2, Steps: 118 Train Loss: 0.3016 (Forecasting Loss:0.2984 + XiCon Loss:3.1223 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2777
Validation loss decreased (0.434660 --> 0.311293).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2431653
	speed: 0.0732s/iter; left time: 839.3723s
Epoch: 3 cost time: 8.757256746292114
Epoch: 3, Steps: 118 Train Loss: 0.2542 (Forecasting Loss:0.2511 + XiCon Loss:3.0920 x Lambda(0.001)), Vali MSE Loss: 0.2856 Test MSE Loss: 0.2651
Validation loss decreased (0.311293 --> 0.285562).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2320531
	speed: 0.0727s/iter; left time: 824.8510s
Epoch: 4 cost time: 8.661773681640625
Epoch: 4, Steps: 118 Train Loss: 0.2419 (Forecasting Loss:0.2388 + XiCon Loss:3.0887 x Lambda(0.001)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2613
Validation loss decreased (0.285562 --> 0.281615).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2359175
	speed: 0.0749s/iter; left time: 840.9177s
Epoch: 5 cost time: 8.836187839508057
Epoch: 5, Steps: 118 Train Loss: 0.2366 (Forecasting Loss:0.2335 + XiCon Loss:3.0857 x Lambda(0.001)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2642
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2515329
	speed: 0.0731s/iter; left time: 812.1200s
Epoch: 6 cost time: 8.583191156387329
Epoch: 6, Steps: 118 Train Loss: 0.2340 (Forecasting Loss:0.2309 + XiCon Loss:3.0824 x Lambda(0.001)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2616
Validation loss decreased (0.281615 --> 0.278978).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2176485
	speed: 0.0717s/iter; left time: 788.0749s
Epoch: 7 cost time: 8.318589210510254
Epoch: 7, Steps: 118 Train Loss: 0.2326 (Forecasting Loss:0.2295 + XiCon Loss:3.0803 x Lambda(0.001)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.2610
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2406301
	speed: 0.0729s/iter; left time: 792.5095s
Epoch: 8 cost time: 8.525511741638184
Epoch: 8, Steps: 118 Train Loss: 0.2318 (Forecasting Loss:0.2288 + XiCon Loss:3.0789 x Lambda(0.001)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2610
Validation loss decreased (0.278978 --> 0.278461).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2269318
	speed: 0.0714s/iter; left time: 767.8351s
Epoch: 9 cost time: 8.407922267913818
Epoch: 9, Steps: 118 Train Loss: 0.2316 (Forecasting Loss:0.2285 + XiCon Loss:3.0794 x Lambda(0.001)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.2609
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2323115
	speed: 0.0740s/iter; left time: 787.5160s
Epoch: 10 cost time: 8.672695398330688
Epoch: 10, Steps: 118 Train Loss: 0.2313 (Forecasting Loss:0.2283 + XiCon Loss:3.0788 x Lambda(0.001)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2609
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2201706
	speed: 0.0742s/iter; left time: 780.4048s
Epoch: 11 cost time: 8.454911708831787
Epoch: 11, Steps: 118 Train Loss: 0.2314 (Forecasting Loss:0.2283 + XiCon Loss:3.0804 x Lambda(0.001)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2615
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2441775
	speed: 0.0659s/iter; left time: 685.1465s
Epoch: 12 cost time: 7.614665269851685
Epoch: 12, Steps: 118 Train Loss: 0.2314 (Forecasting Loss:0.2283 + XiCon Loss:3.0777 x Lambda(0.001)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2612
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2313311
	speed: 0.0742s/iter; left time: 763.4724s
Epoch: 13 cost time: 8.845440149307251
Epoch: 13, Steps: 118 Train Loss: 0.2313 (Forecasting Loss:0.2282 + XiCon Loss:3.0779 x Lambda(0.001)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2611
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2280725
	speed: 0.0745s/iter; left time: 757.7264s
Epoch: 14 cost time: 8.849308490753174
Epoch: 14, Steps: 118 Train Loss: 0.2314 (Forecasting Loss:0.2283 + XiCon Loss:3.0794 x Lambda(0.001)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2610
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2310824
	speed: 0.0734s/iter; left time: 737.7688s
Epoch: 15 cost time: 8.844387292861938
Epoch: 15, Steps: 118 Train Loss: 0.2315 (Forecasting Loss:0.2284 + XiCon Loss:3.0807 x Lambda(0.001)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2610
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2277571
	speed: 0.0703s/iter; left time: 698.6144s
Epoch: 16 cost time: 8.318049907684326
Epoch: 16, Steps: 118 Train Loss: 0.2313 (Forecasting Loss:0.2282 + XiCon Loss:3.0797 x Lambda(0.001)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2611
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2212714
	speed: 0.0681s/iter; left time: 668.0188s
Epoch: 17 cost time: 7.938534498214722
Epoch: 17, Steps: 118 Train Loss: 0.2314 (Forecasting Loss:0.2283 + XiCon Loss:3.0790 x Lambda(0.001)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.2611
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2243726
	speed: 0.0741s/iter; left time: 718.0365s
Epoch: 18 cost time: 8.689805507659912
Epoch: 18, Steps: 118 Train Loss: 0.2312 (Forecasting Loss:0.2281 + XiCon Loss:3.0788 x Lambda(0.001)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2611
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17852793633937836, mae:0.3435497283935547, mape:0.6523823738098145, mspe:17.67724609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1891+-0.02337, MAE:0.3514+-0.02181, MAPE:0.6850+-0.06740, MSPE:19.3927+-3.86411, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6631
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5830941
	speed: 0.0795s/iter; left time: 842.7407s
Epoch: 1 cost time: 8.539625644683838
Epoch: 1, Steps: 107 Train Loss: 0.6371 (Forecasting Loss:0.6340 + XiCon Loss:3.1434 x Lambda(0.001)), Vali MSE Loss: 0.5962 Test MSE Loss: 0.4668
Validation loss decreased (inf --> 0.596244).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3091605
	speed: 0.0983s/iter; left time: 1031.7103s
Epoch: 2 cost time: 10.606894493103027
Epoch: 2, Steps: 107 Train Loss: 0.3619 (Forecasting Loss:0.3587 + XiCon Loss:3.1879 x Lambda(0.001)), Vali MSE Loss: 0.3780 Test MSE Loss: 0.2515
Validation loss decreased (0.596244 --> 0.377956).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2627054
	speed: 0.0864s/iter; left time: 896.9724s
Epoch: 3 cost time: 9.382891178131104
Epoch: 3, Steps: 107 Train Loss: 0.2770 (Forecasting Loss:0.2738 + XiCon Loss:3.1661 x Lambda(0.001)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.2622
Validation loss decreased (0.377956 --> 0.352915).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2619622
	speed: 0.1015s/iter; left time: 1043.1615s
Epoch: 4 cost time: 10.976417779922485
Epoch: 4, Steps: 107 Train Loss: 0.2627 (Forecasting Loss:0.2596 + XiCon Loss:3.1496 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2395
Validation loss decreased (0.352915 --> 0.320844).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2694928
	speed: 0.0959s/iter; left time: 975.1685s
Epoch: 5 cost time: 10.328782558441162
Epoch: 5, Steps: 107 Train Loss: 0.2577 (Forecasting Loss:0.2545 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.2398
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2448922
	speed: 0.1015s/iter; left time: 1021.4921s
Epoch: 6 cost time: 10.90264105796814
Epoch: 6, Steps: 107 Train Loss: 0.2550 (Forecasting Loss:0.2519 + XiCon Loss:3.1394 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2423
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2609536
	speed: 0.0950s/iter; left time: 946.1555s
Epoch: 7 cost time: 10.245323657989502
Epoch: 7, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2505 + XiCon Loss:3.1361 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2418
Validation loss decreased (0.320844 --> 0.319003).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2518609
	speed: 0.0962s/iter; left time: 947.9551s
Epoch: 8 cost time: 10.313472747802734
Epoch: 8, Steps: 107 Train Loss: 0.2531 (Forecasting Loss:0.2499 + XiCon Loss:3.1352 x Lambda(0.001)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2422
Validation loss decreased (0.319003 --> 0.318402).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2570174
	speed: 0.0996s/iter; left time: 970.4471s
Epoch: 9 cost time: 10.669533729553223
Epoch: 9, Steps: 107 Train Loss: 0.2525 (Forecasting Loss:0.2494 + XiCon Loss:3.1329 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2409
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2481943
	speed: 0.1008s/iter; left time: 971.6402s
Epoch: 10 cost time: 10.884726524353027
Epoch: 10, Steps: 107 Train Loss: 0.2525 (Forecasting Loss:0.2494 + XiCon Loss:3.1319 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2418
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2529068
	speed: 0.1006s/iter; left time: 958.4868s
Epoch: 11 cost time: 10.820967197418213
Epoch: 11, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2492 + XiCon Loss:3.1317 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2409
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2440580
	speed: 0.0951s/iter; left time: 896.3137s
Epoch: 12 cost time: 10.23523497581482
Epoch: 12, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2490 + XiCon Loss:3.1329 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2410
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2537772
	speed: 0.0980s/iter; left time: 912.7828s
Epoch: 13 cost time: 10.689656257629395
Epoch: 13, Steps: 107 Train Loss: 0.2522 (Forecasting Loss:0.2490 + XiCon Loss:3.1330 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2412
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2503468
	speed: 0.0990s/iter; left time: 911.5073s
Epoch: 14 cost time: 10.577869653701782
Epoch: 14, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.1333 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2413
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2630823
	speed: 0.1032s/iter; left time: 939.2060s
Epoch: 15 cost time: 11.121298789978027
Epoch: 15, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.1315 x Lambda(0.001)), Vali MSE Loss: 0.3189 Test MSE Loss: 0.2413
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2558004
	speed: 0.0932s/iter; left time: 838.4535s
Epoch: 16 cost time: 9.797673463821411
Epoch: 16, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2489 + XiCon Loss:3.1326 x Lambda(0.001)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2412
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2521907
	speed: 0.0993s/iter; left time: 882.6696s
Epoch: 17 cost time: 10.80681586265564
Epoch: 17, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2490 + XiCon Loss:3.1321 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2412
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2468052
	speed: 0.0996s/iter; left time: 874.3116s
Epoch: 18 cost time: 10.677426815032959
Epoch: 18, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2493 + XiCon Loss:3.1323 x Lambda(0.001)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2412
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.15999074280261993, mae:0.3244752287864685, mape:0.6444851756095886, mspe:17.038166046142578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6545
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5997749
	speed: 0.0775s/iter; left time: 821.2888s
Epoch: 1 cost time: 8.351861715316772
Epoch: 1, Steps: 107 Train Loss: 0.6159 (Forecasting Loss:0.6128 + XiCon Loss:3.1288 x Lambda(0.001)), Vali MSE Loss: 0.5467 Test MSE Loss: 0.4052
Validation loss decreased (inf --> 0.546690).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2995974
	speed: 0.0870s/iter; left time: 913.3277s
Epoch: 2 cost time: 9.377015113830566
Epoch: 2, Steps: 107 Train Loss: 0.3518 (Forecasting Loss:0.3486 + XiCon Loss:3.1584 x Lambda(0.001)), Vali MSE Loss: 0.4589 Test MSE Loss: 0.2514
Validation loss decreased (0.546690 --> 0.458943).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2813879
	speed: 0.0933s/iter; left time: 969.6146s
Epoch: 3 cost time: 10.01830005645752
Epoch: 3, Steps: 107 Train Loss: 0.2755 (Forecasting Loss:0.2724 + XiCon Loss:3.1326 x Lambda(0.001)), Vali MSE Loss: 0.4052 Test MSE Loss: 0.2487
Validation loss decreased (0.458943 --> 0.405177).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2514899
	speed: 0.1035s/iter; left time: 1064.1040s
Epoch: 4 cost time: 11.144974708557129
Epoch: 4, Steps: 107 Train Loss: 0.2625 (Forecasting Loss:0.2594 + XiCon Loss:3.1273 x Lambda(0.001)), Vali MSE Loss: 0.3450 Test MSE Loss: 0.2394
Validation loss decreased (0.405177 --> 0.345047).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2576687
	speed: 0.1035s/iter; left time: 1053.1764s
Epoch: 5 cost time: 11.141358375549316
Epoch: 5, Steps: 107 Train Loss: 0.2571 (Forecasting Loss:0.2540 + XiCon Loss:3.1231 x Lambda(0.001)), Vali MSE Loss: 0.3653 Test MSE Loss: 0.2373
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2384453
	speed: 0.0994s/iter; left time: 1000.4654s
Epoch: 6 cost time: 10.841988801956177
Epoch: 6, Steps: 107 Train Loss: 0.2539 (Forecasting Loss:0.2508 + XiCon Loss:3.1208 x Lambda(0.001)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.2342
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2546321
	speed: 0.0967s/iter; left time: 962.6672s
Epoch: 7 cost time: 10.524696350097656
Epoch: 7, Steps: 107 Train Loss: 0.2527 (Forecasting Loss:0.2496 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3503 Test MSE Loss: 0.2337
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2604659
	speed: 0.1032s/iter; left time: 1016.4714s
Epoch: 8 cost time: 11.192936658859253
Epoch: 8, Steps: 107 Train Loss: 0.2519 (Forecasting Loss:0.2487 + XiCon Loss:3.1190 x Lambda(0.001)), Vali MSE Loss: 0.3516 Test MSE Loss: 0.2333
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2421109
	speed: 0.1031s/iter; left time: 1004.3990s
Epoch: 9 cost time: 11.081875324249268
Epoch: 9, Steps: 107 Train Loss: 0.2513 (Forecasting Loss:0.2482 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3496 Test MSE Loss: 0.2342
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2444098
	speed: 0.1059s/iter; left time: 1020.1879s
Epoch: 10 cost time: 11.293401002883911
Epoch: 10, Steps: 107 Train Loss: 0.2509 (Forecasting Loss:0.2478 + XiCon Loss:3.1205 x Lambda(0.001)), Vali MSE Loss: 0.3526 Test MSE Loss: 0.2344
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2551111
	speed: 0.0947s/iter; left time: 903.0281s
Epoch: 11 cost time: 10.196978330612183
Epoch: 11, Steps: 107 Train Loss: 0.2509 (Forecasting Loss:0.2478 + XiCon Loss:3.1207 x Lambda(0.001)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.2340
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2511759
	speed: 0.1027s/iter; left time: 967.4021s
Epoch: 12 cost time: 10.99858808517456
Epoch: 12, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2480 + XiCon Loss:3.1209 x Lambda(0.001)), Vali MSE Loss: 0.3512 Test MSE Loss: 0.2340
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2557837
	speed: 0.1023s/iter; left time: 953.1347s
Epoch: 13 cost time: 11.07177186012268
Epoch: 13, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2479 + XiCon Loss:3.1176 x Lambda(0.001)), Vali MSE Loss: 0.3521 Test MSE Loss: 0.2341
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2552331
	speed: 0.0997s/iter; left time: 918.3027s
Epoch: 14 cost time: 10.863525867462158
Epoch: 14, Steps: 107 Train Loss: 0.2508 (Forecasting Loss:0.2477 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3523 Test MSE Loss: 0.2341
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.15662162005901337, mae:0.3222053050994873, mape:0.6689207553863525, mspe:18.87628936767578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5914690
	speed: 0.0778s/iter; left time: 824.6344s
Epoch: 1 cost time: 8.367969512939453
Epoch: 1, Steps: 107 Train Loss: 0.6202 (Forecasting Loss:0.6171 + XiCon Loss:3.1602 x Lambda(0.001)), Vali MSE Loss: 0.5247 Test MSE Loss: 0.3790
Validation loss decreased (inf --> 0.524666).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3154758
	speed: 0.0747s/iter; left time: 784.0473s
Epoch: 2 cost time: 8.071539640426636
Epoch: 2, Steps: 107 Train Loss: 0.4000 (Forecasting Loss:0.3969 + XiCon Loss:3.1224 x Lambda(0.001)), Vali MSE Loss: 0.3753 Test MSE Loss: 0.3254
Validation loss decreased (0.524666 --> 0.375308).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2843318
	speed: 0.0823s/iter; left time: 854.5195s
Epoch: 3 cost time: 8.873526573181152
Epoch: 3, Steps: 107 Train Loss: 0.2929 (Forecasting Loss:0.2898 + XiCon Loss:3.0896 x Lambda(0.001)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.2568
Validation loss decreased (0.375308 --> 0.345650).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2604565
	speed: 0.0821s/iter; left time: 844.4595s
Epoch: 4 cost time: 8.81365418434143
Epoch: 4, Steps: 107 Train Loss: 0.2708 (Forecasting Loss:0.2677 + XiCon Loss:3.0831 x Lambda(0.001)), Vali MSE Loss: 0.3471 Test MSE Loss: 0.2912
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2728038
	speed: 0.0839s/iter; left time: 853.9558s
Epoch: 5 cost time: 9.015506744384766
Epoch: 5, Steps: 107 Train Loss: 0.2635 (Forecasting Loss:0.2605 + XiCon Loss:3.0806 x Lambda(0.001)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.2892
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2617339
	speed: 0.0778s/iter; left time: 782.8681s
Epoch: 6 cost time: 8.476766347885132
Epoch: 6, Steps: 107 Train Loss: 0.2603 (Forecasting Loss:0.2572 + XiCon Loss:3.0797 x Lambda(0.001)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.2713
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2483497
	speed: 0.0737s/iter; left time: 733.7904s
Epoch: 7 cost time: 8.030909538269043
Epoch: 7, Steps: 107 Train Loss: 0.2582 (Forecasting Loss:0.2551 + XiCon Loss:3.0797 x Lambda(0.001)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2601404
	speed: 0.0909s/iter; left time: 895.5640s
Epoch: 8 cost time: 9.739753484725952
Epoch: 8, Steps: 107 Train Loss: 0.2573 (Forecasting Loss:0.2542 + XiCon Loss:3.0788 x Lambda(0.001)), Vali MSE Loss: 0.3599 Test MSE Loss: 0.3009
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2522288
	speed: 0.0875s/iter; left time: 853.1105s
Epoch: 9 cost time: 9.493001222610474
Epoch: 9, Steps: 107 Train Loss: 0.2567 (Forecasting Loss:0.2536 + XiCon Loss:3.0796 x Lambda(0.001)), Vali MSE Loss: 0.3648 Test MSE Loss: 0.2943
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2472835
	speed: 0.0909s/iter; left time: 876.1357s
Epoch: 10 cost time: 9.811844825744629
Epoch: 10, Steps: 107 Train Loss: 0.2565 (Forecasting Loss:0.2534 + XiCon Loss:3.0782 x Lambda(0.001)), Vali MSE Loss: 0.3621 Test MSE Loss: 0.2961
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2553674
	speed: 0.0858s/iter; left time: 818.1217s
Epoch: 11 cost time: 9.205019235610962
Epoch: 11, Steps: 107 Train Loss: 0.2563 (Forecasting Loss:0.2533 + XiCon Loss:3.0777 x Lambda(0.001)), Vali MSE Loss: 0.3657 Test MSE Loss: 0.2963
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2539477
	speed: 0.0805s/iter; left time: 758.6406s
Epoch: 12 cost time: 8.67178463935852
Epoch: 12, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.0803 x Lambda(0.001)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.2991
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2517091
	speed: 0.0864s/iter; left time: 805.2286s
Epoch: 13 cost time: 9.343733549118042
Epoch: 13, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.0784 x Lambda(0.001)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2988
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17412330210208893, mae:0.33939144015312195, mape:0.5738187432289124, mspe:13.073803901672363 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.0320
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6120039
	speed: 0.0902s/iter; left time: 955.9296s
Epoch: 1 cost time: 9.71911334991455
Epoch: 1, Steps: 107 Train Loss: 0.6207 (Forecasting Loss:0.6175 + XiCon Loss:3.1510 x Lambda(0.001)), Vali MSE Loss: 0.5745 Test MSE Loss: 0.4260
Validation loss decreased (inf --> 0.574477).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2947460
	speed: 0.1045s/iter; left time: 1096.6892s
Epoch: 2 cost time: 11.25916337966919
Epoch: 2, Steps: 107 Train Loss: 0.3404 (Forecasting Loss:0.3373 + XiCon Loss:3.1100 x Lambda(0.001)), Vali MSE Loss: 0.4218 Test MSE Loss: 0.2570
Validation loss decreased (0.574477 --> 0.421845).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2634007
	speed: 0.1019s/iter; left time: 1058.6262s
Epoch: 3 cost time: 10.917584419250488
Epoch: 3, Steps: 107 Train Loss: 0.2716 (Forecasting Loss:0.2685 + XiCon Loss:3.1067 x Lambda(0.001)), Vali MSE Loss: 0.3554 Test MSE Loss: 0.2448
Validation loss decreased (0.421845 --> 0.355400).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2585037
	speed: 0.1032s/iter; left time: 1061.0796s
Epoch: 4 cost time: 11.225450992584229
Epoch: 4, Steps: 107 Train Loss: 0.2597 (Forecasting Loss:0.2566 + XiCon Loss:3.1033 x Lambda(0.001)), Vali MSE Loss: 0.3659 Test MSE Loss: 0.2448
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2649592
	speed: 0.1055s/iter; left time: 1073.6610s
Epoch: 5 cost time: 11.38234543800354
Epoch: 5, Steps: 107 Train Loss: 0.2551 (Forecasting Loss:0.2520 + XiCon Loss:3.1018 x Lambda(0.001)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.2414
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2551310
	speed: 0.1034s/iter; left time: 1040.5954s
Epoch: 6 cost time: 11.16744065284729
Epoch: 6, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2493 + XiCon Loss:3.1024 x Lambda(0.001)), Vali MSE Loss: 0.3613 Test MSE Loss: 0.2390
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2507411
	speed: 0.1022s/iter; left time: 1018.1685s
Epoch: 7 cost time: 10.997936248779297
Epoch: 7, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2480 + XiCon Loss:3.1009 x Lambda(0.001)), Vali MSE Loss: 0.3643 Test MSE Loss: 0.2454
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2617792
	speed: 0.0914s/iter; left time: 900.2317s
Epoch: 8 cost time: 9.871522665023804
Epoch: 8, Steps: 107 Train Loss: 0.2501 (Forecasting Loss:0.2470 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3648 Test MSE Loss: 0.2420
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2463420
	speed: 0.0960s/iter; left time: 935.7425s
Epoch: 9 cost time: 10.380244016647339
Epoch: 9, Steps: 107 Train Loss: 0.2497 (Forecasting Loss:0.2466 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3655 Test MSE Loss: 0.2411
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2568674
	speed: 0.0967s/iter; left time: 931.9548s
Epoch: 10 cost time: 10.428746700286865
Epoch: 10, Steps: 107 Train Loss: 0.2497 (Forecasting Loss:0.2466 + XiCon Loss:3.0997 x Lambda(0.001)), Vali MSE Loss: 0.3663 Test MSE Loss: 0.2417
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2564242
	speed: 0.0967s/iter; left time: 921.2543s
Epoch: 11 cost time: 10.412111759185791
Epoch: 11, Steps: 107 Train Loss: 0.2495 (Forecasting Loss:0.2464 + XiCon Loss:3.1000 x Lambda(0.001)), Vali MSE Loss: 0.3653 Test MSE Loss: 0.2419
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2432220
	speed: 0.0917s/iter; left time: 864.1412s
Epoch: 12 cost time: 9.905275344848633
Epoch: 12, Steps: 107 Train Loss: 0.2496 (Forecasting Loss:0.2465 + XiCon Loss:3.1011 x Lambda(0.001)), Vali MSE Loss: 0.3657 Test MSE Loss: 0.2422
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2479912
	speed: 0.0988s/iter; left time: 920.3059s
Epoch: 13 cost time: 10.594818115234375
Epoch: 13, Steps: 107 Train Loss: 0.2494 (Forecasting Loss:0.2463 + XiCon Loss:3.0995 x Lambda(0.001)), Vali MSE Loss: 0.3653 Test MSE Loss: 0.2419
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.16134309768676758, mae:0.32829636335372925, mape:0.660793662071228, mspe:18.277318954467773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7610
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5421518
	speed: 0.0800s/iter; left time: 847.9927s
Epoch: 1 cost time: 8.62039566040039
Epoch: 1, Steps: 107 Train Loss: 0.6232 (Forecasting Loss:0.6201 + XiCon Loss:3.1268 x Lambda(0.001)), Vali MSE Loss: 0.5741 Test MSE Loss: 0.4371
Validation loss decreased (inf --> 0.574081).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2881164
	speed: 0.0901s/iter; left time: 945.9863s
Epoch: 2 cost time: 9.735820531845093
Epoch: 2, Steps: 107 Train Loss: 0.3449 (Forecasting Loss:0.3418 + XiCon Loss:3.1344 x Lambda(0.001)), Vali MSE Loss: 0.3658 Test MSE Loss: 0.2556
Validation loss decreased (0.574081 --> 0.365808).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2646265
	speed: 0.0925s/iter; left time: 960.8215s
Epoch: 3 cost time: 10.040717124938965
Epoch: 3, Steps: 107 Train Loss: 0.2688 (Forecasting Loss:0.2656 + XiCon Loss:3.1221 x Lambda(0.001)), Vali MSE Loss: 0.3835 Test MSE Loss: 0.2749
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2583606
	speed: 0.0992s/iter; left time: 1019.7250s
Epoch: 4 cost time: 10.691867351531982
Epoch: 4, Steps: 107 Train Loss: 0.2569 (Forecasting Loss:0.2538 + XiCon Loss:3.1077 x Lambda(0.001)), Vali MSE Loss: 0.3686 Test MSE Loss: 0.2868
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2455636
	speed: 0.0992s/iter; left time: 1008.8829s
Epoch: 5 cost time: 10.659096717834473
Epoch: 5, Steps: 107 Train Loss: 0.2512 (Forecasting Loss:0.2481 + XiCon Loss:3.1032 x Lambda(0.001)), Vali MSE Loss: 0.3695 Test MSE Loss: 0.2866
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2470591
	speed: 0.0963s/iter; left time: 969.2806s
Epoch: 6 cost time: 10.474843263626099
Epoch: 6, Steps: 107 Train Loss: 0.2487 (Forecasting Loss:0.2456 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2839
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2307803
	speed: 0.0981s/iter; left time: 976.5685s
Epoch: 7 cost time: 10.55087924003601
Epoch: 7, Steps: 107 Train Loss: 0.2473 (Forecasting Loss:0.2442 + XiCon Loss:3.1018 x Lambda(0.001)), Vali MSE Loss: 0.3717 Test MSE Loss: 0.2883
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2451285
	speed: 0.0936s/iter; left time: 922.3728s
Epoch: 8 cost time: 10.052334308624268
Epoch: 8, Steps: 107 Train Loss: 0.2468 (Forecasting Loss:0.2437 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3705 Test MSE Loss: 0.2850
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2499660
	speed: 0.0982s/iter; left time: 957.4045s
Epoch: 9 cost time: 10.614048480987549
Epoch: 9, Steps: 107 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.2917
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2430056
	speed: 0.0980s/iter; left time: 944.5436s
Epoch: 10 cost time: 10.61150598526001
Epoch: 10, Steps: 107 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1014 x Lambda(0.001)), Vali MSE Loss: 0.3680 Test MSE Loss: 0.2920
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2497832
	speed: 0.0967s/iter; left time: 921.2769s
Epoch: 11 cost time: 10.29331111907959
Epoch: 11, Steps: 107 Train Loss: 0.2462 (Forecasting Loss:0.2431 + XiCon Loss:3.1002 x Lambda(0.001)), Vali MSE Loss: 0.3696 Test MSE Loss: 0.2907
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2412027
	speed: 0.0916s/iter; left time: 863.3929s
Epoch: 12 cost time: 9.702497243881226
Epoch: 12, Steps: 107 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1010 x Lambda(0.001)), Vali MSE Loss: 0.3692 Test MSE Loss: 0.2917
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17351892590522766, mae:0.33766865730285645, mape:0.6529759168624878, mspe:17.30824851989746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1651+-0.01009, MAE:0.3304+-0.00963, MAPE:0.6402+-0.04743, MSPE:16.9148+-2.81964, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5822
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 7.077369213104248
Epoch: 1, Steps: 96 Train Loss: 0.9770 (Forecasting Loss:0.9738 + XiCon Loss:3.1670 x Lambda(0.001)), Vali MSE Loss: 0.6588 Test MSE Loss: 0.9127
Validation loss decreased (inf --> 0.658753).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 6.941421747207642
Epoch: 2, Steps: 96 Train Loss: 0.7538 (Forecasting Loss:0.7506 + XiCon Loss:3.1635 x Lambda(0.001)), Vali MSE Loss: 0.6170 Test MSE Loss: 0.2848
Validation loss decreased (0.658753 --> 0.617049).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.143780946731567
Epoch: 3, Steps: 96 Train Loss: 0.5649 (Forecasting Loss:0.5617 + XiCon Loss:3.1745 x Lambda(0.001)), Vali MSE Loss: 0.5611 Test MSE Loss: 0.2559
Validation loss decreased (0.617049 --> 0.561136).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 6.8114142417907715
Epoch: 4, Steps: 96 Train Loss: 0.5304 (Forecasting Loss:0.5272 + XiCon Loss:3.1705 x Lambda(0.001)), Vali MSE Loss: 0.5151 Test MSE Loss: 0.2539
Validation loss decreased (0.561136 --> 0.515093).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 6.5882041454315186
Epoch: 5, Steps: 96 Train Loss: 0.5162 (Forecasting Loss:0.5130 + XiCon Loss:3.1699 x Lambda(0.001)), Vali MSE Loss: 0.5016 Test MSE Loss: 0.2525
Validation loss decreased (0.515093 --> 0.501615).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.350409269332886
Epoch: 6, Steps: 96 Train Loss: 0.5095 (Forecasting Loss:0.5063 + XiCon Loss:3.1706 x Lambda(0.001)), Vali MSE Loss: 0.4891 Test MSE Loss: 0.2558
Validation loss decreased (0.501615 --> 0.489096).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.243671655654907
Epoch: 7, Steps: 96 Train Loss: 0.5061 (Forecasting Loss:0.5029 + XiCon Loss:3.1684 x Lambda(0.001)), Vali MSE Loss: 0.4933 Test MSE Loss: 0.2525
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 8.62174677848816
Epoch: 8, Steps: 96 Train Loss: 0.5036 (Forecasting Loss:0.5004 + XiCon Loss:3.1679 x Lambda(0.001)), Vali MSE Loss: 0.4879 Test MSE Loss: 0.2539
Validation loss decreased (0.489096 --> 0.487878).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.258403301239014
Epoch: 9, Steps: 96 Train Loss: 0.5029 (Forecasting Loss:0.4997 + XiCon Loss:3.1673 x Lambda(0.001)), Vali MSE Loss: 0.4885 Test MSE Loss: 0.2535
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.2715811729431152
Epoch: 10, Steps: 96 Train Loss: 0.5030 (Forecasting Loss:0.4999 + XiCon Loss:3.1678 x Lambda(0.001)), Vali MSE Loss: 0.4883 Test MSE Loss: 0.2535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 6.924026012420654
Epoch: 11, Steps: 96 Train Loss: 0.5028 (Forecasting Loss:0.4996 + XiCon Loss:3.1686 x Lambda(0.001)), Vali MSE Loss: 0.4877 Test MSE Loss: 0.2535
Validation loss decreased (0.487878 --> 0.487713).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 6.8288164138793945
Epoch: 12, Steps: 96 Train Loss: 0.5022 (Forecasting Loss:0.4991 + XiCon Loss:3.1678 x Lambda(0.001)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2536
Validation loss decreased (0.487713 --> 0.487273).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 6.891645669937134
Epoch: 13, Steps: 96 Train Loss: 0.5018 (Forecasting Loss:0.4986 + XiCon Loss:3.1674 x Lambda(0.001)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2536
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 6.9308836460113525
Epoch: 14, Steps: 96 Train Loss: 0.5017 (Forecasting Loss:0.4985 + XiCon Loss:3.1683 x Lambda(0.001)), Vali MSE Loss: 0.4871 Test MSE Loss: 0.2536
Validation loss decreased (0.487273 --> 0.487072).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 6.641700506210327
Epoch: 15, Steps: 96 Train Loss: 0.5017 (Forecasting Loss:0.4986 + XiCon Loss:3.1687 x Lambda(0.001)), Vali MSE Loss: 0.4869 Test MSE Loss: 0.2536
Validation loss decreased (0.487072 --> 0.486889).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 6.682190656661987
Epoch: 16, Steps: 96 Train Loss: 0.5014 (Forecasting Loss:0.4982 + XiCon Loss:3.1683 x Lambda(0.001)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 3.740924119949341
Epoch: 17, Steps: 96 Train Loss: 0.5023 (Forecasting Loss:0.4991 + XiCon Loss:3.1677 x Lambda(0.001)), Vali MSE Loss: 0.4867 Test MSE Loss: 0.2536
Validation loss decreased (0.486889 --> 0.486699).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 3.4980549812316895
Epoch: 18, Steps: 96 Train Loss: 0.5011 (Forecasting Loss:0.4980 + XiCon Loss:3.1690 x Lambda(0.001)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.2536
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 6.894338846206665
Epoch: 19, Steps: 96 Train Loss: 0.5019 (Forecasting Loss:0.4988 + XiCon Loss:3.1672 x Lambda(0.001)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2536
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 6.698509931564331
Epoch: 20, Steps: 96 Train Loss: 0.5014 (Forecasting Loss:0.4983 + XiCon Loss:3.1670 x Lambda(0.001)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2536
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 6.83052659034729
Epoch: 21, Steps: 96 Train Loss: 0.5015 (Forecasting Loss:0.4983 + XiCon Loss:3.1680 x Lambda(0.001)), Vali MSE Loss: 0.4874 Test MSE Loss: 0.2536
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 6.70321249961853
Epoch: 22, Steps: 96 Train Loss: 0.5025 (Forecasting Loss:0.4993 + XiCon Loss:3.1688 x Lambda(0.001)), Vali MSE Loss: 0.4867 Test MSE Loss: 0.2536
Validation loss decreased (0.486699 --> 0.486675).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 6.57072377204895
Epoch: 23, Steps: 96 Train Loss: 0.5019 (Forecasting Loss:0.4988 + XiCon Loss:3.1692 x Lambda(0.001)), Vali MSE Loss: 0.4869 Test MSE Loss: 0.2536
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 5.840660572052002
Epoch: 24, Steps: 96 Train Loss: 0.5025 (Forecasting Loss:0.4994 + XiCon Loss:3.1674 x Lambda(0.001)), Vali MSE Loss: 0.4877 Test MSE Loss: 0.2536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.4356043338775635
Epoch: 25, Steps: 96 Train Loss: 0.5014 (Forecasting Loss:0.4983 + XiCon Loss:3.1688 x Lambda(0.001)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2536
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 3.15165114402771
Epoch: 26, Steps: 96 Train Loss: 0.5012 (Forecasting Loss:0.4981 + XiCon Loss:3.1675 x Lambda(0.001)), Vali MSE Loss: 0.4871 Test MSE Loss: 0.2536
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 6.665871620178223
Epoch: 27, Steps: 96 Train Loss: 0.5009 (Forecasting Loss:0.4977 + XiCon Loss:3.1672 x Lambda(0.001)), Vali MSE Loss: 0.4877 Test MSE Loss: 0.2536
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 6.74750542640686
Epoch: 28, Steps: 96 Train Loss: 0.5024 (Forecasting Loss:0.4993 + XiCon Loss:3.1687 x Lambda(0.001)), Vali MSE Loss: 0.4870 Test MSE Loss: 0.2536
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 6.92836856842041
Epoch: 29, Steps: 96 Train Loss: 0.5018 (Forecasting Loss:0.4986 + XiCon Loss:3.1674 x Lambda(0.001)), Vali MSE Loss: 0.4874 Test MSE Loss: 0.2536
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 6.853607177734375
Epoch: 30, Steps: 96 Train Loss: 0.5009 (Forecasting Loss:0.4978 + XiCon Loss:3.1684 x Lambda(0.001)), Vali MSE Loss: 0.4870 Test MSE Loss: 0.2536
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 7.251189947128296
Epoch: 31, Steps: 96 Train Loss: 0.5022 (Forecasting Loss:0.4990 + XiCon Loss:3.1674 x Lambda(0.001)), Vali MSE Loss: 0.4874 Test MSE Loss: 0.2536
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 6.061048746109009
Epoch: 32, Steps: 96 Train Loss: 0.5014 (Forecasting Loss:0.4982 + XiCon Loss:3.1689 x Lambda(0.001)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.2536
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.17481879889965057, mae:0.33241504430770874, mape:0.6517334580421448, mspe:19.020639419555664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7682
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 3.1205713748931885
Epoch: 1, Steps: 96 Train Loss: 0.9718 (Forecasting Loss:0.9687 + XiCon Loss:3.1704 x Lambda(0.001)), Vali MSE Loss: 0.6797 Test MSE Loss: 0.9316
Validation loss decreased (inf --> 0.679723).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.3672873973846436
Epoch: 2, Steps: 96 Train Loss: 0.8098 (Forecasting Loss:0.8066 + XiCon Loss:3.1708 x Lambda(0.001)), Vali MSE Loss: 0.6298 Test MSE Loss: 0.5763
Validation loss decreased (0.679723 --> 0.629831).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 6.741557836532593
Epoch: 3, Steps: 96 Train Loss: 0.6174 (Forecasting Loss:0.6142 + XiCon Loss:3.1646 x Lambda(0.001)), Vali MSE Loss: 0.4969 Test MSE Loss: 0.2667
Validation loss decreased (0.629831 --> 0.496886).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 6.717768669128418
Epoch: 4, Steps: 96 Train Loss: 0.5203 (Forecasting Loss:0.5172 + XiCon Loss:3.1626 x Lambda(0.001)), Vali MSE Loss: 0.4914 Test MSE Loss: 0.3175
Validation loss decreased (0.496886 --> 0.491380).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 6.901937246322632
Epoch: 5, Steps: 96 Train Loss: 0.4988 (Forecasting Loss:0.4957 + XiCon Loss:3.1573 x Lambda(0.001)), Vali MSE Loss: 0.4930 Test MSE Loss: 0.3231
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 6.784366607666016
Epoch: 6, Steps: 96 Train Loss: 0.4900 (Forecasting Loss:0.4869 + XiCon Loss:3.1572 x Lambda(0.001)), Vali MSE Loss: 0.4849 Test MSE Loss: 0.3405
Validation loss decreased (0.491380 --> 0.484916).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 6.583664894104004
Epoch: 7, Steps: 96 Train Loss: 0.4873 (Forecasting Loss:0.4842 + XiCon Loss:3.1521 x Lambda(0.001)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.3326
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 6.4058122634887695
Epoch: 8, Steps: 96 Train Loss: 0.4839 (Forecasting Loss:0.4807 + XiCon Loss:3.1522 x Lambda(0.001)), Vali MSE Loss: 0.4843 Test MSE Loss: 0.3401
Validation loss decreased (0.484916 --> 0.484284).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.1717846393585205
Epoch: 9, Steps: 96 Train Loss: 0.4820 (Forecasting Loss:0.4788 + XiCon Loss:3.1528 x Lambda(0.001)), Vali MSE Loss: 0.4843 Test MSE Loss: 0.3432
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.262458801269531
Epoch: 10, Steps: 96 Train Loss: 0.4828 (Forecasting Loss:0.4797 + XiCon Loss:3.1530 x Lambda(0.001)), Vali MSE Loss: 0.4848 Test MSE Loss: 0.3361
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 6.8955395221710205
Epoch: 11, Steps: 96 Train Loss: 0.4797 (Forecasting Loss:0.4766 + XiCon Loss:3.1535 x Lambda(0.001)), Vali MSE Loss: 0.4860 Test MSE Loss: 0.3382
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 6.900078058242798
Epoch: 12, Steps: 96 Train Loss: 0.4833 (Forecasting Loss:0.4801 + XiCon Loss:3.1536 x Lambda(0.001)), Vali MSE Loss: 0.4845 Test MSE Loss: 0.3386
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 6.938668727874756
Epoch: 13, Steps: 96 Train Loss: 0.4818 (Forecasting Loss:0.4786 + XiCon Loss:3.1528 x Lambda(0.001)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3391
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 6.702848196029663
Epoch: 14, Steps: 96 Train Loss: 0.4813 (Forecasting Loss:0.4782 + XiCon Loss:3.1524 x Lambda(0.001)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3390
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 6.661877155303955
Epoch: 15, Steps: 96 Train Loss: 0.4820 (Forecasting Loss:0.4788 + XiCon Loss:3.1550 x Lambda(0.001)), Vali MSE Loss: 0.4850 Test MSE Loss: 0.3393
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 6.355039358139038
Epoch: 16, Steps: 96 Train Loss: 0.4812 (Forecasting Loss:0.4781 + XiCon Loss:3.1533 x Lambda(0.001)), Vali MSE Loss: 0.4852 Test MSE Loss: 0.3392
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 3.1488444805145264
Epoch: 17, Steps: 96 Train Loss: 0.4821 (Forecasting Loss:0.4790 + XiCon Loss:3.1536 x Lambda(0.001)), Vali MSE Loss: 0.4845 Test MSE Loss: 0.3393
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 3.7573511600494385
Epoch: 18, Steps: 96 Train Loss: 0.4822 (Forecasting Loss:0.4790 + XiCon Loss:3.1530 x Lambda(0.001)), Vali MSE Loss: 0.4848 Test MSE Loss: 0.3393
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2722722887992859, mae:0.40790000557899475, mape:0.7963256239891052, mspe:29.635976791381836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 6.9157164096832275
Epoch: 1, Steps: 96 Train Loss: 0.9199 (Forecasting Loss:0.9168 + XiCon Loss:3.1597 x Lambda(0.001)), Vali MSE Loss: 0.6296 Test MSE Loss: 0.8200
Validation loss decreased (inf --> 0.629555).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 6.826315402984619
Epoch: 2, Steps: 96 Train Loss: 0.8171 (Forecasting Loss:0.8139 + XiCon Loss:3.1779 x Lambda(0.001)), Vali MSE Loss: 0.6472 Test MSE Loss: 0.6176
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 6.8015296459198
Epoch: 3, Steps: 96 Train Loss: 0.6693 (Forecasting Loss:0.6661 + XiCon Loss:3.1639 x Lambda(0.001)), Vali MSE Loss: 0.5544 Test MSE Loss: 0.5436
Validation loss decreased (0.629555 --> 0.554373).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.240319490432739
Epoch: 4, Steps: 96 Train Loss: 0.4435 (Forecasting Loss:0.4404 + XiCon Loss:3.1380 x Lambda(0.001)), Vali MSE Loss: 0.4953 Test MSE Loss: 0.5842
Validation loss decreased (0.554373 --> 0.495341).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 6.963363885879517
Epoch: 5, Steps: 96 Train Loss: 0.3693 (Forecasting Loss:0.3662 + XiCon Loss:3.1235 x Lambda(0.001)), Vali MSE Loss: 0.4828 Test MSE Loss: 0.6142
Validation loss decreased (0.495341 --> 0.482750).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 6.595253229141235
Epoch: 6, Steps: 96 Train Loss: 0.3474 (Forecasting Loss:0.3443 + XiCon Loss:3.1226 x Lambda(0.001)), Vali MSE Loss: 0.4656 Test MSE Loss: 0.6154
Validation loss decreased (0.482750 --> 0.465606).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.011418342590332
Epoch: 7, Steps: 96 Train Loss: 0.3390 (Forecasting Loss:0.3359 + XiCon Loss:3.1211 x Lambda(0.001)), Vali MSE Loss: 0.4579 Test MSE Loss: 0.5857
Validation loss decreased (0.465606 --> 0.457935).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.664404630661011
Epoch: 8, Steps: 96 Train Loss: 0.3351 (Forecasting Loss:0.3320 + XiCon Loss:3.1188 x Lambda(0.001)), Vali MSE Loss: 0.4605 Test MSE Loss: 0.6121
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.547514915466309
Epoch: 9, Steps: 96 Train Loss: 0.3330 (Forecasting Loss:0.3299 + XiCon Loss:3.1211 x Lambda(0.001)), Vali MSE Loss: 0.4562 Test MSE Loss: 0.6105
Validation loss decreased (0.457935 --> 0.456172).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.1392223834991455
Epoch: 10, Steps: 96 Train Loss: 0.3326 (Forecasting Loss:0.3294 + XiCon Loss:3.1192 x Lambda(0.001)), Vali MSE Loss: 0.4554 Test MSE Loss: 0.6045
Validation loss decreased (0.456172 --> 0.455424).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.111144304275513
Epoch: 11, Steps: 96 Train Loss: 0.3312 (Forecasting Loss:0.3281 + XiCon Loss:3.1178 x Lambda(0.001)), Vali MSE Loss: 0.4569 Test MSE Loss: 0.6053
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 6.679198265075684
Epoch: 12, Steps: 96 Train Loss: 0.3316 (Forecasting Loss:0.3285 + XiCon Loss:3.1203 x Lambda(0.001)), Vali MSE Loss: 0.4558 Test MSE Loss: 0.6056
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.4287095069885254
Epoch: 13, Steps: 96 Train Loss: 0.3308 (Forecasting Loss:0.3277 + XiCon Loss:3.1193 x Lambda(0.001)), Vali MSE Loss: 0.4560 Test MSE Loss: 0.6057
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.43046760559082
Epoch: 14, Steps: 96 Train Loss: 0.3316 (Forecasting Loss:0.3284 + XiCon Loss:3.1163 x Lambda(0.001)), Vali MSE Loss: 0.4554 Test MSE Loss: 0.6055
Validation loss decreased (0.455424 --> 0.455378).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.390162229537964
Epoch: 15, Steps: 96 Train Loss: 0.3318 (Forecasting Loss:0.3287 + XiCon Loss:3.1175 x Lambda(0.001)), Vali MSE Loss: 0.4563 Test MSE Loss: 0.6056
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.018686294555664
Epoch: 16, Steps: 96 Train Loss: 0.3313 (Forecasting Loss:0.3282 + XiCon Loss:3.1188 x Lambda(0.001)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.6056
Validation loss decreased (0.455378 --> 0.455337).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 7.276628732681274
Epoch: 17, Steps: 96 Train Loss: 0.3311 (Forecasting Loss:0.3279 + XiCon Loss:3.1196 x Lambda(0.001)), Vali MSE Loss: 0.4559 Test MSE Loss: 0.6056
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 7.404841899871826
Epoch: 18, Steps: 96 Train Loss: 0.3312 (Forecasting Loss:0.3281 + XiCon Loss:3.1185 x Lambda(0.001)), Vali MSE Loss: 0.4554 Test MSE Loss: 0.6056
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 6.813478946685791
Epoch: 19, Steps: 96 Train Loss: 0.3313 (Forecasting Loss:0.3281 + XiCon Loss:3.1187 x Lambda(0.001)), Vali MSE Loss: 0.4559 Test MSE Loss: 0.6056
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 7.056756258010864
Epoch: 20, Steps: 96 Train Loss: 0.3316 (Forecasting Loss:0.3285 + XiCon Loss:3.1179 x Lambda(0.001)), Vali MSE Loss: 0.4545 Test MSE Loss: 0.6056
Validation loss decreased (0.455337 --> 0.454484).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 7.125746011734009
Epoch: 21, Steps: 96 Train Loss: 0.3310 (Forecasting Loss:0.3278 + XiCon Loss:3.1207 x Lambda(0.001)), Vali MSE Loss: 0.4548 Test MSE Loss: 0.6056
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 7.526520490646362
Epoch: 22, Steps: 96 Train Loss: 0.3315 (Forecasting Loss:0.3284 + XiCon Loss:3.1188 x Lambda(0.001)), Vali MSE Loss: 0.4567 Test MSE Loss: 0.6056
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 7.143101930618286
Epoch: 23, Steps: 96 Train Loss: 0.3309 (Forecasting Loss:0.3278 + XiCon Loss:3.1188 x Lambda(0.001)), Vali MSE Loss: 0.4559 Test MSE Loss: 0.6056
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 7.3324363231658936
Epoch: 24, Steps: 96 Train Loss: 0.3315 (Forecasting Loss:0.3284 + XiCon Loss:3.1181 x Lambda(0.001)), Vali MSE Loss: 0.4548 Test MSE Loss: 0.6056
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 6.977524280548096
Epoch: 25, Steps: 96 Train Loss: 0.3315 (Forecasting Loss:0.3283 + XiCon Loss:3.1194 x Lambda(0.001)), Vali MSE Loss: 0.4557 Test MSE Loss: 0.6056
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 6.701555490493774
Epoch: 26, Steps: 96 Train Loss: 0.3310 (Forecasting Loss:0.3279 + XiCon Loss:3.1197 x Lambda(0.001)), Vali MSE Loss: 0.4551 Test MSE Loss: 0.6056
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 7.245398759841919
Epoch: 27, Steps: 96 Train Loss: 0.3316 (Forecasting Loss:0.3285 + XiCon Loss:3.1179 x Lambda(0.001)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.6056
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 6.949633598327637
Epoch: 28, Steps: 96 Train Loss: 0.3311 (Forecasting Loss:0.3279 + XiCon Loss:3.1180 x Lambda(0.001)), Vali MSE Loss: 0.4541 Test MSE Loss: 0.6056
Validation loss decreased (0.454484 --> 0.454101).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 7.357633352279663
Epoch: 29, Steps: 96 Train Loss: 0.3312 (Forecasting Loss:0.3281 + XiCon Loss:3.1203 x Lambda(0.001)), Vali MSE Loss: 0.4544 Test MSE Loss: 0.6056
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 7.29390811920166
Epoch: 30, Steps: 96 Train Loss: 0.3308 (Forecasting Loss:0.3277 + XiCon Loss:3.1180 x Lambda(0.001)), Vali MSE Loss: 0.4559 Test MSE Loss: 0.6056
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 7.111029386520386
Epoch: 31, Steps: 96 Train Loss: 0.3313 (Forecasting Loss:0.3281 + XiCon Loss:3.1194 x Lambda(0.001)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.6056
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 6.951791048049927
Epoch: 32, Steps: 96 Train Loss: 0.3314 (Forecasting Loss:0.3282 + XiCon Loss:3.1183 x Lambda(0.001)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.6056
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 6.832904577255249
Epoch: 33, Steps: 96 Train Loss: 0.3311 (Forecasting Loss:0.3280 + XiCon Loss:3.1191 x Lambda(0.001)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.6056
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 7.535017967224121
Epoch: 34, Steps: 96 Train Loss: 0.3316 (Forecasting Loss:0.3285 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.4545 Test MSE Loss: 0.6056
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 7.140880584716797
Epoch: 35, Steps: 96 Train Loss: 0.3315 (Forecasting Loss:0.3284 + XiCon Loss:3.1183 x Lambda(0.001)), Vali MSE Loss: 0.4554 Test MSE Loss: 0.6056
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 7.149823904037476
Epoch: 36, Steps: 96 Train Loss: 0.3310 (Forecasting Loss:0.3279 + XiCon Loss:3.1180 x Lambda(0.001)), Vali MSE Loss: 0.4556 Test MSE Loss: 0.6056
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 7.320461273193359
Epoch: 37, Steps: 96 Train Loss: 0.3311 (Forecasting Loss:0.3280 + XiCon Loss:3.1199 x Lambda(0.001)), Vali MSE Loss: 0.4560 Test MSE Loss: 0.6056
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 6.838172197341919
Epoch: 38, Steps: 96 Train Loss: 0.3310 (Forecasting Loss:0.3278 + XiCon Loss:3.1203 x Lambda(0.001)), Vali MSE Loss: 0.4558 Test MSE Loss: 0.6056
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.5814637541770935, mae:0.6296975612640381, mape:0.6713564991950989, mspe:3.841336488723755 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 6.505856990814209
Epoch: 1, Steps: 96 Train Loss: 0.9267 (Forecasting Loss:0.9236 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.6487 Test MSE Loss: 0.8008
Validation loss decreased (inf --> 0.648665).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.000500202178955
Epoch: 2, Steps: 96 Train Loss: 0.7983 (Forecasting Loss:0.7952 + XiCon Loss:3.1514 x Lambda(0.001)), Vali MSE Loss: 0.6437 Test MSE Loss: 0.4585
Validation loss decreased (0.648665 --> 0.643692).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.1674346923828125
Epoch: 3, Steps: 96 Train Loss: 0.5699 (Forecasting Loss:0.5668 + XiCon Loss:3.1718 x Lambda(0.001)), Vali MSE Loss: 0.5609 Test MSE Loss: 0.2785
Validation loss decreased (0.643692 --> 0.560947).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.244098663330078
Epoch: 4, Steps: 96 Train Loss: 0.5074 (Forecasting Loss:0.5042 + XiCon Loss:3.1656 x Lambda(0.001)), Vali MSE Loss: 0.5453 Test MSE Loss: 0.2852
Validation loss decreased (0.560947 --> 0.545252).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.436935663223267
Epoch: 5, Steps: 96 Train Loss: 0.4877 (Forecasting Loss:0.4845 + XiCon Loss:3.1641 x Lambda(0.001)), Vali MSE Loss: 0.5594 Test MSE Loss: 0.2829
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.4256415367126465
Epoch: 6, Steps: 96 Train Loss: 0.4802 (Forecasting Loss:0.4771 + XiCon Loss:3.1633 x Lambda(0.001)), Vali MSE Loss: 0.5612 Test MSE Loss: 0.2827
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.238025665283203
Epoch: 7, Steps: 96 Train Loss: 0.4749 (Forecasting Loss:0.4717 + XiCon Loss:3.1647 x Lambda(0.001)), Vali MSE Loss: 0.5480 Test MSE Loss: 0.2879
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.297721862792969
Epoch: 8, Steps: 96 Train Loss: 0.4728 (Forecasting Loss:0.4697 + XiCon Loss:3.1629 x Lambda(0.001)), Vali MSE Loss: 0.5493 Test MSE Loss: 0.2879
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.1400041580200195
Epoch: 9, Steps: 96 Train Loss: 0.4722 (Forecasting Loss:0.4690 + XiCon Loss:3.1625 x Lambda(0.001)), Vali MSE Loss: 0.5456 Test MSE Loss: 0.2899
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.3676557540893555
Epoch: 10, Steps: 96 Train Loss: 0.4725 (Forecasting Loss:0.4694 + XiCon Loss:3.1636 x Lambda(0.001)), Vali MSE Loss: 0.5447 Test MSE Loss: 0.2906
Validation loss decreased (0.545252 --> 0.544701).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.041217803955078
Epoch: 11, Steps: 96 Train Loss: 0.4733 (Forecasting Loss:0.4702 + XiCon Loss:3.1621 x Lambda(0.001)), Vali MSE Loss: 0.5459 Test MSE Loss: 0.2900
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 6.882457494735718
Epoch: 12, Steps: 96 Train Loss: 0.4720 (Forecasting Loss:0.4689 + XiCon Loss:3.1621 x Lambda(0.001)), Vali MSE Loss: 0.5463 Test MSE Loss: 0.2898
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 6.832835912704468
Epoch: 13, Steps: 96 Train Loss: 0.4715 (Forecasting Loss:0.4684 + XiCon Loss:3.1629 x Lambda(0.001)), Vali MSE Loss: 0.5453 Test MSE Loss: 0.2897
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.221119165420532
Epoch: 14, Steps: 96 Train Loss: 0.4703 (Forecasting Loss:0.4672 + XiCon Loss:3.1638 x Lambda(0.001)), Vali MSE Loss: 0.5454 Test MSE Loss: 0.2898
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.389082670211792
Epoch: 15, Steps: 96 Train Loss: 0.4742 (Forecasting Loss:0.4710 + XiCon Loss:3.1631 x Lambda(0.001)), Vali MSE Loss: 0.5470 Test MSE Loss: 0.2898
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.3160786628723145
Epoch: 16, Steps: 96 Train Loss: 0.4713 (Forecasting Loss:0.4681 + XiCon Loss:3.1641 x Lambda(0.001)), Vali MSE Loss: 0.5472 Test MSE Loss: 0.2898
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 7.552408933639526
Epoch: 17, Steps: 96 Train Loss: 0.4716 (Forecasting Loss:0.4684 + XiCon Loss:3.1645 x Lambda(0.001)), Vali MSE Loss: 0.5460 Test MSE Loss: 0.2898
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 7.327497243881226
Epoch: 18, Steps: 96 Train Loss: 0.4718 (Forecasting Loss:0.4686 + XiCon Loss:3.1637 x Lambda(0.001)), Vali MSE Loss: 0.5470 Test MSE Loss: 0.2898
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 6.884239435195923
Epoch: 19, Steps: 96 Train Loss: 0.4710 (Forecasting Loss:0.4679 + XiCon Loss:3.1637 x Lambda(0.001)), Vali MSE Loss: 0.5461 Test MSE Loss: 0.2898
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 6.727559804916382
Epoch: 20, Steps: 96 Train Loss: 0.4712 (Forecasting Loss:0.4680 + XiCon Loss:3.1642 x Lambda(0.001)), Vali MSE Loss: 0.5471 Test MSE Loss: 0.2898
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.21435150504112244, mae:0.366824209690094, mape:0.6892977356910706, mspe:21.415611267089844 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7648
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 7.485118627548218
Epoch: 1, Steps: 96 Train Loss: 0.9053 (Forecasting Loss:0.9021 + XiCon Loss:3.1393 x Lambda(0.001)), Vali MSE Loss: 0.6037 Test MSE Loss: 0.7181
Validation loss decreased (inf --> 0.603704).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.528642416000366
Epoch: 2, Steps: 96 Train Loss: 0.7395 (Forecasting Loss:0.7363 + XiCon Loss:3.1568 x Lambda(0.001)), Vali MSE Loss: 0.5579 Test MSE Loss: 0.3182
Validation loss decreased (0.603704 --> 0.557924).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.238925218582153
Epoch: 3, Steps: 96 Train Loss: 0.5106 (Forecasting Loss:0.5074 + XiCon Loss:3.1748 x Lambda(0.001)), Vali MSE Loss: 0.5374 Test MSE Loss: 0.3406
Validation loss decreased (0.557924 --> 0.537408).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.681950569152832
Epoch: 4, Steps: 96 Train Loss: 0.4653 (Forecasting Loss:0.4622 + XiCon Loss:3.1644 x Lambda(0.001)), Vali MSE Loss: 0.5289 Test MSE Loss: 0.3131
Validation loss decreased (0.537408 --> 0.528917).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 6.518478631973267
Epoch: 5, Steps: 96 Train Loss: 0.4498 (Forecasting Loss:0.4466 + XiCon Loss:3.1564 x Lambda(0.001)), Vali MSE Loss: 0.5254 Test MSE Loss: 0.3160
Validation loss decreased (0.528917 --> 0.525377).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 6.786745309829712
Epoch: 6, Steps: 96 Train Loss: 0.4448 (Forecasting Loss:0.4416 + XiCon Loss:3.1539 x Lambda(0.001)), Vali MSE Loss: 0.5149 Test MSE Loss: 0.3067
Validation loss decreased (0.525377 --> 0.514948).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 6.944650173187256
Epoch: 7, Steps: 96 Train Loss: 0.4419 (Forecasting Loss:0.4387 + XiCon Loss:3.1539 x Lambda(0.001)), Vali MSE Loss: 0.5190 Test MSE Loss: 0.2998
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.242842674255371
Epoch: 8, Steps: 96 Train Loss: 0.4397 (Forecasting Loss:0.4365 + XiCon Loss:3.1564 x Lambda(0.001)), Vali MSE Loss: 0.5152 Test MSE Loss: 0.3030
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.036550045013428
Epoch: 9, Steps: 96 Train Loss: 0.4407 (Forecasting Loss:0.4376 + XiCon Loss:3.1535 x Lambda(0.001)), Vali MSE Loss: 0.5157 Test MSE Loss: 0.3032
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.477011442184448
Epoch: 10, Steps: 96 Train Loss: 0.4409 (Forecasting Loss:0.4377 + XiCon Loss:3.1537 x Lambda(0.001)), Vali MSE Loss: 0.5168 Test MSE Loss: 0.3010
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.306143045425415
Epoch: 11, Steps: 96 Train Loss: 0.4379 (Forecasting Loss:0.4348 + XiCon Loss:3.1528 x Lambda(0.001)), Vali MSE Loss: 0.5156 Test MSE Loss: 0.3023
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.077122688293457
Epoch: 12, Steps: 96 Train Loss: 0.4391 (Forecasting Loss:0.4359 + XiCon Loss:3.1553 x Lambda(0.001)), Vali MSE Loss: 0.5155 Test MSE Loss: 0.3022
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 6.8192901611328125
Epoch: 13, Steps: 96 Train Loss: 0.4398 (Forecasting Loss:0.4366 + XiCon Loss:3.1537 x Lambda(0.001)), Vali MSE Loss: 0.5150 Test MSE Loss: 0.3023
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.3069007396698
Epoch: 14, Steps: 96 Train Loss: 0.4382 (Forecasting Loss:0.4351 + XiCon Loss:3.1543 x Lambda(0.001)), Vali MSE Loss: 0.5155 Test MSE Loss: 0.3022
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 7.4465203285217285
Epoch: 15, Steps: 96 Train Loss: 0.4374 (Forecasting Loss:0.4342 + XiCon Loss:3.1529 x Lambda(0.001)), Vali MSE Loss: 0.5154 Test MSE Loss: 0.3023
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 7.416666269302368
Epoch: 16, Steps: 96 Train Loss: 0.4392 (Forecasting Loss:0.4361 + XiCon Loss:3.1547 x Lambda(0.001)), Vali MSE Loss: 0.5159 Test MSE Loss: 0.3023
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.23327288031578064, mae:0.3801974952220917, mape:0.7239511013031006, mspe:24.187915802001953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2952+-0.20340, MAE:0.4234+-0.14711, MAPE:0.7065+-0.07052, MSPE:19.6203+-12.00207, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.4367
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.1864110
	speed: 0.0892s/iter; left time: 2355.2048s
	iters: 200, epoch: 1 | loss: 0.2125571
	speed: 0.0789s/iter; left time: 2074.5273s
Epoch: 1 cost time: 22.092872619628906
Epoch: 1, Steps: 265 Train Loss: 0.2111 (Forecasting Loss:0.2077 + XiCon Loss:3.3765 x Lambda(0.001)), Vali MSE Loss: 0.1494 Test MSE Loss: 0.1001
Validation loss decreased (inf --> 0.149432).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1978491
	speed: 0.0837s/iter; left time: 2188.0118s
	iters: 200, epoch: 2 | loss: 0.1704213
	speed: 0.0733s/iter; left time: 1909.6432s
Epoch: 2 cost time: 20.586217880249023
Epoch: 2, Steps: 265 Train Loss: 0.1882 (Forecasting Loss:0.1849 + XiCon Loss:3.3597 x Lambda(0.001)), Vali MSE Loss: 0.1582 Test MSE Loss: 0.1109
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1614369
	speed: 0.0846s/iter; left time: 2188.2946s
	iters: 200, epoch: 3 | loss: 0.1282054
	speed: 0.0827s/iter; left time: 2130.4835s
Epoch: 3 cost time: 21.994490146636963
Epoch: 3, Steps: 265 Train Loss: 0.1463 (Forecasting Loss:0.1429 + XiCon Loss:3.3437 x Lambda(0.001)), Vali MSE Loss: 0.1803 Test MSE Loss: 0.1212
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1203213
	speed: 0.0845s/iter; left time: 2163.2131s
	iters: 200, epoch: 4 | loss: 0.1229701
	speed: 0.0788s/iter; left time: 2008.7964s
Epoch: 4 cost time: 21.2969708442688
Epoch: 4, Steps: 265 Train Loss: 0.1166 (Forecasting Loss:0.1132 + XiCon Loss:3.3322 x Lambda(0.001)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1233
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1057916
	speed: 0.0824s/iter; left time: 2088.9086s
	iters: 200, epoch: 5 | loss: 0.1033909
	speed: 0.0810s/iter; left time: 2044.1544s
Epoch: 5 cost time: 21.523610591888428
Epoch: 5, Steps: 265 Train Loss: 0.1071 (Forecasting Loss:0.1038 + XiCon Loss:3.3293 x Lambda(0.001)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1276
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.0942524
	speed: 0.0830s/iter; left time: 2082.1022s
	iters: 200, epoch: 6 | loss: 0.1063703
	speed: 0.0825s/iter; left time: 2060.8441s
Epoch: 6 cost time: 21.600287199020386
Epoch: 6, Steps: 265 Train Loss: 0.1029 (Forecasting Loss:0.0996 + XiCon Loss:3.3256 x Lambda(0.001)), Vali MSE Loss: 0.1905 Test MSE Loss: 0.1294
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1011466
	speed: 0.0812s/iter; left time: 2014.2264s
	iters: 200, epoch: 7 | loss: 0.1060975
	speed: 0.0851s/iter; left time: 2104.0825s
Epoch: 7 cost time: 22.248819828033447
Epoch: 7, Steps: 265 Train Loss: 0.1009 (Forecasting Loss:0.0976 + XiCon Loss:3.3269 x Lambda(0.001)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1284
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1010573
	speed: 0.0868s/iter; left time: 2129.4869s
	iters: 200, epoch: 8 | loss: 0.1017087
	speed: 0.0811s/iter; left time: 1983.7532s
Epoch: 8 cost time: 22.00312089920044
Epoch: 8, Steps: 265 Train Loss: 0.0998 (Forecasting Loss:0.0965 + XiCon Loss:3.3275 x Lambda(0.001)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1294
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.0996340
	speed: 0.0849s/iter; left time: 2060.9614s
	iters: 200, epoch: 9 | loss: 0.1013668
	speed: 0.0827s/iter; left time: 2000.7416s
Epoch: 9 cost time: 22.041860818862915
Epoch: 9, Steps: 265 Train Loss: 0.0995 (Forecasting Loss:0.0962 + XiCon Loss:3.3271 x Lambda(0.001)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.1296
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1036952
	speed: 0.0830s/iter; left time: 1992.1569s
	iters: 200, epoch: 10 | loss: 0.0947827
	speed: 0.0806s/iter; left time: 1927.8383s
Epoch: 10 cost time: 21.856383800506592
Epoch: 10, Steps: 265 Train Loss: 0.0993 (Forecasting Loss:0.0959 + XiCon Loss:3.3273 x Lambda(0.001)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1293
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1033749
	speed: 0.0800s/iter; left time: 1899.0941s
	iters: 200, epoch: 11 | loss: 0.0963114
	speed: 0.0815s/iter; left time: 1928.2330s
Epoch: 11 cost time: 21.46007776260376
Epoch: 11, Steps: 265 Train Loss: 0.0991 (Forecasting Loss:0.0958 + XiCon Loss:3.3283 x Lambda(0.001)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1290
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04243702068924904, mae:0.1577908992767334, mape:0.12690074741840363, mspe:0.03032563626766205 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.4537
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2850508
	speed: 0.0773s/iter; left time: 2040.1617s
	iters: 200, epoch: 1 | loss: 0.1819294
	speed: 0.0769s/iter; left time: 2022.5978s
Epoch: 1 cost time: 20.511006593704224
Epoch: 1, Steps: 265 Train Loss: 0.2105 (Forecasting Loss:0.2071 + XiCon Loss:3.3692 x Lambda(0.001)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.0964
Validation loss decreased (inf --> 0.148090).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2038836
	speed: 0.0852s/iter; left time: 2226.1441s
	iters: 200, epoch: 2 | loss: 0.1652206
	speed: 0.0842s/iter; left time: 2193.4532s
Epoch: 2 cost time: 22.547435760498047
Epoch: 2, Steps: 265 Train Loss: 0.1950 (Forecasting Loss:0.1916 + XiCon Loss:3.3987 x Lambda(0.001)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.1038
Validation loss decreased (0.148090 --> 0.147544).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1680395
	speed: 0.0835s/iter; left time: 2159.4633s
	iters: 200, epoch: 3 | loss: 0.1416289
	speed: 0.0807s/iter; left time: 2078.5585s
Epoch: 3 cost time: 21.820321321487427
Epoch: 3, Steps: 265 Train Loss: 0.1577 (Forecasting Loss:0.1544 + XiCon Loss:3.3482 x Lambda(0.001)), Vali MSE Loss: 0.1539 Test MSE Loss: 0.1239
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1302107
	speed: 0.0866s/iter; left time: 2218.6018s
	iters: 200, epoch: 4 | loss: 0.1172881
	speed: 0.0842s/iter; left time: 2148.2843s
Epoch: 4 cost time: 22.54212784767151
Epoch: 4, Steps: 265 Train Loss: 0.1270 (Forecasting Loss:0.1237 + XiCon Loss:3.3309 x Lambda(0.001)), Vali MSE Loss: 0.1592 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1132395
	speed: 0.0809s/iter; left time: 2049.8595s
	iters: 200, epoch: 5 | loss: 0.1229098
	speed: 0.0766s/iter; left time: 1934.7033s
Epoch: 5 cost time: 21.279337644577026
Epoch: 5, Steps: 265 Train Loss: 0.1156 (Forecasting Loss:0.1122 + XiCon Loss:3.3267 x Lambda(0.001)), Vali MSE Loss: 0.1601 Test MSE Loss: 0.1242
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1160038
	speed: 0.0889s/iter; left time: 2229.8875s
	iters: 200, epoch: 6 | loss: 0.1231535
	speed: 0.0851s/iter; left time: 2124.8232s
Epoch: 6 cost time: 23.246776580810547
Epoch: 6, Steps: 265 Train Loss: 0.1111 (Forecasting Loss:0.1078 + XiCon Loss:3.3260 x Lambda(0.001)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1289
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1103170
	speed: 0.0819s/iter; left time: 2031.4656s
	iters: 200, epoch: 7 | loss: 0.1013363
	speed: 0.0798s/iter; left time: 1972.9487s
Epoch: 7 cost time: 21.48911476135254
Epoch: 7, Steps: 265 Train Loss: 0.1091 (Forecasting Loss:0.1057 + XiCon Loss:3.3242 x Lambda(0.001)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1283
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1020265
	speed: 0.0869s/iter; left time: 2133.9304s
	iters: 200, epoch: 8 | loss: 0.1066271
	speed: 0.0862s/iter; left time: 2107.3775s
Epoch: 8 cost time: 22.889105796813965
Epoch: 8, Steps: 265 Train Loss: 0.1081 (Forecasting Loss:0.1047 + XiCon Loss:3.3235 x Lambda(0.001)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1283
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1108703
	speed: 0.0862s/iter; left time: 2092.5208s
	iters: 200, epoch: 9 | loss: 0.1111590
	speed: 0.0773s/iter; left time: 1868.6175s
Epoch: 9 cost time: 20.528076171875
Epoch: 9, Steps: 265 Train Loss: 0.1078 (Forecasting Loss:0.1044 + XiCon Loss:3.3241 x Lambda(0.001)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1285
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1070526
	speed: 0.1099s/iter; left time: 2638.4803s
	iters: 200, epoch: 10 | loss: 0.1058243
	speed: 0.0691s/iter; left time: 1652.8089s
Epoch: 10 cost time: 23.664840936660767
Epoch: 10, Steps: 265 Train Loss: 0.1074 (Forecasting Loss:0.1041 + XiCon Loss:3.3234 x Lambda(0.001)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1289
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1007787
	speed: 0.0864s/iter; left time: 2051.7917s
	iters: 200, epoch: 11 | loss: 0.1116006
	speed: 0.0829s/iter; left time: 1959.8428s
Epoch: 11 cost time: 22.521896362304688
Epoch: 11, Steps: 265 Train Loss: 0.1072 (Forecasting Loss:0.1039 + XiCon Loss:3.3243 x Lambda(0.001)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1286
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1023140
	speed: 0.0867s/iter; left time: 2035.7599s
	iters: 200, epoch: 12 | loss: 0.1113590
	speed: 0.0764s/iter; left time: 1787.1900s
Epoch: 12 cost time: 19.513681173324585
Epoch: 12, Steps: 265 Train Loss: 0.1073 (Forecasting Loss:0.1039 + XiCon Loss:3.3256 x Lambda(0.001)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1288
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04532524570822716, mae:0.16233468055725098, mape:0.13199518620967865, mspe:0.034603167325258255 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.7720
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.1953751
	speed: 0.0867s/iter; left time: 2287.9570s
	iters: 200, epoch: 1 | loss: 0.1943469
	speed: 0.0818s/iter; left time: 2150.4354s
Epoch: 1 cost time: 21.624627828598022
Epoch: 1, Steps: 265 Train Loss: 0.2107 (Forecasting Loss:0.2074 + XiCon Loss:3.3753 x Lambda(0.001)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0969
Validation loss decreased (inf --> 0.146461).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2321745
	speed: 0.0589s/iter; left time: 1539.5209s
	iters: 200, epoch: 2 | loss: 0.2022583
	speed: 0.0701s/iter; left time: 1825.3334s
Epoch: 2 cost time: 18.351737022399902
Epoch: 2, Steps: 265 Train Loss: 0.1932 (Forecasting Loss:0.1898 + XiCon Loss:3.4162 x Lambda(0.001)), Vali MSE Loss: 0.1597 Test MSE Loss: 0.1136
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1664633
	speed: 0.0882s/iter; left time: 2281.6123s
	iters: 200, epoch: 3 | loss: 0.1830564
	speed: 0.0848s/iter; left time: 2185.2139s
Epoch: 3 cost time: 22.80401587486267
Epoch: 3, Steps: 265 Train Loss: 0.1642 (Forecasting Loss:0.1607 + XiCon Loss:3.4032 x Lambda(0.001)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1458351
	speed: 0.0759s/iter; left time: 1942.5458s
	iters: 200, epoch: 4 | loss: 0.1274751
	speed: 0.0597s/iter; left time: 1521.8802s
Epoch: 4 cost time: 16.772170782089233
Epoch: 4, Steps: 265 Train Loss: 0.1366 (Forecasting Loss:0.1332 + XiCon Loss:3.3893 x Lambda(0.001)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1354
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1262254
	speed: 0.0891s/iter; left time: 2257.3145s
	iters: 200, epoch: 5 | loss: 0.1272984
	speed: 0.0846s/iter; left time: 2135.9618s
Epoch: 5 cost time: 22.806435346603394
Epoch: 5, Steps: 265 Train Loss: 0.1227 (Forecasting Loss:0.1193 + XiCon Loss:3.3865 x Lambda(0.001)), Vali MSE Loss: 0.1757 Test MSE Loss: 0.1366
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1226986
	speed: 0.0886s/iter; left time: 2220.5028s
	iters: 200, epoch: 6 | loss: 0.1076256
	speed: 0.0795s/iter; left time: 1984.5188s
Epoch: 6 cost time: 21.769139528274536
Epoch: 6, Steps: 265 Train Loss: 0.1163 (Forecasting Loss:0.1129 + XiCon Loss:3.3847 x Lambda(0.001)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1424
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1118277
	speed: 0.0670s/iter; left time: 1663.1832s
	iters: 200, epoch: 7 | loss: 0.1177071
	speed: 0.0838s/iter; left time: 2070.8808s
Epoch: 7 cost time: 20.56874704360962
Epoch: 7, Steps: 265 Train Loss: 0.1135 (Forecasting Loss:0.1101 + XiCon Loss:3.3828 x Lambda(0.001)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1409
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1062462
	speed: 0.0858s/iter; left time: 2105.8195s
	iters: 200, epoch: 8 | loss: 0.1119561
	speed: 0.0837s/iter; left time: 2045.4008s
Epoch: 8 cost time: 22.36200499534607
Epoch: 8, Steps: 265 Train Loss: 0.1123 (Forecasting Loss:0.1089 + XiCon Loss:3.3815 x Lambda(0.001)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.1423
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1058777
	speed: 0.0801s/iter; left time: 1945.0637s
	iters: 200, epoch: 9 | loss: 0.1154151
	speed: 0.0858s/iter; left time: 2075.0489s
Epoch: 9 cost time: 22.277280569076538
Epoch: 9, Steps: 265 Train Loss: 0.1117 (Forecasting Loss:0.1083 + XiCon Loss:3.3807 x Lambda(0.001)), Vali MSE Loss: 0.1831 Test MSE Loss: 0.1412
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1120500
	speed: 0.0878s/iter; left time: 2108.4591s
	iters: 200, epoch: 10 | loss: 0.1076381
	speed: 0.0849s/iter; left time: 2031.5509s
Epoch: 10 cost time: 22.788919925689697
Epoch: 10, Steps: 265 Train Loss: 0.1113 (Forecasting Loss:0.1079 + XiCon Loss:3.3825 x Lambda(0.001)), Vali MSE Loss: 0.1828 Test MSE Loss: 0.1417
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1152004
	speed: 0.0788s/iter; left time: 1872.2137s
	iters: 200, epoch: 11 | loss: 0.1042642
	speed: 0.0864s/iter; left time: 2044.3953s
Epoch: 11 cost time: 21.989995002746582
Epoch: 11, Steps: 265 Train Loss: 0.1110 (Forecasting Loss:0.1076 + XiCon Loss:3.3813 x Lambda(0.001)), Vali MSE Loss: 0.1828 Test MSE Loss: 0.1420
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04056130722165108, mae:0.15316693484783173, mape:0.12166575342416763, mspe:0.027369121089577675 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.9361
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2413412
	speed: 0.0735s/iter; left time: 1940.2436s
	iters: 200, epoch: 1 | loss: 0.1926572
	speed: 0.0479s/iter; left time: 1259.7697s
Epoch: 1 cost time: 17.38124179840088
Epoch: 1, Steps: 265 Train Loss: 0.2129 (Forecasting Loss:0.2096 + XiCon Loss:3.3762 x Lambda(0.001)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.0975
Validation loss decreased (inf --> 0.148580).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1806850
	speed: 0.0856s/iter; left time: 2237.0022s
	iters: 200, epoch: 2 | loss: 0.1850866
	speed: 0.0845s/iter; left time: 2200.8945s
Epoch: 2 cost time: 22.737879753112793
Epoch: 2, Steps: 265 Train Loss: 0.1935 (Forecasting Loss:0.1901 + XiCon Loss:3.4128 x Lambda(0.001)), Vali MSE Loss: 0.1523 Test MSE Loss: 0.1066
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1632586
	speed: 0.0837s/iter; left time: 2164.6136s
	iters: 200, epoch: 3 | loss: 0.1381144
	speed: 0.0780s/iter; left time: 2009.4280s
Epoch: 3 cost time: 19.47131609916687
Epoch: 3, Steps: 265 Train Loss: 0.1603 (Forecasting Loss:0.1569 + XiCon Loss:3.3934 x Lambda(0.001)), Vali MSE Loss: 0.1625 Test MSE Loss: 0.1342
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1398447
	speed: 0.0842s/iter; left time: 2156.7496s
	iters: 200, epoch: 4 | loss: 0.1301451
	speed: 0.0864s/iter; left time: 2203.9632s
Epoch: 4 cost time: 22.852150917053223
Epoch: 4, Steps: 265 Train Loss: 0.1272 (Forecasting Loss:0.1239 + XiCon Loss:3.3776 x Lambda(0.001)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1329
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1145228
	speed: 0.0894s/iter; left time: 2265.7505s
	iters: 200, epoch: 5 | loss: 0.1146050
	speed: 0.0826s/iter; left time: 2084.3971s
Epoch: 5 cost time: 22.09937024116516
Epoch: 5, Steps: 265 Train Loss: 0.1150 (Forecasting Loss:0.1116 + XiCon Loss:3.3731 x Lambda(0.001)), Vali MSE Loss: 0.1721 Test MSE Loss: 0.1418
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1139179
	speed: 0.0900s/iter; left time: 2256.8154s
	iters: 200, epoch: 6 | loss: 0.1079170
	speed: 0.0832s/iter; left time: 2079.1870s
Epoch: 6 cost time: 23.021031618118286
Epoch: 6, Steps: 265 Train Loss: 0.1105 (Forecasting Loss:0.1072 + XiCon Loss:3.3694 x Lambda(0.001)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1403
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1112341
	speed: 0.0892s/iter; left time: 2213.5265s
	iters: 200, epoch: 7 | loss: 0.1146437
	speed: 0.0846s/iter; left time: 2089.9372s
Epoch: 7 cost time: 22.444775819778442
Epoch: 7, Steps: 265 Train Loss: 0.1082 (Forecasting Loss:0.1049 + XiCon Loss:3.3680 x Lambda(0.001)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1403
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1009396
	speed: 0.0850s/iter; left time: 2085.9241s
	iters: 200, epoch: 8 | loss: 0.1120649
	speed: 0.0841s/iter; left time: 2056.5635s
Epoch: 8 cost time: 22.436569452285767
Epoch: 8, Steps: 265 Train Loss: 0.1073 (Forecasting Loss:0.1040 + XiCon Loss:3.3688 x Lambda(0.001)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1410
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1068961
	speed: 0.0881s/iter; left time: 2138.4017s
	iters: 200, epoch: 9 | loss: 0.1128422
	speed: 0.0853s/iter; left time: 2063.7686s
Epoch: 9 cost time: 22.500126838684082
Epoch: 9, Steps: 265 Train Loss: 0.1066 (Forecasting Loss:0.1033 + XiCon Loss:3.3688 x Lambda(0.001)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1415
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1076943
	speed: 0.0845s/iter; left time: 2029.3078s
	iters: 200, epoch: 10 | loss: 0.0984196
	speed: 0.0878s/iter; left time: 2098.9126s
Epoch: 10 cost time: 22.877912998199463
Epoch: 10, Steps: 265 Train Loss: 0.1065 (Forecasting Loss:0.1032 + XiCon Loss:3.3672 x Lambda(0.001)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1420
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1037604
	speed: 0.0870s/iter; left time: 2066.2833s
	iters: 200, epoch: 11 | loss: 0.1045562
	speed: 0.0834s/iter; left time: 1973.3813s
Epoch: 11 cost time: 21.935827255249023
Epoch: 11, Steps: 265 Train Loss: 0.1063 (Forecasting Loss:0.1030 + XiCon Loss:3.3682 x Lambda(0.001)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1419
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04083140194416046, mae:0.15415845811367035, mape:0.12249650061130524, mspe:0.02755458652973175 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 24.1347
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2195231
	speed: 0.0856s/iter; left time: 2261.0143s
	iters: 200, epoch: 1 | loss: 0.1809042
	speed: 0.0838s/iter; left time: 2204.0989s
Epoch: 1 cost time: 21.917623281478882
Epoch: 1, Steps: 265 Train Loss: 0.2100 (Forecasting Loss:0.2066 + XiCon Loss:3.3782 x Lambda(0.001)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0977
Validation loss decreased (inf --> 0.145694).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1951483
	speed: 0.0827s/iter; left time: 2162.2801s
	iters: 200, epoch: 2 | loss: 0.1925096
	speed: 0.0828s/iter; left time: 2156.2422s
Epoch: 2 cost time: 22.103299140930176
Epoch: 2, Steps: 265 Train Loss: 0.1913 (Forecasting Loss:0.1879 + XiCon Loss:3.3899 x Lambda(0.001)), Vali MSE Loss: 0.1533 Test MSE Loss: 0.1122
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1534414
	speed: 0.0862s/iter; left time: 2230.3029s
	iters: 200, epoch: 3 | loss: 0.1439964
	speed: 0.0846s/iter; left time: 2179.3162s
Epoch: 3 cost time: 22.445778846740723
Epoch: 3, Steps: 265 Train Loss: 0.1543 (Forecasting Loss:0.1509 + XiCon Loss:3.3658 x Lambda(0.001)), Vali MSE Loss: 0.1547 Test MSE Loss: 0.1310
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1349717
	speed: 0.0860s/iter; left time: 2201.6922s
	iters: 200, epoch: 4 | loss: 0.1211592
	speed: 0.0871s/iter; left time: 2221.7265s
Epoch: 4 cost time: 23.0775785446167
Epoch: 4, Steps: 265 Train Loss: 0.1236 (Forecasting Loss:0.1203 + XiCon Loss:3.3556 x Lambda(0.001)), Vali MSE Loss: 0.1561 Test MSE Loss: 0.1393
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1081211
	speed: 0.0873s/iter; left time: 2212.8204s
	iters: 200, epoch: 5 | loss: 0.1170712
	speed: 0.0854s/iter; left time: 2156.7235s
Epoch: 5 cost time: 22.498811721801758
Epoch: 5, Steps: 265 Train Loss: 0.1109 (Forecasting Loss:0.1076 + XiCon Loss:3.3522 x Lambda(0.001)), Vali MSE Loss: 0.1531 Test MSE Loss: 0.1438
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1080908
	speed: 0.0800s/iter; left time: 2005.0254s
	iters: 200, epoch: 6 | loss: 0.1077957
	speed: 0.0858s/iter; left time: 2143.7701s
Epoch: 6 cost time: 22.017449855804443
Epoch: 6, Steps: 265 Train Loss: 0.1060 (Forecasting Loss:0.1026 + XiCon Loss:3.3503 x Lambda(0.001)), Vali MSE Loss: 0.1550 Test MSE Loss: 0.1437
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1013724
	speed: 0.0880s/iter; left time: 2182.7494s
	iters: 200, epoch: 7 | loss: 0.0973729
	speed: 0.0833s/iter; left time: 2057.7075s
Epoch: 7 cost time: 22.39938735961914
Epoch: 7, Steps: 265 Train Loss: 0.1037 (Forecasting Loss:0.1003 + XiCon Loss:3.3486 x Lambda(0.001)), Vali MSE Loss: 0.1574 Test MSE Loss: 0.1463
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.0914984
	speed: 0.0865s/iter; left time: 2123.9107s
	iters: 200, epoch: 8 | loss: 0.1014124
	speed: 0.0838s/iter; left time: 2048.2349s
Epoch: 8 cost time: 22.701972723007202
Epoch: 8, Steps: 265 Train Loss: 0.1025 (Forecasting Loss:0.0992 + XiCon Loss:3.3486 x Lambda(0.001)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.1454
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1014270
	speed: 0.0856s/iter; left time: 2079.5018s
	iters: 200, epoch: 9 | loss: 0.0936604
	speed: 0.0860s/iter; left time: 2080.6242s
Epoch: 9 cost time: 22.577794551849365
Epoch: 9, Steps: 265 Train Loss: 0.1020 (Forecasting Loss:0.0987 + XiCon Loss:3.3485 x Lambda(0.001)), Vali MSE Loss: 0.1566 Test MSE Loss: 0.1456
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.0933575
	speed: 0.0853s/iter; left time: 2047.5072s
	iters: 200, epoch: 10 | loss: 0.0993170
	speed: 0.0850s/iter; left time: 2033.4787s
Epoch: 10 cost time: 22.52748155593872
Epoch: 10, Steps: 265 Train Loss: 0.1019 (Forecasting Loss:0.0985 + XiCon Loss:3.3481 x Lambda(0.001)), Vali MSE Loss: 0.1571 Test MSE Loss: 0.1461
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1046113
	speed: 0.0902s/iter; left time: 2141.3152s
	iters: 200, epoch: 11 | loss: 0.1043145
	speed: 0.0849s/iter; left time: 2007.5114s
Epoch: 11 cost time: 22.866400003433228
Epoch: 11, Steps: 265 Train Loss: 0.1017 (Forecasting Loss:0.0984 + XiCon Loss:3.3492 x Lambda(0.001)), Vali MSE Loss: 0.1571 Test MSE Loss: 0.1463
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.040797170251607895, mae:0.15464697778224945, mape:0.12282019108533859, mspe:0.02742904983460903 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0420+-0.00249, MAE:0.1564+-0.00463, MAPE:0.1252+-0.00536, MSPE:0.0295+-0.00389, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.6501
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3158616
	speed: 0.1492s/iter; left time: 3805.5382s
	iters: 200, epoch: 1 | loss: 0.2823071
	speed: 0.1434s/iter; left time: 3642.2965s
Epoch: 1 cost time: 37.417314529418945
Epoch: 1, Steps: 256 Train Loss: 0.3018 (Forecasting Loss:0.2985 + XiCon Loss:3.3754 x Lambda(0.001)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1607
Validation loss decreased (inf --> 0.213213).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2559558
	speed: 0.1897s/iter; left time: 4787.8934s
	iters: 200, epoch: 2 | loss: 0.2238191
	speed: 0.1949s/iter; left time: 4900.3148s
Epoch: 2 cost time: 48.472484827041626
Epoch: 2, Steps: 256 Train Loss: 0.2497 (Forecasting Loss:0.2463 + XiCon Loss:3.3576 x Lambda(0.001)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1710
Validation loss decreased (0.213213 --> 0.212375).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2053519
	speed: 0.1916s/iter; left time: 4787.1958s
	iters: 200, epoch: 3 | loss: 0.1975984
	speed: 0.1918s/iter; left time: 4774.6102s
Epoch: 3 cost time: 49.06827425956726
Epoch: 3, Steps: 256 Train Loss: 0.1985 (Forecasting Loss:0.1951 + XiCon Loss:3.3428 x Lambda(0.001)), Vali MSE Loss: 0.2268 Test MSE Loss: 0.1743
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1883898
	speed: 0.1918s/iter; left time: 4742.6780s
	iters: 200, epoch: 4 | loss: 0.1741897
	speed: 0.1959s/iter; left time: 4824.7943s
Epoch: 4 cost time: 49.76214122772217
Epoch: 4, Steps: 256 Train Loss: 0.1783 (Forecasting Loss:0.1750 + XiCon Loss:3.3323 x Lambda(0.001)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.1820
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1621813
	speed: 0.1861s/iter; left time: 4553.9945s
	iters: 200, epoch: 5 | loss: 0.1645868
	speed: 0.1918s/iter; left time: 4675.5906s
Epoch: 5 cost time: 48.929627418518066
Epoch: 5, Steps: 256 Train Loss: 0.1675 (Forecasting Loss:0.1642 + XiCon Loss:3.3276 x Lambda(0.001)), Vali MSE Loss: 0.2442 Test MSE Loss: 0.1922
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1715317
	speed: 0.1875s/iter; left time: 4540.3559s
	iters: 200, epoch: 6 | loss: 0.1615676
	speed: 0.1920s/iter; left time: 4631.1327s
Epoch: 6 cost time: 48.75031805038452
Epoch: 6, Steps: 256 Train Loss: 0.1622 (Forecasting Loss:0.1589 + XiCon Loss:3.3266 x Lambda(0.001)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.1926
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1630978
	speed: 0.1824s/iter; left time: 4371.2699s
	iters: 200, epoch: 7 | loss: 0.1554151
	speed: 0.1910s/iter; left time: 4558.2685s
Epoch: 7 cost time: 47.79586100578308
Epoch: 7, Steps: 256 Train Loss: 0.1595 (Forecasting Loss:0.1562 + XiCon Loss:3.3268 x Lambda(0.001)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1940
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1682333
	speed: 0.1842s/iter; left time: 4366.5658s
	iters: 200, epoch: 8 | loss: 0.1596249
	speed: 0.1860s/iter; left time: 4390.3023s
Epoch: 8 cost time: 47.92747449874878
Epoch: 8, Steps: 256 Train Loss: 0.1581 (Forecasting Loss:0.1548 + XiCon Loss:3.3264 x Lambda(0.001)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1946
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1609538
	speed: 0.1845s/iter; left time: 4327.4691s
	iters: 200, epoch: 9 | loss: 0.1482886
	speed: 0.1901s/iter; left time: 4440.2524s
Epoch: 9 cost time: 48.24226212501526
Epoch: 9, Steps: 256 Train Loss: 0.1574 (Forecasting Loss:0.1540 + XiCon Loss:3.3252 x Lambda(0.001)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1942
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1565558
	speed: 0.1863s/iter; left time: 4320.8047s
	iters: 200, epoch: 10 | loss: 0.1602487
	speed: 0.1898s/iter; left time: 4383.4638s
Epoch: 10 cost time: 48.43182611465454
Epoch: 10, Steps: 256 Train Loss: 0.1571 (Forecasting Loss:0.1537 + XiCon Loss:3.3255 x Lambda(0.001)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1944
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1593661
	speed: 0.1852s/iter; left time: 4248.1813s
	iters: 200, epoch: 11 | loss: 0.1520953
	speed: 0.1662s/iter; left time: 3796.2448s
Epoch: 11 cost time: 45.443233489990234
Epoch: 11, Steps: 256 Train Loss: 0.1569 (Forecasting Loss:0.1536 + XiCon Loss:3.3245 x Lambda(0.001)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1944
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1517430
	speed: 0.1911s/iter; left time: 4334.8723s
	iters: 200, epoch: 12 | loss: 0.1588805
	speed: 0.1911s/iter; left time: 4315.0962s
Epoch: 12 cost time: 49.321057081222534
Epoch: 12, Steps: 256 Train Loss: 0.1568 (Forecasting Loss:0.1534 + XiCon Loss:3.3263 x Lambda(0.001)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09641888737678528, mae:0.24552498757839203, mape:0.18940459191799164, mspe:0.06159718707203865 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.5133
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3100326
	speed: 0.1570s/iter; left time: 4003.4964s
	iters: 200, epoch: 1 | loss: 0.2738643
	speed: 0.1517s/iter; left time: 3853.2792s
Epoch: 1 cost time: 39.43861246109009
Epoch: 1, Steps: 256 Train Loss: 0.3031 (Forecasting Loss:0.2997 + XiCon Loss:3.3773 x Lambda(0.001)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1577
Validation loss decreased (inf --> 0.208642).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2378089
	speed: 0.1478s/iter; left time: 3731.1040s
	iters: 200, epoch: 2 | loss: 0.2089304
	speed: 0.1904s/iter; left time: 4788.5864s
Epoch: 2 cost time: 44.907880783081055
Epoch: 2, Steps: 256 Train Loss: 0.2407 (Forecasting Loss:0.2373 + XiCon Loss:3.3434 x Lambda(0.001)), Vali MSE Loss: 0.2214 Test MSE Loss: 0.1884
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1850459
	speed: 0.1560s/iter; left time: 3897.9341s
	iters: 200, epoch: 3 | loss: 0.1801658
	speed: 0.1895s/iter; left time: 4716.2614s
Epoch: 3 cost time: 45.677146911621094
Epoch: 3, Steps: 256 Train Loss: 0.1874 (Forecasting Loss:0.1841 + XiCon Loss:3.3359 x Lambda(0.001)), Vali MSE Loss: 0.2374 Test MSE Loss: 0.2187
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1656104
	speed: 0.1906s/iter; left time: 4714.8058s
	iters: 200, epoch: 4 | loss: 0.1498168
	speed: 0.1476s/iter; left time: 3635.4165s
Epoch: 4 cost time: 44.73778581619263
Epoch: 4, Steps: 256 Train Loss: 0.1642 (Forecasting Loss:0.1608 + XiCon Loss:3.3303 x Lambda(0.001)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2267
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1554544
	speed: 0.1933s/iter; left time: 4732.1455s
	iters: 200, epoch: 5 | loss: 0.1514372
	speed: 0.1844s/iter; left time: 4494.1671s
Epoch: 5 cost time: 48.506890058517456
Epoch: 5, Steps: 256 Train Loss: 0.1533 (Forecasting Loss:0.1499 + XiCon Loss:3.3294 x Lambda(0.001)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.2257
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1514626
	speed: 0.1939s/iter; left time: 4695.9493s
	iters: 200, epoch: 6 | loss: 0.1424380
	speed: 0.1846s/iter; left time: 4453.7216s
Epoch: 6 cost time: 48.504263401031494
Epoch: 6, Steps: 256 Train Loss: 0.1484 (Forecasting Loss:0.1451 + XiCon Loss:3.3308 x Lambda(0.001)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.2223
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1425125
	speed: 0.1962s/iter; left time: 4702.9645s
	iters: 200, epoch: 7 | loss: 0.1425625
	speed: 0.1881s/iter; left time: 4488.6824s
Epoch: 7 cost time: 49.11133909225464
Epoch: 7, Steps: 256 Train Loss: 0.1460 (Forecasting Loss:0.1427 + XiCon Loss:3.3323 x Lambda(0.001)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.2239
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1463288
	speed: 0.1904s/iter; left time: 4513.0809s
	iters: 200, epoch: 8 | loss: 0.1449585
	speed: 0.1887s/iter; left time: 4454.3098s
Epoch: 8 cost time: 47.999123096466064
Epoch: 8, Steps: 256 Train Loss: 0.1448 (Forecasting Loss:0.1415 + XiCon Loss:3.3310 x Lambda(0.001)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.2227
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1474376
	speed: 0.1951s/iter; left time: 4575.0963s
	iters: 200, epoch: 9 | loss: 0.1420462
	speed: 0.1985s/iter; left time: 4635.7771s
Epoch: 9 cost time: 49.68168616294861
Epoch: 9, Steps: 256 Train Loss: 0.1442 (Forecasting Loss:0.1409 + XiCon Loss:3.3309 x Lambda(0.001)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.2248
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1521377
	speed: 0.1990s/iter; left time: 4616.8036s
	iters: 200, epoch: 10 | loss: 0.1444528
	speed: 0.1941s/iter; left time: 4482.7697s
Epoch: 10 cost time: 49.73883938789368
Epoch: 10, Steps: 256 Train Loss: 0.1439 (Forecasting Loss:0.1406 + XiCon Loss:3.3301 x Lambda(0.001)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.2243
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1505490
	speed: 0.1972s/iter; left time: 4523.9135s
	iters: 200, epoch: 11 | loss: 0.1405632
	speed: 0.1983s/iter; left time: 4529.9598s
Epoch: 11 cost time: 50.30217909812927
Epoch: 11, Steps: 256 Train Loss: 0.1437 (Forecasting Loss:0.1404 + XiCon Loss:3.3314 x Lambda(0.001)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.2250
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08606920391321182, mae:0.22937585413455963, mape:0.1697433739900589, mspe:0.04594852030277252 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.9211
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.2779358
	speed: 0.1509s/iter; left time: 3846.8606s
	iters: 200, epoch: 1 | loss: 0.2943087
	speed: 0.1436s/iter; left time: 3647.7678s
Epoch: 1 cost time: 37.89093899726868
Epoch: 1, Steps: 256 Train Loss: 0.2947 (Forecasting Loss:0.2914 + XiCon Loss:3.3790 x Lambda(0.001)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1551
Validation loss decreased (inf --> 0.203625).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2713708
	speed: 0.1582s/iter; left time: 3994.2984s
	iters: 200, epoch: 2 | loss: 0.2450100
	speed: 0.1789s/iter; left time: 4497.4980s
Epoch: 2 cost time: 44.239784479141235
Epoch: 2, Steps: 256 Train Loss: 0.2713 (Forecasting Loss:0.2680 + XiCon Loss:3.3437 x Lambda(0.001)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1729
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2069958
	speed: 0.1936s/iter; left time: 4838.1661s
	iters: 200, epoch: 3 | loss: 0.2068134
	speed: 0.1874s/iter; left time: 4664.7052s
Epoch: 3 cost time: 48.46676707267761
Epoch: 3, Steps: 256 Train Loss: 0.2069 (Forecasting Loss:0.2036 + XiCon Loss:3.3018 x Lambda(0.001)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1870
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1798671
	speed: 0.1889s/iter; left time: 4671.9209s
	iters: 200, epoch: 4 | loss: 0.1886641
	speed: 0.1872s/iter; left time: 4611.1117s
Epoch: 4 cost time: 48.231802225112915
Epoch: 4, Steps: 256 Train Loss: 0.1848 (Forecasting Loss:0.1815 + XiCon Loss:3.2937 x Lambda(0.001)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1954
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1744449
	speed: 0.1911s/iter; left time: 4677.0299s
	iters: 200, epoch: 5 | loss: 0.1668323
	speed: 0.1863s/iter; left time: 4540.4372s
Epoch: 5 cost time: 48.39176154136658
Epoch: 5, Steps: 256 Train Loss: 0.1735 (Forecasting Loss:0.1702 + XiCon Loss:3.2903 x Lambda(0.001)), Vali MSE Loss: 0.2277 Test MSE Loss: 0.2013
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1661058
	speed: 0.1891s/iter; left time: 4581.1119s
	iters: 200, epoch: 6 | loss: 0.1689204
	speed: 0.1875s/iter; left time: 4523.7773s
Epoch: 6 cost time: 48.6406614780426
Epoch: 6, Steps: 256 Train Loss: 0.1677 (Forecasting Loss:0.1644 + XiCon Loss:3.2889 x Lambda(0.001)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.2017
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1681409
	speed: 0.1882s/iter; left time: 4509.6352s
	iters: 200, epoch: 7 | loss: 0.1665579
	speed: 0.1895s/iter; left time: 4522.1360s
Epoch: 7 cost time: 48.60617113113403
Epoch: 7, Steps: 256 Train Loss: 0.1646 (Forecasting Loss:0.1614 + XiCon Loss:3.2893 x Lambda(0.001)), Vali MSE Loss: 0.2247 Test MSE Loss: 0.2017
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1630608
	speed: 0.1897s/iter; left time: 4497.8420s
	iters: 200, epoch: 8 | loss: 0.1590005
	speed: 0.1836s/iter; left time: 4333.9708s
Epoch: 8 cost time: 48.24036622047424
Epoch: 8, Steps: 256 Train Loss: 0.1630 (Forecasting Loss:0.1597 + XiCon Loss:3.2888 x Lambda(0.001)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.2021
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1644026
	speed: 0.1878s/iter; left time: 4404.5252s
	iters: 200, epoch: 9 | loss: 0.1580277
	speed: 0.1962s/iter; left time: 4581.9934s
Epoch: 9 cost time: 49.47926330566406
Epoch: 9, Steps: 256 Train Loss: 0.1623 (Forecasting Loss:0.1590 + XiCon Loss:3.2885 x Lambda(0.001)), Vali MSE Loss: 0.2268 Test MSE Loss: 0.2031
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1628109
	speed: 0.1876s/iter; left time: 4351.7382s
	iters: 200, epoch: 10 | loss: 0.1636084
	speed: 0.1932s/iter; left time: 4462.2968s
Epoch: 10 cost time: 49.11282920837402
Epoch: 10, Steps: 256 Train Loss: 0.1618 (Forecasting Loss:0.1585 + XiCon Loss:3.2891 x Lambda(0.001)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.2032
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1608166
	speed: 0.1862s/iter; left time: 4271.6185s
	iters: 200, epoch: 11 | loss: 0.1575852
	speed: 0.1896s/iter; left time: 4331.1864s
Epoch: 11 cost time: 48.59778547286987
Epoch: 11, Steps: 256 Train Loss: 0.1615 (Forecasting Loss:0.1582 + XiCon Loss:3.2892 x Lambda(0.001)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.2032
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08527286350727081, mae:0.22491754591464996, mape:0.16587482392787933, mspe:0.04474181681871414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 24.4432
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.2888262
	speed: 0.1488s/iter; left time: 3794.3095s
	iters: 200, epoch: 1 | loss: 0.2885656
	speed: 0.1475s/iter; left time: 3746.1745s
Epoch: 1 cost time: 37.96530032157898
Epoch: 1, Steps: 256 Train Loss: 0.3017 (Forecasting Loss:0.2984 + XiCon Loss:3.3660 x Lambda(0.001)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1600
Validation loss decreased (inf --> 0.210251).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2445920
	speed: 0.1895s/iter; left time: 4783.8830s
	iters: 200, epoch: 2 | loss: 0.2216134
	speed: 0.1957s/iter; left time: 4921.2379s
Epoch: 2 cost time: 49.42317247390747
Epoch: 2, Steps: 256 Train Loss: 0.2470 (Forecasting Loss:0.2436 + XiCon Loss:3.3573 x Lambda(0.001)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1788
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1863394
	speed: 0.1579s/iter; left time: 3945.2241s
	iters: 200, epoch: 3 | loss: 0.1816933
	speed: 0.1735s/iter; left time: 4317.3383s
Epoch: 3 cost time: 40.77823066711426
Epoch: 3, Steps: 256 Train Loss: 0.1906 (Forecasting Loss:0.1872 + XiCon Loss:3.3269 x Lambda(0.001)), Vali MSE Loss: 0.2413 Test MSE Loss: 0.1796
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1664066
	speed: 0.1689s/iter; left time: 4177.2618s
	iters: 200, epoch: 4 | loss: 0.1657030
	speed: 0.1641s/iter; left time: 4042.2040s
Epoch: 4 cost time: 42.48178148269653
Epoch: 4, Steps: 256 Train Loss: 0.1663 (Forecasting Loss:0.1629 + XiCon Loss:3.3168 x Lambda(0.001)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1896
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1614662
	speed: 0.1552s/iter; left time: 3798.7582s
	iters: 200, epoch: 5 | loss: 0.1523771
	speed: 0.1546s/iter; left time: 3767.9396s
Epoch: 5 cost time: 39.438013792037964
Epoch: 5, Steps: 256 Train Loss: 0.1546 (Forecasting Loss:0.1513 + XiCon Loss:3.3134 x Lambda(0.001)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1947
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1413243
	speed: 0.1552s/iter; left time: 3758.0310s
	iters: 200, epoch: 6 | loss: 0.1490066
	speed: 0.1594s/iter; left time: 3843.9022s
Epoch: 6 cost time: 40.15746450424194
Epoch: 6, Steps: 256 Train Loss: 0.1491 (Forecasting Loss:0.1458 + XiCon Loss:3.3102 x Lambda(0.001)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1940
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1495179
	speed: 0.1525s/iter; left time: 3654.7705s
	iters: 200, epoch: 7 | loss: 0.1432501
	speed: 0.1556s/iter; left time: 3714.0369s
Epoch: 7 cost time: 39.296401500701904
Epoch: 7, Steps: 256 Train Loss: 0.1464 (Forecasting Loss:0.1431 + XiCon Loss:3.3108 x Lambda(0.001)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.1958
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1493645
	speed: 0.1520s/iter; left time: 3602.6023s
	iters: 200, epoch: 8 | loss: 0.1461288
	speed: 0.1527s/iter; left time: 3606.0117s
Epoch: 8 cost time: 39.466336727142334
Epoch: 8, Steps: 256 Train Loss: 0.1451 (Forecasting Loss:0.1418 + XiCon Loss:3.3092 x Lambda(0.001)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1954
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1397045
	speed: 0.1541s/iter; left time: 3613.3821s
	iters: 200, epoch: 9 | loss: 0.1473039
	speed: 0.1579s/iter; left time: 3688.3263s
Epoch: 9 cost time: 40.035237550735474
Epoch: 9, Steps: 256 Train Loss: 0.1445 (Forecasting Loss:0.1412 + XiCon Loss:3.3098 x Lambda(0.001)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1948
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1464003
	speed: 0.1507s/iter; left time: 3496.5054s
	iters: 200, epoch: 10 | loss: 0.1405695
	speed: 0.1551s/iter; left time: 3581.8348s
Epoch: 10 cost time: 39.50013041496277
Epoch: 10, Steps: 256 Train Loss: 0.1443 (Forecasting Loss:0.1410 + XiCon Loss:3.3087 x Lambda(0.001)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.1953
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1463309
	speed: 0.1520s/iter; left time: 3487.1038s
	iters: 200, epoch: 11 | loss: 0.1530013
	speed: 0.1568s/iter; left time: 3580.4268s
Epoch: 11 cost time: 39.544182777404785
Epoch: 11, Steps: 256 Train Loss: 0.1441 (Forecasting Loss:0.1408 + XiCon Loss:3.3089 x Lambda(0.001)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1953
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08813795447349548, mae:0.23185399174690247, mape:0.17088793218135834, mspe:0.04643445461988449 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 21.2885
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.2988841
	speed: 0.1037s/iter; left time: 2645.4918s
	iters: 200, epoch: 1 | loss: 0.2903349
	speed: 0.1043s/iter; left time: 2648.2902s
Epoch: 1 cost time: 26.89506959915161
Epoch: 1, Steps: 256 Train Loss: 0.2995 (Forecasting Loss:0.2961 + XiCon Loss:3.3738 x Lambda(0.001)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1552
Validation loss decreased (inf --> 0.205865).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2604128
	speed: 0.1342s/iter; left time: 3388.1532s
	iters: 200, epoch: 2 | loss: 0.2419506
	speed: 0.1280s/iter; left time: 3217.9214s
Epoch: 2 cost time: 33.75674796104431
Epoch: 2, Steps: 256 Train Loss: 0.2624 (Forecasting Loss:0.2590 + XiCon Loss:3.4500 x Lambda(0.001)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1726
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2103842
	speed: 0.1345s/iter; left time: 3362.1207s
	iters: 200, epoch: 3 | loss: 0.2076520
	speed: 0.1341s/iter; left time: 3337.4742s
Epoch: 3 cost time: 34.53475904464722
Epoch: 3, Steps: 256 Train Loss: 0.2143 (Forecasting Loss:0.2109 + XiCon Loss:3.4424 x Lambda(0.001)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1852
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1921510
	speed: 0.1339s/iter; left time: 3310.6564s
	iters: 200, epoch: 4 | loss: 0.2031571
	speed: 0.1298s/iter; left time: 3198.5105s
Epoch: 4 cost time: 33.96179437637329
Epoch: 4, Steps: 256 Train Loss: 0.1967 (Forecasting Loss:0.1933 + XiCon Loss:3.4366 x Lambda(0.001)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1913
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1868433
	speed: 0.1357s/iter; left time: 3322.3572s
	iters: 200, epoch: 5 | loss: 0.1865402
	speed: 0.1532s/iter; left time: 3735.1586s
Epoch: 5 cost time: 34.57168126106262
Epoch: 5, Steps: 256 Train Loss: 0.1868 (Forecasting Loss:0.1833 + XiCon Loss:3.4333 x Lambda(0.001)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1938
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1749507
	speed: 0.1324s/iter; left time: 3207.3791s
	iters: 200, epoch: 6 | loss: 0.1813857
	speed: 0.1302s/iter; left time: 3140.2783s
Epoch: 6 cost time: 33.74658274650574
Epoch: 6, Steps: 256 Train Loss: 0.1815 (Forecasting Loss:0.1781 + XiCon Loss:3.4294 x Lambda(0.001)), Vali MSE Loss: 0.2257 Test MSE Loss: 0.1970
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1854567
	speed: 0.1316s/iter; left time: 3153.8258s
	iters: 200, epoch: 7 | loss: 0.1763380
	speed: 0.1295s/iter; left time: 3090.8495s
Epoch: 7 cost time: 33.630701780319214
Epoch: 7, Steps: 256 Train Loss: 0.1786 (Forecasting Loss:0.1752 + XiCon Loss:3.4302 x Lambda(0.001)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1981
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1758990
	speed: 0.1326s/iter; left time: 3144.2353s
	iters: 200, epoch: 8 | loss: 0.1776254
	speed: 0.1302s/iter; left time: 3073.7226s
Epoch: 8 cost time: 33.643895626068115
Epoch: 8, Steps: 256 Train Loss: 0.1773 (Forecasting Loss:0.1739 + XiCon Loss:3.4282 x Lambda(0.001)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.1987
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1675508
	speed: 0.1414s/iter; left time: 3316.7028s
	iters: 200, epoch: 9 | loss: 0.1794842
	speed: 0.1342s/iter; left time: 3134.3989s
Epoch: 9 cost time: 35.065191984176636
Epoch: 9, Steps: 256 Train Loss: 0.1766 (Forecasting Loss:0.1731 + XiCon Loss:3.4291 x Lambda(0.001)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1976
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1787520
	speed: 0.1344s/iter; left time: 3118.1109s
	iters: 200, epoch: 10 | loss: 0.1801815
	speed: 0.1364s/iter; left time: 3150.6470s
Epoch: 10 cost time: 34.6006965637207
Epoch: 10, Steps: 256 Train Loss: 0.1761 (Forecasting Loss:0.1727 + XiCon Loss:3.4287 x Lambda(0.001)), Vali MSE Loss: 0.2248 Test MSE Loss: 0.1985
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1723487
	speed: 0.1345s/iter; left time: 3086.5599s
	iters: 200, epoch: 11 | loss: 0.1772734
	speed: 0.1323s/iter; left time: 3022.9747s
Epoch: 11 cost time: 34.2759006023407
Epoch: 11, Steps: 256 Train Loss: 0.1761 (Forecasting Loss:0.1727 + XiCon Loss:3.4287 x Lambda(0.001)), Vali MSE Loss: 0.2246 Test MSE Loss: 0.1990
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08386393636465073, mae:0.2264510691165924, mape:0.16913464665412903, mspe:0.046506576240062714 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0880+-0.00618, MAE:0.2316+-0.01020, MAPE:0.1730+-0.01161, MSPE:0.0490+-0.00876, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7604
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3433736
	speed: 0.1412s/iter; left time: 3432.0618s
	iters: 200, epoch: 1 | loss: 0.3182358
	speed: 0.1588s/iter; left time: 3842.9964s
Epoch: 1 cost time: 38.46806859970093
Epoch: 1, Steps: 244 Train Loss: 0.3526 (Forecasting Loss:0.3492 + XiCon Loss:3.4147 x Lambda(0.001)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1564
Validation loss decreased (inf --> 0.228275).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3453682
	speed: 0.2026s/iter; left time: 4873.2136s
	iters: 200, epoch: 2 | loss: 0.2853937
	speed: 0.1932s/iter; left time: 4627.7050s
Epoch: 2 cost time: 48.02890396118164
Epoch: 2, Steps: 244 Train Loss: 0.3115 (Forecasting Loss:0.3081 + XiCon Loss:3.3636 x Lambda(0.001)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.1539
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2663877
	speed: 0.1954s/iter; left time: 4653.4812s
	iters: 200, epoch: 3 | loss: 0.2603494
	speed: 0.1912s/iter; left time: 4534.3989s
Epoch: 3 cost time: 47.255069732666016
Epoch: 3, Steps: 244 Train Loss: 0.2739 (Forecasting Loss:0.2706 + XiCon Loss:3.2952 x Lambda(0.001)), Vali MSE Loss: 0.2361 Test MSE Loss: 0.1531
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2619843
	speed: 0.1950s/iter; left time: 4596.2117s
	iters: 200, epoch: 4 | loss: 0.2683343
	speed: 0.1915s/iter; left time: 4494.6743s
Epoch: 4 cost time: 47.103419065475464
Epoch: 4, Steps: 244 Train Loss: 0.2629 (Forecasting Loss:0.2596 + XiCon Loss:3.2839 x Lambda(0.001)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.1559
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2761336
	speed: 0.1929s/iter; left time: 4498.9787s
	iters: 200, epoch: 5 | loss: 0.2532869
	speed: 0.1930s/iter; left time: 4482.7581s
Epoch: 5 cost time: 47.271207094192505
Epoch: 5, Steps: 244 Train Loss: 0.2564 (Forecasting Loss:0.2532 + XiCon Loss:3.2844 x Lambda(0.001)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1537
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2489602
	speed: 0.1934s/iter; left time: 4463.8912s
	iters: 200, epoch: 6 | loss: 0.2558850
	speed: 0.1917s/iter; left time: 4406.2474s
Epoch: 6 cost time: 47.57694363594055
Epoch: 6, Steps: 244 Train Loss: 0.2528 (Forecasting Loss:0.2495 + XiCon Loss:3.2817 x Lambda(0.001)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.1553
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2329026
	speed: 0.1735s/iter; left time: 3961.8418s
	iters: 200, epoch: 7 | loss: 0.2460600
	speed: 0.1916s/iter; left time: 4355.8857s
Epoch: 7 cost time: 44.919721603393555
Epoch: 7, Steps: 244 Train Loss: 0.2507 (Forecasting Loss:0.2475 + XiCon Loss:3.2790 x Lambda(0.001)), Vali MSE Loss: 0.2840 Test MSE Loss: 0.1576
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2592318
	speed: 0.1949s/iter; left time: 4404.0884s
	iters: 200, epoch: 8 | loss: 0.2456828
	speed: 0.1877s/iter; left time: 4222.5783s
Epoch: 8 cost time: 46.89155626296997
Epoch: 8, Steps: 244 Train Loss: 0.2497 (Forecasting Loss:0.2464 + XiCon Loss:3.2779 x Lambda(0.001)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.1557
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2393967
	speed: 0.1902s/iter; left time: 4251.5511s
	iters: 200, epoch: 9 | loss: 0.2446581
	speed: 0.1906s/iter; left time: 4240.5964s
Epoch: 9 cost time: 46.36557936668396
Epoch: 9, Steps: 244 Train Loss: 0.2492 (Forecasting Loss:0.2459 + XiCon Loss:3.2766 x Lambda(0.001)), Vali MSE Loss: 0.2770 Test MSE Loss: 0.1563
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2477481
	speed: 0.1907s/iter; left time: 4215.1832s
	iters: 200, epoch: 10 | loss: 0.2345797
	speed: 0.1918s/iter; left time: 4220.5673s
Epoch: 10 cost time: 46.62917375564575
Epoch: 10, Steps: 244 Train Loss: 0.2489 (Forecasting Loss:0.2457 + XiCon Loss:3.2769 x Lambda(0.001)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1565
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2356324
	speed: 0.1956s/iter; left time: 4275.9692s
	iters: 200, epoch: 11 | loss: 0.2391731
	speed: 0.1924s/iter; left time: 4185.9605s
Epoch: 11 cost time: 47.13553833961487
Epoch: 11, Steps: 244 Train Loss: 0.2488 (Forecasting Loss:0.2455 + XiCon Loss:3.2769 x Lambda(0.001)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.1567
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.0847615897655487, mae:0.2281169444322586, mape:0.16171003878116608, mspe:0.039972059428691864 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.8427
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3344040
	speed: 0.1283s/iter; left time: 3118.1192s
	iters: 200, epoch: 1 | loss: 0.3395254
	speed: 0.1231s/iter; left time: 2979.9755s
Epoch: 1 cost time: 30.91457986831665
Epoch: 1, Steps: 244 Train Loss: 0.3420 (Forecasting Loss:0.3386 + XiCon Loss:3.4025 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1588
Validation loss decreased (inf --> 0.221855).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2983895
	speed: 0.1869s/iter; left time: 4495.8058s
	iters: 200, epoch: 2 | loss: 0.2766748
	speed: 0.2015s/iter; left time: 4828.2063s
Epoch: 2 cost time: 47.80596613883972
Epoch: 2, Steps: 244 Train Loss: 0.3139 (Forecasting Loss:0.3105 + XiCon Loss:3.3537 x Lambda(0.001)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2612908
	speed: 0.1951s/iter; left time: 4646.3649s
	iters: 200, epoch: 3 | loss: 0.2544293
	speed: 0.1947s/iter; left time: 4616.0549s
Epoch: 3 cost time: 47.95722222328186
Epoch: 3, Steps: 244 Train Loss: 0.2624 (Forecasting Loss:0.2591 + XiCon Loss:3.3213 x Lambda(0.001)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2362225
	speed: 0.2033s/iter; left time: 4790.4937s
	iters: 200, epoch: 4 | loss: 0.2358608
	speed: 0.1909s/iter; left time: 4479.4025s
Epoch: 4 cost time: 48.23133182525635
Epoch: 4, Steps: 244 Train Loss: 0.2452 (Forecasting Loss:0.2419 + XiCon Loss:3.3166 x Lambda(0.001)), Vali MSE Loss: 0.2766 Test MSE Loss: 0.1612
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2514955
	speed: 0.1936s/iter; left time: 4515.9621s
	iters: 200, epoch: 5 | loss: 0.2424320
	speed: 0.1982s/iter; left time: 4603.0304s
Epoch: 5 cost time: 47.92257070541382
Epoch: 5, Steps: 244 Train Loss: 0.2378 (Forecasting Loss:0.2345 + XiCon Loss:3.3132 x Lambda(0.001)), Vali MSE Loss: 0.2783 Test MSE Loss: 0.1641
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2312694
	speed: 0.1923s/iter; left time: 4439.3747s
	iters: 200, epoch: 6 | loss: 0.2395646
	speed: 0.1965s/iter; left time: 4516.1229s
Epoch: 6 cost time: 47.435113191604614
Epoch: 6, Steps: 244 Train Loss: 0.2340 (Forecasting Loss:0.2307 + XiCon Loss:3.3097 x Lambda(0.001)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.1656
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2377255
	speed: 0.1998s/iter; left time: 4561.9461s
	iters: 200, epoch: 7 | loss: 0.2294191
	speed: 0.1944s/iter; left time: 4420.7219s
Epoch: 7 cost time: 48.38048815727234
Epoch: 7, Steps: 244 Train Loss: 0.2319 (Forecasting Loss:0.2286 + XiCon Loss:3.3074 x Lambda(0.001)), Vali MSE Loss: 0.2714 Test MSE Loss: 0.1647
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2311658
	speed: 0.1666s/iter; left time: 3763.8449s
	iters: 200, epoch: 8 | loss: 0.2220615
	speed: 0.1935s/iter; left time: 4352.6667s
Epoch: 8 cost time: 44.71846413612366
Epoch: 8, Steps: 244 Train Loss: 0.2307 (Forecasting Loss:0.2274 + XiCon Loss:3.3062 x Lambda(0.001)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.1654
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2298673
	speed: 0.2007s/iter; left time: 4484.6630s
	iters: 200, epoch: 9 | loss: 0.2351426
	speed: 0.2006s/iter; left time: 4462.9565s
Epoch: 9 cost time: 48.829461097717285
Epoch: 9, Steps: 244 Train Loss: 0.2304 (Forecasting Loss:0.2271 + XiCon Loss:3.3059 x Lambda(0.001)), Vali MSE Loss: 0.2712 Test MSE Loss: 0.1660
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2416486
	speed: 0.2001s/iter; left time: 4422.3498s
	iters: 200, epoch: 10 | loss: 0.2319110
	speed: 0.1988s/iter; left time: 4374.1092s
Epoch: 10 cost time: 48.77171301841736
Epoch: 10, Steps: 244 Train Loss: 0.2300 (Forecasting Loss:0.2267 + XiCon Loss:3.3062 x Lambda(0.001)), Vali MSE Loss: 0.2699 Test MSE Loss: 0.1662
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2253642
	speed: 0.2001s/iter; left time: 4374.2818s
	iters: 200, epoch: 11 | loss: 0.2339959
	speed: 0.1982s/iter; left time: 4312.7100s
Epoch: 11 cost time: 48.720054149627686
Epoch: 11, Steps: 244 Train Loss: 0.2300 (Forecasting Loss:0.2267 + XiCon Loss:3.3059 x Lambda(0.001)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.1658
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08614185452461243, mae:0.23148030042648315, mape:0.16735464334487915, mspe:0.04365933686494827 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0180
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3778640
	speed: 0.1283s/iter; left time: 3116.7617s
	iters: 200, epoch: 1 | loss: 0.3454662
	speed: 0.1243s/iter; left time: 3008.0541s
Epoch: 1 cost time: 31.88296604156494
Epoch: 1, Steps: 244 Train Loss: 0.3562 (Forecasting Loss:0.3528 + XiCon Loss:3.3920 x Lambda(0.001)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1521
Validation loss decreased (inf --> 0.235639).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3000988
	speed: 0.1839s/iter; left time: 4423.8933s
	iters: 200, epoch: 2 | loss: 0.2869225
	speed: 0.1699s/iter; left time: 4070.8192s
Epoch: 2 cost time: 43.3999445438385
Epoch: 2, Steps: 244 Train Loss: 0.3160 (Forecasting Loss:0.3126 + XiCon Loss:3.3559 x Lambda(0.001)), Vali MSE Loss: 0.2954 Test MSE Loss: 0.1617
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2737077
	speed: 0.1783s/iter; left time: 4246.3633s
	iters: 200, epoch: 3 | loss: 0.2599024
	speed: 0.1726s/iter; left time: 4093.5006s
Epoch: 3 cost time: 42.762887477874756
Epoch: 3, Steps: 244 Train Loss: 0.2711 (Forecasting Loss:0.2677 + XiCon Loss:3.3376 x Lambda(0.001)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.1524
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2585143
	speed: 0.1728s/iter; left time: 4073.6332s
	iters: 200, epoch: 4 | loss: 0.2493887
	speed: 0.1810s/iter; left time: 4248.4882s
Epoch: 4 cost time: 43.16609454154968
Epoch: 4, Steps: 244 Train Loss: 0.2548 (Forecasting Loss:0.2515 + XiCon Loss:3.3288 x Lambda(0.001)), Vali MSE Loss: 0.3005 Test MSE Loss: 0.1525
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2425888
	speed: 0.1799s/iter; left time: 4195.0754s
	iters: 200, epoch: 5 | loss: 0.2353302
	speed: 0.1784s/iter; left time: 4143.3435s
Epoch: 5 cost time: 43.69984292984009
Epoch: 5, Steps: 244 Train Loss: 0.2441 (Forecasting Loss:0.2408 + XiCon Loss:3.3255 x Lambda(0.001)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.1494
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2431662
	speed: 0.1816s/iter; left time: 4191.7423s
	iters: 200, epoch: 6 | loss: 0.2242436
	speed: 0.1800s/iter; left time: 4137.6666s
Epoch: 6 cost time: 44.09590482711792
Epoch: 6, Steps: 244 Train Loss: 0.2386 (Forecasting Loss:0.2353 + XiCon Loss:3.3234 x Lambda(0.001)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.1493
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2527342
	speed: 0.1775s/iter; left time: 4053.4307s
	iters: 200, epoch: 7 | loss: 0.2356539
	speed: 0.1811s/iter; left time: 4118.5985s
Epoch: 7 cost time: 43.5997416973114
Epoch: 7, Steps: 244 Train Loss: 0.2356 (Forecasting Loss:0.2323 + XiCon Loss:3.3203 x Lambda(0.001)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1526
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2315039
	speed: 0.1770s/iter; left time: 3998.5676s
	iters: 200, epoch: 8 | loss: 0.2286137
	speed: 0.1777s/iter; left time: 3997.3466s
Epoch: 8 cost time: 43.64022254943848
Epoch: 8, Steps: 244 Train Loss: 0.2341 (Forecasting Loss:0.2307 + XiCon Loss:3.3187 x Lambda(0.001)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.1535
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2339393
	speed: 0.1652s/iter; left time: 3691.2059s
	iters: 200, epoch: 9 | loss: 0.2322181
	speed: 0.1734s/iter; left time: 3857.2357s
Epoch: 9 cost time: 41.87894082069397
Epoch: 9, Steps: 244 Train Loss: 0.2332 (Forecasting Loss:0.2299 + XiCon Loss:3.3166 x Lambda(0.001)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.1543
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2402180
	speed: 0.1742s/iter; left time: 3850.9618s
	iters: 200, epoch: 10 | loss: 0.2363167
	speed: 0.1744s/iter; left time: 3837.6669s
Epoch: 10 cost time: 43.257259130477905
Epoch: 10, Steps: 244 Train Loss: 0.2327 (Forecasting Loss:0.2294 + XiCon Loss:3.3165 x Lambda(0.001)), Vali MSE Loss: 0.3017 Test MSE Loss: 0.1545
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2414497
	speed: 0.1810s/iter; left time: 3956.2813s
	iters: 200, epoch: 11 | loss: 0.2325505
	speed: 0.1746s/iter; left time: 3799.3357s
Epoch: 11 cost time: 43.6202929019928
Epoch: 11, Steps: 244 Train Loss: 0.2323 (Forecasting Loss:0.2290 + XiCon Loss:3.3164 x Lambda(0.001)), Vali MSE Loss: 0.3032 Test MSE Loss: 0.1547
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08023804426193237, mae:0.2239558845758438, mape:0.16083291172981262, mspe:0.039693433791399 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.1988
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3647645
	speed: 0.1291s/iter; left time: 3137.7517s
	iters: 200, epoch: 1 | loss: 0.3295873
	speed: 0.1297s/iter; left time: 3138.3313s
Epoch: 1 cost time: 32.58254837989807
Epoch: 1, Steps: 244 Train Loss: 0.3494 (Forecasting Loss:0.3460 + XiCon Loss:3.3913 x Lambda(0.001)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1486
Validation loss decreased (inf --> 0.240117).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3105375
	speed: 0.1959s/iter; left time: 4712.9507s
	iters: 200, epoch: 2 | loss: 0.2704064
	speed: 0.1862s/iter; left time: 4459.7483s
Epoch: 2 cost time: 46.436275005340576
Epoch: 2, Steps: 244 Train Loss: 0.3007 (Forecasting Loss:0.2974 + XiCon Loss:3.3254 x Lambda(0.001)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.1658
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2725858
	speed: 0.1888s/iter; left time: 4496.2091s
	iters: 200, epoch: 3 | loss: 0.2553388
	speed: 0.1751s/iter; left time: 4151.3854s
Epoch: 3 cost time: 44.35553193092346
Epoch: 3, Steps: 244 Train Loss: 0.2599 (Forecasting Loss:0.2566 + XiCon Loss:3.3063 x Lambda(0.001)), Vali MSE Loss: 0.2857 Test MSE Loss: 0.1577
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2414302
	speed: 0.1850s/iter; left time: 4359.1315s
	iters: 200, epoch: 4 | loss: 0.2410913
	speed: 0.1859s/iter; left time: 4363.7041s
Epoch: 4 cost time: 45.16707682609558
Epoch: 4, Steps: 244 Train Loss: 0.2401 (Forecasting Loss:0.2367 + XiCon Loss:3.3085 x Lambda(0.001)), Vali MSE Loss: 0.3023 Test MSE Loss: 0.1585
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2266698
	speed: 0.1854s/iter; left time: 4325.4776s
	iters: 200, epoch: 5 | loss: 0.2234893
	speed: 0.1781s/iter; left time: 4136.6905s
Epoch: 5 cost time: 44.7809693813324
Epoch: 5, Steps: 244 Train Loss: 0.2289 (Forecasting Loss:0.2256 + XiCon Loss:3.3110 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.1635
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2266750
	speed: 0.1848s/iter; left time: 4265.2622s
	iters: 200, epoch: 6 | loss: 0.2232606
	speed: 0.1818s/iter; left time: 4179.0261s
Epoch: 6 cost time: 44.95494079589844
Epoch: 6, Steps: 244 Train Loss: 0.2229 (Forecasting Loss:0.2196 + XiCon Loss:3.3088 x Lambda(0.001)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.1722
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2125164
	speed: 0.1860s/iter; left time: 4247.7907s
	iters: 200, epoch: 7 | loss: 0.2200358
	speed: 0.1785s/iter; left time: 4058.6200s
Epoch: 7 cost time: 44.43839883804321
Epoch: 7, Steps: 244 Train Loss: 0.2200 (Forecasting Loss:0.2167 + XiCon Loss:3.3095 x Lambda(0.001)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.1696
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2166209
	speed: 0.1847s/iter; left time: 4173.8161s
	iters: 200, epoch: 8 | loss: 0.2186666
	speed: 0.1642s/iter; left time: 3693.0160s
Epoch: 8 cost time: 42.97214388847351
Epoch: 8, Steps: 244 Train Loss: 0.2184 (Forecasting Loss:0.2151 + XiCon Loss:3.3078 x Lambda(0.001)), Vali MSE Loss: 0.3123 Test MSE Loss: 0.1708
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2078831
	speed: 0.1694s/iter; left time: 3786.8378s
	iters: 200, epoch: 9 | loss: 0.2110443
	speed: 0.1962s/iter; left time: 4364.4248s
Epoch: 9 cost time: 44.711623191833496
Epoch: 9, Steps: 244 Train Loss: 0.2178 (Forecasting Loss:0.2145 + XiCon Loss:3.3064 x Lambda(0.001)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.1696
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2174032
	speed: 0.2033s/iter; left time: 4494.6488s
	iters: 200, epoch: 10 | loss: 0.2249957
	speed: 0.1927s/iter; left time: 4239.9382s
Epoch: 10 cost time: 48.660398721694946
Epoch: 10, Steps: 244 Train Loss: 0.2172 (Forecasting Loss:0.2139 + XiCon Loss:3.3065 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.1713
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2236952
	speed: 0.1938s/iter; left time: 4237.0660s
	iters: 200, epoch: 11 | loss: 0.2139945
	speed: 0.1930s/iter; left time: 4200.1465s
Epoch: 11 cost time: 46.87626242637634
Epoch: 11, Steps: 244 Train Loss: 0.2171 (Forecasting Loss:0.2138 + XiCon Loss:3.3080 x Lambda(0.001)), Vali MSE Loss: 0.3140 Test MSE Loss: 0.1717
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.07751790434122086, mae:0.21969613432884216, mape:0.15787813067436218, mspe:0.03847429156303406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7933
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3528069
	speed: 0.1461s/iter; left time: 3550.9053s
	iters: 200, epoch: 1 | loss: 0.2786998
	speed: 0.1512s/iter; left time: 3658.2409s
Epoch: 1 cost time: 36.36289739608765
Epoch: 1, Steps: 244 Train Loss: 0.3454 (Forecasting Loss:0.3420 + XiCon Loss:3.3961 x Lambda(0.001)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.234751).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3158379
	speed: 0.2196s/iter; left time: 5282.4208s
	iters: 200, epoch: 2 | loss: 0.2896257
	speed: 0.2373s/iter; left time: 5685.9379s
Epoch: 2 cost time: 56.09044861793518
Epoch: 2, Steps: 244 Train Loss: 0.3285 (Forecasting Loss:0.3251 + XiCon Loss:3.3574 x Lambda(0.001)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.1534
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2483044
	speed: 0.2414s/iter; left time: 5748.1985s
	iters: 200, epoch: 3 | loss: 0.2632879
	speed: 0.2420s/iter; left time: 5738.3102s
Epoch: 3 cost time: 58.8838791847229
Epoch: 3, Steps: 244 Train Loss: 0.2572 (Forecasting Loss:0.2538 + XiCon Loss:3.3288 x Lambda(0.001)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.1506
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2412753
	speed: 0.2366s/iter; left time: 5577.4794s
	iters: 200, epoch: 4 | loss: 0.2415042
	speed: 0.2391s/iter; left time: 5611.6558s
Epoch: 4 cost time: 58.21146488189697
Epoch: 4, Steps: 244 Train Loss: 0.2386 (Forecasting Loss:0.2352 + XiCon Loss:3.3297 x Lambda(0.001)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.1598
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2329581
	speed: 0.2363s/iter; left time: 5510.5769s
	iters: 200, epoch: 5 | loss: 0.2318208
	speed: 0.2291s/iter; left time: 5321.7216s
Epoch: 5 cost time: 56.80261015892029
Epoch: 5, Steps: 244 Train Loss: 0.2294 (Forecasting Loss:0.2261 + XiCon Loss:3.3269 x Lambda(0.001)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.1633
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2302122
	speed: 0.2332s/iter; left time: 5382.9728s
	iters: 200, epoch: 6 | loss: 0.2238764
	speed: 0.2349s/iter; left time: 5397.9182s
Epoch: 6 cost time: 57.21423864364624
Epoch: 6, Steps: 244 Train Loss: 0.2250 (Forecasting Loss:0.2217 + XiCon Loss:3.3245 x Lambda(0.001)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.1625
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2185789
	speed: 0.2346s/iter; left time: 5356.8276s
	iters: 200, epoch: 7 | loss: 0.2198305
	speed: 0.2336s/iter; left time: 5310.8626s
Epoch: 7 cost time: 57.35851049423218
Epoch: 7, Steps: 244 Train Loss: 0.2226 (Forecasting Loss:0.2193 + XiCon Loss:3.3234 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.1636
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2244862
	speed: 0.2330s/iter; left time: 5264.8278s
	iters: 200, epoch: 8 | loss: 0.2114129
	speed: 0.2317s/iter; left time: 5210.6678s
Epoch: 8 cost time: 56.86280417442322
Epoch: 8, Steps: 244 Train Loss: 0.2215 (Forecasting Loss:0.2182 + XiCon Loss:3.3230 x Lambda(0.001)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.1631
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2241886
	speed: 0.2364s/iter; left time: 5283.8190s
	iters: 200, epoch: 9 | loss: 0.2294224
	speed: 0.2317s/iter; left time: 5154.9583s
Epoch: 9 cost time: 57.341034173965454
Epoch: 9, Steps: 244 Train Loss: 0.2211 (Forecasting Loss:0.2178 + XiCon Loss:3.3233 x Lambda(0.001)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.1644
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2227685
	speed: 0.2325s/iter; left time: 5139.4458s
	iters: 200, epoch: 10 | loss: 0.2162441
	speed: 0.2278s/iter; left time: 5012.5810s
Epoch: 10 cost time: 55.68299412727356
Epoch: 10, Steps: 244 Train Loss: 0.2207 (Forecasting Loss:0.2174 + XiCon Loss:3.3203 x Lambda(0.001)), Vali MSE Loss: 0.2849 Test MSE Loss: 0.1651
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2317678
	speed: 0.2046s/iter; left time: 4472.6340s
	iters: 200, epoch: 11 | loss: 0.2222854
	speed: 0.2272s/iter; left time: 4943.2976s
Epoch: 11 cost time: 52.98263239860535
Epoch: 11, Steps: 244 Train Loss: 0.2205 (Forecasting Loss:0.2172 + XiCon Loss:3.3215 x Lambda(0.001)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.1641
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08994216471910477, mae:0.23591816425323486, mape:0.16951866447925568, mspe:0.04447584226727486 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0837+-0.00609, MAE:0.2278+-0.00785, MAPE:0.1635+-0.00599, MSPE:0.0413+-0.00328, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0044
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4322391
	speed: 0.1229s/iter; left time: 2850.8734s
	iters: 200, epoch: 1 | loss: 0.4139475
	speed: 0.1191s/iter; left time: 2752.4446s
Epoch: 1 cost time: 28.471006870269775
Epoch: 1, Steps: 233 Train Loss: 0.4331 (Forecasting Loss:0.4297 + XiCon Loss:3.4216 x Lambda(0.001)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.1700
Validation loss decreased (inf --> 0.298945).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3517246
	speed: 0.1238s/iter; left time: 2843.3489s
	iters: 200, epoch: 2 | loss: 0.3053810
	speed: 0.1210s/iter; left time: 2766.6534s
Epoch: 2 cost time: 28.832828760147095
Epoch: 2, Steps: 233 Train Loss: 0.3403 (Forecasting Loss:0.3370 + XiCon Loss:3.3820 x Lambda(0.001)), Vali MSE Loss: 0.2380 Test MSE Loss: 0.1593
Validation loss decreased (0.298945 --> 0.238016).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2865209
	speed: 0.1264s/iter; left time: 2873.6823s
	iters: 200, epoch: 3 | loss: 0.2838613
	speed: 0.1230s/iter; left time: 2785.0956s
Epoch: 3 cost time: 29.280200958251953
Epoch: 3, Steps: 233 Train Loss: 0.2861 (Forecasting Loss:0.2827 + XiCon Loss:3.3751 x Lambda(0.001)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1606
Validation loss decreased (0.238016 --> 0.234779).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2744669
	speed: 0.1223s/iter; left time: 2752.5887s
	iters: 200, epoch: 4 | loss: 0.2688863
	speed: 0.1209s/iter; left time: 2707.7532s
Epoch: 4 cost time: 27.80295753479004
Epoch: 4, Steps: 233 Train Loss: 0.2743 (Forecasting Loss:0.2709 + XiCon Loss:3.3659 x Lambda(0.001)), Vali MSE Loss: 0.2281 Test MSE Loss: 0.1575
Validation loss decreased (0.234779 --> 0.228125).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2651772
	speed: 0.1211s/iter; left time: 2697.8056s
	iters: 200, epoch: 5 | loss: 0.2662690
	speed: 0.1225s/iter; left time: 2715.3205s
Epoch: 5 cost time: 29.059945583343506
Epoch: 5, Steps: 233 Train Loss: 0.2690 (Forecasting Loss:0.2656 + XiCon Loss:3.3611 x Lambda(0.001)), Vali MSE Loss: 0.2362 Test MSE Loss: 0.1580
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2803524
	speed: 0.1243s/iter; left time: 2739.1779s
	iters: 200, epoch: 6 | loss: 0.2621275
	speed: 0.1201s/iter; left time: 2634.4537s
Epoch: 6 cost time: 28.70918846130371
Epoch: 6, Steps: 233 Train Loss: 0.2658 (Forecasting Loss:0.2625 + XiCon Loss:3.3591 x Lambda(0.001)), Vali MSE Loss: 0.2333 Test MSE Loss: 0.1595
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2754408
	speed: 0.1240s/iter; left time: 2702.7290s
	iters: 200, epoch: 7 | loss: 0.2737758
	speed: 0.1215s/iter; left time: 2636.2958s
Epoch: 7 cost time: 29.105733156204224
Epoch: 7, Steps: 233 Train Loss: 0.2640 (Forecasting Loss:0.2607 + XiCon Loss:3.3571 x Lambda(0.001)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1575
Validation loss decreased (0.228125 --> 0.227840).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2596915
	speed: 0.1228s/iter; left time: 2649.2338s
	iters: 200, epoch: 8 | loss: 0.2722755
	speed: 0.1196s/iter; left time: 2567.0428s
Epoch: 8 cost time: 28.445210456848145
Epoch: 8, Steps: 233 Train Loss: 0.2631 (Forecasting Loss:0.2597 + XiCon Loss:3.3556 x Lambda(0.001)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1580
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2564796
	speed: 0.1194s/iter; left time: 2546.6287s
	iters: 200, epoch: 9 | loss: 0.2696174
	speed: 0.1202s/iter; left time: 2551.8564s
Epoch: 9 cost time: 28.138717889785767
Epoch: 9, Steps: 233 Train Loss: 0.2627 (Forecasting Loss:0.2594 + XiCon Loss:3.3553 x Lambda(0.001)), Vali MSE Loss: 0.2290 Test MSE Loss: 0.1580
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2576681
	speed: 0.1219s/iter; left time: 2572.0676s
	iters: 200, epoch: 10 | loss: 0.2579048
	speed: 0.1212s/iter; left time: 2546.4406s
Epoch: 10 cost time: 28.452691316604614
Epoch: 10, Steps: 233 Train Loss: 0.2624 (Forecasting Loss:0.2591 + XiCon Loss:3.3566 x Lambda(0.001)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1571
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2759400
	speed: 0.1258s/iter; left time: 2625.4027s
	iters: 200, epoch: 11 | loss: 0.2619043
	speed: 0.1165s/iter; left time: 2420.0735s
Epoch: 11 cost time: 28.155808925628662
Epoch: 11, Steps: 233 Train Loss: 0.2624 (Forecasting Loss:0.2591 + XiCon Loss:3.3553 x Lambda(0.001)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.1578
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2652524
	speed: 0.1217s/iter; left time: 2510.6803s
	iters: 200, epoch: 12 | loss: 0.2503363
	speed: 0.1182s/iter; left time: 2428.0429s
Epoch: 12 cost time: 27.849539041519165
Epoch: 12, Steps: 233 Train Loss: 0.2623 (Forecasting Loss:0.2590 + XiCon Loss:3.3547 x Lambda(0.001)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1581
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2670965
	speed: 0.1201s/iter; left time: 2451.3699s
	iters: 200, epoch: 13 | loss: 0.2692524
	speed: 0.1176s/iter; left time: 2388.3836s
Epoch: 13 cost time: 27.793103218078613
Epoch: 13, Steps: 233 Train Loss: 0.2623 (Forecasting Loss:0.2590 + XiCon Loss:3.3547 x Lambda(0.001)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.1581
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2566298
	speed: 0.1208s/iter; left time: 2437.6893s
	iters: 200, epoch: 14 | loss: 0.2545731
	speed: 0.1197s/iter; left time: 2401.9043s
Epoch: 14 cost time: 27.95952868461609
Epoch: 14, Steps: 233 Train Loss: 0.2621 (Forecasting Loss:0.2587 + XiCon Loss:3.3559 x Lambda(0.001)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1582
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2672371
	speed: 0.1222s/iter; left time: 2436.5858s
	iters: 200, epoch: 15 | loss: 0.2588741
	speed: 0.1158s/iter; left time: 2298.1297s
Epoch: 15 cost time: 27.736602544784546
Epoch: 15, Steps: 233 Train Loss: 0.2623 (Forecasting Loss:0.2590 + XiCon Loss:3.3571 x Lambda(0.001)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1582
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2582682
	speed: 0.1233s/iter; left time: 2429.8081s
	iters: 200, epoch: 16 | loss: 0.2675215
	speed: 0.1232s/iter; left time: 2414.5850s
Epoch: 16 cost time: 28.54063868522644
Epoch: 16, Steps: 233 Train Loss: 0.2622 (Forecasting Loss:0.2589 + XiCon Loss:3.3561 x Lambda(0.001)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1581
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2594787
	speed: 0.1246s/iter; left time: 2426.6790s
	iters: 200, epoch: 17 | loss: 0.2539778
	speed: 0.1218s/iter; left time: 2358.8849s
Epoch: 17 cost time: 28.62260103225708
Epoch: 17, Steps: 233 Train Loss: 0.2621 (Forecasting Loss:0.2588 + XiCon Loss:3.3561 x Lambda(0.001)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1581
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08471084386110306, mae:0.2303236573934555, mape:0.16498567163944244, mspe:0.04237867519259453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.3825
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4527076
	speed: 0.1123s/iter; left time: 2605.8056s
	iters: 200, epoch: 1 | loss: 0.4590285
	speed: 0.1124s/iter; left time: 2595.4088s
Epoch: 1 cost time: 26.087165117263794
Epoch: 1, Steps: 233 Train Loss: 0.4513 (Forecasting Loss:0.4479 + XiCon Loss:3.4173 x Lambda(0.001)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1871
Validation loss decreased (inf --> 0.290627).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3181302
	speed: 0.1329s/iter; left time: 3053.5086s
	iters: 200, epoch: 2 | loss: 0.2844034
	speed: 0.1569s/iter; left time: 3587.4434s
Epoch: 2 cost time: 34.26353740692139
Epoch: 2, Steps: 233 Train Loss: 0.3282 (Forecasting Loss:0.3248 + XiCon Loss:3.3559 x Lambda(0.001)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.1739
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2757661
	speed: 0.1615s/iter; left time: 3672.1200s
	iters: 200, epoch: 3 | loss: 0.2695944
	speed: 0.1628s/iter; left time: 3684.8805s
Epoch: 3 cost time: 37.72203469276428
Epoch: 3, Steps: 233 Train Loss: 0.2782 (Forecasting Loss:0.2749 + XiCon Loss:3.3394 x Lambda(0.001)), Vali MSE Loss: 0.3071 Test MSE Loss: 0.1562
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2448814
	speed: 0.1579s/iter; left time: 3553.6090s
	iters: 200, epoch: 4 | loss: 0.2815389
	speed: 0.1557s/iter; left time: 3487.0539s
Epoch: 4 cost time: 36.42030358314514
Epoch: 4, Steps: 233 Train Loss: 0.2665 (Forecasting Loss:0.2632 + XiCon Loss:3.3419 x Lambda(0.001)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.1575
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2547877
	speed: 0.1557s/iter; left time: 3466.8029s
	iters: 200, epoch: 5 | loss: 0.2516244
	speed: 0.1514s/iter; left time: 3355.4770s
Epoch: 5 cost time: 35.76690936088562
Epoch: 5, Steps: 233 Train Loss: 0.2612 (Forecasting Loss:0.2578 + XiCon Loss:3.3433 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2609337
	speed: 0.1604s/iter; left time: 3535.1012s
	iters: 200, epoch: 6 | loss: 0.2551985
	speed: 0.1490s/iter; left time: 3268.9414s
Epoch: 6 cost time: 36.08696889877319
Epoch: 6, Steps: 233 Train Loss: 0.2584 (Forecasting Loss:0.2551 + XiCon Loss:3.3411 x Lambda(0.001)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.1595
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2696075
	speed: 0.1195s/iter; left time: 2605.5077s
	iters: 200, epoch: 7 | loss: 0.2504249
	speed: 0.1501s/iter; left time: 3257.5275s
Epoch: 7 cost time: 32.39653038978577
Epoch: 7, Steps: 233 Train Loss: 0.2571 (Forecasting Loss:0.2538 + XiCon Loss:3.3412 x Lambda(0.001)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.1619
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2623810
	speed: 0.1410s/iter; left time: 3040.5815s
	iters: 200, epoch: 8 | loss: 0.2446294
	speed: 0.1482s/iter; left time: 3181.3877s
Epoch: 8 cost time: 33.957985162734985
Epoch: 8, Steps: 233 Train Loss: 0.2564 (Forecasting Loss:0.2531 + XiCon Loss:3.3410 x Lambda(0.001)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.1610
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2588337
	speed: 0.1553s/iter; left time: 3313.1279s
	iters: 200, epoch: 9 | loss: 0.2563058
	speed: 0.1556s/iter; left time: 3303.7017s
Epoch: 9 cost time: 36.373061180114746
Epoch: 9, Steps: 233 Train Loss: 0.2559 (Forecasting Loss:0.2525 + XiCon Loss:3.3421 x Lambda(0.001)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.1623
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2506401
	speed: 0.1550s/iter; left time: 3270.8308s
	iters: 200, epoch: 10 | loss: 0.2578732
	speed: 0.1517s/iter; left time: 3186.6051s
Epoch: 10 cost time: 36.075018644332886
Epoch: 10, Steps: 233 Train Loss: 0.2558 (Forecasting Loss:0.2524 + XiCon Loss:3.3421 x Lambda(0.001)), Vali MSE Loss: 0.3140 Test MSE Loss: 0.1622
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2504029
	speed: 0.1498s/iter; left time: 3125.6749s
	iters: 200, epoch: 11 | loss: 0.2684762
	speed: 0.1464s/iter; left time: 3039.9353s
Epoch: 11 cost time: 34.430428981781006
Epoch: 11, Steps: 233 Train Loss: 0.2555 (Forecasting Loss:0.2521 + XiCon Loss:3.3421 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.1625
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.10986404865980148, mae:0.2643842399120331, mape:0.18647730350494385, mspe:0.05199890583753586 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.7003
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4411702
	speed: 0.1149s/iter; left time: 2665.5414s
	iters: 200, epoch: 1 | loss: 0.4372814
	speed: 0.1144s/iter; left time: 2641.9393s
Epoch: 1 cost time: 26.858209371566772
Epoch: 1, Steps: 233 Train Loss: 0.4444 (Forecasting Loss:0.4410 + XiCon Loss:3.4117 x Lambda(0.001)), Vali MSE Loss: 0.2967 Test MSE Loss: 0.1909
Validation loss decreased (inf --> 0.296736).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3152961
	speed: 0.1418s/iter; left time: 3257.5160s
	iters: 200, epoch: 2 | loss: 0.2954475
	speed: 0.1487s/iter; left time: 3399.5307s
Epoch: 2 cost time: 33.88886475563049
Epoch: 2, Steps: 233 Train Loss: 0.3214 (Forecasting Loss:0.3180 + XiCon Loss:3.3451 x Lambda(0.001)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.1693
Validation loss decreased (0.296736 --> 0.292211).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2609532
	speed: 0.1465s/iter; left time: 3330.0986s
	iters: 200, epoch: 3 | loss: 0.2736250
	speed: 0.1498s/iter; left time: 3390.5718s
Epoch: 3 cost time: 34.78394556045532
Epoch: 3, Steps: 233 Train Loss: 0.2813 (Forecasting Loss:0.2780 + XiCon Loss:3.3335 x Lambda(0.001)), Vali MSE Loss: 0.2739 Test MSE Loss: 0.1660
Validation loss decreased (0.292211 --> 0.273898).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2679641
	speed: 0.1559s/iter; left time: 3508.6924s
	iters: 200, epoch: 4 | loss: 0.2901632
	speed: 0.1520s/iter; left time: 3404.7944s
Epoch: 4 cost time: 35.78573489189148
Epoch: 4, Steps: 233 Train Loss: 0.2721 (Forecasting Loss:0.2687 + XiCon Loss:3.3269 x Lambda(0.001)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.1533
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2697436
	speed: 0.1512s/iter; left time: 3366.3488s
	iters: 200, epoch: 5 | loss: 0.2706108
	speed: 0.1492s/iter; left time: 3306.7801s
Epoch: 5 cost time: 34.84344482421875
Epoch: 5, Steps: 233 Train Loss: 0.2669 (Forecasting Loss:0.2636 + XiCon Loss:3.3181 x Lambda(0.001)), Vali MSE Loss: 0.2748 Test MSE Loss: 0.1555
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2671779
	speed: 0.1478s/iter; left time: 3255.8929s
	iters: 200, epoch: 6 | loss: 0.2571136
	speed: 0.1512s/iter; left time: 3316.7830s
Epoch: 6 cost time: 34.92990469932556
Epoch: 6, Steps: 233 Train Loss: 0.2640 (Forecasting Loss:0.2607 + XiCon Loss:3.3141 x Lambda(0.001)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.1583
Validation loss decreased (0.273898 --> 0.273414).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2700121
	speed: 0.1568s/iter; left time: 3417.8956s
	iters: 200, epoch: 7 | loss: 0.2568761
	speed: 0.1453s/iter; left time: 3154.4288s
Epoch: 7 cost time: 35.23079180717468
Epoch: 7, Steps: 233 Train Loss: 0.2626 (Forecasting Loss:0.2593 + XiCon Loss:3.3107 x Lambda(0.001)), Vali MSE Loss: 0.2758 Test MSE Loss: 0.1567
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2746372
	speed: 0.1484s/iter; left time: 3201.0864s
	iters: 200, epoch: 8 | loss: 0.2618141
	speed: 0.1539s/iter; left time: 3305.2581s
Epoch: 8 cost time: 35.31934857368469
Epoch: 8, Steps: 233 Train Loss: 0.2617 (Forecasting Loss:0.2584 + XiCon Loss:3.3099 x Lambda(0.001)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.1595
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2537321
	speed: 0.1558s/iter; left time: 3325.0244s
	iters: 200, epoch: 9 | loss: 0.2530380
	speed: 0.1480s/iter; left time: 3143.7809s
Epoch: 9 cost time: 35.15891885757446
Epoch: 9, Steps: 233 Train Loss: 0.2612 (Forecasting Loss:0.2579 + XiCon Loss:3.3102 x Lambda(0.001)), Vali MSE Loss: 0.2756 Test MSE Loss: 0.1584
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2497625
	speed: 0.1484s/iter; left time: 3132.7992s
	iters: 200, epoch: 10 | loss: 0.2616102
	speed: 0.1551s/iter; left time: 3256.7756s
Epoch: 10 cost time: 35.15398979187012
Epoch: 10, Steps: 233 Train Loss: 0.2612 (Forecasting Loss:0.2579 + XiCon Loss:3.3088 x Lambda(0.001)), Vali MSE Loss: 0.2754 Test MSE Loss: 0.1581
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2602671
	speed: 0.1554s/iter; left time: 3243.4199s
	iters: 200, epoch: 11 | loss: 0.2465712
	speed: 0.1518s/iter; left time: 3153.4914s
Epoch: 11 cost time: 35.907930850982666
Epoch: 11, Steps: 233 Train Loss: 0.2608 (Forecasting Loss:0.2575 + XiCon Loss:3.3084 x Lambda(0.001)), Vali MSE Loss: 0.2752 Test MSE Loss: 0.1578
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2687054
	speed: 0.1532s/iter; left time: 3162.5006s
	iters: 200, epoch: 12 | loss: 0.2683675
	speed: 0.1480s/iter; left time: 3039.4900s
Epoch: 12 cost time: 35.72285223007202
Epoch: 12, Steps: 233 Train Loss: 0.2607 (Forecasting Loss:0.2574 + XiCon Loss:3.3106 x Lambda(0.001)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.1578
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2739960
	speed: 0.1552s/iter; left time: 3167.0616s
	iters: 200, epoch: 13 | loss: 0.2540140
	speed: 0.1515s/iter; left time: 3076.2447s
Epoch: 13 cost time: 35.655905961990356
Epoch: 13, Steps: 233 Train Loss: 0.2611 (Forecasting Loss:0.2578 + XiCon Loss:3.3090 x Lambda(0.001)), Vali MSE Loss: 0.2750 Test MSE Loss: 0.1578
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2734710
	speed: 0.1547s/iter; left time: 3119.9492s
	iters: 200, epoch: 14 | loss: 0.2642775
	speed: 0.1477s/iter; left time: 2964.3560s
Epoch: 14 cost time: 35.46621513366699
Epoch: 14, Steps: 233 Train Loss: 0.2609 (Forecasting Loss:0.2576 + XiCon Loss:3.3087 x Lambda(0.001)), Vali MSE Loss: 0.2748 Test MSE Loss: 0.1579
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2865821
	speed: 0.1263s/iter; left time: 2519.1651s
	iters: 200, epoch: 15 | loss: 0.2603071
	speed: 0.1448s/iter; left time: 2873.0981s
Epoch: 15 cost time: 32.29298233985901
Epoch: 15, Steps: 233 Train Loss: 0.2612 (Forecasting Loss:0.2579 + XiCon Loss:3.3084 x Lambda(0.001)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.1579
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2694530
	speed: 0.1394s/iter; left time: 2746.4418s
	iters: 200, epoch: 16 | loss: 0.2560019
	speed: 0.1509s/iter; left time: 2957.7949s
Epoch: 16 cost time: 34.51373291015625
Epoch: 16, Steps: 233 Train Loss: 0.2611 (Forecasting Loss:0.2578 + XiCon Loss:3.3086 x Lambda(0.001)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.1579
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08532781898975372, mae:0.23129096627235413, mape:0.1641806811094284, mspe:0.041215281933546066 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.4295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4659599
	speed: 0.1140s/iter; left time: 2645.3172s
	iters: 200, epoch: 1 | loss: 0.3836925
	speed: 0.1118s/iter; left time: 2581.9078s
Epoch: 1 cost time: 26.528804779052734
Epoch: 1, Steps: 233 Train Loss: 0.4293 (Forecasting Loss:0.4259 + XiCon Loss:3.4210 x Lambda(0.001)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1635
Validation loss decreased (inf --> 0.265349).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3315541
	speed: 0.1209s/iter; left time: 2776.1495s
	iters: 200, epoch: 2 | loss: 0.3313161
	speed: 0.1137s/iter; left time: 2599.0257s
Epoch: 2 cost time: 27.24414849281311
Epoch: 2, Steps: 233 Train Loss: 0.3384 (Forecasting Loss:0.3350 + XiCon Loss:3.3919 x Lambda(0.001)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1711
Validation loss decreased (0.265349 --> 0.221626).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2915993
	speed: 0.1222s/iter; left time: 2778.3058s
	iters: 200, epoch: 3 | loss: 0.2708811
	speed: 0.1100s/iter; left time: 2490.2740s
Epoch: 3 cost time: 27.01183009147644
Epoch: 3, Steps: 233 Train Loss: 0.2866 (Forecasting Loss:0.2832 + XiCon Loss:3.3673 x Lambda(0.001)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.1558
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2650586
	speed: 0.1166s/iter; left time: 2623.7696s
	iters: 200, epoch: 4 | loss: 0.2731792
	speed: 0.1200s/iter; left time: 2687.3161s
Epoch: 4 cost time: 27.496578216552734
Epoch: 4, Steps: 233 Train Loss: 0.2749 (Forecasting Loss:0.2715 + XiCon Loss:3.3736 x Lambda(0.001)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1581
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2540582
	speed: 0.1216s/iter; left time: 2707.5938s
	iters: 200, epoch: 5 | loss: 0.2601612
	speed: 0.1123s/iter; left time: 2489.0460s
Epoch: 5 cost time: 27.43571424484253
Epoch: 5, Steps: 233 Train Loss: 0.2701 (Forecasting Loss:0.2667 + XiCon Loss:3.3734 x Lambda(0.001)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2660124
	speed: 0.1173s/iter; left time: 2585.2441s
	iters: 200, epoch: 6 | loss: 0.2528950
	speed: 0.1111s/iter; left time: 2437.8287s
Epoch: 6 cost time: 26.611969232559204
Epoch: 6, Steps: 233 Train Loss: 0.2675 (Forecasting Loss:0.2641 + XiCon Loss:3.3773 x Lambda(0.001)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.1619
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2585678
	speed: 0.1173s/iter; left time: 2557.2332s
	iters: 200, epoch: 7 | loss: 0.2615584
	speed: 0.1108s/iter; left time: 2405.7485s
Epoch: 7 cost time: 26.55049180984497
Epoch: 7, Steps: 233 Train Loss: 0.2660 (Forecasting Loss:0.2626 + XiCon Loss:3.3758 x Lambda(0.001)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1618
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2715904
	speed: 0.1167s/iter; left time: 2516.7927s
	iters: 200, epoch: 8 | loss: 0.2865318
	speed: 0.1126s/iter; left time: 2417.1604s
Epoch: 8 cost time: 26.604945421218872
Epoch: 8, Steps: 233 Train Loss: 0.2653 (Forecasting Loss:0.2619 + XiCon Loss:3.3749 x Lambda(0.001)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1613
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2569641
	speed: 0.1172s/iter; left time: 2500.0902s
	iters: 200, epoch: 9 | loss: 0.2601968
	speed: 0.1125s/iter; left time: 2389.0668s
Epoch: 9 cost time: 26.784295558929443
Epoch: 9, Steps: 233 Train Loss: 0.2649 (Forecasting Loss:0.2615 + XiCon Loss:3.3755 x Lambda(0.001)), Vali MSE Loss: 0.2286 Test MSE Loss: 0.1634
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2566112
	speed: 0.1154s/iter; left time: 2435.6568s
	iters: 200, epoch: 10 | loss: 0.2639756
	speed: 0.1142s/iter; left time: 2398.3557s
Epoch: 10 cost time: 26.70013928413391
Epoch: 10, Steps: 233 Train Loss: 0.2647 (Forecasting Loss:0.2614 + XiCon Loss:3.3759 x Lambda(0.001)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1641
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2671644
	speed: 0.1150s/iter; left time: 2399.9130s
	iters: 200, epoch: 11 | loss: 0.2630120
	speed: 0.1182s/iter; left time: 2455.0455s
Epoch: 11 cost time: 27.152611255645752
Epoch: 11, Steps: 233 Train Loss: 0.2644 (Forecasting Loss:0.2610 + XiCon Loss:3.3740 x Lambda(0.001)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.1640
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2530280
	speed: 0.1135s/iter; left time: 2342.5820s
	iters: 200, epoch: 12 | loss: 0.2583851
	speed: 0.1127s/iter; left time: 2313.6675s
Epoch: 12 cost time: 26.340792655944824
Epoch: 12, Steps: 233 Train Loss: 0.2644 (Forecasting Loss:0.2610 + XiCon Loss:3.3758 x Lambda(0.001)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.1633
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09635936468839645, mae:0.24586451053619385, mape:0.17231960594654083, mspe:0.04456726834177971 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.7348
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4321132
	speed: 0.1141s/iter; left time: 2648.2580s
	iters: 200, epoch: 1 | loss: 0.4379361
	speed: 0.1103s/iter; left time: 2548.6388s
Epoch: 1 cost time: 26.517789125442505
Epoch: 1, Steps: 233 Train Loss: 0.4468 (Forecasting Loss:0.4434 + XiCon Loss:3.4158 x Lambda(0.001)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.1958
Validation loss decreased (inf --> 0.300011).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2994878
	speed: 0.1386s/iter; left time: 3183.3814s
	iters: 200, epoch: 2 | loss: 0.2906898
	speed: 0.1543s/iter; left time: 3529.1255s
Epoch: 2 cost time: 34.33831834793091
Epoch: 2, Steps: 233 Train Loss: 0.3220 (Forecasting Loss:0.3187 + XiCon Loss:3.3239 x Lambda(0.001)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.1628
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2836621
	speed: 0.1638s/iter; left time: 3724.9105s
	iters: 200, epoch: 3 | loss: 0.2928202
	speed: 0.1593s/iter; left time: 3604.9103s
Epoch: 3 cost time: 38.0185604095459
Epoch: 3, Steps: 233 Train Loss: 0.2779 (Forecasting Loss:0.2746 + XiCon Loss:3.3103 x Lambda(0.001)), Vali MSE Loss: 0.4033 Test MSE Loss: 0.1627
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2745951
	speed: 0.1590s/iter; left time: 3577.7474s
	iters: 200, epoch: 4 | loss: 0.2570358
	speed: 0.1620s/iter; left time: 3628.0346s
Epoch: 4 cost time: 37.57354927062988
Epoch: 4, Steps: 233 Train Loss: 0.2688 (Forecasting Loss:0.2655 + XiCon Loss:3.2996 x Lambda(0.001)), Vali MSE Loss: 0.3630 Test MSE Loss: 0.1544
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2658302
	speed: 0.1577s/iter; left time: 3512.3227s
	iters: 200, epoch: 5 | loss: 0.2747202
	speed: 0.1531s/iter; left time: 3395.1552s
Epoch: 5 cost time: 36.488890171051025
Epoch: 5, Steps: 233 Train Loss: 0.2634 (Forecasting Loss:0.2601 + XiCon Loss:3.2958 x Lambda(0.001)), Vali MSE Loss: 0.3362 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2602415
	speed: 0.1535s/iter; left time: 3381.8198s
	iters: 200, epoch: 6 | loss: 0.2615233
	speed: 0.1123s/iter; left time: 2463.8493s
Epoch: 6 cost time: 32.05027794837952
Epoch: 6, Steps: 233 Train Loss: 0.2612 (Forecasting Loss:0.2579 + XiCon Loss:3.2956 x Lambda(0.001)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.1560
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2577751
	speed: 0.1585s/iter; left time: 3455.8435s
	iters: 200, epoch: 7 | loss: 0.2655087
	speed: 0.1457s/iter; left time: 3162.3662s
Epoch: 7 cost time: 35.9477641582489
Epoch: 7, Steps: 233 Train Loss: 0.2595 (Forecasting Loss:0.2562 + XiCon Loss:3.2957 x Lambda(0.001)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.1560
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2593125
	speed: 0.1601s/iter; left time: 3454.0810s
	iters: 200, epoch: 8 | loss: 0.2538644
	speed: 0.1534s/iter; left time: 3293.3432s
Epoch: 8 cost time: 37.078551292419434
Epoch: 8, Steps: 233 Train Loss: 0.2584 (Forecasting Loss:0.2551 + XiCon Loss:3.2956 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.1559
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2528141
	speed: 0.1567s/iter; left time: 3343.8043s
	iters: 200, epoch: 9 | loss: 0.2555283
	speed: 0.1568s/iter; left time: 3330.3648s
Epoch: 9 cost time: 36.71210837364197
Epoch: 9, Steps: 233 Train Loss: 0.2580 (Forecasting Loss:0.2547 + XiCon Loss:3.2952 x Lambda(0.001)), Vali MSE Loss: 0.3101 Test MSE Loss: 0.1564
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2629748
	speed: 0.1591s/iter; left time: 3357.0231s
	iters: 200, epoch: 10 | loss: 0.2585723
	speed: 0.1573s/iter; left time: 3304.3988s
Epoch: 10 cost time: 37.22675800323486
Epoch: 10, Steps: 233 Train Loss: 0.2577 (Forecasting Loss:0.2544 + XiCon Loss:3.2956 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.1556
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2638456
	speed: 0.1604s/iter; left time: 3348.0245s
	iters: 200, epoch: 11 | loss: 0.2634411
	speed: 0.1532s/iter; left time: 3181.0905s
Epoch: 11 cost time: 36.505263328552246
Epoch: 11, Steps: 233 Train Loss: 0.2576 (Forecasting Loss:0.2543 + XiCon Loss:3.2951 x Lambda(0.001)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.1555
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11764456331729889, mae:0.2738594710826874, mape:0.19268299639225006, mspe:0.05529319867491722 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0988+-0.01824, MAE:0.2491+-0.02426, MAPE:0.1761+-0.01598, MSPE:0.0471+-0.00772, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.7534
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2140859
	speed: 0.0597s/iter; left time: 1576.1364s
	iters: 200, epoch: 1 | loss: 0.2342530
	speed: 0.0552s/iter; left time: 1451.6502s
Epoch: 1 cost time: 14.989398956298828
Epoch: 1, Steps: 265 Train Loss: 0.2295 (Forecasting Loss:0.2261 + XiCon Loss:3.3716 x Lambda(0.001)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1678
Validation loss decreased (inf --> 0.207816).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2011822
	speed: 0.0497s/iter; left time: 1298.3672s
	iters: 200, epoch: 2 | loss: 0.2116635
	speed: 0.0528s/iter; left time: 1374.9123s
Epoch: 2 cost time: 13.782715559005737
Epoch: 2, Steps: 265 Train Loss: 0.2053 (Forecasting Loss:0.2019 + XiCon Loss:3.3687 x Lambda(0.001)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1910
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1670512
	speed: 0.0568s/iter; left time: 1468.6499s
	iters: 200, epoch: 3 | loss: 0.1760130
	speed: 0.0495s/iter; left time: 1276.8257s
Epoch: 3 cost time: 13.600454330444336
Epoch: 3, Steps: 265 Train Loss: 0.1735 (Forecasting Loss:0.1701 + XiCon Loss:3.3567 x Lambda(0.001)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.2005
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1397928
	speed: 0.0571s/iter; left time: 1462.5769s
	iters: 200, epoch: 4 | loss: 0.1435804
	speed: 0.0537s/iter; left time: 1368.4868s
Epoch: 4 cost time: 14.684455394744873
Epoch: 4, Steps: 265 Train Loss: 0.1525 (Forecasting Loss:0.1492 + XiCon Loss:3.3481 x Lambda(0.001)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.2201
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1484094
	speed: 0.0533s/iter; left time: 1350.6886s
	iters: 200, epoch: 5 | loss: 0.1295105
	speed: 0.0454s/iter; left time: 1146.3067s
Epoch: 5 cost time: 13.450324296951294
Epoch: 5, Steps: 265 Train Loss: 0.1411 (Forecasting Loss:0.1378 + XiCon Loss:3.3445 x Lambda(0.001)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.2350
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1394075
	speed: 0.0563s/iter; left time: 1412.1633s
	iters: 200, epoch: 6 | loss: 0.1281452
	speed: 0.0524s/iter; left time: 1308.8602s
Epoch: 6 cost time: 14.37070631980896
Epoch: 6, Steps: 265 Train Loss: 0.1356 (Forecasting Loss:0.1323 + XiCon Loss:3.3417 x Lambda(0.001)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.2424
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1300112
	speed: 0.0485s/iter; left time: 1204.4689s
	iters: 200, epoch: 7 | loss: 0.1420411
	speed: 0.0540s/iter; left time: 1334.7339s
Epoch: 7 cost time: 13.801333665847778
Epoch: 7, Steps: 265 Train Loss: 0.1331 (Forecasting Loss:0.1298 + XiCon Loss:3.3416 x Lambda(0.001)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.2471
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1288766
	speed: 0.0555s/iter; left time: 1361.2099s
	iters: 200, epoch: 8 | loss: 0.1502044
	speed: 0.0557s/iter; left time: 1361.8017s
Epoch: 8 cost time: 14.11997652053833
Epoch: 8, Steps: 265 Train Loss: 0.1321 (Forecasting Loss:0.1287 + XiCon Loss:3.3405 x Lambda(0.001)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2502
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1384070
	speed: 0.0571s/iter; left time: 1386.1739s
	iters: 200, epoch: 9 | loss: 0.1202508
	speed: 0.0544s/iter; left time: 1315.1908s
Epoch: 9 cost time: 14.746011018753052
Epoch: 9, Steps: 265 Train Loss: 0.1312 (Forecasting Loss:0.1279 + XiCon Loss:3.3415 x Lambda(0.001)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.2499
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1338298
	speed: 0.0517s/iter; left time: 1241.9866s
	iters: 200, epoch: 10 | loss: 0.1347921
	speed: 0.0444s/iter; left time: 1061.5176s
Epoch: 10 cost time: 13.167129516601562
Epoch: 10, Steps: 265 Train Loss: 0.1310 (Forecasting Loss:0.1277 + XiCon Loss:3.3383 x Lambda(0.001)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2505
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1265817
	speed: 0.0584s/iter; left time: 1387.7156s
	iters: 200, epoch: 11 | loss: 0.1211748
	speed: 0.0545s/iter; left time: 1288.3751s
Epoch: 11 cost time: 14.871557474136353
Epoch: 11, Steps: 265 Train Loss: 0.1310 (Forecasting Loss:0.1277 + XiCon Loss:3.3410 x Lambda(0.001)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.2506
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09777353703975677, mae:0.23774918913841248, mape:0.5715335011482239, mspe:11.842583656311035 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.9514
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2230443
	speed: 0.0558s/iter; left time: 1473.4292s
	iters: 200, epoch: 1 | loss: 0.2139024
	speed: 0.0516s/iter; left time: 1355.9339s
Epoch: 1 cost time: 13.94700574874878
Epoch: 1, Steps: 265 Train Loss: 0.2268 (Forecasting Loss:0.2235 + XiCon Loss:3.3913 x Lambda(0.001)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.211510).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2239861
	speed: 0.0583s/iter; left time: 1522.6732s
	iters: 200, epoch: 2 | loss: 0.1890669
	speed: 0.0547s/iter; left time: 1424.5983s
Epoch: 2 cost time: 14.715306520462036
Epoch: 2, Steps: 265 Train Loss: 0.2030 (Forecasting Loss:0.1996 + XiCon Loss:3.3551 x Lambda(0.001)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1813
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1803762
	speed: 0.0554s/iter; left time: 1433.2904s
	iters: 200, epoch: 3 | loss: 0.1596545
	speed: 0.0466s/iter; left time: 1200.4505s
Epoch: 3 cost time: 13.79099726676941
Epoch: 3, Steps: 265 Train Loss: 0.1667 (Forecasting Loss:0.1634 + XiCon Loss:3.3240 x Lambda(0.001)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.2169
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1314434
	speed: 0.0573s/iter; left time: 1468.1705s
	iters: 200, epoch: 4 | loss: 0.1349851
	speed: 0.0541s/iter; left time: 1380.3376s
Epoch: 4 cost time: 14.575120687484741
Epoch: 4, Steps: 265 Train Loss: 0.1435 (Forecasting Loss:0.1402 + XiCon Loss:3.3239 x Lambda(0.001)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.2399
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1495403
	speed: 0.0495s/iter; left time: 1254.7806s
	iters: 200, epoch: 5 | loss: 0.1285772
	speed: 0.0547s/iter; left time: 1381.4233s
Epoch: 5 cost time: 13.947551965713501
Epoch: 5, Steps: 265 Train Loss: 0.1344 (Forecasting Loss:0.1311 + XiCon Loss:3.3247 x Lambda(0.001)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.2365
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1219158
	speed: 0.0576s/iter; left time: 1444.1489s
	iters: 200, epoch: 6 | loss: 0.1345063
	speed: 0.0503s/iter; left time: 1256.4571s
Epoch: 6 cost time: 13.717827081680298
Epoch: 6, Steps: 265 Train Loss: 0.1299 (Forecasting Loss:0.1266 + XiCon Loss:3.3244 x Lambda(0.001)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.2469
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1321233
	speed: 0.0587s/iter; left time: 1455.4397s
	iters: 200, epoch: 7 | loss: 0.1292496
	speed: 0.0533s/iter; left time: 1317.7158s
Epoch: 7 cost time: 14.88155460357666
Epoch: 7, Steps: 265 Train Loss: 0.1282 (Forecasting Loss:0.1248 + XiCon Loss:3.3268 x Lambda(0.001)), Vali MSE Loss: 0.2315 Test MSE Loss: 0.2521
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1157069
	speed: 0.0509s/iter; left time: 1249.2390s
	iters: 200, epoch: 8 | loss: 0.1284337
	speed: 0.0461s/iter; left time: 1126.8144s
Epoch: 8 cost time: 13.090519189834595
Epoch: 8, Steps: 265 Train Loss: 0.1272 (Forecasting Loss:0.1239 + XiCon Loss:3.3247 x Lambda(0.001)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.2434
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1335944
	speed: 0.0553s/iter; left time: 1341.7438s
	iters: 200, epoch: 9 | loss: 0.1228459
	speed: 0.0531s/iter; left time: 1283.8884s
Epoch: 9 cost time: 14.359103679656982
Epoch: 9, Steps: 265 Train Loss: 0.1267 (Forecasting Loss:0.1234 + XiCon Loss:3.3258 x Lambda(0.001)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.2452
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1239839
	speed: 0.0527s/iter; left time: 1266.2019s
	iters: 200, epoch: 10 | loss: 0.1291935
	speed: 0.0550s/iter; left time: 1316.2288s
Epoch: 10 cost time: 14.259161710739136
Epoch: 10, Steps: 265 Train Loss: 0.1263 (Forecasting Loss:0.1230 + XiCon Loss:3.3251 x Lambda(0.001)), Vali MSE Loss: 0.2310 Test MSE Loss: 0.2466
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1359323
	speed: 0.0533s/iter; left time: 1264.8006s
	iters: 200, epoch: 11 | loss: 0.1314110
	speed: 0.0513s/iter; left time: 1214.0108s
Epoch: 11 cost time: 13.466373443603516
Epoch: 11, Steps: 265 Train Loss: 0.1263 (Forecasting Loss:0.1230 + XiCon Loss:3.3251 x Lambda(0.001)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.2457
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09923629462718964, mae:0.23903968930244446, mape:0.578664243221283, mspe:12.326769828796387 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.8339
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2165906
	speed: 0.0339s/iter; left time: 895.7632s
	iters: 200, epoch: 1 | loss: 0.2178522
	speed: 0.0303s/iter; left time: 796.9000s
Epoch: 1 cost time: 9.542288780212402
Epoch: 1, Steps: 265 Train Loss: 0.2276 (Forecasting Loss:0.2243 + XiCon Loss:3.3768 x Lambda(0.001)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1678
Validation loss decreased (inf --> 0.207590).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2105876
	speed: 0.0563s/iter; left time: 1472.4961s
	iters: 200, epoch: 2 | loss: 0.1825286
	speed: 0.0547s/iter; left time: 1425.4411s
Epoch: 2 cost time: 14.654814720153809
Epoch: 2, Steps: 265 Train Loss: 0.1979 (Forecasting Loss:0.1945 + XiCon Loss:3.3642 x Lambda(0.001)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.1909
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1708639
	speed: 0.0596s/iter; left time: 1540.8425s
	iters: 200, epoch: 3 | loss: 0.1514975
	speed: 0.0494s/iter; left time: 1273.6943s
Epoch: 3 cost time: 13.87559986114502
Epoch: 3, Steps: 265 Train Loss: 0.1636 (Forecasting Loss:0.1602 + XiCon Loss:3.3562 x Lambda(0.001)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.2129
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1441994
	speed: 0.0317s/iter; left time: 812.3689s
	iters: 200, epoch: 4 | loss: 0.1322337
	speed: 0.0499s/iter; left time: 1272.6789s
Epoch: 4 cost time: 11.717407464981079
Epoch: 4, Steps: 265 Train Loss: 0.1393 (Forecasting Loss:0.1360 + XiCon Loss:3.3529 x Lambda(0.001)), Vali MSE Loss: 0.2543 Test MSE Loss: 0.2352
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1149652
	speed: 0.0565s/iter; left time: 1432.8757s
	iters: 200, epoch: 5 | loss: 0.1239717
	speed: 0.0556s/iter; left time: 1402.1379s
Epoch: 5 cost time: 14.903431177139282
Epoch: 5, Steps: 265 Train Loss: 0.1298 (Forecasting Loss:0.1264 + XiCon Loss:3.3516 x Lambda(0.001)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.2473
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1252725
	speed: 0.0482s/iter; left time: 1208.2849s
	iters: 200, epoch: 6 | loss: 0.1261810
	speed: 0.0315s/iter; left time: 785.5980s
Epoch: 6 cost time: 9.942777872085571
Epoch: 6, Steps: 265 Train Loss: 0.1252 (Forecasting Loss:0.1218 + XiCon Loss:3.3495 x Lambda(0.001)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2500
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1253357
	speed: 0.0571s/iter; left time: 1417.0036s
	iters: 200, epoch: 7 | loss: 0.1230134
	speed: 0.0545s/iter; left time: 1346.4620s
Epoch: 7 cost time: 14.875324487686157
Epoch: 7, Steps: 265 Train Loss: 0.1231 (Forecasting Loss:0.1197 + XiCon Loss:3.3491 x Lambda(0.001)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.2516
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1287195
	speed: 0.0569s/iter; left time: 1396.0309s
	iters: 200, epoch: 8 | loss: 0.1211285
	speed: 0.0514s/iter; left time: 1255.7487s
Epoch: 8 cost time: 13.739738702774048
Epoch: 8, Steps: 265 Train Loss: 0.1223 (Forecasting Loss:0.1189 + XiCon Loss:3.3484 x Lambda(0.001)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.2512
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1085467
	speed: 0.0328s/iter; left time: 796.9523s
	iters: 200, epoch: 9 | loss: 0.1203354
	speed: 0.0500s/iter; left time: 1208.6562s
Epoch: 9 cost time: 11.89441180229187
Epoch: 9, Steps: 265 Train Loss: 0.1217 (Forecasting Loss:0.1183 + XiCon Loss:3.3496 x Lambda(0.001)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2516
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1137556
	speed: 0.0595s/iter; left time: 1429.3023s
	iters: 200, epoch: 10 | loss: 0.1181453
	speed: 0.0557s/iter; left time: 1332.7277s
Epoch: 10 cost time: 15.114738941192627
Epoch: 10, Steps: 265 Train Loss: 0.1216 (Forecasting Loss:0.1182 + XiCon Loss:3.3488 x Lambda(0.001)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.2525
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1281263
	speed: 0.0498s/iter; left time: 1182.0816s
	iters: 200, epoch: 11 | loss: 0.1121876
	speed: 0.0370s/iter; left time: 874.1939s
Epoch: 11 cost time: 10.560804843902588
Epoch: 11, Steps: 265 Train Loss: 0.1214 (Forecasting Loss:0.1181 + XiCon Loss:3.3478 x Lambda(0.001)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.2526
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0980229526758194, mae:0.23758864402770996, mape:0.5698843002319336, mspe:11.693916320800781 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.2971
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2006746
	speed: 0.0573s/iter; left time: 1513.0009s
	iters: 200, epoch: 1 | loss: 0.1965973
	speed: 0.0478s/iter; left time: 1256.7289s
Epoch: 1 cost time: 13.40369725227356
Epoch: 1, Steps: 265 Train Loss: 0.2287 (Forecasting Loss:0.2253 + XiCon Loss:3.3505 x Lambda(0.001)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1682
Validation loss decreased (inf --> 0.210298).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2040139
	speed: 0.0312s/iter; left time: 815.4229s
	iters: 200, epoch: 2 | loss: 0.1876257
	speed: 0.0472s/iter; left time: 1227.9218s
Epoch: 2 cost time: 11.550686120986938
Epoch: 2, Steps: 265 Train Loss: 0.2039 (Forecasting Loss:0.2005 + XiCon Loss:3.3852 x Lambda(0.001)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1980
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1856132
	speed: 0.0579s/iter; left time: 1498.2490s
	iters: 200, epoch: 3 | loss: 0.1591124
	speed: 0.0541s/iter; left time: 1394.3164s
Epoch: 3 cost time: 14.783132076263428
Epoch: 3, Steps: 265 Train Loss: 0.1715 (Forecasting Loss:0.1681 + XiCon Loss:3.3761 x Lambda(0.001)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2260
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1491138
	speed: 0.0495s/iter; left time: 1266.8167s
	iters: 200, epoch: 4 | loss: 0.1480274
	speed: 0.0332s/iter; left time: 846.8158s
Epoch: 4 cost time: 10.171921491622925
Epoch: 4, Steps: 265 Train Loss: 0.1452 (Forecasting Loss:0.1419 + XiCon Loss:3.3731 x Lambda(0.001)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.2317
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1294678
	speed: 0.0588s/iter; left time: 1489.4787s
	iters: 200, epoch: 5 | loss: 0.1307609
	speed: 0.0573s/iter; left time: 1446.1844s
Epoch: 5 cost time: 15.283262729644775
Epoch: 5, Steps: 265 Train Loss: 0.1338 (Forecasting Loss:0.1304 + XiCon Loss:3.3716 x Lambda(0.001)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2583
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1239979
	speed: 0.0569s/iter; left time: 1427.3368s
	iters: 200, epoch: 6 | loss: 0.1364426
	speed: 0.0502s/iter; left time: 1254.5872s
Epoch: 6 cost time: 13.748570442199707
Epoch: 6, Steps: 265 Train Loss: 0.1289 (Forecasting Loss:0.1256 + XiCon Loss:3.3723 x Lambda(0.001)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2611
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1271637
	speed: 0.0332s/iter; left time: 823.9649s
	iters: 200, epoch: 7 | loss: 0.1327266
	speed: 0.0474s/iter; left time: 1170.1243s
Epoch: 7 cost time: 11.866929054260254
Epoch: 7, Steps: 265 Train Loss: 0.1272 (Forecasting Loss:0.1238 + XiCon Loss:3.3724 x Lambda(0.001)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2623
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1316491
	speed: 0.0615s/iter; left time: 1508.6475s
	iters: 200, epoch: 8 | loss: 0.1225798
	speed: 0.0549s/iter; left time: 1342.3559s
Epoch: 8 cost time: 15.18452501296997
Epoch: 8, Steps: 265 Train Loss: 0.1261 (Forecasting Loss:0.1227 + XiCon Loss:3.3720 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2654
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1321625
	speed: 0.0508s/iter; left time: 1234.5488s
	iters: 200, epoch: 9 | loss: 0.1225987
	speed: 0.0538s/iter; left time: 1300.4560s
Epoch: 9 cost time: 14.154998540878296
Epoch: 9, Steps: 265 Train Loss: 0.1256 (Forecasting Loss:0.1222 + XiCon Loss:3.3718 x Lambda(0.001)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2671
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1290116
	speed: 0.0563s/iter; left time: 1351.7585s
	iters: 200, epoch: 10 | loss: 0.1232086
	speed: 0.0582s/iter; left time: 1391.2490s
Epoch: 10 cost time: 15.0761559009552
Epoch: 10, Steps: 265 Train Loss: 0.1252 (Forecasting Loss:0.1218 + XiCon Loss:3.3719 x Lambda(0.001)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2662
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1243229
	speed: 0.0488s/iter; left time: 1158.5225s
	iters: 200, epoch: 11 | loss: 0.1183162
	speed: 0.0543s/iter; left time: 1283.6775s
Epoch: 11 cost time: 13.771162271499634
Epoch: 11, Steps: 265 Train Loss: 0.1253 (Forecasting Loss:0.1219 + XiCon Loss:3.3716 x Lambda(0.001)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2675
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09839289635419846, mae:0.2380160540342331, mape:0.5735026001930237, mspe:12.128968238830566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.2170
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2135338
	speed: 0.0530s/iter; left time: 1400.3883s
	iters: 200, epoch: 1 | loss: 0.2181394
	speed: 0.0560s/iter; left time: 1473.4058s
Epoch: 1 cost time: 14.566035032272339
Epoch: 1, Steps: 265 Train Loss: 0.2295 (Forecasting Loss:0.2261 + XiCon Loss:3.3834 x Lambda(0.001)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.210356).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2015048
	speed: 0.0549s/iter; left time: 1435.5105s
	iters: 200, epoch: 2 | loss: 0.2143706
	speed: 0.0543s/iter; left time: 1414.6167s
Epoch: 2 cost time: 14.324214458465576
Epoch: 2, Steps: 265 Train Loss: 0.2061 (Forecasting Loss:0.2027 + XiCon Loss:3.3742 x Lambda(0.001)), Vali MSE Loss: 0.2239 Test MSE Loss: 0.1888
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1731058
	speed: 0.0510s/iter; left time: 1320.6486s
	iters: 200, epoch: 3 | loss: 0.1683416
	speed: 0.0538s/iter; left time: 1385.8456s
Epoch: 3 cost time: 14.017871856689453
Epoch: 3, Steps: 265 Train Loss: 0.1809 (Forecasting Loss:0.1775 + XiCon Loss:3.3653 x Lambda(0.001)), Vali MSE Loss: 0.2240 Test MSE Loss: 0.1858
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1464033
	speed: 0.0586s/iter; left time: 1501.2005s
	iters: 200, epoch: 4 | loss: 0.1588605
	speed: 0.0572s/iter; left time: 1459.2555s
Epoch: 4 cost time: 15.018002271652222
Epoch: 4, Steps: 265 Train Loss: 0.1567 (Forecasting Loss:0.1533 + XiCon Loss:3.3619 x Lambda(0.001)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.2061
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1479501
	speed: 0.0511s/iter; left time: 1295.6105s
	iters: 200, epoch: 5 | loss: 0.1320167
	speed: 0.0551s/iter; left time: 1392.0223s
Epoch: 5 cost time: 14.449295282363892
Epoch: 5, Steps: 265 Train Loss: 0.1454 (Forecasting Loss:0.1420 + XiCon Loss:3.3667 x Lambda(0.001)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.2093
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1604339
	speed: 0.0578s/iter; left time: 1448.1410s
	iters: 200, epoch: 6 | loss: 0.1256389
	speed: 0.0561s/iter; left time: 1401.3999s
Epoch: 6 cost time: 14.776679992675781
Epoch: 6, Steps: 265 Train Loss: 0.1407 (Forecasting Loss:0.1374 + XiCon Loss:3.3678 x Lambda(0.001)), Vali MSE Loss: 0.2245 Test MSE Loss: 0.2236
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1380182
	speed: 0.0512s/iter; left time: 1271.4366s
	iters: 200, epoch: 7 | loss: 0.1440558
	speed: 0.0562s/iter; left time: 1388.5987s
Epoch: 7 cost time: 14.43502926826477
Epoch: 7, Steps: 265 Train Loss: 0.1385 (Forecasting Loss:0.1351 + XiCon Loss:3.3696 x Lambda(0.001)), Vali MSE Loss: 0.2243 Test MSE Loss: 0.2169
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1387731
	speed: 0.0583s/iter; left time: 1430.3270s
	iters: 200, epoch: 8 | loss: 0.1402987
	speed: 0.0544s/iter; left time: 1328.7296s
Epoch: 8 cost time: 14.601664781570435
Epoch: 8, Steps: 265 Train Loss: 0.1372 (Forecasting Loss:0.1338 + XiCon Loss:3.3694 x Lambda(0.001)), Vali MSE Loss: 0.2239 Test MSE Loss: 0.2200
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1300162
	speed: 0.0539s/iter; left time: 1309.3101s
	iters: 200, epoch: 9 | loss: 0.1359205
	speed: 0.0559s/iter; left time: 1350.7362s
Epoch: 9 cost time: 14.585061073303223
Epoch: 9, Steps: 265 Train Loss: 0.1366 (Forecasting Loss:0.1332 + XiCon Loss:3.3717 x Lambda(0.001)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.2203
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1232443
	speed: 0.0580s/iter; left time: 1392.1877s
	iters: 200, epoch: 10 | loss: 0.1555510
	speed: 0.0544s/iter; left time: 1301.8055s
Epoch: 10 cost time: 14.786768674850464
Epoch: 10, Steps: 265 Train Loss: 0.1364 (Forecasting Loss:0.1330 + XiCon Loss:3.3703 x Lambda(0.001)), Vali MSE Loss: 0.2232 Test MSE Loss: 0.2215
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1314674
	speed: 0.0540s/iter; left time: 1281.5201s
	iters: 200, epoch: 11 | loss: 0.1343377
	speed: 0.0575s/iter; left time: 1359.2549s
Epoch: 11 cost time: 14.93910026550293
Epoch: 11, Steps: 265 Train Loss: 0.1363 (Forecasting Loss:0.1329 + XiCon Loss:3.3703 x Lambda(0.001)), Vali MSE Loss: 0.2232 Test MSE Loss: 0.2219
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09847083687782288, mae:0.23822852969169617, mape:0.5798730850219727, mspe:12.528767585754395 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0984+-0.00069, MAE:0.2381+-0.00070, MAPE:0.5747+-0.00545, MSPE:12.1042+-0.42434, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.9930
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4295347
	speed: 0.0833s/iter; left time: 2123.8519s
	iters: 200, epoch: 1 | loss: 0.4638121
	speed: 0.0768s/iter; left time: 1951.6995s
Epoch: 1 cost time: 20.45089554786682
Epoch: 1, Steps: 256 Train Loss: 0.4376 (Forecasting Loss:0.4343 + XiCon Loss:3.3786 x Lambda(0.001)), Vali MSE Loss: 0.4129 Test MSE Loss: 0.3828
Validation loss decreased (inf --> 0.412855).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3295241
	speed: 0.0697s/iter; left time: 1760.7084s
	iters: 200, epoch: 2 | loss: 0.3372762
	speed: 0.0813s/iter; left time: 2044.2913s
Epoch: 2 cost time: 19.553588151931763
Epoch: 2, Steps: 256 Train Loss: 0.3430 (Forecasting Loss:0.3397 + XiCon Loss:3.3807 x Lambda(0.001)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3036
Validation loss decreased (0.412855 --> 0.327717).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3194764
	speed: 0.0809s/iter; left time: 2020.5681s
	iters: 200, epoch: 3 | loss: 0.3260796
	speed: 0.0707s/iter; left time: 1759.2507s
Epoch: 3 cost time: 19.246872425079346
Epoch: 3, Steps: 256 Train Loss: 0.3192 (Forecasting Loss:0.3158 + XiCon Loss:3.3708 x Lambda(0.001)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.3005
Validation loss decreased (0.327717 --> 0.320982).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3244765
	speed: 0.0818s/iter; left time: 2022.5782s
	iters: 200, epoch: 4 | loss: 0.3186540
	speed: 0.0813s/iter; left time: 2003.6489s
Epoch: 4 cost time: 20.83625340461731
Epoch: 4, Steps: 256 Train Loss: 0.3165 (Forecasting Loss:0.3131 + XiCon Loss:3.3713 x Lambda(0.001)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.3000
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3267127
	speed: 0.0690s/iter; left time: 1687.9301s
	iters: 200, epoch: 5 | loss: 0.3364162
	speed: 0.0807s/iter; left time: 1966.3569s
Epoch: 5 cost time: 19.48905372619629
Epoch: 5, Steps: 256 Train Loss: 0.3155 (Forecasting Loss:0.3121 + XiCon Loss:3.3709 x Lambda(0.001)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3051836
	speed: 0.0819s/iter; left time: 1982.5256s
	iters: 200, epoch: 6 | loss: 0.2898366
	speed: 0.0723s/iter; left time: 1743.3736s
Epoch: 6 cost time: 19.3501033782959
Epoch: 6, Steps: 256 Train Loss: 0.3150 (Forecasting Loss:0.3116 + XiCon Loss:3.3709 x Lambda(0.001)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2995
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3328969
	speed: 0.0825s/iter; left time: 1976.4089s
	iters: 200, epoch: 7 | loss: 0.3041037
	speed: 0.0803s/iter; left time: 1916.2650s
Epoch: 7 cost time: 20.748602867126465
Epoch: 7, Steps: 256 Train Loss: 0.3148 (Forecasting Loss:0.3114 + XiCon Loss:3.3714 x Lambda(0.001)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2994
Validation loss decreased (0.320982 --> 0.320944).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3120454
	speed: 0.0686s/iter; left time: 1627.1657s
	iters: 200, epoch: 8 | loss: 0.2969244
	speed: 0.0777s/iter; left time: 1835.5763s
Epoch: 8 cost time: 19.184173822402954
Epoch: 8, Steps: 256 Train Loss: 0.3147 (Forecasting Loss:0.3114 + XiCon Loss:3.3719 x Lambda(0.001)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2995
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3440965
	speed: 0.0797s/iter; left time: 1868.8952s
	iters: 200, epoch: 9 | loss: 0.3163030
	speed: 0.0757s/iter; left time: 1767.6506s
Epoch: 9 cost time: 19.292744874954224
Epoch: 9, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3112 + XiCon Loss:3.3723 x Lambda(0.001)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2995
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3193475
	speed: 0.0814s/iter; left time: 1887.3353s
	iters: 200, epoch: 10 | loss: 0.3257077
	speed: 0.0791s/iter; left time: 1826.1454s
Epoch: 10 cost time: 20.73084568977356
Epoch: 10, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3710 x Lambda(0.001)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2995
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3246570
	speed: 0.0717s/iter; left time: 1645.1845s
	iters: 200, epoch: 11 | loss: 0.3315755
	speed: 0.0759s/iter; left time: 1733.8790s
Epoch: 11 cost time: 19.377296686172485
Epoch: 11, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3724 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3210344
	speed: 0.0837s/iter; left time: 1899.6627s
	iters: 200, epoch: 12 | loss: 0.3047752
	speed: 0.0754s/iter; left time: 1702.3702s
Epoch: 12 cost time: 19.599361658096313
Epoch: 12, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3112 + XiCon Loss:3.3718 x Lambda(0.001)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.2995
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3220960
	speed: 0.0796s/iter; left time: 1784.5786s
	iters: 200, epoch: 13 | loss: 0.3129119
	speed: 0.0813s/iter; left time: 1814.7438s
Epoch: 13 cost time: 20.678303241729736
Epoch: 13, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3727 x Lambda(0.001)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2995
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3100516
	speed: 0.0703s/iter; left time: 1559.3028s
	iters: 200, epoch: 14 | loss: 0.3080886
	speed: 0.0781s/iter; left time: 1723.9603s
Epoch: 14 cost time: 19.229681730270386
Epoch: 14, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3111 + XiCon Loss:3.3713 x Lambda(0.001)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2995
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3231255
	speed: 0.0814s/iter; left time: 1782.9881s
	iters: 200, epoch: 15 | loss: 0.2976358
	speed: 0.0764s/iter; left time: 1667.2222s
Epoch: 15 cost time: 19.451229095458984
Epoch: 15, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3710 x Lambda(0.001)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2995
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3456196
	speed: 0.0807s/iter; left time: 1748.7770s
	iters: 200, epoch: 16 | loss: 0.3047611
	speed: 0.0776s/iter; left time: 1673.9068s
Epoch: 16 cost time: 20.23212504386902
Epoch: 16, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3711 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2995
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2981793
	speed: 0.0736s/iter; left time: 1574.5632s
	iters: 200, epoch: 17 | loss: 0.3213241
	speed: 0.0574s/iter; left time: 1223.0612s
Epoch: 17 cost time: 18.745689868927002
Epoch: 17, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3111 + XiCon Loss:3.3705 x Lambda(0.001)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2995
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22584810853004456, mae:0.37288451194763184, mape:0.7442099452018738, mspe:18.80574607849121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.1796
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4757170
	speed: 0.0790s/iter; left time: 2015.0163s
	iters: 200, epoch: 1 | loss: 0.4511199
	speed: 0.0743s/iter; left time: 1887.5618s
Epoch: 1 cost time: 19.051111221313477
Epoch: 1, Steps: 256 Train Loss: 0.4342 (Forecasting Loss:0.4309 + XiCon Loss:3.3697 x Lambda(0.001)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3794
Validation loss decreased (inf --> 0.409491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3443582
	speed: 0.0437s/iter; left time: 1103.1951s
	iters: 200, epoch: 2 | loss: 0.3172104
	speed: 0.0765s/iter; left time: 1924.1035s
Epoch: 2 cost time: 16.49652099609375
Epoch: 2, Steps: 256 Train Loss: 0.3491 (Forecasting Loss:0.3458 + XiCon Loss:3.3651 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2976
Validation loss decreased (0.409491 --> 0.320553).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3129904
	speed: 0.0799s/iter; left time: 1996.2344s
	iters: 200, epoch: 3 | loss: 0.3278750
	speed: 0.0742s/iter; left time: 1848.0053s
Epoch: 3 cost time: 18.909552335739136
Epoch: 3, Steps: 256 Train Loss: 0.3206 (Forecasting Loss:0.3173 + XiCon Loss:3.3590 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2968
Validation loss decreased (0.320553 --> 0.319622).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3384881
	speed: 0.0595s/iter; left time: 1471.1442s
	iters: 200, epoch: 4 | loss: 0.3128627
	speed: 0.0789s/iter; left time: 1942.9876s
Epoch: 4 cost time: 18.179494619369507
Epoch: 4, Steps: 256 Train Loss: 0.3174 (Forecasting Loss:0.3140 + XiCon Loss:3.3573 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2967
Validation loss decreased (0.319622 --> 0.318247).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2921501
	speed: 0.0826s/iter; left time: 2020.6190s
	iters: 200, epoch: 5 | loss: 0.3393167
	speed: 0.0680s/iter; left time: 1658.2056s
Epoch: 5 cost time: 17.617631912231445
Epoch: 5, Steps: 256 Train Loss: 0.3163 (Forecasting Loss:0.3129 + XiCon Loss:3.3570 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2965
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3459833
	speed: 0.0756s/iter; left time: 1830.8515s
	iters: 200, epoch: 6 | loss: 0.3069380
	speed: 0.0785s/iter; left time: 1893.9098s
Epoch: 6 cost time: 19.888206481933594
Epoch: 6, Steps: 256 Train Loss: 0.3158 (Forecasting Loss:0.3124 + XiCon Loss:3.3572 x Lambda(0.001)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.2965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3306239
	speed: 0.0802s/iter; left time: 1921.3712s
	iters: 200, epoch: 7 | loss: 0.3201929
	speed: 0.0607s/iter; left time: 1449.6976s
Epoch: 7 cost time: 16.397555112838745
Epoch: 7, Steps: 256 Train Loss: 0.3155 (Forecasting Loss:0.3121 + XiCon Loss:3.3550 x Lambda(0.001)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2966
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2949609
	speed: 0.0811s/iter; left time: 1922.9610s
	iters: 200, epoch: 8 | loss: 0.3068859
	speed: 0.0791s/iter; left time: 1868.1570s
Epoch: 8 cost time: 20.40985655784607
Epoch: 8, Steps: 256 Train Loss: 0.3153 (Forecasting Loss:0.3120 + XiCon Loss:3.3568 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2965
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3074137
	speed: 0.0759s/iter; left time: 1779.7310s
	iters: 200, epoch: 9 | loss: 0.3504237
	speed: 0.0524s/iter; left time: 1222.5701s
Epoch: 9 cost time: 15.120084047317505
Epoch: 9, Steps: 256 Train Loss: 0.3152 (Forecasting Loss:0.3119 + XiCon Loss:3.3563 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2965
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3178520
	speed: 0.0805s/iter; left time: 1867.5902s
	iters: 200, epoch: 10 | loss: 0.3116255
	speed: 0.0767s/iter; left time: 1772.3693s
Epoch: 10 cost time: 20.21525549888611
Epoch: 10, Steps: 256 Train Loss: 0.3155 (Forecasting Loss:0.3121 + XiCon Loss:3.3576 x Lambda(0.001)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2965
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3129908
	speed: 0.0744s/iter; left time: 1707.0711s
	iters: 200, epoch: 11 | loss: 0.3422479
	speed: 0.0462s/iter; left time: 1055.2365s
Epoch: 11 cost time: 15.416157007217407
Epoch: 11, Steps: 256 Train Loss: 0.3153 (Forecasting Loss:0.3119 + XiCon Loss:3.3576 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2965
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3203573
	speed: 0.0822s/iter; left time: 1863.6863s
	iters: 200, epoch: 12 | loss: 0.3296366
	speed: 0.0786s/iter; left time: 1776.2607s
Epoch: 12 cost time: 20.51714253425598
Epoch: 12, Steps: 256 Train Loss: 0.3154 (Forecasting Loss:0.3121 + XiCon Loss:3.3577 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2965
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3052567
	speed: 0.0668s/iter; left time: 1497.5779s
	iters: 200, epoch: 13 | loss: 0.3349181
	speed: 0.0406s/iter; left time: 906.0072s
Epoch: 13 cost time: 14.910573720932007
Epoch: 13, Steps: 256 Train Loss: 0.3152 (Forecasting Loss:0.3119 + XiCon Loss:3.3572 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2965
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3207766
	speed: 0.0822s/iter; left time: 1821.5615s
	iters: 200, epoch: 14 | loss: 0.3136185
	speed: 0.0784s/iter; left time: 1729.6079s
Epoch: 14 cost time: 20.592846393585205
Epoch: 14, Steps: 256 Train Loss: 0.3152 (Forecasting Loss:0.3119 + XiCon Loss:3.3568 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2965
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22224362194538116, mae:0.37110453844070435, mape:0.7442964911460876, mspe:19.088584899902344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.1457
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4877154
	speed: 0.0773s/iter; left time: 1971.2456s
	iters: 200, epoch: 1 | loss: 0.4326598
	speed: 0.0733s/iter; left time: 1861.0014s
Epoch: 1 cost time: 18.131239652633667
Epoch: 1, Steps: 256 Train Loss: 0.4363 (Forecasting Loss:0.4329 + XiCon Loss:3.3948 x Lambda(0.001)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3773
Validation loss decreased (inf --> 0.405987).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3311179
	speed: 0.0731s/iter; left time: 1845.3717s
	iters: 200, epoch: 2 | loss: 0.3272675
	speed: 0.0741s/iter; left time: 1862.9914s
Epoch: 2 cost time: 18.765031814575195
Epoch: 2, Steps: 256 Train Loss: 0.3454 (Forecasting Loss:0.3420 + XiCon Loss:3.3844 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.3025
Validation loss decreased (0.405987 --> 0.313502).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3093061
	speed: 0.0782s/iter; left time: 1955.1265s
	iters: 200, epoch: 3 | loss: 0.3242500
	speed: 0.0572s/iter; left time: 1422.8538s
Epoch: 3 cost time: 17.33263349533081
Epoch: 3, Steps: 256 Train Loss: 0.3185 (Forecasting Loss:0.3151 + XiCon Loss:3.3815 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.3042
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3107462
	speed: 0.0781s/iter; left time: 1932.7419s
	iters: 200, epoch: 4 | loss: 0.3098404
	speed: 0.0749s/iter; left time: 1845.5636s
Epoch: 4 cost time: 19.41428017616272
Epoch: 4, Steps: 256 Train Loss: 0.3159 (Forecasting Loss:0.3125 + XiCon Loss:3.3776 x Lambda(0.001)), Vali MSE Loss: 0.3125 Test MSE Loss: 0.3026
Validation loss decreased (0.313502 --> 0.312502).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3036445
	speed: 0.0601s/iter; left time: 1471.4508s
	iters: 200, epoch: 5 | loss: 0.3068950
	speed: 0.0662s/iter; left time: 1614.0509s
Epoch: 5 cost time: 17.056335926055908
Epoch: 5, Steps: 256 Train Loss: 0.3148 (Forecasting Loss:0.3114 + XiCon Loss:3.3788 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.3025
Validation loss decreased (0.312502 --> 0.311686).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3452897
	speed: 0.0767s/iter; left time: 1856.9576s
	iters: 200, epoch: 6 | loss: 0.3208388
	speed: 0.0764s/iter; left time: 1843.5895s
Epoch: 6 cost time: 18.97851061820984
Epoch: 6, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3783 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.3022
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3451170
	speed: 0.0737s/iter; left time: 1766.3502s
	iters: 200, epoch: 7 | loss: 0.3297344
	speed: 0.0755s/iter; left time: 1802.4102s
Epoch: 7 cost time: 19.10431170463562
Epoch: 7, Steps: 256 Train Loss: 0.3141 (Forecasting Loss:0.3107 + XiCon Loss:3.3795 x Lambda(0.001)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.3019
Validation loss decreased (0.311686 --> 0.311127).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2872187
	speed: 0.0754s/iter; left time: 1787.1251s
	iters: 200, epoch: 8 | loss: 0.3034088
	speed: 0.0589s/iter; left time: 1390.1044s
Epoch: 8 cost time: 17.253599405288696
Epoch: 8, Steps: 256 Train Loss: 0.3140 (Forecasting Loss:0.3106 + XiCon Loss:3.3792 x Lambda(0.001)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.3019
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3323137
	speed: 0.0781s/iter; left time: 1832.4115s
	iters: 200, epoch: 9 | loss: 0.3242483
	speed: 0.0736s/iter; left time: 1718.8656s
Epoch: 9 cost time: 19.44179892539978
Epoch: 9, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3106 + XiCon Loss:3.3792 x Lambda(0.001)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.3021
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3220907
	speed: 0.0644s/iter; left time: 1493.1785s
	iters: 200, epoch: 10 | loss: 0.3150385
	speed: 0.0720s/iter; left time: 1662.3310s
Epoch: 10 cost time: 17.862204790115356
Epoch: 10, Steps: 256 Train Loss: 0.3140 (Forecasting Loss:0.3106 + XiCon Loss:3.3775 x Lambda(0.001)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.3021
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3302675
	speed: 0.0756s/iter; left time: 1734.4947s
	iters: 200, epoch: 11 | loss: 0.3116165
	speed: 0.0739s/iter; left time: 1687.9476s
Epoch: 11 cost time: 18.362099409103394
Epoch: 11, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3105 + XiCon Loss:3.3785 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3109661
	speed: 0.0735s/iter; left time: 1667.3984s
	iters: 200, epoch: 12 | loss: 0.3335842
	speed: 0.0733s/iter; left time: 1655.7644s
Epoch: 12 cost time: 18.869752883911133
Epoch: 12, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3105 + XiCon Loss:3.3780 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3020
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3001519
	speed: 0.0772s/iter; left time: 1731.6584s
	iters: 200, epoch: 13 | loss: 0.3016103
	speed: 0.0595s/iter; left time: 1329.6790s
Epoch: 13 cost time: 17.306065559387207
Epoch: 13, Steps: 256 Train Loss: 0.3138 (Forecasting Loss:0.3105 + XiCon Loss:3.3788 x Lambda(0.001)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.3020
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3139268
	speed: 0.0773s/iter; left time: 1713.1165s
	iters: 200, epoch: 14 | loss: 0.3082899
	speed: 0.0744s/iter; left time: 1643.2897s
Epoch: 14 cost time: 19.633504390716553
Epoch: 14, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3105 + XiCon Loss:3.3774 x Lambda(0.001)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.3020
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2998954
	speed: 0.0616s/iter; left time: 1351.0589s
	iters: 200, epoch: 15 | loss: 0.3027961
	speed: 0.0662s/iter; left time: 1443.4429s
Epoch: 15 cost time: 17.15574026107788
Epoch: 15, Steps: 256 Train Loss: 0.3138 (Forecasting Loss:0.3105 + XiCon Loss:3.3785 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3020
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2747358
	speed: 0.0766s/iter; left time: 1660.2014s
	iters: 200, epoch: 16 | loss: 0.2994536
	speed: 0.0746s/iter; left time: 1609.1565s
Epoch: 16 cost time: 18.52314567565918
Epoch: 16, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3105 + XiCon Loss:3.3781 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3020
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3086960
	speed: 0.0705s/iter; left time: 1509.5329s
	iters: 200, epoch: 17 | loss: 0.3270068
	speed: 0.0769s/iter; left time: 1638.8682s
Epoch: 17 cost time: 18.837321043014526
Epoch: 17, Steps: 256 Train Loss: 0.3139 (Forecasting Loss:0.3106 + XiCon Loss:3.3800 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3020
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22841563820838928, mae:0.37540143728256226, mape:0.7491980195045471, mspe:18.886011123657227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.5602
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4079501
	speed: 0.0839s/iter; left time: 2140.4041s
	iters: 200, epoch: 1 | loss: 0.4136539
	speed: 0.0781s/iter; left time: 1983.1887s
Epoch: 1 cost time: 20.69431209564209
Epoch: 1, Steps: 256 Train Loss: 0.4364 (Forecasting Loss:0.4330 + XiCon Loss:3.3737 x Lambda(0.001)), Vali MSE Loss: 0.4104 Test MSE Loss: 0.3797
Validation loss decreased (inf --> 0.410429).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3647877
	speed: 0.0733s/iter; left time: 1850.3070s
	iters: 200, epoch: 2 | loss: 0.3183663
	speed: 0.0785s/iter; left time: 1972.7162s
Epoch: 2 cost time: 19.82970404624939
Epoch: 2, Steps: 256 Train Loss: 0.3514 (Forecasting Loss:0.3481 + XiCon Loss:3.3658 x Lambda(0.001)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3062
Validation loss decreased (0.410429 --> 0.338254).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3336377
	speed: 0.0825s/iter; left time: 2062.1286s
	iters: 200, epoch: 3 | loss: 0.3221074
	speed: 0.0691s/iter; left time: 1720.3154s
Epoch: 3 cost time: 19.17111110687256
Epoch: 3, Steps: 256 Train Loss: 0.3245 (Forecasting Loss:0.3211 + XiCon Loss:3.3595 x Lambda(0.001)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3044
Validation loss decreased (0.338254 --> 0.333289).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3033381
	speed: 0.0832s/iter; left time: 2057.7930s
	iters: 200, epoch: 4 | loss: 0.3120483
	speed: 0.0802s/iter; left time: 1976.6742s
Epoch: 4 cost time: 20.998886585235596
Epoch: 4, Steps: 256 Train Loss: 0.3181 (Forecasting Loss:0.3147 + XiCon Loss:3.3661 x Lambda(0.001)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.3061
Validation loss decreased (0.333289 --> 0.328751).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3111605
	speed: 0.0706s/iter; left time: 1726.8618s
	iters: 200, epoch: 5 | loss: 0.3277671
	speed: 0.0768s/iter; left time: 1872.5290s
Epoch: 5 cost time: 19.345587491989136
Epoch: 5, Steps: 256 Train Loss: 0.3158 (Forecasting Loss:0.3125 + XiCon Loss:3.3701 x Lambda(0.001)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.3050
Validation loss decreased (0.328751 --> 0.326595).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3240281
	speed: 0.0817s/iter; left time: 1978.0759s
	iters: 200, epoch: 6 | loss: 0.3114769
	speed: 0.0739s/iter; left time: 1783.4564s
Epoch: 6 cost time: 19.45702290534973
Epoch: 6, Steps: 256 Train Loss: 0.3150 (Forecasting Loss:0.3117 + XiCon Loss:3.3720 x Lambda(0.001)), Vali MSE Loss: 0.3256 Test MSE Loss: 0.3053
Validation loss decreased (0.326595 --> 0.325571).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3104896
	speed: 0.0814s/iter; left time: 1950.4805s
	iters: 200, epoch: 7 | loss: 0.3133886
	speed: 0.0778s/iter; left time: 1857.6475s
Epoch: 7 cost time: 20.364726066589355
Epoch: 7, Steps: 256 Train Loss: 0.3147 (Forecasting Loss:0.3114 + XiCon Loss:3.3726 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3054
Validation loss decreased (0.325571 --> 0.325201).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3129566
	speed: 0.0722s/iter; left time: 1712.4246s
	iters: 200, epoch: 8 | loss: 0.2953960
	speed: 0.0767s/iter; left time: 1810.6739s
Epoch: 8 cost time: 19.356432914733887
Epoch: 8, Steps: 256 Train Loss: 0.3146 (Forecasting Loss:0.3112 + XiCon Loss:3.3713 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
Validation loss decreased (0.325201 --> 0.325167).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3212930
	speed: 0.0810s/iter; left time: 1899.9757s
	iters: 200, epoch: 9 | loss: 0.3151183
	speed: 0.0746s/iter; left time: 1741.6369s
Epoch: 9 cost time: 19.375547647476196
Epoch: 9, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3111 + XiCon Loss:3.3721 x Lambda(0.001)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.3055
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3077578
	speed: 0.0819s/iter; left time: 1899.1138s
	iters: 200, epoch: 10 | loss: 0.2889376
	speed: 0.0781s/iter; left time: 1803.5891s
Epoch: 10 cost time: 20.545191287994385
Epoch: 10, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3111 + XiCon Loss:3.3729 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
Validation loss decreased (0.325167 --> 0.325099).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3205705
	speed: 0.0712s/iter; left time: 1632.5256s
	iters: 200, epoch: 11 | loss: 0.3156482
	speed: 0.0734s/iter; left time: 1676.4407s
Epoch: 11 cost time: 18.832321166992188
Epoch: 11, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3728 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3031399
	speed: 0.0832s/iter; left time: 1887.8368s
	iters: 200, epoch: 12 | loss: 0.3076077
	speed: 0.0816s/iter; left time: 1843.6099s
Epoch: 12 cost time: 20.101227521896362
Epoch: 12, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3725 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
Validation loss decreased (0.325099 --> 0.325090).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3180021
	speed: 0.0740s/iter; left time: 1658.9729s
	iters: 200, epoch: 13 | loss: 0.3186327
	speed: 0.0968s/iter; left time: 2160.9879s
Epoch: 13 cost time: 19.693617343902588
Epoch: 13, Steps: 256 Train Loss: 0.3145 (Forecasting Loss:0.3111 + XiCon Loss:3.3728 x Lambda(0.001)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.3055
Validation loss decreased (0.325090 --> 0.325023).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3212313
	speed: 0.0546s/iter; left time: 1211.4815s
	iters: 200, epoch: 14 | loss: 0.3200723
	speed: 0.0781s/iter; left time: 1724.1287s
Epoch: 14 cost time: 17.58263659477234
Epoch: 14, Steps: 256 Train Loss: 0.3143 (Forecasting Loss:0.3109 + XiCon Loss:3.3714 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3026934
	speed: 0.0820s/iter; left time: 1798.2084s
	iters: 200, epoch: 15 | loss: 0.3177421
	speed: 0.0691s/iter; left time: 1507.3751s
Epoch: 15 cost time: 18.086216688156128
Epoch: 15, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3711 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3212230
	speed: 0.0752s/iter; left time: 1629.3935s
	iters: 200, epoch: 16 | loss: 0.3112637
	speed: 0.0802s/iter; left time: 1728.2773s
Epoch: 16 cost time: 20.01990795135498
Epoch: 16, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3726 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3231740
	speed: 0.0784s/iter; left time: 1677.2751s
	iters: 200, epoch: 17 | loss: 0.3437432
	speed: 0.0591s/iter; left time: 1259.8501s
Epoch: 17 cost time: 16.0287344455719
Epoch: 17, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3111 + XiCon Loss:3.3723 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.3267156
	speed: 0.0771s/iter; left time: 1630.3172s
	iters: 200, epoch: 18 | loss: 0.3021559
	speed: 0.0797s/iter; left time: 1677.5412s
Epoch: 18 cost time: 20.061213970184326
Epoch: 18, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3721 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.3397693
	speed: 0.0760s/iter; left time: 1588.2843s
	iters: 200, epoch: 19 | loss: 0.2957668
	speed: 0.0518s/iter; left time: 1076.9017s
Epoch: 19 cost time: 15.510692834854126
Epoch: 19, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3729 x Lambda(0.001)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.3055
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2994040
	speed: 0.0807s/iter; left time: 1665.9996s
	iters: 200, epoch: 20 | loss: 0.3194403
	speed: 0.0798s/iter; left time: 1638.3045s
Epoch: 20 cost time: 20.551834106445312
Epoch: 20, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3717 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.3094108
	speed: 0.0702s/iter; left time: 1431.7424s
	iters: 200, epoch: 21 | loss: 0.3235145
	speed: 0.0398s/iter; left time: 806.3630s
Epoch: 21 cost time: 14.78635859489441
Epoch: 21, Steps: 256 Train Loss: 0.3143 (Forecasting Loss:0.3110 + XiCon Loss:3.3702 x Lambda(0.001)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3055
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.3464751
	speed: 0.0811s/iter; left time: 1632.8777s
	iters: 200, epoch: 22 | loss: 0.3188002
	speed: 0.0798s/iter; left time: 1597.4832s
Epoch: 22 cost time: 20.626904010772705
Epoch: 22, Steps: 256 Train Loss: 0.3143 (Forecasting Loss:0.3110 + XiCon Loss:3.3721 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.3101378
	speed: 0.0637s/iter; left time: 1266.3924s
	iters: 200, epoch: 23 | loss: 0.3116144
	speed: 0.0398s/iter; left time: 786.4555s
Epoch: 23 cost time: 13.979965686798096
Epoch: 23, Steps: 256 Train Loss: 0.3144 (Forecasting Loss:0.3110 + XiCon Loss:3.3719 x Lambda(0.001)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22878800332546234, mae:0.3822298049926758, mape:0.7419615983963013, mspe:18.7626953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.1900
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4293509
	speed: 0.0646s/iter; left time: 1647.3241s
	iters: 200, epoch: 1 | loss: 0.4186639
	speed: 0.0668s/iter; left time: 1696.5677s
Epoch: 1 cost time: 17.24909734725952
Epoch: 1, Steps: 256 Train Loss: 0.4401 (Forecasting Loss:0.4368 + XiCon Loss:3.3858 x Lambda(0.001)), Vali MSE Loss: 0.4019 Test MSE Loss: 0.3737
Validation loss decreased (inf --> 0.401898).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3325360
	speed: 0.0779s/iter; left time: 1966.2662s
	iters: 200, epoch: 2 | loss: 0.3681069
	speed: 0.0737s/iter; left time: 1853.4456s
Epoch: 2 cost time: 18.89647102355957
Epoch: 2, Steps: 256 Train Loss: 0.3503 (Forecasting Loss:0.3469 + XiCon Loss:3.3810 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2990
Validation loss decreased (0.401898 --> 0.315663).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3238344
	speed: 0.0714s/iter; left time: 1784.5862s
	iters: 200, epoch: 3 | loss: 0.3525308
	speed: 0.0739s/iter; left time: 1839.2488s
Epoch: 3 cost time: 18.68943452835083
Epoch: 3, Steps: 256 Train Loss: 0.3217 (Forecasting Loss:0.3183 + XiCon Loss:3.3888 x Lambda(0.001)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2984
Validation loss decreased (0.315663 --> 0.314284).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3216614
	speed: 0.0785s/iter; left time: 1940.8791s
	iters: 200, epoch: 4 | loss: 0.3554993
	speed: 0.0610s/iter; left time: 1503.0180s
Epoch: 4 cost time: 17.223065614700317
Epoch: 4, Steps: 256 Train Loss: 0.3180 (Forecasting Loss:0.3147 + XiCon Loss:3.3878 x Lambda(0.001)), Vali MSE Loss: 0.3156 Test MSE Loss: 0.2990
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3455158
	speed: 0.0778s/iter; left time: 1905.4235s
	iters: 200, epoch: 5 | loss: 0.2953597
	speed: 0.0750s/iter; left time: 1827.8161s
Epoch: 5 cost time: 19.449965476989746
Epoch: 5, Steps: 256 Train Loss: 0.3168 (Forecasting Loss:0.3135 + XiCon Loss:3.3871 x Lambda(0.001)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.2982
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3194736
	speed: 0.0640s/iter; left time: 1549.7548s
	iters: 200, epoch: 6 | loss: 0.3132323
	speed: 0.0409s/iter; left time: 985.5988s
Epoch: 6 cost time: 12.479433536529541
Epoch: 6, Steps: 256 Train Loss: 0.3163 (Forecasting Loss:0.3129 + XiCon Loss:3.3886 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.2983
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3373960
	speed: 0.0762s/iter; left time: 1826.1039s
	iters: 200, epoch: 7 | loss: 0.3034998
	speed: 0.0765s/iter; left time: 1824.5736s
Epoch: 7 cost time: 19.260860443115234
Epoch: 7, Steps: 256 Train Loss: 0.3160 (Forecasting Loss:0.3126 + XiCon Loss:3.3885 x Lambda(0.001)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.2983
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3414756
	speed: 0.0722s/iter; left time: 1712.2233s
	iters: 200, epoch: 8 | loss: 0.3111937
	speed: 0.0572s/iter; left time: 1349.9011s
Epoch: 8 cost time: 17.028120279312134
Epoch: 8, Steps: 256 Train Loss: 0.3160 (Forecasting Loss:0.3126 + XiCon Loss:3.3877 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2983
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3096101
	speed: 0.0768s/iter; left time: 1801.4044s
	iters: 200, epoch: 9 | loss: 0.3150942
	speed: 0.0769s/iter; left time: 1796.8453s
Epoch: 9 cost time: 19.614290475845337
Epoch: 9, Steps: 256 Train Loss: 0.3157 (Forecasting Loss:0.3123 + XiCon Loss:3.3890 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2983
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3363939
	speed: 0.0628s/iter; left time: 1457.1462s
	iters: 200, epoch: 10 | loss: 0.3299524
	speed: 0.0753s/iter; left time: 1739.7446s
Epoch: 10 cost time: 17.967901945114136
Epoch: 10, Steps: 256 Train Loss: 0.3158 (Forecasting Loss:0.3125 + XiCon Loss:3.3872 x Lambda(0.001)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.2983
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3254077
	speed: 0.0785s/iter; left time: 1800.9851s
	iters: 200, epoch: 11 | loss: 0.3053246
	speed: 0.0677s/iter; left time: 1547.2369s
Epoch: 11 cost time: 17.822635173797607
Epoch: 11, Steps: 256 Train Loss: 0.3158 (Forecasting Loss:0.3124 + XiCon Loss:3.3882 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2983
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2939007
	speed: 0.0750s/iter; left time: 1701.8835s
	iters: 200, epoch: 12 | loss: 0.3360833
	speed: 0.0741s/iter; left time: 1672.5495s
Epoch: 12 cost time: 19.18437933921814
Epoch: 12, Steps: 256 Train Loss: 0.3158 (Forecasting Loss:0.3124 + XiCon Loss:3.3889 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2983
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3061872
	speed: 0.0721s/iter; left time: 1616.6762s
	iters: 200, epoch: 13 | loss: 0.3408113
	speed: 0.0611s/iter; left time: 1363.9707s
Epoch: 13 cost time: 17.385286331176758
Epoch: 13, Steps: 256 Train Loss: 0.3159 (Forecasting Loss:0.3125 + XiCon Loss:3.3865 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2983
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22268205881118774, mae:0.3740459680557251, mape:0.7756126523017883, mspe:20.872480392456055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2256+-0.00382, MAE:0.3751+-0.00530, MAPE:0.7511+-0.01736, MSPE:19.2831+-1.11410, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.7248
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4432815
	speed: 0.1197s/iter; left time: 2909.2273s
	iters: 200, epoch: 1 | loss: 0.4129944
	speed: 0.1144s/iter; left time: 2767.6293s
Epoch: 1 cost time: 28.61464786529541
Epoch: 1, Steps: 244 Train Loss: 0.4585 (Forecasting Loss:0.4552 + XiCon Loss:3.3887 x Lambda(0.001)), Vali MSE Loss: 0.4363 Test MSE Loss: 0.3351
Validation loss decreased (inf --> 0.436251).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3518021
	speed: 0.1140s/iter; left time: 2741.6420s
	iters: 200, epoch: 2 | loss: 0.3411758
	speed: 0.1190s/iter; left time: 2850.2012s
Epoch: 2 cost time: 28.188895225524902
Epoch: 2, Steps: 244 Train Loss: 0.3589 (Forecasting Loss:0.3555 + XiCon Loss:3.3822 x Lambda(0.001)), Vali MSE Loss: 0.3795 Test MSE Loss: 0.3276
Validation loss decreased (0.436251 --> 0.379467).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3235123
	speed: 0.1102s/iter; left time: 2624.5684s
	iters: 200, epoch: 3 | loss: 0.3445854
	speed: 0.1193s/iter; left time: 2829.7707s
Epoch: 3 cost time: 28.179282426834106
Epoch: 3, Steps: 244 Train Loss: 0.3437 (Forecasting Loss:0.3404 + XiCon Loss:3.3724 x Lambda(0.001)), Vali MSE Loss: 0.3782 Test MSE Loss: 0.3373
Validation loss decreased (0.379467 --> 0.378206).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3239836
	speed: 0.1126s/iter; left time: 2653.8314s
	iters: 200, epoch: 4 | loss: 0.3475076
	speed: 0.1147s/iter; left time: 2691.6667s
Epoch: 4 cost time: 27.897361516952515
Epoch: 4, Steps: 244 Train Loss: 0.3398 (Forecasting Loss:0.3365 + XiCon Loss:3.3718 x Lambda(0.001)), Vali MSE Loss: 0.3660 Test MSE Loss: 0.3349
Validation loss decreased (0.378206 --> 0.366029).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3441833
	speed: 0.1148s/iter; left time: 2677.2083s
	iters: 200, epoch: 5 | loss: 0.3657483
	speed: 0.1063s/iter; left time: 2468.2805s
Epoch: 5 cost time: 27.389029502868652
Epoch: 5, Steps: 244 Train Loss: 0.3378 (Forecasting Loss:0.3344 + XiCon Loss:3.3728 x Lambda(0.001)), Vali MSE Loss: 0.3733 Test MSE Loss: 0.3369
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3341155
	speed: 0.1196s/iter; left time: 2761.3776s
	iters: 200, epoch: 6 | loss: 0.3337698
	speed: 0.1063s/iter; left time: 2442.9506s
Epoch: 6 cost time: 27.999000549316406
Epoch: 6, Steps: 244 Train Loss: 0.3363 (Forecasting Loss:0.3330 + XiCon Loss:3.3716 x Lambda(0.001)), Vali MSE Loss: 0.3780 Test MSE Loss: 0.3397
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3143822
	speed: 0.1197s/iter; left time: 2733.7446s
	iters: 200, epoch: 7 | loss: 0.3143053
	speed: 0.1144s/iter; left time: 2600.0956s
Epoch: 7 cost time: 27.99506402015686
Epoch: 7, Steps: 244 Train Loss: 0.3356 (Forecasting Loss:0.3322 + XiCon Loss:3.3722 x Lambda(0.001)), Vali MSE Loss: 0.3748 Test MSE Loss: 0.3379
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3342827
	speed: 0.1213s/iter; left time: 2740.5583s
	iters: 200, epoch: 8 | loss: 0.3366911
	speed: 0.1154s/iter; left time: 2596.6764s
Epoch: 8 cost time: 28.32122540473938
Epoch: 8, Steps: 244 Train Loss: 0.3354 (Forecasting Loss:0.3320 + XiCon Loss:3.3741 x Lambda(0.001)), Vali MSE Loss: 0.3754 Test MSE Loss: 0.3374
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3317127
	speed: 0.1204s/iter; left time: 2691.1106s
	iters: 200, epoch: 9 | loss: 0.3137243
	speed: 0.1209s/iter; left time: 2689.1242s
Epoch: 9 cost time: 29.10406470298767
Epoch: 9, Steps: 244 Train Loss: 0.3350 (Forecasting Loss:0.3317 + XiCon Loss:3.3739 x Lambda(0.001)), Vali MSE Loss: 0.3748 Test MSE Loss: 0.3372
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3273289
	speed: 0.1179s/iter; left time: 2605.9432s
	iters: 200, epoch: 10 | loss: 0.3234557
	speed: 0.1206s/iter; left time: 2652.8034s
Epoch: 10 cost time: 29.28090500831604
Epoch: 10, Steps: 244 Train Loss: 0.3347 (Forecasting Loss:0.3313 + XiCon Loss:3.3733 x Lambda(0.001)), Vali MSE Loss: 0.3748 Test MSE Loss: 0.3372
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3519071
	speed: 0.1120s/iter; left time: 2449.2412s
	iters: 200, epoch: 11 | loss: 0.3324412
	speed: 0.1175s/iter; left time: 2556.3669s
Epoch: 11 cost time: 28.125593900680542
Epoch: 11, Steps: 244 Train Loss: 0.3349 (Forecasting Loss:0.3316 + XiCon Loss:3.3725 x Lambda(0.001)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3370
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3589988
	speed: 0.1081s/iter; left time: 2337.2866s
	iters: 200, epoch: 12 | loss: 0.3159463
	speed: 0.1170s/iter; left time: 2518.4783s
Epoch: 12 cost time: 27.724032640457153
Epoch: 12, Steps: 244 Train Loss: 0.3348 (Forecasting Loss:0.3315 + XiCon Loss:3.3733 x Lambda(0.001)), Vali MSE Loss: 0.3746 Test MSE Loss: 0.3372
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3546923
	speed: 0.1148s/iter; left time: 2453.0310s
	iters: 200, epoch: 13 | loss: 0.3409589
	speed: 0.1134s/iter; left time: 2411.9193s
Epoch: 13 cost time: 28.006459951400757
Epoch: 13, Steps: 244 Train Loss: 0.3347 (Forecasting Loss:0.3314 + XiCon Loss:3.3737 x Lambda(0.001)), Vali MSE Loss: 0.3746 Test MSE Loss: 0.3372
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3147921
	speed: 0.1193s/iter; left time: 2521.1127s
	iters: 200, epoch: 14 | loss: 0.3296806
	speed: 0.1057s/iter; left time: 2221.7230s
Epoch: 14 cost time: 27.808470249176025
Epoch: 14, Steps: 244 Train Loss: 0.3347 (Forecasting Loss:0.3314 + XiCon Loss:3.3729 x Lambda(0.001)), Vali MSE Loss: 0.3746 Test MSE Loss: 0.3372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.26521584391593933, mae:0.4046059548854828, mape:0.7235106229782104, mspe:19.608760833740234 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.5701
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4766403
	speed: 0.1081s/iter; left time: 2627.0675s
	iters: 200, epoch: 1 | loss: 0.4435667
	speed: 0.1004s/iter; left time: 2429.2172s
Epoch: 1 cost time: 25.69190263748169
Epoch: 1, Steps: 244 Train Loss: 0.4608 (Forecasting Loss:0.4574 + XiCon Loss:3.3823 x Lambda(0.001)), Vali MSE Loss: 0.4543 Test MSE Loss: 0.3573
Validation loss decreased (inf --> 0.454315).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3304493
	speed: 0.1035s/iter; left time: 2490.5506s
	iters: 200, epoch: 2 | loss: 0.3266666
	speed: 0.1172s/iter; left time: 2807.7707s
Epoch: 2 cost time: 27.174206256866455
Epoch: 2, Steps: 244 Train Loss: 0.3510 (Forecasting Loss:0.3476 + XiCon Loss:3.4094 x Lambda(0.001)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.3114
Validation loss decreased (0.454315 --> 0.327399).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3062244
	speed: 0.1157s/iter; left time: 2754.8580s
	iters: 200, epoch: 3 | loss: 0.2934136
	speed: 0.0959s/iter; left time: 2273.0211s
Epoch: 3 cost time: 27.370877981185913
Epoch: 3, Steps: 244 Train Loss: 0.3158 (Forecasting Loss:0.3124 + XiCon Loss:3.4092 x Lambda(0.001)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.3049
Validation loss decreased (0.327399 --> 0.314239).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2967095
	speed: 0.0692s/iter; left time: 1630.6919s
	iters: 200, epoch: 4 | loss: 0.3022942
	speed: 0.1204s/iter; left time: 2825.9079s
Epoch: 4 cost time: 24.597662687301636
Epoch: 4, Steps: 244 Train Loss: 0.3100 (Forecasting Loss:0.3066 + XiCon Loss:3.4083 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.3029
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3176199
	speed: 0.1228s/iter; left time: 2863.4189s
	iters: 200, epoch: 5 | loss: 0.3055729
	speed: 0.0784s/iter; left time: 1820.6602s
Epoch: 5 cost time: 23.953599452972412
Epoch: 5, Steps: 244 Train Loss: 0.3081 (Forecasting Loss:0.3047 + XiCon Loss:3.4093 x Lambda(0.001)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.3044
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3276621
	speed: 0.1274s/iter; left time: 2941.4346s
	iters: 200, epoch: 6 | loss: 0.3053934
	speed: 0.1229s/iter; left time: 2823.9885s
Epoch: 6 cost time: 30.421775102615356
Epoch: 6, Steps: 244 Train Loss: 0.3072 (Forecasting Loss:0.3038 + XiCon Loss:3.4091 x Lambda(0.001)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.3045
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3198579
	speed: 0.0911s/iter; left time: 2080.8131s
	iters: 200, epoch: 7 | loss: 0.3099853
	speed: 0.1219s/iter; left time: 2772.2315s
Epoch: 7 cost time: 26.710442304611206
Epoch: 7, Steps: 244 Train Loss: 0.3067 (Forecasting Loss:0.3032 + XiCon Loss:3.4105 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.3046
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2930025
	speed: 0.1159s/iter; left time: 2619.1465s
	iters: 200, epoch: 8 | loss: 0.3092189
	speed: 0.0720s/iter; left time: 1619.3472s
Epoch: 8 cost time: 24.30596923828125
Epoch: 8, Steps: 244 Train Loss: 0.3063 (Forecasting Loss:0.3029 + XiCon Loss:3.4105 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.3047
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3053557
	speed: 0.1263s/iter; left time: 2823.1492s
	iters: 200, epoch: 9 | loss: 0.3050036
	speed: 0.1217s/iter; left time: 2707.3025s
Epoch: 9 cost time: 28.944618463516235
Epoch: 9, Steps: 244 Train Loss: 0.3065 (Forecasting Loss:0.3031 + XiCon Loss:3.4107 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.3049
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3089958
	speed: 0.1175s/iter; left time: 2597.8390s
	iters: 200, epoch: 10 | loss: 0.3087155
	speed: 0.1238s/iter; left time: 2724.6207s
Epoch: 10 cost time: 29.790185689926147
Epoch: 10, Steps: 244 Train Loss: 0.3062 (Forecasting Loss:0.3028 + XiCon Loss:3.4106 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.3048
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2970976
	speed: 0.0927s/iter; left time: 2027.3305s
	iters: 200, epoch: 11 | loss: 0.3152635
	speed: 0.0966s/iter; left time: 2102.3380s
Epoch: 11 cost time: 24.51062035560608
Epoch: 11, Steps: 244 Train Loss: 0.3061 (Forecasting Loss:0.3027 + XiCon Loss:3.4109 x Lambda(0.001)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.3047
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2939043
	speed: 0.1263s/iter; left time: 2729.9763s
	iters: 200, epoch: 12 | loss: 0.3038516
	speed: 0.1090s/iter; left time: 2344.5614s
Epoch: 12 cost time: 26.437063932418823
Epoch: 12, Steps: 244 Train Loss: 0.3062 (Forecasting Loss:0.3028 + XiCon Loss:3.4106 x Lambda(0.001)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.3048
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3170015
	speed: 0.1255s/iter; left time: 2681.8705s
	iters: 200, epoch: 13 | loss: 0.2975524
	speed: 0.1254s/iter; left time: 2668.5745s
Epoch: 13 cost time: 30.658610820770264
Epoch: 13, Steps: 244 Train Loss: 0.3062 (Forecasting Loss:0.3028 + XiCon Loss:3.4107 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.3048
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22687652707099915, mae:0.3828490078449249, mape:0.7278958559036255, mspe:18.719806671142578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2438
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4533638
	speed: 0.1077s/iter; left time: 2616.4465s
	iters: 200, epoch: 1 | loss: 0.4468770
	speed: 0.0975s/iter; left time: 2358.8280s
Epoch: 1 cost time: 23.363212823867798
Epoch: 1, Steps: 244 Train Loss: 0.4615 (Forecasting Loss:0.4581 + XiCon Loss:3.3758 x Lambda(0.001)), Vali MSE Loss: 0.4459 Test MSE Loss: 0.3475
Validation loss decreased (inf --> 0.445887).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3488444
	speed: 0.1119s/iter; left time: 2691.5027s
	iters: 200, epoch: 2 | loss: 0.3507704
	speed: 0.1109s/iter; left time: 2655.8543s
Epoch: 2 cost time: 27.25546360015869
Epoch: 2, Steps: 244 Train Loss: 0.3591 (Forecasting Loss:0.3557 + XiCon Loss:3.3783 x Lambda(0.001)), Vali MSE Loss: 0.3560 Test MSE Loss: 0.3331
Validation loss decreased (0.445887 --> 0.355966).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3502021
	speed: 0.0874s/iter; left time: 2081.7885s
	iters: 200, epoch: 3 | loss: 0.3239896
	speed: 0.0706s/iter; left time: 1673.0546s
Epoch: 3 cost time: 20.564059257507324
Epoch: 3, Steps: 244 Train Loss: 0.3425 (Forecasting Loss:0.3391 + XiCon Loss:3.3726 x Lambda(0.001)), Vali MSE Loss: 0.3686 Test MSE Loss: 0.3264
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3284591
	speed: 0.1126s/iter; left time: 2653.0186s
	iters: 200, epoch: 4 | loss: 0.3313210
	speed: 0.1076s/iter; left time: 2524.9651s
Epoch: 4 cost time: 26.015050172805786
Epoch: 4, Steps: 244 Train Loss: 0.3380 (Forecasting Loss:0.3347 + XiCon Loss:3.3708 x Lambda(0.001)), Vali MSE Loss: 0.3615 Test MSE Loss: 0.3274
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3483106
	speed: 0.1078s/iter; left time: 2513.8343s
	iters: 200, epoch: 5 | loss: 0.3283692
	speed: 0.1087s/iter; left time: 2523.5893s
Epoch: 5 cost time: 26.55234670639038
Epoch: 5, Steps: 244 Train Loss: 0.3352 (Forecasting Loss:0.3319 + XiCon Loss:3.3720 x Lambda(0.001)), Vali MSE Loss: 0.3688 Test MSE Loss: 0.3282
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3445564
	speed: 0.0963s/iter; left time: 2222.9663s
	iters: 200, epoch: 6 | loss: 0.3544269
	speed: 0.0681s/iter; left time: 1565.6698s
Epoch: 6 cost time: 21.270480155944824
Epoch: 6, Steps: 244 Train Loss: 0.3339 (Forecasting Loss:0.3305 + XiCon Loss:3.3692 x Lambda(0.001)), Vali MSE Loss: 0.3636 Test MSE Loss: 0.3235
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3462719
	speed: 0.1119s/iter; left time: 2556.0099s
	iters: 200, epoch: 7 | loss: 0.3345332
	speed: 0.1073s/iter; left time: 2440.3831s
Epoch: 7 cost time: 26.131783962249756
Epoch: 7, Steps: 244 Train Loss: 0.3332 (Forecasting Loss:0.3298 + XiCon Loss:3.3714 x Lambda(0.001)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.3287
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3236975
	speed: 0.1122s/iter; left time: 2534.3148s
	iters: 200, epoch: 8 | loss: 0.3259873
	speed: 0.1109s/iter; left time: 2494.6451s
Epoch: 8 cost time: 27.154696702957153
Epoch: 8, Steps: 244 Train Loss: 0.3328 (Forecasting Loss:0.3294 + XiCon Loss:3.3688 x Lambda(0.001)), Vali MSE Loss: 0.3672 Test MSE Loss: 0.3250
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3295401
	speed: 0.1075s/iter; left time: 2403.1387s
	iters: 200, epoch: 9 | loss: 0.3262626
	speed: 0.1101s/iter; left time: 2448.9189s
Epoch: 9 cost time: 26.651352405548096
Epoch: 9, Steps: 244 Train Loss: 0.3327 (Forecasting Loss:0.3293 + XiCon Loss:3.3706 x Lambda(0.001)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.3258
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3427681
	speed: 0.1016s/iter; left time: 2244.8205s
	iters: 200, epoch: 10 | loss: 0.3321296
	speed: 0.1079s/iter; left time: 2374.4401s
Epoch: 10 cost time: 26.08854579925537
Epoch: 10, Steps: 244 Train Loss: 0.3325 (Forecasting Loss:0.3291 + XiCon Loss:3.3705 x Lambda(0.001)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3253
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3266114
	speed: 0.1138s/iter; left time: 2487.7139s
	iters: 200, epoch: 11 | loss: 0.3471223
	speed: 0.0997s/iter; left time: 2169.5072s
Epoch: 11 cost time: 26.263750553131104
Epoch: 11, Steps: 244 Train Loss: 0.3326 (Forecasting Loss:0.3292 + XiCon Loss:3.3703 x Lambda(0.001)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3259
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3300000
	speed: 0.1118s/iter; left time: 2417.3513s
	iters: 200, epoch: 12 | loss: 0.3202706
	speed: 0.1001s/iter; left time: 2153.6919s
Epoch: 12 cost time: 25.379753828048706
Epoch: 12, Steps: 244 Train Loss: 0.3323 (Forecasting Loss:0.3289 + XiCon Loss:3.3703 x Lambda(0.001)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3260
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2618512511253357, mae:0.4043194353580475, mape:0.7563051581382751, mspe:21.777240753173828 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9239
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4600798
	speed: 0.0929s/iter; left time: 2258.6405s
	iters: 200, epoch: 1 | loss: 0.4366826
	speed: 0.1068s/iter; left time: 2583.9463s
Epoch: 1 cost time: 24.601640701293945
Epoch: 1, Steps: 244 Train Loss: 0.4639 (Forecasting Loss:0.4605 + XiCon Loss:3.3845 x Lambda(0.001)), Vali MSE Loss: 0.4467 Test MSE Loss: 0.3498
Validation loss decreased (inf --> 0.446660).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3758671
	speed: 0.1045s/iter; left time: 2512.8152s
	iters: 200, epoch: 2 | loss: 0.3393856
	speed: 0.0957s/iter; left time: 2291.8253s
Epoch: 2 cost time: 24.775375366210938
Epoch: 2, Steps: 244 Train Loss: 0.3663 (Forecasting Loss:0.3629 + XiCon Loss:3.3872 x Lambda(0.001)), Vali MSE Loss: 0.3877 Test MSE Loss: 0.3266
Validation loss decreased (0.446660 --> 0.387743).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3172741
	speed: 0.1095s/iter; left time: 2607.7906s
	iters: 200, epoch: 3 | loss: 0.3194227
	speed: 0.1135s/iter; left time: 2690.7037s
Epoch: 3 cost time: 26.45817756652832
Epoch: 3, Steps: 244 Train Loss: 0.3412 (Forecasting Loss:0.3379 + XiCon Loss:3.3687 x Lambda(0.001)), Vali MSE Loss: 0.3695 Test MSE Loss: 0.3326
Validation loss decreased (0.387743 --> 0.369487).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3442205
	speed: 0.1110s/iter; left time: 2615.6386s
	iters: 200, epoch: 4 | loss: 0.3335236
	speed: 0.1064s/iter; left time: 2497.8047s
Epoch: 4 cost time: 26.783459901809692
Epoch: 4, Steps: 244 Train Loss: 0.3281 (Forecasting Loss:0.3248 + XiCon Loss:3.3607 x Lambda(0.001)), Vali MSE Loss: 0.3311 Test MSE Loss: 0.3041
Validation loss decreased (0.369487 --> 0.331051).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3035658
	speed: 0.1011s/iter; left time: 2358.7579s
	iters: 200, epoch: 5 | loss: 0.3137056
	speed: 0.1058s/iter; left time: 2457.8464s
Epoch: 5 cost time: 25.42190456390381
Epoch: 5, Steps: 244 Train Loss: 0.3174 (Forecasting Loss:0.3140 + XiCon Loss:3.3585 x Lambda(0.001)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.3074
Validation loss decreased (0.331051 --> 0.327138).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3225855
	speed: 0.1024s/iter; left time: 2362.6609s
	iters: 200, epoch: 6 | loss: 0.3325267
	speed: 0.1026s/iter; left time: 2357.6477s
Epoch: 6 cost time: 25.640769243240356
Epoch: 6, Steps: 244 Train Loss: 0.3132 (Forecasting Loss:0.3099 + XiCon Loss:3.3558 x Lambda(0.001)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.3038
Validation loss decreased (0.327138 --> 0.316969).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2966698
	speed: 0.1104s/iter; left time: 2521.5623s
	iters: 200, epoch: 7 | loss: 0.3279795
	speed: 0.0992s/iter; left time: 2255.5530s
Epoch: 7 cost time: 25.470616579055786
Epoch: 7, Steps: 244 Train Loss: 0.3114 (Forecasting Loss:0.3081 + XiCon Loss:3.3545 x Lambda(0.001)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.3032
Validation loss decreased (0.316969 --> 0.316306).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3210944
	speed: 0.1104s/iter; left time: 2493.7227s
	iters: 200, epoch: 8 | loss: 0.2981413
	speed: 0.1074s/iter; left time: 2415.6318s
Epoch: 8 cost time: 26.42346978187561
Epoch: 8, Steps: 244 Train Loss: 0.3107 (Forecasting Loss:0.3073 + XiCon Loss:3.3531 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.3041
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2869940
	speed: 0.1090s/iter; left time: 2436.9883s
	iters: 200, epoch: 9 | loss: 0.3049411
	speed: 0.1046s/iter; left time: 2327.7954s
Epoch: 9 cost time: 26.302449703216553
Epoch: 9, Steps: 244 Train Loss: 0.3100 (Forecasting Loss:0.3067 + XiCon Loss:3.3548 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.3046
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3128321
	speed: 0.0959s/iter; left time: 2120.6349s
	iters: 200, epoch: 10 | loss: 0.2882345
	speed: 0.1057s/iter; left time: 2325.6673s
Epoch: 10 cost time: 24.92486333847046
Epoch: 10, Steps: 244 Train Loss: 0.3100 (Forecasting Loss:0.3066 + XiCon Loss:3.3524 x Lambda(0.001)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.3042
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3126323
	speed: 0.1071s/iter; left time: 2341.9903s
	iters: 200, epoch: 11 | loss: 0.3112115
	speed: 0.0947s/iter; left time: 2061.2785s
Epoch: 11 cost time: 25.12924289703369
Epoch: 11, Steps: 244 Train Loss: 0.3099 (Forecasting Loss:0.3065 + XiCon Loss:3.3533 x Lambda(0.001)), Vali MSE Loss: 0.3168 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3100819
	speed: 0.1096s/iter; left time: 2369.0624s
	iters: 200, epoch: 12 | loss: 0.3102280
	speed: 0.1006s/iter; left time: 2163.9594s
Epoch: 12 cost time: 25.012072563171387
Epoch: 12, Steps: 244 Train Loss: 0.3101 (Forecasting Loss:0.3068 + XiCon Loss:3.3532 x Lambda(0.001)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.3045
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3282382
	speed: 0.1141s/iter; left time: 2438.5659s
	iters: 200, epoch: 13 | loss: 0.3003189
	speed: 0.1063s/iter; left time: 2261.4681s
Epoch: 13 cost time: 26.613678693771362
Epoch: 13, Steps: 244 Train Loss: 0.3099 (Forecasting Loss:0.3066 + XiCon Loss:3.3529 x Lambda(0.001)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.3045
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3049892
	speed: 0.1057s/iter; left time: 2234.2904s
	iters: 200, epoch: 14 | loss: 0.3203534
	speed: 0.1058s/iter; left time: 2225.2734s
Epoch: 14 cost time: 26.033005237579346
Epoch: 14, Steps: 244 Train Loss: 0.3097 (Forecasting Loss:0.3064 + XiCon Loss:3.3535 x Lambda(0.001)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.3044
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3010485
	speed: 0.1043s/iter; left time: 2177.7645s
	iters: 200, epoch: 15 | loss: 0.2983807
	speed: 0.1028s/iter; left time: 2137.5103s
Epoch: 15 cost time: 25.562458753585815
Epoch: 15, Steps: 244 Train Loss: 0.3099 (Forecasting Loss:0.3065 + XiCon Loss:3.3533 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.3044
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.2990293
	speed: 0.1109s/iter; left time: 2289.4375s
	iters: 200, epoch: 16 | loss: 0.3045474
	speed: 0.0974s/iter; left time: 2001.3579s
Epoch: 16 cost time: 25.661502599716187
Epoch: 16, Steps: 244 Train Loss: 0.3099 (Forecasting Loss:0.3065 + XiCon Loss:3.3539 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.3044
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3056151
	speed: 0.1077s/iter; left time: 2197.2426s
	iters: 200, epoch: 17 | loss: 0.3003025
	speed: 0.1088s/iter; left time: 2208.5075s
Epoch: 17 cost time: 25.852368354797363
Epoch: 17, Steps: 244 Train Loss: 0.3096 (Forecasting Loss:0.3062 + XiCon Loss:3.3540 x Lambda(0.001)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.3044
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2256641536951065, mae:0.3807685673236847, mape:0.6863279342651367, mspe:16.85171127319336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.2664
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4736511
	speed: 0.1001s/iter; left time: 2431.5983s
	iters: 200, epoch: 1 | loss: 0.4588359
	speed: 0.0847s/iter; left time: 2048.7417s
Epoch: 1 cost time: 23.65005588531494
Epoch: 1, Steps: 244 Train Loss: 0.4687 (Forecasting Loss:0.4653 + XiCon Loss:3.3905 x Lambda(0.001)), Vali MSE Loss: 0.4780 Test MSE Loss: 0.3839
Validation loss decreased (inf --> 0.477994).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3416921
	speed: 0.0610s/iter; left time: 1467.4079s
	iters: 200, epoch: 2 | loss: 0.3171008
	speed: 0.1139s/iter; left time: 2729.1937s
Epoch: 2 cost time: 22.854955673217773
Epoch: 2, Steps: 244 Train Loss: 0.3606 (Forecasting Loss:0.3572 + XiCon Loss:3.3690 x Lambda(0.001)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.3144
Validation loss decreased (0.477994 --> 0.318713).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3041446
	speed: 0.1167s/iter; left time: 2779.7221s
	iters: 200, epoch: 3 | loss: 0.3282547
	speed: 0.0843s/iter; left time: 1999.5978s
Epoch: 3 cost time: 24.587217330932617
Epoch: 3, Steps: 244 Train Loss: 0.3138 (Forecasting Loss:0.3104 + XiCon Loss:3.3547 x Lambda(0.001)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.3095
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2967694
	speed: 0.1306s/iter; left time: 3076.9812s
	iters: 200, epoch: 4 | loss: 0.3077327
	speed: 0.1202s/iter; left time: 2821.2329s
Epoch: 4 cost time: 29.632328033447266
Epoch: 4, Steps: 244 Train Loss: 0.3071 (Forecasting Loss:0.3037 + XiCon Loss:3.3531 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.3089
Validation loss decreased (0.318713 --> 0.311951).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3118024
	speed: 0.1034s/iter; left time: 2412.9343s
	iters: 200, epoch: 5 | loss: 0.3180317
	speed: 0.1212s/iter; left time: 2813.8733s
Epoch: 5 cost time: 27.81138515472412
Epoch: 5, Steps: 244 Train Loss: 0.3042 (Forecasting Loss:0.3009 + XiCon Loss:3.3506 x Lambda(0.001)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3087
Validation loss decreased (0.311951 --> 0.309474).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3238903
	speed: 0.1074s/iter; left time: 2479.2200s
	iters: 200, epoch: 6 | loss: 0.3017184
	speed: 0.0884s/iter; left time: 2031.3980s
Epoch: 6 cost time: 24.85182809829712
Epoch: 6, Steps: 244 Train Loss: 0.3029 (Forecasting Loss:0.2995 + XiCon Loss:3.3484 x Lambda(0.001)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.3085
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2900089
	speed: 0.1252s/iter; left time: 2859.1827s
	iters: 200, epoch: 7 | loss: 0.2824315
	speed: 0.1161s/iter; left time: 2638.8567s
Epoch: 7 cost time: 27.02534818649292
Epoch: 7, Steps: 244 Train Loss: 0.3021 (Forecasting Loss:0.2988 + XiCon Loss:3.3475 x Lambda(0.001)), Vali MSE Loss: 0.3099 Test MSE Loss: 0.3093
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2961989
	speed: 0.1244s/iter; left time: 2811.3971s
	iters: 200, epoch: 8 | loss: 0.3085732
	speed: 0.1248s/iter; left time: 2807.6247s
Epoch: 8 cost time: 30.493699312210083
Epoch: 8, Steps: 244 Train Loss: 0.3017 (Forecasting Loss:0.2984 + XiCon Loss:3.3451 x Lambda(0.001)), Vali MSE Loss: 0.3108 Test MSE Loss: 0.3086
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2984329
	speed: 0.1204s/iter; left time: 2690.9905s
	iters: 200, epoch: 9 | loss: 0.3111177
	speed: 0.1189s/iter; left time: 2644.9658s
Epoch: 9 cost time: 29.20629334449768
Epoch: 9, Steps: 244 Train Loss: 0.3017 (Forecasting Loss:0.2983 + XiCon Loss:3.3468 x Lambda(0.001)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.3094
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3080524
	speed: 0.1006s/iter; left time: 2224.1777s
	iters: 200, epoch: 10 | loss: 0.2985166
	speed: 0.0877s/iter; left time: 1929.9603s
Epoch: 10 cost time: 24.359039545059204
Epoch: 10, Steps: 244 Train Loss: 0.3015 (Forecasting Loss:0.2982 + XiCon Loss:3.3476 x Lambda(0.001)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3094
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3359998
	speed: 0.1277s/iter; left time: 2792.3548s
	iters: 200, epoch: 11 | loss: 0.2984585
	speed: 0.1113s/iter; left time: 2423.0123s
Epoch: 11 cost time: 26.84971046447754
Epoch: 11, Steps: 244 Train Loss: 0.3013 (Forecasting Loss:0.2979 + XiCon Loss:3.3469 x Lambda(0.001)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.3096
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2914681
	speed: 0.1303s/iter; left time: 2817.3732s
	iters: 200, epoch: 12 | loss: 0.2938789
	speed: 0.1275s/iter; left time: 2743.1503s
Epoch: 12 cost time: 31.026758909225464
Epoch: 12, Steps: 244 Train Loss: 0.3013 (Forecasting Loss:0.2979 + XiCon Loss:3.3453 x Lambda(0.001)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.3096
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.2947268
	speed: 0.0955s/iter; left time: 2041.4298s
	iters: 200, epoch: 13 | loss: 0.3021427
	speed: 0.1231s/iter; left time: 2619.7109s
Epoch: 13 cost time: 27.1439847946167
Epoch: 13, Steps: 244 Train Loss: 0.3015 (Forecasting Loss:0.2981 + XiCon Loss:3.3461 x Lambda(0.001)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3096
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.2976168
	speed: 0.1150s/iter; left time: 2429.8459s
	iters: 200, epoch: 14 | loss: 0.3049921
	speed: 0.0867s/iter; left time: 1822.6880s
Epoch: 14 cost time: 25.918771982192993
Epoch: 14, Steps: 244 Train Loss: 0.3015 (Forecasting Loss:0.2982 + XiCon Loss:3.3478 x Lambda(0.001)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.3096
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.2985885
	speed: 0.1254s/iter; left time: 2619.2752s
	iters: 200, epoch: 15 | loss: 0.3086557
	speed: 0.1149s/iter; left time: 2388.4073s
Epoch: 15 cost time: 27.120093822479248
Epoch: 15, Steps: 244 Train Loss: 0.3014 (Forecasting Loss:0.2980 + XiCon Loss:3.3461 x Lambda(0.001)), Vali MSE Loss: 0.3097 Test MSE Loss: 0.3096
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.23435479402542114, mae:0.38299116492271423, mape:0.6769648194313049, mspe:16.464696884155273 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2428+-0.02392, MAE:0.3911+-0.01518, MAPE:0.7142+-0.04028, MSPE:18.6844+-2.68521, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.1031
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5208562
	speed: 0.2161s/iter; left time: 5014.3576s
	iters: 200, epoch: 1 | loss: 0.5437939
	speed: 0.2171s/iter; left time: 5015.0223s
Epoch: 1 cost time: 50.36093258857727
Epoch: 1, Steps: 233 Train Loss: 0.5466 (Forecasting Loss:0.5432 + XiCon Loss:3.3992 x Lambda(0.001)), Vali MSE Loss: 0.4845 Test MSE Loss: 0.3721
Validation loss decreased (inf --> 0.484458).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3907441
	speed: 0.2212s/iter; left time: 5080.9066s
	iters: 200, epoch: 2 | loss: 0.3816925
	speed: 0.2134s/iter; left time: 4879.9130s
Epoch: 2 cost time: 50.776901721954346
Epoch: 2, Steps: 233 Train Loss: 0.4022 (Forecasting Loss:0.3988 + XiCon Loss:3.3944 x Lambda(0.001)), Vali MSE Loss: 0.3792 Test MSE Loss: 0.3530
Validation loss decreased (0.484458 --> 0.379193).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3868987
	speed: 0.2162s/iter; left time: 4915.8519s
	iters: 200, epoch: 3 | loss: 0.3798100
	speed: 0.2164s/iter; left time: 4898.1229s
Epoch: 3 cost time: 50.65569877624512
Epoch: 3, Steps: 233 Train Loss: 0.3824 (Forecasting Loss:0.3790 + XiCon Loss:3.3819 x Lambda(0.001)), Vali MSE Loss: 0.3851 Test MSE Loss: 0.3403
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3632698
	speed: 0.2189s/iter; left time: 4926.3544s
	iters: 200, epoch: 4 | loss: 0.3568906
	speed: 0.2226s/iter; left time: 4987.6622s
Epoch: 4 cost time: 50.98566961288452
Epoch: 4, Steps: 233 Train Loss: 0.3761 (Forecasting Loss:0.3728 + XiCon Loss:3.3806 x Lambda(0.001)), Vali MSE Loss: 0.3873 Test MSE Loss: 0.3281
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3818904
	speed: 0.2222s/iter; left time: 4948.5989s
	iters: 200, epoch: 5 | loss: 0.3713766
	speed: 0.2173s/iter; left time: 4816.4502s
Epoch: 5 cost time: 51.30708694458008
Epoch: 5, Steps: 233 Train Loss: 0.3728 (Forecasting Loss:0.3694 + XiCon Loss:3.3813 x Lambda(0.001)), Vali MSE Loss: 0.3829 Test MSE Loss: 0.3220
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3709696
	speed: 0.2155s/iter; left time: 4748.9521s
	iters: 200, epoch: 6 | loss: 0.3762591
	speed: 0.2251s/iter; left time: 4938.2772s
Epoch: 6 cost time: 51.842145919799805
Epoch: 6, Steps: 233 Train Loss: 0.3707 (Forecasting Loss:0.3673 + XiCon Loss:3.3822 x Lambda(0.001)), Vali MSE Loss: 0.3869 Test MSE Loss: 0.3221
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3708808
	speed: 0.2198s/iter; left time: 4792.0530s
	iters: 200, epoch: 7 | loss: 0.3854018
	speed: 0.2144s/iter; left time: 4652.5333s
Epoch: 7 cost time: 50.55929899215698
Epoch: 7, Steps: 233 Train Loss: 0.3695 (Forecasting Loss:0.3661 + XiCon Loss:3.3842 x Lambda(0.001)), Vali MSE Loss: 0.3828 Test MSE Loss: 0.3212
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3571841
	speed: 0.2197s/iter; left time: 4739.3241s
	iters: 200, epoch: 8 | loss: 0.3533157
	speed: 0.2152s/iter; left time: 4619.7308s
Epoch: 8 cost time: 50.9938428401947
Epoch: 8, Steps: 233 Train Loss: 0.3690 (Forecasting Loss:0.3656 + XiCon Loss:3.3863 x Lambda(0.001)), Vali MSE Loss: 0.3822 Test MSE Loss: 0.3215
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3564298
	speed: 0.2137s/iter; left time: 4559.8679s
	iters: 200, epoch: 9 | loss: 0.3712485
	speed: 0.2220s/iter; left time: 4714.4442s
Epoch: 9 cost time: 51.26308560371399
Epoch: 9, Steps: 233 Train Loss: 0.3685 (Forecasting Loss:0.3652 + XiCon Loss:3.3836 x Lambda(0.001)), Vali MSE Loss: 0.3801 Test MSE Loss: 0.3213
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3838782
	speed: 0.2197s/iter; left time: 4637.4309s
	iters: 200, epoch: 10 | loss: 0.3699604
	speed: 0.2211s/iter; left time: 4644.7129s
Epoch: 10 cost time: 51.36639332771301
Epoch: 10, Steps: 233 Train Loss: 0.3685 (Forecasting Loss:0.3651 + XiCon Loss:3.3856 x Lambda(0.001)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.3212
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3705590
	speed: 0.2261s/iter; left time: 4719.9164s
	iters: 200, epoch: 11 | loss: 0.3612162
	speed: 0.2111s/iter; left time: 4384.1826s
Epoch: 11 cost time: 51.180402517318726
Epoch: 11, Steps: 233 Train Loss: 0.3684 (Forecasting Loss:0.3650 + XiCon Loss:3.3851 x Lambda(0.001)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.3212
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3718897
	speed: 0.2136s/iter; left time: 4408.1930s
	iters: 200, epoch: 12 | loss: 0.3573743
	speed: 0.2207s/iter; left time: 4532.5036s
Epoch: 12 cost time: 51.33428955078125
Epoch: 12, Steps: 233 Train Loss: 0.3682 (Forecasting Loss:0.3648 + XiCon Loss:3.3842 x Lambda(0.001)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.3211
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2874411642551422, mae:0.4185817539691925, mape:0.7574471235275269, mspe:24.444543838500977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.0461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5421467
	speed: 0.1978s/iter; left time: 4589.8326s
	iters: 200, epoch: 1 | loss: 0.5279269
	speed: 0.2030s/iter; left time: 4690.3074s
Epoch: 1 cost time: 47.5407600402832
Epoch: 1, Steps: 233 Train Loss: 0.5514 (Forecasting Loss:0.5480 + XiCon Loss:3.3990 x Lambda(0.001)), Vali MSE Loss: 0.5243 Test MSE Loss: 0.4323
Validation loss decreased (inf --> 0.524272).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4318075
	speed: 0.2030s/iter; left time: 4661.9039s
	iters: 200, epoch: 2 | loss: 0.3958630
	speed: 0.2113s/iter; left time: 4832.0890s
Epoch: 2 cost time: 47.942487955093384
Epoch: 2, Steps: 233 Train Loss: 0.4287 (Forecasting Loss:0.4253 + XiCon Loss:3.4016 x Lambda(0.001)), Vali MSE Loss: 0.3501 Test MSE Loss: 0.3259
Validation loss decreased (0.524272 --> 0.350137).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3592716
	speed: 0.1719s/iter; left time: 3908.5025s
	iters: 200, epoch: 3 | loss: 0.3419305
	speed: 0.1801s/iter; left time: 4077.5436s
Epoch: 3 cost time: 42.89883995056152
Epoch: 3, Steps: 233 Train Loss: 0.3511 (Forecasting Loss:0.3477 + XiCon Loss:3.3690 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3061
Validation loss decreased (0.350137 --> 0.319054).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3455432
	speed: 0.2330s/iter; left time: 5242.2394s
	iters: 200, epoch: 4 | loss: 0.3315377
	speed: 0.1688s/iter; left time: 3780.6542s
Epoch: 4 cost time: 48.03574204444885
Epoch: 4, Steps: 233 Train Loss: 0.3341 (Forecasting Loss:0.3307 + XiCon Loss:3.3613 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3163
Validation loss decreased (0.319054 --> 0.318347).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3312217
	speed: 0.2357s/iter; left time: 5248.0122s
	iters: 200, epoch: 5 | loss: 0.3346781
	speed: 0.2336s/iter; left time: 5178.8018s
Epoch: 5 cost time: 54.93224740028381
Epoch: 5, Steps: 233 Train Loss: 0.3286 (Forecasting Loss:0.3252 + XiCon Loss:3.3593 x Lambda(0.001)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.3229
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2925071
	speed: 0.2411s/iter; left time: 5313.0705s
	iters: 200, epoch: 6 | loss: 0.3491842
	speed: 0.2019s/iter; left time: 4428.7358s
Epoch: 6 cost time: 50.349653244018555
Epoch: 6, Steps: 233 Train Loss: 0.3263 (Forecasting Loss:0.3230 + XiCon Loss:3.3604 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3201
Validation loss decreased (0.318347 --> 0.318330).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3206485
	speed: 0.2433s/iter; left time: 5304.0032s
	iters: 200, epoch: 7 | loss: 0.3299895
	speed: 0.2370s/iter; left time: 5144.6064s
Epoch: 7 cost time: 52.78489351272583
Epoch: 7, Steps: 233 Train Loss: 0.3250 (Forecasting Loss:0.3216 + XiCon Loss:3.3586 x Lambda(0.001)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.3238
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3347049
	speed: 0.2474s/iter; left time: 5336.5606s
	iters: 200, epoch: 8 | loss: 0.3236870
	speed: 0.2398s/iter; left time: 5148.7009s
Epoch: 8 cost time: 56.564579486846924
Epoch: 8, Steps: 233 Train Loss: 0.3244 (Forecasting Loss:0.3211 + XiCon Loss:3.3594 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3227
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3170992
	speed: 0.2366s/iter; left time: 5048.9480s
	iters: 200, epoch: 9 | loss: 0.3597263
	speed: 0.2418s/iter; left time: 5135.3884s
Epoch: 9 cost time: 55.86754512786865
Epoch: 9, Steps: 233 Train Loss: 0.3244 (Forecasting Loss:0.3210 + XiCon Loss:3.3582 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.3231
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3112805
	speed: 0.2518s/iter; left time: 5313.0581s
	iters: 200, epoch: 10 | loss: 0.3144425
	speed: 0.2447s/iter; left time: 5138.6351s
Epoch: 10 cost time: 57.892048835754395
Epoch: 10, Steps: 233 Train Loss: 0.3242 (Forecasting Loss:0.3208 + XiCon Loss:3.3589 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.3228
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3401172
	speed: 0.2274s/iter; left time: 4745.6307s
	iters: 200, epoch: 11 | loss: 0.3174979
	speed: 0.2470s/iter; left time: 5130.2393s
Epoch: 11 cost time: 55.91608691215515
Epoch: 11, Steps: 233 Train Loss: 0.3239 (Forecasting Loss:0.3206 + XiCon Loss:3.3599 x Lambda(0.001)), Vali MSE Loss: 0.3189 Test MSE Loss: 0.3228
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3218605
	speed: 0.2037s/iter; left time: 4204.3791s
	iters: 200, epoch: 12 | loss: 0.3353121
	speed: 0.2499s/iter; left time: 5132.7047s
Epoch: 12 cost time: 53.53292536735535
Epoch: 12, Steps: 233 Train Loss: 0.3241 (Forecasting Loss:0.3207 + XiCon Loss:3.3591 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3230
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3135063
	speed: 0.2510s/iter; left time: 5122.2234s
	iters: 200, epoch: 13 | loss: 0.3203482
	speed: 0.2435s/iter; left time: 4943.3652s
Epoch: 13 cost time: 57.18866276741028
Epoch: 13, Steps: 233 Train Loss: 0.3237 (Forecasting Loss:0.3203 + XiCon Loss:3.3595 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3229
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3365448
	speed: 0.2523s/iter; left time: 5090.0885s
	iters: 200, epoch: 14 | loss: 0.3385746
	speed: 0.2402s/iter; left time: 4821.5877s
Epoch: 14 cost time: 57.68618321418762
Epoch: 14, Steps: 233 Train Loss: 0.3241 (Forecasting Loss:0.3207 + XiCon Loss:3.3589 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3228
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3121584
	speed: 0.2218s/iter; left time: 4421.9103s
	iters: 200, epoch: 15 | loss: 0.3311080
	speed: 0.2450s/iter; left time: 4859.6639s
Epoch: 15 cost time: 54.72916841506958
Epoch: 15, Steps: 233 Train Loss: 0.3241 (Forecasting Loss:0.3207 + XiCon Loss:3.3589 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.3228
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3217479
	speed: 0.2511s/iter; left time: 4948.0400s
	iters: 200, epoch: 16 | loss: 0.3230255
	speed: 0.2459s/iter; left time: 4821.4777s
Epoch: 16 cost time: 57.913878440856934
Epoch: 16, Steps: 233 Train Loss: 0.3240 (Forecasting Loss:0.3206 + XiCon Loss:3.3577 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.3228
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.24294181168079376, mae:0.39725247025489807, mape:0.6462967395782471, mspe:14.366744041442871 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8652
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.6005912
	speed: 0.2196s/iter; left time: 5094.7004s
	iters: 200, epoch: 1 | loss: 0.5522292
	speed: 0.2108s/iter; left time: 4869.0225s
Epoch: 1 cost time: 50.4571270942688
Epoch: 1, Steps: 233 Train Loss: 0.5531 (Forecasting Loss:0.5497 + XiCon Loss:3.3925 x Lambda(0.001)), Vali MSE Loss: 0.5025 Test MSE Loss: 0.4080
Validation loss decreased (inf --> 0.502499).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3961576
	speed: 0.2220s/iter; left time: 5099.1993s
	iters: 200, epoch: 2 | loss: 0.3788430
	speed: 0.2206s/iter; left time: 5044.5683s
Epoch: 2 cost time: 51.71730136871338
Epoch: 2, Steps: 233 Train Loss: 0.4086 (Forecasting Loss:0.4052 + XiCon Loss:3.3994 x Lambda(0.001)), Vali MSE Loss: 0.3858 Test MSE Loss: 0.3235
Validation loss decreased (0.502499 --> 0.385805).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3823441
	speed: 0.2112s/iter; left time: 4802.4338s
	iters: 200, epoch: 3 | loss: 0.3987802
	speed: 0.2239s/iter; left time: 5068.5414s
Epoch: 3 cost time: 50.782840967178345
Epoch: 3, Steps: 233 Train Loss: 0.3783 (Forecasting Loss:0.3749 + XiCon Loss:3.3858 x Lambda(0.001)), Vali MSE Loss: 0.3562 Test MSE Loss: 0.3181
Validation loss decreased (0.385805 --> 0.356233).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3723102
	speed: 0.2145s/iter; left time: 4827.5380s
	iters: 200, epoch: 4 | loss: 0.3578422
	speed: 0.2160s/iter; left time: 4838.2825s
Epoch: 4 cost time: 50.57875323295593
Epoch: 4, Steps: 233 Train Loss: 0.3664 (Forecasting Loss:0.3630 + XiCon Loss:3.3775 x Lambda(0.001)), Vali MSE Loss: 0.3513 Test MSE Loss: 0.3097
Validation loss decreased (0.356233 --> 0.351317).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3583904
	speed: 0.2163s/iter; left time: 4816.5212s
	iters: 200, epoch: 5 | loss: 0.3543421
	speed: 0.2138s/iter; left time: 4739.5919s
Epoch: 5 cost time: 50.5547137260437
Epoch: 5, Steps: 233 Train Loss: 0.3573 (Forecasting Loss:0.3539 + XiCon Loss:3.3722 x Lambda(0.001)), Vali MSE Loss: 0.3416 Test MSE Loss: 0.3066
Validation loss decreased (0.351317 --> 0.341601).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3316490
	speed: 0.2141s/iter; left time: 4717.0643s
	iters: 200, epoch: 6 | loss: 0.3587012
	speed: 0.2101s/iter; left time: 4607.9558s
Epoch: 6 cost time: 49.92276740074158
Epoch: 6, Steps: 233 Train Loss: 0.3513 (Forecasting Loss:0.3479 + XiCon Loss:3.3667 x Lambda(0.001)), Vali MSE Loss: 0.3390 Test MSE Loss: 0.3050
Validation loss decreased (0.341601 --> 0.339034).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3450703
	speed: 0.2173s/iter; left time: 4737.6898s
	iters: 200, epoch: 7 | loss: 0.3907786
	speed: 0.2151s/iter; left time: 4667.4833s
Epoch: 7 cost time: 50.89024233818054
Epoch: 7, Steps: 233 Train Loss: 0.3481 (Forecasting Loss:0.3447 + XiCon Loss:3.3617 x Lambda(0.001)), Vali MSE Loss: 0.3371 Test MSE Loss: 0.3035
Validation loss decreased (0.339034 --> 0.337088).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3458588
	speed: 0.2183s/iter; left time: 4709.0676s
	iters: 200, epoch: 8 | loss: 0.3549175
	speed: 0.2146s/iter; left time: 4607.0444s
Epoch: 8 cost time: 50.24682545661926
Epoch: 8, Steps: 233 Train Loss: 0.3461 (Forecasting Loss:0.3427 + XiCon Loss:3.3605 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3034
Validation loss decreased (0.337088 --> 0.334719).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3327719
	speed: 0.2235s/iter; left time: 4768.2284s
	iters: 200, epoch: 9 | loss: 0.3409969
	speed: 0.2163s/iter; left time: 4592.9563s
Epoch: 9 cost time: 51.31681823730469
Epoch: 9, Steps: 233 Train Loss: 0.3454 (Forecasting Loss:0.3420 + XiCon Loss:3.3602 x Lambda(0.001)), Vali MSE Loss: 0.3345 Test MSE Loss: 0.3031
Validation loss decreased (0.334719 --> 0.334481).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3883553
	speed: 0.2237s/iter; left time: 4720.1639s
	iters: 200, epoch: 10 | loss: 0.3372100
	speed: 0.2219s/iter; left time: 4661.8372s
Epoch: 10 cost time: 51.48112607002258
Epoch: 10, Steps: 233 Train Loss: 0.3450 (Forecasting Loss:0.3416 + XiCon Loss:3.3578 x Lambda(0.001)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.3027
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3400522
	speed: 0.2158s/iter; left time: 4504.6369s
	iters: 200, epoch: 11 | loss: 0.3424895
	speed: 0.2155s/iter; left time: 4475.4228s
Epoch: 11 cost time: 50.24788975715637
Epoch: 11, Steps: 233 Train Loss: 0.3447 (Forecasting Loss:0.3413 + XiCon Loss:3.3569 x Lambda(0.001)), Vali MSE Loss: 0.3346 Test MSE Loss: 0.3026
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3467993
	speed: 0.2215s/iter; left time: 4571.1056s
	iters: 200, epoch: 12 | loss: 0.3302205
	speed: 0.2236s/iter; left time: 4592.5895s
Epoch: 12 cost time: 51.96904015541077
Epoch: 12, Steps: 233 Train Loss: 0.3446 (Forecasting Loss:0.3413 + XiCon Loss:3.3583 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3537605
	speed: 0.2203s/iter; left time: 4496.0357s
	iters: 200, epoch: 13 | loss: 0.3330107
	speed: 0.2220s/iter; left time: 4507.2353s
Epoch: 13 cost time: 51.783957958221436
Epoch: 13, Steps: 233 Train Loss: 0.3446 (Forecasting Loss:0.3413 + XiCon Loss:3.3561 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3240920
	speed: 0.2109s/iter; left time: 4254.4366s
	iters: 200, epoch: 14 | loss: 0.3707561
	speed: 0.2196s/iter; left time: 4408.5163s
Epoch: 14 cost time: 50.51975464820862
Epoch: 14, Steps: 233 Train Loss: 0.3445 (Forecasting Loss:0.3411 + XiCon Loss:3.3573 x Lambda(0.001)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.3026
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3546495
	speed: 0.2124s/iter; left time: 4234.3882s
	iters: 200, epoch: 15 | loss: 0.3175962
	speed: 0.2226s/iter; left time: 4416.9769s
Epoch: 15 cost time: 51.00319790840149
Epoch: 15, Steps: 233 Train Loss: 0.3445 (Forecasting Loss:0.3411 + XiCon Loss:3.3568 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3779418
	speed: 0.2242s/iter; left time: 4418.1563s
	iters: 200, epoch: 16 | loss: 0.3583667
	speed: 0.2232s/iter; left time: 4375.4684s
Epoch: 16 cost time: 52.501689434051514
Epoch: 16, Steps: 233 Train Loss: 0.3445 (Forecasting Loss:0.3411 + XiCon Loss:3.3593 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3529714
	speed: 0.2194s/iter; left time: 4271.5605s
	iters: 200, epoch: 17 | loss: 0.3452361
	speed: 0.2153s/iter; left time: 4171.1929s
Epoch: 17 cost time: 50.38596034049988
Epoch: 17, Steps: 233 Train Loss: 0.3446 (Forecasting Loss:0.3413 + XiCon Loss:3.3582 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3316263
	speed: 0.1801s/iter; left time: 3465.1673s
	iters: 200, epoch: 18 | loss: 0.3344648
	speed: 0.1609s/iter; left time: 3079.9135s
Epoch: 18 cost time: 41.69513916969299
Epoch: 18, Steps: 233 Train Loss: 0.3447 (Forecasting Loss:0.3413 + XiCon Loss:3.3586 x Lambda(0.001)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.3026
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3562910
	speed: 0.2215s/iter; left time: 4209.7353s
	iters: 200, epoch: 19 | loss: 0.3320997
	speed: 0.1924s/iter; left time: 3636.8016s
Epoch: 19 cost time: 45.49224781990051
Epoch: 19, Steps: 233 Train Loss: 0.3445 (Forecasting Loss:0.3411 + XiCon Loss:3.3579 x Lambda(0.001)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.3026
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.22651369869709015, mae:0.37973126769065857, mape:0.6534446477890015, mspe:16.393117904663086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9250
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5699346
	speed: 0.2016s/iter; left time: 4676.9148s
	iters: 200, epoch: 1 | loss: 0.5677073
	speed: 0.1841s/iter; left time: 4253.7301s
Epoch: 1 cost time: 45.84116578102112
Epoch: 1, Steps: 233 Train Loss: 0.5528 (Forecasting Loss:0.5494 + XiCon Loss:3.3894 x Lambda(0.001)), Vali MSE Loss: 0.5046 Test MSE Loss: 0.4067
Validation loss decreased (inf --> 0.504574).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4128054
	speed: 0.2118s/iter; left time: 4864.6556s
	iters: 200, epoch: 2 | loss: 0.3945554
	speed: 0.1675s/iter; left time: 3831.2964s
Epoch: 2 cost time: 45.755918741226196
Epoch: 2, Steps: 233 Train Loss: 0.4057 (Forecasting Loss:0.4023 + XiCon Loss:3.3988 x Lambda(0.001)), Vali MSE Loss: 0.3805 Test MSE Loss: 0.3351
Validation loss decreased (0.504574 --> 0.380549).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3852923
	speed: 0.2191s/iter; left time: 4980.9028s
	iters: 200, epoch: 3 | loss: 0.3882576
	speed: 0.1994s/iter; left time: 4514.1908s
Epoch: 3 cost time: 46.32675123214722
Epoch: 3, Steps: 233 Train Loss: 0.3811 (Forecasting Loss:0.3777 + XiCon Loss:3.3850 x Lambda(0.001)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3324
Validation loss decreased (0.380549 --> 0.367574).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3857946
	speed: 0.2092s/iter; left time: 4708.1549s
	iters: 200, epoch: 4 | loss: 0.3598325
	speed: 0.2054s/iter; left time: 4601.4567s
Epoch: 4 cost time: 49.07636022567749
Epoch: 4, Steps: 233 Train Loss: 0.3747 (Forecasting Loss:0.3713 + XiCon Loss:3.3783 x Lambda(0.001)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.3345
Validation loss decreased (0.367574 --> 0.362245).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3473833
	speed: 0.2003s/iter; left time: 4459.9673s
	iters: 200, epoch: 5 | loss: 0.3979689
	speed: 0.2050s/iter; left time: 4544.7825s
Epoch: 5 cost time: 47.45595908164978
Epoch: 5, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3691 + XiCon Loss:3.3761 x Lambda(0.001)), Vali MSE Loss: 0.3642 Test MSE Loss: 0.3280
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3859997
	speed: 0.1670s/iter; left time: 3680.0753s
	iters: 200, epoch: 6 | loss: 0.3600690
	speed: 0.2067s/iter; left time: 4535.1795s
Epoch: 6 cost time: 44.856121301651
Epoch: 6, Steps: 233 Train Loss: 0.3707 (Forecasting Loss:0.3674 + XiCon Loss:3.3743 x Lambda(0.001)), Vali MSE Loss: 0.3618 Test MSE Loss: 0.3256
Validation loss decreased (0.362245 --> 0.361808).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3745531
	speed: 0.1972s/iter; left time: 4299.5258s
	iters: 200, epoch: 7 | loss: 0.3506067
	speed: 0.1907s/iter; left time: 4137.9947s
Epoch: 7 cost time: 45.98274755477905
Epoch: 7, Steps: 233 Train Loss: 0.3702 (Forecasting Loss:0.3668 + XiCon Loss:3.3743 x Lambda(0.001)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.3231
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3501198
	speed: 0.2164s/iter; left time: 4667.0954s
	iters: 200, epoch: 8 | loss: 0.3551789
	speed: 0.1645s/iter; left time: 3531.3844s
Epoch: 8 cost time: 45.11514353752136
Epoch: 8, Steps: 233 Train Loss: 0.3701 (Forecasting Loss:0.3667 + XiCon Loss:3.3731 x Lambda(0.001)), Vali MSE Loss: 0.3630 Test MSE Loss: 0.3240
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3636485
	speed: 0.2188s/iter; left time: 4668.7455s
	iters: 200, epoch: 9 | loss: 0.3414471
	speed: 0.2003s/iter; left time: 4253.0786s
Epoch: 9 cost time: 46.42981839179993
Epoch: 9, Steps: 233 Train Loss: 0.3697 (Forecasting Loss:0.3663 + XiCon Loss:3.3746 x Lambda(0.001)), Vali MSE Loss: 0.3617 Test MSE Loss: 0.3248
Validation loss decreased (0.361808 --> 0.361692).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3726951
	speed: 0.2104s/iter; left time: 4441.1873s
	iters: 200, epoch: 10 | loss: 0.3574712
	speed: 0.2060s/iter; left time: 4327.8012s
Epoch: 10 cost time: 49.47501182556152
Epoch: 10, Steps: 233 Train Loss: 0.3692 (Forecasting Loss:0.3658 + XiCon Loss:3.3752 x Lambda(0.001)), Vali MSE Loss: 0.3623 Test MSE Loss: 0.3243
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3596280
	speed: 0.2051s/iter; left time: 4281.3783s
	iters: 200, epoch: 11 | loss: 0.3808556
	speed: 0.2166s/iter; left time: 4498.5792s
Epoch: 11 cost time: 49.46260404586792
Epoch: 11, Steps: 233 Train Loss: 0.3694 (Forecasting Loss:0.3660 + XiCon Loss:3.3742 x Lambda(0.001)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.3243
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3820612
	speed: 0.2228s/iter; left time: 4597.8975s
	iters: 200, epoch: 12 | loss: 0.3643351
	speed: 0.2133s/iter; left time: 4381.7056s
Epoch: 12 cost time: 50.49138045310974
Epoch: 12, Steps: 233 Train Loss: 0.3691 (Forecasting Loss:0.3658 + XiCon Loss:3.3744 x Lambda(0.001)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.3243
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3700733
	speed: 0.2146s/iter; left time: 4378.0057s
	iters: 200, epoch: 13 | loss: 0.3876933
	speed: 0.2108s/iter; left time: 4280.5009s
Epoch: 13 cost time: 49.42691206932068
Epoch: 13, Steps: 233 Train Loss: 0.3694 (Forecasting Loss:0.3660 + XiCon Loss:3.3732 x Lambda(0.001)), Vali MSE Loss: 0.3621 Test MSE Loss: 0.3243
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3747817
	speed: 0.2171s/iter; left time: 4378.5593s
	iters: 200, epoch: 14 | loss: 0.3870493
	speed: 0.2200s/iter; left time: 4415.8561s
Epoch: 14 cost time: 51.03383731842041
Epoch: 14, Steps: 233 Train Loss: 0.3692 (Forecasting Loss:0.3659 + XiCon Loss:3.3729 x Lambda(0.001)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.3243
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3412274
	speed: 0.2141s/iter; left time: 4268.0376s
	iters: 200, epoch: 15 | loss: 0.3794211
	speed: 0.2144s/iter; left time: 4253.9632s
Epoch: 15 cost time: 50.072856187820435
Epoch: 15, Steps: 233 Train Loss: 0.3692 (Forecasting Loss:0.3658 + XiCon Loss:3.3744 x Lambda(0.001)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.3243
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3686844
	speed: 0.1605s/iter; left time: 3161.8680s
	iters: 200, epoch: 16 | loss: 0.3674554
	speed: 0.2111s/iter; left time: 4139.0307s
Epoch: 16 cost time: 44.470720052719116
Epoch: 16, Steps: 233 Train Loss: 0.3694 (Forecasting Loss:0.3661 + XiCon Loss:3.3742 x Lambda(0.001)), Vali MSE Loss: 0.3623 Test MSE Loss: 0.3243
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3250752
	speed: 0.2204s/iter; left time: 4292.7527s
	iters: 200, epoch: 17 | loss: 0.3514578
	speed: 0.2048s/iter; left time: 3967.3262s
Epoch: 17 cost time: 49.42295217514038
Epoch: 17, Steps: 233 Train Loss: 0.3693 (Forecasting Loss:0.3659 + XiCon Loss:3.3742 x Lambda(0.001)), Vali MSE Loss: 0.3623 Test MSE Loss: 0.3243
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3573652
	speed: 0.2191s/iter; left time: 4215.3091s
	iters: 200, epoch: 18 | loss: 0.3768287
	speed: 0.2089s/iter; left time: 3998.5909s
Epoch: 18 cost time: 49.70791721343994
Epoch: 18, Steps: 233 Train Loss: 0.3693 (Forecasting Loss:0.3659 + XiCon Loss:3.3736 x Lambda(0.001)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.3243
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3764090
	speed: 0.2225s/iter; left time: 4229.1314s
	iters: 200, epoch: 19 | loss: 0.3757179
	speed: 0.2123s/iter; left time: 4013.7149s
Epoch: 19 cost time: 51.10545206069946
Epoch: 19, Steps: 233 Train Loss: 0.3693 (Forecasting Loss:0.3659 + XiCon Loss:3.3735 x Lambda(0.001)), Vali MSE Loss: 0.3621 Test MSE Loss: 0.3243
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.25499317049980164, mae:0.39458292722702026, mape:0.7103844285011292, mspe:21.17408561706543 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.7041
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.6067045
	speed: 0.2160s/iter; left time: 5012.1744s
	iters: 200, epoch: 1 | loss: 0.5204124
	speed: 0.2129s/iter; left time: 4917.1049s
Epoch: 1 cost time: 50.479092836380005
Epoch: 1, Steps: 233 Train Loss: 0.5582 (Forecasting Loss:0.5548 + XiCon Loss:3.4045 x Lambda(0.001)), Vali MSE Loss: 0.5108 Test MSE Loss: 0.4187
Validation loss decreased (inf --> 0.510805).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4049512
	speed: 0.2347s/iter; left time: 5390.1446s
	iters: 200, epoch: 2 | loss: 0.3812778
	speed: 0.2248s/iter; left time: 5139.6445s
Epoch: 2 cost time: 53.87130069732666
Epoch: 2, Steps: 233 Train Loss: 0.4092 (Forecasting Loss:0.4058 + XiCon Loss:3.4053 x Lambda(0.001)), Vali MSE Loss: 0.3647 Test MSE Loss: 0.3265
Validation loss decreased (0.510805 --> 0.364661).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3858309
	speed: 0.2275s/iter; left time: 5171.7044s
	iters: 200, epoch: 3 | loss: 0.3651080
	speed: 0.2091s/iter; left time: 4733.5146s
Epoch: 3 cost time: 51.174485206604004
Epoch: 3, Steps: 233 Train Loss: 0.3689 (Forecasting Loss:0.3655 + XiCon Loss:3.3719 x Lambda(0.001)), Vali MSE Loss: 0.3447 Test MSE Loss: 0.3007
Validation loss decreased (0.364661 --> 0.344747).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3360548
	speed: 0.2333s/iter; left time: 5249.3775s
	iters: 200, epoch: 4 | loss: 0.3337723
	speed: 0.2258s/iter; left time: 5059.2027s
Epoch: 4 cost time: 53.36974215507507
Epoch: 4, Steps: 233 Train Loss: 0.3457 (Forecasting Loss:0.3423 + XiCon Loss:3.3536 x Lambda(0.001)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3068
Validation loss decreased (0.344747 --> 0.331625).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3464101
	speed: 0.2301s/iter; left time: 5123.0147s
	iters: 200, epoch: 5 | loss: 0.3606376
	speed: 0.2236s/iter; left time: 4956.0253s
Epoch: 5 cost time: 53.0468270778656
Epoch: 5, Steps: 233 Train Loss: 0.3366 (Forecasting Loss:0.3332 + XiCon Loss:3.3504 x Lambda(0.001)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.3031
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3469869
	speed: 0.2296s/iter; left time: 5060.2114s
	iters: 200, epoch: 6 | loss: 0.3508097
	speed: 0.2201s/iter; left time: 4828.3843s
Epoch: 6 cost time: 52.711559534072876
Epoch: 6, Steps: 233 Train Loss: 0.3334 (Forecasting Loss:0.3301 + XiCon Loss:3.3478 x Lambda(0.001)), Vali MSE Loss: 0.3341 Test MSE Loss: 0.3072
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3392250
	speed: 0.2307s/iter; left time: 5030.4214s
	iters: 200, epoch: 7 | loss: 0.3365976
	speed: 0.2220s/iter; left time: 4818.7999s
Epoch: 7 cost time: 52.95076513290405
Epoch: 7, Steps: 233 Train Loss: 0.3320 (Forecasting Loss:0.3286 + XiCon Loss:3.3451 x Lambda(0.001)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.3089
Validation loss decreased (0.331625 --> 0.327971).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3196495
	speed: 0.2216s/iter; left time: 4778.8972s
	iters: 200, epoch: 8 | loss: 0.3507670
	speed: 0.2236s/iter; left time: 4801.2496s
Epoch: 8 cost time: 52.246793270111084
Epoch: 8, Steps: 233 Train Loss: 0.3311 (Forecasting Loss:0.3278 + XiCon Loss:3.3451 x Lambda(0.001)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.3109
Validation loss decreased (0.327971 --> 0.325935).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3165584
	speed: 0.2317s/iter; left time: 4943.0236s
	iters: 200, epoch: 9 | loss: 0.3312325
	speed: 0.2125s/iter; left time: 4512.2488s
Epoch: 9 cost time: 51.95346999168396
Epoch: 9, Steps: 233 Train Loss: 0.3306 (Forecasting Loss:0.3273 + XiCon Loss:3.3433 x Lambda(0.001)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.3113
Validation loss decreased (0.325935 --> 0.325719).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3253180
	speed: 0.2298s/iter; left time: 4848.7795s
	iters: 200, epoch: 10 | loss: 0.3207552
	speed: 0.2194s/iter; left time: 4607.3912s
Epoch: 10 cost time: 52.74954700469971
Epoch: 10, Steps: 233 Train Loss: 0.3307 (Forecasting Loss:0.3273 + XiCon Loss:3.3434 x Lambda(0.001)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3095
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3364473
	speed: 0.2293s/iter; left time: 4785.1233s
	iters: 200, epoch: 11 | loss: 0.3102741
	speed: 0.2172s/iter; left time: 4510.4789s
Epoch: 11 cost time: 52.53312921524048
Epoch: 11, Steps: 233 Train Loss: 0.3305 (Forecasting Loss:0.3271 + XiCon Loss:3.3438 x Lambda(0.001)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.3101
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3377255
	speed: 0.2246s/iter; left time: 4635.9606s
	iters: 200, epoch: 12 | loss: 0.3144231
	speed: 0.2150s/iter; left time: 4415.3320s
Epoch: 12 cost time: 51.670249223709106
Epoch: 12, Steps: 233 Train Loss: 0.3304 (Forecasting Loss:0.3271 + XiCon Loss:3.3446 x Lambda(0.001)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.3100
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3218464
	speed: 0.2340s/iter; left time: 4774.8261s
	iters: 200, epoch: 13 | loss: 0.3333189
	speed: 0.2211s/iter; left time: 4489.1104s
Epoch: 13 cost time: 52.74976897239685
Epoch: 13, Steps: 233 Train Loss: 0.3304 (Forecasting Loss:0.3270 + XiCon Loss:3.3443 x Lambda(0.001)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.3098
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.2947557
	speed: 0.2265s/iter; left time: 4568.5798s
	iters: 200, epoch: 14 | loss: 0.3495445
	speed: 0.2142s/iter; left time: 4298.9799s
Epoch: 14 cost time: 51.53032445907593
Epoch: 14, Steps: 233 Train Loss: 0.3304 (Forecasting Loss:0.3271 + XiCon Loss:3.3444 x Lambda(0.001)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3097
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3016187
	speed: 0.2307s/iter; left time: 4599.1605s
	iters: 200, epoch: 15 | loss: 0.3368263
	speed: 0.2259s/iter; left time: 4481.4846s
Epoch: 15 cost time: 53.2439980506897
Epoch: 15, Steps: 233 Train Loss: 0.3301 (Forecasting Loss:0.3268 + XiCon Loss:3.3430 x Lambda(0.001)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3097
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3294488
	speed: 0.2226s/iter; left time: 4387.1365s
	iters: 200, epoch: 16 | loss: 0.3462462
	speed: 0.1887s/iter; left time: 3700.3882s
Epoch: 16 cost time: 47.1331090927124
Epoch: 16, Steps: 233 Train Loss: 0.3303 (Forecasting Loss:0.3270 + XiCon Loss:3.3436 x Lambda(0.001)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3097
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3537856
	speed: 0.2137s/iter; left time: 4161.2902s
	iters: 200, epoch: 17 | loss: 0.3350510
	speed: 0.2199s/iter; left time: 4260.2967s
Epoch: 17 cost time: 51.12173008918762
Epoch: 17, Steps: 233 Train Loss: 0.3300 (Forecasting Loss:0.3267 + XiCon Loss:3.3446 x Lambda(0.001)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3097
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3378923
	speed: 0.1525s/iter; left time: 2933.9922s
	iters: 200, epoch: 18 | loss: 0.3289761
	speed: 0.2228s/iter; left time: 4264.7186s
Epoch: 18 cost time: 44.84109163284302
Epoch: 18, Steps: 233 Train Loss: 0.3303 (Forecasting Loss:0.3270 + XiCon Loss:3.3437 x Lambda(0.001)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3097
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3203891
	speed: 0.2036s/iter; left time: 3868.9799s
	iters: 200, epoch: 19 | loss: 0.3366350
	speed: 0.1707s/iter; left time: 3226.5279s
Epoch: 19 cost time: 45.3208966255188
Epoch: 19, Steps: 233 Train Loss: 0.3303 (Forecasting Loss:0.3270 + XiCon Loss:3.3452 x Lambda(0.001)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.3097
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2340136021375656, mae:0.3885807394981384, mape:0.6164688467979431, mspe:13.400984764099121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2492+-0.02965, MAE:0.3957+-0.01792, MAPE:0.6768+-0.07010, MSPE:17.9559+-5.84146, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
