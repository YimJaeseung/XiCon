Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4030
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5501723
	speed: 0.0231s/iter; left time: 292.9857s
Epoch: 1 cost time: 2.9797980785369873
Epoch: 1, Steps: 128 Train Loss: 0.5543 (Forecasting Loss:0.2442 + XiCon Loss:3.1009 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1220
Validation loss decreased (inf --> 0.173529).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5635999
	speed: 0.0240s/iter; left time: 301.5788s
Epoch: 2 cost time: 3.0790841579437256
Epoch: 2, Steps: 128 Train Loss: 0.5369 (Forecasting Loss:0.2423 + XiCon Loss:2.9460 x Lambda(0.1)), Vali MSE Loss: 0.1805 Test MSE Loss: 0.1325
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4819084
	speed: 0.0244s/iter; left time: 303.0537s
Epoch: 3 cost time: 3.1718626022338867
Epoch: 3, Steps: 128 Train Loss: 0.5240 (Forecasting Loss:0.2319 + XiCon Loss:2.9209 x Lambda(0.1)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1251
Validation loss decreased (0.173529 --> 0.168536).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4942312
	speed: 0.0238s/iter; left time: 293.2373s
Epoch: 4 cost time: 3.0584685802459717
Epoch: 4, Steps: 128 Train Loss: 0.5093 (Forecasting Loss:0.2213 + XiCon Loss:2.8791 x Lambda(0.1)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1185
Validation loss decreased (0.168536 --> 0.167736).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4848228
	speed: 0.0242s/iter; left time: 295.2309s
Epoch: 5 cost time: 3.049936532974243
Epoch: 5, Steps: 128 Train Loss: 0.5034 (Forecasting Loss:0.2153 + XiCon Loss:2.8816 x Lambda(0.1)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1220
Validation loss decreased (0.167736 --> 0.165300).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4943701
	speed: 0.0242s/iter; left time: 291.7087s
Epoch: 6 cost time: 3.0744478702545166
Epoch: 6, Steps: 128 Train Loss: 0.4997 (Forecasting Loss:0.2127 + XiCon Loss:2.8705 x Lambda(0.1)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1204
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4740178
	speed: 0.0214s/iter; left time: 255.6938s
Epoch: 7 cost time: 2.7517802715301514
Epoch: 7, Steps: 128 Train Loss: 0.4980 (Forecasting Loss:0.2111 + XiCon Loss:2.8685 x Lambda(0.1)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1218
Validation loss decreased (0.165300 --> 0.164589).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5021483
	speed: 0.0259s/iter; left time: 305.6973s
Epoch: 8 cost time: 3.228092908859253
Epoch: 8, Steps: 128 Train Loss: 0.4971 (Forecasting Loss:0.2105 + XiCon Loss:2.8657 x Lambda(0.1)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1215
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5438083
	speed: 0.0244s/iter; left time: 284.9863s
Epoch: 9 cost time: 3.097306966781616
Epoch: 9, Steps: 128 Train Loss: 0.4965 (Forecasting Loss:0.2101 + XiCon Loss:2.8640 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1213
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5087683
	speed: 0.0235s/iter; left time: 271.7358s
Epoch: 10 cost time: 3.003645420074463
Epoch: 10, Steps: 128 Train Loss: 0.4965 (Forecasting Loss:0.2099 + XiCon Loss:2.8661 x Lambda(0.1)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1219
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4858519
	speed: 0.0251s/iter; left time: 286.2258s
Epoch: 11 cost time: 3.194195032119751
Epoch: 11, Steps: 128 Train Loss: 0.4958 (Forecasting Loss:0.2098 + XiCon Loss:2.8601 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1219
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5026964
	speed: 0.0253s/iter; left time: 285.9314s
Epoch: 12 cost time: 3.176053285598755
Epoch: 12, Steps: 128 Train Loss: 0.4958 (Forecasting Loss:0.2095 + XiCon Loss:2.8624 x Lambda(0.1)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1218
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5229453
	speed: 0.0225s/iter; left time: 250.9652s
Epoch: 13 cost time: 2.8389694690704346
Epoch: 13, Steps: 128 Train Loss: 0.4961 (Forecasting Loss:0.2096 + XiCon Loss:2.8645 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1219
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4896630
	speed: 0.0250s/iter; left time: 276.1654s
Epoch: 14 cost time: 3.1117396354675293
Epoch: 14, Steps: 128 Train Loss: 0.4960 (Forecasting Loss:0.2096 + XiCon Loss:2.8645 x Lambda(0.1)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1219
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5352064
	speed: 0.0252s/iter; left time: 275.2025s
Epoch: 15 cost time: 3.1171481609344482
Epoch: 15, Steps: 128 Train Loss: 0.4960 (Forecasting Loss:0.2096 + XiCon Loss:2.8647 x Lambda(0.1)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1218
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4796266
	speed: 0.0236s/iter; left time: 254.3887s
Epoch: 16 cost time: 3.0128610134124756
Epoch: 16, Steps: 128 Train Loss: 0.4963 (Forecasting Loss:0.2098 + XiCon Loss:2.8655 x Lambda(0.1)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1218
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4965919
	speed: 0.0234s/iter; left time: 249.5503s
Epoch: 17 cost time: 3.0018198490142822
Epoch: 17, Steps: 128 Train Loss: 0.4963 (Forecasting Loss:0.2099 + XiCon Loss:2.8645 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1218
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0590568408370018, mae:0.18454523384571075, mape:0.15317967534065247, mspe:0.05494854226708412 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5352231
	speed: 0.0229s/iter; left time: 290.4206s
Epoch: 1 cost time: 2.928396701812744
Epoch: 1, Steps: 128 Train Loss: 0.5503 (Forecasting Loss:0.2412 + XiCon Loss:3.0903 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1198
Validation loss decreased (inf --> 0.171222).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5786128
	speed: 0.0214s/iter; left time: 269.5153s
Epoch: 2 cost time: 2.811915636062622
Epoch: 2, Steps: 128 Train Loss: 0.5318 (Forecasting Loss:0.2373 + XiCon Loss:2.9450 x Lambda(0.1)), Vali MSE Loss: 0.1898 Test MSE Loss: 0.1224
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4798198
	speed: 0.0253s/iter; left time: 314.8680s
Epoch: 3 cost time: 3.138676404953003
Epoch: 3, Steps: 128 Train Loss: 0.4877 (Forecasting Loss:0.2002 + XiCon Loss:2.8754 x Lambda(0.1)), Vali MSE Loss: 0.1811 Test MSE Loss: 0.1479
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4599417
	speed: 0.0247s/iter; left time: 303.7896s
Epoch: 4 cost time: 3.0650007724761963
Epoch: 4, Steps: 128 Train Loss: 0.4707 (Forecasting Loss:0.1764 + XiCon Loss:2.9434 x Lambda(0.1)), Vali MSE Loss: 0.1761 Test MSE Loss: 0.1504
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4556746
	speed: 0.0244s/iter; left time: 297.5012s
Epoch: 5 cost time: 3.0836126804351807
Epoch: 5, Steps: 128 Train Loss: 0.4511 (Forecasting Loss:0.1612 + XiCon Loss:2.8992 x Lambda(0.1)), Vali MSE Loss: 0.1747 Test MSE Loss: 0.1515
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4449080
	speed: 0.0243s/iter; left time: 292.6654s
Epoch: 6 cost time: 3.043013334274292
Epoch: 6, Steps: 128 Train Loss: 0.4447 (Forecasting Loss:0.1553 + XiCon Loss:2.8939 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1576
Validation loss decreased (0.171222 --> 0.170339).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4329289
	speed: 0.0221s/iter; left time: 264.2748s
Epoch: 7 cost time: 2.902731418609619
Epoch: 7, Steps: 128 Train Loss: 0.4397 (Forecasting Loss:0.1512 + XiCon Loss:2.8847 x Lambda(0.1)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1660
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4455180
	speed: 0.0212s/iter; left time: 249.7239s
Epoch: 8 cost time: 2.725344181060791
Epoch: 8, Steps: 128 Train Loss: 0.4381 (Forecasting Loss:0.1494 + XiCon Loss:2.8864 x Lambda(0.1)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1653
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4349495
	speed: 0.0250s/iter; left time: 291.9576s
Epoch: 9 cost time: 3.1136221885681152
Epoch: 9, Steps: 128 Train Loss: 0.4380 (Forecasting Loss:0.1486 + XiCon Loss:2.8934 x Lambda(0.1)), Vali MSE Loss: 0.1748 Test MSE Loss: 0.1672
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4359974
	speed: 0.0263s/iter; left time: 303.2298s
Epoch: 10 cost time: 3.293962001800537
Epoch: 10, Steps: 128 Train Loss: 0.4364 (Forecasting Loss:0.1479 + XiCon Loss:2.8851 x Lambda(0.1)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4436658
	speed: 0.0239s/iter; left time: 272.6449s
Epoch: 11 cost time: 3.0250391960144043
Epoch: 11, Steps: 128 Train Loss: 0.4365 (Forecasting Loss:0.1478 + XiCon Loss:2.8865 x Lambda(0.1)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1660
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4207376
	speed: 0.0273s/iter; left time: 308.6985s
Epoch: 12 cost time: 3.3845696449279785
Epoch: 12, Steps: 128 Train Loss: 0.4364 (Forecasting Loss:0.1476 + XiCon Loss:2.8879 x Lambda(0.1)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1660
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4235333
	speed: 0.0228s/iter; left time: 254.3925s
Epoch: 13 cost time: 2.8074324131011963
Epoch: 13, Steps: 128 Train Loss: 0.4364 (Forecasting Loss:0.1479 + XiCon Loss:2.8853 x Lambda(0.1)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1662
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4274538
	speed: 0.0217s/iter; left time: 239.2486s
Epoch: 14 cost time: 2.672762393951416
Epoch: 14, Steps: 128 Train Loss: 0.4355 (Forecasting Loss:0.1476 + XiCon Loss:2.8785 x Lambda(0.1)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1662
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4326132
	speed: 0.0248s/iter; left time: 270.4552s
Epoch: 15 cost time: 3.1085317134857178
Epoch: 15, Steps: 128 Train Loss: 0.4368 (Forecasting Loss:0.1479 + XiCon Loss:2.8885 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1662
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4370871
	speed: 0.0243s/iter; left time: 262.2462s
Epoch: 16 cost time: 3.049198627471924
Epoch: 16, Steps: 128 Train Loss: 0.4369 (Forecasting Loss:0.1480 + XiCon Loss:2.8894 x Lambda(0.1)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1662
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.08802720159292221, mae:0.22707447409629822, mape:0.1959858238697052, mspe:0.10391905158758163 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3332
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5337553
	speed: 0.0267s/iter; left time: 338.8089s
Epoch: 1 cost time: 3.4075167179107666
Epoch: 1, Steps: 128 Train Loss: 0.5509 (Forecasting Loss:0.2429 + XiCon Loss:3.0802 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1202
Validation loss decreased (inf --> 0.169781).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5656931
	speed: 0.0253s/iter; left time: 318.5561s
Epoch: 2 cost time: 3.2150919437408447
Epoch: 2, Steps: 128 Train Loss: 0.5455 (Forecasting Loss:0.2475 + XiCon Loss:2.9797 x Lambda(0.1)), Vali MSE Loss: 0.1803 Test MSE Loss: 0.1198
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5370671
	speed: 0.0213s/iter; left time: 265.1619s
Epoch: 3 cost time: 2.5741500854492188
Epoch: 3, Steps: 128 Train Loss: 0.5265 (Forecasting Loss:0.2316 + XiCon Loss:2.9486 x Lambda(0.1)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1216
Validation loss decreased (0.169781 --> 0.165675).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5082471
	speed: 0.0222s/iter; left time: 272.8850s
Epoch: 4 cost time: 2.8964438438415527
Epoch: 4, Steps: 128 Train Loss: 0.5140 (Forecasting Loss:0.2230 + XiCon Loss:2.9104 x Lambda(0.1)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1224
Validation loss decreased (0.165675 --> 0.165240).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5198256
	speed: 0.0251s/iter; left time: 305.7486s
Epoch: 5 cost time: 3.141303777694702
Epoch: 5, Steps: 128 Train Loss: 0.5065 (Forecasting Loss:0.2174 + XiCon Loss:2.8918 x Lambda(0.1)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1151
Validation loss decreased (0.165240 --> 0.163407).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4816963
	speed: 0.0261s/iter; left time: 314.9484s
Epoch: 6 cost time: 3.2731428146362305
Epoch: 6, Steps: 128 Train Loss: 0.5037 (Forecasting Loss:0.2149 + XiCon Loss:2.8885 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
Validation loss decreased (0.163407 --> 0.163254).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4821055
	speed: 0.0260s/iter; left time: 310.0672s
Epoch: 7 cost time: 3.2400543689727783
Epoch: 7, Steps: 128 Train Loss: 0.5032 (Forecasting Loss:0.2141 + XiCon Loss:2.8910 x Lambda(0.1)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5115474
	speed: 0.0250s/iter; left time: 295.3662s
Epoch: 8 cost time: 3.203364610671997
Epoch: 8, Steps: 128 Train Loss: 0.5021 (Forecasting Loss:0.2136 + XiCon Loss:2.8850 x Lambda(0.1)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1162
Validation loss decreased (0.163254 --> 0.163173).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5096440
	speed: 0.0224s/iter; left time: 261.5161s
Epoch: 9 cost time: 2.7979531288146973
Epoch: 9, Steps: 128 Train Loss: 0.5018 (Forecasting Loss:0.2133 + XiCon Loss:2.8848 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1151
Validation loss decreased (0.163173 --> 0.162886).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5339532
	speed: 0.0224s/iter; left time: 258.5192s
Epoch: 10 cost time: 2.9547107219696045
Epoch: 10, Steps: 128 Train Loss: 0.5013 (Forecasting Loss:0.2131 + XiCon Loss:2.8822 x Lambda(0.1)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5074550
	speed: 0.0254s/iter; left time: 290.6157s
Epoch: 11 cost time: 3.210232973098755
Epoch: 11, Steps: 128 Train Loss: 0.5013 (Forecasting Loss:0.2128 + XiCon Loss:2.8856 x Lambda(0.1)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5277017
	speed: 0.0262s/iter; left time: 296.0818s
Epoch: 12 cost time: 3.224071741104126
Epoch: 12, Steps: 128 Train Loss: 0.5012 (Forecasting Loss:0.2130 + XiCon Loss:2.8827 x Lambda(0.1)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1151
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4919155
	speed: 0.0242s/iter; left time: 270.6671s
Epoch: 13 cost time: 3.0485501289367676
Epoch: 13, Steps: 128 Train Loss: 0.5015 (Forecasting Loss:0.2127 + XiCon Loss:2.8877 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1151
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5098493
	speed: 0.0250s/iter; left time: 276.2326s
Epoch: 14 cost time: 3.0969161987304688
Epoch: 14, Steps: 128 Train Loss: 0.5009 (Forecasting Loss:0.2129 + XiCon Loss:2.8799 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1151
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4960831
	speed: 0.0220s/iter; left time: 239.5643s
Epoch: 15 cost time: 2.6455063819885254
Epoch: 15, Steps: 128 Train Loss: 0.5011 (Forecasting Loss:0.2128 + XiCon Loss:2.8833 x Lambda(0.1)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1151
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4784498
	speed: 0.0214s/iter; left time: 230.6414s
Epoch: 16 cost time: 2.7696306705474854
Epoch: 16, Steps: 128 Train Loss: 0.5006 (Forecasting Loss:0.2128 + XiCon Loss:2.8784 x Lambda(0.1)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1151
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5232673
	speed: 0.0253s/iter; left time: 269.2943s
Epoch: 17 cost time: 3.1855521202087402
Epoch: 17, Steps: 128 Train Loss: 0.5011 (Forecasting Loss:0.2128 + XiCon Loss:2.8832 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1151
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.4960827
	speed: 0.0251s/iter; left time: 264.6106s
Epoch: 18 cost time: 3.1931893825531006
Epoch: 18, Steps: 128 Train Loss: 0.5009 (Forecasting Loss:0.2128 + XiCon Loss:2.8808 x Lambda(0.1)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1151
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5035638
	speed: 0.0252s/iter; left time: 262.3162s
Epoch: 19 cost time: 3.1508822441101074
Epoch: 19, Steps: 128 Train Loss: 0.5010 (Forecasting Loss:0.2129 + XiCon Loss:2.8811 x Lambda(0.1)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1151
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054133497178554535, mae:0.17603914439678192, mape:0.13988147675991058, mspe:0.03709198907017708 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3787
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5456648
	speed: 0.0246s/iter; left time: 312.7376s
Epoch: 1 cost time: 3.015097141265869
Epoch: 1, Steps: 128 Train Loss: 0.5507 (Forecasting Loss:0.2420 + XiCon Loss:3.0870 x Lambda(0.1)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.172258).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5458976
	speed: 0.0218s/iter; left time: 274.1172s
Epoch: 2 cost time: 2.713719367980957
Epoch: 2, Steps: 128 Train Loss: 0.5435 (Forecasting Loss:0.2459 + XiCon Loss:2.9760 x Lambda(0.1)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1265
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5784373
	speed: 0.0186s/iter; left time: 231.5625s
Epoch: 3 cost time: 2.2055342197418213
Epoch: 3, Steps: 128 Train Loss: 0.5213 (Forecasting Loss:0.2289 + XiCon Loss:2.9246 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1229
Validation loss decreased (0.172258 --> 0.169307).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5014067
	speed: 0.0564s/iter; left time: 694.2411s
Epoch: 4 cost time: 6.57252311706543
Epoch: 4, Steps: 128 Train Loss: 0.5080 (Forecasting Loss:0.2191 + XiCon Loss:2.8888 x Lambda(0.1)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1180
Validation loss decreased (0.169307 --> 0.168796).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5344354
	speed: 0.0185s/iter; left time: 225.4032s
Epoch: 5 cost time: 2.2100541591644287
Epoch: 5, Steps: 128 Train Loss: 0.5005 (Forecasting Loss:0.2117 + XiCon Loss:2.8875 x Lambda(0.1)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1151
Validation loss decreased (0.168796 --> 0.164391).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4873471
	speed: 0.0134s/iter; left time: 161.2944s
Epoch: 6 cost time: 1.6837244033813477
Epoch: 6, Steps: 128 Train Loss: 0.4933 (Forecasting Loss:0.2051 + XiCon Loss:2.8824 x Lambda(0.1)), Vali MSE Loss: 0.1597 Test MSE Loss: 0.1158
Validation loss decreased (0.164391 --> 0.159739).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4679906
	speed: 0.0127s/iter; left time: 151.4419s
Epoch: 7 cost time: 1.580758810043335
Epoch: 7, Steps: 128 Train Loss: 0.4907 (Forecasting Loss:0.2023 + XiCon Loss:2.8834 x Lambda(0.1)), Vali MSE Loss: 0.1597 Test MSE Loss: 0.1167
Validation loss decreased (0.159739 --> 0.159685).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4875086
	speed: 0.0138s/iter; left time: 162.4433s
Epoch: 8 cost time: 1.9726347923278809
Epoch: 8, Steps: 128 Train Loss: 0.4888 (Forecasting Loss:0.2004 + XiCon Loss:2.8835 x Lambda(0.1)), Vali MSE Loss: 0.1591 Test MSE Loss: 0.1166
Validation loss decreased (0.159685 --> 0.159106).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4646901
	speed: 0.0252s/iter; left time: 294.1588s
Epoch: 9 cost time: 3.1408376693725586
Epoch: 9, Steps: 128 Train Loss: 0.4883 (Forecasting Loss:0.2001 + XiCon Loss:2.8825 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1168
Validation loss decreased (0.159106 --> 0.158746).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5012736
	speed: 0.0252s/iter; left time: 291.4385s
Epoch: 10 cost time: 3.190272331237793
Epoch: 10, Steps: 128 Train Loss: 0.4876 (Forecasting Loss:0.1998 + XiCon Loss:2.8779 x Lambda(0.1)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4894395
	speed: 0.0254s/iter; left time: 290.4669s
Epoch: 11 cost time: 3.2412686347961426
Epoch: 11, Steps: 128 Train Loss: 0.4870 (Forecasting Loss:0.1988 + XiCon Loss:2.8827 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1171
Validation loss decreased (0.158746 --> 0.158719).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4715055
	speed: 0.0242s/iter; left time: 273.8271s
Epoch: 12 cost time: 3.068605422973633
Epoch: 12, Steps: 128 Train Loss: 0.4867 (Forecasting Loss:0.1989 + XiCon Loss:2.8775 x Lambda(0.1)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1170
Validation loss decreased (0.158719 --> 0.158580).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4427897
	speed: 0.0233s/iter; left time: 259.7839s
Epoch: 13 cost time: 2.9407882690429688
Epoch: 13, Steps: 128 Train Loss: 0.4871 (Forecasting Loss:0.1987 + XiCon Loss:2.8838 x Lambda(0.1)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4985553
	speed: 0.0195s/iter; left time: 215.1119s
Epoch: 14 cost time: 2.460744857788086
Epoch: 14, Steps: 128 Train Loss: 0.4864 (Forecasting Loss:0.1989 + XiCon Loss:2.8752 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4956708
	speed: 0.0248s/iter; left time: 270.9850s
Epoch: 15 cost time: 3.188194751739502
Epoch: 15, Steps: 128 Train Loss: 0.4876 (Forecasting Loss:0.1988 + XiCon Loss:2.8876 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1170
Validation loss decreased (0.158580 --> 0.158538).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4840033
	speed: 0.0247s/iter; left time: 265.7880s
Epoch: 16 cost time: 3.1894280910491943
Epoch: 16, Steps: 128 Train Loss: 0.4866 (Forecasting Loss:0.1986 + XiCon Loss:2.8807 x Lambda(0.1)), Vali MSE Loss: 0.1584 Test MSE Loss: 0.1170
Validation loss decreased (0.158538 --> 0.158400).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5134330
	speed: 0.0244s/iter; left time: 260.4186s
Epoch: 17 cost time: 3.0480594635009766
Epoch: 17, Steps: 128 Train Loss: 0.4874 (Forecasting Loss:0.1987 + XiCon Loss:2.8871 x Lambda(0.1)), Vali MSE Loss: 0.1589 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5153311
	speed: 0.0253s/iter; left time: 266.5969s
Epoch: 18 cost time: 3.1593596935272217
Epoch: 18, Steps: 128 Train Loss: 0.4872 (Forecasting Loss:0.1986 + XiCon Loss:2.8855 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5122180
	speed: 0.0217s/iter; left time: 225.6804s
Epoch: 19 cost time: 2.8462164402008057
Epoch: 19, Steps: 128 Train Loss: 0.4868 (Forecasting Loss:0.1989 + XiCon Loss:2.8786 x Lambda(0.1)), Vali MSE Loss: 0.1584 Test MSE Loss: 0.1170
Validation loss decreased (0.158400 --> 0.158382).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.4888061
	speed: 0.0191s/iter; left time: 196.2486s
Epoch: 20 cost time: 2.45271372795105
Epoch: 20, Steps: 128 Train Loss: 0.4867 (Forecasting Loss:0.1987 + XiCon Loss:2.8796 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.4943386
	speed: 0.0123s/iter; left time: 124.4684s
Epoch: 21 cost time: 1.5218329429626465
Epoch: 21, Steps: 128 Train Loss: 0.4862 (Forecasting Loss:0.1988 + XiCon Loss:2.8739 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 0.5142585
	speed: 0.0250s/iter; left time: 250.6215s
Epoch: 22 cost time: 3.1044254302978516
Epoch: 22, Steps: 128 Train Loss: 0.4872 (Forecasting Loss:0.1989 + XiCon Loss:2.8829 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 0.4676809
	speed: 0.0252s/iter; left time: 249.1650s
Epoch: 23 cost time: 3.149756669998169
Epoch: 23, Steps: 128 Train Loss: 0.4874 (Forecasting Loss:0.1991 + XiCon Loss:2.8836 x Lambda(0.1)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 0.4771323
	speed: 0.0263s/iter; left time: 256.7793s
Epoch: 24 cost time: 3.4244821071624756
Epoch: 24, Steps: 128 Train Loss: 0.4868 (Forecasting Loss:0.1986 + XiCon Loss:2.8820 x Lambda(0.1)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 0.4823248
	speed: 0.0266s/iter; left time: 256.3437s
Epoch: 25 cost time: 3.3899264335632324
Epoch: 25, Steps: 128 Train Loss: 0.4867 (Forecasting Loss:0.1988 + XiCon Loss:2.8791 x Lambda(0.1)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1170
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 0.4665419
	speed: 0.0256s/iter; left time: 243.0510s
Epoch: 26 cost time: 2.9795305728912354
Epoch: 26, Steps: 128 Train Loss: 0.4869 (Forecasting Loss:0.1985 + XiCon Loss:2.8838 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1170
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 0.4965833
	speed: 0.0211s/iter; left time: 197.6094s
Epoch: 27 cost time: 2.634767770767212
Epoch: 27, Steps: 128 Train Loss: 0.4870 (Forecasting Loss:0.1988 + XiCon Loss:2.8819 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1170
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 0.4845731
	speed: 0.0254s/iter; left time: 235.1189s
Epoch: 28 cost time: 3.2445499897003174
Epoch: 28, Steps: 128 Train Loss: 0.4867 (Forecasting Loss:0.1986 + XiCon Loss:2.8817 x Lambda(0.1)), Vali MSE Loss: 0.1587 Test MSE Loss: 0.1170
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 0.5098071
	speed: 0.0243s/iter; left time: 221.1481s
Epoch: 29 cost time: 3.0037829875946045
Epoch: 29, Steps: 128 Train Loss: 0.4864 (Forecasting Loss:0.1984 + XiCon Loss:2.8800 x Lambda(0.1)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1170
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054664064198732376, mae:0.17943452298641205, mape:0.1453125923871994, mspe:0.04222699627280235 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5097
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5324326
	speed: 0.0242s/iter; left time: 307.8957s
Epoch: 1 cost time: 3.173365592956543
Epoch: 1, Steps: 128 Train Loss: 0.5534 (Forecasting Loss:0.2449 + XiCon Loss:3.0850 x Lambda(0.1)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1209
Validation loss decreased (inf --> 0.172750).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5305976
	speed: 0.0256s/iter; left time: 322.2133s
Epoch: 2 cost time: 3.1672420501708984
Epoch: 2, Steps: 128 Train Loss: 0.5383 (Forecasting Loss:0.2463 + XiCon Loss:2.9197 x Lambda(0.1)), Vali MSE Loss: 0.1804 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5462199
	speed: 0.0198s/iter; left time: 246.7038s
Epoch: 3 cost time: 2.4646973609924316
Epoch: 3, Steps: 128 Train Loss: 0.5289 (Forecasting Loss:0.2302 + XiCon Loss:2.9874 x Lambda(0.1)), Vali MSE Loss: 0.1691 Test MSE Loss: 0.1209
Validation loss decreased (0.172750 --> 0.169128).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5183969
	speed: 0.0223s/iter; left time: 274.1456s
Epoch: 4 cost time: 2.888230800628662
Epoch: 4, Steps: 128 Train Loss: 0.5159 (Forecasting Loss:0.2226 + XiCon Loss:2.9332 x Lambda(0.1)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1222
Validation loss decreased (0.169128 --> 0.164831).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5059826
	speed: 0.0248s/iter; left time: 302.8566s
Epoch: 5 cost time: 3.122575044631958
Epoch: 5, Steps: 128 Train Loss: 0.5084 (Forecasting Loss:0.2183 + XiCon Loss:2.9006 x Lambda(0.1)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5356099
	speed: 0.0252s/iter; left time: 303.7537s
Epoch: 6 cost time: 3.1376895904541016
Epoch: 6, Steps: 128 Train Loss: 0.5043 (Forecasting Loss:0.2152 + XiCon Loss:2.8904 x Lambda(0.1)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1171
Validation loss decreased (0.164831 --> 0.164674).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5031777
	speed: 0.0254s/iter; left time: 302.8052s
Epoch: 7 cost time: 3.2372610569000244
Epoch: 7, Steps: 128 Train Loss: 0.5041 (Forecasting Loss:0.2147 + XiCon Loss:2.8939 x Lambda(0.1)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1155
Validation loss decreased (0.164674 --> 0.164091).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4925142
	speed: 0.0239s/iter; left time: 282.2386s
Epoch: 8 cost time: 2.983165979385376
Epoch: 8, Steps: 128 Train Loss: 0.5028 (Forecasting Loss:0.2139 + XiCon Loss:2.8899 x Lambda(0.1)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5215043
	speed: 0.0231s/iter; left time: 270.2033s
Epoch: 9 cost time: 2.8480076789855957
Epoch: 9, Steps: 128 Train Loss: 0.5025 (Forecasting Loss:0.2136 + XiCon Loss:2.8891 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5017903
	speed: 0.0228s/iter; left time: 262.8516s
Epoch: 10 cost time: 2.9451236724853516
Epoch: 10, Steps: 128 Train Loss: 0.5021 (Forecasting Loss:0.2133 + XiCon Loss:2.8880 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4995762
	speed: 0.0247s/iter; left time: 282.3588s
Epoch: 11 cost time: 3.178518772125244
Epoch: 11, Steps: 128 Train Loss: 0.5024 (Forecasting Loss:0.2133 + XiCon Loss:2.8904 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
Validation loss decreased (0.164091 --> 0.163733).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4992898
	speed: 0.0253s/iter; left time: 285.4041s
Epoch: 12 cost time: 3.1731293201446533
Epoch: 12, Steps: 128 Train Loss: 0.5019 (Forecasting Loss:0.2132 + XiCon Loss:2.8875 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5256264
	speed: 0.0243s/iter; left time: 270.8158s
Epoch: 13 cost time: 3.042170763015747
Epoch: 13, Steps: 128 Train Loss: 0.5023 (Forecasting Loss:0.2133 + XiCon Loss:2.8894 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
Validation loss decreased (0.163733 --> 0.163732).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4946593
	speed: 0.0255s/iter; left time: 281.4822s
Epoch: 14 cost time: 3.192734956741333
Epoch: 14, Steps: 128 Train Loss: 0.5024 (Forecasting Loss:0.2131 + XiCon Loss:2.8938 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4783888
	speed: 0.0234s/iter; left time: 255.3460s
Epoch: 15 cost time: 2.9745700359344482
Epoch: 15, Steps: 128 Train Loss: 0.5020 (Forecasting Loss:0.2132 + XiCon Loss:2.8884 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5138961
	speed: 0.0255s/iter; left time: 275.1445s
Epoch: 16 cost time: 3.205965757369995
Epoch: 16, Steps: 128 Train Loss: 0.5015 (Forecasting Loss:0.2132 + XiCon Loss:2.8826 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
Validation loss decreased (0.163732 --> 0.163721).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4969260
	speed: 0.0248s/iter; left time: 264.2780s
Epoch: 17 cost time: 3.0824639797210693
Epoch: 17, Steps: 128 Train Loss: 0.5021 (Forecasting Loss:0.2133 + XiCon Loss:2.8886 x Lambda(0.1)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
Validation loss decreased (0.163721 --> 0.163648).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5293632
	speed: 0.0254s/iter; left time: 267.5337s
Epoch: 18 cost time: 3.1971685886383057
Epoch: 18, Steps: 128 Train Loss: 0.5033 (Forecasting Loss:0.2133 + XiCon Loss:2.8997 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1159
Validation loss decreased (0.163648 --> 0.163268).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5041058
	speed: 0.0261s/iter; left time: 271.0055s
Epoch: 19 cost time: 3.3876006603240967
Epoch: 19, Steps: 128 Train Loss: 0.5020 (Forecasting Loss:0.2132 + XiCon Loss:2.8879 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5382335
	speed: 0.0250s/iter; left time: 256.7786s
Epoch: 20 cost time: 3.1367268562316895
Epoch: 20, Steps: 128 Train Loss: 0.5019 (Forecasting Loss:0.2132 + XiCon Loss:2.8866 x Lambda(0.1)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5018226
	speed: 0.0220s/iter; left time: 223.2744s
Epoch: 21 cost time: 2.7477221488952637
Epoch: 21, Steps: 128 Train Loss: 0.5020 (Forecasting Loss:0.2131 + XiCon Loss:2.8888 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 0.5207835
	speed: 0.0249s/iter; left time: 249.8129s
Epoch: 22 cost time: 3.1434741020202637
Epoch: 22, Steps: 128 Train Loss: 0.5020 (Forecasting Loss:0.2132 + XiCon Loss:2.8875 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 0.4914789
	speed: 0.0258s/iter; left time: 254.5590s
Epoch: 23 cost time: 3.241074800491333
Epoch: 23, Steps: 128 Train Loss: 0.5023 (Forecasting Loss:0.2133 + XiCon Loss:2.8897 x Lambda(0.1)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 0.4926725
	speed: 0.0267s/iter; left time: 260.4558s
Epoch: 24 cost time: 3.3106672763824463
Epoch: 24, Steps: 128 Train Loss: 0.5020 (Forecasting Loss:0.2132 + XiCon Loss:2.8880 x Lambda(0.1)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 0.5340750
	speed: 0.0309s/iter; left time: 297.6346s
Epoch: 25 cost time: 3.7258007526397705
Epoch: 25, Steps: 128 Train Loss: 0.5023 (Forecasting Loss:0.2132 + XiCon Loss:2.8915 x Lambda(0.1)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 0.5218158
	speed: 0.0224s/iter; left time: 212.4337s
Epoch: 26 cost time: 2.8443961143493652
Epoch: 26, Steps: 128 Train Loss: 0.5022 (Forecasting Loss:0.2133 + XiCon Loss:2.8894 x Lambda(0.1)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1159
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 0.5060843
	speed: 0.0222s/iter; left time: 208.3464s
Epoch: 27 cost time: 2.711416006088257
Epoch: 27, Steps: 128 Train Loss: 0.5019 (Forecasting Loss:0.2132 + XiCon Loss:2.8865 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 0.5131921
	speed: 0.0241s/iter; left time: 222.6572s
Epoch: 28 cost time: 3.0870745182037354
Epoch: 28, Steps: 128 Train Loss: 0.5021 (Forecasting Loss:0.2133 + XiCon Loss:2.8878 x Lambda(0.1)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054278433322906494, mae:0.1775418221950531, mape:0.14106126129627228, mspe:0.03722762316465378 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0620+-0.01822, MAE:0.1889+-0.02678, MAPE:0.1551+-0.02912, MSPE:0.0551+-0.03508, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4869
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6437063
	speed: 0.0471s/iter; left time: 550.6146s
Epoch: 1 cost time: 5.442496061325073
Epoch: 1, Steps: 118 Train Loss: 0.6807 (Forecasting Loss:0.3673 + XiCon Loss:3.1335 x Lambda(0.1)), Vali MSE Loss: 0.2672 Test MSE Loss: 0.1738
Validation loss decreased (inf --> 0.267155).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5589237
	speed: 0.0446s/iter; left time: 516.6669s
Epoch: 2 cost time: 5.416880130767822
Epoch: 2, Steps: 118 Train Loss: 0.5808 (Forecasting Loss:0.2826 + XiCon Loss:2.9826 x Lambda(0.1)), Vali MSE Loss: 0.2962 Test MSE Loss: 0.1511
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5461904
	speed: 0.0473s/iter; left time: 542.1809s
Epoch: 3 cost time: 5.606772422790527
Epoch: 3, Steps: 118 Train Loss: 0.5448 (Forecasting Loss:0.2435 + XiCon Loss:3.0129 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.1484
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5310301
	speed: 0.0536s/iter; left time: 608.2001s
Epoch: 4 cost time: 6.243633031845093
Epoch: 4, Steps: 118 Train Loss: 0.5366 (Forecasting Loss:0.2366 + XiCon Loss:3.0005 x Lambda(0.1)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.1430
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5251927
	speed: 0.0514s/iter; left time: 576.9199s
Epoch: 5 cost time: 6.012551784515381
Epoch: 5, Steps: 118 Train Loss: 0.5307 (Forecasting Loss:0.2317 + XiCon Loss:2.9905 x Lambda(0.1)), Vali MSE Loss: 0.2967 Test MSE Loss: 0.1403
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5402067
	speed: 0.0470s/iter; left time: 521.7131s
Epoch: 6 cost time: 5.664036273956299
Epoch: 6, Steps: 118 Train Loss: 0.5280 (Forecasting Loss:0.2300 + XiCon Loss:2.9804 x Lambda(0.1)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.1413
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5354356
	speed: 0.0477s/iter; left time: 523.8430s
Epoch: 7 cost time: 5.68538498878479
Epoch: 7, Steps: 118 Train Loss: 0.5275 (Forecasting Loss:0.2291 + XiCon Loss:2.9838 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1410
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5232278
	speed: 0.0536s/iter; left time: 582.9840s
Epoch: 8 cost time: 6.269190788269043
Epoch: 8, Steps: 118 Train Loss: 0.5262 (Forecasting Loss:0.2280 + XiCon Loss:2.9820 x Lambda(0.1)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.1413
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5360949
	speed: 0.0537s/iter; left time: 577.2312s
Epoch: 9 cost time: 6.261785507202148
Epoch: 9, Steps: 118 Train Loss: 0.5250 (Forecasting Loss:0.2275 + XiCon Loss:2.9749 x Lambda(0.1)), Vali MSE Loss: 0.2867 Test MSE Loss: 0.1409
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5524582
	speed: 0.0506s/iter; left time: 538.4109s
Epoch: 10 cost time: 5.942212820053101
Epoch: 10, Steps: 118 Train Loss: 0.5249 (Forecasting Loss:0.2277 + XiCon Loss:2.9717 x Lambda(0.1)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.1412
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5333012
	speed: 0.0486s/iter; left time: 511.2217s
Epoch: 11 cost time: 5.789691686630249
Epoch: 11, Steps: 118 Train Loss: 0.5252 (Forecasting Loss:0.2275 + XiCon Loss:2.9777 x Lambda(0.1)), Vali MSE Loss: 0.2873 Test MSE Loss: 0.1411
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09935206919908524, mae:0.24826636910438538, mape:0.18031556904315948, mspe:0.05186702683568001 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4066
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6341117
	speed: 0.0430s/iter; left time: 503.6646s
Epoch: 1 cost time: 4.99473237991333
Epoch: 1, Steps: 118 Train Loss: 0.6840 (Forecasting Loss:0.3709 + XiCon Loss:3.1312 x Lambda(0.1)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1704
Validation loss decreased (inf --> 0.262262).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5819350
	speed: 0.0483s/iter; left time: 559.5852s
Epoch: 2 cost time: 5.739172458648682
Epoch: 2, Steps: 118 Train Loss: 0.5894 (Forecasting Loss:0.2851 + XiCon Loss:3.0426 x Lambda(0.1)), Vali MSE Loss: 0.4215 Test MSE Loss: 0.1443
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5609014
	speed: 0.0468s/iter; left time: 536.7699s
Epoch: 3 cost time: 5.626546859741211
Epoch: 3, Steps: 118 Train Loss: 0.5534 (Forecasting Loss:0.2464 + XiCon Loss:3.0699 x Lambda(0.1)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.1364
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5312335
	speed: 0.0536s/iter; left time: 608.5286s
Epoch: 4 cost time: 6.336631536483765
Epoch: 4, Steps: 118 Train Loss: 0.5437 (Forecasting Loss:0.2379 + XiCon Loss:3.0580 x Lambda(0.1)), Vali MSE Loss: 0.2996 Test MSE Loss: 0.1422
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5507174
	speed: 0.0520s/iter; left time: 584.1193s
Epoch: 5 cost time: 6.067972421646118
Epoch: 5, Steps: 118 Train Loss: 0.5364 (Forecasting Loss:0.2336 + XiCon Loss:3.0281 x Lambda(0.1)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.1438
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5238627
	speed: 0.0518s/iter; left time: 575.5777s
Epoch: 6 cost time: 6.119754791259766
Epoch: 6, Steps: 118 Train Loss: 0.5316 (Forecasting Loss:0.2310 + XiCon Loss:3.0052 x Lambda(0.1)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.1451
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5522075
	speed: 0.0461s/iter; left time: 506.8294s
Epoch: 7 cost time: 5.5519819259643555
Epoch: 7, Steps: 118 Train Loss: 0.5291 (Forecasting Loss:0.2297 + XiCon Loss:2.9945 x Lambda(0.1)), Vali MSE Loss: 0.2962 Test MSE Loss: 0.1456
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5435878
	speed: 0.0513s/iter; left time: 558.2640s
Epoch: 8 cost time: 6.039582252502441
Epoch: 8, Steps: 118 Train Loss: 0.5283 (Forecasting Loss:0.2289 + XiCon Loss:2.9942 x Lambda(0.1)), Vali MSE Loss: 0.3001 Test MSE Loss: 0.1457
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5336934
	speed: 0.0527s/iter; left time: 566.7549s
Epoch: 9 cost time: 6.124149322509766
Epoch: 9, Steps: 118 Train Loss: 0.5278 (Forecasting Loss:0.2285 + XiCon Loss:2.9925 x Lambda(0.1)), Vali MSE Loss: 0.3058 Test MSE Loss: 0.1461
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5221962
	speed: 0.0521s/iter; left time: 554.8014s
Epoch: 10 cost time: 6.096621036529541
Epoch: 10, Steps: 118 Train Loss: 0.5276 (Forecasting Loss:0.2282 + XiCon Loss:2.9933 x Lambda(0.1)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.1461
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5413132
	speed: 0.0461s/iter; left time: 485.2131s
Epoch: 11 cost time: 5.612828493118286
Epoch: 11, Steps: 118 Train Loss: 0.5275 (Forecasting Loss:0.2280 + XiCon Loss:2.9957 x Lambda(0.1)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.1461
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09608229249715805, mae:0.24463266134262085, mape:0.17850849032402039, mspe:0.051109831780195236 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3605
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6471364
	speed: 0.0390s/iter; left time: 456.8501s
Epoch: 1 cost time: 4.668198347091675
Epoch: 1, Steps: 118 Train Loss: 0.6647 (Forecasting Loss:0.3524 + XiCon Loss:3.1228 x Lambda(0.1)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1611
Validation loss decreased (inf --> 0.250936).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5853107
	speed: 0.0432s/iter; left time: 500.3359s
Epoch: 2 cost time: 5.001458644866943
Epoch: 2, Steps: 118 Train Loss: 0.6024 (Forecasting Loss:0.3007 + XiCon Loss:3.0175 x Lambda(0.1)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1532
Validation loss decreased (0.250936 --> 0.231260).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5292513
	speed: 0.0405s/iter; left time: 464.8964s
Epoch: 3 cost time: 4.74353289604187
Epoch: 3, Steps: 118 Train Loss: 0.5319 (Forecasting Loss:0.2364 + XiCon Loss:2.9549 x Lambda(0.1)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.1536
Validation loss decreased (0.231260 --> 0.229887).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5201418
	speed: 0.0406s/iter; left time: 461.0455s
Epoch: 4 cost time: 4.605950117111206
Epoch: 4, Steps: 118 Train Loss: 0.5196 (Forecasting Loss:0.2248 + XiCon Loss:2.9488 x Lambda(0.1)), Vali MSE Loss: 0.2369 Test MSE Loss: 0.1460
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5192456
	speed: 0.0207s/iter; left time: 232.8671s
Epoch: 5 cost time: 2.425180435180664
Epoch: 5, Steps: 118 Train Loss: 0.5162 (Forecasting Loss:0.2198 + XiCon Loss:2.9642 x Lambda(0.1)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1451
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5182482
	speed: 0.0415s/iter; left time: 460.7020s
Epoch: 6 cost time: 4.8844218254089355
Epoch: 6, Steps: 118 Train Loss: 0.5151 (Forecasting Loss:0.2175 + XiCon Loss:2.9765 x Lambda(0.1)), Vali MSE Loss: 0.2378 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5317613
	speed: 0.0409s/iter; left time: 449.1588s
Epoch: 7 cost time: 4.737969636917114
Epoch: 7, Steps: 118 Train Loss: 0.5153 (Forecasting Loss:0.2165 + XiCon Loss:2.9883 x Lambda(0.1)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1439
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5229690
	speed: 0.0423s/iter; left time: 460.3008s
Epoch: 8 cost time: 4.965137481689453
Epoch: 8, Steps: 118 Train Loss: 0.5145 (Forecasting Loss:0.2156 + XiCon Loss:2.9894 x Lambda(0.1)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.1442
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5102702
	speed: 0.0422s/iter; left time: 454.0966s
Epoch: 9 cost time: 4.819271564483643
Epoch: 9, Steps: 118 Train Loss: 0.5145 (Forecasting Loss:0.2154 + XiCon Loss:2.9910 x Lambda(0.1)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1432
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5246863
	speed: 0.0370s/iter; left time: 393.7792s
Epoch: 10 cost time: 4.439589023590088
Epoch: 10, Steps: 118 Train Loss: 0.5145 (Forecasting Loss:0.2154 + XiCon Loss:2.9915 x Lambda(0.1)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1432
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5135390
	speed: 0.0416s/iter; left time: 437.7937s
Epoch: 11 cost time: 4.923145055770874
Epoch: 11, Steps: 118 Train Loss: 0.5142 (Forecasting Loss:0.2151 + XiCon Loss:2.9911 x Lambda(0.1)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.1435
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5147351
	speed: 0.0414s/iter; left time: 431.1469s
Epoch: 12 cost time: 4.844518661499023
Epoch: 12, Steps: 118 Train Loss: 0.5149 (Forecasting Loss:0.2152 + XiCon Loss:2.9964 x Lambda(0.1)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.1432
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5150600
	speed: 0.0411s/iter; left time: 423.1902s
Epoch: 13 cost time: 4.871990203857422
Epoch: 13, Steps: 118 Train Loss: 0.5146 (Forecasting Loss:0.2152 + XiCon Loss:2.9937 x Lambda(0.1)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1435
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07988372445106506, mae:0.22733032703399658, mape:0.174325630068779, mspe:0.05370889604091644 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3478
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6403019
	speed: 0.0396s/iter; left time: 463.5118s
Epoch: 1 cost time: 4.52478289604187
Epoch: 1, Steps: 118 Train Loss: 0.6644 (Forecasting Loss:0.3515 + XiCon Loss:3.1288 x Lambda(0.1)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1661
Validation loss decreased (inf --> 0.253644).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5854850
	speed: 0.0462s/iter; left time: 535.3737s
Epoch: 2 cost time: 5.541302919387817
Epoch: 2, Steps: 118 Train Loss: 0.6201 (Forecasting Loss:0.3173 + XiCon Loss:3.0280 x Lambda(0.1)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1593
Validation loss decreased (0.253644 --> 0.230526).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5167000
	speed: 0.0513s/iter; left time: 588.2542s
Epoch: 3 cost time: 6.008940696716309
Epoch: 3, Steps: 118 Train Loss: 0.5390 (Forecasting Loss:0.2458 + XiCon Loss:2.9322 x Lambda(0.1)), Vali MSE Loss: 0.2396 Test MSE Loss: 0.1525
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5528864
	speed: 0.0510s/iter; left time: 579.0799s
Epoch: 4 cost time: 5.944534540176392
Epoch: 4, Steps: 118 Train Loss: 0.5246 (Forecasting Loss:0.2275 + XiCon Loss:2.9707 x Lambda(0.1)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1545
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4987039
	speed: 0.0445s/iter; left time: 499.9341s
Epoch: 5 cost time: 5.238750219345093
Epoch: 5, Steps: 118 Train Loss: 0.5206 (Forecasting Loss:0.2214 + XiCon Loss:2.9922 x Lambda(0.1)), Vali MSE Loss: 0.2334 Test MSE Loss: 0.1519
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5180120
	speed: 0.0508s/iter; left time: 564.2280s
Epoch: 6 cost time: 5.931877613067627
Epoch: 6, Steps: 118 Train Loss: 0.5174 (Forecasting Loss:0.2180 + XiCon Loss:2.9940 x Lambda(0.1)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.1546
Validation loss decreased (0.230526 --> 0.226432).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5172812
	speed: 0.0537s/iter; left time: 590.0315s
Epoch: 7 cost time: 6.337587356567383
Epoch: 7, Steps: 118 Train Loss: 0.5166 (Forecasting Loss:0.2167 + XiCon Loss:2.9993 x Lambda(0.1)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.1514
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5174693
	speed: 0.0494s/iter; left time: 537.6844s
Epoch: 8 cost time: 5.841121196746826
Epoch: 8, Steps: 118 Train Loss: 0.5158 (Forecasting Loss:0.2160 + XiCon Loss:2.9984 x Lambda(0.1)), Vali MSE Loss: 0.2246 Test MSE Loss: 0.1520
Validation loss decreased (0.226432 --> 0.224639).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4995877
	speed: 0.0446s/iter; left time: 479.6819s
Epoch: 9 cost time: 5.198648929595947
Epoch: 9, Steps: 118 Train Loss: 0.5159 (Forecasting Loss:0.2156 + XiCon Loss:3.0027 x Lambda(0.1)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1507
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5115319
	speed: 0.0505s/iter; left time: 536.8655s
Epoch: 10 cost time: 6.076456546783447
Epoch: 10, Steps: 118 Train Loss: 0.5169 (Forecasting Loss:0.2156 + XiCon Loss:3.0125 x Lambda(0.1)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1515
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5103232
	speed: 0.0515s/iter; left time: 541.4524s
Epoch: 11 cost time: 6.170819044113159
Epoch: 11, Steps: 118 Train Loss: 0.5152 (Forecasting Loss:0.2151 + XiCon Loss:3.0006 x Lambda(0.1)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.1515
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5119300
	speed: 0.0496s/iter; left time: 515.6610s
Epoch: 12 cost time: 5.838383913040161
Epoch: 12, Steps: 118 Train Loss: 0.5155 (Forecasting Loss:0.2155 + XiCon Loss:3.0007 x Lambda(0.1)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1515
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5176446
	speed: 0.0460s/iter; left time: 472.7645s
Epoch: 13 cost time: 5.478672027587891
Epoch: 13, Steps: 118 Train Loss: 0.5155 (Forecasting Loss:0.2156 + XiCon Loss:2.9991 x Lambda(0.1)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.1515
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5163016
	speed: 0.0523s/iter; left time: 531.4112s
Epoch: 14 cost time: 6.141916513442993
Epoch: 14, Steps: 118 Train Loss: 0.5152 (Forecasting Loss:0.2153 + XiCon Loss:2.9987 x Lambda(0.1)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1515
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5084090
	speed: 0.0499s/iter; left time: 501.8101s
Epoch: 15 cost time: 5.884989023208618
Epoch: 15, Steps: 118 Train Loss: 0.5157 (Forecasting Loss:0.2154 + XiCon Loss:3.0031 x Lambda(0.1)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1515
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5234972
	speed: 0.0511s/iter; left time: 507.3296s
Epoch: 16 cost time: 6.00179386138916
Epoch: 16, Steps: 118 Train Loss: 0.5150 (Forecasting Loss:0.2150 + XiCon Loss:3.0004 x Lambda(0.1)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.1515
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5182112
	speed: 0.0442s/iter; left time: 433.7511s
Epoch: 17 cost time: 5.260159969329834
Epoch: 17, Steps: 118 Train Loss: 0.5153 (Forecasting Loss:0.2151 + XiCon Loss:3.0019 x Lambda(0.1)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.1515
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5174939
	speed: 0.0500s/iter; left time: 485.1631s
Epoch: 18 cost time: 5.944398880004883
Epoch: 18, Steps: 118 Train Loss: 0.5152 (Forecasting Loss:0.2152 + XiCon Loss:2.9996 x Lambda(0.1)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1515
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07958510518074036, mae:0.22447293996810913, mape:0.1684531718492508, mspe:0.04942331090569496 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3742
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6255437
	speed: 0.0418s/iter; left time: 488.9625s
Epoch: 1 cost time: 4.862498760223389
Epoch: 1, Steps: 118 Train Loss: 0.6662 (Forecasting Loss:0.3540 + XiCon Loss:3.1222 x Lambda(0.1)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1658
Validation loss decreased (inf --> 0.255352).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5883226
	speed: 0.0394s/iter; left time: 456.7755s
Epoch: 2 cost time: 4.732609987258911
Epoch: 2, Steps: 118 Train Loss: 0.6059 (Forecasting Loss:0.3061 + XiCon Loss:2.9981 x Lambda(0.1)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.1470
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5407650
	speed: 0.0404s/iter; left time: 463.5444s
Epoch: 3 cost time: 4.7650463581085205
Epoch: 3, Steps: 118 Train Loss: 0.5431 (Forecasting Loss:0.2449 + XiCon Loss:2.9821 x Lambda(0.1)), Vali MSE Loss: 0.2937 Test MSE Loss: 0.1470
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5419416
	speed: 0.0424s/iter; left time: 480.6939s
Epoch: 4 cost time: 4.910736322402954
Epoch: 4, Steps: 118 Train Loss: 0.5283 (Forecasting Loss:0.2295 + XiCon Loss:2.9877 x Lambda(0.1)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.1555
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5152758
	speed: 0.0435s/iter; left time: 488.7560s
Epoch: 5 cost time: 5.08329176902771
Epoch: 5, Steps: 118 Train Loss: 0.5219 (Forecasting Loss:0.2233 + XiCon Loss:2.9856 x Lambda(0.1)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.1573
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5072010
	speed: 0.0427s/iter; left time: 474.1001s
Epoch: 6 cost time: 4.970839500427246
Epoch: 6, Steps: 118 Train Loss: 0.5200 (Forecasting Loss:0.2216 + XiCon Loss:2.9845 x Lambda(0.1)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.1523
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5351119
	speed: 0.0418s/iter; left time: 459.2421s
Epoch: 7 cost time: 4.9438636302948
Epoch: 7, Steps: 118 Train Loss: 0.5181 (Forecasting Loss:0.2194 + XiCon Loss:2.9869 x Lambda(0.1)), Vali MSE Loss: 0.2872 Test MSE Loss: 0.1522
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5126597
	speed: 0.0390s/iter; left time: 424.3551s
Epoch: 8 cost time: 4.639732122421265
Epoch: 8, Steps: 118 Train Loss: 0.5180 (Forecasting Loss:0.2188 + XiCon Loss:2.9921 x Lambda(0.1)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.1519
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5236738
	speed: 0.0430s/iter; left time: 462.5766s
Epoch: 9 cost time: 5.08541464805603
Epoch: 9, Steps: 118 Train Loss: 0.5168 (Forecasting Loss:0.2185 + XiCon Loss:2.9833 x Lambda(0.1)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.1524
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5260263
	speed: 0.0434s/iter; left time: 461.2804s
Epoch: 10 cost time: 5.080345869064331
Epoch: 10, Steps: 118 Train Loss: 0.5164 (Forecasting Loss:0.2180 + XiCon Loss:2.9845 x Lambda(0.1)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.1523
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5078966
	speed: 0.0422s/iter; left time: 443.8564s
Epoch: 11 cost time: 4.969756126403809
Epoch: 11, Steps: 118 Train Loss: 0.5165 (Forecasting Loss:0.2181 + XiCon Loss:2.9846 x Lambda(0.1)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.1521
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09189016371965408, mae:0.2396925836801529, mape:0.17505811154842377, mspe:0.048915959894657135 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0894+-0.01139, MAE:0.2369+-0.01306, MAPE:0.1753+-0.00567, MSPE:0.0510+-0.00240, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5991
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8049200
	speed: 0.0795s/iter; left time: 843.2681s
Epoch: 1 cost time: 8.507121324539185
Epoch: 1, Steps: 107 Train Loss: 0.8464 (Forecasting Loss:0.5322 + XiCon Loss:3.1420 x Lambda(0.1)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.1970
Validation loss decreased (inf --> 0.345639).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5833482
	speed: 0.0819s/iter; left time: 859.3054s
Epoch: 2 cost time: 8.846639633178711
Epoch: 2, Steps: 107 Train Loss: 0.6861 (Forecasting Loss:0.3782 + XiCon Loss:3.0796 x Lambda(0.1)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1391
Validation loss decreased (0.345639 --> 0.250584).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5623639
	speed: 0.0792s/iter; left time: 822.6104s
Epoch: 3 cost time: 8.570402145385742
Epoch: 3, Steps: 107 Train Loss: 0.5693 (Forecasting Loss:0.2684 + XiCon Loss:3.0093 x Lambda(0.1)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5566403
	speed: 0.0788s/iter; left time: 809.6227s
Epoch: 4 cost time: 8.449682474136353
Epoch: 4, Steps: 107 Train Loss: 0.5521 (Forecasting Loss:0.2546 + XiCon Loss:2.9753 x Lambda(0.1)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1460
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5361783
	speed: 0.0758s/iter; left time: 771.0004s
Epoch: 5 cost time: 8.096920728683472
Epoch: 5, Steps: 107 Train Loss: 0.5422 (Forecasting Loss:0.2471 + XiCon Loss:2.9507 x Lambda(0.1)), Vali MSE Loss: 0.2634 Test MSE Loss: 0.1365
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5345314
	speed: 0.0774s/iter; left time: 779.3659s
Epoch: 6 cost time: 8.308974027633667
Epoch: 6, Steps: 107 Train Loss: 0.5381 (Forecasting Loss:0.2438 + XiCon Loss:2.9428 x Lambda(0.1)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5195950
	speed: 0.0757s/iter; left time: 753.9122s
Epoch: 7 cost time: 8.128028869628906
Epoch: 7, Steps: 107 Train Loss: 0.5373 (Forecasting Loss:0.2428 + XiCon Loss:2.9454 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1354
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5461572
	speed: 0.0784s/iter; left time: 772.7198s
Epoch: 8 cost time: 8.36886715888977
Epoch: 8, Steps: 107 Train Loss: 0.5369 (Forecasting Loss:0.2423 + XiCon Loss:2.9459 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1374
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5521278
	speed: 0.0800s/iter; left time: 779.1389s
Epoch: 9 cost time: 8.548295497894287
Epoch: 9, Steps: 107 Train Loss: 0.5365 (Forecasting Loss:0.2416 + XiCon Loss:2.9490 x Lambda(0.1)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5454750
	speed: 0.0753s/iter; left time: 726.1740s
Epoch: 10 cost time: 8.078200340270996
Epoch: 10, Steps: 107 Train Loss: 0.5359 (Forecasting Loss:0.2414 + XiCon Loss:2.9456 x Lambda(0.1)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.1370
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5368055
	speed: 0.0778s/iter; left time: 741.7694s
Epoch: 11 cost time: 8.296684265136719
Epoch: 11, Steps: 107 Train Loss: 0.5358 (Forecasting Loss:0.2410 + XiCon Loss:2.9484 x Lambda(0.1)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.1366
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5409898
	speed: 0.0771s/iter; left time: 726.6899s
Epoch: 12 cost time: 8.271981239318848
Epoch: 12, Steps: 107 Train Loss: 0.5360 (Forecasting Loss:0.2410 + XiCon Loss:2.9496 x Lambda(0.1)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1359
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06948374956846237, mae:0.20879240334033966, mape:0.15292179584503174, mspe:0.0388140045106411 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3659
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8111053
	speed: 0.0787s/iter; left time: 834.4287s
Epoch: 1 cost time: 8.499694108963013
Epoch: 1, Steps: 107 Train Loss: 0.8617 (Forecasting Loss:0.5476 + XiCon Loss:3.1418 x Lambda(0.1)), Vali MSE Loss: 0.3477 Test MSE Loss: 0.2136
Validation loss decreased (inf --> 0.347707).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5851332
	speed: 0.0870s/iter; left time: 912.7735s
Epoch: 2 cost time: 9.353929042816162
Epoch: 2, Steps: 107 Train Loss: 0.7012 (Forecasting Loss:0.3902 + XiCon Loss:3.1100 x Lambda(0.1)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.1553
Validation loss decreased (0.347707 --> 0.263207).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5593073
	speed: 0.0908s/iter; left time: 942.8563s
Epoch: 3 cost time: 9.82185697555542
Epoch: 3, Steps: 107 Train Loss: 0.5722 (Forecasting Loss:0.2626 + XiCon Loss:3.0953 x Lambda(0.1)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1562
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5694278
	speed: 0.0893s/iter; left time: 918.1237s
Epoch: 4 cost time: 9.629436016082764
Epoch: 4, Steps: 107 Train Loss: 0.5604 (Forecasting Loss:0.2498 + XiCon Loss:3.1059 x Lambda(0.1)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.1508
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5626919
	speed: 0.0888s/iter; left time: 903.7645s
Epoch: 5 cost time: 9.480865716934204
Epoch: 5, Steps: 107 Train Loss: 0.5547 (Forecasting Loss:0.2426 + XiCon Loss:3.1209 x Lambda(0.1)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.1552
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5535425
	speed: 0.0874s/iter; left time: 879.5329s
Epoch: 6 cost time: 9.376304626464844
Epoch: 6, Steps: 107 Train Loss: 0.5520 (Forecasting Loss:0.2395 + XiCon Loss:3.1249 x Lambda(0.1)), Vali MSE Loss: 0.2638 Test MSE Loss: 0.1572
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5490848
	speed: 0.0864s/iter; left time: 860.6937s
Epoch: 7 cost time: 9.346285581588745
Epoch: 7, Steps: 107 Train Loss: 0.5511 (Forecasting Loss:0.2384 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.2660 Test MSE Loss: 0.1542
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5419806
	speed: 0.0854s/iter; left time: 841.6063s
Epoch: 8 cost time: 9.15972113609314
Epoch: 8, Steps: 107 Train Loss: 0.5501 (Forecasting Loss:0.2373 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.2676 Test MSE Loss: 0.1541
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5385911
	speed: 0.0877s/iter; left time: 854.3307s
Epoch: 9 cost time: 9.414335489273071
Epoch: 9, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2369 + XiCon Loss:3.1262 x Lambda(0.1)), Vali MSE Loss: 0.2668 Test MSE Loss: 0.1542
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5373564
	speed: 0.0861s/iter; left time: 829.9373s
Epoch: 10 cost time: 9.25270962715149
Epoch: 10, Steps: 107 Train Loss: 0.5485 (Forecasting Loss:0.2360 + XiCon Loss:3.1244 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1548
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5460172
	speed: 0.0830s/iter; left time: 791.1977s
Epoch: 11 cost time: 8.87767481803894
Epoch: 11, Steps: 107 Train Loss: 0.5493 (Forecasting Loss:0.2363 + XiCon Loss:3.1303 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1534
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5584346
	speed: 0.0870s/iter; left time: 819.5985s
Epoch: 12 cost time: 9.292246341705322
Epoch: 12, Steps: 107 Train Loss: 0.5491 (Forecasting Loss:0.2365 + XiCon Loss:3.1256 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1542
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08257097005844116, mae:0.2280195951461792, mape:0.1644640564918518, mspe:0.04404731094837189 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3024
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8945969
	speed: 0.0762s/iter; left time: 808.2938s
Epoch: 1 cost time: 8.21849536895752
Epoch: 1, Steps: 107 Train Loss: 0.8565 (Forecasting Loss:0.5414 + XiCon Loss:3.1514 x Lambda(0.1)), Vali MSE Loss: 0.3729 Test MSE Loss: 0.2208
Validation loss decreased (inf --> 0.372859).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5707289
	speed: 0.0973s/iter; left time: 1020.8773s
Epoch: 2 cost time: 10.516757011413574
Epoch: 2, Steps: 107 Train Loss: 0.6343 (Forecasting Loss:0.3327 + XiCon Loss:3.0167 x Lambda(0.1)), Vali MSE Loss: 0.3633 Test MSE Loss: 0.1552
Validation loss decreased (0.372859 --> 0.363349).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5438606
	speed: 0.1081s/iter; left time: 1122.8549s
Epoch: 3 cost time: 11.755205869674683
Epoch: 3, Steps: 107 Train Loss: 0.5426 (Forecasting Loss:0.2531 + XiCon Loss:2.8949 x Lambda(0.1)), Vali MSE Loss: 0.3464 Test MSE Loss: 0.1514
Validation loss decreased (0.363349 --> 0.346446).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5471399
	speed: 0.1049s/iter; left time: 1078.8490s
Epoch: 4 cost time: 11.418727397918701
Epoch: 4, Steps: 107 Train Loss: 0.5317 (Forecasting Loss:0.2434 + XiCon Loss:2.8833 x Lambda(0.1)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.1485
Validation loss decreased (0.346446 --> 0.340537).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5337589
	speed: 0.1093s/iter; left time: 1111.8402s
Epoch: 5 cost time: 11.775666952133179
Epoch: 5, Steps: 107 Train Loss: 0.5303 (Forecasting Loss:0.2390 + XiCon Loss:2.9128 x Lambda(0.1)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.1487
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5315632
	speed: 0.1077s/iter; left time: 1084.5553s
Epoch: 6 cost time: 11.568215370178223
Epoch: 6, Steps: 107 Train Loss: 0.5292 (Forecasting Loss:0.2359 + XiCon Loss:2.9328 x Lambda(0.1)), Vali MSE Loss: 0.3467 Test MSE Loss: 0.1482
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5335008
	speed: 0.1071s/iter; left time: 1066.2766s
Epoch: 7 cost time: 11.638537168502808
Epoch: 7, Steps: 107 Train Loss: 0.5281 (Forecasting Loss:0.2345 + XiCon Loss:2.9359 x Lambda(0.1)), Vali MSE Loss: 0.3402 Test MSE Loss: 0.1465
Validation loss decreased (0.340537 --> 0.340236).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5312247
	speed: 0.1033s/iter; left time: 1018.1624s
Epoch: 8 cost time: 11.089814901351929
Epoch: 8, Steps: 107 Train Loss: 0.5278 (Forecasting Loss:0.2340 + XiCon Loss:2.9383 x Lambda(0.1)), Vali MSE Loss: 0.3452 Test MSE Loss: 0.1456
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5231642
	speed: 0.1039s/iter; left time: 1012.6619s
Epoch: 9 cost time: 11.18263554573059
Epoch: 9, Steps: 107 Train Loss: 0.5278 (Forecasting Loss:0.2339 + XiCon Loss:2.9389 x Lambda(0.1)), Vali MSE Loss: 0.3432 Test MSE Loss: 0.1456
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5289266
	speed: 0.1054s/iter; left time: 1015.5492s
Epoch: 10 cost time: 11.373514652252197
Epoch: 10, Steps: 107 Train Loss: 0.5281 (Forecasting Loss:0.2342 + XiCon Loss:2.9387 x Lambda(0.1)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.1451
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5280043
	speed: 0.1068s/iter; left time: 1017.6399s
Epoch: 11 cost time: 11.316183090209961
Epoch: 11, Steps: 107 Train Loss: 0.5274 (Forecasting Loss:0.2334 + XiCon Loss:2.9394 x Lambda(0.1)), Vali MSE Loss: 0.3413 Test MSE Loss: 0.1459
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5293331
	speed: 0.0641s/iter; left time: 604.4681s
Epoch: 12 cost time: 7.160581588745117
Epoch: 12, Steps: 107 Train Loss: 0.5274 (Forecasting Loss:0.2336 + XiCon Loss:2.9385 x Lambda(0.1)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.1457
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5325475
	speed: 0.1023s/iter; left time: 953.4221s
Epoch: 13 cost time: 11.050740480422974
Epoch: 13, Steps: 107 Train Loss: 0.5275 (Forecasting Loss:0.2335 + XiCon Loss:2.9402 x Lambda(0.1)), Vali MSE Loss: 0.3419 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5347893
	speed: 0.1037s/iter; left time: 954.7412s
Epoch: 14 cost time: 11.170680284500122
Epoch: 14, Steps: 107 Train Loss: 0.5271 (Forecasting Loss:0.2331 + XiCon Loss:2.9404 x Lambda(0.1)), Vali MSE Loss: 0.3423 Test MSE Loss: 0.1455
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5222447
	speed: 0.1012s/iter; left time: 921.5337s
Epoch: 15 cost time: 10.998940706253052
Epoch: 15, Steps: 107 Train Loss: 0.5266 (Forecasting Loss:0.2330 + XiCon Loss:2.9354 x Lambda(0.1)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.1455
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5215243
	speed: 0.1034s/iter; left time: 930.4381s
Epoch: 16 cost time: 11.102960348129272
Epoch: 16, Steps: 107 Train Loss: 0.5276 (Forecasting Loss:0.2335 + XiCon Loss:2.9410 x Lambda(0.1)), Vali MSE Loss: 0.3422 Test MSE Loss: 0.1455
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5348309
	speed: 0.1036s/iter; left time: 921.1708s
Epoch: 17 cost time: 11.128963947296143
Epoch: 17, Steps: 107 Train Loss: 0.5268 (Forecasting Loss:0.2332 + XiCon Loss:2.9357 x Lambda(0.1)), Vali MSE Loss: 0.3428 Test MSE Loss: 0.1455
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07598444074392319, mae:0.2169298380613327, mape:0.1571081429719925, mspe:0.041968949139118195 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4879
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.7986202
	speed: 0.0579s/iter; left time: 614.1827s
Epoch: 1 cost time: 6.2074761390686035
Epoch: 1, Steps: 107 Train Loss: 0.8554 (Forecasting Loss:0.5398 + XiCon Loss:3.1554 x Lambda(0.1)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.2038
Validation loss decreased (inf --> 0.353834).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6225806
	speed: 0.0795s/iter; left time: 834.6290s
Epoch: 2 cost time: 8.502829313278198
Epoch: 2, Steps: 107 Train Loss: 0.6905 (Forecasting Loss:0.3818 + XiCon Loss:3.0876 x Lambda(0.1)), Vali MSE Loss: 0.2570 Test MSE Loss: 0.1442
Validation loss decreased (0.353834 --> 0.256977).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5815820
	speed: 0.0772s/iter; left time: 801.5944s
Epoch: 3 cost time: 8.232367515563965
Epoch: 3, Steps: 107 Train Loss: 0.5815 (Forecasting Loss:0.2792 + XiCon Loss:3.0230 x Lambda(0.1)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.1408
Validation loss decreased (0.256977 --> 0.254147).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5605954
	speed: 0.0762s/iter; left time: 783.7381s
Epoch: 4 cost time: 8.031885147094727
Epoch: 4, Steps: 107 Train Loss: 0.5609 (Forecasting Loss:0.2592 + XiCon Loss:3.0172 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5472934
	speed: 0.0795s/iter; left time: 808.9344s
Epoch: 5 cost time: 8.550463199615479
Epoch: 5, Steps: 107 Train Loss: 0.5555 (Forecasting Loss:0.2522 + XiCon Loss:3.0331 x Lambda(0.1)), Vali MSE Loss: 0.2669 Test MSE Loss: 0.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5485718
	speed: 0.0777s/iter; left time: 781.6675s
Epoch: 6 cost time: 8.325767517089844
Epoch: 6, Steps: 107 Train Loss: 0.5525 (Forecasting Loss:0.2491 + XiCon Loss:3.0342 x Lambda(0.1)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.1422
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5635675
	speed: 0.0769s/iter; left time: 765.9732s
Epoch: 7 cost time: 8.22815203666687
Epoch: 7, Steps: 107 Train Loss: 0.5510 (Forecasting Loss:0.2472 + XiCon Loss:3.0382 x Lambda(0.1)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5401119
	speed: 0.0756s/iter; left time: 744.9499s
Epoch: 8 cost time: 8.093775033950806
Epoch: 8, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2463 + XiCon Loss:3.0316 x Lambda(0.1)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1388
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5551379
	speed: 0.0778s/iter; left time: 757.9521s
Epoch: 9 cost time: 8.418707847595215
Epoch: 9, Steps: 107 Train Loss: 0.5494 (Forecasting Loss:0.2457 + XiCon Loss:3.0371 x Lambda(0.1)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.1398
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5507706
	speed: 0.0787s/iter; left time: 758.3674s
Epoch: 10 cost time: 8.483810901641846
Epoch: 10, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2454 + XiCon Loss:3.0410 x Lambda(0.1)), Vali MSE Loss: 0.2639 Test MSE Loss: 0.1394
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5552420
	speed: 0.0764s/iter; left time: 728.0844s
Epoch: 11 cost time: 8.220015048980713
Epoch: 11, Steps: 107 Train Loss: 0.5498 (Forecasting Loss:0.2455 + XiCon Loss:3.0429 x Lambda(0.1)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.1394
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5538436
	speed: 0.0759s/iter; left time: 715.1806s
Epoch: 12 cost time: 8.16205096244812
Epoch: 12, Steps: 107 Train Loss: 0.5494 (Forecasting Loss:0.2456 + XiCon Loss:3.0380 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1394
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5345144
	speed: 0.0811s/iter; left time: 755.8152s
Epoch: 13 cost time: 8.677138566970825
Epoch: 13, Steps: 107 Train Loss: 0.5491 (Forecasting Loss:0.2453 + XiCon Loss:3.0371 x Lambda(0.1)), Vali MSE Loss: 0.2634 Test MSE Loss: 0.1393
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.0708320289850235, mae:0.2108025997877121, mape:0.15566092729568481, mspe:0.04111286997795105 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3830
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8200938
	speed: 0.0812s/iter; left time: 860.4291s
Epoch: 1 cost time: 8.77826476097107
Epoch: 1, Steps: 107 Train Loss: 0.8545 (Forecasting Loss:0.5389 + XiCon Loss:3.1563 x Lambda(0.1)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.1939
Validation loss decreased (inf --> 0.330985).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5842013
	speed: 0.0767s/iter; left time: 805.3263s
Epoch: 2 cost time: 8.229137182235718
Epoch: 2, Steps: 107 Train Loss: 0.6798 (Forecasting Loss:0.3696 + XiCon Loss:3.1020 x Lambda(0.1)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.1469
Validation loss decreased (0.330985 --> 0.258188).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5765640
	speed: 0.0751s/iter; left time: 780.0893s
Epoch: 3 cost time: 8.114324569702148
Epoch: 3, Steps: 107 Train Loss: 0.5912 (Forecasting Loss:0.2863 + XiCon Loss:3.0493 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1416
Validation loss decreased (0.258188 --> 0.242583).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5651133
	speed: 0.0752s/iter; left time: 773.2204s
Epoch: 4 cost time: 8.09778380393982
Epoch: 4, Steps: 107 Train Loss: 0.5661 (Forecasting Loss:0.2638 + XiCon Loss:3.0234 x Lambda(0.1)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1403
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5604011
	speed: 0.0751s/iter; left time: 763.6603s
Epoch: 5 cost time: 8.11165189743042
Epoch: 5, Steps: 107 Train Loss: 0.5588 (Forecasting Loss:0.2579 + XiCon Loss:3.0090 x Lambda(0.1)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1402
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5680874
	speed: 0.0761s/iter; left time: 765.7522s
Epoch: 6 cost time: 8.160727977752686
Epoch: 6, Steps: 107 Train Loss: 0.5537 (Forecasting Loss:0.2536 + XiCon Loss:3.0011 x Lambda(0.1)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.1396
Validation loss decreased (0.242583 --> 0.241739).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5564297
	speed: 0.0751s/iter; left time: 747.6018s
Epoch: 7 cost time: 8.121129274368286
Epoch: 7, Steps: 107 Train Loss: 0.5523 (Forecasting Loss:0.2524 + XiCon Loss:2.9990 x Lambda(0.1)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.1395
Validation loss decreased (0.241739 --> 0.241472).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5566894
	speed: 0.0760s/iter; left time: 748.3308s
Epoch: 8 cost time: 8.220056533813477
Epoch: 8, Steps: 107 Train Loss: 0.5512 (Forecasting Loss:0.2515 + XiCon Loss:2.9967 x Lambda(0.1)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5563800
	speed: 0.0789s/iter; left time: 769.1610s
Epoch: 9 cost time: 8.546607732772827
Epoch: 9, Steps: 107 Train Loss: 0.5507 (Forecasting Loss:0.2511 + XiCon Loss:2.9956 x Lambda(0.1)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1392
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5636882
	speed: 0.0769s/iter; left time: 741.4271s
Epoch: 10 cost time: 8.260442972183228
Epoch: 10, Steps: 107 Train Loss: 0.5505 (Forecasting Loss:0.2510 + XiCon Loss:2.9955 x Lambda(0.1)), Vali MSE Loss: 0.2421 Test MSE Loss: 0.1392
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5469999
	speed: 0.0775s/iter; left time: 738.9828s
Epoch: 11 cost time: 8.301318883895874
Epoch: 11, Steps: 107 Train Loss: 0.5504 (Forecasting Loss:0.2508 + XiCon Loss:2.9962 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1391
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5525165
	speed: 0.0734s/iter; left time: 691.5140s
Epoch: 12 cost time: 7.914205074310303
Epoch: 12, Steps: 107 Train Loss: 0.5500 (Forecasting Loss:0.2504 + XiCon Loss:2.9960 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1391
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5592918
	speed: 0.0769s/iter; left time: 716.5828s
Epoch: 13 cost time: 8.275076866149902
Epoch: 13, Steps: 107 Train Loss: 0.5496 (Forecasting Loss:0.2501 + XiCon Loss:2.9951 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1391
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5472775
	speed: 0.0819s/iter; left time: 754.2084s
Epoch: 14 cost time: 8.724981307983398
Epoch: 14, Steps: 107 Train Loss: 0.5507 (Forecasting Loss:0.2512 + XiCon Loss:2.9959 x Lambda(0.1)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1391
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5535169
	speed: 0.0769s/iter; left time: 699.5843s
Epoch: 15 cost time: 8.369328498840332
Epoch: 15, Steps: 107 Train Loss: 0.5498 (Forecasting Loss:0.2503 + XiCon Loss:2.9957 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1391
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5623795
	speed: 0.0773s/iter; left time: 695.1050s
Epoch: 16 cost time: 8.448080778121948
Epoch: 16, Steps: 107 Train Loss: 0.5501 (Forecasting Loss:0.2505 + XiCon Loss:2.9958 x Lambda(0.1)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.1391
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5469551
	speed: 0.0776s/iter; left time: 689.8786s
Epoch: 17 cost time: 8.336211681365967
Epoch: 17, Steps: 107 Train Loss: 0.5496 (Forecasting Loss:0.2500 + XiCon Loss:2.9962 x Lambda(0.1)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1391
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06965408474206924, mae:0.20926521718502045, mape:0.15478923916816711, mspe:0.040824245661497116 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0737+-0.00698, MAE:0.2148+-0.01005, MAPE:0.1570+-0.00552, MSPE:0.0414+-0.00236, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4617
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.58510684967041
Epoch: 1, Steps: 96 Train Loss: 1.0593 (Forecasting Loss:0.7436 + XiCon Loss:3.1565 x Lambda(0.1)), Vali MSE Loss: 0.4370 Test MSE Loss: 0.2930
Validation loss decreased (inf --> 0.437048).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 15.278800964355469
Epoch: 2, Steps: 96 Train Loss: 0.8610 (Forecasting Loss:0.5503 + XiCon Loss:3.1074 x Lambda(0.1)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.1687
Validation loss decreased (0.437048 --> 0.269509).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.656164407730103
Epoch: 3, Steps: 96 Train Loss: 0.6020 (Forecasting Loss:0.2959 + XiCon Loss:3.0608 x Lambda(0.1)), Vali MSE Loss: 0.2933 Test MSE Loss: 0.1548
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.18627667427063
Epoch: 4, Steps: 96 Train Loss: 0.5604 (Forecasting Loss:0.2575 + XiCon Loss:3.0294 x Lambda(0.1)), Vali MSE Loss: 0.3035 Test MSE Loss: 0.1676
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.505976915359497
Epoch: 5, Steps: 96 Train Loss: 0.5529 (Forecasting Loss:0.2493 + XiCon Loss:3.0352 x Lambda(0.1)), Vali MSE Loss: 0.2904 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.508546590805054
Epoch: 6, Steps: 96 Train Loss: 0.5506 (Forecasting Loss:0.2459 + XiCon Loss:3.0470 x Lambda(0.1)), Vali MSE Loss: 0.2942 Test MSE Loss: 0.1669
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.389023780822754
Epoch: 7, Steps: 96 Train Loss: 0.5496 (Forecasting Loss:0.2442 + XiCon Loss:3.0541 x Lambda(0.1)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.1704
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.776105165481567
Epoch: 8, Steps: 96 Train Loss: 0.5484 (Forecasting Loss:0.2432 + XiCon Loss:3.0518 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1654
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 15.779213666915894
Epoch: 9, Steps: 96 Train Loss: 0.5487 (Forecasting Loss:0.2431 + XiCon Loss:3.0557 x Lambda(0.1)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.1698
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.0094313621521
Epoch: 10, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2427 + XiCon Loss:3.0509 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1696
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 15.092318773269653
Epoch: 11, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2425 + XiCon Loss:3.0575 x Lambda(0.1)), Vali MSE Loss: 0.2913 Test MSE Loss: 0.1687
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.515894174575806
Epoch: 12, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2424 + XiCon Loss:3.0538 x Lambda(0.1)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09432002156972885, mae:0.24300220608711243, mape:0.17222318053245544, mspe:0.04493856802582741 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3990
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.747239589691162
Epoch: 1, Steps: 96 Train Loss: 1.0366 (Forecasting Loss:0.7214 + XiCon Loss:3.1520 x Lambda(0.1)), Vali MSE Loss: 0.4323 Test MSE Loss: 0.2619
Validation loss decreased (inf --> 0.432277).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 15.150633573532104
Epoch: 2, Steps: 96 Train Loss: 0.7810 (Forecasting Loss:0.4725 + XiCon Loss:3.0849 x Lambda(0.1)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.1474
Validation loss decreased (0.432277 --> 0.317249).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 15.36236572265625
Epoch: 3, Steps: 96 Train Loss: 0.5834 (Forecasting Loss:0.2782 + XiCon Loss:3.0520 x Lambda(0.1)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.1401
Validation loss decreased (0.317249 --> 0.282044).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.532284021377563
Epoch: 4, Steps: 96 Train Loss: 0.5649 (Forecasting Loss:0.2582 + XiCon Loss:3.0667 x Lambda(0.1)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.1444
Validation loss decreased (0.282044 --> 0.271534).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.446088790893555
Epoch: 5, Steps: 96 Train Loss: 0.5594 (Forecasting Loss:0.2508 + XiCon Loss:3.0857 x Lambda(0.1)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.1489
Validation loss decreased (0.271534 --> 0.268507).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.252935886383057
Epoch: 6, Steps: 96 Train Loss: 0.5567 (Forecasting Loss:0.2475 + XiCon Loss:3.0919 x Lambda(0.1)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.1445
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.978180408477783
Epoch: 7, Steps: 96 Train Loss: 0.5550 (Forecasting Loss:0.2458 + XiCon Loss:3.0917 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1427
Validation loss decreased (0.268507 --> 0.265250).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.674364566802979
Epoch: 8, Steps: 96 Train Loss: 0.5543 (Forecasting Loss:0.2446 + XiCon Loss:3.0970 x Lambda(0.1)), Vali MSE Loss: 0.2681 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 15.37922716140747
Epoch: 9, Steps: 96 Train Loss: 0.5541 (Forecasting Loss:0.2446 + XiCon Loss:3.0945 x Lambda(0.1)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.1444
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.475017547607422
Epoch: 10, Steps: 96 Train Loss: 0.5540 (Forecasting Loss:0.2444 + XiCon Loss:3.0963 x Lambda(0.1)), Vali MSE Loss: 0.2669 Test MSE Loss: 0.1430
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 15.140535593032837
Epoch: 11, Steps: 96 Train Loss: 0.5545 (Forecasting Loss:0.2444 + XiCon Loss:3.1012 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.1432
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.970929622650146
Epoch: 12, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2440 + XiCon Loss:3.0984 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.702311277389526
Epoch: 13, Steps: 96 Train Loss: 0.5535 (Forecasting Loss:0.2442 + XiCon Loss:3.0932 x Lambda(0.1)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.1433
Validation loss decreased (0.265250 --> 0.265108).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 12.572352170944214
Epoch: 14, Steps: 96 Train Loss: 0.5532 (Forecasting Loss:0.2438 + XiCon Loss:3.0941 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1433
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 15.02425765991211
Epoch: 15, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2439 + XiCon Loss:3.1039 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1433
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 15.106868267059326
Epoch: 16, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2436 + XiCon Loss:3.0974 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 16.27805995941162
Epoch: 17, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2436 + XiCon Loss:3.1021 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 15.510285377502441
Epoch: 18, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2442 + XiCon Loss:3.0973 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1434
Validation loss decreased (0.265108 --> 0.265010).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 14.66028881072998
Epoch: 19, Steps: 96 Train Loss: 0.5536 (Forecasting Loss:0.2438 + XiCon Loss:3.0983 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1434
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 15.55824899673462
Epoch: 20, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2439 + XiCon Loss:3.0985 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 14.269567012786865
Epoch: 21, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2440 + XiCon Loss:3.0986 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 15.702618598937988
Epoch: 22, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2440 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 15.91753602027893
Epoch: 23, Steps: 96 Train Loss: 0.5535 (Forecasting Loss:0.2436 + XiCon Loss:3.0991 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 15.006301879882812
Epoch: 24, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2439 + XiCon Loss:3.0990 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 16.015071392059326
Epoch: 25, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2437 + XiCon Loss:3.0960 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1434
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 15.322258234024048
Epoch: 26, Steps: 96 Train Loss: 0.5537 (Forecasting Loss:0.2438 + XiCon Loss:3.0997 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1434
Validation loss decreased (0.265010 --> 0.264962).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 15.315231084823608
Epoch: 27, Steps: 96 Train Loss: 0.5541 (Forecasting Loss:0.2436 + XiCon Loss:3.1052 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1434
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 15.345278978347778
Epoch: 28, Steps: 96 Train Loss: 0.5536 (Forecasting Loss:0.2439 + XiCon Loss:3.0965 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 15.108601570129395
Epoch: 29, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2441 + XiCon Loss:3.0972 x Lambda(0.1)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 16.485540628433228
Epoch: 30, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2438 + XiCon Loss:3.0997 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 15.423583507537842
Epoch: 31, Steps: 96 Train Loss: 0.5543 (Forecasting Loss:0.2441 + XiCon Loss:3.1017 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 15.75740122795105
Epoch: 32, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2440 + XiCon Loss:3.0980 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 15.117991209030151
Epoch: 33, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2442 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1434
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 15.325243711471558
Epoch: 34, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2442 + XiCon Loss:3.0992 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1434
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 14.98418641090393
Epoch: 35, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2439 + XiCon Loss:3.0944 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 15.583013534545898
Epoch: 36, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2437 + XiCon Loss:3.0959 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07386161386966705, mae:0.21289987862110138, mape:0.15573394298553467, mspe:0.04083433747291565 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3958
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.574581623077393
Epoch: 1, Steps: 96 Train Loss: 1.0626 (Forecasting Loss:0.7479 + XiCon Loss:3.1474 x Lambda(0.1)), Vali MSE Loss: 0.5286 Test MSE Loss: 0.3407
Validation loss decreased (inf --> 0.528568).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 24.802082777023315
Epoch: 2, Steps: 96 Train Loss: 0.6663 (Forecasting Loss:0.3604 + XiCon Loss:3.0585 x Lambda(0.1)), Vali MSE Loss: 0.2880 Test MSE Loss: 0.1642
Validation loss decreased (0.528568 --> 0.288028).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 27.413365125656128
Epoch: 3, Steps: 96 Train Loss: 0.5531 (Forecasting Loss:0.2516 + XiCon Loss:3.0149 x Lambda(0.1)), Vali MSE Loss: 0.3043 Test MSE Loss: 0.1779
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 26.627395391464233
Epoch: 4, Steps: 96 Train Loss: 0.5469 (Forecasting Loss:0.2412 + XiCon Loss:3.0569 x Lambda(0.1)), Vali MSE Loss: 0.2759 Test MSE Loss: 0.1604
Validation loss decreased (0.288028 --> 0.275920).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 26.29304313659668
Epoch: 5, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2368 + XiCon Loss:3.0896 x Lambda(0.1)), Vali MSE Loss: 0.2769 Test MSE Loss: 0.1613
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 26.6237154006958
Epoch: 6, Steps: 96 Train Loss: 0.5451 (Forecasting Loss:0.2349 + XiCon Loss:3.1023 x Lambda(0.1)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.1569
Validation loss decreased (0.275920 --> 0.267023).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 26.39122223854065
Epoch: 7, Steps: 96 Train Loss: 0.5460 (Forecasting Loss:0.2341 + XiCon Loss:3.1182 x Lambda(0.1)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1607
Validation loss decreased (0.267023 --> 0.261147).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 26.153104305267334
Epoch: 8, Steps: 96 Train Loss: 0.5458 (Forecasting Loss:0.2334 + XiCon Loss:3.1241 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1625
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 26.60499382019043
Epoch: 9, Steps: 96 Train Loss: 0.5462 (Forecasting Loss:0.2333 + XiCon Loss:3.1293 x Lambda(0.1)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.1597
Validation loss decreased (0.261147 --> 0.260071).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 26.3557288646698
Epoch: 10, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2330 + XiCon Loss:3.1336 x Lambda(0.1)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1608
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 26.335676431655884
Epoch: 11, Steps: 96 Train Loss: 0.5460 (Forecasting Loss:0.2331 + XiCon Loss:3.1289 x Lambda(0.1)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1607
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 26.331347703933716
Epoch: 12, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2330 + XiCon Loss:3.1338 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1612
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 26.095253944396973
Epoch: 13, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2332 + XiCon Loss:3.1296 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1609
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 26.224069833755493
Epoch: 14, Steps: 96 Train Loss: 0.5459 (Forecasting Loss:0.2330 + XiCon Loss:3.1289 x Lambda(0.1)), Vali MSE Loss: 0.2608 Test MSE Loss: 0.1610
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 26.35799479484558
Epoch: 15, Steps: 96 Train Loss: 0.5456 (Forecasting Loss:0.2328 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.1610
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 26.53590416908264
Epoch: 16, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2332 + XiCon Loss:3.1295 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1609
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 26.08590292930603
Epoch: 17, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2328 + XiCon Loss:3.1333 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.1609
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 26.55168318748474
Epoch: 18, Steps: 96 Train Loss: 0.5465 (Forecasting Loss:0.2333 + XiCon Loss:3.1314 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.1609
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 26.28475856781006
Epoch: 19, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2330 + XiCon Loss:3.1347 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1609
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08751913160085678, mae:0.2319341003894806, mape:0.17410247027873993, mspe:0.05681435763835907 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2380
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.21550703048706
Epoch: 1, Steps: 96 Train Loss: 1.0296 (Forecasting Loss:0.7124 + XiCon Loss:3.1718 x Lambda(0.1)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2468
Validation loss decreased (inf --> 0.406684).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 12.140928983688354
Epoch: 2, Steps: 96 Train Loss: 0.7796 (Forecasting Loss:0.4691 + XiCon Loss:3.1051 x Lambda(0.1)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1633
Validation loss decreased (0.406684 --> 0.259430).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.308896780014038
Epoch: 3, Steps: 96 Train Loss: 0.5961 (Forecasting Loss:0.2907 + XiCon Loss:3.0542 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1405
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.96216106414795
Epoch: 4, Steps: 96 Train Loss: 0.5721 (Forecasting Loss:0.2623 + XiCon Loss:3.0977 x Lambda(0.1)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.1547
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.460552215576172
Epoch: 5, Steps: 96 Train Loss: 0.5647 (Forecasting Loss:0.2525 + XiCon Loss:3.1217 x Lambda(0.1)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.1452
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.2347674369812
Epoch: 6, Steps: 96 Train Loss: 0.5631 (Forecasting Loss:0.2495 + XiCon Loss:3.1356 x Lambda(0.1)), Vali MSE Loss: 0.2822 Test MSE Loss: 0.1465
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.930045127868652
Epoch: 7, Steps: 96 Train Loss: 0.5615 (Forecasting Loss:0.2476 + XiCon Loss:3.1393 x Lambda(0.1)), Vali MSE Loss: 0.2778 Test MSE Loss: 0.1528
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.135135173797607
Epoch: 8, Steps: 96 Train Loss: 0.5606 (Forecasting Loss:0.2459 + XiCon Loss:3.1475 x Lambda(0.1)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.1548
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 15.840149879455566
Epoch: 9, Steps: 96 Train Loss: 0.5606 (Forecasting Loss:0.2459 + XiCon Loss:3.1469 x Lambda(0.1)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.1549
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.944590330123901
Epoch: 10, Steps: 96 Train Loss: 0.5603 (Forecasting Loss:0.2456 + XiCon Loss:3.1477 x Lambda(0.1)), Vali MSE Loss: 0.2870 Test MSE Loss: 0.1538
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.664666652679443
Epoch: 11, Steps: 96 Train Loss: 0.5600 (Forecasting Loss:0.2456 + XiCon Loss:3.1432 x Lambda(0.1)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.1542
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.874304056167603
Epoch: 12, Steps: 96 Train Loss: 0.5600 (Forecasting Loss:0.2455 + XiCon Loss:3.1450 x Lambda(0.1)), Vali MSE Loss: 0.2844 Test MSE Loss: 0.1552
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08946070075035095, mae:0.2371090054512024, mape:0.16825024783611298, mspe:0.04305737093091011 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3743
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.742104291915894
Epoch: 1, Steps: 96 Train Loss: 1.0638 (Forecasting Loss:0.7491 + XiCon Loss:3.1473 x Lambda(0.1)), Vali MSE Loss: 0.5495 Test MSE Loss: 0.3516
Validation loss decreased (inf --> 0.549536).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 24.846174716949463
Epoch: 2, Steps: 96 Train Loss: 0.7089 (Forecasting Loss:0.3993 + XiCon Loss:3.0964 x Lambda(0.1)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.1629
Validation loss decreased (0.549536 --> 0.358546).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 24.625779151916504
Epoch: 3, Steps: 96 Train Loss: 0.5610 (Forecasting Loss:0.2533 + XiCon Loss:3.0765 x Lambda(0.1)), Vali MSE Loss: 0.2703 Test MSE Loss: 0.1454
Validation loss decreased (0.358546 --> 0.270306).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 27.965787887573242
Epoch: 4, Steps: 96 Train Loss: 0.5526 (Forecasting Loss:0.2431 + XiCon Loss:3.0948 x Lambda(0.1)), Vali MSE Loss: 0.2400 Test MSE Loss: 0.1471
Validation loss decreased (0.270306 --> 0.239963).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 28.650301933288574
Epoch: 5, Steps: 96 Train Loss: 0.5493 (Forecasting Loss:0.2384 + XiCon Loss:3.1085 x Lambda(0.1)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1403
Validation loss decreased (0.239963 --> 0.233848).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 26.344659566879272
Epoch: 6, Steps: 96 Train Loss: 0.5475 (Forecasting Loss:0.2358 + XiCon Loss:3.1169 x Lambda(0.1)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1424
Validation loss decreased (0.233848 --> 0.230705).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 27.301271438598633
Epoch: 7, Steps: 96 Train Loss: 0.5468 (Forecasting Loss:0.2346 + XiCon Loss:3.1222 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1404
Validation loss decreased (0.230705 --> 0.228543).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 28.030639171600342
Epoch: 8, Steps: 96 Train Loss: 0.5462 (Forecasting Loss:0.2340 + XiCon Loss:3.1216 x Lambda(0.1)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.1393
Validation loss decreased (0.228543 --> 0.226923).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 27.56924343109131
Epoch: 9, Steps: 96 Train Loss: 0.5458 (Forecasting Loss:0.2337 + XiCon Loss:3.1206 x Lambda(0.1)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 28.12335753440857
Epoch: 10, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2332 + XiCon Loss:3.1241 x Lambda(0.1)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1393
Validation loss decreased (0.226923 --> 0.226138).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 27.70903754234314
Epoch: 11, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2335 + XiCon Loss:3.1252 x Lambda(0.1)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1390
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 27.20160698890686
Epoch: 12, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2335 + XiCon Loss:3.1222 x Lambda(0.1)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 25.454524993896484
Epoch: 13, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2334 + XiCon Loss:3.1229 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1390
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 27.42032027244568
Epoch: 14, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2337 + XiCon Loss:3.1234 x Lambda(0.1)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1390
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 27.281922340393066
Epoch: 15, Steps: 96 Train Loss: 0.5452 (Forecasting Loss:0.2334 + XiCon Loss:3.1187 x Lambda(0.1)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1390
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 27.442049503326416
Epoch: 16, Steps: 96 Train Loss: 0.5455 (Forecasting Loss:0.2334 + XiCon Loss:3.1205 x Lambda(0.1)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1390
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 27.697237014770508
Epoch: 17, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2335 + XiCon Loss:3.1221 x Lambda(0.1)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.1390
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 27.768341064453125
Epoch: 18, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2337 + XiCon Loss:3.1240 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1390
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 27.95869731903076
Epoch: 19, Steps: 96 Train Loss: 0.5456 (Forecasting Loss:0.2333 + XiCon Loss:3.1233 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1390
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 27.603377103805542
Epoch: 20, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2334 + XiCon Loss:3.1296 x Lambda(0.1)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1390
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.0707414448261261, mae:0.2077791392803192, mape:0.15678198635578156, mspe:0.04526461288332939 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0832+-0.01278, MAE:0.2265+-0.01913, MAPE:0.1654+-0.01072, MSPE:0.0462+-0.00770, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4801
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5392143
	speed: 0.0330s/iter; left time: 418.7004s
Epoch: 1 cost time: 4.075403690338135
Epoch: 1, Steps: 128 Train Loss: 0.6005 (Forecasting Loss:0.2925 + XiCon Loss:3.0803 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.2319
Validation loss decreased (inf --> 0.276369).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5067680
	speed: 0.0306s/iter; left time: 384.5105s
Epoch: 2 cost time: 3.9363112449645996
Epoch: 2, Steps: 128 Train Loss: 0.5380 (Forecasting Loss:0.2459 + XiCon Loss:2.9217 x Lambda(0.1)), Vali MSE Loss: 0.2751 Test MSE Loss: 0.2496
Validation loss decreased (0.276369 --> 0.275066).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5139130
	speed: 0.0301s/iter; left time: 374.9419s
Epoch: 3 cost time: 3.7251343727111816
Epoch: 3, Steps: 128 Train Loss: 0.5058 (Forecasting Loss:0.2145 + XiCon Loss:2.9133 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.2282
Validation loss decreased (0.275066 --> 0.243642).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4811319
	speed: 0.0258s/iter; left time: 318.0879s
Epoch: 4 cost time: 3.170090675354004
Epoch: 4, Steps: 128 Train Loss: 0.4958 (Forecasting Loss:0.1993 + XiCon Loss:2.9653 x Lambda(0.1)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.2259
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4982353
	speed: 0.0291s/iter; left time: 355.1726s
Epoch: 5 cost time: 3.6983771324157715
Epoch: 5, Steps: 128 Train Loss: 0.4832 (Forecasting Loss:0.1891 + XiCon Loss:2.9417 x Lambda(0.1)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2207
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4899297
	speed: 0.0297s/iter; left time: 358.3921s
Epoch: 6 cost time: 3.7842965126037598
Epoch: 6, Steps: 128 Train Loss: 0.4771 (Forecasting Loss:0.1834 + XiCon Loss:2.9374 x Lambda(0.1)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2286
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5237131
	speed: 0.0296s/iter; left time: 353.1303s
Epoch: 7 cost time: 3.748532295227051
Epoch: 7, Steps: 128 Train Loss: 0.4729 (Forecasting Loss:0.1804 + XiCon Loss:2.9248 x Lambda(0.1)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.2288
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4753328
	speed: 0.0308s/iter; left time: 363.3758s
Epoch: 8 cost time: 3.8857123851776123
Epoch: 8, Steps: 128 Train Loss: 0.4712 (Forecasting Loss:0.1792 + XiCon Loss:2.9205 x Lambda(0.1)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.2289
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4586383
	speed: 0.0298s/iter; left time: 347.4597s
Epoch: 9 cost time: 3.7905025482177734
Epoch: 9, Steps: 128 Train Loss: 0.4701 (Forecasting Loss:0.1781 + XiCon Loss:2.9208 x Lambda(0.1)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.2294
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4645728
	speed: 0.0241s/iter; left time: 278.2598s
Epoch: 10 cost time: 3.0763654708862305
Epoch: 10, Steps: 128 Train Loss: 0.4705 (Forecasting Loss:0.1780 + XiCon Loss:2.9254 x Lambda(0.1)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.2291
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4508826
	speed: 0.0291s/iter; left time: 332.2132s
Epoch: 11 cost time: 3.6494340896606445
Epoch: 11, Steps: 128 Train Loss: 0.4701 (Forecasting Loss:0.1778 + XiCon Loss:2.9225 x Lambda(0.1)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2289
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4510461
	speed: 0.0286s/iter; left time: 323.3547s
Epoch: 12 cost time: 3.678556203842163
Epoch: 12, Steps: 128 Train Loss: 0.4698 (Forecasting Loss:0.1776 + XiCon Loss:2.9224 x Lambda(0.1)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.2287
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4602236
	speed: 0.0273s/iter; left time: 304.7300s
Epoch: 13 cost time: 3.477562189102173
Epoch: 13, Steps: 128 Train Loss: 0.4696 (Forecasting Loss:0.1776 + XiCon Loss:2.9200 x Lambda(0.1)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.2289
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15218506753444672, mae:0.3041181266307831, mape:0.6908207535743713, mspe:20.042552947998047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3994
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5655848
	speed: 0.0289s/iter; left time: 366.8944s
Epoch: 1 cost time: 3.596713066101074
Epoch: 1, Steps: 128 Train Loss: 0.5973 (Forecasting Loss:0.2884 + XiCon Loss:3.0890 x Lambda(0.1)), Vali MSE Loss: 0.2729 Test MSE Loss: 0.2234
Validation loss decreased (inf --> 0.272932).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4939283
	speed: 0.0294s/iter; left time: 369.7191s
Epoch: 2 cost time: 3.7322418689727783
Epoch: 2, Steps: 128 Train Loss: 0.5405 (Forecasting Loss:0.2443 + XiCon Loss:2.9615 x Lambda(0.1)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2396
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4949327
	speed: 0.0281s/iter; left time: 349.1771s
Epoch: 3 cost time: 3.358750820159912
Epoch: 3, Steps: 128 Train Loss: 0.4897 (Forecasting Loss:0.1976 + XiCon Loss:2.9216 x Lambda(0.1)), Vali MSE Loss: 0.2937 Test MSE Loss: 0.2490
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4596489
	speed: 0.0255s/iter; left time: 313.7920s
Epoch: 4 cost time: 3.4129395484924316
Epoch: 4, Steps: 128 Train Loss: 0.4669 (Forecasting Loss:0.1739 + XiCon Loss:2.9305 x Lambda(0.1)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.2391
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4482545
	speed: 0.0294s/iter; left time: 358.8667s
Epoch: 5 cost time: 3.757091760635376
Epoch: 5, Steps: 128 Train Loss: 0.4588 (Forecasting Loss:0.1638 + XiCon Loss:2.9507 x Lambda(0.1)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.2500
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4670076
	speed: 0.0292s/iter; left time: 352.6089s
Epoch: 6 cost time: 3.569021701812744
Epoch: 6, Steps: 128 Train Loss: 0.4550 (Forecasting Loss:0.1588 + XiCon Loss:2.9621 x Lambda(0.1)), Vali MSE Loss: 0.3038 Test MSE Loss: 0.2561
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4528836
	speed: 0.0297s/iter; left time: 354.6959s
Epoch: 7 cost time: 3.712557077407837
Epoch: 7, Steps: 128 Train Loss: 0.4524 (Forecasting Loss:0.1564 + XiCon Loss:2.9601 x Lambda(0.1)), Vali MSE Loss: 0.3039 Test MSE Loss: 0.2525
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4432575
	speed: 0.0305s/iter; left time: 360.2238s
Epoch: 8 cost time: 3.87241530418396
Epoch: 8, Steps: 128 Train Loss: 0.4516 (Forecasting Loss:0.1547 + XiCon Loss:2.9694 x Lambda(0.1)), Vali MSE Loss: 0.3078 Test MSE Loss: 0.2526
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4499794
	speed: 0.0299s/iter; left time: 348.5752s
Epoch: 9 cost time: 3.5626251697540283
Epoch: 9, Steps: 128 Train Loss: 0.4516 (Forecasting Loss:0.1544 + XiCon Loss:2.9723 x Lambda(0.1)), Vali MSE Loss: 0.3078 Test MSE Loss: 0.2528
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4567173
	speed: 0.0257s/iter; left time: 296.8538s
Epoch: 10 cost time: 3.160156011581421
Epoch: 10, Steps: 128 Train Loss: 0.4512 (Forecasting Loss:0.1538 + XiCon Loss:2.9739 x Lambda(0.1)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.2543
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4618772
	speed: 0.0297s/iter; left time: 339.1416s
Epoch: 11 cost time: 3.702242374420166
Epoch: 11, Steps: 128 Train Loss: 0.4515 (Forecasting Loss:0.1538 + XiCon Loss:2.9777 x Lambda(0.1)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.2530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.14599673449993134, mae:0.3007132411003113, mape:0.6949891448020935, mspe:21.254976272583008 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3509
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5356646
	speed: 0.0300s/iter; left time: 381.2185s
Epoch: 1 cost time: 3.790243148803711
Epoch: 1, Steps: 128 Train Loss: 0.6032 (Forecasting Loss:0.2943 + XiCon Loss:3.0888 x Lambda(0.1)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.2273
Validation loss decreased (inf --> 0.271550).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5109082
	speed: 0.0283s/iter; left time: 355.9191s
Epoch: 2 cost time: 3.642688512802124
Epoch: 2, Steps: 128 Train Loss: 0.5400 (Forecasting Loss:0.2422 + XiCon Loss:2.9784 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.2602
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5145085
	speed: 0.0306s/iter; left time: 381.2208s
Epoch: 3 cost time: 3.836902618408203
Epoch: 3, Steps: 128 Train Loss: 0.5156 (Forecasting Loss:0.2160 + XiCon Loss:2.9959 x Lambda(0.1)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2290
Validation loss decreased (0.271550 --> 0.250375).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4983917
	speed: 0.0302s/iter; left time: 371.6346s
Epoch: 4 cost time: 3.677088737487793
Epoch: 4, Steps: 128 Train Loss: 0.4971 (Forecasting Loss:0.2005 + XiCon Loss:2.9666 x Lambda(0.1)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2367
Validation loss decreased (0.250375 --> 0.247045).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4861921
	speed: 0.0254s/iter; left time: 309.6125s
Epoch: 5 cost time: 3.1255176067352295
Epoch: 5, Steps: 128 Train Loss: 0.4865 (Forecasting Loss:0.1912 + XiCon Loss:2.9522 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.2427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4718173
	speed: 0.0296s/iter; left time: 357.5374s
Epoch: 6 cost time: 3.772362232208252
Epoch: 6, Steps: 128 Train Loss: 0.4810 (Forecasting Loss:0.1859 + XiCon Loss:2.9505 x Lambda(0.1)), Vali MSE Loss: 0.2563 Test MSE Loss: 0.2520
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4997842
	speed: 0.0291s/iter; left time: 346.9378s
Epoch: 7 cost time: 3.722720146179199
Epoch: 7, Steps: 128 Train Loss: 0.4785 (Forecasting Loss:0.1836 + XiCon Loss:2.9491 x Lambda(0.1)), Vali MSE Loss: 0.2567 Test MSE Loss: 0.2491
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4770266
	speed: 0.0311s/iter; left time: 366.8390s
Epoch: 8 cost time: 3.928790807723999
Epoch: 8, Steps: 128 Train Loss: 0.4770 (Forecasting Loss:0.1820 + XiCon Loss:2.9502 x Lambda(0.1)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.2494
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4717672
	speed: 0.0302s/iter; left time: 353.1266s
Epoch: 9 cost time: 3.848402261734009
Epoch: 9, Steps: 128 Train Loss: 0.4762 (Forecasting Loss:0.1814 + XiCon Loss:2.9480 x Lambda(0.1)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2495
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4664466
	speed: 0.0299s/iter; left time: 345.7143s
Epoch: 10 cost time: 3.8154938220977783
Epoch: 10, Steps: 128 Train Loss: 0.4763 (Forecasting Loss:0.1815 + XiCon Loss:2.9481 x Lambda(0.1)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2499
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4885712
	speed: 0.0253s/iter; left time: 288.6733s
Epoch: 11 cost time: 3.2996301651000977
Epoch: 11, Steps: 128 Train Loss: 0.4763 (Forecasting Loss:0.1812 + XiCon Loss:2.9508 x Lambda(0.1)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.2497
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4849506
	speed: 0.0324s/iter; left time: 366.3196s
Epoch: 12 cost time: 4.005859136581421
Epoch: 12, Steps: 128 Train Loss: 0.4765 (Forecasting Loss:0.1813 + XiCon Loss:2.9519 x Lambda(0.1)), Vali MSE Loss: 0.2574 Test MSE Loss: 0.2504
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4858128
	speed: 0.0280s/iter; left time: 312.2591s
Epoch: 13 cost time: 3.5341615676879883
Epoch: 13, Steps: 128 Train Loss: 0.4758 (Forecasting Loss:0.1808 + XiCon Loss:2.9508 x Lambda(0.1)), Vali MSE Loss: 0.2579 Test MSE Loss: 0.2503
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4676513
	speed: 0.0305s/iter; left time: 336.5242s
Epoch: 14 cost time: 3.8709633350372314
Epoch: 14, Steps: 128 Train Loss: 0.4770 (Forecasting Loss:0.1811 + XiCon Loss:2.9589 x Lambda(0.1)), Vali MSE Loss: 0.2576 Test MSE Loss: 0.2502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.164995014667511, mae:0.3084210157394409, mape:0.7024813890457153, mspe:24.53595733642578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4010
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5674015
	speed: 0.0307s/iter; left time: 390.3543s
Epoch: 1 cost time: 3.9003384113311768
Epoch: 1, Steps: 128 Train Loss: 0.6004 (Forecasting Loss:0.2935 + XiCon Loss:3.0689 x Lambda(0.1)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.2296
Validation loss decreased (inf --> 0.275713).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5144041
	speed: 0.0292s/iter; left time: 367.2592s
Epoch: 2 cost time: 3.5702261924743652
Epoch: 2, Steps: 128 Train Loss: 0.5451 (Forecasting Loss:0.2524 + XiCon Loss:2.9269 x Lambda(0.1)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.2267
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5229464
	speed: 0.0247s/iter; left time: 307.9605s
Epoch: 3 cost time: 3.050899028778076
Epoch: 3, Steps: 128 Train Loss: 0.5371 (Forecasting Loss:0.2341 + XiCon Loss:3.0300 x Lambda(0.1)), Vali MSE Loss: 0.2776 Test MSE Loss: 0.2206
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5220272
	speed: 0.0297s/iter; left time: 366.4233s
Epoch: 4 cost time: 3.746000289916992
Epoch: 4, Steps: 128 Train Loss: 0.5196 (Forecasting Loss:0.2185 + XiCon Loss:3.0109 x Lambda(0.1)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2146
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5112052
	speed: 0.0306s/iter; left time: 373.3101s
Epoch: 5 cost time: 3.842207670211792
Epoch: 5, Steps: 128 Train Loss: 0.5088 (Forecasting Loss:0.2092 + XiCon Loss:2.9957 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.2063
Validation loss decreased (0.275713 --> 0.264036).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5007161
	speed: 0.0310s/iter; left time: 373.6238s
Epoch: 6 cost time: 3.9250733852386475
Epoch: 6, Steps: 128 Train Loss: 0.5027 (Forecasting Loss:0.2039 + XiCon Loss:2.9883 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2095
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4933157
	speed: 0.0300s/iter; left time: 357.7385s
Epoch: 7 cost time: 3.7677886486053467
Epoch: 7, Steps: 128 Train Loss: 0.5007 (Forecasting Loss:0.2017 + XiCon Loss:2.9905 x Lambda(0.1)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.2096
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4936192
	speed: 0.0286s/iter; left time: 337.4129s
Epoch: 8 cost time: 3.701655864715576
Epoch: 8, Steps: 128 Train Loss: 0.4991 (Forecasting Loss:0.2004 + XiCon Loss:2.9866 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.2086
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4881456
	speed: 0.0249s/iter; left time: 290.2106s
Epoch: 9 cost time: 3.0639913082122803
Epoch: 9, Steps: 128 Train Loss: 0.4985 (Forecasting Loss:0.2001 + XiCon Loss:2.9839 x Lambda(0.1)), Vali MSE Loss: 0.2683 Test MSE Loss: 0.2086
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5072092
	speed: 0.0260s/iter; left time: 299.9244s
Epoch: 10 cost time: 3.4611384868621826
Epoch: 10, Steps: 128 Train Loss: 0.4988 (Forecasting Loss:0.1996 + XiCon Loss:2.9920 x Lambda(0.1)), Vali MSE Loss: 0.2700 Test MSE Loss: 0.2088
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5004948
	speed: 0.0289s/iter; left time: 329.8795s
Epoch: 11 cost time: 3.689683437347412
Epoch: 11, Steps: 128 Train Loss: 0.4977 (Forecasting Loss:0.1991 + XiCon Loss:2.9859 x Lambda(0.1)), Vali MSE Loss: 0.2697 Test MSE Loss: 0.2089
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4792542
	speed: 0.0309s/iter; left time: 348.7059s
Epoch: 12 cost time: 3.893211841583252
Epoch: 12, Steps: 128 Train Loss: 0.4967 (Forecasting Loss:0.1987 + XiCon Loss:2.9802 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2089
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4798806
	speed: 0.0316s/iter; left time: 352.3014s
Epoch: 13 cost time: 4.0832695960998535
Epoch: 13, Steps: 128 Train Loss: 0.4973 (Forecasting Loss:0.1989 + XiCon Loss:2.9843 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2089
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4983810
	speed: 0.0292s/iter; left time: 322.6484s
Epoch: 14 cost time: 3.7593414783477783
Epoch: 14, Steps: 128 Train Loss: 0.4982 (Forecasting Loss:0.1993 + XiCon Loss:2.9891 x Lambda(0.1)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.2089
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5059118
	speed: 0.0268s/iter; left time: 292.0587s
Epoch: 15 cost time: 3.4530158042907715
Epoch: 15, Steps: 128 Train Loss: 0.4976 (Forecasting Loss:0.1988 + XiCon Loss:2.9884 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2089
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13279597461223602, mae:0.2797616720199585, mape:0.6751301288604736, mspe:21.131385803222656 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4244
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5429057
	speed: 0.0137s/iter; left time: 173.5008s
Epoch: 1 cost time: 1.706118106842041
Epoch: 1, Steps: 128 Train Loss: 0.5989 (Forecasting Loss:0.2927 + XiCon Loss:3.0627 x Lambda(0.1)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2273
Validation loss decreased (inf --> 0.278173).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5261894
	speed: 0.0128s/iter; left time: 161.0501s
Epoch: 2 cost time: 1.6250910758972168
Epoch: 2, Steps: 128 Train Loss: 0.5382 (Forecasting Loss:0.2427 + XiCon Loss:2.9547 x Lambda(0.1)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.2619
Validation loss decreased (0.278173 --> 0.266248).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5063909
	speed: 0.0302s/iter; left time: 375.6097s
Epoch: 3 cost time: 3.8753960132598877
Epoch: 3, Steps: 128 Train Loss: 0.5022 (Forecasting Loss:0.2036 + XiCon Loss:2.9864 x Lambda(0.1)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2797
Validation loss decreased (0.266248 --> 0.258060).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4774914
	speed: 0.0299s/iter; left time: 368.7320s
Epoch: 4 cost time: 3.7712042331695557
Epoch: 4, Steps: 128 Train Loss: 0.4889 (Forecasting Loss:0.1861 + XiCon Loss:3.0285 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2899
Validation loss decreased (0.258060 --> 0.255083).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4799967
	speed: 0.0302s/iter; left time: 367.5416s
Epoch: 5 cost time: 3.9036619663238525
Epoch: 5, Steps: 128 Train Loss: 0.4778 (Forecasting Loss:0.1773 + XiCon Loss:3.0050 x Lambda(0.1)), Vali MSE Loss: 0.2826 Test MSE Loss: 0.2805
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4594874
	speed: 0.0309s/iter; left time: 372.5872s
Epoch: 6 cost time: 3.851954698562622
Epoch: 6, Steps: 128 Train Loss: 0.4716 (Forecasting Loss:0.1721 + XiCon Loss:2.9957 x Lambda(0.1)), Vali MSE Loss: 0.2723 Test MSE Loss: 0.2964
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4715286
	speed: 0.0306s/iter; left time: 364.6891s
Epoch: 7 cost time: 3.860962390899658
Epoch: 7, Steps: 128 Train Loss: 0.4685 (Forecasting Loss:0.1693 + XiCon Loss:2.9920 x Lambda(0.1)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.2900
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4882972
	speed: 0.0252s/iter; left time: 298.0133s
Epoch: 8 cost time: 3.074023485183716
Epoch: 8, Steps: 128 Train Loss: 0.4666 (Forecasting Loss:0.1679 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.2885
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4659359
	speed: 0.0253s/iter; left time: 295.4221s
Epoch: 9 cost time: 3.3684797286987305
Epoch: 9, Steps: 128 Train Loss: 0.4665 (Forecasting Loss:0.1676 + XiCon Loss:2.9894 x Lambda(0.1)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.2890
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4462789
	speed: 0.0330s/iter; left time: 380.8035s
Epoch: 10 cost time: 4.0192365646362305
Epoch: 10, Steps: 128 Train Loss: 0.4659 (Forecasting Loss:0.1673 + XiCon Loss:2.9866 x Lambda(0.1)), Vali MSE Loss: 0.2732 Test MSE Loss: 0.2917
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4721197
	speed: 0.0322s/iter; left time: 368.2280s
Epoch: 11 cost time: 4.049084186553955
Epoch: 11, Steps: 128 Train Loss: 0.4657 (Forecasting Loss:0.1670 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.2930
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4505158
	speed: 0.0313s/iter; left time: 353.6412s
Epoch: 12 cost time: 3.9351234436035156
Epoch: 12, Steps: 128 Train Loss: 0.4659 (Forecasting Loss:0.1669 + XiCon Loss:2.9900 x Lambda(0.1)), Vali MSE Loss: 0.2744 Test MSE Loss: 0.2919
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4744220
	speed: 0.0312s/iter; left time: 347.8559s
Epoch: 13 cost time: 3.9745094776153564
Epoch: 13, Steps: 128 Train Loss: 0.4662 (Forecasting Loss:0.1671 + XiCon Loss:2.9904 x Lambda(0.1)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.2916
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4762640
	speed: 0.0259s/iter; left time: 285.3971s
Epoch: 14 cost time: 3.203972339630127
Epoch: 14, Steps: 128 Train Loss: 0.4656 (Forecasting Loss:0.1670 + XiCon Loss:2.9859 x Lambda(0.1)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.2913
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.22516347467899323, mae:0.3546801507472992, mape:0.8022240400314331, mspe:24.07357406616211 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1642+-0.04468, MAE:0.3095+-0.03419, MAPE:0.7131+-0.06307, MSPE:22.2077+-2.45651, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7170936
	speed: 0.0488s/iter; left time: 570.4362s
Epoch: 1 cost time: 5.683764934539795
Epoch: 1, Steps: 118 Train Loss: 0.7238 (Forecasting Loss:0.4144 + XiCon Loss:3.0937 x Lambda(0.1)), Vali MSE Loss: 0.4342 Test MSE Loss: 0.3303
Validation loss decreased (inf --> 0.434243).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5645261
	speed: 0.0519s/iter; left time: 601.1032s
Epoch: 2 cost time: 6.176167726516724
Epoch: 2, Steps: 118 Train Loss: 0.5979 (Forecasting Loss:0.3056 + XiCon Loss:2.9235 x Lambda(0.1)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.2836
Validation loss decreased (0.434243 --> 0.339942).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5660512
	speed: 0.0590s/iter; left time: 676.3662s
Epoch: 3 cost time: 7.007627248764038
Epoch: 3, Steps: 118 Train Loss: 0.5523 (Forecasting Loss:0.2592 + XiCon Loss:2.9315 x Lambda(0.1)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.2793
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5580611
	speed: 0.0506s/iter; left time: 573.9529s
Epoch: 4 cost time: 5.944007396697998
Epoch: 4, Steps: 118 Train Loss: 0.5438 (Forecasting Loss:0.2481 + XiCon Loss:2.9573 x Lambda(0.1)), Vali MSE Loss: 0.3416 Test MSE Loss: 0.2670
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5285410
	speed: 0.0594s/iter; left time: 667.2033s
Epoch: 5 cost time: 7.00819730758667
Epoch: 5, Steps: 118 Train Loss: 0.5381 (Forecasting Loss:0.2428 + XiCon Loss:2.9527 x Lambda(0.1)), Vali MSE Loss: 0.3256 Test MSE Loss: 0.2698
Validation loss decreased (0.339942 --> 0.325551).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5245978
	speed: 0.0585s/iter; left time: 649.4382s
Epoch: 6 cost time: 6.862900257110596
Epoch: 6, Steps: 118 Train Loss: 0.5335 (Forecasting Loss:0.2395 + XiCon Loss:2.9405 x Lambda(0.1)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2723
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5279937
	speed: 0.0584s/iter; left time: 642.0984s
Epoch: 7 cost time: 6.885228872299194
Epoch: 7, Steps: 118 Train Loss: 0.5320 (Forecasting Loss:0.2380 + XiCon Loss:2.9406 x Lambda(0.1)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.2748
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5135432
	speed: 0.0550s/iter; left time: 597.7192s
Epoch: 8 cost time: 6.311673641204834
Epoch: 8, Steps: 118 Train Loss: 0.5311 (Forecasting Loss:0.2370 + XiCon Loss:2.9401 x Lambda(0.1)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.2730
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5292178
	speed: 0.0554s/iter; left time: 595.9767s
Epoch: 9 cost time: 6.537226438522339
Epoch: 9, Steps: 118 Train Loss: 0.5307 (Forecasting Loss:0.2366 + XiCon Loss:2.9407 x Lambda(0.1)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.2753
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5270923
	speed: 0.0553s/iter; left time: 587.8570s
Epoch: 10 cost time: 6.586831331253052
Epoch: 10, Steps: 118 Train Loss: 0.5294 (Forecasting Loss:0.2362 + XiCon Loss:2.9319 x Lambda(0.1)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.2742
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5233849
	speed: 0.0581s/iter; left time: 611.3502s
Epoch: 11 cost time: 6.91698956489563
Epoch: 11, Steps: 118 Train Loss: 0.5300 (Forecasting Loss:0.2361 + XiCon Loss:2.9383 x Lambda(0.1)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.2754
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5218754
	speed: 0.0576s/iter; left time: 598.7416s
Epoch: 12 cost time: 6.788542032241821
Epoch: 12, Steps: 118 Train Loss: 0.5299 (Forecasting Loss:0.2363 + XiCon Loss:2.9356 x Lambda(0.1)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.2756
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5343871
	speed: 0.0538s/iter; left time: 553.5055s
Epoch: 13 cost time: 6.552021265029907
Epoch: 13, Steps: 118 Train Loss: 0.5298 (Forecasting Loss:0.2361 + XiCon Loss:2.9373 x Lambda(0.1)), Vali MSE Loss: 0.3320 Test MSE Loss: 0.2755
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5311421
	speed: 0.0579s/iter; left time: 588.6839s
Epoch: 14 cost time: 6.848926782608032
Epoch: 14, Steps: 118 Train Loss: 0.5301 (Forecasting Loss:0.2363 + XiCon Loss:2.9380 x Lambda(0.1)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.2755
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5045266
	speed: 0.0582s/iter; left time: 584.5917s
Epoch: 15 cost time: 6.813812255859375
Epoch: 15, Steps: 118 Train Loss: 0.5293 (Forecasting Loss:0.2362 + XiCon Loss:2.9305 x Lambda(0.1)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.2755
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18586288392543793, mae:0.3538362681865692, mape:0.7940197587013245, mspe:25.910959243774414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7530493
	speed: 0.0451s/iter; left time: 528.0580s
Epoch: 1 cost time: 5.289624929428101
Epoch: 1, Steps: 118 Train Loss: 0.7152 (Forecasting Loss:0.4080 + XiCon Loss:3.0722 x Lambda(0.1)), Vali MSE Loss: 0.4295 Test MSE Loss: 0.3202
Validation loss decreased (inf --> 0.429452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6149049
	speed: 0.0461s/iter; left time: 533.6421s
Epoch: 2 cost time: 5.388118743896484
Epoch: 2, Steps: 118 Train Loss: 0.6214 (Forecasting Loss:0.3210 + XiCon Loss:3.0043 x Lambda(0.1)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.2665
Validation loss decreased (0.429452 --> 0.359814).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5698766
	speed: 0.0516s/iter; left time: 592.0681s
Epoch: 3 cost time: 5.9945573806762695
Epoch: 3, Steps: 118 Train Loss: 0.5730 (Forecasting Loss:0.2654 + XiCon Loss:3.0758 x Lambda(0.1)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.2813
Validation loss decreased (0.359814 --> 0.332482).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5470677
	speed: 0.0515s/iter; left time: 584.5197s
Epoch: 4 cost time: 6.058394908905029
Epoch: 4, Steps: 118 Train Loss: 0.5593 (Forecasting Loss:0.2561 + XiCon Loss:3.0317 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.2543
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5499593
	speed: 0.0506s/iter; left time: 567.7526s
Epoch: 5 cost time: 5.968810319900513
Epoch: 5, Steps: 118 Train Loss: 0.5478 (Forecasting Loss:0.2480 + XiCon Loss:2.9984 x Lambda(0.1)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2594
Validation loss decreased (0.332482 --> 0.325005).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5455720
	speed: 0.0524s/iter; left time: 581.8691s
Epoch: 6 cost time: 6.054501056671143
Epoch: 6, Steps: 118 Train Loss: 0.5448 (Forecasting Loss:0.2453 + XiCon Loss:2.9948 x Lambda(0.1)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.2613
Validation loss decreased (0.325005 --> 0.322497).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5640551
	speed: 0.0468s/iter; left time: 514.6339s
Epoch: 7 cost time: 5.349910020828247
Epoch: 7, Steps: 118 Train Loss: 0.5429 (Forecasting Loss:0.2436 + XiCon Loss:2.9926 x Lambda(0.1)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2615
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5449142
	speed: 0.0526s/iter; left time: 572.0127s
Epoch: 8 cost time: 6.188220024108887
Epoch: 8, Steps: 118 Train Loss: 0.5411 (Forecasting Loss:0.2429 + XiCon Loss:2.9820 x Lambda(0.1)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2623
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5379235
	speed: 0.0523s/iter; left time: 562.5964s
Epoch: 9 cost time: 6.0884270668029785
Epoch: 9, Steps: 118 Train Loss: 0.5406 (Forecasting Loss:0.2425 + XiCon Loss:2.9811 x Lambda(0.1)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2630
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5489173
	speed: 0.0548s/iter; left time: 582.5396s
Epoch: 10 cost time: 6.308111667633057
Epoch: 10, Steps: 118 Train Loss: 0.5407 (Forecasting Loss:0.2422 + XiCon Loss:2.9851 x Lambda(0.1)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2612
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5481060
	speed: 0.0538s/iter; left time: 565.8458s
Epoch: 11 cost time: 6.240774154663086
Epoch: 11, Steps: 118 Train Loss: 0.5404 (Forecasting Loss:0.2421 + XiCon Loss:2.9836 x Lambda(0.1)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2621
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5434512
	speed: 0.0465s/iter; left time: 484.0218s
Epoch: 12 cost time: 5.553757667541504
Epoch: 12, Steps: 118 Train Loss: 0.5401 (Forecasting Loss:0.2418 + XiCon Loss:2.9831 x Lambda(0.1)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2622
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5292732
	speed: 0.0505s/iter; left time: 519.0189s
Epoch: 13 cost time: 6.016127109527588
Epoch: 13, Steps: 118 Train Loss: 0.5403 (Forecasting Loss:0.2417 + XiCon Loss:2.9857 x Lambda(0.1)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2619
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5473017
	speed: 0.0521s/iter; left time: 530.0000s
Epoch: 14 cost time: 6.087635040283203
Epoch: 14, Steps: 118 Train Loss: 0.5404 (Forecasting Loss:0.2419 + XiCon Loss:2.9850 x Lambda(0.1)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2619
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5457989
	speed: 0.0529s/iter; left time: 531.5262s
Epoch: 15 cost time: 6.180056095123291
Epoch: 15, Steps: 118 Train Loss: 0.5406 (Forecasting Loss:0.2420 + XiCon Loss:2.9862 x Lambda(0.1)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2617
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5461028
	speed: 0.0492s/iter; left time: 488.5920s
Epoch: 16 cost time: 5.884564161300659
Epoch: 16, Steps: 118 Train Loss: 0.5403 (Forecasting Loss:0.2420 + XiCon Loss:2.9836 x Lambda(0.1)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2618
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17848125100135803, mae:0.34418439865112305, mape:0.6673824191093445, mspe:19.99431037902832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3941
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6863714
	speed: 0.0416s/iter; left time: 486.9355s
Epoch: 1 cost time: 4.910882949829102
Epoch: 1, Steps: 118 Train Loss: 0.7141 (Forecasting Loss:0.4074 + XiCon Loss:3.0675 x Lambda(0.1)), Vali MSE Loss: 0.4226 Test MSE Loss: 0.3132
Validation loss decreased (inf --> 0.422618).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5926634
	speed: 0.0470s/iter; left time: 544.5766s
Epoch: 2 cost time: 5.696278810501099
Epoch: 2, Steps: 118 Train Loss: 0.6016 (Forecasting Loss:0.3008 + XiCon Loss:3.0080 x Lambda(0.1)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.2689
Validation loss decreased (0.422618 --> 0.368876).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5522996
	speed: 0.0563s/iter; left time: 645.5389s
Epoch: 3 cost time: 6.729313611984253
Epoch: 3, Steps: 118 Train Loss: 0.5645 (Forecasting Loss:0.2627 + XiCon Loss:3.0174 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.2878
Validation loss decreased (0.368876 --> 0.299217).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5261717
	speed: 0.0547s/iter; left time: 620.9274s
Epoch: 4 cost time: 6.544600009918213
Epoch: 4, Steps: 118 Train Loss: 0.5478 (Forecasting Loss:0.2493 + XiCon Loss:2.9853 x Lambda(0.1)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.2685
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5509378
	speed: 0.0513s/iter; left time: 575.8315s
Epoch: 5 cost time: 6.187065362930298
Epoch: 5, Steps: 118 Train Loss: 0.5423 (Forecasting Loss:0.2435 + XiCon Loss:2.9882 x Lambda(0.1)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.2690
Validation loss decreased (0.299217 --> 0.297513).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5314611
	speed: 0.0561s/iter; left time: 623.8570s
Epoch: 6 cost time: 6.544893980026245
Epoch: 6, Steps: 118 Train Loss: 0.5394 (Forecasting Loss:0.2408 + XiCon Loss:2.9862 x Lambda(0.1)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.2652
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5413553
	speed: 0.0580s/iter; left time: 637.6481s
Epoch: 7 cost time: 6.86641001701355
Epoch: 7, Steps: 118 Train Loss: 0.5376 (Forecasting Loss:0.2395 + XiCon Loss:2.9814 x Lambda(0.1)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.2648
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5505298
	speed: 0.0541s/iter; left time: 588.6727s
Epoch: 8 cost time: 6.371709823608398
Epoch: 8, Steps: 118 Train Loss: 0.5365 (Forecasting Loss:0.2390 + XiCon Loss:2.9750 x Lambda(0.1)), Vali MSE Loss: 0.2998 Test MSE Loss: 0.2643
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5139496
	speed: 0.0557s/iter; left time: 598.9326s
Epoch: 9 cost time: 6.486459255218506
Epoch: 9, Steps: 118 Train Loss: 0.5359 (Forecasting Loss:0.2387 + XiCon Loss:2.9719 x Lambda(0.1)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2620
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5370727
	speed: 0.0488s/iter; left time: 518.8141s
Epoch: 10 cost time: 5.889909029006958
Epoch: 10, Steps: 118 Train Loss: 0.5357 (Forecasting Loss:0.2382 + XiCon Loss:2.9752 x Lambda(0.1)), Vali MSE Loss: 0.2999 Test MSE Loss: 0.2644
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5209734
	speed: 0.0558s/iter; left time: 587.3010s
Epoch: 11 cost time: 6.590607404708862
Epoch: 11, Steps: 118 Train Loss: 0.5354 (Forecasting Loss:0.2380 + XiCon Loss:2.9747 x Lambda(0.1)), Vali MSE Loss: 0.3007 Test MSE Loss: 0.2639
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5351024
	speed: 0.0543s/iter; left time: 565.0328s
Epoch: 12 cost time: 6.480997800827026
Epoch: 12, Steps: 118 Train Loss: 0.5349 (Forecasting Loss:0.2379 + XiCon Loss:2.9694 x Lambda(0.1)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.2636
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5242681
	speed: 0.0553s/iter; left time: 568.4022s
Epoch: 13 cost time: 6.5211334228515625
Epoch: 13, Steps: 118 Train Loss: 0.5349 (Forecasting Loss:0.2378 + XiCon Loss:2.9700 x Lambda(0.1)), Vali MSE Loss: 0.3004 Test MSE Loss: 0.2639
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5251161
	speed: 0.0566s/iter; left time: 575.7777s
Epoch: 14 cost time: 6.546508073806763
Epoch: 14, Steps: 118 Train Loss: 0.5350 (Forecasting Loss:0.2381 + XiCon Loss:2.9697 x Lambda(0.1)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.2639
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5476797
	speed: 0.0547s/iter; left time: 549.4370s
Epoch: 15 cost time: 6.573491334915161
Epoch: 15, Steps: 118 Train Loss: 0.5357 (Forecasting Loss:0.2378 + XiCon Loss:2.9793 x Lambda(0.1)), Vali MSE Loss: 0.3002 Test MSE Loss: 0.2640
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1850980520248413, mae:0.3528657853603363, mape:0.7929337024688721, mspe:25.365243911743164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3861
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7294396
	speed: 0.0467s/iter; left time: 546.5125s
Epoch: 1 cost time: 5.3991875648498535
Epoch: 1, Steps: 118 Train Loss: 0.7175 (Forecasting Loss:0.4087 + XiCon Loss:3.0883 x Lambda(0.1)), Vali MSE Loss: 0.4265 Test MSE Loss: 0.3209
Validation loss decreased (inf --> 0.426505).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5832743
	speed: 0.0482s/iter; left time: 557.9328s
Epoch: 2 cost time: 5.691433906555176
Epoch: 2, Steps: 118 Train Loss: 0.6174 (Forecasting Loss:0.3225 + XiCon Loss:2.9492 x Lambda(0.1)), Vali MSE Loss: 0.3351 Test MSE Loss: 0.2536
Validation loss decreased (0.426505 --> 0.335091).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5859807
	speed: 0.0522s/iter; left time: 598.2515s
Epoch: 3 cost time: 5.9446234703063965
Epoch: 3, Steps: 118 Train Loss: 0.5691 (Forecasting Loss:0.2695 + XiCon Loss:2.9962 x Lambda(0.1)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2647
Validation loss decreased (0.335091 --> 0.327154).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5477213
	speed: 0.0500s/iter; left time: 567.5114s
Epoch: 4 cost time: 5.979292154312134
Epoch: 4, Steps: 118 Train Loss: 0.5549 (Forecasting Loss:0.2536 + XiCon Loss:3.0130 x Lambda(0.1)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2559
Validation loss decreased (0.327154 --> 0.316441).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5437002
	speed: 0.0528s/iter; left time: 592.6055s
Epoch: 5 cost time: 6.349911451339722
Epoch: 5, Steps: 118 Train Loss: 0.5455 (Forecasting Loss:0.2453 + XiCon Loss:3.0016 x Lambda(0.1)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2582
Validation loss decreased (0.316441 --> 0.314342).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5402997
	speed: 0.0512s/iter; left time: 569.0064s
Epoch: 6 cost time: 6.0627827644348145
Epoch: 6, Steps: 118 Train Loss: 0.5418 (Forecasting Loss:0.2422 + XiCon Loss:2.9962 x Lambda(0.1)), Vali MSE Loss: 0.3099 Test MSE Loss: 0.2549
Validation loss decreased (0.314342 --> 0.309867).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5425079
	speed: 0.0524s/iter; left time: 576.3638s
Epoch: 7 cost time: 6.191336154937744
Epoch: 7, Steps: 118 Train Loss: 0.5402 (Forecasting Loss:0.2403 + XiCon Loss:2.9991 x Lambda(0.1)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5214374
	speed: 0.0501s/iter; left time: 545.0600s
Epoch: 8 cost time: 5.984426498413086
Epoch: 8, Steps: 118 Train Loss: 0.5385 (Forecasting Loss:0.2394 + XiCon Loss:2.9914 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.2575
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5250264
	speed: 0.0483s/iter; left time: 519.8176s
Epoch: 9 cost time: 5.843390226364136
Epoch: 9, Steps: 118 Train Loss: 0.5385 (Forecasting Loss:0.2389 + XiCon Loss:2.9954 x Lambda(0.1)), Vali MSE Loss: 0.3103 Test MSE Loss: 0.2565
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5332528
	speed: 0.0525s/iter; left time: 558.9174s
Epoch: 10 cost time: 6.174531936645508
Epoch: 10, Steps: 118 Train Loss: 0.5383 (Forecasting Loss:0.2390 + XiCon Loss:2.9934 x Lambda(0.1)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.2566
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5460035
	speed: 0.0508s/iter; left time: 534.2429s
Epoch: 11 cost time: 5.960246801376343
Epoch: 11, Steps: 118 Train Loss: 0.5383 (Forecasting Loss:0.2388 + XiCon Loss:2.9951 x Lambda(0.1)), Vali MSE Loss: 0.3098 Test MSE Loss: 0.2578
Validation loss decreased (0.309867 --> 0.309751).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5269225
	speed: 0.0530s/iter; left time: 551.3419s
Epoch: 12 cost time: 6.131946086883545
Epoch: 12, Steps: 118 Train Loss: 0.5376 (Forecasting Loss:0.2384 + XiCon Loss:2.9923 x Lambda(0.1)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2566
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5258738
	speed: 0.0459s/iter; left time: 471.9868s
Epoch: 13 cost time: 5.459811687469482
Epoch: 13, Steps: 118 Train Loss: 0.5380 (Forecasting Loss:0.2385 + XiCon Loss:2.9947 x Lambda(0.1)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.2565
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5343729
	speed: 0.0493s/iter; left time: 501.4766s
Epoch: 14 cost time: 5.825664281845093
Epoch: 14, Steps: 118 Train Loss: 0.5378 (Forecasting Loss:0.2384 + XiCon Loss:2.9937 x Lambda(0.1)), Vali MSE Loss: 0.3108 Test MSE Loss: 0.2567
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5409442
	speed: 0.0507s/iter; left time: 509.0440s
Epoch: 15 cost time: 6.0626397132873535
Epoch: 15, Steps: 118 Train Loss: 0.5375 (Forecasting Loss:0.2384 + XiCon Loss:2.9918 x Lambda(0.1)), Vali MSE Loss: 0.3104 Test MSE Loss: 0.2567
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5326729
	speed: 0.0548s/iter; left time: 543.7898s
Epoch: 16 cost time: 6.509439706802368
Epoch: 16, Steps: 118 Train Loss: 0.5380 (Forecasting Loss:0.2386 + XiCon Loss:2.9933 x Lambda(0.1)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.2567
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5590526
	speed: 0.0528s/iter; left time: 517.9622s
Epoch: 17 cost time: 6.2178955078125
Epoch: 17, Steps: 118 Train Loss: 0.5380 (Forecasting Loss:0.2386 + XiCon Loss:2.9942 x Lambda(0.1)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.2567
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5331478
	speed: 0.0476s/iter; left time: 461.4972s
Epoch: 18 cost time: 5.760225057601929
Epoch: 18, Steps: 118 Train Loss: 0.5375 (Forecasting Loss:0.2382 + XiCon Loss:2.9927 x Lambda(0.1)), Vali MSE Loss: 0.3109 Test MSE Loss: 0.2567
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5224419
	speed: 0.0533s/iter; left time: 510.0345s
Epoch: 19 cost time: 6.209770679473877
Epoch: 19, Steps: 118 Train Loss: 0.5373 (Forecasting Loss:0.2384 + XiCon Loss:2.9897 x Lambda(0.1)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2567
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5191630
	speed: 0.0533s/iter; left time: 504.4403s
Epoch: 20 cost time: 6.278467178344727
Epoch: 20, Steps: 118 Train Loss: 0.5381 (Forecasting Loss:0.2388 + XiCon Loss:2.9929 x Lambda(0.1)), Vali MSE Loss: 0.3109 Test MSE Loss: 0.2567
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5413077
	speed: 0.0553s/iter; left time: 516.7635s
Epoch: 21 cost time: 6.410356044769287
Epoch: 21, Steps: 118 Train Loss: 0.5390 (Forecasting Loss:0.2389 + XiCon Loss:3.0012 x Lambda(0.1)), Vali MSE Loss: 0.3102 Test MSE Loss: 0.2567
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17540550231933594, mae:0.340103417634964, mape:0.6436067223548889, mspe:19.88226890563965 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3835
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6992034
	speed: 0.0427s/iter; left time: 499.9650s
Epoch: 1 cost time: 4.972244024276733
Epoch: 1, Steps: 118 Train Loss: 0.7136 (Forecasting Loss:0.4059 + XiCon Loss:3.0768 x Lambda(0.1)), Vali MSE Loss: 0.4162 Test MSE Loss: 0.3026
Validation loss decreased (inf --> 0.416211).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5815985
	speed: 0.0404s/iter; left time: 467.9036s
Epoch: 2 cost time: 4.8896424770355225
Epoch: 2, Steps: 118 Train Loss: 0.6380 (Forecasting Loss:0.3392 + XiCon Loss:2.9883 x Lambda(0.1)), Vali MSE Loss: 0.3380 Test MSE Loss: 0.2872
Validation loss decreased (0.416211 --> 0.337965).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5874853
	speed: 0.0468s/iter; left time: 536.1639s
Epoch: 3 cost time: 5.516556262969971
Epoch: 3, Steps: 118 Train Loss: 0.5743 (Forecasting Loss:0.2739 + XiCon Loss:3.0040 x Lambda(0.1)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2877
Validation loss decreased (0.337965 --> 0.289399).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5457693
	speed: 0.0452s/iter; left time: 513.1247s
Epoch: 4 cost time: 5.314592599868774
Epoch: 4, Steps: 118 Train Loss: 0.5614 (Forecasting Loss:0.2586 + XiCon Loss:3.0287 x Lambda(0.1)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2668
Validation loss decreased (0.289399 --> 0.289007).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5510986
	speed: 0.0448s/iter; left time: 503.3654s
Epoch: 5 cost time: 5.243741989135742
Epoch: 5, Steps: 118 Train Loss: 0.5536 (Forecasting Loss:0.2513 + XiCon Loss:3.0234 x Lambda(0.1)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.2730
Validation loss decreased (0.289007 --> 0.269603).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5412624
	speed: 0.0463s/iter; left time: 513.9015s
Epoch: 6 cost time: 5.30370569229126
Epoch: 6, Steps: 118 Train Loss: 0.5486 (Forecasting Loss:0.2469 + XiCon Loss:3.0172 x Lambda(0.1)), Vali MSE Loss: 0.2720 Test MSE Loss: 0.2809
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5524530
	speed: 0.0430s/iter; left time: 472.2586s
Epoch: 7 cost time: 5.12004828453064
Epoch: 7, Steps: 118 Train Loss: 0.5481 (Forecasting Loss:0.2456 + XiCon Loss:3.0251 x Lambda(0.1)), Vali MSE Loss: 0.2751 Test MSE Loss: 0.2703
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5624486
	speed: 0.0488s/iter; left time: 530.8029s
Epoch: 8 cost time: 5.682023525238037
Epoch: 8, Steps: 118 Train Loss: 0.5473 (Forecasting Loss:0.2443 + XiCon Loss:3.0295 x Lambda(0.1)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2716
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5299816
	speed: 0.0464s/iter; left time: 499.3921s
Epoch: 9 cost time: 5.441662311553955
Epoch: 9, Steps: 118 Train Loss: 0.5462 (Forecasting Loss:0.2440 + XiCon Loss:3.0217 x Lambda(0.1)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.2749
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5540130
	speed: 0.0442s/iter; left time: 470.7492s
Epoch: 10 cost time: 5.177384614944458
Epoch: 10, Steps: 118 Train Loss: 0.5456 (Forecasting Loss:0.2435 + XiCon Loss:3.0216 x Lambda(0.1)), Vali MSE Loss: 0.2710 Test MSE Loss: 0.2722
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5412271
	speed: 0.0482s/iter; left time: 506.6279s
Epoch: 11 cost time: 5.650731801986694
Epoch: 11, Steps: 118 Train Loss: 0.5457 (Forecasting Loss:0.2435 + XiCon Loss:3.0220 x Lambda(0.1)), Vali MSE Loss: 0.2722 Test MSE Loss: 0.2736
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5462963
	speed: 0.0382s/iter; left time: 397.8626s
Epoch: 12 cost time: 4.59874701499939
Epoch: 12, Steps: 118 Train Loss: 0.5448 (Forecasting Loss:0.2433 + XiCon Loss:3.0155 x Lambda(0.1)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.2736
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5333899
	speed: 0.0463s/iter; left time: 475.7591s
Epoch: 13 cost time: 5.438246726989746
Epoch: 13, Steps: 118 Train Loss: 0.5449 (Forecasting Loss:0.2433 + XiCon Loss:3.0161 x Lambda(0.1)), Vali MSE Loss: 0.2714 Test MSE Loss: 0.2744
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5500839
	speed: 0.0451s/iter; left time: 458.9483s
Epoch: 14 cost time: 5.370703458786011
Epoch: 14, Steps: 118 Train Loss: 0.5459 (Forecasting Loss:0.2435 + XiCon Loss:3.0249 x Lambda(0.1)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.2735
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5368091
	speed: 0.0437s/iter; left time: 438.9266s
Epoch: 15 cost time: 5.14452600479126
Epoch: 15, Steps: 118 Train Loss: 0.5453 (Forecasting Loss:0.2434 + XiCon Loss:3.0192 x Lambda(0.1)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.2738
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.192664235830307, mae:0.3532699644565582, mape:0.6368399262428284, mspe:16.299476623535156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1835+-0.00839, MAE:0.3489+-0.00782, MAPE:0.7070+-0.09908, MSPE:21.4905+-5.05610, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4184
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8973010
	speed: 0.0557s/iter; left time: 590.5964s
Epoch: 1 cost time: 5.811668872833252
Epoch: 1, Steps: 107 Train Loss: 0.9462 (Forecasting Loss:0.6353 + XiCon Loss:3.1090 x Lambda(0.1)), Vali MSE Loss: 0.6090 Test MSE Loss: 0.4838
Validation loss decreased (inf --> 0.608994).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5711150
	speed: 0.0741s/iter; left time: 777.4988s
Epoch: 2 cost time: 8.177704334259033
Epoch: 2, Steps: 107 Train Loss: 0.6533 (Forecasting Loss:0.3550 + XiCon Loss:2.9828 x Lambda(0.1)), Vali MSE Loss: 0.3992 Test MSE Loss: 0.2734
Validation loss decreased (0.608994 --> 0.399206).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5506403
	speed: 0.0499s/iter; left time: 518.1826s
Epoch: 3 cost time: 5.3311357498168945
Epoch: 3, Steps: 107 Train Loss: 0.5520 (Forecasting Loss:0.2697 + XiCon Loss:2.8237 x Lambda(0.1)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.2597
Validation loss decreased (0.399206 --> 0.333634).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5480171
	speed: 0.0458s/iter; left time: 470.4309s
Epoch: 4 cost time: 5.164390563964844
Epoch: 4, Steps: 107 Train Loss: 0.5445 (Forecasting Loss:0.2591 + XiCon Loss:2.8543 x Lambda(0.1)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.2456
Validation loss decreased (0.333634 --> 0.332533).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5572315
	speed: 0.0782s/iter; left time: 795.3546s
Epoch: 5 cost time: 8.389894485473633
Epoch: 5, Steps: 107 Train Loss: 0.5402 (Forecasting Loss:0.2540 + XiCon Loss:2.8621 x Lambda(0.1)), Vali MSE Loss: 0.3341 Test MSE Loss: 0.2538
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5248288
	speed: 0.0791s/iter; left time: 796.1392s
Epoch: 6 cost time: 8.506360054016113
Epoch: 6, Steps: 107 Train Loss: 0.5375 (Forecasting Loss:0.2509 + XiCon Loss:2.8666 x Lambda(0.1)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2482
Validation loss decreased (0.332533 --> 0.329163).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5458374
	speed: 0.0825s/iter; left time: 821.4352s
Epoch: 7 cost time: 8.837508201599121
Epoch: 7, Steps: 107 Train Loss: 0.5357 (Forecasting Loss:0.2489 + XiCon Loss:2.8681 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2676
Validation loss decreased (0.329163 --> 0.325972).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5373713
	speed: 0.0644s/iter; left time: 634.1956s
Epoch: 8 cost time: 7.039676666259766
Epoch: 8, Steps: 107 Train Loss: 0.5350 (Forecasting Loss:0.2483 + XiCon Loss:2.8665 x Lambda(0.1)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.2617
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5338635
	speed: 0.0792s/iter; left time: 771.8795s
Epoch: 9 cost time: 8.511799573898315
Epoch: 9, Steps: 107 Train Loss: 0.5346 (Forecasting Loss:0.2481 + XiCon Loss:2.8647 x Lambda(0.1)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2649
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5318667
	speed: 0.0821s/iter; left time: 791.3028s
Epoch: 10 cost time: 8.8666410446167
Epoch: 10, Steps: 107 Train Loss: 0.5342 (Forecasting Loss:0.2476 + XiCon Loss:2.8656 x Lambda(0.1)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2597
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5381581
	speed: 0.0813s/iter; left time: 775.0067s
Epoch: 11 cost time: 8.704026937484741
Epoch: 11, Steps: 107 Train Loss: 0.5344 (Forecasting Loss:0.2477 + XiCon Loss:2.8671 x Lambda(0.1)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.2590
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5293928
	speed: 0.0611s/iter; left time: 576.1053s
Epoch: 12 cost time: 6.4454662799835205
Epoch: 12, Steps: 107 Train Loss: 0.5340 (Forecasting Loss:0.2473 + XiCon Loss:2.8663 x Lambda(0.1)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2604
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5313324
	speed: 0.0550s/iter; left time: 512.5274s
Epoch: 13 cost time: 6.09560489654541
Epoch: 13, Steps: 107 Train Loss: 0.5340 (Forecasting Loss:0.2475 + XiCon Loss:2.8650 x Lambda(0.1)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.2608
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5274125
	speed: 0.0800s/iter; left time: 737.2214s
Epoch: 14 cost time: 8.602641105651855
Epoch: 14, Steps: 107 Train Loss: 0.5340 (Forecasting Loss:0.2476 + XiCon Loss:2.8641 x Lambda(0.1)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.2607
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5520990
	speed: 0.0801s/iter; left time: 728.9092s
Epoch: 15 cost time: 8.66261887550354
Epoch: 15, Steps: 107 Train Loss: 0.5340 (Forecasting Loss:0.2476 + XiCon Loss:2.8645 x Lambda(0.1)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.2607
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5336549
	speed: 0.0774s/iter; left time: 696.0629s
Epoch: 16 cost time: 8.309882402420044
Epoch: 16, Steps: 107 Train Loss: 0.5342 (Forecasting Loss:0.2475 + XiCon Loss:2.8668 x Lambda(0.1)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.2604
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5320567
	speed: 0.0810s/iter; left time: 720.3166s
Epoch: 17 cost time: 8.685108184814453
Epoch: 17, Steps: 107 Train Loss: 0.5342 (Forecasting Loss:0.2477 + XiCon Loss:2.8646 x Lambda(0.1)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.2604
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.18481478095054626, mae:0.3503858149051666, mape:0.6054844260215759, mspe:13.57444953918457 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3599
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.9117997
	speed: 0.0619s/iter; left time: 656.2791s
Epoch: 1 cost time: 6.631648778915405
Epoch: 1, Steps: 107 Train Loss: 0.9282 (Forecasting Loss:0.6175 + XiCon Loss:3.1074 x Lambda(0.1)), Vali MSE Loss: 0.5524 Test MSE Loss: 0.4159
Validation loss decreased (inf --> 0.552413).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6221955
	speed: 0.0627s/iter; left time: 657.7034s
Epoch: 2 cost time: 6.777231931686401
Epoch: 2, Steps: 107 Train Loss: 0.7202 (Forecasting Loss:0.4192 + XiCon Loss:3.0106 x Lambda(0.1)), Vali MSE Loss: 0.3919 Test MSE Loss: 0.2773
Validation loss decreased (0.552413 --> 0.391926).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5914758
	speed: 0.0620s/iter; left time: 643.5754s
Epoch: 3 cost time: 6.6806254386901855
Epoch: 3, Steps: 107 Train Loss: 0.5932 (Forecasting Loss:0.2965 + XiCon Loss:2.9669 x Lambda(0.1)), Vali MSE Loss: 0.3490 Test MSE Loss: 0.2943
Validation loss decreased (0.391926 --> 0.349026).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5835811
	speed: 0.0365s/iter; left time: 375.0043s
Epoch: 4 cost time: 3.893317461013794
Epoch: 4, Steps: 107 Train Loss: 0.5710 (Forecasting Loss:0.2721 + XiCon Loss:2.9890 x Lambda(0.1)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.4038
Validation loss decreased (0.349026 --> 0.306566).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5505942
	speed: 0.0490s/iter; left time: 498.5359s
Epoch: 5 cost time: 5.445227384567261
Epoch: 5, Steps: 107 Train Loss: 0.5645 (Forecasting Loss:0.2656 + XiCon Loss:2.9898 x Lambda(0.1)), Vali MSE Loss: 0.3035 Test MSE Loss: 0.2996
Validation loss decreased (0.306566 --> 0.303544).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5667673
	speed: 0.0647s/iter; left time: 651.6051s
Epoch: 6 cost time: 6.950602054595947
Epoch: 6, Steps: 107 Train Loss: 0.5592 (Forecasting Loss:0.2601 + XiCon Loss:2.9919 x Lambda(0.1)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.3224
Validation loss decreased (0.303544 --> 0.300642).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5417304
	speed: 0.0632s/iter; left time: 629.4467s
Epoch: 7 cost time: 6.7607152462005615
Epoch: 7, Steps: 107 Train Loss: 0.5571 (Forecasting Loss:0.2578 + XiCon Loss:2.9928 x Lambda(0.1)), Vali MSE Loss: 0.3003 Test MSE Loss: 0.3155
Validation loss decreased (0.300642 --> 0.300298).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5581745
	speed: 0.0599s/iter; left time: 590.0275s
Epoch: 8 cost time: 6.459417104721069
Epoch: 8, Steps: 107 Train Loss: 0.5561 (Forecasting Loss:0.2569 + XiCon Loss:2.9926 x Lambda(0.1)), Vali MSE Loss: 0.3019 Test MSE Loss: 0.3053
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5675937
	speed: 0.0528s/iter; left time: 514.2407s
Epoch: 9 cost time: 5.534824848175049
Epoch: 9, Steps: 107 Train Loss: 0.5551 (Forecasting Loss:0.2559 + XiCon Loss:2.9917 x Lambda(0.1)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.3116
Validation loss decreased (0.300298 --> 0.298902).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5445235
	speed: 0.0293s/iter; left time: 282.7234s
Epoch: 10 cost time: 3.2551350593566895
Epoch: 10, Steps: 107 Train Loss: 0.5550 (Forecasting Loss:0.2555 + XiCon Loss:2.9953 x Lambda(0.1)), Vali MSE Loss: 0.2982 Test MSE Loss: 0.3146
Validation loss decreased (0.298902 --> 0.298159).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5432305
	speed: 0.0649s/iter; left time: 618.9260s
Epoch: 11 cost time: 6.9989213943481445
Epoch: 11, Steps: 107 Train Loss: 0.5554 (Forecasting Loss:0.2556 + XiCon Loss:2.9979 x Lambda(0.1)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.3114
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5546762
	speed: 0.0620s/iter; left time: 584.3767s
Epoch: 12 cost time: 6.6354875564575195
Epoch: 12, Steps: 107 Train Loss: 0.5548 (Forecasting Loss:0.2552 + XiCon Loss:2.9967 x Lambda(0.1)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.3118
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5496408
	speed: 0.0621s/iter; left time: 578.3556s
Epoch: 13 cost time: 6.696481704711914
Epoch: 13, Steps: 107 Train Loss: 0.5549 (Forecasting Loss:0.2552 + XiCon Loss:2.9975 x Lambda(0.1)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.3118
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5662613
	speed: 0.0620s/iter; left time: 570.6938s
Epoch: 14 cost time: 6.706607818603516
Epoch: 14, Steps: 107 Train Loss: 0.5545 (Forecasting Loss:0.2554 + XiCon Loss:2.9913 x Lambda(0.1)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.3120
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5548623
	speed: 0.0355s/iter; left time: 323.4798s
Epoch: 15 cost time: 3.780352830886841
Epoch: 15, Steps: 107 Train Loss: 0.5548 (Forecasting Loss:0.2553 + XiCon Loss:2.9953 x Lambda(0.1)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.3124
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5568525
	speed: 0.0416s/iter; left time: 374.5575s
Epoch: 16 cost time: 4.648273944854736
Epoch: 16, Steps: 107 Train Loss: 0.5547 (Forecasting Loss:0.2553 + XiCon Loss:2.9941 x Lambda(0.1)), Vali MSE Loss: 0.2986 Test MSE Loss: 0.3123
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5419026
	speed: 0.0629s/iter; left time: 559.1518s
Epoch: 17 cost time: 6.764524698257446
Epoch: 17, Steps: 107 Train Loss: 0.5547 (Forecasting Loss:0.2555 + XiCon Loss:2.9920 x Lambda(0.1)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.3123
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5509423
	speed: 0.0618s/iter; left time: 542.4333s
Epoch: 18 cost time: 6.660712957382202
Epoch: 18, Steps: 107 Train Loss: 0.5548 (Forecasting Loss:0.2553 + XiCon Loss:2.9945 x Lambda(0.1)), Vali MSE Loss: 0.2988 Test MSE Loss: 0.3123
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5637398
	speed: 0.0619s/iter; left time: 537.0099s
Epoch: 19 cost time: 6.679702281951904
Epoch: 19, Steps: 107 Train Loss: 0.5546 (Forecasting Loss:0.2555 + XiCon Loss:2.9910 x Lambda(0.1)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.3123
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5434548
	speed: 0.0552s/iter; left time: 472.7401s
Epoch: 20 cost time: 5.946133852005005
Epoch: 20, Steps: 107 Train Loss: 0.5548 (Forecasting Loss:0.2554 + XiCon Loss:2.9938 x Lambda(0.1)), Vali MSE Loss: 0.2986 Test MSE Loss: 0.3123
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.23479725420475006, mae:0.39433038234710693, mape:0.5849441289901733, mspe:10.935726165771484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1761
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8753688
	speed: 0.0348s/iter; left time: 368.4356s
Epoch: 1 cost time: 4.00892186164856
Epoch: 1, Steps: 107 Train Loss: 0.9352 (Forecasting Loss:0.6237 + XiCon Loss:3.1152 x Lambda(0.1)), Vali MSE Loss: 0.5513 Test MSE Loss: 0.4206
Validation loss decreased (inf --> 0.551318).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6463784
	speed: 0.0632s/iter; left time: 663.1189s
Epoch: 2 cost time: 6.78177809715271
Epoch: 2, Steps: 107 Train Loss: 0.7543 (Forecasting Loss:0.4507 + XiCon Loss:3.0355 x Lambda(0.1)), Vali MSE Loss: 0.4031 Test MSE Loss: 0.2785
Validation loss decreased (0.551318 --> 0.403123).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5852283
	speed: 0.0607s/iter; left time: 629.9965s
Epoch: 3 cost time: 6.554407835006714
Epoch: 3, Steps: 107 Train Loss: 0.5951 (Forecasting Loss:0.2964 + XiCon Loss:2.9865 x Lambda(0.1)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.3049
Validation loss decreased (0.403123 --> 0.340352).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5872746
	speed: 0.0619s/iter; left time: 636.6171s
Epoch: 4 cost time: 6.622990846633911
Epoch: 4, Steps: 107 Train Loss: 0.5747 (Forecasting Loss:0.2717 + XiCon Loss:3.0308 x Lambda(0.1)), Vali MSE Loss: 0.3531 Test MSE Loss: 0.2787
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5516987
	speed: 0.0604s/iter; left time: 614.9181s
Epoch: 5 cost time: 6.5044169425964355
Epoch: 5, Steps: 107 Train Loss: 0.5675 (Forecasting Loss:0.2650 + XiCon Loss:3.0246 x Lambda(0.1)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.3435
Validation loss decreased (0.340352 --> 0.328429).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5547912
	speed: 0.0299s/iter; left time: 300.9696s
Epoch: 6 cost time: 3.2293052673339844
Epoch: 6, Steps: 107 Train Loss: 0.5629 (Forecasting Loss:0.2601 + XiCon Loss:3.0275 x Lambda(0.1)), Vali MSE Loss: 0.3502 Test MSE Loss: 0.3365
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5621885
	speed: 0.0542s/iter; left time: 540.0639s
Epoch: 7 cost time: 5.8822877407073975
Epoch: 7, Steps: 107 Train Loss: 0.5608 (Forecasting Loss:0.2581 + XiCon Loss:3.0264 x Lambda(0.1)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.3357
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5563663
	speed: 0.0655s/iter; left time: 644.8678s
Epoch: 8 cost time: 7.0277135372161865
Epoch: 8, Steps: 107 Train Loss: 0.5600 (Forecasting Loss:0.2573 + XiCon Loss:3.0277 x Lambda(0.1)), Vali MSE Loss: 0.3486 Test MSE Loss: 0.3405
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5611406
	speed: 0.0623s/iter; left time: 607.3733s
Epoch: 9 cost time: 6.7999653816223145
Epoch: 9, Steps: 107 Train Loss: 0.5590 (Forecasting Loss:0.2568 + XiCon Loss:3.0220 x Lambda(0.1)), Vali MSE Loss: 0.3569 Test MSE Loss: 0.3344
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5493524
	speed: 0.0639s/iter; left time: 616.0180s
Epoch: 10 cost time: 6.881907939910889
Epoch: 10, Steps: 107 Train Loss: 0.5591 (Forecasting Loss:0.2565 + XiCon Loss:3.0265 x Lambda(0.1)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.3317
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5494769
	speed: 0.0563s/iter; left time: 536.9242s
Epoch: 11 cost time: 6.134159326553345
Epoch: 11, Steps: 107 Train Loss: 0.5592 (Forecasting Loss:0.2561 + XiCon Loss:3.0306 x Lambda(0.1)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.3333
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5624186
	speed: 0.0645s/iter; left time: 607.7709s
Epoch: 12 cost time: 6.955049991607666
Epoch: 12, Steps: 107 Train Loss: 0.5590 (Forecasting Loss:0.2563 + XiCon Loss:3.0274 x Lambda(0.1)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.3342
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5522650
	speed: 0.0651s/iter; left time: 606.8661s
Epoch: 13 cost time: 6.95976185798645
Epoch: 13, Steps: 107 Train Loss: 0.5588 (Forecasting Loss:0.2560 + XiCon Loss:3.0281 x Lambda(0.1)), Vali MSE Loss: 0.3557 Test MSE Loss: 0.3334
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5611283
	speed: 0.0644s/iter; left time: 592.9439s
Epoch: 14 cost time: 6.939051389694214
Epoch: 14, Steps: 107 Train Loss: 0.5592 (Forecasting Loss:0.2565 + XiCon Loss:3.0270 x Lambda(0.1)), Vali MSE Loss: 0.3552 Test MSE Loss: 0.3344
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5548276
	speed: 0.0543s/iter; left time: 493.9261s
Epoch: 15 cost time: 5.7460174560546875
Epoch: 15, Steps: 107 Train Loss: 0.5585 (Forecasting Loss:0.2563 + XiCon Loss:3.0213 x Lambda(0.1)), Vali MSE Loss: 0.3550 Test MSE Loss: 0.3344
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.2653103470802307, mae:0.4217599928379059, mape:0.5923672318458557, mspe:9.394002914428711 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3582
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.9076504
	speed: 0.0621s/iter; left time: 658.1953s
Epoch: 1 cost time: 6.622316837310791
Epoch: 1, Steps: 107 Train Loss: 0.9349 (Forecasting Loss:0.6232 + XiCon Loss:3.1171 x Lambda(0.1)), Vali MSE Loss: 0.5805 Test MSE Loss: 0.4518
Validation loss decreased (inf --> 0.580512).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5946423
	speed: 0.0719s/iter; left time: 754.8918s
Epoch: 2 cost time: 7.78447961807251
Epoch: 2, Steps: 107 Train Loss: 0.6746 (Forecasting Loss:0.3781 + XiCon Loss:2.9647 x Lambda(0.1)), Vali MSE Loss: 0.3587 Test MSE Loss: 0.2489
Validation loss decreased (0.580512 --> 0.358684).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5600450
	speed: 0.0805s/iter; left time: 835.8905s
Epoch: 3 cost time: 8.671911239624023
Epoch: 3, Steps: 107 Train Loss: 0.5611 (Forecasting Loss:0.2701 + XiCon Loss:2.9103 x Lambda(0.1)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.2480
Validation loss decreased (0.358684 --> 0.352871).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5576259
	speed: 0.0726s/iter; left time: 746.5642s
Epoch: 4 cost time: 7.90657901763916
Epoch: 4, Steps: 107 Train Loss: 0.5485 (Forecasting Loss:0.2578 + XiCon Loss:2.9071 x Lambda(0.1)), Vali MSE Loss: 0.3428 Test MSE Loss: 0.2504
Validation loss decreased (0.352871 --> 0.342824).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5408658
	speed: 0.0805s/iter; left time: 819.2118s
Epoch: 5 cost time: 8.708173990249634
Epoch: 5, Steps: 107 Train Loss: 0.5445 (Forecasting Loss:0.2530 + XiCon Loss:2.9154 x Lambda(0.1)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2672
Validation loss decreased (0.342824 --> 0.323337).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5437160
	speed: 0.0835s/iter; left time: 840.4848s
Epoch: 6 cost time: 9.000012159347534
Epoch: 6, Steps: 107 Train Loss: 0.5430 (Forecasting Loss:0.2506 + XiCon Loss:2.9247 x Lambda(0.1)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2593
Validation loss decreased (0.323337 --> 0.321680).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5416529
	speed: 0.0820s/iter; left time: 816.7378s
Epoch: 7 cost time: 8.707438468933105
Epoch: 7, Steps: 107 Train Loss: 0.5427 (Forecasting Loss:0.2495 + XiCon Loss:2.9328 x Lambda(0.1)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.2612
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5462173
	speed: 0.0547s/iter; left time: 538.8899s
Epoch: 8 cost time: 5.795308351516724
Epoch: 8, Steps: 107 Train Loss: 0.5422 (Forecasting Loss:0.2488 + XiCon Loss:2.9343 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2610
Validation loss decreased (0.321680 --> 0.318208).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5265862
	speed: 0.0657s/iter; left time: 640.1655s
Epoch: 9 cost time: 7.195479154586792
Epoch: 9, Steps: 107 Train Loss: 0.5423 (Forecasting Loss:0.2486 + XiCon Loss:2.9367 x Lambda(0.1)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2574
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5282309
	speed: 0.0790s/iter; left time: 761.2093s
Epoch: 10 cost time: 8.522244215011597
Epoch: 10, Steps: 107 Train Loss: 0.5424 (Forecasting Loss:0.2485 + XiCon Loss:2.9383 x Lambda(0.1)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2602
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5414985
	speed: 0.0795s/iter; left time: 757.7730s
Epoch: 11 cost time: 8.527680158615112
Epoch: 11, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2480 + XiCon Loss:2.9324 x Lambda(0.1)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2619
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5408005
	speed: 0.0784s/iter; left time: 739.2330s
Epoch: 12 cost time: 8.492523908615112
Epoch: 12, Steps: 107 Train Loss: 0.5422 (Forecasting Loss:0.2485 + XiCon Loss:2.9371 x Lambda(0.1)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2595
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5596207
	speed: 0.0783s/iter; left time: 729.6901s
Epoch: 13 cost time: 8.401098012924194
Epoch: 13, Steps: 107 Train Loss: 0.5426 (Forecasting Loss:0.2484 + XiCon Loss:2.9417 x Lambda(0.1)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2597
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5486457
	speed: 0.0821s/iter; left time: 756.3007s
Epoch: 14 cost time: 8.83743166923523
Epoch: 14, Steps: 107 Train Loss: 0.5423 (Forecasting Loss:0.2484 + XiCon Loss:2.9387 x Lambda(0.1)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2599
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5421828
	speed: 0.0812s/iter; left time: 739.0491s
Epoch: 15 cost time: 8.687714099884033
Epoch: 15, Steps: 107 Train Loss: 0.5421 (Forecasting Loss:0.2485 + XiCon Loss:2.9361 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2600
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5399407
	speed: 0.0747s/iter; left time: 672.3979s
Epoch: 16 cost time: 8.083977460861206
Epoch: 16, Steps: 107 Train Loss: 0.5426 (Forecasting Loss:0.2485 + XiCon Loss:2.9410 x Lambda(0.1)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2599
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5424929
	speed: 0.0827s/iter; left time: 734.8120s
Epoch: 17 cost time: 8.849050045013428
Epoch: 17, Steps: 107 Train Loss: 0.5424 (Forecasting Loss:0.2485 + XiCon Loss:2.9392 x Lambda(0.1)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2599
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5400527
	speed: 0.0782s/iter; left time: 686.3242s
Epoch: 18 cost time: 8.430183410644531
Epoch: 18, Steps: 107 Train Loss: 0.5416 (Forecasting Loss:0.2483 + XiCon Loss:2.9326 x Lambda(0.1)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2599
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17773817479610443, mae:0.34425002336502075, mape:0.5981142520904541, mspe:14.283047676086426 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4283
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8706959
	speed: 0.0604s/iter; left time: 640.2947s
Epoch: 1 cost time: 6.532791376113892
Epoch: 1, Steps: 107 Train Loss: 0.9306 (Forecasting Loss:0.6203 + XiCon Loss:3.1033 x Lambda(0.1)), Vali MSE Loss: 0.5335 Test MSE Loss: 0.3976
Validation loss decreased (inf --> 0.533542).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6487309
	speed: 0.0529s/iter; left time: 554.8788s
Epoch: 2 cost time: 5.543617248535156
Epoch: 2, Steps: 107 Train Loss: 0.6818 (Forecasting Loss:0.3830 + XiCon Loss:2.9879 x Lambda(0.1)), Vali MSE Loss: 0.3521 Test MSE Loss: 0.2690
Validation loss decreased (0.533542 --> 0.352063).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5753400
	speed: 0.0297s/iter; left time: 307.9799s
Epoch: 3 cost time: 3.192582368850708
Epoch: 3, Steps: 107 Train Loss: 0.5862 (Forecasting Loss:0.2905 + XiCon Loss:2.9573 x Lambda(0.1)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2860
Validation loss decreased (0.352063 --> 0.328948).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5446465
	speed: 0.0645s/iter; left time: 663.4330s
Epoch: 4 cost time: 6.933834791183472
Epoch: 4, Steps: 107 Train Loss: 0.5669 (Forecasting Loss:0.2696 + XiCon Loss:2.9738 x Lambda(0.1)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.3135
Validation loss decreased (0.328948 --> 0.322980).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5500902
	speed: 0.0627s/iter; left time: 637.8039s
Epoch: 5 cost time: 6.751677989959717
Epoch: 5, Steps: 107 Train Loss: 0.5604 (Forecasting Loss:0.2622 + XiCon Loss:2.9817 x Lambda(0.1)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.2819
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5456291
	speed: 0.0633s/iter; left time: 637.0934s
Epoch: 6 cost time: 6.813468933105469
Epoch: 6, Steps: 107 Train Loss: 0.5577 (Forecasting Loss:0.2591 + XiCon Loss:2.9857 x Lambda(0.1)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2868
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5595607
	speed: 0.0596s/iter; left time: 593.5414s
Epoch: 7 cost time: 6.398767709732056
Epoch: 7, Steps: 107 Train Loss: 0.5561 (Forecasting Loss:0.2574 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2844
Validation loss decreased (0.322980 --> 0.320011).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5533853
	speed: 0.0621s/iter; left time: 611.6643s
Epoch: 8 cost time: 6.706451892852783
Epoch: 8, Steps: 107 Train Loss: 0.5557 (Forecasting Loss:0.2568 + XiCon Loss:2.9886 x Lambda(0.1)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2827
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5499464
	speed: 0.0638s/iter; left time: 622.1794s
Epoch: 9 cost time: 6.86450457572937
Epoch: 9, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2561 + XiCon Loss:2.9814 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2876
Validation loss decreased (0.320011 --> 0.319928).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5563157
	speed: 0.0647s/iter; left time: 623.6096s
Epoch: 10 cost time: 6.927868843078613
Epoch: 10, Steps: 107 Train Loss: 0.5546 (Forecasting Loss:0.2558 + XiCon Loss:2.9875 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2797
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5641369
	speed: 0.0646s/iter; left time: 616.1340s
Epoch: 11 cost time: 6.956223011016846
Epoch: 11, Steps: 107 Train Loss: 0.5549 (Forecasting Loss:0.2558 + XiCon Loss:2.9910 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2875
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5747812
	speed: 0.0578s/iter; left time: 544.5065s
Epoch: 12 cost time: 6.263641357421875
Epoch: 12, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2557 + XiCon Loss:2.9865 x Lambda(0.1)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2858
Validation loss decreased (0.319928 --> 0.319290).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5339680
	speed: 0.0635s/iter; left time: 592.0871s
Epoch: 13 cost time: 6.853224277496338
Epoch: 13, Steps: 107 Train Loss: 0.5544 (Forecasting Loss:0.2555 + XiCon Loss:2.9885 x Lambda(0.1)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2848
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5409993
	speed: 0.0637s/iter; left time: 586.2317s
Epoch: 14 cost time: 6.831798791885376
Epoch: 14, Steps: 107 Train Loss: 0.5541 (Forecasting Loss:0.2556 + XiCon Loss:2.9843 x Lambda(0.1)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2840
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5466697
	speed: 0.0642s/iter; left time: 584.4387s
Epoch: 15 cost time: 6.919024467468262
Epoch: 15, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2557 + XiCon Loss:2.9856 x Lambda(0.1)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2844
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5738649
	speed: 0.0575s/iter; left time: 517.2493s
Epoch: 16 cost time: 6.22409725189209
Epoch: 16, Steps: 107 Train Loss: 0.5544 (Forecasting Loss:0.2557 + XiCon Loss:2.9864 x Lambda(0.1)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2846
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5608424
	speed: 0.0626s/iter; left time: 556.6200s
Epoch: 17 cost time: 6.695883750915527
Epoch: 17, Steps: 107 Train Loss: 0.5545 (Forecasting Loss:0.2558 + XiCon Loss:2.9868 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2846
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5602932
	speed: 0.0644s/iter; left time: 565.4109s
Epoch: 18 cost time: 6.9361045360565186
Epoch: 18, Steps: 107 Train Loss: 0.5537 (Forecasting Loss:0.2552 + XiCon Loss:2.9841 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5513476
	speed: 0.0645s/iter; left time: 559.7519s
Epoch: 19 cost time: 6.918125152587891
Epoch: 19, Steps: 107 Train Loss: 0.5544 (Forecasting Loss:0.2556 + XiCon Loss:2.9879 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5566329
	speed: 0.0601s/iter; left time: 515.2200s
Epoch: 20 cost time: 6.444103002548218
Epoch: 20, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2558 + XiCon Loss:2.9840 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2846
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5477109
	speed: 0.0624s/iter; left time: 527.6015s
Epoch: 21 cost time: 6.712527513504028
Epoch: 21, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2558 + XiCon Loss:2.9857 x Lambda(0.1)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2846
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5450633
	speed: 0.0640s/iter; left time: 534.9116s
Epoch: 22 cost time: 6.9092512130737305
Epoch: 22, Steps: 107 Train Loss: 0.5545 (Forecasting Loss:0.2556 + XiCon Loss:2.9891 x Lambda(0.1)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2846
Validation loss decreased (0.319290 --> 0.319257).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.5695185
	speed: 0.0634s/iter; left time: 522.9239s
Epoch: 23 cost time: 6.831684589385986
Epoch: 23, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2557 + XiCon Loss:2.9847 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.5488434
	speed: 0.0607s/iter; left time: 493.7801s
Epoch: 24 cost time: 6.581813812255859
Epoch: 24, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2555 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2846
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5585651
	speed: 0.0562s/iter; left time: 451.5515s
Epoch: 25 cost time: 6.112810134887695
Epoch: 25, Steps: 107 Train Loss: 0.5539 (Forecasting Loss:0.2554 + XiCon Loss:2.9849 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.5634604
	speed: 0.0628s/iter; left time: 497.7382s
Epoch: 26 cost time: 6.817940950393677
Epoch: 26, Steps: 107 Train Loss: 0.5544 (Forecasting Loss:0.2557 + XiCon Loss:2.9868 x Lambda(0.1)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2846
Validation loss decreased (0.319257 --> 0.319247).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.5496615
	speed: 0.0649s/iter; left time: 507.2115s
Epoch: 27 cost time: 6.98175311088562
Epoch: 27, Steps: 107 Train Loss: 0.5545 (Forecasting Loss:0.2558 + XiCon Loss:2.9865 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2846
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.5635696
	speed: 0.0613s/iter; left time: 472.8970s
Epoch: 28 cost time: 6.594505071640015
Epoch: 28, Steps: 107 Train Loss: 0.5535 (Forecasting Loss:0.2553 + XiCon Loss:2.9822 x Lambda(0.1)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2846
Validation loss decreased (0.319247 --> 0.318969).  Saving model ...
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.5561149
	speed: 0.0554s/iter; left time: 421.0173s
Epoch: 29 cost time: 5.961214542388916
Epoch: 29, Steps: 107 Train Loss: 0.5540 (Forecasting Loss:0.2553 + XiCon Loss:2.9866 x Lambda(0.1)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2846
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.5560907
	speed: 0.0630s/iter; left time: 472.2230s
Epoch: 30 cost time: 6.778882741928101
Epoch: 30, Steps: 107 Train Loss: 0.5546 (Forecasting Loss:0.2553 + XiCon Loss:2.9929 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.5377401
	speed: 0.0667s/iter; left time: 493.2429s
Epoch: 31 cost time: 7.166415214538574
Epoch: 31, Steps: 107 Train Loss: 0.5547 (Forecasting Loss:0.2555 + XiCon Loss:2.9920 x Lambda(0.1)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2846
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.5484450
	speed: 0.0640s/iter; left time: 466.5148s
Epoch: 32 cost time: 6.839967489242554
Epoch: 32, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2555 + XiCon Loss:2.9865 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2846
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 0.5593216
	speed: 0.0601s/iter; left time: 431.1432s
Epoch: 33 cost time: 6.430870771408081
Epoch: 33, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2556 + XiCon Loss:2.9866 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2846
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 0.5527164
	speed: 0.0617s/iter; left time: 436.4720s
Epoch: 34 cost time: 6.649823904037476
Epoch: 34, Steps: 107 Train Loss: 0.5546 (Forecasting Loss:0.2557 + XiCon Loss:2.9892 x Lambda(0.1)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2846
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 0.5497747
	speed: 0.0618s/iter; left time: 430.1999s
Epoch: 35 cost time: 6.664489984512329
Epoch: 35, Steps: 107 Train Loss: 0.5543 (Forecasting Loss:0.2556 + XiCon Loss:2.9874 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2846
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 0.5478760
	speed: 0.0651s/iter; left time: 446.2198s
Epoch: 36 cost time: 6.984323024749756
Epoch: 36, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2555 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2846
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 0.5565646
	speed: 0.0649s/iter; left time: 438.1081s
Epoch: 37 cost time: 6.9097700119018555
Epoch: 37, Steps: 107 Train Loss: 0.5542 (Forecasting Loss:0.2554 + XiCon Loss:2.9883 x Lambda(0.1)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2846
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 0.5616081
	speed: 0.0560s/iter; left time: 372.2495s
Epoch: 38 cost time: 6.139370441436768
Epoch: 38, Steps: 107 Train Loss: 0.5541 (Forecasting Loss:0.2556 + XiCon Loss:2.9856 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2846
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.20278625190258026, mae:0.3664036989212036, mape:0.5687357783317566, mspe:11.98896312713623 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2131+-0.04543, MAE:0.3754+-0.04016, MAPE:0.5899+-0.01744, MSPE:12.0352+-2.45280, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.668755531311035
Epoch: 1, Steps: 96 Train Loss: 1.2911 (Forecasting Loss:0.9746 + XiCon Loss:3.1648 x Lambda(0.1)), Vali MSE Loss: 0.6605 Test MSE Loss: 0.9192
Validation loss decreased (inf --> 0.660478).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.5292932987213135
Epoch: 2, Steps: 96 Train Loss: 1.0621 (Forecasting Loss:0.7476 + XiCon Loss:3.1448 x Lambda(0.1)), Vali MSE Loss: 0.6158 Test MSE Loss: 0.2713
Validation loss decreased (0.660478 --> 0.615771).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.031259298324585
Epoch: 3, Steps: 96 Train Loss: 0.8716 (Forecasting Loss:0.5570 + XiCon Loss:3.1460 x Lambda(0.1)), Vali MSE Loss: 0.5599 Test MSE Loss: 0.2551
Validation loss decreased (0.615771 --> 0.559884).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.087308168411255
Epoch: 4, Steps: 96 Train Loss: 0.8356 (Forecasting Loss:0.5220 + XiCon Loss:3.1365 x Lambda(0.1)), Vali MSE Loss: 0.5160 Test MSE Loss: 0.2578
Validation loss decreased (0.559884 --> 0.515991).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.47812557220459
Epoch: 5, Steps: 96 Train Loss: 0.8204 (Forecasting Loss:0.5071 + XiCon Loss:3.1328 x Lambda(0.1)), Vali MSE Loss: 0.5022 Test MSE Loss: 0.2570
Validation loss decreased (0.515991 --> 0.502207).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.510529041290283
Epoch: 6, Steps: 96 Train Loss: 0.8131 (Forecasting Loss:0.4999 + XiCon Loss:3.1315 x Lambda(0.1)), Vali MSE Loss: 0.4908 Test MSE Loss: 0.2638
Validation loss decreased (0.502207 --> 0.490849).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.292745113372803
Epoch: 7, Steps: 96 Train Loss: 0.8096 (Forecasting Loss:0.4967 + XiCon Loss:3.1289 x Lambda(0.1)), Vali MSE Loss: 0.4952 Test MSE Loss: 0.2591
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.488685131072998
Epoch: 8, Steps: 96 Train Loss: 0.8069 (Forecasting Loss:0.4941 + XiCon Loss:3.1281 x Lambda(0.1)), Vali MSE Loss: 0.4900 Test MSE Loss: 0.2615
Validation loss decreased (0.490849 --> 0.489999).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.7332375049591064
Epoch: 9, Steps: 96 Train Loss: 0.8060 (Forecasting Loss:0.4933 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2611
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.433638572692871
Epoch: 10, Steps: 96 Train Loss: 0.8061 (Forecasting Loss:0.4934 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.4905 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.332263469696045
Epoch: 11, Steps: 96 Train Loss: 0.8061 (Forecasting Loss:0.4933 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2611
Validation loss decreased (0.489999 --> 0.489802).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.495775461196899
Epoch: 12, Steps: 96 Train Loss: 0.8056 (Forecasting Loss:0.4928 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
Validation loss decreased (0.489802 --> 0.489572).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.604169607162476
Epoch: 13, Steps: 96 Train Loss: 0.8051 (Forecasting Loss:0.4923 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.8409669399261475
Epoch: 14, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4922 + XiCon Loss:3.1282 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
Validation loss decreased (0.489572 --> 0.489331).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.603570938110352
Epoch: 15, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4922 + XiCon Loss:3.1285 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2613
Validation loss decreased (0.489331 --> 0.489164).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.4715142250061035
Epoch: 16, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4919 + XiCon Loss:3.1279 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 5.340367555618286
Epoch: 17, Steps: 96 Train Loss: 0.8055 (Forecasting Loss:0.4927 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4891 Test MSE Loss: 0.2613
Validation loss decreased (0.489164 --> 0.489131).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 5.208643913269043
Epoch: 18, Steps: 96 Train Loss: 0.8044 (Forecasting Loss:0.4915 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 5.056191444396973
Epoch: 19, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4923 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 5.280136823654175
Epoch: 20, Steps: 96 Train Loss: 0.8045 (Forecasting Loss:0.4918 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2613
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 5.433504819869995
Epoch: 21, Steps: 96 Train Loss: 0.8046 (Forecasting Loss:0.4919 + XiCon Loss:3.1274 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 5.454460144042969
Epoch: 22, Steps: 96 Train Loss: 0.8057 (Forecasting Loss:0.4929 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.4890 Test MSE Loss: 0.2613
Validation loss decreased (0.489131 --> 0.489049).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 5.595226049423218
Epoch: 23, Steps: 96 Train Loss: 0.8054 (Forecasting Loss:0.4925 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 5.245094537734985
Epoch: 24, Steps: 96 Train Loss: 0.8058 (Forecasting Loss:0.4930 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2613
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.863072156906128
Epoch: 25, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4918 + XiCon Loss:3.1288 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 5.425606966018677
Epoch: 26, Steps: 96 Train Loss: 0.8044 (Forecasting Loss:0.4917 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 5.446252346038818
Epoch: 27, Steps: 96 Train Loss: 0.8040 (Forecasting Loss:0.4913 + XiCon Loss:3.1272 x Lambda(0.1)), Vali MSE Loss: 0.4899 Test MSE Loss: 0.2613
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 5.120418071746826
Epoch: 28, Steps: 96 Train Loss: 0.8060 (Forecasting Loss:0.4932 + XiCon Loss:3.1279 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 5.2894158363342285
Epoch: 29, Steps: 96 Train Loss: 0.8049 (Forecasting Loss:0.4922 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.736102819442749
Epoch: 30, Steps: 96 Train Loss: 0.8042 (Forecasting Loss:0.4913 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 5.03179669380188
Epoch: 31, Steps: 96 Train Loss: 0.8053 (Forecasting Loss:0.4926 + XiCon Loss:3.1270 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 5.290082693099976
Epoch: 32, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4918 + XiCon Loss:3.1282 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2613
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.18323467671871185, mae:0.33935263752937317, mape:0.675697386264801, mspe:20.967266082763672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3917
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.422348976135254
Epoch: 1, Steps: 96 Train Loss: 1.2878 (Forecasting Loss:0.9712 + XiCon Loss:3.1662 x Lambda(0.1)), Vali MSE Loss: 0.6861 Test MSE Loss: 0.9596
Validation loss decreased (inf --> 0.686091).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.733026504516602
Epoch: 2, Steps: 96 Train Loss: 1.1148 (Forecasting Loss:0.8000 + XiCon Loss:3.1475 x Lambda(0.1)), Vali MSE Loss: 0.5789 Test MSE Loss: 0.4637
Validation loss decreased (0.686091 --> 0.578919).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.719348192214966
Epoch: 3, Steps: 96 Train Loss: 0.9097 (Forecasting Loss:0.5969 + XiCon Loss:3.1281 x Lambda(0.1)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3099
Validation loss decreased (0.578919 --> 0.485453).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.065803289413452
Epoch: 4, Steps: 96 Train Loss: 0.8166 (Forecasting Loss:0.5049 + XiCon Loss:3.1167 x Lambda(0.1)), Vali MSE Loss: 0.4862 Test MSE Loss: 0.3179
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.520485877990723
Epoch: 5, Steps: 96 Train Loss: 0.7946 (Forecasting Loss:0.4838 + XiCon Loss:3.1084 x Lambda(0.1)), Vali MSE Loss: 0.4882 Test MSE Loss: 0.3244
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.327563047409058
Epoch: 6, Steps: 96 Train Loss: 0.7862 (Forecasting Loss:0.4755 + XiCon Loss:3.1073 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3368
Validation loss decreased (0.485453 --> 0.481730).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.503308534622192
Epoch: 7, Steps: 96 Train Loss: 0.7836 (Forecasting Loss:0.4734 + XiCon Loss:3.1021 x Lambda(0.1)), Vali MSE Loss: 0.4830 Test MSE Loss: 0.3317
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.306577682495117
Epoch: 8, Steps: 96 Train Loss: 0.7804 (Forecasting Loss:0.4702 + XiCon Loss:3.1022 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3361
Validation loss decreased (0.481730 --> 0.480812).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.96928071975708
Epoch: 9, Steps: 96 Train Loss: 0.7788 (Forecasting Loss:0.4685 + XiCon Loss:3.1026 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3398
Validation loss decreased (0.480812 --> 0.480779).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.4387195110321045
Epoch: 10, Steps: 96 Train Loss: 0.7791 (Forecasting Loss:0.4688 + XiCon Loss:3.1023 x Lambda(0.1)), Vali MSE Loss: 0.4809 Test MSE Loss: 0.3330
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.264134883880615
Epoch: 11, Steps: 96 Train Loss: 0.7764 (Forecasting Loss:0.4661 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3348
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.655021667480469
Epoch: 12, Steps: 96 Train Loss: 0.7797 (Forecasting Loss:0.4693 + XiCon Loss:3.1037 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3352
Validation loss decreased (0.480779 --> 0.480525).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.610295295715332
Epoch: 13, Steps: 96 Train Loss: 0.7788 (Forecasting Loss:0.4686 + XiCon Loss:3.1018 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3356
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.934758186340332
Epoch: 14, Steps: 96 Train Loss: 0.7776 (Forecasting Loss:0.4674 + XiCon Loss:3.1017 x Lambda(0.1)), Vali MSE Loss: 0.4820 Test MSE Loss: 0.3356
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.2988317012786865
Epoch: 15, Steps: 96 Train Loss: 0.7785 (Forecasting Loss:0.4681 + XiCon Loss:3.1043 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.330123662948608
Epoch: 16, Steps: 96 Train Loss: 0.7780 (Forecasting Loss:0.4677 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 5.3254265785217285
Epoch: 17, Steps: 96 Train Loss: 0.7791 (Forecasting Loss:0.4687 + XiCon Loss:3.1035 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 5.570701360702515
Epoch: 18, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4685 + XiCon Loss:3.1020 x Lambda(0.1)), Vali MSE Loss: 0.4814 Test MSE Loss: 0.3358
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.754095554351807
Epoch: 19, Steps: 96 Train Loss: 0.7805 (Forecasting Loss:0.4701 + XiCon Loss:3.1042 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3358
Validation loss decreased (0.480525 --> 0.480449).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 5.469879865646362
Epoch: 20, Steps: 96 Train Loss: 0.7784 (Forecasting Loss:0.4679 + XiCon Loss:3.1053 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 5.4093263149261475
Epoch: 21, Steps: 96 Train Loss: 0.7772 (Forecasting Loss:0.4669 + XiCon Loss:3.1032 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 5.404573440551758
Epoch: 22, Steps: 96 Train Loss: 0.7802 (Forecasting Loss:0.4698 + XiCon Loss:3.1038 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 5.354230642318726
Epoch: 23, Steps: 96 Train Loss: 0.7777 (Forecasting Loss:0.4676 + XiCon Loss:3.1011 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.964959383010864
Epoch: 24, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4684 + XiCon Loss:3.1029 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3358
Validation loss decreased (0.480449 --> 0.479543).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 5.02821683883667
Epoch: 25, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4686 + XiCon Loss:3.1017 x Lambda(0.1)), Vali MSE Loss: 0.4798 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 5.414241790771484
Epoch: 26, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4683 + XiCon Loss:3.1037 x Lambda(0.1)), Vali MSE Loss: 0.4810 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 5.5126307010650635
Epoch: 27, Steps: 96 Train Loss: 0.7797 (Forecasting Loss:0.4694 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 5.457897424697876
Epoch: 28, Steps: 96 Train Loss: 0.7798 (Forecasting Loss:0.4695 + XiCon Loss:3.1030 x Lambda(0.1)), Vali MSE Loss: 0.4801 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 5.517249345779419
Epoch: 29, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4682 + XiCon Loss:3.1045 x Lambda(0.1)), Vali MSE Loss: 0.4815 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.413628101348877
Epoch: 30, Steps: 96 Train Loss: 0.7779 (Forecasting Loss:0.4676 + XiCon Loss:3.1035 x Lambda(0.1)), Vali MSE Loss: 0.4793 Test MSE Loss: 0.3358
Validation loss decreased (0.479543 --> 0.479277).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 3.306640386581421
Epoch: 31, Steps: 96 Train Loss: 0.7796 (Forecasting Loss:0.4693 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4796 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 7.732754230499268
Epoch: 32, Steps: 96 Train Loss: 0.7766 (Forecasting Loss:0.4664 + XiCon Loss:3.1024 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 2.771286725997925
Epoch: 33, Steps: 96 Train Loss: 0.7774 (Forecasting Loss:0.4670 + XiCon Loss:3.1047 x Lambda(0.1)), Vali MSE Loss: 0.4828 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 2.5790891647338867
Epoch: 34, Steps: 96 Train Loss: 0.7772 (Forecasting Loss:0.4668 + XiCon Loss:3.1040 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 3.928816795349121
Epoch: 35, Steps: 96 Train Loss: 0.7786 (Forecasting Loss:0.4684 + XiCon Loss:3.1022 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 5.17790150642395
Epoch: 36, Steps: 96 Train Loss: 0.7790 (Forecasting Loss:0.4687 + XiCon Loss:3.1026 x Lambda(0.1)), Vali MSE Loss: 0.4812 Test MSE Loss: 0.3358
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 5.165227651596069
Epoch: 37, Steps: 96 Train Loss: 0.7782 (Forecasting Loss:0.4679 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 5.3752546310424805
Epoch: 38, Steps: 96 Train Loss: 0.7784 (Forecasting Loss:0.4681 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 5.1784443855285645
Epoch: 39, Steps: 96 Train Loss: 0.7785 (Forecasting Loss:0.4682 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 4.764066457748413
Epoch: 40, Steps: 96 Train Loss: 0.7782 (Forecasting Loss:0.4679 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4829 Test MSE Loss: 0.3358
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2674214243888855, mae:0.40422162413597107, mape:0.7771961688995361, mspe:28.227584838867188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3798
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.4870264530181885
Epoch: 1, Steps: 96 Train Loss: 1.2525 (Forecasting Loss:0.9379 + XiCon Loss:3.1459 x Lambda(0.1)), Vali MSE Loss: 0.6599 Test MSE Loss: 0.8491
Validation loss decreased (inf --> 0.659893).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.426913738250732
Epoch: 2, Steps: 96 Train Loss: 1.0561 (Forecasting Loss:0.7435 + XiCon Loss:3.1258 x Lambda(0.1)), Vali MSE Loss: 0.5985 Test MSE Loss: 0.3504
Validation loss decreased (0.659893 --> 0.598520).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.60142707824707
Epoch: 3, Steps: 96 Train Loss: 0.8691 (Forecasting Loss:0.5575 + XiCon Loss:3.1157 x Lambda(0.1)), Vali MSE Loss: 0.5626 Test MSE Loss: 0.2609
Validation loss decreased (0.598520 --> 0.562563).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.431379318237305
Epoch: 4, Steps: 96 Train Loss: 0.8274 (Forecasting Loss:0.5160 + XiCon Loss:3.1143 x Lambda(0.1)), Vali MSE Loss: 0.6195 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.8682780265808105
Epoch: 5, Steps: 96 Train Loss: 0.8136 (Forecasting Loss:0.5026 + XiCon Loss:3.1104 x Lambda(0.1)), Vali MSE Loss: 0.5312 Test MSE Loss: 0.2856
Validation loss decreased (0.562563 --> 0.531241).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 2.5405168533325195
Epoch: 6, Steps: 96 Train Loss: 0.8054 (Forecasting Loss:0.4943 + XiCon Loss:3.1104 x Lambda(0.1)), Vali MSE Loss: 0.5266 Test MSE Loss: 0.2920
Validation loss decreased (0.531241 --> 0.526618).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.031988620758057
Epoch: 7, Steps: 96 Train Loss: 0.8019 (Forecasting Loss:0.4909 + XiCon Loss:3.1102 x Lambda(0.1)), Vali MSE Loss: 0.5316 Test MSE Loss: 0.2864
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.4319469928741455
Epoch: 8, Steps: 96 Train Loss: 0.8010 (Forecasting Loss:0.4900 + XiCon Loss:3.1101 x Lambda(0.1)), Vali MSE Loss: 0.5338 Test MSE Loss: 0.2844
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.3196821212768555
Epoch: 9, Steps: 96 Train Loss: 0.7985 (Forecasting Loss:0.4874 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5341 Test MSE Loss: 0.2848
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.4917638301849365
Epoch: 10, Steps: 96 Train Loss: 0.7983 (Forecasting Loss:0.4873 + XiCon Loss:3.1096 x Lambda(0.1)), Vali MSE Loss: 0.5366 Test MSE Loss: 0.2847
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.326261281967163
Epoch: 11, Steps: 96 Train Loss: 0.7984 (Forecasting Loss:0.4873 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5340 Test MSE Loss: 0.2852
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.78917121887207
Epoch: 12, Steps: 96 Train Loss: 0.7976 (Forecasting Loss:0.4865 + XiCon Loss:3.1107 x Lambda(0.1)), Vali MSE Loss: 0.5325 Test MSE Loss: 0.2861
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 2.5001347064971924
Epoch: 13, Steps: 96 Train Loss: 0.7980 (Forecasting Loss:0.4870 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5334 Test MSE Loss: 0.2861
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.994614601135254
Epoch: 14, Steps: 96 Train Loss: 0.7973 (Forecasting Loss:0.4864 + XiCon Loss:3.1093 x Lambda(0.1)), Vali MSE Loss: 0.5330 Test MSE Loss: 0.2861
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.613980293273926
Epoch: 15, Steps: 96 Train Loss: 0.7987 (Forecasting Loss:0.4875 + XiCon Loss:3.1113 x Lambda(0.1)), Vali MSE Loss: 0.5334 Test MSE Loss: 0.2861
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.54401969909668
Epoch: 16, Steps: 96 Train Loss: 0.7985 (Forecasting Loss:0.4875 + XiCon Loss:3.1100 x Lambda(0.1)), Vali MSE Loss: 0.5346 Test MSE Loss: 0.2861
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2172548919916153, mae:0.3667506277561188, mape:0.7314583659172058, mspe:24.604103088378906 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3594
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.331331491470337
Epoch: 1, Steps: 96 Train Loss: 1.2387 (Forecasting Loss:0.9243 + XiCon Loss:3.1432 x Lambda(0.1)), Vali MSE Loss: 0.6504 Test MSE Loss: 0.8090
Validation loss decreased (inf --> 0.650428).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.8565897941589355
Epoch: 2, Steps: 96 Train Loss: 1.1153 (Forecasting Loss:0.8013 + XiCon Loss:3.1395 x Lambda(0.1)), Vali MSE Loss: 0.5675 Test MSE Loss: 0.4015
Validation loss decreased (0.650428 --> 0.567501).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 2.6392931938171387
Epoch: 3, Steps: 96 Train Loss: 0.8748 (Forecasting Loss:0.5609 + XiCon Loss:3.1392 x Lambda(0.1)), Vali MSE Loss: 0.6590 Test MSE Loss: 0.2756
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 2.68691086769104
Epoch: 4, Steps: 96 Train Loss: 0.8098 (Forecasting Loss:0.4965 + XiCon Loss:3.1324 x Lambda(0.1)), Vali MSE Loss: 0.5492 Test MSE Loss: 0.2849
Validation loss decreased (0.567501 --> 0.549156).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.39680290222168
Epoch: 5, Steps: 96 Train Loss: 0.7898 (Forecasting Loss:0.4769 + XiCon Loss:3.1288 x Lambda(0.1)), Vali MSE Loss: 0.5669 Test MSE Loss: 0.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.5840137004852295
Epoch: 6, Steps: 96 Train Loss: 0.7823 (Forecasting Loss:0.4695 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.5704 Test MSE Loss: 0.2820
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.380465269088745
Epoch: 7, Steps: 96 Train Loss: 0.7768 (Forecasting Loss:0.4640 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.5580 Test MSE Loss: 0.2857
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.538181781768799
Epoch: 8, Steps: 96 Train Loss: 0.7746 (Forecasting Loss:0.4621 + XiCon Loss:3.1257 x Lambda(0.1)), Vali MSE Loss: 0.5592 Test MSE Loss: 0.2858
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.804048538208008
Epoch: 9, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.4615 + XiCon Loss:3.1254 x Lambda(0.1)), Vali MSE Loss: 0.5553 Test MSE Loss: 0.2875
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 2.5539844036102295
Epoch: 10, Steps: 96 Train Loss: 0.7747 (Forecasting Loss:0.4620 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.5545 Test MSE Loss: 0.2879
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 3.05828857421875
Epoch: 11, Steps: 96 Train Loss: 0.7752 (Forecasting Loss:0.4626 + XiCon Loss:3.1257 x Lambda(0.1)), Vali MSE Loss: 0.5557 Test MSE Loss: 0.2875
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.54654598236084
Epoch: 12, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.4615 + XiCon Loss:3.1252 x Lambda(0.1)), Vali MSE Loss: 0.5562 Test MSE Loss: 0.2873
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.41607928276062
Epoch: 13, Steps: 96 Train Loss: 0.7737 (Forecasting Loss:0.4611 + XiCon Loss:3.1258 x Lambda(0.1)), Vali MSE Loss: 0.5552 Test MSE Loss: 0.2873
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.39011287689209
Epoch: 14, Steps: 96 Train Loss: 0.7725 (Forecasting Loss:0.4598 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.5551 Test MSE Loss: 0.2874
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.20806916058063507, mae:0.36165598034858704, mape:0.6832958459854126, mspe:21.043333053588867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3690
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.281855344772339
Epoch: 1, Steps: 96 Train Loss: 1.2284 (Forecasting Loss:0.9104 + XiCon Loss:3.1804 x Lambda(0.1)), Vali MSE Loss: 0.6232 Test MSE Loss: 0.7929
Validation loss decreased (inf --> 0.623236).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.596355676651001
Epoch: 2, Steps: 96 Train Loss: 1.0429 (Forecasting Loss:0.7317 + XiCon Loss:3.1121 x Lambda(0.1)), Vali MSE Loss: 0.5150 Test MSE Loss: 0.2712
Validation loss decreased (0.623236 --> 0.515000).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 2.4989655017852783
Epoch: 3, Steps: 96 Train Loss: 0.8349 (Forecasting Loss:0.5275 + XiCon Loss:3.0738 x Lambda(0.1)), Vali MSE Loss: 0.5521 Test MSE Loss: 0.2848
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.728602647781372
Epoch: 4, Steps: 96 Train Loss: 0.7987 (Forecasting Loss:0.4929 + XiCon Loss:3.0587 x Lambda(0.1)), Vali MSE Loss: 0.5274 Test MSE Loss: 0.3218
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.435133695602417
Epoch: 5, Steps: 96 Train Loss: 0.7835 (Forecasting Loss:0.4782 + XiCon Loss:3.0524 x Lambda(0.1)), Vali MSE Loss: 0.5568 Test MSE Loss: 0.2947
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.253376722335815
Epoch: 6, Steps: 96 Train Loss: 0.7775 (Forecasting Loss:0.4722 + XiCon Loss:3.0530 x Lambda(0.1)), Vali MSE Loss: 0.5301 Test MSE Loss: 0.3107
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.581485748291016
Epoch: 7, Steps: 96 Train Loss: 0.7719 (Forecasting Loss:0.4667 + XiCon Loss:3.0515 x Lambda(0.1)), Vali MSE Loss: 0.5258 Test MSE Loss: 0.3211
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.100766897201538
Epoch: 8, Steps: 96 Train Loss: 0.7714 (Forecasting Loss:0.4664 + XiCon Loss:3.0500 x Lambda(0.1)), Vali MSE Loss: 0.5260 Test MSE Loss: 0.3179
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.9737889766693115
Epoch: 9, Steps: 96 Train Loss: 0.7707 (Forecasting Loss:0.4659 + XiCon Loss:3.0484 x Lambda(0.1)), Vali MSE Loss: 0.5275 Test MSE Loss: 0.3174
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 2.518172025680542
Epoch: 10, Steps: 96 Train Loss: 0.7696 (Forecasting Loss:0.4646 + XiCon Loss:3.0508 x Lambda(0.1)), Vali MSE Loss: 0.5255 Test MSE Loss: 0.3187
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.44910192489624
Epoch: 11, Steps: 96 Train Loss: 0.7703 (Forecasting Loss:0.4653 + XiCon Loss:3.0497 x Lambda(0.1)), Vali MSE Loss: 0.5253 Test MSE Loss: 0.3197
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.45778751373291
Epoch: 12, Steps: 96 Train Loss: 0.7712 (Forecasting Loss:0.4663 + XiCon Loss:3.0487 x Lambda(0.1)), Vali MSE Loss: 0.5252 Test MSE Loss: 0.3198
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.19322246313095093, mae:0.34922483563423157, mape:0.6882543563842773, mspe:21.05060577392578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2138+-0.04060, MAE:0.3642+-0.03077, MAPE:0.7112+-0.05316, MSPE:23.1786+-3.99953, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3521
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5089700
	speed: 0.0651s/iter; left time: 1719.0228s
	iters: 200, epoch: 1 | loss: 0.5266423
	speed: 0.0618s/iter; left time: 1625.8935s
Epoch: 1 cost time: 16.639761686325073
Epoch: 1, Steps: 265 Train Loss: 0.5323 (Forecasting Loss:0.2078 + XiCon Loss:3.2449 x Lambda(0.1)), Vali MSE Loss: 0.1499 Test MSE Loss: 0.1002
Validation loss decreased (inf --> 0.149904).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5134794
	speed: 0.0707s/iter; left time: 1848.7721s
	iters: 200, epoch: 2 | loss: 0.5332949
	speed: 0.0628s/iter; left time: 1636.2365s
Epoch: 2 cost time: 17.701717376708984
Epoch: 2, Steps: 265 Train Loss: 0.5302 (Forecasting Loss:0.1992 + XiCon Loss:3.3098 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.0957
Validation loss decreased (0.149904 --> 0.144497).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5766309
	speed: 0.0681s/iter; left time: 1761.3164s
	iters: 200, epoch: 3 | loss: 0.5699281
	speed: 0.0634s/iter; left time: 1633.9358s
Epoch: 3 cost time: 17.394660234451294
Epoch: 3, Steps: 265 Train Loss: 0.5518 (Forecasting Loss:0.1936 + XiCon Loss:3.5822 x Lambda(0.1)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0955
Validation loss decreased (0.144497 --> 0.143156).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5229933
	speed: 0.0624s/iter; left time: 1597.1888s
	iters: 200, epoch: 4 | loss: 0.5468841
	speed: 0.0622s/iter; left time: 1586.5795s
Epoch: 4 cost time: 16.526179552078247
Epoch: 4, Steps: 265 Train Loss: 0.5325 (Forecasting Loss:0.1913 + XiCon Loss:3.4119 x Lambda(0.1)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5294700
	speed: 0.0678s/iter; left time: 1718.7264s
	iters: 200, epoch: 5 | loss: 0.5474451
	speed: 0.0613s/iter; left time: 1547.7532s
Epoch: 5 cost time: 17.002795457839966
Epoch: 5, Steps: 265 Train Loss: 0.5243 (Forecasting Loss:0.1903 + XiCon Loss:3.3403 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
Validation loss decreased (0.143156 --> 0.141765).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4989057
	speed: 0.0626s/iter; left time: 1569.8185s
	iters: 200, epoch: 6 | loss: 0.5500526
	speed: 0.0650s/iter; left time: 1622.3105s
Epoch: 6 cost time: 16.86394500732422
Epoch: 6, Steps: 265 Train Loss: 0.5222 (Forecasting Loss:0.1898 + XiCon Loss:3.3239 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0946
Validation loss decreased (0.141765 --> 0.141260).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5457124
	speed: 0.0657s/iter; left time: 1631.2986s
	iters: 200, epoch: 7 | loss: 0.5077963
	speed: 0.0615s/iter; left time: 1519.5008s
Epoch: 7 cost time: 16.402628421783447
Epoch: 7, Steps: 265 Train Loss: 0.5220 (Forecasting Loss:0.1894 + XiCon Loss:3.3257 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5235425
	speed: 0.0655s/iter; left time: 1607.5861s
	iters: 200, epoch: 8 | loss: 0.5549383
	speed: 0.0676s/iter; left time: 1653.6242s
Epoch: 8 cost time: 17.536370277404785
Epoch: 8, Steps: 265 Train Loss: 0.5215 (Forecasting Loss:0.1892 + XiCon Loss:3.3234 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4893689
	speed: 0.0646s/iter; left time: 1569.0556s
	iters: 200, epoch: 9 | loss: 0.5007337
	speed: 0.0594s/iter; left time: 1437.0192s
Epoch: 9 cost time: 16.747886180877686
Epoch: 9, Steps: 265 Train Loss: 0.5206 (Forecasting Loss:0.1892 + XiCon Loss:3.3146 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4931252
	speed: 0.0683s/iter; left time: 1641.2567s
	iters: 200, epoch: 10 | loss: 0.5463152
	speed: 0.0616s/iter; left time: 1472.8000s
Epoch: 10 cost time: 17.11401677131653
Epoch: 10, Steps: 265 Train Loss: 0.5206 (Forecasting Loss:0.1891 + XiCon Loss:3.3148 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4920665
	speed: 0.0599s/iter; left time: 1423.0375s
	iters: 200, epoch: 11 | loss: 0.5061412
	speed: 0.0365s/iter; left time: 862.3031s
Epoch: 11 cost time: 12.812386512756348
Epoch: 11, Steps: 265 Train Loss: 0.5215 (Forecasting Loss:0.1892 + XiCon Loss:3.3234 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5057145
	speed: 0.0669s/iter; left time: 1571.4158s
	iters: 200, epoch: 12 | loss: 0.4831969
	speed: 0.0631s/iter; left time: 1475.2803s
Epoch: 12 cost time: 17.075587272644043
Epoch: 12, Steps: 265 Train Loss: 0.5215 (Forecasting Loss:0.1891 + XiCon Loss:3.3238 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4952211
	speed: 0.0672s/iter; left time: 1561.1841s
	iters: 200, epoch: 13 | loss: 0.4971343
	speed: 0.0607s/iter; left time: 1403.6271s
Epoch: 13 cost time: 16.89070153236389
Epoch: 13, Steps: 265 Train Loss: 0.5216 (Forecasting Loss:0.1890 + XiCon Loss:3.3256 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0944
Validation loss decreased (0.141260 --> 0.141259).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4960804
	speed: 0.0674s/iter; left time: 1548.3470s
	iters: 200, epoch: 14 | loss: 0.5373676
	speed: 0.0644s/iter; left time: 1472.5650s
Epoch: 14 cost time: 17.37567687034607
Epoch: 14, Steps: 265 Train Loss: 0.5202 (Forecasting Loss:0.1891 + XiCon Loss:3.3111 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5452958
	speed: 0.0615s/iter; left time: 1396.1215s
	iters: 200, epoch: 15 | loss: 0.5453227
	speed: 0.0642s/iter; left time: 1450.5241s
Epoch: 15 cost time: 16.781580448150635
Epoch: 15, Steps: 265 Train Loss: 0.5217 (Forecasting Loss:0.1891 + XiCon Loss:3.3266 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5127547
	speed: 0.0661s/iter; left time: 1483.0358s
	iters: 200, epoch: 16 | loss: 0.5153534
	speed: 0.0626s/iter; left time: 1398.0679s
Epoch: 16 cost time: 16.739501953125
Epoch: 16, Steps: 265 Train Loss: 0.5204 (Forecasting Loss:0.1890 + XiCon Loss:3.3145 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5436692
	speed: 0.0659s/iter; left time: 1461.1761s
	iters: 200, epoch: 17 | loss: 0.5204939
	speed: 0.0651s/iter; left time: 1436.0782s
Epoch: 17 cost time: 17.221556901931763
Epoch: 17, Steps: 265 Train Loss: 0.5215 (Forecasting Loss:0.1889 + XiCon Loss:3.3257 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5142172
	speed: 0.0667s/iter; left time: 1460.9346s
	iters: 200, epoch: 18 | loss: 0.5106333
	speed: 0.0605s/iter; left time: 1317.7765s
Epoch: 18 cost time: 15.58841609954834
Epoch: 18, Steps: 265 Train Loss: 0.5198 (Forecasting Loss:0.1890 + XiCon Loss:3.3085 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5433271
	speed: 0.0545s/iter; left time: 1179.0604s
	iters: 200, epoch: 19 | loss: 0.5222440
	speed: 0.0651s/iter; left time: 1401.5324s
Epoch: 19 cost time: 16.108576774597168
Epoch: 19, Steps: 265 Train Loss: 0.5212 (Forecasting Loss:0.1890 + XiCon Loss:3.3218 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5273311
	speed: 0.0674s/iter; left time: 1439.6405s
	iters: 200, epoch: 20 | loss: 0.5039088
	speed: 0.0631s/iter; left time: 1341.7245s
Epoch: 20 cost time: 16.78360605239868
Epoch: 20, Steps: 265 Train Loss: 0.5209 (Forecasting Loss:0.1890 + XiCon Loss:3.3195 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5284058
	speed: 0.0659s/iter; left time: 1390.3433s
	iters: 200, epoch: 21 | loss: 0.5330170
	speed: 0.0621s/iter; left time: 1304.8494s
Epoch: 21 cost time: 16.986005306243896
Epoch: 21, Steps: 265 Train Loss: 0.5208 (Forecasting Loss:0.1891 + XiCon Loss:3.3176 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5466120
	speed: 0.0647s/iter; left time: 1348.0965s
	iters: 200, epoch: 22 | loss: 0.5291555
	speed: 0.0595s/iter; left time: 1233.3871s
Epoch: 22 cost time: 16.546733379364014
Epoch: 22, Steps: 265 Train Loss: 0.5209 (Forecasting Loss:0.1890 + XiCon Loss:3.3191 x Lambda(0.1)), Vali MSE Loss: 0.1413 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.5124715
	speed: 0.0660s/iter; left time: 1357.9465s
	iters: 200, epoch: 23 | loss: 0.5323904
	speed: 0.0636s/iter; left time: 1301.0383s
Epoch: 23 cost time: 16.956587314605713
Epoch: 23, Steps: 265 Train Loss: 0.5211 (Forecasting Loss:0.1891 + XiCon Loss:3.3201 x Lambda(0.1)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03936050832271576, mae:0.14952386915683746, mape:0.1186443343758583, mspe:0.02630752883851528 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.5452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5219395
	speed: 0.0645s/iter; left time: 1703.2931s
	iters: 200, epoch: 1 | loss: 0.5204844
	speed: 0.0601s/iter; left time: 1581.3879s
Epoch: 1 cost time: 16.391121864318848
Epoch: 1, Steps: 265 Train Loss: 0.5290 (Forecasting Loss:0.2059 + XiCon Loss:3.2307 x Lambda(0.1)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.0973
Validation loss decreased (inf --> 0.145985).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4840957
	speed: 0.0573s/iter; left time: 1496.4517s
	iters: 200, epoch: 2 | loss: 0.5370628
	speed: 0.0379s/iter; left time: 985.4842s
Epoch: 2 cost time: 13.587668418884277
Epoch: 2, Steps: 265 Train Loss: 0.5204 (Forecasting Loss:0.1982 + XiCon Loss:3.2226 x Lambda(0.1)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0980
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5189926
	speed: 0.0649s/iter; left time: 1679.5107s
	iters: 200, epoch: 3 | loss: 0.5031129
	speed: 0.0633s/iter; left time: 1630.5115s
Epoch: 3 cost time: 16.998258352279663
Epoch: 3, Steps: 265 Train Loss: 0.5075 (Forecasting Loss:0.1936 + XiCon Loss:3.1398 x Lambda(0.1)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0956
Validation loss decreased (0.145985 --> 0.143331).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4841789
	speed: 0.0608s/iter; left time: 1557.6183s
	iters: 200, epoch: 4 | loss: 0.5085246
	speed: 0.0641s/iter; left time: 1635.8784s
Epoch: 4 cost time: 16.58867907524109
Epoch: 4, Steps: 265 Train Loss: 0.5007 (Forecasting Loss:0.1911 + XiCon Loss:3.0965 x Lambda(0.1)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.0955
Validation loss decreased (0.143331 --> 0.142931).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5008823
	speed: 0.0670s/iter; left time: 1697.1576s
	iters: 200, epoch: 5 | loss: 0.5037330
	speed: 0.0623s/iter; left time: 1573.7061s
Epoch: 5 cost time: 17.17109489440918
Epoch: 5, Steps: 265 Train Loss: 0.4994 (Forecasting Loss:0.1901 + XiCon Loss:3.0932 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0948
Validation loss decreased (0.142931 --> 0.141895).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5412480
	speed: 0.0644s/iter; left time: 1614.5649s
	iters: 200, epoch: 6 | loss: 0.5041802
	speed: 0.0636s/iter; left time: 1588.5025s
Epoch: 6 cost time: 16.92907476425171
Epoch: 6, Steps: 265 Train Loss: 0.4986 (Forecasting Loss:0.1897 + XiCon Loss:3.0892 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4793130
	speed: 0.0659s/iter; left time: 1636.0933s
	iters: 200, epoch: 7 | loss: 0.5385146
	speed: 0.0629s/iter; left time: 1553.6538s
Epoch: 7 cost time: 16.99904704093933
Epoch: 7, Steps: 265 Train Loss: 0.4981 (Forecasting Loss:0.1893 + XiCon Loss:3.0879 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
Validation loss decreased (0.141895 --> 0.141804).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5072188
	speed: 0.0410s/iter; left time: 1006.8772s
	iters: 200, epoch: 8 | loss: 0.4974031
	speed: 0.0606s/iter; left time: 1481.0380s
Epoch: 8 cost time: 14.241973400115967
Epoch: 8, Steps: 265 Train Loss: 0.4988 (Forecasting Loss:0.1893 + XiCon Loss:3.0959 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
Validation loss decreased (0.141804 --> 0.141798).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4902576
	speed: 0.0656s/iter; left time: 1592.9171s
	iters: 200, epoch: 9 | loss: 0.5083210
	speed: 0.0622s/iter; left time: 1503.8909s
Epoch: 9 cost time: 16.76956033706665
Epoch: 9, Steps: 265 Train Loss: 0.4975 (Forecasting Loss:0.1891 + XiCon Loss:3.0837 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0947
Validation loss decreased (0.141798 --> 0.141530).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4982028
	speed: 0.0626s/iter; left time: 1502.4217s
	iters: 200, epoch: 10 | loss: 0.5014397
	speed: 0.0636s/iter; left time: 1521.4316s
Epoch: 10 cost time: 16.74471640586853
Epoch: 10, Steps: 265 Train Loss: 0.4980 (Forecasting Loss:0.1890 + XiCon Loss:3.0904 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5066084
	speed: 0.0654s/iter; left time: 1553.4613s
	iters: 200, epoch: 11 | loss: 0.5016940
	speed: 0.0614s/iter; left time: 1451.3383s
Epoch: 11 cost time: 16.479630708694458
Epoch: 11, Steps: 265 Train Loss: 0.4980 (Forecasting Loss:0.1890 + XiCon Loss:3.0893 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5068686
	speed: 0.0645s/iter; left time: 1515.0470s
	iters: 200, epoch: 12 | loss: 0.4952100
	speed: 0.0638s/iter; left time: 1491.6288s
Epoch: 12 cost time: 17.02456545829773
Epoch: 12, Steps: 265 Train Loss: 0.4977 (Forecasting Loss:0.1890 + XiCon Loss:3.0863 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5053269
	speed: 0.0651s/iter; left time: 1511.5000s
	iters: 200, epoch: 13 | loss: 0.4863196
	speed: 0.0592s/iter; left time: 1368.8290s
Epoch: 13 cost time: 16.67680311203003
Epoch: 13, Steps: 265 Train Loss: 0.4981 (Forecasting Loss:0.1891 + XiCon Loss:3.0899 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4729218
	speed: 0.0674s/iter; left time: 1547.5119s
	iters: 200, epoch: 14 | loss: 0.4992706
	speed: 0.0625s/iter; left time: 1427.8936s
Epoch: 14 cost time: 17.229917526245117
Epoch: 14, Steps: 265 Train Loss: 0.4978 (Forecasting Loss:0.1890 + XiCon Loss:3.0872 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4854094
	speed: 0.0616s/iter; left time: 1398.7041s
	iters: 200, epoch: 15 | loss: 0.4824163
	speed: 0.0605s/iter; left time: 1366.2855s
Epoch: 15 cost time: 16.363948106765747
Epoch: 15, Steps: 265 Train Loss: 0.4977 (Forecasting Loss:0.1890 + XiCon Loss:3.0870 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4936116
	speed: 0.0695s/iter; left time: 1559.0468s
	iters: 200, epoch: 16 | loss: 0.5068141
	speed: 0.0605s/iter; left time: 1350.9494s
Epoch: 16 cost time: 16.953742027282715
Epoch: 16, Steps: 265 Train Loss: 0.4980 (Forecasting Loss:0.1890 + XiCon Loss:3.0906 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4907637
	speed: 0.0629s/iter; left time: 1394.9849s
	iters: 200, epoch: 17 | loss: 0.4945885
	speed: 0.0639s/iter; left time: 1409.7455s
Epoch: 17 cost time: 16.93804693222046
Epoch: 17, Steps: 265 Train Loss: 0.4982 (Forecasting Loss:0.1890 + XiCon Loss:3.0912 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5137373
	speed: 0.0654s/iter; left time: 1432.5270s
	iters: 200, epoch: 18 | loss: 0.5345309
	speed: 0.0632s/iter; left time: 1376.8433s
Epoch: 18 cost time: 16.765621423721313
Epoch: 18, Steps: 265 Train Loss: 0.4981 (Forecasting Loss:0.1891 + XiCon Loss:3.0900 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4865427
	speed: 0.0655s/iter; left time: 1417.8845s
	iters: 200, epoch: 19 | loss: 0.4857903
	speed: 0.0636s/iter; left time: 1368.7275s
Epoch: 19 cost time: 17.1259503364563
Epoch: 19, Steps: 265 Train Loss: 0.4976 (Forecasting Loss:0.1890 + XiCon Loss:3.0860 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03954183682799339, mae:0.14984337985515594, mape:0.11891213059425354, mspe:0.02641785703599453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1223
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5232794
	speed: 0.0609s/iter; left time: 1608.7044s
	iters: 200, epoch: 1 | loss: 0.5307549
	speed: 0.0602s/iter; left time: 1582.7622s
Epoch: 1 cost time: 16.045455932617188
Epoch: 1, Steps: 265 Train Loss: 0.5300 (Forecasting Loss:0.2074 + XiCon Loss:3.2266 x Lambda(0.1)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0975
Validation loss decreased (inf --> 0.145573).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5384320
	speed: 0.0618s/iter; left time: 1614.0600s
	iters: 200, epoch: 2 | loss: 0.5279834
	speed: 0.0643s/iter; left time: 1673.0018s
Epoch: 2 cost time: 17.055832624435425
Epoch: 2, Steps: 265 Train Loss: 0.5238 (Forecasting Loss:0.1966 + XiCon Loss:3.2719 x Lambda(0.1)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.0980
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5070873
	speed: 0.0731s/iter; left time: 1891.3116s
	iters: 200, epoch: 3 | loss: 0.4973395
	speed: 0.0691s/iter; left time: 1781.2975s
Epoch: 3 cost time: 18.41649889945984
Epoch: 3, Steps: 265 Train Loss: 0.5118 (Forecasting Loss:0.1910 + XiCon Loss:3.2080 x Lambda(0.1)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1033
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5122427
	speed: 0.0676s/iter; left time: 1731.6871s
	iters: 200, epoch: 4 | loss: 0.5275275
	speed: 0.0696s/iter; left time: 1775.1013s
Epoch: 4 cost time: 18.231504440307617
Epoch: 4, Steps: 265 Train Loss: 0.5093 (Forecasting Loss:0.1877 + XiCon Loss:3.2157 x Lambda(0.1)), Vali MSE Loss: 0.1487 Test MSE Loss: 0.1067
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5054706
	speed: 0.0695s/iter; left time: 1761.3925s
	iters: 200, epoch: 5 | loss: 0.4905759
	speed: 0.0639s/iter; left time: 1613.1974s
Epoch: 5 cost time: 17.21203351020813
Epoch: 5, Steps: 265 Train Loss: 0.5047 (Forecasting Loss:0.1851 + XiCon Loss:3.1964 x Lambda(0.1)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.1057
Validation loss decreased (0.145573 --> 0.143226).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5165054
	speed: 0.0697s/iter; left time: 1747.9285s
	iters: 200, epoch: 6 | loss: 0.5011601
	speed: 0.0692s/iter; left time: 1727.1215s
Epoch: 6 cost time: 18.23949098587036
Epoch: 6, Steps: 265 Train Loss: 0.5017 (Forecasting Loss:0.1823 + XiCon Loss:3.1942 x Lambda(0.1)), Vali MSE Loss: 0.1458 Test MSE Loss: 0.1056
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4928139
	speed: 0.0671s/iter; left time: 1664.8351s
	iters: 200, epoch: 7 | loss: 0.5106597
	speed: 0.0642s/iter; left time: 1585.3149s
Epoch: 7 cost time: 17.608892917633057
Epoch: 7, Steps: 265 Train Loss: 0.4974 (Forecasting Loss:0.1786 + XiCon Loss:3.1873 x Lambda(0.1)), Vali MSE Loss: 0.1450 Test MSE Loss: 0.1130
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4899969
	speed: 0.0724s/iter; left time: 1776.3697s
	iters: 200, epoch: 8 | loss: 0.4733709
	speed: 0.0690s/iter; left time: 1686.6040s
Epoch: 8 cost time: 18.6032133102417
Epoch: 8, Steps: 265 Train Loss: 0.4957 (Forecasting Loss:0.1768 + XiCon Loss:3.1899 x Lambda(0.1)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.1142
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5181160
	speed: 0.0666s/iter; left time: 1618.1065s
	iters: 200, epoch: 9 | loss: 0.4994056
	speed: 0.0674s/iter; left time: 1629.7956s
Epoch: 9 cost time: 17.868637800216675
Epoch: 9, Steps: 265 Train Loss: 0.4945 (Forecasting Loss:0.1758 + XiCon Loss:3.1867 x Lambda(0.1)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5003397
	speed: 0.0726s/iter; left time: 1744.7365s
	iters: 200, epoch: 10 | loss: 0.4913672
	speed: 0.0637s/iter; left time: 1524.5282s
Epoch: 10 cost time: 17.787959814071655
Epoch: 10, Steps: 265 Train Loss: 0.4931 (Forecasting Loss:0.1749 + XiCon Loss:3.1820 x Lambda(0.1)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4629003
	speed: 0.0708s/iter; left time: 1680.8605s
	iters: 200, epoch: 11 | loss: 0.5025573
	speed: 0.0655s/iter; left time: 1548.0174s
Epoch: 11 cost time: 18.30776286125183
Epoch: 11, Steps: 265 Train Loss: 0.4937 (Forecasting Loss:0.1749 + XiCon Loss:3.1871 x Lambda(0.1)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.1132
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5263513
	speed: 0.0689s/iter; left time: 1619.2332s
	iters: 200, epoch: 12 | loss: 0.4738871
	speed: 0.0655s/iter; left time: 1530.8177s
Epoch: 12 cost time: 17.817249536514282
Epoch: 12, Steps: 265 Train Loss: 0.4940 (Forecasting Loss:0.1747 + XiCon Loss:3.1931 x Lambda(0.1)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.1130
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4915188
	speed: 0.0718s/iter; left time: 1666.2810s
	iters: 200, epoch: 13 | loss: 0.4980661
	speed: 0.0667s/iter; left time: 1542.3332s
Epoch: 13 cost time: 18.254525899887085
Epoch: 13, Steps: 265 Train Loss: 0.4932 (Forecasting Loss:0.1745 + XiCon Loss:3.1877 x Lambda(0.1)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.1131
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4873759
	speed: 0.0660s/iter; left time: 1514.6694s
	iters: 200, epoch: 14 | loss: 0.4907410
	speed: 0.0693s/iter; left time: 1584.1765s
Epoch: 14 cost time: 18.030325174331665
Epoch: 14, Steps: 265 Train Loss: 0.4940 (Forecasting Loss:0.1746 + XiCon Loss:3.1941 x Lambda(0.1)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.1130
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4952690
	speed: 0.0713s/iter; left time: 1618.6898s
	iters: 200, epoch: 15 | loss: 0.4990278
	speed: 0.0641s/iter; left time: 1448.1550s
Epoch: 15 cost time: 17.637516736984253
Epoch: 15, Steps: 265 Train Loss: 0.4934 (Forecasting Loss:0.1744 + XiCon Loss:3.1895 x Lambda(0.1)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.1130
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.049960456788539886, mae:0.1614917814731598, mape:0.12776727974414825, mspe:0.032577693462371826 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6815
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5154444
	speed: 0.0610s/iter; left time: 1610.0922s
	iters: 200, epoch: 1 | loss: 0.5064002
	speed: 0.0539s/iter; left time: 1417.3406s
Epoch: 1 cost time: 15.40865421295166
Epoch: 1, Steps: 265 Train Loss: 0.5323 (Forecasting Loss:0.2066 + XiCon Loss:3.2568 x Lambda(0.1)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0967
Validation loss decreased (inf --> 0.146147).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5035195
	speed: 0.0661s/iter; left time: 1727.8007s
	iters: 200, epoch: 2 | loss: 0.5041326
	speed: 0.0700s/iter; left time: 1822.5624s
Epoch: 2 cost time: 18.07975697517395
Epoch: 2, Steps: 265 Train Loss: 0.5225 (Forecasting Loss:0.1974 + XiCon Loss:3.2515 x Lambda(0.1)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.0971
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5125434
	speed: 0.0644s/iter; left time: 1665.0256s
	iters: 200, epoch: 3 | loss: 0.4829494
	speed: 0.0650s/iter; left time: 1676.0445s
Epoch: 3 cost time: 17.295979499816895
Epoch: 3, Steps: 265 Train Loss: 0.5030 (Forecasting Loss:0.1930 + XiCon Loss:3.1004 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.0962
Validation loss decreased (0.146147 --> 0.144348).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4741352
	speed: 0.0712s/iter; left time: 1824.1713s
	iters: 200, epoch: 4 | loss: 0.4984698
	speed: 0.0696s/iter; left time: 1775.6117s
Epoch: 4 cost time: 18.322788953781128
Epoch: 4, Steps: 265 Train Loss: 0.5000 (Forecasting Loss:0.1911 + XiCon Loss:3.0890 x Lambda(0.1)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0950
Validation loss decreased (0.144348 --> 0.142603).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5002835
	speed: 0.0702s/iter; left time: 1779.8155s
	iters: 200, epoch: 5 | loss: 0.4811906
	speed: 0.0676s/iter; left time: 1707.3957s
Epoch: 5 cost time: 18.243136167526245
Epoch: 5, Steps: 265 Train Loss: 0.4990 (Forecasting Loss:0.1902 + XiCon Loss:3.0871 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.142603 --> 0.141765).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4917867
	speed: 0.0685s/iter; left time: 1717.1658s
	iters: 200, epoch: 6 | loss: 0.5440544
	speed: 0.0638s/iter; left time: 1592.7756s
Epoch: 6 cost time: 16.81382942199707
Epoch: 6, Steps: 265 Train Loss: 0.4980 (Forecasting Loss:0.1897 + XiCon Loss:3.0834 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141765 --> 0.141740).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4894038
	speed: 0.0983s/iter; left time: 2439.6873s
	iters: 200, epoch: 7 | loss: 0.4918962
	speed: 0.0442s/iter; left time: 1092.6435s
Epoch: 7 cost time: 16.874995231628418
Epoch: 7, Steps: 265 Train Loss: 0.4977 (Forecasting Loss:0.1894 + XiCon Loss:3.0833 x Lambda(0.1)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4943940
	speed: 0.0665s/iter; left time: 1633.1192s
	iters: 200, epoch: 8 | loss: 0.4830485
	speed: 0.0686s/iter; left time: 1676.0303s
Epoch: 8 cost time: 18.091464042663574
Epoch: 8, Steps: 265 Train Loss: 0.4971 (Forecasting Loss:0.1891 + XiCon Loss:3.0793 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141740 --> 0.141735).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5299505
	speed: 0.0702s/iter; left time: 1703.5351s
	iters: 200, epoch: 9 | loss: 0.5294069
	speed: 0.0622s/iter; left time: 1503.7254s
Epoch: 9 cost time: 16.86809492111206
Epoch: 9, Steps: 265 Train Loss: 0.4972 (Forecasting Loss:0.1890 + XiCon Loss:3.0819 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141735 --> 0.141707).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5383595
	speed: 0.0700s/iter; left time: 1681.1312s
	iters: 200, epoch: 10 | loss: 0.4964197
	speed: 0.0674s/iter; left time: 1612.4087s
Epoch: 10 cost time: 18.219130277633667
Epoch: 10, Steps: 265 Train Loss: 0.4976 (Forecasting Loss:0.1891 + XiCon Loss:3.0854 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5024583
	speed: 0.0674s/iter; left time: 1601.4213s
	iters: 200, epoch: 11 | loss: 0.5492965
	speed: 0.0470s/iter; left time: 1111.0374s
Epoch: 11 cost time: 14.04122805595398
Epoch: 11, Steps: 265 Train Loss: 0.4969 (Forecasting Loss:0.1890 + XiCon Loss:3.0791 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141707 --> 0.141672).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4923999
	speed: 0.0680s/iter; left time: 1597.2337s
	iters: 200, epoch: 12 | loss: 0.4914894
	speed: 0.0675s/iter; left time: 1579.6835s
Epoch: 12 cost time: 18.078248977661133
Epoch: 12, Steps: 265 Train Loss: 0.4968 (Forecasting Loss:0.1889 + XiCon Loss:3.0797 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4769775
	speed: 0.0674s/iter; left time: 1564.2275s
	iters: 200, epoch: 13 | loss: 0.4998881
	speed: 0.0549s/iter; left time: 1268.9695s
Epoch: 13 cost time: 14.813975095748901
Epoch: 13, Steps: 265 Train Loss: 0.4971 (Forecasting Loss:0.1889 + XiCon Loss:3.0822 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141672 --> 0.141628).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5118156
	speed: 0.0697s/iter; left time: 1599.3640s
	iters: 200, epoch: 14 | loss: 0.4897106
	speed: 0.0654s/iter; left time: 1495.9204s
Epoch: 14 cost time: 17.93379259109497
Epoch: 14, Steps: 265 Train Loss: 0.4972 (Forecasting Loss:0.1889 + XiCon Loss:3.0825 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5347503
	speed: 0.0681s/iter; left time: 1544.3950s
	iters: 200, epoch: 15 | loss: 0.4696534
	speed: 0.0594s/iter; left time: 1342.3905s
Epoch: 15 cost time: 15.267398834228516
Epoch: 15, Steps: 265 Train Loss: 0.4978 (Forecasting Loss:0.1889 + XiCon Loss:3.0883 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5038689
	speed: 0.0660s/iter; left time: 1479.7523s
	iters: 200, epoch: 16 | loss: 0.4700747
	speed: 0.0687s/iter; left time: 1534.1198s
Epoch: 16 cost time: 17.96884512901306
Epoch: 16, Steps: 265 Train Loss: 0.4966 (Forecasting Loss:0.1888 + XiCon Loss:3.0782 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141628 --> 0.141593).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5189791
	speed: 0.0702s/iter; left time: 1554.7057s
	iters: 200, epoch: 17 | loss: 0.4692652
	speed: 0.0664s/iter; left time: 1464.1740s
Epoch: 17 cost time: 17.8677339553833
Epoch: 17, Steps: 265 Train Loss: 0.4973 (Forecasting Loss:0.1890 + XiCon Loss:3.0834 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4996296
	speed: 0.0689s/iter; left time: 1507.6538s
	iters: 200, epoch: 18 | loss: 0.4936430
	speed: 0.0677s/iter; left time: 1475.5926s
Epoch: 18 cost time: 18.056074142456055
Epoch: 18, Steps: 265 Train Loss: 0.4971 (Forecasting Loss:0.1889 + XiCon Loss:3.0816 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4983063
	speed: 0.0673s/iter; left time: 1456.1458s
	iters: 200, epoch: 19 | loss: 0.4637099
	speed: 0.0404s/iter; left time: 868.9162s
Epoch: 19 cost time: 13.90711784362793
Epoch: 19, Steps: 265 Train Loss: 0.4970 (Forecasting Loss:0.1889 + XiCon Loss:3.0809 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5037521
	speed: 0.0708s/iter; left time: 1511.9557s
	iters: 200, epoch: 20 | loss: 0.4987848
	speed: 0.0673s/iter; left time: 1430.9688s
Epoch: 20 cost time: 18.353314876556396
Epoch: 20, Steps: 265 Train Loss: 0.4964 (Forecasting Loss:0.1888 + XiCon Loss:3.0754 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4648575
	speed: 0.0665s/iter; left time: 1402.1692s
	iters: 200, epoch: 21 | loss: 0.4948985
	speed: 0.0478s/iter; left time: 1004.3028s
Epoch: 21 cost time: 14.035544633865356
Epoch: 21, Steps: 265 Train Loss: 0.4968 (Forecasting Loss:0.1888 + XiCon Loss:3.0798 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4909945
	speed: 0.0706s/iter; left time: 1469.9893s
	iters: 200, epoch: 22 | loss: 0.5244893
	speed: 0.0667s/iter; left time: 1383.2558s
Epoch: 22 cost time: 18.0996150970459
Epoch: 22, Steps: 265 Train Loss: 0.4964 (Forecasting Loss:0.1888 + XiCon Loss:3.0762 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141593 --> 0.141574).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.5051172
	speed: 0.0686s/iter; left time: 1411.3723s
	iters: 200, epoch: 23 | loss: 0.5015932
	speed: 0.0542s/iter; left time: 1109.6415s
Epoch: 23 cost time: 14.779764413833618
Epoch: 23, Steps: 265 Train Loss: 0.4966 (Forecasting Loss:0.1889 + XiCon Loss:3.0770 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4966932
	speed: 0.0663s/iter; left time: 1345.8007s
	iters: 200, epoch: 24 | loss: 0.4697714
	speed: 0.0685s/iter; left time: 1383.5344s
Epoch: 24 cost time: 17.98688840866089
Epoch: 24, Steps: 265 Train Loss: 0.4968 (Forecasting Loss:0.1889 + XiCon Loss:3.0792 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5342768
	speed: 0.0704s/iter; left time: 1409.9123s
	iters: 200, epoch: 25 | loss: 0.4705459
	speed: 0.0608s/iter; left time: 1212.4664s
Epoch: 25 cost time: 17.550398111343384
Epoch: 25, Steps: 265 Train Loss: 0.4971 (Forecasting Loss:0.1888 + XiCon Loss:3.0830 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141574 --> 0.141570).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4933716
	speed: 0.0692s/iter; left time: 1367.8263s
	iters: 200, epoch: 26 | loss: 0.4946861
	speed: 0.0674s/iter; left time: 1326.7915s
Epoch: 26 cost time: 17.944149255752563
Epoch: 26, Steps: 265 Train Loss: 0.4970 (Forecasting Loss:0.1889 + XiCon Loss:3.0809 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
Validation loss decreased (0.141570 --> 0.141516).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4874322
	speed: 0.0652s/iter; left time: 1272.1467s
	iters: 200, epoch: 27 | loss: 0.5010504
	speed: 0.0665s/iter; left time: 1290.6088s
Epoch: 27 cost time: 17.646965265274048
Epoch: 27, Steps: 265 Train Loss: 0.4970 (Forecasting Loss:0.1890 + XiCon Loss:3.0803 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4851584
	speed: 0.0692s/iter; left time: 1331.8156s
	iters: 200, epoch: 28 | loss: 0.5219148
	speed: 0.0696s/iter; left time: 1331.6129s
Epoch: 28 cost time: 17.878706216812134
Epoch: 28, Steps: 265 Train Loss: 0.4968 (Forecasting Loss:0.1888 + XiCon Loss:3.0798 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4803014
	speed: 0.0686s/iter; left time: 1301.9503s
	iters: 200, epoch: 29 | loss: 0.4880633
	speed: 0.0671s/iter; left time: 1266.1375s
Epoch: 29 cost time: 18.113096237182617
Epoch: 29, Steps: 265 Train Loss: 0.4968 (Forecasting Loss:0.1889 + XiCon Loss:3.0792 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.5105470
	speed: 0.0704s/iter; left time: 1318.3580s
	iters: 200, epoch: 30 | loss: 0.4871078
	speed: 0.0627s/iter; left time: 1167.7881s
Epoch: 30 cost time: 17.520226001739502
Epoch: 30, Steps: 265 Train Loss: 0.4969 (Forecasting Loss:0.1890 + XiCon Loss:3.0791 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.4958205
	speed: 0.0717s/iter; left time: 1322.1475s
	iters: 200, epoch: 31 | loss: 0.4744423
	speed: 0.0706s/iter; left time: 1295.2787s
Epoch: 31 cost time: 18.690245628356934
Epoch: 31, Steps: 265 Train Loss: 0.4960 (Forecasting Loss:0.1888 + XiCon Loss:3.0720 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.4949732
	speed: 0.0641s/iter; left time: 1165.6793s
	iters: 200, epoch: 32 | loss: 0.5050493
	speed: 0.0669s/iter; left time: 1209.5799s
Epoch: 32 cost time: 17.550318479537964
Epoch: 32, Steps: 265 Train Loss: 0.4963 (Forecasting Loss:0.1888 + XiCon Loss:3.0755 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 0.4945034
	speed: 0.0721s/iter; left time: 1292.8743s
	iters: 200, epoch: 33 | loss: 0.4945208
	speed: 0.0676s/iter; left time: 1203.8283s
Epoch: 33 cost time: 18.053651094436646
Epoch: 33, Steps: 265 Train Loss: 0.4971 (Forecasting Loss:0.1890 + XiCon Loss:3.0814 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 0.5013283
	speed: 0.0696s/iter; left time: 1229.3630s
	iters: 200, epoch: 34 | loss: 0.5073675
	speed: 0.0705s/iter; left time: 1236.8382s
Epoch: 34 cost time: 18.315040349960327
Epoch: 34, Steps: 265 Train Loss: 0.4972 (Forecasting Loss:0.1890 + XiCon Loss:3.0821 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 0.5211049
	speed: 0.0698s/iter; left time: 1213.3471s
	iters: 200, epoch: 35 | loss: 0.4928637
	speed: 0.0605s/iter; left time: 1045.6840s
Epoch: 35 cost time: 17.25133776664734
Epoch: 35, Steps: 265 Train Loss: 0.4973 (Forecasting Loss:0.1890 + XiCon Loss:3.0830 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 0.4875663
	speed: 0.0722s/iter; left time: 1236.6860s
	iters: 200, epoch: 36 | loss: 0.5020235
	speed: 0.0684s/iter; left time: 1163.7526s
Epoch: 36 cost time: 18.578526735305786
Epoch: 36, Steps: 265 Train Loss: 0.4966 (Forecasting Loss:0.1889 + XiCon Loss:3.0769 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03936496004462242, mae:0.14957694709300995, mape:0.11882186681032181, mspe:0.026396101340651512 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.5934
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5305681
	speed: 0.0625s/iter; left time: 1649.2810s
	iters: 200, epoch: 1 | loss: 0.5073732
	speed: 0.0609s/iter; left time: 1601.8026s
Epoch: 1 cost time: 16.10361385345459
Epoch: 1, Steps: 265 Train Loss: 0.5328 (Forecasting Loss:0.2086 + XiCon Loss:3.2418 x Lambda(0.1)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.147859).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5369312
	speed: 0.0612s/iter; left time: 1598.3187s
	iters: 200, epoch: 2 | loss: 0.5144112
	speed: 0.0681s/iter; left time: 1774.3126s
Epoch: 2 cost time: 17.174049615859985
Epoch: 2, Steps: 265 Train Loss: 0.5260 (Forecasting Loss:0.1959 + XiCon Loss:3.3014 x Lambda(0.1)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0979
Validation loss decreased (0.147859 --> 0.145656).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4963639
	speed: 0.0720s/iter; left time: 1862.2132s
	iters: 200, epoch: 3 | loss: 0.4753526
	speed: 0.0642s/iter; left time: 1654.6258s
Epoch: 3 cost time: 17.71682381629944
Epoch: 3, Steps: 265 Train Loss: 0.5102 (Forecasting Loss:0.1884 + XiCon Loss:3.2184 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1004
Validation loss decreased (0.145656 --> 0.143994).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4927514
	speed: 0.0722s/iter; left time: 1847.5218s
	iters: 200, epoch: 4 | loss: 0.5013815
	speed: 0.0683s/iter; left time: 1741.1507s
Epoch: 4 cost time: 18.27001690864563
Epoch: 4, Steps: 265 Train Loss: 0.5011 (Forecasting Loss:0.1805 + XiCon Loss:3.2058 x Lambda(0.1)), Vali MSE Loss: 0.1523 Test MSE Loss: 0.1053
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4809930
	speed: 0.0690s/iter; left time: 1748.8854s
	iters: 200, epoch: 5 | loss: 0.4854679
	speed: 0.0646s/iter; left time: 1631.7968s
Epoch: 5 cost time: 18.088671445846558
Epoch: 5, Steps: 265 Train Loss: 0.4941 (Forecasting Loss:0.1738 + XiCon Loss:3.2032 x Lambda(0.1)), Vali MSE Loss: 0.1505 Test MSE Loss: 0.1076
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5017381
	speed: 0.0695s/iter; left time: 1742.6522s
	iters: 200, epoch: 6 | loss: 0.4938940
	speed: 0.0708s/iter; left time: 1767.2507s
Epoch: 6 cost time: 18.276978015899658
Epoch: 6, Steps: 265 Train Loss: 0.4905 (Forecasting Loss:0.1699 + XiCon Loss:3.2057 x Lambda(0.1)), Vali MSE Loss: 0.1535 Test MSE Loss: 0.1076
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5139766
	speed: 0.0680s/iter; left time: 1687.2761s
	iters: 200, epoch: 7 | loss: 0.5016388
	speed: 0.0695s/iter; left time: 1717.7945s
Epoch: 7 cost time: 18.303704977035522
Epoch: 7, Steps: 265 Train Loss: 0.4889 (Forecasting Loss:0.1678 + XiCon Loss:3.2117 x Lambda(0.1)), Vali MSE Loss: 0.1545 Test MSE Loss: 0.1089
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4891981
	speed: 0.0689s/iter; left time: 1690.2853s
	iters: 200, epoch: 8 | loss: 0.5180423
	speed: 0.0649s/iter; left time: 1587.4012s
Epoch: 8 cost time: 17.603721141815186
Epoch: 8, Steps: 265 Train Loss: 0.4875 (Forecasting Loss:0.1666 + XiCon Loss:3.2085 x Lambda(0.1)), Vali MSE Loss: 0.1534 Test MSE Loss: 0.1073
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4680268
	speed: 0.0746s/iter; left time: 1812.3425s
	iters: 200, epoch: 9 | loss: 0.4750930
	speed: 0.0681s/iter; left time: 1646.0355s
Epoch: 9 cost time: 18.721949100494385
Epoch: 9, Steps: 265 Train Loss: 0.4871 (Forecasting Loss:0.1662 + XiCon Loss:3.2090 x Lambda(0.1)), Vali MSE Loss: 0.1535 Test MSE Loss: 0.1084
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4765503
	speed: 0.0662s/iter; left time: 1590.6114s
	iters: 200, epoch: 10 | loss: 0.5100110
	speed: 0.0645s/iter; left time: 1542.2314s
Epoch: 10 cost time: 17.503488302230835
Epoch: 10, Steps: 265 Train Loss: 0.4865 (Forecasting Loss:0.1657 + XiCon Loss:3.2083 x Lambda(0.1)), Vali MSE Loss: 0.1530 Test MSE Loss: 0.1077
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4729074
	speed: 0.0701s/iter; left time: 1664.8889s
	iters: 200, epoch: 11 | loss: 0.4815145
	speed: 0.0678s/iter; left time: 1602.9631s
Epoch: 11 cost time: 18.171767234802246
Epoch: 11, Steps: 265 Train Loss: 0.4855 (Forecasting Loss:0.1654 + XiCon Loss:3.2016 x Lambda(0.1)), Vali MSE Loss: 0.1535 Test MSE Loss: 0.1079
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4697233
	speed: 0.0671s/iter; left time: 1574.8234s
	iters: 200, epoch: 12 | loss: 0.5227181
	speed: 0.0674s/iter; left time: 1576.8685s
Epoch: 12 cost time: 17.999348402023315
Epoch: 12, Steps: 265 Train Loss: 0.4865 (Forecasting Loss:0.1653 + XiCon Loss:3.2124 x Lambda(0.1)), Vali MSE Loss: 0.1535 Test MSE Loss: 0.1081
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4844226
	speed: 0.0706s/iter; left time: 1640.1452s
	iters: 200, epoch: 13 | loss: 0.5121689
	speed: 0.0637s/iter; left time: 1472.7991s
Epoch: 13 cost time: 17.477081298828125
Epoch: 13, Steps: 265 Train Loss: 0.4861 (Forecasting Loss:0.1655 + XiCon Loss:3.2064 x Lambda(0.1)), Vali MSE Loss: 0.1532 Test MSE Loss: 0.1082
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04356655478477478, mae:0.15723232924938202, mape:0.1249590516090393, mspe:0.029601307585835457 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0424+-0.00573, MAE:0.1535+-0.00687, MAPE:0.1218+-0.00530, MSPE:0.0283+-0.00346, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8122
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.6382073
	speed: 0.1228s/iter; left time: 3130.2833s
	iters: 200, epoch: 1 | loss: 0.5943542
	speed: 0.1223s/iter; left time: 3105.8238s
Epoch: 1 cost time: 31.29376530647278
Epoch: 1, Steps: 256 Train Loss: 0.6219 (Forecasting Loss:0.2999 + XiCon Loss:3.2200 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1611
Validation loss decreased (inf --> 0.209300).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6319218
	speed: 0.1731s/iter; left time: 4369.9325s
	iters: 200, epoch: 2 | loss: 0.6129630
	speed: 0.1486s/iter; left time: 3736.0982s
Epoch: 2 cost time: 39.779550313949585
Epoch: 2, Steps: 256 Train Loss: 0.6026 (Forecasting Loss:0.2772 + XiCon Loss:3.2539 x Lambda(0.1)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1650
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5817969
	speed: 0.1326s/iter; left time: 3314.4492s
	iters: 200, epoch: 3 | loss: 0.5823631
	speed: 0.1305s/iter; left time: 3247.3180s
Epoch: 3 cost time: 34.02285647392273
Epoch: 3, Steps: 256 Train Loss: 0.5735 (Forecasting Loss:0.2530 + XiCon Loss:3.2053 x Lambda(0.1)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1652
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5677218
	speed: 0.1363s/iter; left time: 3371.7545s
	iters: 200, epoch: 4 | loss: 0.5547303
	speed: 0.0935s/iter; left time: 2302.2777s
Epoch: 4 cost time: 30.496626377105713
Epoch: 4, Steps: 256 Train Loss: 0.5533 (Forecasting Loss:0.2407 + XiCon Loss:3.1259 x Lambda(0.1)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1690
Validation loss decreased (0.209300 --> 0.206596).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5216237
	speed: 0.1358s/iter; left time: 3323.9366s
	iters: 200, epoch: 5 | loss: 0.5443550
	speed: 0.1279s/iter; left time: 3116.8177s
Epoch: 5 cost time: 33.89329123497009
Epoch: 5, Steps: 256 Train Loss: 0.5448 (Forecasting Loss:0.2347 + XiCon Loss:3.1007 x Lambda(0.1)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1697
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5870929
	speed: 0.1372s/iter; left time: 3324.2077s
	iters: 200, epoch: 6 | loss: 0.5416100
	speed: 0.1211s/iter; left time: 2921.4783s
Epoch: 6 cost time: 32.015024185180664
Epoch: 6, Steps: 256 Train Loss: 0.5402 (Forecasting Loss:0.2312 + XiCon Loss:3.0894 x Lambda(0.1)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1694
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5487402
	speed: 0.1360s/iter; left time: 3258.4399s
	iters: 200, epoch: 7 | loss: 0.5374722
	speed: 0.1314s/iter; left time: 3134.7038s
Epoch: 7 cost time: 32.8311550617218
Epoch: 7, Steps: 256 Train Loss: 0.5375 (Forecasting Loss:0.2293 + XiCon Loss:3.0818 x Lambda(0.1)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1694
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5561470
	speed: 0.1334s/iter; left time: 3162.0298s
	iters: 200, epoch: 8 | loss: 0.5274463
	speed: 0.1320s/iter; left time: 3116.0400s
Epoch: 8 cost time: 34.292481422424316
Epoch: 8, Steps: 256 Train Loss: 0.5366 (Forecasting Loss:0.2285 + XiCon Loss:3.0805 x Lambda(0.1)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5454770
	speed: 0.1238s/iter; left time: 2903.0758s
	iters: 200, epoch: 9 | loss: 0.5178099
	speed: 0.1327s/iter; left time: 3099.1028s
Epoch: 9 cost time: 33.1842987537384
Epoch: 9, Steps: 256 Train Loss: 0.5358 (Forecasting Loss:0.2282 + XiCon Loss:3.0767 x Lambda(0.1)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1694
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5155765
	speed: 0.1374s/iter; left time: 3186.7939s
	iters: 200, epoch: 10 | loss: 0.5435282
	speed: 0.1348s/iter; left time: 3112.9598s
Epoch: 10 cost time: 34.61775207519531
Epoch: 10, Steps: 256 Train Loss: 0.5355 (Forecasting Loss:0.2278 + XiCon Loss:3.0769 x Lambda(0.1)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1697
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5464162
	speed: 0.1120s/iter; left time: 2568.3370s
	iters: 200, epoch: 11 | loss: 0.5419109
	speed: 0.1337s/iter; left time: 3054.0854s
Epoch: 11 cost time: 32.082573652267456
Epoch: 11, Steps: 256 Train Loss: 0.5356 (Forecasting Loss:0.2277 + XiCon Loss:3.0795 x Lambda(0.1)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1696
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5307389
	speed: 0.1149s/iter; left time: 2606.2154s
	iters: 200, epoch: 12 | loss: 0.5379623
	speed: 0.1325s/iter; left time: 2992.2285s
Epoch: 12 cost time: 32.231531381607056
Epoch: 12, Steps: 256 Train Loss: 0.5356 (Forecasting Loss:0.2276 + XiCon Loss:3.0808 x Lambda(0.1)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1696
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5222838
	speed: 0.1368s/iter; left time: 3067.5561s
	iters: 200, epoch: 13 | loss: 0.5189052
	speed: 0.1330s/iter; left time: 2968.8357s
Epoch: 13 cost time: 34.82289361953735
Epoch: 13, Steps: 256 Train Loss: 0.5353 (Forecasting Loss:0.2275 + XiCon Loss:3.0779 x Lambda(0.1)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1696
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5343986
	speed: 0.1204s/iter; left time: 2669.1532s
	iters: 200, epoch: 14 | loss: 0.5445700
	speed: 0.1250s/iter; left time: 2759.7515s
Epoch: 14 cost time: 32.2730016708374
Epoch: 14, Steps: 256 Train Loss: 0.5358 (Forecasting Loss:0.2277 + XiCon Loss:3.0817 x Lambda(0.1)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1696
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09643876552581787, mae:0.24162696301937103, mape:0.17685560882091522, mspe:0.04972972348332405 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2120
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.6298900
	speed: 0.1195s/iter; left time: 3047.8400s
	iters: 200, epoch: 1 | loss: 0.5829535
	speed: 0.1204s/iter; left time: 3059.0989s
Epoch: 1 cost time: 30.30223560333252
Epoch: 1, Steps: 256 Train Loss: 0.6140 (Forecasting Loss:0.2937 + XiCon Loss:3.2033 x Lambda(0.1)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1514
Validation loss decreased (inf --> 0.200918).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6269839
	speed: 0.1270s/iter; left time: 3204.9028s
	iters: 200, epoch: 2 | loss: 0.6011318
	speed: 0.1542s/iter; left time: 3877.5630s
Epoch: 2 cost time: 36.246599435806274
Epoch: 2, Steps: 256 Train Loss: 0.6275 (Forecasting Loss:0.2998 + XiCon Loss:3.2768 x Lambda(0.1)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.1725
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6192967
	speed: 0.1353s/iter; left time: 3381.4681s
	iters: 200, epoch: 3 | loss: 0.6042529
	speed: 0.1313s/iter; left time: 3266.6926s
Epoch: 3 cost time: 34.11073684692383
Epoch: 3, Steps: 256 Train Loss: 0.6159 (Forecasting Loss:0.3005 + XiCon Loss:3.1542 x Lambda(0.1)), Vali MSE Loss: 0.2213 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6212406
	speed: 0.1346s/iter; left time: 3328.9691s
	iters: 200, epoch: 4 | loss: 0.5819927
	speed: 0.1314s/iter; left time: 3236.5883s
Epoch: 4 cost time: 33.63507103919983
Epoch: 4, Steps: 256 Train Loss: 0.6080 (Forecasting Loss:0.2978 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1659
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6255958
	speed: 0.1373s/iter; left time: 3360.9735s
	iters: 200, epoch: 5 | loss: 0.6184641
	speed: 0.1315s/iter; left time: 3206.5001s
Epoch: 5 cost time: 34.402191162109375
Epoch: 5, Steps: 256 Train Loss: 0.6059 (Forecasting Loss:0.2961 + XiCon Loss:3.0976 x Lambda(0.1)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1637
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6068291
	speed: 0.1359s/iter; left time: 3292.1500s
	iters: 200, epoch: 6 | loss: 0.5926523
	speed: 0.1288s/iter; left time: 3107.8681s
Epoch: 6 cost time: 33.490055561065674
Epoch: 6, Steps: 256 Train Loss: 0.6049 (Forecasting Loss:0.2954 + XiCon Loss:3.0954 x Lambda(0.1)), Vali MSE Loss: 0.2210 Test MSE Loss: 0.1632
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6051791
	speed: 0.1369s/iter; left time: 3279.6878s
	iters: 200, epoch: 7 | loss: 0.6127710
	speed: 0.1299s/iter; left time: 3099.9203s
Epoch: 7 cost time: 33.979427099227905
Epoch: 7, Steps: 256 Train Loss: 0.6048 (Forecasting Loss:0.2948 + XiCon Loss:3.0998 x Lambda(0.1)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1634
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.6203690
	speed: 0.1338s/iter; left time: 3172.7621s
	iters: 200, epoch: 8 | loss: 0.6176552
	speed: 0.1301s/iter; left time: 3072.0199s
Epoch: 8 cost time: 33.63586688041687
Epoch: 8, Steps: 256 Train Loss: 0.6040 (Forecasting Loss:0.2946 + XiCon Loss:3.0942 x Lambda(0.1)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1630
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.6113945
	speed: 0.1329s/iter; left time: 3117.3138s
	iters: 200, epoch: 9 | loss: 0.6141344
	speed: 0.1305s/iter; left time: 3048.4655s
Epoch: 9 cost time: 33.74567627906799
Epoch: 9, Steps: 256 Train Loss: 0.6039 (Forecasting Loss:0.2945 + XiCon Loss:3.0939 x Lambda(0.1)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1630
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6152294
	speed: 0.1391s/iter; left time: 3227.6433s
	iters: 200, epoch: 10 | loss: 0.6000150
	speed: 0.1322s/iter; left time: 3054.1359s
Epoch: 10 cost time: 34.603867530822754
Epoch: 10, Steps: 256 Train Loss: 0.6035 (Forecasting Loss:0.2944 + XiCon Loss:3.0908 x Lambda(0.1)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1629
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.6409683
	speed: 0.1344s/iter; left time: 3083.0489s
	iters: 200, epoch: 11 | loss: 0.6142065
	speed: 0.1283s/iter; left time: 2930.1065s
Epoch: 11 cost time: 33.65552234649658
Epoch: 11, Steps: 256 Train Loss: 0.6038 (Forecasting Loss:0.2944 + XiCon Loss:3.0939 x Lambda(0.1)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1630
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0813453420996666, mae:0.22154046595096588, mape:0.16439221799373627, mspe:0.043741852045059204 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.0272
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.6140877
	speed: 0.1131s/iter; left time: 2884.6382s
	iters: 200, epoch: 1 | loss: 0.5980719
	speed: 0.1154s/iter; left time: 2932.1253s
Epoch: 1 cost time: 29.261022567749023
Epoch: 1, Steps: 256 Train Loss: 0.6235 (Forecasting Loss:0.3029 + XiCon Loss:3.2060 x Lambda(0.1)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1624
Validation loss decreased (inf --> 0.210288).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6269307
	speed: 0.1461s/iter; left time: 3688.9025s
	iters: 200, epoch: 2 | loss: 0.6638607
	speed: 0.1351s/iter; left time: 3397.8183s
Epoch: 2 cost time: 35.873573541641235
Epoch: 2, Steps: 256 Train Loss: 0.6330 (Forecasting Loss:0.3041 + XiCon Loss:3.2896 x Lambda(0.1)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1736
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6055475
	speed: 0.1360s/iter; left time: 3398.3228s
	iters: 200, epoch: 3 | loss: 0.6194310
	speed: 0.1354s/iter; left time: 3369.8670s
Epoch: 3 cost time: 34.3890597820282
Epoch: 3, Steps: 256 Train Loss: 0.6208 (Forecasting Loss:0.2996 + XiCon Loss:3.2125 x Lambda(0.1)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1704
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6122509
	speed: 0.1330s/iter; left time: 3288.7752s
	iters: 200, epoch: 4 | loss: 0.6261476
	speed: 0.1338s/iter; left time: 3294.7001s
Epoch: 4 cost time: 34.38719034194946
Epoch: 4, Steps: 256 Train Loss: 0.6177 (Forecasting Loss:0.2970 + XiCon Loss:3.2073 x Lambda(0.1)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1706
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6072267
	speed: 0.1072s/iter; left time: 2623.3732s
	iters: 200, epoch: 5 | loss: 0.6205830
	speed: 0.1218s/iter; left time: 2968.9988s
Epoch: 5 cost time: 30.639551877975464
Epoch: 5, Steps: 256 Train Loss: 0.6169 (Forecasting Loss:0.2956 + XiCon Loss:3.2131 x Lambda(0.1)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1721
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6304376
	speed: 0.1328s/iter; left time: 3215.5413s
	iters: 200, epoch: 6 | loss: 0.5796567
	speed: 0.1303s/iter; left time: 3143.7092s
Epoch: 6 cost time: 33.94445466995239
Epoch: 6, Steps: 256 Train Loss: 0.6159 (Forecasting Loss:0.2945 + XiCon Loss:3.2143 x Lambda(0.1)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1728
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6271189
	speed: 0.1353s/iter; left time: 3242.7735s
	iters: 200, epoch: 7 | loss: 0.6173036
	speed: 0.1340s/iter; left time: 3196.9023s
Epoch: 7 cost time: 34.61352300643921
Epoch: 7, Steps: 256 Train Loss: 0.6146 (Forecasting Loss:0.2939 + XiCon Loss:3.2060 x Lambda(0.1)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1725
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.6109781
	speed: 0.1351s/iter; left time: 3204.1441s
	iters: 200, epoch: 8 | loss: 0.6064825
	speed: 0.1293s/iter; left time: 3053.0009s
Epoch: 8 cost time: 34.37981700897217
Epoch: 8, Steps: 256 Train Loss: 0.6128 (Forecasting Loss:0.2936 + XiCon Loss:3.1919 x Lambda(0.1)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1725
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.6402770
	speed: 0.1323s/iter; left time: 3103.9716s
	iters: 200, epoch: 9 | loss: 0.6114334
	speed: 0.1274s/iter; left time: 2976.2640s
Epoch: 9 cost time: 33.750019788742065
Epoch: 9, Steps: 256 Train Loss: 0.6136 (Forecasting Loss:0.2935 + XiCon Loss:3.2015 x Lambda(0.1)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1726
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5909313
	speed: 0.1326s/iter; left time: 3075.4411s
	iters: 200, epoch: 10 | loss: 0.5982476
	speed: 0.1283s/iter; left time: 2962.6602s
Epoch: 10 cost time: 33.62481999397278
Epoch: 10, Steps: 256 Train Loss: 0.6128 (Forecasting Loss:0.2933 + XiCon Loss:3.1947 x Lambda(0.1)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1726
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5991278
	speed: 0.1421s/iter; left time: 3260.9054s
	iters: 200, epoch: 11 | loss: 0.6263829
	speed: 0.1275s/iter; left time: 2911.3621s
Epoch: 11 cost time: 34.513784646987915
Epoch: 11, Steps: 256 Train Loss: 0.6143 (Forecasting Loss:0.2933 + XiCon Loss:3.2100 x Lambda(0.1)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1728
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08949559926986694, mae:0.23524101078510284, mape:0.17306353151798248, mspe:0.0469665452837944 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2125
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.6201953
	speed: 0.1237s/iter; left time: 3155.0736s
	iters: 200, epoch: 1 | loss: 0.5986239
	speed: 0.1227s/iter; left time: 3117.0822s
Epoch: 1 cost time: 31.352879762649536
Epoch: 1, Steps: 256 Train Loss: 0.6243 (Forecasting Loss:0.3005 + XiCon Loss:3.2374 x Lambda(0.1)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1591
Validation loss decreased (inf --> 0.205191).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6003535
	speed: 0.1473s/iter; left time: 3717.3345s
	iters: 200, epoch: 2 | loss: 0.6178256
	speed: 0.1556s/iter; left time: 3912.0853s
Epoch: 2 cost time: 38.20005941390991
Epoch: 2, Steps: 256 Train Loss: 0.6377 (Forecasting Loss:0.3061 + XiCon Loss:3.3165 x Lambda(0.1)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1714
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6387237
	speed: 0.1348s/iter; left time: 3368.9173s
	iters: 200, epoch: 3 | loss: 0.6394434
	speed: 0.1359s/iter; left time: 3383.2961s
Epoch: 3 cost time: 34.52301216125488
Epoch: 3, Steps: 256 Train Loss: 0.6228 (Forecasting Loss:0.3005 + XiCon Loss:3.2238 x Lambda(0.1)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6298690
	speed: 0.1344s/iter; left time: 3324.5401s
	iters: 200, epoch: 4 | loss: 0.6176690
	speed: 0.1328s/iter; left time: 3271.6279s
Epoch: 4 cost time: 34.38340878486633
Epoch: 4, Steps: 256 Train Loss: 0.6201 (Forecasting Loss:0.2981 + XiCon Loss:3.2198 x Lambda(0.1)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.1677
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6091468
	speed: 0.1336s/iter; left time: 3271.1870s
	iters: 200, epoch: 5 | loss: 0.6061707
	speed: 0.1325s/iter; left time: 3229.6452s
Epoch: 5 cost time: 34.21825909614563
Epoch: 5, Steps: 256 Train Loss: 0.6161 (Forecasting Loss:0.2967 + XiCon Loss:3.1936 x Lambda(0.1)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1671
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6129276
	speed: 0.1334s/iter; left time: 3232.1089s
	iters: 200, epoch: 6 | loss: 0.6209526
	speed: 0.1291s/iter; left time: 3113.3258s
Epoch: 6 cost time: 33.99350380897522
Epoch: 6, Steps: 256 Train Loss: 0.6127 (Forecasting Loss:0.2960 + XiCon Loss:3.1668 x Lambda(0.1)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1664
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5968354
	speed: 0.1351s/iter; left time: 3238.3521s
	iters: 200, epoch: 7 | loss: 0.6209773
	speed: 0.1305s/iter; left time: 3113.2071s
Epoch: 7 cost time: 34.04213237762451
Epoch: 7, Steps: 256 Train Loss: 0.6114 (Forecasting Loss:0.2955 + XiCon Loss:3.1592 x Lambda(0.1)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1667
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5940531
	speed: 0.1339s/iter; left time: 3174.3044s
	iters: 200, epoch: 8 | loss: 0.6296803
	speed: 0.1300s/iter; left time: 3068.7744s
Epoch: 8 cost time: 34.031351804733276
Epoch: 8, Steps: 256 Train Loss: 0.6108 (Forecasting Loss:0.2951 + XiCon Loss:3.1563 x Lambda(0.1)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1664
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.6176926
	speed: 0.1325s/iter; left time: 3106.4119s
	iters: 200, epoch: 9 | loss: 0.6396435
	speed: 0.1323s/iter; left time: 3088.8766s
Epoch: 9 cost time: 33.947227478027344
Epoch: 9, Steps: 256 Train Loss: 0.6106 (Forecasting Loss:0.2949 + XiCon Loss:3.1571 x Lambda(0.1)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1665
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5896009
	speed: 0.1364s/iter; left time: 3164.6770s
	iters: 200, epoch: 10 | loss: 0.6082456
	speed: 0.1307s/iter; left time: 3018.3531s
Epoch: 10 cost time: 34.20200181007385
Epoch: 10, Steps: 256 Train Loss: 0.6092 (Forecasting Loss:0.2948 + XiCon Loss:3.1443 x Lambda(0.1)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1664
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5939393
	speed: 0.1350s/iter; left time: 3096.2418s
	iters: 200, epoch: 11 | loss: 0.5997475
	speed: 0.1343s/iter; left time: 3067.3914s
Epoch: 11 cost time: 34.463521003723145
Epoch: 11, Steps: 256 Train Loss: 0.6095 (Forecasting Loss:0.2948 + XiCon Loss:3.1470 x Lambda(0.1)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1664
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08726881444454193, mae:0.2308417707681656, mape:0.1706181913614273, mspe:0.04627503454685211 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7103
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.6297755
	speed: 0.1195s/iter; left time: 3047.9473s
	iters: 200, epoch: 1 | loss: 0.6052685
	speed: 0.1167s/iter; left time: 2964.9932s
Epoch: 1 cost time: 29.927860021591187
Epoch: 1, Steps: 256 Train Loss: 0.6230 (Forecasting Loss:0.3007 + XiCon Loss:3.2228 x Lambda(0.1)), Vali MSE Loss: 0.2152 Test MSE Loss: 0.1596
Validation loss decreased (inf --> 0.215176).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6219461
	speed: 0.1156s/iter; left time: 2919.1955s
	iters: 200, epoch: 2 | loss: 0.6163927
	speed: 0.1055s/iter; left time: 2652.0169s
Epoch: 2 cost time: 26.771053314208984
Epoch: 2, Steps: 256 Train Loss: 0.6241 (Forecasting Loss:0.2903 + XiCon Loss:3.3375 x Lambda(0.1)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1680
Validation loss decreased (0.215176 --> 0.195931).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5834779
	speed: 0.1459s/iter; left time: 3646.0928s
	iters: 200, epoch: 3 | loss: 0.5842944
	speed: 0.1484s/iter; left time: 3693.9510s
Epoch: 3 cost time: 37.488505601882935
Epoch: 3, Steps: 256 Train Loss: 0.5898 (Forecasting Loss:0.2657 + XiCon Loss:3.2407 x Lambda(0.1)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1624
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5354159
	speed: 0.1380s/iter; left time: 3413.8081s
	iters: 200, epoch: 4 | loss: 0.5558853
	speed: 0.1539s/iter; left time: 3792.1022s
Epoch: 4 cost time: 37.62295961380005
Epoch: 4, Steps: 256 Train Loss: 0.5622 (Forecasting Loss:0.2472 + XiCon Loss:3.1495 x Lambda(0.1)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1667
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5491626
	speed: 0.1476s/iter; left time: 3612.6050s
	iters: 200, epoch: 5 | loss: 0.5520512
	speed: 0.1489s/iter; left time: 3630.4242s
Epoch: 5 cost time: 37.72388243675232
Epoch: 5, Steps: 256 Train Loss: 0.5494 (Forecasting Loss:0.2344 + XiCon Loss:3.1503 x Lambda(0.1)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1674
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5390455
	speed: 0.1523s/iter; left time: 3689.7275s
	iters: 200, epoch: 6 | loss: 0.5430627
	speed: 0.1443s/iter; left time: 3480.0658s
Epoch: 6 cost time: 35.44872689247131
Epoch: 6, Steps: 256 Train Loss: 0.5416 (Forecasting Loss:0.2270 + XiCon Loss:3.1460 x Lambda(0.1)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1707
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5273569
	speed: 0.1498s/iter; left time: 3590.3077s
	iters: 200, epoch: 7 | loss: 0.5324842
	speed: 0.1528s/iter; left time: 3646.5051s
Epoch: 7 cost time: 38.48447918891907
Epoch: 7, Steps: 256 Train Loss: 0.5370 (Forecasting Loss:0.2228 + XiCon Loss:3.1423 x Lambda(0.1)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1712
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5339431
	speed: 0.1298s/iter; left time: 3076.6662s
	iters: 200, epoch: 8 | loss: 0.5358645
	speed: 0.1113s/iter; left time: 2628.7748s
Epoch: 8 cost time: 32.43097376823425
Epoch: 8, Steps: 256 Train Loss: 0.5350 (Forecasting Loss:0.2207 + XiCon Loss:3.1435 x Lambda(0.1)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.1715
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5323018
	speed: 0.1493s/iter; left time: 3501.3658s
	iters: 200, epoch: 9 | loss: 0.5317664
	speed: 0.1463s/iter; left time: 3416.4097s
Epoch: 9 cost time: 36.63683009147644
Epoch: 9, Steps: 256 Train Loss: 0.5339 (Forecasting Loss:0.2193 + XiCon Loss:3.1453 x Lambda(0.1)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5348942
	speed: 0.1364s/iter; left time: 3163.8727s
	iters: 200, epoch: 10 | loss: 0.5409736
	speed: 0.1519s/iter; left time: 3509.4388s
Epoch: 10 cost time: 37.30611276626587
Epoch: 10, Steps: 256 Train Loss: 0.5335 (Forecasting Loss:0.2191 + XiCon Loss:3.1441 x Lambda(0.1)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.1725
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5303897
	speed: 0.1463s/iter; left time: 3355.8296s
	iters: 200, epoch: 11 | loss: 0.5579122
	speed: 0.0798s/iter; left time: 1821.8084s
Epoch: 11 cost time: 30.739529132843018
Epoch: 11, Steps: 256 Train Loss: 0.5328 (Forecasting Loss:0.2186 + XiCon Loss:3.1412 x Lambda(0.1)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1722
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5442848
	speed: 0.1624s/iter; left time: 3683.8077s
	iters: 200, epoch: 12 | loss: 0.5381148
	speed: 0.1517s/iter; left time: 3427.2471s
Epoch: 12 cost time: 39.38081121444702
Epoch: 12, Steps: 256 Train Loss: 0.5325 (Forecasting Loss:0.2185 + XiCon Loss:3.1405 x Lambda(0.1)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.1726
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09473563730716705, mae:0.24121376872062683, mape:0.17656071484088898, mspe:0.04848060756921768 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0899+-0.00751, MAE:0.2341+-0.01033, MAPE:0.1723+-0.00636, MSPE:0.0470+-0.00283, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2228
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.6726917
	speed: 0.1746s/iter; left time: 4243.1733s
	iters: 200, epoch: 1 | loss: 0.6465262
	speed: 0.1696s/iter; left time: 4105.5525s
Epoch: 1 cost time: 42.64327144622803
Epoch: 1, Steps: 244 Train Loss: 0.6815 (Forecasting Loss:0.3545 + XiCon Loss:3.2694 x Lambda(0.1)), Vali MSE Loss: 0.2335 Test MSE Loss: 0.1510
Validation loss decreased (inf --> 0.233517).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6970467
	speed: 0.2203s/iter; left time: 5300.8533s
	iters: 200, epoch: 2 | loss: 0.6345439
	speed: 0.2181s/iter; left time: 5223.9684s
Epoch: 2 cost time: 53.821089029312134
Epoch: 2, Steps: 244 Train Loss: 0.6747 (Forecasting Loss:0.3562 + XiCon Loss:3.1848 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1613
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.6251518
	speed: 0.2105s/iter; left time: 5011.9806s
	iters: 200, epoch: 3 | loss: 0.5924439
	speed: 0.2127s/iter; left time: 5044.2853s
Epoch: 3 cost time: 51.516932010650635
Epoch: 3, Steps: 244 Train Loss: 0.6210 (Forecasting Loss:0.3111 + XiCon Loss:3.0988 x Lambda(0.1)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.1567
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.6090463
	speed: 0.2063s/iter; left time: 4861.6770s
	iters: 200, epoch: 4 | loss: 0.5926679
	speed: 0.1957s/iter; left time: 4591.9299s
Epoch: 4 cost time: 49.447341203689575
Epoch: 4, Steps: 244 Train Loss: 0.6007 (Forecasting Loss:0.2885 + XiCon Loss:3.1215 x Lambda(0.1)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.1684
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5817549
	speed: 0.2027s/iter; left time: 4727.6479s
	iters: 200, epoch: 5 | loss: 0.5790551
	speed: 0.1989s/iter; left time: 4618.8637s
Epoch: 5 cost time: 49.22794508934021
Epoch: 5, Steps: 244 Train Loss: 0.5869 (Forecasting Loss:0.2747 + XiCon Loss:3.1215 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.1642
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5684320
	speed: 0.1988s/iter; left time: 4588.3144s
	iters: 200, epoch: 6 | loss: 0.5890650
	speed: 0.2016s/iter; left time: 4632.0999s
Epoch: 6 cost time: 48.78809475898743
Epoch: 6, Steps: 244 Train Loss: 0.5811 (Forecasting Loss:0.2695 + XiCon Loss:3.1162 x Lambda(0.1)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.1655
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5764751
	speed: 0.2078s/iter; left time: 4745.1796s
	iters: 200, epoch: 7 | loss: 0.5699219
	speed: 0.2006s/iter; left time: 4561.5605s
Epoch: 7 cost time: 49.80372214317322
Epoch: 7, Steps: 244 Train Loss: 0.5781 (Forecasting Loss:0.2666 + XiCon Loss:3.1144 x Lambda(0.1)), Vali MSE Loss: 0.2710 Test MSE Loss: 0.1609
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5878775
	speed: 0.2025s/iter; left time: 4574.7147s
	iters: 200, epoch: 8 | loss: 0.5813212
	speed: 0.2010s/iter; left time: 4521.2801s
Epoch: 8 cost time: 49.34811305999756
Epoch: 8, Steps: 244 Train Loss: 0.5765 (Forecasting Loss:0.2651 + XiCon Loss:3.1141 x Lambda(0.1)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.1593
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5620128
	speed: 0.2036s/iter; left time: 4549.3383s
	iters: 200, epoch: 9 | loss: 0.5729914
	speed: 0.1993s/iter; left time: 4433.7350s
Epoch: 9 cost time: 49.34691333770752
Epoch: 9, Steps: 244 Train Loss: 0.5756 (Forecasting Loss:0.2644 + XiCon Loss:3.1113 x Lambda(0.1)), Vali MSE Loss: 0.2744 Test MSE Loss: 0.1636
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5765946
	speed: 0.2040s/iter; left time: 4510.0113s
	iters: 200, epoch: 10 | loss: 0.5768532
	speed: 0.2007s/iter; left time: 4415.3895s
Epoch: 10 cost time: 49.41487383842468
Epoch: 10, Steps: 244 Train Loss: 0.5749 (Forecasting Loss:0.2636 + XiCon Loss:3.1131 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.1631
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5573794
	speed: 0.2035s/iter; left time: 4448.6871s
	iters: 200, epoch: 11 | loss: 0.5727634
	speed: 0.1973s/iter; left time: 4293.7467s
Epoch: 11 cost time: 48.98757290840149
Epoch: 11, Steps: 244 Train Loss: 0.5748 (Forecasting Loss:0.2637 + XiCon Loss:3.1106 x Lambda(0.1)), Vali MSE Loss: 0.2762 Test MSE Loss: 0.1618
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.07977328449487686, mae:0.22232617437839508, mape:0.1592770516872406, mspe:0.03901088237762451 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8196
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.6675730
	speed: 0.1659s/iter; left time: 4030.5677s
	iters: 200, epoch: 1 | loss: 0.6640779
	speed: 0.1658s/iter; left time: 4012.3367s
Epoch: 1 cost time: 40.432717084884644
Epoch: 1, Steps: 244 Train Loss: 0.6711 (Forecasting Loss:0.3390 + XiCon Loss:3.3216 x Lambda(0.1)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1561
Validation loss decreased (inf --> 0.213689).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6483259
	speed: 0.2265s/iter; left time: 5448.3116s
	iters: 200, epoch: 2 | loss: 0.6508662
	speed: 0.2309s/iter; left time: 5531.3644s
Epoch: 2 cost time: 55.697779178619385
Epoch: 2, Steps: 244 Train Loss: 0.6628 (Forecasting Loss:0.3428 + XiCon Loss:3.2002 x Lambda(0.1)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.6050819
	speed: 0.2161s/iter; left time: 5147.0488s
	iters: 200, epoch: 3 | loss: 0.6008797
	speed: 0.2178s/iter; left time: 5164.7673s
Epoch: 3 cost time: 52.978370666503906
Epoch: 3, Steps: 244 Train Loss: 0.6157 (Forecasting Loss:0.3084 + XiCon Loss:3.0727 x Lambda(0.1)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.1544
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.6044431
	speed: 0.2137s/iter; left time: 5037.6081s
	iters: 200, epoch: 4 | loss: 0.5660764
	speed: 0.2169s/iter; left time: 5091.5225s
Epoch: 4 cost time: 52.63031244277954
Epoch: 4, Steps: 244 Train Loss: 0.6023 (Forecasting Loss:0.2987 + XiCon Loss:3.0358 x Lambda(0.1)), Vali MSE Loss: 0.2942 Test MSE Loss: 0.1526
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.6148931
	speed: 0.2128s/iter; left time: 4963.4283s
	iters: 200, epoch: 5 | loss: 0.5994514
	speed: 0.2131s/iter; left time: 4948.3866s
Epoch: 5 cost time: 51.95416522026062
Epoch: 5, Steps: 244 Train Loss: 0.5946 (Forecasting Loss:0.2921 + XiCon Loss:3.0249 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.1512
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5806099
	speed: 0.2134s/iter; left time: 4924.4605s
	iters: 200, epoch: 6 | loss: 0.5905274
	speed: 0.2145s/iter; left time: 4929.8815s
Epoch: 6 cost time: 52.23158669471741
Epoch: 6, Steps: 244 Train Loss: 0.5893 (Forecasting Loss:0.2872 + XiCon Loss:3.0207 x Lambda(0.1)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.1519
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5772181
	speed: 0.2145s/iter; left time: 4898.6699s
	iters: 200, epoch: 7 | loss: 0.5766485
	speed: 0.2137s/iter; left time: 4859.2190s
Epoch: 7 cost time: 52.2396125793457
Epoch: 7, Steps: 244 Train Loss: 0.5864 (Forecasting Loss:0.2846 + XiCon Loss:3.0176 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1520
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5930234
	speed: 0.2145s/iter; left time: 4846.0765s
	iters: 200, epoch: 8 | loss: 0.5704485
	speed: 0.2104s/iter; left time: 4732.9325s
Epoch: 8 cost time: 51.42439246177673
Epoch: 8, Steps: 244 Train Loss: 0.5845 (Forecasting Loss:0.2829 + XiCon Loss:3.0165 x Lambda(0.1)), Vali MSE Loss: 0.2709 Test MSE Loss: 0.1514
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5866135
	speed: 0.1360s/iter; left time: 3039.8098s
	iters: 200, epoch: 9 | loss: 0.5845969
	speed: 0.2034s/iter; left time: 4524.7897s
Epoch: 9 cost time: 43.118157148361206
Epoch: 9, Steps: 244 Train Loss: 0.5839 (Forecasting Loss:0.2822 + XiCon Loss:3.0171 x Lambda(0.1)), Vali MSE Loss: 0.2686 Test MSE Loss: 0.1520
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5820097
	speed: 0.2101s/iter; left time: 4643.4296s
	iters: 200, epoch: 10 | loss: 0.5714357
	speed: 0.2046s/iter; left time: 4501.7904s
Epoch: 10 cost time: 50.905550479888916
Epoch: 10, Steps: 244 Train Loss: 0.5833 (Forecasting Loss:0.2817 + XiCon Loss:3.0161 x Lambda(0.1)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.1520
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5767124
	speed: 0.1965s/iter; left time: 4296.7793s
	iters: 200, epoch: 11 | loss: 0.5770262
	speed: 0.1606s/iter; left time: 3495.2558s
Epoch: 11 cost time: 44.90648150444031
Epoch: 11, Steps: 244 Train Loss: 0.5835 (Forecasting Loss:0.2816 + XiCon Loss:3.0185 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.1520
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08338872343301773, mae:0.2288329303264618, mape:0.16725893318653107, mspe:0.044241584837436676 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8231
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.7005255
	speed: 0.1627s/iter; left time: 3953.6356s
	iters: 200, epoch: 1 | loss: 0.6774834
	speed: 0.1645s/iter; left time: 3980.3973s
Epoch: 1 cost time: 40.062615633010864
Epoch: 1, Steps: 244 Train Loss: 0.6848 (Forecasting Loss:0.3604 + XiCon Loss:3.2449 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.1647
Validation loss decreased (inf --> 0.256783).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6135316
	speed: 0.1622s/iter; left time: 3901.4812s
	iters: 200, epoch: 2 | loss: 0.6157253
	speed: 0.2053s/iter; left time: 4919.0340s
Epoch: 2 cost time: 45.86182999610901
Epoch: 2, Steps: 244 Train Loss: 0.6344 (Forecasting Loss:0.3101 + XiCon Loss:3.2429 x Lambda(0.1)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.1667
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5956969
	speed: 0.1921s/iter; left time: 4575.0635s
	iters: 200, epoch: 3 | loss: 0.5746964
	speed: 0.2013s/iter; left time: 4773.8643s
Epoch: 3 cost time: 48.685407876968384
Epoch: 3, Steps: 244 Train Loss: 0.5927 (Forecasting Loss:0.2762 + XiCon Loss:3.1650 x Lambda(0.1)), Vali MSE Loss: 0.3671 Test MSE Loss: 0.1562
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5753807
	speed: 0.1748s/iter; left time: 4119.8957s
	iters: 200, epoch: 4 | loss: 0.5808045
	speed: 0.1490s/iter; left time: 3496.8894s
Epoch: 4 cost time: 41.45544791221619
Epoch: 4, Steps: 244 Train Loss: 0.5807 (Forecasting Loss:0.2669 + XiCon Loss:3.1376 x Lambda(0.1)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.1579
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5637841
	speed: 0.1983s/iter; left time: 4625.2032s
	iters: 200, epoch: 5 | loss: 0.5769588
	speed: 0.1447s/iter; left time: 3361.5683s
Epoch: 5 cost time: 40.32962226867676
Epoch: 5, Steps: 244 Train Loss: 0.5708 (Forecasting Loss:0.2594 + XiCon Loss:3.1141 x Lambda(0.1)), Vali MSE Loss: 0.3189 Test MSE Loss: 0.1515
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5740265
	speed: 0.2037s/iter; left time: 4701.3097s
	iters: 200, epoch: 6 | loss: 0.5567433
	speed: 0.1963s/iter; left time: 4510.0505s
Epoch: 6 cost time: 46.97718048095703
Epoch: 6, Steps: 244 Train Loss: 0.5663 (Forecasting Loss:0.2554 + XiCon Loss:3.1086 x Lambda(0.1)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.1526
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5893316
	speed: 0.1888s/iter; left time: 4311.6625s
	iters: 200, epoch: 7 | loss: 0.5640540
	speed: 0.2003s/iter; left time: 4554.2644s
Epoch: 7 cost time: 48.004197120666504
Epoch: 7, Steps: 244 Train Loss: 0.5640 (Forecasting Loss:0.2535 + XiCon Loss:3.1050 x Lambda(0.1)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.1535
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5621027
	speed: 0.1228s/iter; left time: 2775.1230s
	iters: 200, epoch: 8 | loss: 0.5599625
	speed: 0.1995s/iter; left time: 4487.9405s
Epoch: 8 cost time: 41.17272758483887
Epoch: 8, Steps: 244 Train Loss: 0.5630 (Forecasting Loss:0.2528 + XiCon Loss:3.1013 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.1534
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5696714
	speed: 0.1960s/iter; left time: 4380.2091s
	iters: 200, epoch: 9 | loss: 0.5632135
	speed: 0.1961s/iter; left time: 4362.3005s
Epoch: 9 cost time: 48.08774375915527
Epoch: 9, Steps: 244 Train Loss: 0.5621 (Forecasting Loss:0.2520 + XiCon Loss:3.1007 x Lambda(0.1)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.1530
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5740840
	speed: 0.1902s/iter; left time: 4203.7061s
	iters: 200, epoch: 10 | loss: 0.5566982
	speed: 0.2001s/iter; left time: 4402.9026s
Epoch: 10 cost time: 48.12860941886902
Epoch: 10, Steps: 244 Train Loss: 0.5615 (Forecasting Loss:0.2519 + XiCon Loss:3.0960 x Lambda(0.1)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.1530
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5639817
	speed: 0.1888s/iter; left time: 4127.4303s
	iters: 200, epoch: 11 | loss: 0.5715120
	speed: 0.1955s/iter; left time: 4254.6140s
Epoch: 11 cost time: 47.16751003265381
Epoch: 11, Steps: 244 Train Loss: 0.5613 (Forecasting Loss:0.2516 + XiCon Loss:3.0972 x Lambda(0.1)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.1528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09129715710878372, mae:0.23809006810188293, mape:0.1703539788722992, mspe:0.044518765062093735 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6269
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.6922888
	speed: 0.1625s/iter; left time: 3948.9502s
	iters: 200, epoch: 1 | loss: 0.6558267
	speed: 0.1700s/iter; left time: 4114.5928s
Epoch: 1 cost time: 40.23104906082153
Epoch: 1, Steps: 244 Train Loss: 0.6769 (Forecasting Loss:0.3521 + XiCon Loss:3.2475 x Lambda(0.1)), Vali MSE Loss: 0.2331 Test MSE Loss: 0.1530
Validation loss decreased (inf --> 0.233111).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6600899
	speed: 0.2271s/iter; left time: 5462.1514s
	iters: 200, epoch: 2 | loss: 0.6140919
	speed: 0.2240s/iter; left time: 5365.4454s
Epoch: 2 cost time: 55.646039962768555
Epoch: 2, Steps: 244 Train Loss: 0.6484 (Forecasting Loss:0.3237 + XiCon Loss:3.2474 x Lambda(0.1)), Vali MSE Loss: 0.2843 Test MSE Loss: 0.1817
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.6272896
	speed: 0.2300s/iter; left time: 5476.4537s
	iters: 200, epoch: 3 | loss: 0.5982010
	speed: 0.2211s/iter; left time: 5242.1010s
Epoch: 3 cost time: 55.2450315952301
Epoch: 3, Steps: 244 Train Loss: 0.5972 (Forecasting Loss:0.2813 + XiCon Loss:3.1598 x Lambda(0.1)), Vali MSE Loss: 0.3673 Test MSE Loss: 0.1582
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5696100
	speed: 0.2275s/iter; left time: 5361.5611s
	iters: 200, epoch: 4 | loss: 0.5738310
	speed: 0.2257s/iter; left time: 5296.3490s
Epoch: 4 cost time: 55.278300523757935
Epoch: 4, Steps: 244 Train Loss: 0.5760 (Forecasting Loss:0.2656 + XiCon Loss:3.1047 x Lambda(0.1)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.1580
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5667647
	speed: 0.2314s/iter; left time: 5396.2508s
	iters: 200, epoch: 5 | loss: 0.5655186
	speed: 0.2310s/iter; left time: 5365.3399s
Epoch: 5 cost time: 56.375903606414795
Epoch: 5, Steps: 244 Train Loss: 0.5670 (Forecasting Loss:0.2577 + XiCon Loss:3.0937 x Lambda(0.1)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.1566
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5687711
	speed: 0.2315s/iter; left time: 5344.3349s
	iters: 200, epoch: 6 | loss: 0.5591211
	speed: 0.2280s/iter; left time: 5240.0777s
Epoch: 6 cost time: 56.05798101425171
Epoch: 6, Steps: 244 Train Loss: 0.5627 (Forecasting Loss:0.2542 + XiCon Loss:3.0846 x Lambda(0.1)), Vali MSE Loss: 0.3343 Test MSE Loss: 0.1570
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5637175
	speed: 0.2303s/iter; left time: 5258.6202s
	iters: 200, epoch: 7 | loss: 0.5583756
	speed: 0.2261s/iter; left time: 5141.9324s
Epoch: 7 cost time: 55.91668677330017
Epoch: 7, Steps: 244 Train Loss: 0.5609 (Forecasting Loss:0.2526 + XiCon Loss:3.0833 x Lambda(0.1)), Vali MSE Loss: 0.3420 Test MSE Loss: 0.1578
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5588797
	speed: 0.2266s/iter; left time: 5120.0774s
	iters: 200, epoch: 8 | loss: 0.5677198
	speed: 0.2227s/iter; left time: 5009.4116s
Epoch: 8 cost time: 55.08503842353821
Epoch: 8, Steps: 244 Train Loss: 0.5600 (Forecasting Loss:0.2516 + XiCon Loss:3.0846 x Lambda(0.1)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.1600
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5527359
	speed: 0.2300s/iter; left time: 5139.5614s
	iters: 200, epoch: 9 | loss: 0.5539370
	speed: 0.2274s/iter; left time: 5059.0854s
Epoch: 9 cost time: 55.83213567733765
Epoch: 9, Steps: 244 Train Loss: 0.5591 (Forecasting Loss:0.2510 + XiCon Loss:3.0804 x Lambda(0.1)), Vali MSE Loss: 0.3433 Test MSE Loss: 0.1569
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5697384
	speed: 0.2272s/iter; left time: 5021.5635s
	iters: 200, epoch: 10 | loss: 0.5696295
	speed: 0.2270s/iter; left time: 4995.1656s
Epoch: 10 cost time: 55.68483543395996
Epoch: 10, Steps: 244 Train Loss: 0.5584 (Forecasting Loss:0.2507 + XiCon Loss:3.0773 x Lambda(0.1)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.1578
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5680805
	speed: 0.2252s/iter; left time: 4923.0194s
	iters: 200, epoch: 11 | loss: 0.5549869
	speed: 0.1655s/iter; left time: 3602.5166s
Epoch: 11 cost time: 49.065823554992676
Epoch: 11, Steps: 244 Train Loss: 0.5588 (Forecasting Loss:0.2507 + XiCon Loss:3.0814 x Lambda(0.1)), Vali MSE Loss: 0.3447 Test MSE Loss: 0.1578
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08070457726716995, mae:0.2251986563205719, mape:0.16237738728523254, mspe:0.04052988812327385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9261
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.6835819
	speed: 0.1591s/iter; left time: 3865.7820s
	iters: 200, epoch: 1 | loss: 0.6079496
	speed: 0.1603s/iter; left time: 3878.5176s
Epoch: 1 cost time: 39.49737763404846
Epoch: 1, Steps: 244 Train Loss: 0.6768 (Forecasting Loss:0.3449 + XiCon Loss:3.3190 x Lambda(0.1)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1685
Validation loss decreased (inf --> 0.251793).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6386446
	speed: 0.2069s/iter; left time: 4976.3884s
	iters: 200, epoch: 2 | loss: 0.6196164
	speed: 0.2262s/iter; left time: 5419.4410s
Epoch: 2 cost time: 53.19426417350769
Epoch: 2, Steps: 244 Train Loss: 0.6455 (Forecasting Loss:0.3172 + XiCon Loss:3.2828 x Lambda(0.1)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5783950
	speed: 0.2207s/iter; left time: 5254.6022s
	iters: 200, epoch: 3 | loss: 0.6096979
	speed: 0.2175s/iter; left time: 5156.6474s
Epoch: 3 cost time: 53.58467221260071
Epoch: 3, Steps: 244 Train Loss: 0.5965 (Forecasting Loss:0.2742 + XiCon Loss:3.2232 x Lambda(0.1)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1578
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5768830
	speed: 0.2185s/iter; left time: 5150.7242s
	iters: 200, epoch: 4 | loss: 0.5723221
	speed: 0.2168s/iter; left time: 5088.1657s
Epoch: 4 cost time: 53.44357776641846
Epoch: 4, Steps: 244 Train Loss: 0.5754 (Forecasting Loss:0.2586 + XiCon Loss:3.1682 x Lambda(0.1)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.1530
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5739588
	speed: 0.2202s/iter; left time: 5135.7962s
	iters: 200, epoch: 5 | loss: 0.5565958
	speed: 0.2246s/iter; left time: 5216.9477s
Epoch: 5 cost time: 54.18994331359863
Epoch: 5, Steps: 244 Train Loss: 0.5626 (Forecasting Loss:0.2503 + XiCon Loss:3.1230 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1539
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5670967
	speed: 0.2202s/iter; left time: 5082.3677s
	iters: 200, epoch: 6 | loss: 0.5468732
	speed: 0.2157s/iter; left time: 4957.8508s
Epoch: 6 cost time: 53.40735387802124
Epoch: 6, Steps: 244 Train Loss: 0.5551 (Forecasting Loss:0.2447 + XiCon Loss:3.1041 x Lambda(0.1)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1519
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5403104
	speed: 0.2272s/iter; left time: 5189.4905s
	iters: 200, epoch: 7 | loss: 0.5463964
	speed: 0.2164s/iter; left time: 4919.4373s
Epoch: 7 cost time: 54.06749415397644
Epoch: 7, Steps: 244 Train Loss: 0.5513 (Forecasting Loss:0.2418 + XiCon Loss:3.0946 x Lambda(0.1)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.1524
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5524613
	speed: 0.2182s/iter; left time: 4929.9019s
	iters: 200, epoch: 8 | loss: 0.5431236
	speed: 0.2164s/iter; left time: 4868.1364s
Epoch: 8 cost time: 53.01439452171326
Epoch: 8, Steps: 244 Train Loss: 0.5496 (Forecasting Loss:0.2403 + XiCon Loss:3.0934 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.1518
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5546591
	speed: 0.1747s/iter; left time: 3903.8795s
	iters: 200, epoch: 9 | loss: 0.5474356
	speed: 0.2188s/iter; left time: 4868.9513s
Epoch: 9 cost time: 48.87270426750183
Epoch: 9, Steps: 244 Train Loss: 0.5488 (Forecasting Loss:0.2396 + XiCon Loss:3.0921 x Lambda(0.1)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1520
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5527453
	speed: 0.2145s/iter; left time: 4742.5417s
	iters: 200, epoch: 10 | loss: 0.5405013
	speed: 0.2132s/iter; left time: 4691.6287s
Epoch: 10 cost time: 52.41201877593994
Epoch: 10, Steps: 244 Train Loss: 0.5478 (Forecasting Loss:0.2392 + XiCon Loss:3.0862 x Lambda(0.1)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.1521
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5599904
	speed: 0.2130s/iter; left time: 4655.9512s
	iters: 200, epoch: 11 | loss: 0.5514383
	speed: 0.2085s/iter; left time: 4537.5594s
Epoch: 11 cost time: 52.1417818069458
Epoch: 11, Steps: 244 Train Loss: 0.5475 (Forecasting Loss:0.2388 + XiCon Loss:3.0867 x Lambda(0.1)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1521
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09503103792667389, mae:0.24198050796985626, mape:0.1730586588382721, mspe:0.04609249532222748 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0860+-0.00840, MAE:0.2313+-0.01046, MAPE:0.1665+-0.00701, MSPE:0.0429+-0.00369, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7853
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7688196
	speed: 0.1552s/iter; left time: 3600.1331s
	iters: 200, epoch: 1 | loss: 0.7479660
	speed: 0.1493s/iter; left time: 3448.4093s
Epoch: 1 cost time: 35.54298281669617
Epoch: 1, Steps: 233 Train Loss: 0.7702 (Forecasting Loss:0.4292 + XiCon Loss:3.4097 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1704
Validation loss decreased (inf --> 0.299191).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6752990
	speed: 0.1500s/iter; left time: 3445.4317s
	iters: 200, epoch: 2 | loss: 0.6196583
	speed: 0.1546s/iter; left time: 3534.7366s
Epoch: 2 cost time: 35.711079359054565
Epoch: 2, Steps: 233 Train Loss: 0.6631 (Forecasting Loss:0.3345 + XiCon Loss:3.2859 x Lambda(0.1)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1616
Validation loss decreased (0.299191 --> 0.239441).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6153690
	speed: 0.1574s/iter; left time: 3578.1424s
	iters: 200, epoch: 3 | loss: 0.6033499
	speed: 0.1521s/iter; left time: 3442.5912s
Epoch: 3 cost time: 35.80860161781311
Epoch: 3, Steps: 233 Train Loss: 0.6085 (Forecasting Loss:0.2853 + XiCon Loss:3.2319 x Lambda(0.1)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1553
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6007714
	speed: 0.1586s/iter; left time: 3568.5142s
	iters: 200, epoch: 4 | loss: 0.5943062
	speed: 0.1566s/iter; left time: 3508.3050s
Epoch: 4 cost time: 36.462610483169556
Epoch: 4, Steps: 233 Train Loss: 0.5983 (Forecasting Loss:0.2769 + XiCon Loss:3.2145 x Lambda(0.1)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.1617
Validation loss decreased (0.239441 --> 0.229381).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5925666
	speed: 0.1623s/iter; left time: 3615.1497s
	iters: 200, epoch: 5 | loss: 0.5884839
	speed: 0.1565s/iter; left time: 3470.2181s
Epoch: 5 cost time: 37.00796842575073
Epoch: 5, Steps: 233 Train Loss: 0.5934 (Forecasting Loss:0.2728 + XiCon Loss:3.2055 x Lambda(0.1)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1529
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5999104
	speed: 0.1536s/iter; left time: 3385.5541s
	iters: 200, epoch: 6 | loss: 0.5910619
	speed: 0.1556s/iter; left time: 3413.0772s
Epoch: 6 cost time: 36.16504096984863
Epoch: 6, Steps: 233 Train Loss: 0.5910 (Forecasting Loss:0.2708 + XiCon Loss:3.2023 x Lambda(0.1)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.1577
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6060370
	speed: 0.1511s/iter; left time: 3293.8663s
	iters: 200, epoch: 7 | loss: 0.6014415
	speed: 0.1568s/iter; left time: 3403.4807s
Epoch: 7 cost time: 35.88691973686218
Epoch: 7, Steps: 233 Train Loss: 0.5895 (Forecasting Loss:0.2696 + XiCon Loss:3.1990 x Lambda(0.1)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1563
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5738435
	speed: 0.1540s/iter; left time: 3321.5184s
	iters: 200, epoch: 8 | loss: 0.6012250
	speed: 0.1560s/iter; left time: 3349.1890s
Epoch: 8 cost time: 36.34648060798645
Epoch: 8, Steps: 233 Train Loss: 0.5888 (Forecasting Loss:0.2690 + XiCon Loss:3.1978 x Lambda(0.1)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.1567
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5757810
	speed: 0.1587s/iter; left time: 3385.7562s
	iters: 200, epoch: 9 | loss: 0.5968078
	speed: 0.1490s/iter; left time: 3163.6889s
Epoch: 9 cost time: 36.0291063785553
Epoch: 9, Steps: 233 Train Loss: 0.5885 (Forecasting Loss:0.2687 + XiCon Loss:3.1977 x Lambda(0.1)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1576
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5849032
	speed: 0.1555s/iter; left time: 3282.7061s
	iters: 200, epoch: 10 | loss: 0.5876404
	speed: 0.1531s/iter; left time: 3215.9346s
Epoch: 10 cost time: 35.672032833099365
Epoch: 10, Steps: 233 Train Loss: 0.5881 (Forecasting Loss:0.2683 + XiCon Loss:3.1978 x Lambda(0.1)), Vali MSE Loss: 0.2448 Test MSE Loss: 0.1559
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.6009842
	speed: 0.1593s/iter; left time: 3325.4940s
	iters: 200, epoch: 11 | loss: 0.5933786
	speed: 0.1536s/iter; left time: 3190.9911s
Epoch: 11 cost time: 36.38229537010193
Epoch: 11, Steps: 233 Train Loss: 0.5882 (Forecasting Loss:0.2684 + XiCon Loss:3.1972 x Lambda(0.1)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.1571
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5915672
	speed: 0.1601s/iter; left time: 3303.1498s
	iters: 200, epoch: 12 | loss: 0.5671108
	speed: 0.1540s/iter; left time: 3163.3960s
Epoch: 12 cost time: 36.64968299865723
Epoch: 12, Steps: 233 Train Loss: 0.5879 (Forecasting Loss:0.2682 + XiCon Loss:3.1966 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1572
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5938309
	speed: 0.1512s/iter; left time: 3084.4669s
	iters: 200, epoch: 13 | loss: 0.5905378
	speed: 0.1569s/iter; left time: 3186.1024s
Epoch: 13 cost time: 35.979620933532715
Epoch: 13, Steps: 233 Train Loss: 0.5878 (Forecasting Loss:0.2682 + XiCon Loss:3.1964 x Lambda(0.1)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1566
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5827405
	speed: 0.1518s/iter; left time: 3061.9432s
	iters: 200, epoch: 14 | loss: 0.5755481
	speed: 0.1574s/iter; left time: 3159.2732s
Epoch: 14 cost time: 36.27626085281372
Epoch: 14, Steps: 233 Train Loss: 0.5883 (Forecasting Loss:0.2684 + XiCon Loss:3.1988 x Lambda(0.1)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1569
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08790545910596848, mae:0.23551198840141296, mape:0.1676974892616272, mspe:0.04289422929286957 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7962
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7810479
	speed: 0.1538s/iter; left time: 3568.2809s
	iters: 200, epoch: 1 | loss: 0.7317978
	speed: 0.1535s/iter; left time: 3546.5529s
Epoch: 1 cost time: 35.73931622505188
Epoch: 1, Steps: 233 Train Loss: 0.7671 (Forecasting Loss:0.4272 + XiCon Loss:3.3992 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.1701
Validation loss decreased (inf --> 0.301447).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6588473
	speed: 0.1558s/iter; left time: 3577.3816s
	iters: 200, epoch: 2 | loss: 0.6274354
	speed: 0.1558s/iter; left time: 3563.1537s
Epoch: 2 cost time: 36.42345666885376
Epoch: 2, Steps: 233 Train Loss: 0.6604 (Forecasting Loss:0.3325 + XiCon Loss:3.2783 x Lambda(0.1)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.1435
Validation loss decreased (0.301447 --> 0.241649).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6103384
	speed: 0.1527s/iter; left time: 3470.8120s
	iters: 200, epoch: 3 | loss: 0.6115848
	speed: 0.1521s/iter; left time: 3442.1357s
Epoch: 3 cost time: 35.57760238647461
Epoch: 3, Steps: 233 Train Loss: 0.6105 (Forecasting Loss:0.2860 + XiCon Loss:3.2446 x Lambda(0.1)), Vali MSE Loss: 0.2383 Test MSE Loss: 0.1470
Validation loss decreased (0.241649 --> 0.238344).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6014005
	speed: 0.1552s/iter; left time: 3491.3276s
	iters: 200, epoch: 4 | loss: 0.5917084
	speed: 0.1582s/iter; left time: 3544.6624s
Epoch: 4 cost time: 36.668832778930664
Epoch: 4, Steps: 233 Train Loss: 0.5979 (Forecasting Loss:0.2739 + XiCon Loss:3.2398 x Lambda(0.1)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1468
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5894383
	speed: 0.1527s/iter; left time: 3399.3822s
	iters: 200, epoch: 5 | loss: 0.5778757
	speed: 0.1270s/iter; left time: 2816.1820s
Epoch: 5 cost time: 33.235594034194946
Epoch: 5, Steps: 233 Train Loss: 0.5909 (Forecasting Loss:0.2674 + XiCon Loss:3.2355 x Lambda(0.1)), Vali MSE Loss: 0.2433 Test MSE Loss: 0.1482
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5916051
	speed: 0.1066s/iter; left time: 2348.9272s
	iters: 200, epoch: 6 | loss: 0.5817641
	speed: 0.1555s/iter; left time: 3409.9878s
Epoch: 6 cost time: 31.498597621917725
Epoch: 6, Steps: 233 Train Loss: 0.5877 (Forecasting Loss:0.2644 + XiCon Loss:3.2330 x Lambda(0.1)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.1459
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5688826
	speed: 0.1558s/iter; left time: 3396.8297s
	iters: 200, epoch: 7 | loss: 0.5948802
	speed: 0.1399s/iter; left time: 3036.8300s
Epoch: 7 cost time: 34.7337167263031
Epoch: 7, Steps: 233 Train Loss: 0.5858 (Forecasting Loss:0.2626 + XiCon Loss:3.2314 x Lambda(0.1)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1480
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5887390
	speed: 0.1657s/iter; left time: 3574.2512s
	iters: 200, epoch: 8 | loss: 0.5757681
	speed: 0.1259s/iter; left time: 2703.7389s
Epoch: 8 cost time: 31.905468463897705
Epoch: 8, Steps: 233 Train Loss: 0.5849 (Forecasting Loss:0.2619 + XiCon Loss:3.2308 x Lambda(0.1)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.1461
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5913798
	speed: 0.1564s/iter; left time: 3336.6099s
	iters: 200, epoch: 9 | loss: 0.5899777
	speed: 0.1604s/iter; left time: 3405.7517s
Epoch: 9 cost time: 36.90553569793701
Epoch: 9, Steps: 233 Train Loss: 0.5843 (Forecasting Loss:0.2614 + XiCon Loss:3.2289 x Lambda(0.1)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1479
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5974959
	speed: 0.1000s/iter; left time: 2110.6349s
	iters: 200, epoch: 10 | loss: 0.5753866
	speed: 0.1246s/iter; left time: 2617.5761s
Epoch: 10 cost time: 27.84676694869995
Epoch: 10, Steps: 233 Train Loss: 0.5844 (Forecasting Loss:0.2615 + XiCon Loss:3.2289 x Lambda(0.1)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1476
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5897721
	speed: 0.1582s/iter; left time: 3302.5124s
	iters: 200, epoch: 11 | loss: 0.5768157
	speed: 0.1387s/iter; left time: 2881.7565s
Epoch: 11 cost time: 32.45063781738281
Epoch: 11, Steps: 233 Train Loss: 0.5840 (Forecasting Loss:0.2611 + XiCon Loss:3.2289 x Lambda(0.1)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.1476
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5909498
	speed: 0.1550s/iter; left time: 3199.1660s
	iters: 200, epoch: 12 | loss: 0.5876645
	speed: 0.1532s/iter; left time: 3146.5452s
Epoch: 12 cost time: 35.95133876800537
Epoch: 12, Steps: 233 Train Loss: 0.5839 (Forecasting Loss:0.2610 + XiCon Loss:3.2294 x Lambda(0.1)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1473
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5828697
	speed: 0.1174s/iter; left time: 2395.8858s
	iters: 200, epoch: 13 | loss: 0.5920325
	speed: 0.1174s/iter; left time: 2383.9086s
Epoch: 13 cost time: 28.45612382888794
Epoch: 13, Steps: 233 Train Loss: 0.5844 (Forecasting Loss:0.2614 + XiCon Loss:3.2300 x Lambda(0.1)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1472
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.07575783133506775, mae:0.21831053495407104, mape:0.15791334211826324, mspe:0.03980102017521858 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9604
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7782025
	speed: 0.0923s/iter; left time: 2140.9156s
	iters: 200, epoch: 1 | loss: 0.7235440
	speed: 0.1060s/iter; left time: 2448.3079s
Epoch: 1 cost time: 24.50153112411499
Epoch: 1, Steps: 233 Train Loss: 0.7709 (Forecasting Loss:0.4352 + XiCon Loss:3.3575 x Lambda(0.1)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.1665
Validation loss decreased (inf --> 0.281487).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6595454
	speed: 0.1492s/iter; left time: 3426.4972s
	iters: 200, epoch: 2 | loss: 0.6187692
	speed: 0.1385s/iter; left time: 3168.2734s
Epoch: 2 cost time: 33.38219404220581
Epoch: 2, Steps: 233 Train Loss: 0.6588 (Forecasting Loss:0.3341 + XiCon Loss:3.2471 x Lambda(0.1)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1724
Validation loss decreased (0.281487 --> 0.240767).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6036676
	speed: 0.1002s/iter; left time: 2278.4170s
	iters: 200, epoch: 3 | loss: 0.5867383
	speed: 0.1405s/iter; left time: 3179.3340s
Epoch: 3 cost time: 28.97234869003296
Epoch: 3, Steps: 233 Train Loss: 0.6018 (Forecasting Loss:0.2783 + XiCon Loss:3.2348 x Lambda(0.1)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.1676
Validation loss decreased (0.240767 --> 0.228813).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5678012
	speed: 0.1402s/iter; left time: 3154.9189s
	iters: 200, epoch: 4 | loss: 0.5873574
	speed: 0.1087s/iter; left time: 2435.3567s
Epoch: 4 cost time: 27.373197555541992
Epoch: 4, Steps: 233 Train Loss: 0.5893 (Forecasting Loss:0.2668 + XiCon Loss:3.2244 x Lambda(0.1)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1609
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5779005
	speed: 0.1430s/iter; left time: 3183.9177s
	iters: 200, epoch: 5 | loss: 0.6071899
	speed: 0.1414s/iter; left time: 3135.4053s
Epoch: 5 cost time: 33.25199055671692
Epoch: 5, Steps: 233 Train Loss: 0.5831 (Forecasting Loss:0.2614 + XiCon Loss:3.2169 x Lambda(0.1)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.1549
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5804346
	speed: 0.1225s/iter; left time: 2700.2915s
	iters: 200, epoch: 6 | loss: 0.5842175
	speed: 0.0723s/iter; left time: 1586.7242s
Epoch: 6 cost time: 22.586129426956177
Epoch: 6, Steps: 233 Train Loss: 0.5804 (Forecasting Loss:0.2592 + XiCon Loss:3.2117 x Lambda(0.1)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1578
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5772450
	speed: 0.1484s/iter; left time: 3234.5552s
	iters: 200, epoch: 7 | loss: 0.5744358
	speed: 0.1422s/iter; left time: 3086.8152s
Epoch: 7 cost time: 33.94802808761597
Epoch: 7, Steps: 233 Train Loss: 0.5788 (Forecasting Loss:0.2579 + XiCon Loss:3.2091 x Lambda(0.1)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1552
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5910815
	speed: 0.0951s/iter; left time: 2050.6284s
	iters: 200, epoch: 8 | loss: 0.5727373
	speed: 0.1066s/iter; left time: 2288.9600s
Epoch: 8 cost time: 24.814956665039062
Epoch: 8, Steps: 233 Train Loss: 0.5782 (Forecasting Loss:0.2573 + XiCon Loss:3.2083 x Lambda(0.1)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1571
Validation loss decreased (0.228813 --> 0.227548).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5917016
	speed: 0.1446s/iter; left time: 3084.9935s
	iters: 200, epoch: 9 | loss: 0.5820638
	speed: 0.1396s/iter; left time: 2964.6053s
Epoch: 9 cost time: 32.948983907699585
Epoch: 9, Steps: 233 Train Loss: 0.5779 (Forecasting Loss:0.2570 + XiCon Loss:3.2082 x Lambda(0.1)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1571
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5713506
	speed: 0.1424s/iter; left time: 3004.9160s
	iters: 200, epoch: 10 | loss: 0.5681829
	speed: 0.1419s/iter; left time: 2980.2712s
Epoch: 10 cost time: 33.06351017951965
Epoch: 10, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.2566 + XiCon Loss:3.2071 x Lambda(0.1)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.1578
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5679530
	speed: 0.1124s/iter; left time: 2345.7078s
	iters: 200, epoch: 11 | loss: 0.5820853
	speed: 0.0920s/iter; left time: 1911.0665s
Epoch: 11 cost time: 25.034448623657227
Epoch: 11, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2566 + XiCon Loss:3.2088 x Lambda(0.1)), Vali MSE Loss: 0.2290 Test MSE Loss: 0.1577
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5760840
	speed: 0.1448s/iter; left time: 2989.0388s
	iters: 200, epoch: 12 | loss: 0.5653684
	speed: 0.1408s/iter; left time: 2891.8188s
Epoch: 12 cost time: 32.940762996673584
Epoch: 12, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2566 + XiCon Loss:3.2079 x Lambda(0.1)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1578
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5888520
	speed: 0.1408s/iter; left time: 2872.0612s
	iters: 200, epoch: 13 | loss: 0.5878450
	speed: 0.1425s/iter; left time: 2893.0833s
Epoch: 13 cost time: 33.41175198554993
Epoch: 13, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2565 + XiCon Loss:3.2093 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1580
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5840191
	speed: 0.1352s/iter; left time: 2727.1402s
	iters: 200, epoch: 14 | loss: 0.5716315
	speed: 0.1389s/iter; left time: 2787.9977s
Epoch: 14 cost time: 32.123202323913574
Epoch: 14, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2566 + XiCon Loss:3.2073 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1580
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5923789
	speed: 0.1469s/iter; left time: 2928.2490s
	iters: 200, epoch: 15 | loss: 0.5819650
	speed: 0.1326s/iter; left time: 2631.0318s
Epoch: 15 cost time: 32.713024854660034
Epoch: 15, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2567 + XiCon Loss:3.2074 x Lambda(0.1)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1579
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5962914
	speed: 0.1450s/iter; left time: 2857.1617s
	iters: 200, epoch: 16 | loss: 0.5714861
	speed: 0.1407s/iter; left time: 2759.2911s
Epoch: 16 cost time: 32.97557878494263
Epoch: 16, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.2566 + XiCon Loss:3.2071 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1579
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5912013
	speed: 0.1412s/iter; left time: 2749.8671s
	iters: 200, epoch: 17 | loss: 0.5739721
	speed: 0.1406s/iter; left time: 2722.9183s
Epoch: 17 cost time: 32.899588108062744
Epoch: 17, Steps: 233 Train Loss: 0.5776 (Forecasting Loss:0.2568 + XiCon Loss:3.2084 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1579
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5791541
	speed: 0.1377s/iter; left time: 2649.9841s
	iters: 200, epoch: 18 | loss: 0.5753651
	speed: 0.1370s/iter; left time: 2621.9327s
Epoch: 18 cost time: 32.304529905319214
Epoch: 18, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2567 + XiCon Loss:3.2066 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1580
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08367923647165298, mae:0.23056814074516296, mape:0.16448532044887543, mspe:0.041314780712127686 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7115
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8003001
	speed: 0.1404s/iter; left time: 3258.2748s
	iters: 200, epoch: 1 | loss: 0.7936062
	speed: 0.1399s/iter; left time: 3232.9152s
Epoch: 1 cost time: 32.99719476699829
Epoch: 1, Steps: 233 Train Loss: 0.7795 (Forecasting Loss:0.4427 + XiCon Loss:3.3675 x Lambda(0.1)), Vali MSE Loss: 0.2995 Test MSE Loss: 0.1948
Validation loss decreased (inf --> 0.299496).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6402677
	speed: 0.1756s/iter; left time: 4033.7177s
	iters: 200, epoch: 2 | loss: 0.6149193
	speed: 0.1900s/iter; left time: 4344.0068s
Epoch: 2 cost time: 42.847405433654785
Epoch: 2, Steps: 233 Train Loss: 0.6404 (Forecasting Loss:0.3286 + XiCon Loss:3.1186 x Lambda(0.1)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.1788
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5647095
	speed: 0.1887s/iter; left time: 4290.3658s
	iters: 200, epoch: 3 | loss: 0.5750552
	speed: 0.1918s/iter; left time: 4342.3024s
Epoch: 3 cost time: 44.50602698326111
Epoch: 3, Steps: 233 Train Loss: 0.5837 (Forecasting Loss:0.2811 + XiCon Loss:3.0261 x Lambda(0.1)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1821
Validation loss decreased (0.299496 --> 0.292914).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5660247
	speed: 0.1956s/iter; left time: 4400.3707s
	iters: 200, epoch: 4 | loss: 0.5620911
	speed: 0.1884s/iter; left time: 4219.6321s
Epoch: 4 cost time: 45.03575611114502
Epoch: 4, Steps: 233 Train Loss: 0.5709 (Forecasting Loss:0.2705 + XiCon Loss:3.0039 x Lambda(0.1)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.1731
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5618644
	speed: 0.1933s/iter; left time: 4305.4410s
	iters: 200, epoch: 5 | loss: 0.5588348
	speed: 0.1807s/iter; left time: 4006.6335s
Epoch: 5 cost time: 43.685624837875366
Epoch: 5, Steps: 233 Train Loss: 0.5665 (Forecasting Loss:0.2656 + XiCon Loss:3.0089 x Lambda(0.1)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.1627
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5525268
	speed: 0.1959s/iter; left time: 4317.9491s
	iters: 200, epoch: 6 | loss: 0.5593319
	speed: 0.1853s/iter; left time: 4064.6345s
Epoch: 6 cost time: 44.1105523109436
Epoch: 6, Steps: 233 Train Loss: 0.5643 (Forecasting Loss:0.2634 + XiCon Loss:3.0092 x Lambda(0.1)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.1620
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5619861
	speed: 0.1920s/iter; left time: 4185.3177s
	iters: 200, epoch: 7 | loss: 0.5726159
	speed: 0.1892s/iter; left time: 4105.1866s
Epoch: 7 cost time: 44.37451243400574
Epoch: 7, Steps: 233 Train Loss: 0.5625 (Forecasting Loss:0.2619 + XiCon Loss:3.0059 x Lambda(0.1)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.1632
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5466855
	speed: 0.1932s/iter; left time: 4168.2916s
	iters: 200, epoch: 8 | loss: 0.5532026
	speed: 0.1915s/iter; left time: 4111.3642s
Epoch: 8 cost time: 45.27200126647949
Epoch: 8, Steps: 233 Train Loss: 0.5619 (Forecasting Loss:0.2613 + XiCon Loss:3.0055 x Lambda(0.1)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.1652
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5519634
	speed: 0.1838s/iter; left time: 3921.2914s
	iters: 200, epoch: 9 | loss: 0.5582300
	speed: 0.1872s/iter; left time: 3976.3576s
Epoch: 9 cost time: 43.648849964141846
Epoch: 9, Steps: 233 Train Loss: 0.5610 (Forecasting Loss:0.2607 + XiCon Loss:3.0036 x Lambda(0.1)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.1641
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5601610
	speed: 0.1922s/iter; left time: 4055.2217s
	iters: 200, epoch: 10 | loss: 0.5557255
	speed: 0.1945s/iter; left time: 4086.0124s
Epoch: 10 cost time: 45.09129285812378
Epoch: 10, Steps: 233 Train Loss: 0.5608 (Forecasting Loss:0.2605 + XiCon Loss:3.0026 x Lambda(0.1)), Vali MSE Loss: 0.3300 Test MSE Loss: 0.1655
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5618012
	speed: 0.1826s/iter; left time: 3812.0342s
	iters: 200, epoch: 11 | loss: 0.5559472
	speed: 0.1885s/iter; left time: 3914.8914s
Epoch: 11 cost time: 43.26504373550415
Epoch: 11, Steps: 233 Train Loss: 0.5613 (Forecasting Loss:0.2608 + XiCon Loss:3.0050 x Lambda(0.1)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.1651
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5559971
	speed: 0.1804s/iter; left time: 3722.3661s
	iters: 200, epoch: 12 | loss: 0.5598919
	speed: 0.1837s/iter; left time: 3773.5346s
Epoch: 12 cost time: 42.79248332977295
Epoch: 12, Steps: 233 Train Loss: 0.5609 (Forecasting Loss:0.2605 + XiCon Loss:3.0044 x Lambda(0.1)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.1650
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5594915
	speed: 0.1884s/iter; left time: 3845.2304s
	iters: 200, epoch: 13 | loss: 0.5634685
	speed: 0.1821s/iter; left time: 3698.2366s
Epoch: 13 cost time: 43.58537006378174
Epoch: 13, Steps: 233 Train Loss: 0.5608 (Forecasting Loss:0.2605 + XiCon Loss:3.0030 x Lambda(0.1)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.1649
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.10651499778032303, mae:0.2577377259731293, mape:0.18034791946411133, mspe:0.0492815338075161 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1632
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8269864
	speed: 0.1451s/iter; left time: 3366.8580s
	iters: 200, epoch: 1 | loss: 0.7962431
	speed: 0.1462s/iter; left time: 3377.3856s
Epoch: 1 cost time: 34.218815326690674
Epoch: 1, Steps: 233 Train Loss: 0.7804 (Forecasting Loss:0.4425 + XiCon Loss:3.3790 x Lambda(0.1)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.1787
Validation loss decreased (inf --> 0.291788).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6512651
	speed: 0.1432s/iter; left time: 3289.2643s
	iters: 200, epoch: 2 | loss: 0.5962901
	speed: 0.1428s/iter; left time: 3265.0293s
Epoch: 2 cost time: 33.372928857803345
Epoch: 2, Steps: 233 Train Loss: 0.6647 (Forecasting Loss:0.3394 + XiCon Loss:3.2526 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.1533
Validation loss decreased (0.291788 --> 0.269365).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5942515
	speed: 0.1519s/iter; left time: 3453.3202s
	iters: 200, epoch: 3 | loss: 0.6061833
	speed: 0.1186s/iter; left time: 2683.7899s
Epoch: 3 cost time: 31.295364379882812
Epoch: 3, Steps: 233 Train Loss: 0.6050 (Forecasting Loss:0.2820 + XiCon Loss:3.2305 x Lambda(0.1)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.1503
Validation loss decreased (0.269365 --> 0.224918).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5980046
	speed: 0.0846s/iter; left time: 1903.2650s
	iters: 200, epoch: 4 | loss: 0.5873961
	speed: 0.1396s/iter; left time: 3127.0567s
Epoch: 4 cost time: 27.184417486190796
Epoch: 4, Steps: 233 Train Loss: 0.5916 (Forecasting Loss:0.2688 + XiCon Loss:3.2281 x Lambda(0.1)), Vali MSE Loss: 0.2240 Test MSE Loss: 0.1459
Validation loss decreased (0.224918 --> 0.224042).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5841706
	speed: 0.1441s/iter; left time: 3210.0288s
	iters: 200, epoch: 5 | loss: 0.5793052
	speed: 0.1277s/iter; left time: 2831.6563s
Epoch: 5 cost time: 32.01590371131897
Epoch: 5, Steps: 233 Train Loss: 0.5880 (Forecasting Loss:0.2656 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.1473
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5860155
	speed: 0.1428s/iter; left time: 3147.0313s
	iters: 200, epoch: 6 | loss: 0.5762448
	speed: 0.1412s/iter; left time: 3096.8456s
Epoch: 6 cost time: 33.01736664772034
Epoch: 6, Steps: 233 Train Loss: 0.5851 (Forecasting Loss:0.2629 + XiCon Loss:3.2218 x Lambda(0.1)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1438
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5840275
	speed: 0.0795s/iter; left time: 1733.4902s
	iters: 200, epoch: 7 | loss: 0.5833053
	speed: 0.1419s/iter; left time: 3079.9643s
Epoch: 7 cost time: 26.756107568740845
Epoch: 7, Steps: 233 Train Loss: 0.5840 (Forecasting Loss:0.2620 + XiCon Loss:3.2193 x Lambda(0.1)), Vali MSE Loss: 0.2336 Test MSE Loss: 0.1457
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5846849
	speed: 0.1484s/iter; left time: 3200.7603s
	iters: 200, epoch: 8 | loss: 0.5813383
	speed: 0.1349s/iter; left time: 2897.2399s
Epoch: 8 cost time: 30.803568601608276
Epoch: 8, Steps: 233 Train Loss: 0.5834 (Forecasting Loss:0.2615 + XiCon Loss:3.2190 x Lambda(0.1)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.1459
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5846599
	speed: 0.1425s/iter; left time: 3039.4838s
	iters: 200, epoch: 9 | loss: 0.5907934
	speed: 0.1465s/iter; left time: 3111.3041s
Epoch: 9 cost time: 34.008015394210815
Epoch: 9, Steps: 233 Train Loss: 0.5827 (Forecasting Loss:0.2610 + XiCon Loss:3.2172 x Lambda(0.1)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1444
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5900565
	speed: 0.1438s/iter; left time: 3033.9438s
	iters: 200, epoch: 10 | loss: 0.5948818
	speed: 0.1441s/iter; left time: 3026.9827s
Epoch: 10 cost time: 33.79149866104126
Epoch: 10, Steps: 233 Train Loss: 0.5830 (Forecasting Loss:0.2610 + XiCon Loss:3.2197 x Lambda(0.1)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1453
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5814199
	speed: 0.1467s/iter; left time: 3061.9221s
	iters: 200, epoch: 11 | loss: 0.5885391
	speed: 0.1177s/iter; left time: 2445.4360s
Epoch: 11 cost time: 28.92405414581299
Epoch: 11, Steps: 233 Train Loss: 0.5830 (Forecasting Loss:0.2612 + XiCon Loss:3.2184 x Lambda(0.1)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1450
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5791556
	speed: 0.1488s/iter; left time: 3070.0690s
	iters: 200, epoch: 12 | loss: 0.5899150
	speed: 0.1405s/iter; left time: 2885.4394s
Epoch: 12 cost time: 33.622270822525024
Epoch: 12, Steps: 233 Train Loss: 0.5826 (Forecasting Loss:0.2608 + XiCon Loss:3.2175 x Lambda(0.1)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.1451
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5874462
	speed: 0.1463s/iter; left time: 2984.4503s
	iters: 200, epoch: 13 | loss: 0.5886759
	speed: 0.1430s/iter; left time: 2903.1338s
Epoch: 13 cost time: 33.76399278640747
Epoch: 13, Steps: 233 Train Loss: 0.5828 (Forecasting Loss:0.2610 + XiCon Loss:3.2184 x Lambda(0.1)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1451
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5625578
	speed: 0.1432s/iter; left time: 2889.0862s
	iters: 200, epoch: 14 | loss: 0.5785697
	speed: 0.1457s/iter; left time: 2923.6730s
Epoch: 14 cost time: 33.719138383865356
Epoch: 14, Steps: 233 Train Loss: 0.5828 (Forecasting Loss:0.2611 + XiCon Loss:3.2177 x Lambda(0.1)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1451
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.07452429085969925, mae:0.21730847656726837, mape:0.15826015174388885, mspe:0.039994265884160995 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0857+-0.01602, MAE:0.2319+-0.02040, MAPE:0.1657+-0.01138, MSPE:0.0427+-0.00485, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5426292
	speed: 0.0332s/iter; left time: 875.2717s
	iters: 200, epoch: 1 | loss: 0.5583638
	speed: 0.0285s/iter; left time: 749.0423s
Epoch: 1 cost time: 9.968014478683472
Epoch: 1, Steps: 265 Train Loss: 0.5559 (Forecasting Loss:0.2266 + XiCon Loss:3.2930 x Lambda(0.1)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1676
Validation loss decreased (inf --> 0.207500).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5131313
	speed: 0.0612s/iter; left time: 1598.4309s
	iters: 200, epoch: 2 | loss: 0.5397924
	speed: 0.0565s/iter; left time: 1470.1707s
Epoch: 2 cost time: 15.68317723274231
Epoch: 2, Steps: 265 Train Loss: 0.5207 (Forecasting Loss:0.2084 + XiCon Loss:3.1234 x Lambda(0.1)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1675
Validation loss decreased (0.207500 --> 0.206742).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4845692
	speed: 0.0613s/iter; left time: 1585.0809s
	iters: 200, epoch: 3 | loss: 0.4974033
	speed: 0.0588s/iter; left time: 1514.2470s
Epoch: 3 cost time: 15.201341390609741
Epoch: 3, Steps: 265 Train Loss: 0.5039 (Forecasting Loss:0.2001 + XiCon Loss:3.0383 x Lambda(0.1)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1671
Validation loss decreased (0.206742 --> 0.200744).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4760703
	speed: 0.0405s/iter; left time: 1037.4255s
	iters: 200, epoch: 4 | loss: 0.5022337
	speed: 0.0283s/iter; left time: 722.9640s
Epoch: 4 cost time: 8.96231746673584
Epoch: 4, Steps: 265 Train Loss: 0.4977 (Forecasting Loss:0.1956 + XiCon Loss:3.0210 x Lambda(0.1)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1705
Validation loss decreased (0.200744 --> 0.196810).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4996499
	speed: 0.0617s/iter; left time: 1564.1955s
	iters: 200, epoch: 5 | loss: 0.4898937
	speed: 0.0595s/iter; left time: 1501.3556s
Epoch: 5 cost time: 16.175065994262695
Epoch: 5, Steps: 265 Train Loss: 0.4937 (Forecasting Loss:0.1919 + XiCon Loss:3.0186 x Lambda(0.1)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1739
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5156455
	speed: 0.0628s/iter; left time: 1575.5207s
	iters: 200, epoch: 6 | loss: 0.4877619
	speed: 0.0578s/iter; left time: 1442.5642s
Epoch: 6 cost time: 15.832975625991821
Epoch: 6, Steps: 265 Train Loss: 0.4911 (Forecasting Loss:0.1891 + XiCon Loss:3.0195 x Lambda(0.1)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4750807
	speed: 0.0485s/iter; left time: 1203.6640s
	iters: 200, epoch: 7 | loss: 0.5185888
	speed: 0.0300s/iter; left time: 742.4489s
Epoch: 7 cost time: 9.79322361946106
Epoch: 7, Steps: 265 Train Loss: 0.4894 (Forecasting Loss:0.1873 + XiCon Loss:3.0219 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1750
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4968324
	speed: 0.0579s/iter; left time: 1420.7219s
	iters: 200, epoch: 8 | loss: 0.5188489
	speed: 0.0617s/iter; left time: 1509.3468s
Epoch: 8 cost time: 15.858310461044312
Epoch: 8, Steps: 265 Train Loss: 0.4874 (Forecasting Loss:0.1855 + XiCon Loss:3.0190 x Lambda(0.1)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1777
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4952597
	speed: 0.0621s/iter; left time: 1508.4788s
	iters: 200, epoch: 9 | loss: 0.4661518
	speed: 0.0607s/iter; left time: 1468.8634s
Epoch: 9 cost time: 16.273003816604614
Epoch: 9, Steps: 265 Train Loss: 0.4872 (Forecasting Loss:0.1849 + XiCon Loss:3.0226 x Lambda(0.1)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1776
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4908273
	speed: 0.0475s/iter; left time: 1140.5628s
	iters: 200, epoch: 10 | loss: 0.4872428
	speed: 0.0493s/iter; left time: 1180.1009s
Epoch: 10 cost time: 13.55812692642212
Epoch: 10, Steps: 265 Train Loss: 0.4864 (Forecasting Loss:0.1847 + XiCon Loss:3.0172 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1760
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4894863
	speed: 0.0631s/iter; left time: 1498.1783s
	iters: 200, epoch: 11 | loss: 0.4575931
	speed: 0.0607s/iter; left time: 1436.3460s
Epoch: 11 cost time: 16.45842146873474
Epoch: 11, Steps: 265 Train Loss: 0.4864 (Forecasting Loss:0.1844 + XiCon Loss:3.0196 x Lambda(0.1)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1758
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4958597
	speed: 0.0624s/iter; left time: 1466.6488s
	iters: 200, epoch: 12 | loss: 0.4827964
	speed: 0.0538s/iter; left time: 1257.9058s
Epoch: 12 cost time: 14.530714988708496
Epoch: 12, Steps: 265 Train Loss: 0.4867 (Forecasting Loss:0.1843 + XiCon Loss:3.0232 x Lambda(0.1)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1764
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5019617
	speed: 0.0583s/iter; left time: 1354.3645s
	iters: 200, epoch: 13 | loss: 0.4582276
	speed: 0.0588s/iter; left time: 1359.7054s
Epoch: 13 cost time: 15.634360551834106
Epoch: 13, Steps: 265 Train Loss: 0.4862 (Forecasting Loss:0.1842 + XiCon Loss:3.0193 x Lambda(0.1)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1764
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4797244
	speed: 0.0630s/iter; left time: 1446.8454s
	iters: 200, epoch: 14 | loss: 0.4790884
	speed: 0.0573s/iter; left time: 1310.5105s
Epoch: 14 cost time: 15.851738691329956
Epoch: 14, Steps: 265 Train Loss: 0.4860 (Forecasting Loss:0.1841 + XiCon Loss:3.0194 x Lambda(0.1)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1764
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10143953561782837, mae:0.23950503766536713, mape:0.6041420102119446, mspe:14.093687057495117 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.6186
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5417840
	speed: 0.0606s/iter; left time: 1600.9312s
	iters: 200, epoch: 1 | loss: 0.5247442
	speed: 0.0582s/iter; left time: 1532.0141s
Epoch: 1 cost time: 15.786383152008057
Epoch: 1, Steps: 265 Train Loss: 0.5537 (Forecasting Loss:0.2250 + XiCon Loss:3.2871 x Lambda(0.1)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1688
Validation loss decreased (inf --> 0.209731).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5560975
	speed: 0.0618s/iter; left time: 1614.0750s
	iters: 200, epoch: 2 | loss: 0.5075108
	speed: 0.0557s/iter; left time: 1450.6612s
Epoch: 2 cost time: 14.628982782363892
Epoch: 2, Steps: 265 Train Loss: 0.5257 (Forecasting Loss:0.2068 + XiCon Loss:3.1887 x Lambda(0.1)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1667
Validation loss decreased (0.209731 --> 0.208415).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5002859
	speed: 0.0575s/iter; left time: 1486.5039s
	iters: 200, epoch: 3 | loss: 0.5104873
	speed: 0.0610s/iter; left time: 1571.6123s
Epoch: 3 cost time: 15.923672676086426
Epoch: 3, Steps: 265 Train Loss: 0.5030 (Forecasting Loss:0.1988 + XiCon Loss:3.0419 x Lambda(0.1)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1711
Validation loss decreased (0.208415 --> 0.200797).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4968405
	speed: 0.0632s/iter; left time: 1619.4403s
	iters: 200, epoch: 4 | loss: 0.4818687
	speed: 0.0604s/iter; left time: 1539.6893s
Epoch: 4 cost time: 16.31627893447876
Epoch: 4, Steps: 265 Train Loss: 0.4922 (Forecasting Loss:0.1925 + XiCon Loss:2.9975 x Lambda(0.1)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1747
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4720536
	speed: 0.0482s/iter; left time: 1221.4126s
	iters: 200, epoch: 5 | loss: 0.4926442
	speed: 0.0494s/iter; left time: 1247.7447s
Epoch: 5 cost time: 13.617393016815186
Epoch: 5, Steps: 265 Train Loss: 0.4877 (Forecasting Loss:0.1888 + XiCon Loss:2.9884 x Lambda(0.1)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1727
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5043342
	speed: 0.0637s/iter; left time: 1596.9538s
	iters: 200, epoch: 6 | loss: 0.4710382
	speed: 0.0593s/iter; left time: 1481.5697s
Epoch: 6 cost time: 16.1004581451416
Epoch: 6, Steps: 265 Train Loss: 0.4854 (Forecasting Loss:0.1864 + XiCon Loss:2.9909 x Lambda(0.1)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1720
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4926707
	speed: 0.0628s/iter; left time: 1558.3333s
	iters: 200, epoch: 7 | loss: 0.4749113
	speed: 0.0559s/iter; left time: 1381.3772s
Epoch: 7 cost time: 14.799323081970215
Epoch: 7, Steps: 265 Train Loss: 0.4837 (Forecasting Loss:0.1850 + XiCon Loss:2.9870 x Lambda(0.1)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1689
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4954234
	speed: 0.0591s/iter; left time: 1450.0592s
	iters: 200, epoch: 8 | loss: 0.4903610
	speed: 0.0586s/iter; left time: 1433.4973s
Epoch: 8 cost time: 15.68213701248169
Epoch: 8, Steps: 265 Train Loss: 0.4827 (Forecasting Loss:0.1841 + XiCon Loss:2.9862 x Lambda(0.1)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1702
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4995488
	speed: 0.0655s/iter; left time: 1590.4047s
	iters: 200, epoch: 9 | loss: 0.4714159
	speed: 0.0615s/iter; left time: 1486.1767s
Epoch: 9 cost time: 16.66506290435791
Epoch: 9, Steps: 265 Train Loss: 0.4822 (Forecasting Loss:0.1836 + XiCon Loss:2.9858 x Lambda(0.1)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1712
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4863982
	speed: 0.0493s/iter; left time: 1183.5683s
	iters: 200, epoch: 10 | loss: 0.4827406
	speed: 0.0463s/iter; left time: 1106.5493s
Epoch: 10 cost time: 13.372628211975098
Epoch: 10, Steps: 265 Train Loss: 0.4821 (Forecasting Loss:0.1835 + XiCon Loss:2.9864 x Lambda(0.1)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1698
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4676791
	speed: 0.0606s/iter; left time: 1438.5922s
	iters: 200, epoch: 11 | loss: 0.4816547
	speed: 0.0590s/iter; left time: 1396.3549s
Epoch: 11 cost time: 16.014983654022217
Epoch: 11, Steps: 265 Train Loss: 0.4817 (Forecasting Loss:0.1831 + XiCon Loss:2.9856 x Lambda(0.1)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1704
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4882194
	speed: 0.0639s/iter; left time: 1499.7237s
	iters: 200, epoch: 12 | loss: 0.4942579
	speed: 0.0585s/iter; left time: 1367.3481s
Epoch: 12 cost time: 15.27281379699707
Epoch: 12, Steps: 265 Train Loss: 0.4814 (Forecasting Loss:0.1831 + XiCon Loss:2.9829 x Lambda(0.1)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1706
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4778963
	speed: 0.0573s/iter; left time: 1329.4870s
	iters: 200, epoch: 13 | loss: 0.4871546
	speed: 0.0612s/iter; left time: 1414.2975s
Epoch: 13 cost time: 15.874814987182617
Epoch: 13, Steps: 265 Train Loss: 0.4818 (Forecasting Loss:0.1831 + XiCon Loss:2.9866 x Lambda(0.1)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1705
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10260552912950516, mae:0.23967216908931732, mape:0.588165283203125, mspe:13.765480041503906 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.2103
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5473434
	speed: 0.0464s/iter; left time: 1225.2819s
	iters: 200, epoch: 1 | loss: 0.5467335
	speed: 0.0571s/iter; left time: 1501.7979s
Epoch: 1 cost time: 14.193302631378174
Epoch: 1, Steps: 265 Train Loss: 0.5554 (Forecasting Loss:0.2231 + XiCon Loss:3.3229 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1685
Validation loss decreased (inf --> 0.208957).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5427483
	speed: 0.0617s/iter; left time: 1613.2883s
	iters: 200, epoch: 2 | loss: 0.5404512
	speed: 0.0598s/iter; left time: 1555.7284s
Epoch: 2 cost time: 15.969938278198242
Epoch: 2, Steps: 265 Train Loss: 0.5275 (Forecasting Loss:0.2053 + XiCon Loss:3.2217 x Lambda(0.1)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1715
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5098729
	speed: 0.0630s/iter; left time: 1629.6136s
	iters: 200, epoch: 3 | loss: 0.4962491
	speed: 0.0463s/iter; left time: 1192.4921s
Epoch: 3 cost time: 13.813348054885864
Epoch: 3, Steps: 265 Train Loss: 0.5105 (Forecasting Loss:0.1941 + XiCon Loss:3.1641 x Lambda(0.1)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1736
Validation loss decreased (0.208957 --> 0.205091).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4768416
	speed: 0.0600s/iter; left time: 1536.0476s
	iters: 200, epoch: 4 | loss: 0.5056305
	speed: 0.0615s/iter; left time: 1568.5025s
Epoch: 4 cost time: 16.01384162902832
Epoch: 4, Steps: 265 Train Loss: 0.4990 (Forecasting Loss:0.1835 + XiCon Loss:3.1556 x Lambda(0.1)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1908
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4815963
	speed: 0.0622s/iter; left time: 1576.4171s
	iters: 200, epoch: 5 | loss: 0.4750926
	speed: 0.0614s/iter; left time: 1549.8154s
Epoch: 5 cost time: 16.135796785354614
Epoch: 5, Steps: 265 Train Loss: 0.4881 (Forecasting Loss:0.1746 + XiCon Loss:3.1352 x Lambda(0.1)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.2147
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4900134
	speed: 0.0480s/iter; left time: 1204.4170s
	iters: 200, epoch: 6 | loss: 0.4784023
	speed: 0.0570s/iter; left time: 1422.5120s
Epoch: 6 cost time: 14.300724744796753
Epoch: 6, Steps: 265 Train Loss: 0.4839 (Forecasting Loss:0.1702 + XiCon Loss:3.1372 x Lambda(0.1)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.2026
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4846936
	speed: 0.0619s/iter; left time: 1535.1152s
	iters: 200, epoch: 7 | loss: 0.4743587
	speed: 0.0627s/iter; left time: 1550.1018s
Epoch: 7 cost time: 16.59899926185608
Epoch: 7, Steps: 265 Train Loss: 0.4808 (Forecasting Loss:0.1674 + XiCon Loss:3.1340 x Lambda(0.1)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.2112
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4726450
	speed: 0.0637s/iter; left time: 1564.5132s
	iters: 200, epoch: 8 | loss: 0.4780878
	speed: 0.0475s/iter; left time: 1161.8767s
Epoch: 8 cost time: 14.0560884475708
Epoch: 8, Steps: 265 Train Loss: 0.4799 (Forecasting Loss:0.1663 + XiCon Loss:3.1359 x Lambda(0.1)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.2211
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4856555
	speed: 0.0611s/iter; left time: 1483.1407s
	iters: 200, epoch: 9 | loss: 0.4633447
	speed: 0.0614s/iter; left time: 1485.1472s
Epoch: 9 cost time: 16.297574996948242
Epoch: 9, Steps: 265 Train Loss: 0.4788 (Forecasting Loss:0.1656 + XiCon Loss:3.1323 x Lambda(0.1)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.2195
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4758819
	speed: 0.0642s/iter; left time: 1540.7434s
	iters: 200, epoch: 10 | loss: 0.4999799
	speed: 0.0618s/iter; left time: 1477.7965s
Epoch: 10 cost time: 16.221239805221558
Epoch: 10, Steps: 265 Train Loss: 0.4781 (Forecasting Loss:0.1652 + XiCon Loss:3.1291 x Lambda(0.1)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.2202
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4962991
	speed: 0.0464s/iter; left time: 1102.3542s
	iters: 200, epoch: 11 | loss: 0.4797219
	speed: 0.0586s/iter; left time: 1384.9079s
Epoch: 11 cost time: 14.452029705047607
Epoch: 11, Steps: 265 Train Loss: 0.4783 (Forecasting Loss:0.1652 + XiCon Loss:3.1312 x Lambda(0.1)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.2186
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4744357
	speed: 0.0616s/iter; left time: 1447.6731s
	iters: 200, epoch: 12 | loss: 0.4745137
	speed: 0.0620s/iter; left time: 1450.3023s
Epoch: 12 cost time: 16.27078676223755
Epoch: 12, Steps: 265 Train Loss: 0.4785 (Forecasting Loss:0.1651 + XiCon Loss:3.1337 x Lambda(0.1)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.2189
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4986502
	speed: 0.0620s/iter; left time: 1439.7880s
	iters: 200, epoch: 13 | loss: 0.4699084
	speed: 0.0459s/iter; left time: 1060.6801s
Epoch: 13 cost time: 13.78060531616211
Epoch: 13, Steps: 265 Train Loss: 0.4780 (Forecasting Loss:0.1649 + XiCon Loss:3.1317 x Lambda(0.1)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.2189
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10451043397188187, mae:0.24262969195842743, mape:0.6141839027404785, mspe:14.206424713134766 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8079
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5470833
	speed: 0.0646s/iter; left time: 1706.6885s
	iters: 200, epoch: 1 | loss: 0.5280188
	speed: 0.0583s/iter; left time: 1533.4279s
Epoch: 1 cost time: 15.377624988555908
Epoch: 1, Steps: 265 Train Loss: 0.5547 (Forecasting Loss:0.2254 + XiCon Loss:3.2929 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1674
Validation loss decreased (inf --> 0.208085).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5392489
	speed: 0.0543s/iter; left time: 1419.1852s
	iters: 200, epoch: 2 | loss: 0.5497012
	speed: 0.0608s/iter; left time: 1582.2818s
Epoch: 2 cost time: 15.445291519165039
Epoch: 2, Steps: 265 Train Loss: 0.5231 (Forecasting Loss:0.2056 + XiCon Loss:3.1754 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1674
Validation loss decreased (0.208085 --> 0.204726).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4965301
	speed: 0.0633s/iter; left time: 1636.5351s
	iters: 200, epoch: 3 | loss: 0.5058168
	speed: 0.0607s/iter; left time: 1564.4109s
Epoch: 3 cost time: 16.490203380584717
Epoch: 3, Steps: 265 Train Loss: 0.5022 (Forecasting Loss:0.1926 + XiCon Loss:3.0964 x Lambda(0.1)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1705
Validation loss decreased (0.204726 --> 0.201962).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4860759
	speed: 0.0558s/iter; left time: 1429.2680s
	iters: 200, epoch: 4 | loss: 0.4770830
	speed: 0.0430s/iter; left time: 1096.2095s
Epoch: 4 cost time: 13.77808141708374
Epoch: 4, Steps: 265 Train Loss: 0.4933 (Forecasting Loss:0.1847 + XiCon Loss:3.0862 x Lambda(0.1)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1765
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4691155
	speed: 0.0629s/iter; left time: 1593.4913s
	iters: 200, epoch: 5 | loss: 0.4688398
	speed: 0.0610s/iter; left time: 1540.9071s
Epoch: 5 cost time: 16.209882974624634
Epoch: 5, Steps: 265 Train Loss: 0.4865 (Forecasting Loss:0.1785 + XiCon Loss:3.0798 x Lambda(0.1)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1816
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4666798
	speed: 0.0626s/iter; left time: 1570.5361s
	iters: 200, epoch: 6 | loss: 0.5210513
	speed: 0.0603s/iter; left time: 1507.1082s
Epoch: 6 cost time: 15.402408361434937
Epoch: 6, Steps: 265 Train Loss: 0.4827 (Forecasting Loss:0.1744 + XiCon Loss:3.0827 x Lambda(0.1)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1813
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4526547
	speed: 0.0544s/iter; left time: 1349.8782s
	iters: 200, epoch: 7 | loss: 0.4843841
	speed: 0.0604s/iter; left time: 1493.4196s
Epoch: 7 cost time: 15.346791982650757
Epoch: 7, Steps: 265 Train Loss: 0.4806 (Forecasting Loss:0.1726 + XiCon Loss:3.0801 x Lambda(0.1)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1826
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4604715
	speed: 0.0639s/iter; left time: 1569.3231s
	iters: 200, epoch: 8 | loss: 0.4690733
	speed: 0.0600s/iter; left time: 1466.8185s
Epoch: 8 cost time: 16.384195804595947
Epoch: 8, Steps: 265 Train Loss: 0.4794 (Forecasting Loss:0.1713 + XiCon Loss:3.0815 x Lambda(0.1)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1848
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4908655
	speed: 0.0565s/iter; left time: 1372.3454s
	iters: 200, epoch: 9 | loss: 0.4982558
	speed: 0.0443s/iter; left time: 1070.3517s
Epoch: 9 cost time: 14.031625986099243
Epoch: 9, Steps: 265 Train Loss: 0.4790 (Forecasting Loss:0.1708 + XiCon Loss:3.0813 x Lambda(0.1)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1847
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4746618
	speed: 0.0644s/iter; left time: 1547.4553s
	iters: 200, epoch: 10 | loss: 0.4999087
	speed: 0.0619s/iter; left time: 1479.5779s
Epoch: 10 cost time: 16.555575132369995
Epoch: 10, Steps: 265 Train Loss: 0.4785 (Forecasting Loss:0.1706 + XiCon Loss:3.0789 x Lambda(0.1)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1847
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4825429
	speed: 0.0617s/iter; left time: 1466.3871s
	iters: 200, epoch: 11 | loss: 0.4822862
	speed: 0.0594s/iter; left time: 1405.2676s
Epoch: 11 cost time: 15.265620946884155
Epoch: 11, Steps: 265 Train Loss: 0.4785 (Forecasting Loss:0.1704 + XiCon Loss:3.0802 x Lambda(0.1)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1846
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4675932
	speed: 0.0553s/iter; left time: 1299.1643s
	iters: 200, epoch: 12 | loss: 0.4767793
	speed: 0.0594s/iter; left time: 1388.2298s
Epoch: 12 cost time: 15.495586633682251
Epoch: 12, Steps: 265 Train Loss: 0.4786 (Forecasting Loss:0.1703 + XiCon Loss:3.0827 x Lambda(0.1)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1849
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4777126
	speed: 0.0628s/iter; left time: 1458.4503s
	iters: 200, epoch: 13 | loss: 0.4788017
	speed: 0.0616s/iter; left time: 1423.3255s
Epoch: 13 cost time: 16.41878032684326
Epoch: 13, Steps: 265 Train Loss: 0.4785 (Forecasting Loss:0.1703 + XiCon Loss:3.0817 x Lambda(0.1)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1848
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10146782547235489, mae:0.23954594135284424, mape:0.5854095220565796, mspe:13.178394317626953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.6255
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5112550
	speed: 0.0934s/iter; left time: 2464.9864s
	iters: 200, epoch: 1 | loss: 0.5696681
	speed: 0.0550s/iter; left time: 1445.8412s
Epoch: 1 cost time: 16.772738218307495
Epoch: 1, Steps: 265 Train Loss: 0.5529 (Forecasting Loss:0.2235 + XiCon Loss:3.2941 x Lambda(0.1)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1687
Validation loss decreased (inf --> 0.208736).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5081258
	speed: 0.0312s/iter; left time: 814.8739s
	iters: 200, epoch: 2 | loss: 0.5078439
	speed: 0.0568s/iter; left time: 1478.3145s
Epoch: 2 cost time: 12.854971408843994
Epoch: 2, Steps: 265 Train Loss: 0.5195 (Forecasting Loss:0.2039 + XiCon Loss:3.1560 x Lambda(0.1)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1759
Validation loss decreased (0.208736 --> 0.202650).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5033782
	speed: 0.0610s/iter; left time: 1578.7248s
	iters: 200, epoch: 3 | loss: 0.5039416
	speed: 0.0604s/iter; left time: 1555.3697s
Epoch: 3 cost time: 15.976621150970459
Epoch: 3, Steps: 265 Train Loss: 0.5078 (Forecasting Loss:0.1915 + XiCon Loss:3.1632 x Lambda(0.1)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1948
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5171342
	speed: 0.0604s/iter; left time: 1545.6877s
	iters: 200, epoch: 4 | loss: 0.4831958
	speed: 0.0451s/iter; left time: 1150.5873s
Epoch: 4 cost time: 13.201095342636108
Epoch: 4, Steps: 265 Train Loss: 0.4937 (Forecasting Loss:0.1797 + XiCon Loss:3.1399 x Lambda(0.1)), Vali MSE Loss: 0.2148 Test MSE Loss: 0.1893
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4854100
	speed: 0.0608s/iter; left time: 1540.8355s
	iters: 200, epoch: 5 | loss: 0.4763319
	speed: 0.0603s/iter; left time: 1522.8026s
Epoch: 5 cost time: 16.105929136276245
Epoch: 5, Steps: 265 Train Loss: 0.4834 (Forecasting Loss:0.1699 + XiCon Loss:3.1353 x Lambda(0.1)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1865
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4781410
	speed: 0.0618s/iter; left time: 1550.3112s
	iters: 200, epoch: 6 | loss: 0.4732203
	speed: 0.0619s/iter; left time: 1545.0652s
Epoch: 6 cost time: 16.394046306610107
Epoch: 6, Steps: 265 Train Loss: 0.4784 (Forecasting Loss:0.1653 + XiCon Loss:3.1308 x Lambda(0.1)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1931
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4729968
	speed: 0.0478s/iter; left time: 1186.1805s
	iters: 200, epoch: 7 | loss: 0.4572482
	speed: 0.0296s/iter; left time: 731.4786s
Epoch: 7 cost time: 9.721522569656372
Epoch: 7, Steps: 265 Train Loss: 0.4760 (Forecasting Loss:0.1630 + XiCon Loss:3.1301 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1901
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4766130
	speed: 0.0612s/iter; left time: 1501.6250s
	iters: 200, epoch: 8 | loss: 0.4657069
	speed: 0.0593s/iter; left time: 1448.5110s
Epoch: 8 cost time: 15.94223952293396
Epoch: 8, Steps: 265 Train Loss: 0.4743 (Forecasting Loss:0.1622 + XiCon Loss:3.1215 x Lambda(0.1)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1893
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4813747
	speed: 0.0614s/iter; left time: 1491.7874s
	iters: 200, epoch: 9 | loss: 0.4743939
	speed: 0.0600s/iter; left time: 1450.6548s
Epoch: 9 cost time: 16.084484577178955
Epoch: 9, Steps: 265 Train Loss: 0.4744 (Forecasting Loss:0.1615 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1915
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4643714
	speed: 0.0478s/iter; left time: 1146.8776s
	iters: 200, epoch: 10 | loss: 0.4618770
	speed: 0.0325s/iter; left time: 778.3049s
Epoch: 10 cost time: 10.012827634811401
Epoch: 10, Steps: 265 Train Loss: 0.4736 (Forecasting Loss:0.1612 + XiCon Loss:3.1240 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1902
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4741136
	speed: 0.0627s/iter; left time: 1489.6493s
	iters: 200, epoch: 11 | loss: 0.4764524
	speed: 0.0589s/iter; left time: 1392.6588s
Epoch: 11 cost time: 15.909136295318604
Epoch: 11, Steps: 265 Train Loss: 0.4743 (Forecasting Loss:0.1614 + XiCon Loss:3.1295 x Lambda(0.1)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1907
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4823783
	speed: 0.0614s/iter; left time: 1441.7612s
	iters: 200, epoch: 12 | loss: 0.4756945
	speed: 0.0587s/iter; left time: 1373.3276s
Epoch: 12 cost time: 15.845453977584839
Epoch: 12, Steps: 265 Train Loss: 0.4740 (Forecasting Loss:0.1614 + XiCon Loss:3.1265 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1902
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10656792670488358, mae:0.2451665699481964, mape:0.6135056018829346, mspe:14.053350448608398 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1033+-0.00274, MAE:0.2413+-0.00315, MAPE:0.6011+-0.01698, MSPE:13.8595+-0.51403, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0326
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.7623095
	speed: 0.0835s/iter; left time: 2128.4164s
	iters: 200, epoch: 1 | loss: 0.7985899
	speed: 0.0776s/iter; left time: 1971.6699s
Epoch: 1 cost time: 20.420465230941772
Epoch: 1, Steps: 256 Train Loss: 0.7718 (Forecasting Loss:0.4343 + XiCon Loss:3.3753 x Lambda(0.1)), Vali MSE Loss: 0.4134 Test MSE Loss: 0.3833
Validation loss decreased (inf --> 0.413404).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6583395
	speed: 0.0725s/iter; left time: 1829.2511s
	iters: 200, epoch: 2 | loss: 0.6678389
	speed: 0.0398s/iter; left time: 1001.8713s
Epoch: 2 cost time: 13.863345861434937
Epoch: 2, Steps: 256 Train Loss: 0.6751 (Forecasting Loss:0.3419 + XiCon Loss:3.3327 x Lambda(0.1)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.3045
Validation loss decreased (0.413404 --> 0.324334).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6510175
	speed: 0.0791s/iter; left time: 1976.2562s
	iters: 200, epoch: 3 | loss: 0.6495370
	speed: 0.0766s/iter; left time: 1905.8009s
Epoch: 3 cost time: 20.047881841659546
Epoch: 3, Steps: 256 Train Loss: 0.6457 (Forecasting Loss:0.3162 + XiCon Loss:3.2953 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.3017
Validation loss decreased (0.324334 --> 0.318009).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6495819
	speed: 0.0790s/iter; left time: 1953.1656s
	iters: 200, epoch: 4 | loss: 0.6463926
	speed: 0.0761s/iter; left time: 1875.1781s
Epoch: 4 cost time: 19.816750526428223
Epoch: 4, Steps: 256 Train Loss: 0.6420 (Forecasting Loss:0.3134 + XiCon Loss:3.2856 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.3009
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6504390
	speed: 0.0806s/iter; left time: 1973.9469s
	iters: 200, epoch: 5 | loss: 0.6642770
	speed: 0.0796s/iter; left time: 1940.0056s
Epoch: 5 cost time: 20.432751893997192
Epoch: 5, Steps: 256 Train Loss: 0.6403 (Forecasting Loss:0.3123 + XiCon Loss:3.2800 x Lambda(0.1)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.3008
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6290650
	speed: 0.0810s/iter; left time: 1961.1814s
	iters: 200, epoch: 6 | loss: 0.6163626
	speed: 0.0768s/iter; left time: 1852.2546s
Epoch: 6 cost time: 20.27673316001892
Epoch: 6, Steps: 256 Train Loss: 0.6397 (Forecasting Loss:0.3119 + XiCon Loss:3.2779 x Lambda(0.1)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.3005
Validation loss decreased (0.318009 --> 0.317863).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6595193
	speed: 0.0814s/iter; left time: 1949.6835s
	iters: 200, epoch: 7 | loss: 0.6300592
	speed: 0.0792s/iter; left time: 1890.6220s
Epoch: 7 cost time: 20.387550830841064
Epoch: 7, Steps: 256 Train Loss: 0.6394 (Forecasting Loss:0.3117 + XiCon Loss:3.2771 x Lambda(0.1)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.3004
Validation loss decreased (0.317863 --> 0.317114).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6383105
	speed: 0.0790s/iter; left time: 1873.1382s
	iters: 200, epoch: 8 | loss: 0.6213968
	speed: 0.0423s/iter; left time: 997.7434s
Epoch: 8 cost time: 14.349504470825195
Epoch: 8, Steps: 256 Train Loss: 0.6393 (Forecasting Loss:0.3116 + XiCon Loss:3.2771 x Lambda(0.1)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.3005
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6707826
	speed: 0.0820s/iter; left time: 1923.1047s
	iters: 200, epoch: 9 | loss: 0.6424075
	speed: 0.0771s/iter; left time: 1800.1670s
Epoch: 9 cost time: 20.273456811904907
Epoch: 9, Steps: 256 Train Loss: 0.6392 (Forecasting Loss:0.3115 + XiCon Loss:3.2774 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.3005
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6444162
	speed: 0.0804s/iter; left time: 1864.0972s
	iters: 200, epoch: 10 | loss: 0.6531862
	speed: 0.0784s/iter; left time: 1810.8325s
Epoch: 10 cost time: 20.13755464553833
Epoch: 10, Steps: 256 Train Loss: 0.6390 (Forecasting Loss:0.3115 + XiCon Loss:3.2756 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.3005
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6526300
	speed: 0.0816s/iter; left time: 1870.9286s
	iters: 200, epoch: 11 | loss: 0.6563716
	speed: 0.0773s/iter; left time: 1766.6060s
Epoch: 11 cost time: 20.527433156967163
Epoch: 11, Steps: 256 Train Loss: 0.6392 (Forecasting Loss:0.3115 + XiCon Loss:3.2773 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3005
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6456912
	speed: 0.0789s/iter; left time: 1790.8688s
	iters: 200, epoch: 12 | loss: 0.6290191
	speed: 0.0687s/iter; left time: 1552.6729s
Epoch: 12 cost time: 16.96918797492981
Epoch: 12, Steps: 256 Train Loss: 0.6391 (Forecasting Loss:0.3114 + XiCon Loss:3.2766 x Lambda(0.1)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.3005
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6469499
	speed: 0.0675s/iter; left time: 1513.4631s
	iters: 200, epoch: 13 | loss: 0.6396796
	speed: 0.0793s/iter; left time: 1770.3107s
Epoch: 13 cost time: 19.21825861930847
Epoch: 13, Steps: 256 Train Loss: 0.6392 (Forecasting Loss:0.3114 + XiCon Loss:3.2772 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.3004
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6365783
	speed: 0.0803s/iter; left time: 1781.0732s
	iters: 200, epoch: 14 | loss: 0.6324785
	speed: 0.0752s/iter; left time: 1659.1446s
Epoch: 14 cost time: 20.22226619720459
Epoch: 14, Steps: 256 Train Loss: 0.6390 (Forecasting Loss:0.3114 + XiCon Loss:3.2758 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3004
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6482854
	speed: 0.0819s/iter; left time: 1795.5639s
	iters: 200, epoch: 15 | loss: 0.6200559
	speed: 0.0819s/iter; left time: 1786.4154s
Epoch: 15 cost time: 20.794543981552124
Epoch: 15, Steps: 256 Train Loss: 0.6390 (Forecasting Loss:0.3114 + XiCon Loss:3.2756 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3004
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6713076
	speed: 0.0825s/iter; left time: 1787.0104s
	iters: 200, epoch: 16 | loss: 0.6280732
	speed: 0.0740s/iter; left time: 1595.4438s
Epoch: 16 cost time: 19.788691759109497
Epoch: 16, Steps: 256 Train Loss: 0.6391 (Forecasting Loss:0.3115 + XiCon Loss:3.2759 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3004
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6240700
	speed: 0.0829s/iter; left time: 1773.6143s
	iters: 200, epoch: 17 | loss: 0.6467245
	speed: 0.0790s/iter; left time: 1683.1928s
Epoch: 17 cost time: 20.962528467178345
Epoch: 17, Steps: 256 Train Loss: 0.6389 (Forecasting Loss:0.3114 + XiCon Loss:3.2751 x Lambda(0.1)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.3004
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2268252968788147, mae:0.3740510940551758, mape:0.7550504207611084, mspe:19.216394424438477 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8216
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.8081371
	speed: 0.0481s/iter; left time: 1226.6087s
	iters: 200, epoch: 1 | loss: 0.7869293
	speed: 0.0804s/iter; left time: 2043.4826s
Epoch: 1 cost time: 18.15139675140381
Epoch: 1, Steps: 256 Train Loss: 0.7677 (Forecasting Loss:0.4309 + XiCon Loss:3.3680 x Lambda(0.1)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3795
Validation loss decreased (inf --> 0.409640).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6773801
	speed: 0.1034s/iter; left time: 2611.3231s
	iters: 200, epoch: 2 | loss: 0.6486500
	speed: 0.0987s/iter; left time: 2482.4469s
Epoch: 2 cost time: 25.717338800430298
Epoch: 2, Steps: 256 Train Loss: 0.6810 (Forecasting Loss:0.3486 + XiCon Loss:3.3237 x Lambda(0.1)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2966
Validation loss decreased (0.409640 --> 0.324762).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6372848
	speed: 0.0427s/iter; left time: 1066.2647s
	iters: 200, epoch: 3 | loss: 0.6486936
	speed: 0.0329s/iter; left time: 818.4681s
Epoch: 3 cost time: 10.993983507156372
Epoch: 3, Steps: 256 Train Loss: 0.6451 (Forecasting Loss:0.3196 + XiCon Loss:3.2556 x Lambda(0.1)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2956
Validation loss decreased (0.324762 --> 0.320664).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6584404
	speed: 0.0752s/iter; left time: 1858.9464s
	iters: 200, epoch: 4 | loss: 0.6334001
	speed: 0.0747s/iter; left time: 1841.1643s
Epoch: 4 cost time: 19.19175124168396
Epoch: 4, Steps: 256 Train Loss: 0.6387 (Forecasting Loss:0.3154 + XiCon Loss:3.2331 x Lambda(0.1)), Vali MSE Loss: 0.3178 Test MSE Loss: 0.2956
Validation loss decreased (0.320664 --> 0.317796).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6130056
	speed: 0.0780s/iter; left time: 1910.0064s
	iters: 200, epoch: 5 | loss: 0.6572434
	speed: 0.0674s/iter; left time: 1644.1310s
Epoch: 5 cost time: 18.07792019844055
Epoch: 5, Steps: 256 Train Loss: 0.6367 (Forecasting Loss:0.3141 + XiCon Loss:3.2260 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2957
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6662546
	speed: 0.0780s/iter; left time: 1888.5846s
	iters: 200, epoch: 6 | loss: 0.6282567
	speed: 0.0738s/iter; left time: 1781.2425s
Epoch: 6 cost time: 19.1193208694458
Epoch: 6, Steps: 256 Train Loss: 0.6359 (Forecasting Loss:0.3136 + XiCon Loss:3.2238 x Lambda(0.1)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.2957
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6497283
	speed: 0.0780s/iter; left time: 1869.4893s
	iters: 200, epoch: 7 | loss: 0.6380284
	speed: 0.0692s/iter; left time: 1652.6094s
Epoch: 7 cost time: 18.24800205230713
Epoch: 7, Steps: 256 Train Loss: 0.6352 (Forecasting Loss:0.3131 + XiCon Loss:3.2203 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2959
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6118671
	speed: 0.0786s/iter; left time: 1863.5390s
	iters: 200, epoch: 8 | loss: 0.6273878
	speed: 0.0715s/iter; left time: 1688.6176s
Epoch: 8 cost time: 19.01897644996643
Epoch: 8, Steps: 256 Train Loss: 0.6352 (Forecasting Loss:0.3130 + XiCon Loss:3.2214 x Lambda(0.1)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2958
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6245491
	speed: 0.0751s/iter; left time: 1760.6464s
	iters: 200, epoch: 9 | loss: 0.6688304
	speed: 0.0709s/iter; left time: 1656.7878s
Epoch: 9 cost time: 18.341509342193604
Epoch: 9, Steps: 256 Train Loss: 0.6349 (Forecasting Loss:0.3129 + XiCon Loss:3.2205 x Lambda(0.1)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2959
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6386507
	speed: 0.0743s/iter; left time: 1723.5657s
	iters: 200, epoch: 10 | loss: 0.6319364
	speed: 0.0741s/iter; left time: 1711.7924s
Epoch: 10 cost time: 18.98988103866577
Epoch: 10, Steps: 256 Train Loss: 0.6353 (Forecasting Loss:0.3131 + XiCon Loss:3.2221 x Lambda(0.1)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2959
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6317570
	speed: 0.0776s/iter; left time: 1780.9169s
	iters: 200, epoch: 11 | loss: 0.6632502
	speed: 0.0746s/iter; left time: 1704.3674s
Epoch: 11 cost time: 18.728198528289795
Epoch: 11, Steps: 256 Train Loss: 0.6351 (Forecasting Loss:0.3129 + XiCon Loss:3.2220 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2959
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6412465
	speed: 0.0733s/iter; left time: 1662.7535s
	iters: 200, epoch: 12 | loss: 0.6512647
	speed: 0.0752s/iter; left time: 1697.3002s
Epoch: 12 cost time: 18.946192979812622
Epoch: 12, Steps: 256 Train Loss: 0.6353 (Forecasting Loss:0.3131 + XiCon Loss:3.2219 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2959
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6244019
	speed: 0.0787s/iter; left time: 1765.3608s
	iters: 200, epoch: 13 | loss: 0.6551581
	speed: 0.0743s/iter; left time: 1658.5122s
Epoch: 13 cost time: 18.873833417892456
Epoch: 13, Steps: 256 Train Loss: 0.6351 (Forecasting Loss:0.3129 + XiCon Loss:3.2213 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2959
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6391820
	speed: 0.0711s/iter; left time: 1576.2164s
	iters: 200, epoch: 14 | loss: 0.6327208
	speed: 0.0732s/iter; left time: 1615.9790s
Epoch: 14 cost time: 18.75983476638794
Epoch: 14, Steps: 256 Train Loss: 0.6349 (Forecasting Loss:0.3129 + XiCon Loss:3.2208 x Lambda(0.1)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2959
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22087416052818298, mae:0.3702889084815979, mape:0.7460750341415405, mspe:19.190231323242188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9053
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.8241172
	speed: 0.0707s/iter; left time: 1803.1219s
	iters: 200, epoch: 1 | loss: 0.7658448
	speed: 0.0744s/iter; left time: 1890.6296s
Epoch: 1 cost time: 18.741502285003662
Epoch: 1, Steps: 256 Train Loss: 0.7721 (Forecasting Loss:0.4329 + XiCon Loss:3.3916 x Lambda(0.1)), Vali MSE Loss: 0.4059 Test MSE Loss: 0.3771
Validation loss decreased (inf --> 0.405897).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6677135
	speed: 0.0799s/iter; left time: 2016.8542s
	iters: 200, epoch: 2 | loss: 0.6559029
	speed: 0.0741s/iter; left time: 1862.2731s
Epoch: 2 cost time: 19.306854724884033
Epoch: 2, Steps: 256 Train Loss: 0.6803 (Forecasting Loss:0.3474 + XiCon Loss:3.3286 x Lambda(0.1)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.3012
Validation loss decreased (0.405897 --> 0.313139).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6364820
	speed: 0.0680s/iter; left time: 1699.9502s
	iters: 200, epoch: 3 | loss: 0.6504110
	speed: 0.0757s/iter; left time: 1885.0445s
Epoch: 3 cost time: 18.515119791030884
Epoch: 3, Steps: 256 Train Loss: 0.6448 (Forecasting Loss:0.3166 + XiCon Loss:3.2817 x Lambda(0.1)), Vali MSE Loss: 0.3094 Test MSE Loss: 0.3031
Validation loss decreased (0.313139 --> 0.309384).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6354657
	speed: 0.0776s/iter; left time: 1918.2880s
	iters: 200, epoch: 4 | loss: 0.6338511
	speed: 0.0765s/iter; left time: 1884.9196s
Epoch: 4 cost time: 19.59872269630432
Epoch: 4, Steps: 256 Train Loss: 0.6400 (Forecasting Loss:0.3134 + XiCon Loss:3.2661 x Lambda(0.1)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3018
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6288350
	speed: 0.0676s/iter; left time: 1655.5690s
	iters: 200, epoch: 5 | loss: 0.6289750
	speed: 0.0735s/iter; left time: 1790.9868s
Epoch: 5 cost time: 18.31754779815674
Epoch: 5, Steps: 256 Train Loss: 0.6384 (Forecasting Loss:0.3122 + XiCon Loss:3.2613 x Lambda(0.1)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3018
Validation loss decreased (0.309384 --> 0.308565).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6680443
	speed: 0.0770s/iter; left time: 1864.3545s
	iters: 200, epoch: 6 | loss: 0.6442463
	speed: 0.0768s/iter; left time: 1853.6616s
Epoch: 6 cost time: 19.57248306274414
Epoch: 6, Steps: 256 Train Loss: 0.6377 (Forecasting Loss:0.3119 + XiCon Loss:3.2584 x Lambda(0.1)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3016
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6700206
	speed: 0.0686s/iter; left time: 1643.5284s
	iters: 200, epoch: 7 | loss: 0.6545907
	speed: 0.0755s/iter; left time: 1801.7417s
Epoch: 7 cost time: 18.823697090148926
Epoch: 7, Steps: 256 Train Loss: 0.6373 (Forecasting Loss:0.3115 + XiCon Loss:3.2581 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.3013
Validation loss decreased (0.308565 --> 0.308104).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6120334
	speed: 0.0775s/iter; left time: 1837.5705s
	iters: 200, epoch: 8 | loss: 0.6257461
	speed: 0.0752s/iter; left time: 1776.0987s
Epoch: 8 cost time: 19.56244921684265
Epoch: 8, Steps: 256 Train Loss: 0.6372 (Forecasting Loss:0.3114 + XiCon Loss:3.2575 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.3014
Validation loss decreased (0.308104 --> 0.308057).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6526821
	speed: 0.0690s/iter; left time: 1617.8942s
	iters: 200, epoch: 9 | loss: 0.6481267
	speed: 0.0767s/iter; left time: 1792.0738s
Epoch: 9 cost time: 18.823747396469116
Epoch: 9, Steps: 256 Train Loss: 0.6371 (Forecasting Loss:0.3114 + XiCon Loss:3.2569 x Lambda(0.1)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.3015
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6467701
	speed: 0.0781s/iter; left time: 1810.9561s
	iters: 200, epoch: 10 | loss: 0.6391584
	speed: 0.0748s/iter; left time: 1726.5960s
Epoch: 10 cost time: 19.51094388961792
Epoch: 10, Steps: 256 Train Loss: 0.6370 (Forecasting Loss:0.3115 + XiCon Loss:3.2551 x Lambda(0.1)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.3015
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6535760
	speed: 0.0695s/iter; left time: 1594.0518s
	iters: 200, epoch: 11 | loss: 0.6379123
	speed: 0.0770s/iter; left time: 1758.5524s
Epoch: 11 cost time: 18.646668434143066
Epoch: 11, Steps: 256 Train Loss: 0.6370 (Forecasting Loss:0.3114 + XiCon Loss:3.2560 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6341275
	speed: 0.0792s/iter; left time: 1797.1744s
	iters: 200, epoch: 12 | loss: 0.6566145
	speed: 0.0766s/iter; left time: 1731.1009s
Epoch: 12 cost time: 19.90068745613098
Epoch: 12, Steps: 256 Train Loss: 0.6369 (Forecasting Loss:0.3113 + XiCon Loss:3.2557 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6216668
	speed: 0.0710s/iter; left time: 1592.7778s
	iters: 200, epoch: 13 | loss: 0.6251943
	speed: 0.0701s/iter; left time: 1565.1070s
Epoch: 13 cost time: 18.454097509384155
Epoch: 13, Steps: 256 Train Loss: 0.6369 (Forecasting Loss:0.3113 + XiCon Loss:3.2561 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.3014
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6373187
	speed: 0.0769s/iter; left time: 1704.6462s
	iters: 200, epoch: 14 | loss: 0.6350039
	speed: 0.0759s/iter; left time: 1676.1909s
Epoch: 14 cost time: 19.5530047416687
Epoch: 14, Steps: 256 Train Loss: 0.6369 (Forecasting Loss:0.3114 + XiCon Loss:3.2549 x Lambda(0.1)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.3014
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6254353
	speed: 0.0675s/iter; left time: 1478.7812s
	iters: 200, epoch: 15 | loss: 0.6229573
	speed: 0.0708s/iter; left time: 1544.2774s
Epoch: 15 cost time: 17.937708139419556
Epoch: 15, Steps: 256 Train Loss: 0.6369 (Forecasting Loss:0.3113 + XiCon Loss:3.2558 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6019986
	speed: 0.0784s/iter; left time: 1697.5947s
	iters: 200, epoch: 16 | loss: 0.6239804
	speed: 0.0759s/iter; left time: 1635.7539s
Epoch: 16 cost time: 19.724096298217773
Epoch: 16, Steps: 256 Train Loss: 0.6369 (Forecasting Loss:0.3113 + XiCon Loss:3.2560 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6364671
	speed: 0.0683s/iter; left time: 1461.3746s
	iters: 200, epoch: 17 | loss: 0.6515112
	speed: 0.0707s/iter; left time: 1507.0915s
Epoch: 17 cost time: 18.233473777770996
Epoch: 17, Steps: 256 Train Loss: 0.6372 (Forecasting Loss:0.3114 + XiCon Loss:3.2573 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6529405
	speed: 0.0778s/iter; left time: 1645.4420s
	iters: 200, epoch: 18 | loss: 0.6255041
	speed: 0.0756s/iter; left time: 1591.5591s
Epoch: 18 cost time: 19.712259531021118
Epoch: 18, Steps: 256 Train Loss: 0.6370 (Forecasting Loss:0.3113 + XiCon Loss:3.2567 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3014
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22783713042736053, mae:0.3748917579650879, mape:0.7595338225364685, mspe:19.228015899658203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.0084
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.7971385
	speed: 0.0709s/iter; left time: 1808.0720s
	iters: 200, epoch: 1 | loss: 0.7446990
	speed: 0.0691s/iter; left time: 1754.0256s
Epoch: 1 cost time: 17.67232608795166
Epoch: 1, Steps: 256 Train Loss: 0.7752 (Forecasting Loss:0.4362 + XiCon Loss:3.3893 x Lambda(0.1)), Vali MSE Loss: 0.3993 Test MSE Loss: 0.3712
Validation loss decreased (inf --> 0.399326).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6937943
	speed: 0.0700s/iter; left time: 1766.8544s
	iters: 200, epoch: 2 | loss: 0.6580172
	speed: 0.0593s/iter; left time: 1491.4132s
Epoch: 2 cost time: 16.441425561904907
Epoch: 2, Steps: 256 Train Loss: 0.6799 (Forecasting Loss:0.3455 + XiCon Loss:3.3441 x Lambda(0.1)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.3010
Validation loss decreased (0.399326 --> 0.320691).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6320611
	speed: 0.0698s/iter; left time: 1744.5185s
	iters: 200, epoch: 3 | loss: 0.6442119
	speed: 0.0672s/iter; left time: 1671.5126s
Epoch: 3 cost time: 17.634369373321533
Epoch: 3, Steps: 256 Train Loss: 0.6489 (Forecasting Loss:0.3179 + XiCon Loss:3.3095 x Lambda(0.1)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.3042
Validation loss decreased (0.320691 --> 0.314705).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6359000
	speed: 0.0718s/iter; left time: 1775.0466s
	iters: 200, epoch: 4 | loss: 0.6584116
	speed: 0.0681s/iter; left time: 1677.5180s
Epoch: 4 cost time: 17.087138891220093
Epoch: 4, Steps: 256 Train Loss: 0.6444 (Forecasting Loss:0.3146 + XiCon Loss:3.2983 x Lambda(0.1)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.3026
Validation loss decreased (0.314705 --> 0.313541).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6571609
	speed: 0.0659s/iter; left time: 1613.7732s
	iters: 200, epoch: 5 | loss: 0.6473962
	speed: 0.0683s/iter; left time: 1665.7791s
Epoch: 5 cost time: 17.215201139450073
Epoch: 5, Steps: 256 Train Loss: 0.6430 (Forecasting Loss:0.3136 + XiCon Loss:3.2939 x Lambda(0.1)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.3024
Validation loss decreased (0.313541 --> 0.311579).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6379883
	speed: 0.0705s/iter; left time: 1706.4765s
	iters: 200, epoch: 6 | loss: 0.6367878
	speed: 0.0661s/iter; left time: 1593.2447s
Epoch: 6 cost time: 17.471805810928345
Epoch: 6, Steps: 256 Train Loss: 0.6424 (Forecasting Loss:0.3132 + XiCon Loss:3.2919 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6388311
	speed: 0.0646s/iter; left time: 1549.0055s
	iters: 200, epoch: 7 | loss: 0.6244711
	speed: 0.0701s/iter; left time: 1671.8423s
Epoch: 7 cost time: 17.581148624420166
Epoch: 7, Steps: 256 Train Loss: 0.6417 (Forecasting Loss:0.3128 + XiCon Loss:3.2892 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6564001
	speed: 0.0688s/iter; left time: 1631.2479s
	iters: 200, epoch: 8 | loss: 0.6354927
	speed: 0.0692s/iter; left time: 1634.1227s
Epoch: 8 cost time: 17.690213918685913
Epoch: 8, Steps: 256 Train Loss: 0.6415 (Forecasting Loss:0.3127 + XiCon Loss:3.2887 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6264793
	speed: 0.0695s/iter; left time: 1630.1606s
	iters: 200, epoch: 9 | loss: 0.6251557
	speed: 0.0540s/iter; left time: 1261.5901s
Epoch: 9 cost time: 14.102469205856323
Epoch: 9, Steps: 256 Train Loss: 0.6417 (Forecasting Loss:0.3127 + XiCon Loss:3.2895 x Lambda(0.1)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.3024
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6495067
	speed: 0.0332s/iter; left time: 770.5854s
	iters: 200, epoch: 10 | loss: 0.6373065
	speed: 0.0678s/iter; left time: 1565.0573s
Epoch: 10 cost time: 13.642139673233032
Epoch: 10, Steps: 256 Train Loss: 0.6416 (Forecasting Loss:0.3127 + XiCon Loss:3.2892 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3024
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6328627
	speed: 0.0772s/iter; left time: 1770.1564s
	iters: 200, epoch: 11 | loss: 0.6430348
	speed: 0.0701s/iter; left time: 1600.5372s
Epoch: 11 cost time: 18.92483353614807
Epoch: 11, Steps: 256 Train Loss: 0.6416 (Forecasting Loss:0.3128 + XiCon Loss:3.2886 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3024
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6453785
	speed: 0.0635s/iter; left time: 1441.1205s
	iters: 200, epoch: 12 | loss: 0.6511524
	speed: 0.0578s/iter; left time: 1304.5674s
Epoch: 12 cost time: 16.022721767425537
Epoch: 12, Steps: 256 Train Loss: 0.6416 (Forecasting Loss:0.3126 + XiCon Loss:3.2894 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.3024
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6460578
	speed: 0.0708s/iter; left time: 1587.7815s
	iters: 200, epoch: 13 | loss: 0.6391296
	speed: 0.0656s/iter; left time: 1465.6509s
Epoch: 13 cost time: 17.505717992782593
Epoch: 13, Steps: 256 Train Loss: 0.6413 (Forecasting Loss:0.3126 + XiCon Loss:3.2876 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3024
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6255865
	speed: 0.0699s/iter; left time: 1549.0700s
	iters: 200, epoch: 14 | loss: 0.6496620
	speed: 0.0622s/iter; left time: 1373.2001s
Epoch: 14 cost time: 16.433133602142334
Epoch: 14, Steps: 256 Train Loss: 0.6414 (Forecasting Loss:0.3126 + XiCon Loss:3.2875 x Lambda(0.1)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3024
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6524740
	speed: 0.0722s/iter; left time: 1581.9364s
	iters: 200, epoch: 15 | loss: 0.6390394
	speed: 0.0659s/iter; left time: 1437.2428s
Epoch: 15 cost time: 17.573278427124023
Epoch: 15, Steps: 256 Train Loss: 0.6415 (Forecasting Loss:0.3127 + XiCon Loss:3.2886 x Lambda(0.1)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.3024
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22769562900066376, mae:0.37709730863571167, mape:0.7802947163581848, mspe:20.64362335205078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8708
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.7450322
	speed: 0.0792s/iter; left time: 2020.7115s
	iters: 200, epoch: 1 | loss: 0.7613335
	speed: 0.0778s/iter; left time: 1975.4441s
Epoch: 1 cost time: 19.77046227455139
Epoch: 1, Steps: 256 Train Loss: 0.7680 (Forecasting Loss:0.4311 + XiCon Loss:3.3692 x Lambda(0.1)), Vali MSE Loss: 0.4130 Test MSE Loss: 0.3825
Validation loss decreased (inf --> 0.413008).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6775814
	speed: 0.0773s/iter; left time: 1952.2548s
	iters: 200, epoch: 2 | loss: 0.6461842
	speed: 0.0728s/iter; left time: 1830.4186s
Epoch: 2 cost time: 18.593425273895264
Epoch: 2, Steps: 256 Train Loss: 0.6810 (Forecasting Loss:0.3493 + XiCon Loss:3.3166 x Lambda(0.1)), Vali MSE Loss: 0.3287 Test MSE Loss: 0.2979
Validation loss decreased (0.413008 --> 0.328708).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6737014
	speed: 0.0756s/iter; left time: 1888.0430s
	iters: 200, epoch: 3 | loss: 0.6421347
	speed: 0.0796s/iter; left time: 1981.6392s
Epoch: 3 cost time: 19.780887603759766
Epoch: 3, Steps: 256 Train Loss: 0.6464 (Forecasting Loss:0.3209 + XiCon Loss:3.2550 x Lambda(0.1)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2967
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6503899
	speed: 0.0786s/iter; left time: 1943.9626s
	iters: 200, epoch: 4 | loss: 0.6448354
	speed: 0.0747s/iter; left time: 1840.5480s
Epoch: 4 cost time: 19.209232568740845
Epoch: 4, Steps: 256 Train Loss: 0.6389 (Forecasting Loss:0.3153 + XiCon Loss:3.2358 x Lambda(0.1)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2956
Validation loss decreased (0.328708 --> 0.322362).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6207002
	speed: 0.0744s/iter; left time: 1820.4304s
	iters: 200, epoch: 5 | loss: 0.6513820
	speed: 0.0745s/iter; left time: 1816.1095s
Epoch: 5 cost time: 19.073037147521973
Epoch: 5, Steps: 256 Train Loss: 0.6367 (Forecasting Loss:0.3137 + XiCon Loss:3.2299 x Lambda(0.1)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2957
Validation loss decreased (0.322362 --> 0.321026).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5975707
	speed: 0.0787s/iter; left time: 1906.9617s
	iters: 200, epoch: 6 | loss: 0.6341488
	speed: 0.0724s/iter; left time: 1746.5992s
Epoch: 6 cost time: 18.792460441589355
Epoch: 6, Steps: 256 Train Loss: 0.6357 (Forecasting Loss:0.3129 + XiCon Loss:3.2283 x Lambda(0.1)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2955
Validation loss decreased (0.321026 --> 0.319203).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6150936
	speed: 0.0496s/iter; left time: 1188.7413s
	iters: 200, epoch: 7 | loss: 0.6337789
	speed: 0.0346s/iter; left time: 825.4534s
Epoch: 7 cost time: 10.943282842636108
Epoch: 7, Steps: 256 Train Loss: 0.6352 (Forecasting Loss:0.3125 + XiCon Loss:3.2271 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2958
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6286908
	speed: 0.0758s/iter; left time: 1797.5060s
	iters: 200, epoch: 8 | loss: 0.6247494
	speed: 0.0742s/iter; left time: 1751.3795s
Epoch: 8 cost time: 19.327011823654175
Epoch: 8, Steps: 256 Train Loss: 0.6349 (Forecasting Loss:0.3123 + XiCon Loss:3.2261 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2955
Validation loss decreased (0.319203 --> 0.318094).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6242341
	speed: 0.0814s/iter; left time: 1909.5684s
	iters: 200, epoch: 9 | loss: 0.6661177
	speed: 0.0688s/iter; left time: 1606.9643s
Epoch: 9 cost time: 18.680250644683838
Epoch: 9, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2246 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6279470
	speed: 0.0768s/iter; left time: 1781.5295s
	iters: 200, epoch: 10 | loss: 0.6697005
	speed: 0.0751s/iter; left time: 1734.8496s
Epoch: 10 cost time: 19.601099729537964
Epoch: 10, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3123 + XiCon Loss:3.2258 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6371556
	speed: 0.0802s/iter; left time: 1840.3758s
	iters: 200, epoch: 11 | loss: 0.6709194
	speed: 0.0703s/iter; left time: 1606.3743s
Epoch: 11 cost time: 18.42516803741455
Epoch: 11, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6650379
	speed: 0.0786s/iter; left time: 1782.7279s
	iters: 200, epoch: 12 | loss: 0.6153854
	speed: 0.0761s/iter; left time: 1719.3294s
Epoch: 12 cost time: 19.70920467376709
Epoch: 12, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2241 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6345291
	speed: 0.0782s/iter; left time: 1754.3752s
	iters: 200, epoch: 13 | loss: 0.6332546
	speed: 0.0725s/iter; left time: 1618.5050s
Epoch: 13 cost time: 18.818569660186768
Epoch: 13, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3121 + XiCon Loss:3.2258 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2956
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6477103
	speed: 0.0808s/iter; left time: 1791.7712s
	iters: 200, epoch: 14 | loss: 0.6235626
	speed: 0.0757s/iter; left time: 1670.5457s
Epoch: 14 cost time: 20.070807456970215
Epoch: 14, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2253 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2956
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6586505
	speed: 0.0787s/iter; left time: 1725.0367s
	iters: 200, epoch: 15 | loss: 0.6365744
	speed: 0.0710s/iter; left time: 1550.0638s
Epoch: 15 cost time: 18.62913155555725
Epoch: 15, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
Validation loss decreased (0.318094 --> 0.318009).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6316333
	speed: 0.0786s/iter; left time: 1702.7239s
	iters: 200, epoch: 16 | loss: 0.6368930
	speed: 0.0762s/iter; left time: 1643.9441s
Epoch: 16 cost time: 19.735180854797363
Epoch: 16, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3121 + XiCon Loss:3.2264 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6423035
	speed: 0.0794s/iter; left time: 1698.7817s
	iters: 200, epoch: 17 | loss: 0.6462508
	speed: 0.0719s/iter; left time: 1531.8975s
Epoch: 17 cost time: 18.814337491989136
Epoch: 17, Steps: 256 Train Loss: 0.6345 (Forecasting Loss:0.3121 + XiCon Loss:3.2243 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6483035
	speed: 0.0773s/iter; left time: 1635.1962s
	iters: 200, epoch: 18 | loss: 0.6343563
	speed: 0.0753s/iter; left time: 1585.8053s
Epoch: 18 cost time: 19.633397340774536
Epoch: 18, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2253 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6190975
	speed: 0.0784s/iter; left time: 1639.0141s
	iters: 200, epoch: 19 | loss: 0.6608468
	speed: 0.0740s/iter; left time: 1538.4905s
Epoch: 19 cost time: 18.941202640533447
Epoch: 19, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2261 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6337323
	speed: 0.0777s/iter; left time: 1602.5989s
	iters: 200, epoch: 20 | loss: 0.6555710
	speed: 0.0744s/iter; left time: 1527.2715s
Epoch: 20 cost time: 19.565855503082275
Epoch: 20, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2240 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6265450
	speed: 0.0808s/iter; left time: 1647.1772s
	iters: 200, epoch: 21 | loss: 0.6449505
	speed: 0.0724s/iter; left time: 1468.7791s
Epoch: 21 cost time: 18.95309591293335
Epoch: 21, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2247 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6174456
	speed: 0.0755s/iter; left time: 1519.9303s
	iters: 200, epoch: 22 | loss: 0.6324421
	speed: 0.0763s/iter; left time: 1527.3388s
Epoch: 22 cost time: 19.47195291519165
Epoch: 22, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2250 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6157731
	speed: 0.0792s/iter; left time: 1573.3565s
	iters: 200, epoch: 23 | loss: 0.6218916
	speed: 0.0776s/iter; left time: 1533.1033s
Epoch: 23 cost time: 19.38943123817444
Epoch: 23, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2253 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
Validation loss decreased (0.318009 --> 0.317965).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6279397
	speed: 0.0737s/iter; left time: 1445.1620s
	iters: 200, epoch: 24 | loss: 0.6284762
	speed: 0.0772s/iter; left time: 1506.4663s
Epoch: 24 cost time: 19.420574188232422
Epoch: 24, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2262 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6341512
	speed: 0.0782s/iter; left time: 1513.2544s
	iters: 200, epoch: 25 | loss: 0.6598370
	speed: 0.0755s/iter; left time: 1453.2856s
Epoch: 25 cost time: 19.109535455703735
Epoch: 25, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6296288
	speed: 0.0742s/iter; left time: 1417.8284s
	iters: 200, epoch: 26 | loss: 0.6438866
	speed: 0.0770s/iter; left time: 1463.3390s
Epoch: 26 cost time: 19.474844455718994
Epoch: 26, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2264 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2956
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6194925
	speed: 0.0786s/iter; left time: 1481.5079s
	iters: 200, epoch: 27 | loss: 0.6450796
	speed: 0.0776s/iter; left time: 1454.6095s
Epoch: 27 cost time: 19.294469833374023
Epoch: 27, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2245 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6204753
	speed: 0.0751s/iter; left time: 1396.4497s
	iters: 200, epoch: 28 | loss: 0.6256731
	speed: 0.0755s/iter; left time: 1395.8727s
Epoch: 28 cost time: 19.30664300918579
Epoch: 28, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2956
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.6370944
	speed: 0.0794s/iter; left time: 1455.4595s
	iters: 200, epoch: 29 | loss: 0.6252050
	speed: 0.0743s/iter; left time: 1355.1298s
Epoch: 29 cost time: 19.458865642547607
Epoch: 29, Steps: 256 Train Loss: 0.6345 (Forecasting Loss:0.3120 + XiCon Loss:3.2249 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6418289
	speed: 0.0739s/iter; left time: 1335.6614s
	iters: 200, epoch: 30 | loss: 0.6464792
	speed: 0.0757s/iter; left time: 1361.4929s
Epoch: 30 cost time: 19.253065824508667
Epoch: 30, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2250 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.6026850
	speed: 0.0776s/iter; left time: 1383.3379s
	iters: 200, epoch: 31 | loss: 0.6516094
	speed: 0.0754s/iter; left time: 1335.3297s
Epoch: 31 cost time: 18.940720558166504
Epoch: 31, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3123 + XiCon Loss:3.2247 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
Validation loss decreased (0.317965 --> 0.317954).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6478511
	speed: 0.0740s/iter; left time: 1300.2386s
	iters: 200, epoch: 32 | loss: 0.6286054
	speed: 0.0750s/iter; left time: 1309.4716s
Epoch: 32 cost time: 19.148670434951782
Epoch: 32, Steps: 256 Train Loss: 0.6349 (Forecasting Loss:0.3123 + XiCon Loss:3.2261 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6136248
	speed: 0.0790s/iter; left time: 1366.9206s
	iters: 200, epoch: 33 | loss: 0.6438718
	speed: 0.0760s/iter; left time: 1308.5616s
Epoch: 33 cost time: 19.362621307373047
Epoch: 33, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3123 + XiCon Loss:3.2253 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.6579173
	speed: 0.0746s/iter; left time: 1272.1125s
	iters: 200, epoch: 34 | loss: 0.6360165
	speed: 0.0764s/iter; left time: 1294.9221s
Epoch: 34 cost time: 19.336516618728638
Epoch: 34, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3121 + XiCon Loss:3.2258 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.6507193
	speed: 0.0780s/iter; left time: 1310.2880s
	iters: 200, epoch: 35 | loss: 0.5962287
	speed: 0.0769s/iter; left time: 1283.4079s
Epoch: 35 cost time: 19.488699913024902
Epoch: 35, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3121 + XiCon Loss:3.2254 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6078309
	speed: 0.0675s/iter; left time: 1117.1007s
	iters: 200, epoch: 36 | loss: 0.6249331
	speed: 0.0778s/iter; left time: 1279.0359s
Epoch: 36 cost time: 18.873189687728882
Epoch: 36, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2245 x Lambda(0.1)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2956
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.6520661
	speed: 0.0774s/iter; left time: 1259.9590s
	iters: 200, epoch: 37 | loss: 0.6567723
	speed: 0.0751s/iter; left time: 1214.9733s
Epoch: 37 cost time: 19.465885877609253
Epoch: 37, Steps: 256 Train Loss: 0.6347 (Forecasting Loss:0.3122 + XiCon Loss:3.2253 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.6267703
	speed: 0.0697s/iter; left time: 1116.6337s
	iters: 200, epoch: 38 | loss: 0.6292609
	speed: 0.0779s/iter; left time: 1241.4003s
Epoch: 38 cost time: 19.03261399269104
Epoch: 38, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2268 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2956
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.6146160
	speed: 0.0784s/iter; left time: 1236.8255s
	iters: 200, epoch: 39 | loss: 0.6372349
	speed: 0.0767s/iter; left time: 1202.5602s
Epoch: 39 cost time: 19.83270001411438
Epoch: 39, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2242 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2956
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.6308118
	speed: 0.0714s/iter; left time: 1107.4271s
	iters: 200, epoch: 40 | loss: 0.6323745
	speed: 0.0754s/iter; left time: 1162.2191s
Epoch: 40 cost time: 18.89060091972351
Epoch: 40, Steps: 256 Train Loss: 0.6348 (Forecasting Loss:0.3122 + XiCon Loss:3.2260 x Lambda(0.1)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2956
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.6445765
	speed: 0.0787s/iter; left time: 1200.9558s
	iters: 200, epoch: 41 | loss: 0.6439599
	speed: 0.0789s/iter; left time: 1196.5848s
Epoch: 41 cost time: 20.241645336151123
Epoch: 41, Steps: 256 Train Loss: 0.6346 (Forecasting Loss:0.3122 + XiCon Loss:3.2243 x Lambda(0.1)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22103174030780792, mae:0.3702116906642914, mape:0.7343589067459106, mspe:18.434444427490234 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2249+-0.00445, MAE:0.3733+-0.00373, MAPE:0.7551+-0.02120, MSPE:19.3425+-0.99521, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9333
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.7772433
	speed: 0.1236s/iter; left time: 3003.8587s
	iters: 200, epoch: 1 | loss: 0.7485489
	speed: 0.1192s/iter; left time: 2884.8695s
Epoch: 1 cost time: 29.311299562454224
Epoch: 1, Steps: 244 Train Loss: 0.7939 (Forecasting Loss:0.4566 + XiCon Loss:3.3732 x Lambda(0.1)), Vali MSE Loss: 0.4455 Test MSE Loss: 0.3453
Validation loss decreased (inf --> 0.445486).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6706593
	speed: 0.1216s/iter; left time: 2925.0770s
	iters: 200, epoch: 2 | loss: 0.6604242
	speed: 0.1193s/iter; left time: 2859.0495s
Epoch: 2 cost time: 29.31335973739624
Epoch: 2, Steps: 244 Train Loss: 0.6854 (Forecasting Loss:0.3545 + XiCon Loss:3.3089 x Lambda(0.1)), Vali MSE Loss: 0.3738 Test MSE Loss: 0.3308
Validation loss decreased (0.445486 --> 0.373768).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6433185
	speed: 0.1203s/iter; left time: 2864.7877s
	iters: 200, epoch: 3 | loss: 0.6650286
	speed: 0.1162s/iter; left time: 2756.3563s
Epoch: 3 cost time: 28.97774887084961
Epoch: 3, Steps: 244 Train Loss: 0.6647 (Forecasting Loss:0.3397 + XiCon Loss:3.2503 x Lambda(0.1)), Vali MSE Loss: 0.3699 Test MSE Loss: 0.3425
Validation loss decreased (0.373768 --> 0.369931).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6456338
	speed: 0.1240s/iter; left time: 2923.2636s
	iters: 200, epoch: 4 | loss: 0.6641214
	speed: 0.1200s/iter; left time: 2816.3354s
Epoch: 4 cost time: 27.439090251922607
Epoch: 4, Steps: 244 Train Loss: 0.6581 (Forecasting Loss:0.3362 + XiCon Loss:3.2197 x Lambda(0.1)), Vali MSE Loss: 0.3588 Test MSE Loss: 0.3391
Validation loss decreased (0.369931 --> 0.358830).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6631312
	speed: 0.0915s/iter; left time: 2135.2907s
	iters: 200, epoch: 5 | loss: 0.6796753
	speed: 0.0893s/iter; left time: 2073.9553s
Epoch: 5 cost time: 21.960328817367554
Epoch: 5, Steps: 244 Train Loss: 0.6548 (Forecasting Loss:0.3344 + XiCon Loss:3.2040 x Lambda(0.1)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.3415
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6465198
	speed: 0.0893s/iter; left time: 2060.6947s
	iters: 200, epoch: 6 | loss: 0.6515428
	speed: 0.0872s/iter; left time: 2004.2059s
Epoch: 6 cost time: 21.47108507156372
Epoch: 6, Steps: 244 Train Loss: 0.6525 (Forecasting Loss:0.3331 + XiCon Loss:3.1941 x Lambda(0.1)), Vali MSE Loss: 0.3662 Test MSE Loss: 0.3446
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6311363
	speed: 0.0999s/iter; left time: 2281.0340s
	iters: 200, epoch: 7 | loss: 0.6305144
	speed: 0.1006s/iter; left time: 2287.4652s
Epoch: 7 cost time: 24.429879903793335
Epoch: 7, Steps: 244 Train Loss: 0.6514 (Forecasting Loss:0.3324 + XiCon Loss:3.1900 x Lambda(0.1)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.3437
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6514513
	speed: 0.1044s/iter; left time: 2359.2735s
	iters: 200, epoch: 8 | loss: 0.6571168
	speed: 0.0986s/iter; left time: 2218.1844s
Epoch: 8 cost time: 24.85438370704651
Epoch: 8, Steps: 244 Train Loss: 0.6512 (Forecasting Loss:0.3322 + XiCon Loss:3.1895 x Lambda(0.1)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.3426
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6434214
	speed: 0.1057s/iter; left time: 2362.3841s
	iters: 200, epoch: 9 | loss: 0.6305827
	speed: 0.0977s/iter; left time: 2174.8107s
Epoch: 9 cost time: 24.669219970703125
Epoch: 9, Steps: 244 Train Loss: 0.6507 (Forecasting Loss:0.3320 + XiCon Loss:3.1877 x Lambda(0.1)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.3425
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6432565
	speed: 0.1002s/iter; left time: 2215.6731s
	iters: 200, epoch: 10 | loss: 0.6351780
	speed: 0.0996s/iter; left time: 2191.7196s
Epoch: 10 cost time: 24.175513744354248
Epoch: 10, Steps: 244 Train Loss: 0.6502 (Forecasting Loss:0.3315 + XiCon Loss:3.1869 x Lambda(0.1)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.3427
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6688218
	speed: 0.1008s/iter; left time: 2203.1328s
	iters: 200, epoch: 11 | loss: 0.6473985
	speed: 0.0987s/iter; left time: 2146.8324s
Epoch: 11 cost time: 24.224367141723633
Epoch: 11, Steps: 244 Train Loss: 0.6504 (Forecasting Loss:0.3318 + XiCon Loss:3.1860 x Lambda(0.1)), Vali MSE Loss: 0.3626 Test MSE Loss: 0.3425
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6750351
	speed: 0.1020s/iter; left time: 2203.9405s
	iters: 200, epoch: 12 | loss: 0.6329435
	speed: 0.0982s/iter; left time: 2113.3073s
Epoch: 12 cost time: 24.322505474090576
Epoch: 12, Steps: 244 Train Loss: 0.6502 (Forecasting Loss:0.3316 + XiCon Loss:3.1857 x Lambda(0.1)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.3426
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6654935
	speed: 0.1051s/iter; left time: 2246.3433s
	iters: 200, epoch: 13 | loss: 0.6591966
	speed: 0.0993s/iter; left time: 2113.3468s
Epoch: 13 cost time: 24.96967601776123
Epoch: 13, Steps: 244 Train Loss: 0.6502 (Forecasting Loss:0.3316 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.3427
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6297522
	speed: 0.1057s/iter; left time: 2233.3953s
	iters: 200, epoch: 14 | loss: 0.6474110
	speed: 0.0985s/iter; left time: 2071.3346s
Epoch: 14 cost time: 24.66298007965088
Epoch: 14, Steps: 244 Train Loss: 0.6501 (Forecasting Loss:0.3315 + XiCon Loss:3.1855 x Lambda(0.1)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.3427
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.26992008090019226, mae:0.40824005007743835, mape:0.7412649393081665, mspe:20.138744354248047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.8146
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.8115362
	speed: 0.0862s/iter; left time: 2095.8173s
	iters: 200, epoch: 1 | loss: 0.7768068
	speed: 0.0839s/iter; left time: 2031.4381s
Epoch: 1 cost time: 20.706061601638794
Epoch: 1, Steps: 244 Train Loss: 0.7956 (Forecasting Loss:0.4582 + XiCon Loss:3.3741 x Lambda(0.1)), Vali MSE Loss: 0.4572 Test MSE Loss: 0.3603
Validation loss decreased (inf --> 0.457231).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6652499
	speed: 0.0866s/iter; left time: 2082.9836s
	iters: 200, epoch: 2 | loss: 0.6499053
	speed: 0.0826s/iter; left time: 1977.6629s
Epoch: 2 cost time: 20.636698007583618
Epoch: 2, Steps: 244 Train Loss: 0.6830 (Forecasting Loss:0.3580 + XiCon Loss:3.2500 x Lambda(0.1)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.3213
Validation loss decreased (0.457231 --> 0.326569).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6223620
	speed: 0.0888s/iter; left time: 2114.1228s
	iters: 200, epoch: 3 | loss: 0.6123873
	speed: 0.0884s/iter; left time: 2096.9833s
Epoch: 3 cost time: 21.67672371864319
Epoch: 3, Steps: 244 Train Loss: 0.6368 (Forecasting Loss:0.3163 + XiCon Loss:3.2050 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.3100
Validation loss decreased (0.326569 --> 0.301419).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6313226
	speed: 0.0946s/iter; left time: 2229.7922s
	iters: 200, epoch: 4 | loss: 0.6359107
	speed: 0.0945s/iter; left time: 2218.5109s
Epoch: 4 cost time: 23.291380882263184
Epoch: 4, Steps: 244 Train Loss: 0.6378 (Forecasting Loss:0.3111 + XiCon Loss:3.2671 x Lambda(0.1)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.3127
Validation loss decreased (0.301419 --> 0.297571).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6531180
	speed: 0.0956s/iter; left time: 2229.6653s
	iters: 200, epoch: 5 | loss: 0.6312893
	speed: 0.0951s/iter; left time: 2209.7517s
Epoch: 5 cost time: 23.471853256225586
Epoch: 5, Steps: 244 Train Loss: 0.6375 (Forecasting Loss:0.3087 + XiCon Loss:3.2879 x Lambda(0.1)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.3059
Validation loss decreased (0.297571 --> 0.294626).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6551270
	speed: 0.1006s/iter; left time: 2320.9676s
	iters: 200, epoch: 6 | loss: 0.6327995
	speed: 0.0932s/iter; left time: 2141.2566s
Epoch: 6 cost time: 23.582291841506958
Epoch: 6, Steps: 244 Train Loss: 0.6370 (Forecasting Loss:0.3075 + XiCon Loss:3.2947 x Lambda(0.1)), Vali MSE Loss: 0.2955 Test MSE Loss: 0.3095
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6493219
	speed: 0.0964s/iter; left time: 2201.0675s
	iters: 200, epoch: 7 | loss: 0.6463305
	speed: 0.0939s/iter; left time: 2135.5660s
Epoch: 7 cost time: 23.33862590789795
Epoch: 7, Steps: 244 Train Loss: 0.6364 (Forecasting Loss:0.3068 + XiCon Loss:3.2963 x Lambda(0.1)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.3074
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6231665
	speed: 0.1000s/iter; left time: 2260.0101s
	iters: 200, epoch: 8 | loss: 0.6459368
	speed: 0.0936s/iter; left time: 2105.2306s
Epoch: 8 cost time: 23.575420379638672
Epoch: 8, Steps: 244 Train Loss: 0.6363 (Forecasting Loss:0.3063 + XiCon Loss:3.2993 x Lambda(0.1)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.3075
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6355480
	speed: 0.1011s/iter; left time: 2258.5207s
	iters: 200, epoch: 9 | loss: 0.6337751
	speed: 0.0976s/iter; left time: 2171.5454s
Epoch: 9 cost time: 24.220946311950684
Epoch: 9, Steps: 244 Train Loss: 0.6365 (Forecasting Loss:0.3066 + XiCon Loss:3.2995 x Lambda(0.1)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.3077
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6390173
	speed: 0.1002s/iter; left time: 2214.6883s
	iters: 200, epoch: 10 | loss: 0.6307892
	speed: 0.0980s/iter; left time: 2157.4897s
Epoch: 10 cost time: 24.15285897254944
Epoch: 10, Steps: 244 Train Loss: 0.6367 (Forecasting Loss:0.3066 + XiCon Loss:3.3015 x Lambda(0.1)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.3075
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6296741
	speed: 0.1005s/iter; left time: 2197.5073s
	iters: 200, epoch: 11 | loss: 0.6441563
	speed: 0.0964s/iter; left time: 2098.2792s
Epoch: 11 cost time: 23.868358850479126
Epoch: 11, Steps: 244 Train Loss: 0.6360 (Forecasting Loss:0.3061 + XiCon Loss:3.2990 x Lambda(0.1)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.3072
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6269009
	speed: 0.0965s/iter; left time: 2085.0226s
	iters: 200, epoch: 12 | loss: 0.6300880
	speed: 0.0950s/iter; left time: 2044.6777s
Epoch: 12 cost time: 23.424001455307007
Epoch: 12, Steps: 244 Train Loss: 0.6361 (Forecasting Loss:0.3061 + XiCon Loss:3.3002 x Lambda(0.1)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.3075
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6554713
	speed: 0.1000s/iter; left time: 2136.7198s
	iters: 200, epoch: 13 | loss: 0.6176959
	speed: 0.0929s/iter; left time: 1977.0095s
Epoch: 13 cost time: 23.52901315689087
Epoch: 13, Steps: 244 Train Loss: 0.6362 (Forecasting Loss:0.3063 + XiCon Loss:3.2992 x Lambda(0.1)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.3075
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6198056
	speed: 0.0988s/iter; left time: 2088.5467s
	iters: 200, epoch: 14 | loss: 0.6495140
	speed: 0.0949s/iter; left time: 1995.1445s
Epoch: 14 cost time: 23.645101070404053
Epoch: 14, Steps: 244 Train Loss: 0.6364 (Forecasting Loss:0.3063 + XiCon Loss:3.3008 x Lambda(0.1)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.3075
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6035761
	speed: 0.0995s/iter; left time: 2077.7163s
	iters: 200, epoch: 15 | loss: 0.6571670
	speed: 0.0960s/iter; left time: 1994.3273s
Epoch: 15 cost time: 23.875224828720093
Epoch: 15, Steps: 244 Train Loss: 0.6362 (Forecasting Loss:0.3063 + XiCon Loss:3.2986 x Lambda(0.1)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.3075
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22780613601207733, mae:0.38403916358947754, mape:0.6948476433753967, mspe:16.89937400817871 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.3871
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.8282059
	speed: 0.0929s/iter; left time: 2257.0976s
	iters: 200, epoch: 1 | loss: 0.7524945
	speed: 0.0884s/iter; left time: 2139.9371s
Epoch: 1 cost time: 22.01274013519287
Epoch: 1, Steps: 244 Train Loss: 0.7981 (Forecasting Loss:0.4607 + XiCon Loss:3.3740 x Lambda(0.1)), Vali MSE Loss: 0.4633 Test MSE Loss: 0.3677
Validation loss decreased (inf --> 0.463313).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6673254
	speed: 0.0907s/iter; left time: 2180.9875s
	iters: 200, epoch: 2 | loss: 0.6629130
	speed: 0.0865s/iter; left time: 2073.2435s
Epoch: 2 cost time: 21.648163318634033
Epoch: 2, Steps: 244 Train Loss: 0.6888 (Forecasting Loss:0.3619 + XiCon Loss:3.2684 x Lambda(0.1)), Vali MSE Loss: 0.3738 Test MSE Loss: 0.3399
Validation loss decreased (0.463313 --> 0.373825).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6691729
	speed: 0.0915s/iter; left time: 2180.0012s
	iters: 200, epoch: 3 | loss: 0.6464882
	speed: 0.0911s/iter; left time: 2159.7249s
Epoch: 3 cost time: 22.20504927635193
Epoch: 3, Steps: 244 Train Loss: 0.6585 (Forecasting Loss:0.3367 + XiCon Loss:3.2179 x Lambda(0.1)), Vali MSE Loss: 0.3626 Test MSE Loss: 0.3405
Validation loss decreased (0.373825 --> 0.362552).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6609395
	speed: 0.0900s/iter; left time: 2120.5468s
	iters: 200, epoch: 4 | loss: 0.6753289
	speed: 0.0873s/iter; left time: 2048.9537s
Epoch: 4 cost time: 21.792277812957764
Epoch: 4, Steps: 244 Train Loss: 0.6521 (Forecasting Loss:0.3321 + XiCon Loss:3.2004 x Lambda(0.1)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.3297
Validation loss decreased (0.362552 --> 0.353769).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6646197
	speed: 0.0935s/iter; left time: 2180.4192s
	iters: 200, epoch: 5 | loss: 0.6468115
	speed: 0.0884s/iter; left time: 2052.3666s
Epoch: 5 cost time: 22.171558380126953
Epoch: 5, Steps: 244 Train Loss: 0.6482 (Forecasting Loss:0.3288 + XiCon Loss:3.1945 x Lambda(0.1)), Vali MSE Loss: 0.3595 Test MSE Loss: 0.3364
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6373696
	speed: 0.0888s/iter; left time: 2049.1861s
	iters: 200, epoch: 6 | loss: 0.6433843
	speed: 0.0883s/iter; left time: 2029.6360s
Epoch: 6 cost time: 21.658103466033936
Epoch: 6, Steps: 244 Train Loss: 0.6459 (Forecasting Loss:0.3272 + XiCon Loss:3.1877 x Lambda(0.1)), Vali MSE Loss: 0.3559 Test MSE Loss: 0.3352
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6478575
	speed: 0.0919s/iter; left time: 2098.7353s
	iters: 200, epoch: 7 | loss: 0.6409388
	speed: 0.0885s/iter; left time: 2012.7052s
Epoch: 7 cost time: 21.983608961105347
Epoch: 7, Steps: 244 Train Loss: 0.6450 (Forecasting Loss:0.3262 + XiCon Loss:3.1875 x Lambda(0.1)), Vali MSE Loss: 0.3546 Test MSE Loss: 0.3334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6504338
	speed: 0.0908s/iter; left time: 2052.5626s
	iters: 200, epoch: 8 | loss: 0.6415699
	speed: 0.0886s/iter; left time: 1992.4792s
Epoch: 8 cost time: 21.762879371643066
Epoch: 8, Steps: 244 Train Loss: 0.6445 (Forecasting Loss:0.3260 + XiCon Loss:3.1858 x Lambda(0.1)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.3321
Validation loss decreased (0.353769 --> 0.353739).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6472772
	speed: 0.0903s/iter; left time: 2018.6885s
	iters: 200, epoch: 9 | loss: 0.6615235
	speed: 0.0882s/iter; left time: 1963.2010s
Epoch: 9 cost time: 21.767902612686157
Epoch: 9, Steps: 244 Train Loss: 0.6441 (Forecasting Loss:0.3256 + XiCon Loss:3.1848 x Lambda(0.1)), Vali MSE Loss: 0.3557 Test MSE Loss: 0.3344
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6414442
	speed: 0.0899s/iter; left time: 1986.3662s
	iters: 200, epoch: 10 | loss: 0.6349553
	speed: 0.0874s/iter; left time: 1923.3744s
Epoch: 10 cost time: 21.680362701416016
Epoch: 10, Steps: 244 Train Loss: 0.6440 (Forecasting Loss:0.3255 + XiCon Loss:3.1846 x Lambda(0.1)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.3338
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6391121
	speed: 0.0901s/iter; left time: 1970.3823s
	iters: 200, epoch: 11 | loss: 0.6398033
	speed: 0.0868s/iter; left time: 1889.6486s
Epoch: 11 cost time: 21.667354822158813
Epoch: 11, Steps: 244 Train Loss: 0.6437 (Forecasting Loss:0.3253 + XiCon Loss:3.1840 x Lambda(0.1)), Vali MSE Loss: 0.3552 Test MSE Loss: 0.3342
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6579217
	speed: 0.0905s/iter; left time: 1956.8801s
	iters: 200, epoch: 12 | loss: 0.6168090
	speed: 0.0898s/iter; left time: 1932.3235s
Epoch: 12 cost time: 22.07311487197876
Epoch: 12, Steps: 244 Train Loss: 0.6437 (Forecasting Loss:0.3253 + XiCon Loss:3.1843 x Lambda(0.1)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.3340
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6737245
	speed: 0.0910s/iter; left time: 1944.0624s
	iters: 200, epoch: 13 | loss: 0.6617063
	speed: 0.0867s/iter; left time: 1844.8339s
Epoch: 13 cost time: 21.697229146957397
Epoch: 13, Steps: 244 Train Loss: 0.6438 (Forecasting Loss:0.3255 + XiCon Loss:3.1835 x Lambda(0.1)), Vali MSE Loss: 0.3545 Test MSE Loss: 0.3340
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6365466
	speed: 0.0912s/iter; left time: 1927.0205s
	iters: 200, epoch: 14 | loss: 0.6297326
	speed: 0.0871s/iter; left time: 1831.2661s
Epoch: 14 cost time: 21.91564154624939
Epoch: 14, Steps: 244 Train Loss: 0.6439 (Forecasting Loss:0.3253 + XiCon Loss:3.1857 x Lambda(0.1)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.3340
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6479648
	speed: 0.0905s/iter; left time: 1889.8022s
	iters: 200, epoch: 15 | loss: 0.6337067
	speed: 0.0857s/iter; left time: 1780.4061s
Epoch: 15 cost time: 21.65781021118164
Epoch: 15, Steps: 244 Train Loss: 0.6439 (Forecasting Loss:0.3254 + XiCon Loss:3.1849 x Lambda(0.1)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.3340
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6403540
	speed: 0.0909s/iter; left time: 1877.0591s
	iters: 200, epoch: 16 | loss: 0.6354661
	speed: 0.0895s/iter; left time: 1838.5996s
Epoch: 16 cost time: 21.89910078048706
Epoch: 16, Steps: 244 Train Loss: 0.6439 (Forecasting Loss:0.3255 + XiCon Loss:3.1846 x Lambda(0.1)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.3340
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6406819
	speed: 0.0937s/iter; left time: 1910.5886s
	iters: 200, epoch: 17 | loss: 0.6511021
	speed: 0.0887s/iter; left time: 1801.2715s
Epoch: 17 cost time: 22.02578616142273
Epoch: 17, Steps: 244 Train Loss: 0.6440 (Forecasting Loss:0.3256 + XiCon Loss:3.1838 x Lambda(0.1)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.3340
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6554568
	speed: 0.0887s/iter; left time: 1787.9250s
	iters: 200, epoch: 18 | loss: 0.6613696
	speed: 0.0874s/iter; left time: 1752.1668s
Epoch: 18 cost time: 21.449357986450195
Epoch: 18, Steps: 244 Train Loss: 0.6440 (Forecasting Loss:0.3255 + XiCon Loss:3.1856 x Lambda(0.1)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.3340
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2615898549556732, mae:0.40255242586135864, mape:0.709149956703186, mspe:17.603300094604492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.6125
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.7560819
	speed: 0.0822s/iter; left time: 1998.3263s
	iters: 200, epoch: 1 | loss: 0.7752053
	speed: 0.0795s/iter; left time: 1923.1239s
Epoch: 1 cost time: 19.777058124542236
Epoch: 1, Steps: 244 Train Loss: 0.7980 (Forecasting Loss:0.4599 + XiCon Loss:3.3808 x Lambda(0.1)), Vali MSE Loss: 0.4591 Test MSE Loss: 0.3618
Validation loss decreased (inf --> 0.459082).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7284355
	speed: 0.0832s/iter; left time: 2001.2075s
	iters: 200, epoch: 2 | loss: 0.6227679
	speed: 0.0794s/iter; left time: 1902.9517s
Epoch: 2 cost time: 20.0992534160614
Epoch: 2, Steps: 244 Train Loss: 0.6855 (Forecasting Loss:0.3629 + XiCon Loss:3.2259 x Lambda(0.1)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.3087
Validation loss decreased (0.459082 --> 0.315402).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6520548
	speed: 0.0931s/iter; left time: 2216.3258s
	iters: 200, epoch: 3 | loss: 0.6345177
	speed: 0.0881s/iter; left time: 2089.9847s
Epoch: 3 cost time: 22.196749687194824
Epoch: 3, Steps: 244 Train Loss: 0.6366 (Forecasting Loss:0.3146 + XiCon Loss:3.2194 x Lambda(0.1)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3203
Validation loss decreased (0.315402 --> 0.304621).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6304741
	speed: 0.0959s/iter; left time: 2260.3947s
	iters: 200, epoch: 4 | loss: 0.6317223
	speed: 0.0913s/iter; left time: 2143.4354s
Epoch: 4 cost time: 22.983689069747925
Epoch: 4, Steps: 244 Train Loss: 0.6321 (Forecasting Loss:0.3094 + XiCon Loss:3.2272 x Lambda(0.1)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.3081
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6392213
	speed: 0.0990s/iter; left time: 2309.6663s
	iters: 200, epoch: 5 | loss: 0.6228813
	speed: 0.0927s/iter; left time: 2152.5292s
Epoch: 5 cost time: 23.51528811454773
Epoch: 5, Steps: 244 Train Loss: 0.6294 (Forecasting Loss:0.3063 + XiCon Loss:3.2308 x Lambda(0.1)), Vali MSE Loss: 0.3052 Test MSE Loss: 0.3051
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6321210
	speed: 0.0993s/iter; left time: 2292.9647s
	iters: 200, epoch: 6 | loss: 0.6343759
	speed: 0.0941s/iter; left time: 2162.2559s
Epoch: 6 cost time: 23.74268388748169
Epoch: 6, Steps: 244 Train Loss: 0.6280 (Forecasting Loss:0.3050 + XiCon Loss:3.2305 x Lambda(0.1)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.3033
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6243988
	speed: 0.1001s/iter; left time: 2286.8712s
	iters: 200, epoch: 7 | loss: 0.6047923
	speed: 0.0942s/iter; left time: 2142.1744s
Epoch: 7 cost time: 23.816097497940063
Epoch: 7, Steps: 244 Train Loss: 0.6272 (Forecasting Loss:0.3042 + XiCon Loss:3.2304 x Lambda(0.1)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.3047
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6152889
	speed: 0.1008s/iter; left time: 2278.0145s
	iters: 200, epoch: 8 | loss: 0.6215750
	speed: 0.0961s/iter; left time: 2160.4842s
Epoch: 8 cost time: 24.022890090942383
Epoch: 8, Steps: 244 Train Loss: 0.6269 (Forecasting Loss:0.3038 + XiCon Loss:3.2302 x Lambda(0.1)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.3049
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6251911
	speed: 0.1008s/iter; left time: 2251.6703s
	iters: 200, epoch: 9 | loss: 0.6300268
	speed: 0.0952s/iter; left time: 2118.1741s
Epoch: 9 cost time: 24.049381732940674
Epoch: 9, Steps: 244 Train Loss: 0.6266 (Forecasting Loss:0.3034 + XiCon Loss:3.2311 x Lambda(0.1)), Vali MSE Loss: 0.3155 Test MSE Loss: 0.3053
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6381441
	speed: 0.1007s/iter; left time: 2226.5752s
	iters: 200, epoch: 10 | loss: 0.6312867
	speed: 0.0947s/iter; left time: 2082.9021s
Epoch: 10 cost time: 23.832420349121094
Epoch: 10, Steps: 244 Train Loss: 0.6264 (Forecasting Loss:0.3035 + XiCon Loss:3.2287 x Lambda(0.1)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.3047
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6128209
	speed: 0.1007s/iter; left time: 2201.0828s
	iters: 200, epoch: 11 | loss: 0.6200953
	speed: 0.0950s/iter; left time: 2068.1009s
Epoch: 11 cost time: 23.876354694366455
Epoch: 11, Steps: 244 Train Loss: 0.6262 (Forecasting Loss:0.3034 + XiCon Loss:3.2281 x Lambda(0.1)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.3049
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6182640
	speed: 0.1000s/iter; left time: 2162.5542s
	iters: 200, epoch: 12 | loss: 0.6358200
	speed: 0.0966s/iter; left time: 2079.5977s
Epoch: 12 cost time: 23.95139718055725
Epoch: 12, Steps: 244 Train Loss: 0.6267 (Forecasting Loss:0.3036 + XiCon Loss:3.2307 x Lambda(0.1)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.3049
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6109831
	speed: 0.1000s/iter; left time: 2137.4949s
	iters: 200, epoch: 13 | loss: 0.6111215
	speed: 0.0951s/iter; left time: 2022.6571s
Epoch: 13 cost time: 23.815292596817017
Epoch: 13, Steps: 244 Train Loss: 0.6263 (Forecasting Loss:0.3033 + XiCon Loss:3.2301 x Lambda(0.1)), Vali MSE Loss: 0.3141 Test MSE Loss: 0.3049
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2431802749633789, mae:0.3973529040813446, mape:0.6594467759132385, mspe:14.561643600463867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.3465
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.8235048
	speed: 0.0813s/iter; left time: 1976.3380s
	iters: 200, epoch: 1 | loss: 0.8110518
	speed: 0.0766s/iter; left time: 1853.0655s
Epoch: 1 cost time: 19.316004037857056
Epoch: 1, Steps: 244 Train Loss: 0.8000 (Forecasting Loss:0.4621 + XiCon Loss:3.3794 x Lambda(0.1)), Vali MSE Loss: 0.4440 Test MSE Loss: 0.3434
Validation loss decreased (inf --> 0.444008).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7012076
	speed: 0.0812s/iter; left time: 1953.9137s
	iters: 200, epoch: 2 | loss: 0.6587052
	speed: 0.0780s/iter; left time: 1869.5598s
Epoch: 2 cost time: 19.299341201782227
Epoch: 2, Steps: 244 Train Loss: 0.6857 (Forecasting Loss:0.3606 + XiCon Loss:3.2516 x Lambda(0.1)), Vali MSE Loss: 0.3595 Test MSE Loss: 0.3380
Validation loss decreased (0.444008 --> 0.359465).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6328963
	speed: 0.0813s/iter; left time: 1937.0895s
	iters: 200, epoch: 3 | loss: 0.6460118
	speed: 0.0761s/iter; left time: 1804.2940s
Epoch: 3 cost time: 19.124948740005493
Epoch: 3, Steps: 244 Train Loss: 0.6555 (Forecasting Loss:0.3370 + XiCon Loss:3.1858 x Lambda(0.1)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.3424
Validation loss decreased (0.359465 --> 0.345565).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6459498
	speed: 0.0794s/iter; left time: 1871.1927s
	iters: 200, epoch: 4 | loss: 0.6468484
	speed: 0.0776s/iter; left time: 1820.8495s
Epoch: 4 cost time: 19.08924961090088
Epoch: 4, Steps: 244 Train Loss: 0.6474 (Forecasting Loss:0.3305 + XiCon Loss:3.1681 x Lambda(0.1)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.3406
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6429082
	speed: 0.0838s/iter; left time: 1954.4260s
	iters: 200, epoch: 5 | loss: 0.6468918
	speed: 0.0787s/iter; left time: 1827.9827s
Epoch: 5 cost time: 19.722422122955322
Epoch: 5, Steps: 244 Train Loss: 0.6432 (Forecasting Loss:0.3273 + XiCon Loss:3.1592 x Lambda(0.1)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.3437
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6352147
	speed: 0.0825s/iter; left time: 1903.1745s
	iters: 200, epoch: 6 | loss: 0.6406282
	speed: 0.0794s/iter; left time: 1825.3445s
Epoch: 6 cost time: 19.606369256973267
Epoch: 6, Steps: 244 Train Loss: 0.6411 (Forecasting Loss:0.3256 + XiCon Loss:3.1551 x Lambda(0.1)), Vali MSE Loss: 0.3493 Test MSE Loss: 0.3498
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6629754
	speed: 0.0804s/iter; left time: 1835.1319s
	iters: 200, epoch: 7 | loss: 0.6326789
	speed: 0.0790s/iter; left time: 1795.1279s
Epoch: 7 cost time: 19.62629747390747
Epoch: 7, Steps: 244 Train Loss: 0.6400 (Forecasting Loss:0.3248 + XiCon Loss:3.1513 x Lambda(0.1)), Vali MSE Loss: 0.3483 Test MSE Loss: 0.3473
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6301222
	speed: 0.0820s/iter; left time: 1851.5712s
	iters: 200, epoch: 8 | loss: 0.6315020
	speed: 0.0799s/iter; left time: 1797.9796s
Epoch: 8 cost time: 19.727688550949097
Epoch: 8, Steps: 244 Train Loss: 0.6389 (Forecasting Loss:0.3240 + XiCon Loss:3.1492 x Lambda(0.1)), Vali MSE Loss: 0.3481 Test MSE Loss: 0.3461
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6333159
	speed: 0.0812s/iter; left time: 1814.4036s
	iters: 200, epoch: 9 | loss: 0.6267509
	speed: 0.0781s/iter; left time: 1737.3196s
Epoch: 9 cost time: 19.344271898269653
Epoch: 9, Steps: 244 Train Loss: 0.6391 (Forecasting Loss:0.3240 + XiCon Loss:3.1501 x Lambda(0.1)), Vali MSE Loss: 0.3473 Test MSE Loss: 0.3458
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6379428
	speed: 0.0814s/iter; left time: 1798.4638s
	iters: 200, epoch: 10 | loss: 0.6349735
	speed: 0.0772s/iter; left time: 1698.3302s
Epoch: 10 cost time: 19.432540893554688
Epoch: 10, Steps: 244 Train Loss: 0.6391 (Forecasting Loss:0.3239 + XiCon Loss:3.1519 x Lambda(0.1)), Vali MSE Loss: 0.3480 Test MSE Loss: 0.3462
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6390818
	speed: 0.0808s/iter; left time: 1766.1795s
	iters: 200, epoch: 11 | loss: 0.6501746
	speed: 0.0794s/iter; left time: 1727.1860s
Epoch: 11 cost time: 19.70121693611145
Epoch: 11, Steps: 244 Train Loss: 0.6388 (Forecasting Loss:0.3238 + XiCon Loss:3.1505 x Lambda(0.1)), Vali MSE Loss: 0.3477 Test MSE Loss: 0.3460
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6477959
	speed: 0.0820s/iter; left time: 1772.4824s
	iters: 200, epoch: 12 | loss: 0.6472355
	speed: 0.0774s/iter; left time: 1666.4727s
Epoch: 12 cost time: 19.336707592010498
Epoch: 12, Steps: 244 Train Loss: 0.6388 (Forecasting Loss:0.3238 + XiCon Loss:3.1500 x Lambda(0.1)), Vali MSE Loss: 0.3479 Test MSE Loss: 0.3460
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6322027
	speed: 0.0802s/iter; left time: 1714.4922s
	iters: 200, epoch: 13 | loss: 0.6423540
	speed: 0.0779s/iter; left time: 1657.7057s
Epoch: 13 cost time: 19.427269458770752
Epoch: 13, Steps: 244 Train Loss: 0.6389 (Forecasting Loss:0.3239 + XiCon Loss:3.1494 x Lambda(0.1)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.3460
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.27269864082336426, mae:0.4120052754878998, mape:0.7819289565086365, mspe:22.68740463256836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2550+-0.02371, MAE:0.4008+-0.01356, MAPE:0.7173+-0.05780, MSPE:18.3781+-3.87820, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.3384
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8569445
	speed: 0.1643s/iter; left time: 3811.6553s
	iters: 200, epoch: 1 | loss: 0.8825793
	speed: 0.1587s/iter; left time: 3665.5844s
Epoch: 1 cost time: 37.7844934463501
Epoch: 1, Steps: 233 Train Loss: 0.8841 (Forecasting Loss:0.5456 + XiCon Loss:3.3849 x Lambda(0.1)), Vali MSE Loss: 0.4974 Test MSE Loss: 0.3892
Validation loss decreased (inf --> 0.497400).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7182029
	speed: 0.1696s/iter; left time: 3896.0849s
	iters: 200, epoch: 2 | loss: 0.7046545
	speed: 0.1655s/iter; left time: 3783.5571s
Epoch: 2 cost time: 39.07613825798035
Epoch: 2, Steps: 233 Train Loss: 0.7297 (Forecasting Loss:0.3959 + XiCon Loss:3.3374 x Lambda(0.1)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3444
Validation loss decreased (0.497400 --> 0.377084).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7082125
	speed: 0.1686s/iter; left time: 3833.1354s
	iters: 200, epoch: 3 | loss: 0.6999196
	speed: 0.1695s/iter; left time: 3836.9924s
Epoch: 3 cost time: 39.27644920349121
Epoch: 3, Steps: 233 Train Loss: 0.7044 (Forecasting Loss:0.3755 + XiCon Loss:3.2891 x Lambda(0.1)), Vali MSE Loss: 0.3776 Test MSE Loss: 0.3370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6866925
	speed: 0.1684s/iter; left time: 3788.5004s
	iters: 200, epoch: 4 | loss: 0.6773245
	speed: 0.1683s/iter; left time: 3770.9245s
Epoch: 4 cost time: 38.96261644363403
Epoch: 4, Steps: 233 Train Loss: 0.6958 (Forecasting Loss:0.3689 + XiCon Loss:3.2687 x Lambda(0.1)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3243
Validation loss decreased (0.377084 --> 0.374690).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.7052619
	speed: 0.1634s/iter; left time: 3639.1172s
	iters: 200, epoch: 5 | loss: 0.6943808
	speed: 0.1682s/iter; left time: 3728.9854s
Epoch: 5 cost time: 38.50901961326599
Epoch: 5, Steps: 233 Train Loss: 0.6912 (Forecasting Loss:0.3655 + XiCon Loss:3.2574 x Lambda(0.1)), Vali MSE Loss: 0.3714 Test MSE Loss: 0.3194
Validation loss decreased (0.374690 --> 0.371398).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6874230
	speed: 0.1677s/iter; left time: 3696.1969s
	iters: 200, epoch: 6 | loss: 0.6962910
	speed: 0.1635s/iter; left time: 3585.4588s
Epoch: 6 cost time: 38.90901184082031
Epoch: 6, Steps: 233 Train Loss: 0.6885 (Forecasting Loss:0.3632 + XiCon Loss:3.2522 x Lambda(0.1)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.3224
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6902176
	speed: 0.1719s/iter; left time: 3746.9700s
	iters: 200, epoch: 7 | loss: 0.7006754
	speed: 0.1691s/iter; left time: 3670.3635s
Epoch: 7 cost time: 39.72127103805542
Epoch: 7, Steps: 233 Train Loss: 0.6870 (Forecasting Loss:0.3620 + XiCon Loss:3.2497 x Lambda(0.1)), Vali MSE Loss: 0.3711 Test MSE Loss: 0.3209
Validation loss decreased (0.371398 --> 0.371067).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6746167
	speed: 0.1743s/iter; left time: 3758.9844s
	iters: 200, epoch: 8 | loss: 0.6688789
	speed: 0.1693s/iter; left time: 3635.2708s
Epoch: 8 cost time: 40.12276864051819
Epoch: 8, Steps: 233 Train Loss: 0.6866 (Forecasting Loss:0.3616 + XiCon Loss:3.2502 x Lambda(0.1)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3212
Validation loss decreased (0.371067 --> 0.370379).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6750305
	speed: 0.1714s/iter; left time: 3657.6955s
	iters: 200, epoch: 9 | loss: 0.6870532
	speed: 0.1672s/iter; left time: 3551.2615s
Epoch: 9 cost time: 39.302422285079956
Epoch: 9, Steps: 233 Train Loss: 0.6858 (Forecasting Loss:0.3612 + XiCon Loss:3.2465 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
Validation loss decreased (0.370379 --> 0.368329).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.7007931
	speed: 0.1674s/iter; left time: 3532.1784s
	iters: 200, epoch: 10 | loss: 0.6940963
	speed: 0.1686s/iter; left time: 3541.6300s
Epoch: 10 cost time: 39.157329082489014
Epoch: 10, Steps: 233 Train Loss: 0.6857 (Forecasting Loss:0.3610 + XiCon Loss:3.2479 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3208
Validation loss decreased (0.368329 --> 0.368312).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6867527
	speed: 0.1676s/iter; left time: 3497.3997s
	iters: 200, epoch: 11 | loss: 0.6733692
	speed: 0.1692s/iter; left time: 3515.1132s
Epoch: 11 cost time: 39.21936869621277
Epoch: 11, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3609 + XiCon Loss:3.2473 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3207
Validation loss decreased (0.368312 --> 0.368157).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6926073
	speed: 0.1706s/iter; left time: 3521.3980s
	iters: 200, epoch: 12 | loss: 0.6754762
	speed: 0.1705s/iter; left time: 3502.5180s
Epoch: 12 cost time: 39.455671310424805
Epoch: 12, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3608 + XiCon Loss:3.2459 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3207
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6513830
	speed: 0.1647s/iter; left time: 3361.6406s
	iters: 200, epoch: 13 | loss: 0.6870272
	speed: 0.1666s/iter; left time: 3383.2551s
Epoch: 13 cost time: 39.412556171417236
Epoch: 13, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3609 + XiCon Loss:3.2452 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3207
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6936266
	speed: 0.1708s/iter; left time: 3445.8629s
	iters: 200, epoch: 14 | loss: 0.6796299
	speed: 0.1716s/iter; left time: 3445.0953s
Epoch: 14 cost time: 40.00744152069092
Epoch: 14, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3610 + XiCon Loss:3.2466 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6908762
	speed: 0.1687s/iter; left time: 3363.4472s
	iters: 200, epoch: 15 | loss: 0.6814753
	speed: 0.1686s/iter; left time: 3345.2973s
Epoch: 15 cost time: 39.591235637664795
Epoch: 15, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3610 + XiCon Loss:3.2458 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6908531
	speed: 0.1669s/iter; left time: 3289.4478s
	iters: 200, epoch: 16 | loss: 0.6790177
	speed: 0.1723s/iter; left time: 3377.7619s
Epoch: 16 cost time: 39.56758499145508
Epoch: 16, Steps: 233 Train Loss: 0.6857 (Forecasting Loss:0.3610 + XiCon Loss:3.2472 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3206
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.7038658
	speed: 0.1671s/iter; left time: 3253.4751s
	iters: 200, epoch: 17 | loss: 0.7102703
	speed: 0.1708s/iter; left time: 3309.2797s
Epoch: 17 cost time: 39.6721670627594
Epoch: 17, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3608 + XiCon Loss:3.2475 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6786042
	speed: 0.1691s/iter; left time: 3254.2070s
	iters: 200, epoch: 18 | loss: 0.6720926
	speed: 0.1709s/iter; left time: 3271.4409s
Epoch: 18 cost time: 39.4705753326416
Epoch: 18, Steps: 233 Train Loss: 0.6853 (Forecasting Loss:0.3608 + XiCon Loss:3.2457 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.7046114
	speed: 0.1743s/iter; left time: 3312.3791s
	iters: 200, epoch: 19 | loss: 0.6880661
	speed: 0.1688s/iter; left time: 3191.5004s
Epoch: 19 cost time: 39.944632053375244
Epoch: 19, Steps: 233 Train Loss: 0.6855 (Forecasting Loss:0.3608 + XiCon Loss:3.2469 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3206
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6867757
	speed: 0.1664s/iter; left time: 3123.5782s
	iters: 200, epoch: 20 | loss: 0.6868453
	speed: 0.1670s/iter; left time: 3118.6642s
Epoch: 20 cost time: 38.76882553100586
Epoch: 20, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3609 + XiCon Loss:3.2454 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6799712
	speed: 0.1709s/iter; left time: 3167.9991s
	iters: 200, epoch: 21 | loss: 0.6647768
	speed: 0.1683s/iter; left time: 3103.9538s
Epoch: 21 cost time: 39.491142988204956
Epoch: 21, Steps: 233 Train Loss: 0.6855 (Forecasting Loss:0.3609 + XiCon Loss:3.2459 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3206
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.250527560710907, mae:0.39079973101615906, mape:0.684506356716156, mspe:18.97093963623047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.3330
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.9051290
	speed: 0.1595s/iter; left time: 3701.2518s
	iters: 200, epoch: 1 | loss: 0.8437515
	speed: 0.1569s/iter; left time: 3625.4828s
Epoch: 1 cost time: 37.26749801635742
Epoch: 1, Steps: 233 Train Loss: 0.8890 (Forecasting Loss:0.5509 + XiCon Loss:3.3813 x Lambda(0.1)), Vali MSE Loss: 0.5002 Test MSE Loss: 0.4024
Validation loss decreased (inf --> 0.500158).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7374558
	speed: 0.1637s/iter; left time: 3759.5288s
	iters: 200, epoch: 2 | loss: 0.6986927
	speed: 0.1654s/iter; left time: 3781.5219s
Epoch: 2 cost time: 38.48482966423035
Epoch: 2, Steps: 233 Train Loss: 0.7294 (Forecasting Loss:0.4013 + XiCon Loss:3.2816 x Lambda(0.1)), Vali MSE Loss: 0.3713 Test MSE Loss: 0.3172
Validation loss decreased (0.500158 --> 0.371260).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6898234
	speed: 0.1699s/iter; left time: 3863.5696s
	iters: 200, epoch: 3 | loss: 0.6780671
	speed: 0.1675s/iter; left time: 3791.9180s
Epoch: 3 cost time: 39.20284080505371
Epoch: 3, Steps: 233 Train Loss: 0.6835 (Forecasting Loss:0.3631 + XiCon Loss:3.2048 x Lambda(0.1)), Vali MSE Loss: 0.3471 Test MSE Loss: 0.3071
Validation loss decreased (0.371260 --> 0.347120).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6695725
	speed: 0.1655s/iter; left time: 3723.5782s
	iters: 200, epoch: 4 | loss: 0.6563008
	speed: 0.1582s/iter; left time: 3543.6595s
Epoch: 4 cost time: 37.68757438659668
Epoch: 4, Steps: 233 Train Loss: 0.6648 (Forecasting Loss:0.3398 + XiCon Loss:3.2500 x Lambda(0.1)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.3136
Validation loss decreased (0.347120 --> 0.324071).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6670462
	speed: 0.1657s/iter; left time: 3690.8834s
	iters: 200, epoch: 5 | loss: 0.6808748
	speed: 0.1584s/iter; left time: 3510.6305s
Epoch: 5 cost time: 38.16733360290527
Epoch: 5, Steps: 233 Train Loss: 0.6587 (Forecasting Loss:0.3327 + XiCon Loss:3.2596 x Lambda(0.1)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.3327
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6466338
	speed: 0.1668s/iter; left time: 3674.5808s
	iters: 200, epoch: 6 | loss: 0.6635184
	speed: 0.1634s/iter; left time: 3584.7376s
Epoch: 6 cost time: 38.52104115486145
Epoch: 6, Steps: 233 Train Loss: 0.6567 (Forecasting Loss:0.3306 + XiCon Loss:3.2617 x Lambda(0.1)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.3164
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6542366
	speed: 0.1682s/iter; left time: 3667.1138s
	iters: 200, epoch: 7 | loss: 0.6625336
	speed: 0.1596s/iter; left time: 3463.4759s
Epoch: 7 cost time: 37.98768711090088
Epoch: 7, Steps: 233 Train Loss: 0.6555 (Forecasting Loss:0.3294 + XiCon Loss:3.2617 x Lambda(0.1)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.3191
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6528026
	speed: 0.1613s/iter; left time: 3479.6844s
	iters: 200, epoch: 8 | loss: 0.6530313
	speed: 0.1630s/iter; left time: 3499.6186s
Epoch: 8 cost time: 38.054834842681885
Epoch: 8, Steps: 233 Train Loss: 0.6551 (Forecasting Loss:0.3287 + XiCon Loss:3.2634 x Lambda(0.1)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.3186
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6585044
	speed: 0.1679s/iter; left time: 3582.3097s
	iters: 200, epoch: 9 | loss: 0.6513456
	speed: 0.1645s/iter; left time: 3492.7313s
Epoch: 9 cost time: 39.02400732040405
Epoch: 9, Steps: 233 Train Loss: 0.6551 (Forecasting Loss:0.3287 + XiCon Loss:3.2636 x Lambda(0.1)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.3193
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6525531
	speed: 0.1663s/iter; left time: 3509.0639s
	iters: 200, epoch: 10 | loss: 0.6311400
	speed: 0.1660s/iter; left time: 3486.5557s
Epoch: 10 cost time: 38.48867678642273
Epoch: 10, Steps: 233 Train Loss: 0.6551 (Forecasting Loss:0.3287 + XiCon Loss:3.2635 x Lambda(0.1)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.3166
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6378678
	speed: 0.1610s/iter; left time: 3360.1684s
	iters: 200, epoch: 11 | loss: 0.6578426
	speed: 0.1673s/iter; left time: 3474.6888s
Epoch: 11 cost time: 38.46039152145386
Epoch: 11, Steps: 233 Train Loss: 0.6549 (Forecasting Loss:0.3286 + XiCon Loss:3.2635 x Lambda(0.1)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.3183
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6661097
	speed: 0.1675s/iter; left time: 3457.8247s
	iters: 200, epoch: 12 | loss: 0.6765325
	speed: 0.1641s/iter; left time: 3370.0622s
Epoch: 12 cost time: 38.60758447647095
Epoch: 12, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3287 + XiCon Loss:3.2635 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.3181
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6644040
	speed: 0.1612s/iter; left time: 3289.6002s
	iters: 200, epoch: 13 | loss: 0.6693448
	speed: 0.1663s/iter; left time: 3377.7055s
Epoch: 13 cost time: 38.46831822395325
Epoch: 13, Steps: 233 Train Loss: 0.6552 (Forecasting Loss:0.3288 + XiCon Loss:3.2640 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.3178
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6615617
	speed: 0.1717s/iter; left time: 3464.2975s
	iters: 200, epoch: 14 | loss: 0.6501020
	speed: 0.1635s/iter; left time: 3282.7515s
Epoch: 14 cost time: 39.2152681350708
Epoch: 14, Steps: 233 Train Loss: 0.6547 (Forecasting Loss:0.3284 + XiCon Loss:3.2623 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.3179
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2349632829427719, mae:0.3922872245311737, mape:0.6284713745117188, mspe:13.973418235778809 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.8094
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8645270
	speed: 0.1522s/iter; left time: 3530.2138s
	iters: 200, epoch: 1 | loss: 0.9040644
	speed: 0.1529s/iter; left time: 3533.0382s
Epoch: 1 cost time: 35.882559299468994
Epoch: 1, Steps: 233 Train Loss: 0.8928 (Forecasting Loss:0.5542 + XiCon Loss:3.3861 x Lambda(0.1)), Vali MSE Loss: 0.5434 Test MSE Loss: 0.4560
Validation loss decreased (inf --> 0.543405).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6823407
	speed: 0.1578s/iter; left time: 3624.3941s
	iters: 200, epoch: 2 | loss: 0.6591908
	speed: 0.1585s/iter; left time: 3625.7026s
Epoch: 2 cost time: 36.98562169075012
Epoch: 2, Steps: 233 Train Loss: 0.7255 (Forecasting Loss:0.3985 + XiCon Loss:3.2703 x Lambda(0.1)), Vali MSE Loss: 0.3587 Test MSE Loss: 0.3061
Validation loss decreased (0.543405 --> 0.358726).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7145103
	speed: 0.1701s/iter; left time: 3866.9879s
	iters: 200, epoch: 3 | loss: 0.6535437
	speed: 0.1621s/iter; left time: 3669.5965s
Epoch: 3 cost time: 38.418776988983154
Epoch: 3, Steps: 233 Train Loss: 0.6630 (Forecasting Loss:0.3350 + XiCon Loss:3.2793 x Lambda(0.1)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2969
Validation loss decreased (0.358726 --> 0.311139).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6514910
	speed: 0.1629s/iter; left time: 3666.3630s
	iters: 200, epoch: 4 | loss: 0.6456587
	speed: 0.1593s/iter; left time: 3567.8746s
Epoch: 4 cost time: 37.5146107673645
Epoch: 4, Steps: 233 Train Loss: 0.6579 (Forecasting Loss:0.3298 + XiCon Loss:3.2815 x Lambda(0.1)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2998
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6555576
	speed: 0.1639s/iter; left time: 3649.3749s
	iters: 200, epoch: 5 | loss: 0.6284502
	speed: 0.1630s/iter; left time: 3613.7067s
Epoch: 5 cost time: 38.27318358421326
Epoch: 5, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3276 + XiCon Loss:3.2746 x Lambda(0.1)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.2969
Validation loss decreased (0.311139 --> 0.306918).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6609516
	speed: 0.1703s/iter; left time: 3752.2347s
	iters: 200, epoch: 6 | loss: 0.6499338
	speed: 0.1619s/iter; left time: 3551.8736s
Epoch: 6 cost time: 38.86073088645935
Epoch: 6, Steps: 233 Train Loss: 0.6537 (Forecasting Loss:0.3269 + XiCon Loss:3.2687 x Lambda(0.1)), Vali MSE Loss: 0.3057 Test MSE Loss: 0.2972
Validation loss decreased (0.306918 --> 0.305683).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6510341
	speed: 0.1597s/iter; left time: 3482.4002s
	iters: 200, epoch: 7 | loss: 0.6738883
	speed: 0.1605s/iter; left time: 3483.1392s
Epoch: 7 cost time: 37.27012825012207
Epoch: 7, Steps: 233 Train Loss: 0.6527 (Forecasting Loss:0.3260 + XiCon Loss:3.2666 x Lambda(0.1)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2934
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6529037
	speed: 0.1648s/iter; left time: 3555.6540s
	iters: 200, epoch: 8 | loss: 0.6396256
	speed: 0.1562s/iter; left time: 3352.6199s
Epoch: 8 cost time: 37.467467308044434
Epoch: 8, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3258 + XiCon Loss:3.2649 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2963
Validation loss decreased (0.305683 --> 0.304924).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6879117
	speed: 0.1703s/iter; left time: 3633.3026s
	iters: 200, epoch: 9 | loss: 0.6697831
	speed: 0.1576s/iter; left time: 3347.9816s
Epoch: 9 cost time: 38.22070670127869
Epoch: 9, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3255 + XiCon Loss:3.2689 x Lambda(0.1)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2964
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6596136
	speed: 0.1644s/iter; left time: 3470.3558s
	iters: 200, epoch: 10 | loss: 0.6490582
	speed: 0.1570s/iter; left time: 3298.6210s
Epoch: 10 cost time: 37.53625130653381
Epoch: 10, Steps: 233 Train Loss: 0.6521 (Forecasting Loss:0.3256 + XiCon Loss:3.2651 x Lambda(0.1)), Vali MSE Loss: 0.3052 Test MSE Loss: 0.2969
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6429543
	speed: 0.1605s/iter; left time: 3350.8133s
	iters: 200, epoch: 11 | loss: 0.6374584
	speed: 0.1656s/iter; left time: 3438.6599s
Epoch: 11 cost time: 38.24096179008484
Epoch: 11, Steps: 233 Train Loss: 0.6524 (Forecasting Loss:0.3258 + XiCon Loss:3.2655 x Lambda(0.1)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2966
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6711192
	speed: 0.1587s/iter; left time: 3276.0289s
	iters: 200, epoch: 12 | loss: 0.6411225
	speed: 0.1650s/iter; left time: 3388.9346s
Epoch: 12 cost time: 37.74027943611145
Epoch: 12, Steps: 233 Train Loss: 0.6521 (Forecasting Loss:0.3256 + XiCon Loss:3.2647 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6510099
	speed: 0.1660s/iter; left time: 3388.0385s
	iters: 200, epoch: 13 | loss: 0.6621388
	speed: 0.1621s/iter; left time: 3290.4421s
Epoch: 13 cost time: 38.11718249320984
Epoch: 13, Steps: 233 Train Loss: 0.6520 (Forecasting Loss:0.3255 + XiCon Loss:3.2648 x Lambda(0.1)), Vali MSE Loss: 0.3051 Test MSE Loss: 0.2967
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6637795
	speed: 0.1595s/iter; left time: 3218.3631s
	iters: 200, epoch: 14 | loss: 0.6483014
	speed: 0.1597s/iter; left time: 3205.1026s
Epoch: 14 cost time: 37.25275206565857
Epoch: 14, Steps: 233 Train Loss: 0.6519 (Forecasting Loss:0.3252 + XiCon Loss:3.2677 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6325717
	speed: 0.1644s/iter; left time: 3278.5290s
	iters: 200, epoch: 15 | loss: 0.6658174
	speed: 0.1605s/iter; left time: 3183.3065s
Epoch: 15 cost time: 37.9286994934082
Epoch: 15, Steps: 233 Train Loss: 0.6520 (Forecasting Loss:0.3257 + XiCon Loss:3.2628 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6468434
	speed: 0.1513s/iter; left time: 2981.3905s
	iters: 200, epoch: 16 | loss: 0.6504173
	speed: 0.1573s/iter; left time: 3083.3413s
Epoch: 16 cost time: 36.14536190032959
Epoch: 16, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3256 + XiCon Loss:3.2669 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6527991
	speed: 0.1650s/iter; left time: 3213.0063s
	iters: 200, epoch: 17 | loss: 0.6669714
	speed: 0.1656s/iter; left time: 3207.4492s
Epoch: 17 cost time: 38.394164085388184
Epoch: 17, Steps: 233 Train Loss: 0.6519 (Forecasting Loss:0.3253 + XiCon Loss:3.2657 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2968
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6545261
	speed: 0.1661s/iter; left time: 3196.6509s
	iters: 200, epoch: 18 | loss: 0.6682618
	speed: 0.1617s/iter; left time: 3095.8324s
Epoch: 18 cost time: 38.16714644432068
Epoch: 18, Steps: 233 Train Loss: 0.6522 (Forecasting Loss:0.3257 + XiCon Loss:3.2653 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2968
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21633093059062958, mae:0.376216322183609, mape:0.6298172473907471, mspe:14.507866859436035 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.1097
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8622496
	speed: 0.1580s/iter; left time: 3665.8844s
	iters: 200, epoch: 1 | loss: 0.8353570
	speed: 0.1570s/iter; left time: 3627.5073s
Epoch: 1 cost time: 37.063554763793945
Epoch: 1, Steps: 233 Train Loss: 0.8880 (Forecasting Loss:0.5500 + XiCon Loss:3.3803 x Lambda(0.1)), Vali MSE Loss: 0.5199 Test MSE Loss: 0.4296
Validation loss decreased (inf --> 0.519950).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7188964
	speed: 0.1624s/iter; left time: 3730.7040s
	iters: 200, epoch: 2 | loss: 0.7004161
	speed: 0.1571s/iter; left time: 3592.3626s
Epoch: 2 cost time: 37.569037199020386
Epoch: 2, Steps: 233 Train Loss: 0.7427 (Forecasting Loss:0.4174 + XiCon Loss:3.2531 x Lambda(0.1)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.2950
Validation loss decreased (0.519950 --> 0.354416).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6593157
	speed: 0.1605s/iter; left time: 3649.0208s
	iters: 200, epoch: 3 | loss: 0.6467161
	speed: 0.1726s/iter; left time: 3905.8978s
Epoch: 3 cost time: 38.86853003501892
Epoch: 3, Steps: 233 Train Loss: 0.6686 (Forecasting Loss:0.3407 + XiCon Loss:3.2797 x Lambda(0.1)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.3330
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6604625
	speed: 0.1763s/iter; left time: 3966.6799s
	iters: 200, epoch: 4 | loss: 0.6501684
	speed: 0.1767s/iter; left time: 3958.1000s
Epoch: 4 cost time: 41.2377245426178
Epoch: 4, Steps: 233 Train Loss: 0.6543 (Forecasting Loss:0.3258 + XiCon Loss:3.2851 x Lambda(0.1)), Vali MSE Loss: 0.3987 Test MSE Loss: 0.3290
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6268783
	speed: 0.1796s/iter; left time: 3999.4640s
	iters: 200, epoch: 5 | loss: 0.6543676
	speed: 0.1798s/iter; left time: 3985.0911s
Epoch: 5 cost time: 42.056095361709595
Epoch: 5, Steps: 233 Train Loss: 0.6473 (Forecasting Loss:0.3198 + XiCon Loss:3.2743 x Lambda(0.1)), Vali MSE Loss: 0.4687 Test MSE Loss: 0.3155
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6610271
	speed: 0.1861s/iter; left time: 4100.4626s
	iters: 200, epoch: 6 | loss: 0.6420003
	speed: 0.1795s/iter; left time: 3936.5832s
Epoch: 6 cost time: 42.93840312957764
Epoch: 6, Steps: 233 Train Loss: 0.6440 (Forecasting Loss:0.3171 + XiCon Loss:3.2694 x Lambda(0.1)), Vali MSE Loss: 0.4432 Test MSE Loss: 0.3098
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6453516
	speed: 0.1792s/iter; left time: 3906.5095s
	iters: 200, epoch: 7 | loss: 0.6655017
	speed: 0.1829s/iter; left time: 3970.3845s
Epoch: 7 cost time: 42.05734610557556
Epoch: 7, Steps: 233 Train Loss: 0.6427 (Forecasting Loss:0.3160 + XiCon Loss:3.2670 x Lambda(0.1)), Vali MSE Loss: 0.4610 Test MSE Loss: 0.3154
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6587216
	speed: 0.1894s/iter; left time: 4085.9024s
	iters: 200, epoch: 8 | loss: 0.6542504
	speed: 0.1843s/iter; left time: 3955.9819s
Epoch: 8 cost time: 43.350804567337036
Epoch: 8, Steps: 233 Train Loss: 0.6422 (Forecasting Loss:0.3157 + XiCon Loss:3.2651 x Lambda(0.1)), Vali MSE Loss: 0.4788 Test MSE Loss: 0.3129
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6091053
	speed: 0.1883s/iter; left time: 4017.6996s
	iters: 200, epoch: 9 | loss: 0.6463364
	speed: 0.1843s/iter; left time: 3914.8492s
Epoch: 9 cost time: 43.64195442199707
Epoch: 9, Steps: 233 Train Loss: 0.6419 (Forecasting Loss:0.3151 + XiCon Loss:3.2680 x Lambda(0.1)), Vali MSE Loss: 0.4660 Test MSE Loss: 0.3138
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6350938
	speed: 0.1873s/iter; left time: 3953.1991s
	iters: 200, epoch: 10 | loss: 0.6495399
	speed: 0.1867s/iter; left time: 3922.4425s
Epoch: 10 cost time: 43.88981032371521
Epoch: 10, Steps: 233 Train Loss: 0.6413 (Forecasting Loss:0.3149 + XiCon Loss:3.2639 x Lambda(0.1)), Vali MSE Loss: 0.4585 Test MSE Loss: 0.3136
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6101935
	speed: 0.1907s/iter; left time: 3980.5276s
	iters: 200, epoch: 11 | loss: 0.6354064
	speed: 0.1820s/iter; left time: 3780.0046s
Epoch: 11 cost time: 43.771260499954224
Epoch: 11, Steps: 233 Train Loss: 0.6413 (Forecasting Loss:0.3149 + XiCon Loss:3.2635 x Lambda(0.1)), Vali MSE Loss: 0.4637 Test MSE Loss: 0.3134
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6276451
	speed: 0.1881s/iter; left time: 3882.1959s
	iters: 200, epoch: 12 | loss: 0.6310033
	speed: 0.1817s/iter; left time: 3732.0588s
Epoch: 12 cost time: 43.045222759246826
Epoch: 12, Steps: 233 Train Loss: 0.6413 (Forecasting Loss:0.3149 + XiCon Loss:3.2640 x Lambda(0.1)), Vali MSE Loss: 0.4679 Test MSE Loss: 0.3134
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21486909687519073, mae:0.3752037286758423, mape:0.6512797474861145, mspe:16.763879776000977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.5653
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8850025
	speed: 0.1572s/iter; left time: 3646.9515s
	iters: 200, epoch: 1 | loss: 0.9006898
	speed: 0.1555s/iter; left time: 3592.4892s
Epoch: 1 cost time: 36.49466061592102
Epoch: 1, Steps: 233 Train Loss: 0.8884 (Forecasting Loss:0.5501 + XiCon Loss:3.3832 x Lambda(0.1)), Vali MSE Loss: 0.5089 Test MSE Loss: 0.4135
Validation loss decreased (inf --> 0.508915).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7202685
	speed: 0.1612s/iter; left time: 3703.0971s
	iters: 200, epoch: 2 | loss: 0.6631387
	speed: 0.1958s/iter; left time: 4477.6684s
Epoch: 2 cost time: 42.409884452819824
Epoch: 2, Steps: 233 Train Loss: 0.7154 (Forecasting Loss:0.3934 + XiCon Loss:3.2201 x Lambda(0.1)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2896
Validation loss decreased (0.508915 --> 0.322323).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6605695
	speed: 0.2110s/iter; left time: 4797.6507s
	iters: 200, epoch: 3 | loss: 0.6363244
	speed: 0.2051s/iter; left time: 4642.6134s
Epoch: 3 cost time: 49.01978850364685
Epoch: 3, Steps: 233 Train Loss: 0.6471 (Forecasting Loss:0.3278 + XiCon Loss:3.1925 x Lambda(0.1)), Vali MSE Loss: 0.3592 Test MSE Loss: 0.2924
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6569289
	speed: 0.2022s/iter; left time: 4549.3619s
	iters: 200, epoch: 4 | loss: 0.6498923
	speed: 0.1975s/iter; left time: 4424.7682s
Epoch: 4 cost time: 46.291616916656494
Epoch: 4, Steps: 233 Train Loss: 0.6414 (Forecasting Loss:0.3203 + XiCon Loss:3.2111 x Lambda(0.1)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2994
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6257992
	speed: 0.1964s/iter; left time: 4374.3960s
	iters: 200, epoch: 5 | loss: 0.6433722
	speed: 0.1881s/iter; left time: 4169.8925s
Epoch: 5 cost time: 44.331599950790405
Epoch: 5, Steps: 233 Train Loss: 0.6392 (Forecasting Loss:0.3171 + XiCon Loss:3.2212 x Lambda(0.1)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.2953
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6366431
	speed: 0.1865s/iter; left time: 4109.9100s
	iters: 200, epoch: 6 | loss: 0.6691962
	speed: 0.1892s/iter; left time: 4149.5536s
Epoch: 6 cost time: 43.96128988265991
Epoch: 6, Steps: 233 Train Loss: 0.6385 (Forecasting Loss:0.3160 + XiCon Loss:3.2246 x Lambda(0.1)), Vali MSE Loss: 0.3429 Test MSE Loss: 0.2983
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6395229
	speed: 0.1867s/iter; left time: 4069.9396s
	iters: 200, epoch: 7 | loss: 0.6564654
	speed: 0.1740s/iter; left time: 3776.8312s
Epoch: 7 cost time: 42.0065598487854
Epoch: 7, Steps: 233 Train Loss: 0.6374 (Forecasting Loss:0.3149 + XiCon Loss:3.2245 x Lambda(0.1)), Vali MSE Loss: 0.3434 Test MSE Loss: 0.2973
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6388505
	speed: 0.1789s/iter; left time: 3858.9515s
	iters: 200, epoch: 8 | loss: 0.6369191
	speed: 0.1795s/iter; left time: 3854.4190s
Epoch: 8 cost time: 42.021629333496094
Epoch: 8, Steps: 233 Train Loss: 0.6373 (Forecasting Loss:0.3150 + XiCon Loss:3.2235 x Lambda(0.1)), Vali MSE Loss: 0.3486 Test MSE Loss: 0.2967
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6278540
	speed: 0.1791s/iter; left time: 3820.4461s
	iters: 200, epoch: 9 | loss: 0.6464608
	speed: 0.1806s/iter; left time: 3834.8802s
Epoch: 9 cost time: 42.11739373207092
Epoch: 9, Steps: 233 Train Loss: 0.6366 (Forecasting Loss:0.3143 + XiCon Loss:3.2237 x Lambda(0.1)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.2979
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6299047
	speed: 0.1848s/iter; left time: 3900.4906s
	iters: 200, epoch: 10 | loss: 0.6358220
	speed: 0.1752s/iter; left time: 3679.4776s
Epoch: 10 cost time: 42.32945680618286
Epoch: 10, Steps: 233 Train Loss: 0.6369 (Forecasting Loss:0.3145 + XiCon Loss:3.2234 x Lambda(0.1)), Vali MSE Loss: 0.3441 Test MSE Loss: 0.2974
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6354309
	speed: 0.1788s/iter; left time: 3731.9044s
	iters: 200, epoch: 11 | loss: 0.6402372
	speed: 0.1763s/iter; left time: 3660.9002s
Epoch: 11 cost time: 41.35591125488281
Epoch: 11, Steps: 233 Train Loss: 0.6366 (Forecasting Loss:0.3144 + XiCon Loss:3.2219 x Lambda(0.1)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2974
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6497271
	speed: 0.1893s/iter; left time: 3907.1483s
	iters: 200, epoch: 12 | loss: 0.6293795
	speed: 0.1742s/iter; left time: 3578.0828s
Epoch: 12 cost time: 42.8793842792511
Epoch: 12, Steps: 233 Train Loss: 0.6370 (Forecasting Loss:0.3146 + XiCon Loss:3.2239 x Lambda(0.1)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2977
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.20922663807868958, mae:0.3700016140937805, mape:0.6360715627670288, mspe:15.941384315490723 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2252+-0.02130, MAE:0.3809+-0.01243, MAPE:0.6460+-0.02898, MSPE:16.0315+-2.46322, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
