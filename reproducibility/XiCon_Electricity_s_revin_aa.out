Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.6370
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6123407
	speed: 0.0155s/iter; left time: 370.0562s
	iters: 200, epoch: 1 | loss: 0.5767866
	speed: 0.0106s/iter; left time: 251.5617s
Epoch: 1 cost time: 3.0239593982696533
Epoch: 1, Steps: 239 Train Loss: 0.6544 (Forecasting Loss:0.6226 + XiCon Loss:3.1729 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.4445
Validation loss decreased (inf --> 0.327659).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3300128
	speed: 0.0124s/iter; left time: 292.0242s
	iters: 200, epoch: 2 | loss: 0.3011717
	speed: 0.0099s/iter; left time: 233.0434s
Epoch: 2 cost time: 2.6694717407226562
Epoch: 2, Steps: 239 Train Loss: 0.3439 (Forecasting Loss:0.3123 + XiCon Loss:3.1562 x Lambda(0.01)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.2791
Validation loss decreased (0.327659 --> 0.206071).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2990663
	speed: 0.0125s/iter; left time: 292.3967s
	iters: 200, epoch: 3 | loss: 0.3159328
	speed: 0.0103s/iter; left time: 239.3318s
Epoch: 3 cost time: 2.7238051891326904
Epoch: 3, Steps: 239 Train Loss: 0.3039 (Forecasting Loss:0.2725 + XiCon Loss:3.1420 x Lambda(0.01)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.2692
Validation loss decreased (0.206071 --> 0.197348).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2774096
	speed: 0.0128s/iter; left time: 295.8347s
	iters: 200, epoch: 4 | loss: 0.2791486
	speed: 0.0097s/iter; left time: 222.4486s
Epoch: 4 cost time: 2.6774981021881104
Epoch: 4, Steps: 239 Train Loss: 0.2974 (Forecasting Loss:0.2661 + XiCon Loss:3.1362 x Lambda(0.01)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.2661
Validation loss decreased (0.197348 --> 0.195275).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3179926
	speed: 0.0127s/iter; left time: 290.2510s
	iters: 200, epoch: 5 | loss: 0.2868559
	speed: 0.0105s/iter; left time: 239.1492s
Epoch: 5 cost time: 2.7351322174072266
Epoch: 5, Steps: 239 Train Loss: 0.2944 (Forecasting Loss:0.2630 + XiCon Loss:3.1323 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2657
Validation loss decreased (0.195275 --> 0.193802).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2855367
	speed: 0.0124s/iter; left time: 279.5637s
	iters: 200, epoch: 6 | loss: 0.2857334
	speed: 0.0102s/iter; left time: 228.7502s
Epoch: 6 cost time: 2.658352851867676
Epoch: 6, Steps: 239 Train Loss: 0.2930 (Forecasting Loss:0.2617 + XiCon Loss:3.1316 x Lambda(0.01)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2639
Validation loss decreased (0.193802 --> 0.193144).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3019164
	speed: 0.0123s/iter; left time: 275.2445s
	iters: 200, epoch: 7 | loss: 0.3011771
	speed: 0.0096s/iter; left time: 214.3625s
Epoch: 7 cost time: 2.6209909915924072
Epoch: 7, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2606 + XiCon Loss:3.1314 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2636
Validation loss decreased (0.193144 --> 0.192649).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2479140
	speed: 0.0116s/iter; left time: 256.1105s
	iters: 200, epoch: 8 | loss: 0.2900249
	speed: 0.0101s/iter; left time: 221.4671s
Epoch: 8 cost time: 2.5831477642059326
Epoch: 8, Steps: 239 Train Loss: 0.2915 (Forecasting Loss:0.2602 + XiCon Loss:3.1318 x Lambda(0.01)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2633
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2573437
	speed: 0.0120s/iter; left time: 263.3950s
	iters: 200, epoch: 9 | loss: 0.3209227
	speed: 0.0102s/iter; left time: 221.9909s
Epoch: 9 cost time: 2.6776175498962402
Epoch: 9, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2604 + XiCon Loss:3.1302 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2633
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2758793
	speed: 0.0122s/iter; left time: 263.1816s
	iters: 200, epoch: 10 | loss: 0.3080575
	speed: 0.0095s/iter; left time: 203.6883s
Epoch: 10 cost time: 2.5866310596466064
Epoch: 10, Steps: 239 Train Loss: 0.2910 (Forecasting Loss:0.2597 + XiCon Loss:3.1300 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2833004
	speed: 0.0124s/iter; left time: 264.9780s
	iters: 200, epoch: 11 | loss: 0.2798489
	speed: 0.0104s/iter; left time: 222.5391s
Epoch: 11 cost time: 2.742396593093872
Epoch: 11, Steps: 239 Train Loss: 0.2912 (Forecasting Loss:0.2599 + XiCon Loss:3.1302 x Lambda(0.01)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.2632
Validation loss decreased (0.192649 --> 0.192232).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3183184
	speed: 0.0125s/iter; left time: 264.3977s
	iters: 200, epoch: 12 | loss: 0.2763405
	speed: 0.0102s/iter; left time: 215.0023s
Epoch: 12 cost time: 2.6907529830932617
Epoch: 12, Steps: 239 Train Loss: 0.2914 (Forecasting Loss:0.2601 + XiCon Loss:3.1299 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2796805
	speed: 0.0123s/iter; left time: 256.8275s
	iters: 200, epoch: 13 | loss: 0.2910160
	speed: 0.0105s/iter; left time: 218.6459s
Epoch: 13 cost time: 2.705472230911255
Epoch: 13, Steps: 239 Train Loss: 0.2913 (Forecasting Loss:0.2600 + XiCon Loss:3.1314 x Lambda(0.01)), Vali MSE Loss: 0.1927 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2965473
	speed: 0.0123s/iter; left time: 254.7639s
	iters: 200, epoch: 14 | loss: 0.2820474
	speed: 0.0100s/iter; left time: 206.1052s
Epoch: 14 cost time: 2.6647789478302
Epoch: 14, Steps: 239 Train Loss: 0.2914 (Forecasting Loss:0.2601 + XiCon Loss:3.1306 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3209736
	speed: 0.0122s/iter; left time: 249.0186s
	iters: 200, epoch: 15 | loss: 0.2366664
	speed: 0.0097s/iter; left time: 198.0190s
Epoch: 15 cost time: 2.6025290489196777
Epoch: 15, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2603 + XiCon Loss:3.1301 x Lambda(0.01)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2632
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3029857
	speed: 0.0134s/iter; left time: 270.8606s
	iters: 200, epoch: 16 | loss: 0.2750611
	speed: 0.0100s/iter; left time: 200.6614s
Epoch: 16 cost time: 2.7581450939178467
Epoch: 16, Steps: 239 Train Loss: 0.2910 (Forecasting Loss:0.2597 + XiCon Loss:3.1304 x Lambda(0.01)), Vali MSE Loss: 0.1924 Test MSE Loss: 0.2632
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2670502
	speed: 0.0127s/iter; left time: 253.7321s
	iters: 200, epoch: 17 | loss: 0.2817629
	speed: 0.0106s/iter; left time: 211.0579s
Epoch: 17 cost time: 2.742807149887085
Epoch: 17, Steps: 239 Train Loss: 0.2911 (Forecasting Loss:0.2597 + XiCon Loss:3.1308 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2632
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2830334
	speed: 0.0121s/iter; left time: 238.9882s
	iters: 200, epoch: 18 | loss: 0.2974738
	speed: 0.0096s/iter; left time: 188.6138s
Epoch: 18 cost time: 2.6315231323242188
Epoch: 18, Steps: 239 Train Loss: 0.2912 (Forecasting Loss:0.2599 + XiCon Loss:3.1313 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3089988
	speed: 0.0126s/iter; left time: 245.1436s
	iters: 200, epoch: 19 | loss: 0.3316222
	speed: 0.0098s/iter; left time: 189.3940s
Epoch: 19 cost time: 2.6690099239349365
Epoch: 19, Steps: 239 Train Loss: 0.2911 (Forecasting Loss:0.2598 + XiCon Loss:3.1307 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2632
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3033859
	speed: 0.0128s/iter; left time: 247.4236s
	iters: 200, epoch: 20 | loss: 0.3093037
	speed: 0.0101s/iter; left time: 194.2475s
Epoch: 20 cost time: 2.7103731632232666
Epoch: 20, Steps: 239 Train Loss: 0.2912 (Forecasting Loss:0.2599 + XiCon Loss:3.1309 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.3000716
	speed: 0.0127s/iter; left time: 241.2809s
	iters: 200, epoch: 21 | loss: 0.2758792
	speed: 0.0104s/iter; left time: 197.5712s
Epoch: 21 cost time: 2.732750415802002
Epoch: 21, Steps: 239 Train Loss: 0.2910 (Forecasting Loss:0.2597 + XiCon Loss:3.1311 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.2061920017004013, mae:0.3202650845050812, mape:2.33364200592041, mspe:3203.84814453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4861
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6318088
	speed: 0.0125s/iter; left time: 296.4318s
	iters: 200, epoch: 1 | loss: 0.4919098
	speed: 0.0105s/iter; left time: 249.9012s
Epoch: 1 cost time: 2.732361078262329
Epoch: 1, Steps: 239 Train Loss: 0.6440 (Forecasting Loss:0.6124 + XiCon Loss:3.1614 x Lambda(0.01)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.4345
Validation loss decreased (inf --> 0.322188).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3504755
	speed: 0.0120s/iter; left time: 281.6607s
	iters: 200, epoch: 2 | loss: 0.2884945
	speed: 0.0102s/iter; left time: 239.4031s
Epoch: 2 cost time: 2.6754090785980225
Epoch: 2, Steps: 239 Train Loss: 0.3437 (Forecasting Loss:0.3121 + XiCon Loss:3.1635 x Lambda(0.01)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.2777
Validation loss decreased (0.322188 --> 0.202019).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2942370
	speed: 0.0122s/iter; left time: 284.1825s
	iters: 200, epoch: 3 | loss: 0.2740952
	speed: 0.0096s/iter; left time: 223.2160s
Epoch: 3 cost time: 2.587739944458008
Epoch: 3, Steps: 239 Train Loss: 0.3045 (Forecasting Loss:0.2728 + XiCon Loss:3.1673 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2713
Validation loss decreased (0.202019 --> 0.194389).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2333675
	speed: 0.0122s/iter; left time: 281.3997s
	iters: 200, epoch: 4 | loss: 0.2902651
	speed: 0.0099s/iter; left time: 227.8657s
Epoch: 4 cost time: 2.6349706649780273
Epoch: 4, Steps: 239 Train Loss: 0.2975 (Forecasting Loss:0.2659 + XiCon Loss:3.1689 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2649
Validation loss decreased (0.194389 --> 0.191272).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2892289
	speed: 0.0130s/iter; left time: 296.9478s
	iters: 200, epoch: 5 | loss: 0.3000560
	speed: 0.0104s/iter; left time: 235.6596s
Epoch: 5 cost time: 2.7568516731262207
Epoch: 5, Steps: 239 Train Loss: 0.2940 (Forecasting Loss:0.2623 + XiCon Loss:3.1693 x Lambda(0.01)), Vali MSE Loss: 0.1898 Test MSE Loss: 0.2637
Validation loss decreased (0.191272 --> 0.189836).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2835613
	speed: 0.0124s/iter; left time: 280.8222s
	iters: 200, epoch: 6 | loss: 0.3140109
	speed: 0.0105s/iter; left time: 235.6505s
Epoch: 6 cost time: 2.7306833267211914
Epoch: 6, Steps: 239 Train Loss: 0.2923 (Forecasting Loss:0.2606 + XiCon Loss:3.1668 x Lambda(0.01)), Vali MSE Loss: 0.1887 Test MSE Loss: 0.2627
Validation loss decreased (0.189836 --> 0.188653).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2775445
	speed: 0.0128s/iter; left time: 285.4561s
	iters: 200, epoch: 7 | loss: 0.2728873
	speed: 0.0106s/iter; left time: 236.8162s
Epoch: 7 cost time: 2.7635326385498047
Epoch: 7, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2602 + XiCon Loss:3.1677 x Lambda(0.01)), Vali MSE Loss: 0.1887 Test MSE Loss: 0.2623
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2750345
	speed: 0.0117s/iter; left time: 258.8058s
	iters: 200, epoch: 8 | loss: 0.3453369
	speed: 0.0099s/iter; left time: 218.2997s
Epoch: 8 cost time: 2.577570676803589
Epoch: 8, Steps: 239 Train Loss: 0.2913 (Forecasting Loss:0.2596 + XiCon Loss:3.1673 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2622
Validation loss decreased (0.188653 --> 0.188032).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3037929
	speed: 0.0125s/iter; left time: 273.8683s
	iters: 200, epoch: 9 | loss: 0.3041245
	speed: 0.0101s/iter; left time: 220.7170s
Epoch: 9 cost time: 2.6813793182373047
Epoch: 9, Steps: 239 Train Loss: 0.2907 (Forecasting Loss:0.2590 + XiCon Loss:3.1684 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2620
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2842804
	speed: 0.0136s/iter; left time: 294.6658s
	iters: 200, epoch: 10 | loss: 0.3146375
	speed: 0.0101s/iter; left time: 217.6582s
Epoch: 10 cost time: 2.8676419258117676
Epoch: 10, Steps: 239 Train Loss: 0.2908 (Forecasting Loss:0.2592 + XiCon Loss:3.1666 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2856837
	speed: 0.0129s/iter; left time: 275.4856s
	iters: 200, epoch: 11 | loss: 0.2976251
	speed: 0.0095s/iter; left time: 203.3636s
Epoch: 11 cost time: 2.6540093421936035
Epoch: 11, Steps: 239 Train Loss: 0.2909 (Forecasting Loss:0.2593 + XiCon Loss:3.1653 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3068355
	speed: 0.0120s/iter; left time: 253.2365s
	iters: 200, epoch: 12 | loss: 0.2954782
	speed: 0.0096s/iter; left time: 202.4181s
Epoch: 12 cost time: 2.575993776321411
Epoch: 12, Steps: 239 Train Loss: 0.2905 (Forecasting Loss:0.2588 + XiCon Loss:3.1669 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2619
Validation loss decreased (0.188032 --> 0.187965).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2989149
	speed: 0.0130s/iter; left time: 272.5504s
	iters: 200, epoch: 13 | loss: 0.3056338
	speed: 0.0109s/iter; left time: 227.7217s
Epoch: 13 cost time: 2.869572639465332
Epoch: 13, Steps: 239 Train Loss: 0.2905 (Forecasting Loss:0.2589 + XiCon Loss:3.1668 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2619
Validation loss decreased (0.187965 --> 0.187905).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2868321
	speed: 0.0127s/iter; left time: 261.9486s
	iters: 200, epoch: 14 | loss: 0.2886943
	speed: 0.0100s/iter; left time: 206.6855s
Epoch: 14 cost time: 2.6884925365448
Epoch: 14, Steps: 239 Train Loss: 0.2908 (Forecasting Loss:0.2592 + XiCon Loss:3.1668 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3190742
	speed: 0.0121s/iter; left time: 247.9980s
	iters: 200, epoch: 15 | loss: 0.2757269
	speed: 0.0099s/iter; left time: 202.5031s
Epoch: 15 cost time: 2.659327745437622
Epoch: 15, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2586 + XiCon Loss:3.1674 x Lambda(0.01)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.2619
Validation loss decreased (0.187905 --> 0.187808).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2877879
	speed: 0.0123s/iter; left time: 249.0479s
	iters: 200, epoch: 16 | loss: 0.2955744
	speed: 0.0104s/iter; left time: 209.4409s
Epoch: 16 cost time: 2.695711374282837
Epoch: 16, Steps: 239 Train Loss: 0.2905 (Forecasting Loss:0.2589 + XiCon Loss:3.1676 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2647830
	speed: 0.0122s/iter; left time: 242.9065s
	iters: 200, epoch: 17 | loss: 0.2971298
	speed: 0.0096s/iter; left time: 191.6030s
Epoch: 17 cost time: 2.6008541584014893
Epoch: 17, Steps: 239 Train Loss: 0.2910 (Forecasting Loss:0.2593 + XiCon Loss:3.1676 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.3020338
	speed: 0.0134s/iter; left time: 263.8810s
	iters: 200, epoch: 18 | loss: 0.3040415
	speed: 0.0104s/iter; left time: 204.0524s
Epoch: 18 cost time: 2.809042453765869
Epoch: 18, Steps: 239 Train Loss: 0.2908 (Forecasting Loss:0.2591 + XiCon Loss:3.1666 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2619
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3332493
	speed: 0.0130s/iter; left time: 252.7811s
	iters: 200, epoch: 19 | loss: 0.3107126
	speed: 0.0100s/iter; left time: 194.1541s
Epoch: 19 cost time: 2.721121311187744
Epoch: 19, Steps: 239 Train Loss: 0.2912 (Forecasting Loss:0.2595 + XiCon Loss:3.1680 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2619
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.2788424
	speed: 0.0128s/iter; left time: 246.4106s
	iters: 200, epoch: 20 | loss: 0.2725955
	speed: 0.0105s/iter; left time: 201.1455s
Epoch: 20 cost time: 2.7310497760772705
Epoch: 20, Steps: 239 Train Loss: 0.2909 (Forecasting Loss:0.2592 + XiCon Loss:3.1674 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.3234811
	speed: 0.0124s/iter; left time: 236.2973s
	iters: 200, epoch: 21 | loss: 0.3245612
	speed: 0.0111s/iter; left time: 210.9068s
Epoch: 21 cost time: 2.755408525466919
Epoch: 21, Steps: 239 Train Loss: 0.2909 (Forecasting Loss:0.2592 + XiCon Loss:3.1671 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2619
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2684054
	speed: 0.0128s/iter; left time: 239.5333s
	iters: 200, epoch: 22 | loss: 0.2653567
	speed: 0.0096s/iter; left time: 179.2001s
Epoch: 22 cost time: 2.634023666381836
Epoch: 22, Steps: 239 Train Loss: 0.2906 (Forecasting Loss:0.2589 + XiCon Loss:3.1662 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2619
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2803579
	speed: 0.0125s/iter; left time: 232.2176s
	iters: 200, epoch: 23 | loss: 0.3129026
	speed: 0.0103s/iter; left time: 190.7338s
Epoch: 23 cost time: 2.664555311203003
Epoch: 23, Steps: 239 Train Loss: 0.2908 (Forecasting Loss:0.2591 + XiCon Loss:3.1663 x Lambda(0.01)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.2619
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2820174
	speed: 0.0124s/iter; left time: 226.4480s
	iters: 200, epoch: 24 | loss: 0.2728923
	speed: 0.0102s/iter; left time: 185.9434s
Epoch: 24 cost time: 2.6710939407348633
Epoch: 24, Steps: 239 Train Loss: 0.2909 (Forecasting Loss:0.2592 + XiCon Loss:3.1659 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2619
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.3148002
	speed: 0.0125s/iter; left time: 225.5436s
	iters: 200, epoch: 25 | loss: 0.2804644
	speed: 0.0098s/iter; left time: 175.4809s
Epoch: 25 cost time: 2.6410443782806396
Epoch: 25, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2587 + XiCon Loss:3.1668 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2619
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.2033291608095169, mae:0.3204038739204407, mape:2.5421464443206787, mspe:4565.0751953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4330
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6084931
	speed: 0.0128s/iter; left time: 304.3936s
	iters: 200, epoch: 1 | loss: 0.6410418
	speed: 0.0099s/iter; left time: 234.2832s
Epoch: 1 cost time: 2.664005994796753
Epoch: 1, Steps: 239 Train Loss: 0.6758 (Forecasting Loss:0.6435 + XiCon Loss:3.2275 x Lambda(0.01)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.4547
Validation loss decreased (inf --> 0.331922).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3506470
	speed: 0.0127s/iter; left time: 298.4944s
	iters: 200, epoch: 2 | loss: 0.3320453
	speed: 0.0105s/iter; left time: 245.2740s
Epoch: 2 cost time: 2.7884631156921387
Epoch: 2, Steps: 239 Train Loss: 0.3483 (Forecasting Loss:0.3161 + XiCon Loss:3.2186 x Lambda(0.01)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.2812
Validation loss decreased (0.331922 --> 0.205663).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3215687
	speed: 0.0121s/iter; left time: 283.3726s
	iters: 200, epoch: 3 | loss: 0.3388042
	speed: 0.0106s/iter; left time: 246.8821s
Epoch: 3 cost time: 2.7284176349639893
Epoch: 3, Steps: 239 Train Loss: 0.3108 (Forecasting Loss:0.2789 + XiCon Loss:3.1982 x Lambda(0.01)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.2748
Validation loss decreased (0.205663 --> 0.200451).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3254164
	speed: 0.0121s/iter; left time: 279.0512s
	iters: 200, epoch: 4 | loss: 0.3140502
	speed: 0.0101s/iter; left time: 232.4892s
Epoch: 4 cost time: 2.65549635887146
Epoch: 4, Steps: 239 Train Loss: 0.3046 (Forecasting Loss:0.2727 + XiCon Loss:3.1887 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2722
Validation loss decreased (0.200451 --> 0.197931).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3030951
	speed: 0.0122s/iter; left time: 278.1072s
	iters: 200, epoch: 5 | loss: 0.3182657
	speed: 0.0106s/iter; left time: 241.9822s
Epoch: 5 cost time: 2.729950189590454
Epoch: 5, Steps: 239 Train Loss: 0.3016 (Forecasting Loss:0.2697 + XiCon Loss:3.1835 x Lambda(0.01)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.2690
Validation loss decreased (0.197931 --> 0.196244).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3001763
	speed: 0.0128s/iter; left time: 289.7693s
	iters: 200, epoch: 6 | loss: 0.2705402
	speed: 0.0110s/iter; left time: 247.6114s
Epoch: 6 cost time: 2.8258352279663086
Epoch: 6, Steps: 239 Train Loss: 0.2997 (Forecasting Loss:0.2679 + XiCon Loss:3.1794 x Lambda(0.01)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.2684
Validation loss decreased (0.196244 --> 0.195450).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2823547
	speed: 0.0128s/iter; left time: 285.3352s
	iters: 200, epoch: 7 | loss: 0.3080439
	speed: 0.0098s/iter; left time: 217.9256s
Epoch: 7 cost time: 2.6704723834991455
Epoch: 7, Steps: 239 Train Loss: 0.2993 (Forecasting Loss:0.2675 + XiCon Loss:3.1802 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2677
Validation loss decreased (0.195450 --> 0.195221).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2976591
	speed: 0.0120s/iter; left time: 265.1774s
	iters: 200, epoch: 8 | loss: 0.3252153
	speed: 0.0101s/iter; left time: 223.4007s
Epoch: 8 cost time: 2.6885600090026855
Epoch: 8, Steps: 239 Train Loss: 0.2987 (Forecasting Loss:0.2670 + XiCon Loss:3.1792 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2675
Validation loss decreased (0.195221 --> 0.194618).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2498256
	speed: 0.0124s/iter; left time: 272.4303s
	iters: 200, epoch: 9 | loss: 0.2838107
	speed: 0.0104s/iter; left time: 227.1066s
Epoch: 9 cost time: 2.7254414558410645
Epoch: 9, Steps: 239 Train Loss: 0.2983 (Forecasting Loss:0.2666 + XiCon Loss:3.1769 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
Validation loss decreased (0.194618 --> 0.194509).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3030973
	speed: 0.0123s/iter; left time: 266.2774s
	iters: 200, epoch: 10 | loss: 0.3214713
	speed: 0.0099s/iter; left time: 212.8083s
Epoch: 10 cost time: 2.631126642227173
Epoch: 10, Steps: 239 Train Loss: 0.2981 (Forecasting Loss:0.2663 + XiCon Loss:3.1781 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2527170
	speed: 0.0128s/iter; left time: 274.9729s
	iters: 200, epoch: 11 | loss: 0.3331310
	speed: 0.0094s/iter; left time: 200.9157s
Epoch: 11 cost time: 2.6436026096343994
Epoch: 11, Steps: 239 Train Loss: 0.2980 (Forecasting Loss:0.2662 + XiCon Loss:3.1782 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2756954
	speed: 0.0121s/iter; left time: 256.4286s
	iters: 200, epoch: 12 | loss: 0.2910032
	speed: 0.0103s/iter; left time: 216.2148s
Epoch: 12 cost time: 2.683354377746582
Epoch: 12, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1775 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2551040
	speed: 0.0128s/iter; left time: 267.6766s
	iters: 200, epoch: 13 | loss: 0.3200893
	speed: 0.0112s/iter; left time: 232.9917s
Epoch: 13 cost time: 2.872328519821167
Epoch: 13, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1776 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2988742
	speed: 0.0119s/iter; left time: 247.2419s
	iters: 200, epoch: 14 | loss: 0.3065745
	speed: 0.0091s/iter; left time: 187.2056s
Epoch: 14 cost time: 2.495833396911621
Epoch: 14, Steps: 239 Train Loss: 0.2979 (Forecasting Loss:0.2661 + XiCon Loss:3.1781 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2884940
	speed: 0.0122s/iter; left time: 249.5649s
	iters: 200, epoch: 15 | loss: 0.3107636
	speed: 0.0099s/iter; left time: 201.6179s
Epoch: 15 cost time: 2.5852692127227783
Epoch: 15, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1758 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3146353
	speed: 0.0124s/iter; left time: 250.2866s
	iters: 200, epoch: 16 | loss: 0.2706602
	speed: 0.0097s/iter; left time: 195.5309s
Epoch: 16 cost time: 2.6091983318328857
Epoch: 16, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1778 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2910048
	speed: 0.0127s/iter; left time: 253.3108s
	iters: 200, epoch: 17 | loss: 0.2996849
	speed: 0.0104s/iter; left time: 207.6771s
Epoch: 17 cost time: 2.7296009063720703
Epoch: 17, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1754 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.3015009
	speed: 0.0124s/iter; left time: 244.1254s
	iters: 200, epoch: 18 | loss: 0.3275912
	speed: 0.0102s/iter; left time: 200.1637s
Epoch: 18 cost time: 2.6863934993743896
Epoch: 18, Steps: 239 Train Loss: 0.2978 (Forecasting Loss:0.2661 + XiCon Loss:3.1768 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2857454
	speed: 0.0130s/iter; left time: 253.0022s
	iters: 200, epoch: 19 | loss: 0.2886251
	speed: 0.0102s/iter; left time: 197.8967s
Epoch: 19 cost time: 2.7441751956939697
Epoch: 19, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1790 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
Validation loss decreased (0.194509 --> 0.194494).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3103490
	speed: 0.0121s/iter; left time: 232.4226s
	iters: 200, epoch: 20 | loss: 0.2883958
	speed: 0.0111s/iter; left time: 212.4819s
Epoch: 20 cost time: 2.7386016845703125
Epoch: 20, Steps: 239 Train Loss: 0.2981 (Forecasting Loss:0.2663 + XiCon Loss:3.1763 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2749349
	speed: 0.0123s/iter; left time: 234.1051s
	iters: 200, epoch: 21 | loss: 0.3119574
	speed: 0.0094s/iter; left time: 178.1756s
Epoch: 21 cost time: 2.5962276458740234
Epoch: 21, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2665 + XiCon Loss:3.1775 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3077818
	speed: 0.0124s/iter; left time: 232.7845s
	iters: 200, epoch: 22 | loss: 0.3102550
	speed: 0.0100s/iter; left time: 186.4839s
Epoch: 22 cost time: 2.6790761947631836
Epoch: 22, Steps: 239 Train Loss: 0.2983 (Forecasting Loss:0.2665 + XiCon Loss:3.1781 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2790174
	speed: 0.0119s/iter; left time: 220.2651s
	iters: 200, epoch: 23 | loss: 0.3070663
	speed: 0.0103s/iter; left time: 189.0789s
Epoch: 23 cost time: 2.63132905960083
Epoch: 23, Steps: 239 Train Loss: 0.2980 (Forecasting Loss:0.2662 + XiCon Loss:3.1782 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2900621
	speed: 0.0116s/iter; left time: 212.9154s
	iters: 200, epoch: 24 | loss: 0.2976586
	speed: 0.0097s/iter; left time: 177.4642s
Epoch: 24 cost time: 2.576225519180298
Epoch: 24, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1793 x Lambda(0.01)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2674
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2970021
	speed: 0.0128s/iter; left time: 230.4184s
	iters: 200, epoch: 25 | loss: 0.3395313
	speed: 0.0097s/iter; left time: 174.1468s
Epoch: 25 cost time: 2.6551976203918457
Epoch: 25, Steps: 239 Train Loss: 0.2979 (Forecasting Loss:0.2661 + XiCon Loss:3.1760 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.3114965
	speed: 0.0124s/iter; left time: 220.7760s
	iters: 200, epoch: 26 | loss: 0.2577206
	speed: 0.0096s/iter; left time: 170.1709s
Epoch: 26 cost time: 2.621553421020508
Epoch: 26, Steps: 239 Train Loss: 0.2981 (Forecasting Loss:0.2663 + XiCon Loss:3.1762 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2674
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.3019856
	speed: 0.0126s/iter; left time: 222.2040s
	iters: 200, epoch: 27 | loss: 0.2889527
	speed: 0.0102s/iter; left time: 177.8990s
Epoch: 27 cost time: 2.7214834690093994
Epoch: 27, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2664 + XiCon Loss:3.1765 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.3297580
	speed: 0.0122s/iter; left time: 211.5100s
	iters: 200, epoch: 28 | loss: 0.2813465
	speed: 0.0096s/iter; left time: 165.6193s
Epoch: 28 cost time: 2.599154233932495
Epoch: 28, Steps: 239 Train Loss: 0.2978 (Forecasting Loss:0.2660 + XiCon Loss:3.1775 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2541870
	speed: 0.0120s/iter; left time: 205.4188s
	iters: 200, epoch: 29 | loss: 0.3009403
	speed: 0.0101s/iter; left time: 171.3837s
Epoch: 29 cost time: 2.6247143745422363
Epoch: 29, Steps: 239 Train Loss: 0.2980 (Forecasting Loss:0.2663 + XiCon Loss:3.1778 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21018147468566895, mae:0.3245789408683777, mape:2.3913092613220215, mspe:3026.25146484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5951
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6608642
	speed: 0.0122s/iter; left time: 290.4160s
	iters: 200, epoch: 1 | loss: 0.6038340
	speed: 0.0103s/iter; left time: 243.8952s
Epoch: 1 cost time: 2.648151159286499
Epoch: 1, Steps: 239 Train Loss: 0.6490 (Forecasting Loss:0.6176 + XiCon Loss:3.1458 x Lambda(0.01)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.4338
Validation loss decreased (inf --> 0.318376).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3509023
	speed: 0.0119s/iter; left time: 280.9786s
	iters: 200, epoch: 2 | loss: 0.3219518
	speed: 0.0112s/iter; left time: 263.5015s
Epoch: 2 cost time: 2.757704496383667
Epoch: 2, Steps: 239 Train Loss: 0.3453 (Forecasting Loss:0.3139 + XiCon Loss:3.1332 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.2827
Validation loss decreased (0.318376 --> 0.207222).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3109149
	speed: 0.0122s/iter; left time: 285.3611s
	iters: 200, epoch: 3 | loss: 0.3311014
	speed: 0.0110s/iter; left time: 254.8572s
Epoch: 3 cost time: 2.71014404296875
Epoch: 3, Steps: 239 Train Loss: 0.3089 (Forecasting Loss:0.2776 + XiCon Loss:3.1251 x Lambda(0.01)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.2733
Validation loss decreased (0.207222 --> 0.201220).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2823039
	speed: 0.0122s/iter; left time: 282.4906s
	iters: 200, epoch: 4 | loss: 0.3553388
	speed: 0.0098s/iter; left time: 224.4791s
Epoch: 4 cost time: 2.6333491802215576
Epoch: 4, Steps: 239 Train Loss: 0.3018 (Forecasting Loss:0.2706 + XiCon Loss:3.1219 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2679
Validation loss decreased (0.201220 --> 0.195247).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3049645
	speed: 0.0133s/iter; left time: 303.8230s
	iters: 200, epoch: 5 | loss: 0.2867048
	speed: 0.0097s/iter; left time: 220.7616s
Epoch: 5 cost time: 2.7337727546691895
Epoch: 5, Steps: 239 Train Loss: 0.2983 (Forecasting Loss:0.2671 + XiCon Loss:3.1199 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2670
Validation loss decreased (0.195247 --> 0.194929).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3090288
	speed: 0.0125s/iter; left time: 282.7388s
	iters: 200, epoch: 6 | loss: 0.2978913
	speed: 0.0099s/iter; left time: 222.4330s
Epoch: 6 cost time: 2.6177592277526855
Epoch: 6, Steps: 239 Train Loss: 0.2966 (Forecasting Loss:0.2654 + XiCon Loss:3.1174 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2654
Validation loss decreased (0.194929 --> 0.194829).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2984299
	speed: 0.0120s/iter; left time: 268.7890s
	iters: 200, epoch: 7 | loss: 0.2591192
	speed: 0.0101s/iter; left time: 223.9424s
Epoch: 7 cost time: 2.6316304206848145
Epoch: 7, Steps: 239 Train Loss: 0.2960 (Forecasting Loss:0.2648 + XiCon Loss:3.1188 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2649
Validation loss decreased (0.194829 --> 0.193868).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2652772
	speed: 0.0128s/iter; left time: 282.7808s
	iters: 200, epoch: 8 | loss: 0.2836452
	speed: 0.0098s/iter; left time: 215.5054s
Epoch: 8 cost time: 2.677975654602051
Epoch: 8, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2641 + XiCon Loss:3.1199 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2649
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3037210
	speed: 0.0127s/iter; left time: 278.4904s
	iters: 200, epoch: 9 | loss: 0.2990859
	speed: 0.0098s/iter; left time: 213.7859s
Epoch: 9 cost time: 2.7025461196899414
Epoch: 9, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1183 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193868 --> 0.193742).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3107742
	speed: 0.0122s/iter; left time: 264.7700s
	iters: 200, epoch: 10 | loss: 0.3086818
	speed: 0.0105s/iter; left time: 226.4792s
Epoch: 10 cost time: 2.792583465576172
Epoch: 10, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1167 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3246345
	speed: 0.0126s/iter; left time: 269.1200s
	iters: 200, epoch: 11 | loss: 0.3027723
	speed: 0.0100s/iter; left time: 213.0002s
Epoch: 11 cost time: 2.6839447021484375
Epoch: 11, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1192 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193742 --> 0.193729).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3279155
	speed: 0.0130s/iter; left time: 275.0664s
	iters: 200, epoch: 12 | loss: 0.2654265
	speed: 0.0102s/iter; left time: 215.7102s
Epoch: 12 cost time: 2.758605718612671
Epoch: 12, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1205 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193729 --> 0.193392).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2911087
	speed: 0.0123s/iter; left time: 257.7578s
	iters: 200, epoch: 13 | loss: 0.2775224
	speed: 0.0104s/iter; left time: 216.9985s
Epoch: 13 cost time: 2.743246555328369
Epoch: 13, Steps: 239 Train Loss: 0.2945 (Forecasting Loss:0.2633 + XiCon Loss:3.1178 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2738945
	speed: 0.0122s/iter; left time: 251.9923s
	iters: 200, epoch: 14 | loss: 0.3076062
	speed: 0.0100s/iter; left time: 205.7402s
Epoch: 14 cost time: 2.7126569747924805
Epoch: 14, Steps: 239 Train Loss: 0.2947 (Forecasting Loss:0.2635 + XiCon Loss:3.1201 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2760203
	speed: 0.0121s/iter; left time: 246.7434s
	iters: 200, epoch: 15 | loss: 0.2865527
	speed: 0.0104s/iter; left time: 211.6792s
Epoch: 15 cost time: 2.621490001678467
Epoch: 15, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1176 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2695186
	speed: 0.0124s/iter; left time: 250.3229s
	iters: 200, epoch: 16 | loss: 0.2987573
	speed: 0.0105s/iter; left time: 212.0739s
Epoch: 16 cost time: 2.7045469284057617
Epoch: 16, Steps: 239 Train Loss: 0.2947 (Forecasting Loss:0.2635 + XiCon Loss:3.1185 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3012553
	speed: 0.0122s/iter; left time: 243.4869s
	iters: 200, epoch: 17 | loss: 0.2763365
	speed: 0.0107s/iter; left time: 212.7402s
Epoch: 17 cost time: 2.70633864402771
Epoch: 17, Steps: 239 Train Loss: 0.2953 (Forecasting Loss:0.2641 + XiCon Loss:3.1172 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2887787
	speed: 0.0131s/iter; left time: 258.1382s
	iters: 200, epoch: 18 | loss: 0.3042939
	speed: 0.0113s/iter; left time: 222.6873s
Epoch: 18 cost time: 2.8511531352996826
Epoch: 18, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1194 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193392 --> 0.193388).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2831126
	speed: 0.0122s/iter; left time: 238.1527s
	iters: 200, epoch: 19 | loss: 0.3057595
	speed: 0.0103s/iter; left time: 200.2139s
Epoch: 19 cost time: 2.6858599185943604
Epoch: 19, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1188 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3174504
	speed: 0.0123s/iter; left time: 236.5409s
	iters: 200, epoch: 20 | loss: 0.2912203
	speed: 0.0101s/iter; left time: 192.6774s
Epoch: 20 cost time: 2.72914719581604
Epoch: 20, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1197 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2916088
	speed: 0.0121s/iter; left time: 230.1578s
	iters: 200, epoch: 21 | loss: 0.3238127
	speed: 0.0104s/iter; left time: 197.2711s
Epoch: 21 cost time: 2.6796813011169434
Epoch: 21, Steps: 239 Train Loss: 0.2946 (Forecasting Loss:0.2634 + XiCon Loss:3.1193 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3085969
	speed: 0.0134s/iter; left time: 251.0895s
	iters: 200, epoch: 22 | loss: 0.3092885
	speed: 0.0113s/iter; left time: 211.4128s
Epoch: 22 cost time: 2.8825907707214355
Epoch: 22, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1184 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2674183
	speed: 0.0131s/iter; left time: 243.0061s
	iters: 200, epoch: 23 | loss: 0.2809211
	speed: 0.0093s/iter; left time: 171.8910s
Epoch: 23 cost time: 2.624431848526001
Epoch: 23, Steps: 239 Train Loss: 0.2944 (Forecasting Loss:0.2632 + XiCon Loss:3.1199 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3145578
	speed: 0.0117s/iter; left time: 214.3875s
	iters: 200, epoch: 24 | loss: 0.2911094
	speed: 0.0099s/iter; left time: 180.3724s
Epoch: 24 cost time: 2.6295230388641357
Epoch: 24, Steps: 239 Train Loss: 0.2947 (Forecasting Loss:0.2635 + XiCon Loss:3.1187 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193388 --> 0.193383).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2836486
	speed: 0.0120s/iter; left time: 216.7816s
	iters: 200, epoch: 25 | loss: 0.2937172
	speed: 0.0101s/iter; left time: 181.7800s
Epoch: 25 cost time: 2.6369097232818604
Epoch: 25, Steps: 239 Train Loss: 0.2946 (Forecasting Loss:0.2634 + XiCon Loss:3.1193 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2805840
	speed: 0.0122s/iter; left time: 218.0146s
	iters: 200, epoch: 26 | loss: 0.3016505
	speed: 0.0096s/iter; left time: 170.2005s
Epoch: 26 cost time: 2.6075806617736816
Epoch: 26, Steps: 239 Train Loss: 0.2947 (Forecasting Loss:0.2635 + XiCon Loss:3.1187 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2902462
	speed: 0.0135s/iter; left time: 237.5697s
	iters: 200, epoch: 27 | loss: 0.2893842
	speed: 0.0113s/iter; left time: 196.9382s
Epoch: 27 cost time: 2.89768123626709
Epoch: 27, Steps: 239 Train Loss: 0.2944 (Forecasting Loss:0.2632 + XiCon Loss:3.1204 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2806142
	speed: 0.0125s/iter; left time: 217.5744s
	iters: 200, epoch: 28 | loss: 0.2960081
	speed: 0.0103s/iter; left time: 177.2231s
Epoch: 28 cost time: 2.7553439140319824
Epoch: 28, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1178 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.3122000
	speed: 0.0124s/iter; left time: 211.3141s
	iters: 200, epoch: 29 | loss: 0.3076257
	speed: 0.0100s/iter; left time: 169.2832s
Epoch: 29 cost time: 2.647603988647461
Epoch: 29, Steps: 239 Train Loss: 0.2943 (Forecasting Loss:0.2631 + XiCon Loss:3.1200 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.2634380
	speed: 0.0122s/iter; left time: 206.5416s
	iters: 200, epoch: 30 | loss: 0.2766235
	speed: 0.0101s/iter; left time: 169.8533s
Epoch: 30 cost time: 2.657987594604492
Epoch: 30, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1178 x Lambda(0.01)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2647
Validation loss decreased (0.193383 --> 0.193206).  Saving model ...
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3060775
	speed: 0.0128s/iter; left time: 213.1511s
	iters: 200, epoch: 31 | loss: 0.2738627
	speed: 0.0107s/iter; left time: 177.2631s
Epoch: 31 cost time: 2.8027610778808594
Epoch: 31, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1205 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.2552081
	speed: 0.0122s/iter; left time: 199.9642s
	iters: 200, epoch: 32 | loss: 0.2632545
	speed: 0.0103s/iter; left time: 167.7254s
Epoch: 32 cost time: 2.675990581512451
Epoch: 32, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1173 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.2857149
	speed: 0.0124s/iter; left time: 200.4246s
	iters: 200, epoch: 33 | loss: 0.3105784
	speed: 0.0100s/iter; left time: 160.3082s
Epoch: 33 cost time: 2.647441864013672
Epoch: 33, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1175 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2780122
	speed: 0.0128s/iter; left time: 204.4007s
	iters: 200, epoch: 34 | loss: 0.3439303
	speed: 0.0105s/iter; left time: 166.6566s
Epoch: 34 cost time: 2.737820863723755
Epoch: 34, Steps: 239 Train Loss: 0.2946 (Forecasting Loss:0.2634 + XiCon Loss:3.1183 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2842552
	speed: 0.0126s/iter; left time: 197.1986s
	iters: 200, epoch: 35 | loss: 0.3276851
	speed: 0.0104s/iter; left time: 162.2634s
Epoch: 35 cost time: 2.7433972358703613
Epoch: 35, Steps: 239 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1186 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.2788635
	speed: 0.0120s/iter; left time: 184.9403s
	iters: 200, epoch: 36 | loss: 0.3102028
	speed: 0.0096s/iter; left time: 146.4831s
Epoch: 36 cost time: 2.603400468826294
Epoch: 36, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1186 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2841405
	speed: 0.0117s/iter; left time: 177.4980s
	iters: 200, epoch: 37 | loss: 0.3193705
	speed: 0.0094s/iter; left time: 142.3332s
Epoch: 37 cost time: 2.5112409591674805
Epoch: 37, Steps: 239 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1188 x Lambda(0.01)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2647
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2806037
	speed: 0.0124s/iter; left time: 185.7842s
	iters: 200, epoch: 38 | loss: 0.3430743
	speed: 0.0101s/iter; left time: 149.9744s
Epoch: 38 cost time: 2.669454336166382
Epoch: 38, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1183 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.2987147
	speed: 0.0126s/iter; left time: 185.7353s
	iters: 200, epoch: 39 | loss: 0.2888420
	speed: 0.0102s/iter; left time: 149.8200s
Epoch: 39 cost time: 2.7150790691375732
Epoch: 39, Steps: 239 Train Loss: 0.2948 (Forecasting Loss:0.2636 + XiCon Loss:3.1180 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
	iters: 100, epoch: 40 | loss: 0.3019557
	speed: 0.0125s/iter; left time: 181.7169s
	iters: 200, epoch: 40 | loss: 0.2840885
	speed: 0.0106s/iter; left time: 151.7919s
Epoch: 40 cost time: 2.7576072216033936
Epoch: 40, Steps: 239 Train Loss: 0.2945 (Forecasting Loss:0.2633 + XiCon Loss:3.1178 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20760269463062286, mae:0.32172414660453796, mape:2.3988659381866455, mspe:3326.78955078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4645
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6389917
	speed: 0.0127s/iter; left time: 301.7385s
	iters: 200, epoch: 1 | loss: 0.5397571
	speed: 0.0103s/iter; left time: 243.8265s
Epoch: 1 cost time: 2.725614309310913
Epoch: 1, Steps: 239 Train Loss: 0.6682 (Forecasting Loss:0.6367 + XiCon Loss:3.1496 x Lambda(0.01)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.4405
Validation loss decreased (inf --> 0.327542).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3536600
	speed: 0.0122s/iter; left time: 287.8223s
	iters: 200, epoch: 2 | loss: 0.3191667
	speed: 0.0100s/iter; left time: 234.8785s
Epoch: 2 cost time: 2.6455941200256348
Epoch: 2, Steps: 239 Train Loss: 0.3479 (Forecasting Loss:0.3165 + XiCon Loss:3.1404 x Lambda(0.01)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.2813
Validation loss decreased (0.327542 --> 0.206760).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3426219
	speed: 0.0120s/iter; left time: 280.2680s
	iters: 200, epoch: 3 | loss: 0.2958124
	speed: 0.0103s/iter; left time: 238.9198s
Epoch: 3 cost time: 2.639019012451172
Epoch: 3, Steps: 239 Train Loss: 0.3091 (Forecasting Loss:0.2777 + XiCon Loss:3.1395 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2705
Validation loss decreased (0.206760 --> 0.197894).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3017981
	speed: 0.0126s/iter; left time: 291.0058s
	iters: 200, epoch: 4 | loss: 0.2811300
	speed: 0.0102s/iter; left time: 235.4777s
Epoch: 4 cost time: 2.7183406352996826
Epoch: 4, Steps: 239 Train Loss: 0.3001 (Forecasting Loss:0.2686 + XiCon Loss:3.1466 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2668
Validation loss decreased (0.197894 --> 0.194356).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3462617
	speed: 0.0121s/iter; left time: 276.5182s
	iters: 200, epoch: 5 | loss: 0.3057401
	speed: 0.0096s/iter; left time: 218.5396s
Epoch: 5 cost time: 2.5863630771636963
Epoch: 5, Steps: 239 Train Loss: 0.2959 (Forecasting Loss:0.2643 + XiCon Loss:3.1531 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2650
Validation loss decreased (0.194356 --> 0.192900).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2822767
	speed: 0.0121s/iter; left time: 273.1310s
	iters: 200, epoch: 6 | loss: 0.2712606
	speed: 0.0101s/iter; left time: 228.4184s
Epoch: 6 cost time: 2.6434428691864014
Epoch: 6, Steps: 239 Train Loss: 0.2937 (Forecasting Loss:0.2622 + XiCon Loss:3.1558 x Lambda(0.01)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.2633
Validation loss decreased (0.192900 --> 0.192112).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3151878
	speed: 0.0129s/iter; left time: 288.6820s
	iters: 200, epoch: 7 | loss: 0.2805885
	speed: 0.0102s/iter; left time: 227.2172s
Epoch: 7 cost time: 2.714536190032959
Epoch: 7, Steps: 239 Train Loss: 0.2927 (Forecasting Loss:0.2612 + XiCon Loss:3.1563 x Lambda(0.01)), Vali MSE Loss: 0.1917 Test MSE Loss: 0.2629
Validation loss decreased (0.192112 --> 0.191712).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3042243
	speed: 0.0115s/iter; left time: 254.7849s
	iters: 200, epoch: 8 | loss: 0.3309821
	speed: 0.0099s/iter; left time: 219.1045s
Epoch: 8 cost time: 2.5549771785736084
Epoch: 8, Steps: 239 Train Loss: 0.2925 (Forecasting Loss:0.2609 + XiCon Loss:3.1583 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.2627
Validation loss decreased (0.191712 --> 0.191594).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2869821
	speed: 0.0130s/iter; left time: 285.0436s
	iters: 200, epoch: 9 | loss: 0.2684766
	speed: 0.0103s/iter; left time: 224.1994s
Epoch: 9 cost time: 2.7674994468688965
Epoch: 9, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1593 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
Validation loss decreased (0.191594 --> 0.191212).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2795109
	speed: 0.0124s/iter; left time: 268.3137s
	iters: 200, epoch: 10 | loss: 0.2848935
	speed: 0.0098s/iter; left time: 211.7245s
Epoch: 10 cost time: 2.633108615875244
Epoch: 10, Steps: 239 Train Loss: 0.2921 (Forecasting Loss:0.2605 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2625
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3032908
	speed: 0.0123s/iter; left time: 263.7305s
	iters: 200, epoch: 11 | loss: 0.3350791
	speed: 0.0098s/iter; left time: 209.5827s
Epoch: 11 cost time: 2.6367347240448
Epoch: 11, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2600 + XiCon Loss:3.1605 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
Validation loss decreased (0.191212 --> 0.191183).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2951078
	speed: 0.0132s/iter; left time: 278.6493s
	iters: 200, epoch: 12 | loss: 0.2939481
	speed: 0.0108s/iter; left time: 227.0430s
Epoch: 12 cost time: 2.850400447845459
Epoch: 12, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2604 + XiCon Loss:3.1579 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3070774
	speed: 0.0128s/iter; left time: 268.6100s
	iters: 200, epoch: 13 | loss: 0.3144587
	speed: 0.0102s/iter; left time: 211.9411s
Epoch: 13 cost time: 2.7051007747650146
Epoch: 13, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1613 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2704653
	speed: 0.0122s/iter; left time: 252.0355s
	iters: 200, epoch: 14 | loss: 0.2707456
	speed: 0.0107s/iter; left time: 219.5051s
Epoch: 14 cost time: 2.719447374343872
Epoch: 14, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2603 + XiCon Loss:3.1611 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2897598
	speed: 0.0121s/iter; left time: 247.4959s
	iters: 200, epoch: 15 | loss: 0.3020397
	speed: 0.0095s/iter; left time: 193.1812s
Epoch: 15 cost time: 2.579514265060425
Epoch: 15, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2604 + XiCon Loss:3.1587 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2968407
	speed: 0.0121s/iter; left time: 244.6434s
	iters: 200, epoch: 16 | loss: 0.3265516
	speed: 0.0110s/iter; left time: 220.8822s
Epoch: 16 cost time: 2.745225429534912
Epoch: 16, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1585 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3028202
	speed: 0.0122s/iter; left time: 242.8418s
	iters: 200, epoch: 17 | loss: 0.2953510
	speed: 0.0099s/iter; left time: 197.4102s
Epoch: 17 cost time: 2.6555991172790527
Epoch: 17, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1587 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
Validation loss decreased (0.191183 --> 0.191170).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2972313
	speed: 0.0121s/iter; left time: 238.3403s
	iters: 200, epoch: 18 | loss: 0.2778717
	speed: 0.0098s/iter; left time: 191.5991s
Epoch: 18 cost time: 2.59098219871521
Epoch: 18, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1611 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2952744
	speed: 0.0121s/iter; left time: 236.4810s
	iters: 200, epoch: 19 | loss: 0.3073289
	speed: 0.0093s/iter; left time: 180.3181s
Epoch: 19 cost time: 2.5861387252807617
Epoch: 19, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2600 + XiCon Loss:3.1619 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3032520
	speed: 0.0126s/iter; left time: 243.5480s
	iters: 200, epoch: 20 | loss: 0.2406777
	speed: 0.0094s/iter; left time: 180.1776s
Epoch: 20 cost time: 2.6167640686035156
Epoch: 20, Steps: 239 Train Loss: 0.2923 (Forecasting Loss:0.2607 + XiCon Loss:3.1599 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2925414
	speed: 0.0136s/iter; left time: 257.9222s
	iters: 200, epoch: 21 | loss: 0.2938876
	speed: 0.0112s/iter; left time: 212.1125s
Epoch: 21 cost time: 2.9525537490844727
Epoch: 21, Steps: 239 Train Loss: 0.2922 (Forecasting Loss:0.2606 + XiCon Loss:3.1603 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
Validation loss decreased (0.191170 --> 0.191074).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2971473
	speed: 0.0126s/iter; left time: 236.6725s
	iters: 200, epoch: 22 | loss: 0.3088515
	speed: 0.0109s/iter; left time: 204.0249s
Epoch: 22 cost time: 2.786377429962158
Epoch: 22, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1585 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2973147
	speed: 0.0126s/iter; left time: 234.4552s
	iters: 200, epoch: 23 | loss: 0.2803381
	speed: 0.0104s/iter; left time: 191.0332s
Epoch: 23 cost time: 2.742170572280884
Epoch: 23, Steps: 239 Train Loss: 0.2914 (Forecasting Loss:0.2598 + XiCon Loss:3.1584 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3017479
	speed: 0.0136s/iter; left time: 249.7501s
	iters: 200, epoch: 24 | loss: 0.2640430
	speed: 0.0097s/iter; left time: 177.1332s
Epoch: 24 cost time: 2.7659964561462402
Epoch: 24, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1567 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2657515
	speed: 0.0125s/iter; left time: 226.7102s
	iters: 200, epoch: 25 | loss: 0.2843630
	speed: 0.0101s/iter; left time: 180.5914s
Epoch: 25 cost time: 2.690511703491211
Epoch: 25, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2603 + XiCon Loss:3.1580 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2566090
	speed: 0.0127s/iter; left time: 226.8965s
	iters: 200, epoch: 26 | loss: 0.2964618
	speed: 0.0099s/iter; left time: 174.7912s
Epoch: 26 cost time: 2.6541879177093506
Epoch: 26, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2604 + XiCon Loss:3.1591 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2612928
	speed: 0.0122s/iter; left time: 214.0891s
	iters: 200, epoch: 27 | loss: 0.3139089
	speed: 0.0101s/iter; left time: 177.2954s
Epoch: 27 cost time: 2.6629340648651123
Epoch: 27, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1581 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2911882
	speed: 0.0129s/iter; left time: 222.9421s
	iters: 200, epoch: 28 | loss: 0.3051249
	speed: 0.0102s/iter; left time: 176.1401s
Epoch: 28 cost time: 2.7484731674194336
Epoch: 28, Steps: 239 Train Loss: 0.2920 (Forecasting Loss:0.2604 + XiCon Loss:3.1578 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2767717
	speed: 0.0124s/iter; left time: 211.6337s
	iters: 200, epoch: 29 | loss: 0.2903746
	speed: 0.0096s/iter; left time: 163.6508s
Epoch: 29 cost time: 2.6125314235687256
Epoch: 29, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2603 + XiCon Loss:3.1590 x Lambda(0.01)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.2624
Validation loss decreased (0.191074 --> 0.190929).  Saving model ...
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.3128356
	speed: 0.0132s/iter; left time: 222.6751s
	iters: 200, epoch: 30 | loss: 0.2858763
	speed: 0.0098s/iter; left time: 164.5612s
Epoch: 30 cost time: 2.7580654621124268
Epoch: 30, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1593 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3136061
	speed: 0.0123s/iter; left time: 204.3464s
	iters: 200, epoch: 31 | loss: 0.2999181
	speed: 0.0100s/iter; left time: 165.2977s
Epoch: 31 cost time: 2.6452367305755615
Epoch: 31, Steps: 239 Train Loss: 0.2917 (Forecasting Loss:0.2601 + XiCon Loss:3.1582 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.3395887
	speed: 0.0122s/iter; left time: 200.0538s
	iters: 200, epoch: 32 | loss: 0.2667624
	speed: 0.0098s/iter; left time: 159.1839s
Epoch: 32 cost time: 2.6182034015655518
Epoch: 32, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1598 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.3029981
	speed: 0.0128s/iter; left time: 206.0415s
	iters: 200, epoch: 33 | loss: 0.2644898
	speed: 0.0096s/iter; left time: 154.6780s
Epoch: 33 cost time: 2.6207659244537354
Epoch: 33, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1581 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2886605
	speed: 0.0118s/iter; left time: 187.6883s
	iters: 200, epoch: 34 | loss: 0.2568372
	speed: 0.0100s/iter; left time: 158.6350s
Epoch: 34 cost time: 2.6106173992156982
Epoch: 34, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1596 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2655955
	speed: 0.0128s/iter; left time: 201.0566s
	iters: 200, epoch: 35 | loss: 0.2925487
	speed: 0.0103s/iter; left time: 160.6786s
Epoch: 35 cost time: 2.7537035942077637
Epoch: 35, Steps: 239 Train Loss: 0.2916 (Forecasting Loss:0.2600 + XiCon Loss:3.1578 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.3034387
	speed: 0.0133s/iter; left time: 205.6128s
	iters: 200, epoch: 36 | loss: 0.2872114
	speed: 0.0103s/iter; left time: 158.7202s
Epoch: 36 cost time: 2.7808690071105957
Epoch: 36, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2603 + XiCon Loss:3.1596 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2874586
	speed: 0.0127s/iter; left time: 192.9177s
	iters: 200, epoch: 37 | loss: 0.2983670
	speed: 0.0103s/iter; left time: 154.9810s
Epoch: 37 cost time: 2.6675326824188232
Epoch: 37, Steps: 239 Train Loss: 0.2919 (Forecasting Loss:0.2603 + XiCon Loss:3.1581 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2665982
	speed: 0.0124s/iter; left time: 185.8625s
	iters: 200, epoch: 38 | loss: 0.3140296
	speed: 0.0096s/iter; left time: 142.2455s
Epoch: 38 cost time: 2.6588003635406494
Epoch: 38, Steps: 239 Train Loss: 0.2918 (Forecasting Loss:0.2602 + XiCon Loss:3.1586 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.2624
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.3375452
	speed: 0.0122s/iter; left time: 180.0438s
	iters: 200, epoch: 39 | loss: 0.3111454
	speed: 0.0100s/iter; left time: 145.6288s
Epoch: 39 cost time: 2.6549792289733887
Epoch: 39, Steps: 239 Train Loss: 0.2915 (Forecasting Loss:0.2599 + XiCon Loss:3.1590 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20504872500896454, mae:0.31980714201927185, mape:2.4715371131896973, mspe:4034.11376953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2065+-0.00323, MAE:0.3214+-0.00241, MAPE:2.4275+-0.10015, MSPE:3631.2156+-803.66467, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.6859
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.8578994
	speed: 0.0171s/iter; left time: 391.1029s
	iters: 200, epoch: 1 | loss: 3.7350316
	speed: 0.0116s/iter; left time: 263.7595s
Epoch: 1 cost time: 3.2324395179748535
Epoch: 1, Steps: 230 Train Loss: 3.8228 (Forecasting Loss:0.7227 + XiCon Loss:3.1001 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.5301
Validation loss decreased (inf --> 0.330922).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3545053
	speed: 0.0147s/iter; left time: 332.3141s
	iters: 200, epoch: 2 | loss: 3.2972658
	speed: 0.0124s/iter; left time: 279.0190s
Epoch: 2 cost time: 3.0858702659606934
Epoch: 2, Steps: 230 Train Loss: 3.4206 (Forecasting Loss:0.4234 + XiCon Loss:2.9972 x Lambda(1.0)), Vali MSE Loss: 0.2170 Test MSE Loss: 0.3772
Validation loss decreased (0.330922 --> 0.217002).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3063068
	speed: 0.0137s/iter; left time: 306.4513s
	iters: 200, epoch: 3 | loss: 3.3217030
	speed: 0.0110s/iter; left time: 245.2760s
Epoch: 3 cost time: 2.830993890762329
Epoch: 3, Steps: 230 Train Loss: 3.3052 (Forecasting Loss:0.3803 + XiCon Loss:2.9249 x Lambda(1.0)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.3650
Validation loss decreased (0.217002 --> 0.205632).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2693300
	speed: 0.0140s/iter; left time: 310.7625s
	iters: 200, epoch: 4 | loss: 3.2887230
	speed: 0.0121s/iter; left time: 266.5842s
Epoch: 4 cost time: 2.9864633083343506
Epoch: 4, Steps: 230 Train Loss: 3.2869 (Forecasting Loss:0.3717 + XiCon Loss:2.9152 x Lambda(1.0)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.3613
Validation loss decreased (0.205632 --> 0.203755).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3481307
	speed: 0.0143s/iter; left time: 315.3151s
	iters: 200, epoch: 5 | loss: 3.2703719
	speed: 0.0111s/iter; left time: 242.8354s
Epoch: 5 cost time: 2.924530029296875
Epoch: 5, Steps: 230 Train Loss: 3.2800 (Forecasting Loss:0.3682 + XiCon Loss:2.9118 x Lambda(1.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.3617
Validation loss decreased (0.203755 --> 0.203199).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3029244
	speed: 0.0142s/iter; left time: 307.8948s
	iters: 200, epoch: 6 | loss: 3.3139341
	speed: 0.0116s/iter; left time: 251.4663s
Epoch: 6 cost time: 2.9504613876342773
Epoch: 6, Steps: 230 Train Loss: 3.2753 (Forecasting Loss:0.3665 + XiCon Loss:2.9087 x Lambda(1.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.3591
Validation loss decreased (0.203199 --> 0.202604).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.3037014
	speed: 0.0140s/iter; left time: 301.7700s
	iters: 200, epoch: 7 | loss: 3.2711625
	speed: 0.0114s/iter; left time: 243.6539s
Epoch: 7 cost time: 2.9117114543914795
Epoch: 7, Steps: 230 Train Loss: 3.2734 (Forecasting Loss:0.3655 + XiCon Loss:2.9079 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3578
Validation loss decreased (0.202604 --> 0.202428).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3035321
	speed: 0.0139s/iter; left time: 297.0082s
	iters: 200, epoch: 8 | loss: 3.2920613
	speed: 0.0113s/iter; left time: 239.0302s
Epoch: 8 cost time: 2.8981125354766846
Epoch: 8, Steps: 230 Train Loss: 3.2717 (Forecasting Loss:0.3647 + XiCon Loss:2.9069 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3574
Validation loss decreased (0.202428 --> 0.202176).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2563848
	speed: 0.0144s/iter; left time: 303.1488s
	iters: 200, epoch: 9 | loss: 3.2971890
	speed: 0.0122s/iter; left time: 255.5557s
Epoch: 9 cost time: 3.025747537612915
Epoch: 9, Steps: 230 Train Loss: 3.2705 (Forecasting Loss:0.3645 + XiCon Loss:2.9060 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3575
Validation loss decreased (0.202176 --> 0.202016).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2534435
	speed: 0.0138s/iter; left time: 287.5361s
	iters: 200, epoch: 10 | loss: 3.2998760
	speed: 0.0119s/iter; left time: 246.6776s
Epoch: 10 cost time: 2.9739089012145996
Epoch: 10, Steps: 230 Train Loss: 3.2701 (Forecasting Loss:0.3643 + XiCon Loss:2.9058 x Lambda(1.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.3575
Validation loss decreased (0.202016 --> 0.201934).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2340794
	speed: 0.0135s/iter; left time: 278.6046s
	iters: 200, epoch: 11 | loss: 3.2646980
	speed: 0.0120s/iter; left time: 245.5152s
Epoch: 11 cost time: 2.9322562217712402
Epoch: 11, Steps: 230 Train Loss: 3.2695 (Forecasting Loss:0.3639 + XiCon Loss:2.9056 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.3574
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2541332
	speed: 0.0141s/iter; left time: 287.3855s
	iters: 200, epoch: 12 | loss: 3.2780433
	speed: 0.0117s/iter; left time: 237.6783s
Epoch: 12 cost time: 2.951580047607422
Epoch: 12, Steps: 230 Train Loss: 3.2725 (Forecasting Loss:0.3652 + XiCon Loss:2.9074 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2533898
	speed: 0.0140s/iter; left time: 281.3769s
	iters: 200, epoch: 13 | loss: 3.2219176
	speed: 0.0118s/iter; left time: 236.0507s
Epoch: 13 cost time: 2.9671804904937744
Epoch: 13, Steps: 230 Train Loss: 3.2689 (Forecasting Loss:0.3646 + XiCon Loss:2.9043 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2505536
	speed: 0.0138s/iter; left time: 275.7487s
	iters: 200, epoch: 14 | loss: 3.2716002
	speed: 0.0117s/iter; left time: 232.2939s
Epoch: 14 cost time: 2.9327197074890137
Epoch: 14, Steps: 230 Train Loss: 3.2691 (Forecasting Loss:0.3640 + XiCon Loss:2.9051 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2754233
	speed: 0.0142s/iter; left time: 279.1130s
	iters: 200, epoch: 15 | loss: 3.2529023
	speed: 0.0122s/iter; left time: 238.9627s
Epoch: 15 cost time: 3.029721975326538
Epoch: 15, Steps: 230 Train Loss: 3.2708 (Forecasting Loss:0.3646 + XiCon Loss:2.9062 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.3574
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2838306
	speed: 0.0136s/iter; left time: 265.4188s
	iters: 200, epoch: 16 | loss: 3.2595148
	speed: 0.0113s/iter; left time: 219.3888s
Epoch: 16 cost time: 2.870983600616455
Epoch: 16, Steps: 230 Train Loss: 3.2691 (Forecasting Loss:0.3646 + XiCon Loss:2.9045 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.3574
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2302897
	speed: 0.0139s/iter; left time: 267.7601s
	iters: 200, epoch: 17 | loss: 3.2611265
	speed: 0.0115s/iter; left time: 219.6264s
Epoch: 17 cost time: 2.9170374870300293
Epoch: 17, Steps: 230 Train Loss: 3.2712 (Forecasting Loss:0.3642 + XiCon Loss:2.9071 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.2485709
	speed: 0.0138s/iter; left time: 261.5707s
	iters: 200, epoch: 18 | loss: 3.3073363
	speed: 0.0117s/iter; left time: 221.1368s
Epoch: 18 cost time: 2.9189412593841553
Epoch: 18, Steps: 230 Train Loss: 3.2697 (Forecasting Loss:0.3640 + XiCon Loss:2.9057 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3574
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2478724
	speed: 0.0143s/iter; left time: 268.7974s
	iters: 200, epoch: 19 | loss: 3.2550054
	speed: 0.0121s/iter; left time: 224.8793s
Epoch: 19 cost time: 3.0398612022399902
Epoch: 19, Steps: 230 Train Loss: 3.2696 (Forecasting Loss:0.3643 + XiCon Loss:2.9053 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2316661
	speed: 0.0140s/iter; left time: 258.7482s
	iters: 200, epoch: 20 | loss: 3.2913680
	speed: 0.0116s/iter; left time: 213.5364s
Epoch: 20 cost time: 2.93011212348938
Epoch: 20, Steps: 230 Train Loss: 3.2710 (Forecasting Loss:0.3644 + XiCon Loss:2.9066 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3574
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.30721423029899597, mae:0.40769466757774353, mape:4.253900527954102, mspe:28146.64453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3153
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.9131885
	speed: 0.0143s/iter; left time: 326.4985s
	iters: 200, epoch: 1 | loss: 3.6900578
	speed: 0.0116s/iter; left time: 265.0231s
Epoch: 1 cost time: 2.974963903427124
Epoch: 1, Steps: 230 Train Loss: 3.8495 (Forecasting Loss:0.7213 + XiCon Loss:3.1282 x Lambda(1.0)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.5350
Validation loss decreased (inf --> 0.328965).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4608009
	speed: 0.0144s/iter; left time: 325.5043s
	iters: 200, epoch: 2 | loss: 3.3246200
	speed: 0.0111s/iter; left time: 249.4520s
Epoch: 2 cost time: 2.9420745372772217
Epoch: 2, Steps: 230 Train Loss: 3.4270 (Forecasting Loss:0.4225 + XiCon Loss:3.0045 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.3627
Validation loss decreased (0.328965 --> 0.212853).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3111098
	speed: 0.0144s/iter; left time: 323.3834s
	iters: 200, epoch: 3 | loss: 3.3161387
	speed: 0.0119s/iter; left time: 265.8413s
Epoch: 3 cost time: 2.9878108501434326
Epoch: 3, Steps: 230 Train Loss: 3.3046 (Forecasting Loss:0.3756 + XiCon Loss:2.9290 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3547
Validation loss decreased (0.212853 --> 0.206603).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3069243
	speed: 0.0143s/iter; left time: 318.5667s
	iters: 200, epoch: 4 | loss: 3.3093171
	speed: 0.0115s/iter; left time: 254.1134s
Epoch: 4 cost time: 2.9875235557556152
Epoch: 4, Steps: 230 Train Loss: 3.2890 (Forecasting Loss:0.3669 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.3499
Validation loss decreased (0.206603 --> 0.205214).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2724311
	speed: 0.0141s/iter; left time: 309.7875s
	iters: 200, epoch: 5 | loss: 3.2516613
	speed: 0.0121s/iter; left time: 264.9724s
Epoch: 5 cost time: 2.9989545345306396
Epoch: 5, Steps: 230 Train Loss: 3.2824 (Forecasting Loss:0.3629 + XiCon Loss:2.9196 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.3480
Validation loss decreased (0.205214 --> 0.204688).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2802398
	speed: 0.0136s/iter; left time: 295.6661s
	iters: 200, epoch: 6 | loss: 3.2663972
	speed: 0.0115s/iter; left time: 248.6894s
Epoch: 6 cost time: 2.875528335571289
Epoch: 6, Steps: 230 Train Loss: 3.2787 (Forecasting Loss:0.3602 + XiCon Loss:2.9185 x Lambda(1.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.3468
Validation loss decreased (0.204688 --> 0.204036).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2983329
	speed: 0.0142s/iter; left time: 306.3982s
	iters: 200, epoch: 7 | loss: 3.2995725
	speed: 0.0118s/iter; left time: 251.9463s
Epoch: 7 cost time: 2.9543654918670654
Epoch: 7, Steps: 230 Train Loss: 3.2773 (Forecasting Loss:0.3595 + XiCon Loss:2.9179 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.3472
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2927744
	speed: 0.0146s/iter; left time: 309.8855s
	iters: 200, epoch: 8 | loss: 3.2726517
	speed: 0.0118s/iter; left time: 250.0167s
Epoch: 8 cost time: 3.011615514755249
Epoch: 8, Steps: 230 Train Loss: 3.2755 (Forecasting Loss:0.3587 + XiCon Loss:2.9167 x Lambda(1.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.3476
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2467775
	speed: 0.0141s/iter; left time: 297.9379s
	iters: 200, epoch: 9 | loss: 3.2462327
	speed: 0.0120s/iter; left time: 251.1787s
Epoch: 9 cost time: 3.0093348026275635
Epoch: 9, Steps: 230 Train Loss: 3.2742 (Forecasting Loss:0.3584 + XiCon Loss:2.9157 x Lambda(1.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.3470
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2273846
	speed: 0.0141s/iter; left time: 293.4551s
	iters: 200, epoch: 10 | loss: 3.2814434
	speed: 0.0120s/iter; left time: 249.2418s
Epoch: 10 cost time: 3.0015223026275635
Epoch: 10, Steps: 230 Train Loss: 3.2732 (Forecasting Loss:0.3585 + XiCon Loss:2.9147 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.3468
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2728193
	speed: 0.0147s/iter; left time: 301.9470s
	iters: 200, epoch: 11 | loss: 3.2957416
	speed: 0.0119s/iter; left time: 243.7148s
Epoch: 11 cost time: 3.041619300842285
Epoch: 11, Steps: 230 Train Loss: 3.2734 (Forecasting Loss:0.3579 + XiCon Loss:2.9155 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.3468
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2790923
	speed: 0.0135s/iter; left time: 275.2543s
	iters: 200, epoch: 12 | loss: 3.2803771
	speed: 0.0121s/iter; left time: 245.4404s
Epoch: 12 cost time: 2.9660141468048096
Epoch: 12, Steps: 230 Train Loss: 3.2737 (Forecasting Loss:0.3583 + XiCon Loss:2.9153 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.3468
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2797399
	speed: 0.0140s/iter; left time: 282.4924s
	iters: 200, epoch: 13 | loss: 3.2882206
	speed: 0.0126s/iter; left time: 253.2426s
Epoch: 13 cost time: 3.058671712875366
Epoch: 13, Steps: 230 Train Loss: 3.2734 (Forecasting Loss:0.3581 + XiCon Loss:2.9153 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.3468
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2757759
	speed: 0.0138s/iter; left time: 274.1790s
	iters: 200, epoch: 14 | loss: 3.2717168
	speed: 0.0116s/iter; left time: 229.2411s
Epoch: 14 cost time: 2.9207398891448975
Epoch: 14, Steps: 230 Train Loss: 3.2749 (Forecasting Loss:0.3583 + XiCon Loss:2.9165 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.3468
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2844832
	speed: 0.0144s/iter; left time: 283.3945s
	iters: 200, epoch: 15 | loss: 3.3030527
	speed: 0.0121s/iter; left time: 237.8067s
Epoch: 15 cost time: 3.0345256328582764
Epoch: 15, Steps: 230 Train Loss: 3.2751 (Forecasting Loss:0.3585 + XiCon Loss:2.9166 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3468
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.3047101
	speed: 0.0149s/iter; left time: 288.9733s
	iters: 200, epoch: 16 | loss: 3.2126038
	speed: 0.0115s/iter; left time: 222.9845s
Epoch: 16 cost time: 2.9971394538879395
Epoch: 16, Steps: 230 Train Loss: 3.2745 (Forecasting Loss:0.3585 + XiCon Loss:2.9160 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.3468
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.2944922149181366, mae:0.39916738867759705, mape:4.022772312164307, mspe:24873.376953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3328
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.8706779
	speed: 0.0141s/iter; left time: 323.7867s
	iters: 200, epoch: 1 | loss: 3.7221301
	speed: 0.0119s/iter; left time: 270.7438s
Epoch: 1 cost time: 2.989769220352173
Epoch: 1, Steps: 230 Train Loss: 3.8330 (Forecasting Loss:0.7257 + XiCon Loss:3.1073 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.5382
Validation loss decreased (inf --> 0.331614).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3909776
	speed: 0.0142s/iter; left time: 322.4373s
	iters: 200, epoch: 2 | loss: 3.3399301
	speed: 0.0113s/iter; left time: 255.3143s
Epoch: 2 cost time: 2.906491994857788
Epoch: 2, Steps: 230 Train Loss: 3.4238 (Forecasting Loss:0.4349 + XiCon Loss:2.9889 x Lambda(1.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.3886
Validation loss decreased (0.331614 --> 0.220663).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2718472
	speed: 0.0141s/iter; left time: 315.9621s
	iters: 200, epoch: 3 | loss: 3.3070114
	speed: 0.0113s/iter; left time: 253.3188s
Epoch: 3 cost time: 2.9153923988342285
Epoch: 3, Steps: 230 Train Loss: 3.3158 (Forecasting Loss:0.3940 + XiCon Loss:2.9218 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.3814
Validation loss decreased (0.220663 --> 0.214958).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3273382
	speed: 0.0140s/iter; left time: 311.0832s
	iters: 200, epoch: 4 | loss: 3.2769284
	speed: 0.0115s/iter; left time: 254.2649s
Epoch: 4 cost time: 2.9258317947387695
Epoch: 4, Steps: 230 Train Loss: 3.2928 (Forecasting Loss:0.3782 + XiCon Loss:2.9147 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3707
Validation loss decreased (0.214958 --> 0.209797).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2768955
	speed: 0.0143s/iter; left time: 313.3346s
	iters: 200, epoch: 5 | loss: 3.3154364
	speed: 0.0119s/iter; left time: 260.9887s
Epoch: 5 cost time: 2.983492136001587
Epoch: 5, Steps: 230 Train Loss: 3.2829 (Forecasting Loss:0.3699 + XiCon Loss:2.9130 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.3702
Validation loss decreased (0.209797 --> 0.209425).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2696600
	speed: 0.0146s/iter; left time: 317.3469s
	iters: 200, epoch: 6 | loss: 3.3090992
	speed: 0.0116s/iter; left time: 251.8381s
Epoch: 6 cost time: 3.0003514289855957
Epoch: 6, Steps: 230 Train Loss: 3.2803 (Forecasting Loss:0.3669 + XiCon Loss:2.9134 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3676
Validation loss decreased (0.209425 --> 0.208603).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2576773
	speed: 0.0138s/iter; left time: 296.3275s
	iters: 200, epoch: 7 | loss: 3.2999396
	speed: 0.0115s/iter; left time: 246.4797s
Epoch: 7 cost time: 2.9005253314971924
Epoch: 7, Steps: 230 Train Loss: 3.2766 (Forecasting Loss:0.3656 + XiCon Loss:2.9109 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3675
Validation loss decreased (0.208603 --> 0.208462).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2825449
	speed: 0.0138s/iter; left time: 293.6925s
	iters: 200, epoch: 8 | loss: 3.2613170
	speed: 0.0113s/iter; left time: 240.3929s
Epoch: 8 cost time: 2.8750669956207275
Epoch: 8, Steps: 230 Train Loss: 3.2757 (Forecasting Loss:0.3651 + XiCon Loss:2.9106 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3679
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3333755
	speed: 0.0139s/iter; left time: 292.9678s
	iters: 200, epoch: 9 | loss: 3.3120332
	speed: 0.0115s/iter; left time: 240.4281s
Epoch: 9 cost time: 2.922987461090088
Epoch: 9, Steps: 230 Train Loss: 3.2748 (Forecasting Loss:0.3649 + XiCon Loss:2.9099 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3681
Validation loss decreased (0.208462 --> 0.208359).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2836635
	speed: 0.0139s/iter; left time: 289.2940s
	iters: 200, epoch: 10 | loss: 3.3076859
	speed: 0.0119s/iter; left time: 247.5124s
Epoch: 10 cost time: 2.9610040187835693
Epoch: 10, Steps: 230 Train Loss: 3.2759 (Forecasting Loss:0.3644 + XiCon Loss:2.9115 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2870545
	speed: 0.0149s/iter; left time: 306.7819s
	iters: 200, epoch: 11 | loss: 3.2591009
	speed: 0.0122s/iter; left time: 250.5608s
Epoch: 11 cost time: 3.0991411209106445
Epoch: 11, Steps: 230 Train Loss: 3.2737 (Forecasting Loss:0.3642 + XiCon Loss:2.9094 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.3107069
	speed: 0.0134s/iter; left time: 273.0760s
	iters: 200, epoch: 12 | loss: 3.2655857
	speed: 0.0115s/iter; left time: 233.3157s
Epoch: 12 cost time: 2.890866279602051
Epoch: 12, Steps: 230 Train Loss: 3.2740 (Forecasting Loss:0.3646 + XiCon Loss:2.9094 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3676
Validation loss decreased (0.208359 --> 0.208324).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2657542
	speed: 0.0142s/iter; left time: 285.5109s
	iters: 200, epoch: 13 | loss: 3.2647052
	speed: 0.0116s/iter; left time: 233.3126s
Epoch: 13 cost time: 2.9546608924865723
Epoch: 13, Steps: 230 Train Loss: 3.2748 (Forecasting Loss:0.3644 + XiCon Loss:2.9104 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3677
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2599320
	speed: 0.0143s/iter; left time: 285.4027s
	iters: 200, epoch: 14 | loss: 3.2575202
	speed: 0.0114s/iter; left time: 226.0421s
Epoch: 14 cost time: 2.9533965587615967
Epoch: 14, Steps: 230 Train Loss: 3.2748 (Forecasting Loss:0.3644 + XiCon Loss:2.9103 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3677
Validation loss decreased (0.208324 --> 0.208201).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2752039
	speed: 0.0142s/iter; left time: 280.0698s
	iters: 200, epoch: 15 | loss: 3.2569423
	speed: 0.0113s/iter; left time: 220.4585s
Epoch: 15 cost time: 2.923402786254883
Epoch: 15, Steps: 230 Train Loss: 3.2749 (Forecasting Loss:0.3639 + XiCon Loss:2.9110 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3677
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2190921
	speed: 0.0143s/iter; left time: 278.6541s
	iters: 200, epoch: 16 | loss: 3.2289147
	speed: 0.0119s/iter; left time: 230.1248s
Epoch: 16 cost time: 3.0104503631591797
Epoch: 16, Steps: 230 Train Loss: 3.2744 (Forecasting Loss:0.3645 + XiCon Loss:2.9098 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2566006
	speed: 0.0140s/iter; left time: 269.3605s
	iters: 200, epoch: 17 | loss: 3.2618065
	speed: 0.0117s/iter; left time: 224.6059s
Epoch: 17 cost time: 2.948389768600464
Epoch: 17, Steps: 230 Train Loss: 3.2735 (Forecasting Loss:0.3644 + XiCon Loss:2.9091 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.2361815
	speed: 0.0137s/iter; left time: 260.5267s
	iters: 200, epoch: 18 | loss: 3.2559228
	speed: 0.0110s/iter; left time: 206.9379s
Epoch: 18 cost time: 2.8323874473571777
Epoch: 18, Steps: 230 Train Loss: 3.2757 (Forecasting Loss:0.3634 + XiCon Loss:2.9123 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3677
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2466543
	speed: 0.0140s/iter; left time: 263.3322s
	iters: 200, epoch: 19 | loss: 3.3218789
	speed: 0.0127s/iter; left time: 237.7311s
Epoch: 19 cost time: 3.084711790084839
Epoch: 19, Steps: 230 Train Loss: 3.2745 (Forecasting Loss:0.3640 + XiCon Loss:2.9105 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3677
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2716146
	speed: 0.0138s/iter; left time: 256.6297s
	iters: 200, epoch: 20 | loss: 3.2865319
	speed: 0.0115s/iter; left time: 211.4557s
Epoch: 20 cost time: 2.9169368743896484
Epoch: 20, Steps: 230 Train Loss: 3.2737 (Forecasting Loss:0.3644 + XiCon Loss:2.9093 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.2719970
	speed: 0.0141s/iter; left time: 258.8221s
	iters: 200, epoch: 21 | loss: 3.2856936
	speed: 0.0121s/iter; left time: 220.6253s
Epoch: 21 cost time: 3.020625114440918
Epoch: 21, Steps: 230 Train Loss: 3.2733 (Forecasting Loss:0.3641 + XiCon Loss:2.9092 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3677
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.2768195
	speed: 0.0134s/iter; left time: 241.6033s
	iters: 200, epoch: 22 | loss: 3.2513115
	speed: 0.0120s/iter; left time: 214.8525s
Epoch: 22 cost time: 2.924192428588867
Epoch: 22, Steps: 230 Train Loss: 3.2755 (Forecasting Loss:0.3640 + XiCon Loss:2.9115 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.2775307
	speed: 0.0143s/iter; left time: 255.2338s
	iters: 200, epoch: 23 | loss: 3.2715008
	speed: 0.0112s/iter; left time: 197.8923s
Epoch: 23 cost time: 2.917072296142578
Epoch: 23, Steps: 230 Train Loss: 3.2740 (Forecasting Loss:0.3641 + XiCon Loss:2.9098 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3677
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.3051653
	speed: 0.0138s/iter; left time: 243.7717s
	iters: 200, epoch: 24 | loss: 3.2873712
	speed: 0.0114s/iter; left time: 200.0258s
Epoch: 24 cost time: 2.907119035720825
Epoch: 24, Steps: 230 Train Loss: 3.2757 (Forecasting Loss:0.3643 + XiCon Loss:2.9113 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3677
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3194597661495209, mae:0.4159073829650879, mape:3.827709913253784, mspe:19971.4765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3965
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.8151994
	speed: 0.0151s/iter; left time: 346.1438s
	iters: 200, epoch: 1 | loss: 3.6886740
	speed: 0.0118s/iter; left time: 269.0980s
Epoch: 1 cost time: 3.0506343841552734
Epoch: 1, Steps: 230 Train Loss: 3.8286 (Forecasting Loss:0.7225 + XiCon Loss:3.1061 x Lambda(1.0)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.5303
Validation loss decreased (inf --> 0.329732).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4114504
	speed: 0.0142s/iter; left time: 321.7385s
	iters: 200, epoch: 2 | loss: 3.3335173
	speed: 0.0115s/iter; left time: 258.6424s
Epoch: 2 cost time: 2.940542221069336
Epoch: 2, Steps: 230 Train Loss: 3.4357 (Forecasting Loss:0.4282 + XiCon Loss:3.0076 x Lambda(1.0)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.3630
Validation loss decreased (0.329732 --> 0.215909).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2621591
	speed: 0.0142s/iter; left time: 318.0018s
	iters: 200, epoch: 3 | loss: 3.3477416
	speed: 0.0115s/iter; left time: 256.7776s
Epoch: 3 cost time: 2.9441215991973877
Epoch: 3, Steps: 230 Train Loss: 3.3068 (Forecasting Loss:0.3857 + XiCon Loss:2.9211 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.3624
Validation loss decreased (0.215909 --> 0.213380).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3950534
	speed: 0.0139s/iter; left time: 308.0342s
	iters: 200, epoch: 4 | loss: 3.3740158
	speed: 0.0115s/iter; left time: 255.3302s
Epoch: 4 cost time: 2.914783477783203
Epoch: 4, Steps: 230 Train Loss: 3.3492 (Forecasting Loss:0.3783 + XiCon Loss:2.9709 x Lambda(1.0)), Vali MSE Loss: 0.2054 Test MSE Loss: 0.3432
Validation loss decreased (0.213380 --> 0.205385).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2878866
	speed: 0.0141s/iter; left time: 309.9868s
	iters: 200, epoch: 5 | loss: 3.3201542
	speed: 0.0118s/iter; left time: 257.9013s
Epoch: 5 cost time: 2.9696671962738037
Epoch: 5, Steps: 230 Train Loss: 3.3362 (Forecasting Loss:0.3691 + XiCon Loss:2.9672 x Lambda(1.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.3404
Validation loss decreased (0.205385 --> 0.203169).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2988122
	speed: 0.0141s/iter; left time: 306.5261s
	iters: 200, epoch: 6 | loss: 3.3081560
	speed: 0.0116s/iter; left time: 251.6580s
Epoch: 6 cost time: 2.9464447498321533
Epoch: 6, Steps: 230 Train Loss: 3.3300 (Forecasting Loss:0.3671 + XiCon Loss:2.9629 x Lambda(1.0)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.3395
Validation loss decreased (0.203169 --> 0.201570).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.3666918
	speed: 0.0141s/iter; left time: 302.4853s
	iters: 200, epoch: 7 | loss: 3.3035896
	speed: 0.0118s/iter; left time: 253.0696s
Epoch: 7 cost time: 2.9643280506134033
Epoch: 7, Steps: 230 Train Loss: 3.3277 (Forecasting Loss:0.3657 + XiCon Loss:2.9620 x Lambda(1.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.3398
Validation loss decreased (0.201570 --> 0.201145).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3442874
	speed: 0.0137s/iter; left time: 292.6230s
	iters: 200, epoch: 8 | loss: 3.3123832
	speed: 0.0115s/iter; left time: 244.6685s
Epoch: 8 cost time: 2.9062888622283936
Epoch: 8, Steps: 230 Train Loss: 3.3254 (Forecasting Loss:0.3653 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.3393
Validation loss decreased (0.201145 --> 0.201134).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2848921
	speed: 0.0144s/iter; left time: 303.2856s
	iters: 200, epoch: 9 | loss: 3.3634009
	speed: 0.0116s/iter; left time: 244.0113s
Epoch: 9 cost time: 2.9865870475769043
Epoch: 9, Steps: 230 Train Loss: 3.3289 (Forecasting Loss:0.3650 + XiCon Loss:2.9639 x Lambda(1.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.3393
Validation loss decreased (0.201134 --> 0.201103).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.3483543
	speed: 0.0138s/iter; left time: 288.0918s
	iters: 200, epoch: 10 | loss: 3.2669277
	speed: 0.0115s/iter; left time: 237.5228s
Epoch: 10 cost time: 2.9007937908172607
Epoch: 10, Steps: 230 Train Loss: 3.3278 (Forecasting Loss:0.3650 + XiCon Loss:2.9629 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3393
Validation loss decreased (0.201103 --> 0.200936).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2847185
	speed: 0.0152s/iter; left time: 312.6129s
	iters: 200, epoch: 11 | loss: 3.3591614
	speed: 0.0115s/iter; left time: 235.8578s
Epoch: 11 cost time: 3.0194363594055176
Epoch: 11, Steps: 230 Train Loss: 3.3243 (Forecasting Loss:0.3651 + XiCon Loss:2.9593 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
Validation loss decreased (0.200936 --> 0.200922).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2895653
	speed: 0.0140s/iter; left time: 285.4966s
	iters: 200, epoch: 12 | loss: 3.3451858
	speed: 0.0113s/iter; left time: 230.0630s
Epoch: 12 cost time: 2.9042623043060303
Epoch: 12, Steps: 230 Train Loss: 3.3233 (Forecasting Loss:0.3647 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
Validation loss decreased (0.200922 --> 0.200886).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2879190
	speed: 0.0139s/iter; left time: 279.2620s
	iters: 200, epoch: 13 | loss: 3.3561883
	speed: 0.0116s/iter; left time: 232.9445s
Epoch: 13 cost time: 2.935171127319336
Epoch: 13, Steps: 230 Train Loss: 3.3260 (Forecasting Loss:0.3649 + XiCon Loss:2.9611 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.3392
Validation loss decreased (0.200886 --> 0.200819).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.3058174
	speed: 0.0141s/iter; left time: 280.5939s
	iters: 200, epoch: 14 | loss: 3.3274105
	speed: 0.0117s/iter; left time: 231.1387s
Epoch: 14 cost time: 2.9513301849365234
Epoch: 14, Steps: 230 Train Loss: 3.3252 (Forecasting Loss:0.3647 + XiCon Loss:2.9605 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.3392
Validation loss decreased (0.200819 --> 0.200491).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2725270
	speed: 0.0142s/iter; left time: 279.2037s
	iters: 200, epoch: 15 | loss: 3.3206151
	speed: 0.0118s/iter; left time: 230.5302s
Epoch: 15 cost time: 2.9720401763916016
Epoch: 15, Steps: 230 Train Loss: 3.3242 (Forecasting Loss:0.3648 + XiCon Loss:2.9594 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2655060
	speed: 0.0142s/iter; left time: 276.7925s
	iters: 200, epoch: 16 | loss: 3.3038378
	speed: 0.0121s/iter; left time: 235.1059s
Epoch: 16 cost time: 3.025203227996826
Epoch: 16, Steps: 230 Train Loss: 3.3238 (Forecasting Loss:0.3648 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.3392
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.3261867
	speed: 0.0141s/iter; left time: 271.3091s
	iters: 200, epoch: 17 | loss: 3.2493474
	speed: 0.0114s/iter; left time: 217.5480s
Epoch: 17 cost time: 2.9268171787261963
Epoch: 17, Steps: 230 Train Loss: 3.3261 (Forecasting Loss:0.3649 + XiCon Loss:2.9611 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.3392
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.3037393
	speed: 0.0143s/iter; left time: 271.2198s
	iters: 200, epoch: 18 | loss: 3.2974741
	speed: 0.0120s/iter; left time: 225.9529s
Epoch: 18 cost time: 3.019408941268921
Epoch: 18, Steps: 230 Train Loss: 3.3235 (Forecasting Loss:0.3647 + XiCon Loss:2.9588 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.3355441
	speed: 0.0149s/iter; left time: 278.7487s
	iters: 200, epoch: 19 | loss: 3.2843072
	speed: 0.0119s/iter; left time: 222.7210s
Epoch: 19 cost time: 3.040867567062378
Epoch: 19, Steps: 230 Train Loss: 3.3248 (Forecasting Loss:0.3648 + XiCon Loss:2.9600 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2824793
	speed: 0.0135s/iter; left time: 249.5357s
	iters: 200, epoch: 20 | loss: 3.3772488
	speed: 0.0113s/iter; left time: 207.8319s
Epoch: 20 cost time: 2.839118719100952
Epoch: 20, Steps: 230 Train Loss: 3.3267 (Forecasting Loss:0.3647 + XiCon Loss:2.9620 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.3245790
	speed: 0.0136s/iter; left time: 249.2683s
	iters: 200, epoch: 21 | loss: 3.3596072
	speed: 0.0120s/iter; left time: 218.1206s
Epoch: 21 cost time: 2.9287984371185303
Epoch: 21, Steps: 230 Train Loss: 3.3255 (Forecasting Loss:0.3649 + XiCon Loss:2.9606 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.3392
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.3143485
	speed: 0.0144s/iter; left time: 259.6764s
	iters: 200, epoch: 22 | loss: 3.3142474
	speed: 0.0121s/iter; left time: 217.4668s
Epoch: 22 cost time: 3.0214669704437256
Epoch: 22, Steps: 230 Train Loss: 3.3249 (Forecasting Loss:0.3649 + XiCon Loss:2.9600 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.3392
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.3108304
	speed: 0.0141s/iter; left time: 252.4005s
	iters: 200, epoch: 23 | loss: 3.3327167
	speed: 0.0119s/iter; left time: 210.3546s
Epoch: 23 cost time: 3.00130295753479
Epoch: 23, Steps: 230 Train Loss: 3.3252 (Forecasting Loss:0.3648 + XiCon Loss:2.9603 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3392
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.2834609
	speed: 0.0141s/iter; left time: 247.6827s
	iters: 200, epoch: 24 | loss: 3.3279071
	speed: 0.0110s/iter; left time: 192.1953s
Epoch: 24 cost time: 2.8814375400543213
Epoch: 24, Steps: 230 Train Loss: 3.3264 (Forecasting Loss:0.3648 + XiCon Loss:2.9615 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.3392
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.28592443466186523, mae:0.39248284697532654, mape:3.766491413116455, mspe:18894.201171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4539
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.7774429
	speed: 0.0143s/iter; left time: 328.0505s
	iters: 200, epoch: 1 | loss: 3.7417014
	speed: 0.0120s/iter; left time: 272.4902s
Epoch: 1 cost time: 3.0187461376190186
Epoch: 1, Steps: 230 Train Loss: 3.8282 (Forecasting Loss:0.7221 + XiCon Loss:3.1061 x Lambda(1.0)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.5328
Validation loss decreased (inf --> 0.331813).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4531727
	speed: 0.0141s/iter; left time: 320.5302s
	iters: 200, epoch: 2 | loss: 3.4002495
	speed: 0.0118s/iter; left time: 266.4711s
Epoch: 2 cost time: 2.9768311977386475
Epoch: 2, Steps: 230 Train Loss: 3.4353 (Forecasting Loss:0.4325 + XiCon Loss:3.0028 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.3576
Validation loss decreased (0.331813 --> 0.215036).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3556156
	speed: 0.0146s/iter; left time: 327.3541s
	iters: 200, epoch: 3 | loss: 3.2254794
	speed: 0.0115s/iter; left time: 257.3799s
Epoch: 3 cost time: 2.982109308242798
Epoch: 3, Steps: 230 Train Loss: 3.2980 (Forecasting Loss:0.3758 + XiCon Loss:2.9221 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3567
Validation loss decreased (0.215036 --> 0.208722).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3558245
	speed: 0.0144s/iter; left time: 320.4655s
	iters: 200, epoch: 4 | loss: 3.2802916
	speed: 0.0112s/iter; left time: 246.6735s
Epoch: 4 cost time: 2.952110528945923
Epoch: 4, Steps: 230 Train Loss: 3.2877 (Forecasting Loss:0.3702 + XiCon Loss:2.9175 x Lambda(1.0)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.3538
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3261764
	speed: 0.0146s/iter; left time: 321.8117s
	iters: 200, epoch: 5 | loss: 3.2768011
	speed: 0.0122s/iter; left time: 267.6201s
Epoch: 5 cost time: 3.071580410003662
Epoch: 5, Steps: 230 Train Loss: 3.3183 (Forecasting Loss:0.3688 + XiCon Loss:2.9495 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3488
Validation loss decreased (0.208722 --> 0.207510).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2970624
	speed: 0.0145s/iter; left time: 315.7209s
	iters: 200, epoch: 6 | loss: 3.3932896
	speed: 0.0118s/iter; left time: 255.6515s
Epoch: 6 cost time: 2.9837124347686768
Epoch: 6, Steps: 230 Train Loss: 3.3158 (Forecasting Loss:0.3671 + XiCon Loss:2.9487 x Lambda(1.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.3517
Validation loss decreased (0.207510 --> 0.207001).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.3261220
	speed: 0.0146s/iter; left time: 313.1890s
	iters: 200, epoch: 7 | loss: 3.3554759
	speed: 0.0114s/iter; left time: 244.4368s
Epoch: 7 cost time: 2.9582438468933105
Epoch: 7, Steps: 230 Train Loss: 3.3198 (Forecasting Loss:0.3639 + XiCon Loss:2.9560 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3520
Validation loss decreased (0.207001 --> 0.206787).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3139973
	speed: 0.0146s/iter; left time: 310.4364s
	iters: 200, epoch: 8 | loss: 3.3914030
	speed: 0.0116s/iter; left time: 245.9726s
Epoch: 8 cost time: 2.989377021789551
Epoch: 8, Steps: 230 Train Loss: 3.3188 (Forecasting Loss:0.3633 + XiCon Loss:2.9556 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.3552
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3893785
	speed: 0.0142s/iter; left time: 299.7931s
	iters: 200, epoch: 9 | loss: 3.2902081
	speed: 0.0117s/iter; left time: 246.1033s
Epoch: 9 cost time: 2.9603209495544434
Epoch: 9, Steps: 230 Train Loss: 3.3147 (Forecasting Loss:0.3624 + XiCon Loss:2.9523 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3555
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2933934
	speed: 0.0145s/iter; left time: 302.2195s
	iters: 200, epoch: 10 | loss: 3.3303435
	speed: 0.0119s/iter; left time: 247.6003s
Epoch: 10 cost time: 3.0261693000793457
Epoch: 10, Steps: 230 Train Loss: 3.3164 (Forecasting Loss:0.3621 + XiCon Loss:2.9544 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.3551
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.3374243
	speed: 0.0141s/iter; left time: 291.3218s
	iters: 200, epoch: 11 | loss: 3.2961612
	speed: 0.0115s/iter; left time: 235.1052s
Epoch: 11 cost time: 2.970828056335449
Epoch: 11, Steps: 230 Train Loss: 3.3154 (Forecasting Loss:0.3621 + XiCon Loss:2.9533 x Lambda(1.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.3556
Validation loss decreased (0.206787 --> 0.206521).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.3261452
	speed: 0.0146s/iter; left time: 298.1663s
	iters: 200, epoch: 12 | loss: 3.3747349
	speed: 0.0114s/iter; left time: 230.4228s
Epoch: 12 cost time: 2.982280969619751
Epoch: 12, Steps: 230 Train Loss: 3.3182 (Forecasting Loss:0.3621 + XiCon Loss:2.9561 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.3153524
	speed: 0.0145s/iter; left time: 291.0729s
	iters: 200, epoch: 13 | loss: 3.2437391
	speed: 0.0121s/iter; left time: 242.3549s
Epoch: 13 cost time: 3.031872272491455
Epoch: 13, Steps: 230 Train Loss: 3.3154 (Forecasting Loss:0.3613 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.3498566
	speed: 0.0141s/iter; left time: 280.7239s
	iters: 200, epoch: 14 | loss: 3.3756840
	speed: 0.0112s/iter; left time: 221.2931s
Epoch: 14 cost time: 2.893841028213501
Epoch: 14, Steps: 230 Train Loss: 3.3155 (Forecasting Loss:0.3614 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2950525
	speed: 0.0139s/iter; left time: 273.5039s
	iters: 200, epoch: 15 | loss: 3.2740548
	speed: 0.0121s/iter; left time: 236.0756s
Epoch: 15 cost time: 2.9938035011291504
Epoch: 15, Steps: 230 Train Loss: 3.3178 (Forecasting Loss:0.3619 + XiCon Loss:2.9559 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.3641896
	speed: 0.0150s/iter; left time: 291.6869s
	iters: 200, epoch: 16 | loss: 3.3570280
	speed: 0.0123s/iter; left time: 238.4165s
Epoch: 16 cost time: 3.1209022998809814
Epoch: 16, Steps: 230 Train Loss: 3.3138 (Forecasting Loss:0.3619 + XiCon Loss:2.9519 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.3477817
	speed: 0.0146s/iter; left time: 280.4533s
	iters: 200, epoch: 17 | loss: 3.3329871
	speed: 0.0120s/iter; left time: 230.0402s
Epoch: 17 cost time: 3.044402837753296
Epoch: 17, Steps: 230 Train Loss: 3.3176 (Forecasting Loss:0.3616 + XiCon Loss:2.9560 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.3556
Validation loss decreased (0.206521 --> 0.206438).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.3533134
	speed: 0.0142s/iter; left time: 269.4996s
	iters: 200, epoch: 18 | loss: 3.2998919
	speed: 0.0115s/iter; left time: 217.5794s
Epoch: 18 cost time: 2.931441307067871
Epoch: 18, Steps: 230 Train Loss: 3.3163 (Forecasting Loss:0.3617 + XiCon Loss:2.9545 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2652440
	speed: 0.0150s/iter; left time: 282.1275s
	iters: 200, epoch: 19 | loss: 3.3402462
	speed: 0.0114s/iter; left time: 213.2573s
Epoch: 19 cost time: 3.0153427124023438
Epoch: 19, Steps: 230 Train Loss: 3.3135 (Forecasting Loss:0.3617 + XiCon Loss:2.9518 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2707412
	speed: 0.0146s/iter; left time: 271.0200s
	iters: 200, epoch: 20 | loss: 3.2772655
	speed: 0.0126s/iter; left time: 231.9570s
Epoch: 20 cost time: 3.132546901702881
Epoch: 20, Steps: 230 Train Loss: 3.3139 (Forecasting Loss:0.3616 + XiCon Loss:2.9523 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.2668481
	speed: 0.0145s/iter; left time: 264.9828s
	iters: 200, epoch: 21 | loss: 3.2960696
	speed: 0.0117s/iter; left time: 213.2781s
Epoch: 21 cost time: 2.9986047744750977
Epoch: 21, Steps: 230 Train Loss: 3.3152 (Forecasting Loss:0.3618 + XiCon Loss:2.9534 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.2931519
	speed: 0.0137s/iter; left time: 246.8655s
	iters: 200, epoch: 22 | loss: 3.3285334
	speed: 0.0115s/iter; left time: 207.0373s
Epoch: 22 cost time: 2.900869369506836
Epoch: 22, Steps: 230 Train Loss: 3.3149 (Forecasting Loss:0.3620 + XiCon Loss:2.9530 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.2742343
	speed: 0.0140s/iter; left time: 249.4077s
	iters: 200, epoch: 23 | loss: 3.3530078
	speed: 0.0118s/iter; left time: 209.3246s
Epoch: 23 cost time: 2.959648609161377
Epoch: 23, Steps: 230 Train Loss: 3.3187 (Forecasting Loss:0.3618 + XiCon Loss:2.9569 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.2843742
	speed: 0.0139s/iter; left time: 245.6310s
	iters: 200, epoch: 24 | loss: 3.3720562
	speed: 0.0118s/iter; left time: 207.0790s
Epoch: 24 cost time: 2.960334062576294
Epoch: 24, Steps: 230 Train Loss: 3.3151 (Forecasting Loss:0.3619 + XiCon Loss:2.9531 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.2921124
	speed: 0.0139s/iter; left time: 241.2836s
	iters: 200, epoch: 25 | loss: 3.3316619
	speed: 0.0118s/iter; left time: 204.3229s
Epoch: 25 cost time: 2.960528612136841
Epoch: 25, Steps: 230 Train Loss: 3.3155 (Forecasting Loss:0.3619 + XiCon Loss:2.9536 x Lambda(1.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.3556
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.3541298
	speed: 0.0140s/iter; left time: 240.3799s
	iters: 200, epoch: 26 | loss: 3.2763121
	speed: 0.0117s/iter; left time: 199.8060s
Epoch: 26 cost time: 2.9407007694244385
Epoch: 26, Steps: 230 Train Loss: 3.3161 (Forecasting Loss:0.3620 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.3556
Validation loss decreased (0.206438 --> 0.206306).  Saving model ...
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 3.2905881
	speed: 0.0145s/iter; left time: 245.3834s
	iters: 200, epoch: 27 | loss: 3.2946126
	speed: 0.0114s/iter; left time: 192.0681s
Epoch: 27 cost time: 2.9908299446105957
Epoch: 27, Steps: 230 Train Loss: 3.3147 (Forecasting Loss:0.3615 + XiCon Loss:2.9532 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 3.3106246
	speed: 0.0142s/iter; left time: 237.4956s
	iters: 200, epoch: 28 | loss: 3.2875242
	speed: 0.0117s/iter; left time: 193.5278s
Epoch: 28 cost time: 2.980526924133301
Epoch: 28, Steps: 230 Train Loss: 3.3163 (Forecasting Loss:0.3622 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 3.2642140
	speed: 0.0144s/iter; left time: 236.9346s
	iters: 200, epoch: 29 | loss: 3.4001689
	speed: 0.0118s/iter; left time: 192.2699s
Epoch: 29 cost time: 3.0150325298309326
Epoch: 29, Steps: 230 Train Loss: 3.3171 (Forecasting Loss:0.3620 + XiCon Loss:2.9551 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 3.3830371
	speed: 0.0140s/iter; left time: 227.0476s
	iters: 200, epoch: 30 | loss: 3.3100944
	speed: 0.0123s/iter; left time: 197.7370s
Epoch: 30 cost time: 2.9953975677490234
Epoch: 30, Steps: 230 Train Loss: 3.3151 (Forecasting Loss:0.3618 + XiCon Loss:2.9533 x Lambda(1.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.3556
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 3.2470195
	speed: 0.0138s/iter; left time: 220.5364s
	iters: 200, epoch: 31 | loss: 3.3070507
	speed: 0.0115s/iter; left time: 182.9084s
Epoch: 31 cost time: 2.9067516326904297
Epoch: 31, Steps: 230 Train Loss: 3.3197 (Forecasting Loss:0.3620 + XiCon Loss:2.9577 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 3.2530961
	speed: 0.0144s/iter; left time: 227.2081s
	iters: 200, epoch: 32 | loss: 3.3158195
	speed: 0.0119s/iter; left time: 186.3257s
Epoch: 32 cost time: 3.025693655014038
Epoch: 32, Steps: 230 Train Loss: 3.3137 (Forecasting Loss:0.3614 + XiCon Loss:2.9523 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 3.2922704
	speed: 0.0143s/iter; left time: 221.8865s
	iters: 200, epoch: 33 | loss: 3.2874784
	speed: 0.0114s/iter; left time: 176.4602s
Epoch: 33 cost time: 2.942664384841919
Epoch: 33, Steps: 230 Train Loss: 3.3170 (Forecasting Loss:0.3617 + XiCon Loss:2.9552 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.3556
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 3.2866573
	speed: 0.0134s/iter; left time: 205.4980s
	iters: 200, epoch: 34 | loss: 3.3524175
	speed: 0.0116s/iter; left time: 176.5932s
Epoch: 34 cost time: 2.8818652629852295
Epoch: 34, Steps: 230 Train Loss: 3.3166 (Forecasting Loss:0.3621 + XiCon Loss:2.9545 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.3556
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 3.3306956
	speed: 0.0152s/iter; left time: 229.2570s
	iters: 200, epoch: 35 | loss: 3.2844193
	speed: 0.0124s/iter; left time: 185.8413s
Epoch: 35 cost time: 3.139469623565674
Epoch: 35, Steps: 230 Train Loss: 3.3190 (Forecasting Loss:0.3615 + XiCon Loss:2.9575 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.3556
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 3.3134518
	speed: 0.0140s/iter; left time: 208.2066s
	iters: 200, epoch: 36 | loss: 3.2919571
	speed: 0.0118s/iter; left time: 173.7123s
Epoch: 36 cost time: 2.95438551902771
Epoch: 36, Steps: 230 Train Loss: 3.3178 (Forecasting Loss:0.3620 + XiCon Loss:2.9559 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.3556
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.30295267701148987, mae:0.4082954227924347, mape:3.916666030883789, mspe:20553.078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3020+-0.01580, MAE:0.4047+-0.01123, MAPE:3.9575+-0.23812, MSPE:22487.7559+-4837.01366, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4286
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.8827038
	speed: 0.0229s/iter; left time: 495.9284s
	iters: 200, epoch: 1 | loss: 3.9000180
	speed: 0.0181s/iter; left time: 389.9296s
Epoch: 1 cost time: 4.448005199432373
Epoch: 1, Steps: 218 Train Loss: 3.9562 (Forecasting Loss:0.8373 + XiCon Loss:3.1188 x Lambda(1.0)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.6850
Validation loss decreased (inf --> 0.336297).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4640222
	speed: 0.0207s/iter; left time: 444.3746s
	iters: 200, epoch: 2 | loss: 3.4050329
	speed: 0.0180s/iter; left time: 384.4639s
Epoch: 2 cost time: 4.234864234924316
Epoch: 2, Steps: 218 Train Loss: 3.4831 (Forecasting Loss:0.4983 + XiCon Loss:2.9848 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.4259
Validation loss decreased (0.336297 --> 0.214984).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3208528
	speed: 0.0202s/iter; left time: 429.2947s
	iters: 200, epoch: 3 | loss: 3.2948728
	speed: 0.0177s/iter; left time: 375.3062s
Epoch: 3 cost time: 4.144515037536621
Epoch: 3, Steps: 218 Train Loss: 3.3458 (Forecasting Loss:0.4226 + XiCon Loss:2.9233 x Lambda(1.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.4349
Validation loss decreased (0.214984 --> 0.214940).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3320866
	speed: 0.0201s/iter; left time: 422.2638s
	iters: 200, epoch: 4 | loss: 3.2708297
	speed: 0.0182s/iter; left time: 381.2034s
Epoch: 4 cost time: 4.172856569290161
Epoch: 4, Steps: 218 Train Loss: 3.2947 (Forecasting Loss:0.3992 + XiCon Loss:2.8955 x Lambda(1.0)), Vali MSE Loss: 0.2373 Test MSE Loss: 0.4096
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3072343
	speed: 0.0203s/iter; left time: 423.5390s
	iters: 200, epoch: 5 | loss: 3.2383990
	speed: 0.0181s/iter; left time: 374.2198s
Epoch: 5 cost time: 4.187877655029297
Epoch: 5, Steps: 218 Train Loss: 3.2488 (Forecasting Loss:0.3902 + XiCon Loss:2.8586 x Lambda(1.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.4002
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2204878
	speed: 0.0201s/iter; left time: 413.3578s
	iters: 200, epoch: 6 | loss: 3.2331588
	speed: 0.0176s/iter; left time: 361.6255s
Epoch: 6 cost time: 4.1170735359191895
Epoch: 6, Steps: 218 Train Loss: 3.2231 (Forecasting Loss:0.3856 + XiCon Loss:2.8375 x Lambda(1.0)), Vali MSE Loss: 0.2378 Test MSE Loss: 0.4055
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1976018
	speed: 0.0201s/iter; left time: 410.8369s
	iters: 200, epoch: 7 | loss: 3.1957316
	speed: 0.0175s/iter; left time: 355.4342s
Epoch: 7 cost time: 4.118040561676025
Epoch: 7, Steps: 218 Train Loss: 3.2137 (Forecasting Loss:0.3845 + XiCon Loss:2.8292 x Lambda(1.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.3996
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1976881
	speed: 0.0200s/iter; left time: 403.3255s
	iters: 200, epoch: 8 | loss: 3.1995258
	speed: 0.0182s/iter; left time: 365.7106s
Epoch: 8 cost time: 4.181175470352173
Epoch: 8, Steps: 218 Train Loss: 3.2125 (Forecasting Loss:0.3842 + XiCon Loss:2.8283 x Lambda(1.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.4065
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1897783
	speed: 0.0198s/iter; left time: 394.7737s
	iters: 200, epoch: 9 | loss: 3.1864562
	speed: 0.0179s/iter; left time: 354.4696s
Epoch: 9 cost time: 4.129594087600708
Epoch: 9, Steps: 218 Train Loss: 3.2155 (Forecasting Loss:0.3844 + XiCon Loss:2.8311 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.4023
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2228913
	speed: 0.0202s/iter; left time: 399.1561s
	iters: 200, epoch: 10 | loss: 3.2654514
	speed: 0.0179s/iter; left time: 351.8916s
Epoch: 10 cost time: 4.173557758331299
Epoch: 10, Steps: 218 Train Loss: 3.2160 (Forecasting Loss:0.3847 + XiCon Loss:2.8313 x Lambda(1.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.4041
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2237020
	speed: 0.0201s/iter; left time: 393.2504s
	iters: 200, epoch: 11 | loss: 3.2496924
	speed: 0.0179s/iter; left time: 347.3281s
Epoch: 11 cost time: 4.176174640655518
Epoch: 11, Steps: 218 Train Loss: 3.2182 (Forecasting Loss:0.3841 + XiCon Loss:2.8340 x Lambda(1.0)), Vali MSE Loss: 0.2383 Test MSE Loss: 0.4046
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2314103
	speed: 0.0200s/iter; left time: 385.7056s
	iters: 200, epoch: 12 | loss: 3.1774750
	speed: 0.0182s/iter; left time: 350.0767s
Epoch: 12 cost time: 4.17491340637207
Epoch: 12, Steps: 218 Train Loss: 3.2161 (Forecasting Loss:0.3846 + XiCon Loss:2.8315 x Lambda(1.0)), Vali MSE Loss: 0.2382 Test MSE Loss: 0.4048
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2286475
	speed: 0.0202s/iter; left time: 385.6775s
	iters: 200, epoch: 13 | loss: 3.2072182
	speed: 0.0181s/iter; left time: 343.3918s
Epoch: 13 cost time: 4.216673374176025
Epoch: 13, Steps: 218 Train Loss: 3.2158 (Forecasting Loss:0.3840 + XiCon Loss:2.8318 x Lambda(1.0)), Vali MSE Loss: 0.2384 Test MSE Loss: 0.4048
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3899572193622589, mae:0.4797455668449402, mape:6.020240783691406, mspe:96068.2265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4292
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.9594169
	speed: 0.0206s/iter; left time: 447.9750s
	iters: 200, epoch: 1 | loss: 3.7829947
	speed: 0.0179s/iter; left time: 387.5918s
Epoch: 1 cost time: 4.198660850524902
Epoch: 1, Steps: 218 Train Loss: 3.9329 (Forecasting Loss:0.8368 + XiCon Loss:3.0960 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.6599
Validation loss decreased (inf --> 0.332868).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4007607
	speed: 0.0204s/iter; left time: 438.1284s
	iters: 200, epoch: 2 | loss: 3.4144764
	speed: 0.0180s/iter; left time: 383.9426s
Epoch: 2 cost time: 4.1838836669921875
Epoch: 2, Steps: 218 Train Loss: 3.4735 (Forecasting Loss:0.4742 + XiCon Loss:2.9993 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.5039
Validation loss decreased (0.332868 --> 0.244909).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3923006
	speed: 0.0202s/iter; left time: 430.5342s
	iters: 200, epoch: 3 | loss: 3.4145117
	speed: 0.0175s/iter; left time: 369.8567s
Epoch: 3 cost time: 4.127648115158081
Epoch: 3, Steps: 218 Train Loss: 3.4319 (Forecasting Loss:0.4108 + XiCon Loss:3.0211 x Lambda(1.0)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.4029
Validation loss decreased (0.244909 --> 0.227982).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3780439
	speed: 0.0203s/iter; left time: 427.7674s
	iters: 200, epoch: 4 | loss: 3.4337258
	speed: 0.0177s/iter; left time: 370.0308s
Epoch: 4 cost time: 4.145668983459473
Epoch: 4, Steps: 218 Train Loss: 3.4385 (Forecasting Loss:0.3944 + XiCon Loss:3.0441 x Lambda(1.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.4075
Validation loss decreased (0.227982 --> 0.223281).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.4996858
	speed: 0.0206s/iter; left time: 429.6369s
	iters: 200, epoch: 5 | loss: 3.4949088
	speed: 0.0178s/iter; left time: 369.1409s
Epoch: 5 cost time: 4.200275182723999
Epoch: 5, Steps: 218 Train Loss: 3.4337 (Forecasting Loss:0.3835 + XiCon Loss:3.0502 x Lambda(1.0)), Vali MSE Loss: 0.2228 Test MSE Loss: 0.4051
Validation loss decreased (0.223281 --> 0.222774).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3324664
	speed: 0.0206s/iter; left time: 423.8643s
	iters: 200, epoch: 6 | loss: 3.3207190
	speed: 0.0175s/iter; left time: 359.5182s
Epoch: 6 cost time: 4.1649134159088135
Epoch: 6, Steps: 218 Train Loss: 3.4281 (Forecasting Loss:0.3794 + XiCon Loss:3.0487 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.3979
Validation loss decreased (0.222774 --> 0.219107).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.4362297
	speed: 0.0203s/iter; left time: 414.5992s
	iters: 200, epoch: 7 | loss: 3.2965357
	speed: 0.0177s/iter; left time: 358.7437s
Epoch: 7 cost time: 4.149443626403809
Epoch: 7, Steps: 218 Train Loss: 3.4233 (Forecasting Loss:0.3775 + XiCon Loss:3.0458 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.3997
Validation loss decreased (0.219107 --> 0.218192).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.5109072
	speed: 0.0201s/iter; left time: 405.5210s
	iters: 200, epoch: 8 | loss: 3.3428640
	speed: 0.0177s/iter; left time: 355.2654s
Epoch: 8 cost time: 4.1339430809021
Epoch: 8, Steps: 218 Train Loss: 3.4220 (Forecasting Loss:0.3767 + XiCon Loss:3.0453 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3988
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.4461000
	speed: 0.0204s/iter; left time: 407.7663s
	iters: 200, epoch: 9 | loss: 3.4268017
	speed: 0.0181s/iter; left time: 358.4977s
Epoch: 9 cost time: 4.203603029251099
Epoch: 9, Steps: 218 Train Loss: 3.4178 (Forecasting Loss:0.3759 + XiCon Loss:3.0418 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3993
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.3828392
	speed: 0.0202s/iter; left time: 398.6287s
	iters: 200, epoch: 10 | loss: 3.3526316
	speed: 0.0178s/iter; left time: 350.4364s
Epoch: 10 cost time: 4.169915676116943
Epoch: 10, Steps: 218 Train Loss: 3.4220 (Forecasting Loss:0.3756 + XiCon Loss:3.0464 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.4004
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.4065280
	speed: 0.0202s/iter; left time: 394.9306s
	iters: 200, epoch: 11 | loss: 3.3834214
	speed: 0.0177s/iter; left time: 343.4810s
Epoch: 11 cost time: 4.140761852264404
Epoch: 11, Steps: 218 Train Loss: 3.4228 (Forecasting Loss:0.3758 + XiCon Loss:3.0470 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3999
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.4615324
	speed: 0.0203s/iter; left time: 390.9508s
	iters: 200, epoch: 12 | loss: 3.4062920
	speed: 0.0182s/iter; left time: 348.7590s
Epoch: 12 cost time: 4.19178318977356
Epoch: 12, Steps: 218 Train Loss: 3.4203 (Forecasting Loss:0.3753 + XiCon Loss:3.0450 x Lambda(1.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.4001
Validation loss decreased (0.218192 --> 0.218101).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.4022686
	speed: 0.0207s/iter; left time: 394.6647s
	iters: 200, epoch: 13 | loss: 3.5197344
	speed: 0.0176s/iter; left time: 334.4088s
Epoch: 13 cost time: 4.192572593688965
Epoch: 13, Steps: 218 Train Loss: 3.4226 (Forecasting Loss:0.3756 + XiCon Loss:3.0471 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3999
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.3388886
	speed: 0.0205s/iter; left time: 387.4872s
	iters: 200, epoch: 14 | loss: 3.3870776
	speed: 0.0181s/iter; left time: 339.1698s
Epoch: 14 cost time: 4.22403883934021
Epoch: 14, Steps: 218 Train Loss: 3.4243 (Forecasting Loss:0.3758 + XiCon Loss:3.0485 x Lambda(1.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.4000
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.4533486
	speed: 0.0199s/iter; left time: 371.3223s
	iters: 200, epoch: 15 | loss: 3.4889433
	speed: 0.0177s/iter; left time: 329.0506s
Epoch: 15 cost time: 4.123108386993408
Epoch: 15, Steps: 218 Train Loss: 3.4204 (Forecasting Loss:0.3758 + XiCon Loss:3.0446 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.4000
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.3115680
	speed: 0.0200s/iter; left time: 368.3316s
	iters: 200, epoch: 16 | loss: 3.3979607
	speed: 0.0179s/iter; left time: 328.9164s
Epoch: 16 cost time: 4.154984474182129
Epoch: 16, Steps: 218 Train Loss: 3.4211 (Forecasting Loss:0.3756 + XiCon Loss:3.0455 x Lambda(1.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.4000
Validation loss decreased (0.218101 --> 0.218008).  Saving model ...
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.4310036
	speed: 0.0206s/iter; left time: 374.8804s
	iters: 200, epoch: 17 | loss: 3.4596868
	speed: 0.0179s/iter; left time: 324.8876s
Epoch: 17 cost time: 4.224947452545166
Epoch: 17, Steps: 218 Train Loss: 3.4189 (Forecasting Loss:0.3756 + XiCon Loss:3.0433 x Lambda(1.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.4000
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.3571584
	speed: 0.0201s/iter; left time: 361.7260s
	iters: 200, epoch: 18 | loss: 3.4848762
	speed: 0.0177s/iter; left time: 316.7023s
Epoch: 18 cost time: 4.138996601104736
Epoch: 18, Steps: 218 Train Loss: 3.4204 (Forecasting Loss:0.3755 + XiCon Loss:3.0450 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.4000
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.3637915
	speed: 0.0203s/iter; left time: 361.3600s
	iters: 200, epoch: 19 | loss: 3.4112568
	speed: 0.0178s/iter; left time: 315.0464s
Epoch: 19 cost time: 4.18242621421814
Epoch: 19, Steps: 218 Train Loss: 3.4135 (Forecasting Loss:0.3754 + XiCon Loss:3.0381 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.4000
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.5026591
	speed: 0.0205s/iter; left time: 360.4502s
	iters: 200, epoch: 20 | loss: 3.3668649
	speed: 0.0177s/iter; left time: 309.6619s
Epoch: 20 cost time: 4.181389808654785
Epoch: 20, Steps: 218 Train Loss: 3.4190 (Forecasting Loss:0.3752 + XiCon Loss:3.0438 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.4000
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.4238915
	speed: 0.0202s/iter; left time: 349.7129s
	iters: 200, epoch: 21 | loss: 3.3605847
	speed: 0.0176s/iter; left time: 302.8026s
Epoch: 21 cost time: 4.122751712799072
Epoch: 21, Steps: 218 Train Loss: 3.4185 (Forecasting Loss:0.3752 + XiCon Loss:3.0433 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.4000
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.3542247
	speed: 0.0203s/iter; left time: 347.7922s
	iters: 200, epoch: 22 | loss: 3.4230781
	speed: 0.0177s/iter; left time: 300.4735s
Epoch: 22 cost time: 4.155126094818115
Epoch: 22, Steps: 218 Train Loss: 3.4261 (Forecasting Loss:0.3758 + XiCon Loss:3.0503 x Lambda(1.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.4000
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.3066137
	speed: 0.0204s/iter; left time: 345.1192s
	iters: 200, epoch: 23 | loss: 3.4551620
	speed: 0.0186s/iter; left time: 312.4655s
Epoch: 23 cost time: 4.257495164871216
Epoch: 23, Steps: 218 Train Loss: 3.4246 (Forecasting Loss:0.3755 + XiCon Loss:3.0491 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.4000
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.4975026
	speed: 0.0203s/iter; left time: 339.4434s
	iters: 200, epoch: 24 | loss: 3.3231277
	speed: 0.0184s/iter; left time: 304.7171s
Epoch: 24 cost time: 4.236648797988892
Epoch: 24, Steps: 218 Train Loss: 3.4228 (Forecasting Loss:0.3758 + XiCon Loss:3.0470 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.4000
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.3271115
	speed: 0.0202s/iter; left time: 332.5589s
	iters: 200, epoch: 25 | loss: 3.4149551
	speed: 0.0179s/iter; left time: 292.3312s
Epoch: 25 cost time: 4.168875217437744
Epoch: 25, Steps: 218 Train Loss: 3.4188 (Forecasting Loss:0.3756 + XiCon Loss:3.0432 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.4000
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.5291638
	speed: 0.0203s/iter; left time: 329.2426s
	iters: 200, epoch: 26 | loss: 3.3382659
	speed: 0.0178s/iter; left time: 286.7480s
Epoch: 26 cost time: 4.152203798294067
Epoch: 26, Steps: 218 Train Loss: 3.4208 (Forecasting Loss:0.3754 + XiCon Loss:3.0454 x Lambda(1.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.4000
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3502640426158905, mae:0.4497074484825134, mape:5.35215425491333, mspe:73003.6015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3634
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.8818440
	speed: 0.0212s/iter; left time: 459.8577s
	iters: 200, epoch: 1 | loss: 3.7698421
	speed: 0.0178s/iter; left time: 384.9691s
Epoch: 1 cost time: 4.2616870403289795
Epoch: 1, Steps: 218 Train Loss: 3.9376 (Forecasting Loss:0.8368 + XiCon Loss:3.1008 x Lambda(1.0)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.6607
Validation loss decreased (inf --> 0.334805).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4683304
	speed: 0.0200s/iter; left time: 430.2043s
	iters: 200, epoch: 2 | loss: 3.3303409
	speed: 0.0183s/iter; left time: 392.1866s
Epoch: 2 cost time: 4.2014477252960205
Epoch: 2, Steps: 218 Train Loss: 3.4431 (Forecasting Loss:0.4716 + XiCon Loss:2.9714 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.4620
Validation loss decreased (0.334805 --> 0.218628).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3510716
	speed: 0.0206s/iter; left time: 437.0413s
	iters: 200, epoch: 3 | loss: 3.4297562
	speed: 0.0180s/iter; left time: 380.0714s
Epoch: 3 cost time: 4.207385540008545
Epoch: 3, Steps: 218 Train Loss: 3.3787 (Forecasting Loss:0.4200 + XiCon Loss:2.9587 x Lambda(1.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.4345
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.4221625
	speed: 0.0200s/iter; left time: 420.8976s
	iters: 200, epoch: 4 | loss: 3.3729701
	speed: 0.0179s/iter; left time: 374.2527s
Epoch: 4 cost time: 4.171829700469971
Epoch: 4, Steps: 218 Train Loss: 3.4208 (Forecasting Loss:0.4107 + XiCon Loss:3.0101 x Lambda(1.0)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.4261
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3294086
	speed: 0.0203s/iter; left time: 423.1874s
	iters: 200, epoch: 5 | loss: 3.4475701
	speed: 0.0178s/iter; left time: 367.9505s
Epoch: 5 cost time: 4.179321527481079
Epoch: 5, Steps: 218 Train Loss: 3.4180 (Forecasting Loss:0.4014 + XiCon Loss:3.0166 x Lambda(1.0)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.4313
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3842707
	speed: 0.0201s/iter; left time: 413.8922s
	iters: 200, epoch: 6 | loss: 3.3395574
	speed: 0.0181s/iter; left time: 370.3716s
Epoch: 6 cost time: 4.1613359451293945
Epoch: 6, Steps: 218 Train Loss: 3.4047 (Forecasting Loss:0.3954 + XiCon Loss:3.0093 x Lambda(1.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.4226
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.5790594
	speed: 0.0205s/iter; left time: 418.9730s
	iters: 200, epoch: 7 | loss: 3.5304546
	speed: 0.0181s/iter; left time: 368.2417s
Epoch: 7 cost time: 4.228156566619873
Epoch: 7, Steps: 218 Train Loss: 3.4076 (Forecasting Loss:0.3929 + XiCon Loss:3.0147 x Lambda(1.0)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.4298
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3634572
	speed: 0.0203s/iter; left time: 408.9636s
	iters: 200, epoch: 8 | loss: 3.3338063
	speed: 0.0180s/iter; left time: 361.5672s
Epoch: 8 cost time: 4.177776575088501
Epoch: 8, Steps: 218 Train Loss: 3.4081 (Forecasting Loss:0.3913 + XiCon Loss:3.0168 x Lambda(1.0)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.4317
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3564272
	speed: 0.0204s/iter; left time: 407.5897s
	iters: 200, epoch: 9 | loss: 3.3844385
	speed: 0.0178s/iter; left time: 354.1309s
Epoch: 9 cost time: 4.185174226760864
Epoch: 9, Steps: 218 Train Loss: 3.4050 (Forecasting Loss:0.3907 + XiCon Loss:3.0143 x Lambda(1.0)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.4297
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.4673295
	speed: 0.0201s/iter; left time: 396.0557s
	iters: 200, epoch: 10 | loss: 3.4647789
	speed: 0.0179s/iter; left time: 352.2214s
Epoch: 10 cost time: 4.16166615486145
Epoch: 10, Steps: 218 Train Loss: 3.4083 (Forecasting Loss:0.3908 + XiCon Loss:3.0175 x Lambda(1.0)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.4312
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.4374585
	speed: 0.0202s/iter; left time: 393.5412s
	iters: 200, epoch: 11 | loss: 3.3828862
	speed: 0.0179s/iter; left time: 348.0201s
Epoch: 11 cost time: 4.159615993499756
Epoch: 11, Steps: 218 Train Loss: 3.4058 (Forecasting Loss:0.3903 + XiCon Loss:3.0155 x Lambda(1.0)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.4338
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.4565346
	speed: 0.0207s/iter; left time: 400.1069s
	iters: 200, epoch: 12 | loss: 3.3979683
	speed: 0.0180s/iter; left time: 345.4979s
Epoch: 12 cost time: 4.254869699478149
Epoch: 12, Steps: 218 Train Loss: 3.4124 (Forecasting Loss:0.3903 + XiCon Loss:3.0222 x Lambda(1.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.4330
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.4239649474620819, mae:0.5000792145729065, mape:6.090694427490234, mspe:95088.921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5292
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.9416838
	speed: 0.0213s/iter; left time: 461.4146s
	iters: 200, epoch: 1 | loss: 3.8722646
	speed: 0.0179s/iter; left time: 386.3257s
Epoch: 1 cost time: 4.260973691940308
Epoch: 1, Steps: 218 Train Loss: 3.9394 (Forecasting Loss:0.8365 + XiCon Loss:3.1028 x Lambda(1.0)), Vali MSE Loss: 0.3346 Test MSE Loss: 0.6678
Validation loss decreased (inf --> 0.334585).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3857446
	speed: 0.0210s/iter; left time: 450.5273s
	iters: 200, epoch: 2 | loss: 3.4033849
	speed: 0.0179s/iter; left time: 383.1429s
Epoch: 2 cost time: 4.255119800567627
Epoch: 2, Steps: 218 Train Loss: 3.4752 (Forecasting Loss:0.4923 + XiCon Loss:2.9829 x Lambda(1.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.4357
Validation loss decreased (0.334585 --> 0.220707).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3140440
	speed: 0.0205s/iter; left time: 434.9829s
	iters: 200, epoch: 3 | loss: 3.3799038
	speed: 0.0180s/iter; left time: 381.7491s
Epoch: 3 cost time: 4.192590713500977
Epoch: 3, Steps: 218 Train Loss: 3.3525 (Forecasting Loss:0.4136 + XiCon Loss:2.9388 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.3882
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3836310
	speed: 0.0201s/iter; left time: 422.0592s
	iters: 200, epoch: 4 | loss: 3.5410643
	speed: 0.0176s/iter; left time: 368.0945s
Epoch: 4 cost time: 4.112797021865845
Epoch: 4, Steps: 218 Train Loss: 3.4099 (Forecasting Loss:0.4036 + XiCon Loss:3.0064 x Lambda(1.0)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.3783
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.4203961
	speed: 0.0202s/iter; left time: 420.7491s
	iters: 200, epoch: 5 | loss: 3.4481232
	speed: 0.0176s/iter; left time: 365.5963s
Epoch: 5 cost time: 4.141119480133057
Epoch: 5, Steps: 218 Train Loss: 3.4162 (Forecasting Loss:0.3936 + XiCon Loss:3.0227 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.3766
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.4295712
	speed: 0.0200s/iter; left time: 411.2370s
	iters: 200, epoch: 6 | loss: 3.3959041
	speed: 0.0177s/iter; left time: 362.1205s
Epoch: 6 cost time: 4.137136459350586
Epoch: 6, Steps: 218 Train Loss: 3.4172 (Forecasting Loss:0.3871 + XiCon Loss:3.0301 x Lambda(1.0)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.3858
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.4741569
	speed: 0.0199s/iter; left time: 405.4893s
	iters: 200, epoch: 7 | loss: 3.3872952
	speed: 0.0183s/iter; left time: 371.9265s
Epoch: 7 cost time: 4.1811816692352295
Epoch: 7, Steps: 218 Train Loss: 3.4103 (Forecasting Loss:0.3841 + XiCon Loss:3.0263 x Lambda(1.0)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.3850
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.4666610
	speed: 0.0202s/iter; left time: 407.8130s
	iters: 200, epoch: 8 | loss: 3.4607344
	speed: 0.0179s/iter; left time: 360.2222s
Epoch: 8 cost time: 4.1622302532196045
Epoch: 8, Steps: 218 Train Loss: 3.4111 (Forecasting Loss:0.3812 + XiCon Loss:3.0299 x Lambda(1.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.3863
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3756762
	speed: 0.0205s/iter; left time: 408.2782s
	iters: 200, epoch: 9 | loss: 3.4305050
	speed: 0.0177s/iter; left time: 350.5959s
Epoch: 9 cost time: 4.163525819778442
Epoch: 9, Steps: 218 Train Loss: 3.4087 (Forecasting Loss:0.3806 + XiCon Loss:3.0281 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.3853
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.3685207
	speed: 0.0204s/iter; left time: 402.7020s
	iters: 200, epoch: 10 | loss: 3.3687637
	speed: 0.0175s/iter; left time: 344.4670s
Epoch: 10 cost time: 4.158976793289185
Epoch: 10, Steps: 218 Train Loss: 3.4158 (Forecasting Loss:0.3803 + XiCon Loss:3.0355 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.3851
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.4258122
	speed: 0.0202s/iter; left time: 394.6210s
	iters: 200, epoch: 11 | loss: 3.4990914
	speed: 0.0178s/iter; left time: 345.8956s
Epoch: 11 cost time: 4.1605634689331055
Epoch: 11, Steps: 218 Train Loss: 3.4114 (Forecasting Loss:0.3803 + XiCon Loss:3.0311 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.3855
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.4637604
	speed: 0.0202s/iter; left time: 389.9695s
	iters: 200, epoch: 12 | loss: 3.3973763
	speed: 0.0182s/iter; left time: 350.2802s
Epoch: 12 cost time: 4.1930992603302
Epoch: 12, Steps: 218 Train Loss: 3.4158 (Forecasting Loss:0.3801 + XiCon Loss:3.0357 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.3857
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.39141061902046204, mae:0.4800686538219452, mape:5.733893871307373, mspe:83070.4609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.2679
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.9252090
	speed: 0.0216s/iter; left time: 468.0429s
	iters: 200, epoch: 1 | loss: 3.7602119
	speed: 0.0181s/iter; left time: 390.4484s
Epoch: 1 cost time: 4.32038950920105
Epoch: 1, Steps: 218 Train Loss: 3.9280 (Forecasting Loss:0.8309 + XiCon Loss:3.0971 x Lambda(1.0)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.6486
Validation loss decreased (inf --> 0.331665).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.4582317
	speed: 0.0199s/iter; left time: 427.1303s
	iters: 200, epoch: 2 | loss: 3.3830168
	speed: 0.0176s/iter; left time: 377.1664s
Epoch: 2 cost time: 4.096965789794922
Epoch: 2, Steps: 218 Train Loss: 3.4751 (Forecasting Loss:0.4666 + XiCon Loss:3.0086 x Lambda(1.0)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.4594
Validation loss decreased (0.331665 --> 0.216822).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2758992
	speed: 0.0201s/iter; left time: 427.8125s
	iters: 200, epoch: 3 | loss: 3.5009093
	speed: 0.0179s/iter; left time: 377.9462s
Epoch: 3 cost time: 4.172762632369995
Epoch: 3, Steps: 218 Train Loss: 3.3758 (Forecasting Loss:0.4157 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.4191
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3607070
	speed: 0.0203s/iter; left time: 427.7824s
	iters: 200, epoch: 4 | loss: 3.4788706
	speed: 0.0181s/iter; left time: 378.1211s
Epoch: 4 cost time: 4.196101903915405
Epoch: 4, Steps: 218 Train Loss: 3.4132 (Forecasting Loss:0.4046 + XiCon Loss:3.0086 x Lambda(1.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.3955
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3797331
	speed: 0.0204s/iter; left time: 425.7143s
	iters: 200, epoch: 5 | loss: 3.4820209
	speed: 0.0189s/iter; left time: 391.5789s
Epoch: 5 cost time: 4.306153774261475
Epoch: 5, Steps: 218 Train Loss: 3.4115 (Forecasting Loss:0.3946 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.3945
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.4503736
	speed: 0.0199s/iter; left time: 410.5601s
	iters: 200, epoch: 6 | loss: 3.3988919
	speed: 0.0177s/iter; left time: 362.6951s
Epoch: 6 cost time: 4.113338947296143
Epoch: 6, Steps: 218 Train Loss: 3.4033 (Forecasting Loss:0.3904 + XiCon Loss:3.0129 x Lambda(1.0)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.4012
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.3547068
	speed: 0.0200s/iter; left time: 408.5809s
	iters: 200, epoch: 7 | loss: 3.3430929
	speed: 0.0179s/iter; left time: 363.5595s
Epoch: 7 cost time: 4.139681100845337
Epoch: 7, Steps: 218 Train Loss: 3.4061 (Forecasting Loss:0.3882 + XiCon Loss:3.0179 x Lambda(1.0)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.3933
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.4679103
	speed: 0.0202s/iter; left time: 408.2779s
	iters: 200, epoch: 8 | loss: 3.3633773
	speed: 0.0182s/iter; left time: 364.4663s
Epoch: 8 cost time: 4.198916912078857
Epoch: 8, Steps: 218 Train Loss: 3.4082 (Forecasting Loss:0.3871 + XiCon Loss:3.0211 x Lambda(1.0)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.3940
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.3660574
	speed: 0.0203s/iter; left time: 405.9971s
	iters: 200, epoch: 9 | loss: 3.5102348
	speed: 0.0179s/iter; left time: 354.5653s
Epoch: 9 cost time: 4.176649332046509
Epoch: 9, Steps: 218 Train Loss: 3.4106 (Forecasting Loss:0.3862 + XiCon Loss:3.0244 x Lambda(1.0)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.3960
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.4509532
	speed: 0.0200s/iter; left time: 395.0478s
	iters: 200, epoch: 10 | loss: 3.4341955
	speed: 0.0178s/iter; left time: 348.6758s
Epoch: 10 cost time: 4.124534606933594
Epoch: 10, Steps: 218 Train Loss: 3.4072 (Forecasting Loss:0.3860 + XiCon Loss:3.0212 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.3959
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.4520473
	speed: 0.0206s/iter; left time: 402.6200s
	iters: 200, epoch: 11 | loss: 3.3129127
	speed: 0.0180s/iter; left time: 348.6580s
Epoch: 11 cost time: 4.230897426605225
Epoch: 11, Steps: 218 Train Loss: 3.4060 (Forecasting Loss:0.3855 + XiCon Loss:3.0205 x Lambda(1.0)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.3958
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.4154818
	speed: 0.0207s/iter; left time: 398.8368s
	iters: 200, epoch: 12 | loss: 3.4018641
	speed: 0.0180s/iter; left time: 344.9667s
Epoch: 12 cost time: 4.212161302566528
Epoch: 12, Steps: 218 Train Loss: 3.4118 (Forecasting Loss:0.3858 + XiCon Loss:3.0260 x Lambda(1.0)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.3960
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.41828295588493347, mae:0.5006083846092224, mape:5.7447052001953125, mspe:75483.453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3948+-0.03631, MAE:0.4820+-0.02578, MAPE:5.7883+-0.36218, MSPE:84542.9375+-13336.31528, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.7115
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 27.5611992
	speed: 0.0196s/iter; left time: 408.8249s
	iters: 200, epoch: 1 | loss: 27.2268600
	speed: 0.0146s/iter; left time: 302.6930s
Epoch: 1 cost time: 3.579044818878174
Epoch: 1, Steps: 210 Train Loss: 27.5541 (Forecasting Loss:0.8385 + XiCon Loss:2.6716 x Lambda(10.0)), Vali MSE Loss: 0.2803 Test MSE Loss: 0.6984
Validation loss decreased (inf --> 0.280262).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 26.7375698
	speed: 0.0168s/iter; left time: 348.1064s
	iters: 200, epoch: 2 | loss: 25.9360275
	speed: 0.0152s/iter; left time: 312.0151s
Epoch: 2 cost time: 3.390038251876831
Epoch: 2, Steps: 210 Train Loss: 26.0118 (Forecasting Loss:0.5770 + XiCon Loss:2.5435 x Lambda(10.0)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.5871
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 25.8405018
	speed: 0.0175s/iter; left time: 357.8576s
	iters: 200, epoch: 3 | loss: 25.6754189
	speed: 0.0161s/iter; left time: 327.9648s
Epoch: 3 cost time: 3.5399529933929443
Epoch: 3, Steps: 210 Train Loss: 25.8458 (Forecasting Loss:0.5182 + XiCon Loss:2.5328 x Lambda(10.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.5120
Validation loss decreased (0.280262 --> 0.245900).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 24.7621422
	speed: 0.0178s/iter; left time: 361.6628s
	iters: 200, epoch: 4 | loss: 25.6278324
	speed: 0.0152s/iter; left time: 306.5166s
Epoch: 4 cost time: 3.4832096099853516
Epoch: 4, Steps: 210 Train Loss: 25.6674 (Forecasting Loss:0.4934 + XiCon Loss:2.5174 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 24.1724892
	speed: 0.0173s/iter; left time: 347.6483s
	iters: 200, epoch: 5 | loss: 26.0000610
	speed: 0.0146s/iter; left time: 292.3773s
Epoch: 5 cost time: 3.377474069595337
Epoch: 5, Steps: 210 Train Loss: 25.5184 (Forecasting Loss:0.4866 + XiCon Loss:2.5032 x Lambda(10.0)), Vali MSE Loss: 0.2697 Test MSE Loss: 0.5869
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 25.0943241
	speed: 0.0170s/iter; left time: 337.4919s
	iters: 200, epoch: 6 | loss: 24.4255123
	speed: 0.0151s/iter; left time: 298.8313s
Epoch: 6 cost time: 3.3867785930633545
Epoch: 6, Steps: 210 Train Loss: 25.3903 (Forecasting Loss:0.4814 + XiCon Loss:2.4909 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.5493
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 26.0227318
	speed: 0.0169s/iter; left time: 332.3825s
	iters: 200, epoch: 7 | loss: 25.1867676
	speed: 0.0150s/iter; left time: 293.6795s
Epoch: 7 cost time: 3.373361587524414
Epoch: 7, Steps: 210 Train Loss: 25.3375 (Forecasting Loss:0.4786 + XiCon Loss:2.4859 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.5468
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 25.2120457
	speed: 0.0173s/iter; left time: 335.8554s
	iters: 200, epoch: 8 | loss: 25.8514099
	speed: 0.0148s/iter; left time: 286.1242s
Epoch: 8 cost time: 3.3955647945404053
Epoch: 8, Steps: 210 Train Loss: 25.2952 (Forecasting Loss:0.4776 + XiCon Loss:2.4818 x Lambda(10.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.5502
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 25.4994164
	speed: 0.0175s/iter; left time: 335.5499s
	iters: 200, epoch: 9 | loss: 25.3028793
	speed: 0.0144s/iter; left time: 275.5169s
Epoch: 9 cost time: 3.3622846603393555
Epoch: 9, Steps: 210 Train Loss: 25.3223 (Forecasting Loss:0.4778 + XiCon Loss:2.4844 x Lambda(10.0)), Vali MSE Loss: 0.2556 Test MSE Loss: 0.5528
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 24.8994026
	speed: 0.0173s/iter; left time: 328.1339s
	iters: 200, epoch: 10 | loss: 25.5915146
	speed: 0.0150s/iter; left time: 282.8977s
Epoch: 10 cost time: 3.3954219818115234
Epoch: 10, Steps: 210 Train Loss: 25.2987 (Forecasting Loss:0.4766 + XiCon Loss:2.4822 x Lambda(10.0)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.5509
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 25.7069035
	speed: 0.0173s/iter; left time: 325.2539s
	iters: 200, epoch: 11 | loss: 25.4229164
	speed: 0.0150s/iter; left time: 280.3089s
Epoch: 11 cost time: 3.405578374862671
Epoch: 11, Steps: 210 Train Loss: 25.3111 (Forecasting Loss:0.4765 + XiCon Loss:2.4835 x Lambda(10.0)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.5478
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 25.4306831
	speed: 0.0172s/iter; left time: 319.8036s
	iters: 200, epoch: 12 | loss: 25.7957325
	speed: 0.0145s/iter; left time: 268.1443s
Epoch: 12 cost time: 3.357536792755127
Epoch: 12, Steps: 210 Train Loss: 25.2850 (Forecasting Loss:0.4770 + XiCon Loss:2.4808 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.5455
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 24.8826885
	speed: 0.0169s/iter; left time: 310.3236s
	iters: 200, epoch: 13 | loss: 24.7867298
	speed: 0.0143s/iter; left time: 261.8619s
Epoch: 13 cost time: 3.2871317863464355
Epoch: 13, Steps: 210 Train Loss: 25.2794 (Forecasting Loss:0.4772 + XiCon Loss:2.4802 x Lambda(10.0)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.5500
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.4853827655315399, mae:0.5385890007019043, mape:4.0879926681518555, mspe:22426.111328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.7505
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 27.5592079
	speed: 0.0173s/iter; left time: 360.9327s
	iters: 200, epoch: 1 | loss: 26.7633343
	speed: 0.0138s/iter; left time: 287.9818s
Epoch: 1 cost time: 3.2927088737487793
Epoch: 1, Steps: 210 Train Loss: 27.3584 (Forecasting Loss:0.8416 + XiCon Loss:2.6517 x Lambda(10.0)), Vali MSE Loss: 0.2811 Test MSE Loss: 0.7006
Validation loss decreased (inf --> 0.281116).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 25.8645287
	speed: 0.0180s/iter; left time: 372.8526s
	iters: 200, epoch: 2 | loss: 26.9284325
	speed: 0.0171s/iter; left time: 352.7441s
Epoch: 2 cost time: 3.7186031341552734
Epoch: 2, Steps: 210 Train Loss: 25.9069 (Forecasting Loss:0.6859 + XiCon Loss:2.5221 x Lambda(10.0)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.6005
Validation loss decreased (0.281116 --> 0.239123).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 27.5655289
	speed: 0.0186s/iter; left time: 381.9178s
	iters: 200, epoch: 3 | loss: 26.7040329
	speed: 0.0168s/iter; left time: 342.2017s
Epoch: 3 cost time: 3.7452027797698975
Epoch: 3, Steps: 210 Train Loss: 26.3807 (Forecasting Loss:0.5353 + XiCon Loss:2.5845 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.5675
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 26.8935127
	speed: 0.0197s/iter; left time: 400.1422s
	iters: 200, epoch: 4 | loss: 27.2250671
	speed: 0.0168s/iter; left time: 338.6973s
Epoch: 4 cost time: 3.854534864425659
Epoch: 4, Steps: 210 Train Loss: 26.0718 (Forecasting Loss:0.5099 + XiCon Loss:2.5562 x Lambda(10.0)), Vali MSE Loss: 0.2304 Test MSE Loss: 0.5538
Validation loss decreased (0.239123 --> 0.230429).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 25.9451580
	speed: 0.0187s/iter; left time: 375.2854s
	iters: 200, epoch: 5 | loss: 26.2069283
	speed: 0.0168s/iter; left time: 335.3038s
Epoch: 5 cost time: 3.7748935222625732
Epoch: 5, Steps: 210 Train Loss: 25.8069 (Forecasting Loss:0.4944 + XiCon Loss:2.5312 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5386
Validation loss decreased (0.230429 --> 0.225284).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 26.0506039
	speed: 0.0191s/iter; left time: 378.1954s
	iters: 200, epoch: 6 | loss: 25.3952961
	speed: 0.0169s/iter; left time: 332.9024s
Epoch: 6 cost time: 3.7875728607177734
Epoch: 6, Steps: 210 Train Loss: 25.7623 (Forecasting Loss:0.4861 + XiCon Loss:2.5276 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.5475
Validation loss decreased (0.225284 --> 0.219350).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 24.6993561
	speed: 0.0190s/iter; left time: 374.1562s
	iters: 200, epoch: 7 | loss: 25.2932663
	speed: 0.0165s/iter; left time: 323.2200s
Epoch: 7 cost time: 3.7788517475128174
Epoch: 7, Steps: 210 Train Loss: 25.7482 (Forecasting Loss:0.4790 + XiCon Loss:2.5269 x Lambda(10.0)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.5513
Validation loss decreased (0.219350 --> 0.216804).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 24.8514709
	speed: 0.0191s/iter; left time: 371.3367s
	iters: 200, epoch: 8 | loss: 26.8384476
	speed: 0.0165s/iter; left time: 319.3663s
Epoch: 8 cost time: 3.7721121311187744
Epoch: 8, Steps: 210 Train Loss: 25.6364 (Forecasting Loss:0.4766 + XiCon Loss:2.5160 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.5479
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 25.8993034
	speed: 0.0197s/iter; left time: 378.6659s
	iters: 200, epoch: 9 | loss: 24.4798470
	speed: 0.0166s/iter; left time: 317.8747s
Epoch: 9 cost time: 3.85133695602417
Epoch: 9, Steps: 210 Train Loss: 25.6815 (Forecasting Loss:0.4755 + XiCon Loss:2.5206 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5505
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 25.6876221
	speed: 0.0195s/iter; left time: 371.3378s
	iters: 200, epoch: 10 | loss: 25.3269653
	speed: 0.0161s/iter; left time: 304.8712s
Epoch: 10 cost time: 3.7604031562805176
Epoch: 10, Steps: 210 Train Loss: 25.6741 (Forecasting Loss:0.4750 + XiCon Loss:2.5199 x Lambda(10.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.5503
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 26.1628952
	speed: 0.0191s/iter; left time: 358.4479s
	iters: 200, epoch: 11 | loss: 25.9632778
	speed: 0.0167s/iter; left time: 312.4336s
Epoch: 11 cost time: 3.7736823558807373
Epoch: 11, Steps: 210 Train Loss: 25.7074 (Forecasting Loss:0.4749 + XiCon Loss:2.5232 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5504
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 25.1026917
	speed: 0.0189s/iter; left time: 352.1406s
	iters: 200, epoch: 12 | loss: 25.4588165
	speed: 0.0164s/iter; left time: 303.1405s
Epoch: 12 cost time: 3.7364542484283447
Epoch: 12, Steps: 210 Train Loss: 25.6781 (Forecasting Loss:0.4744 + XiCon Loss:2.5204 x Lambda(10.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.5512
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 24.8001099
	speed: 0.0189s/iter; left time: 346.9836s
	iters: 200, epoch: 13 | loss: 25.8876648
	speed: 0.0165s/iter; left time: 302.3290s
Epoch: 13 cost time: 3.7357988357543945
Epoch: 13, Steps: 210 Train Loss: 25.6574 (Forecasting Loss:0.4745 + XiCon Loss:2.5183 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5510
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 24.7728977
	speed: 0.0192s/iter; left time: 349.6915s
	iters: 200, epoch: 14 | loss: 25.7071419
	speed: 0.0165s/iter; left time: 298.1465s
Epoch: 14 cost time: 3.7729673385620117
Epoch: 14, Steps: 210 Train Loss: 25.6730 (Forecasting Loss:0.4744 + XiCon Loss:2.5199 x Lambda(10.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.5511
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 25.4966774
	speed: 0.0191s/iter; left time: 343.8639s
	iters: 200, epoch: 15 | loss: 25.4819717
	speed: 0.0165s/iter; left time: 294.6893s
Epoch: 15 cost time: 3.769057512283325
Epoch: 15, Steps: 210 Train Loss: 25.6711 (Forecasting Loss:0.4742 + XiCon Loss:2.5197 x Lambda(10.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.5511
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 24.6125088
	speed: 0.0187s/iter; left time: 331.5464s
	iters: 200, epoch: 16 | loss: 24.9616032
	speed: 0.0164s/iter; left time: 290.1839s
Epoch: 16 cost time: 3.7155439853668213
Epoch: 16, Steps: 210 Train Loss: 25.6659 (Forecasting Loss:0.4742 + XiCon Loss:2.5192 x Lambda(10.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.5511
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 25.3762932
	speed: 0.0187s/iter; left time: 327.1853s
	iters: 200, epoch: 17 | loss: 25.7017193
	speed: 0.0165s/iter; left time: 287.8428s
Epoch: 17 cost time: 3.7187247276306152
Epoch: 17, Steps: 210 Train Loss: 25.5621 (Forecasting Loss:0.4747 + XiCon Loss:2.5087 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5511
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5360103249549866, mae:0.5666184425354004, mape:3.588414430618286, mspe:10095.982421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.4667
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 27.6141434
	speed: 0.0171s/iter; left time: 357.3174s
	iters: 200, epoch: 1 | loss: 27.1773052
	speed: 0.0136s/iter; left time: 283.8714s
Epoch: 1 cost time: 3.249500274658203
Epoch: 1, Steps: 210 Train Loss: 27.3947 (Forecasting Loss:0.8484 + XiCon Loss:2.6546 x Lambda(10.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.7027
Validation loss decreased (inf --> 0.281210).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 25.2008381
	speed: 0.0186s/iter; left time: 385.6680s
	iters: 200, epoch: 2 | loss: 26.8740959
	speed: 0.0164s/iter; left time: 337.2605s
Epoch: 2 cost time: 3.696840524673462
Epoch: 2, Steps: 210 Train Loss: 26.0417 (Forecasting Loss:0.6762 + XiCon Loss:2.5365 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.5259
Validation loss decreased (0.281210 --> 0.248993).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 26.5885258
	speed: 0.0186s/iter; left time: 380.5828s
	iters: 200, epoch: 3 | loss: 27.1078300
	speed: 0.0169s/iter; left time: 345.3960s
Epoch: 3 cost time: 3.7549283504486084
Epoch: 3, Steps: 210 Train Loss: 26.7022 (Forecasting Loss:0.5348 + XiCon Loss:2.6167 x Lambda(10.0)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.5332
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 27.2734795
	speed: 0.0194s/iter; left time: 392.6487s
	iters: 200, epoch: 4 | loss: 25.1118279
	speed: 0.0166s/iter; left time: 334.9278s
Epoch: 4 cost time: 3.800471067428589
Epoch: 4, Steps: 210 Train Loss: 26.1783 (Forecasting Loss:0.5125 + XiCon Loss:2.5666 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.5373
Validation loss decreased (0.248993 --> 0.247406).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 25.4733429
	speed: 0.0190s/iter; left time: 380.4774s
	iters: 200, epoch: 5 | loss: 26.2723370
	speed: 0.0163s/iter; left time: 325.4301s
Epoch: 5 cost time: 3.7313430309295654
Epoch: 5, Steps: 210 Train Loss: 25.9652 (Forecasting Loss:0.4993 + XiCon Loss:2.5466 x Lambda(10.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.5395
Validation loss decreased (0.247406 --> 0.230072).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 25.8318748
	speed: 0.0189s/iter; left time: 375.8479s
	iters: 200, epoch: 6 | loss: 25.2537136
	speed: 0.0159s/iter; left time: 313.2087s
Epoch: 6 cost time: 3.671066999435425
Epoch: 6, Steps: 210 Train Loss: 25.9538 (Forecasting Loss:0.4899 + XiCon Loss:2.5464 x Lambda(10.0)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.5447
Validation loss decreased (0.230072 --> 0.221064).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 26.0893230
	speed: 0.0178s/iter; left time: 349.8159s
	iters: 200, epoch: 7 | loss: 25.8141079
	speed: 0.0158s/iter; left time: 308.3016s
Epoch: 7 cost time: 3.5461630821228027
Epoch: 7, Steps: 210 Train Loss: 25.8780 (Forecasting Loss:0.4842 + XiCon Loss:2.5394 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5439
Validation loss decreased (0.221064 --> 0.219655).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 25.9477482
	speed: 0.0179s/iter; left time: 346.9547s
	iters: 200, epoch: 8 | loss: 25.8384228
	speed: 0.0152s/iter; left time: 294.4941s
Epoch: 8 cost time: 3.496978282928467
Epoch: 8, Steps: 210 Train Loss: 25.8172 (Forecasting Loss:0.4811 + XiCon Loss:2.5336 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.5420
Validation loss decreased (0.219655 --> 0.219336).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 25.2911034
	speed: 0.0177s/iter; left time: 340.7096s
	iters: 200, epoch: 9 | loss: 25.0444164
	speed: 0.0153s/iter; left time: 293.3447s
Epoch: 9 cost time: 3.4898862838745117
Epoch: 9, Steps: 210 Train Loss: 25.8533 (Forecasting Loss:0.4795 + XiCon Loss:2.5374 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5429
Validation loss decreased (0.219336 --> 0.219019).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 25.8495045
	speed: 0.0178s/iter; left time: 337.5726s
	iters: 200, epoch: 10 | loss: 25.5200005
	speed: 0.0151s/iter; left time: 284.7262s
Epoch: 10 cost time: 3.4722301959991455
Epoch: 10, Steps: 210 Train Loss: 25.7826 (Forecasting Loss:0.4793 + XiCon Loss:2.5303 x Lambda(10.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.5412
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 25.4148369
	speed: 0.0176s/iter; left time: 331.7402s
	iters: 200, epoch: 11 | loss: 26.6900120
	speed: 0.0152s/iter; left time: 283.7673s
Epoch: 11 cost time: 3.470673084259033
Epoch: 11, Steps: 210 Train Loss: 25.8394 (Forecasting Loss:0.4788 + XiCon Loss:2.5361 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5423
Validation loss decreased (0.219019 --> 0.218990).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 26.4929161
	speed: 0.0179s/iter; left time: 332.1823s
	iters: 200, epoch: 12 | loss: 26.7278938
	speed: 0.0149s/iter; left time: 276.1079s
Epoch: 12 cost time: 3.4679386615753174
Epoch: 12, Steps: 210 Train Loss: 25.8288 (Forecasting Loss:0.4786 + XiCon Loss:2.5350 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5421
Validation loss decreased (0.218990 --> 0.218935).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 25.7911663
	speed: 0.0183s/iter; left time: 335.7951s
	iters: 200, epoch: 13 | loss: 25.2856693
	speed: 0.0155s/iter; left time: 284.0202s
Epoch: 13 cost time: 3.5674149990081787
Epoch: 13, Steps: 210 Train Loss: 25.8096 (Forecasting Loss:0.4785 + XiCon Loss:2.5331 x Lambda(10.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.5419
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 25.7022381
	speed: 0.0176s/iter; left time: 319.5236s
	iters: 200, epoch: 14 | loss: 26.8714161
	speed: 0.0150s/iter; left time: 271.4666s
Epoch: 14 cost time: 3.4478232860565186
Epoch: 14, Steps: 210 Train Loss: 25.8055 (Forecasting Loss:0.4784 + XiCon Loss:2.5327 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5419
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 25.7420731
	speed: 0.0176s/iter; left time: 315.3482s
	iters: 200, epoch: 15 | loss: 26.3009071
	speed: 0.0153s/iter; left time: 273.6804s
Epoch: 15 cost time: 3.475635528564453
Epoch: 15, Steps: 210 Train Loss: 25.8238 (Forecasting Loss:0.4785 + XiCon Loss:2.5345 x Lambda(10.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.5419
Validation loss decreased (0.218935 --> 0.218834).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 25.3361855
	speed: 0.0179s/iter; left time: 317.6406s
	iters: 200, epoch: 16 | loss: 26.0201607
	speed: 0.0155s/iter; left time: 273.1193s
Epoch: 16 cost time: 3.527890205383301
Epoch: 16, Steps: 210 Train Loss: 25.8660 (Forecasting Loss:0.4786 + XiCon Loss:2.5387 x Lambda(10.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.5419
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 24.9357338
	speed: 0.0178s/iter; left time: 312.4928s
	iters: 200, epoch: 17 | loss: 25.7124481
	speed: 0.0154s/iter; left time: 267.7903s
Epoch: 17 cost time: 3.505100727081299
Epoch: 17, Steps: 210 Train Loss: 25.8201 (Forecasting Loss:0.4786 + XiCon Loss:2.5341 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5419
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 26.2909641
	speed: 0.0176s/iter; left time: 305.8687s
	iters: 200, epoch: 18 | loss: 26.6644955
	speed: 0.0154s/iter; left time: 265.1981s
Epoch: 18 cost time: 3.4975221157073975
Epoch: 18, Steps: 210 Train Loss: 25.8401 (Forecasting Loss:0.4785 + XiCon Loss:2.5362 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5419
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 24.9508419
	speed: 0.0180s/iter; left time: 307.4904s
	iters: 200, epoch: 19 | loss: 26.0826225
	speed: 0.0156s/iter; left time: 265.5508s
Epoch: 19 cost time: 3.54132080078125
Epoch: 19, Steps: 210 Train Loss: 25.8466 (Forecasting Loss:0.4784 + XiCon Loss:2.5368 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5419
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 26.6701431
	speed: 0.0176s/iter; left time: 297.8203s
	iters: 200, epoch: 20 | loss: 25.7424374
	speed: 0.0154s/iter; left time: 259.6242s
Epoch: 20 cost time: 3.492507219314575
Epoch: 20, Steps: 210 Train Loss: 25.8048 (Forecasting Loss:0.4787 + XiCon Loss:2.5326 x Lambda(10.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.5419
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 27.3749008
	speed: 0.0179s/iter; left time: 298.8945s
	iters: 200, epoch: 21 | loss: 25.7965012
	speed: 0.0150s/iter; left time: 249.3575s
Epoch: 21 cost time: 3.4730265140533447
Epoch: 21, Steps: 210 Train Loss: 25.7491 (Forecasting Loss:0.4784 + XiCon Loss:2.5271 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5419
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 24.9671822
	speed: 0.0178s/iter; left time: 293.9402s
	iters: 200, epoch: 22 | loss: 25.9630070
	speed: 0.0154s/iter; left time: 252.8211s
Epoch: 22 cost time: 3.528327465057373
Epoch: 22, Steps: 210 Train Loss: 25.8657 (Forecasting Loss:0.4781 + XiCon Loss:2.5388 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5419
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 25.5062180
	speed: 0.0180s/iter; left time: 293.4670s
	iters: 200, epoch: 23 | loss: 25.1422749
	speed: 0.0153s/iter; left time: 248.0781s
Epoch: 23 cost time: 3.522481679916382
Epoch: 23, Steps: 210 Train Loss: 25.7888 (Forecasting Loss:0.4783 + XiCon Loss:2.5310 x Lambda(10.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.5419
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 26.6088142
	speed: 0.0174s/iter; left time: 280.3746s
	iters: 200, epoch: 24 | loss: 26.7157040
	speed: 0.0161s/iter; left time: 256.4316s
Epoch: 24 cost time: 3.537045478820801
Epoch: 24, Steps: 210 Train Loss: 25.8301 (Forecasting Loss:0.4786 + XiCon Loss:2.5352 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.5419
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 25.7821064
	speed: 0.0179s/iter; left time: 284.5530s
	iters: 200, epoch: 25 | loss: 25.6367111
	speed: 0.0156s/iter; left time: 245.2333s
Epoch: 25 cost time: 3.5376136302948
Epoch: 25, Steps: 210 Train Loss: 25.7585 (Forecasting Loss:0.4784 + XiCon Loss:2.5280 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5419
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5199941992759705, mae:0.5637893676757812, mape:3.5951716899871826, mspe:7666.69091796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.7228
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 27.1347847
	speed: 0.0168s/iter; left time: 352.1389s
	iters: 200, epoch: 1 | loss: 26.8841915
	speed: 0.0136s/iter; left time: 283.1256s
Epoch: 1 cost time: 3.2139079570770264
Epoch: 1, Steps: 210 Train Loss: 27.2976 (Forecasting Loss:0.8396 + XiCon Loss:2.6458 x Lambda(10.0)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.6859
Validation loss decreased (inf --> 0.279109).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 25.9246769
	speed: 0.0181s/iter; left time: 374.4053s
	iters: 200, epoch: 2 | loss: 25.7302570
	speed: 0.0168s/iter; left time: 345.9481s
Epoch: 2 cost time: 3.702277898788452
Epoch: 2, Steps: 210 Train Loss: 25.8699 (Forecasting Loss:0.7063 + XiCon Loss:2.5164 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.5950
Validation loss decreased (0.279109 --> 0.239385).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 26.8304482
	speed: 0.0203s/iter; left time: 414.9613s
	iters: 200, epoch: 3 | loss: 25.8241978
	speed: 0.0170s/iter; left time: 345.7288s
Epoch: 3 cost time: 3.9283273220062256
Epoch: 3, Steps: 210 Train Loss: 26.9569 (Forecasting Loss:0.5578 + XiCon Loss:2.6399 x Lambda(10.0)), Vali MSE Loss: 0.2703 Test MSE Loss: 0.5248
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 26.3325462
	speed: 0.0192s/iter; left time: 389.6300s
	iters: 200, epoch: 4 | loss: 26.8823013
	speed: 0.0161s/iter; left time: 325.6753s
Epoch: 4 cost time: 3.7349624633789062
Epoch: 4, Steps: 210 Train Loss: 26.5069 (Forecasting Loss:0.5121 + XiCon Loss:2.5995 x Lambda(10.0)), Vali MSE Loss: 0.2392 Test MSE Loss: 0.5177
Validation loss decreased (0.239385 --> 0.239201).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 26.7876701
	speed: 0.0175s/iter; left time: 351.0199s
	iters: 200, epoch: 5 | loss: 25.9833660
	speed: 0.0148s/iter; left time: 296.4028s
Epoch: 5 cost time: 3.4094271659851074
Epoch: 5, Steps: 210 Train Loss: 26.2215 (Forecasting Loss:0.4994 + XiCon Loss:2.5722 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.5192
Validation loss decreased (0.239201 --> 0.229528).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 26.7272587
	speed: 0.0178s/iter; left time: 354.0405s
	iters: 200, epoch: 6 | loss: 25.7005920
	speed: 0.0150s/iter; left time: 295.2845s
Epoch: 6 cost time: 3.454716205596924
Epoch: 6, Steps: 210 Train Loss: 25.9689 (Forecasting Loss:0.4939 + XiCon Loss:2.5475 x Lambda(10.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.5222
Validation loss decreased (0.229528 --> 0.227361).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 25.8071613
	speed: 0.0169s/iter; left time: 331.6210s
	iters: 200, epoch: 7 | loss: 26.3327961
	speed: 0.0142s/iter; left time: 277.7162s
Epoch: 7 cost time: 3.289276123046875
Epoch: 7, Steps: 210 Train Loss: 25.9335 (Forecasting Loss:0.4912 + XiCon Loss:2.5442 x Lambda(10.0)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.5183
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 27.6257782
	speed: 0.0174s/iter; left time: 337.7291s
	iters: 200, epoch: 8 | loss: 25.3608208
	speed: 0.0145s/iter; left time: 279.6988s
Epoch: 8 cost time: 3.3600871562957764
Epoch: 8, Steps: 210 Train Loss: 25.7821 (Forecasting Loss:0.4903 + XiCon Loss:2.5292 x Lambda(10.0)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.5186
Validation loss decreased (0.227361 --> 0.225207).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 26.8873978
	speed: 0.0171s/iter; left time: 328.6365s
	iters: 200, epoch: 9 | loss: 27.2735653
	speed: 0.0146s/iter; left time: 278.6631s
Epoch: 9 cost time: 3.3452064990997314
Epoch: 9, Steps: 210 Train Loss: 25.8170 (Forecasting Loss:0.4897 + XiCon Loss:2.5327 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.5181
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 26.2577591
	speed: 0.0171s/iter; left time: 325.7998s
	iters: 200, epoch: 10 | loss: 25.8416119
	speed: 0.0146s/iter; left time: 276.4288s
Epoch: 10 cost time: 3.3496100902557373
Epoch: 10, Steps: 210 Train Loss: 25.8227 (Forecasting Loss:0.4893 + XiCon Loss:2.5333 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5186
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 26.3037357
	speed: 0.0170s/iter; left time: 319.3281s
	iters: 200, epoch: 11 | loss: 26.0215225
	speed: 0.0151s/iter; left time: 282.7730s
Epoch: 11 cost time: 3.3959388732910156
Epoch: 11, Steps: 210 Train Loss: 25.8566 (Forecasting Loss:0.4891 + XiCon Loss:2.5368 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5184
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 25.4861622
	speed: 0.0170s/iter; left time: 316.2326s
	iters: 200, epoch: 12 | loss: 26.3863049
	speed: 0.0142s/iter; left time: 263.0876s
Epoch: 12 cost time: 3.2976009845733643
Epoch: 12, Steps: 210 Train Loss: 25.8013 (Forecasting Loss:0.4889 + XiCon Loss:2.5312 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.5186
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 26.4681301
	speed: 0.0169s/iter; left time: 310.0122s
	iters: 200, epoch: 13 | loss: 26.2592793
	speed: 0.0148s/iter; left time: 271.1901s
Epoch: 13 cost time: 3.3586597442626953
Epoch: 13, Steps: 210 Train Loss: 25.7569 (Forecasting Loss:0.4889 + XiCon Loss:2.5268 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5187
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 26.9219418
	speed: 0.0178s/iter; left time: 324.0044s
	iters: 200, epoch: 14 | loss: 26.5118465
	speed: 0.0148s/iter; left time: 267.5882s
Epoch: 14 cost time: 3.446920394897461
Epoch: 14, Steps: 210 Train Loss: 25.8184 (Forecasting Loss:0.4889 + XiCon Loss:2.5330 x Lambda(10.0)), Vali MSE Loss: 0.2257 Test MSE Loss: 0.5187
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 26.2091904
	speed: 0.0173s/iter; left time: 310.5177s
	iters: 200, epoch: 15 | loss: 25.5644226
	speed: 0.0147s/iter; left time: 262.1427s
Epoch: 15 cost time: 3.3687667846679688
Epoch: 15, Steps: 210 Train Loss: 25.7865 (Forecasting Loss:0.4889 + XiCon Loss:2.5298 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5187
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 25.4207268
	speed: 0.0171s/iter; left time: 303.3276s
	iters: 200, epoch: 16 | loss: 25.1274071
	speed: 0.0149s/iter; left time: 263.7674s
Epoch: 16 cost time: 3.3866894245147705
Epoch: 16, Steps: 210 Train Loss: 25.7868 (Forecasting Loss:0.4891 + XiCon Loss:2.5298 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5187
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 25.9883919
	speed: 0.0167s/iter; left time: 293.0993s
	iters: 200, epoch: 17 | loss: 25.4244194
	speed: 0.0144s/iter; left time: 251.9384s
Epoch: 17 cost time: 3.318084478378296
Epoch: 17, Steps: 210 Train Loss: 25.7876 (Forecasting Loss:0.4887 + XiCon Loss:2.5299 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.5188
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 25.2119751
	speed: 0.0169s/iter; left time: 293.5183s
	iters: 200, epoch: 18 | loss: 26.3182678
	speed: 0.0143s/iter; left time: 246.5598s
Epoch: 18 cost time: 3.307507276535034
Epoch: 18, Steps: 210 Train Loss: 25.8319 (Forecasting Loss:0.4888 + XiCon Loss:2.5343 x Lambda(10.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.5188
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.4902888238430023, mae:0.5468447208404541, mape:3.583906412124634, mspe:8663.490234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.5021
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 27.6259670
	speed: 0.0171s/iter; left time: 357.7653s
	iters: 200, epoch: 1 | loss: 27.1137486
	speed: 0.0142s/iter; left time: 294.6011s
Epoch: 1 cost time: 3.2982630729675293
Epoch: 1, Steps: 210 Train Loss: 27.3771 (Forecasting Loss:0.8258 + XiCon Loss:2.6551 x Lambda(10.0)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.6210
Validation loss decreased (inf --> 0.274722).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 26.4487743
	speed: 0.0188s/iter; left time: 389.2495s
	iters: 200, epoch: 2 | loss: 27.3079700
	speed: 0.0163s/iter; left time: 335.5662s
Epoch: 2 cost time: 3.711000919342041
Epoch: 2, Steps: 210 Train Loss: 26.6021 (Forecasting Loss:0.6897 + XiCon Loss:2.5912 x Lambda(10.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.6123
Validation loss decreased (0.274722 --> 0.243564).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 26.9004841
	speed: 0.0188s/iter; left time: 385.7032s
	iters: 200, epoch: 3 | loss: 27.7303696
	speed: 0.0169s/iter; left time: 344.3034s
Epoch: 3 cost time: 3.7750933170318604
Epoch: 3, Steps: 210 Train Loss: 26.8243 (Forecasting Loss:0.6035 + XiCon Loss:2.6221 x Lambda(10.0)), Vali MSE Loss: 0.2411 Test MSE Loss: 0.5610
Validation loss decreased (0.243564 --> 0.241089).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 26.2322884
	speed: 0.0197s/iter; left time: 400.0680s
	iters: 200, epoch: 4 | loss: 25.6915207
	speed: 0.0168s/iter; left time: 339.0156s
Epoch: 4 cost time: 3.8567557334899902
Epoch: 4, Steps: 210 Train Loss: 26.4972 (Forecasting Loss:0.5605 + XiCon Loss:2.5937 x Lambda(10.0)), Vali MSE Loss: 0.2370 Test MSE Loss: 0.5358
Validation loss decreased (0.241089 --> 0.236992).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 25.7033939
	speed: 0.0190s/iter; left time: 381.1187s
	iters: 200, epoch: 5 | loss: 26.0403366
	speed: 0.0164s/iter; left time: 326.4677s
Epoch: 5 cost time: 3.736853837966919
Epoch: 5, Steps: 210 Train Loss: 26.3571 (Forecasting Loss:0.5365 + XiCon Loss:2.5821 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.5172
Validation loss decreased (0.236992 --> 0.235285).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 27.1835518
	speed: 0.0187s/iter; left time: 371.9766s
	iters: 200, epoch: 6 | loss: 26.4804516
	speed: 0.0174s/iter; left time: 343.1488s
Epoch: 6 cost time: 3.8312251567840576
Epoch: 6, Steps: 210 Train Loss: 26.2458 (Forecasting Loss:0.5273 + XiCon Loss:2.5719 x Lambda(10.0)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.5145
Validation loss decreased (0.235285 --> 0.234738).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 25.4919891
	speed: 0.0197s/iter; left time: 386.2618s
	iters: 200, epoch: 7 | loss: 27.6336479
	speed: 0.0165s/iter; left time: 323.3115s
Epoch: 7 cost time: 3.845156669616699
Epoch: 7, Steps: 210 Train Loss: 26.2688 (Forecasting Loss:0.5224 + XiCon Loss:2.5746 x Lambda(10.0)), Vali MSE Loss: 0.2344 Test MSE Loss: 0.5107
Validation loss decreased (0.234738 --> 0.234441).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 25.1588802
	speed: 0.0191s/iter; left time: 370.3039s
	iters: 200, epoch: 8 | loss: 27.1840172
	speed: 0.0166s/iter; left time: 321.5043s
Epoch: 8 cost time: 3.7736475467681885
Epoch: 8, Steps: 210 Train Loss: 26.1620 (Forecasting Loss:0.5197 + XiCon Loss:2.5642 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.5114
Validation loss decreased (0.234441 --> 0.232295).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 26.0812664
	speed: 0.0192s/iter; left time: 370.0002s
	iters: 200, epoch: 9 | loss: 26.3092842
	speed: 0.0170s/iter; left time: 325.6860s
Epoch: 9 cost time: 3.8271472454071045
Epoch: 9, Steps: 210 Train Loss: 26.1997 (Forecasting Loss:0.5188 + XiCon Loss:2.5681 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.5110
Validation loss decreased (0.232295 --> 0.232146).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 27.1755085
	speed: 0.0190s/iter; left time: 360.6419s
	iters: 200, epoch: 10 | loss: 26.2687817
	speed: 0.0164s/iter; left time: 310.7831s
Epoch: 10 cost time: 3.744274139404297
Epoch: 10, Steps: 210 Train Loss: 26.3048 (Forecasting Loss:0.5174 + XiCon Loss:2.5787 x Lambda(10.0)), Vali MSE Loss: 0.2327 Test MSE Loss: 0.5109
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 25.7899475
	speed: 0.0189s/iter; left time: 355.8592s
	iters: 200, epoch: 11 | loss: 26.4644337
	speed: 0.0163s/iter; left time: 304.4336s
Epoch: 11 cost time: 3.7201709747314453
Epoch: 11, Steps: 210 Train Loss: 26.2389 (Forecasting Loss:0.5177 + XiCon Loss:2.5721 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 26.2351608
	speed: 0.0188s/iter; left time: 348.5869s
	iters: 200, epoch: 12 | loss: 25.3989944
	speed: 0.0165s/iter; left time: 305.0195s
Epoch: 12 cost time: 3.747518539428711
Epoch: 12, Steps: 210 Train Loss: 26.2703 (Forecasting Loss:0.5172 + XiCon Loss:2.5753 x Lambda(10.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.5110
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 26.4569721
	speed: 0.0189s/iter; left time: 347.4131s
	iters: 200, epoch: 13 | loss: 26.9520092
	speed: 0.0165s/iter; left time: 301.6390s
Epoch: 13 cost time: 3.739267349243164
Epoch: 13, Steps: 210 Train Loss: 26.1737 (Forecasting Loss:0.5172 + XiCon Loss:2.5656 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.5110
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 25.6889420
	speed: 0.0192s/iter; left time: 348.2130s
	iters: 200, epoch: 14 | loss: 25.1797447
	speed: 0.0163s/iter; left time: 293.7935s
Epoch: 14 cost time: 3.737006425857544
Epoch: 14, Steps: 210 Train Loss: 26.2483 (Forecasting Loss:0.5169 + XiCon Loss:2.5731 x Lambda(10.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.5110
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 27.9291229
	speed: 0.0192s/iter; left time: 345.4200s
	iters: 200, epoch: 15 | loss: 25.9654694
	speed: 0.0167s/iter; left time: 298.5010s
Epoch: 15 cost time: 3.79008150100708
Epoch: 15, Steps: 210 Train Loss: 26.2246 (Forecasting Loss:0.5170 + XiCon Loss:2.5708 x Lambda(10.0)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.5110
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 27.2429714
	speed: 0.0190s/iter; left time: 338.1208s
	iters: 200, epoch: 16 | loss: 27.3009529
	speed: 0.0165s/iter; left time: 290.8933s
Epoch: 16 cost time: 3.753384828567505
Epoch: 16, Steps: 210 Train Loss: 26.2259 (Forecasting Loss:0.5170 + XiCon Loss:2.5709 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.5110
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 26.9014931
	speed: 0.0188s/iter; left time: 329.9241s
	iters: 200, epoch: 17 | loss: 25.4828510
	speed: 0.0168s/iter; left time: 292.5998s
Epoch: 17 cost time: 3.756784439086914
Epoch: 17, Steps: 210 Train Loss: 26.2068 (Forecasting Loss:0.5168 + XiCon Loss:2.5690 x Lambda(10.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.5110
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 26.5303078
	speed: 0.0189s/iter; left time: 326.7729s
	iters: 200, epoch: 18 | loss: 25.4450111
	speed: 0.0165s/iter; left time: 284.6966s
Epoch: 18 cost time: 3.739691734313965
Epoch: 18, Steps: 210 Train Loss: 26.1786 (Forecasting Loss:0.5172 + XiCon Loss:2.5661 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.5110
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 26.8249283
	speed: 0.0190s/iter; left time: 324.7456s
	iters: 200, epoch: 19 | loss: 26.3463440
	speed: 0.0166s/iter; left time: 282.0656s
Epoch: 19 cost time: 3.750575304031372
Epoch: 19, Steps: 210 Train Loss: 26.2743 (Forecasting Loss:0.5169 + XiCon Loss:2.5757 x Lambda(10.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.5110
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.4845086336135864, mae:0.537566602230072, mape:3.9670751094818115, mspe:21547.015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5032+-0.02907, MAE:0.5507+-0.01710, MAPE:3.7645+-0.30286, MSPE:14079.8574+-9034.23448, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
