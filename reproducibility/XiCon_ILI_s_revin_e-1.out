Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2675
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 1.0156807899475098
Epoch: 1, Steps: 38 Train Loss: 0.5808 (Forecasting Loss:0.4201 + XiCon Loss:1.6070 x Lambda(0.1)), Vali MSE Loss: 0.2634 Test MSE Loss: 1.0801
Validation loss decreased (inf --> 0.263412).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.8156874179840088
Epoch: 2, Steps: 38 Train Loss: 0.4090 (Forecasting Loss:0.2493 + XiCon Loss:1.5970 x Lambda(0.1)), Vali MSE Loss: 0.1512 Test MSE Loss: 0.6130
Validation loss decreased (0.263412 --> 0.151237).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7118098735809326
Epoch: 3, Steps: 38 Train Loss: 0.3142 (Forecasting Loss:0.1581 + XiCon Loss:1.5607 x Lambda(0.1)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6179
Validation loss decreased (0.151237 --> 0.115348).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8145179748535156
Epoch: 4, Steps: 38 Train Loss: 0.2832 (Forecasting Loss:0.1316 + XiCon Loss:1.5164 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.6384
Validation loss decreased (0.115348 --> 0.107534).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7413375377655029
Epoch: 5, Steps: 38 Train Loss: 0.2747 (Forecasting Loss:0.1263 + XiCon Loss:1.4842 x Lambda(0.1)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.6559
Validation loss decreased (0.107534 --> 0.105029).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7892565727233887
Epoch: 6, Steps: 38 Train Loss: 0.2708 (Forecasting Loss:0.1222 + XiCon Loss:1.4854 x Lambda(0.1)), Vali MSE Loss: 0.1045 Test MSE Loss: 0.6386
Validation loss decreased (0.105029 --> 0.104471).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7102437019348145
Epoch: 7, Steps: 38 Train Loss: 0.2690 (Forecasting Loss:0.1210 + XiCon Loss:1.4799 x Lambda(0.1)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6446
Validation loss decreased (0.104471 --> 0.103809).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7036910057067871
Epoch: 8, Steps: 38 Train Loss: 0.2663 (Forecasting Loss:0.1193 + XiCon Loss:1.4701 x Lambda(0.1)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6467
Validation loss decreased (0.103809 --> 0.103793).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7979280948638916
Epoch: 9, Steps: 38 Train Loss: 0.2676 (Forecasting Loss:0.1196 + XiCon Loss:1.4803 x Lambda(0.1)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6473
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7323691844940186
Epoch: 10, Steps: 38 Train Loss: 0.2655 (Forecasting Loss:0.1192 + XiCon Loss:1.4631 x Lambda(0.1)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6470
Validation loss decreased (0.103793 --> 0.103731).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7032637596130371
Epoch: 11, Steps: 38 Train Loss: 0.2657 (Forecasting Loss:0.1187 + XiCon Loss:1.4702 x Lambda(0.1)), Vali MSE Loss: 0.1027 Test MSE Loss: 0.6463
Validation loss decreased (0.103731 --> 0.102684).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.705651044845581
Epoch: 12, Steps: 38 Train Loss: 0.2659 (Forecasting Loss:0.1185 + XiCon Loss:1.4745 x Lambda(0.1)), Vali MSE Loss: 0.1030 Test MSE Loss: 0.6463
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.858823299407959
Epoch: 13, Steps: 38 Train Loss: 0.2656 (Forecasting Loss:0.1192 + XiCon Loss:1.4642 x Lambda(0.1)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6464
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6849446296691895
Epoch: 14, Steps: 38 Train Loss: 0.2658 (Forecasting Loss:0.1191 + XiCon Loss:1.4673 x Lambda(0.1)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6464
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6203913688659668
Epoch: 15, Steps: 38 Train Loss: 0.2661 (Forecasting Loss:0.1189 + XiCon Loss:1.4723 x Lambda(0.1)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6464
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6720759868621826
Epoch: 16, Steps: 38 Train Loss: 0.2674 (Forecasting Loss:0.1192 + XiCon Loss:1.4823 x Lambda(0.1)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6464
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.718785285949707
Epoch: 17, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1188 + XiCon Loss:1.4791 x Lambda(0.1)), Vali MSE Loss: 0.1035 Test MSE Loss: 0.6464
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6497843265533447
Epoch: 18, Steps: 38 Train Loss: 0.2650 (Forecasting Loss:0.1180 + XiCon Loss:1.4694 x Lambda(0.1)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6464
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6301243305206299
Epoch: 19, Steps: 38 Train Loss: 0.2650 (Forecasting Loss:0.1181 + XiCon Loss:1.4689 x Lambda(0.1)), Vali MSE Loss: 0.1035 Test MSE Loss: 0.6464
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6481876373291016
Epoch: 20, Steps: 38 Train Loss: 0.2648 (Forecasting Loss:0.1187 + XiCon Loss:1.4614 x Lambda(0.1)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6464
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7030990123748779
Epoch: 21, Steps: 38 Train Loss: 0.2665 (Forecasting Loss:0.1190 + XiCon Loss:1.4754 x Lambda(0.1)), Vali MSE Loss: 0.1034 Test MSE Loss: 0.6464
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.7195349931716919, mae:0.5729713439941406, mape:0.2216794639825821, mspe:0.186721071600914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3454
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7281904220581055
Epoch: 1, Steps: 38 Train Loss: 0.6437 (Forecasting Loss:0.4826 + XiCon Loss:1.6111 x Lambda(0.1)), Vali MSE Loss: 0.2959 Test MSE Loss: 1.2481
Validation loss decreased (inf --> 0.295917).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7480268478393555
Epoch: 2, Steps: 38 Train Loss: 0.4246 (Forecasting Loss:0.2653 + XiCon Loss:1.5926 x Lambda(0.1)), Vali MSE Loss: 0.1534 Test MSE Loss: 0.6386
Validation loss decreased (0.295917 --> 0.153422).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.8172945976257324
Epoch: 3, Steps: 38 Train Loss: 0.3160 (Forecasting Loss:0.1606 + XiCon Loss:1.5537 x Lambda(0.1)), Vali MSE Loss: 0.1172 Test MSE Loss: 0.6117
Validation loss decreased (0.153422 --> 0.117199).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.716256856918335
Epoch: 4, Steps: 38 Train Loss: 0.2841 (Forecasting Loss:0.1346 + XiCon Loss:1.4957 x Lambda(0.1)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.6201
Validation loss decreased (0.117199 --> 0.107856).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6967742443084717
Epoch: 5, Steps: 38 Train Loss: 0.2755 (Forecasting Loss:0.1281 + XiCon Loss:1.4745 x Lambda(0.1)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6074
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7506511211395264
Epoch: 6, Steps: 38 Train Loss: 0.2709 (Forecasting Loss:0.1250 + XiCon Loss:1.4583 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.6009
Validation loss decreased (0.107856 --> 0.107428).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6414508819580078
Epoch: 7, Steps: 38 Train Loss: 0.2690 (Forecasting Loss:0.1239 + XiCon Loss:1.4515 x Lambda(0.1)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.6079
Validation loss decreased (0.107428 --> 0.107318).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7290973663330078
Epoch: 8, Steps: 38 Train Loss: 0.2688 (Forecasting Loss:0.1237 + XiCon Loss:1.4512 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6060
Validation loss decreased (0.107318 --> 0.107149).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7003793716430664
Epoch: 9, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1217 + XiCon Loss:1.4503 x Lambda(0.1)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6057
Validation loss decreased (0.107149 --> 0.106468).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7350928783416748
Epoch: 10, Steps: 38 Train Loss: 0.2670 (Forecasting Loss:0.1219 + XiCon Loss:1.4518 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6061
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.776771068572998
Epoch: 11, Steps: 38 Train Loss: 0.2672 (Forecasting Loss:0.1229 + XiCon Loss:1.4428 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.6060
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6981344223022461
Epoch: 12, Steps: 38 Train Loss: 0.2664 (Forecasting Loss:0.1217 + XiCon Loss:1.4463 x Lambda(0.1)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6061
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.8489961624145508
Epoch: 13, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1221 + XiCon Loss:1.4458 x Lambda(0.1)), Vali MSE Loss: 0.1067 Test MSE Loss: 0.6060
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7973835468292236
Epoch: 14, Steps: 38 Train Loss: 0.2668 (Forecasting Loss:0.1222 + XiCon Loss:1.4457 x Lambda(0.1)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6060
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6967778205871582
Epoch: 15, Steps: 38 Train Loss: 0.2653 (Forecasting Loss:0.1217 + XiCon Loss:1.4366 x Lambda(0.1)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.6060
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7490599155426025
Epoch: 16, Steps: 38 Train Loss: 0.2666 (Forecasting Loss:0.1220 + XiCon Loss:1.4468 x Lambda(0.1)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.6060
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7587809562683105
Epoch: 17, Steps: 38 Train Loss: 0.2666 (Forecasting Loss:0.1226 + XiCon Loss:1.4403 x Lambda(0.1)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.6060
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7245705127716064
Epoch: 18, Steps: 38 Train Loss: 0.2672 (Forecasting Loss:0.1227 + XiCon Loss:1.4448 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6060
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7422695159912109
Epoch: 19, Steps: 38 Train Loss: 0.2658 (Forecasting Loss:0.1222 + XiCon Loss:1.4360 x Lambda(0.1)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.6060
Validation loss decreased (0.106468 --> 0.106156).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7227473258972168
Epoch: 20, Steps: 38 Train Loss: 0.2669 (Forecasting Loss:0.1221 + XiCon Loss:1.4477 x Lambda(0.1)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.6060
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7517440319061279
Epoch: 21, Steps: 38 Train Loss: 0.2659 (Forecasting Loss:0.1220 + XiCon Loss:1.4395 x Lambda(0.1)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6060
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6872360706329346
Epoch: 22, Steps: 38 Train Loss: 0.2673 (Forecasting Loss:0.1223 + XiCon Loss:1.4504 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6060
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6788640022277832
Epoch: 23, Steps: 38 Train Loss: 0.2657 (Forecasting Loss:0.1210 + XiCon Loss:1.4468 x Lambda(0.1)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.6060
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7561805248260498
Epoch: 24, Steps: 38 Train Loss: 0.2676 (Forecasting Loss:0.1224 + XiCon Loss:1.4520 x Lambda(0.1)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.6060
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7546219825744629
Epoch: 25, Steps: 38 Train Loss: 0.2673 (Forecasting Loss:0.1226 + XiCon Loss:1.4466 x Lambda(0.1)), Vali MSE Loss: 0.1067 Test MSE Loss: 0.6060
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7704839706420898
Epoch: 26, Steps: 38 Train Loss: 0.2674 (Forecasting Loss:0.1225 + XiCon Loss:1.4483 x Lambda(0.1)), Vali MSE Loss: 0.1066 Test MSE Loss: 0.6060
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7060935497283936
Epoch: 27, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1227 + XiCon Loss:1.4407 x Lambda(0.1)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6060
Validation loss decreased (0.106156 --> 0.105927).  Saving model ...
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.6868789196014404
Epoch: 28, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1228 + XiCon Loss:1.4398 x Lambda(0.1)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.6060
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.642845630645752
Epoch: 29, Steps: 38 Train Loss: 0.2666 (Forecasting Loss:0.1227 + XiCon Loss:1.4383 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6060
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7694272994995117
Epoch: 30, Steps: 38 Train Loss: 0.2671 (Forecasting Loss:0.1225 + XiCon Loss:1.4461 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6060
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7647433280944824
Epoch: 31, Steps: 38 Train Loss: 0.2665 (Forecasting Loss:0.1217 + XiCon Loss:1.4483 x Lambda(0.1)), Vali MSE Loss: 0.1067 Test MSE Loss: 0.6060
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.713341474533081
Epoch: 32, Steps: 38 Train Loss: 0.2677 (Forecasting Loss:0.1216 + XiCon Loss:1.4608 x Lambda(0.1)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6060
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.7227845191955566
Epoch: 33, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1226 + XiCon Loss:1.4412 x Lambda(0.1)), Vali MSE Loss: 0.1066 Test MSE Loss: 0.6060
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.7636902332305908
Epoch: 34, Steps: 38 Train Loss: 0.2674 (Forecasting Loss:0.1224 + XiCon Loss:1.4494 x Lambda(0.1)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.6060
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.7660987377166748
Epoch: 35, Steps: 38 Train Loss: 0.2669 (Forecasting Loss:0.1222 + XiCon Loss:1.4468 x Lambda(0.1)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.6060
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.752124547958374
Epoch: 36, Steps: 38 Train Loss: 0.2668 (Forecasting Loss:0.1223 + XiCon Loss:1.4453 x Lambda(0.1)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6060
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.7151710987091064
Epoch: 37, Steps: 38 Train Loss: 0.2674 (Forecasting Loss:0.1224 + XiCon Loss:1.4503 x Lambda(0.1)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.6060
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6640828251838684, mae:0.5479652285575867, mape:0.2139454185962677, mspe:0.1837751269340515 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3698
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.746478796005249
Epoch: 1, Steps: 38 Train Loss: 0.5745 (Forecasting Loss:0.4149 + XiCon Loss:1.5954 x Lambda(0.1)), Vali MSE Loss: 0.2488 Test MSE Loss: 1.0542
Validation loss decreased (inf --> 0.248833).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7241261005401611
Epoch: 2, Steps: 38 Train Loss: 0.4289 (Forecasting Loss:0.2695 + XiCon Loss:1.5936 x Lambda(0.1)), Vali MSE Loss: 0.1532 Test MSE Loss: 0.5750
Validation loss decreased (0.248833 --> 0.153245).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7272779941558838
Epoch: 3, Steps: 38 Train Loss: 0.3155 (Forecasting Loss:0.1548 + XiCon Loss:1.6068 x Lambda(0.1)), Vali MSE Loss: 0.1092 Test MSE Loss: 0.6138
Validation loss decreased (0.153245 --> 0.109162).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7185935974121094
Epoch: 4, Steps: 38 Train Loss: 0.2863 (Forecasting Loss:0.1322 + XiCon Loss:1.5412 x Lambda(0.1)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5903
Validation loss decreased (0.109162 --> 0.104162).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.653892993927002
Epoch: 5, Steps: 38 Train Loss: 0.2761 (Forecasting Loss:0.1259 + XiCon Loss:1.5021 x Lambda(0.1)), Vali MSE Loss: 0.1021 Test MSE Loss: 0.5935
Validation loss decreased (0.104162 --> 0.102115).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7339482307434082
Epoch: 6, Steps: 38 Train Loss: 0.2728 (Forecasting Loss:0.1238 + XiCon Loss:1.4904 x Lambda(0.1)), Vali MSE Loss: 0.1016 Test MSE Loss: 0.5895
Validation loss decreased (0.102115 --> 0.101628).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7185840606689453
Epoch: 7, Steps: 38 Train Loss: 0.2717 (Forecasting Loss:0.1231 + XiCon Loss:1.4859 x Lambda(0.1)), Vali MSE Loss: 0.1012 Test MSE Loss: 0.5913
Validation loss decreased (0.101628 --> 0.101163).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7039809226989746
Epoch: 8, Steps: 38 Train Loss: 0.2697 (Forecasting Loss:0.1214 + XiCon Loss:1.4831 x Lambda(0.1)), Vali MSE Loss: 0.1007 Test MSE Loss: 0.5908
Validation loss decreased (0.101163 --> 0.100684).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7669117450714111
Epoch: 9, Steps: 38 Train Loss: 0.2705 (Forecasting Loss:0.1224 + XiCon Loss:1.4813 x Lambda(0.1)), Vali MSE Loss: 0.1014 Test MSE Loss: 0.5890
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6110222339630127
Epoch: 10, Steps: 38 Train Loss: 0.2699 (Forecasting Loss:0.1214 + XiCon Loss:1.4853 x Lambda(0.1)), Vali MSE Loss: 0.1007 Test MSE Loss: 0.5897
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6777856349945068
Epoch: 11, Steps: 38 Train Loss: 0.2712 (Forecasting Loss:0.1217 + XiCon Loss:1.4958 x Lambda(0.1)), Vali MSE Loss: 0.1011 Test MSE Loss: 0.5898
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7111160755157471
Epoch: 12, Steps: 38 Train Loss: 0.2707 (Forecasting Loss:0.1215 + XiCon Loss:1.4919 x Lambda(0.1)), Vali MSE Loss: 0.1013 Test MSE Loss: 0.5898
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6555073261260986
Epoch: 13, Steps: 38 Train Loss: 0.2692 (Forecasting Loss:0.1207 + XiCon Loss:1.4846 x Lambda(0.1)), Vali MSE Loss: 0.1008 Test MSE Loss: 0.5898
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7346241474151611
Epoch: 14, Steps: 38 Train Loss: 0.2711 (Forecasting Loss:0.1215 + XiCon Loss:1.4956 x Lambda(0.1)), Vali MSE Loss: 0.1011 Test MSE Loss: 0.5897
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6968472003936768
Epoch: 15, Steps: 38 Train Loss: 0.2708 (Forecasting Loss:0.1218 + XiCon Loss:1.4900 x Lambda(0.1)), Vali MSE Loss: 0.1005 Test MSE Loss: 0.5897
Validation loss decreased (0.100684 --> 0.100539).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6831874847412109
Epoch: 16, Steps: 38 Train Loss: 0.2699 (Forecasting Loss:0.1209 + XiCon Loss:1.4897 x Lambda(0.1)), Vali MSE Loss: 0.1012 Test MSE Loss: 0.5897
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7250292301177979
Epoch: 17, Steps: 38 Train Loss: 0.2684 (Forecasting Loss:0.1203 + XiCon Loss:1.4806 x Lambda(0.1)), Vali MSE Loss: 0.1010 Test MSE Loss: 0.5897
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6647789478302002
Epoch: 18, Steps: 38 Train Loss: 0.2689 (Forecasting Loss:0.1207 + XiCon Loss:1.4820 x Lambda(0.1)), Vali MSE Loss: 0.1010 Test MSE Loss: 0.5897
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7456274032592773
Epoch: 19, Steps: 38 Train Loss: 0.2697 (Forecasting Loss:0.1215 + XiCon Loss:1.4815 x Lambda(0.1)), Vali MSE Loss: 0.1000 Test MSE Loss: 0.5897
Validation loss decreased (0.100539 --> 0.100013).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7366609573364258
Epoch: 20, Steps: 38 Train Loss: 0.2692 (Forecasting Loss:0.1214 + XiCon Loss:1.4779 x Lambda(0.1)), Vali MSE Loss: 0.1009 Test MSE Loss: 0.5897
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.700505256652832
Epoch: 21, Steps: 38 Train Loss: 0.2701 (Forecasting Loss:0.1209 + XiCon Loss:1.4917 x Lambda(0.1)), Vali MSE Loss: 0.1012 Test MSE Loss: 0.5897
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7712743282318115
Epoch: 22, Steps: 38 Train Loss: 0.2687 (Forecasting Loss:0.1207 + XiCon Loss:1.4799 x Lambda(0.1)), Vali MSE Loss: 0.1011 Test MSE Loss: 0.5897
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7040205001831055
Epoch: 23, Steps: 38 Train Loss: 0.2688 (Forecasting Loss:0.1206 + XiCon Loss:1.4815 x Lambda(0.1)), Vali MSE Loss: 0.1010 Test MSE Loss: 0.5897
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6960117816925049
Epoch: 24, Steps: 38 Train Loss: 0.2680 (Forecasting Loss:0.1200 + XiCon Loss:1.4800 x Lambda(0.1)), Vali MSE Loss: 0.1004 Test MSE Loss: 0.5897
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6587123870849609
Epoch: 25, Steps: 38 Train Loss: 0.2688 (Forecasting Loss:0.1203 + XiCon Loss:1.4847 x Lambda(0.1)), Vali MSE Loss: 0.1010 Test MSE Loss: 0.5897
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6796481609344482
Epoch: 26, Steps: 38 Train Loss: 0.2681 (Forecasting Loss:0.1201 + XiCon Loss:1.4795 x Lambda(0.1)), Vali MSE Loss: 0.1008 Test MSE Loss: 0.5897
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.701838493347168
Epoch: 27, Steps: 38 Train Loss: 0.2686 (Forecasting Loss:0.1216 + XiCon Loss:1.4700 x Lambda(0.1)), Vali MSE Loss: 0.1009 Test MSE Loss: 0.5897
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.8276715278625488
Epoch: 28, Steps: 38 Train Loss: 0.2694 (Forecasting Loss:0.1213 + XiCon Loss:1.4813 x Lambda(0.1)), Vali MSE Loss: 0.1013 Test MSE Loss: 0.5897
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7088346481323242
Epoch: 29, Steps: 38 Train Loss: 0.2698 (Forecasting Loss:0.1216 + XiCon Loss:1.4822 x Lambda(0.1)), Vali MSE Loss: 0.1008 Test MSE Loss: 0.5897
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6378493905067444, mae:0.5416427254676819, mape:0.21164041757583618, mspe:0.1795475333929062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7449748516082764
Epoch: 1, Steps: 38 Train Loss: 0.6333 (Forecasting Loss:0.4721 + XiCon Loss:1.6116 x Lambda(0.1)), Vali MSE Loss: 0.2902 Test MSE Loss: 1.2790
Validation loss decreased (inf --> 0.290208).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.702796220779419
Epoch: 2, Steps: 38 Train Loss: 0.4194 (Forecasting Loss:0.2609 + XiCon Loss:1.5848 x Lambda(0.1)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.6161
Validation loss decreased (0.290208 --> 0.182632).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7292912006378174
Epoch: 3, Steps: 38 Train Loss: 0.3226 (Forecasting Loss:0.1668 + XiCon Loss:1.5586 x Lambda(0.1)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.6135
Validation loss decreased (0.182632 --> 0.121201).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7048885822296143
Epoch: 4, Steps: 38 Train Loss: 0.2863 (Forecasting Loss:0.1375 + XiCon Loss:1.4884 x Lambda(0.1)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.6154
Validation loss decreased (0.121201 --> 0.114390).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7013378143310547
Epoch: 5, Steps: 38 Train Loss: 0.2782 (Forecasting Loss:0.1305 + XiCon Loss:1.4769 x Lambda(0.1)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.6256
Validation loss decreased (0.114390 --> 0.111644).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7160892486572266
Epoch: 6, Steps: 38 Train Loss: 0.2752 (Forecasting Loss:0.1281 + XiCon Loss:1.4710 x Lambda(0.1)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6254
Validation loss decreased (0.111644 --> 0.110763).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7121987342834473
Epoch: 7, Steps: 38 Train Loss: 0.2741 (Forecasting Loss:0.1270 + XiCon Loss:1.4706 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6258
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7220642566680908
Epoch: 8, Steps: 38 Train Loss: 0.2726 (Forecasting Loss:0.1254 + XiCon Loss:1.4723 x Lambda(0.1)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6247
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7245416641235352
Epoch: 9, Steps: 38 Train Loss: 0.2718 (Forecasting Loss:0.1253 + XiCon Loss:1.4645 x Lambda(0.1)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6246
Validation loss decreased (0.110763 --> 0.110347).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7485346794128418
Epoch: 10, Steps: 38 Train Loss: 0.2719 (Forecasting Loss:0.1252 + XiCon Loss:1.4668 x Lambda(0.1)), Vali MSE Loss: 0.1101 Test MSE Loss: 0.6256
Validation loss decreased (0.110347 --> 0.110077).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.713494062423706
Epoch: 11, Steps: 38 Train Loss: 0.2721 (Forecasting Loss:0.1249 + XiCon Loss:1.4719 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6256
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6759169101715088
Epoch: 12, Steps: 38 Train Loss: 0.2706 (Forecasting Loss:0.1239 + XiCon Loss:1.4671 x Lambda(0.1)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.6257
Validation loss decreased (0.110077 --> 0.110004).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6965911388397217
Epoch: 13, Steps: 38 Train Loss: 0.2713 (Forecasting Loss:0.1249 + XiCon Loss:1.4643 x Lambda(0.1)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6258
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7196094989776611
Epoch: 14, Steps: 38 Train Loss: 0.2723 (Forecasting Loss:0.1256 + XiCon Loss:1.4667 x Lambda(0.1)), Vali MSE Loss: 0.1106 Test MSE Loss: 0.6258
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7473149299621582
Epoch: 15, Steps: 38 Train Loss: 0.2728 (Forecasting Loss:0.1252 + XiCon Loss:1.4768 x Lambda(0.1)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6259
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7463583946228027
Epoch: 16, Steps: 38 Train Loss: 0.2710 (Forecasting Loss:0.1246 + XiCon Loss:1.4638 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.76043701171875
Epoch: 17, Steps: 38 Train Loss: 0.2719 (Forecasting Loss:0.1252 + XiCon Loss:1.4674 x Lambda(0.1)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.6259
Validation loss decreased (0.110004 --> 0.109841).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7520756721496582
Epoch: 18, Steps: 38 Train Loss: 0.2727 (Forecasting Loss:0.1249 + XiCon Loss:1.4781 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6578798294067383
Epoch: 19, Steps: 38 Train Loss: 0.2717 (Forecasting Loss:0.1247 + XiCon Loss:1.4702 x Lambda(0.1)), Vali MSE Loss: 0.1106 Test MSE Loss: 0.6259
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6669437885284424
Epoch: 20, Steps: 38 Train Loss: 0.2712 (Forecasting Loss:0.1248 + XiCon Loss:1.4639 x Lambda(0.1)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6259
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7474226951599121
Epoch: 21, Steps: 38 Train Loss: 0.2703 (Forecasting Loss:0.1241 + XiCon Loss:1.4629 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6566085815429688
Epoch: 22, Steps: 38 Train Loss: 0.2707 (Forecasting Loss:0.1241 + XiCon Loss:1.4653 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6362907886505127
Epoch: 23, Steps: 38 Train Loss: 0.2718 (Forecasting Loss:0.1247 + XiCon Loss:1.4710 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6791439056396484
Epoch: 24, Steps: 38 Train Loss: 0.2720 (Forecasting Loss:0.1251 + XiCon Loss:1.4689 x Lambda(0.1)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6259
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6633527278900146
Epoch: 25, Steps: 38 Train Loss: 0.2715 (Forecasting Loss:0.1247 + XiCon Loss:1.4679 x Lambda(0.1)), Vali MSE Loss: 0.1106 Test MSE Loss: 0.6259
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7082452774047852
Epoch: 26, Steps: 38 Train Loss: 0.2703 (Forecasting Loss:0.1241 + XiCon Loss:1.4622 x Lambda(0.1)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6259
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7017548084259033
Epoch: 27, Steps: 38 Train Loss: 0.2707 (Forecasting Loss:0.1249 + XiCon Loss:1.4583 x Lambda(0.1)), Vali MSE Loss: 0.1099 Test MSE Loss: 0.6259
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6895463466644287, mae:0.5621843338012695, mape:0.2186516374349594, mspe:0.18793052434921265 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3473
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7010085582733154
Epoch: 1, Steps: 38 Train Loss: 0.5892 (Forecasting Loss:0.4284 + XiCon Loss:1.6079 x Lambda(0.1)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.8962
Validation loss decreased (inf --> 0.282666).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6813247203826904
Epoch: 2, Steps: 38 Train Loss: 0.4411 (Forecasting Loss:0.2818 + XiCon Loss:1.5929 x Lambda(0.1)), Vali MSE Loss: 0.1794 Test MSE Loss: 0.6192
Validation loss decreased (0.282666 --> 0.179377).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7048375606536865
Epoch: 3, Steps: 38 Train Loss: 0.3144 (Forecasting Loss:0.1560 + XiCon Loss:1.5841 x Lambda(0.1)), Vali MSE Loss: 0.1250 Test MSE Loss: 0.6241
Validation loss decreased (0.179377 --> 0.125014).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7392289638519287
Epoch: 4, Steps: 38 Train Loss: 0.2837 (Forecasting Loss:0.1272 + XiCon Loss:1.5651 x Lambda(0.1)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6302
Validation loss decreased (0.125014 --> 0.117268).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6565160751342773
Epoch: 5, Steps: 38 Train Loss: 0.2748 (Forecasting Loss:0.1194 + XiCon Loss:1.5540 x Lambda(0.1)), Vali MSE Loss: 0.1186 Test MSE Loss: 0.6124
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7506997585296631
Epoch: 6, Steps: 38 Train Loss: 0.2715 (Forecasting Loss:0.1167 + XiCon Loss:1.5481 x Lambda(0.1)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6128
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7546184062957764
Epoch: 7, Steps: 38 Train Loss: 0.2688 (Forecasting Loss:0.1142 + XiCon Loss:1.5457 x Lambda(0.1)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6159
Validation loss decreased (0.117268 --> 0.116534).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.707850456237793
Epoch: 8, Steps: 38 Train Loss: 0.2677 (Forecasting Loss:0.1130 + XiCon Loss:1.5472 x Lambda(0.1)), Vali MSE Loss: 0.1184 Test MSE Loss: 0.6103
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7172868251800537
Epoch: 9, Steps: 38 Train Loss: 0.2668 (Forecasting Loss:0.1124 + XiCon Loss:1.5436 x Lambda(0.1)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6110
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6417126655578613
Epoch: 10, Steps: 38 Train Loss: 0.2673 (Forecasting Loss:0.1130 + XiCon Loss:1.5429 x Lambda(0.1)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6110
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6979832649230957
Epoch: 11, Steps: 38 Train Loss: 0.2666 (Forecasting Loss:0.1125 + XiCon Loss:1.5406 x Lambda(0.1)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6110
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7425084114074707
Epoch: 12, Steps: 38 Train Loss: 0.2672 (Forecasting Loss:0.1127 + XiCon Loss:1.5448 x Lambda(0.1)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6109
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7985196113586426
Epoch: 13, Steps: 38 Train Loss: 0.2660 (Forecasting Loss:0.1123 + XiCon Loss:1.5374 x Lambda(0.1)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6109
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7131979465484619
Epoch: 14, Steps: 38 Train Loss: 0.2660 (Forecasting Loss:0.1117 + XiCon Loss:1.5433 x Lambda(0.1)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6109
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7240884304046631
Epoch: 15, Steps: 38 Train Loss: 0.2676 (Forecasting Loss:0.1127 + XiCon Loss:1.5487 x Lambda(0.1)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6109
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6959552764892578
Epoch: 16, Steps: 38 Train Loss: 0.2658 (Forecasting Loss:0.1115 + XiCon Loss:1.5438 x Lambda(0.1)), Vali MSE Loss: 0.1180 Test MSE Loss: 0.6109
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7650647163391113
Epoch: 17, Steps: 38 Train Loss: 0.2667 (Forecasting Loss:0.1121 + XiCon Loss:1.5461 x Lambda(0.1)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6109
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6811731457710266, mae:0.5505425333976746, mape:0.21597115695476532, mspe:0.19665969908237457 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6784+-0.03763, MAE:0.5551+-0.01549, MAPE:0.2164+-0.00488, MSPE:0.1869+-0.00786, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3023
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.9049708843231201
Epoch: 1, Steps: 37 Train Loss: 0.6525 (Forecasting Loss:0.4912 + XiCon Loss:1.6128 x Lambda(0.1)), Vali MSE Loss: 0.3080 Test MSE Loss: 1.2637
Validation loss decreased (inf --> 0.307962).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7113080024719238
Epoch: 2, Steps: 37 Train Loss: 0.4539 (Forecasting Loss:0.2931 + XiCon Loss:1.6077 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.6873
Validation loss decreased (0.307962 --> 0.182313).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7680201530456543
Epoch: 3, Steps: 37 Train Loss: 0.3473 (Forecasting Loss:0.1896 + XiCon Loss:1.5774 x Lambda(0.1)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6586
Validation loss decreased (0.182313 --> 0.130680).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6442267894744873
Epoch: 4, Steps: 37 Train Loss: 0.3055 (Forecasting Loss:0.1501 + XiCon Loss:1.5538 x Lambda(0.1)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6844
Validation loss decreased (0.130680 --> 0.115883).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7174892425537109
Epoch: 5, Steps: 37 Train Loss: 0.2952 (Forecasting Loss:0.1424 + XiCon Loss:1.5275 x Lambda(0.1)), Vali MSE Loss: 0.1171 Test MSE Loss: 0.6608
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.726933479309082
Epoch: 6, Steps: 37 Train Loss: 0.2901 (Forecasting Loss:0.1390 + XiCon Loss:1.5103 x Lambda(0.1)), Vali MSE Loss: 0.1171 Test MSE Loss: 0.6657
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6474001407623291
Epoch: 7, Steps: 37 Train Loss: 0.2866 (Forecasting Loss:0.1365 + XiCon Loss:1.5002 x Lambda(0.1)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6729
Validation loss decreased (0.115883 --> 0.113063).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7069597244262695
Epoch: 8, Steps: 37 Train Loss: 0.2881 (Forecasting Loss:0.1369 + XiCon Loss:1.5117 x Lambda(0.1)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6713
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7973189353942871
Epoch: 9, Steps: 37 Train Loss: 0.2849 (Forecasting Loss:0.1355 + XiCon Loss:1.4941 x Lambda(0.1)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6692
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.702582836151123
Epoch: 10, Steps: 37 Train Loss: 0.2862 (Forecasting Loss:0.1358 + XiCon Loss:1.5040 x Lambda(0.1)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6698
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7117574214935303
Epoch: 11, Steps: 37 Train Loss: 0.2852 (Forecasting Loss:0.1355 + XiCon Loss:1.4968 x Lambda(0.1)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6698
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7177426815032959
Epoch: 12, Steps: 37 Train Loss: 0.2857 (Forecasting Loss:0.1360 + XiCon Loss:1.4970 x Lambda(0.1)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6697
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6548671722412109
Epoch: 13, Steps: 37 Train Loss: 0.2846 (Forecasting Loss:0.1349 + XiCon Loss:1.4970 x Lambda(0.1)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6698
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6621966361999512
Epoch: 14, Steps: 37 Train Loss: 0.2862 (Forecasting Loss:0.1353 + XiCon Loss:1.5091 x Lambda(0.1)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6699
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.748828649520874
Epoch: 15, Steps: 37 Train Loss: 0.2859 (Forecasting Loss:0.1356 + XiCon Loss:1.5024 x Lambda(0.1)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6699
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7515857219696045
Epoch: 16, Steps: 37 Train Loss: 0.2850 (Forecasting Loss:0.1343 + XiCon Loss:1.5068 x Lambda(0.1)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6699
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7646689414978027
Epoch: 17, Steps: 37 Train Loss: 0.2841 (Forecasting Loss:0.1343 + XiCon Loss:1.4983 x Lambda(0.1)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6699
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7293615937232971, mae:0.6163697242736816, mape:0.24149364233016968, mspe:0.20079508423805237 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3285
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.711688756942749
Epoch: 1, Steps: 37 Train Loss: 0.6668 (Forecasting Loss:0.5052 + XiCon Loss:1.6164 x Lambda(0.1)), Vali MSE Loss: 0.2756 Test MSE Loss: 1.0645
Validation loss decreased (inf --> 0.275599).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7234091758728027
Epoch: 2, Steps: 37 Train Loss: 0.4729 (Forecasting Loss:0.3108 + XiCon Loss:1.6209 x Lambda(0.1)), Vali MSE Loss: 0.1746 Test MSE Loss: 0.6821
Validation loss decreased (0.275599 --> 0.174612).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6820473670959473
Epoch: 3, Steps: 37 Train Loss: 0.3412 (Forecasting Loss:0.1785 + XiCon Loss:1.6271 x Lambda(0.1)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.6929
Validation loss decreased (0.174612 --> 0.131498).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7004032135009766
Epoch: 4, Steps: 37 Train Loss: 0.3104 (Forecasting Loss:0.1495 + XiCon Loss:1.6089 x Lambda(0.1)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6494
Validation loss decreased (0.131498 --> 0.126289).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7268893718719482
Epoch: 5, Steps: 37 Train Loss: 0.3034 (Forecasting Loss:0.1433 + XiCon Loss:1.6010 x Lambda(0.1)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6829
Validation loss decreased (0.126289 --> 0.118143).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7482781410217285
Epoch: 6, Steps: 37 Train Loss: 0.2992 (Forecasting Loss:0.1394 + XiCon Loss:1.5978 x Lambda(0.1)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6775
Validation loss decreased (0.118143 --> 0.116172).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7067463397979736
Epoch: 7, Steps: 37 Train Loss: 0.2971 (Forecasting Loss:0.1376 + XiCon Loss:1.5952 x Lambda(0.1)), Vali MSE Loss: 0.1188 Test MSE Loss: 0.6758
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7242236137390137
Epoch: 8, Steps: 37 Train Loss: 0.2963 (Forecasting Loss:0.1370 + XiCon Loss:1.5926 x Lambda(0.1)), Vali MSE Loss: 0.1190 Test MSE Loss: 0.6737
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6751964092254639
Epoch: 9, Steps: 37 Train Loss: 0.2958 (Forecasting Loss:0.1365 + XiCon Loss:1.5922 x Lambda(0.1)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6743
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7267293930053711
Epoch: 10, Steps: 37 Train Loss: 0.2969 (Forecasting Loss:0.1369 + XiCon Loss:1.5995 x Lambda(0.1)), Vali MSE Loss: 0.1192 Test MSE Loss: 0.6761
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6204750537872314
Epoch: 11, Steps: 37 Train Loss: 0.2969 (Forecasting Loss:0.1377 + XiCon Loss:1.5921 x Lambda(0.1)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6754
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7465720176696777
Epoch: 12, Steps: 37 Train Loss: 0.2937 (Forecasting Loss:0.1355 + XiCon Loss:1.5822 x Lambda(0.1)), Vali MSE Loss: 0.1188 Test MSE Loss: 0.6756
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7796390056610107
Epoch: 13, Steps: 37 Train Loss: 0.2957 (Forecasting Loss:0.1366 + XiCon Loss:1.5914 x Lambda(0.1)), Vali MSE Loss: 0.1188 Test MSE Loss: 0.6755
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.682121753692627
Epoch: 14, Steps: 37 Train Loss: 0.2963 (Forecasting Loss:0.1364 + XiCon Loss:1.5998 x Lambda(0.1)), Vali MSE Loss: 0.1197 Test MSE Loss: 0.6755
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6643862724304199
Epoch: 15, Steps: 37 Train Loss: 0.2942 (Forecasting Loss:0.1349 + XiCon Loss:1.5925 x Lambda(0.1)), Vali MSE Loss: 0.1186 Test MSE Loss: 0.6755
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7721524238586426
Epoch: 16, Steps: 37 Train Loss: 0.2949 (Forecasting Loss:0.1359 + XiCon Loss:1.5900 x Lambda(0.1)), Vali MSE Loss: 0.1194 Test MSE Loss: 0.6755
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.731933057308197, mae:0.6229779124259949, mape:0.24634498357772827, mspe:0.2066313624382019 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3143
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7344808578491211
Epoch: 1, Steps: 37 Train Loss: 0.7139 (Forecasting Loss:0.5526 + XiCon Loss:1.6128 x Lambda(0.1)), Vali MSE Loss: 0.3276 Test MSE Loss: 1.3474
Validation loss decreased (inf --> 0.327635).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7449910640716553
Epoch: 2, Steps: 37 Train Loss: 0.4724 (Forecasting Loss:0.3124 + XiCon Loss:1.6006 x Lambda(0.1)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.6970
Validation loss decreased (0.327635 --> 0.173741).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6543247699737549
Epoch: 3, Steps: 37 Train Loss: 0.3416 (Forecasting Loss:0.1832 + XiCon Loss:1.5841 x Lambda(0.1)), Vali MSE Loss: 0.1352 Test MSE Loss: 0.7088
Validation loss decreased (0.173741 --> 0.135214).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6279730796813965
Epoch: 4, Steps: 37 Train Loss: 0.3076 (Forecasting Loss:0.1508 + XiCon Loss:1.5675 x Lambda(0.1)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6721
Validation loss decreased (0.135214 --> 0.124915).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6925177574157715
Epoch: 5, Steps: 37 Train Loss: 0.2969 (Forecasting Loss:0.1411 + XiCon Loss:1.5579 x Lambda(0.1)), Vali MSE Loss: 0.1252 Test MSE Loss: 0.6806
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7998976707458496
Epoch: 6, Steps: 37 Train Loss: 0.2922 (Forecasting Loss:0.1371 + XiCon Loss:1.5512 x Lambda(0.1)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.6789
Validation loss decreased (0.124915 --> 0.123537).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7394258975982666
Epoch: 7, Steps: 37 Train Loss: 0.2906 (Forecasting Loss:0.1354 + XiCon Loss:1.5515 x Lambda(0.1)), Vali MSE Loss: 0.1225 Test MSE Loss: 0.6905
Validation loss decreased (0.123537 --> 0.122476).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7177438735961914
Epoch: 8, Steps: 37 Train Loss: 0.2882 (Forecasting Loss:0.1343 + XiCon Loss:1.5388 x Lambda(0.1)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.6899
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6967971324920654
Epoch: 9, Steps: 37 Train Loss: 0.2883 (Forecasting Loss:0.1333 + XiCon Loss:1.5501 x Lambda(0.1)), Vali MSE Loss: 0.1229 Test MSE Loss: 0.6872
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7362644672393799
Epoch: 10, Steps: 37 Train Loss: 0.2870 (Forecasting Loss:0.1328 + XiCon Loss:1.5421 x Lambda(0.1)), Vali MSE Loss: 0.1219 Test MSE Loss: 0.6863
Validation loss decreased (0.122476 --> 0.121854).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7035441398620605
Epoch: 11, Steps: 37 Train Loss: 0.2875 (Forecasting Loss:0.1335 + XiCon Loss:1.5404 x Lambda(0.1)), Vali MSE Loss: 0.1227 Test MSE Loss: 0.6863
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6730551719665527
Epoch: 12, Steps: 37 Train Loss: 0.2869 (Forecasting Loss:0.1330 + XiCon Loss:1.5386 x Lambda(0.1)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.6863
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6618402004241943
Epoch: 13, Steps: 37 Train Loss: 0.2872 (Forecasting Loss:0.1332 + XiCon Loss:1.5403 x Lambda(0.1)), Vali MSE Loss: 0.1241 Test MSE Loss: 0.6862
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7252130508422852
Epoch: 14, Steps: 37 Train Loss: 0.2873 (Forecasting Loss:0.1330 + XiCon Loss:1.5432 x Lambda(0.1)), Vali MSE Loss: 0.1237 Test MSE Loss: 0.6862
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6934206485748291
Epoch: 15, Steps: 37 Train Loss: 0.2863 (Forecasting Loss:0.1320 + XiCon Loss:1.5424 x Lambda(0.1)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.6862
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6739625930786133
Epoch: 16, Steps: 37 Train Loss: 0.2865 (Forecasting Loss:0.1328 + XiCon Loss:1.5371 x Lambda(0.1)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.6862
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7204527854919434
Epoch: 17, Steps: 37 Train Loss: 0.2869 (Forecasting Loss:0.1327 + XiCon Loss:1.5421 x Lambda(0.1)), Vali MSE Loss: 0.1229 Test MSE Loss: 0.6862
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7245194911956787
Epoch: 18, Steps: 37 Train Loss: 0.2863 (Forecasting Loss:0.1331 + XiCon Loss:1.5314 x Lambda(0.1)), Vali MSE Loss: 0.1246 Test MSE Loss: 0.6862
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6520295143127441
Epoch: 19, Steps: 37 Train Loss: 0.2864 (Forecasting Loss:0.1327 + XiCon Loss:1.5374 x Lambda(0.1)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.6862
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7062485218048096
Epoch: 20, Steps: 37 Train Loss: 0.2868 (Forecasting Loss:0.1330 + XiCon Loss:1.5378 x Lambda(0.1)), Vali MSE Loss: 0.1228 Test MSE Loss: 0.6862
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7480716705322266, mae:0.6245738863945007, mape:0.247826486825943, mspe:0.21735438704490662 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3448
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7460720539093018
Epoch: 1, Steps: 37 Train Loss: 0.6535 (Forecasting Loss:0.4928 + XiCon Loss:1.6061 x Lambda(0.1)), Vali MSE Loss: 0.3159 Test MSE Loss: 1.2690
Validation loss decreased (inf --> 0.315888).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7443332672119141
Epoch: 2, Steps: 37 Train Loss: 0.4571 (Forecasting Loss:0.2975 + XiCon Loss:1.5964 x Lambda(0.1)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.6979
Validation loss decreased (0.315888 --> 0.173558).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7442765235900879
Epoch: 3, Steps: 37 Train Loss: 0.3437 (Forecasting Loss:0.1851 + XiCon Loss:1.5859 x Lambda(0.1)), Vali MSE Loss: 0.1288 Test MSE Loss: 0.7145
Validation loss decreased (0.173558 --> 0.128773).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6927907466888428
Epoch: 4, Steps: 37 Train Loss: 0.3083 (Forecasting Loss:0.1504 + XiCon Loss:1.5785 x Lambda(0.1)), Vali MSE Loss: 0.1261 Test MSE Loss: 0.6401
Validation loss decreased (0.128773 --> 0.126088).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6907837390899658
Epoch: 5, Steps: 37 Train Loss: 0.3010 (Forecasting Loss:0.1449 + XiCon Loss:1.5609 x Lambda(0.1)), Vali MSE Loss: 0.1250 Test MSE Loss: 0.6469
Validation loss decreased (0.126088 --> 0.125007).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6646780967712402
Epoch: 6, Steps: 37 Train Loss: 0.2976 (Forecasting Loss:0.1417 + XiCon Loss:1.5594 x Lambda(0.1)), Vali MSE Loss: 0.1224 Test MSE Loss: 0.6569
Validation loss decreased (0.125007 --> 0.122433).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6901805400848389
Epoch: 7, Steps: 37 Train Loss: 0.2948 (Forecasting Loss:0.1393 + XiCon Loss:1.5543 x Lambda(0.1)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.6520
Validation loss decreased (0.122433 --> 0.121639).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7141151428222656
Epoch: 8, Steps: 37 Train Loss: 0.2947 (Forecasting Loss:0.1392 + XiCon Loss:1.5544 x Lambda(0.1)), Vali MSE Loss: 0.1227 Test MSE Loss: 0.6523
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6824007034301758
Epoch: 9, Steps: 37 Train Loss: 0.2943 (Forecasting Loss:0.1392 + XiCon Loss:1.5510 x Lambda(0.1)), Vali MSE Loss: 0.1223 Test MSE Loss: 0.6528
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7202584743499756
Epoch: 10, Steps: 37 Train Loss: 0.2936 (Forecasting Loss:0.1387 + XiCon Loss:1.5488 x Lambda(0.1)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.6520
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6650998592376709
Epoch: 11, Steps: 37 Train Loss: 0.2945 (Forecasting Loss:0.1389 + XiCon Loss:1.5562 x Lambda(0.1)), Vali MSE Loss: 0.1219 Test MSE Loss: 0.6520
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6777048110961914
Epoch: 12, Steps: 37 Train Loss: 0.2929 (Forecasting Loss:0.1381 + XiCon Loss:1.5482 x Lambda(0.1)), Vali MSE Loss: 0.1218 Test MSE Loss: 0.6522
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6185760498046875
Epoch: 13, Steps: 37 Train Loss: 0.2941 (Forecasting Loss:0.1387 + XiCon Loss:1.5545 x Lambda(0.1)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.6522
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6198709011077881
Epoch: 14, Steps: 37 Train Loss: 0.2950 (Forecasting Loss:0.1388 + XiCon Loss:1.5626 x Lambda(0.1)), Vali MSE Loss: 0.1213 Test MSE Loss: 0.6522
Validation loss decreased (0.121639 --> 0.121255).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.642263650894165
Epoch: 15, Steps: 37 Train Loss: 0.2921 (Forecasting Loss:0.1374 + XiCon Loss:1.5468 x Lambda(0.1)), Vali MSE Loss: 0.1222 Test MSE Loss: 0.6522
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6538732051849365
Epoch: 16, Steps: 37 Train Loss: 0.2933 (Forecasting Loss:0.1376 + XiCon Loss:1.5576 x Lambda(0.1)), Vali MSE Loss: 0.1242 Test MSE Loss: 0.6522
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6278209686279297
Epoch: 17, Steps: 37 Train Loss: 0.2942 (Forecasting Loss:0.1388 + XiCon Loss:1.5534 x Lambda(0.1)), Vali MSE Loss: 0.1247 Test MSE Loss: 0.6522
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6851992607116699
Epoch: 18, Steps: 37 Train Loss: 0.2929 (Forecasting Loss:0.1385 + XiCon Loss:1.5436 x Lambda(0.1)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.6522
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7325026988983154
Epoch: 19, Steps: 37 Train Loss: 0.2932 (Forecasting Loss:0.1382 + XiCon Loss:1.5503 x Lambda(0.1)), Vali MSE Loss: 0.1240 Test MSE Loss: 0.6522
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6438405513763428
Epoch: 20, Steps: 37 Train Loss: 0.2927 (Forecasting Loss:0.1380 + XiCon Loss:1.5470 x Lambda(0.1)), Vali MSE Loss: 0.1238 Test MSE Loss: 0.6522
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6441237926483154
Epoch: 21, Steps: 37 Train Loss: 0.2936 (Forecasting Loss:0.1389 + XiCon Loss:1.5475 x Lambda(0.1)), Vali MSE Loss: 0.1237 Test MSE Loss: 0.6522
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6385378837585449
Epoch: 22, Steps: 37 Train Loss: 0.2931 (Forecasting Loss:0.1387 + XiCon Loss:1.5437 x Lambda(0.1)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.6522
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7594850063323975
Epoch: 23, Steps: 37 Train Loss: 0.2940 (Forecasting Loss:0.1391 + XiCon Loss:1.5486 x Lambda(0.1)), Vali MSE Loss: 0.1240 Test MSE Loss: 0.6522
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7890803813934326
Epoch: 24, Steps: 37 Train Loss: 0.2935 (Forecasting Loss:0.1383 + XiCon Loss:1.5519 x Lambda(0.1)), Vali MSE Loss: 0.1230 Test MSE Loss: 0.6522
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7059674859046936, mae:0.598344087600708, mape:0.24094879627227783, mspe:0.21215687692165375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2907
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6529636383056641
Epoch: 1, Steps: 37 Train Loss: 0.6525 (Forecasting Loss:0.4904 + XiCon Loss:1.6207 x Lambda(0.1)), Vali MSE Loss: 0.2996 Test MSE Loss: 1.2818
Validation loss decreased (inf --> 0.299597).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 1.432056188583374
Epoch: 2, Steps: 37 Train Loss: 0.4457 (Forecasting Loss:0.2840 + XiCon Loss:1.6169 x Lambda(0.1)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.6551
Validation loss decreased (0.299597 --> 0.166485).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 1.5940983295440674
Epoch: 3, Steps: 37 Train Loss: 0.3309 (Forecasting Loss:0.1710 + XiCon Loss:1.5996 x Lambda(0.1)), Vali MSE Loss: 0.1264 Test MSE Loss: 0.7711
Validation loss decreased (0.166485 --> 0.126402).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 1.5770769119262695
Epoch: 4, Steps: 37 Train Loss: 0.3015 (Forecasting Loss:0.1442 + XiCon Loss:1.5733 x Lambda(0.1)), Vali MSE Loss: 0.1230 Test MSE Loss: 0.7648
Validation loss decreased (0.126402 --> 0.122969).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 1.5224418640136719
Epoch: 5, Steps: 37 Train Loss: 0.2900 (Forecasting Loss:0.1359 + XiCon Loss:1.5409 x Lambda(0.1)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.7429
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.9216005802154541
Epoch: 6, Steps: 37 Train Loss: 0.2853 (Forecasting Loss:0.1328 + XiCon Loss:1.5251 x Lambda(0.1)), Vali MSE Loss: 0.1239 Test MSE Loss: 0.7584
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 1.0391058921813965
Epoch: 7, Steps: 37 Train Loss: 0.2832 (Forecasting Loss:0.1307 + XiCon Loss:1.5251 x Lambda(0.1)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.7448
Validation loss decreased (0.122969 --> 0.122086).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.9741787910461426
Epoch: 8, Steps: 37 Train Loss: 0.2816 (Forecasting Loss:0.1298 + XiCon Loss:1.5184 x Lambda(0.1)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.7548
Validation loss decreased (0.122086 --> 0.121639).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.9497780799865723
Epoch: 9, Steps: 37 Train Loss: 0.2804 (Forecasting Loss:0.1283 + XiCon Loss:1.5201 x Lambda(0.1)), Vali MSE Loss: 0.1211 Test MSE Loss: 0.7596
Validation loss decreased (0.121639 --> 0.121084).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.9667482376098633
Epoch: 10, Steps: 37 Train Loss: 0.2807 (Forecasting Loss:0.1291 + XiCon Loss:1.5157 x Lambda(0.1)), Vali MSE Loss: 0.1215 Test MSE Loss: 0.7599
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.9448051452636719
Epoch: 11, Steps: 37 Train Loss: 0.2802 (Forecasting Loss:0.1292 + XiCon Loss:1.5103 x Lambda(0.1)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.7599
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.9471862316131592
Epoch: 12, Steps: 37 Train Loss: 0.2788 (Forecasting Loss:0.1283 + XiCon Loss:1.5057 x Lambda(0.1)), Vali MSE Loss: 0.1222 Test MSE Loss: 0.7610
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.9213075637817383
Epoch: 13, Steps: 37 Train Loss: 0.2812 (Forecasting Loss:0.1285 + XiCon Loss:1.5265 x Lambda(0.1)), Vali MSE Loss: 0.1208 Test MSE Loss: 0.7616
Validation loss decreased (0.121084 --> 0.120824).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.9471616744995117
Epoch: 14, Steps: 37 Train Loss: 0.2805 (Forecasting Loss:0.1289 + XiCon Loss:1.5167 x Lambda(0.1)), Vali MSE Loss: 0.1225 Test MSE Loss: 0.7616
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.937584638595581
Epoch: 15, Steps: 37 Train Loss: 0.2796 (Forecasting Loss:0.1284 + XiCon Loss:1.5117 x Lambda(0.1)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.7615
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.953460693359375
Epoch: 16, Steps: 37 Train Loss: 0.2814 (Forecasting Loss:0.1290 + XiCon Loss:1.5237 x Lambda(0.1)), Vali MSE Loss: 0.1210 Test MSE Loss: 0.7615
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.9396581649780273
Epoch: 17, Steps: 37 Train Loss: 0.2806 (Forecasting Loss:0.1285 + XiCon Loss:1.5215 x Lambda(0.1)), Vali MSE Loss: 0.1218 Test MSE Loss: 0.7615
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.9150271415710449
Epoch: 18, Steps: 37 Train Loss: 0.2783 (Forecasting Loss:0.1280 + XiCon Loss:1.5036 x Lambda(0.1)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.7615
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.9202573299407959
Epoch: 19, Steps: 37 Train Loss: 0.2799 (Forecasting Loss:0.1275 + XiCon Loss:1.5245 x Lambda(0.1)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.7615
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.8948819637298584
Epoch: 20, Steps: 37 Train Loss: 0.2797 (Forecasting Loss:0.1285 + XiCon Loss:1.5116 x Lambda(0.1)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.7615
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.8919284343719482
Epoch: 21, Steps: 37 Train Loss: 0.2801 (Forecasting Loss:0.1287 + XiCon Loss:1.5140 x Lambda(0.1)), Vali MSE Loss: 0.1217 Test MSE Loss: 0.7615
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.8052377700805664
Epoch: 22, Steps: 37 Train Loss: 0.2809 (Forecasting Loss:0.1287 + XiCon Loss:1.5218 x Lambda(0.1)), Vali MSE Loss: 0.1213 Test MSE Loss: 0.7615
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.9149115085601807
Epoch: 23, Steps: 37 Train Loss: 0.2800 (Forecasting Loss:0.1290 + XiCon Loss:1.5099 x Lambda(0.1)), Vali MSE Loss: 0.1229 Test MSE Loss: 0.7615
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.8449611067771912, mae:0.6781622767448425, mape:0.2629711925983429, mspe:0.22232632339000702 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7521+-0.06713, MAE:0.6281+-0.03708, MAPE:0.2479+-0.01109, MSPE:0.2119+-0.01056, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3953
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 1.0631036758422852
Epoch: 1, Steps: 35 Train Loss: 0.6341 (Forecasting Loss:0.4724 + XiCon Loss:1.6172 x Lambda(0.1)), Vali MSE Loss: 0.3108 Test MSE Loss: 1.1643
Validation loss decreased (inf --> 0.310781).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.8388621807098389
Epoch: 2, Steps: 35 Train Loss: 0.4790 (Forecasting Loss:0.3208 + XiCon Loss:1.5816 x Lambda(0.1)), Vali MSE Loss: 0.1825 Test MSE Loss: 0.7322
Validation loss decreased (0.310781 --> 0.182521).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.8650069236755371
Epoch: 3, Steps: 35 Train Loss: 0.3728 (Forecasting Loss:0.2188 + XiCon Loss:1.5407 x Lambda(0.1)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.7032
Validation loss decreased (0.182521 --> 0.145681).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8414139747619629
Epoch: 4, Steps: 35 Train Loss: 0.3367 (Forecasting Loss:0.1877 + XiCon Loss:1.4893 x Lambda(0.1)), Vali MSE Loss: 0.1362 Test MSE Loss: 0.6813
Validation loss decreased (0.145681 --> 0.136202).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.8209953308105469
Epoch: 5, Steps: 35 Train Loss: 0.3227 (Forecasting Loss:0.1746 + XiCon Loss:1.4809 x Lambda(0.1)), Vali MSE Loss: 0.1327 Test MSE Loss: 0.7109
Validation loss decreased (0.136202 --> 0.132713).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7805428504943848
Epoch: 6, Steps: 35 Train Loss: 0.3195 (Forecasting Loss:0.1722 + XiCon Loss:1.4728 x Lambda(0.1)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.6365
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7943613529205322
Epoch: 7, Steps: 35 Train Loss: 0.3156 (Forecasting Loss:0.1685 + XiCon Loss:1.4707 x Lambda(0.1)), Vali MSE Loss: 0.1385 Test MSE Loss: 0.6879
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.8254876136779785
Epoch: 8, Steps: 35 Train Loss: 0.3121 (Forecasting Loss:0.1650 + XiCon Loss:1.4708 x Lambda(0.1)), Vali MSE Loss: 0.1380 Test MSE Loss: 0.6960
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.8293771743774414
Epoch: 9, Steps: 35 Train Loss: 0.3110 (Forecasting Loss:0.1642 + XiCon Loss:1.4681 x Lambda(0.1)), Vali MSE Loss: 0.1400 Test MSE Loss: 0.6937
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8041229248046875
Epoch: 10, Steps: 35 Train Loss: 0.3101 (Forecasting Loss:0.1630 + XiCon Loss:1.4713 x Lambda(0.1)), Vali MSE Loss: 0.1396 Test MSE Loss: 0.6893
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.8099222183227539
Epoch: 11, Steps: 35 Train Loss: 0.3091 (Forecasting Loss:0.1627 + XiCon Loss:1.4634 x Lambda(0.1)), Vali MSE Loss: 0.1408 Test MSE Loss: 0.6902
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.8016369342803955
Epoch: 12, Steps: 35 Train Loss: 0.3089 (Forecasting Loss:0.1619 + XiCon Loss:1.4702 x Lambda(0.1)), Vali MSE Loss: 0.1409 Test MSE Loss: 0.6903
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.8220586776733398
Epoch: 13, Steps: 35 Train Loss: 0.3081 (Forecasting Loss:0.1615 + XiCon Loss:1.4661 x Lambda(0.1)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.6903
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.8210139274597168
Epoch: 14, Steps: 35 Train Loss: 0.3088 (Forecasting Loss:0.1618 + XiCon Loss:1.4700 x Lambda(0.1)), Vali MSE Loss: 0.1394 Test MSE Loss: 0.6905
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7712621688842773
Epoch: 15, Steps: 35 Train Loss: 0.3087 (Forecasting Loss:0.1617 + XiCon Loss:1.4700 x Lambda(0.1)), Vali MSE Loss: 0.1409 Test MSE Loss: 0.6904
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7254841923713684, mae:0.6963608860969543, mape:0.26576554775238037, mspe:0.18094731867313385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4361
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7642049789428711
Epoch: 1, Steps: 35 Train Loss: 0.6107 (Forecasting Loss:0.4482 + XiCon Loss:1.6253 x Lambda(0.1)), Vali MSE Loss: 0.3143 Test MSE Loss: 1.0568
Validation loss decreased (inf --> 0.314292).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.806549072265625
Epoch: 2, Steps: 35 Train Loss: 0.4747 (Forecasting Loss:0.3156 + XiCon Loss:1.5908 x Lambda(0.1)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.7968
Validation loss decreased (0.314292 --> 0.198759).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7248296737670898
Epoch: 3, Steps: 35 Train Loss: 0.3560 (Forecasting Loss:0.2036 + XiCon Loss:1.5244 x Lambda(0.1)), Vali MSE Loss: 0.1812 Test MSE Loss: 0.6874
Validation loss decreased (0.198759 --> 0.181175).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7258908748626709
Epoch: 4, Steps: 35 Train Loss: 0.3067 (Forecasting Loss:0.1596 + XiCon Loss:1.4717 x Lambda(0.1)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.7760
Validation loss decreased (0.181175 --> 0.147462).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6370766162872314
Epoch: 5, Steps: 35 Train Loss: 0.2886 (Forecasting Loss:0.1436 + XiCon Loss:1.4501 x Lambda(0.1)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.8411
Validation loss decreased (0.147462 --> 0.145649).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.645582914352417
Epoch: 6, Steps: 35 Train Loss: 0.2773 (Forecasting Loss:0.1340 + XiCon Loss:1.4329 x Lambda(0.1)), Vali MSE Loss: 0.1558 Test MSE Loss: 0.8049
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.703660249710083
Epoch: 7, Steps: 35 Train Loss: 0.2719 (Forecasting Loss:0.1294 + XiCon Loss:1.4242 x Lambda(0.1)), Vali MSE Loss: 0.1599 Test MSE Loss: 0.7683
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.645557165145874
Epoch: 8, Steps: 35 Train Loss: 0.2684 (Forecasting Loss:0.1264 + XiCon Loss:1.4199 x Lambda(0.1)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.7726
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6158740520477295
Epoch: 9, Steps: 35 Train Loss: 0.2667 (Forecasting Loss:0.1252 + XiCon Loss:1.4147 x Lambda(0.1)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.7919
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8832497596740723
Epoch: 10, Steps: 35 Train Loss: 0.2669 (Forecasting Loss:0.1248 + XiCon Loss:1.4214 x Lambda(0.1)), Vali MSE Loss: 0.1606 Test MSE Loss: 0.7829
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.8150084018707275
Epoch: 11, Steps: 35 Train Loss: 0.2652 (Forecasting Loss:0.1246 + XiCon Loss:1.4060 x Lambda(0.1)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.7799
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7736170291900635
Epoch: 12, Steps: 35 Train Loss: 0.2674 (Forecasting Loss:0.1238 + XiCon Loss:1.4362 x Lambda(0.1)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.7818
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.8631386756896973
Epoch: 13, Steps: 35 Train Loss: 0.2652 (Forecasting Loss:0.1240 + XiCon Loss:1.4110 x Lambda(0.1)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.7824
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.8938214778900146
Epoch: 14, Steps: 35 Train Loss: 0.2660 (Forecasting Loss:0.1241 + XiCon Loss:1.4196 x Lambda(0.1)), Vali MSE Loss: 0.1606 Test MSE Loss: 0.7831
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7981350421905518
Epoch: 15, Steps: 35 Train Loss: 0.2656 (Forecasting Loss:0.1240 + XiCon Loss:1.4165 x Lambda(0.1)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.7830
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.8778194189071655, mae:0.8043650984764099, mape:0.2995785176753998, mspe:0.18594639003276825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3758
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6758241653442383
Epoch: 1, Steps: 35 Train Loss: 0.6431 (Forecasting Loss:0.4825 + XiCon Loss:1.6059 x Lambda(0.1)), Vali MSE Loss: 0.3205 Test MSE Loss: 1.1194
Validation loss decreased (inf --> 0.320500).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.9370532035827637
Epoch: 2, Steps: 35 Train Loss: 0.5312 (Forecasting Loss:0.3693 + XiCon Loss:1.6182 x Lambda(0.1)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.7726
Validation loss decreased (0.320500 --> 0.200440).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7486507892608643
Epoch: 3, Steps: 35 Train Loss: 0.3708 (Forecasting Loss:0.2098 + XiCon Loss:1.6099 x Lambda(0.1)), Vali MSE Loss: 0.1604 Test MSE Loss: 0.7118
Validation loss decreased (0.200440 --> 0.160444).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7516400814056396
Epoch: 4, Steps: 35 Train Loss: 0.3244 (Forecasting Loss:0.1645 + XiCon Loss:1.5992 x Lambda(0.1)), Vali MSE Loss: 0.1537 Test MSE Loss: 0.7164
Validation loss decreased (0.160444 --> 0.153737).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6396944522857666
Epoch: 5, Steps: 35 Train Loss: 0.3105 (Forecasting Loss:0.1515 + XiCon Loss:1.5898 x Lambda(0.1)), Vali MSE Loss: 0.1512 Test MSE Loss: 0.7393
Validation loss decreased (0.153737 --> 0.151233).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6124229431152344
Epoch: 6, Steps: 35 Train Loss: 0.3019 (Forecasting Loss:0.1441 + XiCon Loss:1.5779 x Lambda(0.1)), Vali MSE Loss: 0.1559 Test MSE Loss: 0.6896
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.8966372013092041
Epoch: 7, Steps: 35 Train Loss: 0.2993 (Forecasting Loss:0.1411 + XiCon Loss:1.5824 x Lambda(0.1)), Vali MSE Loss: 0.1538 Test MSE Loss: 0.6843
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.914226770401001
Epoch: 8, Steps: 35 Train Loss: 0.2972 (Forecasting Loss:0.1393 + XiCon Loss:1.5798 x Lambda(0.1)), Vali MSE Loss: 0.1546 Test MSE Loss: 0.7043
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.8811259269714355
Epoch: 9, Steps: 35 Train Loss: 0.2951 (Forecasting Loss:0.1373 + XiCon Loss:1.5778 x Lambda(0.1)), Vali MSE Loss: 0.1556 Test MSE Loss: 0.7002
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8543214797973633
Epoch: 10, Steps: 35 Train Loss: 0.2957 (Forecasting Loss:0.1377 + XiCon Loss:1.5805 x Lambda(0.1)), Vali MSE Loss: 0.1521 Test MSE Loss: 0.6991
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.8969838619232178
Epoch: 11, Steps: 35 Train Loss: 0.2956 (Forecasting Loss:0.1378 + XiCon Loss:1.5789 x Lambda(0.1)), Vali MSE Loss: 0.1545 Test MSE Loss: 0.6964
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7462284564971924
Epoch: 12, Steps: 35 Train Loss: 0.2951 (Forecasting Loss:0.1371 + XiCon Loss:1.5795 x Lambda(0.1)), Vali MSE Loss: 0.1548 Test MSE Loss: 0.6950
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.893744945526123
Epoch: 13, Steps: 35 Train Loss: 0.2954 (Forecasting Loss:0.1372 + XiCon Loss:1.5813 x Lambda(0.1)), Vali MSE Loss: 0.1557 Test MSE Loss: 0.6952
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7948036193847656
Epoch: 14, Steps: 35 Train Loss: 0.2940 (Forecasting Loss:0.1368 + XiCon Loss:1.5719 x Lambda(0.1)), Vali MSE Loss: 0.1544 Test MSE Loss: 0.6954
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.8862686157226562
Epoch: 15, Steps: 35 Train Loss: 0.2954 (Forecasting Loss:0.1372 + XiCon Loss:1.5817 x Lambda(0.1)), Vali MSE Loss: 0.1536 Test MSE Loss: 0.6954
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7689606547355652, mae:0.7095726132392883, mape:0.2618415355682373, mspe:0.1667977273464203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3299
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.8403277397155762
Epoch: 1, Steps: 35 Train Loss: 0.6213 (Forecasting Loss:0.4599 + XiCon Loss:1.6134 x Lambda(0.1)), Vali MSE Loss: 0.3053 Test MSE Loss: 1.2021
Validation loss decreased (inf --> 0.305279).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.8867895603179932
Epoch: 2, Steps: 35 Train Loss: 0.4671 (Forecasting Loss:0.3124 + XiCon Loss:1.5472 x Lambda(0.1)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.9435
Validation loss decreased (0.305279 --> 0.165895).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.8850746154785156
Epoch: 3, Steps: 35 Train Loss: 0.3205 (Forecasting Loss:0.1756 + XiCon Loss:1.4492 x Lambda(0.1)), Vali MSE Loss: 0.1556 Test MSE Loss: 0.7551
Validation loss decreased (0.165895 --> 0.155626).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.898282527923584
Epoch: 4, Steps: 35 Train Loss: 0.2754 (Forecasting Loss:0.1357 + XiCon Loss:1.3972 x Lambda(0.1)), Vali MSE Loss: 0.1519 Test MSE Loss: 0.7435
Validation loss decreased (0.155626 --> 0.151923).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.8801980018615723
Epoch: 5, Steps: 35 Train Loss: 0.2506 (Forecasting Loss:0.1175 + XiCon Loss:1.3318 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.6737
Validation loss decreased (0.151923 --> 0.142400).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.9020729064941406
Epoch: 6, Steps: 35 Train Loss: 0.2417 (Forecasting Loss:0.1122 + XiCon Loss:1.2954 x Lambda(0.1)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.6603
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7966034412384033
Epoch: 7, Steps: 35 Train Loss: 0.2411 (Forecasting Loss:0.1097 + XiCon Loss:1.3134 x Lambda(0.1)), Vali MSE Loss: 0.1524 Test MSE Loss: 0.6888
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6201298236846924
Epoch: 8, Steps: 35 Train Loss: 0.2379 (Forecasting Loss:0.1079 + XiCon Loss:1.3008 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.6948
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5640842914581299
Epoch: 9, Steps: 35 Train Loss: 0.2387 (Forecasting Loss:0.1072 + XiCon Loss:1.3150 x Lambda(0.1)), Vali MSE Loss: 0.1491 Test MSE Loss: 0.6951
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.574282169342041
Epoch: 10, Steps: 35 Train Loss: 0.2349 (Forecasting Loss:0.1067 + XiCon Loss:1.2819 x Lambda(0.1)), Vali MSE Loss: 0.1503 Test MSE Loss: 0.6927
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6309456825256348
Epoch: 11, Steps: 35 Train Loss: 0.2385 (Forecasting Loss:0.1065 + XiCon Loss:1.3200 x Lambda(0.1)), Vali MSE Loss: 0.1488 Test MSE Loss: 0.6909
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6279177665710449
Epoch: 12, Steps: 35 Train Loss: 0.2360 (Forecasting Loss:0.1064 + XiCon Loss:1.2958 x Lambda(0.1)), Vali MSE Loss: 0.1484 Test MSE Loss: 0.6917
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6817030906677246
Epoch: 13, Steps: 35 Train Loss: 0.2360 (Forecasting Loss:0.1065 + XiCon Loss:1.2950 x Lambda(0.1)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.6917
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7669529914855957
Epoch: 14, Steps: 35 Train Loss: 0.2357 (Forecasting Loss:0.1064 + XiCon Loss:1.2922 x Lambda(0.1)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.6920
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6526832580566406
Epoch: 15, Steps: 35 Train Loss: 0.2363 (Forecasting Loss:0.1066 + XiCon Loss:1.2970 x Lambda(0.1)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.6921
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6799680590629578, mae:0.6673524379730225, mape:0.255425363779068, mspe:0.16920974850654602 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3317
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6991612911224365
Epoch: 1, Steps: 35 Train Loss: 0.6358 (Forecasting Loss:0.4745 + XiCon Loss:1.6133 x Lambda(0.1)), Vali MSE Loss: 0.3579 Test MSE Loss: 1.0973
Validation loss decreased (inf --> 0.357922).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6721158027648926
Epoch: 2, Steps: 35 Train Loss: 0.4856 (Forecasting Loss:0.3291 + XiCon Loss:1.5651 x Lambda(0.1)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.7354
Validation loss decreased (0.357922 --> 0.219483).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6865863800048828
Epoch: 3, Steps: 35 Train Loss: 0.3352 (Forecasting Loss:0.1850 + XiCon Loss:1.5029 x Lambda(0.1)), Vali MSE Loss: 0.1496 Test MSE Loss: 0.8476
Validation loss decreased (0.219483 --> 0.149557).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.717775821685791
Epoch: 4, Steps: 35 Train Loss: 0.2973 (Forecasting Loss:0.1525 + XiCon Loss:1.4486 x Lambda(0.1)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.7192
Validation loss decreased (0.149557 --> 0.148098).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6867806911468506
Epoch: 5, Steps: 35 Train Loss: 0.2767 (Forecasting Loss:0.1340 + XiCon Loss:1.4270 x Lambda(0.1)), Vali MSE Loss: 0.1576 Test MSE Loss: 0.6979
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6782093048095703
Epoch: 6, Steps: 35 Train Loss: 0.2688 (Forecasting Loss:0.1282 + XiCon Loss:1.4065 x Lambda(0.1)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.7388
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6291067600250244
Epoch: 7, Steps: 35 Train Loss: 0.2630 (Forecasting Loss:0.1237 + XiCon Loss:1.3926 x Lambda(0.1)), Vali MSE Loss: 0.1600 Test MSE Loss: 0.7493
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6456658840179443
Epoch: 8, Steps: 35 Train Loss: 0.2607 (Forecasting Loss:0.1213 + XiCon Loss:1.3942 x Lambda(0.1)), Vali MSE Loss: 0.1625 Test MSE Loss: 0.7717
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6834323406219482
Epoch: 9, Steps: 35 Train Loss: 0.2577 (Forecasting Loss:0.1203 + XiCon Loss:1.3735 x Lambda(0.1)), Vali MSE Loss: 0.1606 Test MSE Loss: 0.7592
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7073745727539062
Epoch: 10, Steps: 35 Train Loss: 0.2575 (Forecasting Loss:0.1197 + XiCon Loss:1.3782 x Lambda(0.1)), Vali MSE Loss: 0.1599 Test MSE Loss: 0.7642
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6779344081878662
Epoch: 11, Steps: 35 Train Loss: 0.2586 (Forecasting Loss:0.1196 + XiCon Loss:1.3901 x Lambda(0.1)), Vali MSE Loss: 0.1602 Test MSE Loss: 0.7645
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6060950756072998
Epoch: 12, Steps: 35 Train Loss: 0.2571 (Forecasting Loss:0.1193 + XiCon Loss:1.3780 x Lambda(0.1)), Vali MSE Loss: 0.1593 Test MSE Loss: 0.7657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6381027698516846
Epoch: 13, Steps: 35 Train Loss: 0.2580 (Forecasting Loss:0.1194 + XiCon Loss:1.3858 x Lambda(0.1)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.7643
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6547362804412842
Epoch: 14, Steps: 35 Train Loss: 0.2569 (Forecasting Loss:0.1195 + XiCon Loss:1.3743 x Lambda(0.1)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.7644
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7426701784133911, mae:0.6957542896270752, mape:0.2643774747848511, mspe:0.1824798434972763 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7590+-0.09178, MAE:0.7147+-0.06512, MAPE:0.2694+-0.02152, MSPE:0.1771+-0.01058, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.95, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2833
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.840254545211792
Epoch: 1, Steps: 30 Train Loss: 0.7969 (Forecasting Loss:0.6349 + XiCon Loss:1.6195 x Lambda(0.1)), Vali MSE Loss: 0.4252 Test MSE Loss: 1.5884
Validation loss decreased (inf --> 0.425221).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6180357933044434
Epoch: 2, Steps: 30 Train Loss: 0.5838 (Forecasting Loss:0.4274 + XiCon Loss:1.5634 x Lambda(0.1)), Vali MSE Loss: 0.3409 Test MSE Loss: 1.0871
Validation loss decreased (0.425221 --> 0.340942).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.700547456741333
Epoch: 3, Steps: 30 Train Loss: 0.4061 (Forecasting Loss:0.2562 + XiCon Loss:1.4989 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 1.1400
Validation loss decreased (0.340942 --> 0.299178).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.627274751663208
Epoch: 4, Steps: 30 Train Loss: 0.3580 (Forecasting Loss:0.2122 + XiCon Loss:1.4578 x Lambda(0.1)), Vali MSE Loss: 0.3090 Test MSE Loss: 1.1289
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6504783630371094
Epoch: 5, Steps: 30 Train Loss: 0.3321 (Forecasting Loss:0.1894 + XiCon Loss:1.4272 x Lambda(0.1)), Vali MSE Loss: 0.4083 Test MSE Loss: 0.9190
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.593897819519043
Epoch: 6, Steps: 30 Train Loss: 0.3248 (Forecasting Loss:0.1814 + XiCon Loss:1.4338 x Lambda(0.1)), Vali MSE Loss: 0.4031 Test MSE Loss: 0.9026
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5248031616210938
Epoch: 7, Steps: 30 Train Loss: 0.3207 (Forecasting Loss:0.1768 + XiCon Loss:1.4387 x Lambda(0.1)), Vali MSE Loss: 0.3327 Test MSE Loss: 1.0234
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6878035068511963
Epoch: 8, Steps: 30 Train Loss: 0.3166 (Forecasting Loss:0.1726 + XiCon Loss:1.4396 x Lambda(0.1)), Vali MSE Loss: 0.3568 Test MSE Loss: 0.9985
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6468250751495361
Epoch: 9, Steps: 30 Train Loss: 0.3168 (Forecasting Loss:0.1725 + XiCon Loss:1.4431 x Lambda(0.1)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.9995
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6060190200805664
Epoch: 10, Steps: 30 Train Loss: 0.3135 (Forecasting Loss:0.1704 + XiCon Loss:1.4312 x Lambda(0.1)), Vali MSE Loss: 0.3574 Test MSE Loss: 1.0036
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6478714942932129
Epoch: 11, Steps: 30 Train Loss: 0.3147 (Forecasting Loss:0.1713 + XiCon Loss:1.4345 x Lambda(0.1)), Vali MSE Loss: 0.3515 Test MSE Loss: 1.0076
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6063277721405029
Epoch: 12, Steps: 30 Train Loss: 0.3135 (Forecasting Loss:0.1699 + XiCon Loss:1.4361 x Lambda(0.1)), Vali MSE Loss: 0.3520 Test MSE Loss: 1.0045
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6245574951171875
Epoch: 13, Steps: 30 Train Loss: 0.3132 (Forecasting Loss:0.1702 + XiCon Loss:1.4294 x Lambda(0.1)), Vali MSE Loss: 0.3483 Test MSE Loss: 1.0044
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2871450185775757, mae:0.9928250908851624, mape:0.3193764388561249, mspe:0.14001908898353577 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3482
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6516175270080566
Epoch: 1, Steps: 30 Train Loss: 0.7345 (Forecasting Loss:0.5727 + XiCon Loss:1.6184 x Lambda(0.1)), Vali MSE Loss: 0.3361 Test MSE Loss: 1.7708
Validation loss decreased (inf --> 0.336120).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6210906505584717
Epoch: 2, Steps: 30 Train Loss: 0.5632 (Forecasting Loss:0.4047 + XiCon Loss:1.5845 x Lambda(0.1)), Vali MSE Loss: 0.5102 Test MSE Loss: 0.8939
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6208600997924805
Epoch: 3, Steps: 30 Train Loss: 0.3909 (Forecasting Loss:0.2359 + XiCon Loss:1.5497 x Lambda(0.1)), Vali MSE Loss: 0.4501 Test MSE Loss: 0.9546
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6087691783905029
Epoch: 4, Steps: 30 Train Loss: 0.3387 (Forecasting Loss:0.1908 + XiCon Loss:1.4795 x Lambda(0.1)), Vali MSE Loss: 0.2804 Test MSE Loss: 1.1003
Validation loss decreased (0.336120 --> 0.280429).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6514911651611328
Epoch: 5, Steps: 30 Train Loss: 0.3108 (Forecasting Loss:0.1657 + XiCon Loss:1.4509 x Lambda(0.1)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.9245
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6360223293304443
Epoch: 6, Steps: 30 Train Loss: 0.2974 (Forecasting Loss:0.1552 + XiCon Loss:1.4219 x Lambda(0.1)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.9381
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.626025915145874
Epoch: 7, Steps: 30 Train Loss: 0.2916 (Forecasting Loss:0.1494 + XiCon Loss:1.4220 x Lambda(0.1)), Vali MSE Loss: 0.2724 Test MSE Loss: 0.9484
Validation loss decreased (0.280429 --> 0.272450).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6462700366973877
Epoch: 8, Steps: 30 Train Loss: 0.2870 (Forecasting Loss:0.1456 + XiCon Loss:1.4141 x Lambda(0.1)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.9755
Validation loss decreased (0.272450 --> 0.251954).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6067376136779785
Epoch: 9, Steps: 30 Train Loss: 0.2851 (Forecasting Loss:0.1442 + XiCon Loss:1.4082 x Lambda(0.1)), Vali MSE Loss: 0.2672 Test MSE Loss: 0.9445
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6145691871643066
Epoch: 10, Steps: 30 Train Loss: 0.2846 (Forecasting Loss:0.1429 + XiCon Loss:1.4169 x Lambda(0.1)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.9528
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.681004524230957
Epoch: 11, Steps: 30 Train Loss: 0.2837 (Forecasting Loss:0.1418 + XiCon Loss:1.4186 x Lambda(0.1)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.9626
Validation loss decreased (0.251954 --> 0.250412).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6518592834472656
Epoch: 12, Steps: 30 Train Loss: 0.2844 (Forecasting Loss:0.1426 + XiCon Loss:1.4170 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.9574
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6220090389251709
Epoch: 13, Steps: 30 Train Loss: 0.2838 (Forecasting Loss:0.1426 + XiCon Loss:1.4123 x Lambda(0.1)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.9565
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.587017297744751
Epoch: 14, Steps: 30 Train Loss: 0.2846 (Forecasting Loss:0.1423 + XiCon Loss:1.4230 x Lambda(0.1)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.9556
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5936431884765625
Epoch: 15, Steps: 30 Train Loss: 0.2859 (Forecasting Loss:0.1429 + XiCon Loss:1.4303 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.9554
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.5681450366973877
Epoch: 16, Steps: 30 Train Loss: 0.2823 (Forecasting Loss:0.1421 + XiCon Loss:1.4018 x Lambda(0.1)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.9553
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6224493980407715
Epoch: 17, Steps: 30 Train Loss: 0.2853 (Forecasting Loss:0.1431 + XiCon Loss:1.4228 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.9554
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6232974529266357
Epoch: 18, Steps: 30 Train Loss: 0.2851 (Forecasting Loss:0.1430 + XiCon Loss:1.4212 x Lambda(0.1)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.9554
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.560448408126831
Epoch: 19, Steps: 30 Train Loss: 0.2842 (Forecasting Loss:0.1420 + XiCon Loss:1.4219 x Lambda(0.1)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.9554
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.5429911613464355
Epoch: 20, Steps: 30 Train Loss: 0.2839 (Forecasting Loss:0.1423 + XiCon Loss:1.4155 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.9554
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6029131412506104
Epoch: 21, Steps: 30 Train Loss: 0.2844 (Forecasting Loss:0.1428 + XiCon Loss:1.4164 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.9554
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.0393877029418945, mae:0.8858763575553894, mape:0.2923163175582886, mspe:0.1367064118385315 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3315
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6203043460845947
Epoch: 1, Steps: 30 Train Loss: 0.7714 (Forecasting Loss:0.6083 + XiCon Loss:1.6310 x Lambda(0.1)), Vali MSE Loss: 0.3644 Test MSE Loss: 1.7581
Validation loss decreased (inf --> 0.364405).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5477511882781982
Epoch: 2, Steps: 30 Train Loss: 0.5708 (Forecasting Loss:0.4092 + XiCon Loss:1.6155 x Lambda(0.1)), Vali MSE Loss: 0.3130 Test MSE Loss: 1.0086
Validation loss decreased (0.364405 --> 0.312964).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.589613676071167
Epoch: 3, Steps: 30 Train Loss: 0.3941 (Forecasting Loss:0.2345 + XiCon Loss:1.5951 x Lambda(0.1)), Vali MSE Loss: 0.2097 Test MSE Loss: 1.0470
Validation loss decreased (0.312964 --> 0.209656).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5896365642547607
Epoch: 4, Steps: 30 Train Loss: 0.3239 (Forecasting Loss:0.1691 + XiCon Loss:1.5475 x Lambda(0.1)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.8916
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6153719425201416
Epoch: 5, Steps: 30 Train Loss: 0.2942 (Forecasting Loss:0.1443 + XiCon Loss:1.4996 x Lambda(0.1)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.9540
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6148815155029297
Epoch: 6, Steps: 30 Train Loss: 0.2802 (Forecasting Loss:0.1338 + XiCon Loss:1.4649 x Lambda(0.1)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.9344
Validation loss decreased (0.209656 --> 0.206827).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5838162899017334
Epoch: 7, Steps: 30 Train Loss: 0.2738 (Forecasting Loss:0.1286 + XiCon Loss:1.4517 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.9489
Validation loss decreased (0.206827 --> 0.206323).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6002004146575928
Epoch: 8, Steps: 30 Train Loss: 0.2714 (Forecasting Loss:0.1277 + XiCon Loss:1.4364 x Lambda(0.1)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.9590
Validation loss decreased (0.206323 --> 0.192110).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5351881980895996
Epoch: 9, Steps: 30 Train Loss: 0.2714 (Forecasting Loss:0.1267 + XiCon Loss:1.4470 x Lambda(0.1)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.9240
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5696442127227783
Epoch: 10, Steps: 30 Train Loss: 0.2687 (Forecasting Loss:0.1256 + XiCon Loss:1.4309 x Lambda(0.1)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.9382
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6255333423614502
Epoch: 11, Steps: 30 Train Loss: 0.2694 (Forecasting Loss:0.1259 + XiCon Loss:1.4347 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.9347
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5643765926361084
Epoch: 12, Steps: 30 Train Loss: 0.2688 (Forecasting Loss:0.1257 + XiCon Loss:1.4312 x Lambda(0.1)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.9376
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5427937507629395
Epoch: 13, Steps: 30 Train Loss: 0.2690 (Forecasting Loss:0.1257 + XiCon Loss:1.4334 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.9372
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.592282772064209
Epoch: 14, Steps: 30 Train Loss: 0.2677 (Forecasting Loss:0.1253 + XiCon Loss:1.4239 x Lambda(0.1)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.9373
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5413155555725098
Epoch: 15, Steps: 30 Train Loss: 0.2689 (Forecasting Loss:0.1254 + XiCon Loss:1.4346 x Lambda(0.1)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.9369
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.5412793159484863
Epoch: 16, Steps: 30 Train Loss: 0.2680 (Forecasting Loss:0.1256 + XiCon Loss:1.4233 x Lambda(0.1)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.9366
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6008505821228027
Epoch: 17, Steps: 30 Train Loss: 0.2694 (Forecasting Loss:0.1257 + XiCon Loss:1.4368 x Lambda(0.1)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.9365
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.5705859661102295
Epoch: 18, Steps: 30 Train Loss: 0.2682 (Forecasting Loss:0.1254 + XiCon Loss:1.4282 x Lambda(0.1)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.9365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.0595619678497314, mae:0.8583822846412659, mape:0.28495609760284424, mspe:0.14087322354316711 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3454
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6070358753204346
Epoch: 1, Steps: 30 Train Loss: 0.8118 (Forecasting Loss:0.6496 + XiCon Loss:1.6222 x Lambda(0.1)), Vali MSE Loss: 0.3345 Test MSE Loss: 1.8885
Validation loss decreased (inf --> 0.334542).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6783013343811035
Epoch: 2, Steps: 30 Train Loss: 0.5682 (Forecasting Loss:0.4054 + XiCon Loss:1.6279 x Lambda(0.1)), Vali MSE Loss: 0.2936 Test MSE Loss: 1.1341
Validation loss decreased (0.334542 --> 0.293649).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5714013576507568
Epoch: 3, Steps: 30 Train Loss: 0.3959 (Forecasting Loss:0.2343 + XiCon Loss:1.6159 x Lambda(0.1)), Vali MSE Loss: 0.3430 Test MSE Loss: 1.2593
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6743752956390381
Epoch: 4, Steps: 30 Train Loss: 0.3380 (Forecasting Loss:0.1772 + XiCon Loss:1.6077 x Lambda(0.1)), Vali MSE Loss: 0.2940 Test MSE Loss: 1.2715
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6214230060577393
Epoch: 5, Steps: 30 Train Loss: 0.3128 (Forecasting Loss:0.1529 + XiCon Loss:1.5987 x Lambda(0.1)), Vali MSE Loss: 0.3048 Test MSE Loss: 1.1660
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.605309247970581
Epoch: 6, Steps: 30 Train Loss: 0.3003 (Forecasting Loss:0.1410 + XiCon Loss:1.5928 x Lambda(0.1)), Vali MSE Loss: 0.2880 Test MSE Loss: 1.0636
Validation loss decreased (0.293649 --> 0.288015).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5884561538696289
Epoch: 7, Steps: 30 Train Loss: 0.2929 (Forecasting Loss:0.1336 + XiCon Loss:1.5926 x Lambda(0.1)), Vali MSE Loss: 0.2951 Test MSE Loss: 1.0235
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.626767635345459
Epoch: 8, Steps: 30 Train Loss: 0.2899 (Forecasting Loss:0.1309 + XiCon Loss:1.5902 x Lambda(0.1)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6167647838592529
Epoch: 9, Steps: 30 Train Loss: 0.2895 (Forecasting Loss:0.1304 + XiCon Loss:1.5909 x Lambda(0.1)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.9526
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6043667793273926
Epoch: 10, Steps: 30 Train Loss: 0.2886 (Forecasting Loss:0.1297 + XiCon Loss:1.5895 x Lambda(0.1)), Vali MSE Loss: 0.3102 Test MSE Loss: 0.9698
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6138429641723633
Epoch: 11, Steps: 30 Train Loss: 0.2872 (Forecasting Loss:0.1284 + XiCon Loss:1.5876 x Lambda(0.1)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.9636
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6029622554779053
Epoch: 12, Steps: 30 Train Loss: 0.2876 (Forecasting Loss:0.1288 + XiCon Loss:1.5873 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.9577
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.624774694442749
Epoch: 13, Steps: 30 Train Loss: 0.2878 (Forecasting Loss:0.1288 + XiCon Loss:1.5899 x Lambda(0.1)), Vali MSE Loss: 0.3056 Test MSE Loss: 0.9562
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.618088960647583
Epoch: 14, Steps: 30 Train Loss: 0.2872 (Forecasting Loss:0.1281 + XiCon Loss:1.5909 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.9568
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5608136653900146
Epoch: 15, Steps: 30 Train Loss: 0.2875 (Forecasting Loss:0.1288 + XiCon Loss:1.5873 x Lambda(0.1)), Vali MSE Loss: 0.3043 Test MSE Loss: 0.9567
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6754436492919922
Epoch: 16, Steps: 30 Train Loss: 0.2871 (Forecasting Loss:0.1285 + XiCon Loss:1.5860 x Lambda(0.1)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.9566
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2043241262435913, mae:0.9228324294090271, mape:0.2908932864665985, mspe:0.12368499487638474 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3593
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5585718154907227
Epoch: 1, Steps: 30 Train Loss: 0.7375 (Forecasting Loss:0.5758 + XiCon Loss:1.6170 x Lambda(0.1)), Vali MSE Loss: 0.3630 Test MSE Loss: 1.6858
Validation loss decreased (inf --> 0.362983).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5970020294189453
Epoch: 2, Steps: 30 Train Loss: 0.5667 (Forecasting Loss:0.4095 + XiCon Loss:1.5720 x Lambda(0.1)), Vali MSE Loss: 0.3741 Test MSE Loss: 0.9854
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.555678129196167
Epoch: 3, Steps: 30 Train Loss: 0.4215 (Forecasting Loss:0.2690 + XiCon Loss:1.5256 x Lambda(0.1)), Vali MSE Loss: 0.3338 Test MSE Loss: 1.1002
Validation loss decreased (0.362983 --> 0.333770).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5742278099060059
Epoch: 4, Steps: 30 Train Loss: 0.3651 (Forecasting Loss:0.2217 + XiCon Loss:1.4339 x Lambda(0.1)), Vali MSE Loss: 0.3545 Test MSE Loss: 1.0173
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6019377708435059
Epoch: 5, Steps: 30 Train Loss: 0.3449 (Forecasting Loss:0.2035 + XiCon Loss:1.4138 x Lambda(0.1)), Vali MSE Loss: 0.3834 Test MSE Loss: 0.9770
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5370163917541504
Epoch: 6, Steps: 30 Train Loss: 0.3266 (Forecasting Loss:0.1880 + XiCon Loss:1.3861 x Lambda(0.1)), Vali MSE Loss: 0.3594 Test MSE Loss: 1.0011
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6438663005828857
Epoch: 7, Steps: 30 Train Loss: 0.3196 (Forecasting Loss:0.1797 + XiCon Loss:1.3984 x Lambda(0.1)), Vali MSE Loss: 0.3475 Test MSE Loss: 0.9867
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5675289630889893
Epoch: 8, Steps: 30 Train Loss: 0.3155 (Forecasting Loss:0.1763 + XiCon Loss:1.3922 x Lambda(0.1)), Vali MSE Loss: 0.3469 Test MSE Loss: 0.9981
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6120603084564209
Epoch: 9, Steps: 30 Train Loss: 0.3133 (Forecasting Loss:0.1741 + XiCon Loss:1.3914 x Lambda(0.1)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.9759
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5757753849029541
Epoch: 10, Steps: 30 Train Loss: 0.3131 (Forecasting Loss:0.1737 + XiCon Loss:1.3934 x Lambda(0.1)), Vali MSE Loss: 0.3559 Test MSE Loss: 0.9750
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.593113899230957
Epoch: 11, Steps: 30 Train Loss: 0.3119 (Forecasting Loss:0.1736 + XiCon Loss:1.3836 x Lambda(0.1)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.9732
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6670584678649902
Epoch: 12, Steps: 30 Train Loss: 0.3116 (Forecasting Loss:0.1726 + XiCon Loss:1.3898 x Lambda(0.1)), Vali MSE Loss: 0.3514 Test MSE Loss: 0.9724
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5636365413665771
Epoch: 13, Steps: 30 Train Loss: 0.3134 (Forecasting Loss:0.1742 + XiCon Loss:1.3924 x Lambda(0.1)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.9723
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2391347885131836, mae:0.9612054824829102, mape:0.3189285397529602, mspe:0.1593487709760666 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1659+-0.13722, MAE:0.9242+-0.06767, MAPE:0.3013+-0.02053, MSPE:0.1401+-0.01585, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
