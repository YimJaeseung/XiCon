Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.5011
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 31.2197514
	speed: 0.0166s/iter; left time: 394.6187s
	iters: 200, epoch: 1 | loss: 31.1387939
	speed: 0.0111s/iter; left time: 263.9666s
Epoch: 1 cost time: 3.227111339569092
Epoch: 1, Steps: 239 Train Loss: 30.7823 (Forecasting Loss:0.6229 + XiCon Loss:3.0159 x Lambda(10.0)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.4448
Validation loss decreased (inf --> 0.327898).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.5396576
	speed: 0.0138s/iter; left time: 325.1597s
	iters: 200, epoch: 2 | loss: 29.2990017
	speed: 0.0103s/iter; left time: 242.7879s
Epoch: 2 cost time: 2.845395088195801
Epoch: 2, Steps: 239 Train Loss: 29.6324 (Forecasting Loss:0.3121 + XiCon Loss:2.9320 x Lambda(10.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.2802
Validation loss decreased (0.327898 --> 0.207594).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.9927063
	speed: 0.0131s/iter; left time: 306.2956s
	iters: 200, epoch: 3 | loss: 28.9112473
	speed: 0.0111s/iter; left time: 258.5784s
Epoch: 3 cost time: 2.883486032485962
Epoch: 3, Steps: 239 Train Loss: 29.0677 (Forecasting Loss:0.2738 + XiCon Loss:2.8794 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.2724
Validation loss decreased (0.207594 --> 0.198689).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.1220837
	speed: 0.0129s/iter; left time: 297.7436s
	iters: 200, epoch: 4 | loss: 29.1393356
	speed: 0.0121s/iter; left time: 278.4305s
Epoch: 4 cost time: 2.950880527496338
Epoch: 4, Steps: 239 Train Loss: 28.9592 (Forecasting Loss:0.2677 + XiCon Loss:2.8691 x Lambda(10.0)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.2702
Validation loss decreased (0.198689 --> 0.196842).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.7370853
	speed: 0.0129s/iter; left time: 294.4752s
	iters: 200, epoch: 5 | loss: 28.7208004
	speed: 0.0102s/iter; left time: 233.0996s
Epoch: 5 cost time: 2.735548973083496
Epoch: 5, Steps: 239 Train Loss: 28.8986 (Forecasting Loss:0.2650 + XiCon Loss:2.8634 x Lambda(10.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2699
Validation loss decreased (0.196842 --> 0.195183).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.1320534
	speed: 0.0126s/iter; left time: 284.0848s
	iters: 200, epoch: 6 | loss: 28.8403893
	speed: 0.0105s/iter; left time: 236.0855s
Epoch: 6 cost time: 2.7407922744750977
Epoch: 6, Steps: 239 Train Loss: 28.8937 (Forecasting Loss:0.2640 + XiCon Loss:2.8630 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2678
Validation loss decreased (0.195183 --> 0.194643).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.7918854
	speed: 0.0131s/iter; left time: 291.9992s
	iters: 200, epoch: 7 | loss: 29.0798969
	speed: 0.0103s/iter; left time: 229.9288s
Epoch: 7 cost time: 2.821608304977417
Epoch: 7, Steps: 239 Train Loss: 28.8901 (Forecasting Loss:0.2632 + XiCon Loss:2.8627 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.2679
Validation loss decreased (0.194643 --> 0.194096).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.6197376
	speed: 0.0127s/iter; left time: 282.0271s
	iters: 200, epoch: 8 | loss: 28.8257847
	speed: 0.0104s/iter; left time: 228.6591s
Epoch: 8 cost time: 2.745466709136963
Epoch: 8, Steps: 239 Train Loss: 28.8772 (Forecasting Loss:0.2628 + XiCon Loss:2.8614 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.6590729
	speed: 0.0125s/iter; left time: 274.3890s
	iters: 200, epoch: 9 | loss: 28.8789005
	speed: 0.0106s/iter; left time: 231.0220s
Epoch: 9 cost time: 2.742356300354004
Epoch: 9, Steps: 239 Train Loss: 28.8794 (Forecasting Loss:0.2629 + XiCon Loss:2.8616 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2675
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 28.5491638
	speed: 0.0130s/iter; left time: 282.0991s
	iters: 200, epoch: 10 | loss: 28.8274632
	speed: 0.0117s/iter; left time: 253.1623s
Epoch: 10 cost time: 2.9397199153900146
Epoch: 10, Steps: 239 Train Loss: 28.8717 (Forecasting Loss:0.2625 + XiCon Loss:2.8609 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.2328053
	speed: 0.0129s/iter; left time: 276.5030s
	iters: 200, epoch: 11 | loss: 28.8660355
	speed: 0.0102s/iter; left time: 217.8285s
Epoch: 11 cost time: 2.748835802078247
Epoch: 11, Steps: 239 Train Loss: 28.8706 (Forecasting Loss:0.2626 + XiCon Loss:2.8608 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2674
Validation loss decreased (0.194096 --> 0.193693).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.8639393
	speed: 0.0128s/iter; left time: 270.6104s
	iters: 200, epoch: 12 | loss: 29.0535526
	speed: 0.0103s/iter; left time: 217.1868s
Epoch: 12 cost time: 2.7471556663513184
Epoch: 12, Steps: 239 Train Loss: 28.8698 (Forecasting Loss:0.2629 + XiCon Loss:2.8607 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 28.7946510
	speed: 0.0128s/iter; left time: 267.7079s
	iters: 200, epoch: 13 | loss: 29.1022625
	speed: 0.0102s/iter; left time: 213.3491s
Epoch: 13 cost time: 2.727024793624878
Epoch: 13, Steps: 239 Train Loss: 28.8891 (Forecasting Loss:0.2627 + XiCon Loss:2.8626 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2674
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.1493034
	speed: 0.0144s/iter; left time: 298.0522s
	iters: 200, epoch: 14 | loss: 28.9651661
	speed: 0.0105s/iter; left time: 216.7170s
Epoch: 14 cost time: 2.9284820556640625
Epoch: 14, Steps: 239 Train Loss: 28.8761 (Forecasting Loss:0.2626 + XiCon Loss:2.8613 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.0604076
	speed: 0.0141s/iter; left time: 288.1870s
	iters: 200, epoch: 15 | loss: 28.7069931
	speed: 0.0109s/iter; left time: 222.0505s
Epoch: 15 cost time: 2.9574577808380127
Epoch: 15, Steps: 239 Train Loss: 28.8682 (Forecasting Loss:0.2629 + XiCon Loss:2.8605 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2674
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 29.1202717
	speed: 0.0132s/iter; left time: 266.0055s
	iters: 200, epoch: 16 | loss: 28.8947525
	speed: 0.0109s/iter; left time: 219.4318s
Epoch: 16 cost time: 2.8299098014831543
Epoch: 16, Steps: 239 Train Loss: 28.8775 (Forecasting Loss:0.2622 + XiCon Loss:2.8615 x Lambda(10.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2674
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 28.6248512
	speed: 0.0130s/iter; left time: 259.3064s
	iters: 200, epoch: 17 | loss: 29.0313282
	speed: 0.0103s/iter; left time: 205.0770s
Epoch: 17 cost time: 2.7667229175567627
Epoch: 17, Steps: 239 Train Loss: 28.8656 (Forecasting Loss:0.2624 + XiCon Loss:2.8603 x Lambda(10.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2674
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.2856197
	speed: 0.0142s/iter; left time: 280.4962s
	iters: 200, epoch: 18 | loss: 29.4811058
	speed: 0.0113s/iter; left time: 221.8691s
Epoch: 18 cost time: 3.047955274581909
Epoch: 18, Steps: 239 Train Loss: 28.8834 (Forecasting Loss:0.2626 + XiCon Loss:2.8621 x Lambda(10.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2674
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 28.7968960
	speed: 0.0128s/iter; left time: 248.8367s
	iters: 200, epoch: 19 | loss: 28.4088497
	speed: 0.0105s/iter; left time: 203.2952s
Epoch: 19 cost time: 2.749337911605835
Epoch: 19, Steps: 239 Train Loss: 28.8774 (Forecasting Loss:0.2627 + XiCon Loss:2.8615 x Lambda(10.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2674
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 29.1184444
	speed: 0.0134s/iter; left time: 258.8876s
	iters: 200, epoch: 20 | loss: 28.9801235
	speed: 0.0108s/iter; left time: 205.9725s
Epoch: 20 cost time: 2.851508855819702
Epoch: 20, Steps: 239 Train Loss: 28.8701 (Forecasting Loss:0.2626 + XiCon Loss:2.8608 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2674
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 28.6302052
	speed: 0.0131s/iter; left time: 248.5886s
	iters: 200, epoch: 21 | loss: 28.6693268
	speed: 0.0105s/iter; left time: 198.3290s
Epoch: 21 cost time: 2.806818723678589
Epoch: 21, Steps: 239 Train Loss: 28.8690 (Forecasting Loss:0.2624 + XiCon Loss:2.8607 x Lambda(10.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2674
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21063722670078278, mae:0.3241294026374817, mape:2.3017921447753906, mspe:2833.8671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9788
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 30.6562386
	speed: 0.0137s/iter; left time: 326.5912s
	iters: 200, epoch: 1 | loss: 30.3313866
	speed: 0.0120s/iter; left time: 283.7488s
Epoch: 1 cost time: 3.0016043186187744
Epoch: 1, Steps: 239 Train Loss: 30.6679 (Forecasting Loss:0.6126 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.4353
Validation loss decreased (inf --> 0.322572).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.8644962
	speed: 0.0133s/iter; left time: 314.3822s
	iters: 200, epoch: 2 | loss: 29.8476086
	speed: 0.0103s/iter; left time: 240.6621s
Epoch: 2 cost time: 2.867184638977051
Epoch: 2, Steps: 239 Train Loss: 29.8301 (Forecasting Loss:0.3148 + XiCon Loss:2.9515 x Lambda(10.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.2812
Validation loss decreased (0.322572 --> 0.205002).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.5898285
	speed: 0.0129s/iter; left time: 299.7661s
	iters: 200, epoch: 3 | loss: 29.4721127
	speed: 0.0109s/iter; left time: 254.2711s
Epoch: 3 cost time: 2.856670379638672
Epoch: 3, Steps: 239 Train Loss: 29.2446 (Forecasting Loss:0.2793 + XiCon Loss:2.8965 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.2771
Validation loss decreased (0.205002 --> 0.200299).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.1840668
	speed: 0.0133s/iter; left time: 307.5874s
	iters: 200, epoch: 4 | loss: 28.6357613
	speed: 0.0106s/iter; left time: 244.0755s
Epoch: 4 cost time: 2.829061269760132
Epoch: 4, Steps: 239 Train Loss: 29.0275 (Forecasting Loss:0.2732 + XiCon Loss:2.8754 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.2718
Validation loss decreased (0.200299 --> 0.196566).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.0272655
	speed: 0.0130s/iter; left time: 297.9656s
	iters: 200, epoch: 5 | loss: 29.1365013
	speed: 0.0113s/iter; left time: 257.8192s
Epoch: 5 cost time: 2.872818946838379
Epoch: 5, Steps: 239 Train Loss: 28.9784 (Forecasting Loss:0.2693 + XiCon Loss:2.8709 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.2702
Validation loss decreased (0.196566 --> 0.195352).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 28.7493954
	speed: 0.0135s/iter; left time: 305.2677s
	iters: 200, epoch: 6 | loss: 29.5026455
	speed: 0.0112s/iter; left time: 251.2693s
Epoch: 6 cost time: 2.902282953262329
Epoch: 6, Steps: 239 Train Loss: 28.9172 (Forecasting Loss:0.2681 + XiCon Loss:2.8649 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2695
Validation loss decreased (0.195352 --> 0.194200).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.9062805
	speed: 0.0131s/iter; left time: 292.6084s
	iters: 200, epoch: 7 | loss: 28.6918449
	speed: 0.0114s/iter; left time: 252.8021s
Epoch: 7 cost time: 2.8826375007629395
Epoch: 7, Steps: 239 Train Loss: 28.9205 (Forecasting Loss:0.2672 + XiCon Loss:2.8653 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2684
Validation loss decreased (0.194200 --> 0.194163).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.1012554
	speed: 0.0135s/iter; left time: 298.5203s
	iters: 200, epoch: 8 | loss: 28.6881428
	speed: 0.0102s/iter; left time: 224.0929s
Epoch: 8 cost time: 2.8224782943725586
Epoch: 8, Steps: 239 Train Loss: 28.9133 (Forecasting Loss:0.2668 + XiCon Loss:2.8646 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2689
Validation loss decreased (0.194163 --> 0.193413).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.9148312
	speed: 0.0132s/iter; left time: 289.3281s
	iters: 200, epoch: 9 | loss: 28.9246197
	speed: 0.0104s/iter; left time: 226.6051s
Epoch: 9 cost time: 2.7967634201049805
Epoch: 9, Steps: 239 Train Loss: 28.9288 (Forecasting Loss:0.2664 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2686
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 28.9515095
	speed: 0.0133s/iter; left time: 287.8702s
	iters: 200, epoch: 10 | loss: 28.7750034
	speed: 0.0110s/iter; left time: 236.3879s
Epoch: 10 cost time: 2.8863027095794678
Epoch: 10, Steps: 239 Train Loss: 28.9005 (Forecasting Loss:0.2664 + XiCon Loss:2.8634 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.8714199
	speed: 0.0136s/iter; left time: 291.1369s
	iters: 200, epoch: 11 | loss: 28.9332848
	speed: 0.0106s/iter; left time: 226.9614s
Epoch: 11 cost time: 2.931182384490967
Epoch: 11, Steps: 239 Train Loss: 28.8830 (Forecasting Loss:0.2663 + XiCon Loss:2.8617 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2685
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.5743809
	speed: 0.0138s/iter; left time: 292.7601s
	iters: 200, epoch: 12 | loss: 28.8721161
	speed: 0.0109s/iter; left time: 229.7297s
Epoch: 12 cost time: 2.935567855834961
Epoch: 12, Steps: 239 Train Loss: 28.8939 (Forecasting Loss:0.2659 + XiCon Loss:2.8628 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.0015774
	speed: 0.0132s/iter; left time: 275.7944s
	iters: 200, epoch: 13 | loss: 28.7965221
	speed: 0.0102s/iter; left time: 211.4801s
Epoch: 13 cost time: 2.832282066345215
Epoch: 13, Steps: 239 Train Loss: 28.9087 (Forecasting Loss:0.2658 + XiCon Loss:2.8643 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2684
Validation loss decreased (0.193413 --> 0.193398).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.4981136
	speed: 0.0135s/iter; left time: 280.0418s
	iters: 200, epoch: 14 | loss: 28.9964352
	speed: 0.0114s/iter; left time: 235.7803s
Epoch: 14 cost time: 2.942500591278076
Epoch: 14, Steps: 239 Train Loss: 28.9072 (Forecasting Loss:0.2662 + XiCon Loss:2.8641 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.9293804
	speed: 0.0145s/iter; left time: 297.4506s
	iters: 200, epoch: 15 | loss: 29.0856361
	speed: 0.0104s/iter; left time: 212.5914s
Epoch: 15 cost time: 2.9576759338378906
Epoch: 15, Steps: 239 Train Loss: 28.9063 (Forecasting Loss:0.2658 + XiCon Loss:2.8641 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2684
Validation loss decreased (0.193398 --> 0.193376).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 28.9060726
	speed: 0.0136s/iter; left time: 275.6339s
	iters: 200, epoch: 16 | loss: 28.4218006
	speed: 0.0104s/iter; left time: 208.9766s
Epoch: 16 cost time: 2.8577663898468018
Epoch: 16, Steps: 239 Train Loss: 28.9259 (Forecasting Loss:0.2659 + XiCon Loss:2.8660 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 29.0557709
	speed: 0.0137s/iter; left time: 273.4742s
	iters: 200, epoch: 17 | loss: 29.2323227
	speed: 0.0108s/iter; left time: 214.5812s
Epoch: 17 cost time: 2.8798179626464844
Epoch: 17, Steps: 239 Train Loss: 28.9142 (Forecasting Loss:0.2664 + XiCon Loss:2.8648 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 28.5323143
	speed: 0.0145s/iter; left time: 286.8012s
	iters: 200, epoch: 18 | loss: 29.0649567
	speed: 0.0111s/iter; left time: 217.1115s
Epoch: 18 cost time: 2.9958600997924805
Epoch: 18, Steps: 239 Train Loss: 28.8985 (Forecasting Loss:0.2664 + XiCon Loss:2.8632 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 28.8441696
	speed: 0.0133s/iter; left time: 260.1352s
	iters: 200, epoch: 19 | loss: 29.0234718
	speed: 0.0102s/iter; left time: 197.7419s
Epoch: 19 cost time: 2.8069934844970703
Epoch: 19, Steps: 239 Train Loss: 28.9149 (Forecasting Loss:0.2661 + XiCon Loss:2.8649 x Lambda(10.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 28.7263184
	speed: 0.0131s/iter; left time: 251.6351s
	iters: 200, epoch: 20 | loss: 29.1007957
	speed: 0.0109s/iter; left time: 208.4678s
Epoch: 20 cost time: 2.8505921363830566
Epoch: 20, Steps: 239 Train Loss: 28.9228 (Forecasting Loss:0.2663 + XiCon Loss:2.8656 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2684
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 29.0349083
	speed: 0.0134s/iter; left time: 255.4690s
	iters: 200, epoch: 21 | loss: 28.9211388
	speed: 0.0115s/iter; left time: 217.8451s
Epoch: 21 cost time: 2.965949773788452
Epoch: 21, Steps: 239 Train Loss: 28.9162 (Forecasting Loss:0.2663 + XiCon Loss:2.8650 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 29.1687508
	speed: 0.0129s/iter; left time: 242.7982s
	iters: 200, epoch: 22 | loss: 29.1587753
	speed: 0.0107s/iter; left time: 200.3345s
Epoch: 22 cost time: 2.8544230461120605
Epoch: 22, Steps: 239 Train Loss: 28.8967 (Forecasting Loss:0.2660 + XiCon Loss:2.8631 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2684
Validation loss decreased (0.193376 --> 0.193289).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 29.2379398
	speed: 0.0132s/iter; left time: 244.9540s
	iters: 200, epoch: 23 | loss: 29.1370926
	speed: 0.0103s/iter; left time: 189.7867s
Epoch: 23 cost time: 2.779035806655884
Epoch: 23, Steps: 239 Train Loss: 28.8806 (Forecasting Loss:0.2663 + XiCon Loss:2.8614 x Lambda(10.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 28.6340256
	speed: 0.0138s/iter; left time: 251.8657s
	iters: 200, epoch: 24 | loss: 29.2712173
	speed: 0.0117s/iter; left time: 213.8111s
Epoch: 24 cost time: 3.0051686763763428
Epoch: 24, Steps: 239 Train Loss: 28.8989 (Forecasting Loss:0.2663 + XiCon Loss:2.8633 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 29.0311394
	speed: 0.0133s/iter; left time: 239.3673s
	iters: 200, epoch: 25 | loss: 28.9187336
	speed: 0.0103s/iter; left time: 185.8095s
Epoch: 25 cost time: 2.7942259311676025
Epoch: 25, Steps: 239 Train Loss: 28.9060 (Forecasting Loss:0.2662 + XiCon Loss:2.8640 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 28.8242512
	speed: 0.0134s/iter; left time: 238.9777s
	iters: 200, epoch: 26 | loss: 29.1109409
	speed: 0.0119s/iter; left time: 211.1790s
Epoch: 26 cost time: 3.0241539478302
Epoch: 26, Steps: 239 Train Loss: 28.9072 (Forecasting Loss:0.2664 + XiCon Loss:2.8641 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 28.8782825
	speed: 0.0129s/iter; left time: 226.1056s
	iters: 200, epoch: 27 | loss: 28.4159298
	speed: 0.0103s/iter; left time: 180.1730s
Epoch: 27 cost time: 2.777353286743164
Epoch: 27, Steps: 239 Train Loss: 28.9053 (Forecasting Loss:0.2662 + XiCon Loss:2.8639 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2684
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 28.6455364
	speed: 0.0131s/iter; left time: 227.9616s
	iters: 200, epoch: 28 | loss: 28.5298367
	speed: 0.0104s/iter; left time: 178.9981s
Epoch: 28 cost time: 2.8482091426849365
Epoch: 28, Steps: 239 Train Loss: 28.9171 (Forecasting Loss:0.2665 + XiCon Loss:2.8651 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 28.8576965
	speed: 0.0128s/iter; left time: 218.9482s
	iters: 200, epoch: 29 | loss: 28.6540337
	speed: 0.0105s/iter; left time: 179.3618s
Epoch: 29 cost time: 2.8181874752044678
Epoch: 29, Steps: 239 Train Loss: 28.9208 (Forecasting Loss:0.2662 + XiCon Loss:2.8655 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2684
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 28.7553673
	speed: 0.0136s/iter; left time: 230.0617s
	iters: 200, epoch: 30 | loss: 28.5243053
	speed: 0.0113s/iter; left time: 189.4600s
Epoch: 30 cost time: 2.9431545734405518
Epoch: 30, Steps: 239 Train Loss: 28.9007 (Forecasting Loss:0.2664 + XiCon Loss:2.8634 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2684
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 29.3214245
	speed: 0.0128s/iter; left time: 212.4097s
	iters: 200, epoch: 31 | loss: 28.9482460
	speed: 0.0113s/iter; left time: 187.0644s
Epoch: 31 cost time: 2.86855149269104
Epoch: 31, Steps: 239 Train Loss: 28.8920 (Forecasting Loss:0.2659 + XiCon Loss:2.8626 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2684
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 29.1643295
	speed: 0.0136s/iter; left time: 222.5828s
	iters: 200, epoch: 32 | loss: 29.0114555
	speed: 0.0104s/iter; left time: 168.7719s
Epoch: 32 cost time: 2.8304710388183594
Epoch: 32, Steps: 239 Train Loss: 28.8974 (Forecasting Loss:0.2663 + XiCon Loss:2.8631 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.2118590623140335, mae:0.32500123977661133, mape:2.3203136920928955, mspe:2851.5 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9737
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 31.3950443
	speed: 0.0137s/iter; left time: 325.5643s
	iters: 200, epoch: 1 | loss: 31.3058662
	speed: 0.0106s/iter; left time: 251.7383s
Epoch: 1 cost time: 2.906076431274414
Epoch: 1, Steps: 239 Train Loss: 31.2038 (Forecasting Loss:0.6860 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.3591 Test MSE Loss: 0.4908
Validation loss decreased (inf --> 0.359074).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.9095097
	speed: 0.0127s/iter; left time: 298.2264s
	iters: 200, epoch: 2 | loss: 29.3364296
	speed: 0.0114s/iter; left time: 266.6911s
Epoch: 2 cost time: 2.8254289627075195
Epoch: 2, Steps: 239 Train Loss: 29.6324 (Forecasting Loss:0.3171 + XiCon Loss:2.9315 x Lambda(10.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.2797
Validation loss decreased (0.359074 --> 0.206199).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.3993130
	speed: 0.0133s/iter; left time: 311.3617s
	iters: 200, epoch: 3 | loss: 28.7648563
	speed: 0.0115s/iter; left time: 266.1080s
Epoch: 3 cost time: 2.926344394683838
Epoch: 3, Steps: 239 Train Loss: 28.8964 (Forecasting Loss:0.2733 + XiCon Loss:2.8623 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.2672
Validation loss decreased (0.206199 --> 0.197665).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.9371948
	speed: 0.0130s/iter; left time: 300.9863s
	iters: 200, epoch: 4 | loss: 28.7233505
	speed: 0.0109s/iter; left time: 249.7141s
Epoch: 4 cost time: 2.9027247428894043
Epoch: 4, Steps: 239 Train Loss: 28.7623 (Forecasting Loss:0.2670 + XiCon Loss:2.8495 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.2651
Validation loss decreased (0.197665 --> 0.195694).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.1956902
	speed: 0.0135s/iter; left time: 308.3224s
	iters: 200, epoch: 5 | loss: 28.4731693
	speed: 0.0102s/iter; left time: 231.4985s
Epoch: 5 cost time: 2.803467035293579
Epoch: 5, Steps: 239 Train Loss: 28.7351 (Forecasting Loss:0.2647 + XiCon Loss:2.8470 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2636
Validation loss decreased (0.195694 --> 0.194269).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 28.5137653
	speed: 0.0133s/iter; left time: 301.1800s
	iters: 200, epoch: 6 | loss: 29.0199852
	speed: 0.0108s/iter; left time: 242.7207s
Epoch: 6 cost time: 2.846141815185547
Epoch: 6, Steps: 239 Train Loss: 28.6907 (Forecasting Loss:0.2633 + XiCon Loss:2.8427 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2624
Validation loss decreased (0.194269 --> 0.193540).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.4968872
	speed: 0.0140s/iter; left time: 312.8587s
	iters: 200, epoch: 7 | loss: 28.8637104
	speed: 0.0111s/iter; left time: 248.2195s
Epoch: 7 cost time: 2.966926097869873
Epoch: 7, Steps: 239 Train Loss: 28.6851 (Forecasting Loss:0.2623 + XiCon Loss:2.8423 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2622
Validation loss decreased (0.193540 --> 0.193331).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.5900650
	speed: 0.0133s/iter; left time: 295.3904s
	iters: 200, epoch: 8 | loss: 28.4560394
	speed: 0.0106s/iter; left time: 234.1510s
Epoch: 8 cost time: 2.845771312713623
Epoch: 8, Steps: 239 Train Loss: 28.6688 (Forecasting Loss:0.2620 + XiCon Loss:2.8407 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.2620
Validation loss decreased (0.193331 --> 0.192984).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.5783997
	speed: 0.0131s/iter; left time: 286.2134s
	iters: 200, epoch: 9 | loss: 28.2395000
	speed: 0.0104s/iter; left time: 226.8240s
Epoch: 9 cost time: 2.807884454727173
Epoch: 9, Steps: 239 Train Loss: 28.6853 (Forecasting Loss:0.2621 + XiCon Loss:2.8423 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2620
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 28.6728878
	speed: 0.0135s/iter; left time: 292.6998s
	iters: 200, epoch: 10 | loss: 28.8597469
	speed: 0.0111s/iter; left time: 239.0981s
Epoch: 10 cost time: 2.9305357933044434
Epoch: 10, Steps: 239 Train Loss: 28.6584 (Forecasting Loss:0.2620 + XiCon Loss:2.8396 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.4148273
	speed: 0.0134s/iter; left time: 287.8004s
	iters: 200, epoch: 11 | loss: 29.0145988
	speed: 0.0109s/iter; left time: 232.3752s
Epoch: 11 cost time: 2.9407196044921875
Epoch: 11, Steps: 239 Train Loss: 28.6737 (Forecasting Loss:0.2618 + XiCon Loss:2.8412 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2619
Validation loss decreased (0.192984 --> 0.192886).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.6803513
	speed: 0.0130s/iter; left time: 274.4533s
	iters: 200, epoch: 12 | loss: 28.9280910
	speed: 0.0107s/iter; left time: 225.0242s
Epoch: 12 cost time: 2.7911014556884766
Epoch: 12, Steps: 239 Train Loss: 28.7046 (Forecasting Loss:0.2615 + XiCon Loss:2.8443 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2619
Validation loss decreased (0.192886 --> 0.192794).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 28.6126537
	speed: 0.0144s/iter; left time: 300.5375s
	iters: 200, epoch: 13 | loss: 29.1849957
	speed: 0.0111s/iter; left time: 230.3051s
Epoch: 13 cost time: 3.038975715637207
Epoch: 13, Steps: 239 Train Loss: 28.6809 (Forecasting Loss:0.2616 + XiCon Loss:2.8419 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2619
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.2386723
	speed: 0.0137s/iter; left time: 284.4026s
	iters: 200, epoch: 14 | loss: 29.0764866
	speed: 0.0108s/iter; left time: 221.4616s
Epoch: 14 cost time: 2.886925220489502
Epoch: 14, Steps: 239 Train Loss: 28.6766 (Forecasting Loss:0.2620 + XiCon Loss:2.8415 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.5323029
	speed: 0.0130s/iter; left time: 265.2360s
	iters: 200, epoch: 15 | loss: 28.4551849
	speed: 0.0106s/iter; left time: 216.7591s
Epoch: 15 cost time: 2.8119261264801025
Epoch: 15, Steps: 239 Train Loss: 28.6975 (Forecasting Loss:0.2613 + XiCon Loss:2.8436 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2619
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 28.7904720
	speed: 0.0136s/iter; left time: 275.9218s
	iters: 200, epoch: 16 | loss: 28.8213768
	speed: 0.0104s/iter; left time: 208.4915s
Epoch: 16 cost time: 2.851268768310547
Epoch: 16, Steps: 239 Train Loss: 28.6996 (Forecasting Loss:0.2619 + XiCon Loss:2.8438 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2619
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 28.8225231
	speed: 0.0132s/iter; left time: 263.4179s
	iters: 200, epoch: 17 | loss: 29.0585918
	speed: 0.0104s/iter; left time: 207.4527s
Epoch: 17 cost time: 2.7934741973876953
Epoch: 17, Steps: 239 Train Loss: 28.7142 (Forecasting Loss:0.2616 + XiCon Loss:2.8453 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 28.8898029
	speed: 0.0133s/iter; left time: 263.3995s
	iters: 200, epoch: 18 | loss: 28.3721771
	speed: 0.0114s/iter; left time: 223.3462s
Epoch: 18 cost time: 2.9415504932403564
Epoch: 18, Steps: 239 Train Loss: 28.6691 (Forecasting Loss:0.2620 + XiCon Loss:2.8407 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2619
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 28.6379490
	speed: 0.0131s/iter; left time: 255.4251s
	iters: 200, epoch: 19 | loss: 28.3839207
	speed: 0.0104s/iter; left time: 201.7337s
Epoch: 19 cost time: 2.846585512161255
Epoch: 19, Steps: 239 Train Loss: 28.6718 (Forecasting Loss:0.2617 + XiCon Loss:2.8410 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2619
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 28.3791485
	speed: 0.0139s/iter; left time: 267.7895s
	iters: 200, epoch: 20 | loss: 28.6440868
	speed: 0.0109s/iter; left time: 208.4622s
Epoch: 20 cost time: 2.9061503410339355
Epoch: 20, Steps: 239 Train Loss: 28.6641 (Forecasting Loss:0.2616 + XiCon Loss:2.8403 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2619
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 28.6656761
	speed: 0.0136s/iter; left time: 259.1005s
	iters: 200, epoch: 21 | loss: 28.4083824
	speed: 0.0107s/iter; left time: 202.3778s
Epoch: 21 cost time: 2.8677077293395996
Epoch: 21, Steps: 239 Train Loss: 28.6842 (Forecasting Loss:0.2617 + XiCon Loss:2.8422 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.2619
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 28.2543163
	speed: 0.0131s/iter; left time: 245.5220s
	iters: 200, epoch: 22 | loss: 28.5966625
	speed: 0.0109s/iter; left time: 203.4452s
Epoch: 22 cost time: 2.885167121887207
Epoch: 22, Steps: 239 Train Loss: 28.6890 (Forecasting Loss:0.2615 + XiCon Loss:2.8427 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2619
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20475296676158905, mae:0.31907138228416443, mape:2.3947830200195312, mspe:3600.155029296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9730
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 30.4781685
	speed: 0.0135s/iter; left time: 322.0524s
	iters: 200, epoch: 1 | loss: 30.3874378
	speed: 0.0113s/iter; left time: 268.0567s
Epoch: 1 cost time: 2.96975040435791
Epoch: 1, Steps: 239 Train Loss: 30.4930 (Forecasting Loss:0.6184 + XiCon Loss:2.9875 x Lambda(10.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.4358
Validation loss decreased (inf --> 0.319489).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.5621433
	speed: 0.0135s/iter; left time: 317.0720s
	iters: 200, epoch: 2 | loss: 29.7629166
	speed: 0.0104s/iter; left time: 243.4995s
Epoch: 2 cost time: 2.8145623207092285
Epoch: 2, Steps: 239 Train Loss: 29.6923 (Forecasting Loss:0.3168 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.2826
Validation loss decreased (0.319489 --> 0.206575).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.1775665
	speed: 0.0137s/iter; left time: 318.5762s
	iters: 200, epoch: 3 | loss: 29.0373974
	speed: 0.0102s/iter; left time: 237.8987s
Epoch: 3 cost time: 2.8893654346466064
Epoch: 3, Steps: 239 Train Loss: 29.1782 (Forecasting Loss:0.2817 + XiCon Loss:2.8896 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.2758
Validation loss decreased (0.206575 --> 0.200434).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.4530220
	speed: 0.0135s/iter; left time: 311.8272s
	iters: 200, epoch: 4 | loss: 29.1046009
	speed: 0.0106s/iter; left time: 244.6888s
Epoch: 4 cost time: 2.863980531692505
Epoch: 4, Steps: 239 Train Loss: 29.0464 (Forecasting Loss:0.2755 + XiCon Loss:2.8771 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.2705
Validation loss decreased (0.200434 --> 0.196583).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.8117104
	speed: 0.0136s/iter; left time: 310.7206s
	iters: 200, epoch: 5 | loss: 28.6813755
	speed: 0.0112s/iter; left time: 254.3773s
Epoch: 5 cost time: 2.917869806289673
Epoch: 5, Steps: 239 Train Loss: 28.9844 (Forecasting Loss:0.2731 + XiCon Loss:2.8711 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.2707
Validation loss decreased (0.196583 --> 0.195952).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.0985126
	speed: 0.0133s/iter; left time: 301.3920s
	iters: 200, epoch: 6 | loss: 28.4142914
	speed: 0.0104s/iter; left time: 234.0055s
Epoch: 6 cost time: 2.8297948837280273
Epoch: 6, Steps: 239 Train Loss: 28.9507 (Forecasting Loss:0.2714 + XiCon Loss:2.8679 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.2692
Validation loss decreased (0.195952 --> 0.195094).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.9829350
	speed: 0.0127s/iter; left time: 283.6125s
	iters: 200, epoch: 7 | loss: 28.7390137
	speed: 0.0114s/iter; left time: 254.0144s
Epoch: 7 cost time: 2.9039313793182373
Epoch: 7, Steps: 239 Train Loss: 28.9481 (Forecasting Loss:0.2710 + XiCon Loss:2.8677 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2689
Validation loss decreased (0.195094 --> 0.194570).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.6874714
	speed: 0.0139s/iter; left time: 308.0552s
	iters: 200, epoch: 8 | loss: 28.7823200
	speed: 0.0108s/iter; left time: 237.0467s
Epoch: 8 cost time: 2.8906707763671875
Epoch: 8, Steps: 239 Train Loss: 28.9776 (Forecasting Loss:0.2704 + XiCon Loss:2.8707 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2686
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.6377373
	speed: 0.0134s/iter; left time: 294.1382s
	iters: 200, epoch: 9 | loss: 28.8947582
	speed: 0.0109s/iter; left time: 238.0386s
Epoch: 9 cost time: 2.8966548442840576
Epoch: 9, Steps: 239 Train Loss: 28.9474 (Forecasting Loss:0.2699 + XiCon Loss:2.8678 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2685
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.1798134
	speed: 0.0136s/iter; left time: 294.9828s
	iters: 200, epoch: 10 | loss: 29.2508774
	speed: 0.0115s/iter; left time: 248.5736s
Epoch: 10 cost time: 2.967506170272827
Epoch: 10, Steps: 239 Train Loss: 28.9402 (Forecasting Loss:0.2700 + XiCon Loss:2.8670 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.5402889
	speed: 0.0135s/iter; left time: 287.9793s
	iters: 200, epoch: 11 | loss: 28.6570187
	speed: 0.0106s/iter; left time: 225.2796s
Epoch: 11 cost time: 2.839899778366089
Epoch: 11, Steps: 239 Train Loss: 28.9663 (Forecasting Loss:0.2698 + XiCon Loss:2.8697 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2684
Validation loss decreased (0.194570 --> 0.194544).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.0087776
	speed: 0.0138s/iter; left time: 292.7256s
	iters: 200, epoch: 12 | loss: 28.7537384
	speed: 0.0114s/iter; left time: 240.5898s
Epoch: 12 cost time: 3.020754337310791
Epoch: 12, Steps: 239 Train Loss: 28.9703 (Forecasting Loss:0.2700 + XiCon Loss:2.8700 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2684
Validation loss decreased (0.194544 --> 0.194278).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.0301819
	speed: 0.0130s/iter; left time: 272.3007s
	iters: 200, epoch: 13 | loss: 28.8598232
	speed: 0.0108s/iter; left time: 225.4070s
Epoch: 13 cost time: 2.850334405899048
Epoch: 13, Steps: 239 Train Loss: 28.9375 (Forecasting Loss:0.2699 + XiCon Loss:2.8668 x Lambda(10.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 28.8070583
	speed: 0.0129s/iter; left time: 266.0092s
	iters: 200, epoch: 14 | loss: 29.4994526
	speed: 0.0105s/iter; left time: 216.1398s
Epoch: 14 cost time: 2.7535324096679688
Epoch: 14, Steps: 239 Train Loss: 28.9614 (Forecasting Loss:0.2697 + XiCon Loss:2.8692 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.8444977
	speed: 0.0129s/iter; left time: 263.5732s
	iters: 200, epoch: 15 | loss: 28.9443588
	speed: 0.0114s/iter; left time: 232.5022s
Epoch: 15 cost time: 2.8805034160614014
Epoch: 15, Steps: 239 Train Loss: 28.9340 (Forecasting Loss:0.2697 + XiCon Loss:2.8664 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 28.5841274
	speed: 0.0134s/iter; left time: 270.0212s
	iters: 200, epoch: 16 | loss: 29.2330742
	speed: 0.0102s/iter; left time: 205.1338s
Epoch: 16 cost time: 2.878739356994629
Epoch: 16, Steps: 239 Train Loss: 28.9537 (Forecasting Loss:0.2699 + XiCon Loss:2.8684 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 28.8377953
	speed: 0.0139s/iter; left time: 277.2510s
	iters: 200, epoch: 17 | loss: 28.8567314
	speed: 0.0104s/iter; left time: 207.1724s
Epoch: 17 cost time: 2.8641457557678223
Epoch: 17, Steps: 239 Train Loss: 28.9366 (Forecasting Loss:0.2699 + XiCon Loss:2.8667 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2684
Validation loss decreased (0.194278 --> 0.194220).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.0939369
	speed: 0.0150s/iter; left time: 296.2559s
	iters: 200, epoch: 18 | loss: 28.6601067
	speed: 0.0108s/iter; left time: 211.2663s
Epoch: 18 cost time: 3.07448673248291
Epoch: 18, Steps: 239 Train Loss: 28.9486 (Forecasting Loss:0.2699 + XiCon Loss:2.8679 x Lambda(10.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2684
Validation loss decreased (0.194220 --> 0.194178).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 29.1763859
	speed: 0.0133s/iter; left time: 258.3848s
	iters: 200, epoch: 19 | loss: 28.9541969
	speed: 0.0103s/iter; left time: 199.8020s
Epoch: 19 cost time: 2.8653388023376465
Epoch: 19, Steps: 239 Train Loss: 28.9749 (Forecasting Loss:0.2699 + XiCon Loss:2.8705 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 28.5724430
	speed: 0.0132s/iter; left time: 254.7774s
	iters: 200, epoch: 20 | loss: 29.1531792
	speed: 0.0104s/iter; left time: 199.8462s
Epoch: 20 cost time: 2.833793878555298
Epoch: 20, Steps: 239 Train Loss: 28.9649 (Forecasting Loss:0.2700 + XiCon Loss:2.8695 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 29.1257362
	speed: 0.0143s/iter; left time: 271.6280s
	iters: 200, epoch: 21 | loss: 28.9039192
	speed: 0.0124s/iter; left time: 234.0639s
Epoch: 21 cost time: 3.154200315475464
Epoch: 21, Steps: 239 Train Loss: 28.9554 (Forecasting Loss:0.2699 + XiCon Loss:2.8685 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 29.1554813
	speed: 0.0143s/iter; left time: 268.5603s
	iters: 200, epoch: 22 | loss: 28.8023281
	speed: 0.0105s/iter; left time: 195.8917s
Epoch: 22 cost time: 2.902339220046997
Epoch: 22, Steps: 239 Train Loss: 28.9413 (Forecasting Loss:0.2698 + XiCon Loss:2.8672 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 28.8585262
	speed: 0.0131s/iter; left time: 242.4937s
	iters: 200, epoch: 23 | loss: 28.9979763
	speed: 0.0111s/iter; left time: 204.9976s
Epoch: 23 cost time: 2.9135351181030273
Epoch: 23, Steps: 239 Train Loss: 28.9794 (Forecasting Loss:0.2697 + XiCon Loss:2.8710 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2684
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 29.4718189
	speed: 0.0137s/iter; left time: 250.6030s
	iters: 200, epoch: 24 | loss: 28.9174862
	speed: 0.0111s/iter; left time: 201.9728s
Epoch: 24 cost time: 2.9182474613189697
Epoch: 24, Steps: 239 Train Loss: 28.9566 (Forecasting Loss:0.2699 + XiCon Loss:2.8687 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 29.1059399
	speed: 0.0133s/iter; left time: 240.5985s
	iters: 200, epoch: 25 | loss: 29.1446972
	speed: 0.0112s/iter; left time: 200.8039s
Epoch: 25 cost time: 2.8839197158813477
Epoch: 25, Steps: 239 Train Loss: 28.9575 (Forecasting Loss:0.2697 + XiCon Loss:2.8688 x Lambda(10.0)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2684
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 29.1883583
	speed: 0.0135s/iter; left time: 241.4430s
	iters: 200, epoch: 26 | loss: 29.2430000
	speed: 0.0116s/iter; left time: 206.4774s
Epoch: 26 cost time: 2.9638965129852295
Epoch: 26, Steps: 239 Train Loss: 28.9606 (Forecasting Loss:0.2700 + XiCon Loss:2.8691 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2684
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 29.2469769
	speed: 0.0135s/iter; left time: 238.1773s
	iters: 200, epoch: 27 | loss: 28.8357544
	speed: 0.0112s/iter; left time: 195.3009s
Epoch: 27 cost time: 2.899754762649536
Epoch: 27, Steps: 239 Train Loss: 28.9636 (Forecasting Loss:0.2698 + XiCon Loss:2.8694 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2684
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 29.0332985
	speed: 0.0130s/iter; left time: 224.7097s
	iters: 200, epoch: 28 | loss: 29.2377281
	speed: 0.0110s/iter; left time: 190.2772s
Epoch: 28 cost time: 2.9087045192718506
Epoch: 28, Steps: 239 Train Loss: 28.9290 (Forecasting Loss:0.2697 + XiCon Loss:2.8659 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.2684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21154196560382843, mae:0.3252672255039215, mape:2.424372673034668, mspe:3392.933349609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0832
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 30.8944302
	speed: 0.0127s/iter; left time: 301.8707s
	iters: 200, epoch: 1 | loss: 31.1144295
	speed: 0.0104s/iter; left time: 246.0764s
Epoch: 1 cost time: 2.7369210720062256
Epoch: 1, Steps: 239 Train Loss: 31.1823 (Forecasting Loss:0.6457 + XiCon Loss:3.0537 x Lambda(10.0)), Vali MSE Loss: 0.3362 Test MSE Loss: 0.4582
Validation loss decreased (inf --> 0.336159).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 30.3705101
	speed: 0.0126s/iter; left time: 296.5020s
	iters: 200, epoch: 2 | loss: 29.3768539
	speed: 0.0104s/iter; left time: 245.0514s
Epoch: 2 cost time: 2.812708616256714
Epoch: 2, Steps: 239 Train Loss: 29.7801 (Forecasting Loss:0.3178 + XiCon Loss:2.9462 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.2797
Validation loss decreased (0.336159 --> 0.203564).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.2594051
	speed: 0.0137s/iter; left time: 320.6090s
	iters: 200, epoch: 3 | loss: 29.1371727
	speed: 0.0115s/iter; left time: 266.2910s
Epoch: 3 cost time: 2.9513790607452393
Epoch: 3, Steps: 239 Train Loss: 29.0813 (Forecasting Loss:0.2801 + XiCon Loss:2.8801 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.2734
Validation loss decreased (0.203564 --> 0.199003).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.8377075
	speed: 0.0134s/iter; left time: 308.2065s
	iters: 200, epoch: 4 | loss: 29.4057617
	speed: 0.0106s/iter; left time: 243.8814s
Epoch: 4 cost time: 2.8595499992370605
Epoch: 4, Steps: 239 Train Loss: 28.9932 (Forecasting Loss:0.2743 + XiCon Loss:2.8719 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2694
Validation loss decreased (0.199003 --> 0.195014).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.2159767
	speed: 0.0135s/iter; left time: 308.4872s
	iters: 200, epoch: 5 | loss: 29.5439739
	speed: 0.0107s/iter; left time: 244.3626s
Epoch: 5 cost time: 2.861294746398926
Epoch: 5, Steps: 239 Train Loss: 28.9397 (Forecasting Loss:0.2708 + XiCon Loss:2.8669 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2682
Validation loss decreased (0.195014 --> 0.194599).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.1172237
	speed: 0.0144s/iter; left time: 324.7656s
	iters: 200, epoch: 6 | loss: 29.2173595
	speed: 0.0101s/iter; left time: 228.2951s
Epoch: 6 cost time: 2.8895275592803955
Epoch: 6, Steps: 239 Train Loss: 28.9541 (Forecasting Loss:0.2692 + XiCon Loss:2.8685 x Lambda(10.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2674
Validation loss decreased (0.194599 --> 0.193765).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.9311752
	speed: 0.0129s/iter; left time: 289.6206s
	iters: 200, epoch: 7 | loss: 28.7993088
	speed: 0.0106s/iter; left time: 235.6888s
Epoch: 7 cost time: 2.783517837524414
Epoch: 7, Steps: 239 Train Loss: 28.9220 (Forecasting Loss:0.2684 + XiCon Loss:2.8654 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2674
Validation loss decreased (0.193765 --> 0.193182).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.9725437
	speed: 0.0132s/iter; left time: 291.9762s
	iters: 200, epoch: 8 | loss: 29.0701904
	speed: 0.0107s/iter; left time: 235.5573s
Epoch: 8 cost time: 2.8325748443603516
Epoch: 8, Steps: 239 Train Loss: 28.9287 (Forecasting Loss:0.2682 + XiCon Loss:2.8661 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2669
Validation loss decreased (0.193182 --> 0.193085).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.7556419
	speed: 0.0134s/iter; left time: 293.0967s
	iters: 200, epoch: 9 | loss: 29.2688179
	speed: 0.0108s/iter; left time: 234.7285s
Epoch: 9 cost time: 2.8833067417144775
Epoch: 9, Steps: 239 Train Loss: 28.8919 (Forecasting Loss:0.2680 + XiCon Loss:2.8624 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2669
Validation loss decreased (0.193085 --> 0.193084).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.0388737
	speed: 0.0128s/iter; left time: 277.7308s
	iters: 200, epoch: 10 | loss: 28.8745041
	speed: 0.0103s/iter; left time: 221.4338s
Epoch: 10 cost time: 2.741770029067993
Epoch: 10, Steps: 239 Train Loss: 28.9311 (Forecasting Loss:0.2679 + XiCon Loss:2.8663 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2669
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.7610321
	speed: 0.0141s/iter; left time: 301.7177s
	iters: 200, epoch: 11 | loss: 28.9965553
	speed: 0.0110s/iter; left time: 234.3656s
Epoch: 11 cost time: 2.9421579837799072
Epoch: 11, Steps: 239 Train Loss: 28.9312 (Forecasting Loss:0.2679 + XiCon Loss:2.8663 x Lambda(10.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2669
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.5503521
	speed: 0.0135s/iter; left time: 286.7308s
	iters: 200, epoch: 12 | loss: 29.1271515
	speed: 0.0109s/iter; left time: 230.6795s
Epoch: 12 cost time: 2.9443604946136475
Epoch: 12, Steps: 239 Train Loss: 28.9180 (Forecasting Loss:0.2676 + XiCon Loss:2.8650 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2669
Validation loss decreased (0.193084 --> 0.192768).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 28.9515915
	speed: 0.0136s/iter; left time: 284.9475s
	iters: 200, epoch: 13 | loss: 28.6240063
	speed: 0.0113s/iter; left time: 235.0047s
Epoch: 13 cost time: 2.942183494567871
Epoch: 13, Steps: 239 Train Loss: 28.9387 (Forecasting Loss:0.2675 + XiCon Loss:2.8671 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.2669
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 28.9002323
	speed: 0.0135s/iter; left time: 279.4022s
	iters: 200, epoch: 14 | loss: 28.9805164
	speed: 0.0111s/iter; left time: 229.5196s
Epoch: 14 cost time: 2.928691864013672
Epoch: 14, Steps: 239 Train Loss: 28.9237 (Forecasting Loss:0.2677 + XiCon Loss:2.8656 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2669
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.2952137
	speed: 0.0134s/iter; left time: 273.1653s
	iters: 200, epoch: 15 | loss: 28.6969032
	speed: 0.0106s/iter; left time: 216.5621s
Epoch: 15 cost time: 2.8691346645355225
Epoch: 15, Steps: 239 Train Loss: 28.9094 (Forecasting Loss:0.2676 + XiCon Loss:2.8642 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2669
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 28.8350201
	speed: 0.0135s/iter; left time: 272.6188s
	iters: 200, epoch: 16 | loss: 29.1886749
	speed: 0.0103s/iter; left time: 207.7484s
Epoch: 16 cost time: 2.889603614807129
Epoch: 16, Steps: 239 Train Loss: 28.8916 (Forecasting Loss:0.2678 + XiCon Loss:2.8624 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2669
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 28.5768108
	speed: 0.0127s/iter; left time: 253.0108s
	iters: 200, epoch: 17 | loss: 28.8493690
	speed: 0.0115s/iter; left time: 229.0503s
Epoch: 17 cost time: 2.874389410018921
Epoch: 17, Steps: 239 Train Loss: 28.9284 (Forecasting Loss:0.2678 + XiCon Loss:2.8661 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2669
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 28.8722878
	speed: 0.0136s/iter; left time: 268.6987s
	iters: 200, epoch: 18 | loss: 29.1569824
	speed: 0.0116s/iter; left time: 227.7542s
Epoch: 18 cost time: 2.995959997177124
Epoch: 18, Steps: 239 Train Loss: 28.9207 (Forecasting Loss:0.2677 + XiCon Loss:2.8653 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2669
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 28.9966812
	speed: 0.0131s/iter; left time: 256.0866s
	iters: 200, epoch: 19 | loss: 29.0799294
	speed: 0.0108s/iter; left time: 209.6401s
Epoch: 19 cost time: 2.8340671062469482
Epoch: 19, Steps: 239 Train Loss: 28.8966 (Forecasting Loss:0.2676 + XiCon Loss:2.8629 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2669
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 28.8315449
	speed: 0.0136s/iter; left time: 262.5240s
	iters: 200, epoch: 20 | loss: 28.4743576
	speed: 0.0111s/iter; left time: 211.9753s
Epoch: 20 cost time: 2.953770637512207
Epoch: 20, Steps: 239 Train Loss: 28.9199 (Forecasting Loss:0.2676 + XiCon Loss:2.8652 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2669
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 28.7068195
	speed: 0.0126s/iter; left time: 238.8068s
	iters: 200, epoch: 21 | loss: 29.0315094
	speed: 0.0110s/iter; left time: 208.0297s
Epoch: 21 cost time: 2.820673942565918
Epoch: 21, Steps: 239 Train Loss: 28.9178 (Forecasting Loss:0.2679 + XiCon Loss:2.8650 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2669
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 28.8577404
	speed: 0.0129s/iter; left time: 243.1061s
	iters: 200, epoch: 22 | loss: 28.7100735
	speed: 0.0108s/iter; left time: 202.4453s
Epoch: 22 cost time: 2.820380210876465
Epoch: 22, Steps: 239 Train Loss: 28.9348 (Forecasting Loss:0.2679 + XiCon Loss:2.8667 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2669
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.2094716578722, mae:0.3243354558944702, mape:2.4889705181121826, mspe:4056.420654296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2097+-0.00359, MAE:0.3236+-0.00317, MAPE:2.3860+-0.09529, MSPE:3346.9753+-644.67969, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9944
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 30.0753441
	speed: 0.0206s/iter; left time: 472.4035s
	iters: 200, epoch: 1 | loss: 30.3349915
	speed: 0.0126s/iter; left time: 287.1600s
Epoch: 1 cost time: 3.7070789337158203
Epoch: 1, Steps: 230 Train Loss: 30.2054 (Forecasting Loss:0.7228 + XiCon Loss:2.9483 x Lambda(10.0)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.5303
Validation loss decreased (inf --> 0.330951).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.4002972
	speed: 0.0149s/iter; left time: 337.3533s
	iters: 200, epoch: 2 | loss: 27.8017616
	speed: 0.0127s/iter; left time: 287.3699s
Epoch: 2 cost time: 3.1995489597320557
Epoch: 2, Steps: 230 Train Loss: 28.8054 (Forecasting Loss:0.4370 + XiCon Loss:2.8368 x Lambda(10.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.3858
Validation loss decreased (0.330951 --> 0.220733).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.2353420
	speed: 0.0152s/iter; left time: 340.1264s
	iters: 200, epoch: 3 | loss: 27.6277828
	speed: 0.0137s/iter; left time: 305.1072s
Epoch: 3 cost time: 3.288261651992798
Epoch: 3, Steps: 230 Train Loss: 28.0586 (Forecasting Loss:0.4039 + XiCon Loss:2.7655 x Lambda(10.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.3788
Validation loss decreased (0.220733 --> 0.212366).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.0707302
	speed: 0.0151s/iter; left time: 335.3129s
	iters: 200, epoch: 4 | loss: 28.0602016
	speed: 0.0135s/iter; left time: 299.4110s
Epoch: 4 cost time: 3.27361798286438
Epoch: 4, Steps: 230 Train Loss: 27.9730 (Forecasting Loss:0.3958 + XiCon Loss:2.7577 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3728
Validation loss decreased (0.212366 --> 0.209958).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.3416748
	speed: 0.0156s/iter; left time: 343.8272s
	iters: 200, epoch: 5 | loss: 28.0420685
	speed: 0.0125s/iter; left time: 273.8297s
Epoch: 5 cost time: 3.2203078269958496
Epoch: 5, Steps: 230 Train Loss: 27.9568 (Forecasting Loss:0.3922 + XiCon Loss:2.7565 x Lambda(10.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.3700
Validation loss decreased (0.209958 --> 0.208278).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 28.1582851
	speed: 0.0147s/iter; left time: 319.5981s
	iters: 200, epoch: 6 | loss: 27.7864990
	speed: 0.0128s/iter; left time: 276.2730s
Epoch: 6 cost time: 3.151224136352539
Epoch: 6, Steps: 230 Train Loss: 27.9529 (Forecasting Loss:0.3898 + XiCon Loss:2.7563 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.3685
Validation loss decreased (0.208278 --> 0.208213).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.0831566
	speed: 0.0154s/iter; left time: 331.7836s
	iters: 200, epoch: 7 | loss: 27.9703598
	speed: 0.0133s/iter; left time: 284.1488s
Epoch: 7 cost time: 3.3033370971679688
Epoch: 7, Steps: 230 Train Loss: 27.9427 (Forecasting Loss:0.3891 + XiCon Loss:2.7554 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3669
Validation loss decreased (0.208213 --> 0.207540).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.2621422
	speed: 0.0147s/iter; left time: 313.4535s
	iters: 200, epoch: 8 | loss: 27.7518692
	speed: 0.0130s/iter; left time: 275.5140s
Epoch: 8 cost time: 3.191279172897339
Epoch: 8, Steps: 230 Train Loss: 27.9648 (Forecasting Loss:0.3881 + XiCon Loss:2.7577 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3667
Validation loss decreased (0.207540 --> 0.207539).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 27.7899704
	speed: 0.0148s/iter; left time: 311.7439s
	iters: 200, epoch: 9 | loss: 28.0448875
	speed: 0.0123s/iter; left time: 257.5891s
Epoch: 9 cost time: 3.114759922027588
Epoch: 9, Steps: 230 Train Loss: 27.9367 (Forecasting Loss:0.3880 + XiCon Loss:2.7549 x Lambda(10.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3664
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 27.6960754
	speed: 0.0152s/iter; left time: 317.5256s
	iters: 200, epoch: 10 | loss: 28.1385803
	speed: 0.0133s/iter; left time: 275.8784s
Epoch: 10 cost time: 3.2732248306274414
Epoch: 10, Steps: 230 Train Loss: 27.9352 (Forecasting Loss:0.3883 + XiCon Loss:2.7547 x Lambda(10.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3663
Validation loss decreased (0.207539 --> 0.207442).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 27.5596619
	speed: 0.0156s/iter; left time: 322.1808s
	iters: 200, epoch: 11 | loss: 28.0088615
	speed: 0.0125s/iter; left time: 256.8699s
Epoch: 11 cost time: 3.2554430961608887
Epoch: 11, Steps: 230 Train Loss: 27.9224 (Forecasting Loss:0.3877 + XiCon Loss:2.7535 x Lambda(10.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.3663
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 27.8223057
	speed: 0.0145s/iter; left time: 294.9091s
	iters: 200, epoch: 12 | loss: 27.9859772
	speed: 0.0140s/iter; left time: 283.9145s
Epoch: 12 cost time: 3.2699527740478516
Epoch: 12, Steps: 230 Train Loss: 27.9533 (Forecasting Loss:0.3880 + XiCon Loss:2.7565 x Lambda(10.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3664
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 27.9213734
	speed: 0.0153s/iter; left time: 308.7008s
	iters: 200, epoch: 13 | loss: 28.0268745
	speed: 0.0126s/iter; left time: 251.7371s
Epoch: 13 cost time: 3.1939427852630615
Epoch: 13, Steps: 230 Train Loss: 27.9098 (Forecasting Loss:0.3878 + XiCon Loss:2.7522 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3663
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 28.2199211
	speed: 0.0152s/iter; left time: 303.3581s
	iters: 200, epoch: 14 | loss: 28.1349335
	speed: 0.0129s/iter; left time: 255.1249s
Epoch: 14 cost time: 3.217775583267212
Epoch: 14, Steps: 230 Train Loss: 27.9361 (Forecasting Loss:0.3874 + XiCon Loss:2.7549 x Lambda(10.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3663
Validation loss decreased (0.207442 --> 0.207378).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.1734161
	speed: 0.0162s/iter; left time: 318.6340s
	iters: 200, epoch: 15 | loss: 27.8060246
	speed: 0.0127s/iter; left time: 248.8877s
Epoch: 15 cost time: 3.2913384437561035
Epoch: 15, Steps: 230 Train Loss: 27.9379 (Forecasting Loss:0.3880 + XiCon Loss:2.7550 x Lambda(10.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.3663
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 27.7087269
	speed: 0.0149s/iter; left time: 289.0707s
	iters: 200, epoch: 16 | loss: 27.8845005
	speed: 0.0124s/iter; left time: 240.3984s
Epoch: 16 cost time: 3.122183322906494
Epoch: 16, Steps: 230 Train Loss: 27.9219 (Forecasting Loss:0.3884 + XiCon Loss:2.7534 x Lambda(10.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.3663
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 27.8326950
	speed: 0.0147s/iter; left time: 282.7674s
	iters: 200, epoch: 17 | loss: 27.9153557
	speed: 0.0131s/iter; left time: 250.7173s
Epoch: 17 cost time: 3.2074310779571533
Epoch: 17, Steps: 230 Train Loss: 27.9430 (Forecasting Loss:0.3875 + XiCon Loss:2.7555 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3663
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 27.7006474
	speed: 0.0160s/iter; left time: 304.5006s
	iters: 200, epoch: 18 | loss: 28.2193375
	speed: 0.0127s/iter; left time: 240.2929s
Epoch: 18 cost time: 3.277679920196533
Epoch: 18, Steps: 230 Train Loss: 27.9405 (Forecasting Loss:0.3876 + XiCon Loss:2.7553 x Lambda(10.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3663
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 27.4894466
	speed: 0.0155s/iter; left time: 291.0983s
	iters: 200, epoch: 19 | loss: 27.7827358
	speed: 0.0145s/iter; left time: 270.3134s
Epoch: 19 cost time: 3.40211820602417
Epoch: 19, Steps: 230 Train Loss: 27.9323 (Forecasting Loss:0.3878 + XiCon Loss:2.7544 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3663
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 27.7240963
	speed: 0.0155s/iter; left time: 286.9079s
	iters: 200, epoch: 20 | loss: 28.2465115
	speed: 0.0135s/iter; left time: 248.0319s
Epoch: 20 cost time: 3.331761121749878
Epoch: 20, Steps: 230 Train Loss: 27.9597 (Forecasting Loss:0.3878 + XiCon Loss:2.7572 x Lambda(10.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3663
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 27.8059139
	speed: 0.0155s/iter; left time: 284.2660s
	iters: 200, epoch: 21 | loss: 27.9925156
	speed: 0.0126s/iter; left time: 229.0326s
Epoch: 21 cost time: 3.2498037815093994
Epoch: 21, Steps: 230 Train Loss: 27.9180 (Forecasting Loss:0.3878 + XiCon Loss:2.7530 x Lambda(10.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.3663
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 28.0000076
	speed: 0.0158s/iter; left time: 285.5314s
	iters: 200, epoch: 22 | loss: 28.1885223
	speed: 0.0135s/iter; left time: 242.2314s
Epoch: 22 cost time: 3.364828109741211
Epoch: 22, Steps: 230 Train Loss: 27.9490 (Forecasting Loss:0.3875 + XiCon Loss:2.7561 x Lambda(10.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.3663
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 27.9794788
	speed: 0.0148s/iter; left time: 264.0019s
	iters: 200, epoch: 23 | loss: 27.9307575
	speed: 0.0130s/iter; left time: 229.9818s
Epoch: 23 cost time: 3.2348406314849854
Epoch: 23, Steps: 230 Train Loss: 27.9382 (Forecasting Loss:0.3880 + XiCon Loss:2.7550 x Lambda(10.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.3663
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 27.8803730
	speed: 0.0156s/iter; left time: 274.1121s
	iters: 200, epoch: 24 | loss: 27.8265228
	speed: 0.0130s/iter; left time: 227.4880s
Epoch: 24 cost time: 3.314951181411743
Epoch: 24, Steps: 230 Train Loss: 27.9071 (Forecasting Loss:0.3877 + XiCon Loss:2.7519 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3663
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.31636038422584534, mae:0.416289359331131, mape:4.324748516082764, mspe:30512.3125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0443
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 30.3684425
	speed: 0.0162s/iter; left time: 369.9489s
	iters: 200, epoch: 1 | loss: 29.9993439
	speed: 0.0126s/iter; left time: 287.7193s
Epoch: 1 cost time: 3.2997043132781982
Epoch: 1, Steps: 230 Train Loss: 30.4163 (Forecasting Loss:0.7254 + XiCon Loss:2.9691 x Lambda(10.0)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.5337
Validation loss decreased (inf --> 0.331357).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.3577251
	speed: 0.0161s/iter; left time: 363.9160s
	iters: 200, epoch: 2 | loss: 28.3165665
	speed: 0.0136s/iter; left time: 307.6931s
Epoch: 2 cost time: 3.4061641693115234
Epoch: 2, Steps: 230 Train Loss: 28.9695 (Forecasting Loss:0.4387 + XiCon Loss:2.8531 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.3857
Validation loss decreased (0.331357 --> 0.218923).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.3182564
	speed: 0.0147s/iter; left time: 329.7571s
	iters: 200, epoch: 3 | loss: 28.6051121
	speed: 0.0137s/iter; left time: 305.7258s
Epoch: 3 cost time: 3.235384225845337
Epoch: 3, Steps: 230 Train Loss: 28.3824 (Forecasting Loss:0.4045 + XiCon Loss:2.7978 x Lambda(10.0)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.3789
Validation loss decreased (0.218923 --> 0.213926).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.3671093
	speed: 0.0161s/iter; left time: 357.0803s
	iters: 200, epoch: 4 | loss: 28.4573402
	speed: 0.0137s/iter; left time: 302.1553s
Epoch: 4 cost time: 3.376760244369507
Epoch: 4, Steps: 230 Train Loss: 28.2192 (Forecasting Loss:0.3975 + XiCon Loss:2.7822 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.3744
Validation loss decreased (0.213926 --> 0.211639).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.1709309
	speed: 0.0151s/iter; left time: 331.1072s
	iters: 200, epoch: 5 | loss: 28.0013580
	speed: 0.0123s/iter; left time: 269.5978s
Epoch: 5 cost time: 3.1727795600891113
Epoch: 5, Steps: 230 Train Loss: 28.1344 (Forecasting Loss:0.3941 + XiCon Loss:2.7740 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.3739
Validation loss decreased (0.211639 --> 0.210666).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 27.9919930
	speed: 0.0151s/iter; left time: 328.8903s
	iters: 200, epoch: 6 | loss: 28.0201931
	speed: 0.0129s/iter; left time: 279.2624s
Epoch: 6 cost time: 3.247124671936035
Epoch: 6, Steps: 230 Train Loss: 28.0829 (Forecasting Loss:0.3924 + XiCon Loss:2.7691 x Lambda(10.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.3729
Validation loss decreased (0.210666 --> 0.210483).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 27.8439293
	speed: 0.0163s/iter; left time: 351.4421s
	iters: 200, epoch: 7 | loss: 28.8875675
	speed: 0.0139s/iter; left time: 298.6226s
Epoch: 7 cost time: 3.4562408924102783
Epoch: 7, Steps: 230 Train Loss: 28.0864 (Forecasting Loss:0.3914 + XiCon Loss:2.7695 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.3731
Validation loss decreased (0.210483 --> 0.210266).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.2084751
	speed: 0.0162s/iter; left time: 345.7652s
	iters: 200, epoch: 8 | loss: 27.9286613
	speed: 0.0137s/iter; left time: 289.9273s
Epoch: 8 cost time: 3.436863422393799
Epoch: 8, Steps: 230 Train Loss: 28.1030 (Forecasting Loss:0.3910 + XiCon Loss:2.7712 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3731
Validation loss decreased (0.210266 --> 0.210159).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.2734127
	speed: 0.0156s/iter; left time: 328.4250s
	iters: 200, epoch: 9 | loss: 28.3761292
	speed: 0.0139s/iter; left time: 292.1370s
Epoch: 9 cost time: 3.386359453201294
Epoch: 9, Steps: 230 Train Loss: 28.1069 (Forecasting Loss:0.3907 + XiCon Loss:2.7716 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3730
Validation loss decreased (0.210159 --> 0.210114).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 27.6072044
	speed: 0.0159s/iter; left time: 330.4579s
	iters: 200, epoch: 10 | loss: 27.8906651
	speed: 0.0128s/iter; left time: 264.8236s
Epoch: 10 cost time: 3.268735885620117
Epoch: 10, Steps: 230 Train Loss: 28.0962 (Forecasting Loss:0.3906 + XiCon Loss:2.7706 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3730
Validation loss decreased (0.210114 --> 0.209853).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 27.7253952
	speed: 0.0156s/iter; left time: 320.4744s
	iters: 200, epoch: 11 | loss: 28.4437466
	speed: 0.0127s/iter; left time: 261.0517s
Epoch: 11 cost time: 3.241145610809326
Epoch: 11, Steps: 230 Train Loss: 28.1045 (Forecasting Loss:0.3907 + XiCon Loss:2.7714 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3730
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.1004963
	speed: 0.0152s/iter; left time: 309.7452s
	iters: 200, epoch: 12 | loss: 27.7394257
	speed: 0.0127s/iter; left time: 256.6811s
Epoch: 12 cost time: 3.1901743412017822
Epoch: 12, Steps: 230 Train Loss: 28.0951 (Forecasting Loss:0.3906 + XiCon Loss:2.7705 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3730
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 28.6920109
	speed: 0.0166s/iter; left time: 333.7354s
	iters: 200, epoch: 13 | loss: 28.3929577
	speed: 0.0127s/iter; left time: 254.3602s
Epoch: 13 cost time: 3.3637149333953857
Epoch: 13, Steps: 230 Train Loss: 28.0874 (Forecasting Loss:0.3906 + XiCon Loss:2.7697 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.3730
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 28.5859814
	speed: 0.0153s/iter; left time: 305.4126s
	iters: 200, epoch: 14 | loss: 28.5805321
	speed: 0.0126s/iter; left time: 248.9253s
Epoch: 14 cost time: 3.2499260902404785
Epoch: 14, Steps: 230 Train Loss: 28.0836 (Forecasting Loss:0.3906 + XiCon Loss:2.7693 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3730
Validation loss decreased (0.209853 --> 0.209695).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.0044250
	speed: 0.0151s/iter; left time: 297.3458s
	iters: 200, epoch: 15 | loss: 27.6959953
	speed: 0.0132s/iter; left time: 257.7114s
Epoch: 15 cost time: 3.2195475101470947
Epoch: 15, Steps: 230 Train Loss: 28.1273 (Forecasting Loss:0.3904 + XiCon Loss:2.7737 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3730
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 28.4931374
	speed: 0.0157s/iter; left time: 305.7733s
	iters: 200, epoch: 16 | loss: 27.8171406
	speed: 0.0125s/iter; left time: 242.6183s
Epoch: 16 cost time: 3.2321648597717285
Epoch: 16, Steps: 230 Train Loss: 28.0907 (Forecasting Loss:0.3906 + XiCon Loss:2.7700 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3730
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 27.9268227
	speed: 0.0153s/iter; left time: 294.8403s
	iters: 200, epoch: 17 | loss: 27.6296864
	speed: 0.0127s/iter; left time: 242.4548s
Epoch: 17 cost time: 3.2341806888580322
Epoch: 17, Steps: 230 Train Loss: 28.0828 (Forecasting Loss:0.3904 + XiCon Loss:2.7692 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3730
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 28.0172005
	speed: 0.0149s/iter; left time: 283.0291s
	iters: 200, epoch: 18 | loss: 28.0945053
	speed: 0.0127s/iter; left time: 239.8916s
Epoch: 18 cost time: 3.158414363861084
Epoch: 18, Steps: 230 Train Loss: 28.1098 (Forecasting Loss:0.3905 + XiCon Loss:2.7719 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3730
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 28.5633926
	speed: 0.0157s/iter; left time: 295.0697s
	iters: 200, epoch: 19 | loss: 28.0826607
	speed: 0.0125s/iter; left time: 233.3364s
Epoch: 19 cost time: 3.2441554069519043
Epoch: 19, Steps: 230 Train Loss: 28.1025 (Forecasting Loss:0.3906 + XiCon Loss:2.7712 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3730
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 28.3942184
	speed: 0.0150s/iter; left time: 278.6745s
	iters: 200, epoch: 20 | loss: 27.7838268
	speed: 0.0127s/iter; left time: 234.2333s
Epoch: 20 cost time: 3.205599784851074
Epoch: 20, Steps: 230 Train Loss: 28.0789 (Forecasting Loss:0.3906 + XiCon Loss:2.7688 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3730
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 28.0100040
	speed: 0.0155s/iter; left time: 283.6389s
	iters: 200, epoch: 21 | loss: 28.3820400
	speed: 0.0129s/iter; left time: 235.6564s
Epoch: 21 cost time: 3.2671468257904053
Epoch: 21, Steps: 230 Train Loss: 28.1123 (Forecasting Loss:0.3905 + XiCon Loss:2.7722 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3730
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 28.0446739
	speed: 0.0160s/iter; left time: 288.6822s
	iters: 200, epoch: 22 | loss: 27.8367290
	speed: 0.0127s/iter; left time: 227.7386s
Epoch: 22 cost time: 3.2940473556518555
Epoch: 22, Steps: 230 Train Loss: 28.1105 (Forecasting Loss:0.3905 + XiCon Loss:2.7720 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3730
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 28.2227211
	speed: 0.0156s/iter; left time: 278.8321s
	iters: 200, epoch: 23 | loss: 27.8937473
	speed: 0.0134s/iter; left time: 237.0917s
Epoch: 23 cost time: 3.3041627407073975
Epoch: 23, Steps: 230 Train Loss: 28.1130 (Forecasting Loss:0.3906 + XiCon Loss:2.7722 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3730
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 28.0182438
	speed: 0.0151s/iter; left time: 266.3346s
	iters: 200, epoch: 24 | loss: 27.8739700
	speed: 0.0134s/iter; left time: 234.5335s
Epoch: 24 cost time: 3.284451484680176
Epoch: 24, Steps: 230 Train Loss: 28.0862 (Forecasting Loss:0.3905 + XiCon Loss:2.7696 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3730
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.32418933510780334, mae:0.4218463897705078, mape:4.447965145111084, mspe:31717.15625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 30.3979702
	speed: 0.0170s/iter; left time: 388.3444s
	iters: 200, epoch: 1 | loss: 30.2649956
	speed: 0.0131s/iter; left time: 298.4056s
Epoch: 1 cost time: 3.447033405303955
Epoch: 1, Steps: 230 Train Loss: 30.3781 (Forecasting Loss:0.7322 + XiCon Loss:2.9646 x Lambda(10.0)), Vali MSE Loss: 0.3359 Test MSE Loss: 0.5483
Validation loss decreased (inf --> 0.335872).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.0545616
	speed: 0.0147s/iter; left time: 332.5429s
	iters: 200, epoch: 2 | loss: 28.8296490
	speed: 0.0130s/iter; left time: 293.4138s
Epoch: 2 cost time: 3.1823487281799316
Epoch: 2, Steps: 230 Train Loss: 29.0998 (Forecasting Loss:0.4373 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3844
Validation loss decreased (0.335872 --> 0.218257).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.0881977
	speed: 0.0155s/iter; left time: 347.9563s
	iters: 200, epoch: 3 | loss: 28.4230061
	speed: 0.0133s/iter; left time: 296.6923s
Epoch: 3 cost time: 3.3108818531036377
Epoch: 3, Steps: 230 Train Loss: 28.3970 (Forecasting Loss:0.4026 + XiCon Loss:2.7994 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.3796
Validation loss decreased (0.218257 --> 0.213058).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.0225544
	speed: 0.0171s/iter; left time: 380.8094s
	iters: 200, epoch: 4 | loss: 27.5377636
	speed: 0.0132s/iter; left time: 292.8404s
Epoch: 4 cost time: 3.475987672805786
Epoch: 4, Steps: 230 Train Loss: 28.0916 (Forecasting Loss:0.3966 + XiCon Loss:2.7695 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3711
Validation loss decreased (0.213058 --> 0.210151).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 27.5537205
	speed: 0.0160s/iter; left time: 351.1811s
	iters: 200, epoch: 5 | loss: 27.7300797
	speed: 0.0135s/iter; left time: 296.4075s
Epoch: 5 cost time: 3.375175952911377
Epoch: 5, Steps: 230 Train Loss: 27.8926 (Forecasting Loss:0.3955 + XiCon Loss:2.7497 x Lambda(10.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.3764
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 27.2262478
	speed: 0.0150s/iter; left time: 325.9098s
	iters: 200, epoch: 6 | loss: 27.6919956
	speed: 0.0127s/iter; left time: 274.9021s
Epoch: 6 cost time: 3.178854465484619
Epoch: 6, Steps: 230 Train Loss: 27.8783 (Forecasting Loss:0.3953 + XiCon Loss:2.7483 x Lambda(10.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.3760
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 27.5391331
	speed: 0.0159s/iter; left time: 341.3466s
	iters: 200, epoch: 7 | loss: 27.9146252
	speed: 0.0133s/iter; left time: 284.2124s
Epoch: 7 cost time: 3.3269691467285156
Epoch: 7, Steps: 230 Train Loss: 27.8032 (Forecasting Loss:0.3933 + XiCon Loss:2.7410 x Lambda(10.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.3736
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 27.6911316
	speed: 0.0166s/iter; left time: 353.4930s
	iters: 200, epoch: 8 | loss: 27.5581398
	speed: 0.0130s/iter; left time: 275.2635s
Epoch: 8 cost time: 3.391134023666382
Epoch: 8, Steps: 230 Train Loss: 27.7618 (Forecasting Loss:0.3919 + XiCon Loss:2.7370 x Lambda(10.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.3722
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 27.7191048
	speed: 0.0150s/iter; left time: 315.7024s
	iters: 200, epoch: 9 | loss: 27.7784729
	speed: 0.0133s/iter; left time: 277.9671s
Epoch: 9 cost time: 3.245643138885498
Epoch: 9, Steps: 230 Train Loss: 27.7612 (Forecasting Loss:0.3909 + XiCon Loss:2.7370 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.3717
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 27.8447666
	speed: 0.0155s/iter; left time: 322.7616s
	iters: 200, epoch: 10 | loss: 27.5736561
	speed: 0.0123s/iter; left time: 254.6221s
Epoch: 10 cost time: 3.17464542388916
Epoch: 10, Steps: 230 Train Loss: 27.7719 (Forecasting Loss:0.3906 + XiCon Loss:2.7381 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.3715
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 27.5453968
	speed: 0.0152s/iter; left time: 312.6721s
	iters: 200, epoch: 11 | loss: 27.5024586
	speed: 0.0134s/iter; left time: 273.8307s
Epoch: 11 cost time: 3.252229690551758
Epoch: 11, Steps: 230 Train Loss: 27.7585 (Forecasting Loss:0.3904 + XiCon Loss:2.7368 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.3713
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 27.6716576
	speed: 0.0149s/iter; left time: 302.8024s
	iters: 200, epoch: 12 | loss: 27.9507008
	speed: 0.0124s/iter; left time: 252.2132s
Epoch: 12 cost time: 3.156961441040039
Epoch: 12, Steps: 230 Train Loss: 27.7748 (Forecasting Loss:0.3905 + XiCon Loss:2.7384 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.3712
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 27.5369759
	speed: 0.0157s/iter; left time: 316.1139s
	iters: 200, epoch: 13 | loss: 27.3708744
	speed: 0.0133s/iter; left time: 265.9530s
Epoch: 13 cost time: 3.350005865097046
Epoch: 13, Steps: 230 Train Loss: 27.7666 (Forecasting Loss:0.3904 + XiCon Loss:2.7376 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.3712
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 27.7155704
	speed: 0.0154s/iter; left time: 306.9615s
	iters: 200, epoch: 14 | loss: 27.7591248
	speed: 0.0135s/iter; left time: 268.0430s
Epoch: 14 cost time: 3.3706822395324707
Epoch: 14, Steps: 230 Train Loss: 27.7514 (Forecasting Loss:0.3903 + XiCon Loss:2.7361 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.3712
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.322114497423172, mae:0.42009979486465454, mape:4.128940582275391, mspe:25268.3984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9400
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 29.9356823
	speed: 0.0154s/iter; left time: 353.2913s
	iters: 200, epoch: 1 | loss: 30.2029076
	speed: 0.0128s/iter; left time: 292.0241s
Epoch: 1 cost time: 3.2397501468658447
Epoch: 1, Steps: 230 Train Loss: 30.2295 (Forecasting Loss:0.7225 + XiCon Loss:2.9507 x Lambda(10.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.5331
Validation loss decreased (inf --> 0.330756).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.7075481
	speed: 0.0164s/iter; left time: 371.9254s
	iters: 200, epoch: 2 | loss: 27.9317970
	speed: 0.0128s/iter; left time: 288.2720s
Epoch: 2 cost time: 3.3226232528686523
Epoch: 2, Steps: 230 Train Loss: 28.7665 (Forecasting Loss:0.4325 + XiCon Loss:2.8334 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.3886
Validation loss decreased (0.330756 --> 0.218899).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.1336975
	speed: 0.0158s/iter; left time: 354.2274s
	iters: 200, epoch: 3 | loss: 28.2421932
	speed: 0.0125s/iter; left time: 279.6620s
Epoch: 3 cost time: 3.2362372875213623
Epoch: 3, Steps: 230 Train Loss: 28.1250 (Forecasting Loss:0.3869 + XiCon Loss:2.7738 x Lambda(10.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.3745
Validation loss decreased (0.218899 --> 0.213744).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 27.6202621
	speed: 0.0158s/iter; left time: 351.5706s
	iters: 200, epoch: 4 | loss: 28.2370205
	speed: 0.0127s/iter; left time: 281.6082s
Epoch: 4 cost time: 3.2833051681518555
Epoch: 4, Steps: 230 Train Loss: 28.0469 (Forecasting Loss:0.3783 + XiCon Loss:2.7669 x Lambda(10.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3730
Validation loss decreased (0.213744 --> 0.208636).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 28.1468658
	speed: 0.0154s/iter; left time: 338.3275s
	iters: 200, epoch: 5 | loss: 27.5493431
	speed: 0.0124s/iter; left time: 270.7193s
Epoch: 5 cost time: 3.231203556060791
Epoch: 5, Steps: 230 Train Loss: 27.9924 (Forecasting Loss:0.3731 + XiCon Loss:2.7619 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.3669
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 27.8929214
	speed: 0.0152s/iter; left time: 330.8649s
	iters: 200, epoch: 6 | loss: 28.2159348
	speed: 0.0127s/iter; left time: 275.1086s
Epoch: 6 cost time: 3.1956310272216797
Epoch: 6, Steps: 230 Train Loss: 27.9617 (Forecasting Loss:0.3714 + XiCon Loss:2.7590 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3674
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 27.9363461
	speed: 0.0152s/iter; left time: 326.6070s
	iters: 200, epoch: 7 | loss: 27.8440151
	speed: 0.0129s/iter; left time: 275.6456s
Epoch: 7 cost time: 3.2002928256988525
Epoch: 7, Steps: 230 Train Loss: 27.9925 (Forecasting Loss:0.3701 + XiCon Loss:2.7622 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3673
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.0057812
	speed: 0.0150s/iter; left time: 319.4063s
	iters: 200, epoch: 8 | loss: 27.6999321
	speed: 0.0129s/iter; left time: 273.5595s
Epoch: 8 cost time: 3.1979305744171143
Epoch: 8, Steps: 230 Train Loss: 27.9801 (Forecasting Loss:0.3698 + XiCon Loss:2.7610 x Lambda(10.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.3673
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.2808018
	speed: 0.0152s/iter; left time: 320.4151s
	iters: 200, epoch: 9 | loss: 28.0762234
	speed: 0.0132s/iter; left time: 276.6187s
Epoch: 9 cost time: 3.2692391872406006
Epoch: 9, Steps: 230 Train Loss: 28.0011 (Forecasting Loss:0.3697 + XiCon Loss:2.7631 x Lambda(10.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.3674
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 27.7040234
	speed: 0.0150s/iter; left time: 312.8025s
	iters: 200, epoch: 10 | loss: 27.9736862
	speed: 0.0133s/iter; left time: 276.3996s
Epoch: 10 cost time: 3.2427310943603516
Epoch: 10, Steps: 230 Train Loss: 27.9597 (Forecasting Loss:0.3694 + XiCon Loss:2.7590 x Lambda(10.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.3671
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 27.8168430
	speed: 0.0150s/iter; left time: 308.4993s
	iters: 200, epoch: 11 | loss: 27.9329014
	speed: 0.0128s/iter; left time: 261.8395s
Epoch: 11 cost time: 3.1865479946136475
Epoch: 11, Steps: 230 Train Loss: 27.9671 (Forecasting Loss:0.3688 + XiCon Loss:2.7598 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.3671
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 27.9623528
	speed: 0.0150s/iter; left time: 305.7825s
	iters: 200, epoch: 12 | loss: 27.6508446
	speed: 0.0126s/iter; left time: 256.1258s
Epoch: 12 cost time: 3.174391508102417
Epoch: 12, Steps: 230 Train Loss: 27.9853 (Forecasting Loss:0.3687 + XiCon Loss:2.7617 x Lambda(10.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.3671
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 27.7444096
	speed: 0.0148s/iter; left time: 298.3619s
	iters: 200, epoch: 13 | loss: 28.1338005
	speed: 0.0129s/iter; left time: 258.7646s
Epoch: 13 cost time: 3.1815531253814697
Epoch: 13, Steps: 230 Train Loss: 27.9546 (Forecasting Loss:0.3691 + XiCon Loss:2.7585 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.3671
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 27.9348640
	speed: 0.0163s/iter; left time: 325.3512s
	iters: 200, epoch: 14 | loss: 28.2675686
	speed: 0.0127s/iter; left time: 252.0437s
Epoch: 14 cost time: 3.3290908336639404
Epoch: 14, Steps: 230 Train Loss: 27.9792 (Forecasting Loss:0.3686 + XiCon Loss:2.7611 x Lambda(10.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.3671
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3258041441440582, mae:0.420099139213562, mape:4.079573631286621, mspe:23865.015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0235
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 30.3996277
	speed: 0.0159s/iter; left time: 363.0138s
	iters: 200, epoch: 1 | loss: 29.7461128
	speed: 0.0127s/iter; left time: 288.7293s
Epoch: 1 cost time: 3.299445867538452
Epoch: 1, Steps: 230 Train Loss: 30.3084 (Forecasting Loss:0.7202 + XiCon Loss:2.9588 x Lambda(10.0)), Vali MSE Loss: 0.3299 Test MSE Loss: 0.5311
Validation loss decreased (inf --> 0.329865).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.4080544
	speed: 0.0165s/iter; left time: 374.0822s
	iters: 200, epoch: 2 | loss: 28.1167488
	speed: 0.0132s/iter; left time: 298.9948s
Epoch: 2 cost time: 3.432739019393921
Epoch: 2, Steps: 230 Train Loss: 28.7359 (Forecasting Loss:0.4374 + XiCon Loss:2.8299 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.3829
Validation loss decreased (0.329865 --> 0.218947).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.1468887
	speed: 0.0156s/iter; left time: 350.4155s
	iters: 200, epoch: 3 | loss: 28.1200714
	speed: 0.0130s/iter; left time: 291.4953s
Epoch: 3 cost time: 3.2738497257232666
Epoch: 3, Steps: 230 Train Loss: 27.9515 (Forecasting Loss:0.4014 + XiCon Loss:2.7550 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.3745
Validation loss decreased (0.218947 --> 0.214108).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 27.8289165
	speed: 0.0155s/iter; left time: 344.1250s
	iters: 200, epoch: 4 | loss: 28.2678146
	speed: 0.0133s/iter; left time: 294.4649s
Epoch: 4 cost time: 3.2864818572998047
Epoch: 4, Steps: 230 Train Loss: 27.8851 (Forecasting Loss:0.3931 + XiCon Loss:2.7492 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.3800
Validation loss decreased (0.214108 --> 0.212861).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 27.9086494
	speed: 0.0152s/iter; left time: 333.1816s
	iters: 200, epoch: 5 | loss: 27.8568840
	speed: 0.0134s/iter; left time: 292.2596s
Epoch: 5 cost time: 3.2601118087768555
Epoch: 5, Steps: 230 Train Loss: 27.8771 (Forecasting Loss:0.3892 + XiCon Loss:2.7488 x Lambda(10.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.3755
Validation loss decreased (0.212861 --> 0.211020).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 27.6402302
	speed: 0.0154s/iter; left time: 334.8288s
	iters: 200, epoch: 6 | loss: 27.8595428
	speed: 0.0125s/iter; left time: 270.4192s
Epoch: 6 cost time: 3.193519353866577
Epoch: 6, Steps: 230 Train Loss: 27.8860 (Forecasting Loss:0.3875 + XiCon Loss:2.7498 x Lambda(10.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.3763
Validation loss decreased (0.211020 --> 0.210514).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 27.7512016
	speed: 0.0162s/iter; left time: 349.0880s
	iters: 200, epoch: 7 | loss: 28.0702381
	speed: 0.0128s/iter; left time: 274.6368s
Epoch: 7 cost time: 3.3109171390533447
Epoch: 7, Steps: 230 Train Loss: 27.8679 (Forecasting Loss:0.3865 + XiCon Loss:2.7481 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3775
Validation loss decreased (0.210514 --> 0.210129).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 27.4461174
	speed: 0.0158s/iter; left time: 336.8678s
	iters: 200, epoch: 8 | loss: 27.4644775
	speed: 0.0127s/iter; left time: 268.9169s
Epoch: 8 cost time: 3.2646493911743164
Epoch: 8, Steps: 230 Train Loss: 27.8422 (Forecasting Loss:0.3859 + XiCon Loss:2.7456 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.3781
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 27.8112411
	speed: 0.0162s/iter; left time: 341.3602s
	iters: 200, epoch: 9 | loss: 28.0022392
	speed: 0.0134s/iter; left time: 280.5450s
Epoch: 9 cost time: 3.372073173522949
Epoch: 9, Steps: 230 Train Loss: 27.8653 (Forecasting Loss:0.3853 + XiCon Loss:2.7480 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3772
Validation loss decreased (0.210129 --> 0.209762).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 27.8796864
	speed: 0.0156s/iter; left time: 323.9269s
	iters: 200, epoch: 10 | loss: 27.6118412
	speed: 0.0129s/iter; left time: 266.7473s
Epoch: 10 cost time: 3.238048791885376
Epoch: 10, Steps: 230 Train Loss: 27.8458 (Forecasting Loss:0.3850 + XiCon Loss:2.7461 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3772
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 27.6124973
	speed: 0.0153s/iter; left time: 314.7795s
	iters: 200, epoch: 11 | loss: 27.5709476
	speed: 0.0130s/iter; left time: 265.9792s
Epoch: 11 cost time: 3.2435896396636963
Epoch: 11, Steps: 230 Train Loss: 27.8532 (Forecasting Loss:0.3852 + XiCon Loss:2.7468 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3773
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 27.7219219
	speed: 0.0160s/iter; left time: 325.7155s
	iters: 200, epoch: 12 | loss: 28.1555367
	speed: 0.0125s/iter; left time: 253.7911s
Epoch: 12 cost time: 3.3053793907165527
Epoch: 12, Steps: 230 Train Loss: 27.8641 (Forecasting Loss:0.3852 + XiCon Loss:2.7479 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3773
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 27.7052689
	speed: 0.0158s/iter; left time: 317.3548s
	iters: 200, epoch: 13 | loss: 27.5695152
	speed: 0.0131s/iter; left time: 262.3387s
Epoch: 13 cost time: 3.3479371070861816
Epoch: 13, Steps: 230 Train Loss: 27.8812 (Forecasting Loss:0.3854 + XiCon Loss:2.7496 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3772
Validation loss decreased (0.209762 --> 0.209679).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 27.7539597
	speed: 0.0160s/iter; left time: 318.0175s
	iters: 200, epoch: 14 | loss: 27.7162838
	speed: 0.0136s/iter; left time: 270.1991s
Epoch: 14 cost time: 3.4159955978393555
Epoch: 14, Steps: 230 Train Loss: 27.8491 (Forecasting Loss:0.3852 + XiCon Loss:2.7464 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3772
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 28.0171642
	speed: 0.0161s/iter; left time: 317.5094s
	iters: 200, epoch: 15 | loss: 28.2132511
	speed: 0.0124s/iter; left time: 243.2730s
Epoch: 15 cost time: 3.2487452030181885
Epoch: 15, Steps: 230 Train Loss: 27.8661 (Forecasting Loss:0.3851 + XiCon Loss:2.7481 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3772
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 27.6790791
	speed: 0.0149s/iter; left time: 290.6396s
	iters: 200, epoch: 16 | loss: 27.8332787
	speed: 0.0126s/iter; left time: 244.2045s
Epoch: 16 cost time: 3.2306783199310303
Epoch: 16, Steps: 230 Train Loss: 27.8475 (Forecasting Loss:0.3851 + XiCon Loss:2.7462 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3772
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 28.0135422
	speed: 0.0154s/iter; left time: 295.3027s
	iters: 200, epoch: 17 | loss: 28.0183105
	speed: 0.0127s/iter; left time: 242.9587s
Epoch: 17 cost time: 3.2331509590148926
Epoch: 17, Steps: 230 Train Loss: 27.8676 (Forecasting Loss:0.3852 + XiCon Loss:2.7482 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.3772
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 27.8361931
	speed: 0.0157s/iter; left time: 298.0526s
	iters: 200, epoch: 18 | loss: 27.8949547
	speed: 0.0137s/iter; left time: 258.8337s
Epoch: 18 cost time: 3.348975896835327
Epoch: 18, Steps: 230 Train Loss: 27.8543 (Forecasting Loss:0.3850 + XiCon Loss:2.7469 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3772
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 27.5073929
	speed: 0.0148s/iter; left time: 278.5945s
	iters: 200, epoch: 19 | loss: 27.7843094
	speed: 0.0130s/iter; left time: 242.2335s
Epoch: 19 cost time: 3.2025320529937744
Epoch: 19, Steps: 230 Train Loss: 27.8611 (Forecasting Loss:0.3853 + XiCon Loss:2.7476 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3772
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 27.6770172
	speed: 0.0152s/iter; left time: 281.6128s
	iters: 200, epoch: 20 | loss: 28.0301113
	speed: 0.0134s/iter; left time: 247.6991s
Epoch: 20 cost time: 3.281345844268799
Epoch: 20, Steps: 230 Train Loss: 27.8703 (Forecasting Loss:0.3852 + XiCon Loss:2.7485 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3772
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 27.5586624
	speed: 0.0154s/iter; left time: 282.1623s
	iters: 200, epoch: 21 | loss: 27.4641953
	speed: 0.0141s/iter; left time: 257.0277s
Epoch: 21 cost time: 3.3494699001312256
Epoch: 21, Steps: 230 Train Loss: 27.8562 (Forecasting Loss:0.3851 + XiCon Loss:2.7471 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.3772
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 27.8074455
	speed: 0.0164s/iter; left time: 296.8497s
	iters: 200, epoch: 22 | loss: 27.9850311
	speed: 0.0126s/iter; left time: 226.5453s
Epoch: 22 cost time: 3.321446418762207
Epoch: 22, Steps: 230 Train Loss: 27.8705 (Forecasting Loss:0.3850 + XiCon Loss:2.7485 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.3772
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 27.9389782
	speed: 0.0159s/iter; left time: 284.0406s
	iters: 200, epoch: 23 | loss: 27.9039288
	speed: 0.0130s/iter; left time: 229.9106s
Epoch: 23 cost time: 3.3665242195129395
Epoch: 23, Steps: 230 Train Loss: 27.8651 (Forecasting Loss:0.3855 + XiCon Loss:2.7480 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.3772
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.33090293407440186, mae:0.4235469400882721, mape:4.270667552947998, mspe:27361.048828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3239+-0.00659, MAE:0.4204+-0.00335, MAPE:4.2504+-0.18511, MSPE:27744.7871+-4154.07118, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0758
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 30.2299538
	speed: 0.0270s/iter; left time: 585.2007s
	iters: 200, epoch: 1 | loss: 30.8645592
	speed: 0.0204s/iter; left time: 441.0150s
Epoch: 1 cost time: 5.101996898651123
Epoch: 1, Steps: 218 Train Loss: 30.5325 (Forecasting Loss:0.8373 + XiCon Loss:2.9695 x Lambda(10.0)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.6849
Validation loss decreased (inf --> 0.336283).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.4521847
	speed: 0.0225s/iter; left time: 484.1190s
	iters: 200, epoch: 2 | loss: 28.4535141
	speed: 0.0207s/iter; left time: 443.0129s
Epoch: 2 cost time: 4.693253755569458
Epoch: 2, Steps: 218 Train Loss: 28.7786 (Forecasting Loss:0.5205 + XiCon Loss:2.8258 x Lambda(10.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.4375
Validation loss decreased (0.336283 --> 0.218637).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 27.9113197
	speed: 0.0233s/iter; left time: 495.7511s
	iters: 200, epoch: 3 | loss: 27.7294769
	speed: 0.0207s/iter; left time: 438.8743s
Epoch: 3 cost time: 4.7958080768585205
Epoch: 3, Steps: 218 Train Loss: 28.0041 (Forecasting Loss:0.4509 + XiCon Loss:2.7553 x Lambda(10.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.4298
Validation loss decreased (0.218637 --> 0.208595).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.0008030
	speed: 0.0233s/iter; left time: 490.8000s
	iters: 200, epoch: 4 | loss: 28.1100998
	speed: 0.0207s/iter; left time: 434.5659s
Epoch: 4 cost time: 4.782416105270386
Epoch: 4, Steps: 218 Train Loss: 27.9347 (Forecasting Loss:0.4422 + XiCon Loss:2.7492 x Lambda(10.0)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.4102
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.2564659
	speed: 0.0232s/iter; left time: 484.1718s
	iters: 200, epoch: 5 | loss: 29.2446384
	speed: 0.0207s/iter; left time: 428.5606s
Epoch: 5 cost time: 4.796735525131226
Epoch: 5, Steps: 218 Train Loss: 29.0212 (Forecasting Loss:0.4360 + XiCon Loss:2.8585 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.3975
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.1315060
	speed: 0.0226s/iter; left time: 465.6919s
	iters: 200, epoch: 6 | loss: 29.4648209
	speed: 0.0209s/iter; left time: 429.5488s
Epoch: 6 cost time: 4.785889387130737
Epoch: 6, Steps: 218 Train Loss: 29.2902 (Forecasting Loss:0.4409 + XiCon Loss:2.8849 x Lambda(10.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.4063
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 28.9113007
	speed: 0.0228s/iter; left time: 464.7861s
	iters: 200, epoch: 7 | loss: 29.2661018
	speed: 0.0208s/iter; left time: 423.1056s
Epoch: 7 cost time: 4.756083965301514
Epoch: 7, Steps: 218 Train Loss: 29.4184 (Forecasting Loss:0.4509 + XiCon Loss:2.8968 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.4136
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 28.5805206
	speed: 0.0233s/iter; left time: 470.7281s
	iters: 200, epoch: 8 | loss: 29.1960030
	speed: 0.0209s/iter; left time: 418.8705s
Epoch: 8 cost time: 4.800961017608643
Epoch: 8, Steps: 218 Train Loss: 29.4312 (Forecasting Loss:0.4564 + XiCon Loss:2.8975 x Lambda(10.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.4177
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.5027733
	speed: 0.0233s/iter; left time: 464.3330s
	iters: 200, epoch: 9 | loss: 29.0119495
	speed: 0.0212s/iter; left time: 421.4194s
Epoch: 9 cost time: 4.8348588943481445
Epoch: 9, Steps: 218 Train Loss: 29.4817 (Forecasting Loss:0.4575 + XiCon Loss:2.9024 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.4167
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.4107132
	speed: 0.0239s/iter; left time: 472.7139s
	iters: 200, epoch: 10 | loss: 29.3396416
	speed: 0.0209s/iter; left time: 410.6226s
Epoch: 10 cost time: 4.876020193099976
Epoch: 10, Steps: 218 Train Loss: 29.4866 (Forecasting Loss:0.4577 + XiCon Loss:2.9029 x Lambda(10.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.4168
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.5073261
	speed: 0.0232s/iter; left time: 451.9667s
	iters: 200, epoch: 11 | loss: 29.3368492
	speed: 0.0216s/iter; left time: 419.9982s
Epoch: 11 cost time: 4.86968207359314
Epoch: 11, Steps: 218 Train Loss: 29.5091 (Forecasting Loss:0.4578 + XiCon Loss:2.9051 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.4167
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.3097095
	speed: 0.0228s/iter; left time: 440.1621s
	iters: 200, epoch: 12 | loss: 29.9800014
	speed: 0.0209s/iter; left time: 401.7543s
Epoch: 12 cost time: 4.7556726932525635
Epoch: 12, Steps: 218 Train Loss: 29.4585 (Forecasting Loss:0.4580 + XiCon Loss:2.9001 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.4167
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.2183857
	speed: 0.0229s/iter; left time: 436.2504s
	iters: 200, epoch: 13 | loss: 29.2975979
	speed: 0.0210s/iter; left time: 398.6740s
Epoch: 13 cost time: 4.779951810836792
Epoch: 13, Steps: 218 Train Loss: 29.4943 (Forecasting Loss:0.4570 + XiCon Loss:2.9037 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.4167
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3843667507171631, mae:0.47530171275138855, mape:5.845056056976318, mspe:88379.6875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9823
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 30.3391838
	speed: 0.0242s/iter; left time: 526.0599s
	iters: 200, epoch: 1 | loss: 30.0377865
	speed: 0.0205s/iter; left time: 443.3511s
Epoch: 1 cost time: 4.847660303115845
Epoch: 1, Steps: 218 Train Loss: 30.3070 (Forecasting Loss:0.8385 + XiCon Loss:2.9468 x Lambda(10.0)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.6666
Validation loss decreased (inf --> 0.333190).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.5520668
	speed: 0.0237s/iter; left time: 509.6319s
	iters: 200, epoch: 2 | loss: 29.8167877
	speed: 0.0205s/iter; left time: 437.9008s
Epoch: 2 cost time: 4.803481340408325
Epoch: 2, Steps: 218 Train Loss: 28.9824 (Forecasting Loss:0.5096 + XiCon Loss:2.8473 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.4886
Validation loss decreased (0.333190 --> 0.225365).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.0223427
	speed: 0.0226s/iter; left time: 480.9118s
	iters: 200, epoch: 3 | loss: 28.7137737
	speed: 0.0210s/iter; left time: 443.4952s
Epoch: 3 cost time: 4.73742151260376
Epoch: 3, Steps: 218 Train Loss: 29.3427 (Forecasting Loss:0.4383 + XiCon Loss:2.8904 x Lambda(10.0)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.4104
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.9688568
	speed: 0.0229s/iter; left time: 481.2687s
	iters: 200, epoch: 4 | loss: 29.6333771
	speed: 0.0209s/iter; left time: 438.3280s
Epoch: 4 cost time: 4.79195237159729
Epoch: 4, Steps: 218 Train Loss: 29.3775 (Forecasting Loss:0.4350 + XiCon Loss:2.8943 x Lambda(10.0)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.4001
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.4315624
	speed: 0.0236s/iter; left time: 491.2516s
	iters: 200, epoch: 5 | loss: 29.8053894
	speed: 0.0207s/iter; left time: 429.7428s
Epoch: 5 cost time: 4.811495542526245
Epoch: 5, Steps: 218 Train Loss: 29.3712 (Forecasting Loss:0.4321 + XiCon Loss:2.8939 x Lambda(10.0)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.3978
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 28.6509323
	speed: 0.0231s/iter; left time: 476.1423s
	iters: 200, epoch: 6 | loss: 28.5431080
	speed: 0.0207s/iter; left time: 424.8892s
Epoch: 6 cost time: 4.776973724365234
Epoch: 6, Steps: 218 Train Loss: 29.2895 (Forecasting Loss:0.4312 + XiCon Loss:2.8858 x Lambda(10.0)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.4020
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.3717175
	speed: 0.0233s/iter; left time: 475.8948s
	iters: 200, epoch: 7 | loss: 28.8389187
	speed: 0.0206s/iter; left time: 418.9694s
Epoch: 7 cost time: 4.817391872406006
Epoch: 7, Steps: 218 Train Loss: 29.2591 (Forecasting Loss:0.4292 + XiCon Loss:2.8830 x Lambda(10.0)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.4007
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.7435760
	speed: 0.0235s/iter; left time: 474.5349s
	iters: 200, epoch: 8 | loss: 28.8361473
	speed: 0.0207s/iter; left time: 415.4106s
Epoch: 8 cost time: 4.81889271736145
Epoch: 8, Steps: 218 Train Loss: 29.2484 (Forecasting Loss:0.4298 + XiCon Loss:2.8819 x Lambda(10.0)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.3988
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.9153843
	speed: 0.0237s/iter; left time: 472.7911s
	iters: 200, epoch: 9 | loss: 29.2211971
	speed: 0.0211s/iter; left time: 419.2215s
Epoch: 9 cost time: 4.869752407073975
Epoch: 9, Steps: 218 Train Loss: 29.2094 (Forecasting Loss:0.4293 + XiCon Loss:2.8780 x Lambda(10.0)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.3990
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 28.5800514
	speed: 0.0233s/iter; left time: 460.6595s
	iters: 200, epoch: 10 | loss: 28.4589596
	speed: 0.0214s/iter; left time: 421.2440s
Epoch: 10 cost time: 4.884694337844849
Epoch: 10, Steps: 218 Train Loss: 29.2521 (Forecasting Loss:0.4287 + XiCon Loss:2.8823 x Lambda(10.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.3997
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.8959408
	speed: 0.0233s/iter; left time: 455.1276s
	iters: 200, epoch: 11 | loss: 29.0648365
	speed: 0.0213s/iter; left time: 413.5751s
Epoch: 11 cost time: 4.8616602420806885
Epoch: 11, Steps: 218 Train Loss: 29.2487 (Forecasting Loss:0.4287 + XiCon Loss:2.8820 x Lambda(10.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.3999
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.4468250
	speed: 0.0238s/iter; left time: 459.2636s
	iters: 200, epoch: 12 | loss: 29.0195026
	speed: 0.0209s/iter; left time: 401.3089s
Epoch: 12 cost time: 4.870773553848267
Epoch: 12, Steps: 218 Train Loss: 29.2411 (Forecasting Loss:0.4289 + XiCon Loss:2.8812 x Lambda(10.0)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.3998
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.4574776887893677, mae:0.5196917057037354, mape:6.965731620788574, mspe:138896.125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.1012
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 30.7653637
	speed: 0.0237s/iter; left time: 514.8933s
	iters: 200, epoch: 1 | loss: 30.2371159
	speed: 0.0209s/iter; left time: 450.6884s
Epoch: 1 cost time: 4.858011722564697
Epoch: 1, Steps: 218 Train Loss: 30.4395 (Forecasting Loss:0.8433 + XiCon Loss:2.9596 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.6846
Validation loss decreased (inf --> 0.338334).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.8762646
	speed: 0.0230s/iter; left time: 495.0589s
	iters: 200, epoch: 2 | loss: 28.2450428
	speed: 0.0207s/iter; left time: 442.4806s
Epoch: 2 cost time: 4.766948938369751
Epoch: 2, Steps: 218 Train Loss: 28.8116 (Forecasting Loss:0.5531 + XiCon Loss:2.8258 x Lambda(10.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.5522
Validation loss decreased (0.338334 --> 0.245172).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.0012379
	speed: 0.0238s/iter; left time: 506.1011s
	iters: 200, epoch: 3 | loss: 29.0610790
	speed: 0.0208s/iter; left time: 440.3228s
Epoch: 3 cost time: 4.884644985198975
Epoch: 3, Steps: 218 Train Loss: 28.4725 (Forecasting Loss:0.5035 + XiCon Loss:2.7969 x Lambda(10.0)), Vali MSE Loss: 0.2247 Test MSE Loss: 0.4681
Validation loss decreased (0.245172 --> 0.224703).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.9473362
	speed: 0.0231s/iter; left time: 486.5511s
	iters: 200, epoch: 4 | loss: 29.7709827
	speed: 0.0208s/iter; left time: 434.6908s
Epoch: 4 cost time: 4.817075729370117
Epoch: 4, Steps: 218 Train Loss: 29.4680 (Forecasting Loss:0.4625 + XiCon Loss:2.9005 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.4384
Validation loss decreased (0.224703 --> 0.213143).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.2877064
	speed: 0.0228s/iter; left time: 474.5567s
	iters: 200, epoch: 5 | loss: 29.4304409
	speed: 0.0204s/iter; left time: 422.7474s
Epoch: 5 cost time: 4.707444906234741
Epoch: 5, Steps: 218 Train Loss: 29.3715 (Forecasting Loss:0.4497 + XiCon Loss:2.8922 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4265
Validation loss decreased (0.213143 --> 0.212764).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.3947220
	speed: 0.0232s/iter; left time: 477.7868s
	iters: 200, epoch: 6 | loss: 28.7426548
	speed: 0.0212s/iter; left time: 435.1439s
Epoch: 6 cost time: 4.8195109367370605
Epoch: 6, Steps: 218 Train Loss: 29.3635 (Forecasting Loss:0.4457 + XiCon Loss:2.8918 x Lambda(10.0)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.4185
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.2594452
	speed: 0.0228s/iter; left time: 465.0737s
	iters: 200, epoch: 7 | loss: 29.6591034
	speed: 0.0210s/iter; left time: 426.2159s
Epoch: 7 cost time: 4.7699244022369385
Epoch: 7, Steps: 218 Train Loss: 29.3235 (Forecasting Loss:0.4440 + XiCon Loss:2.8879 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.4179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.7146835
	speed: 0.0235s/iter; left time: 473.2269s
	iters: 200, epoch: 8 | loss: 28.8109112
	speed: 0.0210s/iter; left time: 420.6007s
Epoch: 8 cost time: 4.846217632293701
Epoch: 8, Steps: 218 Train Loss: 29.3403 (Forecasting Loss:0.4424 + XiCon Loss:2.8898 x Lambda(10.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.4188
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.0787373
	speed: 0.0232s/iter; left time: 462.6584s
	iters: 200, epoch: 9 | loss: 28.4984989
	speed: 0.0213s/iter; left time: 422.2069s
Epoch: 9 cost time: 4.860860586166382
Epoch: 9, Steps: 218 Train Loss: 29.3467 (Forecasting Loss:0.4424 + XiCon Loss:2.8904 x Lambda(10.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.4188
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 30.0009842
	speed: 0.0234s/iter; left time: 461.0508s
	iters: 200, epoch: 10 | loss: 29.9854755
	speed: 0.0211s/iter; left time: 413.7252s
Epoch: 10 cost time: 4.869035243988037
Epoch: 10, Steps: 218 Train Loss: 29.3024 (Forecasting Loss:0.4419 + XiCon Loss:2.8860 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.4183
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.7365932
	speed: 0.0228s/iter; left time: 445.0519s
	iters: 200, epoch: 11 | loss: 28.9754829
	speed: 0.0218s/iter; left time: 422.6514s
Epoch: 11 cost time: 4.914301156997681
Epoch: 11, Steps: 218 Train Loss: 29.3348 (Forecasting Loss:0.4422 + XiCon Loss:2.8893 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.4182
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.1380653
	speed: 0.0231s/iter; left time: 445.7732s
	iters: 200, epoch: 12 | loss: 29.6508522
	speed: 0.0211s/iter; left time: 404.3079s
Epoch: 12 cost time: 4.825825452804565
Epoch: 12, Steps: 218 Train Loss: 29.3279 (Forecasting Loss:0.4414 + XiCon Loss:2.8887 x Lambda(10.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.4183
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.5239544
	speed: 0.0231s/iter; left time: 441.5210s
	iters: 200, epoch: 13 | loss: 30.2383633
	speed: 0.0210s/iter; left time: 398.5159s
Epoch: 13 cost time: 4.797365665435791
Epoch: 13, Steps: 218 Train Loss: 29.2830 (Forecasting Loss:0.4417 + XiCon Loss:2.8841 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.4183
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.4050865
	speed: 0.0236s/iter; left time: 445.6088s
	iters: 200, epoch: 14 | loss: 28.9238415
	speed: 0.0211s/iter; left time: 396.1455s
Epoch: 14 cost time: 4.883768081665039
Epoch: 14, Steps: 218 Train Loss: 29.3564 (Forecasting Loss:0.4415 + XiCon Loss:2.8915 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.4183
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.1666908
	speed: 0.0234s/iter; left time: 436.0672s
	iters: 200, epoch: 15 | loss: 28.9793224
	speed: 0.0208s/iter; left time: 385.1594s
Epoch: 15 cost time: 4.808773994445801
Epoch: 15, Steps: 218 Train Loss: 29.3354 (Forecasting Loss:0.4420 + XiCon Loss:2.8893 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.4183
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3821655809879303, mae:0.47087424993515015, mape:6.16627836227417, mspe:110212.2578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9535
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 30.4461575
	speed: 0.0240s/iter; left time: 520.1628s
	iters: 200, epoch: 1 | loss: 29.8578262
	speed: 0.0204s/iter; left time: 441.7015s
Epoch: 1 cost time: 4.836251497268677
Epoch: 1, Steps: 218 Train Loss: 30.5325 (Forecasting Loss:0.8319 + XiCon Loss:2.9701 x Lambda(10.0)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.6653
Validation loss decreased (inf --> 0.333432).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.0613937
	speed: 0.0232s/iter; left time: 497.3674s
	iters: 200, epoch: 2 | loss: 28.5285778
	speed: 0.0209s/iter; left time: 447.0658s
Epoch: 2 cost time: 4.785979986190796
Epoch: 2, Steps: 218 Train Loss: 28.8214 (Forecasting Loss:0.5072 + XiCon Loss:2.8314 x Lambda(10.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.4243
Validation loss decreased (0.333432 --> 0.219604).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 27.9783096
	speed: 0.0235s/iter; left time: 500.6026s
	iters: 200, epoch: 3 | loss: 28.5027390
	speed: 0.0208s/iter; left time: 440.3605s
Epoch: 3 cost time: 4.833729028701782
Epoch: 3, Steps: 218 Train Loss: 28.2215 (Forecasting Loss:0.4316 + XiCon Loss:2.7790 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.4736
Validation loss decreased (0.219604 --> 0.213355).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.8491249
	speed: 0.0234s/iter; left time: 493.3917s
	iters: 200, epoch: 4 | loss: 29.0675564
	speed: 0.0209s/iter; left time: 436.9109s
Epoch: 4 cost time: 4.806554555892944
Epoch: 4, Steps: 218 Train Loss: 29.1245 (Forecasting Loss:0.4198 + XiCon Loss:2.8705 x Lambda(10.0)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.4123
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.7267838
	speed: 0.0236s/iter; left time: 491.9634s
	iters: 200, epoch: 5 | loss: 29.9522705
	speed: 0.0205s/iter; left time: 424.0270s
Epoch: 5 cost time: 4.776210308074951
Epoch: 5, Steps: 218 Train Loss: 29.4391 (Forecasting Loss:0.4154 + XiCon Loss:2.9024 x Lambda(10.0)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.4064
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 28.9506378
	speed: 0.0232s/iter; left time: 478.4201s
	iters: 200, epoch: 6 | loss: 29.0426216
	speed: 0.0208s/iter; left time: 427.5746s
Epoch: 6 cost time: 4.78166651725769
Epoch: 6, Steps: 218 Train Loss: 29.4032 (Forecasting Loss:0.4132 + XiCon Loss:2.8990 x Lambda(10.0)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.4119
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.1229782
	speed: 0.0238s/iter; left time: 486.0182s
	iters: 200, epoch: 7 | loss: 29.7397976
	speed: 0.0209s/iter; left time: 423.6786s
Epoch: 7 cost time: 4.8734290599823
Epoch: 7, Steps: 218 Train Loss: 29.4069 (Forecasting Loss:0.4119 + XiCon Loss:2.8995 x Lambda(10.0)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.4130
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 30.1964436
	speed: 0.0242s/iter; left time: 487.9386s
	iters: 200, epoch: 8 | loss: 29.7569866
	speed: 0.0209s/iter; left time: 420.5532s
Epoch: 8 cost time: 4.917582273483276
Epoch: 8, Steps: 218 Train Loss: 29.4333 (Forecasting Loss:0.4109 + XiCon Loss:2.9022 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.4158
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 30.0335636
	speed: 0.0234s/iter; left time: 466.0787s
	iters: 200, epoch: 9 | loss: 29.4016399
	speed: 0.0207s/iter; left time: 411.6046s
Epoch: 9 cost time: 4.8194780349731445
Epoch: 9, Steps: 218 Train Loss: 29.4273 (Forecasting Loss:0.4108 + XiCon Loss:2.9017 x Lambda(10.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.4165
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.4015961
	speed: 0.0233s/iter; left time: 460.8628s
	iters: 200, epoch: 10 | loss: 28.7750759
	speed: 0.0215s/iter; left time: 421.3396s
Epoch: 10 cost time: 4.924261093139648
Epoch: 10, Steps: 218 Train Loss: 29.4998 (Forecasting Loss:0.4115 + XiCon Loss:2.9088 x Lambda(10.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.4164
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 28.9926300
	speed: 0.0232s/iter; left time: 453.6191s
	iters: 200, epoch: 11 | loss: 29.9137650
	speed: 0.0219s/iter; left time: 425.4729s
Epoch: 11 cost time: 4.921011447906494
Epoch: 11, Steps: 218 Train Loss: 29.4946 (Forecasting Loss:0.4107 + XiCon Loss:2.9084 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.4162
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.7596798
	speed: 0.0231s/iter; left time: 446.4667s
	iters: 200, epoch: 12 | loss: 29.1172657
	speed: 0.0222s/iter; left time: 427.0559s
Epoch: 12 cost time: 4.991469621658325
Epoch: 12, Steps: 218 Train Loss: 29.4405 (Forecasting Loss:0.4106 + XiCon Loss:2.9030 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.4165
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.4957695
	speed: 0.0228s/iter; left time: 435.8717s
	iters: 200, epoch: 13 | loss: 30.2111073
	speed: 0.0212s/iter; left time: 402.8886s
Epoch: 13 cost time: 4.8044469356536865
Epoch: 13, Steps: 218 Train Loss: 29.4586 (Forecasting Loss:0.4107 + XiCon Loss:2.9048 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.4165
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.4419380724430084, mae:0.5052139163017273, mape:5.965579509735107, mspe:79890.375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0323
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 30.4939079
	speed: 0.0232s/iter; left time: 503.8255s
	iters: 200, epoch: 1 | loss: 30.0121021
	speed: 0.0212s/iter; left time: 457.9645s
Epoch: 1 cost time: 4.840786695480347
Epoch: 1, Steps: 218 Train Loss: 30.2612 (Forecasting Loss:0.8348 + XiCon Loss:2.9426 x Lambda(10.0)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.6597
Validation loss decreased (inf --> 0.332741).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 28.5083466
	speed: 0.0230s/iter; left time: 494.6847s
	iters: 200, epoch: 2 | loss: 28.4069042
	speed: 0.0207s/iter; left time: 442.8779s
Epoch: 2 cost time: 4.7940614223480225
Epoch: 2, Steps: 218 Train Loss: 28.7541 (Forecasting Loss:0.5632 + XiCon Loss:2.8191 x Lambda(10.0)), Vali MSE Loss: 0.2335 Test MSE Loss: 0.5467
Validation loss decreased (0.332741 --> 0.233544).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 28.2255211
	speed: 0.0245s/iter; left time: 520.0543s
	iters: 200, epoch: 3 | loss: 28.0480080
	speed: 0.0241s/iter; left time: 509.1970s
Epoch: 3 cost time: 5.324466705322266
Epoch: 3, Steps: 218 Train Loss: 28.1841 (Forecasting Loss:0.5266 + XiCon Loss:2.7658 x Lambda(10.0)), Vali MSE Loss: 0.2239 Test MSE Loss: 0.5231
Validation loss decreased (0.233544 --> 0.223904).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 28.7021408
	speed: 0.0262s/iter; left time: 552.2308s
	iters: 200, epoch: 4 | loss: 28.0081463
	speed: 0.0231s/iter; left time: 483.4663s
Epoch: 4 cost time: 5.364888668060303
Epoch: 4, Steps: 218 Train Loss: 28.3673 (Forecasting Loss:0.5016 + XiCon Loss:2.7866 x Lambda(10.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.5073
Validation loss decreased (0.223904 --> 0.218652).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.2059116
	speed: 0.0247s/iter; left time: 513.6336s
	iters: 200, epoch: 5 | loss: 29.3359585
	speed: 0.0220s/iter; left time: 455.4030s
Epoch: 5 cost time: 5.055098056793213
Epoch: 5, Steps: 218 Train Loss: 28.7919 (Forecasting Loss:0.4832 + XiCon Loss:2.8309 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.4673
Validation loss decreased (0.218652 --> 0.216628).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.2587585
	speed: 0.0235s/iter; left time: 483.8432s
	iters: 200, epoch: 6 | loss: 29.5295849
	speed: 0.0209s/iter; left time: 427.6961s
Epoch: 6 cost time: 4.841599702835083
Epoch: 6, Steps: 218 Train Loss: 29.1349 (Forecasting Loss:0.4675 + XiCon Loss:2.8667 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.4478
Validation loss decreased (0.216628 --> 0.213106).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.3273945
	speed: 0.0235s/iter; left time: 480.2252s
	iters: 200, epoch: 7 | loss: 29.6542320
	speed: 0.0207s/iter; left time: 420.5851s
Epoch: 7 cost time: 4.826573848724365
Epoch: 7, Steps: 218 Train Loss: 29.3539 (Forecasting Loss:0.4616 + XiCon Loss:2.8892 x Lambda(10.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.4389
Validation loss decreased (0.213106 --> 0.211293).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.7925091
	speed: 0.0233s/iter; left time: 470.6341s
	iters: 200, epoch: 8 | loss: 29.8716869
	speed: 0.0212s/iter; left time: 424.9653s
Epoch: 8 cost time: 4.878358602523804
Epoch: 8, Steps: 218 Train Loss: 29.4282 (Forecasting Loss:0.4594 + XiCon Loss:2.8969 x Lambda(10.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.4347
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 28.7638302
	speed: 0.0234s/iter; left time: 467.0570s
	iters: 200, epoch: 9 | loss: 29.0704460
	speed: 0.0215s/iter; left time: 426.3167s
Epoch: 9 cost time: 4.897512197494507
Epoch: 9, Steps: 218 Train Loss: 29.4302 (Forecasting Loss:0.4583 + XiCon Loss:2.8972 x Lambda(10.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.4330
Validation loss decreased (0.211293 --> 0.210859).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.3939724
	speed: 0.0238s/iter; left time: 469.9264s
	iters: 200, epoch: 10 | loss: 29.6162796
	speed: 0.0211s/iter; left time: 413.4169s
Epoch: 10 cost time: 4.912248373031616
Epoch: 10, Steps: 218 Train Loss: 29.5013 (Forecasting Loss:0.4578 + XiCon Loss:2.9043 x Lambda(10.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.4325
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 30.1420860
	speed: 0.0233s/iter; left time: 455.2450s
	iters: 200, epoch: 11 | loss: 29.3084221
	speed: 0.0211s/iter; left time: 410.0346s
Epoch: 11 cost time: 4.84572958946228
Epoch: 11, Steps: 218 Train Loss: 29.4889 (Forecasting Loss:0.4573 + XiCon Loss:2.9032 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.4323
Validation loss decreased (0.210859 --> 0.210841).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 28.8179684
	speed: 0.0238s/iter; left time: 459.8846s
	iters: 200, epoch: 12 | loss: 31.0999527
	speed: 0.0217s/iter; left time: 416.1243s
Epoch: 12 cost time: 4.962284088134766
Epoch: 12, Steps: 218 Train Loss: 29.5342 (Forecasting Loss:0.4575 + XiCon Loss:2.9077 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.4322
Validation loss decreased (0.210841 --> 0.210627).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.1181870
	speed: 0.0229s/iter; left time: 436.8927s
	iters: 200, epoch: 13 | loss: 30.5307903
	speed: 0.0210s/iter; left time: 397.7701s
Epoch: 13 cost time: 4.806075572967529
Epoch: 13, Steps: 218 Train Loss: 29.5170 (Forecasting Loss:0.4573 + XiCon Loss:2.9060 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.4320
Validation loss decreased (0.210627 --> 0.210556).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.2161026
	speed: 0.0231s/iter; left time: 436.4459s
	iters: 200, epoch: 14 | loss: 30.6972065
	speed: 0.0210s/iter; left time: 394.5792s
Epoch: 14 cost time: 4.804783821105957
Epoch: 14, Steps: 218 Train Loss: 29.4887 (Forecasting Loss:0.4573 + XiCon Loss:2.9031 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.4320
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.0648289
	speed: 0.0235s/iter; left time: 438.6081s
	iters: 200, epoch: 15 | loss: 29.2300148
	speed: 0.0214s/iter; left time: 396.1704s
Epoch: 15 cost time: 4.899614572525024
Epoch: 15, Steps: 218 Train Loss: 29.4567 (Forecasting Loss:0.4570 + XiCon Loss:2.9000 x Lambda(10.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.4320
Validation loss decreased (0.210556 --> 0.210512).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 29.0979080
	speed: 0.0238s/iter; left time: 437.9003s
	iters: 200, epoch: 16 | loss: 29.2515068
	speed: 0.0224s/iter; left time: 410.7836s
Epoch: 16 cost time: 5.010132551193237
Epoch: 16, Steps: 218 Train Loss: 29.4785 (Forecasting Loss:0.4571 + XiCon Loss:2.9021 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.4320
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 29.1505222
	speed: 0.0229s/iter; left time: 417.8290s
	iters: 200, epoch: 17 | loss: 29.1089191
	speed: 0.0208s/iter; left time: 376.6274s
Epoch: 17 cost time: 4.7573466300964355
Epoch: 17, Steps: 218 Train Loss: 29.4864 (Forecasting Loss:0.4571 + XiCon Loss:2.9029 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.4320
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.4307423
	speed: 0.0231s/iter; left time: 416.3048s
	iters: 200, epoch: 18 | loss: 30.5216732
	speed: 0.0214s/iter; left time: 383.3909s
Epoch: 18 cost time: 4.8687050342559814
Epoch: 18, Steps: 218 Train Loss: 29.4820 (Forecasting Loss:0.4573 + XiCon Loss:2.9025 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.4320
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 29.2865257
	speed: 0.0241s/iter; left time: 427.7755s
	iters: 200, epoch: 19 | loss: 29.5251713
	speed: 0.0215s/iter; left time: 379.6220s
Epoch: 19 cost time: 4.971588850021362
Epoch: 19, Steps: 218 Train Loss: 29.5190 (Forecasting Loss:0.4573 + XiCon Loss:2.9062 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.4320
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 29.6810532
	speed: 0.0230s/iter; left time: 404.3038s
	iters: 200, epoch: 20 | loss: 29.9479408
	speed: 0.0211s/iter; left time: 367.5317s
Epoch: 20 cost time: 4.8363189697265625
Epoch: 20, Steps: 218 Train Loss: 29.5181 (Forecasting Loss:0.4571 + XiCon Loss:2.9061 x Lambda(10.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.4320
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 30.0200081
	speed: 0.0229s/iter; left time: 397.9049s
	iters: 200, epoch: 21 | loss: 29.6260929
	speed: 0.0210s/iter; left time: 362.3212s
Epoch: 21 cost time: 4.792740106582642
Epoch: 21, Steps: 218 Train Loss: 29.5072 (Forecasting Loss:0.4572 + XiCon Loss:2.9050 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.4320
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 30.1440964
	speed: 0.0237s/iter; left time: 405.7844s
	iters: 200, epoch: 22 | loss: 29.6884747
	speed: 0.0213s/iter; left time: 362.0820s
Epoch: 22 cost time: 4.90476131439209
Epoch: 22, Steps: 218 Train Loss: 29.5345 (Forecasting Loss:0.4574 + XiCon Loss:2.9077 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.4320
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 28.7411461
	speed: 0.0230s/iter; left time: 388.0233s
	iters: 200, epoch: 23 | loss: 30.0165997
	speed: 0.0216s/iter; left time: 363.4461s
Epoch: 23 cost time: 4.9022016525268555
Epoch: 23, Steps: 218 Train Loss: 29.4753 (Forecasting Loss:0.4574 + XiCon Loss:2.9018 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.4320
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 30.2756157
	speed: 0.0231s/iter; left time: 385.5902s
	iters: 200, epoch: 24 | loss: 28.8491077
	speed: 0.0209s/iter; left time: 346.3523s
Epoch: 24 cost time: 4.808904409408569
Epoch: 24, Steps: 218 Train Loss: 29.5059 (Forecasting Loss:0.4574 + XiCon Loss:2.9049 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.4320
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 29.3591919
	speed: 0.0230s/iter; left time: 378.8564s
	iters: 200, epoch: 25 | loss: 30.1140823
	speed: 0.0216s/iter; left time: 353.1919s
Epoch: 25 cost time: 4.856552600860596
Epoch: 25, Steps: 218 Train Loss: 29.4875 (Forecasting Loss:0.4575 + XiCon Loss:2.9030 x Lambda(10.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.4320
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.38863450288772583, mae:0.4752945005893707, mape:6.7323198318481445, mspe:146549.484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4109+-0.04459, MAE:0.4893+-0.02712, MAPE:6.3350+-0.60850, MSPE:112785.5859+-36761.04385, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.4217
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.7475948
	speed: 0.0214s/iter; left time: 448.1272s
	iters: 200, epoch: 1 | loss: 25.3295727
	speed: 0.0155s/iter; left time: 323.0261s
Epoch: 1 cost time: 3.8781685829162598
Epoch: 1, Steps: 210 Train Loss: 25.5362 (Forecasting Loss:0.8384 + XiCon Loss:2.4698 x Lambda(10.0)), Vali MSE Loss: 0.2800 Test MSE Loss: 0.6958
Validation loss decreased (inf --> 0.279981).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.0395622
	speed: 0.0183s/iter; left time: 377.6668s
	iters: 200, epoch: 2 | loss: 22.9795399
	speed: 0.0169s/iter; left time: 347.8800s
Epoch: 2 cost time: 3.7146823406219482
Epoch: 2, Steps: 210 Train Loss: 23.3338 (Forecasting Loss:0.5616 + XiCon Loss:2.2772 x Lambda(10.0)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.5762
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 22.2036171
	speed: 0.0204s/iter; left time: 417.7902s
	iters: 200, epoch: 3 | loss: 23.0941620
	speed: 0.0185s/iter; left time: 376.3039s
Epoch: 3 cost time: 4.095667362213135
Epoch: 3, Steps: 210 Train Loss: 22.9210 (Forecasting Loss:0.4995 + XiCon Loss:2.2421 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.5471
Validation loss decreased (0.279981 --> 0.235500).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.6223354
	speed: 0.0205s/iter; left time: 415.3103s
	iters: 200, epoch: 4 | loss: 22.5477467
	speed: 0.0182s/iter; left time: 366.6354s
Epoch: 4 cost time: 4.089617013931274
Epoch: 4, Steps: 210 Train Loss: 22.9123 (Forecasting Loss:0.4892 + XiCon Loss:2.2423 x Lambda(10.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.5224
Validation loss decreased (0.235500 --> 0.218204).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.9751911
	speed: 0.0202s/iter; left time: 405.4757s
	iters: 200, epoch: 5 | loss: 23.3435402
	speed: 0.0186s/iter; left time: 372.0939s
Epoch: 5 cost time: 4.075092077255249
Epoch: 5, Steps: 210 Train Loss: 22.8575 (Forecasting Loss:0.4691 + XiCon Loss:2.2388 x Lambda(10.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.5480
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 22.8595428
	speed: 0.0211s/iter; left time: 419.7405s
	iters: 200, epoch: 6 | loss: 22.2320080
	speed: 0.0187s/iter; left time: 369.8171s
Epoch: 6 cost time: 4.19480562210083
Epoch: 6, Steps: 210 Train Loss: 22.7733 (Forecasting Loss:0.4639 + XiCon Loss:2.2309 x Lambda(10.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.5542
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 22.8876667
	speed: 0.0202s/iter; left time: 396.3729s
	iters: 200, epoch: 7 | loss: 22.0563679
	speed: 0.0181s/iter; left time: 353.3609s
Epoch: 7 cost time: 4.053235769271851
Epoch: 7, Steps: 210 Train Loss: 22.7929 (Forecasting Loss:0.4606 + XiCon Loss:2.2332 x Lambda(10.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.5539
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 22.4661598
	speed: 0.0211s/iter; left time: 409.0312s
	iters: 200, epoch: 8 | loss: 23.1543407
	speed: 0.0186s/iter; left time: 359.9279s
Epoch: 8 cost time: 4.191389799118042
Epoch: 8, Steps: 210 Train Loss: 22.6899 (Forecasting Loss:0.4583 + XiCon Loss:2.2232 x Lambda(10.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.5491
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 21.4924202
	speed: 0.0208s/iter; left time: 399.2032s
	iters: 200, epoch: 9 | loss: 22.0111217
	speed: 0.0182s/iter; left time: 348.8003s
Epoch: 9 cost time: 4.118421316146851
Epoch: 9, Steps: 210 Train Loss: 22.6789 (Forecasting Loss:0.4581 + XiCon Loss:2.2221 x Lambda(10.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.5520
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.8673210
	speed: 0.0207s/iter; left time: 394.1279s
	iters: 200, epoch: 10 | loss: 22.5027332
	speed: 0.0186s/iter; left time: 352.4832s
Epoch: 10 cost time: 4.148515939712524
Epoch: 10, Steps: 210 Train Loss: 22.6901 (Forecasting Loss:0.4571 + XiCon Loss:2.2233 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5476
Validation loss decreased (0.218204 --> 0.217865).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.5690556
	speed: 0.0200s/iter; left time: 376.7569s
	iters: 200, epoch: 11 | loss: 21.9207478
	speed: 0.0175s/iter; left time: 327.9729s
Epoch: 11 cost time: 3.957484483718872
Epoch: 11, Steps: 210 Train Loss: 22.7679 (Forecasting Loss:0.4565 + XiCon Loss:2.2311 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5476
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 21.9315376
	speed: 0.0209s/iter; left time: 387.9321s
	iters: 200, epoch: 12 | loss: 23.7838383
	speed: 0.0181s/iter; left time: 334.1146s
Epoch: 12 cost time: 4.114282608032227
Epoch: 12, Steps: 210 Train Loss: 22.7431 (Forecasting Loss:0.4569 + XiCon Loss:2.2286 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5475
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 22.6304016
	speed: 0.0203s/iter; left time: 373.7964s
	iters: 200, epoch: 13 | loss: 23.5980129
	speed: 0.0183s/iter; left time: 334.9745s
Epoch: 13 cost time: 4.079657316207886
Epoch: 13, Steps: 210 Train Loss: 22.7359 (Forecasting Loss:0.4564 + XiCon Loss:2.2280 x Lambda(10.0)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.5479
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 22.7714233
	speed: 0.0214s/iter; left time: 389.1250s
	iters: 200, epoch: 14 | loss: 22.9553032
	speed: 0.0179s/iter; left time: 324.3259s
Epoch: 14 cost time: 4.152900218963623
Epoch: 14, Steps: 210 Train Loss: 22.7282 (Forecasting Loss:0.4571 + XiCon Loss:2.2271 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5480
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.5218678
	speed: 0.0210s/iter; left time: 377.9265s
	iters: 200, epoch: 15 | loss: 23.5261669
	speed: 0.0178s/iter; left time: 318.3615s
Epoch: 15 cost time: 4.096441268920898
Epoch: 15, Steps: 210 Train Loss: 22.7550 (Forecasting Loss:0.4565 + XiCon Loss:2.2299 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5480
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 22.6597481
	speed: 0.0206s/iter; left time: 365.8015s
	iters: 200, epoch: 16 | loss: 22.3958836
	speed: 0.0181s/iter; left time: 319.2737s
Epoch: 16 cost time: 4.089389085769653
Epoch: 16, Steps: 210 Train Loss: 22.7161 (Forecasting Loss:0.4568 + XiCon Loss:2.2259 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5480
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 21.9146824
	speed: 0.0205s/iter; left time: 358.8976s
	iters: 200, epoch: 17 | loss: 22.4787464
	speed: 0.0181s/iter; left time: 314.8590s
Epoch: 17 cost time: 4.078597784042358
Epoch: 17, Steps: 210 Train Loss: 22.7223 (Forecasting Loss:0.4564 + XiCon Loss:2.2266 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 22.5246048
	speed: 0.0208s/iter; left time: 359.8753s
	iters: 200, epoch: 18 | loss: 21.8437786
	speed: 0.0180s/iter; left time: 310.9312s
Epoch: 18 cost time: 4.086335182189941
Epoch: 18, Steps: 210 Train Loss: 22.7518 (Forecasting Loss:0.4572 + XiCon Loss:2.2295 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 23.4103088
	speed: 0.0208s/iter; left time: 356.4222s
	iters: 200, epoch: 19 | loss: 23.5176659
	speed: 0.0179s/iter; left time: 305.2270s
Epoch: 19 cost time: 4.071585655212402
Epoch: 19, Steps: 210 Train Loss: 22.6842 (Forecasting Loss:0.4567 + XiCon Loss:2.2228 x Lambda(10.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.5479
Validation loss decreased (0.217865 --> 0.217846).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 23.4346123
	speed: 0.0210s/iter; left time: 355.8949s
	iters: 200, epoch: 20 | loss: 21.9874287
	speed: 0.0190s/iter; left time: 319.6640s
Epoch: 20 cost time: 4.220064163208008
Epoch: 20, Steps: 210 Train Loss: 22.7512 (Forecasting Loss:0.4570 + XiCon Loss:2.2294 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 22.3031769
	speed: 0.0201s/iter; left time: 336.3758s
	iters: 200, epoch: 21 | loss: 22.6415024
	speed: 0.0190s/iter; left time: 314.6366s
Epoch: 21 cost time: 4.128933906555176
Epoch: 21, Steps: 210 Train Loss: 22.6840 (Forecasting Loss:0.4567 + XiCon Loss:2.2227 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 22.9920654
	speed: 0.0203s/iter; left time: 333.9747s
	iters: 200, epoch: 22 | loss: 22.6894531
	speed: 0.0184s/iter; left time: 301.2704s
Epoch: 22 cost time: 4.065552234649658
Epoch: 22, Steps: 210 Train Loss: 22.7144 (Forecasting Loss:0.4574 + XiCon Loss:2.2257 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 21.7722015
	speed: 0.0208s/iter; left time: 337.9903s
	iters: 200, epoch: 23 | loss: 22.7235336
	speed: 0.0185s/iter; left time: 299.9368s
Epoch: 23 cost time: 4.127747297286987
Epoch: 23, Steps: 210 Train Loss: 22.7021 (Forecasting Loss:0.4559 + XiCon Loss:2.2246 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 23.1919479
	speed: 0.0212s/iter; left time: 340.0998s
	iters: 200, epoch: 24 | loss: 22.5828896
	speed: 0.0179s/iter; left time: 285.3578s
Epoch: 24 cost time: 4.114436864852905
Epoch: 24, Steps: 210 Train Loss: 22.6954 (Forecasting Loss:0.4559 + XiCon Loss:2.2239 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 22.4359245
	speed: 0.0209s/iter; left time: 331.4749s
	iters: 200, epoch: 25 | loss: 22.6844921
	speed: 0.0179s/iter; left time: 282.8595s
Epoch: 25 cost time: 4.110738754272461
Epoch: 25, Steps: 210 Train Loss: 22.6971 (Forecasting Loss:0.4568 + XiCon Loss:2.2240 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 22.8455639
	speed: 0.0204s/iter; left time: 319.0634s
	iters: 200, epoch: 26 | loss: 22.6630192
	speed: 0.0184s/iter; left time: 286.6304s
Epoch: 26 cost time: 4.080164909362793
Epoch: 26, Steps: 210 Train Loss: 22.6936 (Forecasting Loss:0.4572 + XiCon Loss:2.2236 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 22.9150963
	speed: 0.0200s/iter; left time: 308.2156s
	iters: 200, epoch: 27 | loss: 22.4629021
	speed: 0.0188s/iter; left time: 288.9170s
Epoch: 27 cost time: 4.099658250808716
Epoch: 27, Steps: 210 Train Loss: 22.6903 (Forecasting Loss:0.4565 + XiCon Loss:2.2234 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 22.8855152
	speed: 0.0204s/iter; left time: 311.4479s
	iters: 200, epoch: 28 | loss: 23.2438965
	speed: 0.0179s/iter; left time: 271.3859s
Epoch: 28 cost time: 4.053187608718872
Epoch: 28, Steps: 210 Train Loss: 22.7328 (Forecasting Loss:0.4564 + XiCon Loss:2.2276 x Lambda(10.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.5479
Validation loss decreased (0.217846 --> 0.217823).  Saving model ...
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 23.1029663
	speed: 0.0203s/iter; left time: 304.7582s
	iters: 200, epoch: 29 | loss: 23.1966496
	speed: 0.0182s/iter; left time: 272.1022s
Epoch: 29 cost time: 4.052253484725952
Epoch: 29, Steps: 210 Train Loss: 22.6836 (Forecasting Loss:0.4561 + XiCon Loss:2.2228 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 22.9323311
	speed: 0.0217s/iter; left time: 320.8696s
	iters: 200, epoch: 30 | loss: 22.5321465
	speed: 0.0180s/iter; left time: 264.7475s
Epoch: 30 cost time: 4.173059463500977
Epoch: 30, Steps: 210 Train Loss: 22.7291 (Forecasting Loss:0.4565 + XiCon Loss:2.2273 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 22.7009926
	speed: 0.0212s/iter; left time: 310.2227s
	iters: 200, epoch: 31 | loss: 22.5677948
	speed: 0.0182s/iter; left time: 263.6466s
Epoch: 31 cost time: 4.15070915222168
Epoch: 31, Steps: 210 Train Loss: 22.6729 (Forecasting Loss:0.4567 + XiCon Loss:2.2216 x Lambda(10.0)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.5479
Validation loss decreased (0.217823 --> 0.217746).  Saving model ...
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 23.4709263
	speed: 0.0213s/iter; left time: 306.2250s
	iters: 200, epoch: 32 | loss: 22.7252426
	speed: 0.0182s/iter; left time: 260.2585s
Epoch: 32 cost time: 4.167855978012085
Epoch: 32, Steps: 210 Train Loss: 22.6954 (Forecasting Loss:0.4570 + XiCon Loss:2.2238 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 22.7746429
	speed: 0.0209s/iter; left time: 296.4164s
	iters: 200, epoch: 33 | loss: 21.6256351
	speed: 0.0183s/iter; left time: 257.1043s
Epoch: 33 cost time: 4.135950565338135
Epoch: 33, Steps: 210 Train Loss: 22.6425 (Forecasting Loss:0.4564 + XiCon Loss:2.2186 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 23.0775776
	speed: 0.0203s/iter; left time: 283.7689s
	iters: 200, epoch: 34 | loss: 22.2395058
	speed: 0.0181s/iter; left time: 251.0694s
Epoch: 34 cost time: 4.035924673080444
Epoch: 34, Steps: 210 Train Loss: 22.6920 (Forecasting Loss:0.4578 + XiCon Loss:2.2234 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 22.3311672
	speed: 0.0204s/iter; left time: 280.4771s
	iters: 200, epoch: 35 | loss: 22.6863899
	speed: 0.0184s/iter; left time: 251.6474s
Epoch: 35 cost time: 4.102153778076172
Epoch: 35, Steps: 210 Train Loss: 22.6543 (Forecasting Loss:0.4571 + XiCon Loss:2.2197 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 22.5800037
	speed: 0.0209s/iter; left time: 283.6317s
	iters: 200, epoch: 36 | loss: 23.6368942
	speed: 0.0180s/iter; left time: 242.3314s
Epoch: 36 cost time: 4.1224894523620605
Epoch: 36, Steps: 210 Train Loss: 22.6925 (Forecasting Loss:0.4567 + XiCon Loss:2.2236 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 22.2937202
	speed: 0.0208s/iter; left time: 276.9426s
	iters: 200, epoch: 37 | loss: 22.6250515
	speed: 0.0184s/iter; left time: 244.0062s
Epoch: 37 cost time: 4.114448547363281
Epoch: 37, Steps: 210 Train Loss: 22.6603 (Forecasting Loss:0.4568 + XiCon Loss:2.2203 x Lambda(10.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.5479
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 21.7952595
	speed: 0.0206s/iter; left time: 270.1666s
	iters: 200, epoch: 38 | loss: 23.1960697
	speed: 0.0180s/iter; left time: 235.1899s
Epoch: 38 cost time: 4.084564685821533
Epoch: 38, Steps: 210 Train Loss: 22.6971 (Forecasting Loss:0.4571 + XiCon Loss:2.2240 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 22.7884960
	speed: 0.0206s/iter; left time: 265.6356s
	iters: 200, epoch: 39 | loss: 22.4898186
	speed: 0.0188s/iter; left time: 240.8548s
Epoch: 39 cost time: 4.187956809997559
Epoch: 39, Steps: 210 Train Loss: 22.7258 (Forecasting Loss:0.4569 + XiCon Loss:2.2269 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 22.8092575
	speed: 0.0209s/iter; left time: 265.5038s
	iters: 200, epoch: 40 | loss: 23.4763126
	speed: 0.0185s/iter; left time: 233.1133s
Epoch: 40 cost time: 4.140313386917114
Epoch: 40, Steps: 210 Train Loss: 22.6813 (Forecasting Loss:0.4562 + XiCon Loss:2.2225 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 22.9340420
	speed: 0.0205s/iter; left time: 256.3312s
	iters: 200, epoch: 41 | loss: 23.2336044
	speed: 0.0183s/iter; left time: 227.4920s
Epoch: 41 cost time: 4.08582329750061
Epoch: 41, Steps: 210 Train Loss: 22.7638 (Forecasting Loss:0.4562 + XiCon Loss:2.2308 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.5479
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.533778727054596, mae:0.5620718598365784, mape:3.8024799823760986, mspe:13256.5927734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.2315
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.1678696
	speed: 0.0185s/iter; left time: 386.4076s
	iters: 200, epoch: 1 | loss: 24.1463413
	speed: 0.0153s/iter; left time: 317.4836s
Epoch: 1 cost time: 3.5602495670318604
Epoch: 1, Steps: 210 Train Loss: 25.3247 (Forecasting Loss:0.8359 + XiCon Loss:2.4489 x Lambda(10.0)), Vali MSE Loss: 0.2809 Test MSE Loss: 0.6360
Validation loss decreased (inf --> 0.280852).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 24.0023060
	speed: 0.0185s/iter; left time: 382.3541s
	iters: 200, epoch: 2 | loss: 24.2895584
	speed: 0.0163s/iter; left time: 334.6960s
Epoch: 2 cost time: 3.677070140838623
Epoch: 2, Steps: 210 Train Loss: 24.3848 (Forecasting Loss:0.5884 + XiCon Loss:2.3796 x Lambda(10.0)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.6231
Validation loss decreased (0.280852 --> 0.261103).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 23.6668644
	speed: 0.0196s/iter; left time: 401.9909s
	iters: 200, epoch: 3 | loss: 23.8016624
	speed: 0.0171s/iter; left time: 349.2754s
Epoch: 3 cost time: 3.8946216106414795
Epoch: 3, Steps: 210 Train Loss: 24.0508 (Forecasting Loss:0.5347 + XiCon Loss:2.3516 x Lambda(10.0)), Vali MSE Loss: 0.2241 Test MSE Loss: 0.5258
Validation loss decreased (0.261103 --> 0.224125).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 24.1027298
	speed: 0.0198s/iter; left time: 401.6625s
	iters: 200, epoch: 4 | loss: 23.3054562
	speed: 0.0172s/iter; left time: 347.1054s
Epoch: 4 cost time: 3.8920140266418457
Epoch: 4, Steps: 210 Train Loss: 23.5568 (Forecasting Loss:0.4877 + XiCon Loss:2.3069 x Lambda(10.0)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.5312
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 24.3931503
	speed: 0.0189s/iter; left time: 378.6944s
	iters: 200, epoch: 5 | loss: 23.0924950
	speed: 0.0163s/iter; left time: 325.5705s
Epoch: 5 cost time: 3.722590208053589
Epoch: 5, Steps: 210 Train Loss: 23.4731 (Forecasting Loss:0.4787 + XiCon Loss:2.2994 x Lambda(10.0)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.5386
Validation loss decreased (0.224125 --> 0.217407).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 22.6368351
	speed: 0.0187s/iter; left time: 371.3712s
	iters: 200, epoch: 6 | loss: 23.0486774
	speed: 0.0168s/iter; left time: 331.3418s
Epoch: 6 cost time: 3.741029977798462
Epoch: 6, Steps: 210 Train Loss: 23.3992 (Forecasting Loss:0.4752 + XiCon Loss:2.2924 x Lambda(10.0)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.5333
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 22.7154255
	speed: 0.0191s/iter; left time: 374.3914s
	iters: 200, epoch: 7 | loss: 23.3945503
	speed: 0.0164s/iter; left time: 320.5827s
Epoch: 7 cost time: 3.7333972454071045
Epoch: 7, Steps: 210 Train Loss: 23.3591 (Forecasting Loss:0.4734 + XiCon Loss:2.2886 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.5364
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 22.9225197
	speed: 0.0192s/iter; left time: 373.2381s
	iters: 200, epoch: 8 | loss: 23.3619709
	speed: 0.0163s/iter; left time: 314.7008s
Epoch: 8 cost time: 3.741987466812134
Epoch: 8, Steps: 210 Train Loss: 23.3946 (Forecasting Loss:0.4724 + XiCon Loss:2.2922 x Lambda(10.0)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.5374
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 24.7529163
	speed: 0.0192s/iter; left time: 368.3253s
	iters: 200, epoch: 9 | loss: 24.0494270
	speed: 0.0160s/iter; left time: 306.3273s
Epoch: 9 cost time: 3.727344036102295
Epoch: 9, Steps: 210 Train Loss: 23.3308 (Forecasting Loss:0.4717 + XiCon Loss:2.2859 x Lambda(10.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.5375
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 23.7738132
	speed: 0.0189s/iter; left time: 359.6443s
	iters: 200, epoch: 10 | loss: 24.1448784
	speed: 0.0161s/iter; left time: 304.0599s
Epoch: 10 cost time: 3.6959896087646484
Epoch: 10, Steps: 210 Train Loss: 23.4352 (Forecasting Loss:0.4712 + XiCon Loss:2.2964 x Lambda(10.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.5389
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 23.0800800
	speed: 0.0189s/iter; left time: 355.4116s
	iters: 200, epoch: 11 | loss: 24.5136299
	speed: 0.0166s/iter; left time: 310.8625s
Epoch: 11 cost time: 3.7392959594726562
Epoch: 11, Steps: 210 Train Loss: 23.3671 (Forecasting Loss:0.4714 + XiCon Loss:2.2896 x Lambda(10.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.5388
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 22.2121353
	speed: 0.0193s/iter; left time: 358.2580s
	iters: 200, epoch: 12 | loss: 23.4181042
	speed: 0.0169s/iter; left time: 312.9285s
Epoch: 12 cost time: 3.806460380554199
Epoch: 12, Steps: 210 Train Loss: 23.3542 (Forecasting Loss:0.4713 + XiCon Loss:2.2883 x Lambda(10.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.5381
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.0752869
	speed: 0.0187s/iter; left time: 343.5014s
	iters: 200, epoch: 13 | loss: 23.3511639
	speed: 0.0162s/iter; left time: 296.3106s
Epoch: 13 cost time: 3.6787705421447754
Epoch: 13, Steps: 210 Train Loss: 23.4541 (Forecasting Loss:0.4711 + XiCon Loss:2.2983 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.5384
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 22.5735416
	speed: 0.0193s/iter; left time: 351.3975s
	iters: 200, epoch: 14 | loss: 22.5276756
	speed: 0.0161s/iter; left time: 290.8195s
Epoch: 14 cost time: 3.7416505813598633
Epoch: 14, Steps: 210 Train Loss: 23.4726 (Forecasting Loss:0.4711 + XiCon Loss:2.3002 x Lambda(10.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.5384
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 23.4874210
	speed: 0.0190s/iter; left time: 341.8577s
	iters: 200, epoch: 15 | loss: 22.6227989
	speed: 0.0160s/iter; left time: 285.1222s
Epoch: 15 cost time: 3.705962657928467
Epoch: 15, Steps: 210 Train Loss: 23.3878 (Forecasting Loss:0.4715 + XiCon Loss:2.2916 x Lambda(10.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.5383
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5194734334945679, mae:0.5577294826507568, mape:3.9210243225097656, mspe:12482.8828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.3810
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.6017017
	speed: 0.0182s/iter; left time: 380.4669s
	iters: 200, epoch: 1 | loss: 24.4942799
	speed: 0.0160s/iter; left time: 332.2194s
Epoch: 1 cost time: 3.6324546337127686
Epoch: 1, Steps: 210 Train Loss: 25.3674 (Forecasting Loss:0.8324 + XiCon Loss:2.4535 x Lambda(10.0)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.6308
Validation loss decreased (inf --> 0.284761).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 24.0779533
	speed: 0.0181s/iter; left time: 374.6773s
	iters: 200, epoch: 2 | loss: 23.9945316
	speed: 0.0170s/iter; left time: 349.0510s
Epoch: 2 cost time: 3.6871542930603027
Epoch: 2, Steps: 210 Train Loss: 23.9963 (Forecasting Loss:0.5726 + XiCon Loss:2.3424 x Lambda(10.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.5687
Validation loss decreased (0.284761 --> 0.245244).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 23.9498558
	speed: 0.0204s/iter; left time: 416.8217s
	iters: 200, epoch: 3 | loss: 23.6708717
	speed: 0.0175s/iter; left time: 356.7539s
Epoch: 3 cost time: 4.002738952636719
Epoch: 3, Steps: 210 Train Loss: 23.8095 (Forecasting Loss:0.5087 + XiCon Loss:2.3301 x Lambda(10.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.5379
Validation loss decreased (0.245244 --> 0.229969).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.7238579
	speed: 0.0209s/iter; left time: 423.2480s
	iters: 200, epoch: 4 | loss: 23.0465164
	speed: 0.0186s/iter; left time: 374.4967s
Epoch: 4 cost time: 4.1682517528533936
Epoch: 4, Steps: 210 Train Loss: 23.5574 (Forecasting Loss:0.4864 + XiCon Loss:2.3071 x Lambda(10.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.5627
Validation loss decreased (0.229969 --> 0.220020).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 23.6346664
	speed: 0.0205s/iter; left time: 411.1098s
	iters: 200, epoch: 5 | loss: 22.6558533
	speed: 0.0179s/iter; left time: 358.0595s
Epoch: 5 cost time: 4.061811923980713
Epoch: 5, Steps: 210 Train Loss: 23.4527 (Forecasting Loss:0.4730 + XiCon Loss:2.2980 x Lambda(10.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.5571
Validation loss decreased (0.220020 --> 0.218542).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 22.8540268
	speed: 0.0200s/iter; left time: 397.7222s
	iters: 200, epoch: 6 | loss: 22.1800137
	speed: 0.0175s/iter; left time: 345.1381s
Epoch: 6 cost time: 3.9535553455352783
Epoch: 6, Steps: 210 Train Loss: 23.3997 (Forecasting Loss:0.4669 + XiCon Loss:2.2933 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.5741
Validation loss decreased (0.218542 --> 0.215306).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 23.1816330
	speed: 0.0200s/iter; left time: 391.9698s
	iters: 200, epoch: 7 | loss: 23.2086430
	speed: 0.0177s/iter; left time: 344.9560s
Epoch: 7 cost time: 3.967430591583252
Epoch: 7, Steps: 210 Train Loss: 23.3628 (Forecasting Loss:0.4639 + XiCon Loss:2.2899 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5580
Validation loss decreased (0.215306 --> 0.213572).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.8879337
	speed: 0.0199s/iter; left time: 386.8460s
	iters: 200, epoch: 8 | loss: 24.3037930
	speed: 0.0175s/iter; left time: 337.5451s
Epoch: 8 cost time: 3.9429516792297363
Epoch: 8, Steps: 210 Train Loss: 23.3223 (Forecasting Loss:0.4630 + XiCon Loss:2.2859 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5588
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 22.8175125
	speed: 0.0199s/iter; left time: 382.2962s
	iters: 200, epoch: 9 | loss: 22.7233334
	speed: 0.0177s/iter; left time: 337.7579s
Epoch: 9 cost time: 3.959691047668457
Epoch: 9, Steps: 210 Train Loss: 23.2551 (Forecasting Loss:0.4622 + XiCon Loss:2.2793 x Lambda(10.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.5543
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.4966583
	speed: 0.0201s/iter; left time: 382.9493s
	iters: 200, epoch: 10 | loss: 23.1238708
	speed: 0.0167s/iter; left time: 315.1079s
Epoch: 10 cost time: 3.8795602321624756
Epoch: 10, Steps: 210 Train Loss: 23.3073 (Forecasting Loss:0.4617 + XiCon Loss:2.2846 x Lambda(10.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.5566
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.7531757
	speed: 0.0202s/iter; left time: 379.7520s
	iters: 200, epoch: 11 | loss: 22.7971478
	speed: 0.0178s/iter; left time: 333.3423s
Epoch: 11 cost time: 4.032447814941406
Epoch: 11, Steps: 210 Train Loss: 23.2542 (Forecasting Loss:0.4617 + XiCon Loss:2.2792 x Lambda(10.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.5572
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 24.4807415
	speed: 0.0201s/iter; left time: 373.9935s
	iters: 200, epoch: 12 | loss: 23.4463634
	speed: 0.0178s/iter; left time: 329.8892s
Epoch: 12 cost time: 4.002764463424683
Epoch: 12, Steps: 210 Train Loss: 23.2911 (Forecasting Loss:0.4613 + XiCon Loss:2.2830 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5587
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.8614521
	speed: 0.0194s/iter; left time: 355.9216s
	iters: 200, epoch: 13 | loss: 23.1087475
	speed: 0.0181s/iter; left time: 330.7219s
Epoch: 13 cost time: 3.9441452026367188
Epoch: 13, Steps: 210 Train Loss: 23.2933 (Forecasting Loss:0.4617 + XiCon Loss:2.2832 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.5586
Validation loss decreased (0.213572 --> 0.213517).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.4302788
	speed: 0.0205s/iter; left time: 371.7602s
	iters: 200, epoch: 14 | loss: 23.4867859
	speed: 0.0174s/iter; left time: 315.0215s
Epoch: 14 cost time: 3.984754800796509
Epoch: 14, Steps: 210 Train Loss: 23.2589 (Forecasting Loss:0.4614 + XiCon Loss:2.2797 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.5582
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.9549942
	speed: 0.0195s/iter; left time: 350.9844s
	iters: 200, epoch: 15 | loss: 22.3867283
	speed: 0.0172s/iter; left time: 306.9548s
Epoch: 15 cost time: 3.8654062747955322
Epoch: 15, Steps: 210 Train Loss: 23.2408 (Forecasting Loss:0.4611 + XiCon Loss:2.2780 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 23.8735847
	speed: 0.0198s/iter; left time: 352.2813s
	iters: 200, epoch: 16 | loss: 23.3071194
	speed: 0.0176s/iter; left time: 310.4670s
Epoch: 16 cost time: 3.957669496536255
Epoch: 16, Steps: 210 Train Loss: 23.3174 (Forecasting Loss:0.4617 + XiCon Loss:2.2856 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 22.8740177
	speed: 0.0194s/iter; left time: 339.7071s
	iters: 200, epoch: 17 | loss: 23.5348625
	speed: 0.0172s/iter; left time: 299.1186s
Epoch: 17 cost time: 3.8437001705169678
Epoch: 17, Steps: 210 Train Loss: 23.2383 (Forecasting Loss:0.4618 + XiCon Loss:2.2777 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.5583
Validation loss decreased (0.213517 --> 0.213396).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 23.1267319
	speed: 0.0203s/iter; left time: 351.9485s
	iters: 200, epoch: 18 | loss: 22.4908142
	speed: 0.0168s/iter; left time: 289.4761s
Epoch: 18 cost time: 3.907054901123047
Epoch: 18, Steps: 210 Train Loss: 23.2451 (Forecasting Loss:0.4614 + XiCon Loss:2.2784 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 23.5187302
	speed: 0.0201s/iter; left time: 344.6846s
	iters: 200, epoch: 19 | loss: 24.1188469
	speed: 0.0171s/iter; left time: 291.8228s
Epoch: 19 cost time: 3.919464349746704
Epoch: 19, Steps: 210 Train Loss: 23.2479 (Forecasting Loss:0.4606 + XiCon Loss:2.2787 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 23.0189247
	speed: 0.0196s/iter; left time: 332.2429s
	iters: 200, epoch: 20 | loss: 24.6947212
	speed: 0.0176s/iter; left time: 295.9829s
Epoch: 20 cost time: 3.908311605453491
Epoch: 20, Steps: 210 Train Loss: 23.2892 (Forecasting Loss:0.4620 + XiCon Loss:2.2827 x Lambda(10.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.5583
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 22.9469757
	speed: 0.0201s/iter; left time: 335.1125s
	iters: 200, epoch: 21 | loss: 22.7411118
	speed: 0.0169s/iter; left time: 280.9445s
Epoch: 21 cost time: 3.9005370140075684
Epoch: 21, Steps: 210 Train Loss: 23.2561 (Forecasting Loss:0.4611 + XiCon Loss:2.2795 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.5583
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 23.3153572
	speed: 0.0202s/iter; left time: 332.4502s
	iters: 200, epoch: 22 | loss: 23.4083157
	speed: 0.0178s/iter; left time: 292.0420s
Epoch: 22 cost time: 4.037236452102661
Epoch: 22, Steps: 210 Train Loss: 23.3650 (Forecasting Loss:0.4617 + XiCon Loss:2.2903 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.5583
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 23.6282005
	speed: 0.0199s/iter; left time: 323.2762s
	iters: 200, epoch: 23 | loss: 22.9914036
	speed: 0.0175s/iter; left time: 283.4577s
Epoch: 23 cost time: 3.92690372467041
Epoch: 23, Steps: 210 Train Loss: 23.2770 (Forecasting Loss:0.4612 + XiCon Loss:2.2816 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 23.1597729
	speed: 0.0202s/iter; left time: 324.4794s
	iters: 200, epoch: 24 | loss: 24.2553921
	speed: 0.0176s/iter; left time: 280.3164s
Epoch: 24 cost time: 3.966357707977295
Epoch: 24, Steps: 210 Train Loss: 23.2050 (Forecasting Loss:0.4612 + XiCon Loss:2.2744 x Lambda(10.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.5583
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 22.5284138
	speed: 0.0201s/iter; left time: 319.5032s
	iters: 200, epoch: 25 | loss: 24.5626163
	speed: 0.0175s/iter; left time: 275.5922s
Epoch: 25 cost time: 3.9721803665161133
Epoch: 25, Steps: 210 Train Loss: 23.3132 (Forecasting Loss:0.4609 + XiCon Loss:2.2852 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.5583
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 22.9277020
	speed: 0.0200s/iter; left time: 312.7524s
	iters: 200, epoch: 26 | loss: 23.2964458
	speed: 0.0173s/iter; left time: 268.2642s
Epoch: 26 cost time: 3.9224741458892822
Epoch: 26, Steps: 210 Train Loss: 23.3362 (Forecasting Loss:0.4617 + XiCon Loss:2.2874 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 22.6934891
	speed: 0.0197s/iter; left time: 303.6557s
	iters: 200, epoch: 27 | loss: 22.4621983
	speed: 0.0169s/iter; left time: 258.8758s
Epoch: 27 cost time: 3.861905097961426
Epoch: 27, Steps: 210 Train Loss: 23.3261 (Forecasting Loss:0.4621 + XiCon Loss:2.2864 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.5583
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5454367399215698, mae:0.5711830258369446, mape:3.3269689083099365, mspe:2975.6591796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.1470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.6981812
	speed: 0.0188s/iter; left time: 392.1647s
	iters: 200, epoch: 1 | loss: 25.0032482
	speed: 0.0149s/iter; left time: 310.3786s
Epoch: 1 cost time: 3.561744451522827
Epoch: 1, Steps: 210 Train Loss: 25.3954 (Forecasting Loss:0.8377 + XiCon Loss:2.4558 x Lambda(10.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.6817
Validation loss decreased (inf --> 0.279622).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.8120136
	speed: 0.0220s/iter; left time: 455.0270s
	iters: 200, epoch: 2 | loss: 25.0325069
	speed: 0.0194s/iter; left time: 399.9239s
Epoch: 2 cost time: 4.341054916381836
Epoch: 2, Steps: 210 Train Loss: 24.1908 (Forecasting Loss:0.6657 + XiCon Loss:2.3525 x Lambda(10.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.5382
Validation loss decreased (0.279622 --> 0.253556).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 24.5590801
	speed: 0.0211s/iter; left time: 433.0750s
	iters: 200, epoch: 3 | loss: 24.7818565
	speed: 0.0192s/iter; left time: 392.1833s
Epoch: 3 cost time: 4.25907039642334
Epoch: 3, Steps: 210 Train Loss: 24.8665 (Forecasting Loss:0.5395 + XiCon Loss:2.4327 x Lambda(10.0)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.5481
Validation loss decreased (0.253556 --> 0.235730).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 24.3610477
	speed: 0.0221s/iter; left time: 448.3757s
	iters: 200, epoch: 4 | loss: 23.5669289
	speed: 0.0202s/iter; left time: 407.3138s
Epoch: 4 cost time: 4.448184490203857
Epoch: 4, Steps: 210 Train Loss: 24.4883 (Forecasting Loss:0.5115 + XiCon Loss:2.3977 x Lambda(10.0)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.5530
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 23.9084187
	speed: 0.0224s/iter; left time: 449.8107s
	iters: 200, epoch: 5 | loss: 23.4345417
	speed: 0.0192s/iter; left time: 383.8728s
Epoch: 5 cost time: 4.407259941101074
Epoch: 5, Steps: 210 Train Loss: 24.2417 (Forecasting Loss:0.5062 + XiCon Loss:2.3736 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.5519
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 24.6940746
	speed: 0.0217s/iter; left time: 430.4119s
	iters: 200, epoch: 6 | loss: 23.1293392
	speed: 0.0192s/iter; left time: 378.2816s
Epoch: 6 cost time: 4.324595928192139
Epoch: 6, Steps: 210 Train Loss: 24.1400 (Forecasting Loss:0.5072 + XiCon Loss:2.3633 x Lambda(10.0)), Vali MSE Loss: 0.2381 Test MSE Loss: 0.5575
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 24.0217285
	speed: 0.0222s/iter; left time: 435.2320s
	iters: 200, epoch: 7 | loss: 24.0699692
	speed: 0.0198s/iter; left time: 386.8444s
Epoch: 7 cost time: 4.4179511070251465
Epoch: 7, Steps: 210 Train Loss: 24.0195 (Forecasting Loss:0.5031 + XiCon Loss:2.3516 x Lambda(10.0)), Vali MSE Loss: 0.2334 Test MSE Loss: 0.5563
Validation loss decreased (0.235730 --> 0.233440).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 24.6087685
	speed: 0.0214s/iter; left time: 416.2289s
	iters: 200, epoch: 8 | loss: 23.7746582
	speed: 0.0194s/iter; left time: 374.8308s
Epoch: 8 cost time: 4.3065221309661865
Epoch: 8, Steps: 210 Train Loss: 24.0269 (Forecasting Loss:0.5014 + XiCon Loss:2.3525 x Lambda(10.0)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.5616
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 24.9397831
	speed: 0.0217s/iter; left time: 416.3524s
	iters: 200, epoch: 9 | loss: 24.3032093
	speed: 0.0200s/iter; left time: 381.4709s
Epoch: 9 cost time: 4.386973857879639
Epoch: 9, Steps: 210 Train Loss: 24.0366 (Forecasting Loss:0.5001 + XiCon Loss:2.3536 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.5602
Validation loss decreased (0.233440 --> 0.232333).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 23.8442898
	speed: 0.0219s/iter; left time: 416.9498s
	iters: 200, epoch: 10 | loss: 23.3521004
	speed: 0.0193s/iter; left time: 364.4921s
Epoch: 10 cost time: 4.3690385818481445
Epoch: 10, Steps: 210 Train Loss: 23.9358 (Forecasting Loss:0.5004 + XiCon Loss:2.3435 x Lambda(10.0)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.5605
Validation loss decreased (0.232333 --> 0.232211).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 23.4479523
	speed: 0.0218s/iter; left time: 409.5672s
	iters: 200, epoch: 11 | loss: 24.0124264
	speed: 0.0192s/iter; left time: 358.3817s
Epoch: 11 cost time: 4.333128929138184
Epoch: 11, Steps: 210 Train Loss: 23.9699 (Forecasting Loss:0.4992 + XiCon Loss:2.3471 x Lambda(10.0)), Vali MSE Loss: 0.2315 Test MSE Loss: 0.5597
Validation loss decreased (0.232211 --> 0.231494).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 23.7907925
	speed: 0.0216s/iter; left time: 401.2089s
	iters: 200, epoch: 12 | loss: 24.9390316
	speed: 0.0192s/iter; left time: 355.8663s
Epoch: 12 cost time: 4.293831825256348
Epoch: 12, Steps: 210 Train Loss: 24.0153 (Forecasting Loss:0.4994 + XiCon Loss:2.3516 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.5598
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.4714088
	speed: 0.0223s/iter; left time: 409.4039s
	iters: 200, epoch: 13 | loss: 23.2861366
	speed: 0.0198s/iter; left time: 361.8778s
Epoch: 13 cost time: 4.429555416107178
Epoch: 13, Steps: 210 Train Loss: 23.9855 (Forecasting Loss:0.4978 + XiCon Loss:2.3488 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5599
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.7139492
	speed: 0.0215s/iter; left time: 391.5733s
	iters: 200, epoch: 14 | loss: 23.6229362
	speed: 0.0194s/iter; left time: 350.5795s
Epoch: 14 cost time: 4.322674989700317
Epoch: 14, Steps: 210 Train Loss: 23.9318 (Forecasting Loss:0.4992 + XiCon Loss:2.3433 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.5599
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 23.4060364
	speed: 0.0217s/iter; left time: 390.1306s
	iters: 200, epoch: 15 | loss: 25.4013424
	speed: 0.0195s/iter; left time: 349.1194s
Epoch: 15 cost time: 4.348280429840088
Epoch: 15, Steps: 210 Train Loss: 23.9701 (Forecasting Loss:0.4989 + XiCon Loss:2.3471 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5600
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 23.9702053
	speed: 0.0220s/iter; left time: 389.7143s
	iters: 200, epoch: 16 | loss: 23.8765945
	speed: 0.0194s/iter; left time: 342.1651s
Epoch: 16 cost time: 4.369296073913574
Epoch: 16, Steps: 210 Train Loss: 23.9747 (Forecasting Loss:0.4989 + XiCon Loss:2.3476 x Lambda(10.0)), Vali MSE Loss: 0.2315 Test MSE Loss: 0.5600
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 23.3024693
	speed: 0.0223s/iter; left time: 391.4334s
	iters: 200, epoch: 17 | loss: 23.7908401
	speed: 0.0193s/iter; left time: 336.0494s
Epoch: 17 cost time: 4.3648436069488525
Epoch: 17, Steps: 210 Train Loss: 23.9220 (Forecasting Loss:0.4984 + XiCon Loss:2.3424 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.5600
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 24.4685230
	speed: 0.0217s/iter; left time: 376.3557s
	iters: 200, epoch: 18 | loss: 23.9871407
	speed: 0.0192s/iter; left time: 331.5565s
Epoch: 18 cost time: 4.324009895324707
Epoch: 18, Steps: 210 Train Loss: 23.9738 (Forecasting Loss:0.4988 + XiCon Loss:2.3475 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.5600
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 23.5672760
	speed: 0.0219s/iter; left time: 375.7317s
	iters: 200, epoch: 19 | loss: 24.4788742
	speed: 0.0191s/iter; left time: 324.5872s
Epoch: 19 cost time: 4.3292577266693115
Epoch: 19, Steps: 210 Train Loss: 23.9970 (Forecasting Loss:0.4986 + XiCon Loss:2.3498 x Lambda(10.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.5600
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 23.5491943
	speed: 0.0223s/iter; left time: 376.9281s
	iters: 200, epoch: 20 | loss: 23.6292343
	speed: 0.0194s/iter; left time: 326.0502s
Epoch: 20 cost time: 4.370948314666748
Epoch: 20, Steps: 210 Train Loss: 23.9725 (Forecasting Loss:0.4994 + XiCon Loss:2.3473 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.5600
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 23.0150528
	speed: 0.0218s/iter; left time: 363.7231s
	iters: 200, epoch: 21 | loss: 23.2079067
	speed: 0.0192s/iter; left time: 319.1052s
Epoch: 21 cost time: 4.342169523239136
Epoch: 21, Steps: 210 Train Loss: 23.9745 (Forecasting Loss:0.4984 + XiCon Loss:2.3476 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.5600
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5470729470252991, mae:0.5722349286079407, mape:3.6604199409484863, mspe:8444.7333984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.2942
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.3853188
	speed: 0.0191s/iter; left time: 399.1560s
	iters: 200, epoch: 1 | loss: 25.4321823
	speed: 0.0156s/iter; left time: 324.3648s
Epoch: 1 cost time: 3.6489269733428955
Epoch: 1, Steps: 210 Train Loss: 25.4396 (Forecasting Loss:0.8380 + XiCon Loss:2.4602 x Lambda(10.0)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.6953
Validation loss decreased (inf --> 0.279709).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.9434586
	speed: 0.0212s/iter; left time: 439.1349s
	iters: 200, epoch: 2 | loss: 24.9327011
	speed: 0.0193s/iter; left time: 396.7310s
Epoch: 2 cost time: 4.284084320068359
Epoch: 2, Steps: 210 Train Loss: 23.9925 (Forecasting Loss:0.6943 + XiCon Loss:2.3298 x Lambda(10.0)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.6507
Validation loss decreased (0.279709 --> 0.261807).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 24.4234238
	speed: 0.0224s/iter; left time: 458.2231s
	iters: 200, epoch: 3 | loss: 23.4275894
	speed: 0.0199s/iter; left time: 405.3365s
Epoch: 3 cost time: 4.439732789993286
Epoch: 3, Steps: 210 Train Loss: 24.3385 (Forecasting Loss:0.5618 + XiCon Loss:2.3777 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.5667
Validation loss decreased (0.261807 --> 0.250810).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 23.8394966
	speed: 0.0221s/iter; left time: 447.9538s
	iters: 200, epoch: 4 | loss: 23.8140316
	speed: 0.0192s/iter; left time: 387.0839s
Epoch: 4 cost time: 4.349678039550781
Epoch: 4, Steps: 210 Train Loss: 23.7998 (Forecasting Loss:0.5119 + XiCon Loss:2.3288 x Lambda(10.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.5316
Validation loss decreased (0.250810 --> 0.241166).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 23.2663593
	speed: 0.0218s/iter; left time: 437.2043s
	iters: 200, epoch: 5 | loss: 23.1728802
	speed: 0.0192s/iter; left time: 384.1019s
Epoch: 5 cost time: 4.334589004516602
Epoch: 5, Steps: 210 Train Loss: 23.7701 (Forecasting Loss:0.4960 + XiCon Loss:2.3274 x Lambda(10.0)), Vali MSE Loss: 0.2386 Test MSE Loss: 0.5386
Validation loss decreased (0.241166 --> 0.238593).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 23.9888935
	speed: 0.0216s/iter; left time: 428.2230s
	iters: 200, epoch: 6 | loss: 23.5884418
	speed: 0.0198s/iter; left time: 391.3510s
Epoch: 6 cost time: 4.340857982635498
Epoch: 6, Steps: 210 Train Loss: 23.6745 (Forecasting Loss:0.4981 + XiCon Loss:2.3176 x Lambda(10.0)), Vali MSE Loss: 0.2384 Test MSE Loss: 0.5389
Validation loss decreased (0.238593 --> 0.238382).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 23.8582287
	speed: 0.0220s/iter; left time: 431.8575s
	iters: 200, epoch: 7 | loss: 22.6597290
	speed: 0.0187s/iter; left time: 365.2208s
Epoch: 7 cost time: 4.286211252212524
Epoch: 7, Steps: 210 Train Loss: 23.7080 (Forecasting Loss:0.4964 + XiCon Loss:2.3212 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5344
Validation loss decreased (0.238382 --> 0.235916).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.1468697
	speed: 0.0222s/iter; left time: 431.5731s
	iters: 200, epoch: 8 | loss: 22.7721481
	speed: 0.0196s/iter; left time: 379.7693s
Epoch: 8 cost time: 4.410996437072754
Epoch: 8, Steps: 210 Train Loss: 23.6773 (Forecasting Loss:0.4933 + XiCon Loss:2.3184 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.5335
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 23.3879108
	speed: 0.0223s/iter; left time: 429.2678s
	iters: 200, epoch: 9 | loss: 23.4591351
	speed: 0.0196s/iter; left time: 374.4706s
Epoch: 9 cost time: 4.416876554489136
Epoch: 9, Steps: 210 Train Loss: 23.6636 (Forecasting Loss:0.4936 + XiCon Loss:2.3170 x Lambda(10.0)), Vali MSE Loss: 0.2361 Test MSE Loss: 0.5339
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.8379955
	speed: 0.0208s/iter; left time: 396.1913s
	iters: 200, epoch: 10 | loss: 24.0865993
	speed: 0.0185s/iter; left time: 349.1468s
Epoch: 10 cost time: 4.15029501914978
Epoch: 10, Steps: 210 Train Loss: 23.5810 (Forecasting Loss:0.4939 + XiCon Loss:2.3087 x Lambda(10.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.5344
Validation loss decreased (0.235916 --> 0.235836).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 24.1344395
	speed: 0.0206s/iter; left time: 386.8489s
	iters: 200, epoch: 11 | loss: 23.6087551
	speed: 0.0415s/iter; left time: 775.5562s
Epoch: 11 cost time: 7.030520677566528
Epoch: 11, Steps: 210 Train Loss: 23.6900 (Forecasting Loss:0.4929 + XiCon Loss:2.3197 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.5334
Validation loss decreased (0.235836 --> 0.235529).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 22.7430019
	speed: 0.0637s/iter; left time: 1183.8178s
	iters: 200, epoch: 12 | loss: 23.5757694
	speed: 0.0669s/iter; left time: 1237.4677s
Epoch: 12 cost time: 13.9951753616333
Epoch: 12, Steps: 210 Train Loss: 23.6031 (Forecasting Loss:0.4933 + XiCon Loss:2.3110 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5335
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.0232201
	speed: 0.0791s/iter; left time: 1453.8703s
	iters: 200, epoch: 13 | loss: 24.6782055
	speed: 0.0677s/iter; left time: 1237.0645s
Epoch: 13 cost time: 15.36398696899414
Epoch: 13, Steps: 210 Train Loss: 23.6719 (Forecasting Loss:0.4946 + XiCon Loss:2.3177 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5334
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.0383301
	speed: 0.0646s/iter; left time: 1173.2638s
	iters: 200, epoch: 14 | loss: 23.4146805
	speed: 0.0571s/iter; left time: 1032.0793s
Epoch: 14 cost time: 12.828591585159302
Epoch: 14, Steps: 210 Train Loss: 23.6328 (Forecasting Loss:0.4937 + XiCon Loss:2.3139 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5335
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 23.2062206
	speed: 0.0541s/iter; left time: 971.5316s
	iters: 200, epoch: 15 | loss: 24.3408203
	speed: 0.0399s/iter; left time: 712.9953s
Epoch: 15 cost time: 9.866888523101807
Epoch: 15, Steps: 210 Train Loss: 23.7009 (Forecasting Loss:0.4933 + XiCon Loss:2.3208 x Lambda(10.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.5335
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 24.4509697
	speed: 0.0294s/iter; left time: 521.8658s
	iters: 200, epoch: 16 | loss: 23.6065407
	speed: 0.0233s/iter; left time: 411.6722s
Epoch: 16 cost time: 5.518659353256226
Epoch: 16, Steps: 210 Train Loss: 23.6229 (Forecasting Loss:0.4931 + XiCon Loss:2.3130 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5335
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 23.7572937
	speed: 0.0232s/iter; left time: 406.9261s
	iters: 200, epoch: 17 | loss: 23.0843735
	speed: 0.0207s/iter; left time: 360.5319s
Epoch: 17 cost time: 4.636752605438232
Epoch: 17, Steps: 210 Train Loss: 23.6801 (Forecasting Loss:0.4930 + XiCon Loss:2.3187 x Lambda(10.0)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.5335
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 23.9824734
	speed: 0.0224s/iter; left time: 388.4681s
	iters: 200, epoch: 18 | loss: 22.9144859
	speed: 0.0192s/iter; left time: 330.7839s
Epoch: 18 cost time: 4.3981616497039795
Epoch: 18, Steps: 210 Train Loss: 23.6374 (Forecasting Loss:0.4931 + XiCon Loss:2.3144 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.5336
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 23.6852303
	speed: 0.0215s/iter; left time: 368.8530s
	iters: 200, epoch: 19 | loss: 24.6884861
	speed: 0.0181s/iter; left time: 307.6132s
Epoch: 19 cost time: 4.183290719985962
Epoch: 19, Steps: 210 Train Loss: 23.6193 (Forecasting Loss:0.4940 + XiCon Loss:2.3125 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.5336
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 22.5619164
	speed: 0.0204s/iter; left time: 344.2968s
	iters: 200, epoch: 20 | loss: 22.9275169
	speed: 0.0180s/iter; left time: 302.3334s
Epoch: 20 cost time: 4.060387372970581
Epoch: 20, Steps: 210 Train Loss: 23.6950 (Forecasting Loss:0.4940 + XiCon Loss:2.3201 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.5336
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 24.2178669
	speed: 0.0203s/iter; left time: 338.6115s
	iters: 200, epoch: 21 | loss: 25.1999683
	speed: 0.0177s/iter; left time: 293.7434s
Epoch: 21 cost time: 4.0137245655059814
Epoch: 21, Steps: 210 Train Loss: 23.6459 (Forecasting Loss:0.4933 + XiCon Loss:2.3153 x Lambda(10.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.5336
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.511022686958313, mae:0.5557253360748291, mape:3.8405075073242188, mspe:17710.955078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5314+-0.01969, MAE:0.5638+-0.00943, MAPE:3.7103+-0.29072, MSPE:10974.1660+-6892.19069, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
