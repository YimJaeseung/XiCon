Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3474
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5466877
	speed: 0.0175s/iter; left time: 222.8717s
Epoch: 1 cost time: 2.118436813354492
Epoch: 1, Steps: 128 Train Loss: 0.5508 (Forecasting Loss:0.2442 + XiCon Loss:3.0660 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1220
Validation loss decreased (inf --> 0.173527).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5675901
	speed: 0.0137s/iter; left time: 171.7974s
Epoch: 2 cost time: 1.7666418552398682
Epoch: 2, Steps: 128 Train Loss: 0.5348 (Forecasting Loss:0.2439 + XiCon Loss:2.9093 x Lambda(0.1)), Vali MSE Loss: 0.1768 Test MSE Loss: 0.1340
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4875643
	speed: 0.0138s/iter; left time: 172.3370s
Epoch: 3 cost time: 1.74068284034729
Epoch: 3, Steps: 128 Train Loss: 0.5243 (Forecasting Loss:0.2313 + XiCon Loss:2.9292 x Lambda(0.1)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1231
Validation loss decreased (0.173527 --> 0.166909).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4920767
	speed: 0.0137s/iter; left time: 168.4119s
Epoch: 4 cost time: 1.7101478576660156
Epoch: 4, Steps: 128 Train Loss: 0.5087 (Forecasting Loss:0.2213 + XiCon Loss:2.8741 x Lambda(0.1)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4885694
	speed: 0.0142s/iter; left time: 172.9027s
Epoch: 5 cost time: 1.742835283279419
Epoch: 5, Steps: 128 Train Loss: 0.5032 (Forecasting Loss:0.2158 + XiCon Loss:2.8732 x Lambda(0.1)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1163
Validation loss decreased (0.166909 --> 0.165704).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4970562
	speed: 0.0135s/iter; left time: 162.3574s
Epoch: 6 cost time: 1.6701033115386963
Epoch: 6, Steps: 128 Train Loss: 0.4993 (Forecasting Loss:0.2140 + XiCon Loss:2.8534 x Lambda(0.1)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1161
Validation loss decreased (0.165704 --> 0.164588).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4757473
	speed: 0.0131s/iter; left time: 156.0726s
Epoch: 7 cost time: 1.6652917861938477
Epoch: 7, Steps: 128 Train Loss: 0.4972 (Forecasting Loss:0.2122 + XiCon Loss:2.8504 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1183
Validation loss decreased (0.164588 --> 0.162853).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5016668
	speed: 0.0146s/iter; left time: 172.7772s
Epoch: 8 cost time: 1.8007652759552002
Epoch: 8, Steps: 128 Train Loss: 0.4963 (Forecasting Loss:0.2117 + XiCon Loss:2.8457 x Lambda(0.1)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5451407
	speed: 0.0132s/iter; left time: 153.7795s
Epoch: 9 cost time: 1.68137788772583
Epoch: 9, Steps: 128 Train Loss: 0.4954 (Forecasting Loss:0.2114 + XiCon Loss:2.8396 x Lambda(0.1)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5026085
	speed: 0.0138s/iter; left time: 159.6674s
Epoch: 10 cost time: 1.7666099071502686
Epoch: 10, Steps: 128 Train Loss: 0.4953 (Forecasting Loss:0.2109 + XiCon Loss:2.8438 x Lambda(0.1)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4873800
	speed: 0.0132s/iter; left time: 150.3953s
Epoch: 11 cost time: 1.6747708320617676
Epoch: 11, Steps: 128 Train Loss: 0.4948 (Forecasting Loss:0.2107 + XiCon Loss:2.8411 x Lambda(0.1)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4991195
	speed: 0.0133s/iter; left time: 150.6739s
Epoch: 12 cost time: 1.670752763748169
Epoch: 12, Steps: 128 Train Loss: 0.4945 (Forecasting Loss:0.2105 + XiCon Loss:2.8397 x Lambda(0.1)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5230407
	speed: 0.0136s/iter; left time: 151.8288s
Epoch: 13 cost time: 1.6890065670013428
Epoch: 13, Steps: 128 Train Loss: 0.4944 (Forecasting Loss:0.2105 + XiCon Loss:2.8397 x Lambda(0.1)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4922748
	speed: 0.0129s/iter; left time: 141.8503s
Epoch: 14 cost time: 1.6240043640136719
Epoch: 14, Steps: 128 Train Loss: 0.4952 (Forecasting Loss:0.2107 + XiCon Loss:2.8450 x Lambda(0.1)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5372141
	speed: 0.0145s/iter; left time: 157.9300s
Epoch: 15 cost time: 1.7925574779510498
Epoch: 15, Steps: 128 Train Loss: 0.4949 (Forecasting Loss:0.2107 + XiCon Loss:2.8425 x Lambda(0.1)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4790090
	speed: 0.0131s/iter; left time: 141.3857s
Epoch: 16 cost time: 1.6362342834472656
Epoch: 16, Steps: 128 Train Loss: 0.4951 (Forecasting Loss:0.2107 + XiCon Loss:2.8441 x Lambda(0.1)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4955201
	speed: 0.0140s/iter; left time: 149.1409s
Epoch: 17 cost time: 1.7360234260559082
Epoch: 17, Steps: 128 Train Loss: 0.4949 (Forecasting Loss:0.2108 + XiCon Loss:2.8409 x Lambda(0.1)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05618824437260628, mae:0.18043860793113708, mape:0.14748932421207428, mspe:0.04579711705446243 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3904
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5316653
	speed: 0.0138s/iter; left time: 175.7639s
Epoch: 1 cost time: 1.7280778884887695
Epoch: 1, Steps: 128 Train Loss: 0.5468 (Forecasting Loss:0.2412 + XiCon Loss:3.0556 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1198
Validation loss decreased (inf --> 0.171221).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5721610
	speed: 0.0137s/iter; left time: 172.8447s
Epoch: 2 cost time: 1.734175443649292
Epoch: 2, Steps: 128 Train Loss: 0.5279 (Forecasting Loss:0.2369 + XiCon Loss:2.9095 x Lambda(0.1)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1305
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4654422
	speed: 0.0147s/iter; left time: 182.4827s
Epoch: 3 cost time: 1.8060925006866455
Epoch: 3, Steps: 128 Train Loss: 0.4910 (Forecasting Loss:0.2083 + XiCon Loss:2.8268 x Lambda(0.1)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1300
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4690834
	speed: 0.0134s/iter; left time: 164.7358s
Epoch: 4 cost time: 1.6796197891235352
Epoch: 4, Steps: 128 Train Loss: 0.4825 (Forecasting Loss:0.1897 + XiCon Loss:2.9276 x Lambda(0.1)), Vali MSE Loss: 0.1778 Test MSE Loss: 0.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4710951
	speed: 0.0137s/iter; left time: 167.4063s
Epoch: 5 cost time: 1.7741117477416992
Epoch: 5, Steps: 128 Train Loss: 0.4720 (Forecasting Loss:0.1791 + XiCon Loss:2.9288 x Lambda(0.1)), Vali MSE Loss: 0.1740 Test MSE Loss: 0.1410
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4557425
	speed: 0.0139s/iter; left time: 168.1100s
Epoch: 6 cost time: 1.7432892322540283
Epoch: 6, Steps: 128 Train Loss: 0.4634 (Forecasting Loss:0.1710 + XiCon Loss:2.9236 x Lambda(0.1)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1400
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4502960
	speed: 0.0135s/iter; left time: 161.5266s
Epoch: 7 cost time: 1.6842548847198486
Epoch: 7, Steps: 128 Train Loss: 0.4583 (Forecasting Loss:0.1664 + XiCon Loss:2.9196 x Lambda(0.1)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1433
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4673796
	speed: 0.0131s/iter; left time: 155.2061s
Epoch: 8 cost time: 1.686095952987671
Epoch: 8, Steps: 128 Train Loss: 0.4557 (Forecasting Loss:0.1639 + XiCon Loss:2.9180 x Lambda(0.1)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1390
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4624026
	speed: 0.0146s/iter; left time: 169.9515s
Epoch: 9 cost time: 1.778886079788208
Epoch: 9, Steps: 128 Train Loss: 0.4556 (Forecasting Loss:0.1631 + XiCon Loss:2.9250 x Lambda(0.1)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1417
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4465406
	speed: 0.0131s/iter; left time: 151.4444s
Epoch: 10 cost time: 1.6919326782226562
Epoch: 10, Steps: 128 Train Loss: 0.4545 (Forecasting Loss:0.1626 + XiCon Loss:2.9194 x Lambda(0.1)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1427
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4567605
	speed: 0.0132s/iter; left time: 150.7981s
Epoch: 11 cost time: 1.6865577697753906
Epoch: 11, Steps: 128 Train Loss: 0.4542 (Forecasting Loss:0.1618 + XiCon Loss:2.9233 x Lambda(0.1)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1421
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05709643289446831, mae:0.18245191872119904, mape:0.14511144161224365, mspe:0.03995814174413681 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2554
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5460154
	speed: 0.0137s/iter; left time: 174.5872s
Epoch: 1 cost time: 1.7061102390289307
Epoch: 1, Steps: 128 Train Loss: 0.5509 (Forecasting Loss:0.2446 + XiCon Loss:3.0625 x Lambda(0.1)), Vali MSE Loss: 0.1816 Test MSE Loss: 0.1257
Validation loss decreased (inf --> 0.181617).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5675060
	speed: 0.0134s/iter; left time: 168.9583s
Epoch: 2 cost time: 1.6789772510528564
Epoch: 2, Steps: 128 Train Loss: 0.5438 (Forecasting Loss:0.2469 + XiCon Loss:2.9685 x Lambda(0.1)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1288
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5163328
	speed: 0.0139s/iter; left time: 173.1284s
Epoch: 3 cost time: 1.745924472808838
Epoch: 3, Steps: 128 Train Loss: 0.5197 (Forecasting Loss:0.2234 + XiCon Loss:2.9632 x Lambda(0.1)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1263
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5152583
	speed: 0.0134s/iter; left time: 164.7969s
Epoch: 4 cost time: 1.6870505809783936
Epoch: 4, Steps: 128 Train Loss: 0.5034 (Forecasting Loss:0.2113 + XiCon Loss:2.9209 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1159
Validation loss decreased (0.181617 --> 0.171187).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4873597
	speed: 0.0143s/iter; left time: 174.5149s
Epoch: 5 cost time: 1.7667548656463623
Epoch: 5, Steps: 128 Train Loss: 0.4943 (Forecasting Loss:0.2049 + XiCon Loss:2.8946 x Lambda(0.1)), Vali MSE Loss: 0.1745 Test MSE Loss: 0.1225
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.4984392
	speed: 0.0136s/iter; left time: 164.4605s
Epoch: 6 cost time: 1.700894832611084
Epoch: 6, Steps: 128 Train Loss: 0.4908 (Forecasting Loss:0.2016 + XiCon Loss:2.8925 x Lambda(0.1)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1197
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5134913
	speed: 0.0139s/iter; left time: 166.4129s
Epoch: 7 cost time: 1.7369384765625
Epoch: 7, Steps: 128 Train Loss: 0.4877 (Forecasting Loss:0.1998 + XiCon Loss:2.8781 x Lambda(0.1)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1210
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5112190
	speed: 0.0136s/iter; left time: 160.6072s
Epoch: 8 cost time: 1.692603349685669
Epoch: 8, Steps: 128 Train Loss: 0.4872 (Forecasting Loss:0.1988 + XiCon Loss:2.8840 x Lambda(0.1)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1217
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4823779
	speed: 0.0142s/iter; left time: 166.3117s
Epoch: 9 cost time: 1.7664945125579834
Epoch: 9, Steps: 128 Train Loss: 0.4862 (Forecasting Loss:0.1982 + XiCon Loss:2.8807 x Lambda(0.1)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1217
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5028344
	speed: 0.0136s/iter; left time: 156.6833s
Epoch: 10 cost time: 1.6944541931152344
Epoch: 10, Steps: 128 Train Loss: 0.4861 (Forecasting Loss:0.1978 + XiCon Loss:2.8827 x Lambda(0.1)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1217
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4763837
	speed: 0.0137s/iter; left time: 156.6205s
Epoch: 11 cost time: 1.6996805667877197
Epoch: 11, Steps: 128 Train Loss: 0.4859 (Forecasting Loss:0.1978 + XiCon Loss:2.8808 x Lambda(0.1)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1216
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4630469
	speed: 0.0133s/iter; left time: 150.4871s
Epoch: 12 cost time: 1.6665472984313965
Epoch: 12, Steps: 128 Train Loss: 0.4853 (Forecasting Loss:0.1977 + XiCon Loss:2.8767 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1216
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4905322
	speed: 0.0137s/iter; left time: 153.4642s
Epoch: 13 cost time: 1.7051613330841064
Epoch: 13, Steps: 128 Train Loss: 0.4866 (Forecasting Loss:0.1979 + XiCon Loss:2.8872 x Lambda(0.1)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1216
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4927842
	speed: 0.0138s/iter; left time: 151.9406s
Epoch: 14 cost time: 1.7407755851745605
Epoch: 14, Steps: 128 Train Loss: 0.4861 (Forecasting Loss:0.1979 + XiCon Loss:2.8826 x Lambda(0.1)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1216
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054571352899074554, mae:0.17717522382736206, mape:0.14030033349990845, mspe:0.03746423497796059 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3536
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5475746
	speed: 0.0139s/iter; left time: 176.4914s
Epoch: 1 cost time: 1.7272846698760986
Epoch: 1, Steps: 128 Train Loss: 0.5495 (Forecasting Loss:0.2448 + XiCon Loss:3.0465 x Lambda(0.1)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1232
Validation loss decreased (inf --> 0.173926).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5085555
	speed: 0.0147s/iter; left time: 185.1864s
Epoch: 2 cost time: 1.848649501800537
Epoch: 2, Steps: 128 Train Loss: 0.5359 (Forecasting Loss:0.2456 + XiCon Loss:2.9029 x Lambda(0.1)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5359511
	speed: 0.0137s/iter; left time: 170.1066s
Epoch: 3 cost time: 1.7011182308197021
Epoch: 3, Steps: 128 Train Loss: 0.5174 (Forecasting Loss:0.2322 + XiCon Loss:2.8516 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1209
Validation loss decreased (0.173926 --> 0.169872).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5176007
	speed: 0.0140s/iter; left time: 172.2095s
Epoch: 4 cost time: 1.733293056488037
Epoch: 4, Steps: 128 Train Loss: 0.5212 (Forecasting Loss:0.2223 + XiCon Loss:2.9896 x Lambda(0.1)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1201
Validation loss decreased (0.169872 --> 0.166973).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.4935114
	speed: 0.0136s/iter; left time: 166.0818s
Epoch: 5 cost time: 1.7565369606018066
Epoch: 5, Steps: 128 Train Loss: 0.5124 (Forecasting Loss:0.2178 + XiCon Loss:2.9460 x Lambda(0.1)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1153
Validation loss decreased (0.166973 --> 0.165047).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5206016
	speed: 0.0136s/iter; left time: 163.8730s
Epoch: 6 cost time: 1.7273807525634766
Epoch: 6, Steps: 128 Train Loss: 0.5092 (Forecasting Loss:0.2154 + XiCon Loss:2.9377 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1170
Validation loss decreased (0.165047 --> 0.163940).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4824561
	speed: 0.0140s/iter; left time: 167.4598s
Epoch: 7 cost time: 1.7243857383728027
Epoch: 7, Steps: 128 Train Loss: 0.5071 (Forecasting Loss:0.2142 + XiCon Loss:2.9287 x Lambda(0.1)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
Validation loss decreased (0.163940 --> 0.163394).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5372851
	speed: 0.0139s/iter; left time: 164.0889s
Epoch: 8 cost time: 1.7712311744689941
Epoch: 8, Steps: 128 Train Loss: 0.5065 (Forecasting Loss:0.2135 + XiCon Loss:2.9295 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1163
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5134098
	speed: 0.0132s/iter; left time: 154.3286s
Epoch: 9 cost time: 1.6606130599975586
Epoch: 9, Steps: 128 Train Loss: 0.5059 (Forecasting Loss:0.2134 + XiCon Loss:2.9247 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1162
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5139023
	speed: 0.0137s/iter; left time: 158.0410s
Epoch: 10 cost time: 1.7061026096343994
Epoch: 10, Steps: 128 Train Loss: 0.5056 (Forecasting Loss:0.2132 + XiCon Loss:2.9236 x Lambda(0.1)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1162
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5098212
	speed: 0.0141s/iter; left time: 160.8127s
Epoch: 11 cost time: 1.7729673385620117
Epoch: 11, Steps: 128 Train Loss: 0.5057 (Forecasting Loss:0.2130 + XiCon Loss:2.9278 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5047935
	speed: 0.0133s/iter; left time: 149.9463s
Epoch: 12 cost time: 1.6566190719604492
Epoch: 12, Steps: 128 Train Loss: 0.5051 (Forecasting Loss:0.2131 + XiCon Loss:2.9199 x Lambda(0.1)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5445603
	speed: 0.0138s/iter; left time: 154.4690s
Epoch: 13 cost time: 1.7827303409576416
Epoch: 13, Steps: 128 Train Loss: 0.5052 (Forecasting Loss:0.2130 + XiCon Loss:2.9214 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1161
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5040681
	speed: 0.0131s/iter; left time: 144.3835s
Epoch: 14 cost time: 1.6483421325683594
Epoch: 14, Steps: 128 Train Loss: 0.5052 (Forecasting Loss:0.2130 + XiCon Loss:2.9216 x Lambda(0.1)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1162
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5223603
	speed: 0.0140s/iter; left time: 153.1732s
Epoch: 15 cost time: 1.798410415649414
Epoch: 15, Steps: 128 Train Loss: 0.5051 (Forecasting Loss:0.2129 + XiCon Loss:2.9215 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1162
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5047682
	speed: 0.0135s/iter; left time: 145.7213s
Epoch: 16 cost time: 1.6797382831573486
Epoch: 16, Steps: 128 Train Loss: 0.5048 (Forecasting Loss:0.2129 + XiCon Loss:2.9192 x Lambda(0.1)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1162
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4877329
	speed: 0.0144s/iter; left time: 152.8905s
Epoch: 17 cost time: 1.80832839012146
Epoch: 17, Steps: 128 Train Loss: 0.5051 (Forecasting Loss:0.2130 + XiCon Loss:2.9209 x Lambda(0.1)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1162
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054456666111946106, mae:0.17748519778251648, mape:0.1411035805940628, mspe:0.03749606013298035 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3292
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5385147
	speed: 0.0139s/iter; left time: 177.1533s
Epoch: 1 cost time: 1.735588788986206
Epoch: 1, Steps: 128 Train Loss: 0.5494 (Forecasting Loss:0.2428 + XiCon Loss:3.0667 x Lambda(0.1)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1211
Validation loss decreased (inf --> 0.171604).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5848988
	speed: 0.0143s/iter; left time: 180.0464s
Epoch: 2 cost time: 1.8389594554901123
Epoch: 2, Steps: 128 Train Loss: 0.5402 (Forecasting Loss:0.2457 + XiCon Loss:2.9455 x Lambda(0.1)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1273
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5530472
	speed: 0.0145s/iter; left time: 180.0373s
Epoch: 3 cost time: 1.770207405090332
Epoch: 3, Steps: 128 Train Loss: 0.5268 (Forecasting Loss:0.2304 + XiCon Loss:2.9642 x Lambda(0.1)), Vali MSE Loss: 0.1682 Test MSE Loss: 0.1181
Validation loss decreased (0.171604 --> 0.168213).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5235611
	speed: 0.0139s/iter; left time: 171.5126s
Epoch: 4 cost time: 1.7412166595458984
Epoch: 4, Steps: 128 Train Loss: 0.5132 (Forecasting Loss:0.2212 + XiCon Loss:2.9202 x Lambda(0.1)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1184
Validation loss decreased (0.168213 --> 0.165236).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5034945
	speed: 0.0133s/iter; left time: 162.4123s
Epoch: 5 cost time: 1.6883151531219482
Epoch: 5, Steps: 128 Train Loss: 0.5057 (Forecasting Loss:0.2176 + XiCon Loss:2.8815 x Lambda(0.1)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5167254
	speed: 0.0137s/iter; left time: 165.2753s
Epoch: 6 cost time: 1.7074799537658691
Epoch: 6, Steps: 128 Train Loss: 0.5021 (Forecasting Loss:0.2146 + XiCon Loss:2.8753 x Lambda(0.1)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.4780850
	speed: 0.0144s/iter; left time: 172.3408s
Epoch: 7 cost time: 1.7994792461395264
Epoch: 7, Steps: 128 Train Loss: 0.5000 (Forecasting Loss:0.2130 + XiCon Loss:2.8697 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1151
Validation loss decreased (0.165236 --> 0.162887).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4871752
	speed: 0.0138s/iter; left time: 163.3065s
Epoch: 8 cost time: 1.726233959197998
Epoch: 8, Steps: 128 Train Loss: 0.4988 (Forecasting Loss:0.2123 + XiCon Loss:2.8644 x Lambda(0.1)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5301824
	speed: 0.0136s/iter; left time: 158.7770s
Epoch: 9 cost time: 1.7439908981323242
Epoch: 9, Steps: 128 Train Loss: 0.4982 (Forecasting Loss:0.2118 + XiCon Loss:2.8638 x Lambda(0.1)), Vali MSE Loss: 0.1626 Test MSE Loss: 0.1153
Validation loss decreased (0.162887 --> 0.162639).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4850973
	speed: 0.0139s/iter; left time: 160.9242s
Epoch: 10 cost time: 1.730351448059082
Epoch: 10, Steps: 128 Train Loss: 0.4978 (Forecasting Loss:0.2117 + XiCon Loss:2.8604 x Lambda(0.1)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.1150
Validation loss decreased (0.162639 --> 0.162391).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5012387
	speed: 0.0137s/iter; left time: 156.5294s
Epoch: 11 cost time: 1.7478361129760742
Epoch: 11, Steps: 128 Train Loss: 0.4975 (Forecasting Loss:0.2114 + XiCon Loss:2.8610 x Lambda(0.1)), Vali MSE Loss: 0.1627 Test MSE Loss: 0.1150
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5053982
	speed: 0.0134s/iter; left time: 151.5774s
Epoch: 12 cost time: 1.7312307357788086
Epoch: 12, Steps: 128 Train Loss: 0.4984 (Forecasting Loss:0.2115 + XiCon Loss:2.8686 x Lambda(0.1)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1150
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5167965
	speed: 0.0136s/iter; left time: 151.6536s
Epoch: 13 cost time: 1.7293949127197266
Epoch: 13, Steps: 128 Train Loss: 0.4977 (Forecasting Loss:0.2115 + XiCon Loss:2.8626 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1150
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4946574
	speed: 0.0137s/iter; left time: 150.9579s
Epoch: 14 cost time: 1.7092230319976807
Epoch: 14, Steps: 128 Train Loss: 0.4983 (Forecasting Loss:0.2114 + XiCon Loss:2.8692 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1150
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5173209
	speed: 0.0134s/iter; left time: 146.6901s
Epoch: 15 cost time: 1.6795635223388672
Epoch: 15, Steps: 128 Train Loss: 0.4978 (Forecasting Loss:0.2113 + XiCon Loss:2.8643 x Lambda(0.1)), Vali MSE Loss: 0.1625 Test MSE Loss: 0.1150
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5041107
	speed: 0.0143s/iter; left time: 154.7037s
Epoch: 16 cost time: 1.7675280570983887
Epoch: 16, Steps: 128 Train Loss: 0.4980 (Forecasting Loss:0.2113 + XiCon Loss:2.8674 x Lambda(0.1)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1150
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5020349
	speed: 0.0143s/iter; left time: 152.8389s
Epoch: 17 cost time: 1.7747690677642822
Epoch: 17, Steps: 128 Train Loss: 0.4981 (Forecasting Loss:0.2114 + XiCon Loss:2.8667 x Lambda(0.1)), Vali MSE Loss: 0.1627 Test MSE Loss: 0.1150
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.4872642
	speed: 0.0137s/iter; left time: 143.8757s
Epoch: 18 cost time: 1.706054925918579
Epoch: 18, Steps: 128 Train Loss: 0.4975 (Forecasting Loss:0.2115 + XiCon Loss:2.8603 x Lambda(0.1)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1150
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.4712730
	speed: 0.0134s/iter; left time: 139.7333s
Epoch: 19 cost time: 1.6853086948394775
Epoch: 19, Steps: 128 Train Loss: 0.4983 (Forecasting Loss:0.2115 + XiCon Loss:2.8687 x Lambda(0.1)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1150
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5261891
	speed: 0.0144s/iter; left time: 147.9530s
Epoch: 20 cost time: 1.8092842102050781
Epoch: 20, Steps: 128 Train Loss: 0.4971 (Forecasting Loss:0.2114 + XiCon Loss:2.8569 x Lambda(0.1)), Vali MSE Loss: 0.1627 Test MSE Loss: 0.1150
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.053983986377716064, mae:0.17598408460617065, mape:0.13997173309326172, mspe:0.0372345894575119 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0553+-0.00164, MAE:0.1787+-0.00330, MAPE:0.1428+-0.00414, MSPE:0.0396+-0.00452, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3494
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5356848
	speed: 0.0177s/iter; left time: 221.5207s
Epoch: 1 cost time: 2.125020742416382
Epoch: 1, Steps: 126 Train Loss: 0.5825 (Forecasting Loss:0.2768 + XiCon Loss:3.0564 x Lambda(0.1)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1431
Validation loss decreased (inf --> 0.196719).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5351681
	speed: 0.0148s/iter; left time: 183.5493s
Epoch: 2 cost time: 1.853114128112793
Epoch: 2, Steps: 126 Train Loss: 0.5366 (Forecasting Loss:0.2530 + XiCon Loss:2.8362 x Lambda(0.1)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1414
Validation loss decreased (0.196719 --> 0.193646).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5160432
	speed: 0.0161s/iter; left time: 197.1863s
Epoch: 3 cost time: 2.0081660747528076
Epoch: 3, Steps: 126 Train Loss: 0.5072 (Forecasting Loss:0.2204 + XiCon Loss:2.8681 x Lambda(0.1)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1472
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4906747
	speed: 0.0168s/iter; left time: 203.9280s
Epoch: 4 cost time: 2.074082612991333
Epoch: 4, Steps: 126 Train Loss: 0.4975 (Forecasting Loss:0.2071 + XiCon Loss:2.9035 x Lambda(0.1)), Vali MSE Loss: 0.1873 Test MSE Loss: 0.1480
Validation loss decreased (0.193646 --> 0.187280).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4683989
	speed: 0.0164s/iter; left time: 196.1939s
Epoch: 5 cost time: 2.0230631828308105
Epoch: 5, Steps: 126 Train Loss: 0.4901 (Forecasting Loss:0.2018 + XiCon Loss:2.8836 x Lambda(0.1)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1473
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4580281
	speed: 0.0167s/iter; left time: 197.9808s
Epoch: 6 cost time: 2.063478469848633
Epoch: 6, Steps: 126 Train Loss: 0.4882 (Forecasting Loss:0.1992 + XiCon Loss:2.8901 x Lambda(0.1)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1475
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4839494
	speed: 0.0167s/iter; left time: 195.9955s
Epoch: 7 cost time: 2.0626368522644043
Epoch: 7, Steps: 126 Train Loss: 0.4877 (Forecasting Loss:0.1981 + XiCon Loss:2.8968 x Lambda(0.1)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1496
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5057523
	speed: 0.0162s/iter; left time: 188.6933s
Epoch: 8 cost time: 2.017580032348633
Epoch: 8, Steps: 126 Train Loss: 0.4836 (Forecasting Loss:0.1974 + XiCon Loss:2.8623 x Lambda(0.1)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1486
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4774275
	speed: 0.0163s/iter; left time: 187.2206s
Epoch: 9 cost time: 1.9991183280944824
Epoch: 9, Steps: 126 Train Loss: 0.4846 (Forecasting Loss:0.1970 + XiCon Loss:2.8760 x Lambda(0.1)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1479
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5082998
	speed: 0.0161s/iter; left time: 182.7754s
Epoch: 10 cost time: 1.9886999130249023
Epoch: 10, Steps: 126 Train Loss: 0.4846 (Forecasting Loss:0.1968 + XiCon Loss:2.8779 x Lambda(0.1)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.1488
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4803984
	speed: 0.0174s/iter; left time: 195.5352s
Epoch: 11 cost time: 2.147561550140381
Epoch: 11, Steps: 126 Train Loss: 0.4841 (Forecasting Loss:0.1964 + XiCon Loss:2.8775 x Lambda(0.1)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1489
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4900317
	speed: 0.0165s/iter; left time: 183.4205s
Epoch: 12 cost time: 2.028531551361084
Epoch: 12, Steps: 126 Train Loss: 0.4831 (Forecasting Loss:0.1965 + XiCon Loss:2.8667 x Lambda(0.1)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1488
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5028231
	speed: 0.0169s/iter; left time: 186.2506s
Epoch: 13 cost time: 2.115004777908325
Epoch: 13, Steps: 126 Train Loss: 0.4835 (Forecasting Loss:0.1965 + XiCon Loss:2.8693 x Lambda(0.1)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1487
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4829557
	speed: 0.0166s/iter; left time: 179.8625s
Epoch: 14 cost time: 2.03633975982666
Epoch: 14, Steps: 126 Train Loss: 0.4841 (Forecasting Loss:0.1962 + XiCon Loss:2.8786 x Lambda(0.1)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1488
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07770862430334091, mae:0.21834495663642883, mape:0.17510516941547394, mspe:0.06342056393623352 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3134
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5431461
	speed: 0.0154s/iter; left time: 192.0714s
Epoch: 1 cost time: 1.8921618461608887
Epoch: 1, Steps: 126 Train Loss: 0.5808 (Forecasting Loss:0.2754 + XiCon Loss:3.0541 x Lambda(0.1)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1449
Validation loss decreased (inf --> 0.195872).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5301446
	speed: 0.0158s/iter; left time: 195.6992s
Epoch: 2 cost time: 2.018496513366699
Epoch: 2, Steps: 126 Train Loss: 0.5443 (Forecasting Loss:0.2519 + XiCon Loss:2.9235 x Lambda(0.1)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1395
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5183505
	speed: 0.0159s/iter; left time: 194.3177s
Epoch: 3 cost time: 1.9558191299438477
Epoch: 3, Steps: 126 Train Loss: 0.5222 (Forecasting Loss:0.2166 + XiCon Loss:3.0555 x Lambda(0.1)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1398
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5286354
	speed: 0.0157s/iter; left time: 189.9708s
Epoch: 4 cost time: 1.9394006729125977
Epoch: 4, Steps: 126 Train Loss: 0.5138 (Forecasting Loss:0.2043 + XiCon Loss:3.0954 x Lambda(0.1)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1368
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4900069
	speed: 0.0154s/iter; left time: 184.5158s
Epoch: 5 cost time: 1.9140028953552246
Epoch: 5, Steps: 126 Train Loss: 0.5075 (Forecasting Loss:0.1990 + XiCon Loss:3.0855 x Lambda(0.1)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1403
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5009421
	speed: 0.0155s/iter; left time: 183.5478s
Epoch: 6 cost time: 1.9158291816711426
Epoch: 6, Steps: 126 Train Loss: 0.5052 (Forecasting Loss:0.1963 + XiCon Loss:3.0884 x Lambda(0.1)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.1370
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4869625
	speed: 0.0153s/iter; left time: 180.0200s
Epoch: 7 cost time: 1.9143049716949463
Epoch: 7, Steps: 126 Train Loss: 0.5029 (Forecasting Loss:0.1948 + XiCon Loss:3.0808 x Lambda(0.1)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.1385
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5205685
	speed: 0.0157s/iter; left time: 182.0684s
Epoch: 8 cost time: 1.9837641716003418
Epoch: 8, Steps: 126 Train Loss: 0.5026 (Forecasting Loss:0.1944 + XiCon Loss:3.0829 x Lambda(0.1)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1390
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4975904
	speed: 0.0164s/iter; left time: 187.9287s
Epoch: 9 cost time: 2.009716272354126
Epoch: 9, Steps: 126 Train Loss: 0.5017 (Forecasting Loss:0.1939 + XiCon Loss:3.0788 x Lambda(0.1)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.1389
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4819229
	speed: 0.0155s/iter; left time: 176.3223s
Epoch: 10 cost time: 1.9302635192871094
Epoch: 10, Steps: 126 Train Loss: 0.5020 (Forecasting Loss:0.1938 + XiCon Loss:3.0818 x Lambda(0.1)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1390
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5154754
	speed: 0.0156s/iter; left time: 175.1959s
Epoch: 11 cost time: 1.9855539798736572
Epoch: 11, Steps: 126 Train Loss: 0.5017 (Forecasting Loss:0.1933 + XiCon Loss:3.0842 x Lambda(0.1)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1391
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07567089051008224, mae:0.21415303647518158, mape:0.16373233497142792, mspe:0.0457582101225853 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3224
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5693800
	speed: 0.0149s/iter; left time: 185.8476s
Epoch: 1 cost time: 1.8218238353729248
Epoch: 1, Steps: 126 Train Loss: 0.5844 (Forecasting Loss:0.2783 + XiCon Loss:3.0606 x Lambda(0.1)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1445
Validation loss decreased (inf --> 0.198227).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5527962
	speed: 0.0162s/iter; left time: 200.8454s
Epoch: 2 cost time: 1.9667344093322754
Epoch: 2, Steps: 126 Train Loss: 0.5495 (Forecasting Loss:0.2542 + XiCon Loss:2.9528 x Lambda(0.1)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1347
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5199161
	speed: 0.0150s/iter; left time: 183.4578s
Epoch: 3 cost time: 1.8213961124420166
Epoch: 3, Steps: 126 Train Loss: 0.5360 (Forecasting Loss:0.2264 + XiCon Loss:3.0968 x Lambda(0.1)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.1335
Validation loss decreased (0.198227 --> 0.182646).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5454543
	speed: 0.0153s/iter; left time: 185.4902s
Epoch: 4 cost time: 1.9243521690368652
Epoch: 4, Steps: 126 Train Loss: 0.5253 (Forecasting Loss:0.2160 + XiCon Loss:3.0929 x Lambda(0.1)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1324
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5089375
	speed: 0.0151s/iter; left time: 181.0553s
Epoch: 5 cost time: 1.847778081893921
Epoch: 5, Steps: 126 Train Loss: 0.5161 (Forecasting Loss:0.2105 + XiCon Loss:3.0563 x Lambda(0.1)), Vali MSE Loss: 0.1850 Test MSE Loss: 0.1333
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5300487
	speed: 0.0158s/iter; left time: 187.1630s
Epoch: 6 cost time: 1.9863722324371338
Epoch: 6, Steps: 126 Train Loss: 0.5097 (Forecasting Loss:0.2055 + XiCon Loss:3.0419 x Lambda(0.1)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4926432
	speed: 0.0154s/iter; left time: 181.1769s
Epoch: 7 cost time: 1.875560998916626
Epoch: 7, Steps: 126 Train Loss: 0.5062 (Forecasting Loss:0.2030 + XiCon Loss:3.0324 x Lambda(0.1)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1377
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4982617
	speed: 0.0145s/iter; left time: 168.7130s
Epoch: 8 cost time: 1.787846326828003
Epoch: 8, Steps: 126 Train Loss: 0.5042 (Forecasting Loss:0.2023 + XiCon Loss:3.0187 x Lambda(0.1)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1387
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4850596
	speed: 0.0146s/iter; left time: 167.8003s
Epoch: 9 cost time: 1.8072779178619385
Epoch: 9, Steps: 126 Train Loss: 0.5036 (Forecasting Loss:0.2016 + XiCon Loss:3.0199 x Lambda(0.1)), Vali MSE Loss: 0.1868 Test MSE Loss: 0.1385
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4839510
	speed: 0.0147s/iter; left time: 167.5949s
Epoch: 10 cost time: 1.826411247253418
Epoch: 10, Steps: 126 Train Loss: 0.5041 (Forecasting Loss:0.2012 + XiCon Loss:3.0291 x Lambda(0.1)), Vali MSE Loss: 0.1868 Test MSE Loss: 0.1387
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4862399
	speed: 0.0148s/iter; left time: 166.4535s
Epoch: 11 cost time: 1.8285675048828125
Epoch: 11, Steps: 126 Train Loss: 0.5021 (Forecasting Loss:0.2010 + XiCon Loss:3.0114 x Lambda(0.1)), Vali MSE Loss: 0.1867 Test MSE Loss: 0.1385
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4837244
	speed: 0.0151s/iter; left time: 167.4505s
Epoch: 12 cost time: 1.8540441989898682
Epoch: 12, Steps: 126 Train Loss: 0.5019 (Forecasting Loss:0.2008 + XiCon Loss:3.0104 x Lambda(0.1)), Vali MSE Loss: 0.1871 Test MSE Loss: 0.1384
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5169824
	speed: 0.0151s/iter; left time: 165.9776s
Epoch: 13 cost time: 1.8619601726531982
Epoch: 13, Steps: 126 Train Loss: 0.5026 (Forecasting Loss:0.2012 + XiCon Loss:3.0134 x Lambda(0.1)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1385
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06653480976819992, mae:0.20054401457309723, mape:0.15644682943820953, mspe:0.04482845216989517 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3133
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5564427
	speed: 0.0152s/iter; left time: 189.8932s
Epoch: 1 cost time: 1.8700871467590332
Epoch: 1, Steps: 126 Train Loss: 0.5777 (Forecasting Loss:0.2749 + XiCon Loss:3.0279 x Lambda(0.1)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1440
Validation loss decreased (inf --> 0.196723).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5360495
	speed: 0.0155s/iter; left time: 191.8748s
Epoch: 2 cost time: 1.917348861694336
Epoch: 2, Steps: 126 Train Loss: 0.5448 (Forecasting Loss:0.2579 + XiCon Loss:2.8690 x Lambda(0.1)), Vali MSE Loss: 0.1896 Test MSE Loss: 0.1475
Validation loss decreased (0.196723 --> 0.189566).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5120238
	speed: 0.0156s/iter; left time: 191.6573s
Epoch: 3 cost time: 1.9298458099365234
Epoch: 3, Steps: 126 Train Loss: 0.5240 (Forecasting Loss:0.2266 + XiCon Loss:2.9740 x Lambda(0.1)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1604
Validation loss decreased (0.189566 --> 0.187022).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4874690
	speed: 0.0163s/iter; left time: 197.2736s
Epoch: 4 cost time: 2.0101983547210693
Epoch: 4, Steps: 126 Train Loss: 0.5146 (Forecasting Loss:0.2113 + XiCon Loss:3.0327 x Lambda(0.1)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1543
Validation loss decreased (0.187022 --> 0.185382).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4991023
	speed: 0.0155s/iter; left time: 186.2166s
Epoch: 5 cost time: 1.9315576553344727
Epoch: 5, Steps: 126 Train Loss: 0.5064 (Forecasting Loss:0.2044 + XiCon Loss:3.0205 x Lambda(0.1)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4763112
	speed: 0.0164s/iter; left time: 194.2299s
Epoch: 6 cost time: 2.022205114364624
Epoch: 6, Steps: 126 Train Loss: 0.5020 (Forecasting Loss:0.2015 + XiCon Loss:3.0052 x Lambda(0.1)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5145459
	speed: 0.0163s/iter; left time: 191.1589s
Epoch: 7 cost time: 2.002537250518799
Epoch: 7, Steps: 126 Train Loss: 0.5013 (Forecasting Loss:0.1996 + XiCon Loss:3.0166 x Lambda(0.1)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.1564
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5053658
	speed: 0.0169s/iter; left time: 195.9313s
Epoch: 8 cost time: 2.0776894092559814
Epoch: 8, Steps: 126 Train Loss: 0.4996 (Forecasting Loss:0.1989 + XiCon Loss:3.0063 x Lambda(0.1)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1574
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4753712
	speed: 0.0159s/iter; left time: 183.2924s
Epoch: 9 cost time: 1.980144739151001
Epoch: 9, Steps: 126 Train Loss: 0.4984 (Forecasting Loss:0.1986 + XiCon Loss:2.9985 x Lambda(0.1)), Vali MSE Loss: 0.1873 Test MSE Loss: 0.1566
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5025783
	speed: 0.0157s/iter; left time: 177.8985s
Epoch: 10 cost time: 1.9653887748718262
Epoch: 10, Steps: 126 Train Loss: 0.4988 (Forecasting Loss:0.1985 + XiCon Loss:3.0033 x Lambda(0.1)), Vali MSE Loss: 0.1872 Test MSE Loss: 0.1567
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4975700
	speed: 0.0159s/iter; left time: 178.4934s
Epoch: 11 cost time: 1.9653289318084717
Epoch: 11, Steps: 126 Train Loss: 0.4996 (Forecasting Loss:0.1982 + XiCon Loss:3.0141 x Lambda(0.1)), Vali MSE Loss: 0.1873 Test MSE Loss: 0.1566
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5198947
	speed: 0.0155s/iter; left time: 171.7838s
Epoch: 12 cost time: 1.9186031818389893
Epoch: 12, Steps: 126 Train Loss: 0.4984 (Forecasting Loss:0.1984 + XiCon Loss:2.9999 x Lambda(0.1)), Vali MSE Loss: 0.1871 Test MSE Loss: 0.1570
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5002815
	speed: 0.0168s/iter; left time: 184.2243s
Epoch: 13 cost time: 2.0598249435424805
Epoch: 13, Steps: 126 Train Loss: 0.4974 (Forecasting Loss:0.1979 + XiCon Loss:2.9942 x Lambda(0.1)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1571
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5153744
	speed: 0.0164s/iter; left time: 178.3431s
Epoch: 14 cost time: 2.0560569763183594
Epoch: 14, Steps: 126 Train Loss: 0.4981 (Forecasting Loss:0.1975 + XiCon Loss:3.0068 x Lambda(0.1)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1571
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.08316977322101593, mae:0.22552545368671417, mape:0.1786186695098877, mspe:0.06219102442264557 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4769
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5478754
	speed: 0.0145s/iter; left time: 181.8847s
Epoch: 1 cost time: 1.7920000553131104
Epoch: 1, Steps: 126 Train Loss: 0.5807 (Forecasting Loss:0.2749 + XiCon Loss:3.0583 x Lambda(0.1)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1447
Validation loss decreased (inf --> 0.197176).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5459634
	speed: 0.0160s/iter; left time: 198.0423s
Epoch: 2 cost time: 2.03936767578125
Epoch: 2, Steps: 126 Train Loss: 0.5534 (Forecasting Loss:0.2617 + XiCon Loss:2.9173 x Lambda(0.1)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1507
Validation loss decreased (0.197176 --> 0.192768).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5034748
	speed: 0.0163s/iter; left time: 199.9206s
Epoch: 3 cost time: 2.058986186981201
Epoch: 3, Steps: 126 Train Loss: 0.5356 (Forecasting Loss:0.2513 + XiCon Loss:2.8426 x Lambda(0.1)), Vali MSE Loss: 0.1887 Test MSE Loss: 0.1472
Validation loss decreased (0.192768 --> 0.188680).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5249055
	speed: 0.0175s/iter; left time: 211.6268s
Epoch: 4 cost time: 2.1520416736602783
Epoch: 4, Steps: 126 Train Loss: 0.5268 (Forecasting Loss:0.2446 + XiCon Loss:2.8220 x Lambda(0.1)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1345
Validation loss decreased (0.188680 --> 0.186201).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5146278
	speed: 0.0169s/iter; left time: 202.4383s
Epoch: 5 cost time: 2.0791940689086914
Epoch: 5, Steps: 126 Train Loss: 0.5185 (Forecasting Loss:0.2401 + XiCon Loss:2.7834 x Lambda(0.1)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1374
Validation loss decreased (0.186201 --> 0.184534).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5210406
	speed: 0.0163s/iter; left time: 193.3538s
Epoch: 6 cost time: 1.9992454051971436
Epoch: 6, Steps: 126 Train Loss: 0.5147 (Forecasting Loss:0.2378 + XiCon Loss:2.7692 x Lambda(0.1)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1361
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5122026
	speed: 0.0166s/iter; left time: 194.6941s
Epoch: 7 cost time: 2.0349583625793457
Epoch: 7, Steps: 126 Train Loss: 0.5149 (Forecasting Loss:0.2365 + XiCon Loss:2.7838 x Lambda(0.1)), Vali MSE Loss: 0.1829 Test MSE Loss: 0.1362
Validation loss decreased (0.184534 --> 0.182929).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5291407
	speed: 0.0173s/iter; left time: 200.5920s
Epoch: 8 cost time: 2.140519857406616
Epoch: 8, Steps: 126 Train Loss: 0.5167 (Forecasting Loss:0.2350 + XiCon Loss:2.8166 x Lambda(0.1)), Vali MSE Loss: 0.1828 Test MSE Loss: 0.1359
Validation loss decreased (0.182929 --> 0.182782).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5128393
	speed: 0.0172s/iter; left time: 197.8594s
Epoch: 9 cost time: 2.1094515323638916
Epoch: 9, Steps: 126 Train Loss: 0.5170 (Forecasting Loss:0.2333 + XiCon Loss:2.8372 x Lambda(0.1)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.1361
Validation loss decreased (0.182782 --> 0.182595).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5151014
	speed: 0.0164s/iter; left time: 186.1554s
Epoch: 10 cost time: 2.020477294921875
Epoch: 10, Steps: 126 Train Loss: 0.5175 (Forecasting Loss:0.2328 + XiCon Loss:2.8461 x Lambda(0.1)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.1362
Validation loss decreased (0.182595 --> 0.182585).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5062476
	speed: 0.0165s/iter; left time: 185.6673s
Epoch: 11 cost time: 2.0398001670837402
Epoch: 11, Steps: 126 Train Loss: 0.5181 (Forecasting Loss:0.2325 + XiCon Loss:2.8567 x Lambda(0.1)), Vali MSE Loss: 0.1821 Test MSE Loss: 0.1361
Validation loss decreased (0.182585 --> 0.182067).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5233504
	speed: 0.0164s/iter; left time: 182.6147s
Epoch: 12 cost time: 2.0440173149108887
Epoch: 12, Steps: 126 Train Loss: 0.5185 (Forecasting Loss:0.2324 + XiCon Loss:2.8612 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5128244
	speed: 0.0162s/iter; left time: 178.2822s
Epoch: 13 cost time: 2.02207088470459
Epoch: 13, Steps: 126 Train Loss: 0.5170 (Forecasting Loss:0.2324 + XiCon Loss:2.8457 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5110344
	speed: 0.0168s/iter; left time: 182.4045s
Epoch: 14 cost time: 2.06390380859375
Epoch: 14, Steps: 126 Train Loss: 0.5186 (Forecasting Loss:0.2324 + XiCon Loss:2.8613 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5428493
	speed: 0.0170s/iter; left time: 182.8027s
Epoch: 15 cost time: 2.1127514839172363
Epoch: 15, Steps: 126 Train Loss: 0.5182 (Forecasting Loss:0.2325 + XiCon Loss:2.8562 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5047376
	speed: 0.0161s/iter; left time: 170.5248s
Epoch: 16 cost time: 2.0107362270355225
Epoch: 16, Steps: 126 Train Loss: 0.5180 (Forecasting Loss:0.2324 + XiCon Loss:2.8566 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1362
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5092219
	speed: 0.0164s/iter; left time: 172.3692s
Epoch: 17 cost time: 2.0276176929473877
Epoch: 17, Steps: 126 Train Loss: 0.5185 (Forecasting Loss:0.2323 + XiCon Loss:2.8620 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1362
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5136802
	speed: 0.0172s/iter; left time: 178.4279s
Epoch: 18 cost time: 2.1187965869903564
Epoch: 18, Steps: 126 Train Loss: 0.5186 (Forecasting Loss:0.2325 + XiCon Loss:2.8609 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1362
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5155060
	speed: 0.0169s/iter; left time: 172.9191s
Epoch: 19 cost time: 2.1105105876922607
Epoch: 19, Steps: 126 Train Loss: 0.5184 (Forecasting Loss:0.2324 + XiCon Loss:2.8605 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1362
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5338833
	speed: 0.0170s/iter; left time: 171.8689s
Epoch: 20 cost time: 2.108774185180664
Epoch: 20, Steps: 126 Train Loss: 0.5185 (Forecasting Loss:0.2326 + XiCon Loss:2.8594 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5026144
	speed: 0.0170s/iter; left time: 169.7810s
Epoch: 21 cost time: 2.0952067375183105
Epoch: 21, Steps: 126 Train Loss: 0.5182 (Forecasting Loss:0.2322 + XiCon Loss:2.8595 x Lambda(0.1)), Vali MSE Loss: 0.1822 Test MSE Loss: 0.1362
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.0693640261888504, mae:0.2027984857559204, mape:0.15587423741817474, mspe:0.042775265872478485 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0745+-0.00825, MAE:0.2123+-0.01307, MAPE:0.1660+-0.01304, MSPE:0.0518+-0.01256, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3572
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5848756
	speed: 0.0228s/iter; left time: 280.0615s
Epoch: 1 cost time: 2.7092435359954834
Epoch: 1, Steps: 124 Train Loss: 0.5978 (Forecasting Loss:0.2924 + XiCon Loss:3.0537 x Lambda(0.1)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1593
Validation loss decreased (inf --> 0.216269).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5529956
	speed: 0.0204s/iter; left time: 247.9645s
Epoch: 2 cost time: 2.5019383430480957
Epoch: 2, Steps: 124 Train Loss: 0.5656 (Forecasting Loss:0.2720 + XiCon Loss:2.9362 x Lambda(0.1)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1650
Validation loss decreased (0.216269 --> 0.195606).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5208049
	speed: 0.0200s/iter; left time: 241.4365s
Epoch: 3 cost time: 2.4548182487487793
Epoch: 3, Steps: 124 Train Loss: 0.5329 (Forecasting Loss:0.2464 + XiCon Loss:2.8648 x Lambda(0.1)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1632
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5377923
	speed: 0.0194s/iter; left time: 231.3831s
Epoch: 4 cost time: 2.3721518516540527
Epoch: 4, Steps: 124 Train Loss: 0.5260 (Forecasting Loss:0.2362 + XiCon Loss:2.8972 x Lambda(0.1)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1665
Validation loss decreased (0.195606 --> 0.194152).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5163797
	speed: 0.0195s/iter; left time: 229.7766s
Epoch: 5 cost time: 2.378722667694092
Epoch: 5, Steps: 124 Train Loss: 0.5221 (Forecasting Loss:0.2288 + XiCon Loss:2.9325 x Lambda(0.1)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1647
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5275941
	speed: 0.0196s/iter; left time: 228.4075s
Epoch: 6 cost time: 2.397932529449463
Epoch: 6, Steps: 124 Train Loss: 0.5195 (Forecasting Loss:0.2241 + XiCon Loss:2.9543 x Lambda(0.1)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1652
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4993048
	speed: 0.0193s/iter; left time: 223.3112s
Epoch: 7 cost time: 2.393845796585083
Epoch: 7, Steps: 124 Train Loss: 0.5174 (Forecasting Loss:0.2217 + XiCon Loss:2.9572 x Lambda(0.1)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1654
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5297081
	speed: 0.0197s/iter; left time: 225.4913s
Epoch: 8 cost time: 2.393134593963623
Epoch: 8, Steps: 124 Train Loss: 0.5160 (Forecasting Loss:0.2205 + XiCon Loss:2.9549 x Lambda(0.1)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1618
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5096924
	speed: 0.0206s/iter; left time: 232.5756s
Epoch: 9 cost time: 2.4882395267486572
Epoch: 9, Steps: 124 Train Loss: 0.5159 (Forecasting Loss:0.2200 + XiCon Loss:2.9586 x Lambda(0.1)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1631
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5112224
	speed: 0.0197s/iter; left time: 220.0484s
Epoch: 10 cost time: 2.3988850116729736
Epoch: 10, Steps: 124 Train Loss: 0.5160 (Forecasting Loss:0.2199 + XiCon Loss:2.9618 x Lambda(0.1)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1621
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5082864
	speed: 0.0193s/iter; left time: 213.7323s
Epoch: 11 cost time: 2.377037763595581
Epoch: 11, Steps: 124 Train Loss: 0.5156 (Forecasting Loss:0.2199 + XiCon Loss:2.9575 x Lambda(0.1)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1621
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5043428
	speed: 0.0190s/iter; left time: 208.2137s
Epoch: 12 cost time: 2.368448495864868
Epoch: 12, Steps: 124 Train Loss: 0.5148 (Forecasting Loss:0.2197 + XiCon Loss:2.9513 x Lambda(0.1)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1620
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4984481
	speed: 0.0203s/iter; left time: 219.7678s
Epoch: 13 cost time: 2.451779842376709
Epoch: 13, Steps: 124 Train Loss: 0.5159 (Forecasting Loss:0.2194 + XiCon Loss:2.9657 x Lambda(0.1)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1621
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5148515
	speed: 0.0198s/iter; left time: 211.1551s
Epoch: 14 cost time: 2.4197793006896973
Epoch: 14, Steps: 124 Train Loss: 0.5155 (Forecasting Loss:0.2194 + XiCon Loss:2.9613 x Lambda(0.1)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1621
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.09145363420248032, mae:0.24157090485095978, mape:0.193357914686203, mspe:0.07354774326086044 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2449
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5795478
	speed: 0.0195s/iter; left time: 239.5416s
Epoch: 1 cost time: 2.373112916946411
Epoch: 1, Steps: 124 Train Loss: 0.5999 (Forecasting Loss:0.2960 + XiCon Loss:3.0390 x Lambda(0.1)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1609
Validation loss decreased (inf --> 0.215791).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5940067
	speed: 0.0195s/iter; left time: 237.6014s
Epoch: 2 cost time: 2.4109222888946533
Epoch: 2, Steps: 124 Train Loss: 0.5687 (Forecasting Loss:0.2680 + XiCon Loss:3.0064 x Lambda(0.1)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.1559
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5329286
	speed: 0.0197s/iter; left time: 237.5355s
Epoch: 3 cost time: 2.415158748626709
Epoch: 3, Steps: 124 Train Loss: 0.5444 (Forecasting Loss:0.2403 + XiCon Loss:3.0418 x Lambda(0.1)), Vali MSE Loss: 0.2290 Test MSE Loss: 0.1580
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5251685
	speed: 0.0207s/iter; left time: 246.8387s
Epoch: 4 cost time: 2.536158323287964
Epoch: 4, Steps: 124 Train Loss: 0.5321 (Forecasting Loss:0.2278 + XiCon Loss:3.0434 x Lambda(0.1)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1600
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5091782
	speed: 0.0206s/iter; left time: 243.1115s
Epoch: 5 cost time: 2.518678903579712
Epoch: 5, Steps: 124 Train Loss: 0.5242 (Forecasting Loss:0.2214 + XiCon Loss:3.0275 x Lambda(0.1)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1551
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5188218
	speed: 0.0208s/iter; left time: 243.1316s
Epoch: 6 cost time: 2.514178991317749
Epoch: 6, Steps: 124 Train Loss: 0.5219 (Forecasting Loss:0.2185 + XiCon Loss:3.0340 x Lambda(0.1)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1502
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5277985
	speed: 0.0203s/iter; left time: 234.3740s
Epoch: 7 cost time: 2.5037248134613037
Epoch: 7, Steps: 124 Train Loss: 0.5210 (Forecasting Loss:0.2170 + XiCon Loss:3.0400 x Lambda(0.1)), Vali MSE Loss: 0.2297 Test MSE Loss: 0.1524
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5267074
	speed: 0.0203s/iter; left time: 232.4221s
Epoch: 8 cost time: 2.4807374477386475
Epoch: 8, Steps: 124 Train Loss: 0.5196 (Forecasting Loss:0.2167 + XiCon Loss:3.0284 x Lambda(0.1)), Vali MSE Loss: 0.2327 Test MSE Loss: 0.1521
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5264346
	speed: 0.0207s/iter; left time: 234.3243s
Epoch: 9 cost time: 2.5499460697174072
Epoch: 9, Steps: 124 Train Loss: 0.5208 (Forecasting Loss:0.2163 + XiCon Loss:3.0451 x Lambda(0.1)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.1517
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5377395
	speed: 0.0203s/iter; left time: 226.7141s
Epoch: 10 cost time: 2.5013346672058105
Epoch: 10, Steps: 124 Train Loss: 0.5205 (Forecasting Loss:0.2162 + XiCon Loss:3.0438 x Lambda(0.1)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1516
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5102682
	speed: 0.0206s/iter; left time: 227.9667s
Epoch: 11 cost time: 2.5002167224884033
Epoch: 11, Steps: 124 Train Loss: 0.5188 (Forecasting Loss:0.2158 + XiCon Loss:3.0292 x Lambda(0.1)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1515
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08656810969114304, mae:0.23525546491146088, mape:0.17648786306381226, mspe:0.050348032265901566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3223
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5723945
	speed: 0.0190s/iter; left time: 234.2728s
Epoch: 1 cost time: 2.3818869590759277
Epoch: 1, Steps: 124 Train Loss: 0.6007 (Forecasting Loss:0.2945 + XiCon Loss:3.0623 x Lambda(0.1)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.1600
Validation loss decreased (inf --> 0.215079).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5350451
	speed: 0.0253s/iter; left time: 308.0908s
Epoch: 2 cost time: 3.1532044410705566
Epoch: 2, Steps: 124 Train Loss: 0.5675 (Forecasting Loss:0.2709 + XiCon Loss:2.9658 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1486
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5443308
	speed: 0.0225s/iter; left time: 270.9822s
Epoch: 3 cost time: 2.731154680252075
Epoch: 3, Steps: 124 Train Loss: 0.5480 (Forecasting Loss:0.2423 + XiCon Loss:3.0568 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1522
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5424647
	speed: 0.0236s/iter; left time: 281.4337s
Epoch: 4 cost time: 2.898683547973633
Epoch: 4, Steps: 124 Train Loss: 0.5432 (Forecasting Loss:0.2337 + XiCon Loss:3.0950 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1466
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5303271
	speed: 0.0241s/iter; left time: 284.3383s
Epoch: 5 cost time: 2.954802989959717
Epoch: 5, Steps: 124 Train Loss: 0.5365 (Forecasting Loss:0.2299 + XiCon Loss:3.0661 x Lambda(0.1)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1467
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5208871
	speed: 0.0245s/iter; left time: 286.2874s
Epoch: 6 cost time: 3.0163462162017822
Epoch: 6, Steps: 124 Train Loss: 0.5335 (Forecasting Loss:0.2274 + XiCon Loss:3.0610 x Lambda(0.1)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1468
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5284954
	speed: 0.0242s/iter; left time: 279.5048s
Epoch: 7 cost time: 2.941575527191162
Epoch: 7, Steps: 124 Train Loss: 0.5324 (Forecasting Loss:0.2262 + XiCon Loss:3.0624 x Lambda(0.1)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1437
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5195376
	speed: 0.0242s/iter; left time: 276.5024s
Epoch: 8 cost time: 2.9588463306427
Epoch: 8, Steps: 124 Train Loss: 0.5307 (Forecasting Loss:0.2250 + XiCon Loss:3.0570 x Lambda(0.1)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1440
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5360694
	speed: 0.0242s/iter; left time: 273.1707s
Epoch: 9 cost time: 2.9640979766845703
Epoch: 9, Steps: 124 Train Loss: 0.5290 (Forecasting Loss:0.2246 + XiCon Loss:3.0444 x Lambda(0.1)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.1444
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5400863
	speed: 0.0242s/iter; left time: 270.8501s
Epoch: 10 cost time: 2.973855495452881
Epoch: 10, Steps: 124 Train Loss: 0.5301 (Forecasting Loss:0.2243 + XiCon Loss:3.0578 x Lambda(0.1)), Vali MSE Loss: 0.2413 Test MSE Loss: 0.1441
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5189946
	speed: 0.0246s/iter; left time: 272.1598s
Epoch: 11 cost time: 3.0274765491485596
Epoch: 11, Steps: 124 Train Loss: 0.5287 (Forecasting Loss:0.2242 + XiCon Loss:3.0445 x Lambda(0.1)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1441
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08572103828191757, mae:0.23427438735961914, mape:0.17628473043441772, mspe:0.050536271184682846 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2232
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5576479
	speed: 0.0199s/iter; left time: 244.2559s
Epoch: 1 cost time: 2.4357635974884033
Epoch: 1, Steps: 124 Train Loss: 0.5980 (Forecasting Loss:0.2941 + XiCon Loss:3.0395 x Lambda(0.1)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1602
Validation loss decreased (inf --> 0.215295).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5738344
	speed: 0.0207s/iter; left time: 252.6136s
Epoch: 2 cost time: 2.509080648422241
Epoch: 2, Steps: 124 Train Loss: 0.5616 (Forecasting Loss:0.2632 + XiCon Loss:2.9834 x Lambda(0.1)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1420
Validation loss decreased (0.215295 --> 0.199222).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5352011
	speed: 0.0215s/iter; left time: 259.4958s
Epoch: 3 cost time: 2.658123731613159
Epoch: 3, Steps: 124 Train Loss: 0.5486 (Forecasting Loss:0.2400 + XiCon Loss:3.0856 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1556
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5221642
	speed: 0.0207s/iter; left time: 246.7363s
Epoch: 4 cost time: 2.546766757965088
Epoch: 4, Steps: 124 Train Loss: 0.5363 (Forecasting Loss:0.2301 + XiCon Loss:3.0613 x Lambda(0.1)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1483
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5237160
	speed: 0.0208s/iter; left time: 245.9744s
Epoch: 5 cost time: 2.5602173805236816
Epoch: 5, Steps: 124 Train Loss: 0.5294 (Forecasting Loss:0.2245 + XiCon Loss:3.0481 x Lambda(0.1)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1476
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5495465
	speed: 0.0217s/iter; left time: 253.8115s
Epoch: 6 cost time: 2.657195806503296
Epoch: 6, Steps: 124 Train Loss: 0.5238 (Forecasting Loss:0.2218 + XiCon Loss:3.0195 x Lambda(0.1)), Vali MSE Loss: 0.2039 Test MSE Loss: 0.1471
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5356634
	speed: 0.0215s/iter; left time: 248.7510s
Epoch: 7 cost time: 2.631565809249878
Epoch: 7, Steps: 124 Train Loss: 0.5251 (Forecasting Loss:0.2201 + XiCon Loss:3.0504 x Lambda(0.1)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1455
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5294474
	speed: 0.0212s/iter; left time: 241.8314s
Epoch: 8 cost time: 2.6047770977020264
Epoch: 8, Steps: 124 Train Loss: 0.5231 (Forecasting Loss:0.2193 + XiCon Loss:3.0386 x Lambda(0.1)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1465
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5325012
	speed: 0.0220s/iter; left time: 248.2854s
Epoch: 9 cost time: 2.662498950958252
Epoch: 9, Steps: 124 Train Loss: 0.5219 (Forecasting Loss:0.2188 + XiCon Loss:3.0308 x Lambda(0.1)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1464
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5253456
	speed: 0.0210s/iter; left time: 234.3387s
Epoch: 10 cost time: 2.573214292526245
Epoch: 10, Steps: 124 Train Loss: 0.5230 (Forecasting Loss:0.2187 + XiCon Loss:3.0427 x Lambda(0.1)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1465
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5312920
	speed: 0.0212s/iter; left time: 234.6199s
Epoch: 11 cost time: 2.6351990699768066
Epoch: 11, Steps: 124 Train Loss: 0.5227 (Forecasting Loss:0.2189 + XiCon Loss:3.0379 x Lambda(0.1)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1465
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5254351
	speed: 0.0209s/iter; left time: 228.6282s
Epoch: 12 cost time: 2.5839710235595703
Epoch: 12, Steps: 124 Train Loss: 0.5234 (Forecasting Loss:0.2185 + XiCon Loss:3.0492 x Lambda(0.1)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1466
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07126343995332718, mae:0.2127840220928192, mape:0.16749157011508942, mspe:0.051830049604177475 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3080
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5843507
	speed: 0.0195s/iter; left time: 239.4024s
Epoch: 1 cost time: 2.3700602054595947
Epoch: 1, Steps: 124 Train Loss: 0.6007 (Forecasting Loss:0.2946 + XiCon Loss:3.0605 x Lambda(0.1)), Vali MSE Loss: 0.2176 Test MSE Loss: 0.1638
Validation loss decreased (inf --> 0.217609).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5449532
	speed: 0.0196s/iter; left time: 238.3799s
Epoch: 2 cost time: 2.3760969638824463
Epoch: 2, Steps: 124 Train Loss: 0.5616 (Forecasting Loss:0.2699 + XiCon Loss:2.9167 x Lambda(0.1)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1498
Validation loss decreased (0.217609 --> 0.195033).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5333770
	speed: 0.0196s/iter; left time: 236.0173s
Epoch: 3 cost time: 2.4079062938690186
Epoch: 3, Steps: 124 Train Loss: 0.5355 (Forecasting Loss:0.2445 + XiCon Loss:2.9104 x Lambda(0.1)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1500
Validation loss decreased (0.195033 --> 0.192792).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5200616
	speed: 0.0203s/iter; left time: 242.3499s
Epoch: 4 cost time: 2.4752509593963623
Epoch: 4, Steps: 124 Train Loss: 0.5347 (Forecasting Loss:0.2313 + XiCon Loss:3.0344 x Lambda(0.1)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1513
Validation loss decreased (0.192792 --> 0.184812).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5219935
	speed: 0.0203s/iter; left time: 239.1963s
Epoch: 5 cost time: 2.4776549339294434
Epoch: 5, Steps: 124 Train Loss: 0.5332 (Forecasting Loss:0.2256 + XiCon Loss:3.0755 x Lambda(0.1)), Vali MSE Loss: 0.1874 Test MSE Loss: 0.1496
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5408684
	speed: 0.0199s/iter; left time: 232.3746s
Epoch: 6 cost time: 2.4410483837127686
Epoch: 6, Steps: 124 Train Loss: 0.5300 (Forecasting Loss:0.2228 + XiCon Loss:3.0717 x Lambda(0.1)), Vali MSE Loss: 0.1876 Test MSE Loss: 0.1519
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5154646
	speed: 0.0195s/iter; left time: 224.9900s
Epoch: 7 cost time: 2.385071039199829
Epoch: 7, Steps: 124 Train Loss: 0.5304 (Forecasting Loss:0.2206 + XiCon Loss:3.0979 x Lambda(0.1)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1496
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5244623
	speed: 0.0198s/iter; left time: 226.0906s
Epoch: 8 cost time: 2.4266529083251953
Epoch: 8, Steps: 124 Train Loss: 0.5281 (Forecasting Loss:0.2200 + XiCon Loss:3.0812 x Lambda(0.1)), Vali MSE Loss: 0.1893 Test MSE Loss: 0.1503
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5056441
	speed: 0.0202s/iter; left time: 228.9431s
Epoch: 9 cost time: 2.483651876449585
Epoch: 9, Steps: 124 Train Loss: 0.5274 (Forecasting Loss:0.2198 + XiCon Loss:3.0760 x Lambda(0.1)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.1497
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5329643
	speed: 0.0198s/iter; left time: 221.8018s
Epoch: 10 cost time: 2.4433534145355225
Epoch: 10, Steps: 124 Train Loss: 0.5282 (Forecasting Loss:0.2196 + XiCon Loss:3.0862 x Lambda(0.1)), Vali MSE Loss: 0.1890 Test MSE Loss: 0.1498
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5395312
	speed: 0.0201s/iter; left time: 222.4620s
Epoch: 11 cost time: 2.444253921508789
Epoch: 11, Steps: 124 Train Loss: 0.5295 (Forecasting Loss:0.2197 + XiCon Loss:3.0982 x Lambda(0.1)), Vali MSE Loss: 0.1891 Test MSE Loss: 0.1501
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5381271
	speed: 0.0197s/iter; left time: 215.0354s
Epoch: 12 cost time: 2.3993682861328125
Epoch: 12, Steps: 124 Train Loss: 0.5273 (Forecasting Loss:0.2193 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.1892 Test MSE Loss: 0.1500
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5429808
	speed: 0.0194s/iter; left time: 209.3832s
Epoch: 13 cost time: 2.414506435394287
Epoch: 13, Steps: 124 Train Loss: 0.5292 (Forecasting Loss:0.2194 + XiCon Loss:3.0984 x Lambda(0.1)), Vali MSE Loss: 0.1892 Test MSE Loss: 0.1500
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5447245
	speed: 0.0202s/iter; left time: 216.1637s
Epoch: 14 cost time: 2.478896379470825
Epoch: 14, Steps: 124 Train Loss: 0.5282 (Forecasting Loss:0.2193 + XiCon Loss:3.0885 x Lambda(0.1)), Vali MSE Loss: 0.1890 Test MSE Loss: 0.1500
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07854614406824112, mae:0.22399625182151794, mape:0.1781901866197586, mspe:0.060147929936647415 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0827+-0.00979, MAE:0.2296+-0.01404, MAPE:0.1784+-0.01163, MSPE:0.0573+-0.01236, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4218
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6813674
	speed: 0.0479s/iter; left time: 559.9760s
Epoch: 1 cost time: 5.53143572807312
Epoch: 1, Steps: 118 Train Loss: 0.6759 (Forecasting Loss:0.3597 + XiCon Loss:3.1620 x Lambda(0.1)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.1697
Validation loss decreased (inf --> 0.259061).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5897301
	speed: 0.0449s/iter; left time: 519.7210s
Epoch: 2 cost time: 5.270532846450806
Epoch: 2, Steps: 118 Train Loss: 0.6063 (Forecasting Loss:0.3026 + XiCon Loss:3.0372 x Lambda(0.1)), Vali MSE Loss: 0.2720 Test MSE Loss: 0.1499
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5689274
	speed: 0.0468s/iter; left time: 536.9194s
Epoch: 3 cost time: 5.515021562576294
Epoch: 3, Steps: 118 Train Loss: 0.5599 (Forecasting Loss:0.2448 + XiCon Loss:3.1513 x Lambda(0.1)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.1543
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5485560
	speed: 0.0554s/iter; left time: 628.4995s
Epoch: 4 cost time: 6.542052507400513
Epoch: 4, Steps: 118 Train Loss: 0.5565 (Forecasting Loss:0.2356 + XiCon Loss:3.2091 x Lambda(0.1)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1545
Validation loss decreased (0.259061 --> 0.249093).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5559886
	speed: 0.0544s/iter; left time: 611.4025s
Epoch: 5 cost time: 6.35513710975647
Epoch: 5, Steps: 118 Train Loss: 0.5547 (Forecasting Loss:0.2308 + XiCon Loss:3.2389 x Lambda(0.1)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.1499
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5671607
	speed: 0.0536s/iter; left time: 595.7498s
Epoch: 6 cost time: 6.291187047958374
Epoch: 6, Steps: 118 Train Loss: 0.5541 (Forecasting Loss:0.2293 + XiCon Loss:3.2487 x Lambda(0.1)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.1531
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5533406
	speed: 0.0530s/iter; left time: 582.8761s
Epoch: 7 cost time: 6.229587554931641
Epoch: 7, Steps: 118 Train Loss: 0.5524 (Forecasting Loss:0.2276 + XiCon Loss:3.2487 x Lambda(0.1)), Vali MSE Loss: 0.2579 Test MSE Loss: 0.1542
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5612977
	speed: 0.0595s/iter; left time: 647.4649s
Epoch: 8 cost time: 7.020464181900024
Epoch: 8, Steps: 118 Train Loss: 0.5526 (Forecasting Loss:0.2275 + XiCon Loss:3.2510 x Lambda(0.1)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1538
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5421412
	speed: 0.0562s/iter; left time: 604.4717s
Epoch: 9 cost time: 6.580318212509155
Epoch: 9, Steps: 118 Train Loss: 0.5516 (Forecasting Loss:0.2269 + XiCon Loss:3.2478 x Lambda(0.1)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1531
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5731223
	speed: 0.0548s/iter; left time: 583.0173s
Epoch: 10 cost time: 6.4043824672698975
Epoch: 10, Steps: 118 Train Loss: 0.5515 (Forecasting Loss:0.2270 + XiCon Loss:3.2455 x Lambda(0.1)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1533
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5570022
	speed: 0.0568s/iter; left time: 597.1899s
Epoch: 11 cost time: 6.638706922531128
Epoch: 11, Steps: 118 Train Loss: 0.5527 (Forecasting Loss:0.2268 + XiCon Loss:3.2584 x Lambda(0.1)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.1531
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5588783
	speed: 0.0544s/iter; left time: 565.5514s
Epoch: 12 cost time: 6.435198783874512
Epoch: 12, Steps: 118 Train Loss: 0.5508 (Forecasting Loss:0.2269 + XiCon Loss:3.2389 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1531
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5354950
	speed: 0.0538s/iter; left time: 553.4932s
Epoch: 13 cost time: 6.417626619338989
Epoch: 13, Steps: 118 Train Loss: 0.5522 (Forecasting Loss:0.2269 + XiCon Loss:3.2534 x Lambda(0.1)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1532
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5714053
	speed: 0.0561s/iter; left time: 570.7338s
Epoch: 14 cost time: 6.596008777618408
Epoch: 14, Steps: 118 Train Loss: 0.5503 (Forecasting Loss:0.2265 + XiCon Loss:3.2380 x Lambda(0.1)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1533
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08213015645742416, mae:0.22681427001953125, mape:0.167829230427742, mspe:0.04796353355050087 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3187
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6470497
	speed: 0.0486s/iter; left time: 569.0928s
Epoch: 1 cost time: 5.709779739379883
Epoch: 1, Steps: 118 Train Loss: 0.6737 (Forecasting Loss:0.3578 + XiCon Loss:3.1594 x Lambda(0.1)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.260075).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5743707
	speed: 0.0677s/iter; left time: 784.6284s
Epoch: 2 cost time: 8.073624849319458
Epoch: 2, Steps: 118 Train Loss: 0.5955 (Forecasting Loss:0.2897 + XiCon Loss:3.0584 x Lambda(0.1)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5513889
	speed: 0.0704s/iter; left time: 807.1026s
Epoch: 3 cost time: 8.302900075912476
Epoch: 3, Steps: 118 Train Loss: 0.5601 (Forecasting Loss:0.2399 + XiCon Loss:3.2018 x Lambda(0.1)), Vali MSE Loss: 0.2974 Test MSE Loss: 0.1509
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5546914
	speed: 0.0742s/iter; left time: 841.4521s
Epoch: 4 cost time: 8.683526754379272
Epoch: 4, Steps: 118 Train Loss: 0.5559 (Forecasting Loss:0.2316 + XiCon Loss:3.2429 x Lambda(0.1)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.1436
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5604777
	speed: 0.0740s/iter; left time: 830.7891s
Epoch: 5 cost time: 8.693871021270752
Epoch: 5, Steps: 118 Train Loss: 0.5518 (Forecasting Loss:0.2262 + XiCon Loss:3.2554 x Lambda(0.1)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1470
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5716664
	speed: 0.0765s/iter; left time: 850.1852s
Epoch: 6 cost time: 9.067252397537231
Epoch: 6, Steps: 118 Train Loss: 0.5511 (Forecasting Loss:0.2246 + XiCon Loss:3.2652 x Lambda(0.1)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.1484
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5395150
	speed: 0.0700s/iter; left time: 769.0778s
Epoch: 7 cost time: 8.347111940383911
Epoch: 7, Steps: 118 Train Loss: 0.5502 (Forecasting Loss:0.2235 + XiCon Loss:3.2668 x Lambda(0.1)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.1476
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5828063
	speed: 0.0746s/iter; left time: 811.2056s
Epoch: 8 cost time: 8.727408409118652
Epoch: 8, Steps: 118 Train Loss: 0.5509 (Forecasting Loss:0.2231 + XiCon Loss:3.2781 x Lambda(0.1)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.1456
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5459116
	speed: 0.0722s/iter; left time: 776.7882s
Epoch: 9 cost time: 8.586310386657715
Epoch: 9, Steps: 118 Train Loss: 0.5493 (Forecasting Loss:0.2225 + XiCon Loss:3.2675 x Lambda(0.1)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.1461
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5476944
	speed: 0.0757s/iter; left time: 805.4139s
Epoch: 10 cost time: 8.922070503234863
Epoch: 10, Steps: 118 Train Loss: 0.5493 (Forecasting Loss:0.2224 + XiCon Loss:3.2694 x Lambda(0.1)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1455
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5637659
	speed: 0.0733s/iter; left time: 771.4759s
Epoch: 11 cost time: 8.616003274917603
Epoch: 11, Steps: 118 Train Loss: 0.5487 (Forecasting Loss:0.2220 + XiCon Loss:3.2670 x Lambda(0.1)), Vali MSE Loss: 0.2825 Test MSE Loss: 0.1456
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09417012333869934, mae:0.24235734343528748, mape:0.17741945385932922, mspe:0.05081121623516083 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3523
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6583178
	speed: 0.0461s/iter; left time: 539.8237s
Epoch: 1 cost time: 5.419480562210083
Epoch: 1, Steps: 118 Train Loss: 0.6751 (Forecasting Loss:0.3592 + XiCon Loss:3.1581 x Lambda(0.1)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1662
Validation loss decreased (inf --> 0.257781).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5806865
	speed: 0.0664s/iter; left time: 768.8591s
Epoch: 2 cost time: 8.196356773376465
Epoch: 2, Steps: 118 Train Loss: 0.5826 (Forecasting Loss:0.2746 + XiCon Loss:3.0800 x Lambda(0.1)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.1485
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5582988
	speed: 0.0730s/iter; left time: 837.1180s
Epoch: 3 cost time: 8.633619785308838
Epoch: 3, Steps: 118 Train Loss: 0.5598 (Forecasting Loss:0.2428 + XiCon Loss:3.1696 x Lambda(0.1)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.1460
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5566735
	speed: 0.0749s/iter; left time: 849.8836s
Epoch: 4 cost time: 8.740310192108154
Epoch: 4, Steps: 118 Train Loss: 0.5499 (Forecasting Loss:0.2321 + XiCon Loss:3.1780 x Lambda(0.1)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.1482
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5388260
	speed: 0.0716s/iter; left time: 803.5262s
Epoch: 5 cost time: 8.391894817352295
Epoch: 5, Steps: 118 Train Loss: 0.5459 (Forecasting Loss:0.2285 + XiCon Loss:3.1745 x Lambda(0.1)), Vali MSE Loss: 0.3100 Test MSE Loss: 0.1473
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5665216
	speed: 0.0724s/iter; left time: 804.2802s
Epoch: 6 cost time: 8.531994104385376
Epoch: 6, Steps: 118 Train Loss: 0.5433 (Forecasting Loss:0.2252 + XiCon Loss:3.1807 x Lambda(0.1)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1517
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5362457
	speed: 0.0746s/iter; left time: 820.2247s
Epoch: 7 cost time: 8.728728532791138
Epoch: 7, Steps: 118 Train Loss: 0.5416 (Forecasting Loss:0.2240 + XiCon Loss:3.1759 x Lambda(0.1)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.1487
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5439318
	speed: 0.0696s/iter; left time: 757.3332s
Epoch: 8 cost time: 8.322179555892944
Epoch: 8, Steps: 118 Train Loss: 0.5408 (Forecasting Loss:0.2233 + XiCon Loss:3.1757 x Lambda(0.1)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.1488
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5506756
	speed: 0.0720s/iter; left time: 774.0815s
Epoch: 9 cost time: 8.479209899902344
Epoch: 9, Steps: 118 Train Loss: 0.5399 (Forecasting Loss:0.2232 + XiCon Loss:3.1675 x Lambda(0.1)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.1501
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5477401
	speed: 0.0755s/iter; left time: 802.8518s
Epoch: 10 cost time: 8.860718488693237
Epoch: 10, Steps: 118 Train Loss: 0.5397 (Forecasting Loss:0.2230 + XiCon Loss:3.1667 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.1510
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5365860
	speed: 0.0712s/iter; left time: 749.5528s
Epoch: 11 cost time: 8.391252756118774
Epoch: 11, Steps: 118 Train Loss: 0.5401 (Forecasting Loss:0.2228 + XiCon Loss:3.1737 x Lambda(0.1)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.1506
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09228602796792984, mae:0.24006541073322296, mape:0.17618712782859802, mspe:0.0503239743411541 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3289
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6337794
	speed: 0.0477s/iter; left time: 558.2939s
Epoch: 1 cost time: 5.545651435852051
Epoch: 1, Steps: 118 Train Loss: 0.6679 (Forecasting Loss:0.3517 + XiCon Loss:3.1623 x Lambda(0.1)), Vali MSE Loss: 0.2561 Test MSE Loss: 0.1583
Validation loss decreased (inf --> 0.256133).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5672778
	speed: 0.0483s/iter; left time: 559.4736s
Epoch: 2 cost time: 5.624987602233887
Epoch: 2, Steps: 118 Train Loss: 0.6164 (Forecasting Loss:0.3093 + XiCon Loss:3.0717 x Lambda(0.1)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1469
Validation loss decreased (0.256133 --> 0.223724).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5512798
	speed: 0.0488s/iter; left time: 559.9133s
Epoch: 3 cost time: 5.778564929962158
Epoch: 3, Steps: 118 Train Loss: 0.5534 (Forecasting Loss:0.2516 + XiCon Loss:3.0182 x Lambda(0.1)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1317
Validation loss decreased (0.223724 --> 0.210880).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5334051
	speed: 0.0455s/iter; left time: 516.1237s
Epoch: 4 cost time: 5.3302295207977295
Epoch: 4, Steps: 118 Train Loss: 0.5422 (Forecasting Loss:0.2334 + XiCon Loss:3.0875 x Lambda(0.1)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1330
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5623248
	speed: 0.0476s/iter; left time: 534.3948s
Epoch: 5 cost time: 5.551684617996216
Epoch: 5, Steps: 118 Train Loss: 0.5419 (Forecasting Loss:0.2294 + XiCon Loss:3.1253 x Lambda(0.1)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1318
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5313842
	speed: 0.0449s/iter; left time: 499.1540s
Epoch: 6 cost time: 5.2977519035339355
Epoch: 6, Steps: 118 Train Loss: 0.5410 (Forecasting Loss:0.2269 + XiCon Loss:3.1413 x Lambda(0.1)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1308
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5381935
	speed: 0.0431s/iter; left time: 474.2245s
Epoch: 7 cost time: 5.079769849777222
Epoch: 7, Steps: 118 Train Loss: 0.5407 (Forecasting Loss:0.2257 + XiCon Loss:3.1498 x Lambda(0.1)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1310
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5441357
	speed: 0.0501s/iter; left time: 545.2365s
Epoch: 8 cost time: 5.858872890472412
Epoch: 8, Steps: 118 Train Loss: 0.5397 (Forecasting Loss:0.2250 + XiCon Loss:3.1470 x Lambda(0.1)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1312
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5397742
	speed: 0.0453s/iter; left time: 486.9922s
Epoch: 9 cost time: 5.306105852127075
Epoch: 9, Steps: 118 Train Loss: 0.5402 (Forecasting Loss:0.2249 + XiCon Loss:3.1532 x Lambda(0.1)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1311
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5511305
	speed: 0.0469s/iter; left time: 499.1447s
Epoch: 10 cost time: 5.453366756439209
Epoch: 10, Steps: 118 Train Loss: 0.5393 (Forecasting Loss:0.2247 + XiCon Loss:3.1462 x Lambda(0.1)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1311
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5449784
	speed: 0.0479s/iter; left time: 504.2791s
Epoch: 11 cost time: 5.790755748748779
Epoch: 11, Steps: 118 Train Loss: 0.5392 (Forecasting Loss:0.2244 + XiCon Loss:3.1480 x Lambda(0.1)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1310
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5441740
	speed: 0.0513s/iter; left time: 533.8414s
Epoch: 12 cost time: 6.013261079788208
Epoch: 12, Steps: 118 Train Loss: 0.5401 (Forecasting Loss:0.2243 + XiCon Loss:3.1576 x Lambda(0.1)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1311
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5379339
	speed: 0.0448s/iter; left time: 460.8039s
Epoch: 13 cost time: 5.457356214523315
Epoch: 13, Steps: 118 Train Loss: 0.5394 (Forecasting Loss:0.2244 + XiCon Loss:3.1506 x Lambda(0.1)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1311
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.06287772208452225, mae:0.20057831704616547, mape:0.1515415757894516, mspe:0.03968379274010658 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3091
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.6553984
	speed: 0.0461s/iter; left time: 539.8487s
Epoch: 1 cost time: 5.416833400726318
Epoch: 1, Steps: 118 Train Loss: 0.6690 (Forecasting Loss:0.3538 + XiCon Loss:3.1523 x Lambda(0.1)), Vali MSE Loss: 0.2572 Test MSE Loss: 0.1649
Validation loss decreased (inf --> 0.257206).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5621694
	speed: 0.0469s/iter; left time: 542.9174s
Epoch: 2 cost time: 5.499143838882446
Epoch: 2, Steps: 118 Train Loss: 0.5988 (Forecasting Loss:0.2948 + XiCon Loss:3.0402 x Lambda(0.1)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1372
Validation loss decreased (0.257206 --> 0.211084).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5476434
	speed: 0.0454s/iter; left time: 520.6692s
Epoch: 3 cost time: 5.369967222213745
Epoch: 3, Steps: 118 Train Loss: 0.5655 (Forecasting Loss:0.2467 + XiCon Loss:3.1877 x Lambda(0.1)), Vali MSE Loss: 0.2247 Test MSE Loss: 0.1438
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5533137
	speed: 0.0506s/iter; left time: 574.1848s
Epoch: 4 cost time: 5.907549858093262
Epoch: 4, Steps: 118 Train Loss: 0.5606 (Forecasting Loss:0.2354 + XiCon Loss:3.2528 x Lambda(0.1)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1472
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5611197
	speed: 0.0484s/iter; left time: 542.9352s
Epoch: 5 cost time: 5.666142702102661
Epoch: 5, Steps: 118 Train Loss: 0.5583 (Forecasting Loss:0.2312 + XiCon Loss:3.2710 x Lambda(0.1)), Vali MSE Loss: 0.2337 Test MSE Loss: 0.1461
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5416628
	speed: 0.0495s/iter; left time: 549.5789s
Epoch: 6 cost time: 5.755402088165283
Epoch: 6, Steps: 118 Train Loss: 0.5565 (Forecasting Loss:0.2289 + XiCon Loss:3.2750 x Lambda(0.1)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1437
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5345057
	speed: 0.0455s/iter; left time: 500.4121s
Epoch: 7 cost time: 5.360475301742554
Epoch: 7, Steps: 118 Train Loss: 0.5550 (Forecasting Loss:0.2278 + XiCon Loss:3.2722 x Lambda(0.1)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1435
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5462937
	speed: 0.0467s/iter; left time: 507.7991s
Epoch: 8 cost time: 5.4860217571258545
Epoch: 8, Steps: 118 Train Loss: 0.5548 (Forecasting Loss:0.2270 + XiCon Loss:3.2782 x Lambda(0.1)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1426
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5428616
	speed: 0.0453s/iter; left time: 487.3261s
Epoch: 9 cost time: 5.301082372665405
Epoch: 9, Steps: 118 Train Loss: 0.5543 (Forecasting Loss:0.2272 + XiCon Loss:3.2712 x Lambda(0.1)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1429
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5527110
	speed: 0.0471s/iter; left time: 500.9641s
Epoch: 10 cost time: 5.458409786224365
Epoch: 10, Steps: 118 Train Loss: 0.5547 (Forecasting Loss:0.2265 + XiCon Loss:3.2822 x Lambda(0.1)), Vali MSE Loss: 0.2337 Test MSE Loss: 0.1435
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5488969
	speed: 0.0437s/iter; left time: 459.3817s
Epoch: 11 cost time: 5.165700435638428
Epoch: 11, Steps: 118 Train Loss: 0.5547 (Forecasting Loss:0.2266 + XiCon Loss:3.2807 x Lambda(0.1)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.1435
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5598162
	speed: 0.0494s/iter; left time: 513.8779s
Epoch: 12 cost time: 5.812740325927734
Epoch: 12, Steps: 118 Train Loss: 0.5541 (Forecasting Loss:0.2264 + XiCon Loss:3.2777 x Lambda(0.1)), Vali MSE Loss: 0.2334 Test MSE Loss: 0.1433
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0675605982542038, mae:0.20676322281360626, mape:0.15459784865379333, mspe:0.04055790975689888 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0798+-0.01760, MAE:0.2233+-0.02361, MAPE:0.1655+-0.01489, MSPE:0.0459+-0.00666, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3993
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5359505
	speed: 0.0177s/iter; left time: 224.4729s
Epoch: 1 cost time: 2.1231307983398438
Epoch: 1, Steps: 128 Train Loss: 0.5973 (Forecasting Loss:0.2925 + XiCon Loss:3.0478 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.2319
Validation loss decreased (inf --> 0.276370).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5061279
	speed: 0.0144s/iter; left time: 181.6374s
Epoch: 2 cost time: 1.8271846771240234
Epoch: 2, Steps: 128 Train Loss: 0.5356 (Forecasting Loss:0.2464 + XiCon Loss:2.8924 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.2287
Validation loss decreased (0.276370 --> 0.261316).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4970812
	speed: 0.0138s/iter; left time: 171.6099s
Epoch: 3 cost time: 1.7315726280212402
Epoch: 3, Steps: 128 Train Loss: 0.4924 (Forecasting Loss:0.2055 + XiCon Loss:2.8687 x Lambda(0.1)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.2573
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4793909
	speed: 0.0141s/iter; left time: 173.9579s
Epoch: 4 cost time: 1.8412444591522217
Epoch: 4, Steps: 128 Train Loss: 0.4759 (Forecasting Loss:0.1831 + XiCon Loss:2.9276 x Lambda(0.1)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2493
Validation loss decreased (0.261316 --> 0.258114).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4793931
	speed: 0.0142s/iter; left time: 173.0379s
Epoch: 5 cost time: 1.787065029144287
Epoch: 5, Steps: 128 Train Loss: 0.4646 (Forecasting Loss:0.1717 + XiCon Loss:2.9292 x Lambda(0.1)), Vali MSE Loss: 0.2628 Test MSE Loss: 0.2605
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4733052
	speed: 0.0138s/iter; left time: 166.4169s
Epoch: 6 cost time: 1.757141351699829
Epoch: 6, Steps: 128 Train Loss: 0.4591 (Forecasting Loss:0.1668 + XiCon Loss:2.9226 x Lambda(0.1)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.2609
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4676223
	speed: 0.0147s/iter; left time: 175.5671s
Epoch: 7 cost time: 1.8581533432006836
Epoch: 7, Steps: 128 Train Loss: 0.4567 (Forecasting Loss:0.1642 + XiCon Loss:2.9250 x Lambda(0.1)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.2608
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4543267
	speed: 0.0137s/iter; left time: 161.7245s
Epoch: 8 cost time: 1.725374460220337
Epoch: 8, Steps: 128 Train Loss: 0.4552 (Forecasting Loss:0.1627 + XiCon Loss:2.9245 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.2626
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4582262
	speed: 0.0144s/iter; left time: 168.4401s
Epoch: 9 cost time: 1.7873857021331787
Epoch: 9, Steps: 128 Train Loss: 0.4548 (Forecasting Loss:0.1623 + XiCon Loss:2.9251 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.2608
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4452426
	speed: 0.0138s/iter; left time: 159.1090s
Epoch: 10 cost time: 1.7459626197814941
Epoch: 10, Steps: 128 Train Loss: 0.4546 (Forecasting Loss:0.1622 + XiCon Loss:2.9241 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.2626
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4504230
	speed: 0.0137s/iter; left time: 156.4702s
Epoch: 11 cost time: 1.713961124420166
Epoch: 11, Steps: 128 Train Loss: 0.4540 (Forecasting Loss:0.1617 + XiCon Loss:2.9236 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.2625
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4264708
	speed: 0.0153s/iter; left time: 172.9918s
Epoch: 12 cost time: 1.8864004611968994
Epoch: 12, Steps: 128 Train Loss: 0.4544 (Forecasting Loss:0.1619 + XiCon Loss:2.9242 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.2624
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4408803
	speed: 0.0143s/iter; left time: 159.9830s
Epoch: 13 cost time: 1.7718942165374756
Epoch: 13, Steps: 128 Train Loss: 0.4543 (Forecasting Loss:0.1616 + XiCon Loss:2.9262 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.2626
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4534253
	speed: 0.0146s/iter; left time: 160.6652s
Epoch: 14 cost time: 1.8167893886566162
Epoch: 14, Steps: 128 Train Loss: 0.4539 (Forecasting Loss:0.1617 + XiCon Loss:2.9220 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.2628
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.17214518785476685, mae:0.32636338472366333, mape:0.7855210900306702, mspe:23.560562133789062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4008
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5301670
	speed: 0.0140s/iter; left time: 178.0936s
Epoch: 1 cost time: 1.7477712631225586
Epoch: 1, Steps: 128 Train Loss: 0.5938 (Forecasting Loss:0.2911 + XiCon Loss:3.0272 x Lambda(0.1)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.2302
Validation loss decreased (inf --> 0.271136).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5573156
	speed: 0.0142s/iter; left time: 178.7429s
Epoch: 2 cost time: 1.7744112014770508
Epoch: 2, Steps: 128 Train Loss: 0.5460 (Forecasting Loss:0.2559 + XiCon Loss:2.9005 x Lambda(0.1)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.2150
Validation loss decreased (0.271136 --> 0.264949).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4773705
	speed: 0.0142s/iter; left time: 176.1309s
Epoch: 3 cost time: 1.7683460712432861
Epoch: 3, Steps: 128 Train Loss: 0.5252 (Forecasting Loss:0.2410 + XiCon Loss:2.8417 x Lambda(0.1)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.2173
Validation loss decreased (0.264949 --> 0.253535).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5152116
	speed: 0.0138s/iter; left time: 170.3051s
Epoch: 4 cost time: 1.7227773666381836
Epoch: 4, Steps: 128 Train Loss: 0.5214 (Forecasting Loss:0.2344 + XiCon Loss:2.8695 x Lambda(0.1)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.2118
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5527179
	speed: 0.0139s/iter; left time: 169.8438s
Epoch: 5 cost time: 1.7434520721435547
Epoch: 5, Steps: 128 Train Loss: 0.5203 (Forecasting Loss:0.2304 + XiCon Loss:2.8987 x Lambda(0.1)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2115
Validation loss decreased (0.253535 --> 0.249511).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5265259
	speed: 0.0138s/iter; left time: 165.8597s
Epoch: 6 cost time: 1.7603302001953125
Epoch: 6, Steps: 128 Train Loss: 0.5178 (Forecasting Loss:0.2281 + XiCon Loss:2.8973 x Lambda(0.1)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2115
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5282081
	speed: 0.0138s/iter; left time: 164.5419s
Epoch: 7 cost time: 1.7354443073272705
Epoch: 7, Steps: 128 Train Loss: 0.5180 (Forecasting Loss:0.2265 + XiCon Loss:2.9155 x Lambda(0.1)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2128
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4812933
	speed: 0.0140s/iter; left time: 165.7183s
Epoch: 8 cost time: 1.7515475749969482
Epoch: 8, Steps: 128 Train Loss: 0.5174 (Forecasting Loss:0.2255 + XiCon Loss:2.9189 x Lambda(0.1)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2113
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5396330
	speed: 0.0139s/iter; left time: 162.6841s
Epoch: 9 cost time: 1.7559163570404053
Epoch: 9, Steps: 128 Train Loss: 0.5164 (Forecasting Loss:0.2254 + XiCon Loss:2.9101 x Lambda(0.1)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2119
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5271764
	speed: 0.0140s/iter; left time: 161.5637s
Epoch: 10 cost time: 1.747140645980835
Epoch: 10, Steps: 128 Train Loss: 0.5158 (Forecasting Loss:0.2249 + XiCon Loss:2.9092 x Lambda(0.1)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.2113
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5177438
	speed: 0.0147s/iter; left time: 167.3493s
Epoch: 11 cost time: 1.8199799060821533
Epoch: 11, Steps: 128 Train Loss: 0.5170 (Forecasting Loss:0.2249 + XiCon Loss:2.9209 x Lambda(0.1)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2111
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4952776
	speed: 0.0140s/iter; left time: 157.9008s
Epoch: 12 cost time: 1.786010980606079
Epoch: 12, Steps: 128 Train Loss: 0.5163 (Forecasting Loss:0.2249 + XiCon Loss:2.9133 x Lambda(0.1)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2111
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5081111
	speed: 0.0140s/iter; left time: 156.4737s
Epoch: 13 cost time: 1.7760183811187744
Epoch: 13, Steps: 128 Train Loss: 0.5159 (Forecasting Loss:0.2249 + XiCon Loss:2.9096 x Lambda(0.1)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2111
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5309140
	speed: 0.0141s/iter; left time: 155.2442s
Epoch: 14 cost time: 1.7698636054992676
Epoch: 14, Steps: 128 Train Loss: 0.5164 (Forecasting Loss:0.2248 + XiCon Loss:2.9158 x Lambda(0.1)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2111
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5035990
	speed: 0.0151s/iter; left time: 164.5808s
Epoch: 15 cost time: 1.8875436782836914
Epoch: 15, Steps: 128 Train Loss: 0.5166 (Forecasting Loss:0.2248 + XiCon Loss:2.9178 x Lambda(0.1)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2111
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13765929639339447, mae:0.28538012504577637, mape:0.6778358221054077, mspe:20.4843692779541 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3917
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5657375
	speed: 0.0147s/iter; left time: 186.2204s
Epoch: 1 cost time: 1.8349838256835938
Epoch: 1, Steps: 128 Train Loss: 0.6026 (Forecasting Loss:0.2961 + XiCon Loss:3.0651 x Lambda(0.1)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2311
Validation loss decreased (inf --> 0.278191).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5628209
	speed: 0.0143s/iter; left time: 179.9486s
Epoch: 2 cost time: 1.790755033493042
Epoch: 2, Steps: 128 Train Loss: 0.5402 (Forecasting Loss:0.2481 + XiCon Loss:2.9211 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.2257
Validation loss decreased (0.278191 --> 0.265539).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5097733
	speed: 0.0145s/iter; left time: 180.9525s
Epoch: 3 cost time: 1.8445148468017578
Epoch: 3, Steps: 128 Train Loss: 0.5176 (Forecasting Loss:0.2258 + XiCon Loss:2.9175 x Lambda(0.1)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2424
Validation loss decreased (0.265539 --> 0.248294).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4885423
	speed: 0.0142s/iter; left time: 174.3988s
Epoch: 4 cost time: 1.7988297939300537
Epoch: 4, Steps: 128 Train Loss: 0.5069 (Forecasting Loss:0.2144 + XiCon Loss:2.9252 x Lambda(0.1)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2525
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4934687
	speed: 0.0145s/iter; left time: 176.4526s
Epoch: 5 cost time: 1.8948936462402344
Epoch: 5, Steps: 128 Train Loss: 0.4995 (Forecasting Loss:0.2072 + XiCon Loss:2.9224 x Lambda(0.1)), Vali MSE Loss: 0.2845 Test MSE Loss: 0.2776
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5056422
	speed: 0.0138s/iter; left time: 166.0536s
Epoch: 6 cost time: 1.7245187759399414
Epoch: 6, Steps: 128 Train Loss: 0.4958 (Forecasting Loss:0.2031 + XiCon Loss:2.9271 x Lambda(0.1)), Vali MSE Loss: 0.2832 Test MSE Loss: 0.2808
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5050440
	speed: 0.0145s/iter; left time: 173.1937s
Epoch: 7 cost time: 1.8042705059051514
Epoch: 7, Steps: 128 Train Loss: 0.4926 (Forecasting Loss:0.2004 + XiCon Loss:2.9215 x Lambda(0.1)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2793
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4892867
	speed: 0.0143s/iter; left time: 169.3599s
Epoch: 8 cost time: 1.9004859924316406
Epoch: 8, Steps: 128 Train Loss: 0.4911 (Forecasting Loss:0.1992 + XiCon Loss:2.9188 x Lambda(0.1)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2744
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4775370
	speed: 0.0140s/iter; left time: 163.8598s
Epoch: 9 cost time: 1.7543983459472656
Epoch: 9, Steps: 128 Train Loss: 0.4914 (Forecasting Loss:0.1987 + XiCon Loss:2.9277 x Lambda(0.1)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.2752
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5091751
	speed: 0.0141s/iter; left time: 162.6312s
Epoch: 10 cost time: 1.7603681087493896
Epoch: 10, Steps: 128 Train Loss: 0.4903 (Forecasting Loss:0.1986 + XiCon Loss:2.9174 x Lambda(0.1)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.2777
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4758656
	speed: 0.0136s/iter; left time: 155.8633s
Epoch: 11 cost time: 1.7258667945861816
Epoch: 11, Steps: 128 Train Loss: 0.4902 (Forecasting Loss:0.1979 + XiCon Loss:2.9229 x Lambda(0.1)), Vali MSE Loss: 0.2759 Test MSE Loss: 0.2761
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5265132
	speed: 0.0149s/iter; left time: 168.0460s
Epoch: 12 cost time: 1.840693473815918
Epoch: 12, Steps: 128 Train Loss: 0.4900 (Forecasting Loss:0.1976 + XiCon Loss:2.9240 x Lambda(0.1)), Vali MSE Loss: 0.2767 Test MSE Loss: 0.2771
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5083441
	speed: 0.0145s/iter; left time: 162.3159s
Epoch: 13 cost time: 1.80014967918396
Epoch: 13, Steps: 128 Train Loss: 0.4899 (Forecasting Loss:0.1978 + XiCon Loss:2.9219 x Lambda(0.1)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2775
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.16459451615810394, mae:0.3202199637889862, mape:0.888972282409668, mspe:31.696155548095703 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2776
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.5797958
	speed: 0.0137s/iter; left time: 174.5718s
Epoch: 1 cost time: 1.7401208877563477
Epoch: 1, Steps: 128 Train Loss: 0.5928 (Forecasting Loss:0.2901 + XiCon Loss:3.0274 x Lambda(0.1)), Vali MSE Loss: 0.2723 Test MSE Loss: 0.2241
Validation loss decreased (inf --> 0.272318).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5370157
	speed: 0.0139s/iter; left time: 174.6417s
Epoch: 2 cost time: 1.741760492324829
Epoch: 2, Steps: 128 Train Loss: 0.5377 (Forecasting Loss:0.2448 + XiCon Loss:2.9291 x Lambda(0.1)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.2456
Validation loss decreased (0.272318 --> 0.259772).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4971030
	speed: 0.0144s/iter; left time: 179.6230s
Epoch: 3 cost time: 1.791353702545166
Epoch: 3, Steps: 128 Train Loss: 0.5102 (Forecasting Loss:0.2129 + XiCon Loss:2.9722 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2554
Validation loss decreased (0.259772 --> 0.254390).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4689577
	speed: 0.0142s/iter; left time: 174.9538s
Epoch: 4 cost time: 1.8144409656524658
Epoch: 4, Steps: 128 Train Loss: 0.4950 (Forecasting Loss:0.1988 + XiCon Loss:2.9621 x Lambda(0.1)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2461
Validation loss decreased (0.254390 --> 0.252934).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4757706
	speed: 0.0135s/iter; left time: 164.7490s
Epoch: 5 cost time: 1.730269193649292
Epoch: 5, Steps: 128 Train Loss: 0.4829 (Forecasting Loss:0.1882 + XiCon Loss:2.9475 x Lambda(0.1)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.2612
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4822136
	speed: 0.0143s/iter; left time: 173.0646s
Epoch: 6 cost time: 1.7710962295532227
Epoch: 6, Steps: 128 Train Loss: 0.4777 (Forecasting Loss:0.1835 + XiCon Loss:2.9419 x Lambda(0.1)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.2594
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4709383
	speed: 0.0134s/iter; left time: 160.2605s
Epoch: 7 cost time: 1.6907145977020264
Epoch: 7, Steps: 128 Train Loss: 0.4743 (Forecasting Loss:0.1807 + XiCon Loss:2.9358 x Lambda(0.1)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.2613
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4542808
	speed: 0.0146s/iter; left time: 172.6015s
Epoch: 8 cost time: 1.8331637382507324
Epoch: 8, Steps: 128 Train Loss: 0.4727 (Forecasting Loss:0.1792 + XiCon Loss:2.9354 x Lambda(0.1)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2580
Validation loss decreased (0.252934 --> 0.252662).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4764326
	speed: 0.0138s/iter; left time: 161.5619s
Epoch: 9 cost time: 1.7468321323394775
Epoch: 9, Steps: 128 Train Loss: 0.4712 (Forecasting Loss:0.1780 + XiCon Loss:2.9324 x Lambda(0.1)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.2609
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4863681
	speed: 0.0137s/iter; left time: 158.1285s
Epoch: 10 cost time: 1.7239787578582764
Epoch: 10, Steps: 128 Train Loss: 0.4717 (Forecasting Loss:0.1780 + XiCon Loss:2.9365 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2582
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4593437
	speed: 0.0138s/iter; left time: 157.7550s
Epoch: 11 cost time: 1.7362966537475586
Epoch: 11, Steps: 128 Train Loss: 0.4707 (Forecasting Loss:0.1772 + XiCon Loss:2.9351 x Lambda(0.1)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.2603
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4566234
	speed: 0.0138s/iter; left time: 155.3298s
Epoch: 12 cost time: 1.7202558517456055
Epoch: 12, Steps: 128 Train Loss: 0.4712 (Forecasting Loss:0.1778 + XiCon Loss:2.9344 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2598
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4864659
	speed: 0.0146s/iter; left time: 163.2579s
Epoch: 13 cost time: 1.8584561347961426
Epoch: 13, Steps: 128 Train Loss: 0.4712 (Forecasting Loss:0.1774 + XiCon Loss:2.9374 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2598
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4675117
	speed: 0.0138s/iter; left time: 152.5079s
Epoch: 14 cost time: 1.732712745666504
Epoch: 14, Steps: 128 Train Loss: 0.4706 (Forecasting Loss:0.1776 + XiCon Loss:2.9300 x Lambda(0.1)), Vali MSE Loss: 0.2547 Test MSE Loss: 0.2596
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4554678
	speed: 0.0138s/iter; left time: 150.5723s
Epoch: 15 cost time: 1.7317345142364502
Epoch: 15, Steps: 128 Train Loss: 0.4711 (Forecasting Loss:0.1775 + XiCon Loss:2.9365 x Lambda(0.1)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.2595
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4757442
	speed: 0.0153s/iter; left time: 164.9030s
Epoch: 16 cost time: 1.882270097732544
Epoch: 16, Steps: 128 Train Loss: 0.4711 (Forecasting Loss:0.1773 + XiCon Loss:2.9381 x Lambda(0.1)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.2596
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4588709
	speed: 0.0136s/iter; left time: 145.2618s
Epoch: 17 cost time: 1.7092995643615723
Epoch: 17, Steps: 128 Train Loss: 0.4703 (Forecasting Loss:0.1772 + XiCon Loss:2.9311 x Lambda(0.1)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.2596
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4627572
	speed: 0.0152s/iter; left time: 160.1847s
Epoch: 18 cost time: 1.8678436279296875
Epoch: 18, Steps: 128 Train Loss: 0.4717 (Forecasting Loss:0.1779 + XiCon Loss:2.9383 x Lambda(0.1)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.2596
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1892591118812561, mae:0.32668569684028625, mape:0.7111830115318298, mspe:21.512603759765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4976
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.6118274
	speed: 0.0145s/iter; left time: 183.9654s
Epoch: 1 cost time: 1.7943201065063477
Epoch: 1, Steps: 128 Train Loss: 0.5963 (Forecasting Loss:0.2926 + XiCon Loss:3.0369 x Lambda(0.1)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.2257
Validation loss decreased (inf --> 0.270105).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5005379
	speed: 0.0139s/iter; left time: 174.9873s
Epoch: 2 cost time: 1.7445306777954102
Epoch: 2, Steps: 128 Train Loss: 0.5342 (Forecasting Loss:0.2415 + XiCon Loss:2.9267 x Lambda(0.1)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.2549
Validation loss decreased (0.270105 --> 0.267810).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4877504
	speed: 0.0143s/iter; left time: 177.7136s
Epoch: 3 cost time: 1.771066665649414
Epoch: 3, Steps: 128 Train Loss: 0.4929 (Forecasting Loss:0.2009 + XiCon Loss:2.9199 x Lambda(0.1)), Vali MSE Loss: 0.2628 Test MSE Loss: 0.2922
Validation loss decreased (0.267810 --> 0.262829).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5040711
	speed: 0.0151s/iter; left time: 185.7013s
Epoch: 4 cost time: 1.8464701175689697
Epoch: 4, Steps: 128 Train Loss: 0.4838 (Forecasting Loss:0.1838 + XiCon Loss:3.0001 x Lambda(0.1)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.2601
Validation loss decreased (0.262829 --> 0.255435).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4723948
	speed: 0.0154s/iter; left time: 187.7490s
Epoch: 5 cost time: 1.888692855834961
Epoch: 5, Steps: 128 Train Loss: 0.4709 (Forecasting Loss:0.1734 + XiCon Loss:2.9749 x Lambda(0.1)), Vali MSE Loss: 0.2639 Test MSE Loss: 0.2942
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4694461
	speed: 0.0150s/iter; left time: 180.6628s
Epoch: 6 cost time: 1.882922649383545
Epoch: 6, Steps: 128 Train Loss: 0.4633 (Forecasting Loss:0.1664 + XiCon Loss:2.9683 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.3104
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4722807
	speed: 0.0139s/iter; left time: 165.9067s
Epoch: 7 cost time: 1.742917776107788
Epoch: 7, Steps: 128 Train Loss: 0.4578 (Forecasting Loss:0.1623 + XiCon Loss:2.9541 x Lambda(0.1)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.3090
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4518529
	speed: 0.0141s/iter; left time: 166.5880s
Epoch: 8 cost time: 1.747208595275879
Epoch: 8, Steps: 128 Train Loss: 0.4569 (Forecasting Loss:0.1605 + XiCon Loss:2.9633 x Lambda(0.1)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.3005
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4499903
	speed: 0.0150s/iter; left time: 175.4759s
Epoch: 9 cost time: 1.8798959255218506
Epoch: 9, Steps: 128 Train Loss: 0.4546 (Forecasting Loss:0.1593 + XiCon Loss:2.9532 x Lambda(0.1)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.3048
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4411834
	speed: 0.0135s/iter; left time: 155.7182s
Epoch: 10 cost time: 1.692072868347168
Epoch: 10, Steps: 128 Train Loss: 0.4546 (Forecasting Loss:0.1589 + XiCon Loss:2.9571 x Lambda(0.1)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.3093
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4383025
	speed: 0.0138s/iter; left time: 157.9460s
Epoch: 11 cost time: 1.7400736808776855
Epoch: 11, Steps: 128 Train Loss: 0.4541 (Forecasting Loss:0.1586 + XiCon Loss:2.9552 x Lambda(0.1)), Vali MSE Loss: 0.2743 Test MSE Loss: 0.3086
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4584558
	speed: 0.0147s/iter; left time: 166.4375s
Epoch: 12 cost time: 1.8230257034301758
Epoch: 12, Steps: 128 Train Loss: 0.4545 (Forecasting Loss:0.1590 + XiCon Loss:2.9554 x Lambda(0.1)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.3081
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4469608
	speed: 0.0144s/iter; left time: 161.1640s
Epoch: 13 cost time: 1.8006205558776855
Epoch: 13, Steps: 128 Train Loss: 0.4547 (Forecasting Loss:0.1589 + XiCon Loss:2.9579 x Lambda(0.1)), Vali MSE Loss: 0.2752 Test MSE Loss: 0.3084
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4578101
	speed: 0.0144s/iter; left time: 158.6157s
Epoch: 14 cost time: 1.769547462463379
Epoch: 14, Steps: 128 Train Loss: 0.4551 (Forecasting Loss:0.1590 + XiCon Loss:2.9603 x Lambda(0.1)), Vali MSE Loss: 0.2756 Test MSE Loss: 0.3082
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1871887892484665, mae:0.33303165435791016, mape:0.7362617254257202, mspe:21.870166778564453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1702+-0.02594, MAE:0.3183+-0.02356, MAPE:0.7600+-0.10198, MSPE:23.8248+-5.63397, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4388
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.6175655
	speed: 0.0185s/iter; left time: 231.1939s
Epoch: 1 cost time: 2.2116787433624268
Epoch: 1, Steps: 126 Train Loss: 0.6255 (Forecasting Loss:0.3203 + XiCon Loss:3.0521 x Lambda(0.1)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2676
Validation loss decreased (inf --> 0.308612).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5699232
	speed: 0.0152s/iter; left time: 188.6469s
Epoch: 2 cost time: 1.9603087902069092
Epoch: 2, Steps: 126 Train Loss: 0.5721 (Forecasting Loss:0.2803 + XiCon Loss:2.9173 x Lambda(0.1)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2565
Validation loss decreased (0.308612 --> 0.289157).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5246990
	speed: 0.0176s/iter; left time: 216.1701s
Epoch: 3 cost time: 2.177577495574951
Epoch: 3, Steps: 126 Train Loss: 0.5393 (Forecasting Loss:0.2480 + XiCon Loss:2.9131 x Lambda(0.1)), Vali MSE Loss: 0.2748 Test MSE Loss: 0.2651
Validation loss decreased (0.289157 --> 0.274761).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5046794
	speed: 0.0178s/iter; left time: 215.8137s
Epoch: 4 cost time: 2.2144696712493896
Epoch: 4, Steps: 126 Train Loss: 0.5185 (Forecasting Loss:0.2291 + XiCon Loss:2.8941 x Lambda(0.1)), Vali MSE Loss: 0.2769 Test MSE Loss: 0.2759
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5129164
	speed: 0.0185s/iter; left time: 221.7770s
Epoch: 5 cost time: 2.2663395404815674
Epoch: 5, Steps: 126 Train Loss: 0.5105 (Forecasting Loss:0.2217 + XiCon Loss:2.8876 x Lambda(0.1)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2745
Validation loss decreased (0.274761 --> 0.272512).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4847499
	speed: 0.0188s/iter; left time: 222.6361s
Epoch: 6 cost time: 2.373277187347412
Epoch: 6, Steps: 126 Train Loss: 0.5054 (Forecasting Loss:0.2177 + XiCon Loss:2.8773 x Lambda(0.1)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.2807
Validation loss decreased (0.272512 --> 0.271691).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4883697
	speed: 0.0182s/iter; left time: 214.2725s
Epoch: 7 cost time: 2.276219129562378
Epoch: 7, Steps: 126 Train Loss: 0.5034 (Forecasting Loss:0.2160 + XiCon Loss:2.8747 x Lambda(0.1)), Vali MSE Loss: 0.2722 Test MSE Loss: 0.2756
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5088007
	speed: 0.0185s/iter; left time: 214.6106s
Epoch: 8 cost time: 2.2942700386047363
Epoch: 8, Steps: 126 Train Loss: 0.5025 (Forecasting Loss:0.2149 + XiCon Loss:2.8754 x Lambda(0.1)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2748
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5182632
	speed: 0.0177s/iter; left time: 203.7622s
Epoch: 9 cost time: 2.182997465133667
Epoch: 9, Steps: 126 Train Loss: 0.5019 (Forecasting Loss:0.2144 + XiCon Loss:2.8748 x Lambda(0.1)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4963158
	speed: 0.0181s/iter; left time: 205.6296s
Epoch: 10 cost time: 2.2709383964538574
Epoch: 10, Steps: 126 Train Loss: 0.5015 (Forecasting Loss:0.2140 + XiCon Loss:2.8749 x Lambda(0.1)), Vali MSE Loss: 0.2732 Test MSE Loss: 0.2714
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5204999
	speed: 0.0176s/iter; left time: 197.5420s
Epoch: 11 cost time: 2.190359354019165
Epoch: 11, Steps: 126 Train Loss: 0.5016 (Forecasting Loss:0.2142 + XiCon Loss:2.8736 x Lambda(0.1)), Vali MSE Loss: 0.2729 Test MSE Loss: 0.2715
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5038823
	speed: 0.0178s/iter; left time: 197.8474s
Epoch: 12 cost time: 2.2043075561523438
Epoch: 12, Steps: 126 Train Loss: 0.5018 (Forecasting Loss:0.2140 + XiCon Loss:2.8781 x Lambda(0.1)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2715
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4923372
	speed: 0.0174s/iter; left time: 191.5334s
Epoch: 13 cost time: 2.160457134246826
Epoch: 13, Steps: 126 Train Loss: 0.5011 (Forecasting Loss:0.2138 + XiCon Loss:2.8729 x Lambda(0.1)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2713
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4877527
	speed: 0.0177s/iter; left time: 192.6149s
Epoch: 14 cost time: 2.2230749130249023
Epoch: 14, Steps: 126 Train Loss: 0.5013 (Forecasting Loss:0.2138 + XiCon Loss:2.8748 x Lambda(0.1)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2714
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5280652
	speed: 0.0179s/iter; left time: 191.9477s
Epoch: 15 cost time: 2.2191312313079834
Epoch: 15, Steps: 126 Train Loss: 0.5016 (Forecasting Loss:0.2139 + XiCon Loss:2.8771 x Lambda(0.1)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2713
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4763547
	speed: 0.0178s/iter; left time: 188.3938s
Epoch: 16 cost time: 2.195234537124634
Epoch: 16, Steps: 126 Train Loss: 0.5016 (Forecasting Loss:0.2139 + XiCon Loss:2.8771 x Lambda(0.1)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2713
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.20107069611549377, mae:0.3602744936943054, mape:0.7164842486381531, mspe:15.663424491882324 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3381
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5982282
	speed: 0.0156s/iter; left time: 195.0978s
Epoch: 1 cost time: 1.9269037246704102
Epoch: 1, Steps: 126 Train Loss: 0.6224 (Forecasting Loss:0.3173 + XiCon Loss:3.0508 x Lambda(0.1)), Vali MSE Loss: 0.3078 Test MSE Loss: 0.2631
Validation loss decreased (inf --> 0.307809).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5520957
	speed: 0.0168s/iter; left time: 207.9508s
Epoch: 2 cost time: 2.054880142211914
Epoch: 2, Steps: 126 Train Loss: 0.5790 (Forecasting Loss:0.2863 + XiCon Loss:2.9268 x Lambda(0.1)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2643
Validation loss decreased (0.307809 --> 0.289978).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5628247
	speed: 0.0161s/iter; left time: 197.6674s
Epoch: 3 cost time: 2.0130114555358887
Epoch: 3, Steps: 126 Train Loss: 0.5604 (Forecasting Loss:0.2638 + XiCon Loss:2.9660 x Lambda(0.1)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2547
Validation loss decreased (0.289978 --> 0.278621).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5552159
	speed: 0.0163s/iter; left time: 197.4438s
Epoch: 4 cost time: 2.027784585952759
Epoch: 4, Steps: 126 Train Loss: 0.5442 (Forecasting Loss:0.2521 + XiCon Loss:2.9208 x Lambda(0.1)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.2571
Validation loss decreased (0.278621 --> 0.265142).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5296860
	speed: 0.0170s/iter; left time: 203.7538s
Epoch: 5 cost time: 2.0942153930664062
Epoch: 5, Steps: 126 Train Loss: 0.5343 (Forecasting Loss:0.2436 + XiCon Loss:2.9075 x Lambda(0.1)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.2595
Validation loss decreased (0.265142 --> 0.259047).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5491201
	speed: 0.0167s/iter; left time: 198.7582s
Epoch: 6 cost time: 2.0705366134643555
Epoch: 6, Steps: 126 Train Loss: 0.5277 (Forecasting Loss:0.2388 + XiCon Loss:2.8891 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2581
Validation loss decreased (0.259047 --> 0.255096).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5117570
	speed: 0.0182s/iter; left time: 213.6542s
Epoch: 7 cost time: 2.232583522796631
Epoch: 7, Steps: 126 Train Loss: 0.5252 (Forecasting Loss:0.2369 + XiCon Loss:2.8823 x Lambda(0.1)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.2618
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4968419
	speed: 0.0173s/iter; left time: 201.4235s
Epoch: 8 cost time: 2.1698496341705322
Epoch: 8, Steps: 126 Train Loss: 0.5236 (Forecasting Loss:0.2352 + XiCon Loss:2.8837 x Lambda(0.1)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.2618
Validation loss decreased (0.255096 --> 0.254580).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5270969
	speed: 0.0172s/iter; left time: 198.0273s
Epoch: 9 cost time: 2.1242904663085938
Epoch: 9, Steps: 126 Train Loss: 0.5228 (Forecasting Loss:0.2340 + XiCon Loss:2.8883 x Lambda(0.1)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.2608
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5323526
	speed: 0.0167s/iter; left time: 189.8144s
Epoch: 10 cost time: 2.087973117828369
Epoch: 10, Steps: 126 Train Loss: 0.5228 (Forecasting Loss:0.2343 + XiCon Loss:2.8848 x Lambda(0.1)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.2618
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5256985
	speed: 0.0171s/iter; left time: 191.8985s
Epoch: 11 cost time: 2.1396501064300537
Epoch: 11, Steps: 126 Train Loss: 0.5226 (Forecasting Loss:0.2340 + XiCon Loss:2.8862 x Lambda(0.1)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.2619
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5735838
	speed: 0.0178s/iter; left time: 198.1214s
Epoch: 12 cost time: 2.2278478145599365
Epoch: 12, Steps: 126 Train Loss: 0.5222 (Forecasting Loss:0.2339 + XiCon Loss:2.8831 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2619
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5459742
	speed: 0.0173s/iter; left time: 190.5559s
Epoch: 13 cost time: 2.1305415630340576
Epoch: 13, Steps: 126 Train Loss: 0.5220 (Forecasting Loss:0.2339 + XiCon Loss:2.8807 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5066074
	speed: 0.0166s/iter; left time: 180.7585s
Epoch: 14 cost time: 2.078683614730835
Epoch: 14, Steps: 126 Train Loss: 0.5224 (Forecasting Loss:0.2338 + XiCon Loss:2.8863 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2619
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5304728
	speed: 0.0179s/iter; left time: 191.9682s
Epoch: 15 cost time: 2.1957552433013916
Epoch: 15, Steps: 126 Train Loss: 0.5221 (Forecasting Loss:0.2336 + XiCon Loss:2.8850 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2619
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5307034
	speed: 0.0168s/iter; left time: 178.7240s
Epoch: 16 cost time: 2.082360029220581
Epoch: 16, Steps: 126 Train Loss: 0.5218 (Forecasting Loss:0.2336 + XiCon Loss:2.8819 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2618
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5472869
	speed: 0.0177s/iter; left time: 185.2510s
Epoch: 17 cost time: 2.174504041671753
Epoch: 17, Steps: 126 Train Loss: 0.5225 (Forecasting Loss:0.2338 + XiCon Loss:2.8877 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.2619
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5043905
	speed: 0.0169s/iter; left time: 174.6639s
Epoch: 18 cost time: 2.085892677307129
Epoch: 18, Steps: 126 Train Loss: 0.5224 (Forecasting Loss:0.2337 + XiCon Loss:2.8865 x Lambda(0.1)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.2619
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1810734122991562, mae:0.3425469398498535, mape:0.818731963634491, mspe:26.073556900024414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2341
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5891709
	speed: 0.0152s/iter; left time: 190.3905s
Epoch: 1 cost time: 1.9346177577972412
Epoch: 1, Steps: 126 Train Loss: 0.6213 (Forecasting Loss:0.3179 + XiCon Loss:3.0345 x Lambda(0.1)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2641
Validation loss decreased (inf --> 0.307851).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5503992
	speed: 0.0169s/iter; left time: 209.3812s
Epoch: 2 cost time: 2.1073827743530273
Epoch: 2, Steps: 126 Train Loss: 0.5755 (Forecasting Loss:0.2868 + XiCon Loss:2.8875 x Lambda(0.1)), Vali MSE Loss: 0.2966 Test MSE Loss: 0.2509
Validation loss decreased (0.307851 --> 0.296598).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5359732
	speed: 0.0168s/iter; left time: 205.7079s
Epoch: 3 cost time: 2.066301107406616
Epoch: 3, Steps: 126 Train Loss: 0.5580 (Forecasting Loss:0.2660 + XiCon Loss:2.9195 x Lambda(0.1)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2472
Validation loss decreased (0.296598 --> 0.290820).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5301318
	speed: 0.0162s/iter; left time: 196.0634s
Epoch: 4 cost time: 2.040501356124878
Epoch: 4, Steps: 126 Train Loss: 0.5530 (Forecasting Loss:0.2572 + XiCon Loss:2.9582 x Lambda(0.1)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2536
Validation loss decreased (0.290820 --> 0.279648).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5349121
	speed: 0.0159s/iter; left time: 191.2092s
Epoch: 5 cost time: 1.9660632610321045
Epoch: 5, Steps: 126 Train Loss: 0.5373 (Forecasting Loss:0.2456 + XiCon Loss:2.9170 x Lambda(0.1)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.2494
Validation loss decreased (0.279648 --> 0.269520).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5293345
	speed: 0.0161s/iter; left time: 190.7620s
Epoch: 6 cost time: 1.9945869445800781
Epoch: 6, Steps: 126 Train Loss: 0.5300 (Forecasting Loss:0.2397 + XiCon Loss:2.9030 x Lambda(0.1)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.2460
Validation loss decreased (0.269520 --> 0.269151).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5335519
	speed: 0.0176s/iter; left time: 207.1551s
Epoch: 7 cost time: 2.1962783336639404
Epoch: 7, Steps: 126 Train Loss: 0.5279 (Forecasting Loss:0.2370 + XiCon Loss:2.9089 x Lambda(0.1)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.2523
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5510076
	speed: 0.0159s/iter; left time: 184.9171s
Epoch: 8 cost time: 1.9868555068969727
Epoch: 8, Steps: 126 Train Loss: 0.5261 (Forecasting Loss:0.2358 + XiCon Loss:2.9027 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2519
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5284685
	speed: 0.0160s/iter; left time: 184.4292s
Epoch: 9 cost time: 2.0215554237365723
Epoch: 9, Steps: 126 Train Loss: 0.5249 (Forecasting Loss:0.2350 + XiCon Loss:2.8987 x Lambda(0.1)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.2520
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5080835
	speed: 0.0167s/iter; left time: 189.4501s
Epoch: 10 cost time: 2.076719045639038
Epoch: 10, Steps: 126 Train Loss: 0.5249 (Forecasting Loss:0.2351 + XiCon Loss:2.8980 x Lambda(0.1)), Vali MSE Loss: 0.2686 Test MSE Loss: 0.2514
Validation loss decreased (0.269151 --> 0.268640).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5519308
	speed: 0.0164s/iter; left time: 184.5557s
Epoch: 11 cost time: 2.0348782539367676
Epoch: 11, Steps: 126 Train Loss: 0.5241 (Forecasting Loss:0.2348 + XiCon Loss:2.8933 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2519
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5079309
	speed: 0.0158s/iter; left time: 175.9294s
Epoch: 12 cost time: 1.957099437713623
Epoch: 12, Steps: 126 Train Loss: 0.5240 (Forecasting Loss:0.2347 + XiCon Loss:2.8926 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2523
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5275551
	speed: 0.0169s/iter; left time: 185.5383s
Epoch: 13 cost time: 2.1031486988067627
Epoch: 13, Steps: 126 Train Loss: 0.5241 (Forecasting Loss:0.2345 + XiCon Loss:2.8958 x Lambda(0.1)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.2520
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5245970
	speed: 0.0164s/iter; left time: 178.0188s
Epoch: 14 cost time: 2.0481722354888916
Epoch: 14, Steps: 126 Train Loss: 0.5249 (Forecasting Loss:0.2350 + XiCon Loss:2.8992 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2520
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5197562
	speed: 0.0172s/iter; left time: 184.3804s
Epoch: 15 cost time: 2.1135494709014893
Epoch: 15, Steps: 126 Train Loss: 0.5246 (Forecasting Loss:0.2348 + XiCon Loss:2.8980 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2520
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5353453
	speed: 0.0166s/iter; left time: 176.2847s
Epoch: 16 cost time: 2.0511927604675293
Epoch: 16, Steps: 126 Train Loss: 0.5236 (Forecasting Loss:0.2342 + XiCon Loss:2.8934 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2520
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5341027
	speed: 0.0161s/iter; left time: 168.5855s
Epoch: 17 cost time: 2.0042996406555176
Epoch: 17, Steps: 126 Train Loss: 0.5247 (Forecasting Loss:0.2346 + XiCon Loss:2.9009 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2520
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5405876
	speed: 0.0158s/iter; left time: 163.2082s
Epoch: 18 cost time: 1.961643934249878
Epoch: 18, Steps: 126 Train Loss: 0.5240 (Forecasting Loss:0.2345 + XiCon Loss:2.8949 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.2520
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5323267
	speed: 0.0162s/iter; left time: 165.4672s
Epoch: 19 cost time: 2.030425548553467
Epoch: 19, Steps: 126 Train Loss: 0.5247 (Forecasting Loss:0.2347 + XiCon Loss:2.8999 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2520
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5254619
	speed: 0.0159s/iter; left time: 160.7562s
Epoch: 20 cost time: 1.971796989440918
Epoch: 20, Steps: 126 Train Loss: 0.5239 (Forecasting Loss:0.2343 + XiCon Loss:2.8961 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2520
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.17100323736667633, mae:0.33181190490722656, mape:0.6844998002052307, mspe:18.32735824584961 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3397
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5655165
	speed: 0.0161s/iter; left time: 201.2109s
Epoch: 1 cost time: 1.9796297550201416
Epoch: 1, Steps: 126 Train Loss: 0.6220 (Forecasting Loss:0.3178 + XiCon Loss:3.0427 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.2669
Validation loss decreased (inf --> 0.308116).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5692859
	speed: 0.0162s/iter; left time: 200.1542s
Epoch: 2 cost time: 1.9832472801208496
Epoch: 2, Steps: 126 Train Loss: 0.5719 (Forecasting Loss:0.2813 + XiCon Loss:2.9059 x Lambda(0.1)), Vali MSE Loss: 0.2998 Test MSE Loss: 0.2595
Validation loss decreased (0.308116 --> 0.299763).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5387781
	speed: 0.0160s/iter; left time: 196.2431s
Epoch: 3 cost time: 1.9813854694366455
Epoch: 3, Steps: 126 Train Loss: 0.5534 (Forecasting Loss:0.2610 + XiCon Loss:2.9244 x Lambda(0.1)), Vali MSE Loss: 0.2811 Test MSE Loss: 0.2593
Validation loss decreased (0.299763 --> 0.281133).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5240048
	speed: 0.0160s/iter; left time: 193.9816s
Epoch: 4 cost time: 1.9941644668579102
Epoch: 4, Steps: 126 Train Loss: 0.5368 (Forecasting Loss:0.2465 + XiCon Loss:2.9035 x Lambda(0.1)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.2522
Validation loss decreased (0.281133 --> 0.259036).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4964170
	speed: 0.0170s/iter; left time: 203.8325s
Epoch: 5 cost time: 2.108901262283325
Epoch: 5, Steps: 126 Train Loss: 0.5259 (Forecasting Loss:0.2375 + XiCon Loss:2.8844 x Lambda(0.1)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.2537
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5035318
	speed: 0.0175s/iter; left time: 207.8733s
Epoch: 6 cost time: 2.178196430206299
Epoch: 6, Steps: 126 Train Loss: 0.5175 (Forecasting Loss:0.2296 + XiCon Loss:2.8787 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.2547
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4939675
	speed: 0.0168s/iter; left time: 197.3725s
Epoch: 7 cost time: 2.075523853302002
Epoch: 7, Steps: 126 Train Loss: 0.5127 (Forecasting Loss:0.2252 + XiCon Loss:2.8749 x Lambda(0.1)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.2558
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5185983
	speed: 0.0166s/iter; left time: 192.6680s
Epoch: 8 cost time: 2.0626254081726074
Epoch: 8, Steps: 126 Train Loss: 0.5117 (Forecasting Loss:0.2246 + XiCon Loss:2.8708 x Lambda(0.1)), Vali MSE Loss: 0.2684 Test MSE Loss: 0.2553
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5097995
	speed: 0.0171s/iter; left time: 197.0828s
Epoch: 9 cost time: 2.1276330947875977
Epoch: 9, Steps: 126 Train Loss: 0.5101 (Forecasting Loss:0.2237 + XiCon Loss:2.8645 x Lambda(0.1)), Vali MSE Loss: 0.2689 Test MSE Loss: 0.2544
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5114626
	speed: 0.0173s/iter; left time: 196.3666s
Epoch: 10 cost time: 2.1213979721069336
Epoch: 10, Steps: 126 Train Loss: 0.5102 (Forecasting Loss:0.2230 + XiCon Loss:2.8725 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.2544
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5119454
	speed: 0.0169s/iter; left time: 189.9595s
Epoch: 11 cost time: 2.085784435272217
Epoch: 11, Steps: 126 Train Loss: 0.5101 (Forecasting Loss:0.2231 + XiCon Loss:2.8701 x Lambda(0.1)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.2552
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5128314
	speed: 0.0172s/iter; left time: 190.9712s
Epoch: 12 cost time: 2.1202988624572754
Epoch: 12, Steps: 126 Train Loss: 0.5097 (Forecasting Loss:0.2228 + XiCon Loss:2.8698 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.2548
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5050162
	speed: 0.0169s/iter; left time: 185.7274s
Epoch: 13 cost time: 2.1407597064971924
Epoch: 13, Steps: 126 Train Loss: 0.5101 (Forecasting Loss:0.2227 + XiCon Loss:2.8735 x Lambda(0.1)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.2549
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5261223
	speed: 0.0171s/iter; left time: 186.1098s
Epoch: 14 cost time: 2.1053295135498047
Epoch: 14, Steps: 126 Train Loss: 0.5102 (Forecasting Loss:0.2230 + XiCon Loss:2.8715 x Lambda(0.1)), Vali MSE Loss: 0.2689 Test MSE Loss: 0.2550
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1720968335866928, mae:0.3322516679763794, mape:0.7039996981620789, mspe:20.236818313598633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3220
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.5964885
	speed: 0.0156s/iter; left time: 194.7117s
Epoch: 1 cost time: 1.9331891536712646
Epoch: 1, Steps: 126 Train Loss: 0.6214 (Forecasting Loss:0.3177 + XiCon Loss:3.0365 x Lambda(0.1)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.2640
Validation loss decreased (inf --> 0.307502).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5540520
	speed: 0.0166s/iter; left time: 205.7236s
Epoch: 2 cost time: 2.0908732414245605
Epoch: 2, Steps: 126 Train Loss: 0.5733 (Forecasting Loss:0.2762 + XiCon Loss:2.9711 x Lambda(0.1)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2748
Validation loss decreased (0.307502 --> 0.289168).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5512503
	speed: 0.0177s/iter; left time: 216.4873s
Epoch: 3 cost time: 2.186678886413574
Epoch: 3, Steps: 126 Train Loss: 0.5479 (Forecasting Loss:0.2481 + XiCon Loss:2.9982 x Lambda(0.1)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.2738
Validation loss decreased (0.289168 --> 0.263460).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5490401
	speed: 0.0181s/iter; left time: 218.9453s
Epoch: 4 cost time: 2.2280924320220947
Epoch: 4, Steps: 126 Train Loss: 0.5317 (Forecasting Loss:0.2353 + XiCon Loss:2.9645 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.2749
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5305686
	speed: 0.0173s/iter; left time: 207.9028s
Epoch: 5 cost time: 2.1402289867401123
Epoch: 5, Steps: 126 Train Loss: 0.5233 (Forecasting Loss:0.2288 + XiCon Loss:2.9450 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5294471
	speed: 0.0173s/iter; left time: 205.7855s
Epoch: 6 cost time: 2.1921908855438232
Epoch: 6, Steps: 126 Train Loss: 0.5195 (Forecasting Loss:0.2262 + XiCon Loss:2.9330 x Lambda(0.1)), Vali MSE Loss: 0.2721 Test MSE Loss: 0.2776
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5095197
	speed: 0.0170s/iter; left time: 199.9624s
Epoch: 7 cost time: 2.121680736541748
Epoch: 7, Steps: 126 Train Loss: 0.5180 (Forecasting Loss:0.2252 + XiCon Loss:2.9277 x Lambda(0.1)), Vali MSE Loss: 0.2683 Test MSE Loss: 0.2842
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4996203
	speed: 0.0182s/iter; left time: 211.5465s
Epoch: 8 cost time: 2.253791570663452
Epoch: 8, Steps: 126 Train Loss: 0.5167 (Forecasting Loss:0.2246 + XiCon Loss:2.9217 x Lambda(0.1)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2864
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5291126
	speed: 0.0175s/iter; left time: 200.7559s
Epoch: 9 cost time: 2.143284320831299
Epoch: 9, Steps: 126 Train Loss: 0.5173 (Forecasting Loss:0.2242 + XiCon Loss:2.9317 x Lambda(0.1)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.2875
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5099431
	speed: 0.0176s/iter; left time: 200.3477s
Epoch: 10 cost time: 2.1836509704589844
Epoch: 10, Steps: 126 Train Loss: 0.5160 (Forecasting Loss:0.2239 + XiCon Loss:2.9206 x Lambda(0.1)), Vali MSE Loss: 0.2721 Test MSE Loss: 0.2876
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5254039
	speed: 0.0180s/iter; left time: 202.5223s
Epoch: 11 cost time: 2.232839345932007
Epoch: 11, Steps: 126 Train Loss: 0.5163 (Forecasting Loss:0.2238 + XiCon Loss:2.9250 x Lambda(0.1)), Vali MSE Loss: 0.2721 Test MSE Loss: 0.2863
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5120230
	speed: 0.0177s/iter; left time: 196.6999s
Epoch: 12 cost time: 2.199817419052124
Epoch: 12, Steps: 126 Train Loss: 0.5157 (Forecasting Loss:0.2238 + XiCon Loss:2.9188 x Lambda(0.1)), Vali MSE Loss: 0.2721 Test MSE Loss: 0.2864
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5239561
	speed: 0.0176s/iter; left time: 193.9168s
Epoch: 13 cost time: 2.1933817863464355
Epoch: 13, Steps: 126 Train Loss: 0.5164 (Forecasting Loss:0.2237 + XiCon Loss:2.9272 x Lambda(0.1)), Vali MSE Loss: 0.2722 Test MSE Loss: 0.2867
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.19702640175819397, mae:0.35047391057014465, mape:0.7247492671012878, mspe:22.16322135925293 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1845+-0.01733, MAE:0.3435+-0.01513, MAPE:0.7297+-0.06461, MSPE:20.4929+-4.88894, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3838
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6079409
	speed: 0.0215s/iter; left time: 264.7849s
Epoch: 1 cost time: 2.5529818534851074
Epoch: 1, Steps: 124 Train Loss: 0.6431 (Forecasting Loss:0.3406 + XiCon Loss:3.0253 x Lambda(0.1)), Vali MSE Loss: 0.3441 Test MSE Loss: 0.2894
Validation loss decreased (inf --> 0.344051).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5462815
	speed: 0.0173s/iter; left time: 210.8610s
Epoch: 2 cost time: 2.199293613433838
Epoch: 2, Steps: 124 Train Loss: 0.5720 (Forecasting Loss:0.2825 + XiCon Loss:2.8946 x Lambda(0.1)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.3105
Validation loss decreased (0.344051 --> 0.300568).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5395445
	speed: 0.0220s/iter; left time: 264.9636s
Epoch: 3 cost time: 2.695279598236084
Epoch: 3, Steps: 124 Train Loss: 0.5477 (Forecasting Loss:0.2494 + XiCon Loss:2.9825 x Lambda(0.1)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.2783
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5483886
	speed: 0.0215s/iter; left time: 256.6066s
Epoch: 4 cost time: 2.6286330223083496
Epoch: 4, Steps: 124 Train Loss: 0.5377 (Forecasting Loss:0.2361 + XiCon Loss:3.0161 x Lambda(0.1)), Vali MSE Loss: 0.3104 Test MSE Loss: 0.2871
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5205801
	speed: 0.0216s/iter; left time: 255.1645s
Epoch: 5 cost time: 2.6480824947357178
Epoch: 5, Steps: 124 Train Loss: 0.5292 (Forecasting Loss:0.2268 + XiCon Loss:3.0238 x Lambda(0.1)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2902
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5256438
	speed: 0.0215s/iter; left time: 251.5634s
Epoch: 6 cost time: 2.6308794021606445
Epoch: 6, Steps: 124 Train Loss: 0.5245 (Forecasting Loss:0.2233 + XiCon Loss:3.0114 x Lambda(0.1)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.2812
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5134009
	speed: 0.0221s/iter; left time: 255.7148s
Epoch: 7 cost time: 2.7022507190704346
Epoch: 7, Steps: 124 Train Loss: 0.5229 (Forecasting Loss:0.2217 + XiCon Loss:3.0124 x Lambda(0.1)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3002
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5047810
	speed: 0.0214s/iter; left time: 244.3106s
Epoch: 8 cost time: 2.624289035797119
Epoch: 8, Steps: 124 Train Loss: 0.5216 (Forecasting Loss:0.2205 + XiCon Loss:3.0116 x Lambda(0.1)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2992
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5180466
	speed: 0.0220s/iter; left time: 248.5225s
Epoch: 9 cost time: 2.6727185249328613
Epoch: 9, Steps: 124 Train Loss: 0.5223 (Forecasting Loss:0.2199 + XiCon Loss:3.0240 x Lambda(0.1)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.3030
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5210500
	speed: 0.0209s/iter; left time: 233.7931s
Epoch: 10 cost time: 2.5618350505828857
Epoch: 10, Steps: 124 Train Loss: 0.5222 (Forecasting Loss:0.2199 + XiCon Loss:3.0234 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.3016
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5409501
	speed: 0.0220s/iter; left time: 243.3176s
Epoch: 11 cost time: 2.693223714828491
Epoch: 11, Steps: 124 Train Loss: 0.5213 (Forecasting Loss:0.2198 + XiCon Loss:3.0148 x Lambda(0.1)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2993
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4965420
	speed: 0.0213s/iter; left time: 233.1319s
Epoch: 12 cost time: 2.6314573287963867
Epoch: 12, Steps: 124 Train Loss: 0.5223 (Forecasting Loss:0.2198 + XiCon Loss:3.0254 x Lambda(0.1)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2998
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.2348395437002182, mae:0.38615694642066956, mape:0.7450145483016968, mspe:18.692550659179688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4189
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6327993
	speed: 0.0177s/iter; left time: 217.3294s
Epoch: 1 cost time: 2.1744680404663086
Epoch: 1, Steps: 124 Train Loss: 0.6397 (Forecasting Loss:0.3375 + XiCon Loss:3.0213 x Lambda(0.1)), Vali MSE Loss: 0.3413 Test MSE Loss: 0.2854
Validation loss decreased (inf --> 0.341283).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5551602
	speed: 0.0171s/iter; left time: 207.6701s
Epoch: 2 cost time: 2.077406883239746
Epoch: 2, Steps: 124 Train Loss: 0.5889 (Forecasting Loss:0.2993 + XiCon Loss:2.8958 x Lambda(0.1)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.3008
Validation loss decreased (0.341283 --> 0.316964).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5154229
	speed: 0.0170s/iter; left time: 205.2391s
Epoch: 3 cost time: 2.111963987350464
Epoch: 3, Steps: 124 Train Loss: 0.5561 (Forecasting Loss:0.2678 + XiCon Loss:2.8826 x Lambda(0.1)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2620
Validation loss decreased (0.316964 --> 0.306633).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5299082
	speed: 0.0180s/iter; left time: 214.4861s
Epoch: 4 cost time: 2.164980888366699
Epoch: 4, Steps: 124 Train Loss: 0.5445 (Forecasting Loss:0.2477 + XiCon Loss:2.9678 x Lambda(0.1)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5283427
	speed: 0.0174s/iter; left time: 205.7671s
Epoch: 5 cost time: 2.122175931930542
Epoch: 5, Steps: 124 Train Loss: 0.5387 (Forecasting Loss:0.2402 + XiCon Loss:2.9855 x Lambda(0.1)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.2723
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5216322
	speed: 0.0176s/iter; left time: 205.7733s
Epoch: 6 cost time: 2.1553750038146973
Epoch: 6, Steps: 124 Train Loss: 0.5365 (Forecasting Loss:0.2375 + XiCon Loss:2.9893 x Lambda(0.1)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.2663
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5249363
	speed: 0.0175s/iter; left time: 201.9030s
Epoch: 7 cost time: 2.1641499996185303
Epoch: 7, Steps: 124 Train Loss: 0.5362 (Forecasting Loss:0.2355 + XiCon Loss:3.0070 x Lambda(0.1)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.2609
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5124556
	speed: 0.0176s/iter; left time: 201.4606s
Epoch: 8 cost time: 2.1343493461608887
Epoch: 8, Steps: 124 Train Loss: 0.5343 (Forecasting Loss:0.2343 + XiCon Loss:2.9993 x Lambda(0.1)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2617
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5269932
	speed: 0.0174s/iter; left time: 196.4825s
Epoch: 9 cost time: 2.155668258666992
Epoch: 9, Steps: 124 Train Loss: 0.5340 (Forecasting Loss:0.2340 + XiCon Loss:3.0001 x Lambda(0.1)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.2614
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5290612
	speed: 0.0181s/iter; left time: 202.7933s
Epoch: 10 cost time: 2.201711893081665
Epoch: 10, Steps: 124 Train Loss: 0.5338 (Forecasting Loss:0.2335 + XiCon Loss:3.0038 x Lambda(0.1)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2609
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5611166
	speed: 0.0170s/iter; left time: 188.3492s
Epoch: 11 cost time: 2.0936031341552734
Epoch: 11, Steps: 124 Train Loss: 0.5335 (Forecasting Loss:0.2329 + XiCon Loss:3.0060 x Lambda(0.1)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2601
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5538150
	speed: 0.0169s/iter; left time: 184.4212s
Epoch: 12 cost time: 2.0693016052246094
Epoch: 12, Steps: 124 Train Loss: 0.5349 (Forecasting Loss:0.2332 + XiCon Loss:3.0167 x Lambda(0.1)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.2605
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5662291
	speed: 0.0173s/iter; left time: 187.2554s
Epoch: 13 cost time: 2.104149103164673
Epoch: 13, Steps: 124 Train Loss: 0.5338 (Forecasting Loss:0.2330 + XiCon Loss:3.0077 x Lambda(0.1)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2609
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18019399046897888, mae:0.34385818243026733, mape:0.7006855607032776, mspe:16.492874145507812 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3682
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6170864
	speed: 0.0176s/iter; left time: 216.6200s
Epoch: 1 cost time: 2.1673901081085205
Epoch: 1, Steps: 124 Train Loss: 0.6378 (Forecasting Loss:0.3372 + XiCon Loss:3.0060 x Lambda(0.1)), Vali MSE Loss: 0.3440 Test MSE Loss: 0.2837
Validation loss decreased (inf --> 0.344000).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5746570
	speed: 0.0183s/iter; left time: 222.2329s
Epoch: 2 cost time: 2.2617435455322266
Epoch: 2, Steps: 124 Train Loss: 0.5825 (Forecasting Loss:0.2949 + XiCon Loss:2.8759 x Lambda(0.1)), Vali MSE Loss: 0.2961 Test MSE Loss: 0.2643
Validation loss decreased (0.344000 --> 0.296104).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5661216
	speed: 0.0205s/iter; left time: 246.8772s
Epoch: 3 cost time: 2.510458469390869
Epoch: 3, Steps: 124 Train Loss: 0.5460 (Forecasting Loss:0.2558 + XiCon Loss:2.9020 x Lambda(0.1)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2657
Validation loss decreased (0.296104 --> 0.283847).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5403172
	speed: 0.0196s/iter; left time: 233.8577s
Epoch: 4 cost time: 2.4492199420928955
Epoch: 4, Steps: 124 Train Loss: 0.5432 (Forecasting Loss:0.2433 + XiCon Loss:2.9989 x Lambda(0.1)), Vali MSE Loss: 0.2774 Test MSE Loss: 0.2673
Validation loss decreased (0.283847 --> 0.277427).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5061373
	speed: 0.0195s/iter; left time: 230.5936s
Epoch: 5 cost time: 2.4333770275115967
Epoch: 5, Steps: 124 Train Loss: 0.5375 (Forecasting Loss:0.2351 + XiCon Loss:3.0250 x Lambda(0.1)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.2703
Validation loss decreased (0.277427 --> 0.269162).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5477245
	speed: 0.0198s/iter; left time: 231.0584s
Epoch: 6 cost time: 2.4147801399230957
Epoch: 6, Steps: 124 Train Loss: 0.5328 (Forecasting Loss:0.2304 + XiCon Loss:3.0239 x Lambda(0.1)), Vali MSE Loss: 0.2762 Test MSE Loss: 0.2607
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5093219
	speed: 0.0199s/iter; left time: 230.2188s
Epoch: 7 cost time: 2.438448429107666
Epoch: 7, Steps: 124 Train Loss: 0.5296 (Forecasting Loss:0.2279 + XiCon Loss:3.0174 x Lambda(0.1)), Vali MSE Loss: 0.2755 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5024762
	speed: 0.0200s/iter; left time: 228.3093s
Epoch: 8 cost time: 2.420475482940674
Epoch: 8, Steps: 124 Train Loss: 0.5293 (Forecasting Loss:0.2264 + XiCon Loss:3.0290 x Lambda(0.1)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5268984
	speed: 0.0196s/iter; left time: 222.2001s
Epoch: 9 cost time: 2.405291795730591
Epoch: 9, Steps: 124 Train Loss: 0.5269 (Forecasting Loss:0.2260 + XiCon Loss:3.0089 x Lambda(0.1)), Vali MSE Loss: 0.2738 Test MSE Loss: 0.2640
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5600144
	speed: 0.0195s/iter; left time: 218.3084s
Epoch: 10 cost time: 2.4183743000030518
Epoch: 10, Steps: 124 Train Loss: 0.5287 (Forecasting Loss:0.2257 + XiCon Loss:3.0297 x Lambda(0.1)), Vali MSE Loss: 0.2732 Test MSE Loss: 0.2640
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5348306
	speed: 0.0199s/iter; left time: 220.1065s
Epoch: 11 cost time: 2.4624881744384766
Epoch: 11, Steps: 124 Train Loss: 0.5277 (Forecasting Loss:0.2255 + XiCon Loss:3.0221 x Lambda(0.1)), Vali MSE Loss: 0.2737 Test MSE Loss: 0.2640
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5063771
	speed: 0.0200s/iter; left time: 219.0686s
Epoch: 12 cost time: 2.4661848545074463
Epoch: 12, Steps: 124 Train Loss: 0.5283 (Forecasting Loss:0.2259 + XiCon Loss:3.0247 x Lambda(0.1)), Vali MSE Loss: 0.2740 Test MSE Loss: 0.2642
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5278053
	speed: 0.0200s/iter; left time: 216.6926s
Epoch: 13 cost time: 2.4449987411499023
Epoch: 13, Steps: 124 Train Loss: 0.5273 (Forecasting Loss:0.2256 + XiCon Loss:3.0170 x Lambda(0.1)), Vali MSE Loss: 0.2732 Test MSE Loss: 0.2647
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5253764
	speed: 0.0200s/iter; left time: 214.2012s
Epoch: 14 cost time: 2.4525606632232666
Epoch: 14, Steps: 124 Train Loss: 0.5282 (Forecasting Loss:0.2257 + XiCon Loss:3.0248 x Lambda(0.1)), Vali MSE Loss: 0.2738 Test MSE Loss: 0.2647
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5384833
	speed: 0.0197s/iter; left time: 208.2346s
Epoch: 15 cost time: 2.4314372539520264
Epoch: 15, Steps: 124 Train Loss: 0.5265 (Forecasting Loss:0.2251 + XiCon Loss:3.0138 x Lambda(0.1)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.2646
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18652454018592834, mae:0.3540521562099457, mape:0.7871421575546265, mspe:22.129364013671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3249
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.5874953
	speed: 0.0177s/iter; left time: 217.5573s
Epoch: 1 cost time: 2.1409754753112793
Epoch: 1, Steps: 124 Train Loss: 0.6384 (Forecasting Loss:0.3350 + XiCon Loss:3.0331 x Lambda(0.1)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.2735
Validation loss decreased (inf --> 0.331169).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5813838
	speed: 0.0164s/iter; left time: 199.8322s
Epoch: 2 cost time: 2.050366163253784
Epoch: 2, Steps: 124 Train Loss: 0.5879 (Forecasting Loss:0.2946 + XiCon Loss:2.9326 x Lambda(0.1)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.3202
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5747445
	speed: 0.0178s/iter; left time: 214.6103s
Epoch: 3 cost time: 2.147228240966797
Epoch: 3, Steps: 124 Train Loss: 0.5474 (Forecasting Loss:0.2611 + XiCon Loss:2.8629 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.2811
Validation loss decreased (0.331169 --> 0.301370).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5363300
	speed: 0.0168s/iter; left time: 200.1436s
Epoch: 4 cost time: 2.063865900039673
Epoch: 4, Steps: 124 Train Loss: 0.5362 (Forecasting Loss:0.2422 + XiCon Loss:2.9399 x Lambda(0.1)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2627
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5159906
	speed: 0.0168s/iter; left time: 197.9181s
Epoch: 5 cost time: 2.0477423667907715
Epoch: 5, Steps: 124 Train Loss: 0.5325 (Forecasting Loss:0.2351 + XiCon Loss:2.9739 x Lambda(0.1)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2588
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5163237
	speed: 0.0177s/iter; left time: 206.5102s
Epoch: 6 cost time: 2.138289451599121
Epoch: 6, Steps: 124 Train Loss: 0.5300 (Forecasting Loss:0.2311 + XiCon Loss:2.9888 x Lambda(0.1)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.2620
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5041678
	speed: 0.0170s/iter; left time: 196.5039s
Epoch: 7 cost time: 2.0995640754699707
Epoch: 7, Steps: 124 Train Loss: 0.5284 (Forecasting Loss:0.2289 + XiCon Loss:2.9954 x Lambda(0.1)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.2611
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5254911
	speed: 0.0174s/iter; left time: 198.6843s
Epoch: 8 cost time: 2.1582374572753906
Epoch: 8, Steps: 124 Train Loss: 0.5273 (Forecasting Loss:0.2278 + XiCon Loss:2.9940 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2587
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5442785
	speed: 0.0168s/iter; left time: 189.4412s
Epoch: 9 cost time: 2.080240488052368
Epoch: 9, Steps: 124 Train Loss: 0.5268 (Forecasting Loss:0.2274 + XiCon Loss:2.9942 x Lambda(0.1)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2584
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5483853
	speed: 0.0176s/iter; left time: 197.1849s
Epoch: 10 cost time: 2.1376445293426514
Epoch: 10, Steps: 124 Train Loss: 0.5272 (Forecasting Loss:0.2271 + XiCon Loss:3.0005 x Lambda(0.1)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.2589
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5414215
	speed: 0.0174s/iter; left time: 191.9550s
Epoch: 11 cost time: 2.1087136268615723
Epoch: 11, Steps: 124 Train Loss: 0.5267 (Forecasting Loss:0.2267 + XiCon Loss:2.9998 x Lambda(0.1)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.2599
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5155309
	speed: 0.0171s/iter; left time: 187.0931s
Epoch: 12 cost time: 2.0956130027770996
Epoch: 12, Steps: 124 Train Loss: 0.5275 (Forecasting Loss:0.2267 + XiCon Loss:3.0078 x Lambda(0.1)), Vali MSE Loss: 0.3268 Test MSE Loss: 0.2595
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5298952
	speed: 0.0168s/iter; left time: 181.8746s
Epoch: 13 cost time: 2.06402850151062
Epoch: 13, Steps: 124 Train Loss: 0.5270 (Forecasting Loss:0.2268 + XiCon Loss:3.0019 x Lambda(0.1)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2597
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19895584881305695, mae:0.3632735013961792, mape:0.6357330083847046, mspe:11.674217224121094 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3931
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.6502794
	speed: 0.0169s/iter; left time: 207.8089s
Epoch: 1 cost time: 2.063410997390747
Epoch: 1, Steps: 124 Train Loss: 0.6422 (Forecasting Loss:0.3367 + XiCon Loss:3.0546 x Lambda(0.1)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2888
Validation loss decreased (inf --> 0.344812).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5921183
	speed: 0.0177s/iter; left time: 215.8851s
Epoch: 2 cost time: 2.1550850868225098
Epoch: 2, Steps: 124 Train Loss: 0.5894 (Forecasting Loss:0.2923 + XiCon Loss:2.9716 x Lambda(0.1)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2771
Validation loss decreased (0.344812 --> 0.326730).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5290152
	speed: 0.0196s/iter; left time: 236.1475s
Epoch: 3 cost time: 2.4017114639282227
Epoch: 3, Steps: 124 Train Loss: 0.5701 (Forecasting Loss:0.2613 + XiCon Loss:3.0880 x Lambda(0.1)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.2896
Validation loss decreased (0.326730 --> 0.298912).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5270036
	speed: 0.0202s/iter; left time: 240.7027s
Epoch: 4 cost time: 2.4628403186798096
Epoch: 4, Steps: 124 Train Loss: 0.5511 (Forecasting Loss:0.2453 + XiCon Loss:3.0583 x Lambda(0.1)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.2706
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5597898
	speed: 0.0200s/iter; left time: 236.1975s
Epoch: 5 cost time: 2.462233304977417
Epoch: 5, Steps: 124 Train Loss: 0.5441 (Forecasting Loss:0.2386 + XiCon Loss:3.0555 x Lambda(0.1)), Vali MSE Loss: 0.2843 Test MSE Loss: 0.2674
Validation loss decreased (0.298912 --> 0.284299).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5339684
	speed: 0.0200s/iter; left time: 233.4770s
Epoch: 6 cost time: 2.4332733154296875
Epoch: 6, Steps: 124 Train Loss: 0.5375 (Forecasting Loss:0.2341 + XiCon Loss:3.0338 x Lambda(0.1)), Vali MSE Loss: 0.2803 Test MSE Loss: 0.2658
Validation loss decreased (0.284299 --> 0.280279).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5217087
	speed: 0.0201s/iter; left time: 232.0212s
Epoch: 7 cost time: 2.44389271736145
Epoch: 7, Steps: 124 Train Loss: 0.5344 (Forecasting Loss:0.2323 + XiCon Loss:3.0209 x Lambda(0.1)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5344364
	speed: 0.0206s/iter; left time: 235.9402s
Epoch: 8 cost time: 2.480038642883301
Epoch: 8, Steps: 124 Train Loss: 0.5343 (Forecasting Loss:0.2311 + XiCon Loss:3.0319 x Lambda(0.1)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.2691
Validation loss decreased (0.280279 --> 0.275689).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5305067
	speed: 0.0202s/iter; left time: 228.7340s
Epoch: 9 cost time: 2.462947368621826
Epoch: 9, Steps: 124 Train Loss: 0.5346 (Forecasting Loss:0.2308 + XiCon Loss:3.0387 x Lambda(0.1)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.2691
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5281236
	speed: 0.0205s/iter; left time: 229.4242s
Epoch: 10 cost time: 2.514683723449707
Epoch: 10, Steps: 124 Train Loss: 0.5330 (Forecasting Loss:0.2307 + XiCon Loss:3.0237 x Lambda(0.1)), Vali MSE Loss: 0.2783 Test MSE Loss: 0.2679
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5361373
	speed: 0.0204s/iter; left time: 225.9318s
Epoch: 11 cost time: 2.500343084335327
Epoch: 11, Steps: 124 Train Loss: 0.5346 (Forecasting Loss:0.2303 + XiCon Loss:3.0430 x Lambda(0.1)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2685
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5291345
	speed: 0.0205s/iter; left time: 223.8650s
Epoch: 12 cost time: 2.4845714569091797
Epoch: 12, Steps: 124 Train Loss: 0.5326 (Forecasting Loss:0.2302 + XiCon Loss:3.0241 x Lambda(0.1)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2685
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5648381
	speed: 0.0204s/iter; left time: 220.8921s
Epoch: 13 cost time: 2.4956696033477783
Epoch: 13, Steps: 124 Train Loss: 0.5336 (Forecasting Loss:0.2302 + XiCon Loss:3.0338 x Lambda(0.1)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.2685
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5491974
	speed: 0.0200s/iter; left time: 213.5623s
Epoch: 14 cost time: 2.4485116004943848
Epoch: 14, Steps: 124 Train Loss: 0.5355 (Forecasting Loss:0.2303 + XiCon Loss:3.0517 x Lambda(0.1)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5288867
	speed: 0.0199s/iter; left time: 210.3090s
Epoch: 15 cost time: 2.4661688804626465
Epoch: 15, Steps: 124 Train Loss: 0.5341 (Forecasting Loss:0.2302 + XiCon Loss:3.0389 x Lambda(0.1)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2684
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5232418
	speed: 0.0201s/iter; left time: 209.5921s
Epoch: 16 cost time: 2.4423298835754395
Epoch: 16, Steps: 124 Train Loss: 0.5347 (Forecasting Loss:0.2303 + XiCon Loss:3.0441 x Lambda(0.1)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2684
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5521556
	speed: 0.0204s/iter; left time: 210.6595s
Epoch: 17 cost time: 2.509371042251587
Epoch: 17, Steps: 124 Train Loss: 0.5349 (Forecasting Loss:0.2301 + XiCon Loss:3.0483 x Lambda(0.1)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2684
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5237544
	speed: 0.0202s/iter; left time: 206.3504s
Epoch: 18 cost time: 2.502049446105957
Epoch: 18, Steps: 124 Train Loss: 0.5326 (Forecasting Loss:0.2300 + XiCon Loss:3.0263 x Lambda(0.1)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18626248836517334, mae:0.3519364595413208, mape:0.7239029407501221, mspe:19.037555694580078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1974+-0.02736, MAE:0.3599+-0.02017, MAPE:0.7185+-0.06972, MSPE:17.6053+-4.81358, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3793
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7675981
	speed: 0.0214s/iter; left time: 250.0226s
Epoch: 1 cost time: 2.4244208335876465
Epoch: 1, Steps: 118 Train Loss: 0.7885 (Forecasting Loss:0.4738 + XiCon Loss:3.1470 x Lambda(0.1)), Vali MSE Loss: 0.4777 Test MSE Loss: 0.3637
Validation loss decreased (inf --> 0.477708).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6760428
	speed: 0.0175s/iter; left time: 202.8612s
Epoch: 2 cost time: 2.052332878112793
Epoch: 2, Steps: 118 Train Loss: 0.6582 (Forecasting Loss:0.3476 + XiCon Loss:3.1064 x Lambda(0.1)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2900
Validation loss decreased (0.477708 --> 0.374917).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6105981
	speed: 0.0171s/iter; left time: 195.5547s
Epoch: 3 cost time: 2.0249834060668945
Epoch: 3, Steps: 118 Train Loss: 0.6178 (Forecasting Loss:0.3103 + XiCon Loss:3.0755 x Lambda(0.1)), Vali MSE Loss: 0.3741 Test MSE Loss: 0.2830
Validation loss decreased (0.374917 --> 0.374104).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.6194410
	speed: 0.0175s/iter; left time: 198.7953s
Epoch: 4 cost time: 2.037973403930664
Epoch: 4, Steps: 118 Train Loss: 0.6115 (Forecasting Loss:0.3054 + XiCon Loss:3.0609 x Lambda(0.1)), Vali MSE Loss: 0.3750 Test MSE Loss: 0.2853
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6140201
	speed: 0.0174s/iter; left time: 194.9531s
Epoch: 5 cost time: 2.0304391384124756
Epoch: 5, Steps: 118 Train Loss: 0.6087 (Forecasting Loss:0.3033 + XiCon Loss:3.0533 x Lambda(0.1)), Vali MSE Loss: 0.3824 Test MSE Loss: 0.2858
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5906497
	speed: 0.0172s/iter; left time: 190.8368s
Epoch: 6 cost time: 2.0139753818511963
Epoch: 6, Steps: 118 Train Loss: 0.6074 (Forecasting Loss:0.3022 + XiCon Loss:3.0527 x Lambda(0.1)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.2853
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.6076314
	speed: 0.0178s/iter; left time: 195.2506s
Epoch: 7 cost time: 2.0740652084350586
Epoch: 7, Steps: 118 Train Loss: 0.6072 (Forecasting Loss:0.3023 + XiCon Loss:3.0487 x Lambda(0.1)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2859
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.5908390
	speed: 0.0178s/iter; left time: 193.9643s
Epoch: 8 cost time: 2.0780646800994873
Epoch: 8, Steps: 118 Train Loss: 0.6063 (Forecasting Loss:0.3014 + XiCon Loss:3.0492 x Lambda(0.1)), Vali MSE Loss: 0.3744 Test MSE Loss: 0.2861
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.6049746
	speed: 0.0178s/iter; left time: 191.4054s
Epoch: 9 cost time: 2.078918695449829
Epoch: 9, Steps: 118 Train Loss: 0.6066 (Forecasting Loss:0.3016 + XiCon Loss:3.0491 x Lambda(0.1)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2859
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.6078078
	speed: 0.0182s/iter; left time: 193.4004s
Epoch: 10 cost time: 2.1295533180236816
Epoch: 10, Steps: 118 Train Loss: 0.6064 (Forecasting Loss:0.3015 + XiCon Loss:3.0490 x Lambda(0.1)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.2861
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.5979024
	speed: 0.0179s/iter; left time: 188.2319s
Epoch: 11 cost time: 2.0764570236206055
Epoch: 11, Steps: 118 Train Loss: 0.6064 (Forecasting Loss:0.3015 + XiCon Loss:3.0486 x Lambda(0.1)), Vali MSE Loss: 0.3754 Test MSE Loss: 0.2861
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.6163513
	speed: 0.0173s/iter; left time: 180.0785s
Epoch: 12 cost time: 2.032170534133911
Epoch: 12, Steps: 118 Train Loss: 0.6065 (Forecasting Loss:0.3015 + XiCon Loss:3.0498 x Lambda(0.1)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2861
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.5963385
	speed: 0.0174s/iter; left time: 178.5372s
Epoch: 13 cost time: 2.0375113487243652
Epoch: 13, Steps: 118 Train Loss: 0.6062 (Forecasting Loss:0.3015 + XiCon Loss:3.0467 x Lambda(0.1)), Vali MSE Loss: 0.3758 Test MSE Loss: 0.2861
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2034551501274109, mae:0.36261671781539917, mape:0.7003566026687622, mspe:23.54561424255371 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3166
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7481678
	speed: 0.0177s/iter; left time: 207.6203s
Epoch: 1 cost time: 2.0705244541168213
Epoch: 1, Steps: 118 Train Loss: 0.7841 (Forecasting Loss:0.4687 + XiCon Loss:3.1540 x Lambda(0.1)), Vali MSE Loss: 0.4900 Test MSE Loss: 0.3778
Validation loss decreased (inf --> 0.490016).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6076913
	speed: 0.0181s/iter; left time: 209.8675s
Epoch: 2 cost time: 2.1803507804870605
Epoch: 2, Steps: 118 Train Loss: 0.6553 (Forecasting Loss:0.3475 + XiCon Loss:3.0781 x Lambda(0.1)), Vali MSE Loss: 0.3498 Test MSE Loss: 0.2795
Validation loss decreased (0.490016 --> 0.349770).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.5805125
	speed: 0.0206s/iter; left time: 236.6512s
Epoch: 3 cost time: 2.4374711513519287
Epoch: 3, Steps: 118 Train Loss: 0.5797 (Forecasting Loss:0.2786 + XiCon Loss:3.0106 x Lambda(0.1)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.2791
Validation loss decreased (0.349770 --> 0.328174).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5462888
	speed: 0.0212s/iter; left time: 240.7136s
Epoch: 4 cost time: 2.4824135303497314
Epoch: 4, Steps: 118 Train Loss: 0.5640 (Forecasting Loss:0.2651 + XiCon Loss:2.9889 x Lambda(0.1)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2837
Validation loss decreased (0.328174 --> 0.320485).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5604118
	speed: 0.0218s/iter; left time: 244.8396s
Epoch: 5 cost time: 2.5312020778656006
Epoch: 5, Steps: 118 Train Loss: 0.5589 (Forecasting Loss:0.2609 + XiCon Loss:2.9799 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2853
Validation loss decreased (0.320485 --> 0.320128).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5463582
	speed: 0.0216s/iter; left time: 240.1477s
Epoch: 6 cost time: 2.5174400806427
Epoch: 6, Steps: 118 Train Loss: 0.5565 (Forecasting Loss:0.2590 + XiCon Loss:2.9755 x Lambda(0.1)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2852
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5612807
	speed: 0.0217s/iter; left time: 238.8827s
Epoch: 7 cost time: 2.523650646209717
Epoch: 7, Steps: 118 Train Loss: 0.5553 (Forecasting Loss:0.2580 + XiCon Loss:2.9729 x Lambda(0.1)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2849
Validation loss decreased (0.320128 --> 0.319946).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.5464280
	speed: 0.0220s/iter; left time: 239.6002s
Epoch: 8 cost time: 2.5670058727264404
Epoch: 8, Steps: 118 Train Loss: 0.5551 (Forecasting Loss:0.2578 + XiCon Loss:2.9725 x Lambda(0.1)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2841
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.5418510
	speed: 0.0213s/iter; left time: 229.5186s
Epoch: 9 cost time: 2.4834766387939453
Epoch: 9, Steps: 118 Train Loss: 0.5548 (Forecasting Loss:0.2575 + XiCon Loss:2.9732 x Lambda(0.1)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2842
Validation loss decreased (0.319946 --> 0.319253).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.5622352
	speed: 0.0213s/iter; left time: 226.7667s
Epoch: 10 cost time: 2.497218370437622
Epoch: 10, Steps: 118 Train Loss: 0.5546 (Forecasting Loss:0.2575 + XiCon Loss:2.9710 x Lambda(0.1)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.5608764
	speed: 0.0212s/iter; left time: 223.1446s
Epoch: 11 cost time: 2.48773193359375
Epoch: 11, Steps: 118 Train Loss: 0.5543 (Forecasting Loss:0.2572 + XiCon Loss:2.9716 x Lambda(0.1)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2842
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.5494205
	speed: 0.0219s/iter; left time: 228.2421s
Epoch: 12 cost time: 2.5565192699432373
Epoch: 12, Steps: 118 Train Loss: 0.5546 (Forecasting Loss:0.2573 + XiCon Loss:2.9725 x Lambda(0.1)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2842
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.5718849
	speed: 0.0209s/iter; left time: 214.6814s
Epoch: 13 cost time: 2.4585747718811035
Epoch: 13, Steps: 118 Train Loss: 0.5542 (Forecasting Loss:0.2572 + XiCon Loss:2.9705 x Lambda(0.1)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2842
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.5445524
	speed: 0.0211s/iter; left time: 214.7143s
Epoch: 14 cost time: 2.4728329181671143
Epoch: 14, Steps: 118 Train Loss: 0.5545 (Forecasting Loss:0.2573 + XiCon Loss:2.9715 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2842
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.5612268
	speed: 0.0216s/iter; left time: 216.6219s
Epoch: 15 cost time: 2.5003907680511475
Epoch: 15, Steps: 118 Train Loss: 0.5544 (Forecasting Loss:0.2572 + XiCon Loss:2.9728 x Lambda(0.1)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2842
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.5548248
	speed: 0.0214s/iter; left time: 212.2944s
Epoch: 16 cost time: 2.5023813247680664
Epoch: 16, Steps: 118 Train Loss: 0.5541 (Forecasting Loss:0.2570 + XiCon Loss:2.9711 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2842
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.5394371
	speed: 0.0218s/iter; left time: 213.5395s
Epoch: 17 cost time: 2.5716617107391357
Epoch: 17, Steps: 118 Train Loss: 0.5544 (Forecasting Loss:0.2572 + XiCon Loss:2.9718 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2842
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.5618440
	speed: 0.0215s/iter; left time: 208.3665s
Epoch: 18 cost time: 2.5009114742279053
Epoch: 18, Steps: 118 Train Loss: 0.5543 (Forecasting Loss:0.2572 + XiCon Loss:2.9710 x Lambda(0.1)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2842
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.5529138
	speed: 0.0212s/iter; left time: 202.9553s
Epoch: 19 cost time: 2.4814980030059814
Epoch: 19, Steps: 118 Train Loss: 0.5547 (Forecasting Loss:0.2575 + XiCon Loss:2.9721 x Lambda(0.1)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2842
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20500624179840088, mae:0.3634069263935089, mape:0.7063157558441162, mspe:18.881513595581055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3041
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7581125
	speed: 0.0180s/iter; left time: 211.0573s
Epoch: 1 cost time: 2.106580972671509
Epoch: 1, Steps: 118 Train Loss: 0.7767 (Forecasting Loss:0.4639 + XiCon Loss:3.1277 x Lambda(0.1)), Vali MSE Loss: 0.4729 Test MSE Loss: 0.3570
Validation loss decreased (inf --> 0.472907).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6545052
	speed: 0.0173s/iter; left time: 200.5842s
Epoch: 2 cost time: 2.0352413654327393
Epoch: 2, Steps: 118 Train Loss: 0.6779 (Forecasting Loss:0.3723 + XiCon Loss:3.0554 x Lambda(0.1)), Vali MSE Loss: 0.3891 Test MSE Loss: 0.2751
Validation loss decreased (0.472907 --> 0.389130).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6048702
	speed: 0.0179s/iter; left time: 204.7239s
Epoch: 3 cost time: 2.0907859802246094
Epoch: 3, Steps: 118 Train Loss: 0.6106 (Forecasting Loss:0.3100 + XiCon Loss:3.0058 x Lambda(0.1)), Vali MSE Loss: 0.3475 Test MSE Loss: 0.2684
Validation loss decreased (0.389130 --> 0.347451).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5735613
	speed: 0.0174s/iter; left time: 197.0320s
Epoch: 4 cost time: 2.0324738025665283
Epoch: 4, Steps: 118 Train Loss: 0.5875 (Forecasting Loss:0.2891 + XiCon Loss:2.9833 x Lambda(0.1)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.2651
Validation loss decreased (0.347451 --> 0.333465).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5693982
	speed: 0.0176s/iter; left time: 198.0363s
Epoch: 5 cost time: 2.0539495944976807
Epoch: 5, Steps: 118 Train Loss: 0.5801 (Forecasting Loss:0.2833 + XiCon Loss:2.9677 x Lambda(0.1)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2640
Validation loss decreased (0.333465 --> 0.329026).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5890019
	speed: 0.0182s/iter; left time: 202.6844s
Epoch: 6 cost time: 2.141982078552246
Epoch: 6, Steps: 118 Train Loss: 0.5773 (Forecasting Loss:0.2813 + XiCon Loss:2.9602 x Lambda(0.1)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2638
Validation loss decreased (0.329026 --> 0.327640).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5673575
	speed: 0.0176s/iter; left time: 193.2619s
Epoch: 7 cost time: 2.0593488216400146
Epoch: 7, Steps: 118 Train Loss: 0.5753 (Forecasting Loss:0.2795 + XiCon Loss:2.9580 x Lambda(0.1)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2635
Validation loss decreased (0.327640 --> 0.326657).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.5782968
	speed: 0.0178s/iter; left time: 194.0864s
Epoch: 8 cost time: 2.09564208984375
Epoch: 8, Steps: 118 Train Loss: 0.5749 (Forecasting Loss:0.2795 + XiCon Loss:2.9539 x Lambda(0.1)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.5852184
	speed: 0.0174s/iter; left time: 187.5069s
Epoch: 9 cost time: 2.035926103591919
Epoch: 9, Steps: 118 Train Loss: 0.5745 (Forecasting Loss:0.2793 + XiCon Loss:2.9517 x Lambda(0.1)), Vali MSE Loss: 0.3265 Test MSE Loss: 0.2632
Validation loss decreased (0.326657 --> 0.326504).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.6075011
	speed: 0.0177s/iter; left time: 188.0867s
Epoch: 10 cost time: 2.068293571472168
Epoch: 10, Steps: 118 Train Loss: 0.5738 (Forecasting Loss:0.2787 + XiCon Loss:2.9511 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2632
Validation loss decreased (0.326504 --> 0.326046).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.5504220
	speed: 0.0183s/iter; left time: 193.0005s
Epoch: 11 cost time: 2.1296772956848145
Epoch: 11, Steps: 118 Train Loss: 0.5742 (Forecasting Loss:0.2789 + XiCon Loss:2.9531 x Lambda(0.1)), Vali MSE Loss: 0.3265 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.5822380
	speed: 0.0174s/iter; left time: 181.1192s
Epoch: 12 cost time: 2.0414717197418213
Epoch: 12, Steps: 118 Train Loss: 0.5745 (Forecasting Loss:0.2791 + XiCon Loss:2.9544 x Lambda(0.1)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.5853795
	speed: 0.0178s/iter; left time: 183.0996s
Epoch: 13 cost time: 2.085522413253784
Epoch: 13, Steps: 118 Train Loss: 0.5743 (Forecasting Loss:0.2789 + XiCon Loss:2.9544 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.5735160
	speed: 0.0177s/iter; left time: 180.2922s
Epoch: 14 cost time: 2.068183422088623
Epoch: 14, Steps: 118 Train Loss: 0.5740 (Forecasting Loss:0.2789 + XiCon Loss:2.9515 x Lambda(0.1)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2632
Validation loss decreased (0.326046 --> 0.325133).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.5844942
	speed: 0.0179s/iter; left time: 179.7897s
Epoch: 15 cost time: 2.080514430999756
Epoch: 15, Steps: 118 Train Loss: 0.5738 (Forecasting Loss:0.2787 + XiCon Loss:2.9513 x Lambda(0.1)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.5805866
	speed: 0.0180s/iter; left time: 179.0242s
Epoch: 16 cost time: 2.102673292160034
Epoch: 16, Steps: 118 Train Loss: 0.5744 (Forecasting Loss:0.2791 + XiCon Loss:2.9527 x Lambda(0.1)), Vali MSE Loss: 0.3256 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.5692010
	speed: 0.0171s/iter; left time: 167.7528s
Epoch: 17 cost time: 2.0029752254486084
Epoch: 17, Steps: 118 Train Loss: 0.5736 (Forecasting Loss:0.2785 + XiCon Loss:2.9505 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.5622787
	speed: 0.0177s/iter; left time: 171.5505s
Epoch: 18 cost time: 2.0613913536071777
Epoch: 18, Steps: 118 Train Loss: 0.5740 (Forecasting Loss:0.2787 + XiCon Loss:2.9534 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.2632
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.5808225
	speed: 0.0188s/iter; left time: 180.1734s
Epoch: 19 cost time: 2.19545316696167
Epoch: 19, Steps: 118 Train Loss: 0.5739 (Forecasting Loss:0.2784 + XiCon Loss:2.9548 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.2632
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.5691963
	speed: 0.0176s/iter; left time: 166.6147s
Epoch: 20 cost time: 2.0615499019622803
Epoch: 20, Steps: 118 Train Loss: 0.5742 (Forecasting Loss:0.2788 + XiCon Loss:2.9539 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.2632
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.5834976
	speed: 0.0187s/iter; left time: 174.6048s
Epoch: 21 cost time: 2.167057991027832
Epoch: 21, Steps: 118 Train Loss: 0.5742 (Forecasting Loss:0.2789 + XiCon Loss:2.9523 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2632
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.5516685
	speed: 0.0179s/iter; left time: 164.6505s
Epoch: 22 cost time: 2.1021692752838135
Epoch: 22, Steps: 118 Train Loss: 0.5740 (Forecasting Loss:0.2787 + XiCon Loss:2.9536 x Lambda(0.1)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.2632
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.5877337
	speed: 0.0173s/iter; left time: 157.7855s
Epoch: 23 cost time: 2.052220344543457
Epoch: 23, Steps: 118 Train Loss: 0.5742 (Forecasting Loss:0.2788 + XiCon Loss:2.9546 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.2632
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.5753932
	speed: 0.0173s/iter; left time: 155.7521s
Epoch: 24 cost time: 2.031432628631592
Epoch: 24, Steps: 118 Train Loss: 0.5740 (Forecasting Loss:0.2787 + XiCon Loss:2.9534 x Lambda(0.1)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.2632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1816512644290924, mae:0.34473076462745667, mape:0.7569762468338013, mspe:26.044775009155273 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3178
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7442656
	speed: 0.0174s/iter; left time: 203.8768s
Epoch: 1 cost time: 2.053157329559326
Epoch: 1, Steps: 118 Train Loss: 0.7919 (Forecasting Loss:0.4792 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.5040 Test MSE Loss: 0.4014
Validation loss decreased (inf --> 0.504045).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6213063
	speed: 0.0176s/iter; left time: 204.2216s
Epoch: 2 cost time: 2.066901683807373
Epoch: 2, Steps: 118 Train Loss: 0.6506 (Forecasting Loss:0.3427 + XiCon Loss:3.0785 x Lambda(0.1)), Vali MSE Loss: 0.3673 Test MSE Loss: 0.2949
Validation loss decreased (0.504045 --> 0.367305).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6004153
	speed: 0.0180s/iter; left time: 206.4823s
Epoch: 3 cost time: 2.104663610458374
Epoch: 3, Steps: 118 Train Loss: 0.6078 (Forecasting Loss:0.3034 + XiCon Loss:3.0436 x Lambda(0.1)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2963
Validation loss decreased (0.367305 --> 0.360352).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.5789828
	speed: 0.0175s/iter; left time: 198.4666s
Epoch: 4 cost time: 2.0458545684814453
Epoch: 4, Steps: 118 Train Loss: 0.5998 (Forecasting Loss:0.2966 + XiCon Loss:3.0321 x Lambda(0.1)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.6005677
	speed: 0.0174s/iter; left time: 195.8498s
Epoch: 5 cost time: 2.041539192199707
Epoch: 5, Steps: 118 Train Loss: 0.5965 (Forecasting Loss:0.2938 + XiCon Loss:3.0267 x Lambda(0.1)), Vali MSE Loss: 0.3516 Test MSE Loss: 0.3025
Validation loss decreased (0.360352 --> 0.351573).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5660824
	speed: 0.0183s/iter; left time: 202.8502s
Epoch: 6 cost time: 2.1411375999450684
Epoch: 6, Steps: 118 Train Loss: 0.5946 (Forecasting Loss:0.2921 + XiCon Loss:3.0244 x Lambda(0.1)), Vali MSE Loss: 0.3550 Test MSE Loss: 0.3028
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5831624
	speed: 0.0174s/iter; left time: 191.6571s
Epoch: 7 cost time: 2.0616025924682617
Epoch: 7, Steps: 118 Train Loss: 0.5931 (Forecasting Loss:0.2908 + XiCon Loss:3.0231 x Lambda(0.1)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.3042
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.5771089
	speed: 0.0177s/iter; left time: 192.6177s
Epoch: 8 cost time: 2.0799882411956787
Epoch: 8, Steps: 118 Train Loss: 0.5929 (Forecasting Loss:0.2907 + XiCon Loss:3.0224 x Lambda(0.1)), Vali MSE Loss: 0.3546 Test MSE Loss: 0.3043
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.6103433
	speed: 0.0177s/iter; left time: 189.9856s
Epoch: 9 cost time: 2.0566327571868896
Epoch: 9, Steps: 118 Train Loss: 0.5931 (Forecasting Loss:0.2909 + XiCon Loss:3.0222 x Lambda(0.1)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.3047
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.6114774
	speed: 0.0171s/iter; left time: 181.8901s
Epoch: 10 cost time: 2.02058482170105
Epoch: 10, Steps: 118 Train Loss: 0.5927 (Forecasting Loss:0.2905 + XiCon Loss:3.0219 x Lambda(0.1)), Vali MSE Loss: 0.3536 Test MSE Loss: 0.3046
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.5994619
	speed: 0.0178s/iter; left time: 187.4101s
Epoch: 11 cost time: 2.085123062133789
Epoch: 11, Steps: 118 Train Loss: 0.5923 (Forecasting Loss:0.2902 + XiCon Loss:3.0211 x Lambda(0.1)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.3047
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.6016310
	speed: 0.0174s/iter; left time: 181.1761s
Epoch: 12 cost time: 2.0445303916931152
Epoch: 12, Steps: 118 Train Loss: 0.5927 (Forecasting Loss:0.2906 + XiCon Loss:3.0210 x Lambda(0.1)), Vali MSE Loss: 0.3542 Test MSE Loss: 0.3047
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.6048524
	speed: 0.0175s/iter; left time: 180.4888s
Epoch: 13 cost time: 2.0481061935424805
Epoch: 13, Steps: 118 Train Loss: 0.5929 (Forecasting Loss:0.2907 + XiCon Loss:3.0221 x Lambda(0.1)), Vali MSE Loss: 0.3550 Test MSE Loss: 0.3047
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.5724155
	speed: 0.0178s/iter; left time: 180.7752s
Epoch: 14 cost time: 2.0850956439971924
Epoch: 14, Steps: 118 Train Loss: 0.5925 (Forecasting Loss:0.2903 + XiCon Loss:3.0218 x Lambda(0.1)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.3047
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.5971285
	speed: 0.0179s/iter; left time: 180.0616s
Epoch: 15 cost time: 2.0911178588867188
Epoch: 15, Steps: 118 Train Loss: 0.5925 (Forecasting Loss:0.2902 + XiCon Loss:3.0224 x Lambda(0.1)), Vali MSE Loss: 0.3545 Test MSE Loss: 0.3047
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.22550582885742188, mae:0.37953582406044006, mape:0.7291179895401001, mspe:24.719602584838867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3056
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.7685211
	speed: 0.0184s/iter; left time: 215.0880s
Epoch: 1 cost time: 2.1265671253204346
Epoch: 1, Steps: 118 Train Loss: 0.7864 (Forecasting Loss:0.4703 + XiCon Loss:3.1605 x Lambda(0.1)), Vali MSE Loss: 0.4671 Test MSE Loss: 0.3474
Validation loss decreased (inf --> 0.467127).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.6225450
	speed: 0.0179s/iter; left time: 207.5187s
Epoch: 2 cost time: 2.1092398166656494
Epoch: 2, Steps: 118 Train Loss: 0.6842 (Forecasting Loss:0.3771 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.4434 Test MSE Loss: 0.3164
Validation loss decreased (0.467127 --> 0.443421).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.6110688
	speed: 0.0180s/iter; left time: 206.5251s
Epoch: 3 cost time: 2.1102921962738037
Epoch: 3, Steps: 118 Train Loss: 0.6290 (Forecasting Loss:0.3278 + XiCon Loss:3.0120 x Lambda(0.1)), Vali MSE Loss: 0.4007 Test MSE Loss: 0.3018
Validation loss decreased (0.443421 --> 0.400698).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.6062682
	speed: 0.0181s/iter; left time: 205.3525s
Epoch: 4 cost time: 2.119616985321045
Epoch: 4, Steps: 118 Train Loss: 0.6093 (Forecasting Loss:0.3083 + XiCon Loss:3.0100 x Lambda(0.1)), Vali MSE Loss: 0.3831 Test MSE Loss: 0.3102
Validation loss decreased (0.400698 --> 0.383076).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.5975528
	speed: 0.0180s/iter; left time: 201.6521s
Epoch: 5 cost time: 2.100801467895508
Epoch: 5, Steps: 118 Train Loss: 0.6029 (Forecasting Loss:0.3025 + XiCon Loss:3.0044 x Lambda(0.1)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.3107
Validation loss decreased (0.383076 --> 0.378618).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.5904821
	speed: 0.0185s/iter; left time: 205.5070s
Epoch: 6 cost time: 2.157543897628784
Epoch: 6, Steps: 118 Train Loss: 0.5994 (Forecasting Loss:0.2992 + XiCon Loss:3.0023 x Lambda(0.1)), Vali MSE Loss: 0.3783 Test MSE Loss: 0.3101
Validation loss decreased (0.378618 --> 0.378299).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.5995421
	speed: 0.0177s/iter; left time: 194.5157s
Epoch: 7 cost time: 2.0817527770996094
Epoch: 7, Steps: 118 Train Loss: 0.5977 (Forecasting Loss:0.2976 + XiCon Loss:3.0013 x Lambda(0.1)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.3122
Validation loss decreased (0.378299 --> 0.377166).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.6102181
	speed: 0.0185s/iter; left time: 201.2112s
Epoch: 8 cost time: 2.1536061763763428
Epoch: 8, Steps: 118 Train Loss: 0.5974 (Forecasting Loss:0.2973 + XiCon Loss:3.0004 x Lambda(0.1)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.3114
Validation loss decreased (0.377166 --> 0.376830).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.5739504
	speed: 0.0182s/iter; left time: 196.1696s
Epoch: 9 cost time: 2.136167526245117
Epoch: 9, Steps: 118 Train Loss: 0.5960 (Forecasting Loss:0.2961 + XiCon Loss:2.9990 x Lambda(0.1)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3124
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.5928347
	speed: 0.0181s/iter; left time: 192.2802s
Epoch: 10 cost time: 2.1165318489074707
Epoch: 10, Steps: 118 Train Loss: 0.5971 (Forecasting Loss:0.2970 + XiCon Loss:3.0011 x Lambda(0.1)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.3120
Validation loss decreased (0.376830 --> 0.375609).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.6363197
	speed: 0.0177s/iter; left time: 185.9364s
Epoch: 11 cost time: 2.083366632461548
Epoch: 11, Steps: 118 Train Loss: 0.5966 (Forecasting Loss:0.2966 + XiCon Loss:2.9998 x Lambda(0.1)), Vali MSE Loss: 0.3770 Test MSE Loss: 0.3121
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.5969291
	speed: 0.0174s/iter; left time: 181.2762s
Epoch: 12 cost time: 2.051490068435669
Epoch: 12, Steps: 118 Train Loss: 0.5962 (Forecasting Loss:0.2962 + XiCon Loss:3.0004 x Lambda(0.1)), Vali MSE Loss: 0.3766 Test MSE Loss: 0.3122
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.6106598
	speed: 0.0177s/iter; left time: 181.8459s
Epoch: 13 cost time: 2.148499011993408
Epoch: 13, Steps: 118 Train Loss: 0.5966 (Forecasting Loss:0.2965 + XiCon Loss:3.0002 x Lambda(0.1)), Vali MSE Loss: 0.3764 Test MSE Loss: 0.3122
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.5950347
	speed: 0.0175s/iter; left time: 178.0313s
Epoch: 14 cost time: 2.0653178691864014
Epoch: 14, Steps: 118 Train Loss: 0.5965 (Forecasting Loss:0.2967 + XiCon Loss:2.9985 x Lambda(0.1)), Vali MSE Loss: 0.3759 Test MSE Loss: 0.3122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.6024320
	speed: 0.0184s/iter; left time: 185.0424s
Epoch: 15 cost time: 2.1343729496002197
Epoch: 15, Steps: 118 Train Loss: 0.5967 (Forecasting Loss:0.2967 + XiCon Loss:2.9999 x Lambda(0.1)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.3122
Validation loss decreased (0.375609 --> 0.375558).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.6154604
	speed: 0.0179s/iter; left time: 177.5955s
Epoch: 16 cost time: 2.1224477291107178
Epoch: 16, Steps: 118 Train Loss: 0.5964 (Forecasting Loss:0.2966 + XiCon Loss:2.9981 x Lambda(0.1)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.3122
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.6081057
	speed: 0.0173s/iter; left time: 169.3709s
Epoch: 17 cost time: 2.0268030166625977
Epoch: 17, Steps: 118 Train Loss: 0.5966 (Forecasting Loss:0.2966 + XiCon Loss:2.9998 x Lambda(0.1)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.3122
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.5745186
	speed: 0.0172s/iter; left time: 166.7927s
Epoch: 18 cost time: 2.014969825744629
Epoch: 18, Steps: 118 Train Loss: 0.5963 (Forecasting Loss:0.2961 + XiCon Loss:3.0015 x Lambda(0.1)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.3122
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.6063219
	speed: 0.0178s/iter; left time: 170.5755s
Epoch: 19 cost time: 2.0693790912628174
Epoch: 19, Steps: 118 Train Loss: 0.5967 (Forecasting Loss:0.2966 + XiCon Loss:3.0008 x Lambda(0.1)), Vali MSE Loss: 0.3763 Test MSE Loss: 0.3122
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.6143303
	speed: 0.0186s/iter; left time: 176.0440s
Epoch: 20 cost time: 2.173577308654785
Epoch: 20, Steps: 118 Train Loss: 0.5960 (Forecasting Loss:0.2961 + XiCon Loss:2.9996 x Lambda(0.1)), Vali MSE Loss: 0.3759 Test MSE Loss: 0.3122
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.5914406
	speed: 0.0173s/iter; left time: 161.1418s
Epoch: 21 cost time: 2.0349862575531006
Epoch: 21, Steps: 118 Train Loss: 0.5965 (Forecasting Loss:0.2965 + XiCon Loss:2.9994 x Lambda(0.1)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.3122
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.5800961
	speed: 0.0173s/iter; left time: 159.3593s
Epoch: 22 cost time: 2.0256175994873047
Epoch: 22, Steps: 118 Train Loss: 0.5964 (Forecasting Loss:0.2965 + XiCon Loss:2.9989 x Lambda(0.1)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3122
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.6038682
	speed: 0.0174s/iter; left time: 158.4540s
Epoch: 23 cost time: 2.0352590084075928
Epoch: 23, Steps: 118 Train Loss: 0.5962 (Forecasting Loss:0.2961 + XiCon Loss:3.0012 x Lambda(0.1)), Vali MSE Loss: 0.3759 Test MSE Loss: 0.3122
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.5972447
	speed: 0.0172s/iter; left time: 154.6580s
Epoch: 24 cost time: 2.011323928833008
Epoch: 24, Steps: 118 Train Loss: 0.5967 (Forecasting Loss:0.2966 + XiCon Loss:3.0018 x Lambda(0.1)), Vali MSE Loss: 0.3758 Test MSE Loss: 0.3122
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.6062930
	speed: 0.0177s/iter; left time: 157.4118s
Epoch: 25 cost time: 2.0615015029907227
Epoch: 25, Steps: 118 Train Loss: 0.5968 (Forecasting Loss:0.2969 + XiCon Loss:2.9990 x Lambda(0.1)), Vali MSE Loss: 0.3766 Test MSE Loss: 0.3122
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2361193299293518, mae:0.3882460296154022, mape:0.7540134191513062, mspe:24.211902618408203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2103+-0.02629, MAE:0.3677+-0.02091, MAPE:0.7294+-0.03251, MSPE:23.4807+-3.38913, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1275
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4847114
	speed: 0.0432s/iter; left time: 1145.6336s
	iters: 200, epoch: 1 | loss: 0.4612058
	speed: 0.0362s/iter; left time: 956.0577s
Epoch: 1 cost time: 10.334070920944214
Epoch: 1, Steps: 266 Train Loss: 0.4904 (Forecasting Loss:0.1645 + XiCon Loss:3.2592 x Lambda(0.1)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.0772
Validation loss decreased (inf --> 0.113662).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4635291
	speed: 0.0406s/iter; left time: 1065.3700s
	iters: 200, epoch: 2 | loss: 0.4800400
	speed: 0.0386s/iter; left time: 1009.6815s
Epoch: 2 cost time: 10.461384534835815
Epoch: 2, Steps: 266 Train Loss: 0.4722 (Forecasting Loss:0.1500 + XiCon Loss:3.2224 x Lambda(0.1)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.0761
Validation loss decreased (0.113662 --> 0.111656).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4657983
	speed: 0.0410s/iter; left time: 1064.6107s
	iters: 200, epoch: 3 | loss: 0.4555744
	speed: 0.0377s/iter; left time: 975.9135s
Epoch: 3 cost time: 10.365538358688354
Epoch: 3, Steps: 266 Train Loss: 0.4591 (Forecasting Loss:0.1450 + XiCon Loss:3.1405 x Lambda(0.1)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0761
Validation loss decreased (0.111656 --> 0.109704).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4348375
	speed: 0.0408s/iter; left time: 1048.4554s
	iters: 200, epoch: 4 | loss: 0.4461747
	speed: 0.0385s/iter; left time: 984.5821s
Epoch: 4 cost time: 10.515331745147705
Epoch: 4, Steps: 266 Train Loss: 0.4536 (Forecasting Loss:0.1432 + XiCon Loss:3.1043 x Lambda(0.1)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0749
Validation loss decreased (0.109704 --> 0.108561).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4481922
	speed: 0.0415s/iter; left time: 1056.2265s
	iters: 200, epoch: 5 | loss: 0.4448319
	speed: 0.0390s/iter; left time: 987.4432s
Epoch: 5 cost time: 10.653290033340454
Epoch: 5, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1423 + XiCon Loss:3.0984 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0743
Validation loss decreased (0.108561 --> 0.107782).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4743901
	speed: 0.0400s/iter; left time: 1008.0751s
	iters: 200, epoch: 6 | loss: 0.4510548
	speed: 0.0382s/iter; left time: 958.8610s
Epoch: 6 cost time: 10.346536874771118
Epoch: 6, Steps: 266 Train Loss: 0.4511 (Forecasting Loss:0.1419 + XiCon Loss:3.0915 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107782 --> 0.107681).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4438000
	speed: 0.0393s/iter; left time: 979.9597s
	iters: 200, epoch: 7 | loss: 0.4389661
	speed: 0.0392s/iter; left time: 973.0441s
Epoch: 7 cost time: 10.395318508148193
Epoch: 7, Steps: 266 Train Loss: 0.4507 (Forecasting Loss:0.1417 + XiCon Loss:3.0906 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107681 --> 0.107448).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4531398
	speed: 0.0408s/iter; left time: 1006.1919s
	iters: 200, epoch: 8 | loss: 0.4681906
	speed: 0.0382s/iter; left time: 938.2225s
Epoch: 8 cost time: 10.434660911560059
Epoch: 8, Steps: 266 Train Loss: 0.4506 (Forecasting Loss:0.1415 + XiCon Loss:3.0913 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4333998
	speed: 0.0410s/iter; left time: 999.2246s
	iters: 200, epoch: 9 | loss: 0.4516417
	speed: 0.0382s/iter; left time: 928.2321s
Epoch: 9 cost time: 10.4369637966156
Epoch: 9, Steps: 266 Train Loss: 0.4506 (Forecasting Loss:0.1414 + XiCon Loss:3.0919 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4404195
	speed: 0.0378s/iter; left time: 911.9522s
	iters: 200, epoch: 10 | loss: 0.4542077
	speed: 0.0355s/iter; left time: 852.1292s
Epoch: 10 cost time: 9.947266101837158
Epoch: 10, Steps: 266 Train Loss: 0.4507 (Forecasting Loss:0.1414 + XiCon Loss:3.0929 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4466571
	speed: 0.0402s/iter; left time: 959.3661s
	iters: 200, epoch: 11 | loss: 0.4616365
	speed: 0.0387s/iter; left time: 919.5129s
Epoch: 11 cost time: 10.349343538284302
Epoch: 11, Steps: 266 Train Loss: 0.4498 (Forecasting Loss:0.1413 + XiCon Loss:3.0850 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107448 --> 0.107448).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4455256
	speed: 0.0416s/iter; left time: 979.8819s
	iters: 200, epoch: 12 | loss: 0.4610094
	speed: 0.0386s/iter; left time: 906.5016s
Epoch: 12 cost time: 10.544471740722656
Epoch: 12, Steps: 266 Train Loss: 0.4505 (Forecasting Loss:0.1414 + XiCon Loss:3.0917 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107448 --> 0.107435).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4501330
	speed: 0.0406s/iter; left time: 945.6118s
	iters: 200, epoch: 13 | loss: 0.4519545
	speed: 0.0378s/iter; left time: 876.4355s
Epoch: 13 cost time: 10.290486335754395
Epoch: 13, Steps: 266 Train Loss: 0.4509 (Forecasting Loss:0.1414 + XiCon Loss:3.0950 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4320890
	speed: 0.0433s/iter; left time: 997.5726s
	iters: 200, epoch: 14 | loss: 0.4613791
	speed: 0.0383s/iter; left time: 878.7402s
Epoch: 14 cost time: 10.702000379562378
Epoch: 14, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1414 + XiCon Loss:3.0889 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107435 --> 0.107377).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4930660
	speed: 0.0408s/iter; left time: 929.2862s
	iters: 200, epoch: 15 | loss: 0.4407040
	speed: 0.0382s/iter; left time: 866.2058s
Epoch: 15 cost time: 10.51535415649414
Epoch: 15, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1414 + XiCon Loss:3.0890 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4544267
	speed: 0.0412s/iter; left time: 926.3328s
	iters: 200, epoch: 16 | loss: 0.4674848
	speed: 0.0391s/iter; left time: 877.3151s
Epoch: 16 cost time: 10.526903867721558
Epoch: 16, Steps: 266 Train Loss: 0.4501 (Forecasting Loss:0.1413 + XiCon Loss:3.0878 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4404590
	speed: 0.0402s/iter; left time: 894.0366s
	iters: 200, epoch: 17 | loss: 0.4739705
	speed: 0.0379s/iter; left time: 840.2181s
Epoch: 17 cost time: 10.39790153503418
Epoch: 17, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1413 + XiCon Loss:3.0892 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4512129
	speed: 0.0401s/iter; left time: 881.9361s
	iters: 200, epoch: 18 | loss: 0.4442216
	speed: 0.0385s/iter; left time: 841.8963s
Epoch: 18 cost time: 10.420466423034668
Epoch: 18, Steps: 266 Train Loss: 0.4499 (Forecasting Loss:0.1414 + XiCon Loss:3.0856 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4438786
	speed: 0.0405s/iter; left time: 878.4110s
	iters: 200, epoch: 19 | loss: 0.4260780
	speed: 0.0384s/iter; left time: 830.9284s
Epoch: 19 cost time: 10.21689224243164
Epoch: 19, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1413 + XiCon Loss:3.0893 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4473866
	speed: 0.0391s/iter; left time: 839.2440s
	iters: 200, epoch: 20 | loss: 0.4365743
	speed: 0.0386s/iter; left time: 824.5276s
Epoch: 20 cost time: 10.321211338043213
Epoch: 20, Steps: 266 Train Loss: 0.4501 (Forecasting Loss:0.1413 + XiCon Loss:3.0885 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4407854
	speed: 0.0407s/iter; left time: 861.0105s
	iters: 200, epoch: 21 | loss: 0.4494628
	speed: 0.0394s/iter; left time: 830.4758s
Epoch: 21 cost time: 10.610713481903076
Epoch: 21, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1413 + XiCon Loss:3.0886 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4724996
	speed: 0.0409s/iter; left time: 855.7307s
	iters: 200, epoch: 22 | loss: 0.4431050
	speed: 0.0393s/iter; left time: 817.2062s
Epoch: 22 cost time: 10.580711841583252
Epoch: 22, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1413 + XiCon Loss:3.0900 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107377 --> 0.107360).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4475588
	speed: 0.0404s/iter; left time: 833.6029s
	iters: 200, epoch: 23 | loss: 0.4537274
	speed: 0.0382s/iter; left time: 785.5419s
Epoch: 23 cost time: 10.4229736328125
Epoch: 23, Steps: 266 Train Loss: 0.4506 (Forecasting Loss:0.1414 + XiCon Loss:3.0926 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4583662
	speed: 0.0406s/iter; left time: 827.0313s
	iters: 200, epoch: 24 | loss: 0.4429840
	speed: 0.0385s/iter; left time: 781.5409s
Epoch: 24 cost time: 10.466394186019897
Epoch: 24, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1413 + XiCon Loss:3.0894 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4336600
	speed: 0.0407s/iter; left time: 818.8591s
	iters: 200, epoch: 25 | loss: 0.4242269
	speed: 0.0392s/iter; left time: 784.6805s
Epoch: 25 cost time: 10.564589977264404
Epoch: 25, Steps: 266 Train Loss: 0.4504 (Forecasting Loss:0.1413 + XiCon Loss:3.0912 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4351848
	speed: 0.0397s/iter; left time: 788.8365s
	iters: 200, epoch: 26 | loss: 0.4556343
	speed: 0.0383s/iter; left time: 757.4203s
Epoch: 26 cost time: 10.422368288040161
Epoch: 26, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1413 + XiCon Loss:3.0898 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4696113
	speed: 0.0401s/iter; left time: 785.4141s
	iters: 200, epoch: 27 | loss: 0.4567231
	speed: 0.0388s/iter; left time: 756.7687s
Epoch: 27 cost time: 10.464561462402344
Epoch: 27, Steps: 266 Train Loss: 0.4504 (Forecasting Loss:0.1413 + XiCon Loss:3.0909 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4279698
	speed: 0.0403s/iter; left time: 778.1002s
	iters: 200, epoch: 28 | loss: 0.4449294
	speed: 0.0383s/iter; left time: 736.0955s
Epoch: 28 cost time: 10.40194034576416
Epoch: 28, Steps: 266 Train Loss: 0.4500 (Forecasting Loss:0.1414 + XiCon Loss:3.0860 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4473787
	speed: 0.0393s/iter; left time: 748.0046s
	iters: 200, epoch: 29 | loss: 0.4651381
	speed: 0.0359s/iter; left time: 680.5206s
Epoch: 29 cost time: 10.002050876617432
Epoch: 29, Steps: 266 Train Loss: 0.4505 (Forecasting Loss:0.1414 + XiCon Loss:3.0908 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.4438001
	speed: 0.0405s/iter; left time: 761.7002s
	iters: 200, epoch: 30 | loss: 0.4274883
	speed: 0.0374s/iter; left time: 699.7995s
Epoch: 30 cost time: 10.322307825088501
Epoch: 30, Steps: 266 Train Loss: 0.4505 (Forecasting Loss:0.1413 + XiCon Loss:3.0921 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.4523606
	speed: 0.0407s/iter; left time: 753.7321s
	iters: 200, epoch: 31 | loss: 0.4509483
	speed: 0.0386s/iter; left time: 711.8640s
Epoch: 31 cost time: 10.492969036102295
Epoch: 31, Steps: 266 Train Loss: 0.4505 (Forecasting Loss:0.1413 + XiCon Loss:3.0915 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.4658585
	speed: 0.0410s/iter; left time: 747.9649s
	iters: 200, epoch: 32 | loss: 0.4835335
	speed: 0.0387s/iter; left time: 703.3593s
Epoch: 32 cost time: 10.479379892349243
Epoch: 32, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1413 + XiCon Loss:3.0897 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02646232768893242, mae:0.12200585007667542, mape:0.09858464449644089, mspe:0.019631415605545044 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5147
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4931209
	speed: 0.0399s/iter; left time: 1058.0227s
	iters: 200, epoch: 1 | loss: 0.4775971
	speed: 0.0370s/iter; left time: 977.9929s
Epoch: 1 cost time: 10.13795256614685
Epoch: 1, Steps: 266 Train Loss: 0.4904 (Forecasting Loss:0.1648 + XiCon Loss:3.2563 x Lambda(0.1)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.0766
Validation loss decreased (inf --> 0.113916).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4721076
	speed: 0.0399s/iter; left time: 1047.1497s
	iters: 200, epoch: 2 | loss: 0.4805399
	speed: 0.0384s/iter; left time: 1002.6539s
Epoch: 2 cost time: 10.418720006942749
Epoch: 2, Steps: 266 Train Loss: 0.4725 (Forecasting Loss:0.1500 + XiCon Loss:3.2252 x Lambda(0.1)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.0760
Validation loss decreased (0.113916 --> 0.110808).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4486866
	speed: 0.0397s/iter; left time: 1031.8992s
	iters: 200, epoch: 3 | loss: 0.4379613
	speed: 0.0380s/iter; left time: 982.7649s
Epoch: 3 cost time: 10.223896265029907
Epoch: 3, Steps: 266 Train Loss: 0.4560 (Forecasting Loss:0.1453 + XiCon Loss:3.1068 x Lambda(0.1)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.0752
Validation loss decreased (0.110808 --> 0.108852).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4575796
	speed: 0.0398s/iter; left time: 1022.0560s
	iters: 200, epoch: 4 | loss: 0.4544607
	speed: 0.0377s/iter; left time: 966.5122s
Epoch: 4 cost time: 10.291259050369263
Epoch: 4, Steps: 266 Train Loss: 0.4524 (Forecasting Loss:0.1432 + XiCon Loss:3.0924 x Lambda(0.1)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0749
Validation loss decreased (0.108852 --> 0.108357).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4539942
	speed: 0.0399s/iter; left time: 1014.5169s
	iters: 200, epoch: 5 | loss: 0.4764472
	speed: 0.0374s/iter; left time: 946.6722s
Epoch: 5 cost time: 10.099612951278687
Epoch: 5, Steps: 266 Train Loss: 0.4514 (Forecasting Loss:0.1424 + XiCon Loss:3.0893 x Lambda(0.1)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0748
Validation loss decreased (0.108357 --> 0.107997).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4488648
	speed: 0.0388s/iter; left time: 975.5554s
	iters: 200, epoch: 6 | loss: 0.4609837
	speed: 0.0386s/iter; left time: 966.9681s
Epoch: 6 cost time: 10.17892599105835
Epoch: 6, Steps: 266 Train Loss: 0.4499 (Forecasting Loss:0.1420 + XiCon Loss:3.0800 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0744
Validation loss decreased (0.107997 --> 0.107791).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4462459
	speed: 0.0397s/iter; left time: 988.4707s
	iters: 200, epoch: 7 | loss: 0.4378412
	speed: 0.0376s/iter; left time: 933.5677s
Epoch: 7 cost time: 10.247506141662598
Epoch: 7, Steps: 266 Train Loss: 0.4496 (Forecasting Loss:0.1417 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
Validation loss decreased (0.107791 --> 0.107507).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4673932
	speed: 0.0396s/iter; left time: 974.7748s
	iters: 200, epoch: 8 | loss: 0.4529533
	speed: 0.0372s/iter; left time: 913.8551s
Epoch: 8 cost time: 10.183913469314575
Epoch: 8, Steps: 266 Train Loss: 0.4488 (Forecasting Loss:0.1415 + XiCon Loss:3.0731 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
Validation loss decreased (0.107507 --> 0.107487).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4523345
	speed: 0.0401s/iter; left time: 976.1795s
	iters: 200, epoch: 9 | loss: 0.4659876
	speed: 0.0377s/iter; left time: 914.4614s
Epoch: 9 cost time: 10.283218383789062
Epoch: 9, Steps: 266 Train Loss: 0.4490 (Forecasting Loss:0.1415 + XiCon Loss:3.0746 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4578426
	speed: 0.0397s/iter; left time: 956.7778s
	iters: 200, epoch: 10 | loss: 0.4476154
	speed: 0.0376s/iter; left time: 902.5238s
Epoch: 10 cost time: 10.188247442245483
Epoch: 10, Steps: 266 Train Loss: 0.4493 (Forecasting Loss:0.1415 + XiCon Loss:3.0785 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
Validation loss decreased (0.107487 --> 0.107478).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4568999
	speed: 0.0394s/iter; left time: 938.6028s
	iters: 200, epoch: 11 | loss: 0.4585785
	speed: 0.0373s/iter; left time: 885.8740s
Epoch: 11 cost time: 10.109026432037354
Epoch: 11, Steps: 266 Train Loss: 0.4491 (Forecasting Loss:0.1414 + XiCon Loss:3.0770 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107478 --> 0.107439).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4720630
	speed: 0.0393s/iter; left time: 925.3918s
	iters: 200, epoch: 12 | loss: 0.4660714
	speed: 0.0385s/iter; left time: 902.7761s
Epoch: 12 cost time: 10.249608993530273
Epoch: 12, Steps: 266 Train Loss: 0.4491 (Forecasting Loss:0.1413 + XiCon Loss:3.0779 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107439 --> 0.107433).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4568670
	speed: 0.0400s/iter; left time: 933.2110s
	iters: 200, epoch: 13 | loss: 0.4619141
	speed: 0.0381s/iter; left time: 884.7605s
Epoch: 13 cost time: 10.283252239227295
Epoch: 13, Steps: 266 Train Loss: 0.4492 (Forecasting Loss:0.1414 + XiCon Loss:3.0784 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107433 --> 0.107426).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4571951
	speed: 0.0396s/iter; left time: 912.7047s
	iters: 200, epoch: 14 | loss: 0.4516802
	speed: 0.0374s/iter; left time: 858.8617s
Epoch: 14 cost time: 10.196669101715088
Epoch: 14, Steps: 266 Train Loss: 0.4493 (Forecasting Loss:0.1413 + XiCon Loss:3.0801 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4381183
	speed: 0.0406s/iter; left time: 925.3005s
	iters: 200, epoch: 15 | loss: 0.4498764
	speed: 0.0352s/iter; left time: 799.0180s
Epoch: 15 cost time: 9.926522731781006
Epoch: 15, Steps: 266 Train Loss: 0.4494 (Forecasting Loss:0.1414 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4265692
	speed: 0.0389s/iter; left time: 876.1151s
	iters: 200, epoch: 16 | loss: 0.4549546
	speed: 0.0369s/iter; left time: 827.9385s
Epoch: 16 cost time: 10.107661724090576
Epoch: 16, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1413 + XiCon Loss:3.0727 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4506282
	speed: 0.0394s/iter; left time: 875.8057s
	iters: 200, epoch: 17 | loss: 0.4711258
	speed: 0.0387s/iter; left time: 856.0997s
Epoch: 17 cost time: 10.323905944824219
Epoch: 17, Steps: 266 Train Loss: 0.4496 (Forecasting Loss:0.1414 + XiCon Loss:3.0815 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107426 --> 0.107413).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4340346
	speed: 0.0393s/iter; left time: 864.3304s
	iters: 200, epoch: 18 | loss: 0.4342355
	speed: 0.0378s/iter; left time: 826.7819s
Epoch: 18 cost time: 10.215237140655518
Epoch: 18, Steps: 266 Train Loss: 0.4490 (Forecasting Loss:0.1414 + XiCon Loss:3.0757 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107413 --> 0.107355).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4588772
	speed: 0.0392s/iter; left time: 850.1599s
	iters: 200, epoch: 19 | loss: 0.4329070
	speed: 0.0386s/iter; left time: 834.5503s
Epoch: 19 cost time: 10.270024061203003
Epoch: 19, Steps: 266 Train Loss: 0.4492 (Forecasting Loss:0.1413 + XiCon Loss:3.0789 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4481234
	speed: 0.0402s/iter; left time: 863.0204s
	iters: 200, epoch: 20 | loss: 0.4632317
	speed: 0.0377s/iter; left time: 804.1290s
Epoch: 20 cost time: 10.309336423873901
Epoch: 20, Steps: 266 Train Loss: 0.4494 (Forecasting Loss:0.1413 + XiCon Loss:3.0811 x Lambda(0.1)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0742
Validation loss decreased (0.107355 --> 0.107344).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4281073
	speed: 0.0394s/iter; left time: 835.4793s
	iters: 200, epoch: 21 | loss: 0.4352997
	speed: 0.0378s/iter; left time: 797.4346s
Epoch: 21 cost time: 10.193898677825928
Epoch: 21, Steps: 266 Train Loss: 0.4495 (Forecasting Loss:0.1414 + XiCon Loss:3.0814 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4425292
	speed: 0.0396s/iter; left time: 827.1940s
	iters: 200, epoch: 22 | loss: 0.4508339
	speed: 0.0382s/iter; left time: 794.4319s
Epoch: 22 cost time: 10.23141360282898
Epoch: 22, Steps: 266 Train Loss: 0.4493 (Forecasting Loss:0.1413 + XiCon Loss:3.0801 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4486446
	speed: 0.0400s/iter; left time: 826.1165s
	iters: 200, epoch: 23 | loss: 0.4612604
	speed: 0.0377s/iter; left time: 775.5485s
Epoch: 23 cost time: 10.30166506767273
Epoch: 23, Steps: 266 Train Loss: 0.4496 (Forecasting Loss:0.1413 + XiCon Loss:3.0822 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4367048
	speed: 0.0402s/iter; left time: 819.3470s
	iters: 200, epoch: 24 | loss: 0.4432002
	speed: 0.0377s/iter; left time: 765.4875s
Epoch: 24 cost time: 10.29844617843628
Epoch: 24, Steps: 266 Train Loss: 0.4493 (Forecasting Loss:0.1414 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4590462
	speed: 0.0382s/iter; left time: 768.3490s
	iters: 200, epoch: 25 | loss: 0.4449100
	speed: 0.0353s/iter; left time: 705.8761s
Epoch: 25 cost time: 9.734169960021973
Epoch: 25, Steps: 266 Train Loss: 0.4490 (Forecasting Loss:0.1414 + XiCon Loss:3.0764 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4395891
	speed: 0.0784s/iter; left time: 1557.0533s
	iters: 200, epoch: 26 | loss: 0.4456641
	speed: 0.0850s/iter; left time: 1679.0990s
Epoch: 26 cost time: 22.013100147247314
Epoch: 26, Steps: 266 Train Loss: 0.4492 (Forecasting Loss:0.1413 + XiCon Loss:3.0790 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4505624
	speed: 0.1080s/iter; left time: 2115.3415s
	iters: 200, epoch: 27 | loss: 0.4227478
	speed: 0.0960s/iter; left time: 1870.6400s
Epoch: 27 cost time: 25.982646226882935
Epoch: 27, Steps: 266 Train Loss: 0.4495 (Forecasting Loss:0.1414 + XiCon Loss:3.0814 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4489797
	speed: 0.0780s/iter; left time: 1506.4908s
	iters: 200, epoch: 28 | loss: 0.4518147
	speed: 0.0712s/iter; left time: 1367.7238s
Epoch: 28 cost time: 19.203527688980103
Epoch: 28, Steps: 266 Train Loss: 0.4490 (Forecasting Loss:0.1413 + XiCon Loss:3.0763 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4413176
	speed: 0.0473s/iter; left time: 900.8827s
	iters: 200, epoch: 29 | loss: 0.4486161
	speed: 0.0381s/iter; left time: 722.7706s
Epoch: 29 cost time: 10.896812200546265
Epoch: 29, Steps: 266 Train Loss: 0.4488 (Forecasting Loss:0.1414 + XiCon Loss:3.0741 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.4528965
	speed: 0.0383s/iter; left time: 719.2983s
	iters: 200, epoch: 30 | loss: 0.4515041
	speed: 0.0349s/iter; left time: 651.3593s
Epoch: 30 cost time: 9.66762399673462
Epoch: 30, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1414 + XiCon Loss:3.0718 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026410140097141266, mae:0.12197946012020111, mape:0.0985451489686966, mspe:0.019584786146879196 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.6908
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4971912
	speed: 0.0383s/iter; left time: 1016.0010s
	iters: 200, epoch: 1 | loss: 0.4837742
	speed: 0.0338s/iter; left time: 892.9688s
Epoch: 1 cost time: 9.541382312774658
Epoch: 1, Steps: 266 Train Loss: 0.4874 (Forecasting Loss:0.1661 + XiCon Loss:3.2136 x Lambda(0.1)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.0782
Validation loss decreased (inf --> 0.114085).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4876796
	speed: 0.0367s/iter; left time: 962.4960s
	iters: 200, epoch: 2 | loss: 0.4922004
	speed: 0.0361s/iter; left time: 944.1877s
Epoch: 2 cost time: 9.686872482299805
Epoch: 2, Steps: 266 Train Loss: 0.4827 (Forecasting Loss:0.1511 + XiCon Loss:3.3153 x Lambda(0.1)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.0785
Validation loss decreased (0.114085 --> 0.113732).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4347712
	speed: 0.0396s/iter; left time: 1027.1337s
	iters: 200, epoch: 3 | loss: 0.4692740
	speed: 0.0383s/iter; left time: 989.5721s
Epoch: 3 cost time: 10.341570615768433
Epoch: 3, Steps: 266 Train Loss: 0.4676 (Forecasting Loss:0.1455 + XiCon Loss:3.2215 x Lambda(0.1)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0754
Validation loss decreased (0.113732 --> 0.109747).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4454886
	speed: 0.0396s/iter; left time: 1017.7617s
	iters: 200, epoch: 4 | loss: 0.4601138
	speed: 0.0384s/iter; left time: 984.3590s
Epoch: 4 cost time: 10.330696105957031
Epoch: 4, Steps: 266 Train Loss: 0.4550 (Forecasting Loss:0.1436 + XiCon Loss:3.1145 x Lambda(0.1)), Vali MSE Loss: 0.1085 Test MSE Loss: 0.0750
Validation loss decreased (0.109747 --> 0.108543).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4327790
	speed: 0.0401s/iter; left time: 1020.8043s
	iters: 200, epoch: 5 | loss: 0.4343837
	speed: 0.0391s/iter; left time: 991.4556s
Epoch: 5 cost time: 10.391111612319946
Epoch: 5, Steps: 266 Train Loss: 0.4526 (Forecasting Loss:0.1425 + XiCon Loss:3.1004 x Lambda(0.1)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0744
Validation loss decreased (0.108543 --> 0.108105).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4371858
	speed: 0.0398s/iter; left time: 1002.3777s
	iters: 200, epoch: 6 | loss: 0.4312868
	speed: 0.0379s/iter; left time: 949.4508s
Epoch: 6 cost time: 10.25444221496582
Epoch: 6, Steps: 266 Train Loss: 0.4517 (Forecasting Loss:0.1421 + XiCon Loss:3.0961 x Lambda(0.1)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
Validation loss decreased (0.108105 --> 0.107597).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4430968
	speed: 0.0405s/iter; left time: 1009.2844s
	iters: 200, epoch: 7 | loss: 0.4365627
	speed: 0.0384s/iter; left time: 951.5009s
Epoch: 7 cost time: 10.373213529586792
Epoch: 7, Steps: 266 Train Loss: 0.4498 (Forecasting Loss:0.1417 + XiCon Loss:3.0807 x Lambda(0.1)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
Validation loss decreased (0.107597 --> 0.107560).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4600430
	speed: 0.0400s/iter; left time: 985.0731s
	iters: 200, epoch: 8 | loss: 0.4492574
	speed: 0.0385s/iter; left time: 945.3200s
Epoch: 8 cost time: 10.31262493133545
Epoch: 8, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1416 + XiCon Loss:3.0852 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107560 --> 0.107409).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4460376
	speed: 0.0400s/iter; left time: 973.7676s
	iters: 200, epoch: 9 | loss: 0.4419957
	speed: 0.0378s/iter; left time: 917.2384s
Epoch: 9 cost time: 10.309889554977417
Epoch: 9, Steps: 266 Train Loss: 0.4497 (Forecasting Loss:0.1416 + XiCon Loss:3.0809 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4422299
	speed: 0.0399s/iter; left time: 962.4318s
	iters: 200, epoch: 10 | loss: 0.4382578
	speed: 0.0377s/iter; left time: 906.1836s
Epoch: 10 cost time: 10.224177837371826
Epoch: 10, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1416 + XiCon Loss:3.0867 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107409 --> 0.107394).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4837101
	speed: 0.0401s/iter; left time: 956.3689s
	iters: 200, epoch: 11 | loss: 0.4417605
	speed: 0.0368s/iter; left time: 873.0961s
Epoch: 11 cost time: 10.195786714553833
Epoch: 11, Steps: 266 Train Loss: 0.4500 (Forecasting Loss:0.1416 + XiCon Loss:3.0844 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4481133
	speed: 0.0374s/iter; left time: 882.5989s
	iters: 200, epoch: 12 | loss: 0.4604018
	speed: 0.0356s/iter; left time: 835.8875s
Epoch: 12 cost time: 9.828941822052002
Epoch: 12, Steps: 266 Train Loss: 0.4495 (Forecasting Loss:0.1415 + XiCon Loss:3.0797 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4470825
	speed: 0.0409s/iter; left time: 953.3494s
	iters: 200, epoch: 13 | loss: 0.4357494
	speed: 0.0381s/iter; left time: 885.0022s
Epoch: 13 cost time: 10.465803146362305
Epoch: 13, Steps: 266 Train Loss: 0.4495 (Forecasting Loss:0.1415 + XiCon Loss:3.0796 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4638521
	speed: 0.0396s/iter; left time: 912.7311s
	iters: 200, epoch: 14 | loss: 0.4499857
	speed: 0.0380s/iter; left time: 872.1229s
Epoch: 14 cost time: 10.213457107543945
Epoch: 14, Steps: 266 Train Loss: 0.4497 (Forecasting Loss:0.1416 + XiCon Loss:3.0809 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4625969
	speed: 0.0396s/iter; left time: 903.0430s
	iters: 200, epoch: 15 | loss: 0.4662558
	speed: 0.0384s/iter; left time: 869.8519s
Epoch: 15 cost time: 10.291587829589844
Epoch: 15, Steps: 266 Train Loss: 0.4500 (Forecasting Loss:0.1415 + XiCon Loss:3.0849 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4459078
	speed: 0.0408s/iter; left time: 918.4152s
	iters: 200, epoch: 16 | loss: 0.4392326
	speed: 0.0383s/iter; left time: 857.8745s
Epoch: 16 cost time: 10.389837265014648
Epoch: 16, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1416 + XiCon Loss:3.0872 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4467795
	speed: 0.0405s/iter; left time: 900.6800s
	iters: 200, epoch: 17 | loss: 0.4315695
	speed: 0.0382s/iter; left time: 845.5879s
Epoch: 17 cost time: 10.39978575706482
Epoch: 17, Steps: 266 Train Loss: 0.4503 (Forecasting Loss:0.1415 + XiCon Loss:3.0879 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107394 --> 0.107376).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4479378
	speed: 0.0401s/iter; left time: 881.1990s
	iters: 200, epoch: 18 | loss: 0.4392236
	speed: 0.0381s/iter; left time: 834.4765s
Epoch: 18 cost time: 10.289506912231445
Epoch: 18, Steps: 266 Train Loss: 0.4501 (Forecasting Loss:0.1415 + XiCon Loss:3.0858 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4425604
	speed: 0.0405s/iter; left time: 879.9056s
	iters: 200, epoch: 19 | loss: 0.4554452
	speed: 0.0385s/iter; left time: 832.1145s
Epoch: 19 cost time: 10.387619972229004
Epoch: 19, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1415 + XiCon Loss:3.0875 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4559821
	speed: 0.0407s/iter; left time: 872.9496s
	iters: 200, epoch: 20 | loss: 0.4428461
	speed: 0.0384s/iter; left time: 820.5401s
Epoch: 20 cost time: 10.434430122375488
Epoch: 20, Steps: 266 Train Loss: 0.4498 (Forecasting Loss:0.1415 + XiCon Loss:3.0821 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4443541
	speed: 0.0395s/iter; left time: 837.3580s
	iters: 200, epoch: 21 | loss: 0.4545532
	speed: 0.0382s/iter; left time: 806.3273s
Epoch: 21 cost time: 10.211071014404297
Epoch: 21, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1416 + XiCon Loss:3.0863 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4382502
	speed: 0.0373s/iter; left time: 779.3370s
	iters: 200, epoch: 22 | loss: 0.4405755
	speed: 0.0387s/iter; left time: 806.1979s
Epoch: 22 cost time: 10.09480333328247
Epoch: 22, Steps: 266 Train Loss: 0.4497 (Forecasting Loss:0.1415 + XiCon Loss:3.0825 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4437649
	speed: 0.0399s/iter; left time: 823.7537s
	iters: 200, epoch: 23 | loss: 0.4468594
	speed: 0.0379s/iter; left time: 778.4566s
Epoch: 23 cost time: 10.309613466262817
Epoch: 23, Steps: 266 Train Loss: 0.4500 (Forecasting Loss:0.1415 + XiCon Loss:3.0841 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4522059
	speed: 0.0402s/iter; left time: 818.5519s
	iters: 200, epoch: 24 | loss: 0.4320721
	speed: 0.0380s/iter; left time: 770.3647s
Epoch: 24 cost time: 10.328392744064331
Epoch: 24, Steps: 266 Train Loss: 0.4500 (Forecasting Loss:0.1415 + XiCon Loss:3.0851 x Lambda(0.1)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4454616
	speed: 0.0397s/iter; left time: 799.2930s
	iters: 200, epoch: 25 | loss: 0.4540063
	speed: 0.0377s/iter; left time: 754.6425s
Epoch: 25 cost time: 10.302992820739746
Epoch: 25, Steps: 266 Train Loss: 0.4498 (Forecasting Loss:0.1415 + XiCon Loss:3.0823 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4779779
	speed: 0.0403s/iter; left time: 799.3712s
	iters: 200, epoch: 26 | loss: 0.4564572
	speed: 0.0383s/iter; left time: 756.0914s
Epoch: 26 cost time: 10.410316467285156
Epoch: 26, Steps: 266 Train Loss: 0.4501 (Forecasting Loss:0.1415 + XiCon Loss:3.0852 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4659857
	speed: 0.0403s/iter; left time: 789.9643s
	iters: 200, epoch: 27 | loss: 0.4502273
	speed: 0.0378s/iter; left time: 736.6523s
Epoch: 27 cost time: 10.316573143005371
Epoch: 27, Steps: 266 Train Loss: 0.4499 (Forecasting Loss:0.1415 + XiCon Loss:3.0840 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02639797143638134, mae:0.12191849946975708, mape:0.09850211441516876, mspe:0.01957257278263569 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.0376
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4988164
	speed: 0.0404s/iter; left time: 1069.9191s
	iters: 200, epoch: 1 | loss: 0.4566242
	speed: 0.0375s/iter; left time: 989.1883s
Epoch: 1 cost time: 10.296604633331299
Epoch: 1, Steps: 266 Train Loss: 0.4908 (Forecasting Loss:0.1642 + XiCon Loss:3.2664 x Lambda(0.1)), Vali MSE Loss: 0.1127 Test MSE Loss: 0.0776
Validation loss decreased (inf --> 0.112669).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4925833
	speed: 0.0400s/iter; left time: 1050.2707s
	iters: 200, epoch: 2 | loss: 0.4876105
	speed: 0.0387s/iter; left time: 1011.9929s
Epoch: 2 cost time: 10.388246536254883
Epoch: 2, Steps: 266 Train Loss: 0.4870 (Forecasting Loss:0.1505 + XiCon Loss:3.3652 x Lambda(0.1)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.0766
Validation loss decreased (0.112669 --> 0.110496).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4787930
	speed: 0.0376s/iter; left time: 976.0336s
	iters: 200, epoch: 3 | loss: 0.4770313
	speed: 0.0361s/iter; left time: 934.4587s
Epoch: 3 cost time: 9.853484392166138
Epoch: 3, Steps: 266 Train Loss: 0.4714 (Forecasting Loss:0.1451 + XiCon Loss:3.2630 x Lambda(0.1)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.0754
Validation loss decreased (0.110496 --> 0.109048).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4633511
	speed: 0.0410s/iter; left time: 1054.5320s
	iters: 200, epoch: 4 | loss: 0.4465581
	speed: 0.0388s/iter; left time: 993.8825s
Epoch: 4 cost time: 10.51576042175293
Epoch: 4, Steps: 266 Train Loss: 0.4662 (Forecasting Loss:0.1435 + XiCon Loss:3.2274 x Lambda(0.1)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0749
Validation loss decreased (0.109048 --> 0.107996).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4523492
	speed: 0.0403s/iter; left time: 1025.2617s
	iters: 200, epoch: 5 | loss: 0.4582116
	speed: 0.0384s/iter; left time: 973.1157s
Epoch: 5 cost time: 10.42453384399414
Epoch: 5, Steps: 266 Train Loss: 0.4626 (Forecasting Loss:0.1423 + XiCon Loss:3.2028 x Lambda(0.1)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0743
Validation loss decreased (0.107996 --> 0.107632).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4691470
	speed: 0.0400s/iter; left time: 1006.8585s
	iters: 200, epoch: 6 | loss: 0.4611172
	speed: 0.0382s/iter; left time: 956.9804s
Epoch: 6 cost time: 10.395312786102295
Epoch: 6, Steps: 266 Train Loss: 0.4603 (Forecasting Loss:0.1417 + XiCon Loss:3.1854 x Lambda(0.1)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
Validation loss decreased (0.107632 --> 0.107462).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4747053
	speed: 0.0413s/iter; left time: 1028.9848s
	iters: 200, epoch: 7 | loss: 0.4739913
	speed: 0.0381s/iter; left time: 944.1580s
Epoch: 7 cost time: 10.445878744125366
Epoch: 7, Steps: 266 Train Loss: 0.4601 (Forecasting Loss:0.1413 + XiCon Loss:3.1883 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0742
Validation loss decreased (0.107462 --> 0.107235).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4396751
	speed: 0.0411s/iter; left time: 1013.2624s
	iters: 200, epoch: 8 | loss: 0.4630112
	speed: 0.0382s/iter; left time: 936.8321s
Epoch: 8 cost time: 10.454756021499634
Epoch: 8, Steps: 266 Train Loss: 0.4589 (Forecasting Loss:0.1410 + XiCon Loss:3.1784 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
Validation loss decreased (0.107235 --> 0.107186).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4535921
	speed: 0.0408s/iter; left time: 995.2360s
	iters: 200, epoch: 9 | loss: 0.4489048
	speed: 0.0385s/iter; left time: 935.0287s
Epoch: 9 cost time: 10.51904559135437
Epoch: 9, Steps: 266 Train Loss: 0.4594 (Forecasting Loss:0.1408 + XiCon Loss:3.1858 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0742
Validation loss decreased (0.107186 --> 0.107177).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4647470
	speed: 0.0400s/iter; left time: 963.1859s
	iters: 200, epoch: 10 | loss: 0.4620607
	speed: 0.0374s/iter; left time: 898.0661s
Epoch: 10 cost time: 10.310227155685425
Epoch: 10, Steps: 266 Train Loss: 0.4591 (Forecasting Loss:0.1408 + XiCon Loss:3.1830 x Lambda(0.1)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4444699
	speed: 0.0407s/iter; left time: 970.6657s
	iters: 200, epoch: 11 | loss: 0.4584049
	speed: 0.0381s/iter; left time: 903.6283s
Epoch: 11 cost time: 10.414998292922974
Epoch: 11, Steps: 266 Train Loss: 0.4592 (Forecasting Loss:0.1407 + XiCon Loss:3.1849 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.0742
Validation loss decreased (0.107177 --> 0.107073).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4367868
	speed: 0.0406s/iter; left time: 958.2259s
	iters: 200, epoch: 12 | loss: 0.4575900
	speed: 0.0381s/iter; left time: 894.5813s
Epoch: 12 cost time: 10.222865343093872
Epoch: 12, Steps: 266 Train Loss: 0.4595 (Forecasting Loss:0.1407 + XiCon Loss:3.1881 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4643857
	speed: 0.0388s/iter; left time: 905.0963s
	iters: 200, epoch: 13 | loss: 0.4701560
	speed: 0.0390s/iter; left time: 905.5506s
Epoch: 13 cost time: 10.251543998718262
Epoch: 13, Steps: 266 Train Loss: 0.4590 (Forecasting Loss:0.1407 + XiCon Loss:3.1830 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4491446
	speed: 0.0403s/iter; left time: 928.9835s
	iters: 200, epoch: 14 | loss: 0.4576369
	speed: 0.0392s/iter; left time: 899.6757s
Epoch: 14 cost time: 10.424534320831299
Epoch: 14, Steps: 266 Train Loss: 0.4583 (Forecasting Loss:0.1406 + XiCon Loss:3.1770 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4506433
	speed: 0.0405s/iter; left time: 923.5122s
	iters: 200, epoch: 15 | loss: 0.4601867
	speed: 0.0388s/iter; left time: 878.8736s
Epoch: 15 cost time: 10.472161293029785
Epoch: 15, Steps: 266 Train Loss: 0.4589 (Forecasting Loss:0.1406 + XiCon Loss:3.1831 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.0743
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4693671
	speed: 0.0399s/iter; left time: 899.2993s
	iters: 200, epoch: 16 | loss: 0.4348295
	speed: 0.0376s/iter; left time: 842.8184s
Epoch: 16 cost time: 10.30159854888916
Epoch: 16, Steps: 266 Train Loss: 0.4592 (Forecasting Loss:0.1406 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4478417
	speed: 0.0407s/iter; left time: 905.8125s
	iters: 200, epoch: 17 | loss: 0.4453355
	speed: 0.0388s/iter; left time: 860.1494s
Epoch: 17 cost time: 10.474518775939941
Epoch: 17, Steps: 266 Train Loss: 0.4594 (Forecasting Loss:0.1407 + XiCon Loss:3.1866 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4609615
	speed: 0.0413s/iter; left time: 908.1546s
	iters: 200, epoch: 18 | loss: 0.4587883
	speed: 0.0387s/iter; left time: 846.1187s
Epoch: 18 cost time: 10.518072366714478
Epoch: 18, Steps: 266 Train Loss: 0.4589 (Forecasting Loss:0.1407 + XiCon Loss:3.1821 x Lambda(0.1)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.0743
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4628159
	speed: 0.0402s/iter; left time: 873.8283s
	iters: 200, epoch: 19 | loss: 0.4554450
	speed: 0.0379s/iter; left time: 819.2784s
Epoch: 19 cost time: 10.322052240371704
Epoch: 19, Steps: 266 Train Loss: 0.4588 (Forecasting Loss:0.1406 + XiCon Loss:3.1821 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4640181
	speed: 0.0403s/iter; left time: 864.1089s
	iters: 200, epoch: 20 | loss: 0.4585700
	speed: 0.0375s/iter; left time: 801.5427s
Epoch: 20 cost time: 10.330069541931152
Epoch: 20, Steps: 266 Train Loss: 0.4590 (Forecasting Loss:0.1407 + XiCon Loss:3.1829 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4506039
	speed: 0.0398s/iter; left time: 843.1577s
	iters: 200, epoch: 21 | loss: 0.4425848
	speed: 0.0385s/iter; left time: 811.3010s
Epoch: 21 cost time: 10.367167472839355
Epoch: 21, Steps: 266 Train Loss: 0.4591 (Forecasting Loss:0.1407 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0743
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026495354250073433, mae:0.12198831886053085, mape:0.09852225333452225, mspe:0.019554533064365387 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9988
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4781036
	speed: 0.0394s/iter; left time: 1045.0599s
	iters: 200, epoch: 1 | loss: 0.4607054
	speed: 0.0371s/iter; left time: 978.9769s
Epoch: 1 cost time: 10.043127298355103
Epoch: 1, Steps: 266 Train Loss: 0.4936 (Forecasting Loss:0.1655 + XiCon Loss:3.2812 x Lambda(0.1)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.0779
Validation loss decreased (inf --> 0.114333).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4889270
	speed: 0.0400s/iter; left time: 1049.3173s
	iters: 200, epoch: 2 | loss: 0.4371476
	speed: 0.0384s/iter; left time: 1003.3646s
Epoch: 2 cost time: 10.471620798110962
Epoch: 2, Steps: 266 Train Loss: 0.4726 (Forecasting Loss:0.1509 + XiCon Loss:3.2169 x Lambda(0.1)), Vali MSE Loss: 0.1112 Test MSE Loss: 0.0759
Validation loss decreased (0.114333 --> 0.111189).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4466784
	speed: 0.0407s/iter; left time: 1057.0692s
	iters: 200, epoch: 3 | loss: 0.4675512
	speed: 0.0397s/iter; left time: 1026.0240s
Epoch: 3 cost time: 10.569257974624634
Epoch: 3, Steps: 266 Train Loss: 0.4549 (Forecasting Loss:0.1450 + XiCon Loss:3.0993 x Lambda(0.1)), Vali MSE Loss: 0.1099 Test MSE Loss: 0.0756
Validation loss decreased (0.111189 --> 0.109883).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4428167
	speed: 0.0406s/iter; left time: 1044.4273s
	iters: 200, epoch: 4 | loss: 0.4506327
	speed: 0.0394s/iter; left time: 1008.9174s
Epoch: 4 cost time: 10.550316333770752
Epoch: 4, Steps: 266 Train Loss: 0.4512 (Forecasting Loss:0.1433 + XiCon Loss:3.0787 x Lambda(0.1)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0747
Validation loss decreased (0.109883 --> 0.108395).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4561622
	speed: 0.0408s/iter; left time: 1037.9929s
	iters: 200, epoch: 5 | loss: 0.4453561
	speed: 0.0388s/iter; left time: 983.4386s
Epoch: 5 cost time: 10.537669897079468
Epoch: 5, Steps: 266 Train Loss: 0.4490 (Forecasting Loss:0.1425 + XiCon Loss:3.0656 x Lambda(0.1)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.0741
Validation loss decreased (0.108395 --> 0.108151).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4468426
	speed: 0.0414s/iter; left time: 1041.2349s
	iters: 200, epoch: 6 | loss: 0.4418964
	speed: 0.0389s/iter; left time: 975.9006s
Epoch: 6 cost time: 10.566256284713745
Epoch: 6, Steps: 266 Train Loss: 0.4478 (Forecasting Loss:0.1419 + XiCon Loss:3.0598 x Lambda(0.1)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.0742
Validation loss decreased (0.108151 --> 0.107912).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4499889
	speed: 0.0413s/iter; left time: 1029.5974s
	iters: 200, epoch: 7 | loss: 0.4561758
	speed: 0.0390s/iter; left time: 966.5759s
Epoch: 7 cost time: 10.500307559967041
Epoch: 7, Steps: 266 Train Loss: 0.4479 (Forecasting Loss:0.1416 + XiCon Loss:3.0624 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0741
Validation loss decreased (0.107912 --> 0.107772).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4526466
	speed: 0.0406s/iter; left time: 1001.0979s
	iters: 200, epoch: 8 | loss: 0.4265281
	speed: 0.0390s/iter; left time: 956.7821s
Epoch: 8 cost time: 10.485982656478882
Epoch: 8, Steps: 266 Train Loss: 0.4477 (Forecasting Loss:0.1415 + XiCon Loss:3.0623 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4589229
	speed: 0.0412s/iter; left time: 1004.0629s
	iters: 200, epoch: 9 | loss: 0.4401754
	speed: 0.0399s/iter; left time: 969.0842s
Epoch: 9 cost time: 10.435440301895142
Epoch: 9, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1414 + XiCon Loss:3.0582 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107772 --> 0.107726).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4460607
	speed: 0.0379s/iter; left time: 913.3139s
	iters: 200, epoch: 10 | loss: 0.4272645
	speed: 0.0388s/iter; left time: 931.0011s
Epoch: 10 cost time: 10.19434404373169
Epoch: 10, Steps: 266 Train Loss: 0.4475 (Forecasting Loss:0.1414 + XiCon Loss:3.0619 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107726 --> 0.107703).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4633409
	speed: 0.0406s/iter; left time: 969.0928s
	iters: 200, epoch: 11 | loss: 0.4355298
	speed: 0.0383s/iter; left time: 910.0031s
Epoch: 11 cost time: 10.421962261199951
Epoch: 11, Steps: 266 Train Loss: 0.4474 (Forecasting Loss:0.1413 + XiCon Loss:3.0603 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107703 --> 0.107690).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4477521
	speed: 0.0411s/iter; left time: 968.6334s
	iters: 200, epoch: 12 | loss: 0.4304765
	speed: 0.0394s/iter; left time: 925.2391s
Epoch: 12 cost time: 10.615114450454712
Epoch: 12, Steps: 266 Train Loss: 0.4469 (Forecasting Loss:0.1413 + XiCon Loss:3.0560 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107690 --> 0.107665).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4590837
	speed: 0.0407s/iter; left time: 948.1578s
	iters: 200, epoch: 13 | loss: 0.4459233
	speed: 0.0393s/iter; left time: 912.6232s
Epoch: 13 cost time: 10.560900449752808
Epoch: 13, Steps: 266 Train Loss: 0.4472 (Forecasting Loss:0.1414 + XiCon Loss:3.0584 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
Validation loss decreased (0.107665 --> 0.107652).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4545172
	speed: 0.0412s/iter; left time: 950.2796s
	iters: 200, epoch: 14 | loss: 0.4426148
	speed: 0.0392s/iter; left time: 899.1550s
Epoch: 14 cost time: 10.674920558929443
Epoch: 14, Steps: 266 Train Loss: 0.4471 (Forecasting Loss:0.1413 + XiCon Loss:3.0579 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4400334
	speed: 0.0409s/iter; left time: 932.2012s
	iters: 200, epoch: 15 | loss: 0.4380416
	speed: 0.0391s/iter; left time: 885.8083s
Epoch: 15 cost time: 10.606368064880371
Epoch: 15, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1414 + XiCon Loss:3.0594 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4563356
	speed: 0.0399s/iter; left time: 897.6306s
	iters: 200, epoch: 16 | loss: 0.4305387
	speed: 0.0386s/iter; left time: 865.3713s
Epoch: 16 cost time: 10.399012804031372
Epoch: 16, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1413 + XiCon Loss:3.0598 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4213559
	speed: 0.0407s/iter; left time: 906.2979s
	iters: 200, epoch: 17 | loss: 0.4481246
	speed: 0.0389s/iter; left time: 861.7115s
Epoch: 17 cost time: 10.531798839569092
Epoch: 17, Steps: 266 Train Loss: 0.4471 (Forecasting Loss:0.1414 + XiCon Loss:3.0570 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4346865
	speed: 0.0403s/iter; left time: 884.6813s
	iters: 200, epoch: 18 | loss: 0.4403730
	speed: 0.0385s/iter; left time: 843.4302s
Epoch: 18 cost time: 10.46896505355835
Epoch: 18, Steps: 266 Train Loss: 0.4468 (Forecasting Loss:0.1414 + XiCon Loss:3.0543 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4616991
	speed: 0.0399s/iter; left time: 865.9887s
	iters: 200, epoch: 19 | loss: 0.4479869
	speed: 0.0356s/iter; left time: 770.4466s
Epoch: 19 cost time: 10.028719663619995
Epoch: 19, Steps: 266 Train Loss: 0.4471 (Forecasting Loss:0.1414 + XiCon Loss:3.0567 x Lambda(0.1)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107652 --> 0.107616).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4470286
	speed: 0.0418s/iter; left time: 896.1886s
	iters: 200, epoch: 20 | loss: 0.4295688
	speed: 0.0386s/iter; left time: 824.0241s
Epoch: 20 cost time: 10.607877969741821
Epoch: 20, Steps: 266 Train Loss: 0.4476 (Forecasting Loss:0.1414 + XiCon Loss:3.0621 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4447067
	speed: 0.0402s/iter; left time: 851.4058s
	iters: 200, epoch: 21 | loss: 0.4252271
	speed: 0.0388s/iter; left time: 818.8881s
Epoch: 21 cost time: 10.50045108795166
Epoch: 21, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1414 + XiCon Loss:3.0595 x Lambda(0.1)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4472378
	speed: 0.0408s/iter; left time: 852.7705s
	iters: 200, epoch: 22 | loss: 0.4306361
	speed: 0.0390s/iter; left time: 811.4657s
Epoch: 22 cost time: 10.531676769256592
Epoch: 22, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1413 + XiCon Loss:3.0595 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4278798
	speed: 0.0402s/iter; left time: 830.5767s
	iters: 200, epoch: 23 | loss: 0.4349304
	speed: 0.0388s/iter; left time: 796.8237s
Epoch: 23 cost time: 10.45369029045105
Epoch: 23, Steps: 266 Train Loss: 0.4473 (Forecasting Loss:0.1414 + XiCon Loss:3.0591 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4538362
	speed: 0.0408s/iter; left time: 832.1253s
	iters: 200, epoch: 24 | loss: 0.4444421
	speed: 0.0392s/iter; left time: 795.9801s
Epoch: 24 cost time: 10.624826908111572
Epoch: 24, Steps: 266 Train Loss: 0.4471 (Forecasting Loss:0.1413 + XiCon Loss:3.0581 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4255044
	speed: 0.0403s/iter; left time: 810.9794s
	iters: 200, epoch: 25 | loss: 0.4323378
	speed: 0.0392s/iter; left time: 785.4571s
Epoch: 25 cost time: 10.548228025436401
Epoch: 25, Steps: 266 Train Loss: 0.4472 (Forecasting Loss:0.1414 + XiCon Loss:3.0578 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4566720
	speed: 0.0409s/iter; left time: 812.4477s
	iters: 200, epoch: 26 | loss: 0.4564611
	speed: 0.0387s/iter; left time: 764.9399s
Epoch: 26 cost time: 10.482157230377197
Epoch: 26, Steps: 266 Train Loss: 0.4474 (Forecasting Loss:0.1414 + XiCon Loss:3.0599 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4492372
	speed: 0.0415s/iter; left time: 812.2655s
	iters: 200, epoch: 27 | loss: 0.4306886
	speed: 0.0384s/iter; left time: 747.6766s
Epoch: 27 cost time: 10.583636045455933
Epoch: 27, Steps: 266 Train Loss: 0.4476 (Forecasting Loss:0.1414 + XiCon Loss:3.0623 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4555616
	speed: 0.0404s/iter; left time: 780.6464s
	iters: 200, epoch: 28 | loss: 0.4421383
	speed: 0.0393s/iter; left time: 754.7102s
Epoch: 28 cost time: 10.505864143371582
Epoch: 28, Steps: 266 Train Loss: 0.4474 (Forecasting Loss:0.1414 + XiCon Loss:3.0607 x Lambda(0.1)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4512431
	speed: 0.0374s/iter; left time: 713.5127s
	iters: 200, epoch: 29 | loss: 0.4457533
	speed: 0.0394s/iter; left time: 746.9694s
Epoch: 29 cost time: 10.230891704559326
Epoch: 29, Steps: 266 Train Loss: 0.4471 (Forecasting Loss:0.1413 + XiCon Loss:3.0579 x Lambda(0.1)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02630189247429371, mae:0.1217266172170639, mape:0.09850327670574188, mspe:0.01969982497394085 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0264+-0.00009, MAE:0.1219+-0.00014, MAPE:0.0985+-0.00004, MSPE:0.0196+-0.00007, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1738
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5223778
	speed: 0.0539s/iter; left time: 1423.5441s
	iters: 200, epoch: 1 | loss: 0.5043849
	speed: 0.0474s/iter; left time: 1246.4382s
Epoch: 1 cost time: 13.230949878692627
Epoch: 1, Steps: 265 Train Loss: 0.5226 (Forecasting Loss:0.2082 + XiCon Loss:3.1440 x Lambda(0.1)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.0990
Validation loss decreased (inf --> 0.146803).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5388559
	speed: 0.0537s/iter; left time: 1402.5383s
	iters: 200, epoch: 2 | loss: 0.5687378
	speed: 0.0489s/iter; left time: 1272.9114s
Epoch: 2 cost time: 13.470150470733643
Epoch: 2, Steps: 265 Train Loss: 0.5282 (Forecasting Loss:0.1980 + XiCon Loss:3.3026 x Lambda(0.1)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.0961
Validation loss decreased (0.146803 --> 0.145475).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5328821
	speed: 0.0504s/iter; left time: 1305.0373s
	iters: 200, epoch: 3 | loss: 0.5056089
	speed: 0.0490s/iter; left time: 1262.9857s
Epoch: 3 cost time: 13.180462837219238
Epoch: 3, Steps: 265 Train Loss: 0.5218 (Forecasting Loss:0.1930 + XiCon Loss:3.2880 x Lambda(0.1)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0956
Validation loss decreased (0.145475 --> 0.143548).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5269852
	speed: 0.0505s/iter; left time: 1291.9810s
	iters: 200, epoch: 4 | loss: 0.5271363
	speed: 0.0497s/iter; left time: 1268.2752s
Epoch: 4 cost time: 13.333053350448608
Epoch: 4, Steps: 265 Train Loss: 0.5121 (Forecasting Loss:0.1913 + XiCon Loss:3.2077 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5022362
	speed: 0.0512s/iter; left time: 1298.1790s
	iters: 200, epoch: 5 | loss: 0.5181806
	speed: 0.0491s/iter; left time: 1239.0762s
Epoch: 5 cost time: 13.270829677581787
Epoch: 5, Steps: 265 Train Loss: 0.5081 (Forecasting Loss:0.1905 + XiCon Loss:3.1756 x Lambda(0.1)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0953
Validation loss decreased (0.143548 --> 0.142643).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5072826
	speed: 0.0513s/iter; left time: 1286.5893s
	iters: 200, epoch: 6 | loss: 0.5014325
	speed: 0.0470s/iter; left time: 1174.6750s
Epoch: 6 cost time: 12.992405891418457
Epoch: 6, Steps: 265 Train Loss: 0.5036 (Forecasting Loss:0.1898 + XiCon Loss:3.1383 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0945
Validation loss decreased (0.142643 --> 0.141952).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4733228
	speed: 0.0514s/iter; left time: 1274.3956s
	iters: 200, epoch: 7 | loss: 0.5033033
	speed: 0.0498s/iter; left time: 1230.6531s
Epoch: 7 cost time: 13.451875686645508
Epoch: 7, Steps: 265 Train Loss: 0.5032 (Forecasting Loss:0.1894 + XiCon Loss:3.1384 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5007310
	speed: 0.0520s/iter; left time: 1276.8274s
	iters: 200, epoch: 8 | loss: 0.5000660
	speed: 0.0500s/iter; left time: 1222.1918s
Epoch: 8 cost time: 13.489900350570679
Epoch: 8, Steps: 265 Train Loss: 0.5032 (Forecasting Loss:0.1894 + XiCon Loss:3.1386 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
Validation loss decreased (0.141952 --> 0.141866).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4792309
	speed: 0.0509s/iter; left time: 1236.9567s
	iters: 200, epoch: 9 | loss: 0.4828745
	speed: 0.0495s/iter; left time: 1197.6991s
Epoch: 9 cost time: 13.32478666305542
Epoch: 9, Steps: 265 Train Loss: 0.5025 (Forecasting Loss:0.1892 + XiCon Loss:3.1333 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
Validation loss decreased (0.141866 --> 0.141813).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4704758
	speed: 0.0496s/iter; left time: 1191.5022s
	iters: 200, epoch: 10 | loss: 0.5145302
	speed: 0.0506s/iter; left time: 1209.2502s
Epoch: 10 cost time: 13.206862926483154
Epoch: 10, Steps: 265 Train Loss: 0.5016 (Forecasting Loss:0.1892 + XiCon Loss:3.1241 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
Validation loss decreased (0.141813 --> 0.141676).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5011151
	speed: 0.0525s/iter; left time: 1247.5335s
	iters: 200, epoch: 11 | loss: 0.5050952
	speed: 0.0497s/iter; left time: 1174.5842s
Epoch: 11 cost time: 13.512211084365845
Epoch: 11, Steps: 265 Train Loss: 0.5011 (Forecasting Loss:0.1892 + XiCon Loss:3.1196 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4734117
	speed: 0.0513s/iter; left time: 1204.1946s
	iters: 200, epoch: 12 | loss: 0.4950609
	speed: 0.0505s/iter; left time: 1181.2995s
Epoch: 12 cost time: 13.417471408843994
Epoch: 12, Steps: 265 Train Loss: 0.5018 (Forecasting Loss:0.1891 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.141676 --> 0.141637).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4937031
	speed: 0.0519s/iter; left time: 1205.8927s
	iters: 200, epoch: 13 | loss: 0.4856231
	speed: 0.0494s/iter; left time: 1143.2957s
Epoch: 13 cost time: 13.473996639251709
Epoch: 13, Steps: 265 Train Loss: 0.5019 (Forecasting Loss:0.1891 + XiCon Loss:3.1279 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5257504
	speed: 0.0484s/iter; left time: 1111.4774s
	iters: 200, epoch: 14 | loss: 0.5156862
	speed: 0.0489s/iter; left time: 1116.7253s
Epoch: 14 cost time: 12.931679487228394
Epoch: 14, Steps: 265 Train Loss: 0.5020 (Forecasting Loss:0.1892 + XiCon Loss:3.1284 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5351572
	speed: 0.0525s/iter; left time: 1192.3737s
	iters: 200, epoch: 15 | loss: 0.5220703
	speed: 0.0500s/iter; left time: 1129.9893s
Epoch: 15 cost time: 13.46503734588623
Epoch: 15, Steps: 265 Train Loss: 0.5019 (Forecasting Loss:0.1889 + XiCon Loss:3.1293 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4858257
	speed: 0.0506s/iter; left time: 1134.1791s
	iters: 200, epoch: 16 | loss: 0.4831983
	speed: 0.0490s/iter; left time: 1092.9662s
Epoch: 16 cost time: 13.205069303512573
Epoch: 16, Steps: 265 Train Loss: 0.5021 (Forecasting Loss:0.1891 + XiCon Loss:3.1304 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.141637 --> 0.141575).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4703598
	speed: 0.0505s/iter; left time: 1118.1499s
	iters: 200, epoch: 17 | loss: 0.4733073
	speed: 0.0504s/iter; left time: 1111.7917s
Epoch: 17 cost time: 13.332885026931763
Epoch: 17, Steps: 265 Train Loss: 0.5017 (Forecasting Loss:0.1891 + XiCon Loss:3.1262 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4887005
	speed: 0.0530s/iter; left time: 1159.9808s
	iters: 200, epoch: 18 | loss: 0.5122526
	speed: 0.0506s/iter; left time: 1103.3169s
Epoch: 18 cost time: 13.513098239898682
Epoch: 18, Steps: 265 Train Loss: 0.5023 (Forecasting Loss:0.1890 + XiCon Loss:3.1331 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4996725
	speed: 0.0523s/iter; left time: 1130.3493s
	iters: 200, epoch: 19 | loss: 0.4971612
	speed: 0.0497s/iter; left time: 1069.9481s
Epoch: 19 cost time: 13.455835103988647
Epoch: 19, Steps: 265 Train Loss: 0.5018 (Forecasting Loss:0.1891 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5313882
	speed: 0.0530s/iter; left time: 1132.1332s
	iters: 200, epoch: 20 | loss: 0.5204203
	speed: 0.0493s/iter; left time: 1048.0115s
Epoch: 20 cost time: 13.435476541519165
Epoch: 20, Steps: 265 Train Loss: 0.5022 (Forecasting Loss:0.1891 + XiCon Loss:3.1314 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5216776
	speed: 0.0514s/iter; left time: 1085.2839s
	iters: 200, epoch: 21 | loss: 0.4967234
	speed: 0.0505s/iter; left time: 1060.8194s
Epoch: 21 cost time: 13.323695182800293
Epoch: 21, Steps: 265 Train Loss: 0.5018 (Forecasting Loss:0.1890 + XiCon Loss:3.1277 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5033433
	speed: 0.0512s/iter; left time: 1067.2834s
	iters: 200, epoch: 22 | loss: 0.4729705
	speed: 0.0507s/iter; left time: 1050.4275s
Epoch: 22 cost time: 13.432647228240967
Epoch: 22, Steps: 265 Train Loss: 0.5018 (Forecasting Loss:0.1890 + XiCon Loss:3.1274 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4891717
	speed: 0.0515s/iter; left time: 1059.2227s
	iters: 200, epoch: 23 | loss: 0.5168158
	speed: 0.0497s/iter; left time: 1017.0732s
Epoch: 23 cost time: 13.307791709899902
Epoch: 23, Steps: 265 Train Loss: 0.5016 (Forecasting Loss:0.1892 + XiCon Loss:3.1246 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.5267054
	speed: 0.0513s/iter; left time: 1041.0179s
	iters: 200, epoch: 24 | loss: 0.5298377
	speed: 0.0503s/iter; left time: 1016.9747s
Epoch: 24 cost time: 13.448309183120728
Epoch: 24, Steps: 265 Train Loss: 0.5017 (Forecasting Loss:0.1891 + XiCon Loss:3.1264 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5531706
	speed: 0.0517s/iter; left time: 1035.5859s
	iters: 200, epoch: 25 | loss: 0.4941022
	speed: 0.0484s/iter; left time: 965.7582s
Epoch: 25 cost time: 13.389567852020264
Epoch: 25, Steps: 265 Train Loss: 0.5023 (Forecasting Loss:0.1891 + XiCon Loss:3.1322 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.5199056
	speed: 0.0515s/iter; left time: 1018.1635s
	iters: 200, epoch: 26 | loss: 0.5149782
	speed: 0.0495s/iter; left time: 972.9885s
Epoch: 26 cost time: 13.346935749053955
Epoch: 26, Steps: 265 Train Loss: 0.5025 (Forecasting Loss:0.1891 + XiCon Loss:3.1347 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03955695405602455, mae:0.14971129596233368, mape:0.11877008527517319, mspe:0.0264067854732275 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5164882
	speed: 0.0497s/iter; left time: 1311.2831s
	iters: 200, epoch: 1 | loss: 0.4894588
	speed: 0.0472s/iter; left time: 1240.5755s
Epoch: 1 cost time: 12.727609634399414
Epoch: 1, Steps: 265 Train Loss: 0.5218 (Forecasting Loss:0.2088 + XiCon Loss:3.1305 x Lambda(0.1)), Vali MSE Loss: 0.1512 Test MSE Loss: 0.1003
Validation loss decreased (inf --> 0.151232).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5524114
	speed: 0.0517s/iter; left time: 1352.4875s
	iters: 200, epoch: 2 | loss: 0.5010272
	speed: 0.0481s/iter; left time: 1252.5104s
Epoch: 2 cost time: 13.163935422897339
Epoch: 2, Steps: 265 Train Loss: 0.5213 (Forecasting Loss:0.1987 + XiCon Loss:3.2264 x Lambda(0.1)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0971
Validation loss decreased (0.151232 --> 0.146086).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4790458
	speed: 0.0506s/iter; left time: 1310.1503s
	iters: 200, epoch: 3 | loss: 0.4886474
	speed: 0.0493s/iter; left time: 1270.4750s
Epoch: 3 cost time: 13.132786273956299
Epoch: 3, Steps: 265 Train Loss: 0.4964 (Forecasting Loss:0.1927 + XiCon Loss:3.0370 x Lambda(0.1)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0969
Validation loss decreased (0.146086 --> 0.143709).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4780419
	speed: 0.0520s/iter; left time: 1331.1986s
	iters: 200, epoch: 4 | loss: 0.4915541
	speed: 0.0490s/iter; left time: 1249.0418s
Epoch: 4 cost time: 13.319612264633179
Epoch: 4, Steps: 265 Train Loss: 0.4933 (Forecasting Loss:0.1911 + XiCon Loss:3.0222 x Lambda(0.1)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0959
Validation loss decreased (0.143709 --> 0.142185).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4955124
	speed: 0.0500s/iter; left time: 1266.5125s
	iters: 200, epoch: 5 | loss: 0.4756224
	speed: 0.0504s/iter; left time: 1273.3771s
Epoch: 5 cost time: 13.311956882476807
Epoch: 5, Steps: 265 Train Loss: 0.4915 (Forecasting Loss:0.1896 + XiCon Loss:3.0191 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0996
Validation loss decreased (0.142185 --> 0.141729).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4844897
	speed: 0.0514s/iter; left time: 1289.7468s
	iters: 200, epoch: 6 | loss: 0.4549524
	speed: 0.0492s/iter; left time: 1228.7867s
Epoch: 6 cost time: 13.261529445648193
Epoch: 6, Steps: 265 Train Loss: 0.4913 (Forecasting Loss:0.1892 + XiCon Loss:3.0203 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.1002
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4900753
	speed: 0.0517s/iter; left time: 1281.5026s
	iters: 200, epoch: 7 | loss: 0.4994251
	speed: 0.0495s/iter; left time: 1224.2621s
Epoch: 7 cost time: 13.37538456916809
Epoch: 7, Steps: 265 Train Loss: 0.4911 (Forecasting Loss:0.1889 + XiCon Loss:3.0220 x Lambda(0.1)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0997
Validation loss decreased (0.141729 --> 0.141508).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4697256
	speed: 0.0523s/iter; left time: 1283.3699s
	iters: 200, epoch: 8 | loss: 0.4910071
	speed: 0.0500s/iter; left time: 1222.1444s
Epoch: 8 cost time: 13.464645147323608
Epoch: 8, Steps: 265 Train Loss: 0.4898 (Forecasting Loss:0.1887 + XiCon Loss:3.0110 x Lambda(0.1)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0990
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4907486
	speed: 0.0508s/iter; left time: 1232.9097s
	iters: 200, epoch: 9 | loss: 0.4710404
	speed: 0.0501s/iter; left time: 1210.4063s
Epoch: 9 cost time: 13.411659717559814
Epoch: 9, Steps: 265 Train Loss: 0.4900 (Forecasting Loss:0.1885 + XiCon Loss:3.0142 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0995
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5197644
	speed: 0.0497s/iter; left time: 1193.2007s
	iters: 200, epoch: 10 | loss: 0.4842184
	speed: 0.0506s/iter; left time: 1210.9998s
Epoch: 10 cost time: 13.32573914527893
Epoch: 10, Steps: 265 Train Loss: 0.4902 (Forecasting Loss:0.1885 + XiCon Loss:3.0175 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0994
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4656001
	speed: 0.0520s/iter; left time: 1233.9266s
	iters: 200, epoch: 11 | loss: 0.4821306
	speed: 0.0492s/iter; left time: 1162.8266s
Epoch: 11 cost time: 13.261818885803223
Epoch: 11, Steps: 265 Train Loss: 0.4902 (Forecasting Loss:0.1886 + XiCon Loss:3.0164 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0994
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5009357
	speed: 0.0521s/iter; left time: 1224.4777s
	iters: 200, epoch: 12 | loss: 0.4994541
	speed: 0.0499s/iter; left time: 1167.2784s
Epoch: 12 cost time: 13.467669248580933
Epoch: 12, Steps: 265 Train Loss: 0.4898 (Forecasting Loss:0.1885 + XiCon Loss:3.0134 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0993
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4830836
	speed: 0.0517s/iter; left time: 1201.5436s
	iters: 200, epoch: 13 | loss: 0.4850096
	speed: 0.0501s/iter; left time: 1157.6357s
Epoch: 13 cost time: 13.480694770812988
Epoch: 13, Steps: 265 Train Loss: 0.4898 (Forecasting Loss:0.1885 + XiCon Loss:3.0130 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0993
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4579313
	speed: 0.0521s/iter; left time: 1195.4562s
	iters: 200, epoch: 14 | loss: 0.4988926
	speed: 0.0499s/iter; left time: 1139.6576s
Epoch: 14 cost time: 13.450652599334717
Epoch: 14, Steps: 265 Train Loss: 0.4900 (Forecasting Loss:0.1886 + XiCon Loss:3.0142 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0994
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4975204
	speed: 0.0523s/iter; left time: 1186.5483s
	iters: 200, epoch: 15 | loss: 0.4716912
	speed: 0.0498s/iter; left time: 1124.3589s
Epoch: 15 cost time: 13.407329082489014
Epoch: 15, Steps: 265 Train Loss: 0.4896 (Forecasting Loss:0.1885 + XiCon Loss:3.0114 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0994
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4889249
	speed: 0.0509s/iter; left time: 1142.3497s
	iters: 200, epoch: 16 | loss: 0.4873501
	speed: 0.0489s/iter; left time: 1092.6256s
Epoch: 16 cost time: 13.19340467453003
Epoch: 16, Steps: 265 Train Loss: 0.4897 (Forecasting Loss:0.1885 + XiCon Loss:3.0124 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0994
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4782194
	speed: 0.0516s/iter; left time: 1142.4087s
	iters: 200, epoch: 17 | loss: 0.4801628
	speed: 0.0491s/iter; left time: 1082.9232s
Epoch: 17 cost time: 13.165047645568848
Epoch: 17, Steps: 265 Train Loss: 0.4900 (Forecasting Loss:0.1884 + XiCon Loss:3.0160 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0994
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04573015123605728, mae:0.153661847114563, mape:0.12146586924791336, mspe:0.028997346758842468 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9383
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5509780
	speed: 0.0498s/iter; left time: 1314.8931s
	iters: 200, epoch: 1 | loss: 0.5166049
	speed: 0.0468s/iter; left time: 1231.4590s
Epoch: 1 cost time: 12.735250473022461
Epoch: 1, Steps: 265 Train Loss: 0.5200 (Forecasting Loss:0.2048 + XiCon Loss:3.1518 x Lambda(0.1)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.0989
Validation loss decreased (inf --> 0.147724).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5361902
	speed: 0.0538s/iter; left time: 1404.8982s
	iters: 200, epoch: 2 | loss: 0.5492492
	speed: 0.0499s/iter; left time: 1299.5491s
Epoch: 2 cost time: 13.62228775024414
Epoch: 2, Steps: 265 Train Loss: 0.5212 (Forecasting Loss:0.1979 + XiCon Loss:3.2338 x Lambda(0.1)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0978
Validation loss decreased (0.147724 --> 0.146502).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5289893
	speed: 0.0505s/iter; left time: 1306.1868s
	iters: 200, epoch: 3 | loss: 0.5338921
	speed: 0.0488s/iter; left time: 1258.3484s
Epoch: 3 cost time: 13.14986276626587
Epoch: 3, Steps: 265 Train Loss: 0.5209 (Forecasting Loss:0.1928 + XiCon Loss:3.2805 x Lambda(0.1)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0954
Validation loss decreased (0.146502 --> 0.143035).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5087444
	speed: 0.0518s/iter; left time: 1325.7647s
	iters: 200, epoch: 4 | loss: 0.5063802
	speed: 0.0509s/iter; left time: 1298.5803s
Epoch: 4 cost time: 13.506658792495728
Epoch: 4, Steps: 265 Train Loss: 0.5090 (Forecasting Loss:0.1911 + XiCon Loss:3.1785 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0951
Validation loss decreased (0.143035 --> 0.141970).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5071769
	speed: 0.0515s/iter; left time: 1306.0661s
	iters: 200, epoch: 5 | loss: 0.4986279
	speed: 0.0498s/iter; left time: 1256.0997s
Epoch: 5 cost time: 13.362483263015747
Epoch: 5, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1903 + XiCon Loss:3.1583 x Lambda(0.1)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5218048
	speed: 0.0517s/iter; left time: 1295.5498s
	iters: 200, epoch: 6 | loss: 0.5068913
	speed: 0.0491s/iter; left time: 1227.4765s
Epoch: 6 cost time: 13.373407125473022
Epoch: 6, Steps: 265 Train Loss: 0.5082 (Forecasting Loss:0.1898 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141970 --> 0.141814).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5070909
	speed: 0.0499s/iter; left time: 1238.8704s
	iters: 200, epoch: 7 | loss: 0.4958517
	speed: 0.0497s/iter; left time: 1229.2859s
Epoch: 7 cost time: 13.268709182739258
Epoch: 7, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1895 + XiCon Loss:3.1664 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141814 --> 0.141605).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5023384
	speed: 0.0519s/iter; left time: 1272.9313s
	iters: 200, epoch: 8 | loss: 0.5052246
	speed: 0.0510s/iter; left time: 1247.8264s
Epoch: 8 cost time: 13.595431566238403
Epoch: 8, Steps: 265 Train Loss: 0.5065 (Forecasting Loss:0.1893 + XiCon Loss:3.1724 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4810126
	speed: 0.0507s/iter; left time: 1230.9836s
	iters: 200, epoch: 9 | loss: 0.4977303
	speed: 0.0505s/iter; left time: 1221.4000s
Epoch: 9 cost time: 13.363601922988892
Epoch: 9, Steps: 265 Train Loss: 0.5058 (Forecasting Loss:0.1892 + XiCon Loss:3.1662 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5221655
	speed: 0.0534s/iter; left time: 1281.5514s
	iters: 200, epoch: 10 | loss: 0.5013560
	speed: 0.0492s/iter; left time: 1177.7011s
Epoch: 10 cost time: 13.602341413497925
Epoch: 10, Steps: 265 Train Loss: 0.5052 (Forecasting Loss:0.1891 + XiCon Loss:3.1610 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4786817
	speed: 0.0514s/iter; left time: 1221.3428s
	iters: 200, epoch: 11 | loss: 0.5135301
	speed: 0.0494s/iter; left time: 1167.7673s
Epoch: 11 cost time: 13.362029790878296
Epoch: 11, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1891 + XiCon Loss:3.1707 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5172695
	speed: 0.0513s/iter; left time: 1203.7306s
	iters: 200, epoch: 12 | loss: 0.5033478
	speed: 0.0500s/iter; left time: 1169.1481s
Epoch: 12 cost time: 13.385981559753418
Epoch: 12, Steps: 265 Train Loss: 0.5049 (Forecasting Loss:0.1889 + XiCon Loss:3.1593 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5114087
	speed: 0.0518s/iter; left time: 1201.9044s
	iters: 200, epoch: 13 | loss: 0.5031118
	speed: 0.0496s/iter; left time: 1147.3281s
Epoch: 13 cost time: 13.453591585159302
Epoch: 13, Steps: 265 Train Loss: 0.5056 (Forecasting Loss:0.1890 + XiCon Loss:3.1653 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5173564
	speed: 0.0512s/iter; left time: 1175.9054s
	iters: 200, epoch: 14 | loss: 0.4963747
	speed: 0.0483s/iter; left time: 1103.2775s
Epoch: 14 cost time: 13.139882564544678
Epoch: 14, Steps: 265 Train Loss: 0.5048 (Forecasting Loss:0.1890 + XiCon Loss:3.1572 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4596725
	speed: 0.0518s/iter; left time: 1174.8263s
	iters: 200, epoch: 15 | loss: 0.5107679
	speed: 0.0505s/iter; left time: 1140.1853s
Epoch: 15 cost time: 13.563252925872803
Epoch: 15, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1889 + XiCon Loss:3.1711 x Lambda(0.1)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5077645
	speed: 0.0511s/iter; left time: 1145.0474s
	iters: 200, epoch: 16 | loss: 0.5169453
	speed: 0.0498s/iter; left time: 1112.2043s
Epoch: 16 cost time: 13.345905542373657
Epoch: 16, Steps: 265 Train Loss: 0.5054 (Forecasting Loss:0.1890 + XiCon Loss:3.1642 x Lambda(0.1)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4870962
	speed: 0.0511s/iter; left time: 1132.6759s
	iters: 200, epoch: 17 | loss: 0.4986994
	speed: 0.0488s/iter; left time: 1077.3350s
Epoch: 17 cost time: 13.264647960662842
Epoch: 17, Steps: 265 Train Loss: 0.5067 (Forecasting Loss:0.1890 + XiCon Loss:3.1765 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03932918980717659, mae:0.14945447444915771, mape:0.11877866834402084, mspe:0.026468804106116295 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3987
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5007197
	speed: 0.0504s/iter; left time: 1330.6903s
	iters: 200, epoch: 1 | loss: 0.4791372
	speed: 0.0472s/iter; left time: 1240.8279s
Epoch: 1 cost time: 12.800632953643799
Epoch: 1, Steps: 265 Train Loss: 0.5190 (Forecasting Loss:0.2037 + XiCon Loss:3.1529 x Lambda(0.1)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.1000
Validation loss decreased (inf --> 0.148249).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5495913
	speed: 0.0517s/iter; left time: 1350.1467s
	iters: 200, epoch: 2 | loss: 0.5324463
	speed: 0.0497s/iter; left time: 1293.0169s
Epoch: 2 cost time: 13.2891526222229
Epoch: 2, Steps: 265 Train Loss: 0.5225 (Forecasting Loss:0.1989 + XiCon Loss:3.2356 x Lambda(0.1)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0968
Validation loss decreased (0.148249 --> 0.145647).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5214041
	speed: 0.0510s/iter; left time: 1319.9918s
	iters: 200, epoch: 3 | loss: 0.4951933
	speed: 0.0494s/iter; left time: 1272.7227s
Epoch: 3 cost time: 13.26313328742981
Epoch: 3, Steps: 265 Train Loss: 0.5136 (Forecasting Loss:0.1941 + XiCon Loss:3.1948 x Lambda(0.1)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0957
Validation loss decreased (0.145647 --> 0.143491).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5128384
	speed: 0.0501s/iter; left time: 1281.8188s
	iters: 200, epoch: 4 | loss: 0.4768029
	speed: 0.0482s/iter; left time: 1229.4210s
Epoch: 4 cost time: 13.192974090576172
Epoch: 4, Steps: 265 Train Loss: 0.5069 (Forecasting Loss:0.1910 + XiCon Loss:3.1597 x Lambda(0.1)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0949
Validation loss decreased (0.143491 --> 0.142953).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4898101
	speed: 0.0519s/iter; left time: 1315.0205s
	iters: 200, epoch: 5 | loss: 0.5285010
	speed: 0.0509s/iter; left time: 1284.8663s
Epoch: 5 cost time: 13.590615272521973
Epoch: 5, Steps: 265 Train Loss: 0.5053 (Forecasting Loss:0.1899 + XiCon Loss:3.1532 x Lambda(0.1)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0947
Validation loss decreased (0.142953 --> 0.142199).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5069422
	speed: 0.0519s/iter; left time: 1300.4639s
	iters: 200, epoch: 6 | loss: 0.5105578
	speed: 0.0496s/iter; left time: 1237.8464s
Epoch: 6 cost time: 13.486990451812744
Epoch: 6, Steps: 265 Train Loss: 0.5047 (Forecasting Loss:0.1895 + XiCon Loss:3.1521 x Lambda(0.1)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
Validation loss decreased (0.142199 --> 0.142107).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5137442
	speed: 0.0527s/iter; left time: 1306.3485s
	iters: 200, epoch: 7 | loss: 0.5077044
	speed: 0.0506s/iter; left time: 1250.6696s
Epoch: 7 cost time: 13.649641275405884
Epoch: 7, Steps: 265 Train Loss: 0.5051 (Forecasting Loss:0.1893 + XiCon Loss:3.1577 x Lambda(0.1)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5118024
	speed: 0.0512s/iter; left time: 1256.4246s
	iters: 200, epoch: 8 | loss: 0.5090018
	speed: 0.0504s/iter; left time: 1231.2293s
Epoch: 8 cost time: 13.41322112083435
Epoch: 8, Steps: 265 Train Loss: 0.5045 (Forecasting Loss:0.1890 + XiCon Loss:3.1548 x Lambda(0.1)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5418103
	speed: 0.0521s/iter; left time: 1265.1614s
	iters: 200, epoch: 9 | loss: 0.5420515
	speed: 0.0497s/iter; left time: 1201.4833s
Epoch: 9 cost time: 13.387223482131958
Epoch: 9, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1890 + XiCon Loss:3.1508 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.142107 --> 0.141894).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5119064
	speed: 0.0529s/iter; left time: 1271.2971s
	iters: 200, epoch: 10 | loss: 0.5179361
	speed: 0.0487s/iter; left time: 1165.8129s
Epoch: 10 cost time: 13.485000371932983
Epoch: 10, Steps: 265 Train Loss: 0.5034 (Forecasting Loss:0.1889 + XiCon Loss:3.1453 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5017402
	speed: 0.0529s/iter; left time: 1255.8711s
	iters: 200, epoch: 11 | loss: 0.5186149
	speed: 0.0496s/iter; left time: 1172.5329s
Epoch: 11 cost time: 13.249528646469116
Epoch: 11, Steps: 265 Train Loss: 0.5043 (Forecasting Loss:0.1889 + XiCon Loss:3.1546 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5068278
	speed: 0.0525s/iter; left time: 1233.3537s
	iters: 200, epoch: 12 | loss: 0.5220466
	speed: 0.0493s/iter; left time: 1153.7033s
Epoch: 12 cost time: 13.56015944480896
Epoch: 12, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1889 + XiCon Loss:3.1515 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141894 --> 0.141829).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5063697
	speed: 0.0521s/iter; left time: 1210.8466s
	iters: 200, epoch: 13 | loss: 0.4776774
	speed: 0.0504s/iter; left time: 1164.4250s
Epoch: 13 cost time: 13.552952766418457
Epoch: 13, Steps: 265 Train Loss: 0.5037 (Forecasting Loss:0.1888 + XiCon Loss:3.1482 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5043591
	speed: 0.0508s/iter; left time: 1165.7964s
	iters: 200, epoch: 14 | loss: 0.5172282
	speed: 0.0498s/iter; left time: 1137.4457s
Epoch: 14 cost time: 13.292391777038574
Epoch: 14, Steps: 265 Train Loss: 0.5035 (Forecasting Loss:0.1888 + XiCon Loss:3.1466 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5105534
	speed: 0.0514s/iter; left time: 1165.6887s
	iters: 200, epoch: 15 | loss: 0.5186630
	speed: 0.0504s/iter; left time: 1138.1770s
Epoch: 15 cost time: 13.359982967376709
Epoch: 15, Steps: 265 Train Loss: 0.5038 (Forecasting Loss:0.1888 + XiCon Loss:3.1496 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4957377
	speed: 0.0517s/iter; left time: 1158.8622s
	iters: 200, epoch: 16 | loss: 0.5062163
	speed: 0.0494s/iter; left time: 1102.4813s
Epoch: 16 cost time: 13.26514220237732
Epoch: 16, Steps: 265 Train Loss: 0.5038 (Forecasting Loss:0.1889 + XiCon Loss:3.1494 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5247478
	speed: 0.0506s/iter; left time: 1120.4547s
	iters: 200, epoch: 17 | loss: 0.5036741
	speed: 0.0502s/iter; left time: 1108.4380s
Epoch: 17 cost time: 13.340819358825684
Epoch: 17, Steps: 265 Train Loss: 0.5038 (Forecasting Loss:0.1888 + XiCon Loss:3.1499 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5100955
	speed: 0.0517s/iter; left time: 1133.0913s
	iters: 200, epoch: 18 | loss: 0.5502580
	speed: 0.0504s/iter; left time: 1097.5023s
Epoch: 18 cost time: 13.53161096572876
Epoch: 18, Steps: 265 Train Loss: 0.5037 (Forecasting Loss:0.1888 + XiCon Loss:3.1487 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4980136
	speed: 0.0522s/iter; left time: 1129.1455s
	iters: 200, epoch: 19 | loss: 0.4937897
	speed: 0.0484s/iter; left time: 1041.4584s
Epoch: 19 cost time: 13.242849588394165
Epoch: 19, Steps: 265 Train Loss: 0.5043 (Forecasting Loss:0.1889 + XiCon Loss:3.1547 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5240554
	speed: 0.0509s/iter; left time: 1086.8659s
	iters: 200, epoch: 20 | loss: 0.5102146
	speed: 0.0506s/iter; left time: 1076.1507s
Epoch: 20 cost time: 13.529883623123169
Epoch: 20, Steps: 265 Train Loss: 0.5042 (Forecasting Loss:0.1888 + XiCon Loss:3.1539 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4766270
	speed: 0.0520s/iter; left time: 1096.9547s
	iters: 200, epoch: 21 | loss: 0.5007640
	speed: 0.0504s/iter; left time: 1058.0322s
Epoch: 21 cost time: 13.530674695968628
Epoch: 21, Steps: 265 Train Loss: 0.5034 (Forecasting Loss:0.1888 + XiCon Loss:3.1459 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141829 --> 0.141776).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5150982
	speed: 0.0516s/iter; left time: 1075.6845s
	iters: 200, epoch: 22 | loss: 0.5203968
	speed: 0.0498s/iter; left time: 1033.0904s
Epoch: 22 cost time: 13.451670169830322
Epoch: 22, Steps: 265 Train Loss: 0.5034 (Forecasting Loss:0.1889 + XiCon Loss:3.1441 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4959127
	speed: 0.0523s/iter; left time: 1075.6899s
	iters: 200, epoch: 23 | loss: 0.5093345
	speed: 0.0509s/iter; left time: 1041.5150s
Epoch: 23 cost time: 13.617514371871948
Epoch: 23, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1888 + XiCon Loss:3.1525 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4724221
	speed: 0.0506s/iter; left time: 1027.5666s
	iters: 200, epoch: 24 | loss: 0.5162622
	speed: 0.0509s/iter; left time: 1028.7588s
Epoch: 24 cost time: 13.399513006210327
Epoch: 24, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1890 + XiCon Loss:3.1511 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5426684
	speed: 0.0518s/iter; left time: 1037.8228s
	iters: 200, epoch: 25 | loss: 0.5289309
	speed: 0.0496s/iter; left time: 988.6884s
Epoch: 25 cost time: 13.43755030632019
Epoch: 25, Steps: 265 Train Loss: 0.5056 (Forecasting Loss:0.1889 + XiCon Loss:3.1668 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4749130
	speed: 0.0521s/iter; left time: 1031.1566s
	iters: 200, epoch: 26 | loss: 0.5022358
	speed: 0.0495s/iter; left time: 973.2936s
Epoch: 26 cost time: 13.438343048095703
Epoch: 26, Steps: 265 Train Loss: 0.5042 (Forecasting Loss:0.1889 + XiCon Loss:3.1532 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.5238584
	speed: 0.0516s/iter; left time: 1006.4686s
	iters: 200, epoch: 27 | loss: 0.5031308
	speed: 0.0507s/iter; left time: 983.8574s
Epoch: 27 cost time: 13.406053304672241
Epoch: 27, Steps: 265 Train Loss: 0.5043 (Forecasting Loss:0.1889 + XiCon Loss:3.1535 x Lambda(0.1)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4784929
	speed: 0.0520s/iter; left time: 999.9520s
	iters: 200, epoch: 28 | loss: 0.5091996
	speed: 0.0497s/iter; left time: 951.8937s
Epoch: 28 cost time: 13.44518232345581
Epoch: 28, Steps: 265 Train Loss: 0.5035 (Forecasting Loss:0.1888 + XiCon Loss:3.1470 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4955072
	speed: 0.0510s/iter; left time: 968.3953s
	iters: 200, epoch: 29 | loss: 0.4898632
	speed: 0.0496s/iter; left time: 936.7647s
Epoch: 29 cost time: 13.353884220123291
Epoch: 29, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1888 + XiCon Loss:3.1526 x Lambda(0.1)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.5057894
	speed: 0.0520s/iter; left time: 973.8566s
	iters: 200, epoch: 30 | loss: 0.5100729
	speed: 0.0501s/iter; left time: 933.4445s
Epoch: 30 cost time: 13.525998592376709
Epoch: 30, Steps: 265 Train Loss: 0.5035 (Forecasting Loss:0.1890 + XiCon Loss:3.1453 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.4771219
	speed: 0.0520s/iter; left time: 959.3559s
	iters: 200, epoch: 31 | loss: 0.5202667
	speed: 0.0497s/iter; left time: 911.1370s
Epoch: 31 cost time: 13.55127477645874
Epoch: 31, Steps: 265 Train Loss: 0.5041 (Forecasting Loss:0.1890 + XiCon Loss:3.1510 x Lambda(0.1)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03940751031041145, mae:0.14946062862873077, mape:0.11856631934642792, mspe:0.026324724778532982 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.0015
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.5220249
	speed: 0.0497s/iter; left time: 1312.1835s
	iters: 200, epoch: 1 | loss: 0.5343866
	speed: 0.0475s/iter; left time: 1248.4908s
Epoch: 1 cost time: 12.797096967697144
Epoch: 1, Steps: 265 Train Loss: 0.5228 (Forecasting Loss:0.2077 + XiCon Loss:3.1508 x Lambda(0.1)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.0985
Validation loss decreased (inf --> 0.147305).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5006164
	speed: 0.0526s/iter; left time: 1373.5970s
	iters: 200, epoch: 2 | loss: 0.5282541
	speed: 0.0503s/iter; left time: 1309.4134s
Epoch: 2 cost time: 13.431246280670166
Epoch: 2, Steps: 265 Train Loss: 0.5277 (Forecasting Loss:0.1981 + XiCon Loss:3.2964 x Lambda(0.1)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0967
Validation loss decreased (0.147305 --> 0.146363).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5239912
	speed: 0.0506s/iter; left time: 1308.6610s
	iters: 200, epoch: 3 | loss: 0.5284523
	speed: 0.0486s/iter; left time: 1253.4228s
Epoch: 3 cost time: 13.223189353942871
Epoch: 3, Steps: 265 Train Loss: 0.5176 (Forecasting Loss:0.1931 + XiCon Loss:3.2456 x Lambda(0.1)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0953
Validation loss decreased (0.146363 --> 0.143146).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5351684
	speed: 0.0523s/iter; left time: 1338.6928s
	iters: 200, epoch: 4 | loss: 0.4992703
	speed: 0.0489s/iter; left time: 1246.6190s
Epoch: 4 cost time: 13.356051206588745
Epoch: 4, Steps: 265 Train Loss: 0.5097 (Forecasting Loss:0.1913 + XiCon Loss:3.1837 x Lambda(0.1)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5071653
	speed: 0.0529s/iter; left time: 1341.0367s
	iters: 200, epoch: 5 | loss: 0.5107068
	speed: 0.0495s/iter; left time: 1249.6955s
Epoch: 5 cost time: 13.498887062072754
Epoch: 5, Steps: 265 Train Loss: 0.5064 (Forecasting Loss:0.1900 + XiCon Loss:3.1644 x Lambda(0.1)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0954
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4747391
	speed: 0.0510s/iter; left time: 1278.9089s
	iters: 200, epoch: 6 | loss: 0.4993187
	speed: 0.0497s/iter; left time: 1242.1240s
Epoch: 6 cost time: 13.304261445999146
Epoch: 6, Steps: 265 Train Loss: 0.5056 (Forecasting Loss:0.1895 + XiCon Loss:3.1605 x Lambda(0.1)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0946
Validation loss decreased (0.143146 --> 0.142572).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4955506
	speed: 0.0524s/iter; left time: 1300.6821s
	iters: 200, epoch: 7 | loss: 0.5085824
	speed: 0.0492s/iter; left time: 1215.7901s
Epoch: 7 cost time: 13.507887840270996
Epoch: 7, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1892 + XiCon Loss:3.1689 x Lambda(0.1)), Vali MSE Loss: 0.1427 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4854509
	speed: 0.0522s/iter; left time: 1280.7836s
	iters: 200, epoch: 8 | loss: 0.5203153
	speed: 0.0503s/iter; left time: 1228.6031s
Epoch: 8 cost time: 13.70837116241455
Epoch: 8, Steps: 265 Train Loss: 0.5057 (Forecasting Loss:0.1890 + XiCon Loss:3.1675 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
Validation loss decreased (0.142572 --> 0.142417).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5132883
	speed: 0.0517s/iter; left time: 1255.0305s
	iters: 200, epoch: 9 | loss: 0.5397003
	speed: 0.0506s/iter; left time: 1224.4113s
Epoch: 9 cost time: 13.439003467559814
Epoch: 9, Steps: 265 Train Loss: 0.5054 (Forecasting Loss:0.1889 + XiCon Loss:3.1653 x Lambda(0.1)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
Validation loss decreased (0.142417 --> 0.142281).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5117381
	speed: 0.0503s/iter; left time: 1207.7747s
	iters: 200, epoch: 10 | loss: 0.5143566
	speed: 0.0510s/iter; left time: 1219.0162s
Epoch: 10 cost time: 13.377533674240112
Epoch: 10, Steps: 265 Train Loss: 0.5055 (Forecasting Loss:0.1888 + XiCon Loss:3.1668 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4884479
	speed: 0.0506s/iter; left time: 1200.6347s
	iters: 200, epoch: 11 | loss: 0.4989676
	speed: 0.0496s/iter; left time: 1173.5885s
Epoch: 11 cost time: 13.224867582321167
Epoch: 11, Steps: 265 Train Loss: 0.5055 (Forecasting Loss:0.1889 + XiCon Loss:3.1668 x Lambda(0.1)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
Validation loss decreased (0.142281 --> 0.142281).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4901704
	speed: 0.0509s/iter; left time: 1194.7318s
	iters: 200, epoch: 12 | loss: 0.5201528
	speed: 0.0511s/iter; left time: 1196.1743s
Epoch: 12 cost time: 13.52675747871399
Epoch: 12, Steps: 265 Train Loss: 0.5060 (Forecasting Loss:0.1888 + XiCon Loss:3.1723 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4937334
	speed: 0.0516s/iter; left time: 1198.0730s
	iters: 200, epoch: 13 | loss: 0.4939407
	speed: 0.0496s/iter; left time: 1147.6177s
Epoch: 13 cost time: 13.389151811599731
Epoch: 13, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.1888 + XiCon Loss:3.1733 x Lambda(0.1)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4992904
	speed: 0.0516s/iter; left time: 1185.3108s
	iters: 200, epoch: 14 | loss: 0.5218983
	speed: 0.0489s/iter; left time: 1117.3302s
Epoch: 14 cost time: 13.26713490486145
Epoch: 14, Steps: 265 Train Loss: 0.5056 (Forecasting Loss:0.1888 + XiCon Loss:3.1680 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4932647
	speed: 0.0526s/iter; left time: 1192.5707s
	iters: 200, epoch: 15 | loss: 0.5019648
	speed: 0.0502s/iter; left time: 1133.4160s
Epoch: 15 cost time: 13.587560176849365
Epoch: 15, Steps: 265 Train Loss: 0.5039 (Forecasting Loss:0.1887 + XiCon Loss:3.1518 x Lambda(0.1)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5112125
	speed: 0.0515s/iter; left time: 1154.6388s
	iters: 200, epoch: 16 | loss: 0.4875677
	speed: 0.0512s/iter; left time: 1142.5705s
Epoch: 16 cost time: 13.497395992279053
Epoch: 16, Steps: 265 Train Loss: 0.5051 (Forecasting Loss:0.1887 + XiCon Loss:3.1643 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4580062
	speed: 0.0514s/iter; left time: 1138.0368s
	iters: 200, epoch: 17 | loss: 0.5338147
	speed: 0.0489s/iter; left time: 1078.5241s
Epoch: 17 cost time: 13.154168844223022
Epoch: 17, Steps: 265 Train Loss: 0.5058 (Forecasting Loss:0.1888 + XiCon Loss:3.1700 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5094080
	speed: 0.0538s/iter; left time: 1177.8019s
	iters: 200, epoch: 18 | loss: 0.4873723
	speed: 0.0496s/iter; left time: 1080.1716s
Epoch: 18 cost time: 13.590784788131714
Epoch: 18, Steps: 265 Train Loss: 0.5054 (Forecasting Loss:0.1887 + XiCon Loss:3.1672 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5058402
	speed: 0.0508s/iter; left time: 1099.3357s
	iters: 200, epoch: 19 | loss: 0.5080786
	speed: 0.0500s/iter; left time: 1076.3940s
Epoch: 19 cost time: 13.360832452774048
Epoch: 19, Steps: 265 Train Loss: 0.5047 (Forecasting Loss:0.1888 + XiCon Loss:3.1595 x Lambda(0.1)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4773931
	speed: 0.0516s/iter; left time: 1102.7495s
	iters: 200, epoch: 20 | loss: 0.5083778
	speed: 0.0499s/iter; left time: 1060.9187s
Epoch: 20 cost time: 13.416492938995361
Epoch: 20, Steps: 265 Train Loss: 0.5056 (Forecasting Loss:0.1888 + XiCon Loss:3.1684 x Lambda(0.1)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5055130
	speed: 0.0526s/iter; left time: 1110.3721s
	iters: 200, epoch: 21 | loss: 0.5430731
	speed: 0.0502s/iter; left time: 1053.2285s
Epoch: 21 cost time: 13.582271337509155
Epoch: 21, Steps: 265 Train Loss: 0.5055 (Forecasting Loss:0.1888 + XiCon Loss:3.1664 x Lambda(0.1)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03952164202928543, mae:0.14967666566371918, mape:0.11881572008132935, mspe:0.026456249877810478 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0407+-0.00349, MAE:0.1504+-0.00227, MAPE:0.1193+-0.00152, MSPE:0.0269+-0.00144, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4560
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5517223
	speed: 0.0421s/iter; left time: 1106.3772s
	iters: 200, epoch: 1 | loss: 0.5699434
	speed: 0.0368s/iter; left time: 964.2352s
Epoch: 1 cost time: 10.243718385696411
Epoch: 1, Steps: 264 Train Loss: 0.5442 (Forecasting Loss:0.2365 + XiCon Loss:3.0775 x Lambda(0.1)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1154
Validation loss decreased (inf --> 0.172880).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5627240
	speed: 0.0451s/iter; left time: 1173.5099s
	iters: 200, epoch: 2 | loss: 0.5638108
	speed: 0.0411s/iter; left time: 1066.6680s
Epoch: 2 cost time: 11.250419855117798
Epoch: 2, Steps: 264 Train Loss: 0.5401 (Forecasting Loss:0.2435 + XiCon Loss:2.9659 x Lambda(0.1)), Vali MSE Loss: 0.1788 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5113081
	speed: 0.0419s/iter; left time: 1079.0107s
	iters: 200, epoch: 3 | loss: 0.4840539
	speed: 0.0364s/iter; left time: 934.8962s
Epoch: 3 cost time: 10.187569856643677
Epoch: 3, Steps: 264 Train Loss: 0.5242 (Forecasting Loss:0.2340 + XiCon Loss:2.9025 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1138
Validation loss decreased (0.172880 --> 0.172391).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4987406
	speed: 0.0427s/iter; left time: 1088.6410s
	iters: 200, epoch: 4 | loss: 0.5344707
	speed: 0.0400s/iter; left time: 1016.4217s
Epoch: 4 cost time: 10.927136659622192
Epoch: 4, Steps: 264 Train Loss: 0.5163 (Forecasting Loss:0.2297 + XiCon Loss:2.8659 x Lambda(0.1)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1138
Validation loss decreased (0.172391 --> 0.171756).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5137039
	speed: 0.0424s/iter; left time: 1069.6946s
	iters: 200, epoch: 5 | loss: 0.4911158
	speed: 0.0398s/iter; left time: 1001.9611s
Epoch: 5 cost time: 10.845382690429688
Epoch: 5, Steps: 264 Train Loss: 0.5134 (Forecasting Loss:0.2280 + XiCon Loss:2.8540 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1126
Validation loss decreased (0.171756 --> 0.170796).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5114599
	speed: 0.0407s/iter; left time: 1017.1986s
	iters: 200, epoch: 6 | loss: 0.4976658
	speed: 0.0404s/iter; left time: 1004.6965s
Epoch: 6 cost time: 10.742902517318726
Epoch: 6, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2270 + XiCon Loss:2.8523 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.170796 --> 0.169931).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5256461
	speed: 0.0423s/iter; left time: 1046.7518s
	iters: 200, epoch: 7 | loss: 0.5002509
	speed: 0.0409s/iter; left time: 1007.1230s
Epoch: 7 cost time: 10.959683179855347
Epoch: 7, Steps: 264 Train Loss: 0.5115 (Forecasting Loss:0.2264 + XiCon Loss:2.8513 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5121123
	speed: 0.0417s/iter; left time: 1020.2689s
	iters: 200, epoch: 8 | loss: 0.5133892
	speed: 0.0399s/iter; left time: 971.8447s
Epoch: 8 cost time: 10.661514282226562
Epoch: 8, Steps: 264 Train Loss: 0.5109 (Forecasting Loss:0.2261 + XiCon Loss:2.8481 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1124
Validation loss decreased (0.169931 --> 0.169675).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4907275
	speed: 0.0419s/iter; left time: 1014.2871s
	iters: 200, epoch: 9 | loss: 0.5054379
	speed: 0.0395s/iter; left time: 952.3455s
Epoch: 9 cost time: 10.70096206665039
Epoch: 9, Steps: 264 Train Loss: 0.5107 (Forecasting Loss:0.2260 + XiCon Loss:2.8472 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5333302
	speed: 0.0423s/iter; left time: 1011.7739s
	iters: 200, epoch: 10 | loss: 0.5260686
	speed: 0.0387s/iter; left time: 922.7496s
Epoch: 10 cost time: 10.656252384185791
Epoch: 10, Steps: 264 Train Loss: 0.5108 (Forecasting Loss:0.2259 + XiCon Loss:2.8489 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1123
Validation loss decreased (0.169675 --> 0.169551).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5031046
	speed: 0.0426s/iter; left time: 1007.6898s
	iters: 200, epoch: 11 | loss: 0.4995110
	speed: 0.0409s/iter; left time: 963.3088s
Epoch: 11 cost time: 10.960938215255737
Epoch: 11, Steps: 264 Train Loss: 0.5104 (Forecasting Loss:0.2258 + XiCon Loss:2.8466 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5248486
	speed: 0.0425s/iter; left time: 993.5945s
	iters: 200, epoch: 12 | loss: 0.5007817
	speed: 0.0376s/iter; left time: 875.0196s
Epoch: 12 cost time: 10.383416891098022
Epoch: 12, Steps: 264 Train Loss: 0.5107 (Forecasting Loss:0.2258 + XiCon Loss:2.8493 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4955837
	speed: 0.0462s/iter; left time: 1069.5931s
	iters: 200, epoch: 13 | loss: 0.4934935
	speed: 0.0390s/iter; left time: 898.5088s
Epoch: 13 cost time: 11.134886741638184
Epoch: 13, Steps: 264 Train Loss: 0.5103 (Forecasting Loss:0.2258 + XiCon Loss:2.8449 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1123
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5251138
	speed: 0.0421s/iter; left time: 963.4160s
	iters: 200, epoch: 14 | loss: 0.5025642
	speed: 0.0403s/iter; left time: 918.0145s
Epoch: 14 cost time: 10.850744724273682
Epoch: 14, Steps: 264 Train Loss: 0.5105 (Forecasting Loss:0.2258 + XiCon Loss:2.8472 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5158337
	speed: 0.0430s/iter; left time: 971.0536s
	iters: 200, epoch: 15 | loss: 0.5198699
	speed: 0.0396s/iter; left time: 891.9064s
Epoch: 15 cost time: 10.8498375415802
Epoch: 15, Steps: 264 Train Loss: 0.5105 (Forecasting Loss:0.2257 + XiCon Loss:2.8475 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1123
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4979512
	speed: 0.0426s/iter; left time: 950.6870s
	iters: 200, epoch: 16 | loss: 0.5093924
	speed: 0.0401s/iter; left time: 891.5920s
Epoch: 16 cost time: 10.828974485397339
Epoch: 16, Steps: 264 Train Loss: 0.5103 (Forecasting Loss:0.2257 + XiCon Loss:2.8460 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5132746
	speed: 0.0431s/iter; left time: 950.6935s
	iters: 200, epoch: 17 | loss: 0.5041146
	speed: 0.0401s/iter; left time: 881.5668s
Epoch: 17 cost time: 10.917863130569458
Epoch: 17, Steps: 264 Train Loss: 0.5107 (Forecasting Loss:0.2258 + XiCon Loss:2.8493 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5152558
	speed: 0.0410s/iter; left time: 893.5613s
	iters: 200, epoch: 18 | loss: 0.4990961
	speed: 0.0407s/iter; left time: 883.0306s
Epoch: 18 cost time: 10.767255067825317
Epoch: 18, Steps: 264 Train Loss: 0.5102 (Forecasting Loss:0.2258 + XiCon Loss:2.8441 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.4986647
	speed: 0.0429s/iter; left time: 924.8556s
	iters: 200, epoch: 19 | loss: 0.5264490
	speed: 0.0402s/iter; left time: 862.1994s
Epoch: 19 cost time: 10.823254823684692
Epoch: 19, Steps: 264 Train Loss: 0.5104 (Forecasting Loss:0.2257 + XiCon Loss:2.8473 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1123
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5212069
	speed: 0.0434s/iter; left time: 923.8967s
	iters: 200, epoch: 20 | loss: 0.5018719
	speed: 0.0405s/iter; left time: 858.6142s
Epoch: 20 cost time: 10.9662024974823
Epoch: 20, Steps: 264 Train Loss: 0.5104 (Forecasting Loss:0.2257 + XiCon Loss:2.8467 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1123
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05234626308083534, mae:0.17225822806358337, mape:0.134612575173378, mspe:0.032330047339200974 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.7289
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5407010
	speed: 0.0537s/iter; left time: 1411.4771s
	iters: 200, epoch: 1 | loss: 0.5354384
	speed: 0.0995s/iter; left time: 2605.6983s
Epoch: 1 cost time: 20.837652444839478
Epoch: 1, Steps: 264 Train Loss: 0.5478 (Forecasting Loss:0.2380 + XiCon Loss:3.0985 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1144
Validation loss decreased (inf --> 0.172424).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5686835
	speed: 0.1188s/iter; left time: 3093.7934s
	iters: 200, epoch: 2 | loss: 0.5089568
	speed: 0.1006s/iter; left time: 2609.1972s
Epoch: 2 cost time: 27.797016620635986
Epoch: 2, Steps: 264 Train Loss: 0.5425 (Forecasting Loss:0.2417 + XiCon Loss:3.0079 x Lambda(0.1)), Vali MSE Loss: 0.1783 Test MSE Loss: 0.1173
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4984803
	speed: 0.0880s/iter; left time: 2267.3321s
	iters: 200, epoch: 3 | loss: 0.5420475
	speed: 0.0585s/iter; left time: 1502.2811s
Epoch: 3 cost time: 17.617311239242554
Epoch: 3, Steps: 264 Train Loss: 0.5253 (Forecasting Loss:0.2342 + XiCon Loss:2.9113 x Lambda(0.1)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1156
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5150222
	speed: 0.0399s/iter; left time: 1017.5201s
	iters: 200, epoch: 4 | loss: 0.5458164
	speed: 0.0371s/iter; left time: 943.0165s
Epoch: 4 cost time: 10.128437519073486
Epoch: 4, Steps: 264 Train Loss: 0.5197 (Forecasting Loss:0.2310 + XiCon Loss:2.8867 x Lambda(0.1)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1131
Validation loss decreased (0.172424 --> 0.171031).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5268091
	speed: 0.0408s/iter; left time: 1029.0251s
	iters: 200, epoch: 5 | loss: 0.5367715
	speed: 0.0391s/iter; left time: 983.0516s
Epoch: 5 cost time: 10.446236610412598
Epoch: 5, Steps: 264 Train Loss: 0.5165 (Forecasting Loss:0.2284 + XiCon Loss:2.8812 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1136
Validation loss decreased (0.171031 --> 0.170944).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5235490
	speed: 0.0409s/iter; left time: 1020.9290s
	iters: 200, epoch: 6 | loss: 0.5138435
	speed: 0.0389s/iter; left time: 968.3871s
Epoch: 6 cost time: 10.462120771408081
Epoch: 6, Steps: 264 Train Loss: 0.5154 (Forecasting Loss:0.2274 + XiCon Loss:2.8798 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
Validation loss decreased (0.170944 --> 0.170217).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5054824
	speed: 0.0408s/iter; left time: 1009.4719s
	iters: 200, epoch: 7 | loss: 0.5295190
	speed: 0.0373s/iter; left time: 917.2970s
Epoch: 7 cost time: 10.208377361297607
Epoch: 7, Steps: 264 Train Loss: 0.5146 (Forecasting Loss:0.2268 + XiCon Loss:2.8786 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170217 --> 0.169966).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5083771
	speed: 0.0401s/iter; left time: 981.0227s
	iters: 200, epoch: 8 | loss: 0.5194278
	speed: 0.0374s/iter; left time: 911.9190s
Epoch: 8 cost time: 10.155421257019043
Epoch: 8, Steps: 264 Train Loss: 0.5142 (Forecasting Loss:0.2264 + XiCon Loss:2.8783 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5166811
	speed: 0.0422s/iter; left time: 1019.8935s
	iters: 200, epoch: 9 | loss: 0.4838491
	speed: 0.0400s/iter; left time: 962.5562s
Epoch: 9 cost time: 10.718076944351196
Epoch: 9, Steps: 264 Train Loss: 0.5139 (Forecasting Loss:0.2266 + XiCon Loss:2.8738 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5113053
	speed: 0.0422s/iter; left time: 1010.7696s
	iters: 200, epoch: 10 | loss: 0.5276085
	speed: 0.0399s/iter; left time: 950.9232s
Epoch: 10 cost time: 10.788945198059082
Epoch: 10, Steps: 264 Train Loss: 0.5142 (Forecasting Loss:0.2265 + XiCon Loss:2.8773 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5089451
	speed: 0.0421s/iter; left time: 996.1715s
	iters: 200, epoch: 11 | loss: 0.5075233
	speed: 0.0396s/iter; left time: 934.1589s
Epoch: 11 cost time: 10.699742555618286
Epoch: 11, Steps: 264 Train Loss: 0.5142 (Forecasting Loss:0.2264 + XiCon Loss:2.8786 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5261713
	speed: 0.0417s/iter; left time: 976.2408s
	iters: 200, epoch: 12 | loss: 0.4956940
	speed: 0.0399s/iter; left time: 928.7096s
Epoch: 12 cost time: 10.73153281211853
Epoch: 12, Steps: 264 Train Loss: 0.5142 (Forecasting Loss:0.2264 + XiCon Loss:2.8780 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5061424
	speed: 0.0427s/iter; left time: 988.0410s
	iters: 200, epoch: 13 | loss: 0.5084345
	speed: 0.0405s/iter; left time: 932.9906s
Epoch: 13 cost time: 10.826167583465576
Epoch: 13, Steps: 264 Train Loss: 0.5138 (Forecasting Loss:0.2262 + XiCon Loss:2.8760 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.4988122
	speed: 0.0436s/iter; left time: 996.7612s
	iters: 200, epoch: 14 | loss: 0.5165319
	speed: 0.0408s/iter; left time: 929.9571s
Epoch: 14 cost time: 11.02275800704956
Epoch: 14, Steps: 264 Train Loss: 0.5142 (Forecasting Loss:0.2263 + XiCon Loss:2.8797 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5297991
	speed: 0.0424s/iter; left time: 958.7854s
	iters: 200, epoch: 15 | loss: 0.5134663
	speed: 0.0399s/iter; left time: 898.2654s
Epoch: 15 cost time: 10.847467184066772
Epoch: 15, Steps: 264 Train Loss: 0.5141 (Forecasting Loss:0.2263 + XiCon Loss:2.8776 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5107920
	speed: 0.0422s/iter; left time: 942.6910s
	iters: 200, epoch: 16 | loss: 0.5024212
	speed: 0.0406s/iter; left time: 902.4044s
Epoch: 16 cost time: 10.852890729904175
Epoch: 16, Steps: 264 Train Loss: 0.5144 (Forecasting Loss:0.2263 + XiCon Loss:2.8809 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4940788
	speed: 0.0429s/iter; left time: 946.0159s
	iters: 200, epoch: 17 | loss: 0.5413316
	speed: 0.0403s/iter; left time: 885.6855s
Epoch: 17 cost time: 10.667344093322754
Epoch: 17, Steps: 264 Train Loss: 0.5137 (Forecasting Loss:0.2262 + XiCon Loss:2.8749 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05248229578137398, mae:0.17241023480892181, mape:0.13472743332386017, mspe:0.0324200838804245 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1780
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5702750
	speed: 0.0400s/iter; left time: 1051.6851s
	iters: 200, epoch: 1 | loss: 0.5489451
	speed: 0.0367s/iter; left time: 960.7886s
Epoch: 1 cost time: 10.051998853683472
Epoch: 1, Steps: 264 Train Loss: 0.5434 (Forecasting Loss:0.2364 + XiCon Loss:3.0698 x Lambda(0.1)), Vali MSE Loss: 0.1773 Test MSE Loss: 0.1174
Validation loss decreased (inf --> 0.177271).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5445633
	speed: 0.0461s/iter; left time: 1200.5457s
	iters: 200, epoch: 2 | loss: 0.5327665
	speed: 0.0406s/iter; left time: 1052.6166s
Epoch: 2 cost time: 11.25834846496582
Epoch: 2, Steps: 264 Train Loss: 0.5444 (Forecasting Loss:0.2415 + XiCon Loss:3.0290 x Lambda(0.1)), Vali MSE Loss: 0.1777 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5470929
	speed: 0.0426s/iter; left time: 1096.8746s
	iters: 200, epoch: 3 | loss: 0.5520813
	speed: 0.0402s/iter; left time: 1031.9232s
Epoch: 3 cost time: 10.868443012237549
Epoch: 3, Steps: 264 Train Loss: 0.5308 (Forecasting Loss:0.2335 + XiCon Loss:2.9726 x Lambda(0.1)), Vali MSE Loss: 0.1764 Test MSE Loss: 0.1171
Validation loss decreased (0.177271 --> 0.176429).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5140641
	speed: 0.0422s/iter; left time: 1077.2652s
	iters: 200, epoch: 4 | loss: 0.5139911
	speed: 0.0409s/iter; left time: 1038.1547s
Epoch: 4 cost time: 10.879966020584106
Epoch: 4, Steps: 264 Train Loss: 0.5225 (Forecasting Loss:0.2300 + XiCon Loss:2.9252 x Lambda(0.1)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1136
Validation loss decreased (0.176429 --> 0.171706).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5166014
	speed: 0.0435s/iter; left time: 1097.7079s
	iters: 200, epoch: 5 | loss: 0.4958065
	speed: 0.0408s/iter; left time: 1025.4345s
Epoch: 5 cost time: 10.939311027526855
Epoch: 5, Steps: 264 Train Loss: 0.5168 (Forecasting Loss:0.2283 + XiCon Loss:2.8852 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1128
Validation loss decreased (0.171706 --> 0.170794).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5099139
	speed: 0.0429s/iter; left time: 1072.1497s
	iters: 200, epoch: 6 | loss: 0.5210101
	speed: 0.0404s/iter; left time: 1005.0850s
Epoch: 6 cost time: 10.818511009216309
Epoch: 6, Steps: 264 Train Loss: 0.5147 (Forecasting Loss:0.2274 + XiCon Loss:2.8729 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1130
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5270509
	speed: 0.0423s/iter; left time: 1044.4195s
	iters: 200, epoch: 7 | loss: 0.5063186
	speed: 0.0400s/iter; left time: 984.6126s
Epoch: 7 cost time: 10.740195274353027
Epoch: 7, Steps: 264 Train Loss: 0.5139 (Forecasting Loss:0.2269 + XiCon Loss:2.8703 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1130
Validation loss decreased (0.170794 --> 0.170490).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5007365
	speed: 0.0410s/iter; left time: 1002.9588s
	iters: 200, epoch: 8 | loss: 0.5073707
	speed: 0.0395s/iter; left time: 961.9526s
Epoch: 8 cost time: 10.366317987442017
Epoch: 8, Steps: 264 Train Loss: 0.5130 (Forecasting Loss:0.2264 + XiCon Loss:2.8655 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
Validation loss decreased (0.170490 --> 0.170131).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5337741
	speed: 0.0404s/iter; left time: 977.0194s
	iters: 200, epoch: 9 | loss: 0.5199822
	speed: 0.0402s/iter; left time: 967.1862s
Epoch: 9 cost time: 10.619967937469482
Epoch: 9, Steps: 264 Train Loss: 0.5124 (Forecasting Loss:0.2263 + XiCon Loss:2.8615 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1127
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4965343
	speed: 0.0419s/iter; left time: 1001.5188s
	iters: 200, epoch: 10 | loss: 0.5193335
	speed: 0.0393s/iter; left time: 937.2112s
Epoch: 10 cost time: 10.626664638519287
Epoch: 10, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2263 + XiCon Loss:2.8604 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170131 --> 0.169977).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5183061
	speed: 0.0425s/iter; left time: 1005.1863s
	iters: 200, epoch: 11 | loss: 0.5081607
	speed: 0.0404s/iter; left time: 950.7532s
Epoch: 11 cost time: 10.87872052192688
Epoch: 11, Steps: 264 Train Loss: 0.5128 (Forecasting Loss:0.2261 + XiCon Loss:2.8666 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
Validation loss decreased (0.169977 --> 0.169964).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5222604
	speed: 0.0424s/iter; left time: 993.1672s
	iters: 200, epoch: 12 | loss: 0.5267573
	speed: 0.0406s/iter; left time: 946.3420s
Epoch: 12 cost time: 10.896147727966309
Epoch: 12, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2261 + XiCon Loss:2.8611 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5092875
	speed: 0.0421s/iter; left time: 973.8310s
	iters: 200, epoch: 13 | loss: 0.5025991
	speed: 0.0390s/iter; left time: 898.3427s
Epoch: 13 cost time: 10.642452955245972
Epoch: 13, Steps: 264 Train Loss: 0.5125 (Forecasting Loss:0.2262 + XiCon Loss:2.8628 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5067471
	speed: 0.0418s/iter; left time: 955.4809s
	iters: 200, epoch: 14 | loss: 0.5125980
	speed: 0.0394s/iter; left time: 897.3216s
Epoch: 14 cost time: 10.738317012786865
Epoch: 14, Steps: 264 Train Loss: 0.5124 (Forecasting Loss:0.2261 + XiCon Loss:2.8627 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4746429
	speed: 0.0431s/iter; left time: 974.3651s
	iters: 200, epoch: 15 | loss: 0.5112585
	speed: 0.0400s/iter; left time: 899.4461s
Epoch: 15 cost time: 10.82204818725586
Epoch: 15, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2261 + XiCon Loss:2.8654 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5200798
	speed: 0.0417s/iter; left time: 932.3492s
	iters: 200, epoch: 16 | loss: 0.5077175
	speed: 0.0398s/iter; left time: 885.6703s
Epoch: 16 cost time: 10.684982538223267
Epoch: 16, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2261 + XiCon Loss:2.8620 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.4957600
	speed: 0.0417s/iter; left time: 919.5533s
	iters: 200, epoch: 17 | loss: 0.4965881
	speed: 0.0404s/iter; left time: 888.1709s
Epoch: 17 cost time: 10.821996688842773
Epoch: 17, Steps: 264 Train Loss: 0.5126 (Forecasting Loss:0.2262 + XiCon Loss:2.8641 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5054623
	speed: 0.0385s/iter; left time: 840.2713s
	iters: 200, epoch: 18 | loss: 0.5134577
	speed: 0.0385s/iter; left time: 836.9154s
Epoch: 18 cost time: 10.28022289276123
Epoch: 18, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2262 + XiCon Loss:2.8616 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5270543
	speed: 0.0421s/iter; left time: 906.3622s
	iters: 200, epoch: 19 | loss: 0.5127884
	speed: 0.0395s/iter; left time: 847.7136s
Epoch: 19 cost time: 10.677268981933594
Epoch: 19, Steps: 264 Train Loss: 0.5121 (Forecasting Loss:0.2261 + XiCon Loss:2.8600 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5367035
	speed: 0.0423s/iter; left time: 899.3986s
	iters: 200, epoch: 20 | loss: 0.5165969
	speed: 0.0404s/iter; left time: 856.5940s
Epoch: 20 cost time: 10.895555973052979
Epoch: 20, Steps: 264 Train Loss: 0.5125 (Forecasting Loss:0.2262 + XiCon Loss:2.8635 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5244686
	speed: 0.0434s/iter; left time: 911.3120s
	iters: 200, epoch: 21 | loss: 0.5137634
	speed: 0.0397s/iter; left time: 830.9450s
Epoch: 21 cost time: 10.907866954803467
Epoch: 21, Steps: 264 Train Loss: 0.5125 (Forecasting Loss:0.2262 + XiCon Loss:2.8637 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05260612815618515, mae:0.17261074483394623, mape:0.1347731649875641, mspe:0.032339908182621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.0988
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5549579
	speed: 0.0402s/iter; left time: 1056.8946s
	iters: 200, epoch: 1 | loss: 0.5375947
	speed: 0.0381s/iter; left time: 997.0256s
Epoch: 1 cost time: 10.1453275680542
Epoch: 1, Steps: 264 Train Loss: 0.5479 (Forecasting Loss:0.2382 + XiCon Loss:3.0969 x Lambda(0.1)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1136
Validation loss decreased (inf --> 0.173178).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5744310
	speed: 0.0463s/iter; left time: 1206.1977s
	iters: 200, epoch: 2 | loss: 0.5374403
	speed: 0.0409s/iter; left time: 1060.9496s
Epoch: 2 cost time: 11.311269760131836
Epoch: 2, Steps: 264 Train Loss: 0.5462 (Forecasting Loss:0.2424 + XiCon Loss:3.0377 x Lambda(0.1)), Vali MSE Loss: 0.1755 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5365075
	speed: 0.0432s/iter; left time: 1113.1974s
	iters: 200, epoch: 3 | loss: 0.4993742
	speed: 0.0410s/iter; left time: 1051.3716s
Epoch: 3 cost time: 11.069265127182007
Epoch: 3, Steps: 264 Train Loss: 0.5298 (Forecasting Loss:0.2332 + XiCon Loss:2.9657 x Lambda(0.1)), Vali MSE Loss: 0.1746 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5253724
	speed: 0.0423s/iter; left time: 1080.2086s
	iters: 200, epoch: 4 | loss: 0.5433320
	speed: 0.0404s/iter; left time: 1027.4244s
Epoch: 4 cost time: 10.815420627593994
Epoch: 4, Steps: 264 Train Loss: 0.5244 (Forecasting Loss:0.2300 + XiCon Loss:2.9438 x Lambda(0.1)), Vali MSE Loss: 0.1768 Test MSE Loss: 0.1163
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5066687
	speed: 0.0390s/iter; left time: 983.6431s
	iters: 200, epoch: 5 | loss: 0.5059213
	speed: 0.0394s/iter; left time: 991.4729s
Epoch: 5 cost time: 10.439087152481079
Epoch: 5, Steps: 264 Train Loss: 0.5211 (Forecasting Loss:0.2272 + XiCon Loss:2.9392 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1135
Validation loss decreased (0.173178 --> 0.170476).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5011302
	speed: 0.0422s/iter; left time: 1054.1885s
	iters: 200, epoch: 6 | loss: 0.5371497
	speed: 0.0401s/iter; left time: 998.6739s
Epoch: 6 cost time: 10.835745096206665
Epoch: 6, Steps: 264 Train Loss: 0.5189 (Forecasting Loss:0.2258 + XiCon Loss:2.9312 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1139
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5229453
	speed: 0.0429s/iter; left time: 1060.8297s
	iters: 200, epoch: 7 | loss: 0.5025139
	speed: 0.0403s/iter; left time: 992.0917s
Epoch: 7 cost time: 10.912764072418213
Epoch: 7, Steps: 264 Train Loss: 0.5173 (Forecasting Loss:0.2250 + XiCon Loss:2.9225 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1131
Validation loss decreased (0.170476 --> 0.170371).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4966473
	speed: 0.0419s/iter; left time: 1025.6051s
	iters: 200, epoch: 8 | loss: 0.5262546
	speed: 0.0404s/iter; left time: 983.4419s
Epoch: 8 cost time: 10.81681513786316
Epoch: 8, Steps: 264 Train Loss: 0.5162 (Forecasting Loss:0.2242 + XiCon Loss:2.9202 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1134
Validation loss decreased (0.170371 --> 0.170346).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5059161
	speed: 0.0425s/iter; left time: 1027.7223s
	iters: 200, epoch: 9 | loss: 0.4931131
	speed: 0.0398s/iter; left time: 959.2926s
Epoch: 9 cost time: 10.833825826644897
Epoch: 9, Steps: 264 Train Loss: 0.5157 (Forecasting Loss:0.2239 + XiCon Loss:2.9175 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1137
Validation loss decreased (0.170346 --> 0.170244).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4940141
	speed: 0.0429s/iter; left time: 1025.8547s
	iters: 200, epoch: 10 | loss: 0.5364743
	speed: 0.0407s/iter; left time: 969.4210s
Epoch: 10 cost time: 10.958118915557861
Epoch: 10, Steps: 264 Train Loss: 0.5148 (Forecasting Loss:0.2236 + XiCon Loss:2.9120 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1137
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4945903
	speed: 0.0429s/iter; left time: 1014.7436s
	iters: 200, epoch: 11 | loss: 0.4915691
	speed: 0.0403s/iter; left time: 950.4367s
Epoch: 11 cost time: 10.878106117248535
Epoch: 11, Steps: 264 Train Loss: 0.5154 (Forecasting Loss:0.2236 + XiCon Loss:2.9180 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1136
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4996115
	speed: 0.0428s/iter; left time: 1002.0326s
	iters: 200, epoch: 12 | loss: 0.5094828
	speed: 0.0404s/iter; left time: 940.3400s
Epoch: 12 cost time: 10.94753909111023
Epoch: 12, Steps: 264 Train Loss: 0.5156 (Forecasting Loss:0.2236 + XiCon Loss:2.9198 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1137
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5346481
	speed: 0.0425s/iter; left time: 983.2854s
	iters: 200, epoch: 13 | loss: 0.5179234
	speed: 0.0401s/iter; left time: 922.8975s
Epoch: 13 cost time: 10.79551649093628
Epoch: 13, Steps: 264 Train Loss: 0.5150 (Forecasting Loss:0.2235 + XiCon Loss:2.9157 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1137
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5148888
	speed: 0.0389s/iter; left time: 889.8108s
	iters: 200, epoch: 14 | loss: 0.5154503
	speed: 0.0367s/iter; left time: 834.7045s
Epoch: 14 cost time: 10.212381601333618
Epoch: 14, Steps: 264 Train Loss: 0.5152 (Forecasting Loss:0.2236 + XiCon Loss:2.9162 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1137
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5112022
	speed: 0.0429s/iter; left time: 970.7640s
	iters: 200, epoch: 15 | loss: 0.5095375
	speed: 0.0396s/iter; left time: 891.4950s
Epoch: 15 cost time: 10.871697902679443
Epoch: 15, Steps: 264 Train Loss: 0.5155 (Forecasting Loss:0.2236 + XiCon Loss:2.9191 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1137
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5127376
	speed: 0.0424s/iter; left time: 948.2950s
	iters: 200, epoch: 16 | loss: 0.5278749
	speed: 0.0403s/iter; left time: 895.7180s
Epoch: 16 cost time: 10.934781312942505
Epoch: 16, Steps: 264 Train Loss: 0.5154 (Forecasting Loss:0.2236 + XiCon Loss:2.9184 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1137
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5245793
	speed: 0.0424s/iter; left time: 935.4220s
	iters: 200, epoch: 17 | loss: 0.5170168
	speed: 0.0396s/iter; left time: 870.2574s
Epoch: 17 cost time: 10.78760576248169
Epoch: 17, Steps: 264 Train Loss: 0.5153 (Forecasting Loss:0.2236 + XiCon Loss:2.9175 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1137
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5454910
	speed: 0.0423s/iter; left time: 922.0891s
	iters: 200, epoch: 18 | loss: 0.5273256
	speed: 0.0406s/iter; left time: 880.6358s
Epoch: 18 cost time: 10.839828729629517
Epoch: 18, Steps: 264 Train Loss: 0.5152 (Forecasting Loss:0.2235 + XiCon Loss:2.9169 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1137
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5349846
	speed: 0.0430s/iter; left time: 926.3530s
	iters: 200, epoch: 19 | loss: 0.5026373
	speed: 0.0403s/iter; left time: 865.3856s
Epoch: 19 cost time: 10.960320711135864
Epoch: 19, Steps: 264 Train Loss: 0.5154 (Forecasting Loss:0.2235 + XiCon Loss:2.9191 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1137
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05359521508216858, mae:0.1737571507692337, mape:0.13630987703800201, mspe:0.033734291791915894 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.8768
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5179309
	speed: 0.0408s/iter; left time: 1074.2407s
	iters: 200, epoch: 1 | loss: 0.5384713
	speed: 0.0379s/iter; left time: 992.6257s
Epoch: 1 cost time: 10.2428879737854
Epoch: 1, Steps: 264 Train Loss: 0.5454 (Forecasting Loss:0.2363 + XiCon Loss:3.0901 x Lambda(0.1)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1158
Validation loss decreased (inf --> 0.174149).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5723489
	speed: 0.0444s/iter; left time: 1154.9801s
	iters: 200, epoch: 2 | loss: 0.5462573
	speed: 0.0409s/iter; left time: 1061.3251s
Epoch: 2 cost time: 11.062874794006348
Epoch: 2, Steps: 264 Train Loss: 0.5442 (Forecasting Loss:0.2437 + XiCon Loss:3.0052 x Lambda(0.1)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1224
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5108463
	speed: 0.0386s/iter; left time: 994.6983s
	iters: 200, epoch: 3 | loss: 0.4898638
	speed: 0.0363s/iter; left time: 932.2492s
Epoch: 3 cost time: 10.152952671051025
Epoch: 3, Steps: 264 Train Loss: 0.5260 (Forecasting Loss:0.2333 + XiCon Loss:2.9268 x Lambda(0.1)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1154
Validation loss decreased (0.174149 --> 0.173282).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5352418
	speed: 0.0431s/iter; left time: 1099.1181s
	iters: 200, epoch: 4 | loss: 0.5271316
	speed: 0.0402s/iter; left time: 1021.6881s
Epoch: 4 cost time: 10.927749156951904
Epoch: 4, Steps: 264 Train Loss: 0.5206 (Forecasting Loss:0.2301 + XiCon Loss:2.9047 x Lambda(0.1)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1139
Validation loss decreased (0.173282 --> 0.171808).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5027876
	speed: 0.0432s/iter; left time: 1091.1537s
	iters: 200, epoch: 5 | loss: 0.5055546
	speed: 0.0404s/iter; left time: 1016.1866s
Epoch: 5 cost time: 10.99804401397705
Epoch: 5, Steps: 264 Train Loss: 0.5163 (Forecasting Loss:0.2272 + XiCon Loss:2.8911 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1133
Validation loss decreased (0.171808 --> 0.170949).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5267235
	speed: 0.0422s/iter; left time: 1053.1298s
	iters: 200, epoch: 6 | loss: 0.5041858
	speed: 0.0400s/iter; left time: 995.2102s
Epoch: 6 cost time: 10.817769050598145
Epoch: 6, Steps: 264 Train Loss: 0.5139 (Forecasting Loss:0.2255 + XiCon Loss:2.8840 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1122
Validation loss decreased (0.170949 --> 0.169686).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5397130
	speed: 0.0423s/iter; left time: 1046.5726s
	iters: 200, epoch: 7 | loss: 0.5182549
	speed: 0.0410s/iter; left time: 1008.6239s
Epoch: 7 cost time: 10.89566707611084
Epoch: 7, Steps: 264 Train Loss: 0.5132 (Forecasting Loss:0.2247 + XiCon Loss:2.8850 x Lambda(0.1)), Vali MSE Loss: 0.1696 Test MSE Loss: 0.1122
Validation loss decreased (0.169686 --> 0.169575).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5249399
	speed: 0.0421s/iter; left time: 1029.0715s
	iters: 200, epoch: 8 | loss: 0.5143622
	speed: 0.0416s/iter; left time: 1013.5959s
Epoch: 8 cost time: 10.897185802459717
Epoch: 8, Steps: 264 Train Loss: 0.5123 (Forecasting Loss:0.2240 + XiCon Loss:2.8822 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1121
Validation loss decreased (0.169575 --> 0.169255).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5061158
	speed: 0.0426s/iter; left time: 1030.7650s
	iters: 200, epoch: 9 | loss: 0.5152771
	speed: 0.0412s/iter; left time: 992.6823s
Epoch: 9 cost time: 10.901218891143799
Epoch: 9, Steps: 264 Train Loss: 0.5117 (Forecasting Loss:0.2239 + XiCon Loss:2.8782 x Lambda(0.1)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1120
Validation loss decreased (0.169255 --> 0.169195).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5514380
	speed: 0.0423s/iter; left time: 1011.7095s
	iters: 200, epoch: 10 | loss: 0.5226164
	speed: 0.0406s/iter; left time: 967.3012s
Epoch: 10 cost time: 10.876014232635498
Epoch: 10, Steps: 264 Train Loss: 0.5122 (Forecasting Loss:0.2238 + XiCon Loss:2.8835 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4862915
	speed: 0.0417s/iter; left time: 987.7042s
	iters: 200, epoch: 11 | loss: 0.5193375
	speed: 0.0404s/iter; left time: 952.9158s
Epoch: 11 cost time: 10.85147738456726
Epoch: 11, Steps: 264 Train Loss: 0.5116 (Forecasting Loss:0.2236 + XiCon Loss:2.8798 x Lambda(0.1)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1122
Validation loss decreased (0.169195 --> 0.169156).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5027432
	speed: 0.0408s/iter; left time: 954.2624s
	iters: 200, epoch: 12 | loss: 0.5368787
	speed: 0.0364s/iter; left time: 848.2969s
Epoch: 12 cost time: 10.145678997039795
Epoch: 12, Steps: 264 Train Loss: 0.5118 (Forecasting Loss:0.2237 + XiCon Loss:2.8804 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4944000
	speed: 0.0417s/iter; left time: 964.9128s
	iters: 200, epoch: 13 | loss: 0.4858914
	speed: 0.0407s/iter; left time: 936.4987s
Epoch: 13 cost time: 10.831760883331299
Epoch: 13, Steps: 264 Train Loss: 0.5116 (Forecasting Loss:0.2236 + XiCon Loss:2.8803 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5087017
	speed: 0.0425s/iter; left time: 972.0891s
	iters: 200, epoch: 14 | loss: 0.5044092
	speed: 0.0394s/iter; left time: 896.9220s
Epoch: 14 cost time: 10.744502067565918
Epoch: 14, Steps: 264 Train Loss: 0.5117 (Forecasting Loss:0.2236 + XiCon Loss:2.8817 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5351759
	speed: 0.0424s/iter; left time: 959.1165s
	iters: 200, epoch: 15 | loss: 0.5391450
	speed: 0.0399s/iter; left time: 897.7954s
Epoch: 15 cost time: 10.853282690048218
Epoch: 15, Steps: 264 Train Loss: 0.5118 (Forecasting Loss:0.2235 + XiCon Loss:2.8825 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5152590
	speed: 0.0428s/iter; left time: 955.9111s
	iters: 200, epoch: 16 | loss: 0.5127683
	speed: 0.0406s/iter; left time: 904.0448s
Epoch: 16 cost time: 10.93308138847351
Epoch: 16, Steps: 264 Train Loss: 0.5118 (Forecasting Loss:0.2236 + XiCon Loss:2.8825 x Lambda(0.1)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1122
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5226872
	speed: 0.0424s/iter; left time: 936.1887s
	iters: 200, epoch: 17 | loss: 0.4894326
	speed: 0.0404s/iter; left time: 888.3385s
Epoch: 17 cost time: 10.873603105545044
Epoch: 17, Steps: 264 Train Loss: 0.5116 (Forecasting Loss:0.2235 + XiCon Loss:2.8809 x Lambda(0.1)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1122
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.4985353
	speed: 0.0440s/iter; left time: 959.0190s
	iters: 200, epoch: 18 | loss: 0.5352272
	speed: 0.0398s/iter; left time: 864.4630s
Epoch: 18 cost time: 11.043902158737183
Epoch: 18, Steps: 264 Train Loss: 0.5119 (Forecasting Loss:0.2235 + XiCon Loss:2.8833 x Lambda(0.1)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1122
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5308255
	speed: 0.0428s/iter; left time: 922.9494s
	iters: 200, epoch: 19 | loss: 0.5167570
	speed: 0.0406s/iter; left time: 871.3803s
Epoch: 19 cost time: 10.92972469329834
Epoch: 19, Steps: 264 Train Loss: 0.5118 (Forecasting Loss:0.2236 + XiCon Loss:2.8816 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5140785
	speed: 0.0435s/iter; left time: 925.6281s
	iters: 200, epoch: 20 | loss: 0.5079178
	speed: 0.0408s/iter; left time: 864.1755s
Epoch: 20 cost time: 11.073314666748047
Epoch: 20, Steps: 264 Train Loss: 0.5117 (Forecasting Loss:0.2235 + XiCon Loss:2.8827 x Lambda(0.1)), Vali MSE Loss: 0.1693 Test MSE Loss: 0.1122
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5306692
	speed: 0.0423s/iter; left time: 888.7345s
	iters: 200, epoch: 21 | loss: 0.5198590
	speed: 0.0361s/iter; left time: 754.6211s
Epoch: 21 cost time: 10.20768427848816
Epoch: 21, Steps: 264 Train Loss: 0.5120 (Forecasting Loss:0.2237 + XiCon Loss:2.8833 x Lambda(0.1)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1122
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05222931131720543, mae:0.1721697747707367, mape:0.134660542011261, mspe:0.03237928822636604 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0527+-0.00068, MAE:0.1726+-0.00080, MAPE:0.1350+-0.00090, MSPE:0.0326+-0.00076, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9823
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6175165
	speed: 0.0435s/iter; left time: 1130.8131s
	iters: 200, epoch: 1 | loss: 0.6410234
	speed: 0.0374s/iter; left time: 969.9381s
Epoch: 1 cost time: 10.378162622451782
Epoch: 1, Steps: 261 Train Loss: 0.6150 (Forecasting Loss:0.2770 + XiCon Loss:3.3801 x Lambda(0.1)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1413
Validation loss decreased (inf --> 0.199812).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5816404
	speed: 0.0405s/iter; left time: 1041.4697s
	iters: 200, epoch: 2 | loss: 0.5689257
	speed: 0.0429s/iter; left time: 1100.4082s
Epoch: 2 cost time: 11.029799222946167
Epoch: 2, Steps: 261 Train Loss: 0.5824 (Forecasting Loss:0.2675 + XiCon Loss:3.1491 x Lambda(0.1)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.1401
Validation loss decreased (0.199812 --> 0.188407).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5682486
	speed: 0.0450s/iter; left time: 1145.4128s
	iters: 200, epoch: 3 | loss: 0.5632043
	speed: 0.0395s/iter; left time: 1002.5974s
Epoch: 3 cost time: 10.742326021194458
Epoch: 3, Steps: 261 Train Loss: 0.5631 (Forecasting Loss:0.2536 + XiCon Loss:3.0953 x Lambda(0.1)), Vali MSE Loss: 0.1919 Test MSE Loss: 0.1413
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5765218
	speed: 0.0410s/iter; left time: 1034.2863s
	iters: 200, epoch: 4 | loss: 0.5631689
	speed: 0.0392s/iter; left time: 983.5801s
Epoch: 4 cost time: 10.32849669456482
Epoch: 4, Steps: 261 Train Loss: 0.5562 (Forecasting Loss:0.2478 + XiCon Loss:3.0846 x Lambda(0.1)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1476
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5566107
	speed: 0.0416s/iter; left time: 1037.9533s
	iters: 200, epoch: 5 | loss: 0.5677242
	speed: 0.0401s/iter; left time: 996.4009s
Epoch: 5 cost time: 10.617212057113647
Epoch: 5, Steps: 261 Train Loss: 0.5506 (Forecasting Loss:0.2432 + XiCon Loss:3.0740 x Lambda(0.1)), Vali MSE Loss: 0.1896 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5614479
	speed: 0.0406s/iter; left time: 1002.7764s
	iters: 200, epoch: 6 | loss: 0.5289668
	speed: 0.0398s/iter; left time: 980.1297s
Epoch: 6 cost time: 10.431403875350952
Epoch: 6, Steps: 261 Train Loss: 0.5476 (Forecasting Loss:0.2405 + XiCon Loss:3.0708 x Lambda(0.1)), Vali MSE Loss: 0.1906 Test MSE Loss: 0.1439
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5433990
	speed: 0.0414s/iter; left time: 1011.1539s
	iters: 200, epoch: 7 | loss: 0.5425342
	speed: 0.0391s/iter; left time: 950.3478s
Epoch: 7 cost time: 10.394740104675293
Epoch: 7, Steps: 261 Train Loss: 0.5462 (Forecasting Loss:0.2393 + XiCon Loss:3.0691 x Lambda(0.1)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.1446
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5554100
	speed: 0.0392s/iter; left time: 947.7434s
	iters: 200, epoch: 8 | loss: 0.5435726
	speed: 0.0362s/iter; left time: 870.4513s
Epoch: 8 cost time: 9.787545919418335
Epoch: 8, Steps: 261 Train Loss: 0.5457 (Forecasting Loss:0.2387 + XiCon Loss:3.0699 x Lambda(0.1)), Vali MSE Loss: 0.1918 Test MSE Loss: 0.1446
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5543936
	speed: 0.0418s/iter; left time: 999.2406s
	iters: 200, epoch: 9 | loss: 0.5538443
	speed: 0.0390s/iter; left time: 928.4807s
Epoch: 9 cost time: 10.44290280342102
Epoch: 9, Steps: 261 Train Loss: 0.5453 (Forecasting Loss:0.2383 + XiCon Loss:3.0706 x Lambda(0.1)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.1444
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5356383
	speed: 0.0411s/iter; left time: 972.5554s
	iters: 200, epoch: 10 | loss: 0.5398496
	speed: 0.0395s/iter; left time: 929.2007s
Epoch: 10 cost time: 10.41570258140564
Epoch: 10, Steps: 261 Train Loss: 0.5448 (Forecasting Loss:0.2381 + XiCon Loss:3.0668 x Lambda(0.1)), Vali MSE Loss: 0.1917 Test MSE Loss: 0.1445
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5563788
	speed: 0.0409s/iter; left time: 957.0218s
	iters: 200, epoch: 11 | loss: 0.5516813
	speed: 0.0400s/iter; left time: 931.8792s
Epoch: 11 cost time: 10.502949714660645
Epoch: 11, Steps: 261 Train Loss: 0.5447 (Forecasting Loss:0.2379 + XiCon Loss:3.0681 x Lambda(0.1)), Vali MSE Loss: 0.1918 Test MSE Loss: 0.1443
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5595942
	speed: 0.0406s/iter; left time: 938.1444s
	iters: 200, epoch: 12 | loss: 0.5401995
	speed: 0.0392s/iter; left time: 903.6007s
Epoch: 12 cost time: 10.418686151504517
Epoch: 12, Steps: 261 Train Loss: 0.5446 (Forecasting Loss:0.2378 + XiCon Loss:3.0687 x Lambda(0.1)), Vali MSE Loss: 0.1918 Test MSE Loss: 0.1445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07344240695238113, mae:0.20667771995067596, mape:0.15993431210517883, mspe:0.04507929086685181 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1355
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6089419
	speed: 0.0406s/iter; left time: 1055.1191s
	iters: 200, epoch: 1 | loss: 0.5870394
	speed: 0.0368s/iter; left time: 952.3717s
Epoch: 1 cost time: 10.065892934799194
Epoch: 1, Steps: 261 Train Loss: 0.6131 (Forecasting Loss:0.2752 + XiCon Loss:3.3795 x Lambda(0.1)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1409
Validation loss decreased (inf --> 0.199016).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5909187
	speed: 0.0433s/iter; left time: 1115.5417s
	iters: 200, epoch: 2 | loss: 0.5629364
	speed: 0.0427s/iter; left time: 1095.9837s
Epoch: 2 cost time: 11.302314519882202
Epoch: 2, Steps: 261 Train Loss: 0.5842 (Forecasting Loss:0.2712 + XiCon Loss:3.1306 x Lambda(0.1)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6000003
	speed: 0.0441s/iter; left time: 1124.5495s
	iters: 200, epoch: 3 | loss: 0.5819225
	speed: 0.0432s/iter; left time: 1096.3878s
Epoch: 3 cost time: 11.263402462005615
Epoch: 3, Steps: 261 Train Loss: 0.5728 (Forecasting Loss:0.2636 + XiCon Loss:3.0920 x Lambda(0.1)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1421
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5594208
	speed: 0.0415s/iter; left time: 1045.4651s
	iters: 200, epoch: 4 | loss: 0.5700155
	speed: 0.0378s/iter; left time: 949.6936s
Epoch: 4 cost time: 10.395232677459717
Epoch: 4, Steps: 261 Train Loss: 0.5645 (Forecasting Loss:0.2589 + XiCon Loss:3.0558 x Lambda(0.1)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1398
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5619745
	speed: 0.0445s/iter; left time: 1109.6179s
	iters: 200, epoch: 5 | loss: 0.6026582
	speed: 0.0414s/iter; left time: 1029.6252s
Epoch: 5 cost time: 11.15859055519104
Epoch: 5, Steps: 261 Train Loss: 0.5597 (Forecasting Loss:0.2550 + XiCon Loss:3.0469 x Lambda(0.1)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1408
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5494345
	speed: 0.0445s/iter; left time: 1098.4310s
	iters: 200, epoch: 6 | loss: 0.5394340
	speed: 0.0410s/iter; left time: 1007.2328s
Epoch: 6 cost time: 11.074182987213135
Epoch: 6, Steps: 261 Train Loss: 0.5570 (Forecasting Loss:0.2529 + XiCon Loss:3.0410 x Lambda(0.1)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1406
Validation loss decreased (0.199016 --> 0.198430).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5534120
	speed: 0.0447s/iter; left time: 1092.1007s
	iters: 200, epoch: 7 | loss: 0.5503390
	speed: 0.0409s/iter; left time: 996.2308s
Epoch: 7 cost time: 11.1176016330719
Epoch: 7, Steps: 261 Train Loss: 0.5555 (Forecasting Loss:0.2515 + XiCon Loss:3.0402 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1408
Validation loss decreased (0.198430 --> 0.197858).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5596324
	speed: 0.0442s/iter; left time: 1067.3684s
	iters: 200, epoch: 8 | loss: 0.5696599
	speed: 0.0416s/iter; left time: 1000.7606s
Epoch: 8 cost time: 11.084461450576782
Epoch: 8, Steps: 261 Train Loss: 0.5548 (Forecasting Loss:0.2510 + XiCon Loss:3.0383 x Lambda(0.1)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1409
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5432483
	speed: 0.0435s/iter; left time: 1041.2036s
	iters: 200, epoch: 9 | loss: 0.5386713
	speed: 0.0422s/iter; left time: 1003.8993s
Epoch: 9 cost time: 11.122000455856323
Epoch: 9, Steps: 261 Train Loss: 0.5544 (Forecasting Loss:0.2506 + XiCon Loss:3.0383 x Lambda(0.1)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1415
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5685555
	speed: 0.0439s/iter; left time: 1038.6250s
	iters: 200, epoch: 10 | loss: 0.5509489
	speed: 0.0417s/iter; left time: 981.9996s
Epoch: 10 cost time: 11.234182596206665
Epoch: 10, Steps: 261 Train Loss: 0.5541 (Forecasting Loss:0.2501 + XiCon Loss:3.0393 x Lambda(0.1)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1415
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5338057
	speed: 0.0443s/iter; left time: 1037.0237s
	iters: 200, epoch: 11 | loss: 0.5477067
	speed: 0.0419s/iter; left time: 975.3814s
Epoch: 11 cost time: 11.241278409957886
Epoch: 11, Steps: 261 Train Loss: 0.5540 (Forecasting Loss:0.2503 + XiCon Loss:3.0373 x Lambda(0.1)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1412
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5480847
	speed: 0.0439s/iter; left time: 1015.1145s
	iters: 200, epoch: 12 | loss: 0.5948814
	speed: 0.0428s/iter; left time: 985.1327s
Epoch: 12 cost time: 11.171091794967651
Epoch: 12, Steps: 261 Train Loss: 0.5541 (Forecasting Loss:0.2502 + XiCon Loss:3.0389 x Lambda(0.1)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1411
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5397934
	speed: 0.0403s/iter; left time: 921.4742s
	iters: 200, epoch: 13 | loss: 0.5680672
	speed: 0.0376s/iter; left time: 857.1263s
Epoch: 13 cost time: 10.343528270721436
Epoch: 13, Steps: 261 Train Loss: 0.5540 (Forecasting Loss:0.2501 + XiCon Loss:3.0385 x Lambda(0.1)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1411
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5709611
	speed: 0.0447s/iter; left time: 1010.7924s
	iters: 200, epoch: 14 | loss: 0.5449512
	speed: 0.0414s/iter; left time: 931.4166s
Epoch: 14 cost time: 11.128759622573853
Epoch: 14, Steps: 261 Train Loss: 0.5539 (Forecasting Loss:0.2501 + XiCon Loss:3.0386 x Lambda(0.1)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1411
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5489758
	speed: 0.0449s/iter; left time: 1002.8939s
	iters: 200, epoch: 15 | loss: 0.5409229
	speed: 0.0420s/iter; left time: 933.5686s
Epoch: 15 cost time: 11.270917654037476
Epoch: 15, Steps: 261 Train Loss: 0.5540 (Forecasting Loss:0.2500 + XiCon Loss:3.0401 x Lambda(0.1)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1411
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5485788
	speed: 0.0443s/iter; left time: 979.0549s
	iters: 200, epoch: 16 | loss: 0.5487329
	speed: 0.0420s/iter; left time: 922.6536s
Epoch: 16 cost time: 11.13028883934021
Epoch: 16, Steps: 261 Train Loss: 0.5539 (Forecasting Loss:0.2502 + XiCon Loss:3.0371 x Lambda(0.1)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1411
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5511836
	speed: 0.0445s/iter; left time: 972.1734s
	iters: 200, epoch: 17 | loss: 0.5632337
	speed: 0.0428s/iter; left time: 929.0375s
Epoch: 17 cost time: 11.245318412780762
Epoch: 17, Steps: 261 Train Loss: 0.5538 (Forecasting Loss:0.2500 + XiCon Loss:3.0383 x Lambda(0.1)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1411
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07369983196258545, mae:0.20786328613758087, mape:0.15739981830120087, mspe:0.04154045507311821 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7469
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6028460
	speed: 0.0414s/iter; left time: 1075.9199s
	iters: 200, epoch: 1 | loss: 0.6037517
	speed: 0.0381s/iter; left time: 985.9348s
Epoch: 1 cost time: 10.270734310150146
Epoch: 1, Steps: 261 Train Loss: 0.6135 (Forecasting Loss:0.2759 + XiCon Loss:3.3755 x Lambda(0.1)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1418
Validation loss decreased (inf --> 0.199322).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5783896
	speed: 0.0398s/iter; left time: 1025.5598s
	iters: 200, epoch: 2 | loss: 0.5765342
	speed: 0.0407s/iter; left time: 1044.5107s
Epoch: 2 cost time: 10.721795797348022
Epoch: 2, Steps: 261 Train Loss: 0.5826 (Forecasting Loss:0.2697 + XiCon Loss:3.1295 x Lambda(0.1)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1450
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5696431
	speed: 0.0453s/iter; left time: 1154.0039s
	iters: 200, epoch: 3 | loss: 0.5985895
	speed: 0.0437s/iter; left time: 1108.4044s
Epoch: 3 cost time: 11.522938251495361
Epoch: 3, Steps: 261 Train Loss: 0.5646 (Forecasting Loss:0.2586 + XiCon Loss:3.0605 x Lambda(0.1)), Vali MSE Loss: 0.1892 Test MSE Loss: 0.1434
Validation loss decreased (0.199322 --> 0.189154).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5685230
	speed: 0.0416s/iter; left time: 1050.0305s
	iters: 200, epoch: 4 | loss: 0.5419901
	speed: 0.0444s/iter; left time: 1116.0267s
Epoch: 4 cost time: 11.27920413017273
Epoch: 4, Steps: 261 Train Loss: 0.5562 (Forecasting Loss:0.2491 + XiCon Loss:3.0714 x Lambda(0.1)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1405
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5416914
	speed: 0.0460s/iter; left time: 1147.7566s
	iters: 200, epoch: 5 | loss: 0.5463697
	speed: 0.0437s/iter; left time: 1085.5764s
Epoch: 5 cost time: 11.668543100357056
Epoch: 5, Steps: 261 Train Loss: 0.5505 (Forecasting Loss:0.2440 + XiCon Loss:3.0654 x Lambda(0.1)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1406
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5332474
	speed: 0.0468s/iter; left time: 1156.2686s
	iters: 200, epoch: 6 | loss: 0.5576341
	speed: 0.0431s/iter; left time: 1059.8689s
Epoch: 6 cost time: 11.696446418762207
Epoch: 6, Steps: 261 Train Loss: 0.5481 (Forecasting Loss:0.2416 + XiCon Loss:3.0644 x Lambda(0.1)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1437
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5584645
	speed: 0.0462s/iter; left time: 1129.7193s
	iters: 200, epoch: 7 | loss: 0.5543645
	speed: 0.0433s/iter; left time: 1053.1103s
Epoch: 7 cost time: 11.558930397033691
Epoch: 7, Steps: 261 Train Loss: 0.5468 (Forecasting Loss:0.2405 + XiCon Loss:3.0631 x Lambda(0.1)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1426
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5651775
	speed: 0.0456s/iter; left time: 1103.1362s
	iters: 200, epoch: 8 | loss: 0.5381048
	speed: 0.0442s/iter; left time: 1064.2369s
Epoch: 8 cost time: 11.64553165435791
Epoch: 8, Steps: 261 Train Loss: 0.5461 (Forecasting Loss:0.2399 + XiCon Loss:3.0622 x Lambda(0.1)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1418
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5247971
	speed: 0.0458s/iter; left time: 1096.0368s
	iters: 200, epoch: 9 | loss: 0.5735048
	speed: 0.0437s/iter; left time: 1041.5761s
Epoch: 9 cost time: 11.644445896148682
Epoch: 9, Steps: 261 Train Loss: 0.5456 (Forecasting Loss:0.2394 + XiCon Loss:3.0622 x Lambda(0.1)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1416
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5442508
	speed: 0.0466s/iter; left time: 1101.8893s
	iters: 200, epoch: 10 | loss: 0.5262055
	speed: 0.0432s/iter; left time: 1017.6208s
Epoch: 10 cost time: 11.57533049583435
Epoch: 10, Steps: 261 Train Loss: 0.5458 (Forecasting Loss:0.2395 + XiCon Loss:3.0627 x Lambda(0.1)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1422
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5572222
	speed: 0.0461s/iter; left time: 1078.2703s
	iters: 200, epoch: 11 | loss: 0.5454767
	speed: 0.0433s/iter; left time: 1008.8527s
Epoch: 11 cost time: 11.55599045753479
Epoch: 11, Steps: 261 Train Loss: 0.5455 (Forecasting Loss:0.2393 + XiCon Loss:3.0615 x Lambda(0.1)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1422
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5518525
	speed: 0.0460s/iter; left time: 1065.0102s
	iters: 200, epoch: 12 | loss: 0.5499144
	speed: 0.0401s/iter; left time: 922.9086s
Epoch: 12 cost time: 11.125274658203125
Epoch: 12, Steps: 261 Train Loss: 0.5457 (Forecasting Loss:0.2394 + XiCon Loss:3.0632 x Lambda(0.1)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1423
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5458286
	speed: 0.0471s/iter; left time: 1076.4585s
	iters: 200, epoch: 13 | loss: 0.5338892
	speed: 0.0440s/iter; left time: 1002.7563s
Epoch: 13 cost time: 11.682617902755737
Epoch: 13, Steps: 261 Train Loss: 0.5457 (Forecasting Loss:0.2394 + XiCon Loss:3.0631 x Lambda(0.1)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1423
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07594604045152664, mae:0.2109062671661377, mape:0.15963825583457947, mspe:0.04256719350814819 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8312
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6146722
	speed: 0.0407s/iter; left time: 1059.0264s
	iters: 200, epoch: 1 | loss: 0.6048607
	speed: 0.0379s/iter; left time: 982.2001s
Epoch: 1 cost time: 10.113371849060059
Epoch: 1, Steps: 261 Train Loss: 0.6132 (Forecasting Loss:0.2753 + XiCon Loss:3.3787 x Lambda(0.1)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.197289).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5927383
	speed: 0.0405s/iter; left time: 1041.8898s
	iters: 200, epoch: 2 | loss: 0.5777586
	speed: 0.0379s/iter; left time: 972.1267s
Epoch: 2 cost time: 10.116591930389404
Epoch: 2, Steps: 261 Train Loss: 0.5843 (Forecasting Loss:0.2636 + XiCon Loss:3.2066 x Lambda(0.1)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1470
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5871744
	speed: 0.0405s/iter; left time: 1031.3393s
	iters: 200, epoch: 3 | loss: 0.5692358
	speed: 0.0384s/iter; left time: 973.5726s
Epoch: 3 cost time: 10.174782276153564
Epoch: 3, Steps: 261 Train Loss: 0.5705 (Forecasting Loss:0.2552 + XiCon Loss:3.1533 x Lambda(0.1)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1470
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5569929
	speed: 0.0407s/iter; left time: 1027.0620s
	iters: 200, epoch: 4 | loss: 0.5678622
	speed: 0.0383s/iter; left time: 960.8292s
Epoch: 4 cost time: 10.255030632019043
Epoch: 4, Steps: 261 Train Loss: 0.5576 (Forecasting Loss:0.2470 + XiCon Loss:3.1060 x Lambda(0.1)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1481
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5413939
	speed: 0.0408s/iter; left time: 1017.3015s
	iters: 200, epoch: 5 | loss: 0.5368789
	speed: 0.0389s/iter; left time: 965.8259s
Epoch: 5 cost time: 10.23913860321045
Epoch: 5, Steps: 261 Train Loss: 0.5517 (Forecasting Loss:0.2428 + XiCon Loss:3.0890 x Lambda(0.1)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1457
Validation loss decreased (0.197289 --> 0.195611).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5334661
	speed: 0.0418s/iter; left time: 1032.3687s
	iters: 200, epoch: 6 | loss: 0.5624610
	speed: 0.0391s/iter; left time: 962.8078s
Epoch: 6 cost time: 10.427690744400024
Epoch: 6, Steps: 261 Train Loss: 0.5487 (Forecasting Loss:0.2405 + XiCon Loss:3.0817 x Lambda(0.1)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1514
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5456289
	speed: 0.0423s/iter; left time: 1034.4914s
	iters: 200, epoch: 7 | loss: 0.5337399
	speed: 0.0362s/iter; left time: 880.0144s
Epoch: 7 cost time: 10.08351755142212
Epoch: 7, Steps: 261 Train Loss: 0.5470 (Forecasting Loss:0.2390 + XiCon Loss:3.0801 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1494
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5541359
	speed: 0.0422s/iter; left time: 1020.9836s
	iters: 200, epoch: 8 | loss: 0.5430653
	speed: 0.0389s/iter; left time: 935.7755s
Epoch: 8 cost time: 10.462923049926758
Epoch: 8, Steps: 261 Train Loss: 0.5460 (Forecasting Loss:0.2383 + XiCon Loss:3.0769 x Lambda(0.1)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1502
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5230587
	speed: 0.0419s/iter; left time: 1002.2946s
	iters: 200, epoch: 9 | loss: 0.5332892
	speed: 0.0395s/iter; left time: 941.6595s
Epoch: 9 cost time: 10.52334189414978
Epoch: 9, Steps: 261 Train Loss: 0.5459 (Forecasting Loss:0.2381 + XiCon Loss:3.0785 x Lambda(0.1)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1510
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5416586
	speed: 0.0413s/iter; left time: 977.6759s
	iters: 200, epoch: 10 | loss: 0.5605653
	speed: 0.0386s/iter; left time: 909.2485s
Epoch: 10 cost time: 10.356894969940186
Epoch: 10, Steps: 261 Train Loss: 0.5456 (Forecasting Loss:0.2379 + XiCon Loss:3.0762 x Lambda(0.1)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1507
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5610965
	speed: 0.0408s/iter; left time: 954.4003s
	iters: 200, epoch: 11 | loss: 0.5590063
	speed: 0.0393s/iter; left time: 914.5342s
Epoch: 11 cost time: 10.377283573150635
Epoch: 11, Steps: 261 Train Loss: 0.5455 (Forecasting Loss:0.2378 + XiCon Loss:3.0775 x Lambda(0.1)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1511
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5391800
	speed: 0.0422s/iter; left time: 974.9498s
	iters: 200, epoch: 12 | loss: 0.5435909
	speed: 0.0386s/iter; left time: 889.1958s
Epoch: 12 cost time: 10.43793272972107
Epoch: 12, Steps: 261 Train Loss: 0.5454 (Forecasting Loss:0.2377 + XiCon Loss:3.0763 x Lambda(0.1)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1511
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5388368
	speed: 0.0414s/iter; left time: 945.7334s
	iters: 200, epoch: 13 | loss: 0.5504775
	speed: 0.0380s/iter; left time: 864.4318s
Epoch: 13 cost time: 10.25848937034607
Epoch: 13, Steps: 261 Train Loss: 0.5455 (Forecasting Loss:0.2379 + XiCon Loss:3.0760 x Lambda(0.1)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1511
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5594848
	speed: 0.0410s/iter; left time: 927.1503s
	iters: 200, epoch: 14 | loss: 0.5344573
	speed: 0.0391s/iter; left time: 879.3134s
Epoch: 14 cost time: 10.333791971206665
Epoch: 14, Steps: 261 Train Loss: 0.5455 (Forecasting Loss:0.2378 + XiCon Loss:3.0769 x Lambda(0.1)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1512
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5566627
	speed: 0.0412s/iter; left time: 919.9666s
	iters: 200, epoch: 15 | loss: 0.5453793
	speed: 0.0392s/iter; left time: 872.9732s
Epoch: 15 cost time: 10.419148921966553
Epoch: 15, Steps: 261 Train Loss: 0.5453 (Forecasting Loss:0.2376 + XiCon Loss:3.0771 x Lambda(0.1)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1512
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0777314230799675, mae:0.21358975768089294, mape:0.16723713278770447, mspe:0.04990590363740921 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1494
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6497180
	speed: 0.0369s/iter; left time: 958.8011s
	iters: 200, epoch: 1 | loss: 0.6042064
	speed: 0.0342s/iter; left time: 886.1819s
Epoch: 1 cost time: 9.148446798324585
Epoch: 1, Steps: 261 Train Loss: 0.6125 (Forecasting Loss:0.2744 + XiCon Loss:3.3807 x Lambda(0.1)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1415
Validation loss decreased (inf --> 0.199797).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5913951
	speed: 0.0388s/iter; left time: 997.6865s
	iters: 200, epoch: 2 | loss: 0.6146603
	speed: 0.0412s/iter; left time: 1055.3375s
Epoch: 2 cost time: 10.322267532348633
Epoch: 2, Steps: 261 Train Loss: 0.5900 (Forecasting Loss:0.2716 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1432
Validation loss decreased (0.199797 --> 0.196512).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5726322
	speed: 0.0414s/iter; left time: 1053.6493s
	iters: 200, epoch: 3 | loss: 0.5594899
	speed: 0.0384s/iter; left time: 975.4502s
Epoch: 3 cost time: 10.335086584091187
Epoch: 3, Steps: 261 Train Loss: 0.5728 (Forecasting Loss:0.2598 + XiCon Loss:3.1301 x Lambda(0.1)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1429
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5598205
	speed: 0.0412s/iter; left time: 1039.6110s
	iters: 200, epoch: 4 | loss: 0.5711910
	speed: 0.0383s/iter; left time: 962.8039s
Epoch: 4 cost time: 10.330430269241333
Epoch: 4, Steps: 261 Train Loss: 0.5586 (Forecasting Loss:0.2489 + XiCon Loss:3.0972 x Lambda(0.1)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5450602
	speed: 0.0424s/iter; left time: 1057.6440s
	iters: 200, epoch: 5 | loss: 0.5434719
	speed: 0.0392s/iter; left time: 974.9257s
Epoch: 5 cost time: 10.479437589645386
Epoch: 5, Steps: 261 Train Loss: 0.5518 (Forecasting Loss:0.2427 + XiCon Loss:3.0914 x Lambda(0.1)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1409
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5501117
	speed: 0.0421s/iter; left time: 1039.3914s
	iters: 200, epoch: 6 | loss: 0.5289139
	speed: 0.0384s/iter; left time: 944.4780s
Epoch: 6 cost time: 10.380068063735962
Epoch: 6, Steps: 261 Train Loss: 0.5482 (Forecasting Loss:0.2393 + XiCon Loss:3.0892 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1406
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5490559
	speed: 0.0415s/iter; left time: 1015.0089s
	iters: 200, epoch: 7 | loss: 0.5569866
	speed: 0.0384s/iter; left time: 933.4232s
Epoch: 7 cost time: 10.357677459716797
Epoch: 7, Steps: 261 Train Loss: 0.5468 (Forecasting Loss:0.2379 + XiCon Loss:3.0886 x Lambda(0.1)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1403
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5571495
	speed: 0.0426s/iter; left time: 1029.0976s
	iters: 200, epoch: 8 | loss: 0.5508590
	speed: 0.0395s/iter; left time: 951.9959s
Epoch: 8 cost time: 10.553111791610718
Epoch: 8, Steps: 261 Train Loss: 0.5460 (Forecasting Loss:0.2373 + XiCon Loss:3.0872 x Lambda(0.1)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1405
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5227202
	speed: 0.0418s/iter; left time: 999.8240s
	iters: 200, epoch: 9 | loss: 0.5550328
	speed: 0.0386s/iter; left time: 920.2499s
Epoch: 9 cost time: 10.372720718383789
Epoch: 9, Steps: 261 Train Loss: 0.5457 (Forecasting Loss:0.2369 + XiCon Loss:3.0886 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1399
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5424086
	speed: 0.0383s/iter; left time: 906.0410s
	iters: 200, epoch: 10 | loss: 0.5700819
	speed: 0.0361s/iter; left time: 849.9313s
Epoch: 10 cost time: 9.795565128326416
Epoch: 10, Steps: 261 Train Loss: 0.5453 (Forecasting Loss:0.2366 + XiCon Loss:3.0870 x Lambda(0.1)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1402
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5473849
	speed: 0.0426s/iter; left time: 996.5468s
	iters: 200, epoch: 11 | loss: 0.5412526
	speed: 0.0387s/iter; left time: 900.6066s
Epoch: 11 cost time: 10.499014616012573
Epoch: 11, Steps: 261 Train Loss: 0.5452 (Forecasting Loss:0.2366 + XiCon Loss:3.0864 x Lambda(0.1)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1402
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5559724
	speed: 0.0417s/iter; left time: 963.6864s
	iters: 200, epoch: 12 | loss: 0.5397136
	speed: 0.0386s/iter; left time: 889.2512s
Epoch: 12 cost time: 10.385748386383057
Epoch: 12, Steps: 261 Train Loss: 0.5446 (Forecasting Loss:0.2361 + XiCon Loss:3.0852 x Lambda(0.1)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1402
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0757233202457428, mae:0.21058246493339539, mape:0.1594337671995163, mspe:0.04219318926334381 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0753+-0.00220, MAE:0.2099+-0.00338, MAPE:0.1607+-0.00468, MSPE:0.0443+-0.00426, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2415
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4984019
	speed: 0.0364s/iter; left time: 963.6614s
	iters: 200, epoch: 1 | loss: 0.5071563
	speed: 0.0314s/iter; left time: 828.6608s
Epoch: 1 cost time: 8.907282829284668
Epoch: 1, Steps: 266 Train Loss: 0.5147 (Forecasting Loss:0.1849 + XiCon Loss:3.2984 x Lambda(0.1)), Vali MSE Loss: 0.1540 Test MSE Loss: 0.1366
Validation loss decreased (inf --> 0.153958).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4756008
	speed: 0.0327s/iter; left time: 857.5291s
	iters: 200, epoch: 2 | loss: 0.4796640
	speed: 0.0317s/iter; left time: 828.7490s
Epoch: 2 cost time: 8.590287446975708
Epoch: 2, Steps: 266 Train Loss: 0.4723 (Forecasting Loss:0.1585 + XiCon Loss:3.1383 x Lambda(0.1)), Vali MSE Loss: 0.1565 Test MSE Loss: 0.1326
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4497232
	speed: 0.0341s/iter; left time: 886.2008s
	iters: 200, epoch: 3 | loss: 0.4395154
	speed: 0.0319s/iter; left time: 825.9580s
Epoch: 3 cost time: 8.75300121307373
Epoch: 3, Steps: 266 Train Loss: 0.4576 (Forecasting Loss:0.1520 + XiCon Loss:3.0565 x Lambda(0.1)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.1309
Validation loss decreased (0.153958 --> 0.148504).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4339178
	speed: 0.0328s/iter; left time: 842.4769s
	iters: 200, epoch: 4 | loss: 0.4588821
	speed: 0.0316s/iter; left time: 808.2006s
Epoch: 4 cost time: 8.575404167175293
Epoch: 4, Steps: 266 Train Loss: 0.4528 (Forecasting Loss:0.1495 + XiCon Loss:3.0336 x Lambda(0.1)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.1285
Validation loss decreased (0.148504 --> 0.145917).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4682509
	speed: 0.0333s/iter; left time: 847.8655s
	iters: 200, epoch: 5 | loss: 0.4653359
	speed: 0.0318s/iter; left time: 805.8214s
Epoch: 5 cost time: 8.701168060302734
Epoch: 5, Steps: 266 Train Loss: 0.4502 (Forecasting Loss:0.1477 + XiCon Loss:3.0247 x Lambda(0.1)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.1268
Validation loss decreased (0.145917 --> 0.145884).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4451126
	speed: 0.0345s/iter; left time: 869.4396s
	iters: 200, epoch: 6 | loss: 0.4419276
	speed: 0.0320s/iter; left time: 801.2680s
Epoch: 6 cost time: 8.781464576721191
Epoch: 6, Steps: 266 Train Loss: 0.4492 (Forecasting Loss:0.1470 + XiCon Loss:3.0211 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1259
Validation loss decreased (0.145884 --> 0.144409).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4565355
	speed: 0.0342s/iter; left time: 851.1473s
	iters: 200, epoch: 7 | loss: 0.4519701
	speed: 0.0323s/iter; left time: 800.4202s
Epoch: 7 cost time: 8.697416067123413
Epoch: 7, Steps: 266 Train Loss: 0.4488 (Forecasting Loss:0.1468 + XiCon Loss:3.0207 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1255
Validation loss decreased (0.144409 --> 0.144193).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4446030
	speed: 0.0343s/iter; left time: 845.2823s
	iters: 200, epoch: 8 | loss: 0.4551518
	speed: 0.0319s/iter; left time: 783.9821s
Epoch: 8 cost time: 8.747734785079956
Epoch: 8, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1466 + XiCon Loss:3.0188 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1258
Validation loss decreased (0.144193 --> 0.143961).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4448231
	speed: 0.0338s/iter; left time: 823.0908s
	iters: 200, epoch: 9 | loss: 0.4480666
	speed: 0.0317s/iter; left time: 768.4187s
Epoch: 9 cost time: 8.67666244506836
Epoch: 9, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1464 + XiCon Loss:3.0212 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1260
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4588322
	speed: 0.0335s/iter; left time: 806.8440s
	iters: 200, epoch: 10 | loss: 0.4430785
	speed: 0.0319s/iter; left time: 765.8089s
Epoch: 10 cost time: 8.636411905288696
Epoch: 10, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1464 + XiCon Loss:3.0204 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1258
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4313416
	speed: 0.0337s/iter; left time: 802.9240s
	iters: 200, epoch: 11 | loss: 0.4681537
	speed: 0.0307s/iter; left time: 728.9256s
Epoch: 11 cost time: 8.479453802108765
Epoch: 11, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1464 + XiCon Loss:3.0200 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4703750
	speed: 0.0336s/iter; left time: 792.8915s
	iters: 200, epoch: 12 | loss: 0.4350017
	speed: 0.0318s/iter; left time: 746.1441s
Epoch: 12 cost time: 8.61623764038086
Epoch: 12, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1463 + XiCon Loss:3.0226 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4512224
	speed: 0.0329s/iter; left time: 767.7670s
	iters: 200, epoch: 13 | loss: 0.4211796
	speed: 0.0306s/iter; left time: 710.8093s
Epoch: 13 cost time: 8.413659811019897
Epoch: 13, Steps: 266 Train Loss: 0.4480 (Forecasting Loss:0.1463 + XiCon Loss:3.0170 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1257
Validation loss decreased (0.143961 --> 0.143783).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4296815
	speed: 0.0342s/iter; left time: 788.9664s
	iters: 200, epoch: 14 | loss: 0.4388206
	speed: 0.0324s/iter; left time: 743.3448s
Epoch: 14 cost time: 8.836796045303345
Epoch: 14, Steps: 266 Train Loss: 0.4482 (Forecasting Loss:0.1463 + XiCon Loss:3.0188 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4515009
	speed: 0.0342s/iter; left time: 779.7843s
	iters: 200, epoch: 15 | loss: 0.4404893
	speed: 0.0319s/iter; left time: 723.1309s
Epoch: 15 cost time: 8.711777448654175
Epoch: 15, Steps: 266 Train Loss: 0.4480 (Forecasting Loss:0.1463 + XiCon Loss:3.0176 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4414656
	speed: 0.0337s/iter; left time: 759.5563s
	iters: 200, epoch: 16 | loss: 0.4329339
	speed: 0.0314s/iter; left time: 702.7364s
Epoch: 16 cost time: 8.597424745559692
Epoch: 16, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1463 + XiCon Loss:3.0212 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4385710
	speed: 0.0323s/iter; left time: 717.4124s
	iters: 200, epoch: 17 | loss: 0.4302501
	speed: 0.0304s/iter; left time: 673.4951s
Epoch: 17 cost time: 8.31130838394165
Epoch: 17, Steps: 266 Train Loss: 0.4483 (Forecasting Loss:0.1462 + XiCon Loss:3.0203 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1257
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4345142
	speed: 0.0332s/iter; left time: 730.6045s
	iters: 200, epoch: 18 | loss: 0.4486156
	speed: 0.0301s/iter; left time: 658.8028s
Epoch: 18 cost time: 8.433396577835083
Epoch: 18, Steps: 266 Train Loss: 0.4482 (Forecasting Loss:0.1463 + XiCon Loss:3.0197 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1257
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4284499
	speed: 0.0333s/iter; left time: 722.7377s
	iters: 200, epoch: 19 | loss: 0.4227350
	speed: 0.0323s/iter; left time: 697.3080s
Epoch: 19 cost time: 8.664464950561523
Epoch: 19, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1463 + XiCon Loss:3.0207 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4494419
	speed: 0.0327s/iter; left time: 702.2531s
	iters: 200, epoch: 20 | loss: 0.4553122
	speed: 0.0313s/iter; left time: 668.9907s
Epoch: 20 cost time: 8.469650983810425
Epoch: 20, Steps: 266 Train Loss: 0.4483 (Forecasting Loss:0.1463 + XiCon Loss:3.0204 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1257
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4711837
	speed: 0.0346s/iter; left time: 733.1781s
	iters: 200, epoch: 21 | loss: 0.4561905
	speed: 0.0313s/iter; left time: 659.8586s
Epoch: 21 cost time: 8.709361553192139
Epoch: 21, Steps: 266 Train Loss: 0.4482 (Forecasting Loss:0.1463 + XiCon Loss:3.0194 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4540132
	speed: 0.0337s/iter; left time: 705.3511s
	iters: 200, epoch: 22 | loss: 0.4440198
	speed: 0.0310s/iter; left time: 645.1828s
Epoch: 22 cost time: 8.55552887916565
Epoch: 22, Steps: 266 Train Loss: 0.4483 (Forecasting Loss:0.1464 + XiCon Loss:3.0191 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1257
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4500299
	speed: 0.0338s/iter; left time: 696.9457s
	iters: 200, epoch: 23 | loss: 0.4435347
	speed: 0.0315s/iter; left time: 648.1027s
Epoch: 23 cost time: 8.567721366882324
Epoch: 23, Steps: 266 Train Loss: 0.4483 (Forecasting Loss:0.1463 + XiCon Loss:3.0204 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1257
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06606712192296982, mae:0.18530067801475525, mape:0.448996901512146, mspe:8.138273239135742 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2799
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4846040
	speed: 0.0336s/iter; left time: 889.2011s
	iters: 200, epoch: 1 | loss: 0.5019230
	speed: 0.0321s/iter; left time: 848.4002s
Epoch: 1 cost time: 8.621845006942749
Epoch: 1, Steps: 266 Train Loss: 0.5132 (Forecasting Loss:0.1834 + XiCon Loss:3.2976 x Lambda(0.1)), Vali MSE Loss: 0.1552 Test MSE Loss: 0.1347
Validation loss decreased (inf --> 0.155204).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4846894
	speed: 0.0339s/iter; left time: 889.3934s
	iters: 200, epoch: 2 | loss: 0.4771361
	speed: 0.0325s/iter; left time: 848.2020s
Epoch: 2 cost time: 8.679036855697632
Epoch: 2, Steps: 266 Train Loss: 0.4751 (Forecasting Loss:0.1576 + XiCon Loss:3.1754 x Lambda(0.1)), Vali MSE Loss: 0.1516 Test MSE Loss: 0.1365
Validation loss decreased (0.155204 --> 0.151602).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4311364
	speed: 0.0325s/iter; left time: 843.8126s
	iters: 200, epoch: 3 | loss: 0.4488506
	speed: 0.0307s/iter; left time: 793.8373s
Epoch: 3 cost time: 8.458785057067871
Epoch: 3, Steps: 266 Train Loss: 0.4600 (Forecasting Loss:0.1502 + XiCon Loss:3.0980 x Lambda(0.1)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.1300
Validation loss decreased (0.151602 --> 0.148047).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4451250
	speed: 0.0334s/iter; left time: 858.0855s
	iters: 200, epoch: 4 | loss: 0.4527941
	speed: 0.0313s/iter; left time: 801.7650s
Epoch: 4 cost time: 8.49941349029541
Epoch: 4, Steps: 266 Train Loss: 0.4532 (Forecasting Loss:0.1474 + XiCon Loss:3.0585 x Lambda(0.1)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.1277
Validation loss decreased (0.148047 --> 0.146403).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4341375
	speed: 0.0339s/iter; left time: 862.3464s
	iters: 200, epoch: 5 | loss: 0.4467697
	speed: 0.0320s/iter; left time: 811.9861s
Epoch: 5 cost time: 8.780101299285889
Epoch: 5, Steps: 266 Train Loss: 0.4485 (Forecasting Loss:0.1453 + XiCon Loss:3.0315 x Lambda(0.1)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1288
Validation loss decreased (0.146403 --> 0.144824).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4195991
	speed: 0.0344s/iter; left time: 866.8952s
	iters: 200, epoch: 6 | loss: 0.4424542
	speed: 0.0322s/iter; left time: 806.4721s
Epoch: 6 cost time: 8.74367380142212
Epoch: 6, Steps: 266 Train Loss: 0.4470 (Forecasting Loss:0.1441 + XiCon Loss:3.0289 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1272
Validation loss decreased (0.144824 --> 0.144539).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4476153
	speed: 0.0337s/iter; left time: 838.1230s
	iters: 200, epoch: 7 | loss: 0.4538898
	speed: 0.0316s/iter; left time: 783.3775s
Epoch: 7 cost time: 8.661638259887695
Epoch: 7, Steps: 266 Train Loss: 0.4460 (Forecasting Loss:0.1433 + XiCon Loss:3.0270 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1273
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4274802
	speed: 0.0336s/iter; left time: 826.8357s
	iters: 200, epoch: 8 | loss: 0.4404830
	speed: 0.0312s/iter; left time: 766.0891s
Epoch: 8 cost time: 8.487356424331665
Epoch: 8, Steps: 266 Train Loss: 0.4451 (Forecasting Loss:0.1426 + XiCon Loss:3.0250 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1275
Validation loss decreased (0.144539 --> 0.143997).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4367380
	speed: 0.0324s/iter; left time: 790.7859s
	iters: 200, epoch: 9 | loss: 0.4559259
	speed: 0.0301s/iter; left time: 731.4006s
Epoch: 9 cost time: 8.238848686218262
Epoch: 9, Steps: 266 Train Loss: 0.4451 (Forecasting Loss:0.1424 + XiCon Loss:3.0271 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1273
Validation loss decreased (0.143997 --> 0.143836).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4542218
	speed: 0.0326s/iter; left time: 785.8380s
	iters: 200, epoch: 10 | loss: 0.4329952
	speed: 0.0315s/iter; left time: 757.4089s
Epoch: 10 cost time: 8.584242820739746
Epoch: 10, Steps: 266 Train Loss: 0.4449 (Forecasting Loss:0.1423 + XiCon Loss:3.0257 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
Validation loss decreased (0.143836 --> 0.143820).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4454066
	speed: 0.0334s/iter; left time: 796.9894s
	iters: 200, epoch: 11 | loss: 0.4523114
	speed: 0.0322s/iter; left time: 763.7867s
Epoch: 11 cost time: 8.679270505905151
Epoch: 11, Steps: 266 Train Loss: 0.4449 (Forecasting Loss:0.1422 + XiCon Loss:3.0269 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4659930
	speed: 0.0348s/iter; left time: 820.4149s
	iters: 200, epoch: 12 | loss: 0.4451622
	speed: 0.0315s/iter; left time: 739.3400s
Epoch: 12 cost time: 8.784075498580933
Epoch: 12, Steps: 266 Train Loss: 0.4445 (Forecasting Loss:0.1420 + XiCon Loss:3.0249 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
Validation loss decreased (0.143820 --> 0.143777).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4334578
	speed: 0.0334s/iter; left time: 779.6580s
	iters: 200, epoch: 13 | loss: 0.4387797
	speed: 0.0316s/iter; left time: 733.5250s
Epoch: 13 cost time: 8.549674272537231
Epoch: 13, Steps: 266 Train Loss: 0.4443 (Forecasting Loss:0.1421 + XiCon Loss:3.0229 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4605404
	speed: 0.0333s/iter; left time: 767.1560s
	iters: 200, epoch: 14 | loss: 0.4556118
	speed: 0.0317s/iter; left time: 727.9338s
Epoch: 14 cost time: 8.602508544921875
Epoch: 14, Steps: 266 Train Loss: 0.4447 (Forecasting Loss:0.1422 + XiCon Loss:3.0254 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4517999
	speed: 0.0353s/iter; left time: 803.8005s
	iters: 200, epoch: 15 | loss: 0.4468530
	speed: 0.0327s/iter; left time: 741.2073s
Epoch: 15 cost time: 9.002225875854492
Epoch: 15, Steps: 266 Train Loss: 0.4448 (Forecasting Loss:0.1421 + XiCon Loss:3.0268 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4532071
	speed: 0.0334s/iter; left time: 751.9936s
	iters: 200, epoch: 16 | loss: 0.4528149
	speed: 0.0326s/iter; left time: 730.1093s
Epoch: 16 cost time: 8.79433536529541
Epoch: 16, Steps: 266 Train Loss: 0.4445 (Forecasting Loss:0.1419 + XiCon Loss:3.0256 x Lambda(0.1)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.1271
Validation loss decreased (0.143777 --> 0.143748).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4575948
	speed: 0.0336s/iter; left time: 747.4824s
	iters: 200, epoch: 17 | loss: 0.4648798
	speed: 0.0316s/iter; left time: 700.4740s
Epoch: 17 cost time: 8.649173259735107
Epoch: 17, Steps: 266 Train Loss: 0.4446 (Forecasting Loss:0.1421 + XiCon Loss:3.0246 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4397780
	speed: 0.0334s/iter; left time: 734.2360s
	iters: 200, epoch: 18 | loss: 0.4499505
	speed: 0.0312s/iter; left time: 681.9246s
Epoch: 18 cost time: 8.592453241348267
Epoch: 18, Steps: 266 Train Loss: 0.4446 (Forecasting Loss:0.1421 + XiCon Loss:3.0247 x Lambda(0.1)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.1271
Validation loss decreased (0.143748 --> 0.143694).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4574893
	speed: 0.0344s/iter; left time: 746.6581s
	iters: 200, epoch: 19 | loss: 0.4410787
	speed: 0.0326s/iter; left time: 705.2615s
Epoch: 19 cost time: 8.789550304412842
Epoch: 19, Steps: 266 Train Loss: 0.4445 (Forecasting Loss:0.1420 + XiCon Loss:3.0252 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4360093
	speed: 0.0341s/iter; left time: 731.0210s
	iters: 200, epoch: 20 | loss: 0.4355542
	speed: 0.0324s/iter; left time: 691.2594s
Epoch: 20 cost time: 8.79464602470398
Epoch: 20, Steps: 266 Train Loss: 0.4444 (Forecasting Loss:0.1420 + XiCon Loss:3.0238 x Lambda(0.1)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.1271
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4393612
	speed: 0.0345s/iter; left time: 731.1021s
	iters: 200, epoch: 21 | loss: 0.4686378
	speed: 0.0321s/iter; left time: 676.5964s
Epoch: 21 cost time: 8.786572217941284
Epoch: 21, Steps: 266 Train Loss: 0.4446 (Forecasting Loss:0.1420 + XiCon Loss:3.0263 x Lambda(0.1)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1271
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4510209
	speed: 0.0340s/iter; left time: 711.1599s
	iters: 200, epoch: 22 | loss: 0.4492289
	speed: 0.0319s/iter; left time: 664.3461s
Epoch: 22 cost time: 8.685366868972778
Epoch: 22, Steps: 266 Train Loss: 0.4445 (Forecasting Loss:0.1420 + XiCon Loss:3.0246 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1271
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4377973
	speed: 0.0332s/iter; left time: 686.2536s
	iters: 200, epoch: 23 | loss: 0.4453995
	speed: 0.0314s/iter; left time: 645.8606s
Epoch: 23 cost time: 8.52027940750122
Epoch: 23, Steps: 266 Train Loss: 0.4445 (Forecasting Loss:0.1420 + XiCon Loss:3.0246 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4631086
	speed: 0.0342s/iter; left time: 696.5153s
	iters: 200, epoch: 24 | loss: 0.4401508
	speed: 0.0331s/iter; left time: 671.0763s
Epoch: 24 cost time: 8.975215435028076
Epoch: 24, Steps: 266 Train Loss: 0.4444 (Forecasting Loss:0.1420 + XiCon Loss:3.0244 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4565250
	speed: 0.0344s/iter; left time: 691.4850s
	iters: 200, epoch: 25 | loss: 0.4529993
	speed: 0.0317s/iter; left time: 635.2962s
Epoch: 25 cost time: 8.799615859985352
Epoch: 25, Steps: 266 Train Loss: 0.4446 (Forecasting Loss:0.1420 + XiCon Loss:3.0256 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4439954
	speed: 0.0337s/iter; left time: 667.9951s
	iters: 200, epoch: 26 | loss: 0.4487699
	speed: 0.0319s/iter; left time: 629.6266s
Epoch: 26 cost time: 8.657829523086548
Epoch: 26, Steps: 266 Train Loss: 0.4447 (Forecasting Loss:0.1420 + XiCon Loss:3.0271 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4366412
	speed: 0.0328s/iter; left time: 642.8767s
	iters: 200, epoch: 27 | loss: 0.4366142
	speed: 0.0307s/iter; left time: 597.2399s
Epoch: 27 cost time: 8.429169654846191
Epoch: 27, Steps: 266 Train Loss: 0.4447 (Forecasting Loss:0.1421 + XiCon Loss:3.0255 x Lambda(0.1)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1271
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4267071
	speed: 0.0337s/iter; left time: 650.1056s
	iters: 200, epoch: 28 | loss: 0.4445135
	speed: 0.0307s/iter; left time: 590.8741s
Epoch: 28 cost time: 8.559017658233643
Epoch: 28, Steps: 266 Train Loss: 0.4444 (Forecasting Loss:0.1420 + XiCon Loss:3.0243 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06709656119346619, mae:0.18710707128047943, mape:0.4525495171546936, mspe:8.322208404541016 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8211
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4981960
	speed: 0.0329s/iter; left time: 870.7588s
	iters: 200, epoch: 1 | loss: 0.4957328
	speed: 0.0304s/iter; left time: 803.4494s
Epoch: 1 cost time: 8.39026951789856
Epoch: 1, Steps: 266 Train Loss: 0.5103 (Forecasting Loss:0.1794 + XiCon Loss:3.3089 x Lambda(0.1)), Vali MSE Loss: 0.1528 Test MSE Loss: 0.1340
Validation loss decreased (inf --> 0.152791).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4722428
	speed: 0.0329s/iter; left time: 861.8243s
	iters: 200, epoch: 2 | loss: 0.4544437
	speed: 0.0314s/iter; left time: 820.1786s
Epoch: 2 cost time: 8.40571928024292
Epoch: 2, Steps: 266 Train Loss: 0.4722 (Forecasting Loss:0.1578 + XiCon Loss:3.1441 x Lambda(0.1)), Vali MSE Loss: 0.1509 Test MSE Loss: 0.1314
Validation loss decreased (0.152791 --> 0.150895).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4391620
	speed: 0.0339s/iter; left time: 880.7627s
	iters: 200, epoch: 3 | loss: 0.4522759
	speed: 0.0329s/iter; left time: 851.8071s
Epoch: 3 cost time: 8.800538778305054
Epoch: 3, Steps: 266 Train Loss: 0.4571 (Forecasting Loss:0.1501 + XiCon Loss:3.0694 x Lambda(0.1)), Vali MSE Loss: 0.1488 Test MSE Loss: 0.1326
Validation loss decreased (0.150895 --> 0.148794).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4640117
	speed: 0.0337s/iter; left time: 866.1925s
	iters: 200, epoch: 4 | loss: 0.4567622
	speed: 0.0317s/iter; left time: 810.5999s
Epoch: 4 cost time: 8.606571674346924
Epoch: 4, Steps: 266 Train Loss: 0.4534 (Forecasting Loss:0.1480 + XiCon Loss:3.0546 x Lambda(0.1)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1257
Validation loss decreased (0.148794 --> 0.145617).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4371246
	speed: 0.0330s/iter; left time: 839.7117s
	iters: 200, epoch: 5 | loss: 0.4694715
	speed: 0.0311s/iter; left time: 787.5488s
Epoch: 5 cost time: 8.499725103378296
Epoch: 5, Steps: 266 Train Loss: 0.4510 (Forecasting Loss:0.1464 + XiCon Loss:3.0460 x Lambda(0.1)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.1256
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4300179
	speed: 0.0327s/iter; left time: 821.8652s
	iters: 200, epoch: 6 | loss: 0.4553187
	speed: 0.0311s/iter; left time: 780.6254s
Epoch: 6 cost time: 8.436537981033325
Epoch: 6, Steps: 266 Train Loss: 0.4498 (Forecasting Loss:0.1457 + XiCon Loss:3.0409 x Lambda(0.1)), Vali MSE Loss: 0.1452 Test MSE Loss: 0.1254
Validation loss decreased (0.145617 --> 0.145217).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4404114
	speed: 0.0326s/iter; left time: 812.0291s
	iters: 200, epoch: 7 | loss: 0.4429139
	speed: 0.0313s/iter; left time: 776.2678s
Epoch: 7 cost time: 8.48476767539978
Epoch: 7, Steps: 266 Train Loss: 0.4489 (Forecasting Loss:0.1451 + XiCon Loss:3.0371 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1251
Validation loss decreased (0.145217 --> 0.144444).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4472784
	speed: 0.0332s/iter; left time: 818.2239s
	iters: 200, epoch: 8 | loss: 0.4384767
	speed: 0.0314s/iter; left time: 770.6326s
Epoch: 8 cost time: 8.587015390396118
Epoch: 8, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1449 + XiCon Loss:3.0367 x Lambda(0.1)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1256
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4352591
	speed: 0.0339s/iter; left time: 825.4558s
	iters: 200, epoch: 9 | loss: 0.4598716
	speed: 0.0323s/iter; left time: 783.4800s
Epoch: 9 cost time: 8.717573881149292
Epoch: 9, Steps: 266 Train Loss: 0.4487 (Forecasting Loss:0.1448 + XiCon Loss:3.0390 x Lambda(0.1)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1254
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4733855
	speed: 0.0330s/iter; left time: 796.5141s
	iters: 200, epoch: 10 | loss: 0.4667721
	speed: 0.0318s/iter; left time: 762.3359s
Epoch: 10 cost time: 8.555691957473755
Epoch: 10, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1448 + XiCon Loss:3.0379 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1253
Validation loss decreased (0.144444 --> 0.144201).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4405918
	speed: 0.0331s/iter; left time: 788.6379s
	iters: 200, epoch: 11 | loss: 0.4309759
	speed: 0.0310s/iter; left time: 735.6683s
Epoch: 11 cost time: 8.465462923049927
Epoch: 11, Steps: 266 Train Loss: 0.4487 (Forecasting Loss:0.1448 + XiCon Loss:3.0389 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1254
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4496489
	speed: 0.0332s/iter; left time: 783.5681s
	iters: 200, epoch: 12 | loss: 0.4820362
	speed: 0.0296s/iter; left time: 694.6547s
Epoch: 12 cost time: 8.295663356781006
Epoch: 12, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1447 + XiCon Loss:3.0394 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4538715
	speed: 0.0330s/iter; left time: 768.3325s
	iters: 200, epoch: 13 | loss: 0.4415843
	speed: 0.0315s/iter; left time: 731.6565s
Epoch: 13 cost time: 8.512173175811768
Epoch: 13, Steps: 266 Train Loss: 0.4488 (Forecasting Loss:0.1448 + XiCon Loss:3.0398 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4480470
	speed: 0.0327s/iter; left time: 753.1148s
	iters: 200, epoch: 14 | loss: 0.4465467
	speed: 0.0316s/iter; left time: 725.4551s
Epoch: 14 cost time: 8.457690238952637
Epoch: 14, Steps: 266 Train Loss: 0.4486 (Forecasting Loss:0.1448 + XiCon Loss:3.0383 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4729745
	speed: 0.0327s/iter; left time: 744.2465s
	iters: 200, epoch: 15 | loss: 0.4652851
	speed: 0.0308s/iter; left time: 698.2848s
Epoch: 15 cost time: 8.40092945098877
Epoch: 15, Steps: 266 Train Loss: 0.4487 (Forecasting Loss:0.1448 + XiCon Loss:3.0393 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1253
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4134547
	speed: 0.0326s/iter; left time: 734.3402s
	iters: 200, epoch: 16 | loss: 0.4510303
	speed: 0.0315s/iter; left time: 706.8065s
Epoch: 16 cost time: 8.466839790344238
Epoch: 16, Steps: 266 Train Loss: 0.4485 (Forecasting Loss:0.1446 + XiCon Loss:3.0389 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1253
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4486489
	speed: 0.0330s/iter; left time: 733.6937s
	iters: 200, epoch: 17 | loss: 0.4603878
	speed: 0.0316s/iter; left time: 698.9311s
Epoch: 17 cost time: 8.651382207870483
Epoch: 17, Steps: 266 Train Loss: 0.4487 (Forecasting Loss:0.1447 + XiCon Loss:3.0392 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1253
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4439842
	speed: 0.0348s/iter; left time: 765.8965s
	iters: 200, epoch: 18 | loss: 0.4538041
	speed: 0.0328s/iter; left time: 716.6698s
Epoch: 18 cost time: 8.858880996704102
Epoch: 18, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1448 + XiCon Loss:3.0363 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1253
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4562948
	speed: 0.0344s/iter; left time: 746.7691s
	iters: 200, epoch: 19 | loss: 0.4321461
	speed: 0.0323s/iter; left time: 697.5621s
Epoch: 19 cost time: 8.778778314590454
Epoch: 19, Steps: 266 Train Loss: 0.4488 (Forecasting Loss:0.1447 + XiCon Loss:3.0412 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4403155
	speed: 0.0334s/iter; left time: 716.0179s
	iters: 200, epoch: 20 | loss: 0.4462292
	speed: 0.0319s/iter; left time: 681.7779s
Epoch: 20 cost time: 8.561857223510742
Epoch: 20, Steps: 266 Train Loss: 0.4484 (Forecasting Loss:0.1446 + XiCon Loss:3.0382 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1253
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06549877673387527, mae:0.18506981432437897, mape:0.4530456066131592, mspe:8.164196014404297 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2453
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4933736
	speed: 0.0340s/iter; left time: 901.7522s
	iters: 200, epoch: 1 | loss: 0.4751812
	speed: 0.0327s/iter; left time: 863.6425s
Epoch: 1 cost time: 8.766663312911987
Epoch: 1, Steps: 266 Train Loss: 0.5136 (Forecasting Loss:0.1844 + XiCon Loss:3.2922 x Lambda(0.1)), Vali MSE Loss: 0.1556 Test MSE Loss: 0.1377
Validation loss decreased (inf --> 0.155618).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.4975332
	speed: 0.0340s/iter; left time: 892.1916s
	iters: 200, epoch: 2 | loss: 0.4682742
	speed: 0.0319s/iter; left time: 833.2836s
Epoch: 2 cost time: 8.669073820114136
Epoch: 2, Steps: 266 Train Loss: 0.4767 (Forecasting Loss:0.1595 + XiCon Loss:3.1717 x Lambda(0.1)), Vali MSE Loss: 0.1617 Test MSE Loss: 0.1381
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4537338
	speed: 0.0333s/iter; left time: 863.7424s
	iters: 200, epoch: 3 | loss: 0.4586581
	speed: 0.0296s/iter; left time: 766.3400s
Epoch: 3 cost time: 8.364308595657349
Epoch: 3, Steps: 266 Train Loss: 0.4635 (Forecasting Loss:0.1523 + XiCon Loss:3.1125 x Lambda(0.1)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.1278
Validation loss decreased (0.155618 --> 0.148252).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4560933
	speed: 0.0328s/iter; left time: 843.5855s
	iters: 200, epoch: 4 | loss: 0.4391635
	speed: 0.0316s/iter; left time: 809.6909s
Epoch: 4 cost time: 8.458741903305054
Epoch: 4, Steps: 266 Train Loss: 0.4567 (Forecasting Loss:0.1495 + XiCon Loss:3.0718 x Lambda(0.1)), Vali MSE Loss: 0.1474 Test MSE Loss: 0.1272
Validation loss decreased (0.148252 --> 0.147450).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.4630095
	speed: 0.0333s/iter; left time: 845.8222s
	iters: 200, epoch: 5 | loss: 0.4600160
	speed: 0.0319s/iter; left time: 807.0029s
Epoch: 5 cost time: 8.635356426239014
Epoch: 5, Steps: 266 Train Loss: 0.4543 (Forecasting Loss:0.1481 + XiCon Loss:3.0619 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1251
Validation loss decreased (0.147450 --> 0.144198).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4762284
	speed: 0.0333s/iter; left time: 838.6736s
	iters: 200, epoch: 6 | loss: 0.4712246
	speed: 0.0308s/iter; left time: 772.0170s
Epoch: 6 cost time: 8.5022554397583
Epoch: 6, Steps: 266 Train Loss: 0.4532 (Forecasting Loss:0.1475 + XiCon Loss:3.0574 x Lambda(0.1)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4359651
	speed: 0.0340s/iter; left time: 847.0344s
	iters: 200, epoch: 7 | loss: 0.4563345
	speed: 0.0323s/iter; left time: 802.2548s
Epoch: 7 cost time: 8.743959903717041
Epoch: 7, Steps: 266 Train Loss: 0.4526 (Forecasting Loss:0.1471 + XiCon Loss:3.0554 x Lambda(0.1)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1248
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4639595
	speed: 0.0334s/iter; left time: 822.9802s
	iters: 200, epoch: 8 | loss: 0.4528629
	speed: 0.0311s/iter; left time: 762.4402s
Epoch: 8 cost time: 8.525288820266724
Epoch: 8, Steps: 266 Train Loss: 0.4523 (Forecasting Loss:0.1469 + XiCon Loss:3.0533 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4445953
	speed: 0.0330s/iter; left time: 804.4334s
	iters: 200, epoch: 9 | loss: 0.4578568
	speed: 0.0304s/iter; left time: 738.4702s
Epoch: 9 cost time: 8.386624097824097
Epoch: 9, Steps: 266 Train Loss: 0.4525 (Forecasting Loss:0.1470 + XiCon Loss:3.0552 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
Validation loss decreased (0.144198 --> 0.144104).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4439942
	speed: 0.0331s/iter; left time: 798.2679s
	iters: 200, epoch: 10 | loss: 0.4313799
	speed: 0.0324s/iter; left time: 778.1153s
Epoch: 10 cost time: 8.740461349487305
Epoch: 10, Steps: 266 Train Loss: 0.4524 (Forecasting Loss:0.1468 + XiCon Loss:3.0565 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4546792
	speed: 0.0329s/iter; left time: 784.2322s
	iters: 200, epoch: 11 | loss: 0.4526527
	speed: 0.0313s/iter; left time: 744.1411s
Epoch: 11 cost time: 8.568016290664673
Epoch: 11, Steps: 266 Train Loss: 0.4524 (Forecasting Loss:0.1468 + XiCon Loss:3.0561 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4667320
	speed: 0.0332s/iter; left time: 781.8377s
	iters: 200, epoch: 12 | loss: 0.4441129
	speed: 0.0312s/iter; left time: 732.7267s
Epoch: 12 cost time: 8.500597715377808
Epoch: 12, Steps: 266 Train Loss: 0.4523 (Forecasting Loss:0.1468 + XiCon Loss:3.0549 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4528148
	speed: 0.0333s/iter; left time: 777.2800s
	iters: 200, epoch: 13 | loss: 0.4668382
	speed: 0.0302s/iter; left time: 700.0841s
Epoch: 13 cost time: 8.401397943496704
Epoch: 13, Steps: 266 Train Loss: 0.4521 (Forecasting Loss:0.1467 + XiCon Loss:3.0541 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4565366
	speed: 0.0333s/iter; left time: 767.6037s
	iters: 200, epoch: 14 | loss: 0.4548982
	speed: 0.0314s/iter; left time: 720.0472s
Epoch: 14 cost time: 8.609764337539673
Epoch: 14, Steps: 266 Train Loss: 0.4524 (Forecasting Loss:0.1468 + XiCon Loss:3.0557 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
Validation loss decreased (0.144104 --> 0.144077).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4528266
	speed: 0.0337s/iter; left time: 768.1944s
	iters: 200, epoch: 15 | loss: 0.4353827
	speed: 0.0329s/iter; left time: 746.3108s
Epoch: 15 cost time: 8.806923627853394
Epoch: 15, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1468 + XiCon Loss:3.0539 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4541525
	speed: 0.0356s/iter; left time: 800.5748s
	iters: 200, epoch: 16 | loss: 0.4531845
	speed: 0.0325s/iter; left time: 729.3248s
Epoch: 16 cost time: 8.953880548477173
Epoch: 16, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1467 + XiCon Loss:3.0550 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4410617
	speed: 0.0335s/iter; left time: 745.1936s
	iters: 200, epoch: 17 | loss: 0.4432643
	speed: 0.0318s/iter; left time: 703.5221s
Epoch: 17 cost time: 8.672707080841064
Epoch: 17, Steps: 266 Train Loss: 0.4523 (Forecasting Loss:0.1468 + XiCon Loss:3.0558 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4482365
	speed: 0.0343s/iter; left time: 753.4857s
	iters: 200, epoch: 18 | loss: 0.4448500
	speed: 0.0320s/iter; left time: 700.1025s
Epoch: 18 cost time: 8.745161294937134
Epoch: 18, Steps: 266 Train Loss: 0.4523 (Forecasting Loss:0.1468 + XiCon Loss:3.0553 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.4730026
	speed: 0.0342s/iter; left time: 743.3399s
	iters: 200, epoch: 19 | loss: 0.4588801
	speed: 0.0299s/iter; left time: 646.6193s
Epoch: 19 cost time: 8.558879613876343
Epoch: 19, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1468 + XiCon Loss:3.0548 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
Validation loss decreased (0.144077 --> 0.144051).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.4413384
	speed: 0.0334s/iter; left time: 716.7710s
	iters: 200, epoch: 20 | loss: 0.4441119
	speed: 0.0308s/iter; left time: 657.5129s
Epoch: 20 cost time: 8.4254732131958
Epoch: 20, Steps: 266 Train Loss: 0.4525 (Forecasting Loss:0.1467 + XiCon Loss:3.0575 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
Validation loss decreased (0.144051 --> 0.144015).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.4659222
	speed: 0.0332s/iter; left time: 702.4657s
	iters: 200, epoch: 21 | loss: 0.4440062
	speed: 0.0307s/iter; left time: 646.2104s
Epoch: 21 cost time: 8.428185939788818
Epoch: 21, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1467 + XiCon Loss:3.0543 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.4411853
	speed: 0.0334s/iter; left time: 699.2955s
	iters: 200, epoch: 22 | loss: 0.4660112
	speed: 0.0313s/iter; left time: 651.9020s
Epoch: 22 cost time: 8.594796180725098
Epoch: 22, Steps: 266 Train Loss: 0.4521 (Forecasting Loss:0.1468 + XiCon Loss:3.0536 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
Validation loss decreased (0.144015 --> 0.143998).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.4415877
	speed: 0.0336s/iter; left time: 694.7781s
	iters: 200, epoch: 23 | loss: 0.4668523
	speed: 0.0305s/iter; left time: 626.1258s
Epoch: 23 cost time: 8.436369895935059
Epoch: 23, Steps: 266 Train Loss: 0.4519 (Forecasting Loss:0.1467 + XiCon Loss:3.0527 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.4285204
	speed: 0.0330s/iter; left time: 673.5310s
	iters: 200, epoch: 24 | loss: 0.4690924
	speed: 0.0316s/iter; left time: 640.9830s
Epoch: 24 cost time: 8.619028329849243
Epoch: 24, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1467 + XiCon Loss:3.0551 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.4479493
	speed: 0.0337s/iter; left time: 678.5447s
	iters: 200, epoch: 25 | loss: 0.4536702
	speed: 0.0313s/iter; left time: 627.1532s
Epoch: 25 cost time: 8.534384727478027
Epoch: 25, Steps: 266 Train Loss: 0.4524 (Forecasting Loss:0.1468 + XiCon Loss:3.0556 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.4601269
	speed: 0.0338s/iter; left time: 670.0432s
	iters: 200, epoch: 26 | loss: 0.4705758
	speed: 0.0311s/iter; left time: 614.6560s
Epoch: 26 cost time: 8.544192790985107
Epoch: 26, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1467 + XiCon Loss:3.0552 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.4406283
	speed: 0.0334s/iter; left time: 654.2994s
	iters: 200, epoch: 27 | loss: 0.4497283
	speed: 0.0311s/iter; left time: 605.1479s
Epoch: 27 cost time: 8.551059246063232
Epoch: 27, Steps: 266 Train Loss: 0.4521 (Forecasting Loss:0.1467 + XiCon Loss:3.0543 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.4385323
	speed: 0.0321s/iter; left time: 619.3803s
	iters: 200, epoch: 28 | loss: 0.4466343
	speed: 0.0308s/iter; left time: 592.5263s
Epoch: 28 cost time: 8.323086977005005
Epoch: 28, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1467 + XiCon Loss:3.0548 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.4531744
	speed: 0.0329s/iter; left time: 626.5950s
	iters: 200, epoch: 29 | loss: 0.4385212
	speed: 0.0326s/iter; left time: 617.1396s
Epoch: 29 cost time: 8.690234422683716
Epoch: 29, Steps: 266 Train Loss: 0.4523 (Forecasting Loss:0.1467 + XiCon Loss:3.0553 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.4550297
	speed: 0.0339s/iter; left time: 637.0738s
	iters: 200, epoch: 30 | loss: 0.4456160
	speed: 0.0312s/iter; left time: 583.1923s
Epoch: 30 cost time: 8.582841157913208
Epoch: 30, Steps: 266 Train Loss: 0.4522 (Forecasting Loss:0.1468 + XiCon Loss:3.0532 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.4538631
	speed: 0.0337s/iter; left time: 623.8083s
	iters: 200, epoch: 31 | loss: 0.4237103
	speed: 0.0320s/iter; left time: 589.9413s
Epoch: 31 cost time: 8.686618089675903
Epoch: 31, Steps: 266 Train Loss: 0.4521 (Forecasting Loss:0.1467 + XiCon Loss:3.0540 x Lambda(0.1)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.4371946
	speed: 0.0329s/iter; left time: 601.2618s
	iters: 200, epoch: 32 | loss: 0.4479439
	speed: 0.0313s/iter; left time: 568.7145s
Epoch: 32 cost time: 8.536248207092285
Epoch: 32, Steps: 266 Train Loss: 0.4526 (Forecasting Loss:0.1468 + XiCon Loss:3.0578 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06458879262208939, mae:0.18430300056934357, mape:0.4493674337863922, mspe:8.165396690368652 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6626
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.5009755
	speed: 0.0348s/iter; left time: 922.4275s
	iters: 200, epoch: 1 | loss: 0.4933703
	speed: 0.0309s/iter; left time: 815.2511s
Epoch: 1 cost time: 8.733399391174316
Epoch: 1, Steps: 266 Train Loss: 0.5188 (Forecasting Loss:0.1878 + XiCon Loss:3.3103 x Lambda(0.1)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1377
Validation loss decreased (inf --> 0.158517).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5036889
	speed: 0.0339s/iter; left time: 889.4630s
	iters: 200, epoch: 2 | loss: 0.4932507
	speed: 0.0316s/iter; left time: 826.2723s
Epoch: 2 cost time: 8.596723556518555
Epoch: 2, Steps: 266 Train Loss: 0.4765 (Forecasting Loss:0.1585 + XiCon Loss:3.1792 x Lambda(0.1)), Vali MSE Loss: 0.1500 Test MSE Loss: 0.1312
Validation loss decreased (0.158517 --> 0.150014).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.4667445
	speed: 0.0324s/iter; left time: 841.3487s
	iters: 200, epoch: 3 | loss: 0.4645306
	speed: 0.0317s/iter; left time: 819.6758s
Epoch: 3 cost time: 8.428969621658325
Epoch: 3, Steps: 266 Train Loss: 0.4629 (Forecasting Loss:0.1522 + XiCon Loss:3.1075 x Lambda(0.1)), Vali MSE Loss: 0.1478 Test MSE Loss: 0.1266
Validation loss decreased (0.150014 --> 0.147845).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.4716073
	speed: 0.0334s/iter; left time: 859.3490s
	iters: 200, epoch: 4 | loss: 0.4516921
	speed: 0.0318s/iter; left time: 813.1116s
Epoch: 4 cost time: 8.594284772872925
Epoch: 4, Steps: 266 Train Loss: 0.4584 (Forecasting Loss:0.1495 + XiCon Loss:3.0898 x Lambda(0.1)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.1265
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5012631
	speed: 0.0328s/iter; left time: 834.6641s
	iters: 200, epoch: 5 | loss: 0.4678238
	speed: 0.0319s/iter; left time: 808.7168s
Epoch: 5 cost time: 8.609585523605347
Epoch: 5, Steps: 266 Train Loss: 0.4561 (Forecasting Loss:0.1480 + XiCon Loss:3.0813 x Lambda(0.1)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.1249
Validation loss decreased (0.147845 --> 0.146505).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.4529605
	speed: 0.0328s/iter; left time: 826.3248s
	iters: 200, epoch: 6 | loss: 0.4473698
	speed: 0.0302s/iter; left time: 757.0988s
Epoch: 6 cost time: 8.39463996887207
Epoch: 6, Steps: 266 Train Loss: 0.4548 (Forecasting Loss:0.1476 + XiCon Loss:3.0719 x Lambda(0.1)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1250
Validation loss decreased (0.146505 --> 0.144056).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.4863078
	speed: 0.0328s/iter; left time: 816.0725s
	iters: 200, epoch: 7 | loss: 0.4516388
	speed: 0.0306s/iter; left time: 759.8135s
Epoch: 7 cost time: 8.380016326904297
Epoch: 7, Steps: 266 Train Loss: 0.4544 (Forecasting Loss:0.1472 + XiCon Loss:3.0722 x Lambda(0.1)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.4534524
	speed: 0.0325s/iter; left time: 801.4316s
	iters: 200, epoch: 8 | loss: 0.4689566
	speed: 0.0304s/iter; left time: 745.6341s
Epoch: 8 cost time: 8.328454732894897
Epoch: 8, Steps: 266 Train Loss: 0.4544 (Forecasting Loss:0.1471 + XiCon Loss:3.0731 x Lambda(0.1)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1246
Validation loss decreased (0.144056 --> 0.144020).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.4387341
	speed: 0.0327s/iter; left time: 797.3562s
	iters: 200, epoch: 9 | loss: 0.4597701
	speed: 0.0304s/iter; left time: 738.5325s
Epoch: 9 cost time: 8.354789972305298
Epoch: 9, Steps: 266 Train Loss: 0.4541 (Forecasting Loss:0.1470 + XiCon Loss:3.0712 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.4539237
	speed: 0.0327s/iter; left time: 789.3516s
	iters: 200, epoch: 10 | loss: 0.4507794
	speed: 0.0326s/iter; left time: 783.3789s
Epoch: 10 cost time: 8.74203634262085
Epoch: 10, Steps: 266 Train Loss: 0.4541 (Forecasting Loss:0.1469 + XiCon Loss:3.0720 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.4598492
	speed: 0.0334s/iter; left time: 796.3818s
	iters: 200, epoch: 11 | loss: 0.4686724
	speed: 0.0316s/iter; left time: 751.1963s
Epoch: 11 cost time: 8.58622932434082
Epoch: 11, Steps: 266 Train Loss: 0.4538 (Forecasting Loss:0.1469 + XiCon Loss:3.0698 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.4514779
	speed: 0.0335s/iter; left time: 790.8750s
	iters: 200, epoch: 12 | loss: 0.4471692
	speed: 0.0318s/iter; left time: 746.7657s
Epoch: 12 cost time: 8.582092046737671
Epoch: 12, Steps: 266 Train Loss: 0.4537 (Forecasting Loss:0.1469 + XiCon Loss:3.0678 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.4456111
	speed: 0.0380s/iter; left time: 886.3782s
	iters: 200, epoch: 13 | loss: 0.4533771
	speed: 0.0910s/iter; left time: 2112.3979s
Epoch: 13 cost time: 18.20849323272705
Epoch: 13, Steps: 266 Train Loss: 0.4534 (Forecasting Loss:0.1468 + XiCon Loss:3.0660 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.4542696
	speed: 0.1037s/iter; left time: 2389.5568s
	iters: 200, epoch: 14 | loss: 0.4630057
	speed: 0.0931s/iter; left time: 2135.1907s
Epoch: 14 cost time: 25.03586483001709
Epoch: 14, Steps: 266 Train Loss: 0.4538 (Forecasting Loss:0.1469 + XiCon Loss:3.0692 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.4662530
	speed: 0.0744s/iter; left time: 1693.6151s
	iters: 200, epoch: 15 | loss: 0.4672951
	speed: 0.0680s/iter; left time: 1541.1143s
Epoch: 15 cost time: 18.42578148841858
Epoch: 15, Steps: 266 Train Loss: 0.4536 (Forecasting Loss:0.1468 + XiCon Loss:3.0681 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.4422966
	speed: 0.0427s/iter; left time: 960.5225s
	iters: 200, epoch: 16 | loss: 0.4737597
	speed: 0.0386s/iter; left time: 865.4876s
Epoch: 16 cost time: 10.666573762893677
Epoch: 16, Steps: 266 Train Loss: 0.4538 (Forecasting Loss:0.1469 + XiCon Loss:3.0693 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.4488253
	speed: 0.0336s/iter; left time: 747.5388s
	iters: 200, epoch: 17 | loss: 0.4559206
	speed: 0.0309s/iter; left time: 685.3694s
Epoch: 17 cost time: 8.524252653121948
Epoch: 17, Steps: 266 Train Loss: 0.4539 (Forecasting Loss:0.1469 + XiCon Loss:3.0698 x Lambda(0.1)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.4438090
	speed: 0.0330s/iter; left time: 724.3044s
	iters: 200, epoch: 18 | loss: 0.4457754
	speed: 0.0299s/iter; left time: 654.0199s
Epoch: 18 cost time: 8.328996658325195
Epoch: 18, Steps: 266 Train Loss: 0.4540 (Forecasting Loss:0.1468 + XiCon Loss:3.0722 x Lambda(0.1)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06466006487607956, mae:0.18447881937026978, mape:0.4488671123981476, mspe:8.087926864624023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0656+-0.00130, MAE:0.1853+-0.00138, MAPE:0.4506+-0.00255, MSPE:8.1756+-0.10897, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9681
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.6888382
	speed: 0.0371s/iter; left time: 979.2840s
	iters: 200, epoch: 1 | loss: 0.6783187
	speed: 0.0301s/iter; left time: 790.9349s
Epoch: 1 cost time: 8.693259477615356
Epoch: 1, Steps: 265 Train Loss: 0.6759 (Forecasting Loss:0.3531 + XiCon Loss:3.2287 x Lambda(0.1)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.2775
Validation loss decreased (inf --> 0.336324).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5350304
	speed: 0.0297s/iter; left time: 776.8939s
	iters: 200, epoch: 2 | loss: 0.5633405
	speed: 0.0286s/iter; left time: 743.7173s
Epoch: 2 cost time: 7.836661338806152
Epoch: 2, Steps: 265 Train Loss: 0.5568 (Forecasting Loss:0.2383 + XiCon Loss:3.1844 x Lambda(0.1)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1735
Validation loss decreased (0.336324 --> 0.212279).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5045287
	speed: 0.0338s/iter; left time: 874.9059s
	iters: 200, epoch: 3 | loss: 0.5205643
	speed: 0.0307s/iter; left time: 790.4794s
Epoch: 3 cost time: 8.460939168930054
Epoch: 3, Steps: 265 Train Loss: 0.5247 (Forecasting Loss:0.2115 + XiCon Loss:3.1321 x Lambda(0.1)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1698
Validation loss decreased (0.212279 --> 0.208305).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4948025
	speed: 0.0339s/iter; left time: 867.0281s
	iters: 200, epoch: 4 | loss: 0.5199334
	speed: 0.0317s/iter; left time: 808.0734s
Epoch: 4 cost time: 8.601240634918213
Epoch: 4, Steps: 265 Train Loss: 0.5192 (Forecasting Loss:0.2083 + XiCon Loss:3.1092 x Lambda(0.1)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1685
Validation loss decreased (0.208305 --> 0.206777).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5220628
	speed: 0.0333s/iter; left time: 843.5497s
	iters: 200, epoch: 5 | loss: 0.5176458
	speed: 0.0319s/iter; left time: 804.0114s
Epoch: 5 cost time: 8.771406650543213
Epoch: 5, Steps: 265 Train Loss: 0.5166 (Forecasting Loss:0.2070 + XiCon Loss:3.0967 x Lambda(0.1)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1682
Validation loss decreased (0.206777 --> 0.206585).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5447462
	speed: 0.0344s/iter; left time: 861.5093s
	iters: 200, epoch: 6 | loss: 0.5018498
	speed: 0.0323s/iter; left time: 806.8267s
Epoch: 6 cost time: 8.725838899612427
Epoch: 6, Steps: 265 Train Loss: 0.5158 (Forecasting Loss:0.2063 + XiCon Loss:3.0943 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1679
Validation loss decreased (0.206585 --> 0.206488).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5081127
	speed: 0.0342s/iter; left time: 848.1840s
	iters: 200, epoch: 7 | loss: 0.5478245
	speed: 0.0316s/iter; left time: 781.7640s
Epoch: 7 cost time: 8.556909322738647
Epoch: 7, Steps: 265 Train Loss: 0.5155 (Forecasting Loss:0.2063 + XiCon Loss:3.0922 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5286858
	speed: 0.0342s/iter; left time: 840.1336s
	iters: 200, epoch: 8 | loss: 0.5515703
	speed: 0.0308s/iter; left time: 752.2153s
Epoch: 8 cost time: 8.644037008285522
Epoch: 8, Steps: 265 Train Loss: 0.5150 (Forecasting Loss:0.2060 + XiCon Loss:3.0901 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1678
Validation loss decreased (0.206488 --> 0.206417).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5190560
	speed: 0.0330s/iter; left time: 800.3304s
	iters: 200, epoch: 9 | loss: 0.4932218
	speed: 0.0312s/iter; left time: 753.2684s
Epoch: 9 cost time: 8.43695592880249
Epoch: 9, Steps: 265 Train Loss: 0.5150 (Forecasting Loss:0.2059 + XiCon Loss:3.0909 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5303822
	speed: 0.0334s/iter; left time: 801.5870s
	iters: 200, epoch: 10 | loss: 0.5050760
	speed: 0.0328s/iter; left time: 784.3817s
Epoch: 10 cost time: 8.754732608795166
Epoch: 10, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2059 + XiCon Loss:3.0873 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1678
Validation loss decreased (0.206417 --> 0.206257).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5168450
	speed: 0.0339s/iter; left time: 804.3312s
	iters: 200, epoch: 11 | loss: 0.4854234
	speed: 0.0321s/iter; left time: 758.3194s
Epoch: 11 cost time: 8.70421028137207
Epoch: 11, Steps: 265 Train Loss: 0.5150 (Forecasting Loss:0.2059 + XiCon Loss:3.0911 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5270516
	speed: 0.0335s/iter; left time: 786.7305s
	iters: 200, epoch: 12 | loss: 0.5048882
	speed: 0.0317s/iter; left time: 740.2223s
Epoch: 12 cost time: 8.59574031829834
Epoch: 12, Steps: 265 Train Loss: 0.5149 (Forecasting Loss:0.2059 + XiCon Loss:3.0900 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1677
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5278231
	speed: 0.0342s/iter; left time: 793.6679s
	iters: 200, epoch: 13 | loss: 0.4856792
	speed: 0.0310s/iter; left time: 717.4543s
Epoch: 13 cost time: 8.606658220291138
Epoch: 13, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2058 + XiCon Loss:3.0889 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1677
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5110210
	speed: 0.0338s/iter; left time: 774.7684s
	iters: 200, epoch: 14 | loss: 0.5100392
	speed: 0.0311s/iter; left time: 710.7378s
Epoch: 14 cost time: 8.538777589797974
Epoch: 14, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2059 + XiCon Loss:3.0886 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1677
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5454555
	speed: 0.0333s/iter; left time: 755.8631s
	iters: 200, epoch: 15 | loss: 0.4942811
	speed: 0.0319s/iter; left time: 719.9998s
Epoch: 15 cost time: 8.527055263519287
Epoch: 15, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2058 + XiCon Loss:3.0889 x Lambda(0.1)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1677
Validation loss decreased (0.206257 --> 0.206239).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5292051
	speed: 0.0332s/iter; left time: 744.1747s
	iters: 200, epoch: 16 | loss: 0.5233816
	speed: 0.0316s/iter; left time: 706.4187s
Epoch: 16 cost time: 8.499904155731201
Epoch: 16, Steps: 265 Train Loss: 0.5149 (Forecasting Loss:0.2059 + XiCon Loss:3.0907 x Lambda(0.1)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1677
Validation loss decreased (0.206239 --> 0.206184).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5339483
	speed: 0.0331s/iter; left time: 733.7651s
	iters: 200, epoch: 17 | loss: 0.5402112
	speed: 0.0317s/iter; left time: 698.6013s
Epoch: 17 cost time: 8.554211378097534
Epoch: 17, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2058 + XiCon Loss:3.0891 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1677
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5086812
	speed: 0.0339s/iter; left time: 743.0144s
	iters: 200, epoch: 18 | loss: 0.5373908
	speed: 0.0316s/iter; left time: 689.1390s
Epoch: 18 cost time: 8.561031818389893
Epoch: 18, Steps: 265 Train Loss: 0.5145 (Forecasting Loss:0.2057 + XiCon Loss:3.0877 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1677
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5057700
	speed: 0.0338s/iter; left time: 731.8451s
	iters: 200, epoch: 19 | loss: 0.5119606
	speed: 0.0323s/iter; left time: 694.7643s
Epoch: 19 cost time: 8.806777715682983
Epoch: 19, Steps: 265 Train Loss: 0.5146 (Forecasting Loss:0.2058 + XiCon Loss:3.0884 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1677
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.4848591
	speed: 0.0350s/iter; left time: 747.6365s
	iters: 200, epoch: 20 | loss: 0.5159774
	speed: 0.0318s/iter; left time: 676.2562s
Epoch: 20 cost time: 8.817453384399414
Epoch: 20, Steps: 265 Train Loss: 0.5146 (Forecasting Loss:0.2058 + XiCon Loss:3.0879 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1677
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5037096
	speed: 0.0330s/iter; left time: 696.0243s
	iters: 200, epoch: 21 | loss: 0.4919763
	speed: 0.0311s/iter; left time: 653.4581s
Epoch: 21 cost time: 8.461899518966675
Epoch: 21, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2058 + XiCon Loss:3.0890 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1677
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5192156
	speed: 0.0340s/iter; left time: 707.9975s
	iters: 200, epoch: 22 | loss: 0.5114032
	speed: 0.0312s/iter; left time: 646.9656s
Epoch: 22 cost time: 8.627065420150757
Epoch: 22, Steps: 265 Train Loss: 0.5145 (Forecasting Loss:0.2057 + XiCon Loss:3.0883 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1677
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5228747
	speed: 0.0333s/iter; left time: 685.6163s
	iters: 200, epoch: 23 | loss: 0.4976997
	speed: 0.0313s/iter; left time: 640.4100s
Epoch: 23 cost time: 8.464635610580444
Epoch: 23, Steps: 265 Train Loss: 0.5147 (Forecasting Loss:0.2059 + XiCon Loss:3.0886 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1677
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5245366
	speed: 0.0342s/iter; left time: 693.4941s
	iters: 200, epoch: 24 | loss: 0.5171424
	speed: 0.0327s/iter; left time: 660.2643s
Epoch: 24 cost time: 8.906516551971436
Epoch: 24, Steps: 265 Train Loss: 0.5148 (Forecasting Loss:0.2060 + XiCon Loss:3.0877 x Lambda(0.1)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1677
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5189190
	speed: 0.0335s/iter; left time: 671.4648s
	iters: 200, epoch: 25 | loss: 0.5081025
	speed: 0.0323s/iter; left time: 644.7436s
Epoch: 25 cost time: 8.662763118743896
Epoch: 25, Steps: 265 Train Loss: 0.5150 (Forecasting Loss:0.2059 + XiCon Loss:3.0913 x Lambda(0.1)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1677
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5261323
	speed: 0.0340s/iter; left time: 671.5419s
	iters: 200, epoch: 26 | loss: 0.5180678
	speed: 0.0314s/iter; left time: 618.0748s
Epoch: 26 cost time: 8.547809600830078
Epoch: 26, Steps: 265 Train Loss: 0.5148 (Forecasting Loss:0.2058 + XiCon Loss:3.0897 x Lambda(0.1)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1677
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09767207503318787, mae:0.23781895637512207, mape:0.5651686787605286, mspe:11.669036865234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.6498402
	speed: 0.0340s/iter; left time: 897.4007s
	iters: 200, epoch: 1 | loss: 0.6951419
	speed: 0.0327s/iter; left time: 860.7966s
Epoch: 1 cost time: 8.845528364181519
Epoch: 1, Steps: 265 Train Loss: 0.6850 (Forecasting Loss:0.3607 + XiCon Loss:3.2436 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.2829
Validation loss decreased (inf --> 0.335469).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5437151
	speed: 0.0344s/iter; left time: 899.8669s
	iters: 200, epoch: 2 | loss: 0.5528608
	speed: 0.0315s/iter; left time: 821.0137s
Epoch: 2 cost time: 8.652060747146606
Epoch: 2, Steps: 265 Train Loss: 0.5581 (Forecasting Loss:0.2384 + XiCon Loss:3.1969 x Lambda(0.1)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1716
Validation loss decreased (0.335469 --> 0.215560).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5209562
	speed: 0.0337s/iter; left time: 871.7693s
	iters: 200, epoch: 3 | loss: 0.5033942
	speed: 0.0318s/iter; left time: 819.2091s
Epoch: 3 cost time: 8.590650796890259
Epoch: 3, Steps: 265 Train Loss: 0.5221 (Forecasting Loss:0.2105 + XiCon Loss:3.1155 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1683
Validation loss decreased (0.215560 --> 0.211546).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5066926
	speed: 0.0335s/iter; left time: 858.3179s
	iters: 200, epoch: 4 | loss: 0.5123515
	speed: 0.0310s/iter; left time: 789.4148s
Epoch: 4 cost time: 8.52029013633728
Epoch: 4, Steps: 265 Train Loss: 0.5155 (Forecasting Loss:0.2071 + XiCon Loss:3.0838 x Lambda(0.1)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1673
Validation loss decreased (0.211546 --> 0.209822).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5049794
	speed: 0.0337s/iter; left time: 853.7967s
	iters: 200, epoch: 5 | loss: 0.5160646
	speed: 0.0319s/iter; left time: 804.5440s
Epoch: 5 cost time: 8.547006845474243
Epoch: 5, Steps: 265 Train Loss: 0.5128 (Forecasting Loss:0.2058 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1669
Validation loss decreased (0.209822 --> 0.208870).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5329026
	speed: 0.0339s/iter; left time: 850.7791s
	iters: 200, epoch: 6 | loss: 0.5015650
	speed: 0.0340s/iter; left time: 849.7006s
Epoch: 6 cost time: 8.971405982971191
Epoch: 6, Steps: 265 Train Loss: 0.5118 (Forecasting Loss:0.2052 + XiCon Loss:3.0658 x Lambda(0.1)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1666
Validation loss decreased (0.208870 --> 0.208488).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5063069
	speed: 0.0346s/iter; left time: 859.2286s
	iters: 200, epoch: 7 | loss: 0.5111054
	speed: 0.0326s/iter; left time: 806.3994s
Epoch: 7 cost time: 8.80754566192627
Epoch: 7, Steps: 265 Train Loss: 0.5114 (Forecasting Loss:0.2050 + XiCon Loss:3.0640 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1665
Validation loss decreased (0.208488 --> 0.208128).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5398917
	speed: 0.0350s/iter; left time: 858.5217s
	iters: 200, epoch: 8 | loss: 0.5182227
	speed: 0.0320s/iter; left time: 782.2458s
Epoch: 8 cost time: 8.734287738800049
Epoch: 8, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2047 + XiCon Loss:3.0620 x Lambda(0.1)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5082996
	speed: 0.0339s/iter; left time: 822.3296s
	iters: 200, epoch: 9 | loss: 0.5019506
	speed: 0.0308s/iter; left time: 744.5106s
Epoch: 9 cost time: 8.566580772399902
Epoch: 9, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2047 + XiCon Loss:3.0623 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5062425
	speed: 0.0338s/iter; left time: 810.5805s
	iters: 200, epoch: 10 | loss: 0.5017488
	speed: 0.0314s/iter; left time: 750.2729s
Epoch: 10 cost time: 8.550707817077637
Epoch: 10, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2047 + XiCon Loss:3.0617 x Lambda(0.1)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1665
Validation loss decreased (0.208128 --> 0.207875).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.4831993
	speed: 0.0340s/iter; left time: 807.3410s
	iters: 200, epoch: 11 | loss: 0.4917628
	speed: 0.0320s/iter; left time: 757.8691s
Epoch: 11 cost time: 8.678491353988647
Epoch: 11, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2046 + XiCon Loss:3.0629 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.4988227
	speed: 0.0347s/iter; left time: 814.2102s
	iters: 200, epoch: 12 | loss: 0.4932216
	speed: 0.0322s/iter; left time: 753.6216s
Epoch: 12 cost time: 8.704971313476562
Epoch: 12, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2047 + XiCon Loss:3.0608 x Lambda(0.1)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1665
Validation loss decreased (0.207875 --> 0.207818).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5202579
	speed: 0.0341s/iter; left time: 791.0837s
	iters: 200, epoch: 13 | loss: 0.5155406
	speed: 0.0316s/iter; left time: 729.6499s
Epoch: 13 cost time: 8.604939222335815
Epoch: 13, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2047 + XiCon Loss:3.0620 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5079374
	speed: 0.0347s/iter; left time: 797.6799s
	iters: 200, epoch: 14 | loss: 0.5051850
	speed: 0.0321s/iter; left time: 733.4963s
Epoch: 14 cost time: 8.783279418945312
Epoch: 14, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2046 + XiCon Loss:3.0628 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5286651
	speed: 0.0339s/iter; left time: 769.1502s
	iters: 200, epoch: 15 | loss: 0.5119836
	speed: 0.0323s/iter; left time: 729.1033s
Epoch: 15 cost time: 8.735581636428833
Epoch: 15, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2047 + XiCon Loss:3.0615 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.4978002
	speed: 0.0338s/iter; left time: 756.9999s
	iters: 200, epoch: 16 | loss: 0.5068789
	speed: 0.0315s/iter; left time: 702.5743s
Epoch: 16 cost time: 8.543238162994385
Epoch: 16, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2046 + XiCon Loss:3.0605 x Lambda(0.1)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1665
Validation loss decreased (0.207818 --> 0.207798).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.4980364
	speed: 0.0333s/iter; left time: 736.9019s
	iters: 200, epoch: 17 | loss: 0.5236531
	speed: 0.0318s/iter; left time: 701.8147s
Epoch: 17 cost time: 8.524951934814453
Epoch: 17, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2047 + XiCon Loss:3.0629 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5231563
	speed: 0.0338s/iter; left time: 740.2661s
	iters: 200, epoch: 18 | loss: 0.4999209
	speed: 0.0313s/iter; left time: 682.2936s
Epoch: 18 cost time: 8.57793402671814
Epoch: 18, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2046 + XiCon Loss:3.0601 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5103066
	speed: 0.0346s/iter; left time: 748.5933s
	iters: 200, epoch: 19 | loss: 0.5084037
	speed: 0.0314s/iter; left time: 676.0180s
Epoch: 19 cost time: 8.669461011886597
Epoch: 19, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2047 + XiCon Loss:3.0612 x Lambda(0.1)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5329273
	speed: 0.0345s/iter; left time: 736.6238s
	iters: 200, epoch: 20 | loss: 0.4839923
	speed: 0.0331s/iter; left time: 703.4136s
Epoch: 20 cost time: 8.98809266090393
Epoch: 20, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2045 + XiCon Loss:3.0621 x Lambda(0.1)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1665
Validation loss decreased (0.207798 --> 0.207738).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.4979450
	speed: 0.0334s/iter; left time: 705.7674s
	iters: 200, epoch: 21 | loss: 0.5082101
	speed: 0.0322s/iter; left time: 676.7355s
Epoch: 21 cost time: 8.626686811447144
Epoch: 21, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2047 + XiCon Loss:3.0618 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5476632
	speed: 0.0342s/iter; left time: 712.5617s
	iters: 200, epoch: 22 | loss: 0.5087752
	speed: 0.0313s/iter; left time: 649.9876s
Epoch: 22 cost time: 8.67253041267395
Epoch: 22, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2047 + XiCon Loss:3.0621 x Lambda(0.1)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5296836
	speed: 0.0344s/iter; left time: 708.6196s
	iters: 200, epoch: 23 | loss: 0.5263006
	speed: 0.0320s/iter; left time: 654.7394s
Epoch: 23 cost time: 8.660635948181152
Epoch: 23, Steps: 265 Train Loss: 0.5105 (Forecasting Loss:0.2045 + XiCon Loss:3.0600 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1665
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5267898
	speed: 0.0341s/iter; left time: 692.5073s
	iters: 200, epoch: 24 | loss: 0.4996389
	speed: 0.0322s/iter; left time: 650.9277s
Epoch: 24 cost time: 8.696068048477173
Epoch: 24, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2047 + XiCon Loss:3.0631 x Lambda(0.1)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1665
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5318512
	speed: 0.0345s/iter; left time: 690.4348s
	iters: 200, epoch: 25 | loss: 0.5222992
	speed: 0.0324s/iter; left time: 646.4658s
Epoch: 25 cost time: 8.803815841674805
Epoch: 25, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2045 + XiCon Loss:3.0617 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5063210
	speed: 0.0336s/iter; left time: 664.7259s
	iters: 200, epoch: 26 | loss: 0.4999398
	speed: 0.0315s/iter; left time: 619.1768s
Epoch: 26 cost time: 8.483455181121826
Epoch: 26, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2047 + XiCon Loss:3.0630 x Lambda(0.1)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1665
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5204993
	speed: 0.0344s/iter; left time: 670.4109s
	iters: 200, epoch: 27 | loss: 0.4964414
	speed: 0.0303s/iter; left time: 588.0869s
Epoch: 27 cost time: 8.524446487426758
Epoch: 27, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2046 + XiCon Loss:3.0629 x Lambda(0.1)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1665
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5137584
	speed: 0.0344s/iter; left time: 662.3153s
	iters: 200, epoch: 28 | loss: 0.5104432
	speed: 0.0324s/iter; left time: 619.6897s
Epoch: 28 cost time: 8.764321565628052
Epoch: 28, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2046 + XiCon Loss:3.0608 x Lambda(0.1)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1665
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4990888
	speed: 0.0338s/iter; left time: 640.7681s
	iters: 200, epoch: 29 | loss: 0.5111523
	speed: 0.0318s/iter; left time: 599.6983s
Epoch: 29 cost time: 8.597368001937866
Epoch: 29, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2047 + XiCon Loss:3.0591 x Lambda(0.1)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1665
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.4978005
	speed: 0.0352s/iter; left time: 659.5198s
	iters: 200, epoch: 30 | loss: 0.5098191
	speed: 0.0322s/iter; left time: 599.2719s
Epoch: 30 cost time: 8.898425340652466
Epoch: 30, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2044 + XiCon Loss:3.0623 x Lambda(0.1)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09653156995773315, mae:0.23637603223323822, mape:0.5688217878341675, mspe:12.007782936096191 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2518
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.6446762
	speed: 0.0333s/iter; left time: 878.8413s
	iters: 200, epoch: 1 | loss: 0.6204381
	speed: 0.0324s/iter; left time: 851.0716s
Epoch: 1 cost time: 8.665851831436157
Epoch: 1, Steps: 265 Train Loss: 0.6694 (Forecasting Loss:0.3468 + XiCon Loss:3.2261 x Lambda(0.1)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2713
Validation loss decreased (inf --> 0.324920).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5255798
	speed: 0.0352s/iter; left time: 920.2921s
	iters: 200, epoch: 2 | loss: 0.5239785
	speed: 0.0335s/iter; left time: 871.0107s
Epoch: 2 cost time: 8.948802947998047
Epoch: 2, Steps: 265 Train Loss: 0.5542 (Forecasting Loss:0.2367 + XiCon Loss:3.1742 x Lambda(0.1)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1719
Validation loss decreased (0.324920 --> 0.216861).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5368578
	speed: 0.0337s/iter; left time: 873.0995s
	iters: 200, epoch: 3 | loss: 0.5134623
	speed: 0.0318s/iter; left time: 820.1633s
Epoch: 3 cost time: 8.556899547576904
Epoch: 3, Steps: 265 Train Loss: 0.5170 (Forecasting Loss:0.2093 + XiCon Loss:3.0768 x Lambda(0.1)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1712
Validation loss decreased (0.216861 --> 0.211890).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5084463
	speed: 0.0345s/iter; left time: 882.2928s
	iters: 200, epoch: 4 | loss: 0.5010409
	speed: 0.0317s/iter; left time: 809.6599s
Epoch: 4 cost time: 8.71456241607666
Epoch: 4, Steps: 265 Train Loss: 0.5104 (Forecasting Loss:0.2043 + XiCon Loss:3.0605 x Lambda(0.1)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1715
Validation loss decreased (0.211890 --> 0.209650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4984714
	speed: 0.0335s/iter; left time: 850.0230s
	iters: 200, epoch: 5 | loss: 0.5084150
	speed: 0.0317s/iter; left time: 800.9866s
Epoch: 5 cost time: 8.616366624832153
Epoch: 5, Steps: 265 Train Loss: 0.5081 (Forecasting Loss:0.2026 + XiCon Loss:3.0548 x Lambda(0.1)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1719
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5356635
	speed: 0.0333s/iter; left time: 834.3822s
	iters: 200, epoch: 6 | loss: 0.5228914
	speed: 0.0326s/iter; left time: 813.6046s
Epoch: 6 cost time: 8.653829336166382
Epoch: 6, Steps: 265 Train Loss: 0.5069 (Forecasting Loss:0.2018 + XiCon Loss:3.0506 x Lambda(0.1)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1719
Validation loss decreased (0.209650 --> 0.209234).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5300537
	speed: 0.0338s/iter; left time: 839.6548s
	iters: 200, epoch: 7 | loss: 0.5068047
	speed: 0.0321s/iter; left time: 793.7813s
Epoch: 7 cost time: 8.688895463943481
Epoch: 7, Steps: 265 Train Loss: 0.5066 (Forecasting Loss:0.2015 + XiCon Loss:3.0513 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1719
Validation loss decreased (0.209234 --> 0.209029).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5049245
	speed: 0.0343s/iter; left time: 841.0574s
	iters: 200, epoch: 8 | loss: 0.5057058
	speed: 0.0311s/iter; left time: 761.0906s
Epoch: 8 cost time: 8.58185601234436
Epoch: 8, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2012 + XiCon Loss:3.0501 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1719
Validation loss decreased (0.209029 --> 0.209013).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5135188
	speed: 0.0337s/iter; left time: 818.9390s
	iters: 200, epoch: 9 | loss: 0.5070356
	speed: 0.0314s/iter; left time: 760.1643s
Epoch: 9 cost time: 8.630592107772827
Epoch: 9, Steps: 265 Train Loss: 0.5063 (Forecasting Loss:0.2012 + XiCon Loss:3.0505 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1719
Validation loss decreased (0.209013 --> 0.208960).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.4920796
	speed: 0.0347s/iter; left time: 833.2672s
	iters: 200, epoch: 10 | loss: 0.4959601
	speed: 0.0316s/iter; left time: 755.8996s
Epoch: 10 cost time: 8.700088262557983
Epoch: 10, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2013 + XiCon Loss:3.0493 x Lambda(0.1)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1719
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5179493
	speed: 0.0339s/iter; left time: 804.7359s
	iters: 200, epoch: 11 | loss: 0.5106470
	speed: 0.0326s/iter; left time: 770.7997s
Epoch: 11 cost time: 8.822578430175781
Epoch: 11, Steps: 265 Train Loss: 0.5060 (Forecasting Loss:0.2011 + XiCon Loss:3.0491 x Lambda(0.1)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1719
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.4943223
	speed: 0.0354s/iter; left time: 832.0155s
	iters: 200, epoch: 12 | loss: 0.5049608
	speed: 0.0323s/iter; left time: 755.0528s
Epoch: 12 cost time: 8.995452404022217
Epoch: 12, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.2012 + XiCon Loss:3.0489 x Lambda(0.1)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1719
Validation loss decreased (0.208960 --> 0.208815).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.4974232
	speed: 0.0350s/iter; left time: 812.6851s
	iters: 200, epoch: 13 | loss: 0.5023850
	speed: 0.0314s/iter; left time: 726.0647s
Epoch: 13 cost time: 8.706623315811157
Epoch: 13, Steps: 265 Train Loss: 0.5061 (Forecasting Loss:0.2012 + XiCon Loss:3.0496 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1719
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4786275
	speed: 0.0345s/iter; left time: 791.7133s
	iters: 200, epoch: 14 | loss: 0.4855879
	speed: 0.0326s/iter; left time: 744.9978s
Epoch: 14 cost time: 8.813190221786499
Epoch: 14, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2012 + XiCon Loss:3.0494 x Lambda(0.1)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1719
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5067956
	speed: 0.0328s/iter; left time: 743.2324s
	iters: 200, epoch: 15 | loss: 0.4939751
	speed: 0.0322s/iter; left time: 727.0275s
Epoch: 15 cost time: 8.47673487663269
Epoch: 15, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2011 + XiCon Loss:3.0509 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5072160
	speed: 0.0342s/iter; left time: 766.1740s
	iters: 200, epoch: 16 | loss: 0.4963028
	speed: 0.0330s/iter; left time: 735.9884s
Epoch: 16 cost time: 8.902418851852417
Epoch: 16, Steps: 265 Train Loss: 0.5059 (Forecasting Loss:0.2010 + XiCon Loss:3.0496 x Lambda(0.1)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1719
Validation loss decreased (0.208815 --> 0.208509).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5002160
	speed: 0.0347s/iter; left time: 769.4323s
	iters: 200, epoch: 17 | loss: 0.4979561
	speed: 0.0319s/iter; left time: 703.6042s
Epoch: 17 cost time: 8.753029108047485
Epoch: 17, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2011 + XiCon Loss:3.0507 x Lambda(0.1)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1719
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.4872797
	speed: 0.0350s/iter; left time: 765.9066s
	iters: 200, epoch: 18 | loss: 0.4995306
	speed: 0.0317s/iter; left time: 690.2500s
Epoch: 18 cost time: 8.7496657371521
Epoch: 18, Steps: 265 Train Loss: 0.5060 (Forecasting Loss:0.2011 + XiCon Loss:3.0492 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5206505
	speed: 0.0335s/iter; left time: 723.7272s
	iters: 200, epoch: 19 | loss: 0.5168201
	speed: 0.0321s/iter; left time: 691.4606s
Epoch: 19 cost time: 8.59246826171875
Epoch: 19, Steps: 265 Train Loss: 0.5064 (Forecasting Loss:0.2011 + XiCon Loss:3.0524 x Lambda(0.1)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1719
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.4949004
	speed: 0.0346s/iter; left time: 738.8550s
	iters: 200, epoch: 20 | loss: 0.4985831
	speed: 0.0318s/iter; left time: 675.7426s
Epoch: 20 cost time: 8.797909498214722
Epoch: 20, Steps: 265 Train Loss: 0.5060 (Forecasting Loss:0.2011 + XiCon Loss:3.0498 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5081407
	speed: 0.0337s/iter; left time: 710.2161s
	iters: 200, epoch: 21 | loss: 0.5120153
	speed: 0.0327s/iter; left time: 687.1445s
Epoch: 21 cost time: 8.77104640007019
Epoch: 21, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2012 + XiCon Loss:3.0498 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5017562
	speed: 0.0352s/iter; left time: 733.0519s
	iters: 200, epoch: 22 | loss: 0.5012909
	speed: 0.0321s/iter; left time: 665.4505s
Epoch: 22 cost time: 8.822343587875366
Epoch: 22, Steps: 265 Train Loss: 0.5063 (Forecasting Loss:0.2013 + XiCon Loss:3.0506 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.4921854
	speed: 0.0339s/iter; left time: 696.6506s
	iters: 200, epoch: 23 | loss: 0.4749555
	speed: 0.0321s/iter; left time: 656.5963s
Epoch: 23 cost time: 8.629197835922241
Epoch: 23, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2012 + XiCon Loss:3.0499 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4979006
	speed: 0.0341s/iter; left time: 691.9943s
	iters: 200, epoch: 24 | loss: 0.4939498
	speed: 0.0325s/iter; left time: 656.2052s
Epoch: 24 cost time: 8.779057264328003
Epoch: 24, Steps: 265 Train Loss: 0.5065 (Forecasting Loss:0.2013 + XiCon Loss:3.0518 x Lambda(0.1)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1719
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5029353
	speed: 0.0345s/iter; left time: 691.2649s
	iters: 200, epoch: 25 | loss: 0.5186707
	speed: 0.0329s/iter; left time: 656.8151s
Epoch: 25 cost time: 8.928889036178589
Epoch: 25, Steps: 265 Train Loss: 0.5062 (Forecasting Loss:0.2012 + XiCon Loss:3.0498 x Lambda(0.1)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1719
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.4888718
	speed: 0.0344s/iter; left time: 679.8647s
	iters: 200, epoch: 26 | loss: 0.4893603
	speed: 0.0319s/iter; left time: 626.8461s
Epoch: 26 cost time: 8.664952993392944
Epoch: 26, Steps: 265 Train Loss: 0.5063 (Forecasting Loss:0.2012 + XiCon Loss:3.0503 x Lambda(0.1)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1719
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10144864767789841, mae:0.2423492968082428, mape:0.58427494764328, mspe:12.56319522857666 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5610
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.6820379
	speed: 0.0332s/iter; left time: 877.6537s
	iters: 200, epoch: 1 | loss: 0.6638182
	speed: 0.0316s/iter; left time: 830.8803s
Epoch: 1 cost time: 8.614087343215942
Epoch: 1, Steps: 265 Train Loss: 0.6849 (Forecasting Loss:0.3611 + XiCon Loss:3.2381 x Lambda(0.1)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2836
Validation loss decreased (inf --> 0.331472).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5409640
	speed: 0.0352s/iter; left time: 920.0104s
	iters: 200, epoch: 2 | loss: 0.5122359
	speed: 0.0324s/iter; left time: 843.0853s
Epoch: 2 cost time: 8.868454694747925
Epoch: 2, Steps: 265 Train Loss: 0.5540 (Forecasting Loss:0.2351 + XiCon Loss:3.1884 x Lambda(0.1)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1739
Validation loss decreased (0.331472 --> 0.217741).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5042979
	speed: 0.0345s/iter; left time: 892.8259s
	iters: 200, epoch: 3 | loss: 0.5304435
	speed: 0.0320s/iter; left time: 825.7953s
Epoch: 3 cost time: 8.781330585479736
Epoch: 3, Steps: 265 Train Loss: 0.5203 (Forecasting Loss:0.2081 + XiCon Loss:3.1212 x Lambda(0.1)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1703
Validation loss decreased (0.217741 --> 0.213817).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5162317
	speed: 0.0334s/iter; left time: 856.0267s
	iters: 200, epoch: 4 | loss: 0.4867826
	speed: 0.0317s/iter; left time: 808.8255s
Epoch: 4 cost time: 8.69068193435669
Epoch: 4, Steps: 265 Train Loss: 0.5146 (Forecasting Loss:0.2059 + XiCon Loss:3.0875 x Lambda(0.1)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1698
Validation loss decreased (0.213817 --> 0.212564).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5220584
	speed: 0.0338s/iter; left time: 856.1502s
	iters: 200, epoch: 5 | loss: 0.5192437
	speed: 0.0315s/iter; left time: 794.2207s
Epoch: 5 cost time: 8.6715567111969
Epoch: 5, Steps: 265 Train Loss: 0.5127 (Forecasting Loss:0.2048 + XiCon Loss:3.0789 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1694
Validation loss decreased (0.212564 --> 0.211442).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5101181
	speed: 0.0346s/iter; left time: 867.5442s
	iters: 200, epoch: 6 | loss: 0.5123418
	speed: 0.0336s/iter; left time: 839.2030s
Epoch: 6 cost time: 8.96222472190857
Epoch: 6, Steps: 265 Train Loss: 0.5117 (Forecasting Loss:0.2043 + XiCon Loss:3.0739 x Lambda(0.1)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5142418
	speed: 0.0341s/iter; left time: 846.6947s
	iters: 200, epoch: 7 | loss: 0.5093549
	speed: 0.0330s/iter; left time: 815.9833s
Epoch: 7 cost time: 8.79302453994751
Epoch: 7, Steps: 265 Train Loss: 0.5111 (Forecasting Loss:0.2039 + XiCon Loss:3.0725 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
Validation loss decreased (0.211442 --> 0.211286).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4971487
	speed: 0.0338s/iter; left time: 829.6870s
	iters: 200, epoch: 8 | loss: 0.5255147
	speed: 0.0320s/iter; left time: 781.3474s
Epoch: 8 cost time: 8.678979635238647
Epoch: 8, Steps: 265 Train Loss: 0.5112 (Forecasting Loss:0.2040 + XiCon Loss:3.0713 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.4998413
	speed: 0.0343s/iter; left time: 833.3464s
	iters: 200, epoch: 9 | loss: 0.5126638
	speed: 0.0318s/iter; left time: 768.9471s
Epoch: 9 cost time: 8.668125629425049
Epoch: 9, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2037 + XiCon Loss:3.0717 x Lambda(0.1)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5337763
	speed: 0.0347s/iter; left time: 832.7729s
	iters: 200, epoch: 10 | loss: 0.4844555
	speed: 0.0313s/iter; left time: 748.0758s
Epoch: 10 cost time: 8.666003465652466
Epoch: 10, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2037 + XiCon Loss:3.0719 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5127584
	speed: 0.0355s/iter; left time: 842.4311s
	iters: 200, epoch: 11 | loss: 0.5088636
	speed: 0.0343s/iter; left time: 810.8752s
Epoch: 11 cost time: 9.174257516860962
Epoch: 11, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0706 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5147755
	speed: 0.0344s/iter; left time: 808.0890s
	iters: 200, epoch: 12 | loss: 0.5323883
	speed: 0.0324s/iter; left time: 757.2698s
Epoch: 12 cost time: 8.717378377914429
Epoch: 12, Steps: 265 Train Loss: 0.5112 (Forecasting Loss:0.2039 + XiCon Loss:3.0729 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5240631
	speed: 0.0336s/iter; left time: 779.4680s
	iters: 200, epoch: 13 | loss: 0.5247896
	speed: 0.0315s/iter; left time: 727.6124s
Epoch: 13 cost time: 8.584065437316895
Epoch: 13, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2037 + XiCon Loss:3.0698 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5031378
	speed: 0.0336s/iter; left time: 771.6000s
	iters: 200, epoch: 14 | loss: 0.4906235
	speed: 0.0314s/iter; left time: 716.7119s
Epoch: 14 cost time: 8.53104543685913
Epoch: 14, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2036 + XiCon Loss:3.0700 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5242810
	speed: 0.0339s/iter; left time: 768.1699s
	iters: 200, epoch: 15 | loss: 0.4916513
	speed: 0.0316s/iter; left time: 714.6844s
Epoch: 15 cost time: 8.605273246765137
Epoch: 15, Steps: 265 Train Loss: 0.5105 (Forecasting Loss:0.2036 + XiCon Loss:3.0686 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5294954
	speed: 0.0352s/iter; left time: 789.3793s
	iters: 200, epoch: 16 | loss: 0.5042293
	speed: 0.0326s/iter; left time: 728.6711s
Epoch: 16 cost time: 8.874767303466797
Epoch: 16, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2036 + XiCon Loss:3.0718 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5311506
	speed: 0.0333s/iter; left time: 737.1399s
	iters: 200, epoch: 17 | loss: 0.4880383
	speed: 0.0316s/iter; left time: 697.7093s
Epoch: 17 cost time: 8.582886219024658
Epoch: 17, Steps: 265 Train Loss: 0.5105 (Forecasting Loss:0.2037 + XiCon Loss:3.0680 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
Validation loss decreased (0.211286 --> 0.211253).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5124185
	speed: 0.0338s/iter; left time: 740.5606s
	iters: 200, epoch: 18 | loss: 0.5215193
	speed: 0.0316s/iter; left time: 688.8309s
Epoch: 18 cost time: 8.590104103088379
Epoch: 18, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2038 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5086243
	speed: 0.0342s/iter; left time: 740.0591s
	iters: 200, epoch: 19 | loss: 0.5033010
	speed: 0.0319s/iter; left time: 686.8087s
Epoch: 19 cost time: 8.6641206741333
Epoch: 19, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2037 + XiCon Loss:3.0689 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.4837065
	speed: 0.0336s/iter; left time: 717.3446s
	iters: 200, epoch: 20 | loss: 0.5252448
	speed: 0.0333s/iter; left time: 708.4601s
Epoch: 20 cost time: 8.828701496124268
Epoch: 20, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2039 + XiCon Loss:3.0711 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5208802
	speed: 0.0339s/iter; left time: 714.8136s
	iters: 200, epoch: 21 | loss: 0.5094351
	speed: 0.0312s/iter; left time: 656.1868s
Epoch: 21 cost time: 8.661011934280396
Epoch: 21, Steps: 265 Train Loss: 0.5111 (Forecasting Loss:0.2040 + XiCon Loss:3.0710 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.4904929
	speed: 0.0339s/iter; left time: 706.1571s
	iters: 200, epoch: 22 | loss: 0.4952521
	speed: 0.0312s/iter; left time: 647.2431s
Epoch: 22 cost time: 8.549687623977661
Epoch: 22, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2038 + XiCon Loss:3.0717 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5001705
	speed: 0.0334s/iter; left time: 686.1448s
	iters: 200, epoch: 23 | loss: 0.5320364
	speed: 0.0310s/iter; left time: 635.3595s
Epoch: 23 cost time: 8.499789953231812
Epoch: 23, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2037 + XiCon Loss:3.0703 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
Validation loss decreased (0.211253 --> 0.211228).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5085053
	speed: 0.0341s/iter; left time: 692.9089s
	iters: 200, epoch: 24 | loss: 0.5206909
	speed: 0.0321s/iter; left time: 648.1978s
Epoch: 24 cost time: 8.633158206939697
Epoch: 24, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2038 + XiCon Loss:3.0712 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5391220
	speed: 0.0342s/iter; left time: 685.8336s
	iters: 200, epoch: 25 | loss: 0.5329577
	speed: 0.0336s/iter; left time: 669.0341s
Epoch: 25 cost time: 8.922198295593262
Epoch: 25, Steps: 265 Train Loss: 0.5112 (Forecasting Loss:0.2039 + XiCon Loss:3.0731 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.4931684
	speed: 0.0347s/iter; left time: 685.5825s
	iters: 200, epoch: 26 | loss: 0.5064874
	speed: 0.0328s/iter; left time: 644.6382s
Epoch: 26 cost time: 8.854573488235474
Epoch: 26, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0709 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5012076
	speed: 0.0348s/iter; left time: 678.1769s
	iters: 200, epoch: 27 | loss: 0.5437534
	speed: 0.0329s/iter; left time: 637.8808s
Epoch: 27 cost time: 8.856030464172363
Epoch: 27, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2038 + XiCon Loss:3.0719 x Lambda(0.1)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.4972973
	speed: 0.0333s/iter; left time: 641.1072s
	iters: 200, epoch: 28 | loss: 0.5238479
	speed: 0.0317s/iter; left time: 606.8991s
Epoch: 28 cost time: 8.53465223312378
Epoch: 28, Steps: 265 Train Loss: 0.5109 (Forecasting Loss:0.2039 + XiCon Loss:3.0705 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4912102
	speed: 0.0341s/iter; left time: 647.1644s
	iters: 200, epoch: 29 | loss: 0.5105109
	speed: 0.0317s/iter; left time: 597.7607s
Epoch: 29 cost time: 8.631027698516846
Epoch: 29, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0710 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5137983
	speed: 0.0336s/iter; left time: 629.3337s
	iters: 200, epoch: 30 | loss: 0.5218321
	speed: 0.0312s/iter; left time: 580.4010s
Epoch: 30 cost time: 8.563766241073608
Epoch: 30, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2037 + XiCon Loss:3.0725 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5184165
	speed: 0.0334s/iter; left time: 616.1375s
	iters: 200, epoch: 31 | loss: 0.5395806
	speed: 0.0312s/iter; left time: 573.2722s
Epoch: 31 cost time: 8.57686448097229
Epoch: 31, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0711 x Lambda(0.1)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1692
Validation loss decreased (0.211228 --> 0.211130).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5221418
	speed: 0.0341s/iter; left time: 619.3091s
	iters: 200, epoch: 32 | loss: 0.4941387
	speed: 0.0318s/iter; left time: 575.9574s
Epoch: 32 cost time: 8.690699815750122
Epoch: 32, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2037 + XiCon Loss:3.0694 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5204952
	speed: 0.0338s/iter; left time: 605.3322s
	iters: 200, epoch: 33 | loss: 0.5146472
	speed: 0.0321s/iter; left time: 571.5496s
Epoch: 33 cost time: 8.619688272476196
Epoch: 33, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2037 + XiCon Loss:3.0701 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5467276
	speed: 0.0338s/iter; left time: 596.4597s
	iters: 200, epoch: 34 | loss: 0.5226963
	speed: 0.0335s/iter; left time: 587.4410s
Epoch: 34 cost time: 8.933166027069092
Epoch: 34, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0710 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5268927
	speed: 0.0341s/iter; left time: 593.2283s
	iters: 200, epoch: 35 | loss: 0.5538734
	speed: 0.0317s/iter; left time: 547.4478s
Epoch: 35 cost time: 8.642423868179321
Epoch: 35, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2038 + XiCon Loss:3.0721 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.4766792
	speed: 0.0335s/iter; left time: 574.4932s
	iters: 200, epoch: 36 | loss: 0.5185134
	speed: 0.0310s/iter; left time: 527.1177s
Epoch: 36 cost time: 8.485499858856201
Epoch: 36, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2038 + XiCon Loss:3.0699 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5112846
	speed: 0.0341s/iter; left time: 574.4518s
	iters: 200, epoch: 37 | loss: 0.5027183
	speed: 0.0315s/iter; left time: 528.1124s
Epoch: 37 cost time: 8.608896732330322
Epoch: 37, Steps: 265 Train Loss: 0.5106 (Forecasting Loss:0.2036 + XiCon Loss:3.0694 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.4929326
	speed: 0.0338s/iter; left time: 560.3849s
	iters: 200, epoch: 38 | loss: 0.5329362
	speed: 0.0322s/iter; left time: 531.0881s
Epoch: 38 cost time: 8.658568382263184
Epoch: 38, Steps: 265 Train Loss: 0.5107 (Forecasting Loss:0.2037 + XiCon Loss:3.0693 x Lambda(0.1)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5080669
	speed: 0.0348s/iter; left time: 568.3146s
	iters: 200, epoch: 39 | loss: 0.4859097
	speed: 0.0333s/iter; left time: 541.0145s
Epoch: 39 cost time: 9.039560317993164
Epoch: 39, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0714 x Lambda(0.1)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1692
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.5191765
	speed: 0.0345s/iter; left time: 554.6348s
	iters: 200, epoch: 40 | loss: 0.4987804
	speed: 0.0316s/iter; left time: 504.6759s
Epoch: 40 cost time: 8.681519031524658
Epoch: 40, Steps: 265 Train Loss: 0.5110 (Forecasting Loss:0.2038 + XiCon Loss:3.0719 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.4971939
	speed: 0.0339s/iter; left time: 535.7498s
	iters: 200, epoch: 41 | loss: 0.5302876
	speed: 0.0329s/iter; left time: 516.3194s
Epoch: 41 cost time: 8.776017904281616
Epoch: 41, Steps: 265 Train Loss: 0.5108 (Forecasting Loss:0.2037 + XiCon Loss:3.0703 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09918833523988724, mae:0.23924320936203003, mape:0.5832945108413696, mspe:12.480539321899414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5868
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.7108828
	speed: 0.0367s/iter; left time: 967.6291s
	iters: 200, epoch: 1 | loss: 0.6314622
	speed: 0.0337s/iter; left time: 885.6383s
Epoch: 1 cost time: 9.171383380889893
Epoch: 1, Steps: 265 Train Loss: 0.6708 (Forecasting Loss:0.3468 + XiCon Loss:3.2397 x Lambda(0.1)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2725
Validation loss decreased (inf --> 0.327831).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5702693
	speed: 0.0345s/iter; left time: 902.9664s
	iters: 200, epoch: 2 | loss: 0.5238160
	speed: 0.0317s/iter; left time: 825.4441s
Epoch: 2 cost time: 8.78019380569458
Epoch: 2, Steps: 265 Train Loss: 0.5584 (Forecasting Loss:0.2382 + XiCon Loss:3.2027 x Lambda(0.1)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1724
Validation loss decreased (0.327831 --> 0.214110).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5221726
	speed: 0.0346s/iter; left time: 895.7005s
	iters: 200, epoch: 3 | loss: 0.5288589
	speed: 0.0323s/iter; left time: 833.3931s
Epoch: 3 cost time: 8.757080078125
Epoch: 3, Steps: 265 Train Loss: 0.5240 (Forecasting Loss:0.2099 + XiCon Loss:3.1415 x Lambda(0.1)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1690
Validation loss decreased (0.214110 --> 0.210843).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5141826
	speed: 0.0337s/iter; left time: 864.0842s
	iters: 200, epoch: 4 | loss: 0.5377584
	speed: 0.0306s/iter; left time: 781.3678s
Epoch: 4 cost time: 8.54129147529602
Epoch: 4, Steps: 265 Train Loss: 0.5168 (Forecasting Loss:0.2059 + XiCon Loss:3.1084 x Lambda(0.1)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1684
Validation loss decreased (0.210843 --> 0.209891).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5114086
	speed: 0.0337s/iter; left time: 853.3594s
	iters: 200, epoch: 5 | loss: 0.5212258
	speed: 0.0317s/iter; left time: 800.7922s
Epoch: 5 cost time: 8.72502088546753
Epoch: 5, Steps: 265 Train Loss: 0.5146 (Forecasting Loss:0.2047 + XiCon Loss:3.0990 x Lambda(0.1)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1685
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5008484
	speed: 0.0346s/iter; left time: 868.7670s
	iters: 200, epoch: 6 | loss: 0.5255735
	speed: 0.0322s/iter; left time: 804.0985s
Epoch: 6 cost time: 8.755082607269287
Epoch: 6, Steps: 265 Train Loss: 0.5135 (Forecasting Loss:0.2041 + XiCon Loss:3.0942 x Lambda(0.1)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1682
Validation loss decreased (0.209891 --> 0.209468).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5032786
	speed: 0.0341s/iter; left time: 847.0198s
	iters: 200, epoch: 7 | loss: 0.4839505
	speed: 0.0323s/iter; left time: 799.2456s
Epoch: 7 cost time: 8.750401020050049
Epoch: 7, Steps: 265 Train Loss: 0.5127 (Forecasting Loss:0.2036 + XiCon Loss:3.0906 x Lambda(0.1)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1681
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5349197
	speed: 0.0341s/iter; left time: 836.1757s
	iters: 200, epoch: 8 | loss: 0.5168349
	speed: 0.0315s/iter; left time: 769.1381s
Epoch: 8 cost time: 8.572827577590942
Epoch: 8, Steps: 265 Train Loss: 0.5127 (Forecasting Loss:0.2036 + XiCon Loss:3.0917 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
Validation loss decreased (0.209468 --> 0.209324).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5074601
	speed: 0.0336s/iter; left time: 816.9519s
	iters: 200, epoch: 9 | loss: 0.4963627
	speed: 0.0319s/iter; left time: 772.5600s
Epoch: 9 cost time: 8.625030279159546
Epoch: 9, Steps: 265 Train Loss: 0.5129 (Forecasting Loss:0.2036 + XiCon Loss:3.0924 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
Validation loss decreased (0.209324 --> 0.209306).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5256725
	speed: 0.0346s/iter; left time: 829.8412s
	iters: 200, epoch: 10 | loss: 0.5254421
	speed: 0.0327s/iter; left time: 783.0533s
Epoch: 10 cost time: 8.946779251098633
Epoch: 10, Steps: 265 Train Loss: 0.5129 (Forecasting Loss:0.2037 + XiCon Loss:3.0927 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
Validation loss decreased (0.209306 --> 0.209268).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5197866
	speed: 0.0336s/iter; left time: 799.1380s
	iters: 200, epoch: 11 | loss: 0.5138682
	speed: 0.0316s/iter; left time: 746.9398s
Epoch: 11 cost time: 8.574992418289185
Epoch: 11, Steps: 265 Train Loss: 0.5125 (Forecasting Loss:0.2034 + XiCon Loss:3.0908 x Lambda(0.1)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1680
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5127158
	speed: 0.0332s/iter; left time: 779.1580s
	iters: 200, epoch: 12 | loss: 0.5182404
	speed: 0.0316s/iter; left time: 737.9672s
Epoch: 12 cost time: 8.569645404815674
Epoch: 12, Steps: 265 Train Loss: 0.5130 (Forecasting Loss:0.2036 + XiCon Loss:3.0936 x Lambda(0.1)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1680
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5204489
	speed: 0.0348s/iter; left time: 806.9588s
	iters: 200, epoch: 13 | loss: 0.4953963
	speed: 0.0313s/iter; left time: 723.6706s
Epoch: 13 cost time: 8.701815366744995
Epoch: 13, Steps: 265 Train Loss: 0.5127 (Forecasting Loss:0.2035 + XiCon Loss:3.0925 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5120195
	speed: 0.0336s/iter; left time: 771.7075s
	iters: 200, epoch: 14 | loss: 0.5030837
	speed: 0.0319s/iter; left time: 728.4142s
Epoch: 14 cost time: 8.514325618743896
Epoch: 14, Steps: 265 Train Loss: 0.5126 (Forecasting Loss:0.2035 + XiCon Loss:3.0911 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5246851
	speed: 0.0344s/iter; left time: 779.6417s
	iters: 200, epoch: 15 | loss: 0.5285791
	speed: 0.0323s/iter; left time: 730.6024s
Epoch: 15 cost time: 8.778425455093384
Epoch: 15, Steps: 265 Train Loss: 0.5124 (Forecasting Loss:0.2035 + XiCon Loss:3.0891 x Lambda(0.1)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1680
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5033900
	speed: 0.0333s/iter; left time: 747.0997s
	iters: 200, epoch: 16 | loss: 0.5023403
	speed: 0.0323s/iter; left time: 720.7084s
Epoch: 16 cost time: 8.643471002578735
Epoch: 16, Steps: 265 Train Loss: 0.5127 (Forecasting Loss:0.2035 + XiCon Loss:3.0921 x Lambda(0.1)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1680
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5437374
	speed: 0.0333s/iter; left time: 739.0675s
	iters: 200, epoch: 17 | loss: 0.5180458
	speed: 0.0315s/iter; left time: 694.7988s
Epoch: 17 cost time: 8.61317229270935
Epoch: 17, Steps: 265 Train Loss: 0.5124 (Forecasting Loss:0.2034 + XiCon Loss:3.0905 x Lambda(0.1)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1680
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5547701
	speed: 0.0338s/iter; left time: 739.8018s
	iters: 200, epoch: 18 | loss: 0.4837833
	speed: 0.0323s/iter; left time: 704.1258s
Epoch: 18 cost time: 8.730737209320068
Epoch: 18, Steps: 265 Train Loss: 0.5125 (Forecasting Loss:0.2034 + XiCon Loss:3.0907 x Lambda(0.1)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1680
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.4880806
	speed: 0.0334s/iter; left time: 722.2551s
	iters: 200, epoch: 19 | loss: 0.5426979
	speed: 0.0319s/iter; left time: 685.8351s
Epoch: 19 cost time: 8.574338436126709
Epoch: 19, Steps: 265 Train Loss: 0.5128 (Forecasting Loss:0.2035 + XiCon Loss:3.0929 x Lambda(0.1)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1680
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.4721536
	speed: 0.0345s/iter; left time: 737.3060s
	iters: 200, epoch: 20 | loss: 0.5014591
	speed: 0.0325s/iter; left time: 691.1020s
Epoch: 20 cost time: 8.825011968612671
Epoch: 20, Steps: 265 Train Loss: 0.5126 (Forecasting Loss:0.2036 + XiCon Loss:3.0901 x Lambda(0.1)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09822296351194382, mae:0.23776988685131073, mape:0.5806733965873718, mspe:12.69386100769043 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0986+-0.00230, MAE:0.2387+-0.00282, MAPE:0.5764+-0.01096, MSPE:12.2829+-0.53371, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0595
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6786368
	speed: 0.0402s/iter; left time: 1058.1479s
	iters: 200, epoch: 1 | loss: 0.6193885
	speed: 0.0341s/iter; left time: 894.5388s
Epoch: 1 cost time: 9.64514422416687
Epoch: 1, Steps: 264 Train Loss: 0.6573 (Forecasting Loss:0.3354 + XiCon Loss:3.2187 x Lambda(0.1)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.295674).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5479201
	speed: 0.0359s/iter; left time: 935.3346s
	iters: 200, epoch: 2 | loss: 0.5510268
	speed: 0.0341s/iter; left time: 885.3551s
Epoch: 2 cost time: 9.25318455696106
Epoch: 2, Steps: 264 Train Loss: 0.5568 (Forecasting Loss:0.2513 + XiCon Loss:3.0543 x Lambda(0.1)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1963
Validation loss decreased (0.295674 --> 0.249735).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5367326
	speed: 0.0370s/iter; left time: 952.4495s
	iters: 200, epoch: 3 | loss: 0.5098149
	speed: 0.0334s/iter; left time: 856.7945s
Epoch: 3 cost time: 9.271679162979126
Epoch: 3, Steps: 264 Train Loss: 0.5388 (Forecasting Loss:0.2397 + XiCon Loss:2.9906 x Lambda(0.1)), Vali MSE Loss: 0.2574 Test MSE Loss: 0.2006
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.4988635
	speed: 0.0360s/iter; left time: 918.9429s
	iters: 200, epoch: 4 | loss: 0.5355431
	speed: 0.0353s/iter; left time: 896.3646s
Epoch: 4 cost time: 9.340370178222656
Epoch: 4, Steps: 264 Train Loss: 0.5345 (Forecasting Loss:0.2359 + XiCon Loss:2.9856 x Lambda(0.1)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1993
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5024942
	speed: 0.0366s/iter; left time: 925.2111s
	iters: 200, epoch: 5 | loss: 0.5189719
	speed: 0.0353s/iter; left time: 887.1569s
Epoch: 5 cost time: 9.467459917068481
Epoch: 5, Steps: 264 Train Loss: 0.5328 (Forecasting Loss:0.2342 + XiCon Loss:2.9860 x Lambda(0.1)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.2001
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5371524
	speed: 0.0367s/iter; left time: 917.3856s
	iters: 200, epoch: 6 | loss: 0.5222626
	speed: 0.0336s/iter; left time: 836.1121s
Epoch: 6 cost time: 9.24121356010437
Epoch: 6, Steps: 264 Train Loss: 0.5317 (Forecasting Loss:0.2334 + XiCon Loss:2.9829 x Lambda(0.1)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.2013
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.4994140
	speed: 0.0368s/iter; left time: 909.2574s
	iters: 200, epoch: 7 | loss: 0.5445431
	speed: 0.0355s/iter; left time: 873.4131s
Epoch: 7 cost time: 9.506798267364502
Epoch: 7, Steps: 264 Train Loss: 0.5310 (Forecasting Loss:0.2329 + XiCon Loss:2.9808 x Lambda(0.1)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.2010
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5397884
	speed: 0.0361s/iter; left time: 883.6786s
	iters: 200, epoch: 8 | loss: 0.5327476
	speed: 0.0347s/iter; left time: 845.5375s
Epoch: 8 cost time: 9.321274042129517
Epoch: 8, Steps: 264 Train Loss: 0.5309 (Forecasting Loss:0.2327 + XiCon Loss:2.9826 x Lambda(0.1)), Vali MSE Loss: 0.2553 Test MSE Loss: 0.2012
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5160086
	speed: 0.0374s/iter; left time: 904.6301s
	iters: 200, epoch: 9 | loss: 0.5426050
	speed: 0.0338s/iter; left time: 814.8711s
Epoch: 9 cost time: 9.398932695388794
Epoch: 9, Steps: 264 Train Loss: 0.5310 (Forecasting Loss:0.2326 + XiCon Loss:2.9832 x Lambda(0.1)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.2012
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5585006
	speed: 0.0362s/iter; left time: 866.5045s
	iters: 200, epoch: 10 | loss: 0.5159503
	speed: 0.0350s/iter; left time: 832.8575s
Epoch: 10 cost time: 9.315780639648438
Epoch: 10, Steps: 264 Train Loss: 0.5309 (Forecasting Loss:0.2326 + XiCon Loss:2.9830 x Lambda(0.1)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.2013
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5220206
	speed: 0.0359s/iter; left time: 848.8168s
	iters: 200, epoch: 11 | loss: 0.5445443
	speed: 0.0352s/iter; left time: 830.0135s
Epoch: 11 cost time: 9.329694032669067
Epoch: 11, Steps: 264 Train Loss: 0.5310 (Forecasting Loss:0.2326 + XiCon Loss:2.9840 x Lambda(0.1)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.2013
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5466986
	speed: 0.0367s/iter; left time: 857.9594s
	iters: 200, epoch: 12 | loss: 0.4989194
	speed: 0.0349s/iter; left time: 812.2204s
Epoch: 12 cost time: 9.318443059921265
Epoch: 12, Steps: 264 Train Loss: 0.5308 (Forecasting Loss:0.2324 + XiCon Loss:2.9833 x Lambda(0.1)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.2013
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12318017333745956, mae:0.26939451694488525, mape:0.6537361145019531, mspe:14.999398231506348 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1780
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6747625
	speed: 0.0384s/iter; left time: 1009.0556s
	iters: 200, epoch: 1 | loss: 0.6114373
	speed: 0.0345s/iter; left time: 902.8574s
Epoch: 1 cost time: 9.54382848739624
Epoch: 1, Steps: 264 Train Loss: 0.6543 (Forecasting Loss:0.3318 + XiCon Loss:3.2246 x Lambda(0.1)), Vali MSE Loss: 0.2932 Test MSE Loss: 0.2301
Validation loss decreased (inf --> 0.293172).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5525661
	speed: 0.0367s/iter; left time: 956.6854s
	iters: 200, epoch: 2 | loss: 0.5198501
	speed: 0.0350s/iter; left time: 907.2539s
Epoch: 2 cost time: 9.355807065963745
Epoch: 2, Steps: 264 Train Loss: 0.5538 (Forecasting Loss:0.2473 + XiCon Loss:3.0654 x Lambda(0.1)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.2037
Validation loss decreased (0.293172 --> 0.256208).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5331395
	speed: 0.0369s/iter; left time: 951.1473s
	iters: 200, epoch: 3 | loss: 0.5353310
	speed: 0.0342s/iter; left time: 878.0060s
Epoch: 3 cost time: 9.310718536376953
Epoch: 3, Steps: 264 Train Loss: 0.5328 (Forecasting Loss:0.2327 + XiCon Loss:3.0005 x Lambda(0.1)), Vali MSE Loss: 0.2579 Test MSE Loss: 0.2034
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5135170
	speed: 0.0368s/iter; left time: 939.6153s
	iters: 200, epoch: 4 | loss: 0.5251672
	speed: 0.0344s/iter; left time: 874.8801s
Epoch: 4 cost time: 9.387627840042114
Epoch: 4, Steps: 264 Train Loss: 0.5285 (Forecasting Loss:0.2288 + XiCon Loss:2.9966 x Lambda(0.1)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.2072
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5493490
	speed: 0.0373s/iter; left time: 942.6998s
	iters: 200, epoch: 5 | loss: 0.5184723
	speed: 0.0346s/iter; left time: 870.6718s
Epoch: 5 cost time: 9.461701154708862
Epoch: 5, Steps: 264 Train Loss: 0.5263 (Forecasting Loss:0.2268 + XiCon Loss:2.9943 x Lambda(0.1)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.2077
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5606505
	speed: 0.0366s/iter; left time: 913.5430s
	iters: 200, epoch: 6 | loss: 0.5250095
	speed: 0.0348s/iter; left time: 865.2599s
Epoch: 6 cost time: 9.406881332397461
Epoch: 6, Steps: 264 Train Loss: 0.5255 (Forecasting Loss:0.2261 + XiCon Loss:2.9935 x Lambda(0.1)), Vali MSE Loss: 0.2608 Test MSE Loss: 0.2079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5373221
	speed: 0.0375s/iter; left time: 927.3104s
	iters: 200, epoch: 7 | loss: 0.5099089
	speed: 0.0348s/iter; left time: 856.5891s
Epoch: 7 cost time: 9.432270526885986
Epoch: 7, Steps: 264 Train Loss: 0.5244 (Forecasting Loss:0.2253 + XiCon Loss:2.9917 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.2084
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5155218
	speed: 0.0370s/iter; left time: 905.4531s
	iters: 200, epoch: 8 | loss: 0.5291593
	speed: 0.0356s/iter; left time: 866.1084s
Epoch: 8 cost time: 9.496207475662231
Epoch: 8, Steps: 264 Train Loss: 0.5242 (Forecasting Loss:0.2249 + XiCon Loss:2.9928 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.2087
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5323688
	speed: 0.0370s/iter; left time: 894.5668s
	iters: 200, epoch: 9 | loss: 0.5367296
	speed: 0.0353s/iter; left time: 849.8693s
Epoch: 9 cost time: 9.437211036682129
Epoch: 9, Steps: 264 Train Loss: 0.5243 (Forecasting Loss:0.2251 + XiCon Loss:2.9920 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.2089
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5322584
	speed: 0.0372s/iter; left time: 889.5105s
	iters: 200, epoch: 10 | loss: 0.5065781
	speed: 0.0349s/iter; left time: 832.3832s
Epoch: 10 cost time: 9.41762924194336
Epoch: 10, Steps: 264 Train Loss: 0.5241 (Forecasting Loss:0.2249 + XiCon Loss:2.9919 x Lambda(0.1)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.2090
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5252684
	speed: 0.0366s/iter; left time: 866.4051s
	iters: 200, epoch: 11 | loss: 0.5293299
	speed: 0.0348s/iter; left time: 819.6855s
Epoch: 11 cost time: 9.363362073898315
Epoch: 11, Steps: 264 Train Loss: 0.5241 (Forecasting Loss:0.2249 + XiCon Loss:2.9923 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.2090
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5322630
	speed: 0.0369s/iter; left time: 862.6669s
	iters: 200, epoch: 12 | loss: 0.5455322
	speed: 0.0352s/iter; left time: 819.2025s
Epoch: 12 cost time: 9.44984769821167
Epoch: 12, Steps: 264 Train Loss: 0.5243 (Forecasting Loss:0.2249 + XiCon Loss:2.9943 x Lambda(0.1)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.2090
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12972229719161987, mae:0.27764075994491577, mape:0.6665822267532349, mspe:15.789722442626953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0993
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6534483
	speed: 0.0381s/iter; left time: 1000.7923s
	iters: 200, epoch: 1 | loss: 0.6739968
	speed: 0.0363s/iter; left time: 951.5335s
Epoch: 1 cost time: 9.727823734283447
Epoch: 1, Steps: 264 Train Loss: 0.6582 (Forecasting Loss:0.3347 + XiCon Loss:3.2344 x Lambda(0.1)), Vali MSE Loss: 0.2959 Test MSE Loss: 0.2325
Validation loss decreased (inf --> 0.295872).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5878479
	speed: 0.0370s/iter; left time: 963.5174s
	iters: 200, epoch: 2 | loss: 0.5330099
	speed: 0.0352s/iter; left time: 911.9047s
Epoch: 2 cost time: 9.443764686584473
Epoch: 2, Steps: 264 Train Loss: 0.5518 (Forecasting Loss:0.2483 + XiCon Loss:3.0352 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.2029
Validation loss decreased (0.295872 --> 0.256780).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5421773
	speed: 0.0357s/iter; left time: 920.7801s
	iters: 200, epoch: 3 | loss: 0.5503076
	speed: 0.0356s/iter; left time: 913.5046s
Epoch: 3 cost time: 9.421563625335693
Epoch: 3, Steps: 264 Train Loss: 0.5327 (Forecasting Loss:0.2344 + XiCon Loss:2.9830 x Lambda(0.1)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.2087
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5400631
	speed: 0.0363s/iter; left time: 926.5415s
	iters: 200, epoch: 4 | loss: 0.5359020
	speed: 0.0347s/iter; left time: 880.8173s
Epoch: 4 cost time: 9.376100540161133
Epoch: 4, Steps: 264 Train Loss: 0.5290 (Forecasting Loss:0.2283 + XiCon Loss:3.0072 x Lambda(0.1)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.2107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5286942
	speed: 0.0365s/iter; left time: 921.4534s
	iters: 200, epoch: 5 | loss: 0.5162439
	speed: 0.0340s/iter; left time: 854.2398s
Epoch: 5 cost time: 9.232255935668945
Epoch: 5, Steps: 264 Train Loss: 0.5300 (Forecasting Loss:0.2252 + XiCon Loss:3.0475 x Lambda(0.1)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.2143
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5328212
	speed: 0.0371s/iter; left time: 925.7656s
	iters: 200, epoch: 6 | loss: 0.5628287
	speed: 0.0347s/iter; left time: 862.3176s
Epoch: 6 cost time: 9.403576612472534
Epoch: 6, Steps: 264 Train Loss: 0.5304 (Forecasting Loss:0.2246 + XiCon Loss:3.0578 x Lambda(0.1)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.2157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5416577
	speed: 0.0370s/iter; left time: 914.0665s
	iters: 200, epoch: 7 | loss: 0.5513299
	speed: 0.0346s/iter; left time: 850.8461s
Epoch: 7 cost time: 9.348851203918457
Epoch: 7, Steps: 264 Train Loss: 0.5302 (Forecasting Loss:0.2241 + XiCon Loss:3.0605 x Lambda(0.1)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.2157
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5282140
	speed: 0.0369s/iter; left time: 901.3528s
	iters: 200, epoch: 8 | loss: 0.5093417
	speed: 0.0355s/iter; left time: 864.0509s
Epoch: 8 cost time: 9.501442670822144
Epoch: 8, Steps: 264 Train Loss: 0.5304 (Forecasting Loss:0.2239 + XiCon Loss:3.0654 x Lambda(0.1)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2166
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5197620
	speed: 0.0376s/iter; left time: 910.3784s
	iters: 200, epoch: 9 | loss: 0.5289921
	speed: 0.0353s/iter; left time: 849.5873s
Epoch: 9 cost time: 9.527620553970337
Epoch: 9, Steps: 264 Train Loss: 0.5304 (Forecasting Loss:0.2237 + XiCon Loss:3.0665 x Lambda(0.1)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.2167
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5176746
	speed: 0.0373s/iter; left time: 893.3459s
	iters: 200, epoch: 10 | loss: 0.5749533
	speed: 0.0350s/iter; left time: 833.6330s
Epoch: 10 cost time: 9.412660837173462
Epoch: 10, Steps: 264 Train Loss: 0.5305 (Forecasting Loss:0.2236 + XiCon Loss:3.0691 x Lambda(0.1)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.2166
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5147626
	speed: 0.0367s/iter; left time: 868.2460s
	iters: 200, epoch: 11 | loss: 0.5203094
	speed: 0.0352s/iter; left time: 830.2411s
Epoch: 11 cost time: 9.469884395599365
Epoch: 11, Steps: 264 Train Loss: 0.5304 (Forecasting Loss:0.2238 + XiCon Loss:3.0659 x Lambda(0.1)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.2167
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5301920
	speed: 0.0368s/iter; left time: 861.2512s
	iters: 200, epoch: 12 | loss: 0.5271112
	speed: 0.0346s/iter; left time: 806.5383s
Epoch: 12 cost time: 9.341602802276611
Epoch: 12, Steps: 264 Train Loss: 0.5301 (Forecasting Loss:0.2235 + XiCon Loss:3.0661 x Lambda(0.1)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.2167
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.1291140466928482, mae:0.27669185400009155, mape:0.6641067862510681, mspe:15.707633018493652 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7851
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6683869
	speed: 0.0364s/iter; left time: 958.3294s
	iters: 200, epoch: 1 | loss: 0.6151775
	speed: 0.0340s/iter; left time: 891.9470s
Epoch: 1 cost time: 9.247737646102905
Epoch: 1, Steps: 264 Train Loss: 0.6582 (Forecasting Loss:0.3363 + XiCon Loss:3.2188 x Lambda(0.1)), Vali MSE Loss: 0.2974 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.297399).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5526154
	speed: 0.0373s/iter; left time: 971.1659s
	iters: 200, epoch: 2 | loss: 0.5374534
	speed: 0.0351s/iter; left time: 909.9765s
Epoch: 2 cost time: 9.45774531364441
Epoch: 2, Steps: 264 Train Loss: 0.5586 (Forecasting Loss:0.2518 + XiCon Loss:3.0675 x Lambda(0.1)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1938
Validation loss decreased (0.297399 --> 0.252626).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5196381
	speed: 0.0364s/iter; left time: 936.8624s
	iters: 200, epoch: 3 | loss: 0.5540383
	speed: 0.0341s/iter; left time: 874.2760s
Epoch: 3 cost time: 9.272340774536133
Epoch: 3, Steps: 264 Train Loss: 0.5393 (Forecasting Loss:0.2397 + XiCon Loss:2.9956 x Lambda(0.1)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1972
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5359099
	speed: 0.0370s/iter; left time: 943.4182s
	iters: 200, epoch: 4 | loss: 0.5190005
	speed: 0.0351s/iter; left time: 890.6579s
Epoch: 4 cost time: 9.43747329711914
Epoch: 4, Steps: 264 Train Loss: 0.5343 (Forecasting Loss:0.2352 + XiCon Loss:2.9903 x Lambda(0.1)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1985
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5342011
	speed: 0.0370s/iter; left time: 933.8151s
	iters: 200, epoch: 5 | loss: 0.5409067
	speed: 0.0342s/iter; left time: 860.8692s
Epoch: 5 cost time: 9.331436157226562
Epoch: 5, Steps: 264 Train Loss: 0.5322 (Forecasting Loss:0.2336 + XiCon Loss:2.9862 x Lambda(0.1)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.1995
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5391228
	speed: 0.0358s/iter; left time: 893.2186s
	iters: 200, epoch: 6 | loss: 0.5269629
	speed: 0.0349s/iter; left time: 869.5030s
Epoch: 6 cost time: 9.296242952346802
Epoch: 6, Steps: 264 Train Loss: 0.5312 (Forecasting Loss:0.2326 + XiCon Loss:2.9863 x Lambda(0.1)), Vali MSE Loss: 0.2556 Test MSE Loss: 0.1996
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5534129
	speed: 0.0372s/iter; left time: 918.2902s
	iters: 200, epoch: 7 | loss: 0.5432873
	speed: 0.0346s/iter; left time: 852.5035s
Epoch: 7 cost time: 9.440680742263794
Epoch: 7, Steps: 264 Train Loss: 0.5309 (Forecasting Loss:0.2321 + XiCon Loss:2.9876 x Lambda(0.1)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1998
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5399735
	speed: 0.0367s/iter; left time: 896.3917s
	iters: 200, epoch: 8 | loss: 0.5482299
	speed: 0.0346s/iter; left time: 843.6226s
Epoch: 8 cost time: 9.337872743606567
Epoch: 8, Steps: 264 Train Loss: 0.5304 (Forecasting Loss:0.2318 + XiCon Loss:2.9859 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.1998
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5398781
	speed: 0.0368s/iter; left time: 889.0872s
	iters: 200, epoch: 9 | loss: 0.5495964
	speed: 0.0349s/iter; left time: 840.3109s
Epoch: 9 cost time: 9.384527683258057
Epoch: 9, Steps: 264 Train Loss: 0.5300 (Forecasting Loss:0.2314 + XiCon Loss:2.9865 x Lambda(0.1)), Vali MSE Loss: 0.2560 Test MSE Loss: 0.1999
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5613753
	speed: 0.0370s/iter; left time: 885.9738s
	iters: 200, epoch: 10 | loss: 0.5248515
	speed: 0.0340s/iter; left time: 810.7221s
Epoch: 10 cost time: 9.276580095291138
Epoch: 10, Steps: 264 Train Loss: 0.5300 (Forecasting Loss:0.2315 + XiCon Loss:2.9852 x Lambda(0.1)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.1999
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5320656
	speed: 0.0365s/iter; left time: 863.6139s
	iters: 200, epoch: 11 | loss: 0.5347657
	speed: 0.0342s/iter; left time: 806.7882s
Epoch: 11 cost time: 9.286665916442871
Epoch: 11, Steps: 264 Train Loss: 0.5298 (Forecasting Loss:0.2313 + XiCon Loss:2.9853 x Lambda(0.1)), Vali MSE Loss: 0.2561 Test MSE Loss: 0.1999
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5324599
	speed: 0.0366s/iter; left time: 857.4643s
	iters: 200, epoch: 12 | loss: 0.5332916
	speed: 0.0355s/iter; left time: 826.7541s
Epoch: 12 cost time: 9.433541774749756
Epoch: 12, Steps: 264 Train Loss: 0.5303 (Forecasting Loss:0.2315 + XiCon Loss:2.9882 x Lambda(0.1)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.1999
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12190468609333038, mae:0.2656012773513794, mape:0.6271247267723083, mspe:13.826870918273926 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5604
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.6639242
	speed: 0.0387s/iter; left time: 1017.6293s
	iters: 200, epoch: 1 | loss: 0.6498104
	speed: 0.0355s/iter; left time: 928.9337s
Epoch: 1 cost time: 9.717642068862915
Epoch: 1, Steps: 264 Train Loss: 0.6595 (Forecasting Loss:0.3357 + XiCon Loss:3.2387 x Lambda(0.1)), Vali MSE Loss: 0.2915 Test MSE Loss: 0.2312
Validation loss decreased (inf --> 0.291550).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5308513
	speed: 0.0369s/iter; left time: 960.9078s
	iters: 200, epoch: 2 | loss: 0.5534815
	speed: 0.0340s/iter; left time: 882.8082s
Epoch: 2 cost time: 9.312580347061157
Epoch: 2, Steps: 264 Train Loss: 0.5532 (Forecasting Loss:0.2455 + XiCon Loss:3.0770 x Lambda(0.1)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2016
Validation loss decreased (0.291550 --> 0.250524).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5398420
	speed: 0.0363s/iter; left time: 934.3139s
	iters: 200, epoch: 3 | loss: 0.5292822
	speed: 0.0355s/iter; left time: 910.7984s
Epoch: 3 cost time: 9.430315256118774
Epoch: 3, Steps: 264 Train Loss: 0.5371 (Forecasting Loss:0.2342 + XiCon Loss:3.0295 x Lambda(0.1)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2074
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5782664
	speed: 0.0372s/iter; left time: 949.2581s
	iters: 200, epoch: 4 | loss: 0.5344400
	speed: 0.0349s/iter; left time: 887.1272s
Epoch: 4 cost time: 9.44633173942566
Epoch: 4, Steps: 264 Train Loss: 0.5398 (Forecasting Loss:0.2296 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2076
Validation loss decreased (0.250524 --> 0.248984).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5471226
	speed: 0.0367s/iter; left time: 926.9117s
	iters: 200, epoch: 5 | loss: 0.5185584
	speed: 0.0354s/iter; left time: 889.7356s
Epoch: 5 cost time: 9.421203851699829
Epoch: 5, Steps: 264 Train Loss: 0.5384 (Forecasting Loss:0.2264 + XiCon Loss:3.1203 x Lambda(0.1)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2112
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5629719
	speed: 0.0377s/iter; left time: 941.5142s
	iters: 200, epoch: 6 | loss: 0.5304694
	speed: 0.0344s/iter; left time: 856.8394s
Epoch: 6 cost time: 9.412393808364868
Epoch: 6, Steps: 264 Train Loss: 0.5381 (Forecasting Loss:0.2250 + XiCon Loss:3.1305 x Lambda(0.1)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2130
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5415167
	speed: 0.0359s/iter; left time: 887.5446s
	iters: 200, epoch: 7 | loss: 0.5615395
	speed: 0.0352s/iter; left time: 867.0720s
Epoch: 7 cost time: 9.426454305648804
Epoch: 7, Steps: 264 Train Loss: 0.5377 (Forecasting Loss:0.2242 + XiCon Loss:3.1343 x Lambda(0.1)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.2136
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5331279
	speed: 0.0362s/iter; left time: 885.2015s
	iters: 200, epoch: 8 | loss: 0.5199981
	speed: 0.0349s/iter; left time: 850.5517s
Epoch: 8 cost time: 9.29426121711731
Epoch: 8, Steps: 264 Train Loss: 0.5378 (Forecasting Loss:0.2244 + XiCon Loss:3.1344 x Lambda(0.1)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2137
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5260403
	speed: 0.0361s/iter; left time: 873.5229s
	iters: 200, epoch: 9 | loss: 0.5591116
	speed: 0.0341s/iter; left time: 820.6370s
Epoch: 9 cost time: 9.23825192451477
Epoch: 9, Steps: 264 Train Loss: 0.5374 (Forecasting Loss:0.2241 + XiCon Loss:3.1329 x Lambda(0.1)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2136
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5373669
	speed: 0.0368s/iter; left time: 880.5653s
	iters: 200, epoch: 10 | loss: 0.5026555
	speed: 0.0352s/iter; left time: 837.9972s
Epoch: 10 cost time: 9.445281982421875
Epoch: 10, Steps: 264 Train Loss: 0.5378 (Forecasting Loss:0.2239 + XiCon Loss:3.1398 x Lambda(0.1)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.2137
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5555423
	speed: 0.0376s/iter; left time: 890.5909s
	iters: 200, epoch: 11 | loss: 0.5075861
	speed: 0.0357s/iter; left time: 841.6185s
Epoch: 11 cost time: 9.587936639785767
Epoch: 11, Steps: 264 Train Loss: 0.5375 (Forecasting Loss:0.2239 + XiCon Loss:3.1363 x Lambda(0.1)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2138
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5334327
	speed: 0.0370s/iter; left time: 866.8470s
	iters: 200, epoch: 12 | loss: 0.5565786
	speed: 0.0350s/iter; left time: 815.8898s
Epoch: 12 cost time: 9.474669218063354
Epoch: 12, Steps: 264 Train Loss: 0.5377 (Forecasting Loss:0.2240 + XiCon Loss:3.1372 x Lambda(0.1)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2138
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.5560861
	speed: 0.0368s/iter; left time: 850.7559s
	iters: 200, epoch: 13 | loss: 0.4918788
	speed: 0.0342s/iter; left time: 787.6386s
Epoch: 13 cost time: 9.390419960021973
Epoch: 13, Steps: 264 Train Loss: 0.5375 (Forecasting Loss:0.2238 + XiCon Loss:3.1372 x Lambda(0.1)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.2138
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.5476884
	speed: 0.0373s/iter; left time: 852.7916s
	iters: 200, epoch: 14 | loss: 0.5286882
	speed: 0.0350s/iter; left time: 797.6861s
Epoch: 14 cost time: 9.386215448379517
Epoch: 14, Steps: 264 Train Loss: 0.5377 (Forecasting Loss:0.2241 + XiCon Loss:3.1356 x Lambda(0.1)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2138
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.13383039832115173, mae:0.28137582540512085, mape:0.7103126645088196, mspe:18.48486328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1276+-0.00613, MAE:0.2741+-0.00801, MAPE:0.6644+-0.03733, MSPE:15.7617+-2.12756, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.3943
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.7040778
	speed: 0.0532s/iter; left time: 1384.2581s
	iters: 200, epoch: 1 | loss: 0.6428730
	speed: 0.0479s/iter; left time: 1241.0703s
Epoch: 1 cost time: 13.09316897392273
Epoch: 1, Steps: 261 Train Loss: 0.6943 (Forecasting Loss:0.3719 + XiCon Loss:3.2241 x Lambda(0.1)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2800
Validation loss decreased (inf --> 0.323095).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5809963
	speed: 0.0502s/iter; left time: 1293.1473s
	iters: 200, epoch: 2 | loss: 0.5702362
	speed: 0.0476s/iter; left time: 1220.1771s
Epoch: 2 cost time: 12.68932318687439
Epoch: 2, Steps: 261 Train Loss: 0.6024 (Forecasting Loss:0.2941 + XiCon Loss:3.0836 x Lambda(0.1)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.2502
Validation loss decreased (0.323095 --> 0.294965).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5808662
	speed: 0.0502s/iter; left time: 1278.8294s
	iters: 200, epoch: 3 | loss: 0.6008152
	speed: 0.0482s/iter; left time: 1222.2918s
Epoch: 3 cost time: 12.733114242553711
Epoch: 3, Steps: 261 Train Loss: 0.5834 (Forecasting Loss:0.2820 + XiCon Loss:3.0139 x Lambda(0.1)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2529
Validation loss decreased (0.294965 --> 0.288851).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5652176
	speed: 0.0501s/iter; left time: 1263.6890s
	iters: 200, epoch: 4 | loss: 0.5804179
	speed: 0.0487s/iter; left time: 1223.2058s
Epoch: 4 cost time: 12.883322954177856
Epoch: 4, Steps: 261 Train Loss: 0.5787 (Forecasting Loss:0.2779 + XiCon Loss:3.0075 x Lambda(0.1)), Vali MSE Loss: 0.3033 Test MSE Loss: 0.2509
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5859313
	speed: 0.0502s/iter; left time: 1252.6268s
	iters: 200, epoch: 5 | loss: 0.5699330
	speed: 0.0496s/iter; left time: 1233.9659s
Epoch: 5 cost time: 13.173956394195557
Epoch: 5, Steps: 261 Train Loss: 0.5762 (Forecasting Loss:0.2758 + XiCon Loss:3.0041 x Lambda(0.1)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.2533
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6107608
	speed: 0.0528s/iter; left time: 1303.5197s
	iters: 200, epoch: 6 | loss: 0.5812621
	speed: 0.0500s/iter; left time: 1230.1135s
Epoch: 6 cost time: 13.394883394241333
Epoch: 6, Steps: 261 Train Loss: 0.5744 (Forecasting Loss:0.2741 + XiCon Loss:3.0034 x Lambda(0.1)), Vali MSE Loss: 0.2982 Test MSE Loss: 0.2552
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5590754
	speed: 0.0513s/iter; left time: 1253.4690s
	iters: 200, epoch: 7 | loss: 0.5644338
	speed: 0.0465s/iter; left time: 1131.9976s
Epoch: 7 cost time: 12.735076427459717
Epoch: 7, Steps: 261 Train Loss: 0.5738 (Forecasting Loss:0.2736 + XiCon Loss:3.0016 x Lambda(0.1)), Vali MSE Loss: 0.2981 Test MSE Loss: 0.2568
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5770534
	speed: 0.0500s/iter; left time: 1207.8147s
	iters: 200, epoch: 8 | loss: 0.5844820
	speed: 0.0499s/iter; left time: 1201.6606s
Epoch: 8 cost time: 12.924379587173462
Epoch: 8, Steps: 261 Train Loss: 0.5738 (Forecasting Loss:0.2735 + XiCon Loss:3.0023 x Lambda(0.1)), Vali MSE Loss: 0.3005 Test MSE Loss: 0.2556
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5637541
	speed: 0.0512s/iter; left time: 1224.8306s
	iters: 200, epoch: 9 | loss: 0.5626924
	speed: 0.0482s/iter; left time: 1148.1539s
Epoch: 9 cost time: 12.934708833694458
Epoch: 9, Steps: 261 Train Loss: 0.5736 (Forecasting Loss:0.2732 + XiCon Loss:3.0033 x Lambda(0.1)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.2557
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5945398
	speed: 0.0504s/iter; left time: 1192.7760s
	iters: 200, epoch: 10 | loss: 0.5538001
	speed: 0.0502s/iter; left time: 1183.1304s
Epoch: 10 cost time: 13.037926435470581
Epoch: 10, Steps: 261 Train Loss: 0.5732 (Forecasting Loss:0.2730 + XiCon Loss:3.0017 x Lambda(0.1)), Vali MSE Loss: 0.3003 Test MSE Loss: 0.2559
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5810977
	speed: 0.0515s/iter; left time: 1203.5155s
	iters: 200, epoch: 11 | loss: 0.5538018
	speed: 0.0481s/iter; left time: 1121.0309s
Epoch: 11 cost time: 12.921779870986938
Epoch: 11, Steps: 261 Train Loss: 0.5731 (Forecasting Loss:0.2731 + XiCon Loss:3.0003 x Lambda(0.1)), Vali MSE Loss: 0.3006 Test MSE Loss: 0.2557
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5486113
	speed: 0.0518s/iter; left time: 1197.2866s
	iters: 200, epoch: 12 | loss: 0.5920516
	speed: 0.0498s/iter; left time: 1147.3272s
Epoch: 12 cost time: 13.214844703674316
Epoch: 12, Steps: 261 Train Loss: 0.5735 (Forecasting Loss:0.2731 + XiCon Loss:3.0039 x Lambda(0.1)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.2557
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.5843442
	speed: 0.0515s/iter; left time: 1177.0966s
	iters: 200, epoch: 13 | loss: 0.5808172
	speed: 0.0498s/iter; left time: 1133.0953s
Epoch: 13 cost time: 13.156250476837158
Epoch: 13, Steps: 261 Train Loss: 0.5733 (Forecasting Loss:0.2732 + XiCon Loss:3.0012 x Lambda(0.1)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.2556
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17658257484436035, mae:0.3291904926300049, mape:0.7472506761550903, mspe:20.305177688598633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8271
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.7013836
	speed: 0.0449s/iter; left time: 1168.7312s
	iters: 200, epoch: 1 | loss: 0.6588811
	speed: 0.0443s/iter; left time: 1146.6990s
Epoch: 1 cost time: 11.565261840820312
Epoch: 1, Steps: 261 Train Loss: 0.6949 (Forecasting Loss:0.3711 + XiCon Loss:3.2385 x Lambda(0.1)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2804
Validation loss decreased (inf --> 0.323375).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5984792
	speed: 0.0474s/iter; left time: 1221.3409s
	iters: 200, epoch: 2 | loss: 0.5918479
	speed: 0.0450s/iter; left time: 1154.3236s
Epoch: 2 cost time: 11.872861385345459
Epoch: 2, Steps: 261 Train Loss: 0.6001 (Forecasting Loss:0.2944 + XiCon Loss:3.0568 x Lambda(0.1)), Vali MSE Loss: 0.2865 Test MSE Loss: 0.2510
Validation loss decreased (0.323375 --> 0.286485).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5742887
	speed: 0.0471s/iter; left time: 1201.0302s
	iters: 200, epoch: 3 | loss: 0.6012195
	speed: 0.0448s/iter; left time: 1138.0374s
Epoch: 3 cost time: 11.938764333724976
Epoch: 3, Steps: 261 Train Loss: 0.5803 (Forecasting Loss:0.2808 + XiCon Loss:2.9952 x Lambda(0.1)), Vali MSE Loss: 0.2822 Test MSE Loss: 0.2595
Validation loss decreased (0.286485 --> 0.282192).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6014342
	speed: 0.0470s/iter; left time: 1186.3715s
	iters: 200, epoch: 4 | loss: 0.5747008
	speed: 0.0466s/iter; left time: 1171.6219s
Epoch: 4 cost time: 12.178261756896973
Epoch: 4, Steps: 261 Train Loss: 0.5810 (Forecasting Loss:0.2777 + XiCon Loss:3.0328 x Lambda(0.1)), Vali MSE Loss: 0.2805 Test MSE Loss: 0.2567
Validation loss decreased (0.282192 --> 0.280526).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5809685
	speed: 0.0478s/iter; left time: 1192.3201s
	iters: 200, epoch: 5 | loss: 0.5671333
	speed: 0.0452s/iter; left time: 1124.2803s
Epoch: 5 cost time: 12.029761552810669
Epoch: 5, Steps: 261 Train Loss: 0.5801 (Forecasting Loss:0.2757 + XiCon Loss:3.0437 x Lambda(0.1)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2557
Validation loss decreased (0.280526 --> 0.278692).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5684796
	speed: 0.0474s/iter; left time: 1170.1372s
	iters: 200, epoch: 6 | loss: 0.5594653
	speed: 0.0459s/iter; left time: 1127.9463s
Epoch: 6 cost time: 12.147249460220337
Epoch: 6, Steps: 261 Train Loss: 0.5784 (Forecasting Loss:0.2742 + XiCon Loss:3.0416 x Lambda(0.1)), Vali MSE Loss: 0.2805 Test MSE Loss: 0.2562
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5727977
	speed: 0.0478s/iter; left time: 1167.5350s
	iters: 200, epoch: 7 | loss: 0.5914950
	speed: 0.0453s/iter; left time: 1101.8319s
Epoch: 7 cost time: 12.078811883926392
Epoch: 7, Steps: 261 Train Loss: 0.5782 (Forecasting Loss:0.2736 + XiCon Loss:3.0465 x Lambda(0.1)), Vali MSE Loss: 0.2805 Test MSE Loss: 0.2576
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5536846
	speed: 0.0481s/iter; left time: 1163.3680s
	iters: 200, epoch: 8 | loss: 0.5897677
	speed: 0.0452s/iter; left time: 1087.4297s
Epoch: 8 cost time: 12.003946781158447
Epoch: 8, Steps: 261 Train Loss: 0.5779 (Forecasting Loss:0.2733 + XiCon Loss:3.0455 x Lambda(0.1)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.2569
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6053435
	speed: 0.0453s/iter; left time: 1084.1417s
	iters: 200, epoch: 9 | loss: 0.5828832
	speed: 0.0476s/iter; left time: 1134.4497s
Epoch: 9 cost time: 12.046609163284302
Epoch: 9, Steps: 261 Train Loss: 0.5779 (Forecasting Loss:0.2732 + XiCon Loss:3.0472 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2573
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5680872
	speed: 0.0473s/iter; left time: 1118.2783s
	iters: 200, epoch: 10 | loss: 0.5812981
	speed: 0.0450s/iter; left time: 1059.1111s
Epoch: 10 cost time: 12.11234998703003
Epoch: 10, Steps: 261 Train Loss: 0.5785 (Forecasting Loss:0.2732 + XiCon Loss:3.0533 x Lambda(0.1)), Vali MSE Loss: 0.2809 Test MSE Loss: 0.2574
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6014986
	speed: 0.0479s/iter; left time: 1120.2734s
	iters: 200, epoch: 11 | loss: 0.5972551
	speed: 0.0448s/iter; left time: 1042.8483s
Epoch: 11 cost time: 11.97885274887085
Epoch: 11, Steps: 261 Train Loss: 0.5777 (Forecasting Loss:0.2732 + XiCon Loss:3.0447 x Lambda(0.1)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.2573
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5615946
	speed: 0.0503s/iter; left time: 1162.7050s
	iters: 200, epoch: 12 | loss: 0.5756410
	speed: 0.0452s/iter; left time: 1041.8124s
Epoch: 12 cost time: 12.421459674835205
Epoch: 12, Steps: 261 Train Loss: 0.5777 (Forecasting Loss:0.2730 + XiCon Loss:3.0466 x Lambda(0.1)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.2574
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.5799938
	speed: 0.0473s/iter; left time: 1080.6495s
	iters: 200, epoch: 13 | loss: 0.5459108
	speed: 0.0456s/iter; left time: 1038.6676s
Epoch: 13 cost time: 12.060181856155396
Epoch: 13, Steps: 261 Train Loss: 0.5780 (Forecasting Loss:0.2730 + XiCon Loss:3.0505 x Lambda(0.1)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.2574
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.5724329
	speed: 0.0473s/iter; left time: 1068.2744s
	iters: 200, epoch: 14 | loss: 0.6157831
	speed: 0.0454s/iter; left time: 1022.9640s
Epoch: 14 cost time: 12.01391863822937
Epoch: 14, Steps: 261 Train Loss: 0.5776 (Forecasting Loss:0.2730 + XiCon Loss:3.0461 x Lambda(0.1)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.2574
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6002403
	speed: 0.0487s/iter; left time: 1088.0203s
	iters: 200, epoch: 15 | loss: 0.5541660
	speed: 0.0446s/iter; left time: 991.4196s
Epoch: 15 cost time: 12.112518787384033
Epoch: 15, Steps: 261 Train Loss: 0.5780 (Forecasting Loss:0.2731 + XiCon Loss:3.0487 x Lambda(0.1)), Vali MSE Loss: 0.2811 Test MSE Loss: 0.2574
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.18076881766319275, mae:0.3306393027305603, mape:0.7346760630607605, mspe:20.68782615661621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9479
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.6797060
	speed: 0.0450s/iter; left time: 1170.3032s
	iters: 200, epoch: 1 | loss: 0.6981490
	speed: 0.0421s/iter; left time: 1089.1510s
Epoch: 1 cost time: 11.259860038757324
Epoch: 1, Steps: 261 Train Loss: 0.6931 (Forecasting Loss:0.3706 + XiCon Loss:3.2248 x Lambda(0.1)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2819
Validation loss decreased (inf --> 0.329697).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5895838
	speed: 0.0451s/iter; left time: 1161.0604s
	iters: 200, epoch: 2 | loss: 0.5961214
	speed: 0.0442s/iter; left time: 1133.6197s
Epoch: 2 cost time: 11.473782539367676
Epoch: 2, Steps: 261 Train Loss: 0.6005 (Forecasting Loss:0.2919 + XiCon Loss:3.0863 x Lambda(0.1)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.2537
Validation loss decreased (0.329697 --> 0.296021).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5884529
	speed: 0.0439s/iter; left time: 1118.3996s
	iters: 200, epoch: 3 | loss: 0.5851302
	speed: 0.0417s/iter; left time: 1057.5707s
Epoch: 3 cost time: 11.136868715286255
Epoch: 3, Steps: 261 Train Loss: 0.5797 (Forecasting Loss:0.2783 + XiCon Loss:3.0131 x Lambda(0.1)), Vali MSE Loss: 0.3003 Test MSE Loss: 0.2591
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5780699
	speed: 0.0449s/iter; left time: 1132.1656s
	iters: 200, epoch: 4 | loss: 0.5629679
	speed: 0.0427s/iter; left time: 1072.9442s
Epoch: 4 cost time: 11.378786563873291
Epoch: 4, Steps: 261 Train Loss: 0.5738 (Forecasting Loss:0.2735 + XiCon Loss:3.0033 x Lambda(0.1)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.2633
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5641806
	speed: 0.0437s/iter; left time: 1090.8318s
	iters: 200, epoch: 5 | loss: 0.5556921
	speed: 0.0424s/iter; left time: 1052.8007s
Epoch: 5 cost time: 11.258026838302612
Epoch: 5, Steps: 261 Train Loss: 0.5703 (Forecasting Loss:0.2708 + XiCon Loss:2.9956 x Lambda(0.1)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5719754
	speed: 0.0453s/iter; left time: 1119.6257s
	iters: 200, epoch: 6 | loss: 0.5542231
	speed: 0.0444s/iter; left time: 1091.2648s
Epoch: 6 cost time: 11.743803024291992
Epoch: 6, Steps: 261 Train Loss: 0.5687 (Forecasting Loss:0.2695 + XiCon Loss:2.9922 x Lambda(0.1)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.2657
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5612701
	speed: 0.0446s/iter; left time: 1090.3267s
	iters: 200, epoch: 7 | loss: 0.5861789
	speed: 0.0417s/iter; left time: 1015.2357s
Epoch: 7 cost time: 11.213685989379883
Epoch: 7, Steps: 261 Train Loss: 0.5681 (Forecasting Loss:0.2689 + XiCon Loss:2.9921 x Lambda(0.1)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.2656
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5627275
	speed: 0.0450s/iter; left time: 1088.4831s
	iters: 200, epoch: 8 | loss: 0.5510714
	speed: 0.0431s/iter; left time: 1037.2669s
Epoch: 8 cost time: 11.628077030181885
Epoch: 8, Steps: 261 Train Loss: 0.5674 (Forecasting Loss:0.2685 + XiCon Loss:2.9886 x Lambda(0.1)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.2657
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6013845
	speed: 0.0417s/iter; left time: 997.6221s
	iters: 200, epoch: 9 | loss: 0.5707133
	speed: 0.0404s/iter; left time: 962.5671s
Epoch: 9 cost time: 10.866994142532349
Epoch: 9, Steps: 261 Train Loss: 0.5673 (Forecasting Loss:0.2684 + XiCon Loss:2.9891 x Lambda(0.1)), Vali MSE Loss: 0.3039 Test MSE Loss: 0.2657
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5551197
	speed: 0.0474s/iter; left time: 1120.3054s
	iters: 200, epoch: 10 | loss: 0.5517466
	speed: 0.0423s/iter; left time: 996.2029s
Epoch: 10 cost time: 11.545608043670654
Epoch: 10, Steps: 261 Train Loss: 0.5673 (Forecasting Loss:0.2683 + XiCon Loss:2.9897 x Lambda(0.1)), Vali MSE Loss: 0.3038 Test MSE Loss: 0.2657
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5671635
	speed: 0.0499s/iter; left time: 1167.9939s
	iters: 200, epoch: 11 | loss: 0.5830435
	speed: 0.0420s/iter; left time: 978.8653s
Epoch: 11 cost time: 11.793473720550537
Epoch: 11, Steps: 261 Train Loss: 0.5674 (Forecasting Loss:0.2684 + XiCon Loss:2.9900 x Lambda(0.1)), Vali MSE Loss: 0.3039 Test MSE Loss: 0.2656
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5647105
	speed: 0.0470s/iter; left time: 1087.7999s
	iters: 200, epoch: 12 | loss: 0.5656537
	speed: 0.0428s/iter; left time: 985.6951s
Epoch: 12 cost time: 11.65841293334961
Epoch: 12, Steps: 261 Train Loss: 0.5674 (Forecasting Loss:0.2684 + XiCon Loss:2.9907 x Lambda(0.1)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.2656
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1774464249610901, mae:0.3299493193626404, mape:0.7195591330528259, mspe:19.004823684692383 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2045
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.7282864
	speed: 0.0515s/iter; left time: 1338.9497s
	iters: 200, epoch: 1 | loss: 0.6556540
	speed: 0.0485s/iter; left time: 1256.5512s
Epoch: 1 cost time: 13.011199235916138
Epoch: 1, Steps: 261 Train Loss: 0.6952 (Forecasting Loss:0.3714 + XiCon Loss:3.2379 x Lambda(0.1)), Vali MSE Loss: 0.3263 Test MSE Loss: 0.2814
Validation loss decreased (inf --> 0.326275).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6271646
	speed: 0.0511s/iter; left time: 1315.5651s
	iters: 200, epoch: 2 | loss: 0.6091187
	speed: 0.0483s/iter; left time: 1237.6817s
Epoch: 2 cost time: 12.956388711929321
Epoch: 2, Steps: 261 Train Loss: 0.6019 (Forecasting Loss:0.2954 + XiCon Loss:3.0650 x Lambda(0.1)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.2465
Validation loss decreased (0.326275 --> 0.295315).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5992218
	speed: 0.0503s/iter; left time: 1282.5198s
	iters: 200, epoch: 3 | loss: 0.5532623
	speed: 0.0486s/iter; left time: 1234.4659s
Epoch: 3 cost time: 12.799659490585327
Epoch: 3, Steps: 261 Train Loss: 0.5877 (Forecasting Loss:0.2849 + XiCon Loss:3.0272 x Lambda(0.1)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2454
Validation loss decreased (0.295315 --> 0.280211).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5688928
	speed: 0.0506s/iter; left time: 1276.0481s
	iters: 200, epoch: 4 | loss: 0.5861456
	speed: 0.0488s/iter; left time: 1225.6016s
Epoch: 4 cost time: 12.928163051605225
Epoch: 4, Steps: 261 Train Loss: 0.5912 (Forecasting Loss:0.2823 + XiCon Loss:3.0889 x Lambda(0.1)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2505
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5738515
	speed: 0.0523s/iter; left time: 1305.2114s
	iters: 200, epoch: 5 | loss: 0.5823215
	speed: 0.0500s/iter; left time: 1242.1033s
Epoch: 5 cost time: 13.333441972732544
Epoch: 5, Steps: 261 Train Loss: 0.5908 (Forecasting Loss:0.2806 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.2841 Test MSE Loss: 0.2513
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5918067
	speed: 0.0521s/iter; left time: 1286.1658s
	iters: 200, epoch: 6 | loss: 0.5870262
	speed: 0.0495s/iter; left time: 1216.4770s
Epoch: 6 cost time: 13.179553508758545
Epoch: 6, Steps: 261 Train Loss: 0.5909 (Forecasting Loss:0.2798 + XiCon Loss:3.1109 x Lambda(0.1)), Vali MSE Loss: 0.2799 Test MSE Loss: 0.2512
Validation loss decreased (0.280211 --> 0.279864).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.5818782
	speed: 0.0526s/iter; left time: 1284.6345s
	iters: 200, epoch: 7 | loss: 0.6068819
	speed: 0.0504s/iter; left time: 1225.6995s
Epoch: 7 cost time: 13.377333641052246
Epoch: 7, Steps: 261 Train Loss: 0.5900 (Forecasting Loss:0.2792 + XiCon Loss:3.1083 x Lambda(0.1)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2507
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5911065
	speed: 0.0532s/iter; left time: 1287.0740s
	iters: 200, epoch: 8 | loss: 0.6337563
	speed: 0.0504s/iter; left time: 1213.0785s
Epoch: 8 cost time: 13.357515335083008
Epoch: 8, Steps: 261 Train Loss: 0.5903 (Forecasting Loss:0.2793 + XiCon Loss:3.1100 x Lambda(0.1)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.2506
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5822713
	speed: 0.0514s/iter; left time: 1229.7156s
	iters: 200, epoch: 9 | loss: 0.6027338
	speed: 0.0499s/iter; left time: 1189.4346s
Epoch: 9 cost time: 13.169533967971802
Epoch: 9, Steps: 261 Train Loss: 0.5901 (Forecasting Loss:0.2791 + XiCon Loss:3.1102 x Lambda(0.1)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2507
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5981681
	speed: 0.0519s/iter; left time: 1227.8037s
	iters: 200, epoch: 10 | loss: 0.6083134
	speed: 0.0494s/iter; left time: 1162.8956s
Epoch: 10 cost time: 13.1375892162323
Epoch: 10, Steps: 261 Train Loss: 0.5901 (Forecasting Loss:0.2791 + XiCon Loss:3.1106 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2507
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5999184
	speed: 0.0495s/iter; left time: 1157.8145s
	iters: 200, epoch: 11 | loss: 0.6395761
	speed: 0.0492s/iter; left time: 1146.7999s
Epoch: 11 cost time: 13.059653759002686
Epoch: 11, Steps: 261 Train Loss: 0.5900 (Forecasting Loss:0.2790 + XiCon Loss:3.1099 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2507
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5835671
	speed: 0.0509s/iter; left time: 1178.2172s
	iters: 200, epoch: 12 | loss: 0.5807436
	speed: 0.0500s/iter; left time: 1152.3667s
Epoch: 12 cost time: 13.014504194259644
Epoch: 12, Steps: 261 Train Loss: 0.5902 (Forecasting Loss:0.2791 + XiCon Loss:3.1102 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2507
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.5897055
	speed: 0.0536s/iter; left time: 1225.5204s
	iters: 200, epoch: 13 | loss: 0.5671364
	speed: 0.0492s/iter; left time: 1120.1462s
Epoch: 13 cost time: 13.309915542602539
Epoch: 13, Steps: 261 Train Loss: 0.5899 (Forecasting Loss:0.2790 + XiCon Loss:3.1093 x Lambda(0.1)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.2507
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.5914189
	speed: 0.0506s/iter; left time: 1144.3784s
	iters: 200, epoch: 14 | loss: 0.5888282
	speed: 0.0507s/iter; left time: 1141.6367s
Epoch: 14 cost time: 13.09374475479126
Epoch: 14, Steps: 261 Train Loss: 0.5899 (Forecasting Loss:0.2793 + XiCon Loss:3.1060 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2507
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.5892208
	speed: 0.0520s/iter; left time: 1162.4862s
	iters: 200, epoch: 15 | loss: 0.5819064
	speed: 0.0502s/iter; left time: 1117.0546s
Epoch: 15 cost time: 13.201647996902466
Epoch: 15, Steps: 261 Train Loss: 0.5900 (Forecasting Loss:0.2790 + XiCon Loss:3.1097 x Lambda(0.1)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.2507
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.5671222
	speed: 0.0518s/iter; left time: 1144.2425s
	iters: 200, epoch: 16 | loss: 0.5878843
	speed: 0.0488s/iter; left time: 1073.0873s
Epoch: 16 cost time: 13.119334697723389
Epoch: 16, Steps: 261 Train Loss: 0.5903 (Forecasting Loss:0.2791 + XiCon Loss:3.1113 x Lambda(0.1)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.2507
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17658571898937225, mae:0.325897216796875, mape:0.7227187752723694, mspe:19.175405502319336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6438
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.7223731
	speed: 0.0511s/iter; left time: 1327.7019s
	iters: 200, epoch: 1 | loss: 0.6674161
	speed: 0.0471s/iter; left time: 1219.5037s
Epoch: 1 cost time: 12.632932424545288
Epoch: 1, Steps: 261 Train Loss: 0.6947 (Forecasting Loss:0.3712 + XiCon Loss:3.2350 x Lambda(0.1)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2808
Validation loss decreased (inf --> 0.323140).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.5944118
	speed: 0.0741s/iter; left time: 1906.2076s
	iters: 200, epoch: 2 | loss: 0.5871715
	speed: 0.1005s/iter; left time: 2576.6565s
Epoch: 2 cost time: 23.655272722244263
Epoch: 2, Steps: 261 Train Loss: 0.6010 (Forecasting Loss:0.2957 + XiCon Loss:3.0526 x Lambda(0.1)), Vali MSE Loss: 0.2955 Test MSE Loss: 0.2491
Validation loss decreased (0.323140 --> 0.295543).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.5798750
	speed: 0.1194s/iter; left time: 3041.0181s
	iters: 200, epoch: 3 | loss: 0.5876247
	speed: 0.1015s/iter; left time: 2575.3636s
Epoch: 3 cost time: 28.137837409973145
Epoch: 3, Steps: 261 Train Loss: 0.5812 (Forecasting Loss:0.2814 + XiCon Loss:2.9975 x Lambda(0.1)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2522
Validation loss decreased (0.295543 --> 0.294053).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5575071
	speed: 0.0805s/iter; left time: 2030.9383s
	iters: 200, epoch: 4 | loss: 0.5578750
	speed: 0.0551s/iter; left time: 1384.7117s
Epoch: 4 cost time: 16.633079290390015
Epoch: 4, Steps: 261 Train Loss: 0.5765 (Forecasting Loss:0.2773 + XiCon Loss:2.9922 x Lambda(0.1)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.2532
Validation loss decreased (0.294053 --> 0.293801).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5628018
	speed: 0.0481s/iter; left time: 1199.7303s
	iters: 200, epoch: 5 | loss: 0.5760510
	speed: 0.0444s/iter; left time: 1103.0124s
Epoch: 5 cost time: 12.038692712783813
Epoch: 5, Steps: 261 Train Loss: 0.5739 (Forecasting Loss:0.2751 + XiCon Loss:2.9884 x Lambda(0.1)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.2523
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5571295
	speed: 0.0480s/iter; left time: 1185.6423s
	iters: 200, epoch: 6 | loss: 0.5586240
	speed: 0.0459s/iter; left time: 1127.8218s
Epoch: 6 cost time: 12.237454414367676
Epoch: 6, Steps: 261 Train Loss: 0.5729 (Forecasting Loss:0.2742 + XiCon Loss:2.9862 x Lambda(0.1)), Vali MSE Loss: 0.2934 Test MSE Loss: 0.2509
Validation loss decreased (0.293801 --> 0.293433).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6162587
	speed: 0.0481s/iter; left time: 1176.5134s
	iters: 200, epoch: 7 | loss: 0.5731796
	speed: 0.0456s/iter; left time: 1110.7703s
Epoch: 7 cost time: 12.20982027053833
Epoch: 7, Steps: 261 Train Loss: 0.5718 (Forecasting Loss:0.2735 + XiCon Loss:2.9828 x Lambda(0.1)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.2521
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.5802910
	speed: 0.0470s/iter; left time: 1135.4006s
	iters: 200, epoch: 8 | loss: 0.5624473
	speed: 0.0447s/iter; left time: 1076.2510s
Epoch: 8 cost time: 12.08935284614563
Epoch: 8, Steps: 261 Train Loss: 0.5715 (Forecasting Loss:0.2733 + XiCon Loss:2.9819 x Lambda(0.1)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.2521
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5637336
	speed: 0.0512s/iter; left time: 1223.6512s
	iters: 200, epoch: 9 | loss: 0.5477672
	speed: 0.0484s/iter; left time: 1153.6498s
Epoch: 9 cost time: 12.998824119567871
Epoch: 9, Steps: 261 Train Loss: 0.5712 (Forecasting Loss:0.2732 + XiCon Loss:2.9797 x Lambda(0.1)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2521
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.5798934
	speed: 0.0514s/iter; left time: 1215.0386s
	iters: 200, epoch: 10 | loss: 0.5740057
	speed: 0.0488s/iter; left time: 1149.6299s
Epoch: 10 cost time: 12.983715295791626
Epoch: 10, Steps: 261 Train Loss: 0.5713 (Forecasting Loss:0.2732 + XiCon Loss:2.9813 x Lambda(0.1)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2520
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.5737255
	speed: 0.0513s/iter; left time: 1201.1078s
	iters: 200, epoch: 11 | loss: 0.6011403
	speed: 0.0489s/iter; left time: 1137.9952s
Epoch: 11 cost time: 13.006127119064331
Epoch: 11, Steps: 261 Train Loss: 0.5715 (Forecasting Loss:0.2732 + XiCon Loss:2.9825 x Lambda(0.1)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2521
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.5647197
	speed: 0.0509s/iter; left time: 1177.4646s
	iters: 200, epoch: 12 | loss: 0.5694081
	speed: 0.0491s/iter; left time: 1130.5147s
Epoch: 12 cost time: 12.976578712463379
Epoch: 12, Steps: 261 Train Loss: 0.5715 (Forecasting Loss:0.2732 + XiCon Loss:2.9836 x Lambda(0.1)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2521
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.5859988
	speed: 0.0503s/iter; left time: 1150.1930s
	iters: 200, epoch: 13 | loss: 0.5631884
	speed: 0.0495s/iter; left time: 1127.0271s
Epoch: 13 cost time: 12.986262321472168
Epoch: 13, Steps: 261 Train Loss: 0.5714 (Forecasting Loss:0.2731 + XiCon Loss:2.9835 x Lambda(0.1)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.2521
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.5625688
	speed: 0.0511s/iter; left time: 1155.8980s
	iters: 200, epoch: 14 | loss: 0.5628961
	speed: 0.0478s/iter; left time: 1075.3237s
Epoch: 14 cost time: 12.862438917160034
Epoch: 14, Steps: 261 Train Loss: 0.5714 (Forecasting Loss:0.2731 + XiCon Loss:2.9832 x Lambda(0.1)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.2521
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.5532441
	speed: 0.0506s/iter; left time: 1131.7835s
	iters: 200, epoch: 15 | loss: 0.5640315
	speed: 0.0480s/iter; left time: 1067.9236s
Epoch: 15 cost time: 12.804292678833008
Epoch: 15, Steps: 261 Train Loss: 0.5713 (Forecasting Loss:0.2731 + XiCon Loss:2.9822 x Lambda(0.1)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2521
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.5868820
	speed: 0.0496s/iter; left time: 1094.8310s
	iters: 200, epoch: 16 | loss: 0.5767891
	speed: 0.0488s/iter; left time: 1073.9419s
Epoch: 16 cost time: 12.910346031188965
Epoch: 16, Steps: 261 Train Loss: 0.5716 (Forecasting Loss:0.2732 + XiCon Loss:2.9845 x Lambda(0.1)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2521
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17461679875850677, mae:0.32718053460121155, mape:0.7482807040214539, mspe:20.807655334472656 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1772+-0.00279, MAE:0.3286+-0.00246, MAPE:0.7345+-0.01660, MSPE:19.9962+-1.05520, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
