Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5806
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.1291439533233643
Epoch: 1, Steps: 69 Train Loss: 2.1319 (Forecasting Loss:0.1324 + XiCon Loss:1.9995 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.285087).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8680074214935303
Epoch: 2, Steps: 69 Train Loss: 2.1074 (Forecasting Loss:0.1112 + XiCon Loss:1.9962 x Lambda(1.0)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.1226
Validation loss decreased (0.285087 --> 0.213917).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.7977986335754395
Epoch: 3, Steps: 69 Train Loss: 2.0951 (Forecasting Loss:0.1023 + XiCon Loss:1.9927 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1202
Validation loss decreased (0.213917 --> 0.209112).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8582601547241211
Epoch: 4, Steps: 69 Train Loss: 2.0850 (Forecasting Loss:0.1006 + XiCon Loss:1.9844 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1191
Validation loss decreased (0.209112 --> 0.207550).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8318476676940918
Epoch: 5, Steps: 69 Train Loss: 2.0815 (Forecasting Loss:0.1000 + XiCon Loss:1.9815 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1187
Validation loss decreased (0.207550 --> 0.206675).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.798969030380249
Epoch: 6, Steps: 69 Train Loss: 2.0800 (Forecasting Loss:0.0998 + XiCon Loss:1.9802 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1184
Validation loss decreased (0.206675 --> 0.206422).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8150429725646973
Epoch: 7, Steps: 69 Train Loss: 2.0814 (Forecasting Loss:0.0996 + XiCon Loss:1.9818 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1182
Validation loss decreased (0.206422 --> 0.206226).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8935277462005615
Epoch: 8, Steps: 69 Train Loss: 2.0757 (Forecasting Loss:0.0996 + XiCon Loss:1.9761 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1181
Validation loss decreased (0.206226 --> 0.206186).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8551883697509766
Epoch: 9, Steps: 69 Train Loss: 2.0734 (Forecasting Loss:0.0997 + XiCon Loss:1.9738 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206186 --> 0.206142).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8906829357147217
Epoch: 10, Steps: 69 Train Loss: 2.0794 (Forecasting Loss:0.0996 + XiCon Loss:1.9798 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206142 --> 0.206120).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8629300594329834
Epoch: 11, Steps: 69 Train Loss: 2.0754 (Forecasting Loss:0.0996 + XiCon Loss:1.9759 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206120 --> 0.206112).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8286330699920654
Epoch: 12, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.0993 + XiCon Loss:1.9741 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206112 --> 0.206106).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.866788387298584
Epoch: 13, Steps: 69 Train Loss: 2.0773 (Forecasting Loss:0.0994 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206106 --> 0.206102).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8567507266998291
Epoch: 14, Steps: 69 Train Loss: 2.0768 (Forecasting Loss:0.0996 + XiCon Loss:1.9772 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206102 --> 0.206101).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9036617279052734
Epoch: 15, Steps: 69 Train Loss: 2.0755 (Forecasting Loss:0.0996 + XiCon Loss:1.9759 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206101 --> 0.206101).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8460755348205566
Epoch: 16, Steps: 69 Train Loss: 2.0762 (Forecasting Loss:0.0995 + XiCon Loss:1.9768 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206101 --> 0.206100).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8442072868347168
Epoch: 17, Steps: 69 Train Loss: 2.0737 (Forecasting Loss:0.0995 + XiCon Loss:1.9742 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8580639362335205
Epoch: 18, Steps: 69 Train Loss: 2.0771 (Forecasting Loss:0.0995 + XiCon Loss:1.9776 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8745367527008057
Epoch: 19, Steps: 69 Train Loss: 2.0754 (Forecasting Loss:0.0994 + XiCon Loss:1.9760 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8146812915802002
Epoch: 20, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.0998 + XiCon Loss:1.9788 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9149913787841797
Epoch: 21, Steps: 69 Train Loss: 2.0765 (Forecasting Loss:0.0995 + XiCon Loss:1.9770 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9231221675872803
Epoch: 22, Steps: 69 Train Loss: 2.0727 (Forecasting Loss:0.0996 + XiCon Loss:1.9731 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.771296501159668
Epoch: 23, Steps: 69 Train Loss: 2.0768 (Forecasting Loss:0.0996 + XiCon Loss:1.9771 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8393287658691406
Epoch: 24, Steps: 69 Train Loss: 2.0752 (Forecasting Loss:0.0992 + XiCon Loss:1.9760 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.7948784828186035
Epoch: 25, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.0995 + XiCon Loss:1.9793 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8184990882873535
Epoch: 26, Steps: 69 Train Loss: 2.0766 (Forecasting Loss:0.0993 + XiCon Loss:1.9772 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.7979865074157715
Epoch: 27, Steps: 69 Train Loss: 2.0766 (Forecasting Loss:0.0996 + XiCon Loss:1.9770 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8784334659576416
Epoch: 28, Steps: 69 Train Loss: 2.0777 (Forecasting Loss:0.0995 + XiCon Loss:1.9782 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8655116558074951
Epoch: 29, Steps: 69 Train Loss: 2.0740 (Forecasting Loss:0.0995 + XiCon Loss:1.9745 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.89396071434021
Epoch: 30, Steps: 69 Train Loss: 2.0745 (Forecasting Loss:0.0996 + XiCon Loss:1.9749 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8418982028961182
Epoch: 31, Steps: 69 Train Loss: 2.0747 (Forecasting Loss:0.0995 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
Validation loss decreased (0.206100 --> 0.206100).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8635711669921875
Epoch: 32, Steps: 69 Train Loss: 2.0775 (Forecasting Loss:0.0997 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8642544746398926
Epoch: 33, Steps: 69 Train Loss: 2.0765 (Forecasting Loss:0.0996 + XiCon Loss:1.9769 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8287744522094727
Epoch: 34, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.0994 + XiCon Loss:1.9741 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8325908184051514
Epoch: 35, Steps: 69 Train Loss: 2.0768 (Forecasting Loss:0.0996 + XiCon Loss:1.9771 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8479738235473633
Epoch: 36, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.0995 + XiCon Loss:1.9734 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8482141494750977
Epoch: 37, Steps: 69 Train Loss: 2.0770 (Forecasting Loss:0.0995 + XiCon Loss:1.9774 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8038473129272461
Epoch: 38, Steps: 69 Train Loss: 2.0753 (Forecasting Loss:0.0994 + XiCon Loss:1.9759 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8614847660064697
Epoch: 39, Steps: 69 Train Loss: 2.0766 (Forecasting Loss:0.0996 + XiCon Loss:1.9769 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8529260158538818
Epoch: 40, Steps: 69 Train Loss: 2.0765 (Forecasting Loss:0.0994 + XiCon Loss:1.9771 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8462464809417725
Epoch: 41, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.0996 + XiCon Loss:1.9734 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1180
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05575896427035332, mae:0.18025346100330353, mape:0.12639527022838593, mspe:0.037649642676115036 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5587
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.863445520401001
Epoch: 1, Steps: 69 Train Loss: 2.1333 (Forecasting Loss:0.1337 + XiCon Loss:1.9996 x Lambda(1.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.1507
Validation loss decreased (inf --> 0.288228).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8856453895568848
Epoch: 2, Steps: 69 Train Loss: 2.1082 (Forecasting Loss:0.1120 + XiCon Loss:1.9963 x Lambda(1.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1209
Validation loss decreased (0.288228 --> 0.214948).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9244177341461182
Epoch: 3, Steps: 69 Train Loss: 2.0925 (Forecasting Loss:0.1029 + XiCon Loss:1.9895 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1188
Validation loss decreased (0.214948 --> 0.210232).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8146517276763916
Epoch: 4, Steps: 69 Train Loss: 2.0807 (Forecasting Loss:0.1013 + XiCon Loss:1.9794 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1182
Validation loss decreased (0.210232 --> 0.208715).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.817551851272583
Epoch: 5, Steps: 69 Train Loss: 2.0749 (Forecasting Loss:0.1004 + XiCon Loss:1.9745 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1180
Validation loss decreased (0.208715 --> 0.207769).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8526871204376221
Epoch: 6, Steps: 69 Train Loss: 2.0742 (Forecasting Loss:0.1004 + XiCon Loss:1.9738 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1179
Validation loss decreased (0.207769 --> 0.207258).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.81142258644104
Epoch: 7, Steps: 69 Train Loss: 2.0714 (Forecasting Loss:0.1001 + XiCon Loss:1.9714 x Lambda(1.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.1178
Validation loss decreased (0.207258 --> 0.206992).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.981196403503418
Epoch: 8, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.1001 + XiCon Loss:1.9785 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1177
Validation loss decreased (0.206992 --> 0.206911).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8374342918395996
Epoch: 9, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.1001 + XiCon Loss:1.9734 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1177
Validation loss decreased (0.206911 --> 0.206881).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.7979001998901367
Epoch: 10, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.1000 + XiCon Loss:1.9730 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206881 --> 0.206847).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8116841316223145
Epoch: 11, Steps: 69 Train Loss: 2.0719 (Forecasting Loss:0.1002 + XiCon Loss:1.9717 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206847 --> 0.206833).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8709511756896973
Epoch: 12, Steps: 69 Train Loss: 2.0764 (Forecasting Loss:0.0997 + XiCon Loss:1.9767 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206833 --> 0.206825).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.839667558670044
Epoch: 13, Steps: 69 Train Loss: 2.0765 (Forecasting Loss:0.0999 + XiCon Loss:1.9766 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206825 --> 0.206821).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8143811225891113
Epoch: 14, Steps: 69 Train Loss: 2.0731 (Forecasting Loss:0.0999 + XiCon Loss:1.9731 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206821 --> 0.206819).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8120529651641846
Epoch: 15, Steps: 69 Train Loss: 2.0764 (Forecasting Loss:0.1000 + XiCon Loss:1.9764 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206819 --> 0.206818).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8544747829437256
Epoch: 16, Steps: 69 Train Loss: 2.0751 (Forecasting Loss:0.0999 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206818 --> 0.206817).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8126025199890137
Epoch: 17, Steps: 69 Train Loss: 2.0717 (Forecasting Loss:0.1002 + XiCon Loss:1.9716 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.7964158058166504
Epoch: 18, Steps: 69 Train Loss: 2.0728 (Forecasting Loss:0.1000 + XiCon Loss:1.9729 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8184123039245605
Epoch: 19, Steps: 69 Train Loss: 2.0745 (Forecasting Loss:0.1001 + XiCon Loss:1.9744 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9062058925628662
Epoch: 20, Steps: 69 Train Loss: 2.0728 (Forecasting Loss:0.1002 + XiCon Loss:1.9726 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8208508491516113
Epoch: 21, Steps: 69 Train Loss: 2.0745 (Forecasting Loss:0.0999 + XiCon Loss:1.9745 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.846843957901001
Epoch: 22, Steps: 69 Train Loss: 2.0754 (Forecasting Loss:0.1002 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.7858641147613525
Epoch: 23, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.0998 + XiCon Loss:1.9732 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.844109058380127
Epoch: 24, Steps: 69 Train Loss: 2.0746 (Forecasting Loss:0.1000 + XiCon Loss:1.9745 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8634655475616455
Epoch: 25, Steps: 69 Train Loss: 2.0742 (Forecasting Loss:0.0998 + XiCon Loss:1.9744 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.0101423263549805
Epoch: 26, Steps: 69 Train Loss: 2.0728 (Forecasting Loss:0.0999 + XiCon Loss:1.9729 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8161783218383789
Epoch: 27, Steps: 69 Train Loss: 2.0750 (Forecasting Loss:0.1000 + XiCon Loss:1.9750 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8066837787628174
Epoch: 28, Steps: 69 Train Loss: 2.0733 (Forecasting Loss:0.1000 + XiCon Loss:1.9733 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8239805698394775
Epoch: 29, Steps: 69 Train Loss: 2.0750 (Forecasting Loss:0.0998 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.7946851253509521
Epoch: 30, Steps: 69 Train Loss: 2.0752 (Forecasting Loss:0.0996 + XiCon Loss:1.9755 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8344993591308594
Epoch: 31, Steps: 69 Train Loss: 2.0749 (Forecasting Loss:0.1000 + XiCon Loss:1.9749 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8309512138366699
Epoch: 32, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.0999 + XiCon Loss:1.9736 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8591442108154297
Epoch: 33, Steps: 69 Train Loss: 2.0722 (Forecasting Loss:0.1001 + XiCon Loss:1.9721 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8287897109985352
Epoch: 34, Steps: 69 Train Loss: 2.0733 (Forecasting Loss:0.1001 + XiCon Loss:1.9732 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8230905532836914
Epoch: 35, Steps: 69 Train Loss: 2.0724 (Forecasting Loss:0.1000 + XiCon Loss:1.9724 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.897864580154419
Epoch: 36, Steps: 69 Train Loss: 2.0725 (Forecasting Loss:0.0999 + XiCon Loss:1.9727 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
Validation loss decreased (0.206817 --> 0.206817).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8201615810394287
Epoch: 37, Steps: 69 Train Loss: 2.0758 (Forecasting Loss:0.0999 + XiCon Loss:1.9758 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8707869052886963
Epoch: 38, Steps: 69 Train Loss: 2.0762 (Forecasting Loss:0.1001 + XiCon Loss:1.9761 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8337409496307373
Epoch: 39, Steps: 69 Train Loss: 2.0722 (Forecasting Loss:0.0999 + XiCon Loss:1.9723 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8237142562866211
Epoch: 40, Steps: 69 Train Loss: 2.0744 (Forecasting Loss:0.0998 + XiCon Loss:1.9746 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8726983070373535
Epoch: 41, Steps: 69 Train Loss: 2.0734 (Forecasting Loss:0.0999 + XiCon Loss:1.9735 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8005785942077637
Epoch: 42, Steps: 69 Train Loss: 2.0763 (Forecasting Loss:0.0999 + XiCon Loss:1.9764 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.831000566482544
Epoch: 43, Steps: 69 Train Loss: 2.0750 (Forecasting Loss:0.1000 + XiCon Loss:1.9751 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8497228622436523
Epoch: 44, Steps: 69 Train Loss: 2.0760 (Forecasting Loss:0.0998 + XiCon Loss:1.9762 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8079602718353271
Epoch: 45, Steps: 69 Train Loss: 2.0753 (Forecasting Loss:0.1000 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8306806087493896
Epoch: 46, Steps: 69 Train Loss: 2.0753 (Forecasting Loss:0.0999 + XiCon Loss:1.9755 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1177
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05545105040073395, mae:0.17996729910373688, mape:0.12528882920742035, mspe:0.03640863671898842 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5692
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8434567451477051
Epoch: 1, Steps: 69 Train Loss: 2.1317 (Forecasting Loss:0.1333 + XiCon Loss:1.9984 x Lambda(1.0)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.1474
Validation loss decreased (inf --> 0.285459).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8284180164337158
Epoch: 2, Steps: 69 Train Loss: 2.1032 (Forecasting Loss:0.1126 + XiCon Loss:1.9905 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1212
Validation loss decreased (0.285459 --> 0.214205).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8784301280975342
Epoch: 3, Steps: 69 Train Loss: 2.0813 (Forecasting Loss:0.1028 + XiCon Loss:1.9785 x Lambda(1.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1191
Validation loss decreased (0.214205 --> 0.209335).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8610293865203857
Epoch: 4, Steps: 69 Train Loss: 2.0741 (Forecasting Loss:0.1007 + XiCon Loss:1.9735 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1185
Validation loss decreased (0.209335 --> 0.207194).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.786717414855957
Epoch: 5, Steps: 69 Train Loss: 2.0767 (Forecasting Loss:0.1006 + XiCon Loss:1.9761 x Lambda(1.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.207194 --> 0.205968).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8723499774932861
Epoch: 6, Steps: 69 Train Loss: 2.0703 (Forecasting Loss:0.1001 + XiCon Loss:1.9702 x Lambda(1.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1180
Validation loss decreased (0.205968 --> 0.205520).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8225781917572021
Epoch: 7, Steps: 69 Train Loss: 2.0708 (Forecasting Loss:0.0999 + XiCon Loss:1.9708 x Lambda(1.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1179
Validation loss decreased (0.205520 --> 0.205343).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8388381004333496
Epoch: 8, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.0999 + XiCon Loss:1.9736 x Lambda(1.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1178
Validation loss decreased (0.205343 --> 0.205263).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8768966197967529
Epoch: 9, Steps: 69 Train Loss: 2.0692 (Forecasting Loss:0.0994 + XiCon Loss:1.9698 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1178
Validation loss decreased (0.205263 --> 0.205199).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8640375137329102
Epoch: 10, Steps: 69 Train Loss: 2.0717 (Forecasting Loss:0.0998 + XiCon Loss:1.9719 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1178
Validation loss decreased (0.205199 --> 0.205169).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8530514240264893
Epoch: 11, Steps: 69 Train Loss: 2.0722 (Forecasting Loss:0.0997 + XiCon Loss:1.9725 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205169 --> 0.205149).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.89691162109375
Epoch: 12, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.0996 + XiCon Loss:1.9733 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205149 --> 0.205144).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9026341438293457
Epoch: 13, Steps: 69 Train Loss: 2.0767 (Forecasting Loss:0.0999 + XiCon Loss:1.9769 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205144 --> 0.205140).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8208537101745605
Epoch: 14, Steps: 69 Train Loss: 2.0701 (Forecasting Loss:0.0996 + XiCon Loss:1.9704 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205140 --> 0.205138).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8709218502044678
Epoch: 15, Steps: 69 Train Loss: 2.0722 (Forecasting Loss:0.0997 + XiCon Loss:1.9725 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205138 --> 0.205137).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.7782449722290039
Epoch: 16, Steps: 69 Train Loss: 2.0704 (Forecasting Loss:0.0998 + XiCon Loss:1.9706 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205137 --> 0.205136).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.91493821144104
Epoch: 17, Steps: 69 Train Loss: 2.0736 (Forecasting Loss:0.0997 + XiCon Loss:1.9739 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8804540634155273
Epoch: 18, Steps: 69 Train Loss: 2.0709 (Forecasting Loss:0.0997 + XiCon Loss:1.9713 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8380365371704102
Epoch: 19, Steps: 69 Train Loss: 2.0713 (Forecasting Loss:0.0996 + XiCon Loss:1.9717 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8240478038787842
Epoch: 20, Steps: 69 Train Loss: 2.0703 (Forecasting Loss:0.0997 + XiCon Loss:1.9705 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8953866958618164
Epoch: 21, Steps: 69 Train Loss: 2.0703 (Forecasting Loss:0.0997 + XiCon Loss:1.9705 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8739211559295654
Epoch: 22, Steps: 69 Train Loss: 2.0689 (Forecasting Loss:0.0997 + XiCon Loss:1.9692 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.952345609664917
Epoch: 23, Steps: 69 Train Loss: 2.0719 (Forecasting Loss:0.0996 + XiCon Loss:1.9723 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8600883483886719
Epoch: 24, Steps: 69 Train Loss: 2.0675 (Forecasting Loss:0.0996 + XiCon Loss:1.9680 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8046414852142334
Epoch: 25, Steps: 69 Train Loss: 2.0721 (Forecasting Loss:0.0995 + XiCon Loss:1.9726 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8023326396942139
Epoch: 26, Steps: 69 Train Loss: 2.0740 (Forecasting Loss:0.0995 + XiCon Loss:1.9745 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8080759048461914
Epoch: 27, Steps: 69 Train Loss: 2.0710 (Forecasting Loss:0.0999 + XiCon Loss:1.9711 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8254544734954834
Epoch: 28, Steps: 69 Train Loss: 2.0714 (Forecasting Loss:0.0997 + XiCon Loss:1.9717 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8461043834686279
Epoch: 29, Steps: 69 Train Loss: 2.0734 (Forecasting Loss:0.0995 + XiCon Loss:1.9739 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8603816032409668
Epoch: 30, Steps: 69 Train Loss: 2.0735 (Forecasting Loss:0.0998 + XiCon Loss:1.9737 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8990612030029297
Epoch: 31, Steps: 69 Train Loss: 2.0685 (Forecasting Loss:0.0998 + XiCon Loss:1.9687 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8896970748901367
Epoch: 32, Steps: 69 Train Loss: 2.0720 (Forecasting Loss:0.0996 + XiCon Loss:1.9724 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8193883895874023
Epoch: 33, Steps: 69 Train Loss: 2.0731 (Forecasting Loss:0.0996 + XiCon Loss:1.9735 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8564605712890625
Epoch: 34, Steps: 69 Train Loss: 2.0705 (Forecasting Loss:0.0998 + XiCon Loss:1.9707 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8392553329467773
Epoch: 35, Steps: 69 Train Loss: 2.0699 (Forecasting Loss:0.0996 + XiCon Loss:1.9703 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8355019092559814
Epoch: 36, Steps: 69 Train Loss: 2.0681 (Forecasting Loss:0.0998 + XiCon Loss:1.9683 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8153233528137207
Epoch: 37, Steps: 69 Train Loss: 2.0726 (Forecasting Loss:0.0999 + XiCon Loss:1.9727 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9376928806304932
Epoch: 38, Steps: 69 Train Loss: 2.0699 (Forecasting Loss:0.0997 + XiCon Loss:1.9703 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8775119781494141
Epoch: 39, Steps: 69 Train Loss: 2.0695 (Forecasting Loss:0.0994 + XiCon Loss:1.9701 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8964054584503174
Epoch: 40, Steps: 69 Train Loss: 2.0728 (Forecasting Loss:0.0998 + XiCon Loss:1.9731 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8400821685791016
Epoch: 41, Steps: 69 Train Loss: 2.0756 (Forecasting Loss:0.0995 + XiCon Loss:1.9761 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.842501163482666
Epoch: 42, Steps: 69 Train Loss: 2.0727 (Forecasting Loss:0.0997 + XiCon Loss:1.9730 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8657660484313965
Epoch: 43, Steps: 69 Train Loss: 2.0712 (Forecasting Loss:0.0996 + XiCon Loss:1.9716 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8918890953063965
Epoch: 44, Steps: 69 Train Loss: 2.0737 (Forecasting Loss:0.0997 + XiCon Loss:1.9740 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.785114049911499
Epoch: 45, Steps: 69 Train Loss: 2.0707 (Forecasting Loss:0.0995 + XiCon Loss:1.9711 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8012878894805908
Epoch: 46, Steps: 69 Train Loss: 2.0727 (Forecasting Loss:0.0997 + XiCon Loss:1.9729 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8989861011505127
Epoch: 47, Steps: 69 Train Loss: 2.0697 (Forecasting Loss:0.0996 + XiCon Loss:1.9701 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8335747718811035
Epoch: 48, Steps: 69 Train Loss: 2.0701 (Forecasting Loss:0.0995 + XiCon Loss:1.9706 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.820420503616333
Epoch: 49, Steps: 69 Train Loss: 2.0755 (Forecasting Loss:0.0997 + XiCon Loss:1.9758 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8025996685028076
Epoch: 50, Steps: 69 Train Loss: 2.0738 (Forecasting Loss:0.0995 + XiCon Loss:1.9744 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.882110595703125
Epoch: 51, Steps: 69 Train Loss: 2.0712 (Forecasting Loss:0.0997 + XiCon Loss:1.9715 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.8136270046234131
Epoch: 52, Steps: 69 Train Loss: 2.0717 (Forecasting Loss:0.0995 + XiCon Loss:1.9722 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8157422542572021
Epoch: 53, Steps: 69 Train Loss: 2.0717 (Forecasting Loss:0.0997 + XiCon Loss:1.9721 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.9181308746337891
Epoch: 54, Steps: 69 Train Loss: 2.0754 (Forecasting Loss:0.0997 + XiCon Loss:1.9757 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.8829131126403809
Epoch: 55, Steps: 69 Train Loss: 2.0742 (Forecasting Loss:0.0996 + XiCon Loss:1.9747 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8696949481964111
Epoch: 56, Steps: 69 Train Loss: 2.0714 (Forecasting Loss:0.0994 + XiCon Loss:1.9720 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.7949409484863281
Epoch: 57, Steps: 69 Train Loss: 2.0751 (Forecasting Loss:0.0999 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8288729190826416
Epoch: 58, Steps: 69 Train Loss: 2.0707 (Forecasting Loss:0.0998 + XiCon Loss:1.9710 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.9204461574554443
Epoch: 59, Steps: 69 Train Loss: 2.0730 (Forecasting Loss:0.0996 + XiCon Loss:1.9734 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.8688256740570068
Epoch: 60, Steps: 69 Train Loss: 2.0703 (Forecasting Loss:0.0998 + XiCon Loss:1.9705 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.883681058883667
Epoch: 61, Steps: 69 Train Loss: 2.0687 (Forecasting Loss:0.0996 + XiCon Loss:1.9691 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.8511364459991455
Epoch: 62, Steps: 69 Train Loss: 2.0702 (Forecasting Loss:0.0995 + XiCon Loss:1.9707 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.9102098941802979
Epoch: 63, Steps: 69 Train Loss: 2.0745 (Forecasting Loss:0.0995 + XiCon Loss:1.9749 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.8504288196563721
Epoch: 64, Steps: 69 Train Loss: 2.0741 (Forecasting Loss:0.0999 + XiCon Loss:1.9742 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.8794112205505371
Epoch: 65, Steps: 69 Train Loss: 2.0744 (Forecasting Loss:0.0998 + XiCon Loss:1.9746 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.9388043880462646
Epoch: 66, Steps: 69 Train Loss: 2.0690 (Forecasting Loss:0.0996 + XiCon Loss:1.9695 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.8596415519714355
Epoch: 67, Steps: 69 Train Loss: 2.0709 (Forecasting Loss:0.0998 + XiCon Loss:1.9711 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 1.1338229179382324
Epoch: 68, Steps: 69 Train Loss: 2.0721 (Forecasting Loss:0.0996 + XiCon Loss:1.9725 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.8171653747558594
Epoch: 69, Steps: 69 Train Loss: 2.0726 (Forecasting Loss:0.0997 + XiCon Loss:1.9729 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.9073224067687988
Epoch: 70, Steps: 69 Train Loss: 2.0744 (Forecasting Loss:0.0995 + XiCon Loss:1.9749 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.9149219989776611
Epoch: 71, Steps: 69 Train Loss: 2.0746 (Forecasting Loss:0.0995 + XiCon Loss:1.9751 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.8295786380767822
Epoch: 72, Steps: 69 Train Loss: 2.0720 (Forecasting Loss:0.0995 + XiCon Loss:1.9724 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.8469676971435547
Epoch: 73, Steps: 69 Train Loss: 2.0707 (Forecasting Loss:0.0995 + XiCon Loss:1.9711 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.891157865524292
Epoch: 74, Steps: 69 Train Loss: 2.0745 (Forecasting Loss:0.0996 + XiCon Loss:1.9749 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.8081910610198975
Epoch: 75, Steps: 69 Train Loss: 2.0701 (Forecasting Loss:0.0996 + XiCon Loss:1.9705 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.8960411548614502
Epoch: 76, Steps: 69 Train Loss: 2.0712 (Forecasting Loss:0.0996 + XiCon Loss:1.9716 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.7705721855163574
Epoch: 77, Steps: 69 Train Loss: 2.0721 (Forecasting Loss:0.0994 + XiCon Loss:1.9727 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.8103697299957275
Epoch: 78, Steps: 69 Train Loss: 2.0732 (Forecasting Loss:0.1000 + XiCon Loss:1.9732 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
Validation loss decreased (0.205136 --> 0.205136).  Saving model ...
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.8395881652832031
Epoch: 79, Steps: 69 Train Loss: 2.0712 (Forecasting Loss:0.0997 + XiCon Loss:1.9715 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.8005166053771973
Epoch: 80, Steps: 69 Train Loss: 2.0739 (Forecasting Loss:0.0996 + XiCon Loss:1.9742 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.8285722732543945
Epoch: 81, Steps: 69 Train Loss: 2.0699 (Forecasting Loss:0.0997 + XiCon Loss:1.9701 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8576443195343018
Epoch: 82, Steps: 69 Train Loss: 2.0731 (Forecasting Loss:0.0996 + XiCon Loss:1.9735 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.8186988830566406
Epoch: 83, Steps: 69 Train Loss: 2.0702 (Forecasting Loss:0.0995 + XiCon Loss:1.9706 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.86224365234375
Epoch: 84, Steps: 69 Train Loss: 2.0733 (Forecasting Loss:0.0997 + XiCon Loss:1.9736 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.8306593894958496
Epoch: 85, Steps: 69 Train Loss: 2.0726 (Forecasting Loss:0.0993 + XiCon Loss:1.9734 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.8507535457611084
Epoch: 86, Steps: 69 Train Loss: 2.0710 (Forecasting Loss:0.0997 + XiCon Loss:1.9712 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.7591273784637451
Epoch: 87, Steps: 69 Train Loss: 2.0677 (Forecasting Loss:0.0996 + XiCon Loss:1.9681 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.8382217884063721
Epoch: 88, Steps: 69 Train Loss: 2.0738 (Forecasting Loss:0.0997 + XiCon Loss:1.9741 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1178
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05551276355981827, mae:0.18005810678005219, mape:0.12571538984775543, mspe:0.0368645042181015 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5565
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8423399925231934
Epoch: 1, Steps: 69 Train Loss: 2.1304 (Forecasting Loss:0.1335 + XiCon Loss:1.9969 x Lambda(1.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.1525
Validation loss decreased (inf --> 0.287481).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7854630947113037
Epoch: 2, Steps: 69 Train Loss: 2.1054 (Forecasting Loss:0.1117 + XiCon Loss:1.9937 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1217
Validation loss decreased (0.287481 --> 0.213709).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.871492862701416
Epoch: 3, Steps: 69 Train Loss: 2.0870 (Forecasting Loss:0.1025 + XiCon Loss:1.9845 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1193
Validation loss decreased (0.213709 --> 0.210232).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8777153491973877
Epoch: 4, Steps: 69 Train Loss: 2.0825 (Forecasting Loss:0.1011 + XiCon Loss:1.9814 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1187
Validation loss decreased (0.210232 --> 0.208368).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.7531032562255859
Epoch: 5, Steps: 69 Train Loss: 2.0777 (Forecasting Loss:0.1005 + XiCon Loss:1.9771 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1183
Validation loss decreased (0.208368 --> 0.207691).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9429061412811279
Epoch: 6, Steps: 69 Train Loss: 2.0764 (Forecasting Loss:0.1002 + XiCon Loss:1.9762 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1182
Validation loss decreased (0.207691 --> 0.207372).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.855579137802124
Epoch: 7, Steps: 69 Train Loss: 2.0787 (Forecasting Loss:0.0999 + XiCon Loss:1.9788 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1181
Validation loss decreased (0.207372 --> 0.207230).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8104984760284424
Epoch: 8, Steps: 69 Train Loss: 2.0781 (Forecasting Loss:0.1000 + XiCon Loss:1.9781 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1180
Validation loss decreased (0.207230 --> 0.207199).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8046677112579346
Epoch: 9, Steps: 69 Train Loss: 2.0771 (Forecasting Loss:0.0999 + XiCon Loss:1.9772 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1180
Validation loss decreased (0.207199 --> 0.207175).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9423260688781738
Epoch: 10, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.1000 + XiCon Loss:1.9786 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207175 --> 0.207145).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8464257717132568
Epoch: 11, Steps: 69 Train Loss: 2.0822 (Forecasting Loss:0.1000 + XiCon Loss:1.9822 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207145 --> 0.207140).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.864124059677124
Epoch: 12, Steps: 69 Train Loss: 2.0789 (Forecasting Loss:0.0999 + XiCon Loss:1.9791 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207140 --> 0.207137).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.811161994934082
Epoch: 13, Steps: 69 Train Loss: 2.0793 (Forecasting Loss:0.1001 + XiCon Loss:1.9792 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207137 --> 0.207134).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9034883975982666
Epoch: 14, Steps: 69 Train Loss: 2.0812 (Forecasting Loss:0.0999 + XiCon Loss:1.9812 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207134 --> 0.207134).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8400633335113525
Epoch: 15, Steps: 69 Train Loss: 2.0787 (Forecasting Loss:0.0999 + XiCon Loss:1.9789 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207134 --> 0.207133).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8725295066833496
Epoch: 16, Steps: 69 Train Loss: 2.0772 (Forecasting Loss:0.1000 + XiCon Loss:1.9772 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207133 --> 0.207133).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8445444107055664
Epoch: 17, Steps: 69 Train Loss: 2.0843 (Forecasting Loss:0.1000 + XiCon Loss:1.9843 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207133 --> 0.207132).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8646607398986816
Epoch: 18, Steps: 69 Train Loss: 2.0783 (Forecasting Loss:0.0999 + XiCon Loss:1.9784 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8931701183319092
Epoch: 19, Steps: 69 Train Loss: 2.0780 (Forecasting Loss:0.0997 + XiCon Loss:1.9783 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8739891052246094
Epoch: 20, Steps: 69 Train Loss: 2.0784 (Forecasting Loss:0.1000 + XiCon Loss:1.9784 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8580341339111328
Epoch: 21, Steps: 69 Train Loss: 2.0781 (Forecasting Loss:0.1000 + XiCon Loss:1.9781 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8319573402404785
Epoch: 22, Steps: 69 Train Loss: 2.0805 (Forecasting Loss:0.1001 + XiCon Loss:1.9804 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9002254009246826
Epoch: 23, Steps: 69 Train Loss: 2.0793 (Forecasting Loss:0.0999 + XiCon Loss:1.9794 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8693222999572754
Epoch: 24, Steps: 69 Train Loss: 2.0787 (Forecasting Loss:0.0999 + XiCon Loss:1.9787 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8439364433288574
Epoch: 25, Steps: 69 Train Loss: 2.0762 (Forecasting Loss:0.1000 + XiCon Loss:1.9762 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.931342601776123
Epoch: 26, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.1000 + XiCon Loss:1.9788 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8495638370513916
Epoch: 27, Steps: 69 Train Loss: 2.0781 (Forecasting Loss:0.1001 + XiCon Loss:1.9781 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8861796855926514
Epoch: 28, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.1000 + XiCon Loss:1.9786 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8845808506011963
Epoch: 29, Steps: 69 Train Loss: 2.0797 (Forecasting Loss:0.0997 + XiCon Loss:1.9800 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8700358867645264
Epoch: 30, Steps: 69 Train Loss: 2.0806 (Forecasting Loss:0.1000 + XiCon Loss:1.9806 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.7917325496673584
Epoch: 31, Steps: 69 Train Loss: 2.0817 (Forecasting Loss:0.1002 + XiCon Loss:1.9815 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8370356559753418
Epoch: 32, Steps: 69 Train Loss: 2.0792 (Forecasting Loss:0.0999 + XiCon Loss:1.9793 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8371386528015137
Epoch: 33, Steps: 69 Train Loss: 2.0742 (Forecasting Loss:0.0999 + XiCon Loss:1.9743 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.840843677520752
Epoch: 34, Steps: 69 Train Loss: 2.0795 (Forecasting Loss:0.0999 + XiCon Loss:1.9796 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.7812504768371582
Epoch: 35, Steps: 69 Train Loss: 2.0808 (Forecasting Loss:0.0998 + XiCon Loss:1.9809 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8359544277191162
Epoch: 36, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.1002 + XiCon Loss:1.9786 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8485743999481201
Epoch: 37, Steps: 69 Train Loss: 2.0725 (Forecasting Loss:0.0998 + XiCon Loss:1.9727 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8105323314666748
Epoch: 38, Steps: 69 Train Loss: 2.0795 (Forecasting Loss:0.1001 + XiCon Loss:1.9793 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8901717662811279
Epoch: 39, Steps: 69 Train Loss: 2.0818 (Forecasting Loss:0.1001 + XiCon Loss:1.9817 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8482933044433594
Epoch: 40, Steps: 69 Train Loss: 2.0796 (Forecasting Loss:0.1002 + XiCon Loss:1.9794 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8146347999572754
Epoch: 41, Steps: 69 Train Loss: 2.0769 (Forecasting Loss:0.1000 + XiCon Loss:1.9769 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8735485076904297
Epoch: 42, Steps: 69 Train Loss: 2.0775 (Forecasting Loss:0.0996 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9249987602233887
Epoch: 43, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.1000 + XiCon Loss:1.9787 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.840700626373291
Epoch: 44, Steps: 69 Train Loss: 2.0795 (Forecasting Loss:0.1001 + XiCon Loss:1.9794 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8618617057800293
Epoch: 45, Steps: 69 Train Loss: 2.0811 (Forecasting Loss:0.0999 + XiCon Loss:1.9811 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8696627616882324
Epoch: 46, Steps: 69 Train Loss: 2.0806 (Forecasting Loss:0.0998 + XiCon Loss:1.9808 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8672971725463867
Epoch: 47, Steps: 69 Train Loss: 2.0811 (Forecasting Loss:0.0997 + XiCon Loss:1.9814 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8690671920776367
Epoch: 48, Steps: 69 Train Loss: 2.0817 (Forecasting Loss:0.1002 + XiCon Loss:1.9815 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8805205821990967
Epoch: 49, Steps: 69 Train Loss: 2.0818 (Forecasting Loss:0.1001 + XiCon Loss:1.9817 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8960187435150146
Epoch: 50, Steps: 69 Train Loss: 2.0756 (Forecasting Loss:0.0999 + XiCon Loss:1.9757 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.8206202983856201
Epoch: 51, Steps: 69 Train Loss: 2.0810 (Forecasting Loss:0.0999 + XiCon Loss:1.9811 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.8216173648834229
Epoch: 52, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.0998 + XiCon Loss:1.9789 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.9151620864868164
Epoch: 53, Steps: 69 Train Loss: 2.0790 (Forecasting Loss:0.0998 + XiCon Loss:1.9792 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8150615692138672
Epoch: 54, Steps: 69 Train Loss: 2.0779 (Forecasting Loss:0.1002 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.8876290321350098
Epoch: 55, Steps: 69 Train Loss: 2.0771 (Forecasting Loss:0.1000 + XiCon Loss:1.9771 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8373138904571533
Epoch: 56, Steps: 69 Train Loss: 2.0798 (Forecasting Loss:0.1000 + XiCon Loss:1.9798 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.9580473899841309
Epoch: 57, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.1000 + XiCon Loss:1.9786 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8126068115234375
Epoch: 58, Steps: 69 Train Loss: 2.0776 (Forecasting Loss:0.0998 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.8756442070007324
Epoch: 59, Steps: 69 Train Loss: 2.0787 (Forecasting Loss:0.0998 + XiCon Loss:1.9788 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.8250908851623535
Epoch: 60, Steps: 69 Train Loss: 2.0778 (Forecasting Loss:0.1000 + XiCon Loss:1.9778 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.7564296722412109
Epoch: 61, Steps: 69 Train Loss: 2.0790 (Forecasting Loss:0.1000 + XiCon Loss:1.9789 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.8491332530975342
Epoch: 62, Steps: 69 Train Loss: 2.0781 (Forecasting Loss:0.1000 + XiCon Loss:1.9781 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.8231475353240967
Epoch: 63, Steps: 69 Train Loss: 2.0775 (Forecasting Loss:0.1000 + XiCon Loss:1.9775 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.8910214900970459
Epoch: 64, Steps: 69 Train Loss: 2.0764 (Forecasting Loss:0.0998 + XiCon Loss:1.9767 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.8775804042816162
Epoch: 65, Steps: 69 Train Loss: 2.0800 (Forecasting Loss:0.1000 + XiCon Loss:1.9800 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.8502204418182373
Epoch: 66, Steps: 69 Train Loss: 2.0788 (Forecasting Loss:0.1000 + XiCon Loss:1.9787 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.8591125011444092
Epoch: 67, Steps: 69 Train Loss: 2.0815 (Forecasting Loss:0.0999 + XiCon Loss:1.9817 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.833043098449707
Epoch: 68, Steps: 69 Train Loss: 2.0799 (Forecasting Loss:0.1000 + XiCon Loss:1.9798 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.8851945400238037
Epoch: 69, Steps: 69 Train Loss: 2.0806 (Forecasting Loss:0.0999 + XiCon Loss:1.9807 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.8510518074035645
Epoch: 70, Steps: 69 Train Loss: 2.0766 (Forecasting Loss:0.1000 + XiCon Loss:1.9766 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.8580350875854492
Epoch: 71, Steps: 69 Train Loss: 2.0774 (Forecasting Loss:0.1001 + XiCon Loss:1.9773 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.8315069675445557
Epoch: 72, Steps: 69 Train Loss: 2.0815 (Forecasting Loss:0.0999 + XiCon Loss:1.9816 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.8261415958404541
Epoch: 73, Steps: 69 Train Loss: 2.0773 (Forecasting Loss:0.0998 + XiCon Loss:1.9775 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.860220193862915
Epoch: 74, Steps: 69 Train Loss: 2.0772 (Forecasting Loss:0.0997 + XiCon Loss:1.9775 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.8201303482055664
Epoch: 75, Steps: 69 Train Loss: 2.0770 (Forecasting Loss:0.1000 + XiCon Loss:1.9770 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.8218767642974854
Epoch: 76, Steps: 69 Train Loss: 2.0812 (Forecasting Loss:0.1000 + XiCon Loss:1.9812 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.9005618095397949
Epoch: 77, Steps: 69 Train Loss: 2.0813 (Forecasting Loss:0.0999 + XiCon Loss:1.9814 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.9408204555511475
Epoch: 78, Steps: 69 Train Loss: 2.0805 (Forecasting Loss:0.0999 + XiCon Loss:1.9805 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.92714524269104
Epoch: 79, Steps: 69 Train Loss: 2.0811 (Forecasting Loss:0.0998 + XiCon Loss:1.9813 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.8432745933532715
Epoch: 80, Steps: 69 Train Loss: 2.0769 (Forecasting Loss:0.1001 + XiCon Loss:1.9768 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.8596081733703613
Epoch: 81, Steps: 69 Train Loss: 2.0802 (Forecasting Loss:0.0999 + XiCon Loss:1.9803 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8551158905029297
Epoch: 82, Steps: 69 Train Loss: 2.0814 (Forecasting Loss:0.1000 + XiCon Loss:1.9814 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.819476842880249
Epoch: 83, Steps: 69 Train Loss: 2.0808 (Forecasting Loss:0.0998 + XiCon Loss:1.9810 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.7724161148071289
Epoch: 84, Steps: 69 Train Loss: 2.0805 (Forecasting Loss:0.0996 + XiCon Loss:1.9809 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.8806991577148438
Epoch: 85, Steps: 69 Train Loss: 2.0762 (Forecasting Loss:0.0998 + XiCon Loss:1.9763 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.8457834720611572
Epoch: 86, Steps: 69 Train Loss: 2.0814 (Forecasting Loss:0.1001 + XiCon Loss:1.9814 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.8311362266540527
Epoch: 87, Steps: 69 Train Loss: 2.0830 (Forecasting Loss:0.1001 + XiCon Loss:1.9829 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.9457035064697266
Epoch: 88, Steps: 69 Train Loss: 2.0806 (Forecasting Loss:0.0999 + XiCon Loss:1.9807 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 0.8256185054779053
Epoch: 89, Steps: 69 Train Loss: 2.0795 (Forecasting Loss:0.1002 + XiCon Loss:1.9794 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 0.8507623672485352
Epoch: 90, Steps: 69 Train Loss: 2.0805 (Forecasting Loss:0.1000 + XiCon Loss:1.9805 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 0.9011833667755127
Epoch: 91, Steps: 69 Train Loss: 2.0782 (Forecasting Loss:0.0999 + XiCon Loss:1.9783 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 0.9407048225402832
Epoch: 92, Steps: 69 Train Loss: 2.0752 (Forecasting Loss:0.0999 + XiCon Loss:1.9752 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 0.8816189765930176
Epoch: 93, Steps: 69 Train Loss: 2.0779 (Forecasting Loss:0.0997 + XiCon Loss:1.9782 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 0.8579504489898682
Epoch: 94, Steps: 69 Train Loss: 2.0783 (Forecasting Loss:0.0999 + XiCon Loss:1.9784 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 0.8588466644287109
Epoch: 95, Steps: 69 Train Loss: 2.0804 (Forecasting Loss:0.1000 + XiCon Loss:1.9804 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 0.9510142803192139
Epoch: 96, Steps: 69 Train Loss: 2.0768 (Forecasting Loss:0.1000 + XiCon Loss:1.9768 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 0.7817156314849854
Epoch: 97, Steps: 69 Train Loss: 2.0798 (Forecasting Loss:0.0999 + XiCon Loss:1.9800 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 0.8475120067596436
Epoch: 98, Steps: 69 Train Loss: 2.0787 (Forecasting Loss:0.0997 + XiCon Loss:1.9790 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.310887241768095e-33
Epoch: 99 cost time: 0.821972131729126
Epoch: 99, Steps: 69 Train Loss: 2.0786 (Forecasting Loss:0.1002 + XiCon Loss:1.9784 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
Validation loss decreased (0.207132 --> 0.207132).  Saving model ...
Updating learning rate to 3.155443620884047e-33
Epoch: 100 cost time: 0.8640396595001221
Epoch: 100, Steps: 69 Train Loss: 2.0768 (Forecasting Loss:0.0998 + XiCon Loss:1.9770 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5777218104420236e-33
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055895425379276276, mae:0.1800241619348526, mape:0.12629957497119904, mspe:0.03771474212408066 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5689
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8244707584381104
Epoch: 1, Steps: 69 Train Loss: 2.1361 (Forecasting Loss:0.1344 + XiCon Loss:2.0017 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.1503
Validation loss decreased (inf --> 0.289181).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8296840190887451
Epoch: 2, Steps: 69 Train Loss: 2.1095 (Forecasting Loss:0.1130 + XiCon Loss:1.9965 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1220
Validation loss decreased (0.289181 --> 0.213512).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8811619281768799
Epoch: 3, Steps: 69 Train Loss: 2.0872 (Forecasting Loss:0.1023 + XiCon Loss:1.9849 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1191
Validation loss decreased (0.213512 --> 0.208966).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8624072074890137
Epoch: 4, Steps: 69 Train Loss: 2.0778 (Forecasting Loss:0.1010 + XiCon Loss:1.9768 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1186
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8682529926300049
Epoch: 5, Steps: 69 Train Loss: 2.0845 (Forecasting Loss:0.1020 + XiCon Loss:1.9826 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1189
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8751554489135742
Epoch: 6, Steps: 69 Train Loss: 2.0905 (Forecasting Loss:0.1021 + XiCon Loss:1.9885 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.7846400737762451
Epoch: 7, Steps: 69 Train Loss: 2.0980 (Forecasting Loss:0.1023 + XiCon Loss:1.9957 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1182
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.832463264465332
Epoch: 8, Steps: 69 Train Loss: 2.1056 (Forecasting Loss:0.1016 + XiCon Loss:2.0040 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8962972164154053
Epoch: 9, Steps: 69 Train Loss: 2.0968 (Forecasting Loss:0.1017 + XiCon Loss:1.9951 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8173322677612305
Epoch: 10, Steps: 69 Train Loss: 2.0957 (Forecasting Loss:0.1016 + XiCon Loss:1.9941 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1180
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8343460559844971
Epoch: 11, Steps: 69 Train Loss: 2.0954 (Forecasting Loss:0.1019 + XiCon Loss:1.9936 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1180
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8594307899475098
Epoch: 12, Steps: 69 Train Loss: 2.0994 (Forecasting Loss:0.1019 + XiCon Loss:1.9975 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1180
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8018991947174072
Epoch: 13, Steps: 69 Train Loss: 2.0983 (Forecasting Loss:0.1016 + XiCon Loss:1.9967 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1180
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05624706298112869, mae:0.18199864029884338, mape:0.12739713490009308, mspe:0.03751450031995773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0558+-0.00040, MAE:0.1805+-0.00108, MAPE:0.1262+-0.00099, MSPE:0.0372+-0.00071, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5939
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.1861827373504639
Epoch: 1, Steps: 64 Train Loss: 20.5780 (Forecasting Loss:0.5016 + XiCon Loss:2.0076 x Lambda(10.0)), Vali MSE Loss: 0.9639 Test MSE Loss: 0.5135
Validation loss decreased (inf --> 0.963855).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9666619300842285
Epoch: 2, Steps: 64 Train Loss: 20.5656 (Forecasting Loss:0.4974 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9529 Test MSE Loss: 0.5068
Validation loss decreased (0.963855 --> 0.952946).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9390933513641357
Epoch: 3, Steps: 64 Train Loss: 20.5588 (Forecasting Loss:0.4909 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.5042
Validation loss decreased (0.952946 --> 0.942598).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.933753490447998
Epoch: 4, Steps: 64 Train Loss: 20.5443 (Forecasting Loss:0.4890 + XiCon Loss:2.0055 x Lambda(10.0)), Vali MSE Loss: 0.9451 Test MSE Loss: 0.5029
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8580613136291504
Epoch: 5, Steps: 64 Train Loss: 20.5460 (Forecasting Loss:0.4864 + XiCon Loss:2.0060 x Lambda(10.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5023
Validation loss decreased (0.942598 --> 0.938755).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9169406890869141
Epoch: 6, Steps: 64 Train Loss: 20.5433 (Forecasting Loss:0.4857 + XiCon Loss:2.0058 x Lambda(10.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.92038893699646
Epoch: 7, Steps: 64 Train Loss: 20.5421 (Forecasting Loss:0.4858 + XiCon Loss:2.0056 x Lambda(10.0)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5019
Validation loss decreased (0.938755 --> 0.936980).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9429793357849121
Epoch: 8, Steps: 64 Train Loss: 20.5561 (Forecasting Loss:0.4855 + XiCon Loss:2.0071 x Lambda(10.0)), Vali MSE Loss: 0.9368 Test MSE Loss: 0.5018
Validation loss decreased (0.936980 --> 0.936766).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9471452236175537
Epoch: 9, Steps: 64 Train Loss: 20.5421 (Forecasting Loss:0.4848 + XiCon Loss:2.0057 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5018
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8747861385345459
Epoch: 10, Steps: 64 Train Loss: 20.5428 (Forecasting Loss:0.4844 + XiCon Loss:2.0058 x Lambda(10.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9657819271087646
Epoch: 11, Steps: 64 Train Loss: 20.5374 (Forecasting Loss:0.4856 + XiCon Loss:2.0052 x Lambda(10.0)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8857285976409912
Epoch: 12, Steps: 64 Train Loss: 20.5583 (Forecasting Loss:0.4852 + XiCon Loss:2.0073 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9237587451934814
Epoch: 13, Steps: 64 Train Loss: 20.5404 (Forecasting Loss:0.4855 + XiCon Loss:2.0055 x Lambda(10.0)), Vali MSE Loss: 0.9397 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9618861675262451
Epoch: 14, Steps: 64 Train Loss: 20.5433 (Forecasting Loss:0.4847 + XiCon Loss:2.0059 x Lambda(10.0)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9310846328735352
Epoch: 15, Steps: 64 Train Loss: 20.5304 (Forecasting Loss:0.4859 + XiCon Loss:2.0045 x Lambda(10.0)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9388434886932373
Epoch: 16, Steps: 64 Train Loss: 20.5350 (Forecasting Loss:0.4849 + XiCon Loss:2.0050 x Lambda(10.0)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.924267053604126
Epoch: 17, Steps: 64 Train Loss: 20.5467 (Forecasting Loss:0.4858 + XiCon Loss:2.0061 x Lambda(10.0)), Vali MSE Loss: 0.9358 Test MSE Loss: 0.5017
Validation loss decreased (0.936766 --> 0.935772).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9156153202056885
Epoch: 18, Steps: 64 Train Loss: 20.5425 (Forecasting Loss:0.4857 + XiCon Loss:2.0057 x Lambda(10.0)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.872281551361084
Epoch: 19, Steps: 64 Train Loss: 20.5417 (Forecasting Loss:0.4857 + XiCon Loss:2.0056 x Lambda(10.0)), Vali MSE Loss: 0.9390 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9403669834136963
Epoch: 20, Steps: 64 Train Loss: 20.5293 (Forecasting Loss:0.4852 + XiCon Loss:2.0044 x Lambda(10.0)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8962581157684326
Epoch: 21, Steps: 64 Train Loss: 20.5522 (Forecasting Loss:0.4847 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.8701972961425781
Epoch: 22, Steps: 64 Train Loss: 20.5579 (Forecasting Loss:0.4847 + XiCon Loss:2.0073 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.903832197189331
Epoch: 23, Steps: 64 Train Loss: 20.5375 (Forecasting Loss:0.4845 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9290392398834229
Epoch: 24, Steps: 64 Train Loss: 20.5325 (Forecasting Loss:0.4857 + XiCon Loss:2.0047 x Lambda(10.0)), Vali MSE Loss: 0.9394 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.948432445526123
Epoch: 25, Steps: 64 Train Loss: 20.5474 (Forecasting Loss:0.4846 + XiCon Loss:2.0063 x Lambda(10.0)), Vali MSE Loss: 0.9402 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9040212631225586
Epoch: 26, Steps: 64 Train Loss: 20.5530 (Forecasting Loss:0.4845 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9379 Test MSE Loss: 0.5017
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9315550327301025
Epoch: 27, Steps: 64 Train Loss: 20.5456 (Forecasting Loss:0.4851 + XiCon Loss:2.0061 x Lambda(10.0)), Vali MSE Loss: 0.9399 Test MSE Loss: 0.5017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.47017037868499756, mae:0.533263087272644, mape:0.44959431886672974, mspe:0.5999920964241028 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9158902168273926
Epoch: 1, Steps: 64 Train Loss: 20.5438 (Forecasting Loss:0.4928 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.9330 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932956).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8538048267364502
Epoch: 2, Steps: 64 Train Loss: 20.5357 (Forecasting Loss:0.4901 + XiCon Loss:2.0046 x Lambda(10.0)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932956 --> 0.915081).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.906876802444458
Epoch: 3, Steps: 64 Train Loss: 20.5270 (Forecasting Loss:0.4837 + XiCon Loss:2.0043 x Lambda(10.0)), Vali MSE Loss: 0.9128 Test MSE Loss: 0.5130
Validation loss decreased (0.915081 --> 0.912763).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.934298038482666
Epoch: 4, Steps: 64 Train Loss: 20.5315 (Forecasting Loss:0.4808 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.9097 Test MSE Loss: 0.5118
Validation loss decreased (0.912763 --> 0.909689).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8841235637664795
Epoch: 5, Steps: 64 Train Loss: 20.5311 (Forecasting Loss:0.4798 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5113
Validation loss decreased (0.909689 --> 0.907142).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9202466011047363
Epoch: 6, Steps: 64 Train Loss: 20.5164 (Forecasting Loss:0.4799 + XiCon Loss:2.0036 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5110
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9213309288024902
Epoch: 7, Steps: 64 Train Loss: 20.5182 (Forecasting Loss:0.4789 + XiCon Loss:2.0039 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9222514629364014
Epoch: 8, Steps: 64 Train Loss: 20.5188 (Forecasting Loss:0.4784 + XiCon Loss:2.0040 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5108
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8670017719268799
Epoch: 9, Steps: 64 Train Loss: 20.5327 (Forecasting Loss:0.4793 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5108
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8765525817871094
Epoch: 10, Steps: 64 Train Loss: 20.5381 (Forecasting Loss:0.4788 + XiCon Loss:2.0059 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8654482364654541
Epoch: 11, Steps: 64 Train Loss: 20.5227 (Forecasting Loss:0.4778 + XiCon Loss:2.0045 x Lambda(10.0)), Vali MSE Loss: 0.9084 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8797891139984131
Epoch: 12, Steps: 64 Train Loss: 20.5044 (Forecasting Loss:0.4791 + XiCon Loss:2.0025 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
Validation loss decreased (0.907142 --> 0.906434).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8952491283416748
Epoch: 13, Steps: 64 Train Loss: 20.5145 (Forecasting Loss:0.4778 + XiCon Loss:2.0037 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906434 --> 0.906216).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8972587585449219
Epoch: 14, Steps: 64 Train Loss: 20.5309 (Forecasting Loss:0.4780 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9284894466400146
Epoch: 15, Steps: 64 Train Loss: 20.5059 (Forecasting Loss:0.4800 + XiCon Loss:2.0026 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8866381645202637
Epoch: 16, Steps: 64 Train Loss: 20.5132 (Forecasting Loss:0.4790 + XiCon Loss:2.0034 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906216 --> 0.906188).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8952682018280029
Epoch: 17, Steps: 64 Train Loss: 20.5235 (Forecasting Loss:0.4784 + XiCon Loss:2.0045 x Lambda(10.0)), Vali MSE Loss: 0.9035 Test MSE Loss: 0.5107
Validation loss decreased (0.906188 --> 0.903495).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9013645648956299
Epoch: 18, Steps: 64 Train Loss: 20.5234 (Forecasting Loss:0.4780 + XiCon Loss:2.0045 x Lambda(10.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8957233428955078
Epoch: 19, Steps: 64 Train Loss: 20.5226 (Forecasting Loss:0.4789 + XiCon Loss:2.0044 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0242633819580078
Epoch: 20, Steps: 64 Train Loss: 20.5106 (Forecasting Loss:0.4784 + XiCon Loss:2.0032 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9173777103424072
Epoch: 21, Steps: 64 Train Loss: 20.5324 (Forecasting Loss:0.4780 + XiCon Loss:2.0054 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9140417575836182
Epoch: 22, Steps: 64 Train Loss: 20.5132 (Forecasting Loss:0.4784 + XiCon Loss:2.0035 x Lambda(10.0)), Vali MSE Loss: 0.9012 Test MSE Loss: 0.5107
Validation loss decreased (0.903495 --> 0.901201).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8771967887878418
Epoch: 23, Steps: 64 Train Loss: 20.5246 (Forecasting Loss:0.4781 + XiCon Loss:2.0047 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8870060443878174
Epoch: 24, Steps: 64 Train Loss: 20.5180 (Forecasting Loss:0.4786 + XiCon Loss:2.0039 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9138789176940918
Epoch: 25, Steps: 64 Train Loss: 20.5171 (Forecasting Loss:0.4777 + XiCon Loss:2.0039 x Lambda(10.0)), Vali MSE Loss: 0.9028 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9130728244781494
Epoch: 26, Steps: 64 Train Loss: 20.5218 (Forecasting Loss:0.4798 + XiCon Loss:2.0042 x Lambda(10.0)), Vali MSE Loss: 0.9050 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8874943256378174
Epoch: 27, Steps: 64 Train Loss: 20.5182 (Forecasting Loss:0.4790 + XiCon Loss:2.0039 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.9046564102172852
Epoch: 28, Steps: 64 Train Loss: 20.5221 (Forecasting Loss:0.4782 + XiCon Loss:2.0044 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 0.9238555431365967
Epoch: 29, Steps: 64 Train Loss: 20.5265 (Forecasting Loss:0.4786 + XiCon Loss:2.0048 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.8791284561157227
Epoch: 30, Steps: 64 Train Loss: 20.5222 (Forecasting Loss:0.4779 + XiCon Loss:2.0044 x Lambda(10.0)), Vali MSE Loss: 0.9104 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.9046461582183838
Epoch: 31, Steps: 64 Train Loss: 20.5268 (Forecasting Loss:0.4793 + XiCon Loss:2.0047 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 0.9308376312255859
Epoch: 32, Steps: 64 Train Loss: 20.5205 (Forecasting Loss:0.4787 + XiCon Loss:2.0042 x Lambda(10.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4846416711807251, mae:0.5368223786354065, mape:0.45702823996543884, mspe:0.6300199031829834 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5617
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9017982482910156
Epoch: 1, Steps: 64 Train Loss: 20.5796 (Forecasting Loss:0.5013 + XiCon Loss:2.0078 x Lambda(10.0)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973866).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8656916618347168
Epoch: 2, Steps: 64 Train Loss: 20.5900 (Forecasting Loss:0.4983 + XiCon Loss:2.0092 x Lambda(10.0)), Vali MSE Loss: 0.9577 Test MSE Loss: 0.5002
Validation loss decreased (0.973866 --> 0.957699).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8732843399047852
Epoch: 3, Steps: 64 Train Loss: 20.5596 (Forecasting Loss:0.4914 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9526 Test MSE Loss: 0.4981
Validation loss decreased (0.957699 --> 0.952624).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9636659622192383
Epoch: 4, Steps: 64 Train Loss: 20.5720 (Forecasting Loss:0.4903 + XiCon Loss:2.0082 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4972
Validation loss decreased (0.952624 --> 0.950826).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9285702705383301
Epoch: 5, Steps: 64 Train Loss: 20.5563 (Forecasting Loss:0.4878 + XiCon Loss:2.0069 x Lambda(10.0)), Vali MSE Loss: 0.9474 Test MSE Loss: 0.4968
Validation loss decreased (0.950826 --> 0.947363).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9034194946289062
Epoch: 6, Steps: 64 Train Loss: 20.5602 (Forecasting Loss:0.4877 + XiCon Loss:2.0072 x Lambda(10.0)), Vali MSE Loss: 0.9504 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8912255764007568
Epoch: 7, Steps: 64 Train Loss: 20.5582 (Forecasting Loss:0.4863 + XiCon Loss:2.0072 x Lambda(10.0)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.4965
Validation loss decreased (0.947363 --> 0.944028).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8956258296966553
Epoch: 8, Steps: 64 Train Loss: 20.5511 (Forecasting Loss:0.4872 + XiCon Loss:2.0064 x Lambda(10.0)), Vali MSE Loss: 0.9462 Test MSE Loss: 0.4965
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.879368782043457
Epoch: 9, Steps: 64 Train Loss: 20.5612 (Forecasting Loss:0.4860 + XiCon Loss:2.0075 x Lambda(10.0)), Vali MSE Loss: 0.9503 Test MSE Loss: 0.4965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9166302680969238
Epoch: 10, Steps: 64 Train Loss: 20.5445 (Forecasting Loss:0.4859 + XiCon Loss:2.0059 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.4964
Validation loss decreased (0.944028 --> 0.942633).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.945563793182373
Epoch: 11, Steps: 64 Train Loss: 20.5513 (Forecasting Loss:0.4865 + XiCon Loss:2.0065 x Lambda(10.0)), Vali MSE Loss: 0.9441 Test MSE Loss: 0.4964
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8872520923614502
Epoch: 12, Steps: 64 Train Loss: 20.5738 (Forecasting Loss:0.4871 + XiCon Loss:2.0087 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4964
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9657166004180908
Epoch: 13, Steps: 64 Train Loss: 20.5443 (Forecasting Loss:0.4871 + XiCon Loss:2.0057 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8887434005737305
Epoch: 14, Steps: 64 Train Loss: 20.5774 (Forecasting Loss:0.4868 + XiCon Loss:2.0091 x Lambda(10.0)), Vali MSE Loss: 0.9449 Test MSE Loss: 0.4964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9375200271606445
Epoch: 15, Steps: 64 Train Loss: 20.5688 (Forecasting Loss:0.4862 + XiCon Loss:2.0083 x Lambda(10.0)), Vali MSE Loss: 0.9466 Test MSE Loss: 0.4964
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9187114238739014
Epoch: 16, Steps: 64 Train Loss: 20.5605 (Forecasting Loss:0.4870 + XiCon Loss:2.0074 x Lambda(10.0)), Vali MSE Loss: 0.9486 Test MSE Loss: 0.4964
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9004652500152588
Epoch: 17, Steps: 64 Train Loss: 20.5632 (Forecasting Loss:0.4873 + XiCon Loss:2.0076 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9558377265930176
Epoch: 18, Steps: 64 Train Loss: 20.5365 (Forecasting Loss:0.4859 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.9480 Test MSE Loss: 0.4964
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9207108020782471
Epoch: 19, Steps: 64 Train Loss: 20.5514 (Forecasting Loss:0.4860 + XiCon Loss:2.0065 x Lambda(10.0)), Vali MSE Loss: 0.9446 Test MSE Loss: 0.4964
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9061782360076904
Epoch: 20, Steps: 64 Train Loss: 20.5801 (Forecasting Loss:0.4859 + XiCon Loss:2.0094 x Lambda(10.0)), Vali MSE Loss: 0.9427 Test MSE Loss: 0.4964
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4627090394496918, mae:0.5301684141159058, mape:0.4449203312397003, mspe:0.5856637358665466 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5746
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9329617023468018
Epoch: 1, Steps: 64 Train Loss: 20.5574 (Forecasting Loss:0.4951 + XiCon Loss:2.0062 x Lambda(10.0)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933434).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8810093402862549
Epoch: 2, Steps: 64 Train Loss: 20.5356 (Forecasting Loss:0.4905 + XiCon Loss:2.0045 x Lambda(10.0)), Vali MSE Loss: 0.9194 Test MSE Loss: 0.5152
Validation loss decreased (0.933434 --> 0.919424).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9058270454406738
Epoch: 3, Steps: 64 Train Loss: 20.5476 (Forecasting Loss:0.4821 + XiCon Loss:2.0065 x Lambda(10.0)), Vali MSE Loss: 0.9156 Test MSE Loss: 0.5120
Validation loss decreased (0.919424 --> 0.915649).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8541312217712402
Epoch: 4, Steps: 64 Train Loss: 20.5396 (Forecasting Loss:0.4807 + XiCon Loss:2.0059 x Lambda(10.0)), Vali MSE Loss: 0.9115 Test MSE Loss: 0.5105
Validation loss decreased (0.915649 --> 0.911525).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8920409679412842
Epoch: 5, Steps: 64 Train Loss: 20.5571 (Forecasting Loss:0.4796 + XiCon Loss:2.0078 x Lambda(10.0)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5099
Validation loss decreased (0.911525 --> 0.906602).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8678381443023682
Epoch: 6, Steps: 64 Train Loss: 20.5296 (Forecasting Loss:0.4798 + XiCon Loss:2.0050 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5095
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9286949634552002
Epoch: 7, Steps: 64 Train Loss: 20.5423 (Forecasting Loss:0.4792 + XiCon Loss:2.0063 x Lambda(10.0)), Vali MSE Loss: 0.9099 Test MSE Loss: 0.5093
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9513826370239258
Epoch: 8, Steps: 64 Train Loss: 20.5317 (Forecasting Loss:0.4781 + XiCon Loss:2.0054 x Lambda(10.0)), Vali MSE Loss: 0.9096 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9367876052856445
Epoch: 9, Steps: 64 Train Loss: 20.5325 (Forecasting Loss:0.4773 + XiCon Loss:2.0055 x Lambda(10.0)), Vali MSE Loss: 0.9047 Test MSE Loss: 0.5092
Validation loss decreased (0.906602 --> 0.904686).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8799686431884766
Epoch: 10, Steps: 64 Train Loss: 20.5275 (Forecasting Loss:0.4784 + XiCon Loss:2.0049 x Lambda(10.0)), Vali MSE Loss: 0.9078 Test MSE Loss: 0.5092
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.881519079208374
Epoch: 11, Steps: 64 Train Loss: 20.5360 (Forecasting Loss:0.4783 + XiCon Loss:2.0058 x Lambda(10.0)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5092
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9004507064819336
Epoch: 12, Steps: 64 Train Loss: 20.5349 (Forecasting Loss:0.4784 + XiCon Loss:2.0057 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.870255708694458
Epoch: 13, Steps: 64 Train Loss: 20.5581 (Forecasting Loss:0.4783 + XiCon Loss:2.0080 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5092
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9860696792602539
Epoch: 14, Steps: 64 Train Loss: 20.5320 (Forecasting Loss:0.4780 + XiCon Loss:2.0054 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5092
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9321346282958984
Epoch: 15, Steps: 64 Train Loss: 20.5322 (Forecasting Loss:0.4787 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5092
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.912968635559082
Epoch: 16, Steps: 64 Train Loss: 20.5331 (Forecasting Loss:0.4777 + XiCon Loss:2.0055 x Lambda(10.0)), Vali MSE Loss: 0.9022 Test MSE Loss: 0.5092
Validation loss decreased (0.904686 --> 0.902197).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9740710258483887
Epoch: 17, Steps: 64 Train Loss: 20.5440 (Forecasting Loss:0.4779 + XiCon Loss:2.0066 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5092
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.940251350402832
Epoch: 18, Steps: 64 Train Loss: 20.5348 (Forecasting Loss:0.4792 + XiCon Loss:2.0056 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5092
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8748059272766113
Epoch: 19, Steps: 64 Train Loss: 20.5442 (Forecasting Loss:0.4789 + XiCon Loss:2.0065 x Lambda(10.0)), Vali MSE Loss: 0.9088 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9102301597595215
Epoch: 20, Steps: 64 Train Loss: 20.5143 (Forecasting Loss:0.4776 + XiCon Loss:2.0037 x Lambda(10.0)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5092
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8464386463165283
Epoch: 21, Steps: 64 Train Loss: 20.5360 (Forecasting Loss:0.4787 + XiCon Loss:2.0057 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5092
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.896193265914917
Epoch: 22, Steps: 64 Train Loss: 20.5261 (Forecasting Loss:0.4784 + XiCon Loss:2.0048 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5092
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9078967571258545
Epoch: 23, Steps: 64 Train Loss: 20.5311 (Forecasting Loss:0.4779 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5092
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9048113822937012
Epoch: 24, Steps: 64 Train Loss: 20.5462 (Forecasting Loss:0.4779 + XiCon Loss:2.0068 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5092
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9468860626220703
Epoch: 25, Steps: 64 Train Loss: 20.5388 (Forecasting Loss:0.4779 + XiCon Loss:2.0061 x Lambda(10.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5092
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9117846488952637
Epoch: 26, Steps: 64 Train Loss: 20.5206 (Forecasting Loss:0.4778 + XiCon Loss:2.0043 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5092
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4827086329460144, mae:0.5355945825576782, mape:0.45603418350219727, mspe:0.6266008615493774 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9174458980560303
Epoch: 1, Steps: 64 Train Loss: 20.5500 (Forecasting Loss:0.4949 + XiCon Loss:2.0055 x Lambda(10.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908222).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9235310554504395
Epoch: 2, Steps: 64 Train Loss: 20.5491 (Forecasting Loss:0.4914 + XiCon Loss:2.0058 x Lambda(10.0)), Vali MSE Loss: 0.8924 Test MSE Loss: 0.5398
Validation loss decreased (0.908222 --> 0.892417).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.952054500579834
Epoch: 3, Steps: 64 Train Loss: 20.5430 (Forecasting Loss:0.4865 + XiCon Loss:2.0056 x Lambda(10.0)), Vali MSE Loss: 0.8930 Test MSE Loss: 0.5365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9020330905914307
Epoch: 4, Steps: 64 Train Loss: 20.5310 (Forecasting Loss:0.4827 + XiCon Loss:2.0048 x Lambda(10.0)), Vali MSE Loss: 0.8856 Test MSE Loss: 0.5349
Validation loss decreased (0.892417 --> 0.885594).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9004747867584229
Epoch: 5, Steps: 64 Train Loss: 20.5352 (Forecasting Loss:0.4819 + XiCon Loss:2.0053 x Lambda(10.0)), Vali MSE Loss: 0.8841 Test MSE Loss: 0.5341
Validation loss decreased (0.885594 --> 0.884078).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9241597652435303
Epoch: 6, Steps: 64 Train Loss: 20.5292 (Forecasting Loss:0.4802 + XiCon Loss:2.0049 x Lambda(10.0)), Vali MSE Loss: 0.8865 Test MSE Loss: 0.5337
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9060463905334473
Epoch: 7, Steps: 64 Train Loss: 20.5460 (Forecasting Loss:0.4804 + XiCon Loss:2.0066 x Lambda(10.0)), Vali MSE Loss: 0.8883 Test MSE Loss: 0.5335
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.86269211769104
Epoch: 8, Steps: 64 Train Loss: 20.5339 (Forecasting Loss:0.4828 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.8900 Test MSE Loss: 0.5334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9046444892883301
Epoch: 9, Steps: 64 Train Loss: 20.5315 (Forecasting Loss:0.4791 + XiCon Loss:2.0052 x Lambda(10.0)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5334
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9217202663421631
Epoch: 10, Steps: 64 Train Loss: 20.5203 (Forecasting Loss:0.4807 + XiCon Loss:2.0040 x Lambda(10.0)), Vali MSE Loss: 0.8857 Test MSE Loss: 0.5334
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8999135494232178
Epoch: 11, Steps: 64 Train Loss: 20.5442 (Forecasting Loss:0.4812 + XiCon Loss:2.0063 x Lambda(10.0)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5334
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8681180477142334
Epoch: 12, Steps: 64 Train Loss: 20.5301 (Forecasting Loss:0.4796 + XiCon Loss:2.0051 x Lambda(10.0)), Vali MSE Loss: 0.8855 Test MSE Loss: 0.5334
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9214010238647461
Epoch: 13, Steps: 64 Train Loss: 20.5298 (Forecasting Loss:0.4812 + XiCon Loss:2.0049 x Lambda(10.0)), Vali MSE Loss: 0.8868 Test MSE Loss: 0.5334
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8947710990905762
Epoch: 14, Steps: 64 Train Loss: 20.5389 (Forecasting Loss:0.4805 + XiCon Loss:2.0058 x Lambda(10.0)), Vali MSE Loss: 0.8851 Test MSE Loss: 0.5334
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9353554248809814
Epoch: 15, Steps: 64 Train Loss: 20.5334 (Forecasting Loss:0.4812 + XiCon Loss:2.0052 x Lambda(10.0)), Vali MSE Loss: 0.8853 Test MSE Loss: 0.5334
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5174544453620911, mae:0.5507442355155945, mape:0.4755381941795349, mspe:0.6888563632965088 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4835+-0.02608, MAE:0.5373+-0.00984, MAPE:0.4566+-0.01449, MSPE:0.6262+-0.04916, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5973
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.433211326599121
Epoch: 1, Steps: 59 Train Loss: 21.1191 (Forecasting Loss:0.9906 + XiCon Loss:2.0128 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248621).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1136558055877686
Epoch: 2, Steps: 59 Train Loss: 21.1091 (Forecasting Loss:0.9904 + XiCon Loss:2.0119 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1116464138031006
Epoch: 3, Steps: 59 Train Loss: 21.1161 (Forecasting Loss:0.9892 + XiCon Loss:2.0127 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1291015148162842
Epoch: 4, Steps: 59 Train Loss: 21.0991 (Forecasting Loss:0.9890 + XiCon Loss:2.0110 x Lambda(10.0)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9822
Validation loss decreased (1.248621 --> 1.246889).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1330430507659912
Epoch: 5, Steps: 59 Train Loss: 21.1113 (Forecasting Loss:0.9890 + XiCon Loss:2.0122 x Lambda(10.0)), Vali MSE Loss: 1.2510 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.111945390701294
Epoch: 6, Steps: 59 Train Loss: 21.1028 (Forecasting Loss:0.9899 + XiCon Loss:2.0113 x Lambda(10.0)), Vali MSE Loss: 1.2460 Test MSE Loss: 0.9822
Validation loss decreased (1.246889 --> 1.246025).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1301321983337402
Epoch: 7, Steps: 59 Train Loss: 21.1143 (Forecasting Loss:0.9887 + XiCon Loss:2.0126 x Lambda(10.0)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9822
Validation loss decreased (1.246025 --> 1.244972).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1067523956298828
Epoch: 8, Steps: 59 Train Loss: 21.1184 (Forecasting Loss:0.9881 + XiCon Loss:2.0130 x Lambda(10.0)), Vali MSE Loss: 1.2479 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1097142696380615
Epoch: 9, Steps: 59 Train Loss: 21.1142 (Forecasting Loss:0.9890 + XiCon Loss:2.0125 x Lambda(10.0)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9822
Validation loss decreased (1.244972 --> 1.244434).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.0987470149993896
Epoch: 10, Steps: 59 Train Loss: 21.1190 (Forecasting Loss:0.9889 + XiCon Loss:2.0130 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1311185359954834
Epoch: 11, Steps: 59 Train Loss: 21.1050 (Forecasting Loss:0.9878 + XiCon Loss:2.0117 x Lambda(10.0)), Vali MSE Loss: 1.2446 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.168086051940918
Epoch: 12, Steps: 59 Train Loss: 21.1284 (Forecasting Loss:0.9887 + XiCon Loss:2.0140 x Lambda(10.0)), Vali MSE Loss: 1.2523 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1386070251464844
Epoch: 13, Steps: 59 Train Loss: 21.1056 (Forecasting Loss:0.9890 + XiCon Loss:2.0117 x Lambda(10.0)), Vali MSE Loss: 1.2456 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1217293739318848
Epoch: 14, Steps: 59 Train Loss: 21.1014 (Forecasting Loss:0.9889 + XiCon Loss:2.0113 x Lambda(10.0)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1175017356872559
Epoch: 15, Steps: 59 Train Loss: 21.1171 (Forecasting Loss:0.9888 + XiCon Loss:2.0128 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.098513126373291
Epoch: 16, Steps: 59 Train Loss: 21.1097 (Forecasting Loss:0.9894 + XiCon Loss:2.0120 x Lambda(10.0)), Vali MSE Loss: 1.2490 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1273181438446045
Epoch: 17, Steps: 59 Train Loss: 21.1120 (Forecasting Loss:0.9889 + XiCon Loss:2.0123 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1558358669281006
Epoch: 18, Steps: 59 Train Loss: 21.1228 (Forecasting Loss:0.9896 + XiCon Loss:2.0133 x Lambda(10.0)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.1192572116851807
Epoch: 19, Steps: 59 Train Loss: 21.1227 (Forecasting Loss:0.9895 + XiCon Loss:2.0133 x Lambda(10.0)), Vali MSE Loss: 1.2416 Test MSE Loss: 0.9822
Validation loss decreased (1.244434 --> 1.241621).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.1162750720977783
Epoch: 20, Steps: 59 Train Loss: 21.1203 (Forecasting Loss:0.9888 + XiCon Loss:2.0132 x Lambda(10.0)), Vali MSE Loss: 1.2439 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1064825057983398
Epoch: 21, Steps: 59 Train Loss: 21.1159 (Forecasting Loss:0.9898 + XiCon Loss:2.0126 x Lambda(10.0)), Vali MSE Loss: 1.2514 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.1234536170959473
Epoch: 22, Steps: 59 Train Loss: 21.0991 (Forecasting Loss:0.9903 + XiCon Loss:2.0109 x Lambda(10.0)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.13153076171875
Epoch: 23, Steps: 59 Train Loss: 21.1274 (Forecasting Loss:0.9880 + XiCon Loss:2.0139 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.1593377590179443
Epoch: 24, Steps: 59 Train Loss: 21.1102 (Forecasting Loss:0.9893 + XiCon Loss:2.0121 x Lambda(10.0)), Vali MSE Loss: 1.2547 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.123070240020752
Epoch: 25, Steps: 59 Train Loss: 21.0980 (Forecasting Loss:0.9890 + XiCon Loss:2.0109 x Lambda(10.0)), Vali MSE Loss: 1.2521 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.1206996440887451
Epoch: 26, Steps: 59 Train Loss: 21.1059 (Forecasting Loss:0.9891 + XiCon Loss:2.0117 x Lambda(10.0)), Vali MSE Loss: 1.2574 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.1192867755889893
Epoch: 27, Steps: 59 Train Loss: 21.1203 (Forecasting Loss:0.9887 + XiCon Loss:2.0132 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.0975654125213623
Epoch: 28, Steps: 59 Train Loss: 21.1037 (Forecasting Loss:0.9901 + XiCon Loss:2.0114 x Lambda(10.0)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.1274449825286865
Epoch: 29, Steps: 59 Train Loss: 21.1158 (Forecasting Loss:0.9886 + XiCon Loss:2.0127 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9822
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.145627498626709, mae:0.8187288641929626, mape:0.7821675539016724, mspe:1.830514669418335 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5392
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.131389856338501
Epoch: 1, Steps: 59 Train Loss: 21.1024 (Forecasting Loss:0.9892 + XiCon Loss:2.0113 x Lambda(10.0)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236818).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.0987107753753662
Epoch: 2, Steps: 59 Train Loss: 21.1127 (Forecasting Loss:0.9886 + XiCon Loss:2.0124 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236818 --> 1.234322).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1064326763153076
Epoch: 3, Steps: 59 Train Loss: 21.0906 (Forecasting Loss:0.9873 + XiCon Loss:2.0103 x Lambda(10.0)), Vali MSE Loss: 1.2391 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1100802421569824
Epoch: 4, Steps: 59 Train Loss: 21.1311 (Forecasting Loss:0.9879 + XiCon Loss:2.0143 x Lambda(10.0)), Vali MSE Loss: 1.2406 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1255555152893066
Epoch: 5, Steps: 59 Train Loss: 21.0988 (Forecasting Loss:0.9886 + XiCon Loss:2.0110 x Lambda(10.0)), Vali MSE Loss: 1.2296 Test MSE Loss: 0.9929
Validation loss decreased (1.234322 --> 1.229633).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1451270580291748
Epoch: 6, Steps: 59 Train Loss: 21.1099 (Forecasting Loss:0.9885 + XiCon Loss:2.0121 x Lambda(10.0)), Vali MSE Loss: 1.2381 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1374192237854004
Epoch: 7, Steps: 59 Train Loss: 21.1162 (Forecasting Loss:0.9858 + XiCon Loss:2.0130 x Lambda(10.0)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.136488437652588
Epoch: 8, Steps: 59 Train Loss: 21.1290 (Forecasting Loss:0.9868 + XiCon Loss:2.0142 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1277732849121094
Epoch: 9, Steps: 59 Train Loss: 21.1120 (Forecasting Loss:0.9868 + XiCon Loss:2.0125 x Lambda(10.0)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1650605201721191
Epoch: 10, Steps: 59 Train Loss: 21.0957 (Forecasting Loss:0.9879 + XiCon Loss:2.0108 x Lambda(10.0)), Vali MSE Loss: 1.2337 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1286988258361816
Epoch: 11, Steps: 59 Train Loss: 21.1082 (Forecasting Loss:0.9873 + XiCon Loss:2.0121 x Lambda(10.0)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1029284000396729
Epoch: 12, Steps: 59 Train Loss: 21.1016 (Forecasting Loss:0.9877 + XiCon Loss:2.0114 x Lambda(10.0)), Vali MSE Loss: 1.2262 Test MSE Loss: 0.9928
Validation loss decreased (1.229633 --> 1.226231).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1001710891723633
Epoch: 13, Steps: 59 Train Loss: 21.1153 (Forecasting Loss:0.9882 + XiCon Loss:2.0127 x Lambda(10.0)), Vali MSE Loss: 1.2306 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.130528450012207
Epoch: 14, Steps: 59 Train Loss: 21.1185 (Forecasting Loss:0.9877 + XiCon Loss:2.0131 x Lambda(10.0)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.107419729232788
Epoch: 15, Steps: 59 Train Loss: 21.1096 (Forecasting Loss:0.9883 + XiCon Loss:2.0121 x Lambda(10.0)), Vali MSE Loss: 1.2265 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.1494297981262207
Epoch: 16, Steps: 59 Train Loss: 21.1033 (Forecasting Loss:0.9869 + XiCon Loss:2.0116 x Lambda(10.0)), Vali MSE Loss: 1.2418 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1322662830352783
Epoch: 17, Steps: 59 Train Loss: 21.1207 (Forecasting Loss:0.9875 + XiCon Loss:2.0133 x Lambda(10.0)), Vali MSE Loss: 1.2282 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1366605758666992
Epoch: 18, Steps: 59 Train Loss: 21.1149 (Forecasting Loss:0.9880 + XiCon Loss:2.0127 x Lambda(10.0)), Vali MSE Loss: 1.2301 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.116159439086914
Epoch: 19, Steps: 59 Train Loss: 21.1103 (Forecasting Loss:0.9874 + XiCon Loss:2.0123 x Lambda(10.0)), Vali MSE Loss: 1.2360 Test MSE Loss: 0.9928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.1148886680603027
Epoch: 20, Steps: 59 Train Loss: 21.1038 (Forecasting Loss:0.9875 + XiCon Loss:2.0116 x Lambda(10.0)), Vali MSE Loss: 1.2332 Test MSE Loss: 0.9928
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1307780742645264
Epoch: 21, Steps: 59 Train Loss: 21.0946 (Forecasting Loss:0.9875 + XiCon Loss:2.0107 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9928
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.149683952331543
Epoch: 22, Steps: 59 Train Loss: 21.1254 (Forecasting Loss:0.9885 + XiCon Loss:2.0137 x Lambda(10.0)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9928
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1612162590026855, mae:0.8244359493255615, mape:0.7876425981521606, mspe:1.8507174253463745 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5529
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1743125915527344
Epoch: 1, Steps: 59 Train Loss: 21.0913 (Forecasting Loss:0.9902 + XiCon Loss:2.0101 x Lambda(10.0)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247579).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1190507411956787
Epoch: 2, Steps: 59 Train Loss: 21.1160 (Forecasting Loss:0.9906 + XiCon Loss:2.0125 x Lambda(10.0)), Vali MSE Loss: 1.2355 Test MSE Loss: 0.9844
Validation loss decreased (1.247579 --> 1.235483).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1503207683563232
Epoch: 3, Steps: 59 Train Loss: 21.1014 (Forecasting Loss:0.9899 + XiCon Loss:2.0112 x Lambda(10.0)), Vali MSE Loss: 1.2347 Test MSE Loss: 0.9842
Validation loss decreased (1.235483 --> 1.234669).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.139172077178955
Epoch: 4, Steps: 59 Train Loss: 21.1088 (Forecasting Loss:0.9884 + XiCon Loss:2.0120 x Lambda(10.0)), Vali MSE Loss: 1.2540 Test MSE Loss: 0.9842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.125084638595581
Epoch: 5, Steps: 59 Train Loss: 21.1053 (Forecasting Loss:0.9886 + XiCon Loss:2.0117 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9842
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1115634441375732
Epoch: 6, Steps: 59 Train Loss: 21.1174 (Forecasting Loss:0.9894 + XiCon Loss:2.0128 x Lambda(10.0)), Vali MSE Loss: 1.2441 Test MSE Loss: 0.9841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1280076503753662
Epoch: 7, Steps: 59 Train Loss: 21.0947 (Forecasting Loss:0.9893 + XiCon Loss:2.0105 x Lambda(10.0)), Vali MSE Loss: 1.2497 Test MSE Loss: 0.9841
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1355781555175781
Epoch: 8, Steps: 59 Train Loss: 21.0987 (Forecasting Loss:0.9882 + XiCon Loss:2.0110 x Lambda(10.0)), Vali MSE Loss: 1.2581 Test MSE Loss: 0.9841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1323130130767822
Epoch: 9, Steps: 59 Train Loss: 21.1190 (Forecasting Loss:0.9876 + XiCon Loss:2.0131 x Lambda(10.0)), Vali MSE Loss: 1.2505 Test MSE Loss: 0.9841
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.132890224456787
Epoch: 10, Steps: 59 Train Loss: 21.1123 (Forecasting Loss:0.9892 + XiCon Loss:2.0123 x Lambda(10.0)), Vali MSE Loss: 1.2537 Test MSE Loss: 0.9841
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1655936241149902
Epoch: 11, Steps: 59 Train Loss: 21.1223 (Forecasting Loss:0.9878 + XiCon Loss:2.0134 x Lambda(10.0)), Vali MSE Loss: 1.2474 Test MSE Loss: 0.9841
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.191669225692749
Epoch: 12, Steps: 59 Train Loss: 21.0905 (Forecasting Loss:0.9884 + XiCon Loss:2.0102 x Lambda(10.0)), Vali MSE Loss: 1.2410 Test MSE Loss: 0.9841
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1154625415802002
Epoch: 13, Steps: 59 Train Loss: 21.0976 (Forecasting Loss:0.9889 + XiCon Loss:2.0109 x Lambda(10.0)), Vali MSE Loss: 1.2571 Test MSE Loss: 0.9841
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.148036241531372, mae:0.8204626441001892, mape:0.7830780744552612, mspe:1.8314367532730103 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5756
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.162451982498169
Epoch: 1, Steps: 59 Train Loss: 21.1179 (Forecasting Loss:0.9890 + XiCon Loss:2.0129 x Lambda(10.0)), Vali MSE Loss: 1.2401 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240053).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1236956119537354
Epoch: 2, Steps: 59 Train Loss: 21.1159 (Forecasting Loss:0.9898 + XiCon Loss:2.0126 x Lambda(10.0)), Vali MSE Loss: 1.2226 Test MSE Loss: 0.9957
Validation loss decreased (1.240053 --> 1.222586).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.115424633026123
Epoch: 3, Steps: 59 Train Loss: 21.1103 (Forecasting Loss:0.9878 + XiCon Loss:2.0123 x Lambda(10.0)), Vali MSE Loss: 1.2322 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1335408687591553
Epoch: 4, Steps: 59 Train Loss: 21.1217 (Forecasting Loss:0.9888 + XiCon Loss:2.0133 x Lambda(10.0)), Vali MSE Loss: 1.2315 Test MSE Loss: 0.9956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1382083892822266
Epoch: 5, Steps: 59 Train Loss: 21.1138 (Forecasting Loss:0.9883 + XiCon Loss:2.0125 x Lambda(10.0)), Vali MSE Loss: 1.2234 Test MSE Loss: 0.9956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1481304168701172
Epoch: 6, Steps: 59 Train Loss: 21.1267 (Forecasting Loss:0.9890 + XiCon Loss:2.0138 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1205215454101562
Epoch: 7, Steps: 59 Train Loss: 21.1239 (Forecasting Loss:0.9881 + XiCon Loss:2.0136 x Lambda(10.0)), Vali MSE Loss: 1.2252 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.106536626815796
Epoch: 8, Steps: 59 Train Loss: 21.1320 (Forecasting Loss:0.9873 + XiCon Loss:2.0145 x Lambda(10.0)), Vali MSE Loss: 1.2240 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1167867183685303
Epoch: 9, Steps: 59 Train Loss: 21.1189 (Forecasting Loss:0.9874 + XiCon Loss:2.0131 x Lambda(10.0)), Vali MSE Loss: 1.2348 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1640899181365967
Epoch: 10, Steps: 59 Train Loss: 21.1107 (Forecasting Loss:0.9883 + XiCon Loss:2.0122 x Lambda(10.0)), Vali MSE Loss: 1.2329 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1193530559539795
Epoch: 11, Steps: 59 Train Loss: 21.1134 (Forecasting Loss:0.9864 + XiCon Loss:2.0127 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1177678108215332
Epoch: 12, Steps: 59 Train Loss: 21.1124 (Forecasting Loss:0.9881 + XiCon Loss:2.0124 x Lambda(10.0)), Vali MSE Loss: 1.2323 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1653854846954346, mae:0.826111912727356, mape:0.7890901565551758, mspe:1.8549636602401733 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6799
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1361074447631836
Epoch: 1, Steps: 59 Train Loss: 21.0875 (Forecasting Loss:0.9941 + XiCon Loss:2.0093 x Lambda(10.0)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275613).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1086900234222412
Epoch: 2, Steps: 59 Train Loss: 21.0934 (Forecasting Loss:0.9928 + XiCon Loss:2.0101 x Lambda(10.0)), Vali MSE Loss: 1.2745 Test MSE Loss: 0.9658
Validation loss decreased (1.275613 --> 1.274494).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1482367515563965
Epoch: 3, Steps: 59 Train Loss: 21.0913 (Forecasting Loss:0.9934 + XiCon Loss:2.0098 x Lambda(10.0)), Vali MSE Loss: 1.2849 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.127077579498291
Epoch: 4, Steps: 59 Train Loss: 21.0708 (Forecasting Loss:0.9923 + XiCon Loss:2.0078 x Lambda(10.0)), Vali MSE Loss: 1.2803 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1153950691223145
Epoch: 5, Steps: 59 Train Loss: 21.0862 (Forecasting Loss:0.9928 + XiCon Loss:2.0093 x Lambda(10.0)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9657
Validation loss decreased (1.274494 --> 1.274269).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.151017427444458
Epoch: 6, Steps: 59 Train Loss: 21.0874 (Forecasting Loss:0.9935 + XiCon Loss:2.0094 x Lambda(10.0)), Vali MSE Loss: 1.2845 Test MSE Loss: 0.9657
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1820924282073975
Epoch: 7, Steps: 59 Train Loss: 21.0824 (Forecasting Loss:0.9924 + XiCon Loss:2.0090 x Lambda(10.0)), Vali MSE Loss: 1.2775 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1282305717468262
Epoch: 8, Steps: 59 Train Loss: 21.0801 (Forecasting Loss:0.9921 + XiCon Loss:2.0088 x Lambda(10.0)), Vali MSE Loss: 1.2825 Test MSE Loss: 0.9657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1206285953521729
Epoch: 9, Steps: 59 Train Loss: 21.0874 (Forecasting Loss:0.9931 + XiCon Loss:2.0094 x Lambda(10.0)), Vali MSE Loss: 1.2886 Test MSE Loss: 0.9657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1529667377471924
Epoch: 10, Steps: 59 Train Loss: 21.0782 (Forecasting Loss:0.9923 + XiCon Loss:2.0086 x Lambda(10.0)), Vali MSE Loss: 1.2792 Test MSE Loss: 0.9657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1084461212158203
Epoch: 11, Steps: 59 Train Loss: 21.0968 (Forecasting Loss:0.9928 + XiCon Loss:2.0104 x Lambda(10.0)), Vali MSE Loss: 1.2748 Test MSE Loss: 0.9657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1498057842254639
Epoch: 12, Steps: 59 Train Loss: 21.0626 (Forecasting Loss:0.9934 + XiCon Loss:2.0069 x Lambda(10.0)), Vali MSE Loss: 1.2767 Test MSE Loss: 0.9657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1701014041900635
Epoch: 13, Steps: 59 Train Loss: 21.0926 (Forecasting Loss:0.9922 + XiCon Loss:2.0100 x Lambda(10.0)), Vali MSE Loss: 1.2820 Test MSE Loss: 0.9657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1537108421325684
Epoch: 14, Steps: 59 Train Loss: 21.0994 (Forecasting Loss:0.9917 + XiCon Loss:2.0108 x Lambda(10.0)), Vali MSE Loss: 1.2818 Test MSE Loss: 0.9657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1165530681610107
Epoch: 15, Steps: 59 Train Loss: 21.0773 (Forecasting Loss:0.9928 + XiCon Loss:2.0084 x Lambda(10.0)), Vali MSE Loss: 1.2801 Test MSE Loss: 0.9657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206097602844238, mae:0.8108487725257874, mape:0.773126482963562, mspe:1.792566180229187 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00777, MSPE:1.8320+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5689
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.787318468093872
Epoch: 1, Steps: 53 Train Loss: 1.6879 (Forecasting Loss:1.4862 + XiCon Loss:2.0170 x Lambda(0.1)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858728).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.492931842803955
Epoch: 2, Steps: 53 Train Loss: 1.6814 (Forecasting Loss:1.4798 + XiCon Loss:2.0156 x Lambda(0.1)), Vali MSE Loss: 1.8415 Test MSE Loss: 0.9182
Validation loss decreased (1.858728 --> 1.841478).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4927153587341309
Epoch: 3, Steps: 53 Train Loss: 1.6752 (Forecasting Loss:1.4737 + XiCon Loss:2.0146 x Lambda(0.1)), Vali MSE Loss: 1.8451 Test MSE Loss: 0.9228
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.4667327404022217
Epoch: 4, Steps: 53 Train Loss: 1.6734 (Forecasting Loss:1.4718 + XiCon Loss:2.0168 x Lambda(0.1)), Vali MSE Loss: 1.8425 Test MSE Loss: 0.9249
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4599788188934326
Epoch: 5, Steps: 53 Train Loss: 1.6691 (Forecasting Loss:1.4674 + XiCon Loss:2.0173 x Lambda(0.1)), Vali MSE Loss: 1.8229 Test MSE Loss: 0.9260
Validation loss decreased (1.841478 --> 1.822879).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.4569728374481201
Epoch: 6, Steps: 53 Train Loss: 1.6716 (Forecasting Loss:1.4701 + XiCon Loss:2.0153 x Lambda(0.1)), Vali MSE Loss: 1.8259 Test MSE Loss: 0.9265
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5159292221069336
Epoch: 7, Steps: 53 Train Loss: 1.6683 (Forecasting Loss:1.4668 + XiCon Loss:2.0148 x Lambda(0.1)), Vali MSE Loss: 1.7964 Test MSE Loss: 0.9268
Validation loss decreased (1.822879 --> 1.796361).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5042359828948975
Epoch: 8, Steps: 53 Train Loss: 1.6671 (Forecasting Loss:1.4657 + XiCon Loss:2.0144 x Lambda(0.1)), Vali MSE Loss: 1.8524 Test MSE Loss: 0.9270
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.484938144683838
Epoch: 9, Steps: 53 Train Loss: 1.6680 (Forecasting Loss:1.4667 + XiCon Loss:2.0133 x Lambda(0.1)), Vali MSE Loss: 1.8147 Test MSE Loss: 0.9270
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5071921348571777
Epoch: 10, Steps: 53 Train Loss: 1.6698 (Forecasting Loss:1.4682 + XiCon Loss:2.0156 x Lambda(0.1)), Vali MSE Loss: 1.8543 Test MSE Loss: 0.9271
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4873449802398682
Epoch: 11, Steps: 53 Train Loss: 1.6665 (Forecasting Loss:1.4649 + XiCon Loss:2.0152 x Lambda(0.1)), Vali MSE Loss: 1.8366 Test MSE Loss: 0.9271
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4738397598266602
Epoch: 12, Steps: 53 Train Loss: 1.6675 (Forecasting Loss:1.4660 + XiCon Loss:2.0147 x Lambda(0.1)), Vali MSE Loss: 1.8127 Test MSE Loss: 0.9271
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.474005937576294
Epoch: 13, Steps: 53 Train Loss: 1.6685 (Forecasting Loss:1.4667 + XiCon Loss:2.0178 x Lambda(0.1)), Vali MSE Loss: 1.8496 Test MSE Loss: 0.9271
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4949750900268555
Epoch: 14, Steps: 53 Train Loss: 1.6693 (Forecasting Loss:1.4679 + XiCon Loss:2.0145 x Lambda(0.1)), Vali MSE Loss: 1.8041 Test MSE Loss: 0.9271
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4624979496002197
Epoch: 15, Steps: 53 Train Loss: 1.6662 (Forecasting Loss:1.4647 + XiCon Loss:2.0146 x Lambda(0.1)), Vali MSE Loss: 1.8463 Test MSE Loss: 0.9271
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.511401891708374
Epoch: 16, Steps: 53 Train Loss: 1.6670 (Forecasting Loss:1.4655 + XiCon Loss:2.0147 x Lambda(0.1)), Vali MSE Loss: 1.8265 Test MSE Loss: 0.9271
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.4636366367340088
Epoch: 17, Steps: 53 Train Loss: 1.6688 (Forecasting Loss:1.4673 + XiCon Loss:2.0148 x Lambda(0.1)), Vali MSE Loss: 1.8433 Test MSE Loss: 0.9271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0580922365188599, mae:0.7955502867698669, mape:0.7947980165481567, mspe:1.7963435649871826 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5585
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.490767002105713
Epoch: 1, Steps: 53 Train Loss: 1.6847 (Forecasting Loss:1.4830 + XiCon Loss:2.0172 x Lambda(0.1)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828229).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5015885829925537
Epoch: 2, Steps: 53 Train Loss: 1.6807 (Forecasting Loss:1.4788 + XiCon Loss:2.0187 x Lambda(0.1)), Vali MSE Loss: 1.8218 Test MSE Loss: 0.9332
Validation loss decreased (1.828229 --> 1.821752).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4696214199066162
Epoch: 3, Steps: 53 Train Loss: 1.6749 (Forecasting Loss:1.4730 + XiCon Loss:2.0185 x Lambda(0.1)), Vali MSE Loss: 1.7988 Test MSE Loss: 0.9348
Validation loss decreased (1.821752 --> 1.798842).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.493088722229004
Epoch: 4, Steps: 53 Train Loss: 1.6733 (Forecasting Loss:1.4713 + XiCon Loss:2.0201 x Lambda(0.1)), Vali MSE Loss: 1.8007 Test MSE Loss: 0.9356
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4568443298339844
Epoch: 5, Steps: 53 Train Loss: 1.6761 (Forecasting Loss:1.4742 + XiCon Loss:2.0198 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9361
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.4561965465545654
Epoch: 6, Steps: 53 Train Loss: 1.6709 (Forecasting Loss:1.4691 + XiCon Loss:2.0184 x Lambda(0.1)), Vali MSE Loss: 1.8083 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.4786837100982666
Epoch: 7, Steps: 53 Train Loss: 1.6696 (Forecasting Loss:1.4677 + XiCon Loss:2.0189 x Lambda(0.1)), Vali MSE Loss: 1.7826 Test MSE Loss: 0.9364
Validation loss decreased (1.798842 --> 1.782636).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.490654468536377
Epoch: 8, Steps: 53 Train Loss: 1.6709 (Forecasting Loss:1.4690 + XiCon Loss:2.0191 x Lambda(0.1)), Vali MSE Loss: 1.8251 Test MSE Loss: 0.9364
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.4918091297149658
Epoch: 9, Steps: 53 Train Loss: 1.6670 (Forecasting Loss:1.4651 + XiCon Loss:2.0182 x Lambda(0.1)), Vali MSE Loss: 1.8223 Test MSE Loss: 0.9365
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5006606578826904
Epoch: 10, Steps: 53 Train Loss: 1.6726 (Forecasting Loss:1.4705 + XiCon Loss:2.0210 x Lambda(0.1)), Vali MSE Loss: 1.8325 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4767265319824219
Epoch: 11, Steps: 53 Train Loss: 1.6712 (Forecasting Loss:1.4694 + XiCon Loss:2.0176 x Lambda(0.1)), Vali MSE Loss: 1.8406 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.509263038635254
Epoch: 12, Steps: 53 Train Loss: 1.6709 (Forecasting Loss:1.4689 + XiCon Loss:2.0208 x Lambda(0.1)), Vali MSE Loss: 1.7660 Test MSE Loss: 0.9365
Validation loss decreased (1.782636 --> 1.766023).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4851830005645752
Epoch: 13, Steps: 53 Train Loss: 1.6717 (Forecasting Loss:1.4698 + XiCon Loss:2.0194 x Lambda(0.1)), Vali MSE Loss: 1.8090 Test MSE Loss: 0.9365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.467151403427124
Epoch: 14, Steps: 53 Train Loss: 1.6722 (Forecasting Loss:1.4703 + XiCon Loss:2.0190 x Lambda(0.1)), Vali MSE Loss: 1.8040 Test MSE Loss: 0.9365
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5287880897521973
Epoch: 15, Steps: 53 Train Loss: 1.6687 (Forecasting Loss:1.4669 + XiCon Loss:2.0187 x Lambda(0.1)), Vali MSE Loss: 1.7979 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5115156173706055
Epoch: 16, Steps: 53 Train Loss: 1.6724 (Forecasting Loss:1.4706 + XiCon Loss:2.0179 x Lambda(0.1)), Vali MSE Loss: 1.7909 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.462468147277832
Epoch: 17, Steps: 53 Train Loss: 1.6699 (Forecasting Loss:1.4679 + XiCon Loss:2.0196 x Lambda(0.1)), Vali MSE Loss: 1.8298 Test MSE Loss: 0.9365
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.4915242195129395
Epoch: 18, Steps: 53 Train Loss: 1.6704 (Forecasting Loss:1.4685 + XiCon Loss:2.0195 x Lambda(0.1)), Vali MSE Loss: 1.8233 Test MSE Loss: 0.9365
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.4809272289276123
Epoch: 19, Steps: 53 Train Loss: 1.6735 (Forecasting Loss:1.4716 + XiCon Loss:2.0184 x Lambda(0.1)), Vali MSE Loss: 1.8128 Test MSE Loss: 0.9365
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.5054912567138672
Epoch: 20, Steps: 53 Train Loss: 1.6693 (Forecasting Loss:1.4675 + XiCon Loss:2.0178 x Lambda(0.1)), Vali MSE Loss: 1.8118 Test MSE Loss: 0.9365
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.4807970523834229
Epoch: 21, Steps: 53 Train Loss: 1.6707 (Forecasting Loss:1.4688 + XiCon Loss:2.0182 x Lambda(0.1)), Vali MSE Loss: 1.8081 Test MSE Loss: 0.9365
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.534377098083496
Epoch: 22, Steps: 53 Train Loss: 1.6724 (Forecasting Loss:1.4705 + XiCon Loss:2.0196 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.072970986366272, mae:0.7999846935272217, mape:0.8005089163780212, mspe:1.821057677268982 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5640
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5209100246429443
Epoch: 1, Steps: 53 Train Loss: 1.6879 (Forecasting Loss:1.4859 + XiCon Loss:2.0196 x Lambda(0.1)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899226).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.494901180267334
Epoch: 2, Steps: 53 Train Loss: 1.6856 (Forecasting Loss:1.4836 + XiCon Loss:2.0198 x Lambda(0.1)), Vali MSE Loss: 1.8448 Test MSE Loss: 0.9161
Validation loss decreased (1.899226 --> 1.844779).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5165917873382568
Epoch: 3, Steps: 53 Train Loss: 1.6823 (Forecasting Loss:1.4805 + XiCon Loss:2.0181 x Lambda(0.1)), Vali MSE Loss: 1.8756 Test MSE Loss: 0.9186
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5183956623077393
Epoch: 4, Steps: 53 Train Loss: 1.6705 (Forecasting Loss:1.4686 + XiCon Loss:2.0191 x Lambda(0.1)), Vali MSE Loss: 1.8565 Test MSE Loss: 0.9199
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5086383819580078
Epoch: 5, Steps: 53 Train Loss: 1.6746 (Forecasting Loss:1.4728 + XiCon Loss:2.0186 x Lambda(0.1)), Vali MSE Loss: 1.8091 Test MSE Loss: 0.9206
Validation loss decreased (1.844779 --> 1.809051).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5154836177825928
Epoch: 6, Steps: 53 Train Loss: 1.6749 (Forecasting Loss:1.4731 + XiCon Loss:2.0181 x Lambda(0.1)), Vali MSE Loss: 1.8718 Test MSE Loss: 0.9210
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5072295665740967
Epoch: 7, Steps: 53 Train Loss: 1.6764 (Forecasting Loss:1.4746 + XiCon Loss:2.0188 x Lambda(0.1)), Vali MSE Loss: 1.8675 Test MSE Loss: 0.9212
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5074741840362549
Epoch: 8, Steps: 53 Train Loss: 1.6743 (Forecasting Loss:1.4725 + XiCon Loss:2.0180 x Lambda(0.1)), Vali MSE Loss: 1.8521 Test MSE Loss: 0.9213
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.481952428817749
Epoch: 9, Steps: 53 Train Loss: 1.6736 (Forecasting Loss:1.4719 + XiCon Loss:2.0164 x Lambda(0.1)), Vali MSE Loss: 1.8343 Test MSE Loss: 0.9213
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4769346714019775
Epoch: 10, Steps: 53 Train Loss: 1.6702 (Forecasting Loss:1.4683 + XiCon Loss:2.0189 x Lambda(0.1)), Vali MSE Loss: 1.8586 Test MSE Loss: 0.9213
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4968593120574951
Epoch: 11, Steps: 53 Train Loss: 1.6751 (Forecasting Loss:1.4731 + XiCon Loss:2.0200 x Lambda(0.1)), Vali MSE Loss: 1.8448 Test MSE Loss: 0.9214
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.465970754623413
Epoch: 12, Steps: 53 Train Loss: 1.6708 (Forecasting Loss:1.4690 + XiCon Loss:2.0181 x Lambda(0.1)), Vali MSE Loss: 1.8315 Test MSE Loss: 0.9214
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5138635635375977
Epoch: 13, Steps: 53 Train Loss: 1.6702 (Forecasting Loss:1.4683 + XiCon Loss:2.0190 x Lambda(0.1)), Vali MSE Loss: 1.8585 Test MSE Loss: 0.9214
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.490994930267334
Epoch: 14, Steps: 53 Train Loss: 1.6709 (Forecasting Loss:1.4690 + XiCon Loss:2.0190 x Lambda(0.1)), Vali MSE Loss: 1.8337 Test MSE Loss: 0.9214
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4722542762756348
Epoch: 15, Steps: 53 Train Loss: 1.6713 (Forecasting Loss:1.4695 + XiCon Loss:2.0186 x Lambda(0.1)), Vali MSE Loss: 1.8908 Test MSE Loss: 0.9214
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0488890409469604, mae:0.7923252582550049, mape:0.7911188006401062, mspe:1.77994704246521 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5634
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5357794761657715
Epoch: 1, Steps: 53 Train Loss: 1.7019 (Forecasting Loss:1.4999 + XiCon Loss:2.0209 x Lambda(0.1)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995505).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.470310926437378
Epoch: 2, Steps: 53 Train Loss: 1.6993 (Forecasting Loss:1.4971 + XiCon Loss:2.0219 x Lambda(0.1)), Vali MSE Loss: 1.9519 Test MSE Loss: 0.8741
Validation loss decreased (1.995505 --> 1.951941).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4866929054260254
Epoch: 3, Steps: 53 Train Loss: 1.6919 (Forecasting Loss:1.4899 + XiCon Loss:2.0202 x Lambda(0.1)), Vali MSE Loss: 1.9649 Test MSE Loss: 0.8826
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.485954999923706
Epoch: 4, Steps: 53 Train Loss: 1.6829 (Forecasting Loss:1.4810 + XiCon Loss:2.0194 x Lambda(0.1)), Vali MSE Loss: 1.9483 Test MSE Loss: 0.8884
Validation loss decreased (1.951941 --> 1.948276).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.510627269744873
Epoch: 5, Steps: 53 Train Loss: 1.6767 (Forecasting Loss:1.4747 + XiCon Loss:2.0201 x Lambda(0.1)), Vali MSE Loss: 1.9110 Test MSE Loss: 0.8918
Validation loss decreased (1.948276 --> 1.910986).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5158021450042725
Epoch: 6, Steps: 53 Train Loss: 1.6774 (Forecasting Loss:1.4755 + XiCon Loss:2.0193 x Lambda(0.1)), Vali MSE Loss: 1.9541 Test MSE Loss: 0.8936
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5011792182922363
Epoch: 7, Steps: 53 Train Loss: 1.6801 (Forecasting Loss:1.4778 + XiCon Loss:2.0225 x Lambda(0.1)), Vali MSE Loss: 1.9037 Test MSE Loss: 0.8945
Validation loss decreased (1.910986 --> 1.903696).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.4673049449920654
Epoch: 8, Steps: 53 Train Loss: 1.6760 (Forecasting Loss:1.4739 + XiCon Loss:2.0210 x Lambda(0.1)), Vali MSE Loss: 1.9137 Test MSE Loss: 0.8950
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5245399475097656
Epoch: 9, Steps: 53 Train Loss: 1.6759 (Forecasting Loss:1.4740 + XiCon Loss:2.0191 x Lambda(0.1)), Vali MSE Loss: 1.9159 Test MSE Loss: 0.8952
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4691519737243652
Epoch: 10, Steps: 53 Train Loss: 1.6773 (Forecasting Loss:1.4752 + XiCon Loss:2.0212 x Lambda(0.1)), Vali MSE Loss: 1.8925 Test MSE Loss: 0.8953
Validation loss decreased (1.903696 --> 1.892455).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.478550672531128
Epoch: 11, Steps: 53 Train Loss: 1.6767 (Forecasting Loss:1.4748 + XiCon Loss:2.0190 x Lambda(0.1)), Vali MSE Loss: 1.9066 Test MSE Loss: 0.8954
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4850835800170898
Epoch: 12, Steps: 53 Train Loss: 1.6760 (Forecasting Loss:1.4742 + XiCon Loss:2.0186 x Lambda(0.1)), Vali MSE Loss: 1.8738 Test MSE Loss: 0.8954
Validation loss decreased (1.892455 --> 1.873772).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4993958473205566
Epoch: 13, Steps: 53 Train Loss: 1.6772 (Forecasting Loss:1.4751 + XiCon Loss:2.0206 x Lambda(0.1)), Vali MSE Loss: 1.9051 Test MSE Loss: 0.8954
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4872653484344482
Epoch: 14, Steps: 53 Train Loss: 1.6790 (Forecasting Loss:1.4770 + XiCon Loss:2.0206 x Lambda(0.1)), Vali MSE Loss: 1.9093 Test MSE Loss: 0.8954
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5053861141204834
Epoch: 15, Steps: 53 Train Loss: 1.6789 (Forecasting Loss:1.4769 + XiCon Loss:2.0204 x Lambda(0.1)), Vali MSE Loss: 1.9085 Test MSE Loss: 0.8954
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5287926197052002
Epoch: 16, Steps: 53 Train Loss: 1.6756 (Forecasting Loss:1.4737 + XiCon Loss:2.0192 x Lambda(0.1)), Vali MSE Loss: 1.8990 Test MSE Loss: 0.8954
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.498655080795288
Epoch: 17, Steps: 53 Train Loss: 1.6745 (Forecasting Loss:1.4725 + XiCon Loss:2.0194 x Lambda(0.1)), Vali MSE Loss: 1.9189 Test MSE Loss: 0.8954
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.517441749572754
Epoch: 18, Steps: 53 Train Loss: 1.6754 (Forecasting Loss:1.4732 + XiCon Loss:2.0216 x Lambda(0.1)), Vali MSE Loss: 1.9335 Test MSE Loss: 0.8954
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.47998046875
Epoch: 19, Steps: 53 Train Loss: 1.6725 (Forecasting Loss:1.4703 + XiCon Loss:2.0214 x Lambda(0.1)), Vali MSE Loss: 1.8974 Test MSE Loss: 0.8954
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.48063325881958
Epoch: 20, Steps: 53 Train Loss: 1.6785 (Forecasting Loss:1.4765 + XiCon Loss:2.0196 x Lambda(0.1)), Vali MSE Loss: 1.9149 Test MSE Loss: 0.8954
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.5268807411193848
Epoch: 21, Steps: 53 Train Loss: 1.6754 (Forecasting Loss:1.4733 + XiCon Loss:2.0211 x Lambda(0.1)), Vali MSE Loss: 1.8809 Test MSE Loss: 0.8954
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.5171620845794678
Epoch: 22, Steps: 53 Train Loss: 1.6776 (Forecasting Loss:1.4755 + XiCon Loss:2.0214 x Lambda(0.1)), Vali MSE Loss: 1.9087 Test MSE Loss: 0.8954
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0109028816223145, mae:0.7798909544944763, mape:0.7757231593132019, mspe:1.7174534797668457 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5576
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.495107889175415
Epoch: 1, Steps: 53 Train Loss: 1.6783 (Forecasting Loss:1.4763 + XiCon Loss:2.0195 x Lambda(0.1)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740656).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4740312099456787
Epoch: 2, Steps: 53 Train Loss: 1.6751 (Forecasting Loss:1.4731 + XiCon Loss:2.0193 x Lambda(0.1)), Vali MSE Loss: 1.7206 Test MSE Loss: 0.9607
Validation loss decreased (1.740656 --> 1.720572).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4736135005950928
Epoch: 3, Steps: 53 Train Loss: 1.6678 (Forecasting Loss:1.4659 + XiCon Loss:2.0188 x Lambda(0.1)), Vali MSE Loss: 1.7406 Test MSE Loss: 0.9644
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5042808055877686
Epoch: 4, Steps: 53 Train Loss: 1.6654 (Forecasting Loss:1.4635 + XiCon Loss:2.0190 x Lambda(0.1)), Vali MSE Loss: 1.7427 Test MSE Loss: 0.9664
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.516129970550537
Epoch: 5, Steps: 53 Train Loss: 1.6639 (Forecasting Loss:1.4619 + XiCon Loss:2.0204 x Lambda(0.1)), Vali MSE Loss: 1.7446 Test MSE Loss: 0.9675
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.4843506813049316
Epoch: 6, Steps: 53 Train Loss: 1.6638 (Forecasting Loss:1.4618 + XiCon Loss:2.0204 x Lambda(0.1)), Vali MSE Loss: 1.7540 Test MSE Loss: 0.9680
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5052986145019531
Epoch: 7, Steps: 53 Train Loss: 1.6650 (Forecasting Loss:1.4632 + XiCon Loss:2.0177 x Lambda(0.1)), Vali MSE Loss: 1.7538 Test MSE Loss: 0.9683
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.4537196159362793
Epoch: 8, Steps: 53 Train Loss: 1.6624 (Forecasting Loss:1.4604 + XiCon Loss:2.0200 x Lambda(0.1)), Vali MSE Loss: 1.7245 Test MSE Loss: 0.9684
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.4865548610687256
Epoch: 9, Steps: 53 Train Loss: 1.6640 (Forecasting Loss:1.4621 + XiCon Loss:2.0195 x Lambda(0.1)), Vali MSE Loss: 1.7700 Test MSE Loss: 0.9685
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4891762733459473
Epoch: 10, Steps: 53 Train Loss: 1.6611 (Forecasting Loss:1.4593 + XiCon Loss:2.0175 x Lambda(0.1)), Vali MSE Loss: 1.7456 Test MSE Loss: 0.9685
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4927196502685547
Epoch: 11, Steps: 53 Train Loss: 1.6640 (Forecasting Loss:1.4619 + XiCon Loss:2.0211 x Lambda(0.1)), Vali MSE Loss: 1.7521 Test MSE Loss: 0.9685
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4787514209747314
Epoch: 12, Steps: 53 Train Loss: 1.6607 (Forecasting Loss:1.4584 + XiCon Loss:2.0229 x Lambda(0.1)), Vali MSE Loss: 1.7511 Test MSE Loss: 0.9685
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1089285612106323, mae:0.8124861121177673, mape:0.8144559264183044, mspe:1.8784761428833008 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0600+-0.04434, MAE:0.7960+-0.01470, MAPE:0.7953+-0.01751, MSPE:1.7987+-0.07299, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.3164
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.9081660
	speed: 0.0180s/iter; left time: 876.0516s
	iters: 200, epoch: 1 | loss: 0.8218982
	speed: 0.0128s/iter; left time: 622.9914s
	iters: 300, epoch: 1 | loss: 0.5784138
	speed: 0.0125s/iter; left time: 604.8163s
	iters: 400, epoch: 1 | loss: 0.6347100
	speed: 0.0133s/iter; left time: 642.0823s
Epoch: 1 cost time: 6.843621730804443
Epoch: 1, Steps: 487 Train Loss: 0.7684 (Forecasting Loss:0.7417 + XiCon Loss:2.6696 x Lambda(0.01)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036696).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5268246
	speed: 0.0141s/iter; left time: 677.7196s
	iters: 200, epoch: 2 | loss: 0.4843791
	speed: 0.0126s/iter; left time: 605.3742s
	iters: 300, epoch: 2 | loss: 0.5275239
	speed: 0.0124s/iter; left time: 594.7224s
	iters: 400, epoch: 2 | loss: 0.4324725
	speed: 0.0127s/iter; left time: 605.4885s
Epoch: 2 cost time: 6.335495710372925
Epoch: 2, Steps: 487 Train Loss: 0.4612 (Forecasting Loss:0.4346 + XiCon Loss:2.6676 x Lambda(0.01)), Vali MSE Loss: 0.7454 Test MSE Loss: 0.5270
Validation loss decreased (1.036696 --> 0.745402).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.3437201
	speed: 0.0148s/iter; left time: 705.5318s
	iters: 200, epoch: 3 | loss: 0.4496810
	speed: 0.0128s/iter; left time: 610.2282s
	iters: 300, epoch: 3 | loss: 0.5270433
	speed: 0.0131s/iter; left time: 622.3577s
	iters: 400, epoch: 3 | loss: 0.3785675
	speed: 0.0129s/iter; left time: 612.7193s
Epoch: 3 cost time: 6.549962282180786
Epoch: 3, Steps: 487 Train Loss: 0.4315 (Forecasting Loss:0.4049 + XiCon Loss:2.6651 x Lambda(0.01)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5206
Validation loss decreased (0.745402 --> 0.738356).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5036651
	speed: 0.0150s/iter; left time: 705.5038s
	iters: 200, epoch: 4 | loss: 0.4360944
	speed: 0.0139s/iter; left time: 651.6652s
	iters: 300, epoch: 4 | loss: 0.4708540
	speed: 0.0132s/iter; left time: 618.3640s
	iters: 400, epoch: 4 | loss: 0.3473605
	speed: 0.0134s/iter; left time: 625.9491s
Epoch: 4 cost time: 6.701080560684204
Epoch: 4, Steps: 487 Train Loss: 0.4260 (Forecasting Loss:0.3994 + XiCon Loss:2.6657 x Lambda(0.01)), Vali MSE Loss: 0.7318 Test MSE Loss: 0.5151
Validation loss decreased (0.738356 --> 0.731755).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4491687
	speed: 0.0145s/iter; left time: 678.1382s
	iters: 200, epoch: 5 | loss: 0.5396832
	speed: 0.0137s/iter; left time: 637.9367s
	iters: 300, epoch: 5 | loss: 0.3945318
	speed: 0.0121s/iter; left time: 561.6426s
	iters: 400, epoch: 5 | loss: 0.3945587
	speed: 0.0125s/iter; left time: 578.8664s
Epoch: 5 cost time: 6.523911714553833
Epoch: 5, Steps: 487 Train Loss: 0.4235 (Forecasting Loss:0.3969 + XiCon Loss:2.6656 x Lambda(0.01)), Vali MSE Loss: 0.7293 Test MSE Loss: 0.5107
Validation loss decreased (0.731755 --> 0.729323).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4348740
	speed: 0.0153s/iter; left time: 705.4020s
	iters: 200, epoch: 6 | loss: 0.4610073
	speed: 0.0131s/iter; left time: 605.0702s
	iters: 300, epoch: 6 | loss: 0.4473541
	speed: 0.0132s/iter; left time: 605.6530s
	iters: 400, epoch: 6 | loss: 0.3882867
	speed: 0.0133s/iter; left time: 611.4446s
Epoch: 6 cost time: 6.528466701507568
Epoch: 6, Steps: 487 Train Loss: 0.4226 (Forecasting Loss:0.3960 + XiCon Loss:2.6639 x Lambda(0.01)), Vali MSE Loss: 0.7300 Test MSE Loss: 0.5130
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4285835
	speed: 0.0159s/iter; left time: 725.7212s
	iters: 200, epoch: 7 | loss: 0.3259467
	speed: 0.0133s/iter; left time: 605.7965s
	iters: 300, epoch: 7 | loss: 0.4785850
	speed: 0.0134s/iter; left time: 611.4585s
	iters: 400, epoch: 7 | loss: 0.4072741
	speed: 0.0134s/iter; left time: 607.1279s
Epoch: 7 cost time: 6.8469932079315186
Epoch: 7, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3954 + XiCon Loss:2.6632 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5121
Validation loss decreased (0.729323 --> 0.729033).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3980468
	speed: 0.0146s/iter; left time: 661.7456s
	iters: 200, epoch: 8 | loss: 0.3514453
	speed: 0.0130s/iter; left time: 585.6424s
	iters: 300, epoch: 8 | loss: 0.4130512
	speed: 0.0137s/iter; left time: 614.9869s
	iters: 400, epoch: 8 | loss: 0.4699179
	speed: 0.0133s/iter; left time: 597.2233s
Epoch: 8 cost time: 6.602658033370972
Epoch: 8, Steps: 487 Train Loss: 0.4218 (Forecasting Loss:0.3951 + XiCon Loss:2.6649 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5118
Validation loss decreased (0.729033 --> 0.728902).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5700691
	speed: 0.0154s/iter; left time: 689.4424s
	iters: 200, epoch: 9 | loss: 0.3577521
	speed: 0.0140s/iter; left time: 626.2729s
	iters: 300, epoch: 9 | loss: 0.4585973
	speed: 0.0146s/iter; left time: 648.6464s
	iters: 400, epoch: 9 | loss: 0.4327521
	speed: 0.0131s/iter; left time: 583.8241s
Epoch: 9 cost time: 6.8935325145721436
Epoch: 9, Steps: 487 Train Loss: 0.4216 (Forecasting Loss:0.3949 + XiCon Loss:2.6674 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5117
Validation loss decreased (0.728902 --> 0.728630).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3664355
	speed: 0.0153s/iter; left time: 678.4155s
	iters: 200, epoch: 10 | loss: 0.4019577
	speed: 0.0128s/iter; left time: 564.7023s
	iters: 300, epoch: 10 | loss: 0.3799693
	speed: 0.0125s/iter; left time: 551.7428s
	iters: 400, epoch: 10 | loss: 0.3349672
	speed: 0.0127s/iter; left time: 557.6148s
Epoch: 10 cost time: 6.454458951950073
Epoch: 10, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3948 + XiCon Loss:2.6679 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3793991
	speed: 0.0145s/iter; left time: 632.9612s
	iters: 200, epoch: 11 | loss: 0.3509827
	speed: 0.0122s/iter; left time: 533.1898s
	iters: 300, epoch: 11 | loss: 0.4438309
	speed: 0.0132s/iter; left time: 574.2249s
	iters: 400, epoch: 11 | loss: 0.3962423
	speed: 0.0135s/iter; left time: 587.8543s
Epoch: 11 cost time: 6.534173011779785
Epoch: 11, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3949 + XiCon Loss:2.6671 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5116
Validation loss decreased (0.728630 --> 0.728352).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4497827
	speed: 0.0151s/iter; left time: 655.1297s
	iters: 200, epoch: 12 | loss: 0.3770039
	speed: 0.0136s/iter; left time: 585.7843s
	iters: 300, epoch: 12 | loss: 0.3841775
	speed: 0.0127s/iter; left time: 548.4945s
	iters: 400, epoch: 12 | loss: 0.3941301
	speed: 0.0134s/iter; left time: 576.1591s
Epoch: 12 cost time: 6.699982404708862
Epoch: 12, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3946 + XiCon Loss:2.6648 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5597098
	speed: 0.0148s/iter; left time: 632.5156s
	iters: 200, epoch: 13 | loss: 0.4138233
	speed: 0.0134s/iter; left time: 570.1565s
	iters: 300, epoch: 13 | loss: 0.3933656
	speed: 0.0131s/iter; left time: 559.4832s
	iters: 400, epoch: 13 | loss: 0.3290711
	speed: 0.0127s/iter; left time: 540.9331s
Epoch: 13 cost time: 6.543142795562744
Epoch: 13, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3946 + XiCon Loss:2.6646 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4604310
	speed: 0.0147s/iter; left time: 622.8488s
	iters: 200, epoch: 14 | loss: 0.4850357
	speed: 0.0136s/iter; left time: 573.2643s
	iters: 300, epoch: 14 | loss: 0.3597312
	speed: 0.0133s/iter; left time: 560.9330s
	iters: 400, epoch: 14 | loss: 0.3489047
	speed: 0.0150s/iter; left time: 630.8976s
Epoch: 14 cost time: 6.8322014808654785
Epoch: 14, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3948 + XiCon Loss:2.6679 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3976104
	speed: 0.0154s/iter; left time: 645.0979s
	iters: 200, epoch: 15 | loss: 0.4143864
	speed: 0.0133s/iter; left time: 555.7928s
	iters: 300, epoch: 15 | loss: 0.4625659
	speed: 0.0126s/iter; left time: 522.3367s
	iters: 400, epoch: 15 | loss: 0.4263864
	speed: 0.0136s/iter; left time: 562.4488s
Epoch: 15 cost time: 6.632786750793457
Epoch: 15, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3946 + XiCon Loss:2.6665 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4774514
	speed: 0.0146s/iter; left time: 601.3271s
	iters: 200, epoch: 16 | loss: 0.5002590
	speed: 0.0132s/iter; left time: 543.4604s
	iters: 300, epoch: 16 | loss: 0.4077185
	speed: 0.0138s/iter; left time: 566.3873s
	iters: 400, epoch: 16 | loss: 0.4410935
	speed: 0.0133s/iter; left time: 546.3022s
Epoch: 16 cost time: 6.631136417388916
Epoch: 16, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3948 + XiCon Loss:2.6625 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3966531
	speed: 0.0146s/iter; left time: 593.7719s
	iters: 200, epoch: 17 | loss: 0.3952743
	speed: 0.0130s/iter; left time: 527.3443s
	iters: 300, epoch: 17 | loss: 0.4808972
	speed: 0.0130s/iter; left time: 528.2221s
	iters: 400, epoch: 17 | loss: 0.4568910
	speed: 0.0137s/iter; left time: 556.3543s
Epoch: 17 cost time: 6.576185703277588
Epoch: 17, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3947 + XiCon Loss:2.6667 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3662205
	speed: 0.0148s/iter; left time: 597.2769s
	iters: 200, epoch: 18 | loss: 0.4438323
	speed: 0.0131s/iter; left time: 528.7889s
	iters: 300, epoch: 18 | loss: 0.3670490
	speed: 0.0125s/iter; left time: 501.7647s
	iters: 400, epoch: 18 | loss: 0.3434625
	speed: 0.0136s/iter; left time: 545.9564s
Epoch: 18 cost time: 6.593147277832031
Epoch: 18, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3945 + XiCon Loss:2.6674 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5116
Validation loss decreased (0.728352 --> 0.728180).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4009149
	speed: 0.0138s/iter; left time: 551.2094s
	iters: 200, epoch: 19 | loss: 0.4155427
	speed: 0.0131s/iter; left time: 521.8673s
	iters: 300, epoch: 19 | loss: 0.4115108
	speed: 0.0135s/iter; left time: 534.2267s
	iters: 400, epoch: 19 | loss: 0.4366049
	speed: 0.0137s/iter; left time: 541.1685s
Epoch: 19 cost time: 6.659687757492065
Epoch: 19, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3944 + XiCon Loss:2.6645 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4166936
	speed: 0.0149s/iter; left time: 585.5100s
	iters: 200, epoch: 20 | loss: 0.4111101
	speed: 0.0134s/iter; left time: 526.5816s
	iters: 300, epoch: 20 | loss: 0.3457426
	speed: 0.0131s/iter; left time: 511.9051s
	iters: 400, epoch: 20 | loss: 0.3875459
	speed: 0.0132s/iter; left time: 517.2451s
Epoch: 20 cost time: 6.789082050323486
Epoch: 20, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3947 + XiCon Loss:2.6695 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.3295214
	speed: 0.0146s/iter; left time: 568.1878s
	iters: 200, epoch: 21 | loss: 0.4045581
	speed: 0.0125s/iter; left time: 485.4307s
	iters: 300, epoch: 21 | loss: 0.3501565
	speed: 0.0127s/iter; left time: 492.3921s
	iters: 400, epoch: 21 | loss: 0.4290337
	speed: 0.0128s/iter; left time: 493.0651s
Epoch: 21 cost time: 6.41872501373291
Epoch: 21, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3948 + XiCon Loss:2.6647 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4235188
	speed: 0.0161s/iter; left time: 617.1588s
	iters: 200, epoch: 22 | loss: 0.4738469
	speed: 0.0127s/iter; left time: 486.9710s
	iters: 300, epoch: 22 | loss: 0.4894287
	speed: 0.0136s/iter; left time: 517.9463s
	iters: 400, epoch: 22 | loss: 0.3840353
	speed: 0.0142s/iter; left time: 539.8742s
Epoch: 22 cost time: 6.924077033996582
Epoch: 22, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3948 + XiCon Loss:2.6705 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.5002329
	speed: 0.0150s/iter; left time: 569.8579s
	iters: 200, epoch: 23 | loss: 0.3806414
	speed: 0.0128s/iter; left time: 483.1320s
	iters: 300, epoch: 23 | loss: 0.3913423
	speed: 0.0133s/iter; left time: 500.6156s
	iters: 400, epoch: 23 | loss: 0.4666737
	speed: 0.0128s/iter; left time: 479.7081s
Epoch: 23 cost time: 6.551156044006348
Epoch: 23, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3946 + XiCon Loss:2.6632 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.5067033
	speed: 0.0155s/iter; left time: 579.7313s
	iters: 200, epoch: 24 | loss: 0.4061790
	speed: 0.0128s/iter; left time: 476.0685s
	iters: 300, epoch: 24 | loss: 0.4594086
	speed: 0.0134s/iter; left time: 497.1502s
	iters: 400, epoch: 24 | loss: 0.3493382
	speed: 0.0117s/iter; left time: 434.8207s
Epoch: 24 cost time: 6.353893041610718
Epoch: 24, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3946 + XiCon Loss:2.6672 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4158620
	speed: 0.0155s/iter; left time: 572.6698s
	iters: 200, epoch: 25 | loss: 0.4357005
	speed: 0.0138s/iter; left time: 508.7397s
	iters: 300, epoch: 25 | loss: 0.3833151
	speed: 0.0132s/iter; left time: 483.4325s
	iters: 400, epoch: 25 | loss: 0.4292547
	speed: 0.0132s/iter; left time: 484.2461s
Epoch: 25 cost time: 6.780969142913818
Epoch: 25, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3946 + XiCon Loss:2.6654 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5116
Validation loss decreased (0.728180 --> 0.728086).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3903766
	speed: 0.0145s/iter; left time: 528.7319s
	iters: 200, epoch: 26 | loss: 0.3905366
	speed: 0.0130s/iter; left time: 471.2676s
	iters: 300, epoch: 26 | loss: 0.5172966
	speed: 0.0129s/iter; left time: 468.5029s
	iters: 400, epoch: 26 | loss: 0.3541142
	speed: 0.0129s/iter; left time: 467.7186s
Epoch: 26 cost time: 6.5368263721466064
Epoch: 26, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3947 + XiCon Loss:2.6692 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4017307
	speed: 0.0157s/iter; left time: 563.4703s
	iters: 200, epoch: 27 | loss: 0.4253625
	speed: 0.0129s/iter; left time: 460.8240s
	iters: 300, epoch: 27 | loss: 0.3553030
	speed: 0.0136s/iter; left time: 485.8822s
	iters: 400, epoch: 27 | loss: 0.3697401
	speed: 0.0133s/iter; left time: 472.3086s
Epoch: 27 cost time: 6.6967713832855225
Epoch: 27, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3948 + XiCon Loss:2.6656 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4224508
	speed: 0.0147s/iter; left time: 520.9709s
	iters: 200, epoch: 28 | loss: 0.4262867
	speed: 0.0128s/iter; left time: 453.1346s
	iters: 300, epoch: 28 | loss: 0.4305628
	speed: 0.0134s/iter; left time: 471.8027s
	iters: 400, epoch: 28 | loss: 0.3993034
	speed: 0.0127s/iter; left time: 446.2973s
Epoch: 28 cost time: 6.5240302085876465
Epoch: 28, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3945 + XiCon Loss:2.6655 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3676675
	speed: 0.0146s/iter; left time: 509.3551s
	iters: 200, epoch: 29 | loss: 0.4704680
	speed: 0.0137s/iter; left time: 478.8160s
	iters: 300, epoch: 29 | loss: 0.4411024
	speed: 0.0122s/iter; left time: 424.3876s
	iters: 400, epoch: 29 | loss: 0.4300461
	speed: 0.0129s/iter; left time: 445.9909s
Epoch: 29 cost time: 6.464698314666748
Epoch: 29, Steps: 487 Train Loss: 0.4215 (Forecasting Loss:0.3949 + XiCon Loss:2.6675 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3945658
	speed: 0.0145s/iter; left time: 500.9485s
	iters: 200, epoch: 30 | loss: 0.4190138
	speed: 0.0136s/iter; left time: 466.5843s
	iters: 300, epoch: 30 | loss: 0.4603334
	speed: 0.0143s/iter; left time: 489.0949s
	iters: 400, epoch: 30 | loss: 0.4058992
	speed: 0.0131s/iter; left time: 446.3684s
Epoch: 30 cost time: 6.785446643829346
Epoch: 30, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3945 + XiCon Loss:2.6691 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.5108685
	speed: 0.0148s/iter; left time: 502.6596s
	iters: 200, epoch: 31 | loss: 0.3355294
	speed: 0.0128s/iter; left time: 433.1885s
	iters: 300, epoch: 31 | loss: 0.4301626
	speed: 0.0134s/iter; left time: 454.4889s
	iters: 400, epoch: 31 | loss: 0.3526621
	speed: 0.0138s/iter; left time: 463.2685s
Epoch: 31 cost time: 6.745656490325928
Epoch: 31, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3945 + XiCon Loss:2.6677 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4136757
	speed: 0.0147s/iter; left time: 490.9532s
	iters: 200, epoch: 32 | loss: 0.4957878
	speed: 0.0129s/iter; left time: 432.2715s
	iters: 300, epoch: 32 | loss: 0.3672460
	speed: 0.0142s/iter; left time: 472.7212s
	iters: 400, epoch: 32 | loss: 0.3294986
	speed: 0.0136s/iter; left time: 452.0318s
Epoch: 32 cost time: 6.731785535812378
Epoch: 32, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3943 + XiCon Loss:2.6649 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3823175
	speed: 0.0144s/iter; left time: 476.6339s
	iters: 200, epoch: 33 | loss: 0.3407454
	speed: 0.0126s/iter; left time: 413.8999s
	iters: 300, epoch: 33 | loss: 0.4316148
	speed: 0.0129s/iter; left time: 423.7031s
	iters: 400, epoch: 33 | loss: 0.5017069
	speed: 0.0130s/iter; left time: 424.6745s
Epoch: 33 cost time: 6.45029091835022
Epoch: 33, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3947 + XiCon Loss:2.6665 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4238502
	speed: 0.0150s/iter; left time: 487.5147s
	iters: 200, epoch: 34 | loss: 0.4628091
	speed: 0.0145s/iter; left time: 469.0994s
	iters: 300, epoch: 34 | loss: 0.3791370
	speed: 0.0132s/iter; left time: 426.1985s
	iters: 400, epoch: 34 | loss: 0.3933528
	speed: 0.0132s/iter; left time: 424.4148s
Epoch: 34 cost time: 6.746229887008667
Epoch: 34, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3945 + XiCon Loss:2.6658 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5116
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4077713
	speed: 0.0153s/iter; left time: 490.9575s
	iters: 200, epoch: 35 | loss: 0.3410329
	speed: 0.0133s/iter; left time: 425.9668s
	iters: 300, epoch: 35 | loss: 0.4230591
	speed: 0.0136s/iter; left time: 433.8133s
	iters: 400, epoch: 35 | loss: 0.4337775
	speed: 0.0130s/iter; left time: 411.4151s
Epoch: 35 cost time: 6.730549097061157
Epoch: 35, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3946 + XiCon Loss:2.6687 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.518225371837616, mae:0.5050102472305298, mape:3.5332536697387695, mspe:1158.85986328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.4008
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.7009231
	speed: 0.0151s/iter; left time: 732.4023s
	iters: 200, epoch: 1 | loss: 0.8921248
	speed: 0.0137s/iter; left time: 666.5646s
	iters: 300, epoch: 1 | loss: 0.5855586
	speed: 0.0128s/iter; left time: 621.3690s
	iters: 400, epoch: 1 | loss: 0.5167214
	speed: 0.0128s/iter; left time: 620.1484s
Epoch: 1 cost time: 6.645057201385498
Epoch: 1, Steps: 487 Train Loss: 0.7614 (Forecasting Loss:0.7348 + XiCon Loss:2.6587 x Lambda(0.01)), Vali MSE Loss: 1.0307 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030660).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5172090
	speed: 0.0155s/iter; left time: 746.6817s
	iters: 200, epoch: 2 | loss: 0.5126851
	speed: 0.0130s/iter; left time: 622.2198s
	iters: 300, epoch: 2 | loss: 0.4194948
	speed: 0.0129s/iter; left time: 619.2296s
	iters: 400, epoch: 2 | loss: 0.5017230
	speed: 0.0129s/iter; left time: 615.3811s
Epoch: 2 cost time: 6.605892658233643
Epoch: 2, Steps: 487 Train Loss: 0.4650 (Forecasting Loss:0.4383 + XiCon Loss:2.6666 x Lambda(0.01)), Vali MSE Loss: 0.7327 Test MSE Loss: 0.5270
Validation loss decreased (1.030660 --> 0.732736).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4477281
	speed: 0.0153s/iter; left time: 727.3388s
	iters: 200, epoch: 3 | loss: 0.4151647
	speed: 0.0127s/iter; left time: 604.8645s
	iters: 300, epoch: 3 | loss: 0.4374674
	speed: 0.0133s/iter; left time: 630.8815s
	iters: 400, epoch: 3 | loss: 0.3845559
	speed: 0.0131s/iter; left time: 619.8579s
Epoch: 3 cost time: 6.579984903335571
Epoch: 3, Steps: 487 Train Loss: 0.4315 (Forecasting Loss:0.4049 + XiCon Loss:2.6585 x Lambda(0.01)), Vali MSE Loss: 0.7178 Test MSE Loss: 0.5186
Validation loss decreased (0.732736 --> 0.717786).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5476831
	speed: 0.0149s/iter; left time: 701.6521s
	iters: 200, epoch: 4 | loss: 0.3921292
	speed: 0.0128s/iter; left time: 602.8261s
	iters: 300, epoch: 4 | loss: 0.5382837
	speed: 0.0128s/iter; left time: 601.2173s
	iters: 400, epoch: 4 | loss: 0.5243036
	speed: 0.0128s/iter; left time: 597.8143s
Epoch: 4 cost time: 6.486315727233887
Epoch: 4, Steps: 487 Train Loss: 0.4254 (Forecasting Loss:0.3989 + XiCon Loss:2.6543 x Lambda(0.01)), Vali MSE Loss: 0.7115 Test MSE Loss: 0.5165
Validation loss decreased (0.717786 --> 0.711494).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3863748
	speed: 0.0161s/iter; left time: 752.8324s
	iters: 200, epoch: 5 | loss: 0.4433203
	speed: 0.0126s/iter; left time: 584.2960s
	iters: 300, epoch: 5 | loss: 0.3968615
	speed: 0.0132s/iter; left time: 610.9142s
	iters: 400, epoch: 5 | loss: 0.3286223
	speed: 0.0129s/iter; left time: 598.7850s
Epoch: 5 cost time: 6.603734254837036
Epoch: 5, Steps: 487 Train Loss: 0.4232 (Forecasting Loss:0.3966 + XiCon Loss:2.6587 x Lambda(0.01)), Vali MSE Loss: 0.7100 Test MSE Loss: 0.5146
Validation loss decreased (0.711494 --> 0.710003).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3646336
	speed: 0.0149s/iter; left time: 686.3437s
	iters: 200, epoch: 6 | loss: 0.3945199
	speed: 0.0132s/iter; left time: 609.5820s
	iters: 300, epoch: 6 | loss: 0.3295019
	speed: 0.0135s/iter; left time: 620.2605s
	iters: 400, epoch: 6 | loss: 0.4506327
	speed: 0.0129s/iter; left time: 589.5171s
Epoch: 6 cost time: 6.757009267807007
Epoch: 6, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3955 + XiCon Loss:2.6612 x Lambda(0.01)), Vali MSE Loss: 0.7074 Test MSE Loss: 0.5133
Validation loss decreased (0.710003 --> 0.707366).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3781405
	speed: 0.0149s/iter; left time: 679.3566s
	iters: 200, epoch: 7 | loss: 0.3766484
	speed: 0.0131s/iter; left time: 597.3587s
	iters: 300, epoch: 7 | loss: 0.4964242
	speed: 0.0134s/iter; left time: 610.1603s
	iters: 400, epoch: 7 | loss: 0.3870389
	speed: 0.0132s/iter; left time: 601.0003s
Epoch: 7 cost time: 6.666834354400635
Epoch: 7, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3948 + XiCon Loss:2.6545 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5133
Validation loss decreased (0.707366 --> 0.706828).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4599708
	speed: 0.0149s/iter; left time: 671.4933s
	iters: 200, epoch: 8 | loss: 0.4407340
	speed: 0.0120s/iter; left time: 541.1330s
	iters: 300, epoch: 8 | loss: 0.3832311
	speed: 0.0132s/iter; left time: 596.1199s
	iters: 400, epoch: 8 | loss: 0.3291532
	speed: 0.0135s/iter; left time: 606.8911s
Epoch: 8 cost time: 6.426363468170166
Epoch: 8, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3944 + XiCon Loss:2.6548 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5132
Validation loss decreased (0.706828 --> 0.706627).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3975914
	speed: 0.0150s/iter; left time: 672.2938s
	iters: 200, epoch: 9 | loss: 0.4113095
	speed: 0.0131s/iter; left time: 583.7995s
	iters: 300, epoch: 9 | loss: 0.4020212
	speed: 0.0140s/iter; left time: 624.8917s
	iters: 400, epoch: 9 | loss: 0.5004852
	speed: 0.0137s/iter; left time: 607.8034s
Epoch: 9 cost time: 6.740047216415405
Epoch: 9, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3942 + XiCon Loss:2.6545 x Lambda(0.01)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5130
Validation loss decreased (0.706627 --> 0.705961).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4211936
	speed: 0.0152s/iter; left time: 673.8848s
	iters: 200, epoch: 10 | loss: 0.4187294
	speed: 0.0124s/iter; left time: 546.3880s
	iters: 300, epoch: 10 | loss: 0.2951266
	speed: 0.0125s/iter; left time: 548.0663s
	iters: 400, epoch: 10 | loss: 0.4296542
	speed: 0.0126s/iter; left time: 551.7594s
Epoch: 10 cost time: 6.413534164428711
Epoch: 10, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3942 + XiCon Loss:2.6539 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3382239
	speed: 0.0157s/iter; left time: 684.6638s
	iters: 200, epoch: 11 | loss: 0.3817662
	speed: 0.0130s/iter; left time: 567.2340s
	iters: 300, epoch: 11 | loss: 0.3864723
	speed: 0.0130s/iter; left time: 565.0166s
	iters: 400, epoch: 11 | loss: 0.5390767
	speed: 0.0126s/iter; left time: 545.7566s
Epoch: 11 cost time: 6.570261716842651
Epoch: 11, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3939 + XiCon Loss:2.6474 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5130
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3964332
	speed: 0.0153s/iter; left time: 663.5478s
	iters: 200, epoch: 12 | loss: 0.4254990
	speed: 0.0130s/iter; left time: 559.8708s
	iters: 300, epoch: 12 | loss: 0.4536667
	speed: 0.0130s/iter; left time: 561.1086s
	iters: 400, epoch: 12 | loss: 0.4372335
	speed: 0.0132s/iter; left time: 566.9887s
Epoch: 12 cost time: 6.648008108139038
Epoch: 12, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3943 + XiCon Loss:2.6542 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5129
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4304472
	speed: 0.0154s/iter; left time: 656.5069s
	iters: 200, epoch: 13 | loss: 0.4933959
	speed: 0.0133s/iter; left time: 565.3844s
	iters: 300, epoch: 13 | loss: 0.3856767
	speed: 0.0135s/iter; left time: 575.0076s
	iters: 400, epoch: 13 | loss: 0.3917657
	speed: 0.0131s/iter; left time: 556.1422s
Epoch: 13 cost time: 6.721447706222534
Epoch: 13, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3942 + XiCon Loss:2.6588 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4000646
	speed: 0.0159s/iter; left time: 673.3717s
	iters: 200, epoch: 14 | loss: 0.4332527
	speed: 0.0137s/iter; left time: 578.2125s
	iters: 300, epoch: 14 | loss: 0.3880930
	speed: 0.0137s/iter; left time: 576.4800s
	iters: 400, epoch: 14 | loss: 0.4169782
	speed: 0.0131s/iter; left time: 551.4916s
Epoch: 14 cost time: 6.844314098358154
Epoch: 14, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3941 + XiCon Loss:2.6557 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5129
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4739562
	speed: 0.0149s/iter; left time: 621.1573s
	iters: 200, epoch: 15 | loss: 0.4368798
	speed: 0.0128s/iter; left time: 532.4054s
	iters: 300, epoch: 15 | loss: 0.4382748
	speed: 0.0132s/iter; left time: 550.4070s
	iters: 400, epoch: 15 | loss: 0.3991731
	speed: 0.0130s/iter; left time: 540.0770s
Epoch: 15 cost time: 6.571587800979614
Epoch: 15, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3938 + XiCon Loss:2.6508 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4425050
	speed: 0.0156s/iter; left time: 643.3772s
	iters: 200, epoch: 16 | loss: 0.4663182
	speed: 0.0129s/iter; left time: 531.2398s
	iters: 300, epoch: 16 | loss: 0.3998472
	speed: 0.0135s/iter; left time: 554.6861s
	iters: 400, epoch: 16 | loss: 0.4814303
	speed: 0.0136s/iter; left time: 556.5351s
Epoch: 16 cost time: 6.751811742782593
Epoch: 16, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3939 + XiCon Loss:2.6534 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5129
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4166687
	speed: 0.0153s/iter; left time: 625.2691s
	iters: 200, epoch: 17 | loss: 0.4638007
	speed: 0.0128s/iter; left time: 522.6075s
	iters: 300, epoch: 17 | loss: 0.4340900
	speed: 0.0123s/iter; left time: 500.0461s
	iters: 400, epoch: 17 | loss: 0.4677695
	speed: 0.0129s/iter; left time: 522.6424s
Epoch: 17 cost time: 6.503647327423096
Epoch: 17, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3942 + XiCon Loss:2.6557 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4573159
	speed: 0.0147s/iter; left time: 594.7018s
	iters: 200, epoch: 18 | loss: 0.4376463
	speed: 0.0137s/iter; left time: 550.8573s
	iters: 300, epoch: 18 | loss: 0.6022031
	speed: 0.0137s/iter; left time: 549.5570s
	iters: 400, epoch: 18 | loss: 0.4216045
	speed: 0.0130s/iter; left time: 521.6281s
Epoch: 18 cost time: 6.620006084442139
Epoch: 18, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3939 + XiCon Loss:2.6517 x Lambda(0.01)), Vali MSE Loss: 0.7063 Test MSE Loss: 0.5129
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3199081
	speed: 0.0166s/iter; left time: 659.3054s
	iters: 200, epoch: 19 | loss: 0.4889931
	speed: 0.0133s/iter; left time: 526.5266s
	iters: 300, epoch: 19 | loss: 0.4457757
	speed: 0.0143s/iter; left time: 567.2847s
	iters: 400, epoch: 19 | loss: 0.3698759
	speed: 0.0131s/iter; left time: 519.1924s
Epoch: 19 cost time: 6.875880479812622
Epoch: 19, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3942 + XiCon Loss:2.6535 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5129
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5196647644042969, mae:0.506325900554657, mape:3.44498872756958, mspe:1084.7376708984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.7846
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1409546
	speed: 0.0157s/iter; left time: 764.1055s
	iters: 200, epoch: 1 | loss: 0.7941714
	speed: 0.0134s/iter; left time: 649.2357s
	iters: 300, epoch: 1 | loss: 0.7082366
	speed: 0.0129s/iter; left time: 626.6587s
	iters: 400, epoch: 1 | loss: 0.7599608
	speed: 0.0136s/iter; left time: 659.2279s
Epoch: 1 cost time: 6.710418462753296
Epoch: 1, Steps: 487 Train Loss: 0.8677 (Forecasting Loss:0.8409 + XiCon Loss:2.6767 x Lambda(0.01)), Vali MSE Loss: 1.1923 Test MSE Loss: 0.6744
Validation loss decreased (inf --> 1.192288).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4701758
	speed: 0.0148s/iter; left time: 713.1452s
	iters: 200, epoch: 2 | loss: 0.4471898
	speed: 0.0129s/iter; left time: 618.7319s
	iters: 300, epoch: 2 | loss: 0.3960865
	speed: 0.0134s/iter; left time: 642.0245s
	iters: 400, epoch: 2 | loss: 0.5385317
	speed: 0.0136s/iter; left time: 650.3374s
Epoch: 2 cost time: 6.777791976928711
Epoch: 2, Steps: 487 Train Loss: 0.4793 (Forecasting Loss:0.4526 + XiCon Loss:2.6693 x Lambda(0.01)), Vali MSE Loss: 0.7520 Test MSE Loss: 0.5336
Validation loss decreased (1.192288 --> 0.752004).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4810035
	speed: 0.0158s/iter; left time: 750.4483s
	iters: 200, epoch: 3 | loss: 0.4139219
	speed: 0.0129s/iter; left time: 614.5014s
	iters: 300, epoch: 3 | loss: 0.3566201
	speed: 0.0136s/iter; left time: 642.9399s
	iters: 400, epoch: 3 | loss: 0.4124674
	speed: 0.0136s/iter; left time: 642.4588s
Epoch: 3 cost time: 6.791685342788696
Epoch: 3, Steps: 487 Train Loss: 0.4348 (Forecasting Loss:0.4081 + XiCon Loss:2.6683 x Lambda(0.01)), Vali MSE Loss: 0.7396 Test MSE Loss: 0.5304
Validation loss decreased (0.752004 --> 0.739594).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4045609
	speed: 0.0155s/iter; left time: 729.6827s
	iters: 200, epoch: 4 | loss: 0.3739676
	speed: 0.0127s/iter; left time: 599.2258s
	iters: 300, epoch: 4 | loss: 0.4308657
	speed: 0.0128s/iter; left time: 600.2777s
	iters: 400, epoch: 4 | loss: 0.4942011
	speed: 0.0124s/iter; left time: 581.8276s
Epoch: 4 cost time: 6.466367483139038
Epoch: 4, Steps: 487 Train Loss: 0.4290 (Forecasting Loss:0.4024 + XiCon Loss:2.6602 x Lambda(0.01)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5269
Validation loss decreased (0.739594 --> 0.731950).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4084721
	speed: 0.0155s/iter; left time: 721.5425s
	iters: 200, epoch: 5 | loss: 0.3899400
	speed: 0.0130s/iter; left time: 606.9213s
	iters: 300, epoch: 5 | loss: 0.4196550
	speed: 0.0131s/iter; left time: 610.6027s
	iters: 400, epoch: 5 | loss: 0.4512233
	speed: 0.0135s/iter; left time: 623.9275s
Epoch: 5 cost time: 6.727627515792847
Epoch: 5, Steps: 487 Train Loss: 0.4265 (Forecasting Loss:0.3999 + XiCon Loss:2.6620 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5231
Validation loss decreased (0.731950 --> 0.730066).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4128061
	speed: 0.0151s/iter; left time: 697.3070s
	iters: 200, epoch: 6 | loss: 0.3990178
	speed: 0.0138s/iter; left time: 634.1040s
	iters: 300, epoch: 6 | loss: 0.4116946
	speed: 0.0134s/iter; left time: 617.2236s
	iters: 400, epoch: 6 | loss: 0.4010139
	speed: 0.0124s/iter; left time: 570.6913s
Epoch: 6 cost time: 6.621118545532227
Epoch: 6, Steps: 487 Train Loss: 0.4250 (Forecasting Loss:0.3984 + XiCon Loss:2.6602 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5222
Validation loss decreased (0.730066 --> 0.728166).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3988958
	speed: 0.0144s/iter; left time: 658.2873s
	iters: 200, epoch: 7 | loss: 0.4145556
	speed: 0.0130s/iter; left time: 591.8029s
	iters: 300, epoch: 7 | loss: 0.4744808
	speed: 0.0129s/iter; left time: 588.3274s
	iters: 400, epoch: 7 | loss: 0.4400351
	speed: 0.0130s/iter; left time: 588.7999s
Epoch: 7 cost time: 6.539828300476074
Epoch: 7, Steps: 487 Train Loss: 0.4246 (Forecasting Loss:0.3980 + XiCon Loss:2.6634 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5216
Validation loss decreased (0.728166 --> 0.727800).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4419234
	speed: 0.0156s/iter; left time: 705.8641s
	iters: 200, epoch: 8 | loss: 0.3975177
	speed: 0.0129s/iter; left time: 581.8254s
	iters: 300, epoch: 8 | loss: 0.4282210
	speed: 0.0131s/iter; left time: 589.0059s
	iters: 400, epoch: 8 | loss: 0.3711331
	speed: 0.0136s/iter; left time: 612.4688s
Epoch: 8 cost time: 6.765517473220825
Epoch: 8, Steps: 487 Train Loss: 0.4243 (Forecasting Loss:0.3977 + XiCon Loss:2.6609 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5215
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4962900
	speed: 0.0149s/iter; left time: 664.0090s
	iters: 200, epoch: 9 | loss: 0.4159059
	speed: 0.0141s/iter; left time: 627.7521s
	iters: 300, epoch: 9 | loss: 0.4792767
	speed: 0.0135s/iter; left time: 599.0076s
	iters: 400, epoch: 9 | loss: 0.3437348
	speed: 0.0132s/iter; left time: 588.1443s
Epoch: 9 cost time: 6.727623224258423
Epoch: 9, Steps: 487 Train Loss: 0.4241 (Forecasting Loss:0.3975 + XiCon Loss:2.6615 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5215
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.5210841
	speed: 0.0152s/iter; left time: 672.9744s
	iters: 200, epoch: 10 | loss: 0.4355019
	speed: 0.0123s/iter; left time: 543.9176s
	iters: 300, epoch: 10 | loss: 0.3780424
	speed: 0.0133s/iter; left time: 584.1481s
	iters: 400, epoch: 10 | loss: 0.3652385
	speed: 0.0130s/iter; left time: 572.2899s
Epoch: 10 cost time: 6.547125339508057
Epoch: 10, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6594 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
Validation loss decreased (0.727800 --> 0.727798).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4360430
	speed: 0.0146s/iter; left time: 639.1210s
	iters: 200, epoch: 11 | loss: 0.3966801
	speed: 0.0123s/iter; left time: 538.2222s
	iters: 300, epoch: 11 | loss: 0.4421819
	speed: 0.0132s/iter; left time: 574.6807s
	iters: 400, epoch: 11 | loss: 0.3808370
	speed: 0.0136s/iter; left time: 589.6210s
Epoch: 11 cost time: 6.538285732269287
Epoch: 11, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6604 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3931179
	speed: 0.0153s/iter; left time: 662.1880s
	iters: 200, epoch: 12 | loss: 0.5155531
	speed: 0.0141s/iter; left time: 608.9277s
	iters: 300, epoch: 12 | loss: 0.3831224
	speed: 0.0129s/iter; left time: 553.3320s
	iters: 400, epoch: 12 | loss: 0.4748246
	speed: 0.0132s/iter; left time: 565.0819s
Epoch: 12 cost time: 6.711652040481567
Epoch: 12, Steps: 487 Train Loss: 0.4241 (Forecasting Loss:0.3975 + XiCon Loss:2.6594 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
Validation loss decreased (0.727798 --> 0.727657).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3567224
	speed: 0.0161s/iter; left time: 686.3809s
	iters: 200, epoch: 13 | loss: 0.4586493
	speed: 0.0137s/iter; left time: 584.8585s
	iters: 300, epoch: 13 | loss: 0.4563237
	speed: 0.0131s/iter; left time: 557.4371s
	iters: 400, epoch: 13 | loss: 0.3468122
	speed: 0.0131s/iter; left time: 557.8034s
Epoch: 13 cost time: 6.718066453933716
Epoch: 13, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6599 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4374049
	speed: 0.0153s/iter; left time: 646.2571s
	iters: 200, epoch: 14 | loss: 0.4992135
	speed: 0.0133s/iter; left time: 558.8581s
	iters: 300, epoch: 14 | loss: 0.3671872
	speed: 0.0142s/iter; left time: 596.2341s
	iters: 400, epoch: 14 | loss: 0.5862241
	speed: 0.0129s/iter; left time: 539.8911s
Epoch: 14 cost time: 6.77184796333313
Epoch: 14, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3974 + XiCon Loss:2.6560 x Lambda(0.01)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5214
Validation loss decreased (0.727657 --> 0.727252).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3944059
	speed: 0.0150s/iter; left time: 624.8488s
	iters: 200, epoch: 15 | loss: 0.4527118
	speed: 0.0131s/iter; left time: 548.0837s
	iters: 300, epoch: 15 | loss: 0.4399216
	speed: 0.0130s/iter; left time: 540.1029s
	iters: 400, epoch: 15 | loss: 0.3407569
	speed: 0.0138s/iter; left time: 573.0197s
Epoch: 15 cost time: 6.6462883949279785
Epoch: 15, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6579 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3512067
	speed: 0.0160s/iter; left time: 660.6013s
	iters: 200, epoch: 16 | loss: 0.4026479
	speed: 0.0130s/iter; left time: 537.2400s
	iters: 300, epoch: 16 | loss: 0.3947199
	speed: 0.0131s/iter; left time: 539.6856s
	iters: 400, epoch: 16 | loss: 0.4597969
	speed: 0.0127s/iter; left time: 519.2312s
Epoch: 16 cost time: 6.761732339859009
Epoch: 16, Steps: 487 Train Loss: 0.4237 (Forecasting Loss:0.3971 + XiCon Loss:2.6605 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4033473
	speed: 0.0156s/iter; left time: 635.6098s
	iters: 200, epoch: 17 | loss: 0.4617079
	speed: 0.0134s/iter; left time: 545.4381s
	iters: 300, epoch: 17 | loss: 0.4526243
	speed: 0.0146s/iter; left time: 594.1138s
	iters: 400, epoch: 17 | loss: 0.3463843
	speed: 0.0129s/iter; left time: 521.5920s
Epoch: 17 cost time: 6.87938928604126
Epoch: 17, Steps: 487 Train Loss: 0.4241 (Forecasting Loss:0.3974 + XiCon Loss:2.6622 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3829997
	speed: 0.0152s/iter; left time: 612.8379s
	iters: 200, epoch: 18 | loss: 0.5248308
	speed: 0.0137s/iter; left time: 551.1045s
	iters: 300, epoch: 18 | loss: 0.4300261
	speed: 0.0134s/iter; left time: 538.3053s
	iters: 400, epoch: 18 | loss: 0.4902656
	speed: 0.0132s/iter; left time: 530.1655s
Epoch: 18 cost time: 6.7095725536346436
Epoch: 18, Steps: 487 Train Loss: 0.4237 (Forecasting Loss:0.3971 + XiCon Loss:2.6568 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3465339
	speed: 0.0152s/iter; left time: 606.0523s
	iters: 200, epoch: 19 | loss: 0.4047607
	speed: 0.0140s/iter; left time: 557.8751s
	iters: 300, epoch: 19 | loss: 0.4290750
	speed: 0.0130s/iter; left time: 516.6222s
	iters: 400, epoch: 19 | loss: 0.5046182
	speed: 0.0136s/iter; left time: 536.1134s
Epoch: 19 cost time: 6.743719100952148
Epoch: 19, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3974 + XiCon Loss:2.6560 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5214
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3571768
	speed: 0.0157s/iter; left time: 618.3197s
	iters: 200, epoch: 20 | loss: 0.4534557
	speed: 0.0131s/iter; left time: 512.2736s
	iters: 300, epoch: 20 | loss: 0.3918512
	speed: 0.0140s/iter; left time: 547.4848s
	iters: 400, epoch: 20 | loss: 0.4279509
	speed: 0.0127s/iter; left time: 497.3239s
Epoch: 20 cost time: 6.776907444000244
Epoch: 20, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6604 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5214
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4644527
	speed: 0.0147s/iter; left time: 572.0027s
	iters: 200, epoch: 21 | loss: 0.4177885
	speed: 0.0133s/iter; left time: 516.6961s
	iters: 300, epoch: 21 | loss: 0.4500397
	speed: 0.0132s/iter; left time: 510.7489s
	iters: 400, epoch: 21 | loss: 0.4496816
	speed: 0.0133s/iter; left time: 513.3483s
Epoch: 21 cost time: 6.618093967437744
Epoch: 21, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6615 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4962970
	speed: 0.0162s/iter; left time: 621.2696s
	iters: 200, epoch: 22 | loss: 0.4148465
	speed: 0.0138s/iter; left time: 527.3970s
	iters: 300, epoch: 22 | loss: 0.4657649
	speed: 0.0131s/iter; left time: 500.2437s
	iters: 400, epoch: 22 | loss: 0.3905065
	speed: 0.0136s/iter; left time: 519.5037s
Epoch: 22 cost time: 6.87073278427124
Epoch: 22, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6605 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5214
Validation loss decreased (0.727252 --> 0.727106).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4213190
	speed: 0.0150s/iter; left time: 567.0921s
	iters: 200, epoch: 23 | loss: 0.4281298
	speed: 0.0130s/iter; left time: 489.5055s
	iters: 300, epoch: 23 | loss: 0.3854997
	speed: 0.0131s/iter; left time: 494.1673s
	iters: 400, epoch: 23 | loss: 0.4101622
	speed: 0.0131s/iter; left time: 492.1949s
Epoch: 23 cost time: 6.563794374465942
Epoch: 23, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3971 + XiCon Loss:2.6642 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4032057
	speed: 0.0159s/iter; left time: 594.5074s
	iters: 200, epoch: 24 | loss: 0.3924422
	speed: 0.0131s/iter; left time: 487.9740s
	iters: 300, epoch: 24 | loss: 0.3955726
	speed: 0.0129s/iter; left time: 478.5431s
	iters: 400, epoch: 24 | loss: 0.4869350
	speed: 0.0133s/iter; left time: 493.1278s
Epoch: 24 cost time: 6.775808811187744
Epoch: 24, Steps: 487 Train Loss: 0.4237 (Forecasting Loss:0.3971 + XiCon Loss:2.6610 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5214
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4643569
	speed: 0.0152s/iter; left time: 562.8291s
	iters: 200, epoch: 25 | loss: 0.3204411
	speed: 0.0134s/iter; left time: 492.2208s
	iters: 300, epoch: 25 | loss: 0.3847967
	speed: 0.0139s/iter; left time: 512.0360s
	iters: 400, epoch: 25 | loss: 0.3977486
	speed: 0.0133s/iter; left time: 485.3346s
Epoch: 25 cost time: 6.745575666427612
Epoch: 25, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6612 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4009032
	speed: 0.0151s/iter; left time: 551.7281s
	iters: 200, epoch: 26 | loss: 0.4291449
	speed: 0.0135s/iter; left time: 490.0587s
	iters: 300, epoch: 26 | loss: 0.3910970
	speed: 0.0127s/iter; left time: 460.4118s
	iters: 400, epoch: 26 | loss: 0.4440498
	speed: 0.0128s/iter; left time: 461.5576s
Epoch: 26 cost time: 6.6011717319488525
Epoch: 26, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3971 + XiCon Loss:2.6652 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5214
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3758502
	speed: 0.0152s/iter; left time: 546.6382s
	iters: 200, epoch: 27 | loss: 0.3925612
	speed: 0.0135s/iter; left time: 484.8250s
	iters: 300, epoch: 27 | loss: 0.4765480
	speed: 0.0133s/iter; left time: 475.1787s
	iters: 400, epoch: 27 | loss: 0.4735456
	speed: 0.0127s/iter; left time: 451.4123s
Epoch: 27 cost time: 6.703282833099365
Epoch: 27, Steps: 487 Train Loss: 0.4237 (Forecasting Loss:0.3972 + XiCon Loss:2.6586 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5214
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4298482
	speed: 0.0150s/iter; left time: 533.2439s
	iters: 200, epoch: 28 | loss: 0.4411415
	speed: 0.0132s/iter; left time: 465.4946s
	iters: 300, epoch: 28 | loss: 0.4080939
	speed: 0.0134s/iter; left time: 471.5447s
	iters: 400, epoch: 28 | loss: 0.3894984
	speed: 0.0130s/iter; left time: 458.5719s
Epoch: 28 cost time: 6.621748208999634
Epoch: 28, Steps: 487 Train Loss: 0.4242 (Forecasting Loss:0.3975 + XiCon Loss:2.6647 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5214
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4488895
	speed: 0.0156s/iter; left time: 546.8286s
	iters: 200, epoch: 29 | loss: 0.4163929
	speed: 0.0130s/iter; left time: 452.1684s
	iters: 300, epoch: 29 | loss: 0.5000668
	speed: 0.0132s/iter; left time: 460.1605s
	iters: 400, epoch: 29 | loss: 0.4960496
	speed: 0.0137s/iter; left time: 475.5901s
Epoch: 29 cost time: 6.780881404876709
Epoch: 29, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6614 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5214
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4904767
	speed: 0.0148s/iter; left time: 508.7054s
	iters: 200, epoch: 30 | loss: 0.4320411
	speed: 0.0125s/iter; left time: 430.9912s
	iters: 300, epoch: 30 | loss: 0.5089902
	speed: 0.0127s/iter; left time: 434.1170s
	iters: 400, epoch: 30 | loss: 0.4363580
	speed: 0.0136s/iter; left time: 463.1317s
Epoch: 30 cost time: 6.583329916000366
Epoch: 30, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6566 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5214
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4337435
	speed: 0.0157s/iter; left time: 533.6199s
	iters: 200, epoch: 31 | loss: 0.3275826
	speed: 0.0124s/iter; left time: 420.6988s
	iters: 300, epoch: 31 | loss: 0.3832494
	speed: 0.0129s/iter; left time: 437.4104s
	iters: 400, epoch: 31 | loss: 0.4506745
	speed: 0.0130s/iter; left time: 437.8966s
Epoch: 31 cost time: 6.5751051902771
Epoch: 31, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6643 x Lambda(0.01)), Vali MSE Loss: 0.7270 Test MSE Loss: 0.5214
Validation loss decreased (0.727106 --> 0.726955).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4058583
	speed: 0.0153s/iter; left time: 511.2452s
	iters: 200, epoch: 32 | loss: 0.4014570
	speed: 0.0129s/iter; left time: 429.3223s
	iters: 300, epoch: 32 | loss: 0.3405605
	speed: 0.0139s/iter; left time: 462.7294s
	iters: 400, epoch: 32 | loss: 0.3200094
	speed: 0.0135s/iter; left time: 446.8443s
Epoch: 32 cost time: 6.750543594360352
Epoch: 32, Steps: 487 Train Loss: 0.4237 (Forecasting Loss:0.3972 + XiCon Loss:2.6533 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3692208
	speed: 0.0155s/iter; left time: 511.8604s
	iters: 200, epoch: 33 | loss: 0.4508990
	speed: 0.0130s/iter; left time: 428.3915s
	iters: 300, epoch: 33 | loss: 0.4270230
	speed: 0.0138s/iter; left time: 454.0498s
	iters: 400, epoch: 33 | loss: 0.3854758
	speed: 0.0131s/iter; left time: 430.0245s
Epoch: 33 cost time: 6.713611125946045
Epoch: 33, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6614 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5214
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4503710
	speed: 0.0157s/iter; left time: 510.1227s
	iters: 200, epoch: 34 | loss: 0.4967778
	speed: 0.0132s/iter; left time: 427.7626s
	iters: 300, epoch: 34 | loss: 0.3921665
	speed: 0.0129s/iter; left time: 418.2310s
	iters: 400, epoch: 34 | loss: 0.4269256
	speed: 0.0134s/iter; left time: 432.2519s
Epoch: 34 cost time: 6.685635089874268
Epoch: 34, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3973 + XiCon Loss:2.6632 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5214
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3716803
	speed: 0.0157s/iter; left time: 503.9106s
	iters: 200, epoch: 35 | loss: 0.3614590
	speed: 0.0143s/iter; left time: 456.3843s
	iters: 300, epoch: 35 | loss: 0.3607198
	speed: 0.0138s/iter; left time: 440.4622s
	iters: 400, epoch: 35 | loss: 0.3976301
	speed: 0.0129s/iter; left time: 408.3288s
Epoch: 35 cost time: 6.885759353637695
Epoch: 35, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.3972 + XiCon Loss:2.6625 x Lambda(0.01)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5214
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4689382
	speed: 0.0151s/iter; left time: 476.2445s
	iters: 200, epoch: 36 | loss: 0.4729416
	speed: 0.0132s/iter; left time: 414.1472s
	iters: 300, epoch: 36 | loss: 0.3853368
	speed: 0.0133s/iter; left time: 418.1594s
	iters: 400, epoch: 36 | loss: 0.4732693
	speed: 0.0133s/iter; left time: 416.1278s
Epoch: 36 cost time: 6.690279722213745
Epoch: 36, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6598 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4099190
	speed: 0.0148s/iter; left time: 461.0551s
	iters: 200, epoch: 37 | loss: 0.3517145
	speed: 0.0130s/iter; left time: 403.8779s
	iters: 300, epoch: 37 | loss: 0.4171314
	speed: 0.0129s/iter; left time: 396.7742s
	iters: 400, epoch: 37 | loss: 0.4716703
	speed: 0.0134s/iter; left time: 413.4476s
Epoch: 37 cost time: 6.570652484893799
Epoch: 37, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6633 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5214
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3983067
	speed: 0.0146s/iter; left time: 445.7883s
	iters: 200, epoch: 38 | loss: 0.4257589
	speed: 0.0130s/iter; left time: 397.4949s
	iters: 300, epoch: 38 | loss: 0.4318959
	speed: 0.0124s/iter; left time: 378.0852s
	iters: 400, epoch: 38 | loss: 0.3709915
	speed: 0.0131s/iter; left time: 395.4402s
Epoch: 38 cost time: 6.593749523162842
Epoch: 38, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6638 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.3831300
	speed: 0.0156s/iter; left time: 469.3304s
	iters: 200, epoch: 39 | loss: 0.3903093
	speed: 0.0127s/iter; left time: 381.2111s
	iters: 300, epoch: 39 | loss: 0.4253142
	speed: 0.0140s/iter; left time: 419.9873s
	iters: 400, epoch: 39 | loss: 0.4203106
	speed: 0.0133s/iter; left time: 397.1530s
Epoch: 39 cost time: 6.6900153160095215
Epoch: 39, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3972 + XiCon Loss:2.6572 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5214
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4756770
	speed: 0.0156s/iter; left time: 461.7898s
	iters: 200, epoch: 40 | loss: 0.4146200
	speed: 0.0136s/iter; left time: 402.3740s
	iters: 300, epoch: 40 | loss: 0.4343131
	speed: 0.0135s/iter; left time: 395.6068s
	iters: 400, epoch: 40 | loss: 0.3293259
	speed: 0.0132s/iter; left time: 388.2370s
Epoch: 40 cost time: 6.7493369579315186
Epoch: 40, Steps: 487 Train Loss: 0.4240 (Forecasting Loss:0.3974 + XiCon Loss:2.6577 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4683275
	speed: 0.0152s/iter; left time: 442.2803s
	iters: 200, epoch: 41 | loss: 0.3550155
	speed: 0.0132s/iter; left time: 383.2877s
	iters: 300, epoch: 41 | loss: 0.3999449
	speed: 0.0122s/iter; left time: 353.0979s
	iters: 400, epoch: 41 | loss: 0.3980954
	speed: 0.0131s/iter; left time: 378.3225s
Epoch: 41 cost time: 6.589540958404541
Epoch: 41, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.3973 + XiCon Loss:2.6575 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5214
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5307210683822632, mae:0.5120498538017273, mape:3.6044158935546875, mspe:1211.864501953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.4124
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1092558
	speed: 0.0155s/iter; left time: 754.8330s
	iters: 200, epoch: 1 | loss: 0.8702701
	speed: 0.0140s/iter; left time: 678.5076s
	iters: 300, epoch: 1 | loss: 0.7740153
	speed: 0.0127s/iter; left time: 616.0462s
	iters: 400, epoch: 1 | loss: 0.8371021
	speed: 0.0113s/iter; left time: 547.4858s
Epoch: 1 cost time: 6.356968879699707
Epoch: 1, Steps: 487 Train Loss: 0.8273 (Forecasting Loss:0.8010 + XiCon Loss:2.6295 x Lambda(0.01)), Vali MSE Loss: 1.0984 Test MSE Loss: 0.6609
Validation loss decreased (inf --> 1.098372).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5771649
	speed: 0.0153s/iter; left time: 734.7560s
	iters: 200, epoch: 2 | loss: 0.4391890
	speed: 0.0126s/iter; left time: 606.0458s
	iters: 300, epoch: 2 | loss: 0.4313056
	speed: 0.0132s/iter; left time: 630.8932s
	iters: 400, epoch: 2 | loss: 0.3941355
	speed: 0.0127s/iter; left time: 607.0891s
Epoch: 2 cost time: 6.554665803909302
Epoch: 2, Steps: 487 Train Loss: 0.4615 (Forecasting Loss:0.4353 + XiCon Loss:2.6266 x Lambda(0.01)), Vali MSE Loss: 0.7548 Test MSE Loss: 0.5191
Validation loss decreased (1.098372 --> 0.754789).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4398004
	speed: 0.0159s/iter; left time: 759.4858s
	iters: 200, epoch: 3 | loss: 0.4508728
	speed: 0.0135s/iter; left time: 643.8144s
	iters: 300, epoch: 3 | loss: 0.4305019
	speed: 0.0129s/iter; left time: 611.1511s
	iters: 400, epoch: 3 | loss: 0.4654078
	speed: 0.0130s/iter; left time: 614.7086s
Epoch: 3 cost time: 6.656820297241211
Epoch: 3, Steps: 487 Train Loss: 0.4285 (Forecasting Loss:0.4023 + XiCon Loss:2.6265 x Lambda(0.01)), Vali MSE Loss: 0.7486 Test MSE Loss: 0.5120
Validation loss decreased (0.754789 --> 0.748640).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4156901
	speed: 0.0152s/iter; left time: 716.5151s
	iters: 200, epoch: 4 | loss: 0.4273555
	speed: 0.0130s/iter; left time: 612.9617s
	iters: 300, epoch: 4 | loss: 0.4988326
	speed: 0.0128s/iter; left time: 600.3306s
	iters: 400, epoch: 4 | loss: 0.3633471
	speed: 0.0126s/iter; left time: 590.1840s
Epoch: 4 cost time: 6.5609002113342285
Epoch: 4, Steps: 487 Train Loss: 0.4236 (Forecasting Loss:0.3973 + XiCon Loss:2.6266 x Lambda(0.01)), Vali MSE Loss: 0.7408 Test MSE Loss: 0.5092
Validation loss decreased (0.748640 --> 0.740815).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4004782
	speed: 0.0155s/iter; left time: 721.9071s
	iters: 200, epoch: 5 | loss: 0.4513856
	speed: 0.0129s/iter; left time: 602.0327s
	iters: 300, epoch: 5 | loss: 0.4441847
	speed: 0.0129s/iter; left time: 597.3127s
	iters: 400, epoch: 5 | loss: 0.4301084
	speed: 0.0138s/iter; left time: 641.9181s
Epoch: 5 cost time: 6.660462141036987
Epoch: 5, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3951 + XiCon Loss:2.6298 x Lambda(0.01)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5092
Validation loss decreased (0.740815 --> 0.738959).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4357813
	speed: 0.0153s/iter; left time: 705.3484s
	iters: 200, epoch: 6 | loss: 0.3861981
	speed: 0.0130s/iter; left time: 599.7864s
	iters: 300, epoch: 6 | loss: 0.4857280
	speed: 0.0131s/iter; left time: 600.5251s
	iters: 400, epoch: 6 | loss: 0.5305363
	speed: 0.0129s/iter; left time: 592.1201s
Epoch: 6 cost time: 6.556765556335449
Epoch: 6, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3941 + XiCon Loss:2.6265 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5086
Validation loss decreased (0.738959 --> 0.737588).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4071991
	speed: 0.0158s/iter; left time: 722.2292s
	iters: 200, epoch: 7 | loss: 0.3808175
	speed: 0.0142s/iter; left time: 648.2925s
	iters: 300, epoch: 7 | loss: 0.4049630
	speed: 0.0137s/iter; left time: 624.3970s
	iters: 400, epoch: 7 | loss: 0.4108342
	speed: 0.0134s/iter; left time: 606.0871s
Epoch: 7 cost time: 6.878984451293945
Epoch: 7, Steps: 487 Train Loss: 0.4198 (Forecasting Loss:0.3936 + XiCon Loss:2.6209 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5082
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4520753
	speed: 0.0148s/iter; left time: 667.1988s
	iters: 200, epoch: 8 | loss: 0.4806671
	speed: 0.0126s/iter; left time: 569.6752s
	iters: 300, epoch: 8 | loss: 0.4092386
	speed: 0.0138s/iter; left time: 622.0773s
	iters: 400, epoch: 8 | loss: 0.3729185
	speed: 0.0133s/iter; left time: 595.9641s
Epoch: 8 cost time: 6.598891973495483
Epoch: 8, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3932 + XiCon Loss:2.6225 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
Validation loss decreased (0.737588 --> 0.737127).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4101472
	speed: 0.0163s/iter; left time: 729.8443s
	iters: 200, epoch: 9 | loss: 0.4074355
	speed: 0.0124s/iter; left time: 553.0603s
	iters: 300, epoch: 9 | loss: 0.4479633
	speed: 0.0133s/iter; left time: 590.1562s
	iters: 400, epoch: 9 | loss: 0.4525139
	speed: 0.0129s/iter; left time: 574.7969s
Epoch: 9 cost time: 6.640724182128906
Epoch: 9, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3933 + XiCon Loss:2.6260 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5080
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4359185
	speed: 0.0148s/iter; left time: 655.5585s
	iters: 200, epoch: 10 | loss: 0.4223190
	speed: 0.0137s/iter; left time: 604.9307s
	iters: 300, epoch: 10 | loss: 0.4979298
	speed: 0.0127s/iter; left time: 557.6341s
	iters: 400, epoch: 10 | loss: 0.4470591
	speed: 0.0133s/iter; left time: 585.3312s
Epoch: 10 cost time: 6.68435525894165
Epoch: 10, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3930 + XiCon Loss:2.6218 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4086628
	speed: 0.0149s/iter; left time: 653.3239s
	iters: 200, epoch: 11 | loss: 0.3581746
	speed: 0.0124s/iter; left time: 542.0655s
	iters: 300, epoch: 11 | loss: 0.3819985
	speed: 0.0133s/iter; left time: 577.2760s
	iters: 400, epoch: 11 | loss: 0.3644043
	speed: 0.0130s/iter; left time: 563.1507s
Epoch: 11 cost time: 6.589469909667969
Epoch: 11, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3929 + XiCon Loss:2.6225 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
Validation loss decreased (0.737127 --> 0.736965).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.5096952
	speed: 0.0147s/iter; left time: 635.4307s
	iters: 200, epoch: 12 | loss: 0.4221877
	speed: 0.0130s/iter; left time: 562.7660s
	iters: 300, epoch: 12 | loss: 0.4884188
	speed: 0.0132s/iter; left time: 568.9729s
	iters: 400, epoch: 12 | loss: 0.3789955
	speed: 0.0130s/iter; left time: 558.9676s
Epoch: 12 cost time: 6.586835861206055
Epoch: 12, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3931 + XiCon Loss:2.6273 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4520502
	speed: 0.0140s/iter; left time: 599.4194s
	iters: 200, epoch: 13 | loss: 0.4176371
	speed: 0.0128s/iter; left time: 546.8234s
	iters: 300, epoch: 13 | loss: 0.3482987
	speed: 0.0134s/iter; left time: 568.3956s
	iters: 400, epoch: 13 | loss: 0.4193749
	speed: 0.0133s/iter; left time: 563.1323s
Epoch: 13 cost time: 6.542140007019043
Epoch: 13, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3929 + XiCon Loss:2.6220 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3861777
	speed: 0.0147s/iter; left time: 620.0828s
	iters: 200, epoch: 14 | loss: 0.3413942
	speed: 0.0124s/iter; left time: 521.0192s
	iters: 300, epoch: 14 | loss: 0.3595725
	speed: 0.0140s/iter; left time: 588.4084s
	iters: 400, epoch: 14 | loss: 0.4149458
	speed: 0.0133s/iter; left time: 557.3676s
Epoch: 14 cost time: 6.616811037063599
Epoch: 14, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3928 + XiCon Loss:2.6228 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4409819
	speed: 0.0154s/iter; left time: 641.5259s
	iters: 200, epoch: 15 | loss: 0.4154836
	speed: 0.0134s/iter; left time: 557.9545s
	iters: 300, epoch: 15 | loss: 0.5444130
	speed: 0.0128s/iter; left time: 533.8202s
	iters: 400, epoch: 15 | loss: 0.3645304
	speed: 0.0141s/iter; left time: 583.6153s
Epoch: 15 cost time: 6.762843370437622
Epoch: 15, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3934 + XiCon Loss:2.6209 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736965 --> 0.736914).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3764372
	speed: 0.0158s/iter; left time: 652.7971s
	iters: 200, epoch: 16 | loss: 0.3596423
	speed: 0.0133s/iter; left time: 546.6832s
	iters: 300, epoch: 16 | loss: 0.4086656
	speed: 0.0137s/iter; left time: 561.9733s
	iters: 400, epoch: 16 | loss: 0.3988450
	speed: 0.0140s/iter; left time: 575.8817s
Epoch: 16 cost time: 6.867680788040161
Epoch: 16, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3928 + XiCon Loss:2.6183 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4032902
	speed: 0.0158s/iter; left time: 643.3722s
	iters: 200, epoch: 17 | loss: 0.4007509
	speed: 0.0134s/iter; left time: 545.7685s
	iters: 300, epoch: 17 | loss: 0.4256891
	speed: 0.0141s/iter; left time: 572.2510s
	iters: 400, epoch: 17 | loss: 0.4292783
	speed: 0.0139s/iter; left time: 562.0047s
Epoch: 17 cost time: 6.902923345565796
Epoch: 17, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3930 + XiCon Loss:2.6289 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5068434
	speed: 0.0157s/iter; left time: 631.9662s
	iters: 200, epoch: 18 | loss: 0.4381250
	speed: 0.0127s/iter; left time: 510.7283s
	iters: 300, epoch: 18 | loss: 0.3765557
	speed: 0.0133s/iter; left time: 533.0282s
	iters: 400, epoch: 18 | loss: 0.3520753
	speed: 0.0135s/iter; left time: 540.6160s
Epoch: 18 cost time: 6.694284200668335
Epoch: 18, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3930 + XiCon Loss:2.6241 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4399210
	speed: 0.0152s/iter; left time: 607.2714s
	iters: 200, epoch: 19 | loss: 0.4200910
	speed: 0.0131s/iter; left time: 519.9328s
	iters: 300, epoch: 19 | loss: 0.3279549
	speed: 0.0140s/iter; left time: 555.4182s
	iters: 400, epoch: 19 | loss: 0.4676405
	speed: 0.0130s/iter; left time: 512.2277s
Epoch: 19 cost time: 6.714065074920654
Epoch: 19, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3931 + XiCon Loss:2.6258 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4357957
	speed: 0.0151s/iter; left time: 592.6598s
	iters: 200, epoch: 20 | loss: 0.3898877
	speed: 0.0129s/iter; left time: 504.3870s
	iters: 300, epoch: 20 | loss: 0.3785678
	speed: 0.0135s/iter; left time: 529.5200s
	iters: 400, epoch: 20 | loss: 0.3562124
	speed: 0.0134s/iter; left time: 524.6236s
Epoch: 20 cost time: 6.6862099170684814
Epoch: 20, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3931 + XiCon Loss:2.6233 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736914 --> 0.736912).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4400396
	speed: 0.0160s/iter; left time: 622.5449s
	iters: 200, epoch: 21 | loss: 0.4312192
	speed: 0.0124s/iter; left time: 481.0542s
	iters: 300, epoch: 21 | loss: 0.3529895
	speed: 0.0132s/iter; left time: 509.1827s
	iters: 400, epoch: 21 | loss: 0.3789984
	speed: 0.0131s/iter; left time: 504.0002s
Epoch: 21 cost time: 6.6220383644104
Epoch: 21, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3929 + XiCon Loss:2.6285 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4229009
	speed: 0.0158s/iter; left time: 605.3789s
	iters: 200, epoch: 22 | loss: 0.4351850
	speed: 0.0137s/iter; left time: 525.9350s
	iters: 300, epoch: 22 | loss: 0.4468233
	speed: 0.0137s/iter; left time: 524.2106s
	iters: 400, epoch: 22 | loss: 0.3948715
	speed: 0.0143s/iter; left time: 543.3932s
Epoch: 22 cost time: 6.953658580780029
Epoch: 22, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3929 + XiCon Loss:2.6273 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3627614
	speed: 0.0161s/iter; left time: 611.0420s
	iters: 200, epoch: 23 | loss: 0.3883539
	speed: 0.0134s/iter; left time: 506.4330s
	iters: 300, epoch: 23 | loss: 0.4765054
	speed: 0.0136s/iter; left time: 511.2716s
	iters: 400, epoch: 23 | loss: 0.4292146
	speed: 0.0143s/iter; left time: 536.5672s
Epoch: 23 cost time: 6.897271633148193
Epoch: 23, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3929 + XiCon Loss:2.6257 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4386895
	speed: 0.0157s/iter; left time: 586.9764s
	iters: 200, epoch: 24 | loss: 0.4675193
	speed: 0.0128s/iter; left time: 477.7542s
	iters: 300, epoch: 24 | loss: 0.3444335
	speed: 0.0133s/iter; left time: 493.1647s
	iters: 400, epoch: 24 | loss: 0.4513513
	speed: 0.0136s/iter; left time: 506.1247s
Epoch: 24 cost time: 6.704454660415649
Epoch: 24, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3930 + XiCon Loss:2.6214 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4059395
	speed: 0.0155s/iter; left time: 570.8719s
	iters: 200, epoch: 25 | loss: 0.3651072
	speed: 0.0141s/iter; left time: 517.6481s
	iters: 300, epoch: 25 | loss: 0.4143123
	speed: 0.0131s/iter; left time: 480.8345s
	iters: 400, epoch: 25 | loss: 0.4470419
	speed: 0.0135s/iter; left time: 495.2025s
Epoch: 25 cost time: 6.808575391769409
Epoch: 25, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3930 + XiCon Loss:2.6282 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5079
Validation loss decreased (0.736912 --> 0.736571).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4170099
	speed: 0.0156s/iter; left time: 569.1023s
	iters: 200, epoch: 26 | loss: 0.3715671
	speed: 0.0134s/iter; left time: 485.5225s
	iters: 300, epoch: 26 | loss: 0.4465164
	speed: 0.0135s/iter; left time: 490.7822s
	iters: 400, epoch: 26 | loss: 0.4712946
	speed: 0.0130s/iter; left time: 471.3429s
Epoch: 26 cost time: 6.765292406082153
Epoch: 26, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3928 + XiCon Loss:2.6230 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4175943
	speed: 0.0158s/iter; left time: 566.4251s
	iters: 200, epoch: 27 | loss: 0.4602285
	speed: 0.0127s/iter; left time: 455.9301s
	iters: 300, epoch: 27 | loss: 0.3681783
	speed: 0.0137s/iter; left time: 489.4486s
	iters: 400, epoch: 27 | loss: 0.4205456
	speed: 0.0133s/iter; left time: 474.9794s
Epoch: 27 cost time: 6.74118709564209
Epoch: 27, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3929 + XiCon Loss:2.6266 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3920056
	speed: 0.0156s/iter; left time: 552.1731s
	iters: 200, epoch: 28 | loss: 0.3870107
	speed: 0.0139s/iter; left time: 491.1557s
	iters: 300, epoch: 28 | loss: 0.3784288
	speed: 0.0135s/iter; left time: 475.7898s
	iters: 400, epoch: 28 | loss: 0.4429723
	speed: 0.0134s/iter; left time: 470.7119s
Epoch: 28 cost time: 6.906914472579956
Epoch: 28, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3931 + XiCon Loss:2.6238 x Lambda(0.01)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5079
Validation loss decreased (0.736571 --> 0.736469).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4742669
	speed: 0.0158s/iter; left time: 552.5494s
	iters: 200, epoch: 29 | loss: 0.4269183
	speed: 0.0133s/iter; left time: 462.3165s
	iters: 300, epoch: 29 | loss: 0.3838111
	speed: 0.0130s/iter; left time: 452.0950s
	iters: 400, epoch: 29 | loss: 0.4200536
	speed: 0.0127s/iter; left time: 438.9930s
Epoch: 29 cost time: 6.64935302734375
Epoch: 29, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3929 + XiCon Loss:2.6247 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4768234
	speed: 0.0154s/iter; left time: 532.6720s
	iters: 200, epoch: 30 | loss: 0.4526385
	speed: 0.0133s/iter; left time: 456.4647s
	iters: 300, epoch: 30 | loss: 0.4085551
	speed: 0.0132s/iter; left time: 453.2371s
	iters: 400, epoch: 30 | loss: 0.3844516
	speed: 0.0127s/iter; left time: 433.4126s
Epoch: 30 cost time: 6.7418742179870605
Epoch: 30, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3930 + XiCon Loss:2.6276 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3746192
	speed: 0.0153s/iter; left time: 519.8648s
	iters: 200, epoch: 31 | loss: 0.3307805
	speed: 0.0129s/iter; left time: 437.2783s
	iters: 300, epoch: 31 | loss: 0.4559034
	speed: 0.0134s/iter; left time: 452.4766s
	iters: 400, epoch: 31 | loss: 0.4111850
	speed: 0.0127s/iter; left time: 428.9035s
Epoch: 31 cost time: 6.633696556091309
Epoch: 31, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3930 + XiCon Loss:2.6233 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4668929
	speed: 0.0147s/iter; left time: 491.8620s
	iters: 200, epoch: 32 | loss: 0.4866888
	speed: 0.0134s/iter; left time: 446.8177s
	iters: 300, epoch: 32 | loss: 0.4025868
	speed: 0.0143s/iter; left time: 476.3138s
	iters: 400, epoch: 32 | loss: 0.4274020
	speed: 0.0125s/iter; left time: 415.7445s
Epoch: 32 cost time: 6.770212888717651
Epoch: 32, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3930 + XiCon Loss:2.6252 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4486582
	speed: 0.0155s/iter; left time: 510.5312s
	iters: 200, epoch: 33 | loss: 0.4429743
	speed: 0.0122s/iter; left time: 402.1914s
	iters: 300, epoch: 33 | loss: 0.3785243
	speed: 0.0135s/iter; left time: 444.4207s
	iters: 400, epoch: 33 | loss: 0.3665821
	speed: 0.0135s/iter; left time: 441.0796s
Epoch: 33 cost time: 6.660842418670654
Epoch: 33, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3929 + XiCon Loss:2.6209 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3787253
	speed: 0.0170s/iter; left time: 552.5528s
	iters: 200, epoch: 34 | loss: 0.4258258
	speed: 0.0130s/iter; left time: 422.5545s
	iters: 300, epoch: 34 | loss: 0.3344539
	speed: 0.0137s/iter; left time: 443.5564s
	iters: 400, epoch: 34 | loss: 0.3675369
	speed: 0.0140s/iter; left time: 450.0713s
Epoch: 34 cost time: 7.001203298568726
Epoch: 34, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3930 + XiCon Loss:2.6226 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4109368
	speed: 0.0148s/iter; left time: 474.0013s
	iters: 200, epoch: 35 | loss: 0.4440071
	speed: 0.0128s/iter; left time: 407.6850s
	iters: 300, epoch: 35 | loss: 0.3680764
	speed: 0.0137s/iter; left time: 435.5003s
	iters: 400, epoch: 35 | loss: 0.3602623
	speed: 0.0131s/iter; left time: 416.0312s
Epoch: 35 cost time: 6.596414566040039
Epoch: 35, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3932 + XiCon Loss:2.6222 x Lambda(0.01)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5079
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.3916573
	speed: 0.0151s/iter; left time: 475.0184s
	iters: 200, epoch: 36 | loss: 0.5073990
	speed: 0.0138s/iter; left time: 432.9695s
	iters: 300, epoch: 36 | loss: 0.3775638
	speed: 0.0130s/iter; left time: 406.1596s
	iters: 400, epoch: 36 | loss: 0.4695821
	speed: 0.0134s/iter; left time: 418.0524s
Epoch: 36 cost time: 6.726318359375
Epoch: 36, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3928 + XiCon Loss:2.6237 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3942576
	speed: 0.0152s/iter; left time: 471.7487s
	iters: 200, epoch: 37 | loss: 0.4286925
	speed: 0.0135s/iter; left time: 416.9202s
	iters: 300, epoch: 37 | loss: 0.4708628
	speed: 0.0132s/iter; left time: 408.3530s
	iters: 400, epoch: 37 | loss: 0.4146970
	speed: 0.0135s/iter; left time: 415.6371s
Epoch: 37 cost time: 6.658154249191284
Epoch: 37, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3930 + XiCon Loss:2.6217 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3656693
	speed: 0.0153s/iter; left time: 468.3891s
	iters: 200, epoch: 38 | loss: 0.3590148
	speed: 0.0132s/iter; left time: 402.6450s
	iters: 300, epoch: 38 | loss: 0.4425552
	speed: 0.0126s/iter; left time: 381.8910s
	iters: 400, epoch: 38 | loss: 0.4484839
	speed: 0.0132s/iter; left time: 398.8637s
Epoch: 38 cost time: 6.710480213165283
Epoch: 38, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3929 + XiCon Loss:2.6291 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5129405856132507, mae:0.5028850436210632, mape:3.5703647136688232, mspe:1174.8885498046875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.3352
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8759356
	speed: 0.0142s/iter; left time: 691.2480s
	iters: 200, epoch: 1 | loss: 0.8417083
	speed: 0.0137s/iter; left time: 663.7846s
	iters: 300, epoch: 1 | loss: 0.7431151
	speed: 0.0128s/iter; left time: 617.4184s
	iters: 400, epoch: 1 | loss: 0.6639085
	speed: 0.0129s/iter; left time: 622.6611s
Epoch: 1 cost time: 6.5318522453308105
Epoch: 1, Steps: 487 Train Loss: 0.7795 (Forecasting Loss:0.7529 + XiCon Loss:2.6664 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005157).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5238748
	speed: 0.0158s/iter; left time: 760.4691s
	iters: 200, epoch: 2 | loss: 0.4362850
	speed: 0.0133s/iter; left time: 638.7012s
	iters: 300, epoch: 2 | loss: 0.5778841
	speed: 0.0136s/iter; left time: 649.3087s
	iters: 400, epoch: 2 | loss: 0.4233164
	speed: 0.0130s/iter; left time: 620.6391s
Epoch: 2 cost time: 6.739331483840942
Epoch: 2, Steps: 487 Train Loss: 0.4627 (Forecasting Loss:0.4361 + XiCon Loss:2.6607 x Lambda(0.01)), Vali MSE Loss: 0.7607 Test MSE Loss: 0.5392
Validation loss decreased (1.005157 --> 0.760659).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4793991
	speed: 0.0155s/iter; left time: 736.7358s
	iters: 200, epoch: 3 | loss: 0.4062323
	speed: 0.0133s/iter; left time: 631.7063s
	iters: 300, epoch: 3 | loss: 0.5061175
	speed: 0.0133s/iter; left time: 631.0301s
	iters: 400, epoch: 3 | loss: 0.3816607
	speed: 0.0131s/iter; left time: 622.2393s
Epoch: 3 cost time: 6.687439680099487
Epoch: 3, Steps: 487 Train Loss: 0.4327 (Forecasting Loss:0.4061 + XiCon Loss:2.6566 x Lambda(0.01)), Vali MSE Loss: 0.7459 Test MSE Loss: 0.5193
Validation loss decreased (0.760659 --> 0.745927).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5111712
	speed: 0.0147s/iter; left time: 691.2292s
	iters: 200, epoch: 4 | loss: 0.4256880
	speed: 0.0136s/iter; left time: 641.1055s
	iters: 300, epoch: 4 | loss: 0.4173802
	speed: 0.0141s/iter; left time: 660.1019s
	iters: 400, epoch: 4 | loss: 0.3176434
	speed: 0.0137s/iter; left time: 640.7950s
Epoch: 4 cost time: 6.853623867034912
Epoch: 4, Steps: 487 Train Loss: 0.4268 (Forecasting Loss:0.4003 + XiCon Loss:2.6501 x Lambda(0.01)), Vali MSE Loss: 0.7463 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3857117
	speed: 0.0158s/iter; left time: 736.1623s
	iters: 200, epoch: 5 | loss: 0.4862384
	speed: 0.0132s/iter; left time: 613.8145s
	iters: 300, epoch: 5 | loss: 0.4069266
	speed: 0.0131s/iter; left time: 609.6216s
	iters: 400, epoch: 5 | loss: 0.4716732
	speed: 0.0131s/iter; left time: 607.7911s
Epoch: 5 cost time: 6.739480257034302
Epoch: 5, Steps: 487 Train Loss: 0.4247 (Forecasting Loss:0.3982 + XiCon Loss:2.6527 x Lambda(0.01)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5126
Validation loss decreased (0.745927 --> 0.739135).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4711963
	speed: 0.0154s/iter; left time: 713.0252s
	iters: 200, epoch: 6 | loss: 0.4474865
	speed: 0.0135s/iter; left time: 619.9218s
	iters: 300, epoch: 6 | loss: 0.5946998
	speed: 0.0127s/iter; left time: 583.9371s
	iters: 400, epoch: 6 | loss: 0.4901060
	speed: 0.0122s/iter; left time: 558.6620s
Epoch: 6 cost time: 6.563108682632446
Epoch: 6, Steps: 487 Train Loss: 0.4235 (Forecasting Loss:0.3969 + XiCon Loss:2.6551 x Lambda(0.01)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5117
Validation loss decreased (0.739135 --> 0.738564).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3524460
	speed: 0.0153s/iter; left time: 698.3780s
	iters: 200, epoch: 7 | loss: 0.3848801
	speed: 0.0133s/iter; left time: 607.2231s
	iters: 300, epoch: 7 | loss: 0.3443437
	speed: 0.0134s/iter; left time: 609.6702s
	iters: 400, epoch: 7 | loss: 0.3769718
	speed: 0.0139s/iter; left time: 629.5263s
Epoch: 7 cost time: 6.882118225097656
Epoch: 7, Steps: 487 Train Loss: 0.4230 (Forecasting Loss:0.3965 + XiCon Loss:2.6511 x Lambda(0.01)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5126
Validation loss decreased (0.738564 --> 0.738329).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3796186
	speed: 0.0156s/iter; left time: 704.4227s
	iters: 200, epoch: 8 | loss: 0.4115035
	speed: 0.0129s/iter; left time: 583.4703s
	iters: 300, epoch: 8 | loss: 0.5723739
	speed: 0.0130s/iter; left time: 587.0821s
	iters: 400, epoch: 8 | loss: 0.4537661
	speed: 0.0139s/iter; left time: 623.1333s
Epoch: 8 cost time: 6.780977010726929
Epoch: 8, Steps: 487 Train Loss: 0.4226 (Forecasting Loss:0.3961 + XiCon Loss:2.6522 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5118
Validation loss decreased (0.738329 --> 0.737792).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3821065
	speed: 0.0152s/iter; left time: 679.7821s
	iters: 200, epoch: 9 | loss: 0.5099786
	speed: 0.0127s/iter; left time: 567.2664s
	iters: 300, epoch: 9 | loss: 0.4953234
	speed: 0.0127s/iter; left time: 565.7449s
	iters: 400, epoch: 9 | loss: 0.4308352
	speed: 0.0132s/iter; left time: 587.3537s
Epoch: 9 cost time: 6.631190776824951
Epoch: 9, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3960 + XiCon Loss:2.6533 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5120
Validation loss decreased (0.737792 --> 0.737716).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3892065
	speed: 0.0162s/iter; left time: 716.2803s
	iters: 200, epoch: 10 | loss: 0.4858052
	speed: 0.0136s/iter; left time: 601.9567s
	iters: 300, epoch: 10 | loss: 0.4052640
	speed: 0.0140s/iter; left time: 618.2064s
	iters: 400, epoch: 10 | loss: 0.4335080
	speed: 0.0133s/iter; left time: 582.8293s
Epoch: 10 cost time: 6.962264776229858
Epoch: 10, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3958 + XiCon Loss:2.6549 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
Validation loss decreased (0.737716 --> 0.737680).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4029301
	speed: 0.0144s/iter; left time: 630.4464s
	iters: 200, epoch: 11 | loss: 0.4316933
	speed: 0.0128s/iter; left time: 558.4463s
	iters: 300, epoch: 11 | loss: 0.3641105
	speed: 0.0129s/iter; left time: 563.0092s
	iters: 400, epoch: 11 | loss: 0.4231738
	speed: 0.0131s/iter; left time: 569.8451s
Epoch: 11 cost time: 6.493650674819946
Epoch: 11, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6506 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4640289
	speed: 0.0154s/iter; left time: 667.4794s
	iters: 200, epoch: 12 | loss: 0.2956515
	speed: 0.0134s/iter; left time: 578.2364s
	iters: 300, epoch: 12 | loss: 0.4279091
	speed: 0.0131s/iter; left time: 564.1797s
	iters: 400, epoch: 12 | loss: 0.4600489
	speed: 0.0129s/iter; left time: 554.3447s
Epoch: 12 cost time: 6.645208835601807
Epoch: 12, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6482 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
Validation loss decreased (0.737680 --> 0.737360).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3964462
	speed: 0.0158s/iter; left time: 674.0627s
	iters: 200, epoch: 13 | loss: 0.3463928
	speed: 0.0139s/iter; left time: 591.7798s
	iters: 300, epoch: 13 | loss: 0.4136836
	speed: 0.0131s/iter; left time: 559.5891s
	iters: 400, epoch: 13 | loss: 0.4073820
	speed: 0.0136s/iter; left time: 575.5948s
Epoch: 13 cost time: 6.936433792114258
Epoch: 13, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6551 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3775396
	speed: 0.0159s/iter; left time: 672.0919s
	iters: 200, epoch: 14 | loss: 0.3693602
	speed: 0.0139s/iter; left time: 585.5055s
	iters: 300, epoch: 14 | loss: 0.4058293
	speed: 0.0131s/iter; left time: 550.2561s
	iters: 400, epoch: 14 | loss: 0.3895677
	speed: 0.0135s/iter; left time: 568.4684s
Epoch: 14 cost time: 6.8603644371032715
Epoch: 14, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3956 + XiCon Loss:2.6542 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4184138
	speed: 0.0154s/iter; left time: 643.7557s
	iters: 200, epoch: 15 | loss: 0.4023176
	speed: 0.0135s/iter; left time: 561.7159s
	iters: 300, epoch: 15 | loss: 0.4205529
	speed: 0.0137s/iter; left time: 568.5728s
	iters: 400, epoch: 15 | loss: 0.4667577
	speed: 0.0133s/iter; left time: 551.6571s
Epoch: 15 cost time: 6.798120975494385
Epoch: 15, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3959 + XiCon Loss:2.6559 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4489063
	speed: 0.0158s/iter; left time: 651.4043s
	iters: 200, epoch: 16 | loss: 0.3928706
	speed: 0.0138s/iter; left time: 567.2305s
	iters: 300, epoch: 16 | loss: 0.4903323
	speed: 0.0131s/iter; left time: 536.9124s
	iters: 400, epoch: 16 | loss: 0.4299415
	speed: 0.0121s/iter; left time: 498.0302s
Epoch: 16 cost time: 6.64077353477478
Epoch: 16, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3960 + XiCon Loss:2.6511 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3368840
	speed: 0.0162s/iter; left time: 661.1149s
	iters: 200, epoch: 17 | loss: 0.4048256
	speed: 0.0136s/iter; left time: 553.7477s
	iters: 300, epoch: 17 | loss: 0.3702396
	speed: 0.0132s/iter; left time: 536.6069s
	iters: 400, epoch: 17 | loss: 0.3439368
	speed: 0.0129s/iter; left time: 520.6586s
Epoch: 17 cost time: 6.783935070037842
Epoch: 17, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6508 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4313140
	speed: 0.0153s/iter; left time: 618.7524s
	iters: 200, epoch: 18 | loss: 0.4156254
	speed: 0.0128s/iter; left time: 514.1015s
	iters: 300, epoch: 18 | loss: 0.4351797
	speed: 0.0138s/iter; left time: 552.6878s
	iters: 400, epoch: 18 | loss: 0.3460383
	speed: 0.0131s/iter; left time: 526.2096s
Epoch: 18 cost time: 6.732498645782471
Epoch: 18, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3958 + XiCon Loss:2.6530 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4463485
	speed: 0.0154s/iter; left time: 614.7654s
	iters: 200, epoch: 19 | loss: 0.4692169
	speed: 0.0131s/iter; left time: 519.4119s
	iters: 300, epoch: 19 | loss: 0.3560036
	speed: 0.0131s/iter; left time: 520.2231s
	iters: 400, epoch: 19 | loss: 0.4985371
	speed: 0.0132s/iter; left time: 520.2109s
Epoch: 19 cost time: 6.675825834274292
Epoch: 19, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3957 + XiCon Loss:2.6508 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4158182
	speed: 0.0153s/iter; left time: 601.3033s
	iters: 200, epoch: 20 | loss: 0.3586029
	speed: 0.0132s/iter; left time: 518.7687s
	iters: 300, epoch: 20 | loss: 0.5567602
	speed: 0.0135s/iter; left time: 528.5564s
	iters: 400, epoch: 20 | loss: 0.4404051
	speed: 0.0131s/iter; left time: 510.5248s
Epoch: 20 cost time: 6.772966146469116
Epoch: 20, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3957 + XiCon Loss:2.6534 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
Validation loss decreased (0.737360 --> 0.737055).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4430041
	speed: 0.0152s/iter; left time: 591.5935s
	iters: 200, epoch: 21 | loss: 0.3669046
	speed: 0.0130s/iter; left time: 503.1720s
	iters: 300, epoch: 21 | loss: 0.3649677
	speed: 0.0133s/iter; left time: 512.2592s
	iters: 400, epoch: 21 | loss: 0.4158884
	speed: 0.0138s/iter; left time: 531.5646s
Epoch: 21 cost time: 6.642451047897339
Epoch: 21, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3957 + XiCon Loss:2.6512 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4260433
	speed: 0.0158s/iter; left time: 605.0613s
	iters: 200, epoch: 22 | loss: 0.3997940
	speed: 0.0133s/iter; left time: 508.4215s
	iters: 300, epoch: 22 | loss: 0.4059817
	speed: 0.0125s/iter; left time: 477.7411s
	iters: 400, epoch: 22 | loss: 0.4219332
	speed: 0.0128s/iter; left time: 487.5942s
Epoch: 22 cost time: 6.670978784561157
Epoch: 22, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6498 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4299960
	speed: 0.0155s/iter; left time: 588.6043s
	iters: 200, epoch: 23 | loss: 0.4797217
	speed: 0.0142s/iter; left time: 535.4597s
	iters: 300, epoch: 23 | loss: 0.4497262
	speed: 0.0142s/iter; left time: 536.1989s
	iters: 400, epoch: 23 | loss: 0.4509258
	speed: 0.0134s/iter; left time: 504.7444s
Epoch: 23 cost time: 6.9685118198394775
Epoch: 23, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6499 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4640797
	speed: 0.0160s/iter; left time: 599.8114s
	iters: 200, epoch: 24 | loss: 0.4494171
	speed: 0.0125s/iter; left time: 466.9037s
	iters: 300, epoch: 24 | loss: 0.4286411
	speed: 0.0131s/iter; left time: 488.8668s
	iters: 400, epoch: 24 | loss: 0.3851375
	speed: 0.0131s/iter; left time: 487.5028s
Epoch: 24 cost time: 6.696610450744629
Epoch: 24, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3960 + XiCon Loss:2.6488 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5117
Validation loss decreased (0.737055 --> 0.736937).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4539885
	speed: 0.0152s/iter; left time: 561.8921s
	iters: 200, epoch: 25 | loss: 0.4479360
	speed: 0.0135s/iter; left time: 496.0779s
	iters: 300, epoch: 25 | loss: 0.4267906
	speed: 0.0131s/iter; left time: 480.8562s
	iters: 400, epoch: 25 | loss: 0.4802853
	speed: 0.0137s/iter; left time: 503.3956s
Epoch: 25 cost time: 6.757909774780273
Epoch: 25, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3960 + XiCon Loss:2.6548 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4987568
	speed: 0.0151s/iter; left time: 551.4033s
	iters: 200, epoch: 26 | loss: 0.4421001
	speed: 0.0136s/iter; left time: 492.2961s
	iters: 300, epoch: 26 | loss: 0.3678462
	speed: 0.0143s/iter; left time: 519.7075s
	iters: 400, epoch: 26 | loss: 0.4007353
	speed: 0.0130s/iter; left time: 469.0488s
Epoch: 26 cost time: 6.876328468322754
Epoch: 26, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3957 + XiCon Loss:2.6512 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4550248
	speed: 0.0168s/iter; left time: 603.4855s
	iters: 200, epoch: 27 | loss: 0.5651889
	speed: 0.0127s/iter; left time: 455.6086s
	iters: 300, epoch: 27 | loss: 0.4032480
	speed: 0.0130s/iter; left time: 464.8595s
	iters: 400, epoch: 27 | loss: 0.3628509
	speed: 0.0130s/iter; left time: 464.6244s
Epoch: 27 cost time: 6.730188846588135
Epoch: 27, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6519 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3592742
	speed: 0.0155s/iter; left time: 547.8468s
	iters: 200, epoch: 28 | loss: 0.3706569
	speed: 0.0136s/iter; left time: 480.0519s
	iters: 300, epoch: 28 | loss: 0.4466774
	speed: 0.0130s/iter; left time: 459.4289s
	iters: 400, epoch: 28 | loss: 0.4398140
	speed: 0.0126s/iter; left time: 443.9389s
Epoch: 28 cost time: 6.638391017913818
Epoch: 28, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6502 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3804190
	speed: 0.0146s/iter; left time: 511.0751s
	iters: 200, epoch: 29 | loss: 0.4016042
	speed: 0.0130s/iter; left time: 452.7542s
	iters: 300, epoch: 29 | loss: 0.4517635
	speed: 0.0131s/iter; left time: 453.8634s
	iters: 400, epoch: 29 | loss: 0.3888496
	speed: 0.0129s/iter; left time: 446.8548s
Epoch: 29 cost time: 6.530285835266113
Epoch: 29, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6529 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3886079
	speed: 0.0163s/iter; left time: 562.7235s
	iters: 200, epoch: 30 | loss: 0.3984811
	speed: 0.0136s/iter; left time: 468.2680s
	iters: 300, epoch: 30 | loss: 0.3421575
	speed: 0.0131s/iter; left time: 448.0088s
	iters: 400, epoch: 30 | loss: 0.3767069
	speed: 0.0126s/iter; left time: 429.8318s
Epoch: 30 cost time: 6.745152950286865
Epoch: 30, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3956 + XiCon Loss:2.6553 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4032533
	speed: 0.0154s/iter; left time: 523.6835s
	iters: 200, epoch: 31 | loss: 0.4216755
	speed: 0.0126s/iter; left time: 426.6609s
	iters: 300, epoch: 31 | loss: 0.3232167
	speed: 0.0131s/iter; left time: 442.6635s
	iters: 400, epoch: 31 | loss: 0.3760438
	speed: 0.0135s/iter; left time: 454.1680s
Epoch: 31 cost time: 6.6445701122283936
Epoch: 31, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6544 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4336643
	speed: 0.0153s/iter; left time: 511.6963s
	iters: 200, epoch: 32 | loss: 0.4504498
	speed: 0.0131s/iter; left time: 438.5967s
	iters: 300, epoch: 32 | loss: 0.3674867
	speed: 0.0145s/iter; left time: 481.7532s
	iters: 400, epoch: 32 | loss: 0.4487974
	speed: 0.0139s/iter; left time: 461.8170s
Epoch: 32 cost time: 6.873312950134277
Epoch: 32, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6567 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4096453
	speed: 0.0158s/iter; left time: 521.4343s
	iters: 200, epoch: 33 | loss: 0.4825073
	speed: 0.0138s/iter; left time: 453.5252s
	iters: 300, epoch: 33 | loss: 0.3759271
	speed: 0.0134s/iter; left time: 440.1362s
	iters: 400, epoch: 33 | loss: 0.4770815
	speed: 0.0131s/iter; left time: 428.5692s
Epoch: 33 cost time: 6.7519690990448
Epoch: 33, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3959 + XiCon Loss:2.6509 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4148652
	speed: 0.0154s/iter; left time: 500.8027s
	iters: 200, epoch: 34 | loss: 0.4773250
	speed: 0.0138s/iter; left time: 448.3695s
	iters: 300, epoch: 34 | loss: 0.4368841
	speed: 0.0138s/iter; left time: 446.2017s
	iters: 400, epoch: 34 | loss: 0.4181115
	speed: 0.0130s/iter; left time: 418.4510s
Epoch: 34 cost time: 6.804735898971558
Epoch: 34, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3956 + XiCon Loss:2.6528 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5117
Validation loss decreased (0.736937 --> 0.736621).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3986437
	speed: 0.0149s/iter; left time: 478.5582s
	iters: 200, epoch: 35 | loss: 0.3961374
	speed: 0.0136s/iter; left time: 432.8571s
	iters: 300, epoch: 35 | loss: 0.4547538
	speed: 0.0139s/iter; left time: 441.2128s
	iters: 400, epoch: 35 | loss: 0.3711655
	speed: 0.0139s/iter; left time: 439.7622s
Epoch: 35 cost time: 6.911681890487671
Epoch: 35, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6573 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4936665
	speed: 0.0154s/iter; left time: 486.5203s
	iters: 200, epoch: 36 | loss: 0.3453646
	speed: 0.0132s/iter; left time: 414.3154s
	iters: 300, epoch: 36 | loss: 0.3672969
	speed: 0.0137s/iter; left time: 429.4919s
	iters: 400, epoch: 36 | loss: 0.4231170
	speed: 0.0134s/iter; left time: 417.9088s
Epoch: 36 cost time: 6.764674425125122
Epoch: 36, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3956 + XiCon Loss:2.6517 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4656506
	speed: 0.0153s/iter; left time: 475.6235s
	iters: 200, epoch: 37 | loss: 0.3961455
	speed: 0.0129s/iter; left time: 400.1671s
	iters: 300, epoch: 37 | loss: 0.3994629
	speed: 0.0141s/iter; left time: 434.0422s
	iters: 400, epoch: 37 | loss: 0.5132824
	speed: 0.0131s/iter; left time: 404.5397s
Epoch: 37 cost time: 6.750391006469727
Epoch: 37, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3958 + XiCon Loss:2.6532 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3938548
	speed: 0.0152s/iter; left time: 464.2395s
	iters: 200, epoch: 38 | loss: 0.4315977
	speed: 0.0132s/iter; left time: 401.2459s
	iters: 300, epoch: 38 | loss: 0.4079818
	speed: 0.0138s/iter; left time: 419.4115s
	iters: 400, epoch: 38 | loss: 0.4557460
	speed: 0.0140s/iter; left time: 424.7749s
Epoch: 38 cost time: 6.793803930282593
Epoch: 38, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3958 + XiCon Loss:2.6578 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.4944026
	speed: 0.0147s/iter; left time: 442.6550s
	iters: 200, epoch: 39 | loss: 0.3689062
	speed: 0.0127s/iter; left time: 379.5687s
	iters: 300, epoch: 39 | loss: 0.4729390
	speed: 0.0130s/iter; left time: 389.2135s
	iters: 400, epoch: 39 | loss: 0.4242470
	speed: 0.0125s/iter; left time: 373.3651s
Epoch: 39 cost time: 6.502708196640015
Epoch: 39, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6544 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4910859
	speed: 0.0147s/iter; left time: 434.9122s
	iters: 200, epoch: 40 | loss: 0.4399511
	speed: 0.0136s/iter; left time: 401.6510s
	iters: 300, epoch: 40 | loss: 0.4066291
	speed: 0.0145s/iter; left time: 425.0396s
	iters: 400, epoch: 40 | loss: 0.4705987
	speed: 0.0136s/iter; left time: 397.1264s
Epoch: 40 cost time: 6.862722635269165
Epoch: 40, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3960 + XiCon Loss:2.6501 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4022732
	speed: 0.0153s/iter; left time: 445.8559s
	iters: 200, epoch: 41 | loss: 0.4017051
	speed: 0.0131s/iter; left time: 381.2800s
	iters: 300, epoch: 41 | loss: 0.4513634
	speed: 0.0134s/iter; left time: 387.8581s
	iters: 400, epoch: 41 | loss: 0.4250217
	speed: 0.0133s/iter; left time: 382.2625s
Epoch: 41 cost time: 6.646920919418335
Epoch: 41, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6503 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.3626108
	speed: 0.0156s/iter; left time: 446.0822s
	iters: 200, epoch: 42 | loss: 0.3939447
	speed: 0.0128s/iter; left time: 363.9750s
	iters: 300, epoch: 42 | loss: 0.4561709
	speed: 0.0137s/iter; left time: 389.2435s
	iters: 400, epoch: 42 | loss: 0.4933233
	speed: 0.0131s/iter; left time: 372.4732s
Epoch: 42 cost time: 6.671250343322754
Epoch: 42, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3958 + XiCon Loss:2.6534 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.3807394
	speed: 0.0160s/iter; left time: 451.2497s
	iters: 200, epoch: 43 | loss: 0.4830824
	speed: 0.0132s/iter; left time: 370.7428s
	iters: 300, epoch: 43 | loss: 0.4229264
	speed: 0.0138s/iter; left time: 385.2652s
	iters: 400, epoch: 43 | loss: 0.4342846
	speed: 0.0129s/iter; left time: 359.9318s
Epoch: 43 cost time: 6.813883066177368
Epoch: 43, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3959 + XiCon Loss:2.6588 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.4226953
	speed: 0.0157s/iter; left time: 435.1891s
	iters: 200, epoch: 44 | loss: 0.4692615
	speed: 0.0146s/iter; left time: 401.4269s
	iters: 300, epoch: 44 | loss: 0.5323120
	speed: 0.0136s/iter; left time: 372.5457s
	iters: 400, epoch: 44 | loss: 0.4750477
	speed: 0.0130s/iter; left time: 354.9638s
Epoch: 44 cost time: 6.88664698600769
Epoch: 44, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3957 + XiCon Loss:2.6531 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182431936264038, mae:0.5052440762519836, mape:3.4785256385803223, mspe:1099.089111328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5200+-0.00812, MAE:0.5063+-0.00428, MAPE:3.5263+-0.08091, MSPE:1145.8879+-65.97110, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.2371
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9626117
	speed: 0.0280s/iter; left time: 663.5831s
	iters: 200, epoch: 1 | loss: 0.9853863
	speed: 0.0225s/iter; left time: 532.0854s
Epoch: 1 cost time: 5.911465167999268
Epoch: 1, Steps: 238 Train Loss: 1.0127 (Forecasting Loss:0.9803 + XiCon Loss:3.2378 x Lambda(0.01)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755403).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6397848
	speed: 0.0252s/iter; left time: 590.3646s
	iters: 200, epoch: 2 | loss: 0.6161349
	speed: 0.0226s/iter; left time: 527.2154s
Epoch: 2 cost time: 5.664275646209717
Epoch: 2, Steps: 238 Train Loss: 0.6493 (Forecasting Loss:0.6169 + XiCon Loss:3.2354 x Lambda(0.01)), Vali MSE Loss: 1.0368 Test MSE Loss: 0.8580
Validation loss decreased (1.755403 --> 1.036818).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5905139
	speed: 0.0250s/iter; left time: 581.1722s
	iters: 200, epoch: 3 | loss: 0.5972610
	speed: 0.0228s/iter; left time: 526.5999s
Epoch: 3 cost time: 5.668322324752808
Epoch: 3, Steps: 238 Train Loss: 0.5850 (Forecasting Loss:0.5527 + XiCon Loss:3.2326 x Lambda(0.01)), Vali MSE Loss: 1.0179 Test MSE Loss: 0.8515
Validation loss decreased (1.036818 --> 1.017899).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5709457
	speed: 0.0259s/iter; left time: 596.4803s
	iters: 200, epoch: 4 | loss: 0.5369074
	speed: 0.0223s/iter; left time: 511.0705s
Epoch: 4 cost time: 5.7458336353302
Epoch: 4, Steps: 238 Train Loss: 0.5769 (Forecasting Loss:0.5446 + XiCon Loss:3.2303 x Lambda(0.01)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8494
Validation loss decreased (1.017899 --> 1.010522).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5537441
	speed: 0.0247s/iter; left time: 561.6868s
	iters: 200, epoch: 5 | loss: 0.6004141
	speed: 0.0235s/iter; left time: 531.2196s
Epoch: 5 cost time: 5.713991165161133
Epoch: 5, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5414 + XiCon Loss:3.2320 x Lambda(0.01)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8490
Validation loss decreased (1.010522 --> 1.007491).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5612641
	speed: 0.0257s/iter; left time: 578.8260s
	iters: 200, epoch: 6 | loss: 0.5742394
	speed: 0.0221s/iter; left time: 494.9060s
Epoch: 6 cost time: 5.671300888061523
Epoch: 6, Steps: 238 Train Loss: 0.5722 (Forecasting Loss:0.5399 + XiCon Loss:3.2287 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8487
Validation loss decreased (1.007491 --> 1.006175).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5629115
	speed: 0.0254s/iter; left time: 565.5399s
	iters: 200, epoch: 7 | loss: 0.5741057
	speed: 0.0222s/iter; left time: 492.9129s
Epoch: 7 cost time: 5.70433497428894
Epoch: 7, Steps: 238 Train Loss: 0.5715 (Forecasting Loss:0.5391 + XiCon Loss:3.2328 x Lambda(0.01)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8487
Validation loss decreased (1.006175 --> 1.004490).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5253991
	speed: 0.0255s/iter; left time: 561.3440s
	iters: 200, epoch: 8 | loss: 0.5982974
	speed: 0.0231s/iter; left time: 507.0073s
Epoch: 8 cost time: 5.770115613937378
Epoch: 8, Steps: 238 Train Loss: 0.5710 (Forecasting Loss:0.5387 + XiCon Loss:3.2317 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8486
Validation loss decreased (1.004490 --> 1.004422).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6017577
	speed: 0.0246s/iter; left time: 535.9478s
	iters: 200, epoch: 9 | loss: 0.6204187
	speed: 0.0234s/iter; left time: 507.4242s
Epoch: 9 cost time: 5.667012453079224
Epoch: 9, Steps: 238 Train Loss: 0.5710 (Forecasting Loss:0.5386 + XiCon Loss:3.2322 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8486
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5600513
	speed: 0.0258s/iter; left time: 556.8381s
	iters: 200, epoch: 10 | loss: 0.5899228
	speed: 0.0234s/iter; left time: 501.6415s
Epoch: 10 cost time: 5.848846197128296
Epoch: 10, Steps: 238 Train Loss: 0.5708 (Forecasting Loss:0.5385 + XiCon Loss:3.2313 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8485
Validation loss decreased (1.004422 --> 1.004362).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5291634
	speed: 0.0254s/iter; left time: 541.3357s
	iters: 200, epoch: 11 | loss: 0.5899742
	speed: 0.0230s/iter; left time: 488.8324s
Epoch: 11 cost time: 5.790882110595703
Epoch: 11, Steps: 238 Train Loss: 0.5705 (Forecasting Loss:0.5382 + XiCon Loss:3.2288 x Lambda(0.01)), Vali MSE Loss: 1.0036 Test MSE Loss: 0.8485
Validation loss decreased (1.004362 --> 1.003586).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5901294
	speed: 0.0241s/iter; left time: 507.2358s
	iters: 200, epoch: 12 | loss: 0.5406613
	speed: 0.0230s/iter; left time: 483.5736s
Epoch: 12 cost time: 5.6093268394470215
Epoch: 12, Steps: 238 Train Loss: 0.5705 (Forecasting Loss:0.5382 + XiCon Loss:3.2294 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5734058
	speed: 0.0249s/iter; left time: 518.5837s
	iters: 200, epoch: 13 | loss: 0.5635471
	speed: 0.0220s/iter; left time: 457.0732s
Epoch: 13 cost time: 5.59434700012207
Epoch: 13, Steps: 238 Train Loss: 0.5706 (Forecasting Loss:0.5383 + XiCon Loss:3.2320 x Lambda(0.01)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8485
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4840702
	speed: 0.0274s/iter; left time: 564.9258s
	iters: 200, epoch: 14 | loss: 0.5665790
	speed: 0.0270s/iter; left time: 554.4477s
Epoch: 14 cost time: 6.446734666824341
Epoch: 14, Steps: 238 Train Loss: 0.5704 (Forecasting Loss:0.5381 + XiCon Loss:3.2287 x Lambda(0.01)), Vali MSE Loss: 1.0042 Test MSE Loss: 0.8485
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5723618
	speed: 0.0259s/iter; left time: 528.3172s
	iters: 200, epoch: 15 | loss: 0.5727042
	speed: 0.0230s/iter; left time: 466.2435s
Epoch: 15 cost time: 5.793568849563599
Epoch: 15, Steps: 238 Train Loss: 0.5705 (Forecasting Loss:0.5382 + XiCon Loss:3.2275 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5333897
	speed: 0.0247s/iter; left time: 497.0114s
	iters: 200, epoch: 16 | loss: 0.5631981
	speed: 0.0224s/iter; left time: 449.5279s
Epoch: 16 cost time: 5.699256181716919
Epoch: 16, Steps: 238 Train Loss: 0.5708 (Forecasting Loss:0.5385 + XiCon Loss:3.2295 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8485
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5630898
	speed: 0.0255s/iter; left time: 506.8240s
	iters: 200, epoch: 17 | loss: 0.5700427
	speed: 0.0224s/iter; left time: 443.7807s
Epoch: 17 cost time: 5.676518678665161
Epoch: 17, Steps: 238 Train Loss: 0.5703 (Forecasting Loss:0.5380 + XiCon Loss:3.2346 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8485
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5354466
	speed: 0.0252s/iter; left time: 494.6155s
	iters: 200, epoch: 18 | loss: 0.5056538
	speed: 0.0220s/iter; left time: 430.3431s
Epoch: 18 cost time: 5.616122722625732
Epoch: 18, Steps: 238 Train Loss: 0.5705 (Forecasting Loss:0.5382 + XiCon Loss:3.2290 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8485
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5732572
	speed: 0.0261s/iter; left time: 506.0092s
	iters: 200, epoch: 19 | loss: 0.5655526
	speed: 0.0232s/iter; left time: 447.8736s
Epoch: 19 cost time: 5.821322441101074
Epoch: 19, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5384 + XiCon Loss:3.2299 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5489846
	speed: 0.0255s/iter; left time: 488.8438s
	iters: 200, epoch: 20 | loss: 0.5809064
	speed: 0.0228s/iter; left time: 434.3307s
Epoch: 20 cost time: 5.725668668746948
Epoch: 20, Steps: 238 Train Loss: 0.5704 (Forecasting Loss:0.5381 + XiCon Loss:3.2313 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5248594
	speed: 0.0253s/iter; left time: 479.7828s
	iters: 200, epoch: 21 | loss: 0.5819912
	speed: 0.0224s/iter; left time: 422.8502s
Epoch: 21 cost time: 5.706686496734619
Epoch: 21, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5384 + XiCon Loss:3.2327 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9777077436447144, mae:0.7193635106086731, mape:4.778619289398193, mspe:2691.169677734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.5365
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1171514
	speed: 0.0270s/iter; left time: 639.8971s
	iters: 200, epoch: 1 | loss: 1.1909451
	speed: 0.0234s/iter; left time: 552.1153s
Epoch: 1 cost time: 5.957103252410889
Epoch: 1, Steps: 238 Train Loss: 1.1315 (Forecasting Loss:1.0993 + XiCon Loss:3.2248 x Lambda(0.01)), Vali MSE Loss: 1.9677 Test MSE Loss: 1.0361
Validation loss decreased (inf --> 1.967728).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6576868
	speed: 0.0252s/iter; left time: 590.3030s
	iters: 200, epoch: 2 | loss: 0.5735569
	speed: 0.0226s/iter; left time: 527.7827s
Epoch: 2 cost time: 5.686724901199341
Epoch: 2, Steps: 238 Train Loss: 0.6635 (Forecasting Loss:0.6313 + XiCon Loss:3.2219 x Lambda(0.01)), Vali MSE Loss: 1.0219 Test MSE Loss: 0.8588
Validation loss decreased (1.967728 --> 1.021875).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5738332
	speed: 0.0250s/iter; left time: 579.9407s
	iters: 200, epoch: 3 | loss: 0.5566677
	speed: 0.0228s/iter; left time: 527.2005s
Epoch: 3 cost time: 5.684126853942871
Epoch: 3, Steps: 238 Train Loss: 0.5838 (Forecasting Loss:0.5516 + XiCon Loss:3.2174 x Lambda(0.01)), Vali MSE Loss: 1.0005 Test MSE Loss: 0.8528
Validation loss decreased (1.021875 --> 1.000548).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5085431
	speed: 0.0251s/iter; left time: 576.1459s
	iters: 200, epoch: 4 | loss: 0.5926875
	speed: 0.0229s/iter; left time: 523.7135s
Epoch: 4 cost time: 5.715997219085693
Epoch: 4, Steps: 238 Train Loss: 0.5754 (Forecasting Loss:0.5432 + XiCon Loss:3.2164 x Lambda(0.01)), Vali MSE Loss: 0.9941 Test MSE Loss: 0.8515
Validation loss decreased (1.000548 --> 0.994068).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5994819
	speed: 0.0250s/iter; left time: 568.1413s
	iters: 200, epoch: 5 | loss: 0.5565694
	speed: 0.0233s/iter; left time: 528.5681s
Epoch: 5 cost time: 5.739871501922607
Epoch: 5, Steps: 238 Train Loss: 0.5720 (Forecasting Loss:0.5399 + XiCon Loss:3.2139 x Lambda(0.01)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8508
Validation loss decreased (0.994068 --> 0.989102).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5480593
	speed: 0.0249s/iter; left time: 560.3273s
	iters: 200, epoch: 6 | loss: 0.5805450
	speed: 0.0230s/iter; left time: 514.4051s
Epoch: 6 cost time: 5.684176683425903
Epoch: 6, Steps: 238 Train Loss: 0.5708 (Forecasting Loss:0.5386 + XiCon Loss:3.2120 x Lambda(0.01)), Vali MSE Loss: 0.9880 Test MSE Loss: 0.8507
Validation loss decreased (0.989102 --> 0.988022).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5719632
	speed: 0.0250s/iter; left time: 557.6432s
	iters: 200, epoch: 7 | loss: 0.5422736
	speed: 0.0225s/iter; left time: 498.7456s
Epoch: 7 cost time: 5.641970157623291
Epoch: 7, Steps: 238 Train Loss: 0.5698 (Forecasting Loss:0.5376 + XiCon Loss:3.2127 x Lambda(0.01)), Vali MSE Loss: 0.9870 Test MSE Loss: 0.8506
Validation loss decreased (0.988022 --> 0.987046).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5766387
	speed: 0.0257s/iter; left time: 565.8306s
	iters: 200, epoch: 8 | loss: 0.5370364
	speed: 0.0233s/iter; left time: 510.9854s
Epoch: 8 cost time: 5.8078694343566895
Epoch: 8, Steps: 238 Train Loss: 0.5697 (Forecasting Loss:0.5376 + XiCon Loss:3.2113 x Lambda(0.01)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8505
Validation loss decreased (0.987046 --> 0.986949).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5555562
	speed: 0.0251s/iter; left time: 547.6807s
	iters: 200, epoch: 9 | loss: 0.6075395
	speed: 0.0228s/iter; left time: 495.2647s
Epoch: 9 cost time: 5.703652381896973
Epoch: 9, Steps: 238 Train Loss: 0.5693 (Forecasting Loss:0.5372 + XiCon Loss:3.2128 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
Validation loss decreased (0.986949 --> 0.985931).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5657280
	speed: 0.0247s/iter; left time: 533.2260s
	iters: 200, epoch: 10 | loss: 0.6345508
	speed: 0.0227s/iter; left time: 487.5392s
Epoch: 10 cost time: 5.641501426696777
Epoch: 10, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5370 + XiCon Loss:3.2121 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985931 --> 0.985570).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5731590
	speed: 0.0250s/iter; left time: 533.1920s
	iters: 200, epoch: 11 | loss: 0.6042070
	speed: 0.0231s/iter; left time: 489.7573s
Epoch: 11 cost time: 5.704106092453003
Epoch: 11, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2110 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5773622
	speed: 0.0252s/iter; left time: 531.0206s
	iters: 200, epoch: 12 | loss: 0.5297941
	speed: 0.0229s/iter; left time: 481.2672s
Epoch: 12 cost time: 5.739499807357788
Epoch: 12, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2114 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5441232
	speed: 0.0254s/iter; left time: 529.3190s
	iters: 200, epoch: 13 | loss: 0.5653560
	speed: 0.0230s/iter; left time: 477.1345s
Epoch: 13 cost time: 5.752564430236816
Epoch: 13, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5367 + XiCon Loss:3.2138 x Lambda(0.01)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5164810
	speed: 0.0251s/iter; left time: 517.6621s
	iters: 200, epoch: 14 | loss: 0.5558440
	speed: 0.0231s/iter; left time: 473.7986s
Epoch: 14 cost time: 5.720638751983643
Epoch: 14, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2126 x Lambda(0.01)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5607742
	speed: 0.0251s/iter; left time: 511.5057s
	iters: 200, epoch: 15 | loss: 0.4951832
	speed: 0.0230s/iter; left time: 465.3904s
Epoch: 15 cost time: 5.703701734542847
Epoch: 15, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5368 + XiCon Loss:3.2154 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5966058
	speed: 0.0250s/iter; left time: 503.5872s
	iters: 200, epoch: 16 | loss: 0.5909223
	speed: 0.0231s/iter; left time: 462.7688s
Epoch: 16 cost time: 5.701026916503906
Epoch: 16, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2128 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5503751
	speed: 0.0251s/iter; left time: 499.8952s
	iters: 200, epoch: 17 | loss: 0.6000373
	speed: 0.0232s/iter; left time: 458.7312s
Epoch: 17 cost time: 5.739704132080078
Epoch: 17, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5371 + XiCon Loss:3.2104 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5890449
	speed: 0.0257s/iter; left time: 504.2338s
	iters: 200, epoch: 18 | loss: 0.6644152
	speed: 0.0226s/iter; left time: 441.7613s
Epoch: 18 cost time: 5.7473859786987305
Epoch: 18, Steps: 238 Train Loss: 0.5693 (Forecasting Loss:0.5372 + XiCon Loss:3.2091 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5638225
	speed: 0.0249s/iter; left time: 482.9056s
	iters: 200, epoch: 19 | loss: 0.5671178
	speed: 0.0229s/iter; left time: 441.4558s
Epoch: 19 cost time: 5.676375865936279
Epoch: 19, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2138 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5779937
	speed: 0.0258s/iter; left time: 494.4917s
	iters: 200, epoch: 20 | loss: 0.5862374
	speed: 0.0225s/iter; left time: 429.5206s
Epoch: 20 cost time: 5.716944694519043
Epoch: 20, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2125 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985570 --> 0.985540).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5254124
	speed: 0.0247s/iter; left time: 468.6175s
	iters: 200, epoch: 21 | loss: 0.5401648
	speed: 0.0230s/iter; left time: 433.7784s
Epoch: 21 cost time: 5.690362930297852
Epoch: 21, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5367 + XiCon Loss:3.2118 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5419346
	speed: 0.0247s/iter; left time: 461.8824s
	iters: 200, epoch: 22 | loss: 0.5646183
	speed: 0.0231s/iter; left time: 429.6699s
Epoch: 22 cost time: 5.686336517333984
Epoch: 22, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5369 + XiCon Loss:3.2138 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5587569
	speed: 0.0252s/iter; left time: 466.1464s
	iters: 200, epoch: 23 | loss: 0.5435672
	speed: 0.0232s/iter; left time: 425.8574s
Epoch: 23 cost time: 5.802227973937988
Epoch: 23, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5371 + XiCon Loss:3.2100 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5828028
	speed: 0.0249s/iter; left time: 453.0165s
	iters: 200, epoch: 24 | loss: 0.5602202
	speed: 0.0230s/iter; left time: 417.2757s
Epoch: 24 cost time: 5.698078632354736
Epoch: 24, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2111 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5657008
	speed: 0.0248s/iter; left time: 446.5200s
	iters: 200, epoch: 25 | loss: 0.5767859
	speed: 0.0227s/iter; left time: 406.4015s
Epoch: 25 cost time: 5.683354616165161
Epoch: 25, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2123 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5886308
	speed: 0.0256s/iter; left time: 453.7309s
	iters: 200, epoch: 26 | loss: 0.5475091
	speed: 0.0230s/iter; left time: 406.3825s
Epoch: 26 cost time: 5.740334510803223
Epoch: 26, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2113 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6127507
	speed: 0.0256s/iter; left time: 447.8264s
	iters: 200, epoch: 27 | loss: 0.6083401
	speed: 0.0228s/iter; left time: 397.1760s
Epoch: 27 cost time: 5.7165367603302
Epoch: 27, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5371 + XiCon Loss:3.2109 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5441916
	speed: 0.0252s/iter; left time: 435.6696s
	iters: 200, epoch: 28 | loss: 0.5422404
	speed: 0.0233s/iter; left time: 400.2883s
Epoch: 28 cost time: 5.821735143661499
Epoch: 28, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5367 + XiCon Loss:3.2122 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4968691
	speed: 0.0259s/iter; left time: 440.6310s
	iters: 200, epoch: 29 | loss: 0.5612953
	speed: 0.0234s/iter; left time: 396.4617s
Epoch: 29 cost time: 5.813674688339233
Epoch: 29, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5368 + XiCon Loss:3.2095 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5116028
	speed: 0.0252s/iter; left time: 423.2559s
	iters: 200, epoch: 30 | loss: 0.5803412
	speed: 0.0240s/iter; left time: 400.3496s
Epoch: 30 cost time: 5.81832480430603
Epoch: 30, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2115 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985540 --> 0.985455).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5676799
	speed: 0.0255s/iter; left time: 422.2339s
	iters: 200, epoch: 31 | loss: 0.5259970
	speed: 0.0233s/iter; left time: 382.8986s
Epoch: 31 cost time: 5.774004220962524
Epoch: 31, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5367 + XiCon Loss:3.2111 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5881363
	speed: 0.0265s/iter; left time: 433.2988s
	iters: 200, epoch: 32 | loss: 0.6133400
	speed: 0.0230s/iter; left time: 373.6057s
Epoch: 32 cost time: 5.878839731216431
Epoch: 32, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2116 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5563129
	speed: 0.0256s/iter; left time: 411.6166s
	iters: 200, epoch: 33 | loss: 0.5488172
	speed: 0.0229s/iter; left time: 365.3622s
Epoch: 33 cost time: 5.777024269104004
Epoch: 33, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2071 x Lambda(0.01)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8504
Validation loss decreased (0.985455 --> 0.985417).  Saving model ...
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5461944
	speed: 0.0254s/iter; left time: 402.2335s
	iters: 200, epoch: 34 | loss: 0.5477651
	speed: 0.0230s/iter; left time: 362.8736s
Epoch: 34 cost time: 5.742229461669922
Epoch: 34, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2111 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5544761
	speed: 0.0253s/iter; left time: 394.2330s
	iters: 200, epoch: 35 | loss: 0.6063823
	speed: 0.0227s/iter; left time: 351.6991s
Epoch: 35 cost time: 5.6944684982299805
Epoch: 35, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5367 + XiCon Loss:3.2129 x Lambda(0.01)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5417832
	speed: 0.0253s/iter; left time: 389.5202s
	iters: 200, epoch: 36 | loss: 0.5547200
	speed: 0.0229s/iter; left time: 350.1609s
Epoch: 36 cost time: 5.703170299530029
Epoch: 36, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5368 + XiCon Loss:3.2144 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5242350
	speed: 0.0254s/iter; left time: 383.8991s
	iters: 200, epoch: 37 | loss: 0.6240181
	speed: 0.0234s/iter; left time: 352.2679s
Epoch: 37 cost time: 5.783966779708862
Epoch: 37, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2123 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5990058
	speed: 0.0250s/iter; left time: 372.5043s
	iters: 200, epoch: 38 | loss: 0.6009924
	speed: 0.0231s/iter; left time: 341.5531s
Epoch: 38 cost time: 5.698023557662964
Epoch: 38, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5367 + XiCon Loss:3.2112 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5675780
	speed: 0.0256s/iter; left time: 374.6634s
	iters: 200, epoch: 39 | loss: 0.6008024
	speed: 0.0233s/iter; left time: 338.5240s
Epoch: 39 cost time: 5.802627086639404
Epoch: 39, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5368 + XiCon Loss:3.2114 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.6029207
	speed: 0.0257s/iter; left time: 370.4641s
	iters: 200, epoch: 40 | loss: 0.5944989
	speed: 0.0233s/iter; left time: 333.2629s
Epoch: 40 cost time: 5.875729084014893
Epoch: 40, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5370 + XiCon Loss:3.2150 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.6108609
	speed: 0.0246s/iter; left time: 348.9726s
	iters: 200, epoch: 41 | loss: 0.5432831
	speed: 0.0228s/iter; left time: 321.6729s
Epoch: 41 cost time: 5.657620429992676
Epoch: 41, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5369 + XiCon Loss:3.2140 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.5531908
	speed: 0.0252s/iter; left time: 351.3896s
	iters: 200, epoch: 42 | loss: 0.5680338
	speed: 0.0230s/iter; left time: 318.3196s
Epoch: 42 cost time: 5.76738977432251
Epoch: 42, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5369 + XiCon Loss:3.2121 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.5839381
	speed: 0.0253s/iter; left time: 346.1455s
	iters: 200, epoch: 43 | loss: 0.5764631
	speed: 0.0224s/iter; left time: 305.3722s
Epoch: 43 cost time: 5.663837194442749
Epoch: 43, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5369 + XiCon Loss:3.2141 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9793381094932556, mae:0.7214691042900085, mape:4.789019584655762, mspe:2695.2119140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9093
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1476784
	speed: 0.0270s/iter; left time: 641.0262s
	iters: 200, epoch: 1 | loss: 1.0622754
	speed: 0.0235s/iter; left time: 554.3503s
Epoch: 1 cost time: 5.974789381027222
Epoch: 1, Steps: 238 Train Loss: 1.1293 (Forecasting Loss:1.0971 + XiCon Loss:3.2262 x Lambda(0.01)), Vali MSE Loss: 1.9328 Test MSE Loss: 1.0252
Validation loss decreased (inf --> 1.932778).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6284251
	speed: 0.0257s/iter; left time: 602.9370s
	iters: 200, epoch: 2 | loss: 0.6077445
	speed: 0.0228s/iter; left time: 532.4101s
Epoch: 2 cost time: 5.751590967178345
Epoch: 2, Steps: 238 Train Loss: 0.6558 (Forecasting Loss:0.6235 + XiCon Loss:3.2248 x Lambda(0.01)), Vali MSE Loss: 1.0344 Test MSE Loss: 0.8764
Validation loss decreased (1.932778 --> 1.034354).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5529325
	speed: 0.0254s/iter; left time: 588.8168s
	iters: 200, epoch: 3 | loss: 0.6344127
	speed: 0.0230s/iter; left time: 531.2809s
Epoch: 3 cost time: 5.706924676895142
Epoch: 3, Steps: 238 Train Loss: 0.5846 (Forecasting Loss:0.5523 + XiCon Loss:3.2267 x Lambda(0.01)), Vali MSE Loss: 1.0101 Test MSE Loss: 0.8681
Validation loss decreased (1.034354 --> 1.010063).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5598549
	speed: 0.0260s/iter; left time: 596.9609s
	iters: 200, epoch: 4 | loss: 0.6306921
	speed: 0.0233s/iter; left time: 532.7891s
Epoch: 4 cost time: 5.8233582973480225
Epoch: 4, Steps: 238 Train Loss: 0.5758 (Forecasting Loss:0.5435 + XiCon Loss:3.2312 x Lambda(0.01)), Vali MSE Loss: 1.0028 Test MSE Loss: 0.8657
Validation loss decreased (1.010063 --> 1.002817).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5669263
	speed: 0.0257s/iter; left time: 584.7541s
	iters: 200, epoch: 5 | loss: 0.6025836
	speed: 0.0234s/iter; left time: 529.6360s
Epoch: 5 cost time: 5.763820171356201
Epoch: 5, Steps: 238 Train Loss: 0.5722 (Forecasting Loss:0.5400 + XiCon Loss:3.2251 x Lambda(0.01)), Vali MSE Loss: 0.9986 Test MSE Loss: 0.8647
Validation loss decreased (1.002817 --> 0.998574).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5919728
	speed: 0.0256s/iter; left time: 575.1922s
	iters: 200, epoch: 6 | loss: 0.5360139
	speed: 0.0226s/iter; left time: 505.7628s
Epoch: 6 cost time: 5.696204900741577
Epoch: 6, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5384 + XiCon Loss:3.2305 x Lambda(0.01)), Vali MSE Loss: 0.9977 Test MSE Loss: 0.8649
Validation loss decreased (0.998574 --> 0.997696).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5695594
	speed: 0.0257s/iter; left time: 573.1904s
	iters: 200, epoch: 7 | loss: 0.5979111
	speed: 0.0231s/iter; left time: 512.0668s
Epoch: 7 cost time: 5.836396932601929
Epoch: 7, Steps: 238 Train Loss: 0.5697 (Forecasting Loss:0.5375 + XiCon Loss:3.2257 x Lambda(0.01)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8646
Validation loss decreased (0.997696 --> 0.996982).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5692562
	speed: 0.0261s/iter; left time: 575.1485s
	iters: 200, epoch: 8 | loss: 0.5410505
	speed: 0.0237s/iter; left time: 519.3146s
Epoch: 8 cost time: 5.925732851028442
Epoch: 8, Steps: 238 Train Loss: 0.5693 (Forecasting Loss:0.5371 + XiCon Loss:3.2246 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8646
Validation loss decreased (0.996982 --> 0.996195).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5949463
	speed: 0.0256s/iter; left time: 557.4959s
	iters: 200, epoch: 9 | loss: 0.5581924
	speed: 0.0228s/iter; left time: 494.7585s
Epoch: 9 cost time: 5.773635625839233
Epoch: 9, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5369 + XiCon Loss:3.2248 x Lambda(0.01)), Vali MSE Loss: 0.9969 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5695858
	speed: 0.0262s/iter; left time: 564.3723s
	iters: 200, epoch: 10 | loss: 0.5690753
	speed: 0.0238s/iter; left time: 510.0457s
Epoch: 10 cost time: 5.905727386474609
Epoch: 10, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5365 + XiCon Loss:3.2311 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
Validation loss decreased (0.996195 --> 0.995976).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5667962
	speed: 0.0260s/iter; left time: 553.9710s
	iters: 200, epoch: 11 | loss: 0.5358427
	speed: 0.0234s/iter; left time: 497.5757s
Epoch: 11 cost time: 5.907718181610107
Epoch: 11, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5368 + XiCon Loss:3.2288 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5539588
	speed: 0.0264s/iter; left time: 557.5224s
	iters: 200, epoch: 12 | loss: 0.5543684
	speed: 0.0230s/iter; left time: 482.3860s
Epoch: 12 cost time: 5.886990547180176
Epoch: 12, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5368 + XiCon Loss:3.2246 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5367169
	speed: 0.0262s/iter; left time: 546.7988s
	iters: 200, epoch: 13 | loss: 0.5172109
	speed: 0.0237s/iter; left time: 490.8561s
Epoch: 13 cost time: 5.9159533977508545
Epoch: 13, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5368 + XiCon Loss:3.2255 x Lambda(0.01)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
Validation loss decreased (0.995976 --> 0.995912).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5931871
	speed: 0.0260s/iter; left time: 536.7529s
	iters: 200, epoch: 14 | loss: 0.6602215
	speed: 0.0230s/iter; left time: 472.0697s
Epoch: 14 cost time: 5.835418701171875
Epoch: 14, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5366 + XiCon Loss:3.2272 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5433715
	speed: 0.0264s/iter; left time: 538.3780s
	iters: 200, epoch: 15 | loss: 0.5494929
	speed: 0.0233s/iter; left time: 472.0689s
Epoch: 15 cost time: 5.880096197128296
Epoch: 15, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5366 + XiCon Loss:3.2327 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995912 --> 0.995523).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5924922
	speed: 0.0262s/iter; left time: 527.3372s
	iters: 200, epoch: 16 | loss: 0.5413004
	speed: 0.0234s/iter; left time: 468.9453s
Epoch: 16 cost time: 5.835225343704224
Epoch: 16, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5368 + XiCon Loss:3.2314 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995523 --> 0.995512).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5373918
	speed: 0.0267s/iter; left time: 531.7437s
	iters: 200, epoch: 17 | loss: 0.5903047
	speed: 0.0230s/iter; left time: 454.7818s
Epoch: 17 cost time: 5.881172180175781
Epoch: 17, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5368 + XiCon Loss:3.2277 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5652698
	speed: 0.0249s/iter; left time: 490.1679s
	iters: 200, epoch: 18 | loss: 0.5473827
	speed: 0.0229s/iter; left time: 448.0058s
Epoch: 18 cost time: 5.697605133056641
Epoch: 18, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2290 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5629472
	speed: 0.0252s/iter; left time: 489.9076s
	iters: 200, epoch: 19 | loss: 0.5683007
	speed: 0.0226s/iter; left time: 436.2317s
Epoch: 19 cost time: 5.722992658615112
Epoch: 19, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2302 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995512 --> 0.995507).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5451749
	speed: 0.0254s/iter; left time: 487.9871s
	iters: 200, epoch: 20 | loss: 0.5772635
	speed: 0.0231s/iter; left time: 440.0138s
Epoch: 20 cost time: 5.75926399230957
Epoch: 20, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5366 + XiCon Loss:3.2286 x Lambda(0.01)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5847242
	speed: 0.0251s/iter; left time: 475.2376s
	iters: 200, epoch: 21 | loss: 0.5572606
	speed: 0.0229s/iter; left time: 431.7453s
Epoch: 21 cost time: 5.673262596130371
Epoch: 21, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2293 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5207489
	speed: 0.0257s/iter; left time: 480.0231s
	iters: 200, epoch: 22 | loss: 0.5622492
	speed: 0.0226s/iter; left time: 419.5307s
Epoch: 22 cost time: 5.709695816040039
Epoch: 22, Steps: 238 Train Loss: 0.5688 (Forecasting Loss:0.5365 + XiCon Loss:3.2325 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5933201
	speed: 0.0265s/iter; left time: 490.0367s
	iters: 200, epoch: 23 | loss: 0.5962321
	speed: 0.0227s/iter; left time: 417.4615s
Epoch: 23 cost time: 5.832833766937256
Epoch: 23, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5369 + XiCon Loss:3.2305 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5377796
	speed: 0.0258s/iter; left time: 469.8961s
	iters: 200, epoch: 24 | loss: 0.5859722
	speed: 0.0223s/iter; left time: 403.4580s
Epoch: 24 cost time: 5.7079126834869385
Epoch: 24, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5368 + XiCon Loss:3.2303 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6007533
	speed: 0.0254s/iter; left time: 456.7301s
	iters: 200, epoch: 25 | loss: 0.5858147
	speed: 0.0226s/iter; left time: 403.8607s
Epoch: 25 cost time: 5.725852966308594
Epoch: 25, Steps: 238 Train Loss: 0.5687 (Forecasting Loss:0.5364 + XiCon Loss:3.2307 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5613535
	speed: 0.0259s/iter; left time: 459.3678s
	iters: 200, epoch: 26 | loss: 0.6107603
	speed: 0.0234s/iter; left time: 413.0722s
Epoch: 26 cost time: 5.8313117027282715
Epoch: 26, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5368 + XiCon Loss:3.2287 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5867536
	speed: 0.0258s/iter; left time: 450.9997s
	iters: 200, epoch: 27 | loss: 0.5729685
	speed: 0.0228s/iter; left time: 397.8736s
Epoch: 27 cost time: 5.743427038192749
Epoch: 27, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5367 + XiCon Loss:3.2234 x Lambda(0.01)), Vali MSE Loss: 0.9950 Test MSE Loss: 0.8645
Validation loss decreased (0.995507 --> 0.995034).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5931517
	speed: 0.0260s/iter; left time: 449.4636s
	iters: 200, epoch: 28 | loss: 0.5568383
	speed: 0.0223s/iter; left time: 382.9300s
Epoch: 28 cost time: 5.731938362121582
Epoch: 28, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5366 + XiCon Loss:3.2303 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5949643
	speed: 0.0253s/iter; left time: 431.4658s
	iters: 200, epoch: 29 | loss: 0.5719236
	speed: 0.0237s/iter; left time: 400.5773s
Epoch: 29 cost time: 5.810769557952881
Epoch: 29, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5367 + XiCon Loss:3.2268 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6008187
	speed: 0.0260s/iter; left time: 436.6520s
	iters: 200, epoch: 30 | loss: 0.5698820
	speed: 0.0229s/iter; left time: 382.5113s
Epoch: 30 cost time: 5.785417795181274
Epoch: 30, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5369 + XiCon Loss:3.2315 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5637320
	speed: 0.0249s/iter; left time: 412.2812s
	iters: 200, epoch: 31 | loss: 0.5671073
	speed: 0.0232s/iter; left time: 381.2571s
Epoch: 31 cost time: 5.731200695037842
Epoch: 31, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5366 + XiCon Loss:3.2287 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5824296
	speed: 0.0258s/iter; left time: 420.9513s
	iters: 200, epoch: 32 | loss: 0.5425323
	speed: 0.0225s/iter; left time: 365.5588s
Epoch: 32 cost time: 5.720276832580566
Epoch: 32, Steps: 238 Train Loss: 0.5692 (Forecasting Loss:0.5369 + XiCon Loss:3.2317 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6290935
	speed: 0.0263s/iter; left time: 422.8535s
	iters: 200, epoch: 33 | loss: 0.5610801
	speed: 0.0222s/iter; left time: 354.7090s
Epoch: 33 cost time: 5.788167715072632
Epoch: 33, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2295 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5362095
	speed: 0.0262s/iter; left time: 414.6188s
	iters: 200, epoch: 34 | loss: 0.6002741
	speed: 0.0236s/iter; left time: 372.3405s
Epoch: 34 cost time: 5.902186870574951
Epoch: 34, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2252 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5940579
	speed: 0.0255s/iter; left time: 397.5704s
	iters: 200, epoch: 35 | loss: 0.5490212
	speed: 0.0235s/iter; left time: 364.5507s
Epoch: 35 cost time: 5.8588502407073975
Epoch: 35, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5366 + XiCon Loss:3.2289 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5153329
	speed: 0.0259s/iter; left time: 398.5279s
	iters: 200, epoch: 36 | loss: 0.5605805
	speed: 0.0234s/iter; left time: 357.6554s
Epoch: 36 cost time: 5.8357093334198
Epoch: 36, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2298 x Lambda(0.01)), Vali MSE Loss: 0.9967 Test MSE Loss: 0.8645
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5313827
	speed: 0.0256s/iter; left time: 387.6614s
	iters: 200, epoch: 37 | loss: 0.5745986
	speed: 0.0227s/iter; left time: 341.8132s
Epoch: 37 cost time: 5.745298624038696
Epoch: 37, Steps: 238 Train Loss: 0.5690 (Forecasting Loss:0.5367 + XiCon Loss:3.2305 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.997125506401062, mae:0.7319390773773193, mape:5.079895973205566, mspe:3079.94775390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9266
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0988094
	speed: 0.0275s/iter; left time: 652.8993s
	iters: 200, epoch: 1 | loss: 1.1265283
	speed: 0.0244s/iter; left time: 576.1972s
Epoch: 1 cost time: 6.147618770599365
Epoch: 1, Steps: 238 Train Loss: 1.2286 (Forecasting Loss:1.1962 + XiCon Loss:3.2378 x Lambda(0.01)), Vali MSE Loss: 2.1664 Test MSE Loss: 1.1068
Validation loss decreased (inf --> 2.166445).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8064485
	speed: 0.0257s/iter; left time: 603.8565s
	iters: 200, epoch: 2 | loss: 0.6024039
	speed: 0.0256s/iter; left time: 597.6268s
Epoch: 2 cost time: 6.048848867416382
Epoch: 2, Steps: 238 Train Loss: 0.7606 (Forecasting Loss:0.7283 + XiCon Loss:3.2331 x Lambda(0.01)), Vali MSE Loss: 1.0373 Test MSE Loss: 0.8756
Validation loss decreased (2.166445 --> 1.037337).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6296157
	speed: 0.0267s/iter; left time: 620.1933s
	iters: 200, epoch: 3 | loss: 0.6168820
	speed: 0.0235s/iter; left time: 542.4365s
Epoch: 3 cost time: 5.912342071533203
Epoch: 3, Steps: 238 Train Loss: 0.5929 (Forecasting Loss:0.5606 + XiCon Loss:3.2341 x Lambda(0.01)), Vali MSE Loss: 1.0330 Test MSE Loss: 0.8586
Validation loss decreased (1.037337 --> 1.033039).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5998276
	speed: 0.0259s/iter; left time: 595.1886s
	iters: 200, epoch: 4 | loss: 0.6029542
	speed: 0.0234s/iter; left time: 536.3281s
Epoch: 4 cost time: 5.827584743499756
Epoch: 4, Steps: 238 Train Loss: 0.5804 (Forecasting Loss:0.5480 + XiCon Loss:3.2395 x Lambda(0.01)), Vali MSE Loss: 1.0257 Test MSE Loss: 0.8553
Validation loss decreased (1.033039 --> 1.025687).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5613496
	speed: 0.0257s/iter; left time: 585.6504s
	iters: 200, epoch: 5 | loss: 0.5419536
	speed: 0.0233s/iter; left time: 527.2361s
Epoch: 5 cost time: 5.812262296676636
Epoch: 5, Steps: 238 Train Loss: 0.5771 (Forecasting Loss:0.5447 + XiCon Loss:3.2408 x Lambda(0.01)), Vali MSE Loss: 1.0208 Test MSE Loss: 0.8542
Validation loss decreased (1.025687 --> 1.020803).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5790887
	speed: 0.0267s/iter; left time: 602.1357s
	iters: 200, epoch: 6 | loss: 0.5563371
	speed: 0.0231s/iter; left time: 518.5803s
Epoch: 6 cost time: 5.901045322418213
Epoch: 6, Steps: 238 Train Loss: 0.5755 (Forecasting Loss:0.5431 + XiCon Loss:3.2385 x Lambda(0.01)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8539
Validation loss decreased (1.020803 --> 1.020297).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6050054
	speed: 0.0269s/iter; left time: 598.3517s
	iters: 200, epoch: 7 | loss: 0.5216010
	speed: 0.0236s/iter; left time: 524.0789s
Epoch: 7 cost time: 5.984144926071167
Epoch: 7, Steps: 238 Train Loss: 0.5743 (Forecasting Loss:0.5419 + XiCon Loss:3.2386 x Lambda(0.01)), Vali MSE Loss: 1.0209 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5891488
	speed: 0.0272s/iter; left time: 598.3954s
	iters: 200, epoch: 8 | loss: 0.6460652
	speed: 0.0233s/iter; left time: 510.2672s
Epoch: 8 cost time: 5.990655422210693
Epoch: 8, Steps: 238 Train Loss: 0.5741 (Forecasting Loss:0.5417 + XiCon Loss:3.2434 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8536
Validation loss decreased (1.020297 --> 1.019104).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5835438
	speed: 0.0260s/iter; left time: 566.7825s
	iters: 200, epoch: 9 | loss: 0.5670049
	speed: 0.0231s/iter; left time: 502.2120s
Epoch: 9 cost time: 5.813284397125244
Epoch: 9, Steps: 238 Train Loss: 0.5739 (Forecasting Loss:0.5415 + XiCon Loss:3.2384 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5867099
	speed: 0.0258s/iter; left time: 556.4454s
	iters: 200, epoch: 10 | loss: 0.5953268
	speed: 0.0233s/iter; left time: 500.5359s
Epoch: 10 cost time: 5.8348307609558105
Epoch: 10, Steps: 238 Train Loss: 0.5739 (Forecasting Loss:0.5415 + XiCon Loss:3.2400 x Lambda(0.01)), Vali MSE Loss: 1.0197 Test MSE Loss: 0.8536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5514706
	speed: 0.0270s/iter; left time: 576.2647s
	iters: 200, epoch: 11 | loss: 0.5487858
	speed: 0.0244s/iter; left time: 516.7552s
Epoch: 11 cost time: 6.0479090213775635
Epoch: 11, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5414 + XiCon Loss:3.2370 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019104 --> 1.019042).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5621616
	speed: 0.0265s/iter; left time: 558.7036s
	iters: 200, epoch: 12 | loss: 0.5545909
	speed: 0.0236s/iter; left time: 495.2096s
Epoch: 12 cost time: 5.905850410461426
Epoch: 12, Steps: 238 Train Loss: 0.5736 (Forecasting Loss:0.5412 + XiCon Loss:3.2377 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019042 --> 1.019021).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5580843
	speed: 0.0261s/iter; left time: 543.1666s
	iters: 200, epoch: 13 | loss: 0.6332943
	speed: 0.0226s/iter; left time: 469.7219s
Epoch: 13 cost time: 5.768375873565674
Epoch: 13, Steps: 238 Train Loss: 0.5738 (Forecasting Loss:0.5414 + XiCon Loss:3.2366 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6313415
	speed: 0.0262s/iter; left time: 539.3978s
	iters: 200, epoch: 14 | loss: 0.5837085
	speed: 0.0229s/iter; left time: 469.0996s
Epoch: 14 cost time: 5.791203260421753
Epoch: 14, Steps: 238 Train Loss: 0.5734 (Forecasting Loss:0.5411 + XiCon Loss:3.2381 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5652890
	speed: 0.0260s/iter; left time: 529.7339s
	iters: 200, epoch: 15 | loss: 0.5927008
	speed: 0.0230s/iter; left time: 467.0995s
Epoch: 15 cost time: 5.82399582862854
Epoch: 15, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5414 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5633031
	speed: 0.0265s/iter; left time: 534.3692s
	iters: 200, epoch: 16 | loss: 0.5525769
	speed: 0.0244s/iter; left time: 488.0589s
Epoch: 16 cost time: 6.00534987449646
Epoch: 16, Steps: 238 Train Loss: 0.5738 (Forecasting Loss:0.5414 + XiCon Loss:3.2366 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
Validation loss decreased (1.019021 --> 1.018914).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5693601
	speed: 0.0265s/iter; left time: 528.0686s
	iters: 200, epoch: 17 | loss: 0.5654587
	speed: 0.0235s/iter; left time: 465.7397s
Epoch: 17 cost time: 6.007491827011108
Epoch: 17, Steps: 238 Train Loss: 0.5736 (Forecasting Loss:0.5412 + XiCon Loss:3.2355 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5547513
	speed: 0.0260s/iter; left time: 510.7082s
	iters: 200, epoch: 18 | loss: 0.6243578
	speed: 0.0237s/iter; left time: 464.1691s
Epoch: 18 cost time: 5.895854473114014
Epoch: 18, Steps: 238 Train Loss: 0.5731 (Forecasting Loss:0.5407 + XiCon Loss:3.2390 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6347214
	speed: 0.0258s/iter; left time: 501.0528s
	iters: 200, epoch: 19 | loss: 0.6090068
	speed: 0.0230s/iter; left time: 445.0184s
Epoch: 19 cost time: 5.7927374839782715
Epoch: 19, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5411 + XiCon Loss:3.2392 x Lambda(0.01)), Vali MSE Loss: 1.0197 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6111644
	speed: 0.0264s/iter; left time: 506.7943s
	iters: 200, epoch: 20 | loss: 0.6001595
	speed: 0.0228s/iter; left time: 434.3888s
Epoch: 20 cost time: 5.837095022201538
Epoch: 20, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5413 + XiCon Loss:3.2386 x Lambda(0.01)), Vali MSE Loss: 1.0201 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6263261
	speed: 0.0260s/iter; left time: 492.5307s
	iters: 200, epoch: 21 | loss: 0.5318534
	speed: 0.0233s/iter; left time: 439.7599s
Epoch: 21 cost time: 5.8314008712768555
Epoch: 21, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5413 + XiCon Loss:3.2384 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5560835
	speed: 0.0252s/iter; left time: 470.6814s
	iters: 200, epoch: 22 | loss: 0.5859368
	speed: 0.0236s/iter; left time: 439.2095s
Epoch: 22 cost time: 5.783633232116699
Epoch: 22, Steps: 238 Train Loss: 0.5736 (Forecasting Loss:0.5412 + XiCon Loss:3.2390 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6195074
	speed: 0.0261s/iter; left time: 482.7869s
	iters: 200, epoch: 23 | loss: 0.5941097
	speed: 0.0232s/iter; left time: 425.2871s
Epoch: 23 cost time: 5.848577976226807
Epoch: 23, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5412 + XiCon Loss:3.2364 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5976310
	speed: 0.0266s/iter; left time: 485.5121s
	iters: 200, epoch: 24 | loss: 0.5602963
	speed: 0.0230s/iter; left time: 417.1588s
Epoch: 24 cost time: 5.885771989822388
Epoch: 24, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5411 + XiCon Loss:3.2413 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5774466
	speed: 0.0260s/iter; left time: 467.3086s
	iters: 200, epoch: 25 | loss: 0.5951649
	speed: 0.0240s/iter; left time: 429.2491s
Epoch: 25 cost time: 5.9590582847595215
Epoch: 25, Steps: 238 Train Loss: 0.5741 (Forecasting Loss:0.5417 + XiCon Loss:3.2376 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5604195
	speed: 0.0257s/iter; left time: 456.3968s
	iters: 200, epoch: 26 | loss: 0.5978579
	speed: 0.0235s/iter; left time: 415.4022s
Epoch: 26 cost time: 5.87383246421814
Epoch: 26, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5413 + XiCon Loss:3.2412 x Lambda(0.01)), Vali MSE Loss: 1.0185 Test MSE Loss: 0.8535
Validation loss decreased (1.018914 --> 1.018527).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5575584
	speed: 0.0256s/iter; left time: 449.0510s
	iters: 200, epoch: 27 | loss: 0.5602967
	speed: 0.0231s/iter; left time: 401.8873s
Epoch: 27 cost time: 5.79805326461792
Epoch: 27, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5413 + XiCon Loss:3.2368 x Lambda(0.01)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8535
Validation loss decreased (1.018527 --> 1.018111).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6236011
	speed: 0.0253s/iter; left time: 436.3726s
	iters: 200, epoch: 28 | loss: 0.5587074
	speed: 0.0232s/iter; left time: 398.6989s
Epoch: 28 cost time: 5.777451276779175
Epoch: 28, Steps: 238 Train Loss: 0.5731 (Forecasting Loss:0.5407 + XiCon Loss:3.2384 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5745562
	speed: 0.0256s/iter; left time: 435.3879s
	iters: 200, epoch: 29 | loss: 0.5758751
	speed: 0.0232s/iter; left time: 392.8437s
Epoch: 29 cost time: 5.778162479400635
Epoch: 29, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5412 + XiCon Loss:3.2334 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5715554
	speed: 0.0267s/iter; left time: 448.1143s
	iters: 200, epoch: 30 | loss: 0.5566124
	speed: 0.0235s/iter; left time: 392.2294s
Epoch: 30 cost time: 5.902271032333374
Epoch: 30, Steps: 238 Train Loss: 0.5736 (Forecasting Loss:0.5412 + XiCon Loss:3.2398 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5889714
	speed: 0.0262s/iter; left time: 433.6445s
	iters: 200, epoch: 31 | loss: 0.5709301
	speed: 0.0235s/iter; left time: 387.5799s
Epoch: 31 cost time: 5.918059349060059
Epoch: 31, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5414 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5276877
	speed: 0.0266s/iter; left time: 433.5390s
	iters: 200, epoch: 32 | loss: 0.6128420
	speed: 0.0231s/iter; left time: 375.4866s
Epoch: 32 cost time: 5.867944002151489
Epoch: 32, Steps: 238 Train Loss: 0.5738 (Forecasting Loss:0.5415 + XiCon Loss:3.2350 x Lambda(0.01)), Vali MSE Loss: 1.0193 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5104490
	speed: 0.0252s/iter; left time: 405.7761s
	iters: 200, epoch: 33 | loss: 0.5452141
	speed: 0.0234s/iter; left time: 374.2309s
Epoch: 33 cost time: 5.753978967666626
Epoch: 33, Steps: 238 Train Loss: 0.5732 (Forecasting Loss:0.5408 + XiCon Loss:3.2405 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5720628
	speed: 0.0258s/iter; left time: 408.2967s
	iters: 200, epoch: 34 | loss: 0.5669715
	speed: 0.0228s/iter; left time: 358.5911s
Epoch: 34 cost time: 5.762154817581177
Epoch: 34, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5413 + XiCon Loss:3.2409 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5629883
	speed: 0.0258s/iter; left time: 402.3870s
	iters: 200, epoch: 35 | loss: 0.5906826
	speed: 0.0233s/iter; left time: 361.9523s
Epoch: 35 cost time: 5.825887441635132
Epoch: 35, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5411 + XiCon Loss:3.2387 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5814255
	speed: 0.0249s/iter; left time: 382.3277s
	iters: 200, epoch: 36 | loss: 0.5824096
	speed: 0.0240s/iter; left time: 365.9921s
Epoch: 36 cost time: 5.785556793212891
Epoch: 36, Steps: 238 Train Loss: 0.5735 (Forecasting Loss:0.5412 + XiCon Loss:3.2371 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5629188
	speed: 0.0266s/iter; left time: 402.9855s
	iters: 200, epoch: 37 | loss: 0.6007568
	speed: 0.0228s/iter; left time: 343.2868s
Epoch: 37 cost time: 5.864331960678101
Epoch: 37, Steps: 238 Train Loss: 0.5734 (Forecasting Loss:0.5411 + XiCon Loss:3.2357 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9859791398048401, mae:0.7210736274719238, mape:4.676759719848633, mspe:2546.37890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9668
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9780228
	speed: 0.0262s/iter; left time: 620.6756s
	iters: 200, epoch: 1 | loss: 1.0311199
	speed: 0.0230s/iter; left time: 542.1802s
Epoch: 1 cost time: 5.872674465179443
Epoch: 1, Steps: 238 Train Loss: 1.0591 (Forecasting Loss:1.0271 + XiCon Loss:3.2035 x Lambda(0.01)), Vali MSE Loss: 1.8388 Test MSE Loss: 0.9830
Validation loss decreased (inf --> 1.838782).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6563796
	speed: 0.0252s/iter; left time: 590.9496s
	iters: 200, epoch: 2 | loss: 0.5442564
	speed: 0.0232s/iter; left time: 542.6896s
Epoch: 2 cost time: 5.746658802032471
Epoch: 2, Steps: 238 Train Loss: 0.6553 (Forecasting Loss:0.6233 + XiCon Loss:3.1991 x Lambda(0.01)), Vali MSE Loss: 1.0469 Test MSE Loss: 0.8597
Validation loss decreased (1.838782 --> 1.046915).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6037731
	speed: 0.0257s/iter; left time: 597.4515s
	iters: 200, epoch: 3 | loss: 0.6130826
	speed: 0.0237s/iter; left time: 549.0939s
Epoch: 3 cost time: 5.885771989822388
Epoch: 3, Steps: 238 Train Loss: 0.5865 (Forecasting Loss:0.5546 + XiCon Loss:3.1951 x Lambda(0.01)), Vali MSE Loss: 1.0221 Test MSE Loss: 0.8525
Validation loss decreased (1.046915 --> 1.022101).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6035660
	speed: 0.0260s/iter; left time: 597.5758s
	iters: 200, epoch: 4 | loss: 0.6177922
	speed: 0.0225s/iter; left time: 514.8276s
Epoch: 4 cost time: 5.775187015533447
Epoch: 4, Steps: 238 Train Loss: 0.5779 (Forecasting Loss:0.5459 + XiCon Loss:3.1953 x Lambda(0.01)), Vali MSE Loss: 1.0136 Test MSE Loss: 0.8513
Validation loss decreased (1.022101 --> 1.013563).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5970011
	speed: 0.0252s/iter; left time: 573.5395s
	iters: 200, epoch: 5 | loss: 0.6001787
	speed: 0.0231s/iter; left time: 523.7820s
Epoch: 5 cost time: 5.701022386550903
Epoch: 5, Steps: 238 Train Loss: 0.5743 (Forecasting Loss:0.5424 + XiCon Loss:3.1909 x Lambda(0.01)), Vali MSE Loss: 1.0108 Test MSE Loss: 0.8508
Validation loss decreased (1.013563 --> 1.010797).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5505245
	speed: 0.0251s/iter; left time: 565.8287s
	iters: 200, epoch: 6 | loss: 0.5588329
	speed: 0.0239s/iter; left time: 534.6147s
Epoch: 6 cost time: 5.829889297485352
Epoch: 6, Steps: 238 Train Loss: 0.5727 (Forecasting Loss:0.5408 + XiCon Loss:3.1918 x Lambda(0.01)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8504
Validation loss decreased (1.010797 --> 1.008192).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6002495
	speed: 0.0257s/iter; left time: 572.2929s
	iters: 200, epoch: 7 | loss: 0.5907364
	speed: 0.0230s/iter; left time: 508.8880s
Epoch: 7 cost time: 5.762035846710205
Epoch: 7, Steps: 238 Train Loss: 0.5720 (Forecasting Loss:0.5400 + XiCon Loss:3.1952 x Lambda(0.01)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8503
Validation loss decreased (1.008192 --> 1.007915).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6306896
	speed: 0.0256s/iter; left time: 563.3868s
	iters: 200, epoch: 8 | loss: 0.5505074
	speed: 0.0230s/iter; left time: 505.5166s
Epoch: 8 cost time: 5.79233717918396
Epoch: 8, Steps: 238 Train Loss: 0.5715 (Forecasting Loss:0.5395 + XiCon Loss:3.1912 x Lambda(0.01)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8503
Validation loss decreased (1.007915 --> 1.006872).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5476326
	speed: 0.0242s/iter; left time: 528.4725s
	iters: 200, epoch: 9 | loss: 0.5331489
	speed: 0.0227s/iter; left time: 492.3841s
Epoch: 9 cost time: 5.5831358432769775
Epoch: 9, Steps: 238 Train Loss: 0.5714 (Forecasting Loss:0.5394 + XiCon Loss:3.1931 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
Validation loss decreased (1.006872 --> 1.006326).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5437425
	speed: 0.0260s/iter; left time: 560.6737s
	iters: 200, epoch: 10 | loss: 0.5789293
	speed: 0.0225s/iter; left time: 481.8332s
Epoch: 10 cost time: 5.750860929489136
Epoch: 10, Steps: 238 Train Loss: 0.5710 (Forecasting Loss:0.5391 + XiCon Loss:3.1938 x Lambda(0.01)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.8502
Validation loss decreased (1.006326 --> 1.005914).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6444693
	speed: 0.0256s/iter; left time: 545.1921s
	iters: 200, epoch: 11 | loss: 0.5622812
	speed: 0.0233s/iter; left time: 493.5391s
Epoch: 11 cost time: 5.8135764598846436
Epoch: 11, Steps: 238 Train Loss: 0.5708 (Forecasting Loss:0.5388 + XiCon Loss:3.1937 x Lambda(0.01)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5640333
	speed: 0.0254s/iter; left time: 535.4234s
	iters: 200, epoch: 12 | loss: 0.5558553
	speed: 0.0238s/iter; left time: 500.4357s
Epoch: 12 cost time: 5.8750364780426025
Epoch: 12, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5392 + XiCon Loss:3.1935 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6141039
	speed: 0.0246s/iter; left time: 513.1224s
	iters: 200, epoch: 13 | loss: 0.5999116
	speed: 0.0232s/iter; left time: 481.3991s
Epoch: 13 cost time: 5.7031450271606445
Epoch: 13, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1950 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5976677
	speed: 0.0265s/iter; left time: 545.9407s
	iters: 200, epoch: 14 | loss: 0.5335253
	speed: 0.0240s/iter; left time: 491.4535s
Epoch: 14 cost time: 5.971994638442993
Epoch: 14, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1950 x Lambda(0.01)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5546114
	speed: 0.0260s/iter; left time: 529.2925s
	iters: 200, epoch: 15 | loss: 0.6166540
	speed: 0.0229s/iter; left time: 464.5258s
Epoch: 15 cost time: 5.803544998168945
Epoch: 15, Steps: 238 Train Loss: 0.5709 (Forecasting Loss:0.5389 + XiCon Loss:3.1925 x Lambda(0.01)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5489739
	speed: 0.0256s/iter; left time: 516.1819s
	iters: 200, epoch: 16 | loss: 0.5505762
	speed: 0.0236s/iter; left time: 472.3838s
Epoch: 16 cost time: 5.854207992553711
Epoch: 16, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1946 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
Validation loss decreased (1.005914 --> 1.005739).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5791454
	speed: 0.0258s/iter; left time: 512.8142s
	iters: 200, epoch: 17 | loss: 0.5351225
	speed: 0.0232s/iter; left time: 460.1337s
Epoch: 17 cost time: 5.796573638916016
Epoch: 17, Steps: 238 Train Loss: 0.5708 (Forecasting Loss:0.5389 + XiCon Loss:3.1929 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8502
Validation loss decreased (1.005739 --> 1.004943).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5259644
	speed: 0.0251s/iter; left time: 494.0264s
	iters: 200, epoch: 18 | loss: 0.6465311
	speed: 0.0230s/iter; left time: 449.7573s
Epoch: 18 cost time: 5.716369152069092
Epoch: 18, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1938 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5432537
	speed: 0.0248s/iter; left time: 481.2138s
	iters: 200, epoch: 19 | loss: 0.5312608
	speed: 0.0233s/iter; left time: 449.9020s
Epoch: 19 cost time: 5.706192493438721
Epoch: 19, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5388 + XiCon Loss:3.1903 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6244937
	speed: 0.0259s/iter; left time: 497.6844s
	iters: 200, epoch: 20 | loss: 0.5531788
	speed: 0.0222s/iter; left time: 423.6194s
Epoch: 20 cost time: 5.694534778594971
Epoch: 20, Steps: 238 Train Loss: 0.5710 (Forecasting Loss:0.5391 + XiCon Loss:3.1907 x Lambda(0.01)), Vali MSE Loss: 1.0061 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5497363
	speed: 0.0254s/iter; left time: 480.2277s
	iters: 200, epoch: 21 | loss: 0.6144587
	speed: 0.0227s/iter; left time: 428.1668s
Epoch: 21 cost time: 5.69691801071167
Epoch: 21, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5392 + XiCon Loss:3.1936 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6081762
	speed: 0.0256s/iter; left time: 477.9587s
	iters: 200, epoch: 22 | loss: 0.6003443
	speed: 0.0234s/iter; left time: 434.6739s
Epoch: 22 cost time: 5.773862600326538
Epoch: 22, Steps: 238 Train Loss: 0.5709 (Forecasting Loss:0.5390 + XiCon Loss:3.1916 x Lambda(0.01)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5740095
	speed: 0.0247s/iter; left time: 455.9016s
	iters: 200, epoch: 23 | loss: 0.6148775
	speed: 0.0236s/iter; left time: 433.0487s
Epoch: 23 cost time: 5.780486106872559
Epoch: 23, Steps: 238 Train Loss: 0.5709 (Forecasting Loss:0.5390 + XiCon Loss:3.1961 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4994435
	speed: 0.0257s/iter; left time: 468.5908s
	iters: 200, epoch: 24 | loss: 0.5353770
	speed: 0.0231s/iter; left time: 419.3058s
Epoch: 24 cost time: 5.794910669326782
Epoch: 24, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1945 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5949518
	speed: 0.0256s/iter; left time: 460.3544s
	iters: 200, epoch: 25 | loss: 0.5619789
	speed: 0.0238s/iter; left time: 425.2307s
Epoch: 25 cost time: 5.836487770080566
Epoch: 25, Steps: 238 Train Loss: 0.5710 (Forecasting Loss:0.5391 + XiCon Loss:3.1942 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5519663
	speed: 0.0253s/iter; left time: 448.9864s
	iters: 200, epoch: 26 | loss: 0.5939531
	speed: 0.0230s/iter; left time: 406.8118s
Epoch: 26 cost time: 5.762303352355957
Epoch: 26, Steps: 238 Train Loss: 0.5709 (Forecasting Loss:0.5390 + XiCon Loss:3.1935 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5694315
	speed: 0.0256s/iter; left time: 449.1786s
	iters: 200, epoch: 27 | loss: 0.5402218
	speed: 0.0232s/iter; left time: 403.8796s
Epoch: 27 cost time: 5.8179075717926025
Epoch: 27, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5391 + XiCon Loss:3.1974 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9806056618690491, mae:0.7197717428207397, mape:4.738994598388672, mspe:2656.26611328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9842+-0.00980, MAE:0.7227+-0.00649, MAPE:4.8127+-0.19339, MSPE:2733.7949+-251.61919, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.1112
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 0.9971343
	speed: 0.0356s/iter; left time: 825.2106s
	iters: 200, epoch: 1 | loss: 0.9508857
	speed: 0.0286s/iter; left time: 660.3428s
Epoch: 1 cost time: 7.349217176437378
Epoch: 1, Steps: 233 Train Loss: 1.0507 (Forecasting Loss:1.0189 + XiCon Loss:3.1755 x Lambda(0.01)), Vali MSE Loss: 1.8606 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860589).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6327983
	speed: 0.0305s/iter; left time: 699.4142s
	iters: 200, epoch: 2 | loss: 0.6950642
	speed: 0.0279s/iter; left time: 637.7090s
Epoch: 2 cost time: 6.753129005432129
Epoch: 2, Steps: 233 Train Loss: 0.6839 (Forecasting Loss:0.6522 + XiCon Loss:3.1713 x Lambda(0.01)), Vali MSE Loss: 1.1270 Test MSE Loss: 1.1495
Validation loss decreased (1.860589 --> 1.126974).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6595389
	speed: 0.0312s/iter; left time: 708.7323s
	iters: 200, epoch: 3 | loss: 0.6023842
	speed: 0.0282s/iter; left time: 638.1104s
Epoch: 3 cost time: 6.879296541213989
Epoch: 3, Steps: 233 Train Loss: 0.6197 (Forecasting Loss:0.5881 + XiCon Loss:3.1643 x Lambda(0.01)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1437
Validation loss decreased (1.126974 --> 1.104192).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6270989
	speed: 0.0301s/iter; left time: 677.8427s
	iters: 200, epoch: 4 | loss: 0.6254696
	speed: 0.0281s/iter; left time: 630.5312s
Epoch: 4 cost time: 6.753634929656982
Epoch: 4, Steps: 233 Train Loss: 0.6116 (Forecasting Loss:0.5799 + XiCon Loss:3.1625 x Lambda(0.01)), Vali MSE Loss: 1.0969 Test MSE Loss: 1.1410
Validation loss decreased (1.104192 --> 1.096890).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6000840
	speed: 0.0297s/iter; left time: 660.3923s
	iters: 200, epoch: 5 | loss: 0.5971085
	speed: 0.0279s/iter; left time: 617.6919s
Epoch: 5 cost time: 6.688575744628906
Epoch: 5, Steps: 233 Train Loss: 0.6083 (Forecasting Loss:0.5767 + XiCon Loss:3.1629 x Lambda(0.01)), Vali MSE Loss: 1.0935 Test MSE Loss: 1.1402
Validation loss decreased (1.096890 --> 1.093468).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6213473
	speed: 0.0296s/iter; left time: 651.9178s
	iters: 200, epoch: 6 | loss: 0.6317047
	speed: 0.0279s/iter; left time: 611.1519s
Epoch: 6 cost time: 6.695263147354126
Epoch: 6, Steps: 233 Train Loss: 0.6069 (Forecasting Loss:0.5752 + XiCon Loss:3.1650 x Lambda(0.01)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1398
Validation loss decreased (1.093468 --> 1.091776).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5969284
	speed: 0.0311s/iter; left time: 678.9647s
	iters: 200, epoch: 7 | loss: 0.6527740
	speed: 0.0287s/iter; left time: 623.3220s
Epoch: 7 cost time: 6.906327962875366
Epoch: 7, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5744 + XiCon Loss:3.1617 x Lambda(0.01)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1398
Validation loss decreased (1.091776 --> 1.090931).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5748726
	speed: 0.0309s/iter; left time: 667.3391s
	iters: 200, epoch: 8 | loss: 0.6180940
	speed: 0.0283s/iter; left time: 606.7221s
Epoch: 8 cost time: 6.868013858795166
Epoch: 8, Steps: 233 Train Loss: 0.6056 (Forecasting Loss:0.5740 + XiCon Loss:3.1639 x Lambda(0.01)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1397
Validation loss decreased (1.090931 --> 1.090789).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6513433
	speed: 0.0305s/iter; left time: 651.6740s
	iters: 200, epoch: 9 | loss: 0.6502720
	speed: 0.0280s/iter; left time: 593.7860s
Epoch: 9 cost time: 6.7714314460754395
Epoch: 9, Steps: 233 Train Loss: 0.6054 (Forecasting Loss:0.5738 + XiCon Loss:3.1653 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
Validation loss decreased (1.090789 --> 1.090328).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5733251
	speed: 0.0303s/iter; left time: 639.6335s
	iters: 200, epoch: 10 | loss: 0.5955529
	speed: 0.0278s/iter; left time: 584.1403s
Epoch: 10 cost time: 6.75678014755249
Epoch: 10, Steps: 233 Train Loss: 0.6054 (Forecasting Loss:0.5737 + XiCon Loss:3.1627 x Lambda(0.01)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5916883
	speed: 0.0304s/iter; left time: 635.2946s
	iters: 200, epoch: 11 | loss: 0.6161483
	speed: 0.0280s/iter; left time: 582.3798s
Epoch: 11 cost time: 6.779914617538452
Epoch: 11, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1611 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
Validation loss decreased (1.090328 --> 1.090116).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6186262
	speed: 0.0318s/iter; left time: 657.2931s
	iters: 200, epoch: 12 | loss: 0.6050848
	speed: 0.0276s/iter; left time: 565.8229s
Epoch: 12 cost time: 6.906754970550537
Epoch: 12, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1595 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
Validation loss decreased (1.090116 --> 1.089955).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5930042
	speed: 0.0291s/iter; left time: 594.7809s
	iters: 200, epoch: 13 | loss: 0.6172238
	speed: 0.0272s/iter; left time: 551.6311s
Epoch: 13 cost time: 6.58141565322876
Epoch: 13, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1622 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.089955 --> 1.089896).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6167305
	speed: 0.0299s/iter; left time: 604.0994s
	iters: 200, epoch: 14 | loss: 0.5984464
	speed: 0.0286s/iter; left time: 574.4180s
Epoch: 14 cost time: 6.796928405761719
Epoch: 14, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1603 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5884528
	speed: 0.0297s/iter; left time: 591.7174s
	iters: 200, epoch: 15 | loss: 0.6413191
	speed: 0.0278s/iter; left time: 551.4976s
Epoch: 15 cost time: 6.702566385269165
Epoch: 15, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1608 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6214674
	speed: 0.0297s/iter; left time: 584.5016s
	iters: 200, epoch: 16 | loss: 0.6323433
	speed: 0.0281s/iter; left time: 551.5291s
Epoch: 16 cost time: 6.705635070800781
Epoch: 16, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 1.0895 Test MSE Loss: 1.1396
Validation loss decreased (1.089896 --> 1.089486).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5984089
	speed: 0.0300s/iter; left time: 583.4355s
	iters: 200, epoch: 17 | loss: 0.5905602
	speed: 0.0277s/iter; left time: 536.3049s
Epoch: 17 cost time: 6.730685710906982
Epoch: 17, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1594 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6416044
	speed: 0.0311s/iter; left time: 598.4174s
	iters: 200, epoch: 18 | loss: 0.6122864
	speed: 0.0284s/iter; left time: 542.6216s
Epoch: 18 cost time: 6.9568235874176025
Epoch: 18, Steps: 233 Train Loss: 0.6051 (Forecasting Loss:0.5735 + XiCon Loss:3.1617 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5948291
	speed: 0.0300s/iter; left time: 569.4142s
	iters: 200, epoch: 19 | loss: 0.6846015
	speed: 0.0277s/iter; left time: 524.2410s
Epoch: 19 cost time: 6.677731513977051
Epoch: 19, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1629 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5776451
	speed: 0.0301s/iter; left time: 565.9896s
	iters: 200, epoch: 20 | loss: 0.5845613
	speed: 0.0284s/iter; left time: 530.7289s
Epoch: 20 cost time: 6.828543424606323
Epoch: 20, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1615 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6048673
	speed: 0.0304s/iter; left time: 564.4076s
	iters: 200, epoch: 21 | loss: 0.5855972
	speed: 0.0286s/iter; left time: 527.5300s
Epoch: 21 cost time: 6.848772287368774
Epoch: 21, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1626 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5785081
	speed: 0.0300s/iter; left time: 549.3887s
	iters: 200, epoch: 22 | loss: 0.5802355
	speed: 0.0286s/iter; left time: 520.2674s
Epoch: 22 cost time: 6.829814910888672
Epoch: 22, Steps: 233 Train Loss: 0.6053 (Forecasting Loss:0.5737 + XiCon Loss:3.1642 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5487075
	speed: 0.0304s/iter; left time: 550.2075s
	iters: 200, epoch: 23 | loss: 0.6053826
	speed: 0.0281s/iter; left time: 504.2322s
Epoch: 23 cost time: 6.783358335494995
Epoch: 23, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1598 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5941208
	speed: 0.0295s/iter; left time: 526.9343s
	iters: 200, epoch: 24 | loss: 0.5779436
	speed: 0.0279s/iter; left time: 495.4731s
Epoch: 24 cost time: 6.694194078445435
Epoch: 24, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1639 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6018741
	speed: 0.0305s/iter; left time: 536.9072s
	iters: 200, epoch: 25 | loss: 0.5798060
	speed: 0.0277s/iter; left time: 484.9754s
Epoch: 25 cost time: 6.765569448471069
Epoch: 25, Steps: 233 Train Loss: 0.6053 (Forecasting Loss:0.5736 + XiCon Loss:3.1650 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5795884
	speed: 0.0301s/iter; left time: 523.1567s
	iters: 200, epoch: 26 | loss: 0.6481820
	speed: 0.0290s/iter; left time: 501.6305s
Epoch: 26 cost time: 6.866377830505371
Epoch: 26, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5736 + XiCon Loss:3.1575 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3994741439819336, mae:0.8796904683113098, mape:6.137996196746826, mspe:4546.4443359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.0377
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1819329
	speed: 0.0309s/iter; left time: 716.4133s
	iters: 200, epoch: 1 | loss: 1.1431679
	speed: 0.0261s/iter; left time: 602.6527s
Epoch: 1 cost time: 6.546151638031006
Epoch: 1, Steps: 233 Train Loss: 1.1661 (Forecasting Loss:1.1341 + XiCon Loss:3.1984 x Lambda(0.01)), Vali MSE Loss: 2.0405 Test MSE Loss: 1.3313
Validation loss decreased (inf --> 2.040485).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7119903
	speed: 0.0294s/iter; left time: 674.6074s
	iters: 200, epoch: 2 | loss: 0.6273822
	speed: 0.0250s/iter; left time: 570.7110s
Epoch: 2 cost time: 6.259308576583862
Epoch: 2, Steps: 233 Train Loss: 0.6918 (Forecasting Loss:0.6598 + XiCon Loss:3.1988 x Lambda(0.01)), Vali MSE Loss: 1.1148 Test MSE Loss: 1.1427
Validation loss decreased (2.040485 --> 1.114845).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6047333
	speed: 0.0292s/iter; left time: 662.9599s
	iters: 200, epoch: 3 | loss: 0.5958018
	speed: 0.0265s/iter; left time: 599.8913s
Epoch: 3 cost time: 6.444089412689209
Epoch: 3, Steps: 233 Train Loss: 0.6194 (Forecasting Loss:0.5874 + XiCon Loss:3.1992 x Lambda(0.01)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1376
Validation loss decreased (1.114845 --> 1.091933).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6612445
	speed: 0.0292s/iter; left time: 656.3418s
	iters: 200, epoch: 4 | loss: 0.5893528
	speed: 0.0253s/iter; left time: 565.6663s
Epoch: 4 cost time: 6.267545700073242
Epoch: 4, Steps: 233 Train Loss: 0.6109 (Forecasting Loss:0.5790 + XiCon Loss:3.1964 x Lambda(0.01)), Vali MSE Loss: 1.0847 Test MSE Loss: 1.1360
Validation loss decreased (1.091933 --> 1.084654).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6816360
	speed: 0.0298s/iter; left time: 664.2612s
	iters: 200, epoch: 5 | loss: 0.5736156
	speed: 0.0249s/iter; left time: 551.7928s
Epoch: 5 cost time: 6.290971040725708
Epoch: 5, Steps: 233 Train Loss: 0.6076 (Forecasting Loss:0.5756 + XiCon Loss:3.2011 x Lambda(0.01)), Vali MSE Loss: 1.0800 Test MSE Loss: 1.1359
Validation loss decreased (1.084654 --> 1.079992).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6674478
	speed: 0.0295s/iter; left time: 650.8318s
	iters: 200, epoch: 6 | loss: 0.6456578
	speed: 0.0258s/iter; left time: 565.3948s
Epoch: 6 cost time: 6.396225690841675
Epoch: 6, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5740 + XiCon Loss:3.2002 x Lambda(0.01)), Vali MSE Loss: 1.0789 Test MSE Loss: 1.1350
Validation loss decreased (1.079992 --> 1.078882).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6069394
	speed: 0.0287s/iter; left time: 625.0052s
	iters: 200, epoch: 7 | loss: 0.5935559
	speed: 0.0263s/iter; left time: 570.2313s
Epoch: 7 cost time: 6.340210437774658
Epoch: 7, Steps: 233 Train Loss: 0.6053 (Forecasting Loss:0.5733 + XiCon Loss:3.1981 x Lambda(0.01)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1352
Validation loss decreased (1.078882 --> 1.077420).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6007934
	speed: 0.0294s/iter; left time: 633.4467s
	iters: 200, epoch: 8 | loss: 0.6549537
	speed: 0.0249s/iter; left time: 535.0599s
Epoch: 8 cost time: 6.2736897468566895
Epoch: 8, Steps: 233 Train Loss: 0.6047 (Forecasting Loss:0.5728 + XiCon Loss:3.1982 x Lambda(0.01)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1352
Validation loss decreased (1.077420 --> 1.076865).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5823193
	speed: 0.0290s/iter; left time: 618.7245s
	iters: 200, epoch: 9 | loss: 0.5887203
	speed: 0.0259s/iter; left time: 550.7474s
Epoch: 9 cost time: 6.315065383911133
Epoch: 9, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5726 + XiCon Loss:3.1960 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1352
Validation loss decreased (1.076865 --> 1.076512).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6124312
	speed: 0.0292s/iter; left time: 615.5793s
	iters: 200, epoch: 10 | loss: 0.6099961
	speed: 0.0254s/iter; left time: 532.8913s
Epoch: 10 cost time: 6.299275636672974
Epoch: 10, Steps: 233 Train Loss: 0.6046 (Forecasting Loss:0.5726 + XiCon Loss:3.2033 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5445910
	speed: 0.0291s/iter; left time: 607.9800s
	iters: 200, epoch: 11 | loss: 0.6072168
	speed: 0.0257s/iter; left time: 534.6414s
Epoch: 11 cost time: 6.340474843978882
Epoch: 11, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1950 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5864250
	speed: 0.0285s/iter; left time: 587.4023s
	iters: 200, epoch: 12 | loss: 0.5938388
	speed: 0.0256s/iter; left time: 526.5415s
Epoch: 12 cost time: 6.2795844078063965
Epoch: 12, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1970 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076512 --> 1.076447).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6216936
	speed: 0.0291s/iter; left time: 593.5226s
	iters: 200, epoch: 13 | loss: 0.6201646
	speed: 0.0253s/iter; left time: 514.7272s
Epoch: 13 cost time: 6.30147385597229
Epoch: 13, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1954 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5906649
	speed: 0.0287s/iter; left time: 579.3624s
	iters: 200, epoch: 14 | loss: 0.5979166
	speed: 0.0246s/iter; left time: 494.4756s
Epoch: 14 cost time: 6.139678955078125
Epoch: 14, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5725 + XiCon Loss:3.1940 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076447 --> 1.076414).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6148133
	speed: 0.0285s/iter; left time: 568.0639s
	iters: 200, epoch: 15 | loss: 0.5766854
	speed: 0.0243s/iter; left time: 482.5630s
Epoch: 15 cost time: 6.08083963394165
Epoch: 15, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1975 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6105205
	speed: 0.0290s/iter; left time: 571.9070s
	iters: 200, epoch: 16 | loss: 0.6366811
	speed: 0.0258s/iter; left time: 506.0567s
Epoch: 16 cost time: 6.312272548675537
Epoch: 16, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1978 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5830287
	speed: 0.0294s/iter; left time: 572.2750s
	iters: 200, epoch: 17 | loss: 0.5598777
	speed: 0.0250s/iter; left time: 484.2297s
Epoch: 17 cost time: 6.246465682983398
Epoch: 17, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1988 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6461598
	speed: 0.0295s/iter; left time: 567.8344s
	iters: 200, epoch: 18 | loss: 0.5786483
	speed: 0.0251s/iter; left time: 480.4838s
Epoch: 18 cost time: 6.287050724029541
Epoch: 18, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1978 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5733435
	speed: 0.0287s/iter; left time: 544.6081s
	iters: 200, epoch: 19 | loss: 0.5998068
	speed: 0.0252s/iter; left time: 476.9023s
Epoch: 19 cost time: 6.2516562938690186
Epoch: 19, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1992 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6434284
	speed: 0.0299s/iter; left time: 561.0428s
	iters: 200, epoch: 20 | loss: 0.5771865
	speed: 0.0261s/iter; left time: 487.1828s
Epoch: 20 cost time: 6.437418460845947
Epoch: 20, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1958 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5790142
	speed: 0.0296s/iter; left time: 548.3215s
	iters: 200, epoch: 21 | loss: 0.5998875
	speed: 0.0252s/iter; left time: 465.0404s
Epoch: 21 cost time: 6.299727916717529
Epoch: 21, Steps: 233 Train Loss: 0.6046 (Forecasting Loss:0.5726 + XiCon Loss:3.1981 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
Validation loss decreased (1.076414 --> 1.076271).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6358428
	speed: 0.0297s/iter; left time: 543.2259s
	iters: 200, epoch: 22 | loss: 0.6215672
	speed: 0.0252s/iter; left time: 459.5522s
Epoch: 22 cost time: 6.292459011077881
Epoch: 22, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1972 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5880708
	speed: 0.0293s/iter; left time: 529.9863s
	iters: 200, epoch: 23 | loss: 0.6259571
	speed: 0.0254s/iter; left time: 457.0309s
Epoch: 23 cost time: 6.288886308670044
Epoch: 23, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1965 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5867823
	speed: 0.0293s/iter; left time: 522.7673s
	iters: 200, epoch: 24 | loss: 0.5721230
	speed: 0.0257s/iter; left time: 456.2945s
Epoch: 24 cost time: 6.348532438278198
Epoch: 24, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1996 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6739147
	speed: 0.0296s/iter; left time: 522.0670s
	iters: 200, epoch: 25 | loss: 0.6206555
	speed: 0.0256s/iter; left time: 448.3736s
Epoch: 25 cost time: 6.3737993240356445
Epoch: 25, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1975 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
Validation loss decreased (1.076271 --> 1.076183).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6203855
	speed: 0.0290s/iter; left time: 504.4411s
	iters: 200, epoch: 26 | loss: 0.5805706
	speed: 0.0264s/iter; left time: 456.2992s
Epoch: 26 cost time: 6.435753583908081
Epoch: 26, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1976 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5948967
	speed: 0.0290s/iter; left time: 496.3209s
	iters: 200, epoch: 27 | loss: 0.6469540
	speed: 0.0251s/iter; left time: 427.7157s
Epoch: 27 cost time: 6.2521727085113525
Epoch: 27, Steps: 233 Train Loss: 0.6046 (Forecasting Loss:0.5726 + XiCon Loss:3.1986 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5422797
	speed: 0.0289s/iter; left time: 488.2548s
	iters: 200, epoch: 28 | loss: 0.6095605
	speed: 0.0254s/iter; left time: 427.0218s
Epoch: 28 cost time: 6.264476299285889
Epoch: 28, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5724 + XiCon Loss:3.1958 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.6168277
	speed: 0.0290s/iter; left time: 484.4086s
	iters: 200, epoch: 29 | loss: 0.5966983
	speed: 0.0251s/iter; left time: 416.1636s
Epoch: 29 cost time: 6.2723376750946045
Epoch: 29, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1988 x Lambda(0.01)), Vali MSE Loss: 1.0768 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6246625
	speed: 0.0298s/iter; left time: 489.3314s
	iters: 200, epoch: 30 | loss: 0.6324680
	speed: 0.0260s/iter; left time: 424.7165s
Epoch: 30 cost time: 6.409299373626709
Epoch: 30, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1973 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5815679
	speed: 0.0292s/iter; left time: 472.8431s
	iters: 200, epoch: 31 | loss: 0.5995113
	speed: 0.0248s/iter; left time: 398.8271s
Epoch: 31 cost time: 6.228662967681885
Epoch: 31, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1968 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6226974
	speed: 0.0290s/iter; left time: 463.5535s
	iters: 200, epoch: 32 | loss: 0.6312640
	speed: 0.0252s/iter; left time: 399.8976s
Epoch: 32 cost time: 6.243883848190308
Epoch: 32, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5724 + XiCon Loss:3.1976 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5697115
	speed: 0.0294s/iter; left time: 462.6215s
	iters: 200, epoch: 33 | loss: 0.6269011
	speed: 0.0258s/iter; left time: 403.8582s
Epoch: 33 cost time: 6.348911285400391
Epoch: 33, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5725 + XiCon Loss:3.1971 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5790542
	speed: 0.0286s/iter; left time: 444.0479s
	iters: 200, epoch: 34 | loss: 0.5799468
	speed: 0.0255s/iter; left time: 393.5249s
Epoch: 34 cost time: 6.289292097091675
Epoch: 34, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.5725 + XiCon Loss:3.1959 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.6032501
	speed: 0.0291s/iter; left time: 445.1679s
	iters: 200, epoch: 35 | loss: 0.6203908
	speed: 0.0259s/iter; left time: 393.7380s
Epoch: 35 cost time: 6.354696989059448
Epoch: 35, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.5723 + XiCon Loss:3.1986 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3928602933883667, mae:0.8773928880691528, mape:6.102296829223633, mspe:4463.390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.1674
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1747906
	speed: 0.0321s/iter; left time: 744.6363s
	iters: 200, epoch: 1 | loss: 0.9932049
	speed: 0.0288s/iter; left time: 665.2437s
Epoch: 1 cost time: 7.08152961730957
Epoch: 1, Steps: 233 Train Loss: 1.0457 (Forecasting Loss:1.0137 + XiCon Loss:3.2027 x Lambda(0.01)), Vali MSE Loss: 1.8333 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833313).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6758002
	speed: 0.0298s/iter; left time: 684.0190s
	iters: 200, epoch: 2 | loss: 0.5821276
	speed: 0.0274s/iter; left time: 626.3323s
Epoch: 2 cost time: 6.657998323440552
Epoch: 2, Steps: 233 Train Loss: 0.6845 (Forecasting Loss:0.6525 + XiCon Loss:3.1997 x Lambda(0.01)), Vali MSE Loss: 1.1219 Test MSE Loss: 1.1452
Validation loss decreased (1.833313 --> 1.121918).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6129141
	speed: 0.0310s/iter; left time: 704.1782s
	iters: 200, epoch: 3 | loss: 0.5989712
	speed: 0.0281s/iter; left time: 636.8483s
Epoch: 3 cost time: 6.851871490478516
Epoch: 3, Steps: 233 Train Loss: 0.6202 (Forecasting Loss:0.5883 + XiCon Loss:3.1890 x Lambda(0.01)), Vali MSE Loss: 1.0999 Test MSE Loss: 1.1377
Validation loss decreased (1.121918 --> 1.099879).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6487404
	speed: 0.0306s/iter; left time: 688.8060s
	iters: 200, epoch: 4 | loss: 0.6263414
	speed: 0.0278s/iter; left time: 622.7131s
Epoch: 4 cost time: 6.810778379440308
Epoch: 4, Steps: 233 Train Loss: 0.6116 (Forecasting Loss:0.5797 + XiCon Loss:3.1875 x Lambda(0.01)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1365
Validation loss decreased (1.099879 --> 1.090999).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5779880
	speed: 0.0302s/iter; left time: 672.2470s
	iters: 200, epoch: 5 | loss: 0.5671113
	speed: 0.0282s/iter; left time: 624.7748s
Epoch: 5 cost time: 6.82132363319397
Epoch: 5, Steps: 233 Train Loss: 0.6081 (Forecasting Loss:0.5762 + XiCon Loss:3.1861 x Lambda(0.01)), Vali MSE Loss: 1.0870 Test MSE Loss: 1.1360
Validation loss decreased (1.090999 --> 1.087020).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6171465
	speed: 0.0299s/iter; left time: 658.3397s
	iters: 200, epoch: 6 | loss: 0.6197228
	speed: 0.0280s/iter; left time: 614.9589s
Epoch: 6 cost time: 6.772034406661987
Epoch: 6, Steps: 233 Train Loss: 0.6065 (Forecasting Loss:0.5746 + XiCon Loss:3.1885 x Lambda(0.01)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1358
Validation loss decreased (1.087020 --> 1.085382).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5536676
	speed: 0.0301s/iter; left time: 656.7599s
	iters: 200, epoch: 7 | loss: 0.6556589
	speed: 0.0277s/iter; left time: 600.8229s
Epoch: 7 cost time: 6.75434422492981
Epoch: 7, Steps: 233 Train Loss: 0.6057 (Forecasting Loss:0.5738 + XiCon Loss:3.1846 x Lambda(0.01)), Vali MSE Loss: 1.0846 Test MSE Loss: 1.1356
Validation loss decreased (1.085382 --> 1.084562).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6043903
	speed: 0.0292s/iter; left time: 629.6094s
	iters: 200, epoch: 8 | loss: 0.5893158
	speed: 0.0277s/iter; left time: 595.1389s
Epoch: 8 cost time: 6.626456260681152
Epoch: 8, Steps: 233 Train Loss: 0.6052 (Forecasting Loss:0.5734 + XiCon Loss:3.1850 x Lambda(0.01)), Vali MSE Loss: 1.0842 Test MSE Loss: 1.1356
Validation loss decreased (1.084562 --> 1.084154).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6324298
	speed: 0.0298s/iter; left time: 635.1555s
	iters: 200, epoch: 9 | loss: 0.5842999
	speed: 0.0279s/iter; left time: 593.2100s
Epoch: 9 cost time: 6.719705820083618
Epoch: 9, Steps: 233 Train Loss: 0.6051 (Forecasting Loss:0.5732 + XiCon Loss:3.1925 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
Validation loss decreased (1.084154 --> 1.083814).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5749203
	speed: 0.0306s/iter; left time: 645.7738s
	iters: 200, epoch: 10 | loss: 0.6069337
	speed: 0.0286s/iter; left time: 600.7949s
Epoch: 10 cost time: 6.858114957809448
Epoch: 10, Steps: 233 Train Loss: 0.6050 (Forecasting Loss:0.5731 + XiCon Loss:3.1881 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6073411
	speed: 0.0308s/iter; left time: 642.5573s
	iters: 200, epoch: 11 | loss: 0.6115528
	speed: 0.0282s/iter; left time: 586.1864s
Epoch: 11 cost time: 6.8429176807403564
Epoch: 11, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5731 + XiCon Loss:3.1862 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083814 --> 1.083726).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5682360
	speed: 0.0303s/iter; left time: 625.8333s
	iters: 200, epoch: 12 | loss: 0.5694149
	speed: 0.0282s/iter; left time: 579.2523s
Epoch: 12 cost time: 6.757754325866699
Epoch: 12, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5730 + XiCon Loss:3.1845 x Lambda(0.01)), Vali MSE Loss: 1.0840 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6508094
	speed: 0.0306s/iter; left time: 625.3220s
	iters: 200, epoch: 13 | loss: 0.6019880
	speed: 0.0280s/iter; left time: 569.0247s
Epoch: 13 cost time: 6.824144601821899
Epoch: 13, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5731 + XiCon Loss:3.1872 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6095705
	speed: 0.0304s/iter; left time: 612.6763s
	iters: 200, epoch: 14 | loss: 0.6225120
	speed: 0.0280s/iter; left time: 562.6451s
Epoch: 14 cost time: 6.794001579284668
Epoch: 14, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5729 + XiCon Loss:3.1848 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5620409
	speed: 0.0302s/iter; left time: 602.6427s
	iters: 200, epoch: 15 | loss: 0.6131760
	speed: 0.0278s/iter; left time: 551.5532s
Epoch: 15 cost time: 6.7467217445373535
Epoch: 15, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1859 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6076588
	speed: 0.0307s/iter; left time: 604.6435s
	iters: 200, epoch: 16 | loss: 0.5934753
	speed: 0.0282s/iter; left time: 552.6064s
Epoch: 16 cost time: 6.875811576843262
Epoch: 16, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1865 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5505207
	speed: 0.0305s/iter; left time: 593.5910s
	iters: 200, epoch: 17 | loss: 0.5780360
	speed: 0.0282s/iter; left time: 545.6541s
Epoch: 17 cost time: 6.841064929962158
Epoch: 17, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1865 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083726 --> 1.083700).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6152375
	speed: 0.0300s/iter; left time: 577.5155s
	iters: 200, epoch: 18 | loss: 0.5887243
	speed: 0.0279s/iter; left time: 534.3764s
Epoch: 18 cost time: 6.744811058044434
Epoch: 18, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5730 + XiCon Loss:3.1841 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5914505
	speed: 0.0303s/iter; left time: 576.4662s
	iters: 200, epoch: 19 | loss: 0.6180364
	speed: 0.0286s/iter; left time: 540.9219s
Epoch: 19 cost time: 6.873568058013916
Epoch: 19, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5729 + XiCon Loss:3.1887 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6273109
	speed: 0.0299s/iter; left time: 562.2553s
	iters: 200, epoch: 20 | loss: 0.5752063
	speed: 0.0272s/iter; left time: 507.4849s
Epoch: 20 cost time: 6.654926538467407
Epoch: 20, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1851 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6796106
	speed: 0.0305s/iter; left time: 565.1790s
	iters: 200, epoch: 21 | loss: 0.5424204
	speed: 0.0278s/iter; left time: 512.9499s
Epoch: 21 cost time: 6.778307676315308
Epoch: 21, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5729 + XiCon Loss:3.1904 x Lambda(0.01)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
Validation loss decreased (1.083700 --> 1.083572).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5573688
	speed: 0.0303s/iter; left time: 554.7513s
	iters: 200, epoch: 22 | loss: 0.5897529
	speed: 0.0278s/iter; left time: 505.5044s
Epoch: 22 cost time: 6.766697406768799
Epoch: 22, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5729 + XiCon Loss:3.1890 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5956178
	speed: 0.0311s/iter; left time: 561.6048s
	iters: 200, epoch: 23 | loss: 0.6521958
	speed: 0.0286s/iter; left time: 514.5480s
Epoch: 23 cost time: 6.939262628555298
Epoch: 23, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5730 + XiCon Loss:3.1836 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5607277
	speed: 0.0298s/iter; left time: 532.3726s
	iters: 200, epoch: 24 | loss: 0.6232204
	speed: 0.0282s/iter; left time: 500.0054s
Epoch: 24 cost time: 6.808060169219971
Epoch: 24, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5730 + XiCon Loss:3.1853 x Lambda(0.01)), Vali MSE Loss: 1.0840 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6638433
	speed: 0.0309s/iter; left time: 544.3546s
	iters: 200, epoch: 25 | loss: 0.5270447
	speed: 0.0281s/iter; left time: 492.6769s
Epoch: 25 cost time: 6.8319313526153564
Epoch: 25, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1835 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6292704
	speed: 0.0305s/iter; left time: 529.2293s
	iters: 200, epoch: 26 | loss: 0.6118326
	speed: 0.0285s/iter; left time: 491.7695s
Epoch: 26 cost time: 6.8560850620269775
Epoch: 26, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5730 + XiCon Loss:3.1838 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6014750
	speed: 0.0307s/iter; left time: 526.7341s
	iters: 200, epoch: 27 | loss: 0.6438792
	speed: 0.0280s/iter; left time: 476.5091s
Epoch: 27 cost time: 6.8669068813323975
Epoch: 27, Steps: 233 Train Loss: 0.6047 (Forecasting Loss:0.5729 + XiCon Loss:3.1810 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6003237
	speed: 0.0304s/iter; left time: 513.8516s
	iters: 200, epoch: 28 | loss: 0.6113470
	speed: 0.0280s/iter; left time: 470.5709s
Epoch: 28 cost time: 6.793402910232544
Epoch: 28, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5729 + XiCon Loss:3.1872 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5833991
	speed: 0.0304s/iter; left time: 507.4943s
	iters: 200, epoch: 29 | loss: 0.6035334
	speed: 0.0275s/iter; left time: 455.1457s
Epoch: 29 cost time: 6.736042261123657
Epoch: 29, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1912 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6100013
	speed: 0.0303s/iter; left time: 497.9390s
	iters: 200, epoch: 30 | loss: 0.5626684
	speed: 0.0283s/iter; left time: 463.1209s
Epoch: 30 cost time: 6.807117938995361
Epoch: 30, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5729 + XiCon Loss:3.1855 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5560899
	speed: 0.0306s/iter; left time: 495.6500s
	iters: 200, epoch: 31 | loss: 0.5928058
	speed: 0.0277s/iter; left time: 446.0067s
Epoch: 31 cost time: 6.829926252365112
Epoch: 31, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5730 + XiCon Loss:3.1872 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.391629695892334, mae:0.8793686032295227, mape:6.165745258331299, mspe:4547.01611328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.5338
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0533841
	speed: 0.0280s/iter; left time: 650.2366s
	iters: 200, epoch: 1 | loss: 1.0197421
	speed: 0.0236s/iter; left time: 545.1096s
Epoch: 1 cost time: 5.965153932571411
Epoch: 1, Steps: 233 Train Loss: 1.0600 (Forecasting Loss:1.0277 + XiCon Loss:3.2241 x Lambda(0.01)), Vali MSE Loss: 1.8645 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864500).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6572347
	speed: 0.0261s/iter; left time: 598.5534s
	iters: 200, epoch: 2 | loss: 0.6303611
	speed: 0.0238s/iter; left time: 544.2205s
Epoch: 2 cost time: 5.821327209472656
Epoch: 2, Steps: 233 Train Loss: 0.6867 (Forecasting Loss:0.6545 + XiCon Loss:3.2186 x Lambda(0.01)), Vali MSE Loss: 1.1221 Test MSE Loss: 1.1462
Validation loss decreased (1.864500 --> 1.122148).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6379023
	speed: 0.0268s/iter; left time: 608.7297s
	iters: 200, epoch: 3 | loss: 0.6713470
	speed: 0.0237s/iter; left time: 536.2339s
Epoch: 3 cost time: 5.876094341278076
Epoch: 3, Steps: 233 Train Loss: 0.6215 (Forecasting Loss:0.5893 + XiCon Loss:3.2157 x Lambda(0.01)), Vali MSE Loss: 1.1027 Test MSE Loss: 1.1399
Validation loss decreased (1.122148 --> 1.102670).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5735917
	speed: 0.0263s/iter; left time: 590.8634s
	iters: 200, epoch: 4 | loss: 0.6322988
	speed: 0.0232s/iter; left time: 520.1659s
Epoch: 4 cost time: 5.749741554260254
Epoch: 4, Steps: 233 Train Loss: 0.6131 (Forecasting Loss:0.5811 + XiCon Loss:3.2088 x Lambda(0.01)), Vali MSE Loss: 1.0941 Test MSE Loss: 1.1380
Validation loss decreased (1.102670 --> 1.094085).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5904227
	speed: 0.0269s/iter; left time: 598.3746s
	iters: 200, epoch: 5 | loss: 0.5904006
	speed: 0.0235s/iter; left time: 521.4218s
Epoch: 5 cost time: 5.836553573608398
Epoch: 5, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5776 + XiCon Loss:3.2084 x Lambda(0.01)), Vali MSE Loss: 1.0906 Test MSE Loss: 1.1375
Validation loss decreased (1.094085 --> 1.090634).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5920669
	speed: 0.0265s/iter; left time: 583.9876s
	iters: 200, epoch: 6 | loss: 0.6308038
	speed: 0.0235s/iter; left time: 514.7462s
Epoch: 6 cost time: 5.809316635131836
Epoch: 6, Steps: 233 Train Loss: 0.6081 (Forecasting Loss:0.5760 + XiCon Loss:3.2112 x Lambda(0.01)), Vali MSE Loss: 1.0886 Test MSE Loss: 1.1374
Validation loss decreased (1.090634 --> 1.088556).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6130292
	speed: 0.0264s/iter; left time: 575.1984s
	iters: 200, epoch: 7 | loss: 0.6318505
	speed: 0.0235s/iter; left time: 509.0154s
Epoch: 7 cost time: 5.819973945617676
Epoch: 7, Steps: 233 Train Loss: 0.6072 (Forecasting Loss:0.5751 + XiCon Loss:3.2077 x Lambda(0.01)), Vali MSE Loss: 1.0875 Test MSE Loss: 1.1373
Validation loss decreased (1.088556 --> 1.087528).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6351479
	speed: 0.0269s/iter; left time: 580.9475s
	iters: 200, epoch: 8 | loss: 0.5913631
	speed: 0.0236s/iter; left time: 505.8529s
Epoch: 8 cost time: 5.862925291061401
Epoch: 8, Steps: 233 Train Loss: 0.6068 (Forecasting Loss:0.5747 + XiCon Loss:3.2072 x Lambda(0.01)), Vali MSE Loss: 1.0872 Test MSE Loss: 1.1373
Validation loss decreased (1.087528 --> 1.087195).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6256294
	speed: 0.0271s/iter; left time: 578.8371s
	iters: 200, epoch: 9 | loss: 0.6635538
	speed: 0.0235s/iter; left time: 499.9686s
Epoch: 9 cost time: 5.873396635055542
Epoch: 9, Steps: 233 Train Loss: 0.6065 (Forecasting Loss:0.5745 + XiCon Loss:3.2060 x Lambda(0.01)), Vali MSE Loss: 1.0867 Test MSE Loss: 1.1373
Validation loss decreased (1.087195 --> 1.086715).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6216293
	speed: 0.0264s/iter; left time: 557.2219s
	iters: 200, epoch: 10 | loss: 0.5842786
	speed: 0.0234s/iter; left time: 492.3683s
Epoch: 10 cost time: 5.797405958175659
Epoch: 10, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5743 + XiCon Loss:3.2096 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
Validation loss decreased (1.086715 --> 1.086572).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6022733
	speed: 0.0267s/iter; left time: 557.6832s
	iters: 200, epoch: 11 | loss: 0.6090184
	speed: 0.0233s/iter; left time: 484.6057s
Epoch: 11 cost time: 5.793211221694946
Epoch: 11, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5743 + XiCon Loss:3.2093 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
Validation loss decreased (1.086572 --> 1.086480).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6358037
	speed: 0.0262s/iter; left time: 540.1232s
	iters: 200, epoch: 12 | loss: 0.5623817
	speed: 0.0231s/iter; left time: 475.0759s
Epoch: 12 cost time: 5.732660293579102
Epoch: 12, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2111 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6299486
	speed: 0.0263s/iter; left time: 537.3312s
	iters: 200, epoch: 13 | loss: 0.5902861
	speed: 0.0237s/iter; left time: 480.8807s
Epoch: 13 cost time: 5.799787759780884
Epoch: 13, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5743 + XiCon Loss:3.2065 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5968265
	speed: 0.0269s/iter; left time: 542.1044s
	iters: 200, epoch: 14 | loss: 0.6579192
	speed: 0.0236s/iter; left time: 473.7561s
Epoch: 14 cost time: 5.85481595993042
Epoch: 14, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2078 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6327649
	speed: 0.0266s/iter; left time: 530.9443s
	iters: 200, epoch: 15 | loss: 0.6152286
	speed: 0.0233s/iter; left time: 461.8979s
Epoch: 15 cost time: 5.8084635734558105
Epoch: 15, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2084 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6191339
	speed: 0.0268s/iter; left time: 528.8143s
	iters: 200, epoch: 16 | loss: 0.6210974
	speed: 0.0233s/iter; left time: 457.3730s
Epoch: 16 cost time: 5.817733287811279
Epoch: 16, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5741 + XiCon Loss:3.2092 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1372
Validation loss decreased (1.086480 --> 1.086214).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5204801
	speed: 0.0262s/iter; left time: 511.0634s
	iters: 200, epoch: 17 | loss: 0.6905332
	speed: 0.0236s/iter; left time: 457.7657s
Epoch: 17 cost time: 5.806316137313843
Epoch: 17, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2105 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6137111
	speed: 0.0265s/iter; left time: 510.3834s
	iters: 200, epoch: 18 | loss: 0.5945508
	speed: 0.0237s/iter; left time: 453.0675s
Epoch: 18 cost time: 5.8216423988342285
Epoch: 18, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2093 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6194117
	speed: 0.0267s/iter; left time: 507.4929s
	iters: 200, epoch: 19 | loss: 0.6699070
	speed: 0.0234s/iter; left time: 442.4683s
Epoch: 19 cost time: 5.844479084014893
Epoch: 19, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2096 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1372
Validation loss decreased (1.086214 --> 1.086204).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6636791
	speed: 0.0270s/iter; left time: 507.4395s
	iters: 200, epoch: 20 | loss: 0.6257616
	speed: 0.0237s/iter; left time: 443.2398s
Epoch: 20 cost time: 5.879777908325195
Epoch: 20, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2101 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5851959
	speed: 0.0267s/iter; left time: 494.5306s
	iters: 200, epoch: 21 | loss: 0.5951633
	speed: 0.0234s/iter; left time: 432.3028s
Epoch: 21 cost time: 5.817425966262817
Epoch: 21, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5742 + XiCon Loss:3.2036 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6182896
	speed: 0.0265s/iter; left time: 485.3342s
	iters: 200, epoch: 22 | loss: 0.5598032
	speed: 0.0234s/iter; left time: 426.8408s
Epoch: 22 cost time: 5.800955057144165
Epoch: 22, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2083 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5709969
	speed: 0.0261s/iter; left time: 472.3900s
	iters: 200, epoch: 23 | loss: 0.6138752
	speed: 0.0230s/iter; left time: 413.2612s
Epoch: 23 cost time: 5.731607437133789
Epoch: 23, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5741 + XiCon Loss:3.2066 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5990824
	speed: 0.0271s/iter; left time: 483.5444s
	iters: 200, epoch: 24 | loss: 0.6290559
	speed: 0.0235s/iter; left time: 416.6582s
Epoch: 24 cost time: 5.860053777694702
Epoch: 24, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2031 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5710710
	speed: 0.0261s/iter; left time: 459.2279s
	iters: 200, epoch: 25 | loss: 0.6084507
	speed: 0.0234s/iter; left time: 409.0486s
Epoch: 25 cost time: 5.794151306152344
Epoch: 25, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2087 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6506575
	speed: 0.0268s/iter; left time: 465.5482s
	iters: 200, epoch: 26 | loss: 0.6189643
	speed: 0.0235s/iter; left time: 406.3590s
Epoch: 26 cost time: 5.8694305419921875
Epoch: 26, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5741 + XiCon Loss:3.2100 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6365237
	speed: 0.0264s/iter; left time: 453.1812s
	iters: 200, epoch: 27 | loss: 0.5726023
	speed: 0.0236s/iter; left time: 402.4812s
Epoch: 27 cost time: 5.8305439949035645
Epoch: 27, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5742 + XiCon Loss:3.2068 x Lambda(0.01)), Vali MSE Loss: 1.0867 Test MSE Loss: 1.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6282138
	speed: 0.0265s/iter; left time: 447.4715s
	iters: 200, epoch: 28 | loss: 0.6131915
	speed: 0.0233s/iter; left time: 391.5652s
Epoch: 28 cost time: 5.7743847370147705
Epoch: 28, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2073 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5882434
	speed: 0.0271s/iter; left time: 451.7659s
	iters: 200, epoch: 29 | loss: 0.6259196
	speed: 0.0234s/iter; left time: 388.1181s
Epoch: 29 cost time: 5.846081972122192
Epoch: 29, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5741 + XiCon Loss:3.2082 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1372
Validation loss decreased (1.086204 --> 1.086150).  Saving model ...
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5786769
	speed: 0.0267s/iter; left time: 439.5009s
	iters: 200, epoch: 30 | loss: 0.5580902
	speed: 0.0236s/iter; left time: 385.8822s
Epoch: 30 cost time: 5.851571559906006
Epoch: 30, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2095 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5857408
	speed: 0.0262s/iter; left time: 424.3118s
	iters: 200, epoch: 31 | loss: 0.6085705
	speed: 0.0235s/iter; left time: 378.5916s
Epoch: 31 cost time: 5.770756006240845
Epoch: 31, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2053 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5913458
	speed: 0.0265s/iter; left time: 423.0918s
	iters: 200, epoch: 32 | loss: 0.5838388
	speed: 0.0233s/iter; left time: 369.7608s
Epoch: 32 cost time: 5.80086874961853
Epoch: 32, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2051 x Lambda(0.01)), Vali MSE Loss: 1.0869 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5621842
	speed: 0.0271s/iter; left time: 426.5928s
	iters: 200, epoch: 33 | loss: 0.6618666
	speed: 0.0235s/iter; left time: 367.5437s
Epoch: 33 cost time: 5.863018035888672
Epoch: 33, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5741 + XiCon Loss:3.2103 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5848590
	speed: 0.0264s/iter; left time: 409.4468s
	iters: 200, epoch: 34 | loss: 0.5745171
	speed: 0.0234s/iter; left time: 361.0636s
Epoch: 34 cost time: 5.777731895446777
Epoch: 34, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5741 + XiCon Loss:3.2060 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5749789
	speed: 0.0265s/iter; left time: 404.7469s
	iters: 200, epoch: 35 | loss: 0.6296022
	speed: 0.0235s/iter; left time: 356.7625s
Epoch: 35 cost time: 5.814903497695923
Epoch: 35, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5741 + XiCon Loss:3.2041 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6308680
	speed: 0.0266s/iter; left time: 400.8509s
	iters: 200, epoch: 36 | loss: 0.5751058
	speed: 0.0234s/iter; left time: 349.2666s
Epoch: 36 cost time: 5.801630258560181
Epoch: 36, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2054 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5795030
	speed: 0.0263s/iter; left time: 390.3056s
	iters: 200, epoch: 37 | loss: 0.6229464
	speed: 0.0233s/iter; left time: 342.6187s
Epoch: 37 cost time: 5.752523422241211
Epoch: 37, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5743 + XiCon Loss:3.2102 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5972449
	speed: 0.0267s/iter; left time: 388.6299s
	iters: 200, epoch: 38 | loss: 0.5864040
	speed: 0.0235s/iter; left time: 340.1729s
Epoch: 38 cost time: 5.827059030532837
Epoch: 38, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2099 x Lambda(0.01)), Vali MSE Loss: 1.0867 Test MSE Loss: 1.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.6106282
	speed: 0.0265s/iter; left time: 380.2820s
	iters: 200, epoch: 39 | loss: 0.5844982
	speed: 0.0236s/iter; left time: 336.8334s
Epoch: 39 cost time: 5.808788299560547
Epoch: 39, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5742 + XiCon Loss:3.2066 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3956904411315918, mae:0.8787773251533508, mape:6.154308319091797, mspe:4556.47021484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.4714
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0449101
	speed: 0.0275s/iter; left time: 637.8662s
	iters: 200, epoch: 1 | loss: 0.9899211
	speed: 0.0238s/iter; left time: 550.6572s
Epoch: 1 cost time: 5.936985492706299
Epoch: 1, Steps: 233 Train Loss: 1.0598 (Forecasting Loss:1.0279 + XiCon Loss:3.1834 x Lambda(0.01)), Vali MSE Loss: 1.8929 Test MSE Loss: 1.2473
Validation loss decreased (inf --> 1.892949).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6924697
	speed: 0.0269s/iter; left time: 618.6243s
	iters: 200, epoch: 2 | loss: 0.6122801
	speed: 0.0241s/iter; left time: 551.7673s
Epoch: 2 cost time: 5.913691520690918
Epoch: 2, Steps: 233 Train Loss: 0.6888 (Forecasting Loss:0.6569 + XiCon Loss:3.1897 x Lambda(0.01)), Vali MSE Loss: 1.1382 Test MSE Loss: 1.1436
Validation loss decreased (1.892949 --> 1.138163).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6541008
	speed: 0.0268s/iter; left time: 609.3052s
	iters: 200, epoch: 3 | loss: 0.5879317
	speed: 0.0237s/iter; left time: 537.3405s
Epoch: 3 cost time: 5.855524063110352
Epoch: 3, Steps: 233 Train Loss: 0.6239 (Forecasting Loss:0.5921 + XiCon Loss:3.1872 x Lambda(0.01)), Vali MSE Loss: 1.1169 Test MSE Loss: 1.1349
Validation loss decreased (1.138163 --> 1.116908).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6591353
	speed: 0.0272s/iter; left time: 611.9005s
	iters: 200, epoch: 4 | loss: 0.6097737
	speed: 0.0237s/iter; left time: 531.6459s
Epoch: 4 cost time: 5.886549234390259
Epoch: 4, Steps: 233 Train Loss: 0.6159 (Forecasting Loss:0.5840 + XiCon Loss:3.1900 x Lambda(0.01)), Vali MSE Loss: 1.1090 Test MSE Loss: 1.1334
Validation loss decreased (1.116908 --> 1.108997).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6271383
	speed: 0.0268s/iter; left time: 597.2950s
	iters: 200, epoch: 5 | loss: 0.6103888
	speed: 0.0235s/iter; left time: 520.2960s
Epoch: 5 cost time: 5.8257155418396
Epoch: 5, Steps: 233 Train Loss: 0.6127 (Forecasting Loss:0.5808 + XiCon Loss:3.1855 x Lambda(0.01)), Vali MSE Loss: 1.1057 Test MSE Loss: 1.1327
Validation loss decreased (1.108997 --> 1.105682).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6075524
	speed: 0.0268s/iter; left time: 591.3178s
	iters: 200, epoch: 6 | loss: 0.6639141
	speed: 0.0232s/iter; left time: 509.9941s
Epoch: 6 cost time: 5.810686826705933
Epoch: 6, Steps: 233 Train Loss: 0.6113 (Forecasting Loss:0.5794 + XiCon Loss:3.1894 x Lambda(0.01)), Vali MSE Loss: 1.1043 Test MSE Loss: 1.1324
Validation loss decreased (1.105682 --> 1.104326).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6195660
	speed: 0.0269s/iter; left time: 586.1758s
	iters: 200, epoch: 7 | loss: 0.6128620
	speed: 0.0238s/iter; left time: 515.7964s
Epoch: 7 cost time: 5.869371652603149
Epoch: 7, Steps: 233 Train Loss: 0.6105 (Forecasting Loss:0.5786 + XiCon Loss:3.1888 x Lambda(0.01)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1323
Validation loss decreased (1.104326 --> 1.103119).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5822086
	speed: 0.0270s/iter; left time: 581.6510s
	iters: 200, epoch: 8 | loss: 0.6474798
	speed: 0.0235s/iter; left time: 504.0862s
Epoch: 8 cost time: 5.837756872177124
Epoch: 8, Steps: 233 Train Loss: 0.6100 (Forecasting Loss:0.5782 + XiCon Loss:3.1850 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1323
Validation loss decreased (1.103119 --> 1.102568).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5976899
	speed: 0.0269s/iter; left time: 574.1899s
	iters: 200, epoch: 9 | loss: 0.6310897
	speed: 0.0234s/iter; left time: 497.2535s
Epoch: 9 cost time: 5.826108694076538
Epoch: 9, Steps: 233 Train Loss: 0.6100 (Forecasting Loss:0.5781 + XiCon Loss:3.1886 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5841483
	speed: 0.0269s/iter; left time: 567.2181s
	iters: 200, epoch: 10 | loss: 0.6087176
	speed: 0.0237s/iter; left time: 496.9918s
Epoch: 10 cost time: 5.858157396316528
Epoch: 10, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5779 + XiCon Loss:3.1867 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5714294
	speed: 0.0264s/iter; left time: 550.4095s
	iters: 200, epoch: 11 | loss: 0.5816196
	speed: 0.0233s/iter; left time: 483.1650s
Epoch: 11 cost time: 5.764347791671753
Epoch: 11, Steps: 233 Train Loss: 0.6098 (Forecasting Loss:0.5779 + XiCon Loss:3.1895 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102568 --> 1.102231).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5834697
	speed: 0.0265s/iter; left time: 547.0527s
	iters: 200, epoch: 12 | loss: 0.6463256
	speed: 0.0235s/iter; left time: 482.2395s
Epoch: 12 cost time: 5.819946765899658
Epoch: 12, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1878 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6248082
	speed: 0.0262s/iter; left time: 534.9430s
	iters: 200, epoch: 13 | loss: 0.6008692
	speed: 0.0233s/iter; left time: 472.5863s
Epoch: 13 cost time: 5.7461090087890625
Epoch: 13, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1929 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5719651
	speed: 0.0267s/iter; left time: 538.3643s
	iters: 200, epoch: 14 | loss: 0.5958841
	speed: 0.0238s/iter; left time: 477.4398s
Epoch: 14 cost time: 5.885955333709717
Epoch: 14, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1883 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5978785
	speed: 0.0268s/iter; left time: 533.5360s
	iters: 200, epoch: 15 | loss: 0.6292029
	speed: 0.0235s/iter; left time: 466.3485s
Epoch: 15 cost time: 5.83628249168396
Epoch: 15, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1921 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102231 --> 1.102184).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6421321
	speed: 0.0267s/iter; left time: 525.3099s
	iters: 200, epoch: 16 | loss: 0.5936836
	speed: 0.0233s/iter; left time: 457.0369s
Epoch: 16 cost time: 5.820028781890869
Epoch: 16, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1907 x Lambda(0.01)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1322
Validation loss decreased (1.102184 --> 1.102017).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6113666
	speed: 0.0267s/iter; left time: 519.8125s
	iters: 200, epoch: 17 | loss: 0.6342498
	speed: 0.0233s/iter; left time: 452.3560s
Epoch: 17 cost time: 5.831310510635376
Epoch: 17, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5778 + XiCon Loss:3.1841 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6331832
	speed: 0.0270s/iter; left time: 519.4261s
	iters: 200, epoch: 18 | loss: 0.6181855
	speed: 0.0232s/iter; left time: 444.1622s
Epoch: 18 cost time: 5.835388898849487
Epoch: 18, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1908 x Lambda(0.01)), Vali MSE Loss: 1.1019 Test MSE Loss: 1.1322
Validation loss decreased (1.102017 --> 1.101884).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5894992
	speed: 0.0265s/iter; left time: 503.8584s
	iters: 200, epoch: 19 | loss: 0.6634933
	speed: 0.0235s/iter; left time: 445.1928s
Epoch: 19 cost time: 5.826555013656616
Epoch: 19, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5777 + XiCon Loss:3.1876 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6117603
	speed: 0.0273s/iter; left time: 511.6892s
	iters: 200, epoch: 20 | loss: 0.5842766
	speed: 0.0239s/iter; left time: 445.6273s
Epoch: 20 cost time: 5.93894624710083
Epoch: 20, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5777 + XiCon Loss:3.1877 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6293284
	speed: 0.0264s/iter; left time: 489.6646s
	iters: 200, epoch: 21 | loss: 0.6213692
	speed: 0.0235s/iter; left time: 433.7753s
Epoch: 21 cost time: 5.7906084060668945
Epoch: 21, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5777 + XiCon Loss:3.1890 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6295607
	speed: 0.0272s/iter; left time: 498.4447s
	iters: 200, epoch: 22 | loss: 0.5848942
	speed: 0.0235s/iter; left time: 427.8229s
Epoch: 22 cost time: 5.876396417617798
Epoch: 22, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1890 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6300083
	speed: 0.0268s/iter; left time: 484.7798s
	iters: 200, epoch: 23 | loss: 0.6084321
	speed: 0.0234s/iter; left time: 419.8746s
Epoch: 23 cost time: 5.816572904586792
Epoch: 23, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5778 + XiCon Loss:3.1872 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6361426
	speed: 0.0273s/iter; left time: 486.6797s
	iters: 200, epoch: 24 | loss: 0.5613295
	speed: 0.0235s/iter; left time: 416.8317s
Epoch: 24 cost time: 5.919895887374878
Epoch: 24, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5778 + XiCon Loss:3.1826 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6536418
	speed: 0.0277s/iter; left time: 487.7922s
	iters: 200, epoch: 25 | loss: 0.5990009
	speed: 0.0238s/iter; left time: 415.9447s
Epoch: 25 cost time: 5.9719085693359375
Epoch: 25, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1914 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6130033
	speed: 0.0272s/iter; left time: 473.4835s
	iters: 200, epoch: 26 | loss: 0.6327077
	speed: 0.0235s/iter; left time: 406.5279s
Epoch: 26 cost time: 5.87520170211792
Epoch: 26, Steps: 233 Train Loss: 0.6097 (Forecasting Loss:0.5778 + XiCon Loss:3.1908 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6488892
	speed: 0.0269s/iter; left time: 460.8461s
	iters: 200, epoch: 27 | loss: 0.5748462
	speed: 0.0242s/iter; left time: 411.6888s
Epoch: 27 cost time: 5.905863523483276
Epoch: 27, Steps: 233 Train Loss: 0.6098 (Forecasting Loss:0.5780 + XiCon Loss:3.1867 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5450583
	speed: 0.0268s/iter; left time: 452.8100s
	iters: 200, epoch: 28 | loss: 0.5752649
	speed: 0.0234s/iter; left time: 393.6095s
Epoch: 28 cost time: 5.839517593383789
Epoch: 28, Steps: 233 Train Loss: 0.6095 (Forecasting Loss:0.5776 + XiCon Loss:3.1883 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.389225721359253, mae:0.8751733899116516, mape:6.027319431304932, mspe:4359.78759765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3938+-0.00490, MAE:0.8781+-0.00229, MAPE:6.1175+-0.06932, MSPE:4494.6221+-104.64586, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.4160
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 33.7533379
	speed: 0.0504s/iter; left time: 1138.8865s
	iters: 200, epoch: 1 | loss: 32.5701332
	speed: 0.0454s/iter; left time: 1021.4752s
Epoch: 1 cost time: 10.841383218765259
Epoch: 1, Steps: 227 Train Loss: 32.9138 (Forecasting Loss:1.0262 + XiCon Loss:3.1888 x Lambda(10.0)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936042).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.3233757
	speed: 0.0472s/iter; left time: 1055.1795s
	iters: 200, epoch: 2 | loss: 32.2719002
	speed: 0.0469s/iter; left time: 1044.1902s
Epoch: 2 cost time: 10.696141719818115
Epoch: 2, Steps: 227 Train Loss: 32.4474 (Forecasting Loss:0.6690 + XiCon Loss:3.1778 x Lambda(10.0)), Vali MSE Loss: 1.2116 Test MSE Loss: 1.2843
Validation loss decreased (1.936042 --> 1.211644).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 31.7869873
	speed: 0.0484s/iter; left time: 1073.0191s
	iters: 200, epoch: 3 | loss: 32.4758301
	speed: 0.0466s/iter; left time: 1026.5840s
Epoch: 3 cost time: 10.804093599319458
Epoch: 3, Steps: 227 Train Loss: 32.1634 (Forecasting Loss:0.6064 + XiCon Loss:3.1557 x Lambda(10.0)), Vali MSE Loss: 1.1893 Test MSE Loss: 1.2758
Validation loss decreased (1.211644 --> 1.189330).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 31.4745579
	speed: 0.0488s/iter; left time: 1070.2913s
	iters: 200, epoch: 4 | loss: 31.6395321
	speed: 0.0465s/iter; left time: 1015.1336s
Epoch: 4 cost time: 10.805790662765503
Epoch: 4, Steps: 227 Train Loss: 31.9545 (Forecasting Loss:0.5989 + XiCon Loss:3.1356 x Lambda(10.0)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2739
Validation loss decreased (1.189330 --> 1.183872).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.3870678
	speed: 0.0492s/iter; left time: 1067.6576s
	iters: 200, epoch: 5 | loss: 32.1730957
	speed: 0.0466s/iter; left time: 1005.2523s
Epoch: 5 cost time: 10.962570667266846
Epoch: 5, Steps: 227 Train Loss: 31.8328 (Forecasting Loss:0.5960 + XiCon Loss:3.1237 x Lambda(10.0)), Vali MSE Loss: 1.1813 Test MSE Loss: 1.2728
Validation loss decreased (1.183872 --> 1.181337).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 31.7207355
	speed: 0.0497s/iter; left time: 1066.1299s
	iters: 200, epoch: 6 | loss: 31.5980377
	speed: 0.0467s/iter; left time: 998.3299s
Epoch: 6 cost time: 10.96086072921753
Epoch: 6, Steps: 227 Train Loss: 31.7155 (Forecasting Loss:0.5947 + XiCon Loss:3.1121 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2725
Validation loss decreased (1.181337 --> 1.179690).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 32.3987198
	speed: 0.0495s/iter; left time: 1052.0458s
	iters: 200, epoch: 7 | loss: 31.6519642
	speed: 0.0466s/iter; left time: 985.2917s
Epoch: 7 cost time: 10.94444227218628
Epoch: 7, Steps: 227 Train Loss: 31.6958 (Forecasting Loss:0.5940 + XiCon Loss:3.1102 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2722
Validation loss decreased (1.179690 --> 1.179137).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.1306572
	speed: 0.0488s/iter; left time: 1025.9869s
	iters: 200, epoch: 8 | loss: 32.0615387
	speed: 0.0483s/iter; left time: 1009.6798s
Epoch: 8 cost time: 11.052273035049438
Epoch: 8, Steps: 227 Train Loss: 31.6999 (Forecasting Loss:0.5936 + XiCon Loss:3.1106 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2721
Validation loss decreased (1.179137 --> 1.178326).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.5815392
	speed: 0.0496s/iter; left time: 1031.4896s
	iters: 200, epoch: 9 | loss: 31.4117203
	speed: 0.0482s/iter; left time: 996.9062s
Epoch: 9 cost time: 11.12534761428833
Epoch: 9, Steps: 227 Train Loss: 31.6916 (Forecasting Loss:0.5934 + XiCon Loss:3.1098 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2721
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 31.9692402
	speed: 0.0502s/iter; left time: 1032.3585s
	iters: 200, epoch: 10 | loss: 32.1212082
	speed: 0.0471s/iter; left time: 964.1697s
Epoch: 10 cost time: 11.098257303237915
Epoch: 10, Steps: 227 Train Loss: 31.6674 (Forecasting Loss:0.5934 + XiCon Loss:3.1074 x Lambda(10.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2721
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 32.0921249
	speed: 0.0487s/iter; left time: 989.4483s
	iters: 200, epoch: 11 | loss: 31.8786087
	speed: 0.0482s/iter; left time: 974.8834s
Epoch: 11 cost time: 11.052343130111694
Epoch: 11, Steps: 227 Train Loss: 31.7028 (Forecasting Loss:0.5931 + XiCon Loss:3.1110 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.4849834
	speed: 0.0488s/iter; left time: 981.7501s
	iters: 200, epoch: 12 | loss: 31.5870037
	speed: 0.0474s/iter; left time: 947.2086s
Epoch: 12 cost time: 10.907591581344604
Epoch: 12, Steps: 227 Train Loss: 31.6732 (Forecasting Loss:0.5932 + XiCon Loss:3.1080 x Lambda(10.0)), Vali MSE Loss: 1.1781 Test MSE Loss: 1.2720
Validation loss decreased (1.178326 --> 1.178108).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.6283684
	speed: 0.0484s/iter; left time: 962.2061s
	iters: 200, epoch: 13 | loss: 31.8356133
	speed: 0.0484s/iter; left time: 957.8368s
Epoch: 13 cost time: 11.024895668029785
Epoch: 13, Steps: 227 Train Loss: 31.6701 (Forecasting Loss:0.5934 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 31.6708126
	speed: 0.0489s/iter; left time: 960.1595s
	iters: 200, epoch: 14 | loss: 31.6546097
	speed: 0.0479s/iter; left time: 936.1757s
Epoch: 14 cost time: 11.014899015426636
Epoch: 14, Steps: 227 Train Loss: 31.6587 (Forecasting Loss:0.5934 + XiCon Loss:3.1065 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 32.0261650
	speed: 0.0504s/iter; left time: 979.1094s
	iters: 200, epoch: 15 | loss: 31.8721771
	speed: 0.0475s/iter; left time: 917.7561s
Epoch: 15 cost time: 11.112403154373169
Epoch: 15, Steps: 227 Train Loss: 31.6440 (Forecasting Loss:0.5934 + XiCon Loss:3.1051 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 31.2800980
	speed: 0.0497s/iter; left time: 954.7826s
	iters: 200, epoch: 16 | loss: 32.3271713
	speed: 0.0469s/iter; left time: 895.2075s
Epoch: 16 cost time: 11.040213584899902
Epoch: 16, Steps: 227 Train Loss: 31.6853 (Forecasting Loss:0.5931 + XiCon Loss:3.1092 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 32.6757240
	speed: 0.0503s/iter; left time: 953.9378s
	iters: 200, epoch: 17 | loss: 31.9528427
	speed: 0.0481s/iter; left time: 906.8281s
Epoch: 17 cost time: 11.154375076293945
Epoch: 17, Steps: 227 Train Loss: 31.6274 (Forecasting Loss:0.5932 + XiCon Loss:3.1034 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 31.5378361
	speed: 0.0495s/iter; left time: 927.8088s
	iters: 200, epoch: 18 | loss: 31.8971233
	speed: 0.0478s/iter; left time: 891.1190s
Epoch: 18 cost time: 11.051213026046753
Epoch: 18, Steps: 227 Train Loss: 31.6652 (Forecasting Loss:0.5933 + XiCon Loss:3.1072 x Lambda(10.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2720
Validation loss decreased (1.178108 --> 1.177963).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 31.5197258
	speed: 0.0509s/iter; left time: 943.2465s
	iters: 200, epoch: 19 | loss: 31.8478699
	speed: 0.0484s/iter; left time: 890.7842s
Epoch: 19 cost time: 11.236510753631592
Epoch: 19, Steps: 227 Train Loss: 31.6993 (Forecasting Loss:0.5932 + XiCon Loss:3.1106 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 31.3513279
	speed: 0.0506s/iter; left time: 926.1382s
	iters: 200, epoch: 20 | loss: 31.7137012
	speed: 0.0473s/iter; left time: 859.4512s
Epoch: 20 cost time: 11.149074077606201
Epoch: 20, Steps: 227 Train Loss: 31.6745 (Forecasting Loss:0.5933 + XiCon Loss:3.1081 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.6257172
	speed: 0.0489s/iter; left time: 884.0263s
	iters: 200, epoch: 21 | loss: 31.8374615
	speed: 0.0472s/iter; left time: 847.6172s
Epoch: 21 cost time: 10.917182207107544
Epoch: 21, Steps: 227 Train Loss: 31.6861 (Forecasting Loss:0.5933 + XiCon Loss:3.1093 x Lambda(10.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 31.8323288
	speed: 0.0485s/iter; left time: 865.0069s
	iters: 200, epoch: 22 | loss: 32.5243111
	speed: 0.0474s/iter; left time: 840.0022s
Epoch: 22 cost time: 10.963407754898071
Epoch: 22, Steps: 227 Train Loss: 31.6745 (Forecasting Loss:0.5933 + XiCon Loss:3.1081 x Lambda(10.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.4126511
	speed: 0.0502s/iter; left time: 884.1974s
	iters: 200, epoch: 23 | loss: 31.3271599
	speed: 0.0479s/iter; left time: 838.4448s
Epoch: 23 cost time: 11.110478639602661
Epoch: 23, Steps: 227 Train Loss: 31.7015 (Forecasting Loss:0.5932 + XiCon Loss:3.1108 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 32.0077248
	speed: 0.0491s/iter; left time: 852.5198s
	iters: 200, epoch: 24 | loss: 31.8128700
	speed: 0.0489s/iter; left time: 845.0872s
Epoch: 24 cost time: 11.155520677566528
Epoch: 24, Steps: 227 Train Loss: 31.6706 (Forecasting Loss:0.5934 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 31.3954659
	speed: 0.0483s/iter; left time: 829.1289s
	iters: 200, epoch: 25 | loss: 31.9189453
	speed: 0.0476s/iter; left time: 811.1057s
Epoch: 25 cost time: 10.915566444396973
Epoch: 25, Steps: 227 Train Loss: 31.6752 (Forecasting Loss:0.5933 + XiCon Loss:3.1082 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 31.5614986
	speed: 0.0496s/iter; left time: 838.7525s
	iters: 200, epoch: 26 | loss: 31.5123444
	speed: 0.0478s/iter; left time: 803.9700s
Epoch: 26 cost time: 11.186718940734863
Epoch: 26, Steps: 227 Train Loss: 31.6701 (Forecasting Loss:0.5932 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 32.2275276
	speed: 0.0498s/iter; left time: 832.2788s
	iters: 200, epoch: 27 | loss: 31.5993519
	speed: 0.0472s/iter; left time: 783.1477s
Epoch: 27 cost time: 11.049667596817017
Epoch: 27, Steps: 227 Train Loss: 31.6706 (Forecasting Loss:0.5932 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2720
Validation loss decreased (1.177963 --> 1.177421).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 31.5015144
	speed: 0.0492s/iter; left time: 810.1430s
	iters: 200, epoch: 28 | loss: 31.7865925
	speed: 0.0472s/iter; left time: 772.3249s
Epoch: 28 cost time: 10.930117845535278
Epoch: 28, Steps: 227 Train Loss: 31.6876 (Forecasting Loss:0.5933 + XiCon Loss:3.1094 x Lambda(10.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 31.9379215
	speed: 0.0504s/iter; left time: 818.2057s
	iters: 200, epoch: 29 | loss: 31.8032341
	speed: 0.0467s/iter; left time: 753.9067s
Epoch: 29 cost time: 11.003756046295166
Epoch: 29, Steps: 227 Train Loss: 31.6611 (Forecasting Loss:0.5934 + XiCon Loss:3.1068 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 31.6391335
	speed: 0.0493s/iter; left time: 788.8961s
	iters: 200, epoch: 30 | loss: 31.8395596
	speed: 0.0478s/iter; left time: 760.8015s
Epoch: 30 cost time: 11.022823333740234
Epoch: 30, Steps: 227 Train Loss: 31.6598 (Forecasting Loss:0.5932 + XiCon Loss:3.1067 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 31.6403141
	speed: 0.0485s/iter; left time: 766.1048s
	iters: 200, epoch: 31 | loss: 31.9220104
	speed: 0.0448s/iter; left time: 702.8456s
Epoch: 31 cost time: 10.647702932357788
Epoch: 31, Steps: 227 Train Loss: 31.6645 (Forecasting Loss:0.5934 + XiCon Loss:3.1071 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 31.4614258
	speed: 0.0488s/iter; left time: 759.7780s
	iters: 200, epoch: 32 | loss: 31.9584312
	speed: 0.0476s/iter; left time: 736.0522s
Epoch: 32 cost time: 10.981771469116211
Epoch: 32, Steps: 227 Train Loss: 31.6639 (Forecasting Loss:0.5933 + XiCon Loss:3.1071 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 31.4730358
	speed: 0.0492s/iter; left time: 754.3194s
	iters: 200, epoch: 33 | loss: 31.5653362
	speed: 0.0486s/iter; left time: 740.3573s
Epoch: 33 cost time: 11.113806962966919
Epoch: 33, Steps: 227 Train Loss: 31.6710 (Forecasting Loss:0.5933 + XiCon Loss:3.1078 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 32.0487213
	speed: 0.0498s/iter; left time: 752.5380s
	iters: 200, epoch: 34 | loss: 31.4936352
	speed: 0.0484s/iter; left time: 726.0067s
Epoch: 34 cost time: 11.166242361068726
Epoch: 34, Steps: 227 Train Loss: 31.6842 (Forecasting Loss:0.5932 + XiCon Loss:3.1091 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 31.8764381
	speed: 0.0494s/iter; left time: 735.7113s
	iters: 200, epoch: 35 | loss: 31.1257744
	speed: 0.0476s/iter; left time: 703.3040s
Epoch: 35 cost time: 11.003239393234253
Epoch: 35, Steps: 227 Train Loss: 31.6704 (Forecasting Loss:0.5933 + XiCon Loss:3.1077 x Lambda(10.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 31.7274837
	speed: 0.0495s/iter; left time: 725.5575s
	iters: 200, epoch: 36 | loss: 31.9594669
	speed: 0.0467s/iter; left time: 679.5990s
Epoch: 36 cost time: 10.980888843536377
Epoch: 36, Steps: 227 Train Loss: 31.6949 (Forecasting Loss:0.5934 + XiCon Loss:3.1101 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 31.6440239
	speed: 0.0488s/iter; left time: 704.1717s
	iters: 200, epoch: 37 | loss: 31.5705929
	speed: 0.0477s/iter; left time: 684.0416s
Epoch: 37 cost time: 10.974210739135742
Epoch: 37, Steps: 227 Train Loss: 31.7090 (Forecasting Loss:0.5932 + XiCon Loss:3.1116 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.589458703994751, mae:0.954611599445343, mape:6.259336948394775, mspe:4844.8955078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.3909
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 33.1327553
	speed: 0.0453s/iter; left time: 1022.8495s
	iters: 200, epoch: 1 | loss: 33.0671654
	speed: 0.0421s/iter; left time: 948.0150s
Epoch: 1 cost time: 9.881531476974487
Epoch: 1, Steps: 227 Train Loss: 33.0867 (Forecasting Loss:1.0243 + XiCon Loss:3.2062 x Lambda(10.0)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932089).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.1458549
	speed: 0.0460s/iter; left time: 1028.5687s
	iters: 200, epoch: 2 | loss: 32.3665504
	speed: 0.0413s/iter; left time: 918.9510s
Epoch: 2 cost time: 9.930376529693604
Epoch: 2, Steps: 227 Train Loss: 32.6568 (Forecasting Loss:0.6694 + XiCon Loss:3.1987 x Lambda(10.0)), Vali MSE Loss: 1.2131 Test MSE Loss: 1.2808
Validation loss decreased (1.932089 --> 1.213135).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.6194458
	speed: 0.0453s/iter; left time: 1002.3146s
	iters: 200, epoch: 3 | loss: 32.5635719
	speed: 0.0422s/iter; left time: 930.4841s
Epoch: 3 cost time: 9.925230026245117
Epoch: 3, Steps: 227 Train Loss: 32.4852 (Forecasting Loss:0.6076 + XiCon Loss:3.1878 x Lambda(10.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2732
Validation loss decreased (1.213135 --> 1.194243).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 32.1296120
	speed: 0.0449s/iter; left time: 984.5370s
	iters: 200, epoch: 4 | loss: 32.2171249
	speed: 0.0430s/iter; left time: 937.7364s
Epoch: 4 cost time: 9.98788046836853
Epoch: 4, Steps: 227 Train Loss: 32.3899 (Forecasting Loss:0.6004 + XiCon Loss:3.1790 x Lambda(10.0)), Vali MSE Loss: 1.1884 Test MSE Loss: 1.2713
Validation loss decreased (1.194243 --> 1.188423).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 33.0014267
	speed: 0.0468s/iter; left time: 1014.9319s
	iters: 200, epoch: 5 | loss: 32.5521088
	speed: 0.0430s/iter; left time: 929.1021s
Epoch: 5 cost time: 10.174906492233276
Epoch: 5, Steps: 227 Train Loss: 32.3662 (Forecasting Loss:0.5976 + XiCon Loss:3.1769 x Lambda(10.0)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2705
Validation loss decreased (1.188423 --> 1.185807).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 32.9156570
	speed: 0.0452s/iter; left time: 970.6103s
	iters: 200, epoch: 6 | loss: 32.4451561
	speed: 0.0426s/iter; left time: 909.3979s
Epoch: 6 cost time: 9.983541250228882
Epoch: 6, Steps: 227 Train Loss: 32.3340 (Forecasting Loss:0.5962 + XiCon Loss:3.1738 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2702
Validation loss decreased (1.185807 --> 1.184084).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 32.0961876
	speed: 0.0465s/iter; left time: 988.0148s
	iters: 200, epoch: 7 | loss: 32.4630394
	speed: 0.0415s/iter; left time: 876.6738s
Epoch: 7 cost time: 10.025155782699585
Epoch: 7, Steps: 227 Train Loss: 32.3550 (Forecasting Loss:0.5954 + XiCon Loss:3.1760 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2700
Validation loss decreased (1.184084 --> 1.183802).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.2731819
	speed: 0.0457s/iter; left time: 959.5776s
	iters: 200, epoch: 8 | loss: 32.7704468
	speed: 0.0431s/iter; left time: 901.3839s
Epoch: 8 cost time: 10.078486442565918
Epoch: 8, Steps: 227 Train Loss: 32.3481 (Forecasting Loss:0.5952 + XiCon Loss:3.1753 x Lambda(10.0)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2699
Validation loss decreased (1.183802 --> 1.183377).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 32.0806427
	speed: 0.0459s/iter; left time: 954.2936s
	iters: 200, epoch: 9 | loss: 32.0102959
	speed: 0.0430s/iter; left time: 888.6619s
Epoch: 9 cost time: 10.052981853485107
Epoch: 9, Steps: 227 Train Loss: 32.3153 (Forecasting Loss:0.5950 + XiCon Loss:3.1720 x Lambda(10.0)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2699
Validation loss decreased (1.183377 --> 1.182136).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 32.0877724
	speed: 0.0464s/iter; left time: 954.6176s
	iters: 200, epoch: 10 | loss: 32.3885956
	speed: 0.0434s/iter; left time: 887.5902s
Epoch: 10 cost time: 10.193968772888184
Epoch: 10, Steps: 227 Train Loss: 32.3377 (Forecasting Loss:0.5948 + XiCon Loss:3.1743 x Lambda(10.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2699
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.9275455
	speed: 0.0457s/iter; left time: 929.4461s
	iters: 200, epoch: 11 | loss: 33.2422829
	speed: 0.0421s/iter; left time: 851.5787s
Epoch: 11 cost time: 9.957271814346313
Epoch: 11, Steps: 227 Train Loss: 32.3167 (Forecasting Loss:0.5948 + XiCon Loss:3.1722 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2699
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 32.2285614
	speed: 0.0453s/iter; left time: 910.0309s
	iters: 200, epoch: 12 | loss: 32.1891174
	speed: 0.0423s/iter; left time: 845.7407s
Epoch: 12 cost time: 9.909666538238525
Epoch: 12, Steps: 227 Train Loss: 32.3244 (Forecasting Loss:0.5948 + XiCon Loss:3.1730 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2699
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 32.3012581
	speed: 0.0459s/iter; left time: 912.5151s
	iters: 200, epoch: 13 | loss: 32.2094803
	speed: 0.0431s/iter; left time: 852.0779s
Epoch: 13 cost time: 10.12550973892212
Epoch: 13, Steps: 227 Train Loss: 32.3185 (Forecasting Loss:0.5948 + XiCon Loss:3.1724 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 32.0441933
	speed: 0.0465s/iter; left time: 912.8847s
	iters: 200, epoch: 14 | loss: 32.7927856
	speed: 0.0427s/iter; left time: 834.6984s
Epoch: 14 cost time: 10.130096435546875
Epoch: 14, Steps: 227 Train Loss: 32.3029 (Forecasting Loss:0.5948 + XiCon Loss:3.1708 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 32.5627518
	speed: 0.0454s/iter; left time: 882.7180s
	iters: 200, epoch: 15 | loss: 33.1077194
	speed: 0.0426s/iter; left time: 823.5083s
Epoch: 15 cost time: 10.021176099777222
Epoch: 15, Steps: 227 Train Loss: 32.3307 (Forecasting Loss:0.5947 + XiCon Loss:3.1736 x Lambda(10.0)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2698
Validation loss decreased (1.182136 --> 1.181863).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 32.0916138
	speed: 0.0455s/iter; left time: 873.9997s
	iters: 200, epoch: 16 | loss: 32.3484726
	speed: 0.0429s/iter; left time: 819.2713s
Epoch: 16 cost time: 10.069932699203491
Epoch: 16, Steps: 227 Train Loss: 32.3341 (Forecasting Loss:0.5946 + XiCon Loss:3.1740 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 32.4142303
	speed: 0.0456s/iter; left time: 864.4286s
	iters: 200, epoch: 17 | loss: 32.3658104
	speed: 0.0426s/iter; left time: 802.9357s
Epoch: 17 cost time: 9.983575105667114
Epoch: 17, Steps: 227 Train Loss: 32.3422 (Forecasting Loss:0.5948 + XiCon Loss:3.1747 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 32.7470169
	speed: 0.0454s/iter; left time: 850.9003s
	iters: 200, epoch: 18 | loss: 31.8205261
	speed: 0.0419s/iter; left time: 781.3382s
Epoch: 18 cost time: 9.91816520690918
Epoch: 18, Steps: 227 Train Loss: 32.3102 (Forecasting Loss:0.5947 + XiCon Loss:3.1715 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 32.0911446
	speed: 0.0454s/iter; left time: 840.3088s
	iters: 200, epoch: 19 | loss: 32.2542267
	speed: 0.0436s/iter; left time: 802.7256s
Epoch: 19 cost time: 10.088552713394165
Epoch: 19, Steps: 227 Train Loss: 32.3373 (Forecasting Loss:0.5947 + XiCon Loss:3.1743 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 32.5560341
	speed: 0.0464s/iter; left time: 848.8318s
	iters: 200, epoch: 20 | loss: 32.4125252
	speed: 0.0431s/iter; left time: 784.6149s
Epoch: 20 cost time: 10.116591930389404
Epoch: 20, Steps: 227 Train Loss: 32.3352 (Forecasting Loss:0.5947 + XiCon Loss:3.1740 x Lambda(10.0)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.9459076
	speed: 0.0469s/iter; left time: 847.0822s
	iters: 200, epoch: 21 | loss: 32.2036438
	speed: 0.0430s/iter; left time: 772.5243s
Epoch: 21 cost time: 10.142571210861206
Epoch: 21, Steps: 227 Train Loss: 32.3194 (Forecasting Loss:0.5947 + XiCon Loss:3.1725 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 31.5757504
	speed: 0.0456s/iter; left time: 812.6069s
	iters: 200, epoch: 22 | loss: 32.1391754
	speed: 0.0417s/iter; left time: 739.9806s
Epoch: 22 cost time: 9.8885657787323
Epoch: 22, Steps: 227 Train Loss: 32.3331 (Forecasting Loss:0.5947 + XiCon Loss:3.1738 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.1934052
	speed: 0.0457s/iter; left time: 804.5323s
	iters: 200, epoch: 23 | loss: 32.5034409
	speed: 0.0428s/iter; left time: 750.0395s
Epoch: 23 cost time: 10.066395998001099
Epoch: 23, Steps: 227 Train Loss: 32.2878 (Forecasting Loss:0.5947 + XiCon Loss:3.1693 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 32.6408348
	speed: 0.0456s/iter; left time: 791.8045s
	iters: 200, epoch: 24 | loss: 32.8062859
	speed: 0.0435s/iter; left time: 751.7701s
Epoch: 24 cost time: 10.084473371505737
Epoch: 24, Steps: 227 Train Loss: 32.2991 (Forecasting Loss:0.5946 + XiCon Loss:3.1705 x Lambda(10.0)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 32.6429367
	speed: 0.0469s/iter; left time: 804.8643s
	iters: 200, epoch: 25 | loss: 31.7835426
	speed: 0.0420s/iter; left time: 716.2083s
Epoch: 25 cost time: 10.061547994613647
Epoch: 25, Steps: 227 Train Loss: 32.3219 (Forecasting Loss:0.5948 + XiCon Loss:3.1727 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5868135690689087, mae:0.9528726935386658, mape:6.204734802246094, mspe:4737.64306640625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.3414
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 33.5435371
	speed: 0.0450s/iter; left time: 1016.3134s
	iters: 200, epoch: 1 | loss: 33.6292458
	speed: 0.0411s/iter; left time: 925.0922s
Epoch: 1 cost time: 9.751237630844116
Epoch: 1, Steps: 227 Train Loss: 33.2283 (Forecasting Loss:1.0400 + XiCon Loss:3.2188 x Lambda(10.0)), Vali MSE Loss: 1.9472 Test MSE Loss: 1.3972
Validation loss decreased (inf --> 1.947245).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.1984138
	speed: 0.0452s/iter; left time: 1011.1530s
	iters: 200, epoch: 2 | loss: 32.3809052
	speed: 0.0411s/iter; left time: 914.9635s
Epoch: 2 cost time: 9.787928342819214
Epoch: 2, Steps: 227 Train Loss: 32.6344 (Forecasting Loss:0.6718 + XiCon Loss:3.1963 x Lambda(10.0)), Vali MSE Loss: 1.2058 Test MSE Loss: 1.2762
Validation loss decreased (1.947245 --> 1.205844).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.1330833
	speed: 0.0448s/iter; left time: 993.1110s
	iters: 200, epoch: 3 | loss: 31.6954327
	speed: 0.0416s/iter; left time: 917.6248s
Epoch: 3 cost time: 9.80432939529419
Epoch: 3, Steps: 227 Train Loss: 32.2330 (Forecasting Loss:0.6076 + XiCon Loss:3.1625 x Lambda(10.0)), Vali MSE Loss: 1.1880 Test MSE Loss: 1.2692
Validation loss decreased (1.205844 --> 1.188010).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 31.9528351
	speed: 0.0455s/iter; left time: 997.9295s
	iters: 200, epoch: 4 | loss: 32.2045822
	speed: 0.0416s/iter; left time: 906.9240s
Epoch: 4 cost time: 9.8624267578125
Epoch: 4, Steps: 227 Train Loss: 31.8565 (Forecasting Loss:0.6004 + XiCon Loss:3.1256 x Lambda(10.0)), Vali MSE Loss: 1.1843 Test MSE Loss: 1.2679
Validation loss decreased (1.188010 --> 1.184291).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.7803993
	speed: 0.0453s/iter; left time: 981.8620s
	iters: 200, epoch: 5 | loss: 31.5203400
	speed: 0.0419s/iter; left time: 905.1595s
Epoch: 5 cost time: 9.868497133255005
Epoch: 5, Steps: 227 Train Loss: 31.6341 (Forecasting Loss:0.5976 + XiCon Loss:3.1037 x Lambda(10.0)), Vali MSE Loss: 1.1809 Test MSE Loss: 1.2672
Validation loss decreased (1.184291 --> 1.180858).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 31.6661301
	speed: 0.0482s/iter; left time: 1033.7858s
	iters: 200, epoch: 6 | loss: 31.3582573
	speed: 0.0420s/iter; left time: 897.5242s
Epoch: 6 cost time: 10.216856956481934
Epoch: 6, Steps: 227 Train Loss: 31.5243 (Forecasting Loss:0.5964 + XiCon Loss:3.0928 x Lambda(10.0)), Vali MSE Loss: 1.1805 Test MSE Loss: 1.2668
Validation loss decreased (1.180858 --> 1.180452).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.0144081
	speed: 0.0448s/iter; left time: 950.8779s
	iters: 200, epoch: 7 | loss: 31.2437496
	speed: 0.0429s/iter; left time: 907.8568s
Epoch: 7 cost time: 9.941770553588867
Epoch: 7, Steps: 227 Train Loss: 31.4699 (Forecasting Loss:0.5956 + XiCon Loss:3.0874 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2666
Validation loss decreased (1.180452 --> 1.180143).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.1103210
	speed: 0.0456s/iter; left time: 958.1259s
	iters: 200, epoch: 8 | loss: 31.0072002
	speed: 0.0421s/iter; left time: 880.2154s
Epoch: 8 cost time: 9.937140226364136
Epoch: 8, Steps: 227 Train Loss: 31.4277 (Forecasting Loss:0.5953 + XiCon Loss:3.0832 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2666
Validation loss decreased (1.180143 --> 1.179381).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.4618759
	speed: 0.0466s/iter; left time: 969.4291s
	iters: 200, epoch: 9 | loss: 31.1002598
	speed: 0.0435s/iter; left time: 898.8017s
Epoch: 9 cost time: 10.203253507614136
Epoch: 9, Steps: 227 Train Loss: 31.4356 (Forecasting Loss:0.5953 + XiCon Loss:3.0840 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2665
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 31.3287563
	speed: 0.0451s/iter; left time: 927.9749s
	iters: 200, epoch: 10 | loss: 31.7138138
	speed: 0.0417s/iter; left time: 853.8958s
Epoch: 10 cost time: 9.904100894927979
Epoch: 10, Steps: 227 Train Loss: 31.4057 (Forecasting Loss:0.5951 + XiCon Loss:3.0811 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.2295532
	speed: 0.0480s/iter; left time: 976.5099s
	iters: 200, epoch: 11 | loss: 31.2715149
	speed: 0.0430s/iter; left time: 870.0009s
Epoch: 11 cost time: 10.282899618148804
Epoch: 11, Steps: 227 Train Loss: 31.4477 (Forecasting Loss:0.5949 + XiCon Loss:3.0853 x Lambda(10.0)), Vali MSE Loss: 1.1795 Test MSE Loss: 1.2665
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.1688023
	speed: 0.0450s/iter; left time: 905.4033s
	iters: 200, epoch: 12 | loss: 31.2886772
	speed: 0.0414s/iter; left time: 828.0693s
Epoch: 12 cost time: 9.835457801818848
Epoch: 12, Steps: 227 Train Loss: 31.4291 (Forecasting Loss:0.5949 + XiCon Loss:3.0834 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2665
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.0694847
	speed: 0.0445s/iter; left time: 885.2737s
	iters: 200, epoch: 13 | loss: 31.1664295
	speed: 0.0432s/iter; left time: 853.6663s
Epoch: 13 cost time: 10.075289011001587
Epoch: 13, Steps: 227 Train Loss: 31.4373 (Forecasting Loss:0.5949 + XiCon Loss:3.0842 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2665
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.7231483
	speed: 0.0456s/iter; left time: 896.8474s
	iters: 200, epoch: 14 | loss: 31.4816513
	speed: 0.0430s/iter; left time: 839.9563s
Epoch: 14 cost time: 10.072338581085205
Epoch: 14, Steps: 227 Train Loss: 31.3914 (Forecasting Loss:0.5950 + XiCon Loss:3.0796 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2665
Validation loss decreased (1.179381 --> 1.179169).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 31.9920197
	speed: 0.0456s/iter; left time: 885.7433s
	iters: 200, epoch: 15 | loss: 30.9252682
	speed: 0.0420s/iter; left time: 812.3167s
Epoch: 15 cost time: 9.917325019836426
Epoch: 15, Steps: 227 Train Loss: 31.3914 (Forecasting Loss:0.5949 + XiCon Loss:3.0797 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2665
Validation loss decreased (1.179169 --> 1.178933).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 31.2185497
	speed: 0.0450s/iter; left time: 863.7597s
	iters: 200, epoch: 16 | loss: 31.3029003
	speed: 0.0425s/iter; left time: 811.9445s
Epoch: 16 cost time: 9.96453070640564
Epoch: 16, Steps: 227 Train Loss: 31.4151 (Forecasting Loss:0.5949 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2665
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 31.7122898
	speed: 0.0453s/iter; left time: 859.9880s
	iters: 200, epoch: 17 | loss: 31.3191929
	speed: 0.0423s/iter; left time: 798.7407s
Epoch: 17 cost time: 9.945931673049927
Epoch: 17, Steps: 227 Train Loss: 31.4144 (Forecasting Loss:0.5950 + XiCon Loss:3.0819 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 31.5534134
	speed: 0.0455s/iter; left time: 853.5781s
	iters: 200, epoch: 18 | loss: 31.1361866
	speed: 0.0432s/iter; left time: 805.9139s
Epoch: 18 cost time: 10.098987579345703
Epoch: 18, Steps: 227 Train Loss: 31.3833 (Forecasting Loss:0.5950 + XiCon Loss:3.0788 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2665
Validation loss decreased (1.178933 --> 1.178890).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 31.5344486
	speed: 0.0466s/iter; left time: 862.3491s
	iters: 200, epoch: 19 | loss: 31.3998432
	speed: 0.0420s/iter; left time: 772.8722s
Epoch: 19 cost time: 10.020975589752197
Epoch: 19, Steps: 227 Train Loss: 31.4138 (Forecasting Loss:0.5951 + XiCon Loss:3.0819 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2665
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 31.3625393
	speed: 0.0455s/iter; left time: 831.3606s
	iters: 200, epoch: 20 | loss: 31.7072334
	speed: 0.0425s/iter; left time: 773.5957s
Epoch: 20 cost time: 9.960839033126831
Epoch: 20, Steps: 227 Train Loss: 31.4271 (Forecasting Loss:0.5950 + XiCon Loss:3.0832 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.3259773
	speed: 0.0451s/iter; left time: 814.2112s
	iters: 200, epoch: 21 | loss: 31.0067997
	speed: 0.0417s/iter; left time: 748.1261s
Epoch: 21 cost time: 9.835702419281006
Epoch: 21, Steps: 227 Train Loss: 31.4089 (Forecasting Loss:0.5949 + XiCon Loss:3.0814 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2665
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 31.8450413
	speed: 0.0467s/iter; left time: 832.2714s
	iters: 200, epoch: 22 | loss: 31.6233864
	speed: 0.0440s/iter; left time: 779.7761s
Epoch: 22 cost time: 10.293875932693481
Epoch: 22, Steps: 227 Train Loss: 31.4000 (Forecasting Loss:0.5951 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2665
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 31.5820713
	speed: 0.0454s/iter; left time: 799.4718s
	iters: 200, epoch: 23 | loss: 31.6428242
	speed: 0.0417s/iter; left time: 729.5884s
Epoch: 23 cost time: 9.906168699264526
Epoch: 23, Steps: 227 Train Loss: 31.4059 (Forecasting Loss:0.5949 + XiCon Loss:3.0811 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2665
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 31.3538322
	speed: 0.0458s/iter; left time: 795.6667s
	iters: 200, epoch: 24 | loss: 31.7199211
	speed: 0.0420s/iter; left time: 725.6264s
Epoch: 24 cost time: 9.978477954864502
Epoch: 24, Steps: 227 Train Loss: 31.4002 (Forecasting Loss:0.5949 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2665
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 31.5844536
	speed: 0.0455s/iter; left time: 780.0975s
	iters: 200, epoch: 25 | loss: 31.3230362
	speed: 0.0418s/iter; left time: 712.8492s
Epoch: 25 cost time: 9.907898902893066
Epoch: 25, Steps: 227 Train Loss: 31.3979 (Forecasting Loss:0.5950 + XiCon Loss:3.0803 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2665
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 31.5606861
	speed: 0.0449s/iter; left time: 760.2300s
	iters: 200, epoch: 26 | loss: 31.4910412
	speed: 0.0427s/iter; left time: 718.1475s
Epoch: 26 cost time: 9.987128019332886
Epoch: 26, Steps: 227 Train Loss: 31.4355 (Forecasting Loss:0.5950 + XiCon Loss:3.0841 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2665
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 31.3444099
	speed: 0.0466s/iter; left time: 778.4012s
	iters: 200, epoch: 27 | loss: 30.8554955
	speed: 0.0419s/iter; left time: 695.9436s
Epoch: 27 cost time: 10.032238960266113
Epoch: 27, Steps: 227 Train Loss: 31.4019 (Forecasting Loss:0.5951 + XiCon Loss:3.0807 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2665
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 30.9541397
	speed: 0.0466s/iter; left time: 767.4068s
	iters: 200, epoch: 28 | loss: 31.2516117
	speed: 0.0442s/iter; left time: 724.0128s
Epoch: 28 cost time: 10.267662286758423
Epoch: 28, Steps: 227 Train Loss: 31.4200 (Forecasting Loss:0.5950 + XiCon Loss:3.0825 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5822890996932983, mae:0.9506646394729614, mape:6.099025249481201, mspe:4549.59521484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.2855
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 33.0436440
	speed: 0.0449s/iter; left time: 1015.7612s
	iters: 200, epoch: 1 | loss: 32.5833664
	speed: 0.0411s/iter; left time: 925.5806s
Epoch: 1 cost time: 9.786648988723755
Epoch: 1, Steps: 227 Train Loss: 33.0340 (Forecasting Loss:1.1623 + XiCon Loss:3.1872 x Lambda(10.0)), Vali MSE Loss: 2.2089 Test MSE Loss: 1.4658
Validation loss decreased (inf --> 2.208932).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.4984932
	speed: 0.0446s/iter; left time: 998.7867s
	iters: 200, epoch: 2 | loss: 32.2205048
	speed: 0.0418s/iter; left time: 930.7176s
Epoch: 2 cost time: 9.811745882034302
Epoch: 2, Steps: 227 Train Loss: 32.4995 (Forecasting Loss:0.7705 + XiCon Loss:3.1729 x Lambda(10.0)), Vali MSE Loss: 1.3394 Test MSE Loss: 1.3362
Validation loss decreased (2.208932 --> 1.339431).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.1654358
	speed: 0.0454s/iter; left time: 1005.4018s
	iters: 200, epoch: 3 | loss: 32.2036438
	speed: 0.0414s/iter; left time: 913.0106s
Epoch: 3 cost time: 9.833600997924805
Epoch: 3, Steps: 227 Train Loss: 32.1649 (Forecasting Loss:0.6560 + XiCon Loss:3.1509 x Lambda(10.0)), Vali MSE Loss: 1.2463 Test MSE Loss: 1.3074
Validation loss decreased (1.339431 --> 1.246284).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 32.1075554
	speed: 0.0461s/iter; left time: 1009.6895s
	iters: 200, epoch: 4 | loss: 31.5514870
	speed: 0.0418s/iter; left time: 911.6895s
Epoch: 4 cost time: 9.945512533187866
Epoch: 4, Steps: 227 Train Loss: 32.0015 (Forecasting Loss:0.6226 + XiCon Loss:3.1379 x Lambda(10.0)), Vali MSE Loss: 1.2085 Test MSE Loss: 1.2956
Validation loss decreased (1.246284 --> 1.208516).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.6717396
	speed: 0.0449s/iter; left time: 973.9659s
	iters: 200, epoch: 5 | loss: 32.1975594
	speed: 0.0433s/iter; left time: 935.1417s
Epoch: 5 cost time: 10.069616794586182
Epoch: 5, Steps: 227 Train Loss: 31.9043 (Forecasting Loss:0.6099 + XiCon Loss:3.1294 x Lambda(10.0)), Vali MSE Loss: 1.1972 Test MSE Loss: 1.2913
Validation loss decreased (1.208516 --> 1.197228).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 32.1659889
	speed: 0.0462s/iter; left time: 991.6098s
	iters: 200, epoch: 6 | loss: 31.6860123
	speed: 0.0425s/iter; left time: 908.5080s
Epoch: 6 cost time: 10.03335690498352
Epoch: 6, Steps: 227 Train Loss: 31.8553 (Forecasting Loss:0.6051 + XiCon Loss:3.1250 x Lambda(10.0)), Vali MSE Loss: 1.1917 Test MSE Loss: 1.2891
Validation loss decreased (1.197228 --> 1.191739).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.7690601
	speed: 0.0456s/iter; left time: 968.4888s
	iters: 200, epoch: 7 | loss: 31.7204933
	speed: 0.0424s/iter; left time: 895.4634s
Epoch: 7 cost time: 9.967276573181152
Epoch: 7, Steps: 227 Train Loss: 31.8476 (Forecasting Loss:0.6027 + XiCon Loss:3.1245 x Lambda(10.0)), Vali MSE Loss: 1.1893 Test MSE Loss: 1.2882
Validation loss decreased (1.191739 --> 1.189303).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 31.8950691
	speed: 0.0456s/iter; left time: 958.4176s
	iters: 200, epoch: 8 | loss: 31.6772251
	speed: 0.0428s/iter; left time: 894.5429s
Epoch: 8 cost time: 10.06015396118164
Epoch: 8, Steps: 227 Train Loss: 31.8460 (Forecasting Loss:0.6015 + XiCon Loss:3.1245 x Lambda(10.0)), Vali MSE Loss: 1.1888 Test MSE Loss: 1.2877
Validation loss decreased (1.189303 --> 1.188765).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.8241043
	speed: 0.0455s/iter; left time: 945.8805s
	iters: 200, epoch: 9 | loss: 31.7533283
	speed: 0.0420s/iter; left time: 868.1337s
Epoch: 9 cost time: 9.9728262424469
Epoch: 9, Steps: 227 Train Loss: 31.8256 (Forecasting Loss:0.6008 + XiCon Loss:3.1225 x Lambda(10.0)), Vali MSE Loss: 1.1874 Test MSE Loss: 1.2875
Validation loss decreased (1.188765 --> 1.187443).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 32.0347939
	speed: 0.0459s/iter; left time: 943.4565s
	iters: 200, epoch: 10 | loss: 32.1709785
	speed: 0.0424s/iter; left time: 867.4456s
Epoch: 10 cost time: 10.034913063049316
Epoch: 10, Steps: 227 Train Loss: 31.8616 (Forecasting Loss:0.6009 + XiCon Loss:3.1261 x Lambda(10.0)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2873
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.5899849
	speed: 0.0448s/iter; left time: 910.8258s
	iters: 200, epoch: 11 | loss: 32.0853119
	speed: 0.0432s/iter; left time: 874.7581s
Epoch: 11 cost time: 10.012227058410645
Epoch: 11, Steps: 227 Train Loss: 31.8400 (Forecasting Loss:0.6008 + XiCon Loss:3.1239 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2873
Validation loss decreased (1.187443 --> 1.186712).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.7032890
	speed: 0.0459s/iter; left time: 922.0395s
	iters: 200, epoch: 12 | loss: 31.9159203
	speed: 0.0414s/iter; left time: 828.1208s
Epoch: 12 cost time: 9.889759540557861
Epoch: 12, Steps: 227 Train Loss: 31.8767 (Forecasting Loss:0.6007 + XiCon Loss:3.1276 x Lambda(10.0)), Vali MSE Loss: 1.1876 Test MSE Loss: 1.2872
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.4656963
	speed: 0.0471s/iter; left time: 935.5982s
	iters: 200, epoch: 13 | loss: 31.7598629
	speed: 0.0427s/iter; left time: 843.5342s
Epoch: 13 cost time: 10.148627281188965
Epoch: 13, Steps: 227 Train Loss: 31.8294 (Forecasting Loss:0.6006 + XiCon Loss:3.1229 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2872
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 31.4939213
	speed: 0.0446s/iter; left time: 877.1028s
	iters: 200, epoch: 14 | loss: 31.7147465
	speed: 0.0421s/iter; left time: 822.3372s
Epoch: 14 cost time: 9.835545539855957
Epoch: 14, Steps: 227 Train Loss: 31.8450 (Forecasting Loss:0.6006 + XiCon Loss:3.1244 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2872
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 32.2521515
	speed: 0.0443s/iter; left time: 860.6659s
	iters: 200, epoch: 15 | loss: 31.7969780
	speed: 0.0423s/iter; left time: 817.4042s
Epoch: 15 cost time: 9.846528053283691
Epoch: 15, Steps: 227 Train Loss: 31.8270 (Forecasting Loss:0.6005 + XiCon Loss:3.1226 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2872
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 31.0631065
	speed: 0.0453s/iter; left time: 869.2048s
	iters: 200, epoch: 16 | loss: 31.6143856
	speed: 0.0448s/iter; left time: 854.8267s
Epoch: 16 cost time: 10.270888805389404
Epoch: 16, Steps: 227 Train Loss: 31.8096 (Forecasting Loss:0.6006 + XiCon Loss:3.1209 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2872
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 31.6873856
	speed: 0.0461s/iter; left time: 874.4159s
	iters: 200, epoch: 17 | loss: 32.1476212
	speed: 0.0436s/iter; left time: 823.2687s
Epoch: 17 cost time: 10.173770666122437
Epoch: 17, Steps: 227 Train Loss: 31.8442 (Forecasting Loss:0.6005 + XiCon Loss:3.1244 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2872
Validation loss decreased (1.186712 --> 1.186626).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 31.9014721
	speed: 0.0457s/iter; left time: 856.0326s
	iters: 200, epoch: 18 | loss: 31.7184887
	speed: 0.0426s/iter; left time: 794.9326s
Epoch: 18 cost time: 10.0297532081604
Epoch: 18, Steps: 227 Train Loss: 31.8495 (Forecasting Loss:0.6007 + XiCon Loss:3.1249 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2872
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 32.1323891
	speed: 0.0451s/iter; left time: 834.9790s
	iters: 200, epoch: 19 | loss: 31.4789200
	speed: 0.0425s/iter; left time: 783.0446s
Epoch: 19 cost time: 9.96043586730957
Epoch: 19, Steps: 227 Train Loss: 31.8206 (Forecasting Loss:0.6005 + XiCon Loss:3.1220 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2872
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 31.8627720
	speed: 0.0451s/iter; left time: 825.6077s
	iters: 200, epoch: 20 | loss: 31.7403889
	speed: 0.0410s/iter; left time: 745.6424s
Epoch: 20 cost time: 9.775352001190186
Epoch: 20, Steps: 227 Train Loss: 31.8636 (Forecasting Loss:0.6007 + XiCon Loss:3.1263 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2872
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.0830898
	speed: 0.0471s/iter; left time: 851.2395s
	iters: 200, epoch: 21 | loss: 31.6140633
	speed: 0.0425s/iter; left time: 762.7880s
Epoch: 21 cost time: 10.169867992401123
Epoch: 21, Steps: 227 Train Loss: 31.8407 (Forecasting Loss:0.6006 + XiCon Loss:3.1240 x Lambda(10.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2872
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 32.0290413
	speed: 0.0459s/iter; left time: 818.9366s
	iters: 200, epoch: 22 | loss: 31.7369270
	speed: 0.0416s/iter; left time: 737.8867s
Epoch: 22 cost time: 10.036367416381836
Epoch: 22, Steps: 227 Train Loss: 31.8604 (Forecasting Loss:0.6004 + XiCon Loss:3.1260 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2872
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.2384338
	speed: 0.0449s/iter; left time: 790.2553s
	iters: 200, epoch: 23 | loss: 31.6629314
	speed: 0.0428s/iter; left time: 749.3723s
Epoch: 23 cost time: 10.00393009185791
Epoch: 23, Steps: 227 Train Loss: 31.8385 (Forecasting Loss:0.6004 + XiCon Loss:3.1238 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2872
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 31.8458252
	speed: 0.0463s/iter; left time: 804.1895s
	iters: 200, epoch: 24 | loss: 32.0404549
	speed: 0.0434s/iter; left time: 749.4349s
Epoch: 24 cost time: 10.179485559463501
Epoch: 24, Steps: 227 Train Loss: 31.8372 (Forecasting Loss:0.6004 + XiCon Loss:3.1237 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2872
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 32.3263283
	speed: 0.0452s/iter; left time: 774.6351s
	iters: 200, epoch: 25 | loss: 31.2582397
	speed: 0.0430s/iter; left time: 732.9088s
Epoch: 25 cost time: 10.046612977981567
Epoch: 25, Steps: 227 Train Loss: 31.8436 (Forecasting Loss:0.6004 + XiCon Loss:3.1243 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2872
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 32.3340607
	speed: 0.0461s/iter; left time: 780.4270s
	iters: 200, epoch: 26 | loss: 31.5372257
	speed: 0.0418s/iter; left time: 704.0388s
Epoch: 26 cost time: 9.953632593154907
Epoch: 26, Steps: 227 Train Loss: 31.8156 (Forecasting Loss:0.6006 + XiCon Loss:3.1215 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2872
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 31.9104729
	speed: 0.0455s/iter; left time: 759.9027s
	iters: 200, epoch: 27 | loss: 31.7366447
	speed: 0.0431s/iter; left time: 715.6878s
Epoch: 27 cost time: 10.054489374160767
Epoch: 27, Steps: 227 Train Loss: 31.8377 (Forecasting Loss:0.6003 + XiCon Loss:3.1237 x Lambda(10.0)), Vali MSE Loss: 1.1874 Test MSE Loss: 1.2872
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.6085574626922607, mae:0.9658793807029724, mape:6.6103196144104, mspe:5427.64697265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.5474
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 33.0303230
	speed: 0.0510s/iter; left time: 1152.1696s
	iters: 200, epoch: 1 | loss: 33.0251541
	speed: 0.0457s/iter; left time: 1029.1151s
Epoch: 1 cost time: 10.972562313079834
Epoch: 1, Steps: 227 Train Loss: 33.2019 (Forecasting Loss:1.0351 + XiCon Loss:3.2167 x Lambda(10.0)), Vali MSE Loss: 1.9647 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964679).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.3965683
	speed: 0.0485s/iter; left time: 1084.4897s
	iters: 200, epoch: 2 | loss: 32.2647896
	speed: 0.0459s/iter; left time: 1022.3536s
Epoch: 2 cost time: 10.77840542793274
Epoch: 2, Steps: 227 Train Loss: 32.6926 (Forecasting Loss:0.6716 + XiCon Loss:3.2021 x Lambda(10.0)), Vali MSE Loss: 1.2188 Test MSE Loss: 1.2819
Validation loss decreased (1.964679 --> 1.218816).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.2801514
	speed: 0.0493s/iter; left time: 1091.8137s
	iters: 200, epoch: 3 | loss: 32.3037415
	speed: 0.0456s/iter; left time: 1005.4914s
Epoch: 3 cost time: 10.772836208343506
Epoch: 3, Steps: 227 Train Loss: 32.4100 (Forecasting Loss:0.6086 + XiCon Loss:3.1801 x Lambda(10.0)), Vali MSE Loss: 1.1997 Test MSE Loss: 1.2744
Validation loss decreased (1.218816 --> 1.199664).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 31.9490471
	speed: 0.0478s/iter; left time: 1047.5407s
	iters: 200, epoch: 4 | loss: 32.4396400
	speed: 0.0474s/iter; left time: 1034.8550s
Epoch: 4 cost time: 10.833050966262817
Epoch: 4, Steps: 227 Train Loss: 32.3081 (Forecasting Loss:0.6009 + XiCon Loss:3.1707 x Lambda(10.0)), Vali MSE Loss: 1.1921 Test MSE Loss: 1.2723
Validation loss decreased (1.199664 --> 1.192121).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.6129818
	speed: 0.0495s/iter; left time: 1072.8218s
	iters: 200, epoch: 5 | loss: 31.9517365
	speed: 0.0472s/iter; left time: 1019.0068s
Epoch: 5 cost time: 11.015007495880127
Epoch: 5, Steps: 227 Train Loss: 32.2185 (Forecasting Loss:0.5980 + XiCon Loss:3.1621 x Lambda(10.0)), Vali MSE Loss: 1.1889 Test MSE Loss: 1.2713
Validation loss decreased (1.192121 --> 1.188870).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 32.2376709
	speed: 0.0487s/iter; left time: 1044.4238s
	iters: 200, epoch: 6 | loss: 32.3660278
	speed: 0.0481s/iter; left time: 1027.9624s
Epoch: 6 cost time: 11.014081239700317
Epoch: 6, Steps: 227 Train Loss: 32.2018 (Forecasting Loss:0.5967 + XiCon Loss:3.1605 x Lambda(10.0)), Vali MSE Loss: 1.1876 Test MSE Loss: 1.2708
Validation loss decreased (1.188870 --> 1.187559).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.9153728
	speed: 0.0493s/iter; left time: 1047.2180s
	iters: 200, epoch: 7 | loss: 32.2825012
	speed: 0.0469s/iter; left time: 992.2613s
Epoch: 7 cost time: 10.940558195114136
Epoch: 7, Steps: 227 Train Loss: 32.1922 (Forecasting Loss:0.5962 + XiCon Loss:3.1596 x Lambda(10.0)), Vali MSE Loss: 1.1865 Test MSE Loss: 1.2707
Validation loss decreased (1.187559 --> 1.186540).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 31.9327431
	speed: 0.0492s/iter; left time: 1033.1028s
	iters: 200, epoch: 8 | loss: 31.9317398
	speed: 0.0469s/iter; left time: 980.6172s
Epoch: 8 cost time: 10.9124755859375
Epoch: 8, Steps: 227 Train Loss: 32.1946 (Forecasting Loss:0.5958 + XiCon Loss:3.1599 x Lambda(10.0)), Vali MSE Loss: 1.1864 Test MSE Loss: 1.2706
Validation loss decreased (1.186540 --> 1.186405).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.9343872
	speed: 0.0511s/iter; left time: 1061.3136s
	iters: 200, epoch: 9 | loss: 32.4191132
	speed: 0.0467s/iter; left time: 966.9481s
Epoch: 9 cost time: 11.127220630645752
Epoch: 9, Steps: 227 Train Loss: 32.1646 (Forecasting Loss:0.5955 + XiCon Loss:3.1569 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 32.3821564
	speed: 0.0507s/iter; left time: 1041.7456s
	iters: 200, epoch: 10 | loss: 32.2623978
	speed: 0.0478s/iter; left time: 977.4857s
Epoch: 10 cost time: 11.152379035949707
Epoch: 10, Steps: 227 Train Loss: 32.1856 (Forecasting Loss:0.5953 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.9991760
	speed: 0.0503s/iter; left time: 1021.7609s
	iters: 200, epoch: 11 | loss: 32.1209297
	speed: 0.0464s/iter; left time: 937.8259s
Epoch: 11 cost time: 10.948781251907349
Epoch: 11, Steps: 227 Train Loss: 32.1593 (Forecasting Loss:0.5952 + XiCon Loss:3.1564 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 32.0001831
	speed: 0.0504s/iter; left time: 1013.7250s
	iters: 200, epoch: 12 | loss: 32.0559235
	speed: 0.0468s/iter; left time: 935.8561s
Epoch: 12 cost time: 11.090598106384277
Epoch: 12, Steps: 227 Train Loss: 32.1576 (Forecasting Loss:0.5952 + XiCon Loss:3.1562 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.9773979
	speed: 0.0496s/iter; left time: 985.8695s
	iters: 200, epoch: 13 | loss: 32.3141327
	speed: 0.0470s/iter; left time: 928.9330s
Epoch: 13 cost time: 11.012322902679443
Epoch: 13, Steps: 227 Train Loss: 32.1854 (Forecasting Loss:0.5952 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 1.1864 Test MSE Loss: 1.2705
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 32.1254997
	speed: 0.0498s/iter; left time: 978.0504s
	iters: 200, epoch: 14 | loss: 31.9099274
	speed: 0.0461s/iter; left time: 900.9778s
Epoch: 14 cost time: 10.962985515594482
Epoch: 14, Steps: 227 Train Loss: 32.1804 (Forecasting Loss:0.5952 + XiCon Loss:3.1585 x Lambda(10.0)), Vali MSE Loss: 1.1856 Test MSE Loss: 1.2705
Validation loss decreased (1.186405 --> 1.185614).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 32.4353714
	speed: 0.0499s/iter; left time: 968.8578s
	iters: 200, epoch: 15 | loss: 32.4182663
	speed: 0.0471s/iter; left time: 909.3840s
Epoch: 15 cost time: 11.04464840888977
Epoch: 15, Steps: 227 Train Loss: 32.1842 (Forecasting Loss:0.5953 + XiCon Loss:3.1589 x Lambda(10.0)), Vali MSE Loss: 1.1861 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 32.4543762
	speed: 0.0481s/iter; left time: 922.7479s
	iters: 200, epoch: 16 | loss: 32.2383270
	speed: 0.0467s/iter; left time: 891.7154s
Epoch: 16 cost time: 10.799540042877197
Epoch: 16, Steps: 227 Train Loss: 32.1821 (Forecasting Loss:0.5952 + XiCon Loss:3.1587 x Lambda(10.0)), Vali MSE Loss: 1.1863 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 32.0776443
	speed: 0.0488s/iter; left time: 925.2020s
	iters: 200, epoch: 17 | loss: 32.0563202
	speed: 0.0471s/iter; left time: 888.7596s
Epoch: 17 cost time: 10.909603834152222
Epoch: 17, Steps: 227 Train Loss: 32.1526 (Forecasting Loss:0.5952 + XiCon Loss:3.1557 x Lambda(10.0)), Vali MSE Loss: 1.1864 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 32.2491302
	speed: 0.0488s/iter; left time: 914.6267s
	iters: 200, epoch: 18 | loss: 32.0567169
	speed: 0.0463s/iter; left time: 863.0373s
Epoch: 18 cost time: 10.821581840515137
Epoch: 18, Steps: 227 Train Loss: 32.1549 (Forecasting Loss:0.5952 + XiCon Loss:3.1560 x Lambda(10.0)), Vali MSE Loss: 1.1863 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 31.7414436
	speed: 0.0509s/iter; left time: 942.9714s
	iters: 200, epoch: 19 | loss: 32.0151711
	speed: 0.0473s/iter; left time: 871.0095s
Epoch: 19 cost time: 11.180979490280151
Epoch: 19, Steps: 227 Train Loss: 32.1931 (Forecasting Loss:0.5950 + XiCon Loss:3.1598 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 32.3537941
	speed: 0.0516s/iter; left time: 943.1696s
	iters: 200, epoch: 20 | loss: 32.1686935
	speed: 0.0469s/iter; left time: 853.0520s
Epoch: 20 cost time: 11.215153217315674
Epoch: 20, Steps: 227 Train Loss: 32.1949 (Forecasting Loss:0.5951 + XiCon Loss:3.1600 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.5481529
	speed: 0.0493s/iter; left time: 890.8044s
	iters: 200, epoch: 21 | loss: 32.5787659
	speed: 0.0461s/iter; left time: 828.0207s
Epoch: 21 cost time: 10.829095125198364
Epoch: 21, Steps: 227 Train Loss: 32.1732 (Forecasting Loss:0.5952 + XiCon Loss:3.1578 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 31.7898788
	speed: 0.0498s/iter; left time: 887.5834s
	iters: 200, epoch: 22 | loss: 32.0785637
	speed: 0.0468s/iter; left time: 830.1509s
Epoch: 22 cost time: 10.962459802627563
Epoch: 22, Steps: 227 Train Loss: 32.1678 (Forecasting Loss:0.5953 + XiCon Loss:3.1573 x Lambda(10.0)), Vali MSE Loss: 1.1862 Test MSE Loss: 1.2705
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.0459290
	speed: 0.0488s/iter; left time: 858.3945s
	iters: 200, epoch: 23 | loss: 32.5132980
	speed: 0.0470s/iter; left time: 822.4730s
Epoch: 23 cost time: 10.881495714187622
Epoch: 23, Steps: 227 Train Loss: 32.1659 (Forecasting Loss:0.5953 + XiCon Loss:3.1571 x Lambda(10.0)), Vali MSE Loss: 1.1865 Test MSE Loss: 1.2705
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 31.8627472
	speed: 0.0506s/iter; left time: 879.2291s
	iters: 200, epoch: 24 | loss: 32.3202209
	speed: 0.0479s/iter; left time: 827.8672s
Epoch: 24 cost time: 11.216829299926758
Epoch: 24, Steps: 227 Train Loss: 32.1769 (Forecasting Loss:0.5953 + XiCon Loss:3.1582 x Lambda(10.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2705
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.587955117225647, mae:0.9530411958694458, mape:6.191324710845947, mspe:4727.10205078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5910+-0.01262, MAE:0.9554+-0.00747, MAPE:6.2729+-0.24487, MSPE:4857.3765+-417.11457, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
