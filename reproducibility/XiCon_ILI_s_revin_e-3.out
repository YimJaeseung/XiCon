Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2709
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 1.1101503372192383
Epoch: 1, Steps: 38 Train Loss: 0.4215 (Forecasting Loss:0.4199 + XiCon Loss:1.6081 x Lambda(0.001)), Vali MSE Loss: 0.2633 Test MSE Loss: 1.0786
Validation loss decreased (inf --> 0.263251).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7433369159698486
Epoch: 2, Steps: 38 Train Loss: 0.2528 (Forecasting Loss:0.2512 + XiCon Loss:1.6285 x Lambda(0.001)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.5856
Validation loss decreased (0.263251 --> 0.147243).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7089078426361084
Epoch: 3, Steps: 38 Train Loss: 0.1602 (Forecasting Loss:0.1586 + XiCon Loss:1.6241 x Lambda(0.001)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6047
Validation loss decreased (0.147243 --> 0.115967).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7986900806427002
Epoch: 4, Steps: 38 Train Loss: 0.1340 (Forecasting Loss:0.1324 + XiCon Loss:1.6297 x Lambda(0.001)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.6073
Validation loss decreased (0.115967 --> 0.108381).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7359578609466553
Epoch: 5, Steps: 38 Train Loss: 0.1293 (Forecasting Loss:0.1277 + XiCon Loss:1.6250 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6334
Validation loss decreased (0.108381 --> 0.103926).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6918792724609375
Epoch: 6, Steps: 38 Train Loss: 0.1256 (Forecasting Loss:0.1240 + XiCon Loss:1.6261 x Lambda(0.001)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6139
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7407407760620117
Epoch: 7, Steps: 38 Train Loss: 0.1254 (Forecasting Loss:0.1237 + XiCon Loss:1.6314 x Lambda(0.001)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6128
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7493646144866943
Epoch: 8, Steps: 38 Train Loss: 0.1239 (Forecasting Loss:0.1223 + XiCon Loss:1.6234 x Lambda(0.001)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.6141
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7252168655395508
Epoch: 9, Steps: 38 Train Loss: 0.1243 (Forecasting Loss:0.1226 + XiCon Loss:1.6251 x Lambda(0.001)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.6146
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.719839334487915
Epoch: 10, Steps: 38 Train Loss: 0.1241 (Forecasting Loss:0.1225 + XiCon Loss:1.6196 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6148
Validation loss decreased (0.103926 --> 0.103882).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6778149604797363
Epoch: 11, Steps: 38 Train Loss: 0.1236 (Forecasting Loss:0.1219 + XiCon Loss:1.6224 x Lambda(0.001)), Vali MSE Loss: 0.1027 Test MSE Loss: 0.6146
Validation loss decreased (0.103882 --> 0.102737).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6921343803405762
Epoch: 12, Steps: 38 Train Loss: 0.1231 (Forecasting Loss:0.1215 + XiCon Loss:1.6201 x Lambda(0.001)), Vali MSE Loss: 0.1031 Test MSE Loss: 0.6148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6914877891540527
Epoch: 13, Steps: 38 Train Loss: 0.1237 (Forecasting Loss:0.1220 + XiCon Loss:1.6202 x Lambda(0.001)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7496976852416992
Epoch: 14, Steps: 38 Train Loss: 0.1235 (Forecasting Loss:0.1219 + XiCon Loss:1.6196 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6148
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6919012069702148
Epoch: 15, Steps: 38 Train Loss: 0.1240 (Forecasting Loss:0.1224 + XiCon Loss:1.6197 x Lambda(0.001)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.6148
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6900146007537842
Epoch: 16, Steps: 38 Train Loss: 0.1238 (Forecasting Loss:0.1222 + XiCon Loss:1.6231 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6148
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.701871395111084
Epoch: 17, Steps: 38 Train Loss: 0.1233 (Forecasting Loss:0.1217 + XiCon Loss:1.6253 x Lambda(0.001)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6148
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7255003452301025
Epoch: 18, Steps: 38 Train Loss: 0.1227 (Forecasting Loss:0.1211 + XiCon Loss:1.6210 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6148
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6614711284637451
Epoch: 19, Steps: 38 Train Loss: 0.1230 (Forecasting Loss:0.1214 + XiCon Loss:1.6221 x Lambda(0.001)), Vali MSE Loss: 0.1036 Test MSE Loss: 0.6148
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6997010707855225
Epoch: 20, Steps: 38 Train Loss: 0.1240 (Forecasting Loss:0.1224 + XiCon Loss:1.6139 x Lambda(0.001)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6148
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6963183879852295
Epoch: 21, Steps: 38 Train Loss: 0.1241 (Forecasting Loss:0.1224 + XiCon Loss:1.6276 x Lambda(0.001)), Vali MSE Loss: 0.1036 Test MSE Loss: 0.6148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6675819158554077, mae:0.5617108941078186, mape:0.21816261112689972, mspe:0.17986245453357697 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3264
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.6882801055908203
Epoch: 1, Steps: 38 Train Loss: 0.4834 (Forecasting Loss:0.4818 + XiCon Loss:1.6123 x Lambda(0.001)), Vali MSE Loss: 0.2949 Test MSE Loss: 1.2404
Validation loss decreased (inf --> 0.294919).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6794297695159912
Epoch: 2, Steps: 38 Train Loss: 0.2659 (Forecasting Loss:0.2643 + XiCon Loss:1.6172 x Lambda(0.001)), Vali MSE Loss: 0.1514 Test MSE Loss: 0.6549
Validation loss decreased (0.294919 --> 0.151393).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7402899265289307
Epoch: 3, Steps: 38 Train Loss: 0.1618 (Forecasting Loss:0.1602 + XiCon Loss:1.6349 x Lambda(0.001)), Vali MSE Loss: 0.1220 Test MSE Loss: 0.5801
Validation loss decreased (0.151393 --> 0.121976).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 1.0469510555267334
Epoch: 4, Steps: 38 Train Loss: 0.1339 (Forecasting Loss:0.1323 + XiCon Loss:1.6167 x Lambda(0.001)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.6200
Validation loss decreased (0.121976 --> 0.109651).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.8310034275054932
Epoch: 5, Steps: 38 Train Loss: 0.1267 (Forecasting Loss:0.1251 + XiCon Loss:1.6178 x Lambda(0.001)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.5842
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6860923767089844
Epoch: 6, Steps: 38 Train Loss: 0.1222 (Forecasting Loss:0.1206 + XiCon Loss:1.6149 x Lambda(0.001)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.5792
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7265443801879883
Epoch: 7, Steps: 38 Train Loss: 0.1197 (Forecasting Loss:0.1181 + XiCon Loss:1.6106 x Lambda(0.001)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.5884
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7512779235839844
Epoch: 8, Steps: 38 Train Loss: 0.1189 (Forecasting Loss:0.1173 + XiCon Loss:1.6235 x Lambda(0.001)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.5865
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7608394622802734
Epoch: 9, Steps: 38 Train Loss: 0.1172 (Forecasting Loss:0.1156 + XiCon Loss:1.6162 x Lambda(0.001)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.5890
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6767644882202148
Epoch: 10, Steps: 38 Train Loss: 0.1172 (Forecasting Loss:0.1156 + XiCon Loss:1.6175 x Lambda(0.001)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.5893
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6798732280731201
Epoch: 11, Steps: 38 Train Loss: 0.1180 (Forecasting Loss:0.1164 + XiCon Loss:1.6138 x Lambda(0.001)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.5886
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.705209493637085
Epoch: 12, Steps: 38 Train Loss: 0.1168 (Forecasting Loss:0.1151 + XiCon Loss:1.6209 x Lambda(0.001)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.5883
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7339963912963867
Epoch: 13, Steps: 38 Train Loss: 0.1176 (Forecasting Loss:0.1160 + XiCon Loss:1.6163 x Lambda(0.001)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.5882
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7239251136779785
Epoch: 14, Steps: 38 Train Loss: 0.1170 (Forecasting Loss:0.1153 + XiCon Loss:1.6163 x Lambda(0.001)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.5883
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6793449521064758, mae:0.5605950951576233, mape:0.2189251184463501, mspe:0.1882837414741516 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3276
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7143490314483643
Epoch: 1, Steps: 38 Train Loss: 0.4358 (Forecasting Loss:0.4342 + XiCon Loss:1.5988 x Lambda(0.001)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.8332
Validation loss decreased (inf --> 0.306238).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.739891767501831
Epoch: 2, Steps: 38 Train Loss: 0.2819 (Forecasting Loss:0.2803 + XiCon Loss:1.6116 x Lambda(0.001)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.5486
Validation loss decreased (0.306238 --> 0.169244).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7635025978088379
Epoch: 3, Steps: 38 Train Loss: 0.1630 (Forecasting Loss:0.1613 + XiCon Loss:1.6359 x Lambda(0.001)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6349
Validation loss decreased (0.169244 --> 0.117778).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6314327716827393
Epoch: 4, Steps: 38 Train Loss: 0.1387 (Forecasting Loss:0.1371 + XiCon Loss:1.6439 x Lambda(0.001)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.5885
Validation loss decreased (0.117778 --> 0.109731).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6377434730529785
Epoch: 5, Steps: 38 Train Loss: 0.1331 (Forecasting Loss:0.1314 + XiCon Loss:1.6427 x Lambda(0.001)), Vali MSE Loss: 0.1087 Test MSE Loss: 0.5851
Validation loss decreased (0.109731 --> 0.108747).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7040133476257324
Epoch: 6, Steps: 38 Train Loss: 0.1303 (Forecasting Loss:0.1287 + XiCon Loss:1.6400 x Lambda(0.001)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.5921
Validation loss decreased (0.108747 --> 0.107399).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7260067462921143
Epoch: 7, Steps: 38 Train Loss: 0.1293 (Forecasting Loss:0.1277 + XiCon Loss:1.6447 x Lambda(0.001)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.5899
Validation loss decreased (0.107399 --> 0.106817).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7299256324768066
Epoch: 8, Steps: 38 Train Loss: 0.1288 (Forecasting Loss:0.1271 + XiCon Loss:1.6444 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5902
Validation loss decreased (0.106817 --> 0.106283).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7678670883178711
Epoch: 9, Steps: 38 Train Loss: 0.1283 (Forecasting Loss:0.1267 + XiCon Loss:1.6459 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5901
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6645119190216064
Epoch: 10, Steps: 38 Train Loss: 0.1282 (Forecasting Loss:0.1265 + XiCon Loss:1.6401 x Lambda(0.001)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.5901
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7078566551208496
Epoch: 11, Steps: 38 Train Loss: 0.1285 (Forecasting Loss:0.1269 + XiCon Loss:1.6452 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5898
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7290565967559814
Epoch: 12, Steps: 38 Train Loss: 0.1282 (Forecasting Loss:0.1265 + XiCon Loss:1.6464 x Lambda(0.001)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.5899
Validation loss decreased (0.106283 --> 0.106138).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7266945838928223
Epoch: 13, Steps: 38 Train Loss: 0.1286 (Forecasting Loss:0.1269 + XiCon Loss:1.6408 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5899
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7534921169281006
Epoch: 14, Steps: 38 Train Loss: 0.1276 (Forecasting Loss:0.1259 + XiCon Loss:1.6434 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5899
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7926812171936035
Epoch: 15, Steps: 38 Train Loss: 0.1279 (Forecasting Loss:0.1262 + XiCon Loss:1.6443 x Lambda(0.001)), Vali MSE Loss: 0.1060 Test MSE Loss: 0.5899
Validation loss decreased (0.106138 --> 0.106024).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6930258274078369
Epoch: 16, Steps: 38 Train Loss: 0.1284 (Forecasting Loss:0.1268 + XiCon Loss:1.6444 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5899
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7074325084686279
Epoch: 17, Steps: 38 Train Loss: 0.1264 (Forecasting Loss:0.1248 + XiCon Loss:1.6373 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
Validation loss decreased (0.106024 --> 0.105904).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7517893314361572
Epoch: 18, Steps: 38 Train Loss: 0.1285 (Forecasting Loss:0.1268 + XiCon Loss:1.6427 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
Validation loss decreased (0.105904 --> 0.105851).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6679432392120361
Epoch: 19, Steps: 38 Train Loss: 0.1283 (Forecasting Loss:0.1267 + XiCon Loss:1.6396 x Lambda(0.001)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.5899
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.8350124359130859
Epoch: 20, Steps: 38 Train Loss: 0.1280 (Forecasting Loss:0.1264 + XiCon Loss:1.6450 x Lambda(0.001)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.5899
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7460126876831055
Epoch: 21, Steps: 38 Train Loss: 0.1287 (Forecasting Loss:0.1270 + XiCon Loss:1.6433 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.700439453125
Epoch: 22, Steps: 38 Train Loss: 0.1283 (Forecasting Loss:0.1267 + XiCon Loss:1.6403 x Lambda(0.001)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.5899
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.8035609722137451
Epoch: 23, Steps: 38 Train Loss: 0.1282 (Forecasting Loss:0.1266 + XiCon Loss:1.6421 x Lambda(0.001)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.5899
Validation loss decreased (0.105851 --> 0.105833).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7049291133880615
Epoch: 24, Steps: 38 Train Loss: 0.1275 (Forecasting Loss:0.1258 + XiCon Loss:1.6412 x Lambda(0.001)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.5899
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7368466854095459
Epoch: 25, Steps: 38 Train Loss: 0.1278 (Forecasting Loss:0.1262 + XiCon Loss:1.6408 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5899
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7228577136993408
Epoch: 26, Steps: 38 Train Loss: 0.1285 (Forecasting Loss:0.1268 + XiCon Loss:1.6438 x Lambda(0.001)), Vali MSE Loss: 0.1052 Test MSE Loss: 0.5899
Validation loss decreased (0.105833 --> 0.105185).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7226536273956299
Epoch: 27, Steps: 38 Train Loss: 0.1280 (Forecasting Loss:0.1263 + XiCon Loss:1.6426 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5899
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7345478534698486
Epoch: 28, Steps: 38 Train Loss: 0.1274 (Forecasting Loss:0.1258 + XiCon Loss:1.6472 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.8175020217895508
Epoch: 29, Steps: 38 Train Loss: 0.1277 (Forecasting Loss:0.1261 + XiCon Loss:1.6407 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7451636791229248
Epoch: 30, Steps: 38 Train Loss: 0.1284 (Forecasting Loss:0.1268 + XiCon Loss:1.6387 x Lambda(0.001)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.5899
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7577238082885742
Epoch: 31, Steps: 38 Train Loss: 0.1275 (Forecasting Loss:0.1259 + XiCon Loss:1.6414 x Lambda(0.001)), Vali MSE Loss: 0.1057 Test MSE Loss: 0.5899
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.7479639053344727
Epoch: 32, Steps: 38 Train Loss: 0.1284 (Forecasting Loss:0.1267 + XiCon Loss:1.6395 x Lambda(0.001)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.5899
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.7292282581329346
Epoch: 33, Steps: 38 Train Loss: 0.1277 (Forecasting Loss:0.1261 + XiCon Loss:1.6431 x Lambda(0.001)), Vali MSE Loss: 0.1060 Test MSE Loss: 0.5899
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.771618127822876
Epoch: 34, Steps: 38 Train Loss: 0.1281 (Forecasting Loss:0.1265 + XiCon Loss:1.6407 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5899
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.662412166595459
Epoch: 35, Steps: 38 Train Loss: 0.1284 (Forecasting Loss:0.1267 + XiCon Loss:1.6458 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5899
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.7699692249298096
Epoch: 36, Steps: 38 Train Loss: 0.1275 (Forecasting Loss:0.1259 + XiCon Loss:1.6423 x Lambda(0.001)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.5899
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6334422826766968, mae:0.5462888479232788, mape:0.21202988922595978, mspe:0.1755833923816681 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3300
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7075393199920654
Epoch: 1, Steps: 38 Train Loss: 0.5270 (Forecasting Loss:0.5254 + XiCon Loss:1.6066 x Lambda(0.001)), Vali MSE Loss: 0.3240 Test MSE Loss: 1.3232
Validation loss decreased (inf --> 0.323967).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7285504341125488
Epoch: 2, Steps: 38 Train Loss: 0.2865 (Forecasting Loss:0.2849 + XiCon Loss:1.6220 x Lambda(0.001)), Vali MSE Loss: 0.1626 Test MSE Loss: 0.6088
Validation loss decreased (0.323967 --> 0.162586).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7745754718780518
Epoch: 3, Steps: 38 Train Loss: 0.1691 (Forecasting Loss:0.1675 + XiCon Loss:1.6363 x Lambda(0.001)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.6224
Validation loss decreased (0.162586 --> 0.121578).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7126212120056152
Epoch: 4, Steps: 38 Train Loss: 0.1400 (Forecasting Loss:0.1384 + XiCon Loss:1.6393 x Lambda(0.001)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.6084
Validation loss decreased (0.121578 --> 0.108641).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7693371772766113
Epoch: 5, Steps: 38 Train Loss: 0.1315 (Forecasting Loss:0.1298 + XiCon Loss:1.6434 x Lambda(0.001)), Vali MSE Loss: 0.1067 Test MSE Loss: 0.6048
Validation loss decreased (0.108641 --> 0.106727).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7648332118988037
Epoch: 6, Steps: 38 Train Loss: 0.1282 (Forecasting Loss:0.1266 + XiCon Loss:1.6336 x Lambda(0.001)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.5948
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7435383796691895
Epoch: 7, Steps: 38 Train Loss: 0.1262 (Forecasting Loss:0.1246 + XiCon Loss:1.6453 x Lambda(0.001)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.5937
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7162444591522217
Epoch: 8, Steps: 38 Train Loss: 0.1251 (Forecasting Loss:0.1234 + XiCon Loss:1.6363 x Lambda(0.001)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.5951
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7497398853302002
Epoch: 9, Steps: 38 Train Loss: 0.1246 (Forecasting Loss:0.1230 + XiCon Loss:1.6422 x Lambda(0.001)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.5949
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7088625431060791
Epoch: 10, Steps: 38 Train Loss: 0.1240 (Forecasting Loss:0.1223 + XiCon Loss:1.6428 x Lambda(0.001)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.5948
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7286732196807861
Epoch: 11, Steps: 38 Train Loss: 0.1237 (Forecasting Loss:0.1220 + XiCon Loss:1.6422 x Lambda(0.001)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.5951
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7121367454528809
Epoch: 12, Steps: 38 Train Loss: 0.1239 (Forecasting Loss:0.1223 + XiCon Loss:1.6394 x Lambda(0.001)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.5952
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7318997383117676
Epoch: 13, Steps: 38 Train Loss: 0.1241 (Forecasting Loss:0.1224 + XiCon Loss:1.6441 x Lambda(0.001)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.5953
Validation loss decreased (0.106727 --> 0.106171).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7371389865875244
Epoch: 14, Steps: 38 Train Loss: 0.1232 (Forecasting Loss:0.1215 + XiCon Loss:1.6396 x Lambda(0.001)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.5952
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7384717464447021
Epoch: 15, Steps: 38 Train Loss: 0.1235 (Forecasting Loss:0.1219 + XiCon Loss:1.6363 x Lambda(0.001)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.5952
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7869954109191895
Epoch: 16, Steps: 38 Train Loss: 0.1233 (Forecasting Loss:0.1217 + XiCon Loss:1.6417 x Lambda(0.001)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.5952
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7535223960876465
Epoch: 17, Steps: 38 Train Loss: 0.1223 (Forecasting Loss:0.1206 + XiCon Loss:1.6427 x Lambda(0.001)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.5952
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.802992582321167
Epoch: 18, Steps: 38 Train Loss: 0.1239 (Forecasting Loss:0.1222 + XiCon Loss:1.6395 x Lambda(0.001)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.5952
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.690868616104126
Epoch: 19, Steps: 38 Train Loss: 0.1240 (Forecasting Loss:0.1223 + XiCon Loss:1.6452 x Lambda(0.001)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.5952
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6574916839599609
Epoch: 20, Steps: 38 Train Loss: 0.1229 (Forecasting Loss:0.1212 + XiCon Loss:1.6396 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5952
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6792540550231934
Epoch: 21, Steps: 38 Train Loss: 0.1235 (Forecasting Loss:0.1218 + XiCon Loss:1.6408 x Lambda(0.001)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.5952
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6872880458831787
Epoch: 22, Steps: 38 Train Loss: 0.1239 (Forecasting Loss:0.1222 + XiCon Loss:1.6387 x Lambda(0.001)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.5952
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7548208236694336
Epoch: 23, Steps: 38 Train Loss: 0.1239 (Forecasting Loss:0.1223 + XiCon Loss:1.6417 x Lambda(0.001)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.5952
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6555960774421692, mae:0.5349239706993103, mape:0.21116696298122406, mspe:0.1851503998041153 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3275
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7662081718444824
Epoch: 1, Steps: 38 Train Loss: 0.4915 (Forecasting Loss:0.4899 + XiCon Loss:1.5982 x Lambda(0.001)), Vali MSE Loss: 0.2646 Test MSE Loss: 1.3766
Validation loss decreased (inf --> 0.264562).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6638648509979248
Epoch: 2, Steps: 38 Train Loss: 0.2753 (Forecasting Loss:0.2737 + XiCon Loss:1.6061 x Lambda(0.001)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.6120
Validation loss decreased (0.264562 --> 0.147278).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.70674729347229
Epoch: 3, Steps: 38 Train Loss: 0.1628 (Forecasting Loss:0.1611 + XiCon Loss:1.6352 x Lambda(0.001)), Vali MSE Loss: 0.1217 Test MSE Loss: 0.5925
Validation loss decreased (0.147278 --> 0.121688).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7528722286224365
Epoch: 4, Steps: 38 Train Loss: 0.1345 (Forecasting Loss:0.1328 + XiCon Loss:1.6286 x Lambda(0.001)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.5998
Validation loss decreased (0.121688 --> 0.111606).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.800771951675415
Epoch: 5, Steps: 38 Train Loss: 0.1231 (Forecasting Loss:0.1214 + XiCon Loss:1.6366 x Lambda(0.001)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.5970
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7550442218780518
Epoch: 6, Steps: 38 Train Loss: 0.1209 (Forecasting Loss:0.1193 + XiCon Loss:1.6314 x Lambda(0.001)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6045
Validation loss decreased (0.111606 --> 0.110303).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6772043704986572
Epoch: 7, Steps: 38 Train Loss: 0.1179 (Forecasting Loss:0.1162 + XiCon Loss:1.6368 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6037
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.762474775314331
Epoch: 8, Steps: 38 Train Loss: 0.1167 (Forecasting Loss:0.1151 + XiCon Loss:1.6343 x Lambda(0.001)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6038
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7069919109344482
Epoch: 9, Steps: 38 Train Loss: 0.1162 (Forecasting Loss:0.1146 + XiCon Loss:1.6339 x Lambda(0.001)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6035
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7506778240203857
Epoch: 10, Steps: 38 Train Loss: 0.1154 (Forecasting Loss:0.1137 + XiCon Loss:1.6357 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6040
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.699556827545166
Epoch: 11, Steps: 38 Train Loss: 0.1158 (Forecasting Loss:0.1142 + XiCon Loss:1.6371 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6044
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7455103397369385
Epoch: 12, Steps: 38 Train Loss: 0.1159 (Forecasting Loss:0.1143 + XiCon Loss:1.6366 x Lambda(0.001)), Vali MSE Loss: 0.1112 Test MSE Loss: 0.6044
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7019946575164795
Epoch: 13, Steps: 38 Train Loss: 0.1165 (Forecasting Loss:0.1149 + XiCon Loss:1.6355 x Lambda(0.001)), Vali MSE Loss: 0.1112 Test MSE Loss: 0.6044
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7218334674835205
Epoch: 14, Steps: 38 Train Loss: 0.1153 (Forecasting Loss:0.1137 + XiCon Loss:1.6309 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6043
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6735110282897949
Epoch: 15, Steps: 38 Train Loss: 0.1156 (Forecasting Loss:0.1140 + XiCon Loss:1.6378 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7523829936981201
Epoch: 16, Steps: 38 Train Loss: 0.1157 (Forecasting Loss:0.1141 + XiCon Loss:1.6375 x Lambda(0.001)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6044
Validation loss decreased (0.110303 --> 0.110214).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.750659704208374
Epoch: 17, Steps: 38 Train Loss: 0.1164 (Forecasting Loss:0.1147 + XiCon Loss:1.6347 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7837421894073486
Epoch: 18, Steps: 38 Train Loss: 0.1171 (Forecasting Loss:0.1154 + XiCon Loss:1.6326 x Lambda(0.001)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6044
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6654865741729736
Epoch: 19, Steps: 38 Train Loss: 0.1157 (Forecasting Loss:0.1141 + XiCon Loss:1.6357 x Lambda(0.001)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6044
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.684776782989502
Epoch: 20, Steps: 38 Train Loss: 0.1159 (Forecasting Loss:0.1142 + XiCon Loss:1.6391 x Lambda(0.001)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6044
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6836299896240234
Epoch: 21, Steps: 38 Train Loss: 0.1166 (Forecasting Loss:0.1150 + XiCon Loss:1.6366 x Lambda(0.001)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6044
Validation loss decreased (0.110214 --> 0.110200).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7497155666351318
Epoch: 22, Steps: 38 Train Loss: 0.1159 (Forecasting Loss:0.1142 + XiCon Loss:1.6332 x Lambda(0.001)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6044
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6910064220428467
Epoch: 23, Steps: 38 Train Loss: 0.1155 (Forecasting Loss:0.1139 + XiCon Loss:1.6312 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.630122184753418
Epoch: 24, Steps: 38 Train Loss: 0.1161 (Forecasting Loss:0.1144 + XiCon Loss:1.6343 x Lambda(0.001)), Vali MSE Loss: 0.1106 Test MSE Loss: 0.6044
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6986141204833984
Epoch: 25, Steps: 38 Train Loss: 0.1174 (Forecasting Loss:0.1158 + XiCon Loss:1.6333 x Lambda(0.001)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6044
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6266677379608154
Epoch: 26, Steps: 38 Train Loss: 0.1170 (Forecasting Loss:0.1154 + XiCon Loss:1.6345 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.694023609161377
Epoch: 27, Steps: 38 Train Loss: 0.1156 (Forecasting Loss:0.1140 + XiCon Loss:1.6367 x Lambda(0.001)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6044
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.6889793872833252
Epoch: 28, Steps: 38 Train Loss: 0.1162 (Forecasting Loss:0.1146 + XiCon Loss:1.6348 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6044
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.6818349361419678
Epoch: 29, Steps: 38 Train Loss: 0.1168 (Forecasting Loss:0.1152 + XiCon Loss:1.6324 x Lambda(0.001)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6044
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7282497882843018
Epoch: 30, Steps: 38 Train Loss: 0.1162 (Forecasting Loss:0.1145 + XiCon Loss:1.6349 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7634274959564209
Epoch: 31, Steps: 38 Train Loss: 0.1154 (Forecasting Loss:0.1138 + XiCon Loss:1.6305 x Lambda(0.001)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6044
Validation loss decreased (0.110200 --> 0.110173).  Saving model ...
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.6827042102813721
Epoch: 32, Steps: 38 Train Loss: 0.1152 (Forecasting Loss:0.1136 + XiCon Loss:1.6295 x Lambda(0.001)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6044
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.7508125305175781
Epoch: 33, Steps: 38 Train Loss: 0.1158 (Forecasting Loss:0.1142 + XiCon Loss:1.6305 x Lambda(0.001)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6044
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.7876300811767578
Epoch: 34, Steps: 38 Train Loss: 0.1161 (Forecasting Loss:0.1144 + XiCon Loss:1.6357 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6044
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.7029600143432617
Epoch: 35, Steps: 38 Train Loss: 0.1165 (Forecasting Loss:0.1148 + XiCon Loss:1.6358 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.7755553722381592
Epoch: 36, Steps: 38 Train Loss: 0.1159 (Forecasting Loss:0.1143 + XiCon Loss:1.6329 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.7080564498901367
Epoch: 37, Steps: 38 Train Loss: 0.1161 (Forecasting Loss:0.1144 + XiCon Loss:1.6331 x Lambda(0.001)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6044
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-14
Epoch: 38 cost time: 0.7995007038116455
Epoch: 38, Steps: 38 Train Loss: 0.1159 (Forecasting Loss:0.1142 + XiCon Loss:1.6340 x Lambda(0.001)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6044
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-14
Epoch: 39 cost time: 0.708491325378418
Epoch: 39, Steps: 38 Train Loss: 0.1166 (Forecasting Loss:0.1149 + XiCon Loss:1.6314 x Lambda(0.001)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6044
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-14
Epoch: 40 cost time: 0.7046933174133301
Epoch: 40, Steps: 38 Train Loss: 0.1156 (Forecasting Loss:0.1140 + XiCon Loss:1.6339 x Lambda(0.001)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6044
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-15
Epoch: 41 cost time: 0.727543830871582
Epoch: 41, Steps: 38 Train Loss: 0.1170 (Forecasting Loss:0.1153 + XiCon Loss:1.6361 x Lambda(0.001)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6044
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6616545915603638, mae:0.5470551252365112, mape:0.21015039086341858, mspe:0.1747516244649887 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6595+-0.02113, MAE:0.5501+-0.01387, MAPE:0.2141+-0.00513, MSPE:0.1807+-0.00733, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2671
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.9495031833648682
Epoch: 1, Steps: 37 Train Loss: 0.4926 (Forecasting Loss:0.4910 + XiCon Loss:1.6140 x Lambda(0.001)), Vali MSE Loss: 0.3076 Test MSE Loss: 1.2624
Validation loss decreased (inf --> 0.307627).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6877396106719971
Epoch: 2, Steps: 37 Train Loss: 0.2944 (Forecasting Loss:0.2927 + XiCon Loss:1.6395 x Lambda(0.001)), Vali MSE Loss: 0.1808 Test MSE Loss: 0.6838
Validation loss decreased (0.307627 --> 0.180833).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6704142093658447
Epoch: 3, Steps: 37 Train Loss: 0.1894 (Forecasting Loss:0.1877 + XiCon Loss:1.6440 x Lambda(0.001)), Vali MSE Loss: 0.1284 Test MSE Loss: 0.6656
Validation loss decreased (0.180833 --> 0.128385).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6715600490570068
Epoch: 4, Steps: 37 Train Loss: 0.1541 (Forecasting Loss:0.1524 + XiCon Loss:1.6453 x Lambda(0.001)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6867
Validation loss decreased (0.128385 --> 0.114915).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7307672500610352
Epoch: 5, Steps: 37 Train Loss: 0.1484 (Forecasting Loss:0.1468 + XiCon Loss:1.6501 x Lambda(0.001)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6688
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7221100330352783
Epoch: 6, Steps: 37 Train Loss: 0.1461 (Forecasting Loss:0.1444 + XiCon Loss:1.6445 x Lambda(0.001)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6609
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6295099258422852
Epoch: 7, Steps: 37 Train Loss: 0.1437 (Forecasting Loss:0.1421 + XiCon Loss:1.6489 x Lambda(0.001)), Vali MSE Loss: 0.1126 Test MSE Loss: 0.6693
Validation loss decreased (0.114915 --> 0.112631).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7259542942047119
Epoch: 8, Steps: 37 Train Loss: 0.1446 (Forecasting Loss:0.1430 + XiCon Loss:1.6486 x Lambda(0.001)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6697
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6966300010681152
Epoch: 9, Steps: 37 Train Loss: 0.1432 (Forecasting Loss:0.1415 + XiCon Loss:1.6400 x Lambda(0.001)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7713131904602051
Epoch: 10, Steps: 37 Train Loss: 0.1436 (Forecasting Loss:0.1419 + XiCon Loss:1.6464 x Lambda(0.001)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.6688
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7523901462554932
Epoch: 11, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6417 x Lambda(0.001)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6687
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6839118003845215
Epoch: 12, Steps: 37 Train Loss: 0.1436 (Forecasting Loss:0.1420 + XiCon Loss:1.6412 x Lambda(0.001)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6687
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6708104610443115
Epoch: 13, Steps: 37 Train Loss: 0.1426 (Forecasting Loss:0.1409 + XiCon Loss:1.6446 x Lambda(0.001)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6686
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7364773750305176
Epoch: 14, Steps: 37 Train Loss: 0.1431 (Forecasting Loss:0.1415 + XiCon Loss:1.6440 x Lambda(0.001)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6687
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7505655288696289
Epoch: 15, Steps: 37 Train Loss: 0.1436 (Forecasting Loss:0.1420 + XiCon Loss:1.6447 x Lambda(0.001)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6687
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7242980003356934
Epoch: 16, Steps: 37 Train Loss: 0.1418 (Forecasting Loss:0.1402 + XiCon Loss:1.6466 x Lambda(0.001)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.6687
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.705801248550415
Epoch: 17, Steps: 37 Train Loss: 0.1419 (Forecasting Loss:0.1403 + XiCon Loss:1.6453 x Lambda(0.001)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6687
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7219916582107544, mae:0.6166379451751709, mape:0.2433338165283203, mspe:0.20374934375286102 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3482
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7284574508666992
Epoch: 1, Steps: 37 Train Loss: 0.5048 (Forecasting Loss:0.5032 + XiCon Loss:1.6183 x Lambda(0.001)), Vali MSE Loss: 0.2759 Test MSE Loss: 1.0452
Validation loss decreased (inf --> 0.275887).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6286911964416504
Epoch: 2, Steps: 37 Train Loss: 0.3116 (Forecasting Loss:0.3099 + XiCon Loss:1.6233 x Lambda(0.001)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.6827
Validation loss decreased (0.275887 --> 0.172413).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6997222900390625
Epoch: 3, Steps: 37 Train Loss: 0.1789 (Forecasting Loss:0.1773 + XiCon Loss:1.6379 x Lambda(0.001)), Vali MSE Loss: 0.1371 Test MSE Loss: 0.6806
Validation loss decreased (0.172413 --> 0.137098).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7162823677062988
Epoch: 4, Steps: 37 Train Loss: 0.1504 (Forecasting Loss:0.1487 + XiCon Loss:1.6325 x Lambda(0.001)), Vali MSE Loss: 0.1274 Test MSE Loss: 0.6456
Validation loss decreased (0.137098 --> 0.127435).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7328004837036133
Epoch: 5, Steps: 37 Train Loss: 0.1442 (Forecasting Loss:0.1426 + XiCon Loss:1.6338 x Lambda(0.001)), Vali MSE Loss: 0.1183 Test MSE Loss: 0.6914
Validation loss decreased (0.127435 --> 0.118309).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6620872020721436
Epoch: 6, Steps: 37 Train Loss: 0.1391 (Forecasting Loss:0.1375 + XiCon Loss:1.6321 x Lambda(0.001)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6780
Validation loss decreased (0.118309 --> 0.117885).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6300976276397705
Epoch: 7, Steps: 37 Train Loss: 0.1374 (Forecasting Loss:0.1357 + XiCon Loss:1.6333 x Lambda(0.001)), Vali MSE Loss: 0.1202 Test MSE Loss: 0.6782
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.735438346862793
Epoch: 8, Steps: 37 Train Loss: 0.1367 (Forecasting Loss:0.1351 + XiCon Loss:1.6301 x Lambda(0.001)), Vali MSE Loss: 0.1205 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7053942680358887
Epoch: 9, Steps: 37 Train Loss: 0.1360 (Forecasting Loss:0.1344 + XiCon Loss:1.6341 x Lambda(0.001)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6796
Validation loss decreased (0.117885 --> 0.117820).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7919270992279053
Epoch: 10, Steps: 37 Train Loss: 0.1364 (Forecasting Loss:0.1348 + XiCon Loss:1.6376 x Lambda(0.001)), Vali MSE Loss: 0.1205 Test MSE Loss: 0.6819
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7938723564147949
Epoch: 11, Steps: 37 Train Loss: 0.1370 (Forecasting Loss:0.1354 + XiCon Loss:1.6324 x Lambda(0.001)), Vali MSE Loss: 0.1187 Test MSE Loss: 0.6809
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7105269432067871
Epoch: 12, Steps: 37 Train Loss: 0.1353 (Forecasting Loss:0.1337 + XiCon Loss:1.6271 x Lambda(0.001)), Vali MSE Loss: 0.1202 Test MSE Loss: 0.6810
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7534852027893066
Epoch: 13, Steps: 37 Train Loss: 0.1358 (Forecasting Loss:0.1341 + XiCon Loss:1.6336 x Lambda(0.001)), Vali MSE Loss: 0.1200 Test MSE Loss: 0.6809
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7073047161102295
Epoch: 14, Steps: 37 Train Loss: 0.1357 (Forecasting Loss:0.1340 + XiCon Loss:1.6387 x Lambda(0.001)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.6809
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7083194255828857
Epoch: 15, Steps: 37 Train Loss: 0.1349 (Forecasting Loss:0.1332 + XiCon Loss:1.6321 x Lambda(0.001)), Vali MSE Loss: 0.1200 Test MSE Loss: 0.6809
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7082889080047607
Epoch: 16, Steps: 37 Train Loss: 0.1353 (Forecasting Loss:0.1337 + XiCon Loss:1.6322 x Lambda(0.001)), Vali MSE Loss: 0.1207 Test MSE Loss: 0.6809
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7209763526916504
Epoch: 17, Steps: 37 Train Loss: 0.1349 (Forecasting Loss:0.1333 + XiCon Loss:1.6324 x Lambda(0.001)), Vali MSE Loss: 0.1218 Test MSE Loss: 0.6809
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7611119747161865
Epoch: 18, Steps: 37 Train Loss: 0.1360 (Forecasting Loss:0.1344 + XiCon Loss:1.6364 x Lambda(0.001)), Vali MSE Loss: 0.1192 Test MSE Loss: 0.6809
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7154250144958496
Epoch: 19, Steps: 37 Train Loss: 0.1363 (Forecasting Loss:0.1347 + XiCon Loss:1.6331 x Lambda(0.001)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.6809
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7315741181373596, mae:0.6275639533996582, mape:0.24802395701408386, mspe:0.20470143854618073 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3339
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6824617385864258
Epoch: 1, Steps: 37 Train Loss: 0.4445 (Forecasting Loss:0.4429 + XiCon Loss:1.6102 x Lambda(0.001)), Vali MSE Loss: 0.2819 Test MSE Loss: 1.0362
Validation loss decreased (inf --> 0.281888).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6694400310516357
Epoch: 2, Steps: 37 Train Loss: 0.2888 (Forecasting Loss:0.2872 + XiCon Loss:1.6231 x Lambda(0.001)), Vali MSE Loss: 0.1838 Test MSE Loss: 0.6953
Validation loss decreased (0.281888 --> 0.183781).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7183105945587158
Epoch: 3, Steps: 37 Train Loss: 0.1911 (Forecasting Loss:0.1895 + XiCon Loss:1.6362 x Lambda(0.001)), Vali MSE Loss: 0.1287 Test MSE Loss: 0.6396
Validation loss decreased (0.183781 --> 0.128657).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7118744850158691
Epoch: 4, Steps: 37 Train Loss: 0.1568 (Forecasting Loss:0.1551 + XiCon Loss:1.6361 x Lambda(0.001)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.6525
Validation loss decreased (0.128657 --> 0.117702).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6816658973693848
Epoch: 5, Steps: 37 Train Loss: 0.1482 (Forecasting Loss:0.1466 + XiCon Loss:1.6273 x Lambda(0.001)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6491
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6949570178985596
Epoch: 6, Steps: 37 Train Loss: 0.1456 (Forecasting Loss:0.1439 + XiCon Loss:1.6287 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6460
Validation loss decreased (0.117702 --> 0.116248).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6972289085388184
Epoch: 7, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6222 x Lambda(0.001)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6533
Validation loss decreased (0.116248 --> 0.115968).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6865758895874023
Epoch: 8, Steps: 37 Train Loss: 0.1436 (Forecasting Loss:0.1420 + XiCon Loss:1.6244 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6548
Validation loss decreased (0.115968 --> 0.115893).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7740552425384521
Epoch: 9, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6207 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6560
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.759462833404541
Epoch: 10, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6238 x Lambda(0.001)), Vali MSE Loss: 0.1168 Test MSE Loss: 0.6555
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6988158226013184
Epoch: 11, Steps: 37 Train Loss: 0.1431 (Forecasting Loss:0.1415 + XiCon Loss:1.6254 x Lambda(0.001)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6560
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7467880249023438
Epoch: 12, Steps: 37 Train Loss: 0.1422 (Forecasting Loss:0.1406 + XiCon Loss:1.6295 x Lambda(0.001)), Vali MSE Loss: 0.1171 Test MSE Loss: 0.6558
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7349033355712891
Epoch: 13, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6212 x Lambda(0.001)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6557
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6961660385131836
Epoch: 14, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6227 x Lambda(0.001)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.6558
Validation loss decreased (0.115893 --> 0.115795).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6870057582855225
Epoch: 15, Steps: 37 Train Loss: 0.1432 (Forecasting Loss:0.1416 + XiCon Loss:1.6228 x Lambda(0.001)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6558
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7149465084075928
Epoch: 16, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6212 x Lambda(0.001)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.6558
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7439849376678467
Epoch: 17, Steps: 37 Train Loss: 0.1431 (Forecasting Loss:0.1414 + XiCon Loss:1.6185 x Lambda(0.001)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6558
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7703173160552979
Epoch: 18, Steps: 37 Train Loss: 0.1424 (Forecasting Loss:0.1408 + XiCon Loss:1.6276 x Lambda(0.001)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6558
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.687448263168335
Epoch: 19, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6238 x Lambda(0.001)), Vali MSE Loss: 0.1166 Test MSE Loss: 0.6558
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6502482891082764
Epoch: 20, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6249 x Lambda(0.001)), Vali MSE Loss: 0.1172 Test MSE Loss: 0.6558
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6481454372406006
Epoch: 21, Steps: 37 Train Loss: 0.1428 (Forecasting Loss:0.1412 + XiCon Loss:1.6228 x Lambda(0.001)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.6558
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7167115211486816
Epoch: 22, Steps: 37 Train Loss: 0.1428 (Forecasting Loss:0.1412 + XiCon Loss:1.6256 x Lambda(0.001)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.6558
Validation loss decreased (0.115795 --> 0.115378).  Saving model ...
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6644330024719238
Epoch: 23, Steps: 37 Train Loss: 0.1433 (Forecasting Loss:0.1417 + XiCon Loss:1.6208 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6558
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7225115299224854
Epoch: 24, Steps: 37 Train Loss: 0.1413 (Forecasting Loss:0.1397 + XiCon Loss:1.6210 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6558
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6504528522491455
Epoch: 25, Steps: 37 Train Loss: 0.1432 (Forecasting Loss:0.1416 + XiCon Loss:1.6154 x Lambda(0.001)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6558
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7268116474151611
Epoch: 26, Steps: 37 Train Loss: 0.1418 (Forecasting Loss:0.1402 + XiCon Loss:1.6270 x Lambda(0.001)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6558
Validation loss decreased (0.115378 --> 0.115150).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7556085586547852
Epoch: 27, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6252 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6558
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7572922706604004
Epoch: 28, Steps: 37 Train Loss: 0.1419 (Forecasting Loss:0.1402 + XiCon Loss:1.6190 x Lambda(0.001)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6558
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7115123271942139
Epoch: 29, Steps: 37 Train Loss: 0.1426 (Forecasting Loss:0.1410 + XiCon Loss:1.6217 x Lambda(0.001)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6558
Validation loss decreased (0.115150 --> 0.113935).  Saving model ...
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.6952061653137207
Epoch: 30, Steps: 37 Train Loss: 0.1427 (Forecasting Loss:0.1411 + XiCon Loss:1.6197 x Lambda(0.001)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.6558
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.6566474437713623
Epoch: 31, Steps: 37 Train Loss: 0.1419 (Forecasting Loss:0.1402 + XiCon Loss:1.6281 x Lambda(0.001)), Vali MSE Loss: 0.1166 Test MSE Loss: 0.6558
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.6988029479980469
Epoch: 32, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6222 x Lambda(0.001)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6558
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.6655712127685547
Epoch: 33, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1412 + XiCon Loss:1.6244 x Lambda(0.001)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6558
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.702160120010376
Epoch: 34, Steps: 37 Train Loss: 0.1427 (Forecasting Loss:0.1411 + XiCon Loss:1.6201 x Lambda(0.001)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6558
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.7242119312286377
Epoch: 35, Steps: 37 Train Loss: 0.1425 (Forecasting Loss:0.1409 + XiCon Loss:1.6249 x Lambda(0.001)), Vali MSE Loss: 0.1171 Test MSE Loss: 0.6558
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.6988511085510254
Epoch: 36, Steps: 37 Train Loss: 0.1421 (Forecasting Loss:0.1405 + XiCon Loss:1.6208 x Lambda(0.001)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6558
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.7112307548522949
Epoch: 37, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6230 x Lambda(0.001)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6558
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
Epoch: 38 cost time: 0.7295091152191162
Epoch: 38, Steps: 37 Train Loss: 0.1429 (Forecasting Loss:0.1413 + XiCon Loss:1.6233 x Lambda(0.001)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6558
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
Epoch: 39 cost time: 0.7108826637268066
Epoch: 39, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1413 + XiCon Loss:1.6296 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6558
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.6991646885871887, mae:0.612349271774292, mape:0.2413172423839569, mspe:0.19982048869132996 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3298
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6940100193023682
Epoch: 1, Steps: 37 Train Loss: 0.5280 (Forecasting Loss:0.5264 + XiCon Loss:1.6061 x Lambda(0.001)), Vali MSE Loss: 0.3131 Test MSE Loss: 1.3077
Validation loss decreased (inf --> 0.313098).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.685786247253418
Epoch: 2, Steps: 37 Train Loss: 0.3198 (Forecasting Loss:0.3182 + XiCon Loss:1.6110 x Lambda(0.001)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.7558
Validation loss decreased (0.313098 --> 0.168427).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7218341827392578
Epoch: 3, Steps: 37 Train Loss: 0.1860 (Forecasting Loss:0.1843 + XiCon Loss:1.6155 x Lambda(0.001)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6878
Validation loss decreased (0.168427 --> 0.130893).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7038757801055908
Epoch: 4, Steps: 37 Train Loss: 0.1579 (Forecasting Loss:0.1563 + XiCon Loss:1.6115 x Lambda(0.001)), Vali MSE Loss: 0.1190 Test MSE Loss: 0.6733
Validation loss decreased (0.130893 --> 0.119009).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6892333030700684
Epoch: 5, Steps: 37 Train Loss: 0.1498 (Forecasting Loss:0.1482 + XiCon Loss:1.6110 x Lambda(0.001)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6760
Validation loss decreased (0.119009 --> 0.116951).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7417562007904053
Epoch: 6, Steps: 37 Train Loss: 0.1451 (Forecasting Loss:0.1435 + XiCon Loss:1.6090 x Lambda(0.001)), Vali MSE Loss: 0.1185 Test MSE Loss: 0.6624
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6121649742126465
Epoch: 7, Steps: 37 Train Loss: 0.1437 (Forecasting Loss:0.1421 + XiCon Loss:1.6169 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6676
Validation loss decreased (0.116951 --> 0.116348).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7298109531402588
Epoch: 8, Steps: 37 Train Loss: 0.1432 (Forecasting Loss:0.1416 + XiCon Loss:1.6141 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6719
Validation loss decreased (0.116348 --> 0.115884).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6252248287200928
Epoch: 9, Steps: 37 Train Loss: 0.1430 (Forecasting Loss:0.1414 + XiCon Loss:1.6175 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6718
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6771624088287354
Epoch: 10, Steps: 37 Train Loss: 0.1415 (Forecasting Loss:0.1399 + XiCon Loss:1.6151 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6717
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6417121887207031
Epoch: 11, Steps: 37 Train Loss: 0.1418 (Forecasting Loss:0.1402 + XiCon Loss:1.6149 x Lambda(0.001)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6720
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6802501678466797
Epoch: 12, Steps: 37 Train Loss: 0.1425 (Forecasting Loss:0.1409 + XiCon Loss:1.6138 x Lambda(0.001)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6720
Validation loss decreased (0.115884 --> 0.115704).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7168064117431641
Epoch: 13, Steps: 37 Train Loss: 0.1409 (Forecasting Loss:0.1393 + XiCon Loss:1.6116 x Lambda(0.001)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6720
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7364847660064697
Epoch: 14, Steps: 37 Train Loss: 0.1413 (Forecasting Loss:0.1397 + XiCon Loss:1.6137 x Lambda(0.001)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6720
Validation loss decreased (0.115704 --> 0.114260).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7474269866943359
Epoch: 15, Steps: 37 Train Loss: 0.1416 (Forecasting Loss:0.1400 + XiCon Loss:1.6118 x Lambda(0.001)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6356384754180908
Epoch: 16, Steps: 37 Train Loss: 0.1410 (Forecasting Loss:0.1394 + XiCon Loss:1.6065 x Lambda(0.001)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.6721
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.751854419708252
Epoch: 17, Steps: 37 Train Loss: 0.1415 (Forecasting Loss:0.1399 + XiCon Loss:1.6146 x Lambda(0.001)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6721
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7016265392303467
Epoch: 18, Steps: 37 Train Loss: 0.1420 (Forecasting Loss:0.1404 + XiCon Loss:1.6084 x Lambda(0.001)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6721
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7149491310119629
Epoch: 19, Steps: 37 Train Loss: 0.1420 (Forecasting Loss:0.1404 + XiCon Loss:1.6164 x Lambda(0.001)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6721
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.728243350982666
Epoch: 20, Steps: 37 Train Loss: 0.1413 (Forecasting Loss:0.1397 + XiCon Loss:1.6091 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6721
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.728309154510498
Epoch: 21, Steps: 37 Train Loss: 0.1424 (Forecasting Loss:0.1408 + XiCon Loss:1.6117 x Lambda(0.001)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6721
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6431684494018555
Epoch: 22, Steps: 37 Train Loss: 0.1419 (Forecasting Loss:0.1403 + XiCon Loss:1.6118 x Lambda(0.001)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.6721
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7191781997680664
Epoch: 23, Steps: 37 Train Loss: 0.1418 (Forecasting Loss:0.1401 + XiCon Loss:1.6107 x Lambda(0.001)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6721
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.729588508605957
Epoch: 24, Steps: 37 Train Loss: 0.1421 (Forecasting Loss:0.1404 + XiCon Loss:1.6116 x Lambda(0.001)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6721
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7319136261940002, mae:0.6121494174003601, mape:0.2429133802652359, mspe:0.21117982268333435 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3341
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6851041316986084
Epoch: 1, Steps: 37 Train Loss: 0.5079 (Forecasting Loss:0.5063 + XiCon Loss:1.6109 x Lambda(0.001)), Vali MSE Loss: 0.3097 Test MSE Loss: 1.2669
Validation loss decreased (inf --> 0.309719).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7182643413543701
Epoch: 2, Steps: 37 Train Loss: 0.2858 (Forecasting Loss:0.2842 + XiCon Loss:1.6154 x Lambda(0.001)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.6923
Validation loss decreased (0.309719 --> 0.210956).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7813882827758789
Epoch: 3, Steps: 37 Train Loss: 0.1981 (Forecasting Loss:0.1964 + XiCon Loss:1.6466 x Lambda(0.001)), Vali MSE Loss: 0.1353 Test MSE Loss: 0.7194
Validation loss decreased (0.210956 --> 0.135254).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7145495414733887
Epoch: 4, Steps: 37 Train Loss: 0.1623 (Forecasting Loss:0.1606 + XiCon Loss:1.6474 x Lambda(0.001)), Vali MSE Loss: 0.1191 Test MSE Loss: 0.6861
Validation loss decreased (0.135254 --> 0.119141).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6921901702880859
Epoch: 5, Steps: 37 Train Loss: 0.1520 (Forecasting Loss:0.1503 + XiCon Loss:1.6450 x Lambda(0.001)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6735
Validation loss decreased (0.119141 --> 0.116913).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7539560794830322
Epoch: 6, Steps: 37 Train Loss: 0.1484 (Forecasting Loss:0.1468 + XiCon Loss:1.6546 x Lambda(0.001)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6656
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7615878582000732
Epoch: 7, Steps: 37 Train Loss: 0.1473 (Forecasting Loss:0.1456 + XiCon Loss:1.6557 x Lambda(0.001)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6639
Validation loss decreased (0.116913 --> 0.116074).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7209534645080566
Epoch: 8, Steps: 37 Train Loss: 0.1453 (Forecasting Loss:0.1436 + XiCon Loss:1.6496 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6670
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6310503482818604
Epoch: 9, Steps: 37 Train Loss: 0.1447 (Forecasting Loss:0.1430 + XiCon Loss:1.6503 x Lambda(0.001)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6689
Validation loss decreased (0.116074 --> 0.115972).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7592427730560303
Epoch: 10, Steps: 37 Train Loss: 0.1457 (Forecasting Loss:0.1440 + XiCon Loss:1.6504 x Lambda(0.001)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.6686
Validation loss decreased (0.115972 --> 0.114955).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.754835844039917
Epoch: 11, Steps: 37 Train Loss: 0.1454 (Forecasting Loss:0.1438 + XiCon Loss:1.6480 x Lambda(0.001)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.6687
Validation loss decreased (0.114955 --> 0.114171).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7561681270599365
Epoch: 12, Steps: 37 Train Loss: 0.1454 (Forecasting Loss:0.1438 + XiCon Loss:1.6512 x Lambda(0.001)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6688
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6688873767852783
Epoch: 13, Steps: 37 Train Loss: 0.1452 (Forecasting Loss:0.1435 + XiCon Loss:1.6511 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6686
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.708930492401123
Epoch: 14, Steps: 37 Train Loss: 0.1450 (Forecasting Loss:0.1434 + XiCon Loss:1.6499 x Lambda(0.001)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6686
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7347314357757568
Epoch: 15, Steps: 37 Train Loss: 0.1452 (Forecasting Loss:0.1436 + XiCon Loss:1.6503 x Lambda(0.001)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6686
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7326505184173584
Epoch: 16, Steps: 37 Train Loss: 0.1452 (Forecasting Loss:0.1435 + XiCon Loss:1.6519 x Lambda(0.001)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6686
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.633965253829956
Epoch: 17, Steps: 37 Train Loss: 0.1457 (Forecasting Loss:0.1441 + XiCon Loss:1.6487 x Lambda(0.001)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.6686
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7196660041809082
Epoch: 18, Steps: 37 Train Loss: 0.1444 (Forecasting Loss:0.1428 + XiCon Loss:1.6454 x Lambda(0.001)), Vali MSE Loss: 0.1172 Test MSE Loss: 0.6686
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6664400100708008
Epoch: 19, Steps: 37 Train Loss: 0.1449 (Forecasting Loss:0.1433 + XiCon Loss:1.6501 x Lambda(0.001)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6686
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7270758152008057
Epoch: 20, Steps: 37 Train Loss: 0.1450 (Forecasting Loss:0.1433 + XiCon Loss:1.6505 x Lambda(0.001)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6686
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7306711673736572
Epoch: 21, Steps: 37 Train Loss: 0.1435 (Forecasting Loss:0.1418 + XiCon Loss:1.6523 x Lambda(0.001)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6686
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7262684106826782, mae:0.6110736727714539, mape:0.24269726872444153, mspe:0.20823758840560913 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7222+-0.01677, MAE:0.6160+-0.00848, MAPE:0.2437+-0.00317, MSPE:0.2055+-0.00540, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2761
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.9525063037872314
Epoch: 1, Steps: 35 Train Loss: 0.4735 (Forecasting Loss:0.4719 + XiCon Loss:1.6250 x Lambda(0.001)), Vali MSE Loss: 0.3098 Test MSE Loss: 1.1661
Validation loss decreased (inf --> 0.309822).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6453144550323486
Epoch: 2, Steps: 35 Train Loss: 0.3196 (Forecasting Loss:0.3179 + XiCon Loss:1.6340 x Lambda(0.001)), Vali MSE Loss: 0.1892 Test MSE Loss: 0.6864
Validation loss decreased (0.309822 --> 0.189244).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6575927734375
Epoch: 3, Steps: 35 Train Loss: 0.2055 (Forecasting Loss:0.2038 + XiCon Loss:1.6428 x Lambda(0.001)), Vali MSE Loss: 0.1543 Test MSE Loss: 0.7285
Validation loss decreased (0.189244 --> 0.154319).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6673760414123535
Epoch: 4, Steps: 35 Train Loss: 0.1669 (Forecasting Loss:0.1653 + XiCon Loss:1.6545 x Lambda(0.001)), Vali MSE Loss: 0.1549 Test MSE Loss: 0.6330
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6771070957183838
Epoch: 5, Steps: 35 Train Loss: 0.1638 (Forecasting Loss:0.1621 + XiCon Loss:1.6561 x Lambda(0.001)), Vali MSE Loss: 0.1510 Test MSE Loss: 0.6424
Validation loss decreased (0.154319 --> 0.151040).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5919382572174072
Epoch: 6, Steps: 35 Train Loss: 0.1538 (Forecasting Loss:0.1521 + XiCon Loss:1.6537 x Lambda(0.001)), Vali MSE Loss: 0.1498 Test MSE Loss: 0.7181
Validation loss decreased (0.151040 --> 0.149815).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7040719985961914
Epoch: 7, Steps: 35 Train Loss: 0.1481 (Forecasting Loss:0.1464 + XiCon Loss:1.6537 x Lambda(0.001)), Vali MSE Loss: 0.1513 Test MSE Loss: 0.6903
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7090408802032471
Epoch: 8, Steps: 35 Train Loss: 0.1473 (Forecasting Loss:0.1456 + XiCon Loss:1.6516 x Lambda(0.001)), Vali MSE Loss: 0.1514 Test MSE Loss: 0.7012
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.697493314743042
Epoch: 9, Steps: 35 Train Loss: 0.1466 (Forecasting Loss:0.1450 + XiCon Loss:1.6538 x Lambda(0.001)), Vali MSE Loss: 0.1522 Test MSE Loss: 0.7060
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6524949073791504
Epoch: 10, Steps: 35 Train Loss: 0.1465 (Forecasting Loss:0.1448 + XiCon Loss:1.6556 x Lambda(0.001)), Vali MSE Loss: 0.1509 Test MSE Loss: 0.7040
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6619815826416016
Epoch: 11, Steps: 35 Train Loss: 0.1464 (Forecasting Loss:0.1447 + XiCon Loss:1.6535 x Lambda(0.001)), Vali MSE Loss: 0.1521 Test MSE Loss: 0.7045
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6828370094299316
Epoch: 12, Steps: 35 Train Loss: 0.1464 (Forecasting Loss:0.1447 + XiCon Loss:1.6542 x Lambda(0.001)), Vali MSE Loss: 0.1521 Test MSE Loss: 0.7045
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6587409973144531
Epoch: 13, Steps: 35 Train Loss: 0.1458 (Forecasting Loss:0.1441 + XiCon Loss:1.6497 x Lambda(0.001)), Vali MSE Loss: 0.1511 Test MSE Loss: 0.7046
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6886646747589111
Epoch: 14, Steps: 35 Train Loss: 0.1463 (Forecasting Loss:0.1446 + XiCon Loss:1.6554 x Lambda(0.001)), Vali MSE Loss: 0.1502 Test MSE Loss: 0.7047
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.670804500579834
Epoch: 15, Steps: 35 Train Loss: 0.1460 (Forecasting Loss:0.1443 + XiCon Loss:1.6551 x Lambda(0.001)), Vali MSE Loss: 0.1524 Test MSE Loss: 0.7047
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6481590270996094
Epoch: 16, Steps: 35 Train Loss: 0.1463 (Forecasting Loss:0.1447 + XiCon Loss:1.6514 x Lambda(0.001)), Vali MSE Loss: 0.1524 Test MSE Loss: 0.7047
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7377451658248901, mae:0.6985364556312561, mape:0.2579696774482727, mspe:0.16670185327529907 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3357
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6330091953277588
Epoch: 1, Steps: 35 Train Loss: 0.4737 (Forecasting Loss:0.4721 + XiCon Loss:1.6264 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 1.1518
Validation loss decreased (inf --> 0.318241).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7322096824645996
Epoch: 2, Steps: 35 Train Loss: 0.3104 (Forecasting Loss:0.3088 + XiCon Loss:1.6335 x Lambda(0.001)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.6637
Validation loss decreased (0.318241 --> 0.210840).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7952263355255127
Epoch: 3, Steps: 35 Train Loss: 0.2050 (Forecasting Loss:0.2034 + XiCon Loss:1.6239 x Lambda(0.001)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.7550
Validation loss decreased (0.210840 --> 0.142040).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7816486358642578
Epoch: 4, Steps: 35 Train Loss: 0.1700 (Forecasting Loss:0.1683 + XiCon Loss:1.6275 x Lambda(0.001)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.7541
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7118575572967529
Epoch: 5, Steps: 35 Train Loss: 0.1497 (Forecasting Loss:0.1481 + XiCon Loss:1.6251 x Lambda(0.001)), Vali MSE Loss: 0.1601 Test MSE Loss: 0.7577
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7066845893859863
Epoch: 6, Steps: 35 Train Loss: 0.1404 (Forecasting Loss:0.1387 + XiCon Loss:1.6138 x Lambda(0.001)), Vali MSE Loss: 0.1612 Test MSE Loss: 0.7526
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6838090419769287
Epoch: 7, Steps: 35 Train Loss: 0.1343 (Forecasting Loss:0.1327 + XiCon Loss:1.6187 x Lambda(0.001)), Vali MSE Loss: 0.1593 Test MSE Loss: 0.7820
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7169461250305176
Epoch: 8, Steps: 35 Train Loss: 0.1316 (Forecasting Loss:0.1300 + XiCon Loss:1.6222 x Lambda(0.001)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.7730
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6359188556671143
Epoch: 9, Steps: 35 Train Loss: 0.1309 (Forecasting Loss:0.1293 + XiCon Loss:1.6231 x Lambda(0.001)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.7800
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7126286029815674
Epoch: 10, Steps: 35 Train Loss: 0.1305 (Forecasting Loss:0.1289 + XiCon Loss:1.6211 x Lambda(0.001)), Vali MSE Loss: 0.1596 Test MSE Loss: 0.7779
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6916816234588623
Epoch: 11, Steps: 35 Train Loss: 0.1298 (Forecasting Loss:0.1282 + XiCon Loss:1.6157 x Lambda(0.001)), Vali MSE Loss: 0.1604 Test MSE Loss: 0.7788
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6567120552062988
Epoch: 12, Steps: 35 Train Loss: 0.1293 (Forecasting Loss:0.1277 + XiCon Loss:1.6211 x Lambda(0.001)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.7793
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6082432270050049
Epoch: 13, Steps: 35 Train Loss: 0.1294 (Forecasting Loss:0.1278 + XiCon Loss:1.6143 x Lambda(0.001)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.7794
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7761527895927429, mae:0.7337751984596252, mape:0.2810762822628021, mspe:0.18746399879455566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3451
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6433212757110596
Epoch: 1, Steps: 35 Train Loss: 0.4389 (Forecasting Loss:0.4373 + XiCon Loss:1.6172 x Lambda(0.001)), Vali MSE Loss: 0.3665 Test MSE Loss: 0.9070
Validation loss decreased (inf --> 0.366514).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5865998268127441
Epoch: 2, Steps: 35 Train Loss: 0.3070 (Forecasting Loss:0.3054 + XiCon Loss:1.6188 x Lambda(0.001)), Vali MSE Loss: 0.1780 Test MSE Loss: 0.7604
Validation loss decreased (0.366514 --> 0.177972).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7355451583862305
Epoch: 3, Steps: 35 Train Loss: 0.1894 (Forecasting Loss:0.1878 + XiCon Loss:1.6370 x Lambda(0.001)), Vali MSE Loss: 0.1775 Test MSE Loss: 0.6493
Validation loss decreased (0.177972 --> 0.177539).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5951833724975586
Epoch: 4, Steps: 35 Train Loss: 0.1548 (Forecasting Loss:0.1532 + XiCon Loss:1.6353 x Lambda(0.001)), Vali MSE Loss: 0.1541 Test MSE Loss: 0.6466
Validation loss decreased (0.177539 --> 0.154106).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6783609390258789
Epoch: 5, Steps: 35 Train Loss: 0.1397 (Forecasting Loss:0.1381 + XiCon Loss:1.6401 x Lambda(0.001)), Vali MSE Loss: 0.1514 Test MSE Loss: 0.6830
Validation loss decreased (0.154106 --> 0.151425).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7598800659179688
Epoch: 6, Steps: 35 Train Loss: 0.1300 (Forecasting Loss:0.1284 + XiCon Loss:1.6324 x Lambda(0.001)), Vali MSE Loss: 0.1401 Test MSE Loss: 0.6525
Validation loss decreased (0.151425 --> 0.140052).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7144427299499512
Epoch: 7, Steps: 35 Train Loss: 0.1251 (Forecasting Loss:0.1235 + XiCon Loss:1.6310 x Lambda(0.001)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.6630
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6209161281585693
Epoch: 8, Steps: 35 Train Loss: 0.1231 (Forecasting Loss:0.1215 + XiCon Loss:1.6300 x Lambda(0.001)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.6497
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.725351095199585
Epoch: 9, Steps: 35 Train Loss: 0.1219 (Forecasting Loss:0.1203 + XiCon Loss:1.6366 x Lambda(0.001)), Vali MSE Loss: 0.1455 Test MSE Loss: 0.6520
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7086341381072998
Epoch: 10, Steps: 35 Train Loss: 0.1210 (Forecasting Loss:0.1193 + XiCon Loss:1.6288 x Lambda(0.001)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.6546
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6467299461364746
Epoch: 11, Steps: 35 Train Loss: 0.1209 (Forecasting Loss:0.1193 + XiCon Loss:1.6312 x Lambda(0.001)), Vali MSE Loss: 0.1407 Test MSE Loss: 0.6538
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6485791206359863
Epoch: 12, Steps: 35 Train Loss: 0.1207 (Forecasting Loss:0.1190 + XiCon Loss:1.6295 x Lambda(0.001)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.6534
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6097874641418457
Epoch: 13, Steps: 35 Train Loss: 0.1209 (Forecasting Loss:0.1192 + XiCon Loss:1.6363 x Lambda(0.001)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.6534
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6788623332977295
Epoch: 14, Steps: 35 Train Loss: 0.1207 (Forecasting Loss:0.1191 + XiCon Loss:1.6324 x Lambda(0.001)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.6537
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6774177551269531
Epoch: 15, Steps: 35 Train Loss: 0.1209 (Forecasting Loss:0.1192 + XiCon Loss:1.6321 x Lambda(0.001)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.6538
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6296055316925049
Epoch: 16, Steps: 35 Train Loss: 0.1205 (Forecasting Loss:0.1189 + XiCon Loss:1.6315 x Lambda(0.001)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.6537
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6641991138458252, mae:0.6408882737159729, mape:0.24819108843803406, mspe:0.17911383509635925 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3417
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7412679195404053
Epoch: 1, Steps: 35 Train Loss: 0.4600 (Forecasting Loss:0.4584 + XiCon Loss:1.6206 x Lambda(0.001)), Vali MSE Loss: 0.3078 Test MSE Loss: 1.1818
Validation loss decreased (inf --> 0.307842).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6773662567138672
Epoch: 2, Steps: 35 Train Loss: 0.3244 (Forecasting Loss:0.3228 + XiCon Loss:1.6127 x Lambda(0.001)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.7738
Validation loss decreased (0.307842 --> 0.184093).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6780118942260742
Epoch: 3, Steps: 35 Train Loss: 0.1991 (Forecasting Loss:0.1974 + XiCon Loss:1.6115 x Lambda(0.001)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.6702
Validation loss decreased (0.184093 --> 0.172260).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6993284225463867
Epoch: 4, Steps: 35 Train Loss: 0.1505 (Forecasting Loss:0.1489 + XiCon Loss:1.6015 x Lambda(0.001)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.6650
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6503772735595703
Epoch: 5, Steps: 35 Train Loss: 0.1306 (Forecasting Loss:0.1290 + XiCon Loss:1.5965 x Lambda(0.001)), Vali MSE Loss: 0.1568 Test MSE Loss: 0.6931
Validation loss decreased (0.172260 --> 0.156795).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7064690589904785
Epoch: 6, Steps: 35 Train Loss: 0.1188 (Forecasting Loss:0.1172 + XiCon Loss:1.5887 x Lambda(0.001)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.6403
Validation loss decreased (0.156795 --> 0.148246).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6343333721160889
Epoch: 7, Steps: 35 Train Loss: 0.1146 (Forecasting Loss:0.1130 + XiCon Loss:1.5802 x Lambda(0.001)), Vali MSE Loss: 0.1605 Test MSE Loss: 0.6455
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6856307983398438
Epoch: 8, Steps: 35 Train Loss: 0.1128 (Forecasting Loss:0.1113 + XiCon Loss:1.5863 x Lambda(0.001)), Vali MSE Loss: 0.1528 Test MSE Loss: 0.6710
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6802787780761719
Epoch: 9, Steps: 35 Train Loss: 0.1116 (Forecasting Loss:0.1100 + XiCon Loss:1.5821 x Lambda(0.001)), Vali MSE Loss: 0.1562 Test MSE Loss: 0.6435
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5780549049377441
Epoch: 10, Steps: 35 Train Loss: 0.1111 (Forecasting Loss:0.1095 + XiCon Loss:1.5850 x Lambda(0.001)), Vali MSE Loss: 0.1564 Test MSE Loss: 0.6558
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6733756065368652
Epoch: 11, Steps: 35 Train Loss: 0.1106 (Forecasting Loss:0.1090 + XiCon Loss:1.5838 x Lambda(0.001)), Vali MSE Loss: 0.1558 Test MSE Loss: 0.6577
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6174519062042236
Epoch: 12, Steps: 35 Train Loss: 0.1102 (Forecasting Loss:0.1086 + XiCon Loss:1.5859 x Lambda(0.001)), Vali MSE Loss: 0.1557 Test MSE Loss: 0.6559
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.626314640045166
Epoch: 13, Steps: 35 Train Loss: 0.1115 (Forecasting Loss:0.1099 + XiCon Loss:1.5884 x Lambda(0.001)), Vali MSE Loss: 0.1550 Test MSE Loss: 0.6567
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6896820068359375
Epoch: 14, Steps: 35 Train Loss: 0.1110 (Forecasting Loss:0.1094 + XiCon Loss:1.5788 x Lambda(0.001)), Vali MSE Loss: 0.1548 Test MSE Loss: 0.6569
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6991791725158691
Epoch: 15, Steps: 35 Train Loss: 0.1108 (Forecasting Loss:0.1093 + XiCon Loss:1.5848 x Lambda(0.001)), Vali MSE Loss: 0.1556 Test MSE Loss: 0.6570
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6396145820617676
Epoch: 16, Steps: 35 Train Loss: 0.1112 (Forecasting Loss:0.1096 + XiCon Loss:1.5812 x Lambda(0.001)), Vali MSE Loss: 0.1562 Test MSE Loss: 0.6570
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6521627306938171, mae:0.628350019454956, mape:0.24267424643039703, mspe:0.1729040890932083 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3389
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.5840625762939453
Epoch: 1, Steps: 35 Train Loss: 0.4625 (Forecasting Loss:0.4609 + XiCon Loss:1.6250 x Lambda(0.001)), Vali MSE Loss: 0.3610 Test MSE Loss: 1.0277
Validation loss decreased (inf --> 0.360961).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5954113006591797
Epoch: 2, Steps: 35 Train Loss: 0.3575 (Forecasting Loss:0.3559 + XiCon Loss:1.6371 x Lambda(0.001)), Vali MSE Loss: 0.1868 Test MSE Loss: 0.7509
Validation loss decreased (0.360961 --> 0.186837).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.588726282119751
Epoch: 3, Steps: 35 Train Loss: 0.2115 (Forecasting Loss:0.2098 + XiCon Loss:1.6482 x Lambda(0.001)), Vali MSE Loss: 0.1578 Test MSE Loss: 0.7000
Validation loss decreased (0.186837 --> 0.157838).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7203009128570557
Epoch: 4, Steps: 35 Train Loss: 0.1798 (Forecasting Loss:0.1782 + XiCon Loss:1.6410 x Lambda(0.001)), Vali MSE Loss: 0.1395 Test MSE Loss: 0.6901
Validation loss decreased (0.157838 --> 0.139495).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6996591091156006
Epoch: 5, Steps: 35 Train Loss: 0.1622 (Forecasting Loss:0.1605 + XiCon Loss:1.6334 x Lambda(0.001)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.6663
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6428189277648926
Epoch: 6, Steps: 35 Train Loss: 0.1545 (Forecasting Loss:0.1528 + XiCon Loss:1.6298 x Lambda(0.001)), Vali MSE Loss: 0.1601 Test MSE Loss: 0.6227
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.680936336517334
Epoch: 7, Steps: 35 Train Loss: 0.1468 (Forecasting Loss:0.1451 + XiCon Loss:1.6305 x Lambda(0.001)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.6478
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7186200618743896
Epoch: 8, Steps: 35 Train Loss: 0.1416 (Forecasting Loss:0.1399 + XiCon Loss:1.6246 x Lambda(0.001)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.6193
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6364481449127197
Epoch: 9, Steps: 35 Train Loss: 0.1382 (Forecasting Loss:0.1366 + XiCon Loss:1.6259 x Lambda(0.001)), Vali MSE Loss: 0.1603 Test MSE Loss: 0.6330
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6675989627838135
Epoch: 10, Steps: 35 Train Loss: 0.1373 (Forecasting Loss:0.1356 + XiCon Loss:1.6291 x Lambda(0.001)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.6213
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6584491729736328
Epoch: 11, Steps: 35 Train Loss: 0.1362 (Forecasting Loss:0.1345 + XiCon Loss:1.6257 x Lambda(0.001)), Vali MSE Loss: 0.1613 Test MSE Loss: 0.6224
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6288375854492188
Epoch: 12, Steps: 35 Train Loss: 0.1360 (Forecasting Loss:0.1343 + XiCon Loss:1.6292 x Lambda(0.001)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.6238
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.696911096572876
Epoch: 13, Steps: 35 Train Loss: 0.1363 (Forecasting Loss:0.1346 + XiCon Loss:1.6296 x Lambda(0.001)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.6240
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.683340311050415
Epoch: 14, Steps: 35 Train Loss: 0.1360 (Forecasting Loss:0.1343 + XiCon Loss:1.6261 x Lambda(0.001)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.6238
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7105194926261902, mae:0.669739305973053, mape:0.2598695158958435, mspe:0.18778756260871887 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7082+-0.06383, MAE:0.6743+-0.05331, MAPE:0.2580+-0.01828, MSPE:0.1788+-0.01140, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.95, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2237
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.9070470333099365
Epoch: 1, Steps: 30 Train Loss: 0.6349 (Forecasting Loss:0.6333 + XiCon Loss:1.6246 x Lambda(0.001)), Vali MSE Loss: 0.4207 Test MSE Loss: 1.5995
Validation loss decreased (inf --> 0.420721).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5898754596710205
Epoch: 2, Steps: 30 Train Loss: 0.4337 (Forecasting Loss:0.4321 + XiCon Loss:1.6012 x Lambda(0.001)), Vali MSE Loss: 0.3084 Test MSE Loss: 1.1463
Validation loss decreased (0.420721 --> 0.308433).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6300580501556396
Epoch: 3, Steps: 30 Train Loss: 0.2672 (Forecasting Loss:0.2656 + XiCon Loss:1.5971 x Lambda(0.001)), Vali MSE Loss: 0.3078 Test MSE Loss: 1.2716
Validation loss decreased (0.308433 --> 0.307841).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5895564556121826
Epoch: 4, Steps: 30 Train Loss: 0.2204 (Forecasting Loss:0.2188 + XiCon Loss:1.5957 x Lambda(0.001)), Vali MSE Loss: 0.3022 Test MSE Loss: 1.1970
Validation loss decreased (0.307841 --> 0.302205).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6253407001495361
Epoch: 5, Steps: 30 Train Loss: 0.1982 (Forecasting Loss:0.1967 + XiCon Loss:1.5731 x Lambda(0.001)), Vali MSE Loss: 0.3825 Test MSE Loss: 0.9711
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5845785140991211
Epoch: 6, Steps: 30 Train Loss: 0.1922 (Forecasting Loss:0.1906 + XiCon Loss:1.5910 x Lambda(0.001)), Vali MSE Loss: 0.4035 Test MSE Loss: 0.9232
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.595858097076416
Epoch: 7, Steps: 30 Train Loss: 0.1879 (Forecasting Loss:0.1863 + XiCon Loss:1.5869 x Lambda(0.001)), Vali MSE Loss: 0.3309 Test MSE Loss: 1.0470
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5729224681854248
Epoch: 8, Steps: 30 Train Loss: 0.1838 (Forecasting Loss:0.1822 + XiCon Loss:1.5853 x Lambda(0.001)), Vali MSE Loss: 0.3692 Test MSE Loss: 0.9993
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6139514446258545
Epoch: 9, Steps: 30 Train Loss: 0.1839 (Forecasting Loss:0.1823 + XiCon Loss:1.5837 x Lambda(0.001)), Vali MSE Loss: 0.3624 Test MSE Loss: 0.9987
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.557204008102417
Epoch: 10, Steps: 30 Train Loss: 0.1817 (Forecasting Loss:0.1801 + XiCon Loss:1.5919 x Lambda(0.001)), Vali MSE Loss: 0.3634 Test MSE Loss: 1.0040
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5884976387023926
Epoch: 11, Steps: 30 Train Loss: 0.1819 (Forecasting Loss:0.1803 + XiCon Loss:1.5770 x Lambda(0.001)), Vali MSE Loss: 0.3568 Test MSE Loss: 1.0113
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5815975666046143
Epoch: 12, Steps: 30 Train Loss: 0.1813 (Forecasting Loss:0.1797 + XiCon Loss:1.5815 x Lambda(0.001)), Vali MSE Loss: 0.3544 Test MSE Loss: 1.0079
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5658760070800781
Epoch: 13, Steps: 30 Train Loss: 0.1812 (Forecasting Loss:0.1796 + XiCon Loss:1.5883 x Lambda(0.001)), Vali MSE Loss: 0.3536 Test MSE Loss: 1.0071
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5875833034515381
Epoch: 14, Steps: 30 Train Loss: 0.1802 (Forecasting Loss:0.1786 + XiCon Loss:1.5940 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 1.0071
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.378441572189331, mae:1.0156002044677734, mape:0.3246031403541565, mspe:0.1459510773420334 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5804173946380615
Epoch: 1, Steps: 30 Train Loss: 0.6670 (Forecasting Loss:0.6653 + XiCon Loss:1.6152 x Lambda(0.001)), Vali MSE Loss: 0.3696 Test MSE Loss: 1.4782
Validation loss decreased (inf --> 0.369625).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5894062519073486
Epoch: 2, Steps: 30 Train Loss: 1.6008 (Forecasting Loss:1.5992 + XiCon Loss:1.6428 x Lambda(0.001)), Vali MSE Loss: 0.2396 Test MSE Loss: 1.2432
Validation loss decreased (0.369625 --> 0.239572).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6578047275543213
Epoch: 3, Steps: 30 Train Loss: 0.3659 (Forecasting Loss:0.3642 + XiCon Loss:1.6430 x Lambda(0.001)), Vali MSE Loss: 0.1901 Test MSE Loss: 1.1704
Validation loss decreased (0.239572 --> 0.190129).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6846833229064941
Epoch: 4, Steps: 30 Train Loss: 0.3382 (Forecasting Loss:0.3366 + XiCon Loss:1.6497 x Lambda(0.001)), Vali MSE Loss: 0.1667 Test MSE Loss: 1.2416
Validation loss decreased (0.190129 --> 0.166740).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.655853271484375
Epoch: 5, Steps: 30 Train Loss: 0.3173 (Forecasting Loss:0.3157 + XiCon Loss:1.6477 x Lambda(0.001)), Vali MSE Loss: 0.1555 Test MSE Loss: 1.2596
Validation loss decreased (0.166740 --> 0.155504).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5852696895599365
Epoch: 6, Steps: 30 Train Loss: 0.3147 (Forecasting Loss:0.3130 + XiCon Loss:1.6519 x Lambda(0.001)), Vali MSE Loss: 0.1558 Test MSE Loss: 1.2657
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.555609941482544
Epoch: 7, Steps: 30 Train Loss: 0.3107 (Forecasting Loss:0.3091 + XiCon Loss:1.6461 x Lambda(0.001)), Vali MSE Loss: 0.1564 Test MSE Loss: 1.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6199109554290771
Epoch: 8, Steps: 30 Train Loss: 0.3109 (Forecasting Loss:0.3093 + XiCon Loss:1.6459 x Lambda(0.001)), Vali MSE Loss: 0.1503 Test MSE Loss: 1.2692
Validation loss decreased (0.155504 --> 0.150276).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5880508422851562
Epoch: 9, Steps: 30 Train Loss: 0.3072 (Forecasting Loss:0.3055 + XiCon Loss:1.6483 x Lambda(0.001)), Vali MSE Loss: 0.1527 Test MSE Loss: 1.2683
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6652522087097168
Epoch: 10, Steps: 30 Train Loss: 0.3081 (Forecasting Loss:0.3065 + XiCon Loss:1.6510 x Lambda(0.001)), Vali MSE Loss: 0.1497 Test MSE Loss: 1.2680
Validation loss decreased (0.150276 --> 0.149670).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.575594425201416
Epoch: 11, Steps: 30 Train Loss: 0.3088 (Forecasting Loss:0.3071 + XiCon Loss:1.6487 x Lambda(0.001)), Vali MSE Loss: 0.1560 Test MSE Loss: 1.2680
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5559849739074707
Epoch: 12, Steps: 30 Train Loss: 0.3087 (Forecasting Loss:0.3071 + XiCon Loss:1.6465 x Lambda(0.001)), Vali MSE Loss: 0.1546 Test MSE Loss: 1.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.623997688293457
Epoch: 13, Steps: 30 Train Loss: 0.3086 (Forecasting Loss:0.3069 + XiCon Loss:1.6529 x Lambda(0.001)), Vali MSE Loss: 0.1536 Test MSE Loss: 1.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5975933074951172
Epoch: 14, Steps: 30 Train Loss: 0.3083 (Forecasting Loss:0.3066 + XiCon Loss:1.6545 x Lambda(0.001)), Vali MSE Loss: 0.1523 Test MSE Loss: 1.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6621212959289551
Epoch: 15, Steps: 30 Train Loss: 0.3056 (Forecasting Loss:0.3039 + XiCon Loss:1.6521 x Lambda(0.001)), Vali MSE Loss: 0.1543 Test MSE Loss: 1.2682
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.5718269348144531
Epoch: 16, Steps: 30 Train Loss: 0.3073 (Forecasting Loss:0.3056 + XiCon Loss:1.6486 x Lambda(0.001)), Vali MSE Loss: 0.1555 Test MSE Loss: 1.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6133537292480469
Epoch: 17, Steps: 30 Train Loss: 0.3099 (Forecasting Loss:0.3082 + XiCon Loss:1.6439 x Lambda(0.001)), Vali MSE Loss: 0.1525 Test MSE Loss: 1.2681
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.5842173099517822
Epoch: 18, Steps: 30 Train Loss: 0.3080 (Forecasting Loss:0.3063 + XiCon Loss:1.6452 x Lambda(0.001)), Vali MSE Loss: 0.1509 Test MSE Loss: 1.2681
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.5829422473907471
Epoch: 19, Steps: 30 Train Loss: 0.3087 (Forecasting Loss:0.3070 + XiCon Loss:1.6545 x Lambda(0.001)), Vali MSE Loss: 0.1532 Test MSE Loss: 1.2681
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6214261054992676
Epoch: 20, Steps: 30 Train Loss: 0.3081 (Forecasting Loss:0.3064 + XiCon Loss:1.6502 x Lambda(0.001)), Vali MSE Loss: 0.1524 Test MSE Loss: 1.2681
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.4782733917236328, mae:1.0577183961868286, mape:0.3417133092880249, mspe:0.16294848918914795 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3373
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6073780059814453
Epoch: 1, Steps: 30 Train Loss: 0.6098 (Forecasting Loss:0.6081 + XiCon Loss:1.6347 x Lambda(0.001)), Vali MSE Loss: 0.3641 Test MSE Loss: 1.7590
Validation loss decreased (inf --> 0.364135).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6150758266448975
Epoch: 2, Steps: 30 Train Loss: 0.4171 (Forecasting Loss:0.4154 + XiCon Loss:1.6274 x Lambda(0.001)), Vali MSE Loss: 0.3122 Test MSE Loss: 1.0699
Validation loss decreased (0.364135 --> 0.312211).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5878751277923584
Epoch: 3, Steps: 30 Train Loss: 0.2726 (Forecasting Loss:0.2709 + XiCon Loss:1.6154 x Lambda(0.001)), Vali MSE Loss: 0.2307 Test MSE Loss: 1.2388
Validation loss decreased (0.312211 --> 0.230710).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6007730960845947
Epoch: 4, Steps: 30 Train Loss: 0.2237 (Forecasting Loss:0.2221 + XiCon Loss:1.6095 x Lambda(0.001)), Vali MSE Loss: 0.3575 Test MSE Loss: 1.2175
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6224732398986816
Epoch: 5, Steps: 30 Train Loss: 0.1911 (Forecasting Loss:0.1894 + XiCon Loss:1.6088 x Lambda(0.001)), Vali MSE Loss: 0.2372 Test MSE Loss: 1.4032
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.611586332321167
Epoch: 6, Steps: 30 Train Loss: 0.1778 (Forecasting Loss:0.1762 + XiCon Loss:1.5968 x Lambda(0.001)), Vali MSE Loss: 0.2896 Test MSE Loss: 1.2938
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6084246635437012
Epoch: 7, Steps: 30 Train Loss: 0.1711 (Forecasting Loss:0.1695 + XiCon Loss:1.5980 x Lambda(0.001)), Vali MSE Loss: 0.3395 Test MSE Loss: 1.2390
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6601564884185791
Epoch: 8, Steps: 30 Train Loss: 0.1663 (Forecasting Loss:0.1647 + XiCon Loss:1.5954 x Lambda(0.001)), Vali MSE Loss: 0.3235 Test MSE Loss: 1.2418
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6044495105743408
Epoch: 9, Steps: 30 Train Loss: 0.1645 (Forecasting Loss:0.1629 + XiCon Loss:1.5955 x Lambda(0.001)), Vali MSE Loss: 0.3268 Test MSE Loss: 1.2368
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6538023948669434
Epoch: 10, Steps: 30 Train Loss: 0.1633 (Forecasting Loss:0.1617 + XiCon Loss:1.5946 x Lambda(0.001)), Vali MSE Loss: 0.3237 Test MSE Loss: 1.2401
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6361362934112549
Epoch: 11, Steps: 30 Train Loss: 0.1631 (Forecasting Loss:0.1615 + XiCon Loss:1.6017 x Lambda(0.001)), Vali MSE Loss: 0.3304 Test MSE Loss: 1.2347
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6457107067108154
Epoch: 12, Steps: 30 Train Loss: 0.1628 (Forecasting Loss:0.1613 + XiCon Loss:1.5904 x Lambda(0.001)), Vali MSE Loss: 0.3321 Test MSE Loss: 1.2326
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5652933120727539
Epoch: 13, Steps: 30 Train Loss: 0.1629 (Forecasting Loss:0.1613 + XiCon Loss:1.5947 x Lambda(0.001)), Vali MSE Loss: 0.3313 Test MSE Loss: 1.2328
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.4335848093032837, mae:1.043990135192871, mape:0.332317590713501, mspe:0.14923180639743805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3351
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6194634437561035
Epoch: 1, Steps: 30 Train Loss: 0.6622 (Forecasting Loss:0.6606 + XiCon Loss:1.6154 x Lambda(0.001)), Vali MSE Loss: 0.4336 Test MSE Loss: 1.3449
Validation loss decreased (inf --> 0.433557).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5966851711273193
Epoch: 2, Steps: 30 Train Loss: 0.4484 (Forecasting Loss:0.4468 + XiCon Loss:1.6286 x Lambda(0.001)), Vali MSE Loss: 0.2239 Test MSE Loss: 1.3707
Validation loss decreased (0.433557 --> 0.223891).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6234080791473389
Epoch: 3, Steps: 30 Train Loss: 0.3184 (Forecasting Loss:0.3168 + XiCon Loss:1.6318 x Lambda(0.001)), Vali MSE Loss: 0.1939 Test MSE Loss: 1.2803
Validation loss decreased (0.223891 --> 0.193893).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6340701580047607
Epoch: 4, Steps: 30 Train Loss: 0.2649 (Forecasting Loss:0.2632 + XiCon Loss:1.6329 x Lambda(0.001)), Vali MSE Loss: 0.2537 Test MSE Loss: 1.1529
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6389930248260498
Epoch: 5, Steps: 30 Train Loss: 0.2263 (Forecasting Loss:0.2247 + XiCon Loss:1.6255 x Lambda(0.001)), Vali MSE Loss: 0.2552 Test MSE Loss: 1.1104
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5942931175231934
Epoch: 6, Steps: 30 Train Loss: 0.2030 (Forecasting Loss:0.2013 + XiCon Loss:1.6349 x Lambda(0.001)), Vali MSE Loss: 0.2828 Test MSE Loss: 1.0992
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6576159000396729
Epoch: 7, Steps: 30 Train Loss: 0.1900 (Forecasting Loss:0.1884 + XiCon Loss:1.6278 x Lambda(0.001)), Vali MSE Loss: 0.3108 Test MSE Loss: 1.0056
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.597132682800293
Epoch: 8, Steps: 30 Train Loss: 0.1842 (Forecasting Loss:0.1826 + XiCon Loss:1.6329 x Lambda(0.001)), Vali MSE Loss: 0.3422 Test MSE Loss: 0.9802
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.631758451461792
Epoch: 9, Steps: 30 Train Loss: 0.1801 (Forecasting Loss:0.1785 + XiCon Loss:1.6366 x Lambda(0.001)), Vali MSE Loss: 0.3194 Test MSE Loss: 1.0175
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5540516376495361
Epoch: 10, Steps: 30 Train Loss: 0.1761 (Forecasting Loss:0.1744 + XiCon Loss:1.6335 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 1.0012
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6218643188476562
Epoch: 11, Steps: 30 Train Loss: 0.1752 (Forecasting Loss:0.1736 + XiCon Loss:1.6337 x Lambda(0.001)), Vali MSE Loss: 0.3148 Test MSE Loss: 1.0030
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6867728233337402
Epoch: 12, Steps: 30 Train Loss: 0.1765 (Forecasting Loss:0.1749 + XiCon Loss:1.6341 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 1.0032
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.688539981842041
Epoch: 13, Steps: 30 Train Loss: 0.1749 (Forecasting Loss:0.1733 + XiCon Loss:1.6327 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 1.0031
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.5044175386428833, mae:1.056175947189331, mape:0.335296094417572, mspe:0.1551560014486313 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3167
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.593986988067627
Epoch: 1, Steps: 30 Train Loss: 0.5446 (Forecasting Loss:0.5429 + XiCon Loss:1.6182 x Lambda(0.001)), Vali MSE Loss: 0.3554 Test MSE Loss: 1.7628
Validation loss decreased (inf --> 0.355412).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6087713241577148
Epoch: 2, Steps: 30 Train Loss: 0.4053 (Forecasting Loss:0.4037 + XiCon Loss:1.6115 x Lambda(0.001)), Vali MSE Loss: 0.2594 Test MSE Loss: 1.2336
Validation loss decreased (0.355412 --> 0.259356).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5790140628814697
Epoch: 3, Steps: 30 Train Loss: 0.2472 (Forecasting Loss:0.2456 + XiCon Loss:1.6139 x Lambda(0.001)), Vali MSE Loss: 0.2998 Test MSE Loss: 1.1375
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5670816898345947
Epoch: 4, Steps: 30 Train Loss: 0.2091 (Forecasting Loss:0.2075 + XiCon Loss:1.6080 x Lambda(0.001)), Vali MSE Loss: 0.3903 Test MSE Loss: 0.9284
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.583627462387085
Epoch: 5, Steps: 30 Train Loss: 0.1861 (Forecasting Loss:0.1845 + XiCon Loss:1.6156 x Lambda(0.001)), Vali MSE Loss: 0.3510 Test MSE Loss: 0.9614
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5833883285522461
Epoch: 6, Steps: 30 Train Loss: 0.1772 (Forecasting Loss:0.1755 + XiCon Loss:1.6149 x Lambda(0.001)), Vali MSE Loss: 0.3495 Test MSE Loss: 0.9471
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6285433769226074
Epoch: 7, Steps: 30 Train Loss: 0.1698 (Forecasting Loss:0.1682 + XiCon Loss:1.6014 x Lambda(0.001)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.9845
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6242854595184326
Epoch: 8, Steps: 30 Train Loss: 0.1650 (Forecasting Loss:0.1634 + XiCon Loss:1.6139 x Lambda(0.001)), Vali MSE Loss: 0.3263 Test MSE Loss: 0.9441
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6689021587371826
Epoch: 9, Steps: 30 Train Loss: 0.1637 (Forecasting Loss:0.1621 + XiCon Loss:1.6086 x Lambda(0.001)), Vali MSE Loss: 0.3103 Test MSE Loss: 0.9759
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6837408542633057
Epoch: 10, Steps: 30 Train Loss: 0.1629 (Forecasting Loss:0.1613 + XiCon Loss:1.6042 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.9605
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6564598083496094
Epoch: 11, Steps: 30 Train Loss: 0.1619 (Forecasting Loss:0.1603 + XiCon Loss:1.6110 x Lambda(0.001)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.9520
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5343596935272217
Epoch: 12, Steps: 30 Train Loss: 0.1613 (Forecasting Loss:0.1597 + XiCon Loss:1.6112 x Lambda(0.001)), Vali MSE Loss: 0.3350 Test MSE Loss: 0.9526
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.4278991222381592, mae:1.0393873453140259, mape:0.33023807406425476, mspe:0.14604252576828003 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.4445+-0.06048, MAE:1.0426+-0.02109, MAPE:0.3328+-0.00784, MSPE:0.1519+-0.00899, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
