Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7543
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.3255693912506104
Epoch: 1, Steps: 69 Train Loss: 1.9052 (Forecasting Loss:0.1324 + XiCon Loss:1.7728 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.285080).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.072556495666504
Epoch: 2, Steps: 69 Train Loss: 1.8764 (Forecasting Loss:0.1111 + XiCon Loss:1.7652 x Lambda(1.0)), Vali MSE Loss: 0.2140 Test MSE Loss: 0.1226
Validation loss decreased (0.285080 --> 0.214002).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.1128010749816895
Epoch: 3, Steps: 69 Train Loss: 1.8724 (Forecasting Loss:0.1023 + XiCon Loss:1.7701 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1203
Validation loss decreased (0.214002 --> 0.209007).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.1637344360351562
Epoch: 4, Steps: 69 Train Loss: 1.8576 (Forecasting Loss:0.1006 + XiCon Loss:1.7570 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1190
Validation loss decreased (0.209007 --> 0.207487).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.3292360305786133
Epoch: 5, Steps: 69 Train Loss: 1.8564 (Forecasting Loss:0.1000 + XiCon Loss:1.7565 x Lambda(1.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1185
Validation loss decreased (0.207487 --> 0.206518).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.129270076751709
Epoch: 6, Steps: 69 Train Loss: 1.8486 (Forecasting Loss:0.0998 + XiCon Loss:1.7489 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1181
Validation loss decreased (0.206518 --> 0.206304).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0641767978668213
Epoch: 7, Steps: 69 Train Loss: 1.8578 (Forecasting Loss:0.0996 + XiCon Loss:1.7582 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1178
Validation loss decreased (0.206304 --> 0.206162).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.0203924179077148
Epoch: 8, Steps: 69 Train Loss: 1.8459 (Forecasting Loss:0.0996 + XiCon Loss:1.7462 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1177
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.2437636852264404
Epoch: 9, Steps: 69 Train Loss: 1.8442 (Forecasting Loss:0.0997 + XiCon Loss:1.7446 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206162 --> 0.206128).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.102288007736206
Epoch: 10, Steps: 69 Train Loss: 1.8533 (Forecasting Loss:0.0997 + XiCon Loss:1.7536 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206128 --> 0.206111).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.1201972961425781
Epoch: 11, Steps: 69 Train Loss: 1.8546 (Forecasting Loss:0.0996 + XiCon Loss:1.7550 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206111 --> 0.206104).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.085219144821167
Epoch: 12, Steps: 69 Train Loss: 1.8486 (Forecasting Loss:0.0994 + XiCon Loss:1.7492 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206104 --> 0.206099).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.1460967063903809
Epoch: 13, Steps: 69 Train Loss: 1.8516 (Forecasting Loss:0.0995 + XiCon Loss:1.7522 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206099 --> 0.206096).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.0661966800689697
Epoch: 14, Steps: 69 Train Loss: 1.8507 (Forecasting Loss:0.0996 + XiCon Loss:1.7511 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206096 --> 0.206095).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.007868766784668
Epoch: 15, Steps: 69 Train Loss: 1.8534 (Forecasting Loss:0.0997 + XiCon Loss:1.7538 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206095 --> 0.206094).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.1429457664489746
Epoch: 16, Steps: 69 Train Loss: 1.8497 (Forecasting Loss:0.0995 + XiCon Loss:1.7501 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.0793166160583496
Epoch: 17, Steps: 69 Train Loss: 1.8448 (Forecasting Loss:0.0995 + XiCon Loss:1.7453 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.0524909496307373
Epoch: 18, Steps: 69 Train Loss: 1.8469 (Forecasting Loss:0.0995 + XiCon Loss:1.7474 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.162381649017334
Epoch: 19, Steps: 69 Train Loss: 1.8463 (Forecasting Loss:0.0994 + XiCon Loss:1.7468 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.0704877376556396
Epoch: 20, Steps: 69 Train Loss: 1.8524 (Forecasting Loss:0.0998 + XiCon Loss:1.7526 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.0723378658294678
Epoch: 21, Steps: 69 Train Loss: 1.8441 (Forecasting Loss:0.0996 + XiCon Loss:1.7445 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.0839998722076416
Epoch: 22, Steps: 69 Train Loss: 1.8434 (Forecasting Loss:0.0996 + XiCon Loss:1.7438 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.2149972915649414
Epoch: 23, Steps: 69 Train Loss: 1.8508 (Forecasting Loss:0.0997 + XiCon Loss:1.7511 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 1.1708004474639893
Epoch: 24, Steps: 69 Train Loss: 1.8459 (Forecasting Loss:0.0992 + XiCon Loss:1.7467 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 1.1327624320983887
Epoch: 25, Steps: 69 Train Loss: 1.8520 (Forecasting Loss:0.0996 + XiCon Loss:1.7525 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.187849998474121
Epoch: 26, Steps: 69 Train Loss: 1.8472 (Forecasting Loss:0.0994 + XiCon Loss:1.7478 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.0815184116363525
Epoch: 27, Steps: 69 Train Loss: 1.8482 (Forecasting Loss:0.0997 + XiCon Loss:1.7485 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 1.0999407768249512
Epoch: 28, Steps: 69 Train Loss: 1.8497 (Forecasting Loss:0.0995 + XiCon Loss:1.7502 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0967984199523926
Epoch: 29, Steps: 69 Train Loss: 1.8444 (Forecasting Loss:0.0995 + XiCon Loss:1.7449 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.0747992992401123
Epoch: 30, Steps: 69 Train Loss: 1.8469 (Forecasting Loss:0.0996 + XiCon Loss:1.7473 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 1.0615065097808838
Epoch: 31, Steps: 69 Train Loss: 1.8476 (Forecasting Loss:0.0995 + XiCon Loss:1.7481 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 1.127570629119873
Epoch: 32, Steps: 69 Train Loss: 1.8478 (Forecasting Loss:0.0998 + XiCon Loss:1.7481 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 1.1160480976104736
Epoch: 33, Steps: 69 Train Loss: 1.8460 (Forecasting Loss:0.0996 + XiCon Loss:1.7464 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 1.0558512210845947
Epoch: 34, Steps: 69 Train Loss: 1.8470 (Forecasting Loss:0.0995 + XiCon Loss:1.7476 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.1354811191558838
Epoch: 35, Steps: 69 Train Loss: 1.8498 (Forecasting Loss:0.0997 + XiCon Loss:1.7501 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.1238341331481934
Epoch: 36, Steps: 69 Train Loss: 1.8440 (Forecasting Loss:0.0995 + XiCon Loss:1.7444 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 1.051555871963501
Epoch: 37, Steps: 69 Train Loss: 1.8511 (Forecasting Loss:0.0996 + XiCon Loss:1.7515 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 1.0476303100585938
Epoch: 38, Steps: 69 Train Loss: 1.8502 (Forecasting Loss:0.0995 + XiCon Loss:1.7508 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 1.104848861694336
Epoch: 39, Steps: 69 Train Loss: 1.8506 (Forecasting Loss:0.0997 + XiCon Loss:1.7509 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 1.0303733348846436
Epoch: 40, Steps: 69 Train Loss: 1.8478 (Forecasting Loss:0.0995 + XiCon Loss:1.7483 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 1.11570405960083
Epoch: 41, Steps: 69 Train Loss: 1.8478 (Forecasting Loss:0.0996 + XiCon Loss:1.7481 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 1.0449328422546387
Epoch: 42, Steps: 69 Train Loss: 1.8484 (Forecasting Loss:0.0993 + XiCon Loss:1.7491 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 1.1886963844299316
Epoch: 43, Steps: 69 Train Loss: 1.8523 (Forecasting Loss:0.0997 + XiCon Loss:1.7526 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 1.1260008811950684
Epoch: 44, Steps: 69 Train Loss: 1.8515 (Forecasting Loss:0.0996 + XiCon Loss:1.7519 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 1.1238033771514893
Epoch: 45, Steps: 69 Train Loss: 1.8460 (Forecasting Loss:0.0994 + XiCon Loss:1.7466 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 1.1459193229675293
Epoch: 46, Steps: 69 Train Loss: 1.8422 (Forecasting Loss:0.0996 + XiCon Loss:1.7425 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 1.0464658737182617
Epoch: 47, Steps: 69 Train Loss: 1.8484 (Forecasting Loss:0.0997 + XiCon Loss:1.7487 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 1.0926339626312256
Epoch: 48, Steps: 69 Train Loss: 1.8539 (Forecasting Loss:0.0994 + XiCon Loss:1.7545 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 1.0883374214172363
Epoch: 49, Steps: 69 Train Loss: 1.8460 (Forecasting Loss:0.0995 + XiCon Loss:1.7465 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
Validation loss decreased (0.206094 --> 0.206094).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 1.1248424053192139
Epoch: 50, Steps: 69 Train Loss: 1.8463 (Forecasting Loss:0.0998 + XiCon Loss:1.7465 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 1.2762346267700195
Epoch: 51, Steps: 69 Train Loss: 1.8538 (Forecasting Loss:0.0996 + XiCon Loss:1.7542 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 1.069162368774414
Epoch: 52, Steps: 69 Train Loss: 1.8498 (Forecasting Loss:0.0997 + XiCon Loss:1.7501 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 1.2528972625732422
Epoch: 53, Steps: 69 Train Loss: 1.8449 (Forecasting Loss:0.0994 + XiCon Loss:1.7455 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 1.091848611831665
Epoch: 54, Steps: 69 Train Loss: 1.8461 (Forecasting Loss:0.0995 + XiCon Loss:1.7466 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 1.0837297439575195
Epoch: 55, Steps: 69 Train Loss: 1.8481 (Forecasting Loss:0.0997 + XiCon Loss:1.7484 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 1.0912411212921143
Epoch: 56, Steps: 69 Train Loss: 1.8473 (Forecasting Loss:0.0995 + XiCon Loss:1.7478 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 1.155240535736084
Epoch: 57, Steps: 69 Train Loss: 1.8444 (Forecasting Loss:0.0994 + XiCon Loss:1.7450 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 1.0844237804412842
Epoch: 58, Steps: 69 Train Loss: 1.8429 (Forecasting Loss:0.0996 + XiCon Loss:1.7433 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 1.1647398471832275
Epoch: 59, Steps: 69 Train Loss: 1.8487 (Forecasting Loss:0.0996 + XiCon Loss:1.7491 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1176
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055438216775655746, mae:0.17974309623241425, mape:0.1258770078420639, mspe:0.03728364408016205 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6670
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.0907299518585205
Epoch: 1, Steps: 69 Train Loss: 1.9063 (Forecasting Loss:0.1362 + XiCon Loss:1.7700 x Lambda(1.0)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.1517
Validation loss decreased (inf --> 0.293585).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.0649948120117188
Epoch: 2, Steps: 69 Train Loss: 1.8876 (Forecasting Loss:0.1118 + XiCon Loss:1.7757 x Lambda(1.0)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1226
Validation loss decreased (0.293585 --> 0.212195).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.1439146995544434
Epoch: 3, Steps: 69 Train Loss: 1.8700 (Forecasting Loss:0.1019 + XiCon Loss:1.7681 x Lambda(1.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1194
Validation loss decreased (0.212195 --> 0.207981).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.1115107536315918
Epoch: 4, Steps: 69 Train Loss: 1.8664 (Forecasting Loss:0.1005 + XiCon Loss:1.7659 x Lambda(1.0)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1181
Validation loss decreased (0.207981 --> 0.205807).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.0992729663848877
Epoch: 5, Steps: 69 Train Loss: 1.8604 (Forecasting Loss:0.0997 + XiCon Loss:1.7607 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1174
Validation loss decreased (0.205807 --> 0.205120).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.0755083560943604
Epoch: 6, Steps: 69 Train Loss: 1.8567 (Forecasting Loss:0.0998 + XiCon Loss:1.7569 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1170
Validation loss decreased (0.205120 --> 0.204723).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0570731163024902
Epoch: 7, Steps: 69 Train Loss: 1.8539 (Forecasting Loss:0.0993 + XiCon Loss:1.7546 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1168
Validation loss decreased (0.204723 --> 0.204599).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.0916850566864014
Epoch: 8, Steps: 69 Train Loss: 1.8547 (Forecasting Loss:0.0993 + XiCon Loss:1.7555 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1167
Validation loss decreased (0.204599 --> 0.204566).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0784015655517578
Epoch: 9, Steps: 69 Train Loss: 1.8517 (Forecasting Loss:0.0992 + XiCon Loss:1.7525 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204566 --> 0.204506).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.049959659576416
Epoch: 10, Steps: 69 Train Loss: 1.8579 (Forecasting Loss:0.0993 + XiCon Loss:1.7586 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204506 --> 0.204488).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.1053168773651123
Epoch: 11, Steps: 69 Train Loss: 1.8536 (Forecasting Loss:0.0992 + XiCon Loss:1.7544 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204488 --> 0.204482).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.0307917594909668
Epoch: 12, Steps: 69 Train Loss: 1.8564 (Forecasting Loss:0.0990 + XiCon Loss:1.7574 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204482 --> 0.204478).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.0303380489349365
Epoch: 13, Steps: 69 Train Loss: 1.8517 (Forecasting Loss:0.0994 + XiCon Loss:1.7523 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204478 --> 0.204475).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.0442886352539062
Epoch: 14, Steps: 69 Train Loss: 1.8550 (Forecasting Loss:0.0993 + XiCon Loss:1.7557 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204475 --> 0.204473).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.084350347518921
Epoch: 15, Steps: 69 Train Loss: 1.8522 (Forecasting Loss:0.0994 + XiCon Loss:1.7528 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204473 --> 0.204472).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.0820019245147705
Epoch: 16, Steps: 69 Train Loss: 1.8589 (Forecasting Loss:0.0993 + XiCon Loss:1.7596 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.1045291423797607
Epoch: 17, Steps: 69 Train Loss: 1.8544 (Forecasting Loss:0.0994 + XiCon Loss:1.7550 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.0705971717834473
Epoch: 18, Steps: 69 Train Loss: 1.8537 (Forecasting Loss:0.0993 + XiCon Loss:1.7544 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.0707595348358154
Epoch: 19, Steps: 69 Train Loss: 1.8579 (Forecasting Loss:0.0992 + XiCon Loss:1.7587 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.993995189666748
Epoch: 20, Steps: 69 Train Loss: 1.8522 (Forecasting Loss:0.0994 + XiCon Loss:1.7528 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.0195033550262451
Epoch: 21, Steps: 69 Train Loss: 1.8546 (Forecasting Loss:0.0992 + XiCon Loss:1.7554 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.1553761959075928
Epoch: 22, Steps: 69 Train Loss: 1.8527 (Forecasting Loss:0.0991 + XiCon Loss:1.7536 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.05009126663208
Epoch: 23, Steps: 69 Train Loss: 1.8539 (Forecasting Loss:0.0994 + XiCon Loss:1.7545 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 1.056654453277588
Epoch: 24, Steps: 69 Train Loss: 1.8531 (Forecasting Loss:0.0992 + XiCon Loss:1.7538 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 1.1346509456634521
Epoch: 25, Steps: 69 Train Loss: 1.8588 (Forecasting Loss:0.0994 + XiCon Loss:1.7594 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.0554962158203125
Epoch: 26, Steps: 69 Train Loss: 1.8559 (Forecasting Loss:0.0990 + XiCon Loss:1.7569 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.053135871887207
Epoch: 27, Steps: 69 Train Loss: 1.8500 (Forecasting Loss:0.0993 + XiCon Loss:1.7507 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9929664134979248
Epoch: 28, Steps: 69 Train Loss: 1.8585 (Forecasting Loss:0.0991 + XiCon Loss:1.7594 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0946402549743652
Epoch: 29, Steps: 69 Train Loss: 1.8570 (Forecasting Loss:0.0998 + XiCon Loss:1.7572 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.1276311874389648
Epoch: 30, Steps: 69 Train Loss: 1.8559 (Forecasting Loss:0.0992 + XiCon Loss:1.7567 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 1.1388788223266602
Epoch: 31, Steps: 69 Train Loss: 1.8529 (Forecasting Loss:0.0992 + XiCon Loss:1.7537 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 1.097510576248169
Epoch: 32, Steps: 69 Train Loss: 1.8556 (Forecasting Loss:0.0993 + XiCon Loss:1.7564 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 1.125495195388794
Epoch: 33, Steps: 69 Train Loss: 1.8576 (Forecasting Loss:0.0994 + XiCon Loss:1.7582 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 1.0812275409698486
Epoch: 34, Steps: 69 Train Loss: 1.8507 (Forecasting Loss:0.0995 + XiCon Loss:1.7513 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.099050760269165
Epoch: 35, Steps: 69 Train Loss: 1.8539 (Forecasting Loss:0.0993 + XiCon Loss:1.7546 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.0619347095489502
Epoch: 36, Steps: 69 Train Loss: 1.8559 (Forecasting Loss:0.0994 + XiCon Loss:1.7565 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 1.0649933815002441
Epoch: 37, Steps: 69 Train Loss: 1.8524 (Forecasting Loss:0.0991 + XiCon Loss:1.7533 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 1.1466903686523438
Epoch: 38, Steps: 69 Train Loss: 1.8540 (Forecasting Loss:0.0992 + XiCon Loss:1.7548 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 1.1092734336853027
Epoch: 39, Steps: 69 Train Loss: 1.8525 (Forecasting Loss:0.0994 + XiCon Loss:1.7531 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 1.081409215927124
Epoch: 40, Steps: 69 Train Loss: 1.8480 (Forecasting Loss:0.0992 + XiCon Loss:1.7488 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 1.0407323837280273
Epoch: 41, Steps: 69 Train Loss: 1.8518 (Forecasting Loss:0.0992 + XiCon Loss:1.7526 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 1.04170823097229
Epoch: 42, Steps: 69 Train Loss: 1.8501 (Forecasting Loss:0.0991 + XiCon Loss:1.7511 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 1.080561876296997
Epoch: 43, Steps: 69 Train Loss: 1.8506 (Forecasting Loss:0.0991 + XiCon Loss:1.7514 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 1.055631399154663
Epoch: 44, Steps: 69 Train Loss: 1.8593 (Forecasting Loss:0.0995 + XiCon Loss:1.7597 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 1.1108813285827637
Epoch: 45, Steps: 69 Train Loss: 1.8507 (Forecasting Loss:0.0994 + XiCon Loss:1.7513 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 1.0791523456573486
Epoch: 46, Steps: 69 Train Loss: 1.8590 (Forecasting Loss:0.0993 + XiCon Loss:1.7597 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 1.0942811965942383
Epoch: 47, Steps: 69 Train Loss: 1.8494 (Forecasting Loss:0.0995 + XiCon Loss:1.7499 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 1.0249128341674805
Epoch: 48, Steps: 69 Train Loss: 1.8613 (Forecasting Loss:0.0992 + XiCon Loss:1.7621 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 1.148228645324707
Epoch: 49, Steps: 69 Train Loss: 1.8588 (Forecasting Loss:0.0992 + XiCon Loss:1.7596 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 1.1546907424926758
Epoch: 50, Steps: 69 Train Loss: 1.8529 (Forecasting Loss:0.0996 + XiCon Loss:1.7533 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 1.123037576675415
Epoch: 51, Steps: 69 Train Loss: 1.8562 (Forecasting Loss:0.0994 + XiCon Loss:1.7568 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 1.1102187633514404
Epoch: 52, Steps: 69 Train Loss: 1.8545 (Forecasting Loss:0.0991 + XiCon Loss:1.7554 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 1.2169418334960938
Epoch: 53, Steps: 69 Train Loss: 1.8581 (Forecasting Loss:0.0993 + XiCon Loss:1.7589 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 1.1332194805145264
Epoch: 54, Steps: 69 Train Loss: 1.8523 (Forecasting Loss:0.0995 + XiCon Loss:1.7528 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 1.1151833534240723
Epoch: 55, Steps: 69 Train Loss: 1.8534 (Forecasting Loss:0.0994 + XiCon Loss:1.7541 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 1.0598418712615967
Epoch: 56, Steps: 69 Train Loss: 1.8570 (Forecasting Loss:0.0992 + XiCon Loss:1.7577 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 1.1182146072387695
Epoch: 57, Steps: 69 Train Loss: 1.8551 (Forecasting Loss:0.0994 + XiCon Loss:1.7557 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 1.1539151668548584
Epoch: 58, Steps: 69 Train Loss: 1.8493 (Forecasting Loss:0.0994 + XiCon Loss:1.7499 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 1.0571000576019287
Epoch: 59, Steps: 69 Train Loss: 1.8503 (Forecasting Loss:0.0993 + XiCon Loss:1.7511 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 1.117614507675171
Epoch: 60, Steps: 69 Train Loss: 1.8536 (Forecasting Loss:0.0995 + XiCon Loss:1.7541 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 1.0271422863006592
Epoch: 61, Steps: 69 Train Loss: 1.8540 (Forecasting Loss:0.0993 + XiCon Loss:1.7548 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 1.004199504852295
Epoch: 62, Steps: 69 Train Loss: 1.8493 (Forecasting Loss:0.0994 + XiCon Loss:1.7499 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 1.1148464679718018
Epoch: 63, Steps: 69 Train Loss: 1.8535 (Forecasting Loss:0.0994 + XiCon Loss:1.7541 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 1.179919958114624
Epoch: 64, Steps: 69 Train Loss: 1.8556 (Forecasting Loss:0.0990 + XiCon Loss:1.7566 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 1.1039929389953613
Epoch: 65, Steps: 69 Train Loss: 1.8568 (Forecasting Loss:0.0992 + XiCon Loss:1.7576 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 1.0421442985534668
Epoch: 66, Steps: 69 Train Loss: 1.8571 (Forecasting Loss:0.0996 + XiCon Loss:1.7575 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 1.1022484302520752
Epoch: 67, Steps: 69 Train Loss: 1.8583 (Forecasting Loss:0.0994 + XiCon Loss:1.7589 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 1.096841812133789
Epoch: 68, Steps: 69 Train Loss: 1.8567 (Forecasting Loss:0.0994 + XiCon Loss:1.7573 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 1.1026644706726074
Epoch: 69, Steps: 69 Train Loss: 1.8561 (Forecasting Loss:0.0993 + XiCon Loss:1.7568 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 1.0757043361663818
Epoch: 70, Steps: 69 Train Loss: 1.8556 (Forecasting Loss:0.0994 + XiCon Loss:1.7562 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 1.0880250930786133
Epoch: 71, Steps: 69 Train Loss: 1.8528 (Forecasting Loss:0.0993 + XiCon Loss:1.7535 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 1.0795719623565674
Epoch: 72, Steps: 69 Train Loss: 1.8524 (Forecasting Loss:0.0994 + XiCon Loss:1.7531 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 1.291862964630127
Epoch: 73, Steps: 69 Train Loss: 1.8521 (Forecasting Loss:0.0991 + XiCon Loss:1.7530 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 1.0827348232269287
Epoch: 74, Steps: 69 Train Loss: 1.8537 (Forecasting Loss:0.0995 + XiCon Loss:1.7542 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 1.0064072608947754
Epoch: 75, Steps: 69 Train Loss: 1.8516 (Forecasting Loss:0.0992 + XiCon Loss:1.7524 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 1.1540558338165283
Epoch: 76, Steps: 69 Train Loss: 1.8558 (Forecasting Loss:0.0995 + XiCon Loss:1.7563 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 1.1021604537963867
Epoch: 77, Steps: 69 Train Loss: 1.8546 (Forecasting Loss:0.0994 + XiCon Loss:1.7552 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 1.2214241027832031
Epoch: 78, Steps: 69 Train Loss: 1.8522 (Forecasting Loss:0.0993 + XiCon Loss:1.7529 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 1.0474584102630615
Epoch: 79, Steps: 69 Train Loss: 1.8529 (Forecasting Loss:0.0991 + XiCon Loss:1.7538 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 1.1300764083862305
Epoch: 80, Steps: 69 Train Loss: 1.8578 (Forecasting Loss:0.0994 + XiCon Loss:1.7584 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 1.0448575019836426
Epoch: 81, Steps: 69 Train Loss: 1.8547 (Forecasting Loss:0.0994 + XiCon Loss:1.7553 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
Validation loss decreased (0.204472 --> 0.204472).  Saving model ...
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 1.045149564743042
Epoch: 82, Steps: 69 Train Loss: 1.8612 (Forecasting Loss:0.0992 + XiCon Loss:1.7620 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 1.0917994976043701
Epoch: 83, Steps: 69 Train Loss: 1.8587 (Forecasting Loss:0.0995 + XiCon Loss:1.7592 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 1.1069962978363037
Epoch: 84, Steps: 69 Train Loss: 1.8517 (Forecasting Loss:0.0991 + XiCon Loss:1.7526 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 1.1243038177490234
Epoch: 85, Steps: 69 Train Loss: 1.8544 (Forecasting Loss:0.0992 + XiCon Loss:1.7551 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.9855811595916748
Epoch: 86, Steps: 69 Train Loss: 1.8592 (Forecasting Loss:0.0993 + XiCon Loss:1.7599 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 1.072321891784668
Epoch: 87, Steps: 69 Train Loss: 1.8565 (Forecasting Loss:0.0991 + XiCon Loss:1.7573 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 1.1078846454620361
Epoch: 88, Steps: 69 Train Loss: 1.8542 (Forecasting Loss:0.0992 + XiCon Loss:1.7550 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 1.0628480911254883
Epoch: 89, Steps: 69 Train Loss: 1.8544 (Forecasting Loss:0.0994 + XiCon Loss:1.7550 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 1.0694117546081543
Epoch: 90, Steps: 69 Train Loss: 1.8515 (Forecasting Loss:0.0991 + XiCon Loss:1.7524 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 1.137242078781128
Epoch: 91, Steps: 69 Train Loss: 1.8556 (Forecasting Loss:0.0991 + XiCon Loss:1.7565 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1167
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05483024939894676, mae:0.17851124703884125, mape:0.12465683370828629, mspe:0.03657856211066246 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7262
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9780278205871582
Epoch: 1, Steps: 69 Train Loss: 1.8995 (Forecasting Loss:0.1285 + XiCon Loss:1.7710 x Lambda(1.0)), Vali MSE Loss: 0.2748 Test MSE Loss: 0.1432
Validation loss decreased (inf --> 0.274791).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.0423905849456787
Epoch: 2, Steps: 69 Train Loss: 1.8790 (Forecasting Loss:0.1110 + XiCon Loss:1.7679 x Lambda(1.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.1210
Validation loss decreased (0.274791 --> 0.215501).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.0467848777770996
Epoch: 3, Steps: 69 Train Loss: 1.8651 (Forecasting Loss:0.1032 + XiCon Loss:1.7620 x Lambda(1.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1192
Validation loss decreased (0.215501 --> 0.211283).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.0120534896850586
Epoch: 4, Steps: 69 Train Loss: 1.8593 (Forecasting Loss:0.1019 + XiCon Loss:1.7574 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1185
Validation loss decreased (0.211283 --> 0.209380).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.0495412349700928
Epoch: 5, Steps: 69 Train Loss: 1.8592 (Forecasting Loss:0.1011 + XiCon Loss:1.7582 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1182
Validation loss decreased (0.209380 --> 0.208417).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.062394618988037
Epoch: 6, Steps: 69 Train Loss: 1.8672 (Forecasting Loss:0.1010 + XiCon Loss:1.7662 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1181
Validation loss decreased (0.208417 --> 0.208082).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0766067504882812
Epoch: 7, Steps: 69 Train Loss: 1.8636 (Forecasting Loss:0.1006 + XiCon Loss:1.7631 x Lambda(1.0)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1180
Validation loss decreased (0.208082 --> 0.207894).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.1088464260101318
Epoch: 8, Steps: 69 Train Loss: 1.8632 (Forecasting Loss:0.1005 + XiCon Loss:1.7627 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1179
Validation loss decreased (0.207894 --> 0.207787).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0496160984039307
Epoch: 9, Steps: 69 Train Loss: 1.8577 (Forecasting Loss:0.1005 + XiCon Loss:1.7572 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1179
Validation loss decreased (0.207787 --> 0.207751).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.0232124328613281
Epoch: 10, Steps: 69 Train Loss: 1.8674 (Forecasting Loss:0.1005 + XiCon Loss:1.7669 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207751 --> 0.207729).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.209923267364502
Epoch: 11, Steps: 69 Train Loss: 1.8673 (Forecasting Loss:0.1006 + XiCon Loss:1.7667 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207729 --> 0.207717).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.1420397758483887
Epoch: 12, Steps: 69 Train Loss: 1.8679 (Forecasting Loss:0.1004 + XiCon Loss:1.7675 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207717 --> 0.207710).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.0671844482421875
Epoch: 13, Steps: 69 Train Loss: 1.8661 (Forecasting Loss:0.1005 + XiCon Loss:1.7655 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207710 --> 0.207707).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.1414458751678467
Epoch: 14, Steps: 69 Train Loss: 1.8673 (Forecasting Loss:0.1004 + XiCon Loss:1.7669 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207707 --> 0.207705).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.1135344505310059
Epoch: 15, Steps: 69 Train Loss: 1.8706 (Forecasting Loss:0.1009 + XiCon Loss:1.7696 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207705 --> 0.207704).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.1022024154663086
Epoch: 16, Steps: 69 Train Loss: 1.8677 (Forecasting Loss:0.1007 + XiCon Loss:1.7670 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207704 --> 0.207704).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.0567450523376465
Epoch: 17, Steps: 69 Train Loss: 1.8698 (Forecasting Loss:0.1005 + XiCon Loss:1.7694 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207704 --> 0.207703).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.155390977859497
Epoch: 18, Steps: 69 Train Loss: 1.8679 (Forecasting Loss:0.1007 + XiCon Loss:1.7672 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.0833563804626465
Epoch: 19, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1006 + XiCon Loss:1.7686 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.1413586139678955
Epoch: 20, Steps: 69 Train Loss: 1.8688 (Forecasting Loss:0.1005 + XiCon Loss:1.7683 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.103670597076416
Epoch: 21, Steps: 69 Train Loss: 1.8635 (Forecasting Loss:0.1007 + XiCon Loss:1.7628 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.070566177368164
Epoch: 22, Steps: 69 Train Loss: 1.8746 (Forecasting Loss:0.1002 + XiCon Loss:1.7744 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.0860612392425537
Epoch: 23, Steps: 69 Train Loss: 1.8684 (Forecasting Loss:0.1006 + XiCon Loss:1.7678 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 1.0496013164520264
Epoch: 24, Steps: 69 Train Loss: 1.8682 (Forecasting Loss:0.1006 + XiCon Loss:1.7676 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 1.055833339691162
Epoch: 25, Steps: 69 Train Loss: 1.8670 (Forecasting Loss:0.1006 + XiCon Loss:1.7664 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.1297078132629395
Epoch: 26, Steps: 69 Train Loss: 1.8712 (Forecasting Loss:0.1005 + XiCon Loss:1.7707 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.030287504196167
Epoch: 27, Steps: 69 Train Loss: 1.8749 (Forecasting Loss:0.1006 + XiCon Loss:1.7743 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 1.0846467018127441
Epoch: 28, Steps: 69 Train Loss: 1.8670 (Forecasting Loss:0.1008 + XiCon Loss:1.7662 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.1347429752349854
Epoch: 29, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1005 + XiCon Loss:1.7687 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.0264997482299805
Epoch: 30, Steps: 69 Train Loss: 1.8615 (Forecasting Loss:0.1006 + XiCon Loss:1.7609 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9819271564483643
Epoch: 31, Steps: 69 Train Loss: 1.8653 (Forecasting Loss:0.1007 + XiCon Loss:1.7646 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8951442241668701
Epoch: 32, Steps: 69 Train Loss: 1.8706 (Forecasting Loss:0.1007 + XiCon Loss:1.7699 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8200581073760986
Epoch: 33, Steps: 69 Train Loss: 1.8710 (Forecasting Loss:0.1008 + XiCon Loss:1.7702 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 3.062732458114624
Epoch: 34, Steps: 69 Train Loss: 1.8669 (Forecasting Loss:0.1003 + XiCon Loss:1.7665 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 2.825164794921875
Epoch: 35, Steps: 69 Train Loss: 1.8662 (Forecasting Loss:0.1003 + XiCon Loss:1.7658 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.8639411926269531
Epoch: 36, Steps: 69 Train Loss: 1.8698 (Forecasting Loss:0.1006 + XiCon Loss:1.7692 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 1.178542137145996
Epoch: 37, Steps: 69 Train Loss: 1.8722 (Forecasting Loss:0.1007 + XiCon Loss:1.7715 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8963124752044678
Epoch: 38, Steps: 69 Train Loss: 1.8701 (Forecasting Loss:0.1004 + XiCon Loss:1.7697 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9447760581970215
Epoch: 39, Steps: 69 Train Loss: 1.8658 (Forecasting Loss:0.1006 + XiCon Loss:1.7652 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8455312252044678
Epoch: 40, Steps: 69 Train Loss: 1.8699 (Forecasting Loss:0.1008 + XiCon Loss:1.7691 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8174023628234863
Epoch: 41, Steps: 69 Train Loss: 1.8697 (Forecasting Loss:0.1004 + XiCon Loss:1.7693 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 1.0118625164031982
Epoch: 42, Steps: 69 Train Loss: 1.8677 (Forecasting Loss:0.1003 + XiCon Loss:1.7673 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 1.0788369178771973
Epoch: 43, Steps: 69 Train Loss: 1.8682 (Forecasting Loss:0.1006 + XiCon Loss:1.7676 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 1.0838773250579834
Epoch: 44, Steps: 69 Train Loss: 1.8707 (Forecasting Loss:0.1005 + XiCon Loss:1.7703 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 1.1156551837921143
Epoch: 45, Steps: 69 Train Loss: 1.8755 (Forecasting Loss:0.1005 + XiCon Loss:1.7750 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 1.0878090858459473
Epoch: 46, Steps: 69 Train Loss: 1.8702 (Forecasting Loss:0.1006 + XiCon Loss:1.7696 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 1.1199400424957275
Epoch: 47, Steps: 69 Train Loss: 1.8637 (Forecasting Loss:0.1007 + XiCon Loss:1.7630 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 1.086935043334961
Epoch: 48, Steps: 69 Train Loss: 1.8655 (Forecasting Loss:0.1006 + XiCon Loss:1.7649 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 1.0811405181884766
Epoch: 49, Steps: 69 Train Loss: 1.8631 (Forecasting Loss:0.1007 + XiCon Loss:1.7624 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 1.1082160472869873
Epoch: 50, Steps: 69 Train Loss: 1.8651 (Forecasting Loss:0.1005 + XiCon Loss:1.7646 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 1.2351222038269043
Epoch: 51, Steps: 69 Train Loss: 1.8683 (Forecasting Loss:0.1007 + XiCon Loss:1.7676 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 1.109372854232788
Epoch: 52, Steps: 69 Train Loss: 1.8718 (Forecasting Loss:0.1006 + XiCon Loss:1.7712 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 1.10868239402771
Epoch: 53, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1008 + XiCon Loss:1.7684 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 1.0790989398956299
Epoch: 54, Steps: 69 Train Loss: 1.8688 (Forecasting Loss:0.1006 + XiCon Loss:1.7682 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 1.060098648071289
Epoch: 55, Steps: 69 Train Loss: 1.8614 (Forecasting Loss:0.1007 + XiCon Loss:1.7607 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 1.0965192317962646
Epoch: 56, Steps: 69 Train Loss: 1.8704 (Forecasting Loss:0.1006 + XiCon Loss:1.7697 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 1.1645944118499756
Epoch: 57, Steps: 69 Train Loss: 1.8708 (Forecasting Loss:0.1006 + XiCon Loss:1.7703 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 1.1176750659942627
Epoch: 58, Steps: 69 Train Loss: 1.8695 (Forecasting Loss:0.1004 + XiCon Loss:1.7691 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 1.077681303024292
Epoch: 59, Steps: 69 Train Loss: 1.8709 (Forecasting Loss:0.1006 + XiCon Loss:1.7703 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 1.3170206546783447
Epoch: 60, Steps: 69 Train Loss: 1.8614 (Forecasting Loss:0.1006 + XiCon Loss:1.7609 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 1.0936481952667236
Epoch: 61, Steps: 69 Train Loss: 1.8650 (Forecasting Loss:0.1005 + XiCon Loss:1.7645 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 1.0393309593200684
Epoch: 62, Steps: 69 Train Loss: 1.8659 (Forecasting Loss:0.1007 + XiCon Loss:1.7653 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 1.1636323928833008
Epoch: 63, Steps: 69 Train Loss: 1.8617 (Forecasting Loss:0.1006 + XiCon Loss:1.7611 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 1.205885887145996
Epoch: 64, Steps: 69 Train Loss: 1.8660 (Forecasting Loss:0.1008 + XiCon Loss:1.7652 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 1.0623703002929688
Epoch: 65, Steps: 69 Train Loss: 1.8739 (Forecasting Loss:0.1007 + XiCon Loss:1.7732 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 1.1097910404205322
Epoch: 66, Steps: 69 Train Loss: 1.8691 (Forecasting Loss:0.1006 + XiCon Loss:1.7686 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 1.1880958080291748
Epoch: 67, Steps: 69 Train Loss: 1.8670 (Forecasting Loss:0.1005 + XiCon Loss:1.7665 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 1.0152571201324463
Epoch: 68, Steps: 69 Train Loss: 1.8625 (Forecasting Loss:0.1006 + XiCon Loss:1.7619 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 1.047785997390747
Epoch: 69, Steps: 69 Train Loss: 1.8626 (Forecasting Loss:0.1005 + XiCon Loss:1.7621 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 1.190206527709961
Epoch: 70, Steps: 69 Train Loss: 1.8741 (Forecasting Loss:0.1006 + XiCon Loss:1.7736 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 1.1248371601104736
Epoch: 71, Steps: 69 Train Loss: 1.8740 (Forecasting Loss:0.1005 + XiCon Loss:1.7734 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 1.0819060802459717
Epoch: 72, Steps: 69 Train Loss: 1.8751 (Forecasting Loss:0.1006 + XiCon Loss:1.7745 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 1.100700855255127
Epoch: 73, Steps: 69 Train Loss: 1.8675 (Forecasting Loss:0.1008 + XiCon Loss:1.7667 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 1.1130287647247314
Epoch: 74, Steps: 69 Train Loss: 1.8682 (Forecasting Loss:0.1007 + XiCon Loss:1.7675 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.9718306064605713
Epoch: 75, Steps: 69 Train Loss: 1.8665 (Forecasting Loss:0.1005 + XiCon Loss:1.7660 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 1.0582120418548584
Epoch: 76, Steps: 69 Train Loss: 1.8680 (Forecasting Loss:0.1006 + XiCon Loss:1.7675 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 1.120680332183838
Epoch: 77, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1007 + XiCon Loss:1.7686 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 1.069861650466919
Epoch: 78, Steps: 69 Train Loss: 1.8690 (Forecasting Loss:0.1007 + XiCon Loss:1.7683 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 1.1235103607177734
Epoch: 79, Steps: 69 Train Loss: 1.8655 (Forecasting Loss:0.1005 + XiCon Loss:1.7650 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 1.1730961799621582
Epoch: 80, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1005 + XiCon Loss:1.7687 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 1.109783411026001
Epoch: 81, Steps: 69 Train Loss: 1.8672 (Forecasting Loss:0.1006 + XiCon Loss:1.7666 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 1.0924413204193115
Epoch: 82, Steps: 69 Train Loss: 1.8689 (Forecasting Loss:0.1005 + XiCon Loss:1.7683 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 1.1666467189788818
Epoch: 83, Steps: 69 Train Loss: 1.8705 (Forecasting Loss:0.1006 + XiCon Loss:1.7699 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 1.1560215950012207
Epoch: 84, Steps: 69 Train Loss: 1.8672 (Forecasting Loss:0.1008 + XiCon Loss:1.7664 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 1.0655364990234375
Epoch: 85, Steps: 69 Train Loss: 1.8640 (Forecasting Loss:0.1005 + XiCon Loss:1.7634 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 1.1806361675262451
Epoch: 86, Steps: 69 Train Loss: 1.8729 (Forecasting Loss:0.1006 + XiCon Loss:1.7723 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 1.1090381145477295
Epoch: 87, Steps: 69 Train Loss: 1.8672 (Forecasting Loss:0.1003 + XiCon Loss:1.7669 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 1.0783236026763916
Epoch: 88, Steps: 69 Train Loss: 1.8663 (Forecasting Loss:0.1005 + XiCon Loss:1.7658 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
Validation loss decreased (0.207703 --> 0.207703).  Saving model ...
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 1.158491611480713
Epoch: 89, Steps: 69 Train Loss: 1.8659 (Forecasting Loss:0.1004 + XiCon Loss:1.7655 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 1.0733222961425781
Epoch: 90, Steps: 69 Train Loss: 1.8651 (Forecasting Loss:0.1008 + XiCon Loss:1.7644 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 1.1788854598999023
Epoch: 91, Steps: 69 Train Loss: 1.8759 (Forecasting Loss:0.1005 + XiCon Loss:1.7754 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 1.0949571132659912
Epoch: 92, Steps: 69 Train Loss: 1.8724 (Forecasting Loss:0.1004 + XiCon Loss:1.7720 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 1.1011433601379395
Epoch: 93, Steps: 69 Train Loss: 1.8713 (Forecasting Loss:0.1005 + XiCon Loss:1.7707 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 1.072880506515503
Epoch: 94, Steps: 69 Train Loss: 1.8692 (Forecasting Loss:0.1009 + XiCon Loss:1.7683 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 1.0888607501983643
Epoch: 95, Steps: 69 Train Loss: 1.8720 (Forecasting Loss:0.1005 + XiCon Loss:1.7715 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 1.1348791122436523
Epoch: 96, Steps: 69 Train Loss: 1.8665 (Forecasting Loss:0.1007 + XiCon Loss:1.7659 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 1.0807032585144043
Epoch: 97, Steps: 69 Train Loss: 1.8695 (Forecasting Loss:0.1006 + XiCon Loss:1.7688 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 1.1029870510101318
Epoch: 98, Steps: 69 Train Loss: 1.8728 (Forecasting Loss:0.1006 + XiCon Loss:1.7722 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1179
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055570993572473526, mae:0.1801673322916031, mape:0.1258443146944046, mspe:0.0368511900305748 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6943
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.0997445583343506
Epoch: 1, Steps: 69 Train Loss: 1.9070 (Forecasting Loss:0.1351 + XiCon Loss:1.7719 x Lambda(1.0)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.1511
Validation loss decreased (inf --> 0.292021).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.072436809539795
Epoch: 2, Steps: 69 Train Loss: 1.8728 (Forecasting Loss:0.1121 + XiCon Loss:1.7607 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1223
Validation loss decreased (0.292021 --> 0.213670).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.0487289428710938
Epoch: 3, Steps: 69 Train Loss: 1.8552 (Forecasting Loss:0.1027 + XiCon Loss:1.7525 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1182
Validation loss decreased (0.213670 --> 0.210302).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.1461155414581299
Epoch: 4, Steps: 69 Train Loss: 1.8388 (Forecasting Loss:0.1012 + XiCon Loss:1.7376 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1177
Validation loss decreased (0.210302 --> 0.208775).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.1608328819274902
Epoch: 5, Steps: 69 Train Loss: 1.8355 (Forecasting Loss:0.1005 + XiCon Loss:1.7351 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1174
Validation loss decreased (0.208775 --> 0.207803).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.1350293159484863
Epoch: 6, Steps: 69 Train Loss: 1.8374 (Forecasting Loss:0.1000 + XiCon Loss:1.7374 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1171
Validation loss decreased (0.207803 --> 0.207632).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0774192810058594
Epoch: 7, Steps: 69 Train Loss: 1.8366 (Forecasting Loss:0.1002 + XiCon Loss:1.7364 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1170
Validation loss decreased (0.207632 --> 0.207444).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.0799758434295654
Epoch: 8, Steps: 69 Train Loss: 1.8335 (Forecasting Loss:0.1000 + XiCon Loss:1.7335 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207444 --> 0.207346).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0386643409729004
Epoch: 9, Steps: 69 Train Loss: 1.8374 (Forecasting Loss:0.1000 + XiCon Loss:1.7374 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207346 --> 0.207322).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.0803110599517822
Epoch: 10, Steps: 69 Train Loss: 1.8381 (Forecasting Loss:0.0998 + XiCon Loss:1.7383 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207322 --> 0.207281).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.151139497756958
Epoch: 11, Steps: 69 Train Loss: 1.8421 (Forecasting Loss:0.0996 + XiCon Loss:1.7424 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207281 --> 0.207277).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.0828163623809814
Epoch: 12, Steps: 69 Train Loss: 1.8369 (Forecasting Loss:0.0998 + XiCon Loss:1.7370 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207277 --> 0.207269).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.1404175758361816
Epoch: 13, Steps: 69 Train Loss: 1.8391 (Forecasting Loss:0.0999 + XiCon Loss:1.7392 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207269 --> 0.207266).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.0994181632995605
Epoch: 14, Steps: 69 Train Loss: 1.8455 (Forecasting Loss:0.1000 + XiCon Loss:1.7455 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207266 --> 0.207265).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.148397445678711
Epoch: 15, Steps: 69 Train Loss: 1.8346 (Forecasting Loss:0.0999 + XiCon Loss:1.7347 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207265 --> 0.207264).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.1274776458740234
Epoch: 16, Steps: 69 Train Loss: 1.8414 (Forecasting Loss:0.1001 + XiCon Loss:1.7413 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207264 --> 0.207263).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.0742266178131104
Epoch: 17, Steps: 69 Train Loss: 1.8367 (Forecasting Loss:0.0999 + XiCon Loss:1.7368 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.0927886962890625
Epoch: 18, Steps: 69 Train Loss: 1.8376 (Forecasting Loss:0.0999 + XiCon Loss:1.7377 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.0983123779296875
Epoch: 19, Steps: 69 Train Loss: 1.8331 (Forecasting Loss:0.0999 + XiCon Loss:1.7332 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.143364429473877
Epoch: 20, Steps: 69 Train Loss: 1.8351 (Forecasting Loss:0.0997 + XiCon Loss:1.7355 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.1207470893859863
Epoch: 21, Steps: 69 Train Loss: 1.8388 (Forecasting Loss:0.0998 + XiCon Loss:1.7389 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.1493711471557617
Epoch: 22, Steps: 69 Train Loss: 1.8424 (Forecasting Loss:0.0999 + XiCon Loss:1.7425 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.1770427227020264
Epoch: 23, Steps: 69 Train Loss: 1.8317 (Forecasting Loss:0.0999 + XiCon Loss:1.7318 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 1.1553361415863037
Epoch: 24, Steps: 69 Train Loss: 1.8368 (Forecasting Loss:0.0998 + XiCon Loss:1.7370 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 1.2698569297790527
Epoch: 25, Steps: 69 Train Loss: 1.8379 (Forecasting Loss:0.0997 + XiCon Loss:1.7382 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.1074774265289307
Epoch: 26, Steps: 69 Train Loss: 1.8417 (Forecasting Loss:0.1002 + XiCon Loss:1.7416 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.1075820922851562
Epoch: 27, Steps: 69 Train Loss: 1.8360 (Forecasting Loss:0.0997 + XiCon Loss:1.7362 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 1.1145625114440918
Epoch: 28, Steps: 69 Train Loss: 1.8420 (Forecasting Loss:0.0999 + XiCon Loss:1.7421 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0959792137145996
Epoch: 29, Steps: 69 Train Loss: 1.8377 (Forecasting Loss:0.1000 + XiCon Loss:1.7377 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.117081642150879
Epoch: 30, Steps: 69 Train Loss: 1.8382 (Forecasting Loss:0.0998 + XiCon Loss:1.7384 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 1.1333324909210205
Epoch: 31, Steps: 69 Train Loss: 1.8349 (Forecasting Loss:0.1001 + XiCon Loss:1.7349 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 1.0680503845214844
Epoch: 32, Steps: 69 Train Loss: 1.8338 (Forecasting Loss:0.1001 + XiCon Loss:1.7337 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 1.1449840068817139
Epoch: 33, Steps: 69 Train Loss: 1.8375 (Forecasting Loss:0.1000 + XiCon Loss:1.7374 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
Validation loss decreased (0.207263 --> 0.207263).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 1.15492844581604
Epoch: 34, Steps: 69 Train Loss: 1.8369 (Forecasting Loss:0.0998 + XiCon Loss:1.7372 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.0854573249816895
Epoch: 35, Steps: 69 Train Loss: 1.8421 (Forecasting Loss:0.0998 + XiCon Loss:1.7423 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.0906281471252441
Epoch: 36, Steps: 69 Train Loss: 1.8374 (Forecasting Loss:0.1000 + XiCon Loss:1.7375 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 1.110457181930542
Epoch: 37, Steps: 69 Train Loss: 1.8392 (Forecasting Loss:0.0999 + XiCon Loss:1.7393 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 1.1650826930999756
Epoch: 38, Steps: 69 Train Loss: 1.8389 (Forecasting Loss:0.1000 + XiCon Loss:1.7389 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 1.1165509223937988
Epoch: 39, Steps: 69 Train Loss: 1.8425 (Forecasting Loss:0.1000 + XiCon Loss:1.7424 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 1.1526448726654053
Epoch: 40, Steps: 69 Train Loss: 1.8352 (Forecasting Loss:0.1001 + XiCon Loss:1.7350 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 1.2666778564453125
Epoch: 41, Steps: 69 Train Loss: 1.8412 (Forecasting Loss:0.0999 + XiCon Loss:1.7413 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 1.032449722290039
Epoch: 42, Steps: 69 Train Loss: 1.8416 (Forecasting Loss:0.1001 + XiCon Loss:1.7415 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 1.0827741622924805
Epoch: 43, Steps: 69 Train Loss: 1.8341 (Forecasting Loss:0.0997 + XiCon Loss:1.7344 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1169
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05507116764783859, mae:0.17869719862937927, mape:0.12515473365783691, mspe:0.03698393329977989 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6820
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.0962083339691162
Epoch: 1, Steps: 69 Train Loss: 1.9025 (Forecasting Loss:0.1344 + XiCon Loss:1.7681 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.289933).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.1523993015289307
Epoch: 2, Steps: 69 Train Loss: 1.8754 (Forecasting Loss:0.1138 + XiCon Loss:1.7616 x Lambda(1.0)), Vali MSE Loss: 0.2171 Test MSE Loss: 0.1212
Validation loss decreased (0.289933 --> 0.217104).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.1059880256652832
Epoch: 3, Steps: 69 Train Loss: 1.8877 (Forecasting Loss:0.1035 + XiCon Loss:1.7841 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1190
Validation loss decreased (0.217104 --> 0.212592).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.1529090404510498
Epoch: 4, Steps: 69 Train Loss: 1.9090 (Forecasting Loss:0.1021 + XiCon Loss:1.8068 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1182
Validation loss decreased (0.212592 --> 0.210619).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.0569641590118408
Epoch: 5, Steps: 69 Train Loss: 1.9121 (Forecasting Loss:0.1014 + XiCon Loss:1.8107 x Lambda(1.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1179
Validation loss decreased (0.210619 --> 0.209866).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.083787202835083
Epoch: 6, Steps: 69 Train Loss: 1.9200 (Forecasting Loss:0.1011 + XiCon Loss:1.8190 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1177
Validation loss decreased (0.209866 --> 0.209352).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.1002979278564453
Epoch: 7, Steps: 69 Train Loss: 1.9154 (Forecasting Loss:0.1009 + XiCon Loss:1.8145 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1176
Validation loss decreased (0.209352 --> 0.209151).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.1165657043457031
Epoch: 8, Steps: 69 Train Loss: 1.9164 (Forecasting Loss:0.1011 + XiCon Loss:1.8153 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1176
Validation loss decreased (0.209151 --> 0.209059).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.1002576351165771
Epoch: 9, Steps: 69 Train Loss: 1.9164 (Forecasting Loss:0.1011 + XiCon Loss:1.8153 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1175
Validation loss decreased (0.209059 --> 0.208984).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.1214838027954102
Epoch: 10, Steps: 69 Train Loss: 1.9172 (Forecasting Loss:0.1010 + XiCon Loss:1.8162 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1175
Validation loss decreased (0.208984 --> 0.208955).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 1.0951573848724365
Epoch: 11, Steps: 69 Train Loss: 1.9220 (Forecasting Loss:0.1007 + XiCon Loss:1.8213 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208955 --> 0.208941).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.1309542655944824
Epoch: 12, Steps: 69 Train Loss: 1.9142 (Forecasting Loss:0.1009 + XiCon Loss:1.8133 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208941 --> 0.208931).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.1210389137268066
Epoch: 13, Steps: 69 Train Loss: 1.9249 (Forecasting Loss:0.1009 + XiCon Loss:1.8240 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208931 --> 0.208927).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.1206765174865723
Epoch: 14, Steps: 69 Train Loss: 1.9208 (Forecasting Loss:0.1008 + XiCon Loss:1.8200 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208927 --> 0.208925).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.078979730606079
Epoch: 15, Steps: 69 Train Loss: 1.9166 (Forecasting Loss:0.1009 + XiCon Loss:1.8156 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208925 --> 0.208924).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 1.0771183967590332
Epoch: 16, Steps: 69 Train Loss: 1.9154 (Forecasting Loss:0.1011 + XiCon Loss:1.8144 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208924 --> 0.208923).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.1112771034240723
Epoch: 17, Steps: 69 Train Loss: 1.9204 (Forecasting Loss:0.1010 + XiCon Loss:1.8194 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.1537973880767822
Epoch: 18, Steps: 69 Train Loss: 1.9229 (Forecasting Loss:0.1009 + XiCon Loss:1.8220 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 1.1821982860565186
Epoch: 19, Steps: 69 Train Loss: 1.9186 (Forecasting Loss:0.1009 + XiCon Loss:1.8177 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.0672454833984375
Epoch: 20, Steps: 69 Train Loss: 1.9136 (Forecasting Loss:0.1010 + XiCon Loss:1.8127 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 1.1073923110961914
Epoch: 21, Steps: 69 Train Loss: 1.9172 (Forecasting Loss:0.1008 + XiCon Loss:1.8164 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.0911693572998047
Epoch: 22, Steps: 69 Train Loss: 1.9206 (Forecasting Loss:0.1008 + XiCon Loss:1.8198 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.1311607360839844
Epoch: 23, Steps: 69 Train Loss: 1.9262 (Forecasting Loss:0.1010 + XiCon Loss:1.8252 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 1.0648443698883057
Epoch: 24, Steps: 69 Train Loss: 1.9213 (Forecasting Loss:0.1010 + XiCon Loss:1.8203 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 1.1395766735076904
Epoch: 25, Steps: 69 Train Loss: 1.9060 (Forecasting Loss:0.1008 + XiCon Loss:1.8052 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.130507469177246
Epoch: 26, Steps: 69 Train Loss: 1.9215 (Forecasting Loss:0.1010 + XiCon Loss:1.8206 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.0674397945404053
Epoch: 27, Steps: 69 Train Loss: 1.9215 (Forecasting Loss:0.1009 + XiCon Loss:1.8205 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 1.1183819770812988
Epoch: 28, Steps: 69 Train Loss: 1.9209 (Forecasting Loss:0.1009 + XiCon Loss:1.8200 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0721549987792969
Epoch: 29, Steps: 69 Train Loss: 1.9255 (Forecasting Loss:0.1009 + XiCon Loss:1.8246 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.0767114162445068
Epoch: 30, Steps: 69 Train Loss: 1.9127 (Forecasting Loss:0.1008 + XiCon Loss:1.8118 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 1.0691611766815186
Epoch: 31, Steps: 69 Train Loss: 1.9183 (Forecasting Loss:0.1010 + XiCon Loss:1.8173 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 1.0945875644683838
Epoch: 32, Steps: 69 Train Loss: 1.9260 (Forecasting Loss:0.1010 + XiCon Loss:1.8250 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 1.1181302070617676
Epoch: 33, Steps: 69 Train Loss: 1.9166 (Forecasting Loss:0.1009 + XiCon Loss:1.8157 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 1.036834478378296
Epoch: 34, Steps: 69 Train Loss: 1.9177 (Forecasting Loss:0.1010 + XiCon Loss:1.8167 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.124452829360962
Epoch: 35, Steps: 69 Train Loss: 1.9172 (Forecasting Loss:0.1009 + XiCon Loss:1.8163 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.110459327697754
Epoch: 36, Steps: 69 Train Loss: 1.9194 (Forecasting Loss:0.1010 + XiCon Loss:1.8184 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 1.1076514720916748
Epoch: 37, Steps: 69 Train Loss: 1.9198 (Forecasting Loss:0.1007 + XiCon Loss:1.8191 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9781272411346436
Epoch: 38, Steps: 69 Train Loss: 1.9237 (Forecasting Loss:0.1009 + XiCon Loss:1.8228 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 1.0951764583587646
Epoch: 39, Steps: 69 Train Loss: 1.9151 (Forecasting Loss:0.1007 + XiCon Loss:1.8144 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 1.0983624458312988
Epoch: 40, Steps: 69 Train Loss: 1.9095 (Forecasting Loss:0.1010 + XiCon Loss:1.8085 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 1.1096646785736084
Epoch: 41, Steps: 69 Train Loss: 1.9185 (Forecasting Loss:0.1011 + XiCon Loss:1.8175 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 1.1354765892028809
Epoch: 42, Steps: 69 Train Loss: 1.9164 (Forecasting Loss:0.1010 + XiCon Loss:1.8154 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 1.2486562728881836
Epoch: 43, Steps: 69 Train Loss: 1.9224 (Forecasting Loss:0.1008 + XiCon Loss:1.8217 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 1.0934104919433594
Epoch: 44, Steps: 69 Train Loss: 1.9225 (Forecasting Loss:0.1009 + XiCon Loss:1.8216 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 1.0402746200561523
Epoch: 45, Steps: 69 Train Loss: 1.9203 (Forecasting Loss:0.1008 + XiCon Loss:1.8195 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 1.1250026226043701
Epoch: 46, Steps: 69 Train Loss: 1.9156 (Forecasting Loss:0.1007 + XiCon Loss:1.8149 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 1.0841906070709229
Epoch: 47, Steps: 69 Train Loss: 1.9155 (Forecasting Loss:0.1009 + XiCon Loss:1.8146 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 1.1327579021453857
Epoch: 48, Steps: 69 Train Loss: 1.9126 (Forecasting Loss:0.1009 + XiCon Loss:1.8117 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 1.1413676738739014
Epoch: 49, Steps: 69 Train Loss: 1.9197 (Forecasting Loss:0.1008 + XiCon Loss:1.8188 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 1.1777477264404297
Epoch: 50, Steps: 69 Train Loss: 1.9226 (Forecasting Loss:0.1011 + XiCon Loss:1.8215 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9893312454223633
Epoch: 51, Steps: 69 Train Loss: 1.9140 (Forecasting Loss:0.1008 + XiCon Loss:1.8131 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 1.0938889980316162
Epoch: 52, Steps: 69 Train Loss: 1.9172 (Forecasting Loss:0.1008 + XiCon Loss:1.8165 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 1.0692903995513916
Epoch: 53, Steps: 69 Train Loss: 1.9093 (Forecasting Loss:0.1007 + XiCon Loss:1.8087 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 1.065993309020996
Epoch: 54, Steps: 69 Train Loss: 1.9215 (Forecasting Loss:0.1009 + XiCon Loss:1.8206 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 1.1049880981445312
Epoch: 55, Steps: 69 Train Loss: 1.9187 (Forecasting Loss:0.1008 + XiCon Loss:1.8179 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 1.1565594673156738
Epoch: 56, Steps: 69 Train Loss: 1.9153 (Forecasting Loss:0.1009 + XiCon Loss:1.8144 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 1.0949182510375977
Epoch: 57, Steps: 69 Train Loss: 1.9235 (Forecasting Loss:0.1011 + XiCon Loss:1.8224 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 1.1624627113342285
Epoch: 58, Steps: 69 Train Loss: 1.9241 (Forecasting Loss:0.1011 + XiCon Loss:1.8231 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 1.1325814723968506
Epoch: 59, Steps: 69 Train Loss: 1.9197 (Forecasting Loss:0.1007 + XiCon Loss:1.8190 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 1.1617751121520996
Epoch: 60, Steps: 69 Train Loss: 1.9181 (Forecasting Loss:0.1008 + XiCon Loss:1.8173 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 1.126854658126831
Epoch: 61, Steps: 69 Train Loss: 1.9163 (Forecasting Loss:0.1008 + XiCon Loss:1.8155 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 1.169360637664795
Epoch: 62, Steps: 69 Train Loss: 1.9164 (Forecasting Loss:0.1010 + XiCon Loss:1.8153 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 1.0388972759246826
Epoch: 63, Steps: 69 Train Loss: 1.9149 (Forecasting Loss:0.1010 + XiCon Loss:1.8140 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 1.0910582542419434
Epoch: 64, Steps: 69 Train Loss: 1.9155 (Forecasting Loss:0.1010 + XiCon Loss:1.8145 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 1.0381689071655273
Epoch: 65, Steps: 69 Train Loss: 1.9235 (Forecasting Loss:0.1010 + XiCon Loss:1.8225 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 1.068340539932251
Epoch: 66, Steps: 69 Train Loss: 1.9212 (Forecasting Loss:0.1009 + XiCon Loss:1.8202 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 1.0717294216156006
Epoch: 67, Steps: 69 Train Loss: 1.9185 (Forecasting Loss:0.1011 + XiCon Loss:1.8174 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 1.069866418838501
Epoch: 68, Steps: 69 Train Loss: 1.9074 (Forecasting Loss:0.1009 + XiCon Loss:1.8065 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 1.0922071933746338
Epoch: 69, Steps: 69 Train Loss: 1.9262 (Forecasting Loss:0.1007 + XiCon Loss:1.8255 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 1.1690239906311035
Epoch: 70, Steps: 69 Train Loss: 1.9303 (Forecasting Loss:0.1008 + XiCon Loss:1.8295 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 1.0834600925445557
Epoch: 71, Steps: 69 Train Loss: 1.9245 (Forecasting Loss:0.1011 + XiCon Loss:1.8233 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 1.0801162719726562
Epoch: 72, Steps: 69 Train Loss: 1.9161 (Forecasting Loss:0.1010 + XiCon Loss:1.8152 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 1.060234546661377
Epoch: 73, Steps: 69 Train Loss: 1.9171 (Forecasting Loss:0.1010 + XiCon Loss:1.8162 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 1.1556096076965332
Epoch: 74, Steps: 69 Train Loss: 1.9179 (Forecasting Loss:0.1007 + XiCon Loss:1.8172 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 1.1092925071716309
Epoch: 75, Steps: 69 Train Loss: 1.9081 (Forecasting Loss:0.1010 + XiCon Loss:1.8072 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 1.0971183776855469
Epoch: 76, Steps: 69 Train Loss: 1.9241 (Forecasting Loss:0.1007 + XiCon Loss:1.8233 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
Validation loss decreased (0.208923 --> 0.208923).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 1.0694665908813477
Epoch: 77, Steps: 69 Train Loss: 1.9236 (Forecasting Loss:0.1008 + XiCon Loss:1.8228 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 1.1009907722473145
Epoch: 78, Steps: 69 Train Loss: 1.9177 (Forecasting Loss:0.1008 + XiCon Loss:1.8169 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 1.210334300994873
Epoch: 79, Steps: 69 Train Loss: 1.9186 (Forecasting Loss:0.1009 + XiCon Loss:1.8176 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 1.0674493312835693
Epoch: 80, Steps: 69 Train Loss: 1.9245 (Forecasting Loss:0.1010 + XiCon Loss:1.8235 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 1.1517233848571777
Epoch: 81, Steps: 69 Train Loss: 1.9245 (Forecasting Loss:0.1009 + XiCon Loss:1.8237 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 1.122096300125122
Epoch: 82, Steps: 69 Train Loss: 1.9124 (Forecasting Loss:0.1009 + XiCon Loss:1.8115 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 1.1142604351043701
Epoch: 83, Steps: 69 Train Loss: 1.9193 (Forecasting Loss:0.1008 + XiCon Loss:1.8185 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 1.1621994972229004
Epoch: 84, Steps: 69 Train Loss: 1.9204 (Forecasting Loss:0.1010 + XiCon Loss:1.8194 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 1.0304150581359863
Epoch: 85, Steps: 69 Train Loss: 1.9192 (Forecasting Loss:0.1009 + XiCon Loss:1.8184 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 1.0634632110595703
Epoch: 86, Steps: 69 Train Loss: 1.9193 (Forecasting Loss:0.1010 + XiCon Loss:1.8182 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1175
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055276572704315186, mae:0.17974138259887695, mape:0.12491869181394577, mspe:0.0360068716108799 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0552+-0.00037, MAE:0.1794+-0.00090, MAPE:0.1253+-0.00068, MSPE:0.0367+-0.00060, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7276
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.4514293670654297
Epoch: 1, Steps: 64 Train Loss: 18.3967 (Forecasting Loss:0.5016 + XiCon Loss:1.7895 x Lambda(10.0)), Vali MSE Loss: 0.9639 Test MSE Loss: 0.5135
Validation loss decreased (inf --> 0.963855).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.1919522285461426
Epoch: 2, Steps: 64 Train Loss: 18.3790 (Forecasting Loss:0.4974 + XiCon Loss:1.7882 x Lambda(10.0)), Vali MSE Loss: 0.9529 Test MSE Loss: 0.5068
Validation loss decreased (0.963855 --> 0.952946).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.195464849472046
Epoch: 3, Steps: 64 Train Loss: 18.3661 (Forecasting Loss:0.4909 + XiCon Loss:1.7875 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.5042
Validation loss decreased (0.952946 --> 0.942602).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.142829418182373
Epoch: 4, Steps: 64 Train Loss: 18.3095 (Forecasting Loss:0.4890 + XiCon Loss:1.7821 x Lambda(10.0)), Vali MSE Loss: 0.9451 Test MSE Loss: 0.5029
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.1421799659729004
Epoch: 5, Steps: 64 Train Loss: 18.3345 (Forecasting Loss:0.4864 + XiCon Loss:1.7848 x Lambda(10.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5023
Validation loss decreased (0.942602 --> 0.938759).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.1992721557617188
Epoch: 6, Steps: 64 Train Loss: 18.3492 (Forecasting Loss:0.4857 + XiCon Loss:1.7864 x Lambda(10.0)), Vali MSE Loss: 0.9389 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.1393985748291016
Epoch: 7, Steps: 64 Train Loss: 18.3456 (Forecasting Loss:0.4858 + XiCon Loss:1.7860 x Lambda(10.0)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5019
Validation loss decreased (0.938759 --> 0.936985).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.1697916984558105
Epoch: 8, Steps: 64 Train Loss: 18.3539 (Forecasting Loss:0.4855 + XiCon Loss:1.7868 x Lambda(10.0)), Vali MSE Loss: 0.9368 Test MSE Loss: 0.5018
Validation loss decreased (0.936985 --> 0.936770).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0942137241363525
Epoch: 9, Steps: 64 Train Loss: 18.3595 (Forecasting Loss:0.4848 + XiCon Loss:1.7875 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.1437530517578125
Epoch: 10, Steps: 64 Train Loss: 18.3333 (Forecasting Loss:0.4844 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.202601432800293
Epoch: 11, Steps: 64 Train Loss: 18.3240 (Forecasting Loss:0.4856 + XiCon Loss:1.7838 x Lambda(10.0)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.2110927104949951
Epoch: 12, Steps: 64 Train Loss: 18.3984 (Forecasting Loss:0.4852 + XiCon Loss:1.7913 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.1753246784210205
Epoch: 13, Steps: 64 Train Loss: 18.3059 (Forecasting Loss:0.4855 + XiCon Loss:1.7820 x Lambda(10.0)), Vali MSE Loss: 0.9397 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.1920557022094727
Epoch: 14, Steps: 64 Train Loss: 18.3366 (Forecasting Loss:0.4847 + XiCon Loss:1.7852 x Lambda(10.0)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.1656708717346191
Epoch: 15, Steps: 64 Train Loss: 18.3302 (Forecasting Loss:0.4859 + XiCon Loss:1.7844 x Lambda(10.0)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.1683769226074219
Epoch: 16, Steps: 64 Train Loss: 18.3027 (Forecasting Loss:0.4849 + XiCon Loss:1.7818 x Lambda(10.0)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9563641548156738
Epoch: 17, Steps: 64 Train Loss: 18.3531 (Forecasting Loss:0.4858 + XiCon Loss:1.7867 x Lambda(10.0)), Vali MSE Loss: 0.9358 Test MSE Loss: 0.5017
Validation loss decreased (0.936770 --> 0.935776).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9759585857391357
Epoch: 18, Steps: 64 Train Loss: 18.3268 (Forecasting Loss:0.4857 + XiCon Loss:1.7841 x Lambda(10.0)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 2.112680435180664
Epoch: 19, Steps: 64 Train Loss: 18.3470 (Forecasting Loss:0.4857 + XiCon Loss:1.7861 x Lambda(10.0)), Vali MSE Loss: 0.9390 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 2.9125046730041504
Epoch: 20, Steps: 64 Train Loss: 18.3338 (Forecasting Loss:0.4852 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 2.4650070667266846
Epoch: 21, Steps: 64 Train Loss: 18.3297 (Forecasting Loss:0.4847 + XiCon Loss:1.7845 x Lambda(10.0)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.208561658859253
Epoch: 22, Steps: 64 Train Loss: 18.3804 (Forecasting Loss:0.4847 + XiCon Loss:1.7896 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.1227636337280273
Epoch: 23, Steps: 64 Train Loss: 18.3518 (Forecasting Loss:0.4845 + XiCon Loss:1.7867 x Lambda(10.0)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.0751357078552246
Epoch: 24, Steps: 64 Train Loss: 18.3131 (Forecasting Loss:0.4857 + XiCon Loss:1.7827 x Lambda(10.0)), Vali MSE Loss: 0.9394 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9424726963043213
Epoch: 25, Steps: 64 Train Loss: 18.3379 (Forecasting Loss:0.4846 + XiCon Loss:1.7853 x Lambda(10.0)), Vali MSE Loss: 0.9402 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8667564392089844
Epoch: 26, Steps: 64 Train Loss: 18.3667 (Forecasting Loss:0.4845 + XiCon Loss:1.7882 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9631466865539551
Epoch: 27, Steps: 64 Train Loss: 18.3146 (Forecasting Loss:0.4851 + XiCon Loss:1.7829 x Lambda(10.0)), Vali MSE Loss: 0.9399 Test MSE Loss: 0.5017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.470161497592926, mae:0.5332592725753784, mape:0.44958850741386414, mspe:0.5999740362167358 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7047
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.1906788349151611
Epoch: 1, Steps: 64 Train Loss: 18.3205 (Forecasting Loss:0.4928 + XiCon Loss:1.7828 x Lambda(10.0)), Vali MSE Loss: 0.9330 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932956).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.1843914985656738
Epoch: 2, Steps: 64 Train Loss: 18.2970 (Forecasting Loss:0.4901 + XiCon Loss:1.7807 x Lambda(10.0)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932956 --> 0.915088).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.1632192134857178
Epoch: 3, Steps: 64 Train Loss: 18.3076 (Forecasting Loss:0.4837 + XiCon Loss:1.7824 x Lambda(10.0)), Vali MSE Loss: 0.9128 Test MSE Loss: 0.5130
Validation loss decreased (0.915088 --> 0.912782).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.2138867378234863
Epoch: 4, Steps: 64 Train Loss: 18.3565 (Forecasting Loss:0.4808 + XiCon Loss:1.7876 x Lambda(10.0)), Vali MSE Loss: 0.9097 Test MSE Loss: 0.5118
Validation loss decreased (0.912782 --> 0.909719).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.1518805027008057
Epoch: 5, Steps: 64 Train Loss: 18.3399 (Forecasting Loss:0.4798 + XiCon Loss:1.7860 x Lambda(10.0)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5113
Validation loss decreased (0.909719 --> 0.907176).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.109480381011963
Epoch: 6, Steps: 64 Train Loss: 18.2854 (Forecasting Loss:0.4799 + XiCon Loss:1.7806 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5110
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.1590471267700195
Epoch: 7, Steps: 64 Train Loss: 18.2843 (Forecasting Loss:0.4789 + XiCon Loss:1.7805 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.154449701309204
Epoch: 8, Steps: 64 Train Loss: 18.3084 (Forecasting Loss:0.4784 + XiCon Loss:1.7830 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5108
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.15519380569458
Epoch: 9, Steps: 64 Train Loss: 18.3150 (Forecasting Loss:0.4793 + XiCon Loss:1.7836 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5108
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.1506919860839844
Epoch: 10, Steps: 64 Train Loss: 18.3447 (Forecasting Loss:0.4788 + XiCon Loss:1.7866 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.1964926719665527
Epoch: 11, Steps: 64 Train Loss: 18.3472 (Forecasting Loss:0.4778 + XiCon Loss:1.7869 x Lambda(10.0)), Vali MSE Loss: 0.9085 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.150665044784546
Epoch: 12, Steps: 64 Train Loss: 18.3040 (Forecasting Loss:0.4792 + XiCon Loss:1.7825 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5107
Validation loss decreased (0.907176 --> 0.906470).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.1574227809906006
Epoch: 13, Steps: 64 Train Loss: 18.3057 (Forecasting Loss:0.4778 + XiCon Loss:1.7828 x Lambda(10.0)), Vali MSE Loss: 0.9063 Test MSE Loss: 0.5107
Validation loss decreased (0.906470 --> 0.906252).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.1329445838928223
Epoch: 14, Steps: 64 Train Loss: 18.3058 (Forecasting Loss:0.4780 + XiCon Loss:1.7828 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.158231496810913
Epoch: 15, Steps: 64 Train Loss: 18.3044 (Forecasting Loss:0.4801 + XiCon Loss:1.7824 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.1530942916870117
Epoch: 16, Steps: 64 Train Loss: 18.3122 (Forecasting Loss:0.4790 + XiCon Loss:1.7833 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906252 --> 0.906224).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.1588554382324219
Epoch: 17, Steps: 64 Train Loss: 18.3219 (Forecasting Loss:0.4784 + XiCon Loss:1.7844 x Lambda(10.0)), Vali MSE Loss: 0.9035 Test MSE Loss: 0.5107
Validation loss decreased (0.906224 --> 0.903532).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.1400482654571533
Epoch: 18, Steps: 64 Train Loss: 18.3449 (Forecasting Loss:0.4780 + XiCon Loss:1.7867 x Lambda(10.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.5442986488342285
Epoch: 19, Steps: 64 Train Loss: 18.3119 (Forecasting Loss:0.4789 + XiCon Loss:1.7833 x Lambda(10.0)), Vali MSE Loss: 0.9043 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.176933765411377
Epoch: 20, Steps: 64 Train Loss: 18.3036 (Forecasting Loss:0.4784 + XiCon Loss:1.7825 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.1802048683166504
Epoch: 21, Steps: 64 Train Loss: 18.3002 (Forecasting Loss:0.4780 + XiCon Loss:1.7822 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.1129295825958252
Epoch: 22, Steps: 64 Train Loss: 18.3122 (Forecasting Loss:0.4784 + XiCon Loss:1.7834 x Lambda(10.0)), Vali MSE Loss: 0.9012 Test MSE Loss: 0.5107
Validation loss decreased (0.903532 --> 0.901237).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.1235785484313965
Epoch: 23, Steps: 64 Train Loss: 18.3077 (Forecasting Loss:0.4781 + XiCon Loss:1.7830 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.184436321258545
Epoch: 24, Steps: 64 Train Loss: 18.3090 (Forecasting Loss:0.4786 + XiCon Loss:1.7830 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.1553666591644287
Epoch: 25, Steps: 64 Train Loss: 18.3123 (Forecasting Loss:0.4777 + XiCon Loss:1.7835 x Lambda(10.0)), Vali MSE Loss: 0.9028 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.1426818370819092
Epoch: 26, Steps: 64 Train Loss: 18.3108 (Forecasting Loss:0.4798 + XiCon Loss:1.7831 x Lambda(10.0)), Vali MSE Loss: 0.9051 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 1.1514434814453125
Epoch: 27, Steps: 64 Train Loss: 18.3220 (Forecasting Loss:0.4790 + XiCon Loss:1.7843 x Lambda(10.0)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 1.175497055053711
Epoch: 28, Steps: 64 Train Loss: 18.2921 (Forecasting Loss:0.4782 + XiCon Loss:1.7814 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 1.201265811920166
Epoch: 29, Steps: 64 Train Loss: 18.3060 (Forecasting Loss:0.4786 + XiCon Loss:1.7827 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 1.1109931468963623
Epoch: 30, Steps: 64 Train Loss: 18.2950 (Forecasting Loss:0.4779 + XiCon Loss:1.7817 x Lambda(10.0)), Vali MSE Loss: 0.9104 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 1.165933609008789
Epoch: 31, Steps: 64 Train Loss: 18.3253 (Forecasting Loss:0.4793 + XiCon Loss:1.7846 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 1.1413731575012207
Epoch: 32, Steps: 64 Train Loss: 18.2829 (Forecasting Loss:0.4787 + XiCon Loss:1.7804 x Lambda(10.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4846257269382477, mae:0.5368179678916931, mape:0.45702001452445984, mspe:0.6299911737442017 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7136
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.1929981708526611
Epoch: 1, Steps: 64 Train Loss: 18.3397 (Forecasting Loss:0.5013 + XiCon Loss:1.7838 x Lambda(10.0)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973866).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.1820600032806396
Epoch: 2, Steps: 64 Train Loss: 18.4120 (Forecasting Loss:0.4983 + XiCon Loss:1.7914 x Lambda(10.0)), Vali MSE Loss: 0.9577 Test MSE Loss: 0.5002
Validation loss decreased (0.973866 --> 0.957684).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.1045558452606201
Epoch: 3, Steps: 64 Train Loss: 18.3258 (Forecasting Loss:0.4914 + XiCon Loss:1.7834 x Lambda(10.0)), Vali MSE Loss: 0.9526 Test MSE Loss: 0.4982
Validation loss decreased (0.957684 --> 0.952591).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.1783788204193115
Epoch: 4, Steps: 64 Train Loss: 18.3699 (Forecasting Loss:0.4903 + XiCon Loss:1.7880 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4973
Validation loss decreased (0.952591 --> 0.950785).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.2105019092559814
Epoch: 5, Steps: 64 Train Loss: 18.3378 (Forecasting Loss:0.4878 + XiCon Loss:1.7850 x Lambda(10.0)), Vali MSE Loss: 0.9473 Test MSE Loss: 0.4968
Validation loss decreased (0.950785 --> 0.947315).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.1770596504211426
Epoch: 6, Steps: 64 Train Loss: 18.3308 (Forecasting Loss:0.4877 + XiCon Loss:1.7843 x Lambda(10.0)), Vali MSE Loss: 0.9503 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.153961420059204
Epoch: 7, Steps: 64 Train Loss: 18.3536 (Forecasting Loss:0.4863 + XiCon Loss:1.7867 x Lambda(10.0)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.4965
Validation loss decreased (0.947315 --> 0.943971).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.1352968215942383
Epoch: 8, Steps: 64 Train Loss: 18.3347 (Forecasting Loss:0.4872 + XiCon Loss:1.7847 x Lambda(10.0)), Vali MSE Loss: 0.9461 Test MSE Loss: 0.4965
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.1260721683502197
Epoch: 9, Steps: 64 Train Loss: 18.3586 (Forecasting Loss:0.4860 + XiCon Loss:1.7873 x Lambda(10.0)), Vali MSE Loss: 0.9502 Test MSE Loss: 0.4965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.294276237487793
Epoch: 10, Steps: 64 Train Loss: 18.3240 (Forecasting Loss:0.4858 + XiCon Loss:1.7838 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.4965
Validation loss decreased (0.943971 --> 0.942575).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.1448140144348145
Epoch: 11, Steps: 64 Train Loss: 18.3725 (Forecasting Loss:0.4865 + XiCon Loss:1.7886 x Lambda(10.0)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.4964
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.1639151573181152
Epoch: 12, Steps: 64 Train Loss: 18.3871 (Forecasting Loss:0.4871 + XiCon Loss:1.7900 x Lambda(10.0)), Vali MSE Loss: 0.9507 Test MSE Loss: 0.4964
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.1050727367401123
Epoch: 13, Steps: 64 Train Loss: 18.3102 (Forecasting Loss:0.4870 + XiCon Loss:1.7823 x Lambda(10.0)), Vali MSE Loss: 0.9467 Test MSE Loss: 0.4964
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.128957986831665
Epoch: 14, Steps: 64 Train Loss: 18.3694 (Forecasting Loss:0.4868 + XiCon Loss:1.7883 x Lambda(10.0)), Vali MSE Loss: 0.9448 Test MSE Loss: 0.4964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.158421516418457
Epoch: 15, Steps: 64 Train Loss: 18.3926 (Forecasting Loss:0.4862 + XiCon Loss:1.7906 x Lambda(10.0)), Vali MSE Loss: 0.9465 Test MSE Loss: 0.4964
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.1859328746795654
Epoch: 16, Steps: 64 Train Loss: 18.3620 (Forecasting Loss:0.4870 + XiCon Loss:1.7875 x Lambda(10.0)), Vali MSE Loss: 0.9486 Test MSE Loss: 0.4964
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.1794018745422363
Epoch: 17, Steps: 64 Train Loss: 18.3226 (Forecasting Loss:0.4873 + XiCon Loss:1.7835 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.1871278285980225
Epoch: 18, Steps: 64 Train Loss: 18.3296 (Forecasting Loss:0.4858 + XiCon Loss:1.7844 x Lambda(10.0)), Vali MSE Loss: 0.9480 Test MSE Loss: 0.4964
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.149646282196045
Epoch: 19, Steps: 64 Train Loss: 18.3602 (Forecasting Loss:0.4860 + XiCon Loss:1.7874 x Lambda(10.0)), Vali MSE Loss: 0.9445 Test MSE Loss: 0.4964
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.1732149124145508
Epoch: 20, Steps: 64 Train Loss: 18.4053 (Forecasting Loss:0.4859 + XiCon Loss:1.7919 x Lambda(10.0)), Vali MSE Loss: 0.9427 Test MSE Loss: 0.4964
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.46273547410964966, mae:0.5301759243011475, mape:0.4449361562728882, mspe:0.5857211947441101 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.8544
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2003858089447021
Epoch: 1, Steps: 64 Train Loss: 18.3441 (Forecasting Loss:0.4951 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933434).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.1956372261047363
Epoch: 2, Steps: 64 Train Loss: 18.3132 (Forecasting Loss:0.4905 + XiCon Loss:1.7823 x Lambda(10.0)), Vali MSE Loss: 0.9194 Test MSE Loss: 0.5152
Validation loss decreased (0.933434 --> 0.919411).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.220217227935791
Epoch: 3, Steps: 64 Train Loss: 18.3448 (Forecasting Loss:0.4821 + XiCon Loss:1.7863 x Lambda(10.0)), Vali MSE Loss: 0.9156 Test MSE Loss: 0.5120
Validation loss decreased (0.919411 --> 0.915611).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.2267873287200928
Epoch: 4, Steps: 64 Train Loss: 18.3362 (Forecasting Loss:0.4806 + XiCon Loss:1.7856 x Lambda(10.0)), Vali MSE Loss: 0.9115 Test MSE Loss: 0.5105
Validation loss decreased (0.915611 --> 0.911474).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.1057908535003662
Epoch: 5, Steps: 64 Train Loss: 18.3712 (Forecasting Loss:0.4796 + XiCon Loss:1.7892 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5098
Validation loss decreased (0.911474 --> 0.906546).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.158625602722168
Epoch: 6, Steps: 64 Train Loss: 18.3246 (Forecasting Loss:0.4797 + XiCon Loss:1.7845 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5095
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.2581639289855957
Epoch: 7, Steps: 64 Train Loss: 18.3617 (Forecasting Loss:0.4791 + XiCon Loss:1.7883 x Lambda(10.0)), Vali MSE Loss: 0.9099 Test MSE Loss: 0.5093
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.0926764011383057
Epoch: 8, Steps: 64 Train Loss: 18.3390 (Forecasting Loss:0.4780 + XiCon Loss:1.7861 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.162043809890747
Epoch: 9, Steps: 64 Train Loss: 18.3159 (Forecasting Loss:0.4773 + XiCon Loss:1.7839 x Lambda(10.0)), Vali MSE Loss: 0.9046 Test MSE Loss: 0.5092
Validation loss decreased (0.906546 --> 0.904630).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.2200322151184082
Epoch: 10, Steps: 64 Train Loss: 18.2976 (Forecasting Loss:0.4784 + XiCon Loss:1.7819 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5092
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.1580488681793213
Epoch: 11, Steps: 64 Train Loss: 18.3507 (Forecasting Loss:0.4783 + XiCon Loss:1.7872 x Lambda(10.0)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5091
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.1574509143829346
Epoch: 12, Steps: 64 Train Loss: 18.3196 (Forecasting Loss:0.4784 + XiCon Loss:1.7841 x Lambda(10.0)), Vali MSE Loss: 0.9067 Test MSE Loss: 0.5091
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.1659371852874756
Epoch: 13, Steps: 64 Train Loss: 18.3907 (Forecasting Loss:0.4782 + XiCon Loss:1.7912 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5091
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.2121953964233398
Epoch: 14, Steps: 64 Train Loss: 18.3434 (Forecasting Loss:0.4779 + XiCon Loss:1.7865 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5091
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.2199766635894775
Epoch: 15, Steps: 64 Train Loss: 18.3048 (Forecasting Loss:0.4787 + XiCon Loss:1.7826 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.1501822471618652
Epoch: 16, Steps: 64 Train Loss: 18.3199 (Forecasting Loss:0.4777 + XiCon Loss:1.7842 x Lambda(10.0)), Vali MSE Loss: 0.9021 Test MSE Loss: 0.5091
Validation loss decreased (0.904630 --> 0.902142).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.2051351070404053
Epoch: 17, Steps: 64 Train Loss: 18.3483 (Forecasting Loss:0.4779 + XiCon Loss:1.7870 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5091
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.1777400970458984
Epoch: 18, Steps: 64 Train Loss: 18.3277 (Forecasting Loss:0.4792 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5091
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.1695613861083984
Epoch: 19, Steps: 64 Train Loss: 18.3332 (Forecasting Loss:0.4789 + XiCon Loss:1.7854 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5091
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.2091038227081299
Epoch: 20, Steps: 64 Train Loss: 18.3127 (Forecasting Loss:0.4776 + XiCon Loss:1.7835 x Lambda(10.0)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5091
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.1757071018218994
Epoch: 21, Steps: 64 Train Loss: 18.3170 (Forecasting Loss:0.4787 + XiCon Loss:1.7838 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5091
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.2123479843139648
Epoch: 22, Steps: 64 Train Loss: 18.2852 (Forecasting Loss:0.4783 + XiCon Loss:1.7807 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.1109256744384766
Epoch: 23, Steps: 64 Train Loss: 18.2889 (Forecasting Loss:0.4778 + XiCon Loss:1.7811 x Lambda(10.0)), Vali MSE Loss: 0.9052 Test MSE Loss: 0.5091
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.21067214012146
Epoch: 24, Steps: 64 Train Loss: 18.3225 (Forecasting Loss:0.4779 + XiCon Loss:1.7845 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5091
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.1613032817840576
Epoch: 25, Steps: 64 Train Loss: 18.3483 (Forecasting Loss:0.4779 + XiCon Loss:1.7870 x Lambda(10.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5091
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.1212890148162842
Epoch: 26, Steps: 64 Train Loss: 18.3053 (Forecasting Loss:0.4778 + XiCon Loss:1.7828 x Lambda(10.0)), Vali MSE Loss: 0.9089 Test MSE Loss: 0.5091
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4826856553554535, mae:0.5355762839317322, mape:0.45601409673690796, mspe:0.6265523433685303 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7006
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2257750034332275
Epoch: 1, Steps: 64 Train Loss: 18.3588 (Forecasting Loss:0.4949 + XiCon Loss:1.7864 x Lambda(10.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908222).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.152397871017456
Epoch: 2, Steps: 64 Train Loss: 18.3345 (Forecasting Loss:0.4914 + XiCon Loss:1.7843 x Lambda(10.0)), Vali MSE Loss: 0.8924 Test MSE Loss: 0.5398
Validation loss decreased (0.908222 --> 0.892417).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.2638869285583496
Epoch: 3, Steps: 64 Train Loss: 18.3357 (Forecasting Loss:0.4865 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.8930 Test MSE Loss: 0.5365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.2325901985168457
Epoch: 4, Steps: 64 Train Loss: 18.2948 (Forecasting Loss:0.4827 + XiCon Loss:1.7812 x Lambda(10.0)), Vali MSE Loss: 0.8856 Test MSE Loss: 0.5348
Validation loss decreased (0.892417 --> 0.885594).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.1260476112365723
Epoch: 5, Steps: 64 Train Loss: 18.2917 (Forecasting Loss:0.4819 + XiCon Loss:1.7810 x Lambda(10.0)), Vali MSE Loss: 0.8841 Test MSE Loss: 0.5341
Validation loss decreased (0.885594 --> 0.884078).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.2024736404418945
Epoch: 6, Steps: 64 Train Loss: 18.3072 (Forecasting Loss:0.4802 + XiCon Loss:1.7827 x Lambda(10.0)), Vali MSE Loss: 0.8865 Test MSE Loss: 0.5337
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.2094225883483887
Epoch: 7, Steps: 64 Train Loss: 18.3462 (Forecasting Loss:0.4804 + XiCon Loss:1.7866 x Lambda(10.0)), Vali MSE Loss: 0.8883 Test MSE Loss: 0.5335
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.1663966178894043
Epoch: 8, Steps: 64 Train Loss: 18.3305 (Forecasting Loss:0.4828 + XiCon Loss:1.7848 x Lambda(10.0)), Vali MSE Loss: 0.8900 Test MSE Loss: 0.5334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.1283342838287354
Epoch: 9, Steps: 64 Train Loss: 18.3283 (Forecasting Loss:0.4791 + XiCon Loss:1.7849 x Lambda(10.0)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5334
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.1826255321502686
Epoch: 10, Steps: 64 Train Loss: 18.3263 (Forecasting Loss:0.4807 + XiCon Loss:1.7846 x Lambda(10.0)), Vali MSE Loss: 0.8857 Test MSE Loss: 0.5334
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.1612825393676758
Epoch: 11, Steps: 64 Train Loss: 18.3616 (Forecasting Loss:0.4812 + XiCon Loss:1.7880 x Lambda(10.0)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5334
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.1577322483062744
Epoch: 12, Steps: 64 Train Loss: 18.3426 (Forecasting Loss:0.4796 + XiCon Loss:1.7863 x Lambda(10.0)), Vali MSE Loss: 0.8855 Test MSE Loss: 0.5333
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.1707050800323486
Epoch: 13, Steps: 64 Train Loss: 18.3162 (Forecasting Loss:0.4812 + XiCon Loss:1.7835 x Lambda(10.0)), Vali MSE Loss: 0.8868 Test MSE Loss: 0.5333
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.158646821975708
Epoch: 14, Steps: 64 Train Loss: 18.3429 (Forecasting Loss:0.4805 + XiCon Loss:1.7862 x Lambda(10.0)), Vali MSE Loss: 0.8851 Test MSE Loss: 0.5333
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.200911283493042
Epoch: 15, Steps: 64 Train Loss: 18.3224 (Forecasting Loss:0.4812 + XiCon Loss:1.7841 x Lambda(10.0)), Vali MSE Loss: 0.8853 Test MSE Loss: 0.5333
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5174427032470703, mae:0.5507404208183289, mape:0.47553277015686035, mspe:0.68883216381073 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4835+-0.02607, MAE:0.5373+-0.00983, MAPE:0.4566+-0.01448, MSPE:0.6262+-0.04913, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7210
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.743955373764038
Epoch: 1, Steps: 59 Train Loss: 19.0091 (Forecasting Loss:0.9906 + XiCon Loss:1.8018 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248621).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.426602840423584
Epoch: 2, Steps: 59 Train Loss: 18.9919 (Forecasting Loss:0.9903 + XiCon Loss:1.8002 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.4902410507202148
Epoch: 3, Steps: 59 Train Loss: 19.0215 (Forecasting Loss:0.9892 + XiCon Loss:1.8032 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.460512399673462
Epoch: 4, Steps: 59 Train Loss: 18.9810 (Forecasting Loss:0.9890 + XiCon Loss:1.7992 x Lambda(10.0)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9822
Validation loss decreased (1.248621 --> 1.246888).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.4584391117095947
Epoch: 5, Steps: 59 Train Loss: 19.0242 (Forecasting Loss:0.9890 + XiCon Loss:1.8035 x Lambda(10.0)), Vali MSE Loss: 1.2510 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.4298133850097656
Epoch: 6, Steps: 59 Train Loss: 18.9807 (Forecasting Loss:0.9899 + XiCon Loss:1.7991 x Lambda(10.0)), Vali MSE Loss: 1.2460 Test MSE Loss: 0.9822
Validation loss decreased (1.246888 --> 1.246024).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.4864227771759033
Epoch: 7, Steps: 59 Train Loss: 19.0047 (Forecasting Loss:0.9887 + XiCon Loss:1.8016 x Lambda(10.0)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9822
Validation loss decreased (1.246024 --> 1.244972).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.4417076110839844
Epoch: 8, Steps: 59 Train Loss: 19.0482 (Forecasting Loss:0.9881 + XiCon Loss:1.8060 x Lambda(10.0)), Vali MSE Loss: 1.2479 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.4942433834075928
Epoch: 9, Steps: 59 Train Loss: 19.0017 (Forecasting Loss:0.9890 + XiCon Loss:1.8013 x Lambda(10.0)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9822
Validation loss decreased (1.244972 --> 1.244433).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.4485852718353271
Epoch: 10, Steps: 59 Train Loss: 19.0115 (Forecasting Loss:0.9889 + XiCon Loss:1.8023 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.4477698802947998
Epoch: 11, Steps: 59 Train Loss: 18.9924 (Forecasting Loss:0.9878 + XiCon Loss:1.8005 x Lambda(10.0)), Vali MSE Loss: 1.2446 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.474452018737793
Epoch: 12, Steps: 59 Train Loss: 19.0674 (Forecasting Loss:0.9887 + XiCon Loss:1.8079 x Lambda(10.0)), Vali MSE Loss: 1.2523 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.4996724128723145
Epoch: 13, Steps: 59 Train Loss: 18.9909 (Forecasting Loss:0.9890 + XiCon Loss:1.8002 x Lambda(10.0)), Vali MSE Loss: 1.2456 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.588792324066162
Epoch: 14, Steps: 59 Train Loss: 18.9795 (Forecasting Loss:0.9889 + XiCon Loss:1.7991 x Lambda(10.0)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.4896659851074219
Epoch: 15, Steps: 59 Train Loss: 19.0187 (Forecasting Loss:0.9888 + XiCon Loss:1.8030 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.5056531429290771
Epoch: 16, Steps: 59 Train Loss: 19.0118 (Forecasting Loss:0.9894 + XiCon Loss:1.8022 x Lambda(10.0)), Vali MSE Loss: 1.2490 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.4824633598327637
Epoch: 17, Steps: 59 Train Loss: 19.0377 (Forecasting Loss:0.9889 + XiCon Loss:1.8049 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.428257942199707
Epoch: 18, Steps: 59 Train Loss: 18.9951 (Forecasting Loss:0.9896 + XiCon Loss:1.8005 x Lambda(10.0)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.4484312534332275
Epoch: 19, Steps: 59 Train Loss: 19.0723 (Forecasting Loss:0.9895 + XiCon Loss:1.8083 x Lambda(10.0)), Vali MSE Loss: 1.2416 Test MSE Loss: 0.9822
Validation loss decreased (1.244433 --> 1.241621).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.4269623756408691
Epoch: 20, Steps: 59 Train Loss: 19.0444 (Forecasting Loss:0.9888 + XiCon Loss:1.8056 x Lambda(10.0)), Vali MSE Loss: 1.2439 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.4734020233154297
Epoch: 21, Steps: 59 Train Loss: 19.0262 (Forecasting Loss:0.9898 + XiCon Loss:1.8036 x Lambda(10.0)), Vali MSE Loss: 1.2514 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.5231602191925049
Epoch: 22, Steps: 59 Train Loss: 18.9682 (Forecasting Loss:0.9903 + XiCon Loss:1.7978 x Lambda(10.0)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.4564409255981445
Epoch: 23, Steps: 59 Train Loss: 19.0442 (Forecasting Loss:0.9880 + XiCon Loss:1.8056 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.4907605648040771
Epoch: 24, Steps: 59 Train Loss: 18.9920 (Forecasting Loss:0.9893 + XiCon Loss:1.8003 x Lambda(10.0)), Vali MSE Loss: 1.2547 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.4313194751739502
Epoch: 25, Steps: 59 Train Loss: 18.9789 (Forecasting Loss:0.9890 + XiCon Loss:1.7990 x Lambda(10.0)), Vali MSE Loss: 1.2521 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.4679648876190186
Epoch: 26, Steps: 59 Train Loss: 18.9803 (Forecasting Loss:0.9891 + XiCon Loss:1.7991 x Lambda(10.0)), Vali MSE Loss: 1.2574 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.4480736255645752
Epoch: 27, Steps: 59 Train Loss: 19.0260 (Forecasting Loss:0.9887 + XiCon Loss:1.8037 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.474825382232666
Epoch: 28, Steps: 59 Train Loss: 18.9629 (Forecasting Loss:0.9901 + XiCon Loss:1.7973 x Lambda(10.0)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.4109749794006348
Epoch: 29, Steps: 59 Train Loss: 19.0085 (Forecasting Loss:0.9886 + XiCon Loss:1.8020 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9822
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1456271409988403, mae:0.818728506565094, mape:0.7821676135063171, mspe:1.8305141925811768 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7245
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.443528413772583
Epoch: 1, Steps: 59 Train Loss: 18.9694 (Forecasting Loss:0.9892 + XiCon Loss:1.7980 x Lambda(10.0)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236818).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.4376416206359863
Epoch: 2, Steps: 59 Train Loss: 19.0120 (Forecasting Loss:0.9886 + XiCon Loss:1.8023 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236818 --> 1.234320).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.4552323818206787
Epoch: 3, Steps: 59 Train Loss: 18.9451 (Forecasting Loss:0.9873 + XiCon Loss:1.7958 x Lambda(10.0)), Vali MSE Loss: 1.2391 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.4534223079681396
Epoch: 4, Steps: 59 Train Loss: 19.0637 (Forecasting Loss:0.9879 + XiCon Loss:1.8076 x Lambda(10.0)), Vali MSE Loss: 1.2406 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.6467478275299072
Epoch: 5, Steps: 59 Train Loss: 18.9648 (Forecasting Loss:0.9886 + XiCon Loss:1.7976 x Lambda(10.0)), Vali MSE Loss: 1.2296 Test MSE Loss: 0.9929
Validation loss decreased (1.234320 --> 1.229630).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.5610699653625488
Epoch: 6, Steps: 59 Train Loss: 19.0054 (Forecasting Loss:0.9885 + XiCon Loss:1.8017 x Lambda(10.0)), Vali MSE Loss: 1.2381 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.4992599487304688
Epoch: 7, Steps: 59 Train Loss: 19.0168 (Forecasting Loss:0.9858 + XiCon Loss:1.8031 x Lambda(10.0)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.4726099967956543
Epoch: 8, Steps: 59 Train Loss: 19.0359 (Forecasting Loss:0.9868 + XiCon Loss:1.8049 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.4659035205841064
Epoch: 9, Steps: 59 Train Loss: 19.0154 (Forecasting Loss:0.9868 + XiCon Loss:1.8029 x Lambda(10.0)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.4566254615783691
Epoch: 10, Steps: 59 Train Loss: 18.9560 (Forecasting Loss:0.9879 + XiCon Loss:1.7968 x Lambda(10.0)), Vali MSE Loss: 1.2337 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.4202957153320312
Epoch: 11, Steps: 59 Train Loss: 18.9859 (Forecasting Loss:0.9873 + XiCon Loss:1.7999 x Lambda(10.0)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.4932022094726562
Epoch: 12, Steps: 59 Train Loss: 18.9993 (Forecasting Loss:0.9877 + XiCon Loss:1.8012 x Lambda(10.0)), Vali MSE Loss: 1.2262 Test MSE Loss: 0.9928
Validation loss decreased (1.229630 --> 1.226228).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.454399824142456
Epoch: 13, Steps: 59 Train Loss: 19.0469 (Forecasting Loss:0.9882 + XiCon Loss:1.8059 x Lambda(10.0)), Vali MSE Loss: 1.2306 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.496950387954712
Epoch: 14, Steps: 59 Train Loss: 19.0278 (Forecasting Loss:0.9877 + XiCon Loss:1.8040 x Lambda(10.0)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.4985320568084717
Epoch: 15, Steps: 59 Train Loss: 19.0135 (Forecasting Loss:0.9883 + XiCon Loss:1.8025 x Lambda(10.0)), Vali MSE Loss: 1.2265 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.4905829429626465
Epoch: 16, Steps: 59 Train Loss: 19.0135 (Forecasting Loss:0.9869 + XiCon Loss:1.8027 x Lambda(10.0)), Vali MSE Loss: 1.2418 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.4675848484039307
Epoch: 17, Steps: 59 Train Loss: 19.0224 (Forecasting Loss:0.9875 + XiCon Loss:1.8035 x Lambda(10.0)), Vali MSE Loss: 1.2282 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.499864101409912
Epoch: 18, Steps: 59 Train Loss: 18.9869 (Forecasting Loss:0.9880 + XiCon Loss:1.7999 x Lambda(10.0)), Vali MSE Loss: 1.2301 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.4952759742736816
Epoch: 19, Steps: 59 Train Loss: 19.0159 (Forecasting Loss:0.9874 + XiCon Loss:1.8028 x Lambda(10.0)), Vali MSE Loss: 1.2360 Test MSE Loss: 0.9928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.443856954574585
Epoch: 20, Steps: 59 Train Loss: 18.9701 (Forecasting Loss:0.9875 + XiCon Loss:1.7983 x Lambda(10.0)), Vali MSE Loss: 1.2332 Test MSE Loss: 0.9928
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.4424631595611572
Epoch: 21, Steps: 59 Train Loss: 18.9514 (Forecasting Loss:0.9875 + XiCon Loss:1.7964 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9928
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.4364583492279053
Epoch: 22, Steps: 59 Train Loss: 19.0166 (Forecasting Loss:0.9885 + XiCon Loss:1.8028 x Lambda(10.0)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9928
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1612199544906616, mae:0.8244370818138123, mape:0.7876439690589905, mspe:1.850722312927246 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6972
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.4139893054962158
Epoch: 1, Steps: 59 Train Loss: 18.9356 (Forecasting Loss:0.9902 + XiCon Loss:1.7945 x Lambda(10.0)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247579).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.464582920074463
Epoch: 2, Steps: 59 Train Loss: 19.0363 (Forecasting Loss:0.9906 + XiCon Loss:1.8046 x Lambda(10.0)), Vali MSE Loss: 1.2355 Test MSE Loss: 0.9844
Validation loss decreased (1.247579 --> 1.235484).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.4794855117797852
Epoch: 3, Steps: 59 Train Loss: 18.9321 (Forecasting Loss:0.9899 + XiCon Loss:1.7942 x Lambda(10.0)), Vali MSE Loss: 1.2347 Test MSE Loss: 0.9842
Validation loss decreased (1.235484 --> 1.234669).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.4614014625549316
Epoch: 4, Steps: 59 Train Loss: 18.9958 (Forecasting Loss:0.9884 + XiCon Loss:1.8007 x Lambda(10.0)), Vali MSE Loss: 1.2540 Test MSE Loss: 0.9842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.4122488498687744
Epoch: 5, Steps: 59 Train Loss: 18.9723 (Forecasting Loss:0.9886 + XiCon Loss:1.7984 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9842
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.4506263732910156
Epoch: 6, Steps: 59 Train Loss: 19.0406 (Forecasting Loss:0.9894 + XiCon Loss:1.8051 x Lambda(10.0)), Vali MSE Loss: 1.2441 Test MSE Loss: 0.9841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.453512191772461
Epoch: 7, Steps: 59 Train Loss: 18.9568 (Forecasting Loss:0.9893 + XiCon Loss:1.7968 x Lambda(10.0)), Vali MSE Loss: 1.2497 Test MSE Loss: 0.9841
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.5097227096557617
Epoch: 8, Steps: 59 Train Loss: 18.9760 (Forecasting Loss:0.9882 + XiCon Loss:1.7988 x Lambda(10.0)), Vali MSE Loss: 1.2581 Test MSE Loss: 0.9841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.4766004085540771
Epoch: 9, Steps: 59 Train Loss: 19.0219 (Forecasting Loss:0.9876 + XiCon Loss:1.8034 x Lambda(10.0)), Vali MSE Loss: 1.2505 Test MSE Loss: 0.9841
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.4480161666870117
Epoch: 10, Steps: 59 Train Loss: 19.0023 (Forecasting Loss:0.9892 + XiCon Loss:1.8013 x Lambda(10.0)), Vali MSE Loss: 1.2537 Test MSE Loss: 0.9841
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.4954307079315186
Epoch: 11, Steps: 59 Train Loss: 19.0233 (Forecasting Loss:0.9878 + XiCon Loss:1.8035 x Lambda(10.0)), Vali MSE Loss: 1.2474 Test MSE Loss: 0.9841
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.7923378944396973
Epoch: 12, Steps: 59 Train Loss: 18.9255 (Forecasting Loss:0.9884 + XiCon Loss:1.7937 x Lambda(10.0)), Vali MSE Loss: 1.2410 Test MSE Loss: 0.9841
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.5418827533721924
Epoch: 13, Steps: 59 Train Loss: 18.9644 (Forecasting Loss:0.9889 + XiCon Loss:1.7976 x Lambda(10.0)), Vali MSE Loss: 1.2571 Test MSE Loss: 0.9841
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1480365991592407, mae:0.8204628229141235, mape:0.7830780744552612, mspe:1.8314374685287476 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7101
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.4389393329620361
Epoch: 1, Steps: 59 Train Loss: 19.0121 (Forecasting Loss:0.9890 + XiCon Loss:1.8023 x Lambda(10.0)), Vali MSE Loss: 1.2401 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240053).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.4843571186065674
Epoch: 2, Steps: 59 Train Loss: 18.9973 (Forecasting Loss:0.9898 + XiCon Loss:1.8007 x Lambda(10.0)), Vali MSE Loss: 1.2226 Test MSE Loss: 0.9957
Validation loss decreased (1.240053 --> 1.222585).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.4494209289550781
Epoch: 3, Steps: 59 Train Loss: 18.9846 (Forecasting Loss:0.9878 + XiCon Loss:1.7997 x Lambda(10.0)), Vali MSE Loss: 1.2322 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.4104945659637451
Epoch: 4, Steps: 59 Train Loss: 18.9854 (Forecasting Loss:0.9888 + XiCon Loss:1.7997 x Lambda(10.0)), Vali MSE Loss: 1.2315 Test MSE Loss: 0.9956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.516998052597046
Epoch: 5, Steps: 59 Train Loss: 19.0056 (Forecasting Loss:0.9883 + XiCon Loss:1.8017 x Lambda(10.0)), Vali MSE Loss: 1.2234 Test MSE Loss: 0.9956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.4819777011871338
Epoch: 6, Steps: 59 Train Loss: 19.0177 (Forecasting Loss:0.9890 + XiCon Loss:1.8029 x Lambda(10.0)), Vali MSE Loss: 1.2342 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.4629080295562744
Epoch: 7, Steps: 59 Train Loss: 19.0270 (Forecasting Loss:0.9881 + XiCon Loss:1.8039 x Lambda(10.0)), Vali MSE Loss: 1.2252 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.4170773029327393
Epoch: 8, Steps: 59 Train Loss: 19.0543 (Forecasting Loss:0.9873 + XiCon Loss:1.8067 x Lambda(10.0)), Vali MSE Loss: 1.2240 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.4651272296905518
Epoch: 9, Steps: 59 Train Loss: 19.0121 (Forecasting Loss:0.9874 + XiCon Loss:1.8025 x Lambda(10.0)), Vali MSE Loss: 1.2348 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.4876854419708252
Epoch: 10, Steps: 59 Train Loss: 18.9533 (Forecasting Loss:0.9883 + XiCon Loss:1.7965 x Lambda(10.0)), Vali MSE Loss: 1.2329 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.555143117904663
Epoch: 11, Steps: 59 Train Loss: 19.0265 (Forecasting Loss:0.9864 + XiCon Loss:1.8040 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.618579626083374
Epoch: 12, Steps: 59 Train Loss: 19.0278 (Forecasting Loss:0.9881 + XiCon Loss:1.8040 x Lambda(10.0)), Vali MSE Loss: 1.2323 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1653870344161987, mae:0.8261124491691589, mape:0.7890908122062683, mspe:1.8549660444259644 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.8621
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.5098121166229248
Epoch: 1, Steps: 59 Train Loss: 18.9715 (Forecasting Loss:0.9941 + XiCon Loss:1.7977 x Lambda(10.0)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275613).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.646935224533081
Epoch: 2, Steps: 59 Train Loss: 19.0073 (Forecasting Loss:0.9928 + XiCon Loss:1.8014 x Lambda(10.0)), Vali MSE Loss: 1.2745 Test MSE Loss: 0.9658
Validation loss decreased (1.275613 --> 1.274494).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.5520744323730469
Epoch: 3, Steps: 59 Train Loss: 19.0040 (Forecasting Loss:0.9934 + XiCon Loss:1.8011 x Lambda(10.0)), Vali MSE Loss: 1.2849 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.5137958526611328
Epoch: 4, Steps: 59 Train Loss: 18.9384 (Forecasting Loss:0.9923 + XiCon Loss:1.7946 x Lambda(10.0)), Vali MSE Loss: 1.2803 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.519071102142334
Epoch: 5, Steps: 59 Train Loss: 19.0008 (Forecasting Loss:0.9928 + XiCon Loss:1.8008 x Lambda(10.0)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9657
Validation loss decreased (1.274494 --> 1.274270).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.4453744888305664
Epoch: 6, Steps: 59 Train Loss: 18.9869 (Forecasting Loss:0.9935 + XiCon Loss:1.7993 x Lambda(10.0)), Vali MSE Loss: 1.2845 Test MSE Loss: 0.9657
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.4822804927825928
Epoch: 7, Steps: 59 Train Loss: 18.9773 (Forecasting Loss:0.9924 + XiCon Loss:1.7985 x Lambda(10.0)), Vali MSE Loss: 1.2775 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.5139434337615967
Epoch: 8, Steps: 59 Train Loss: 18.9637 (Forecasting Loss:0.9921 + XiCon Loss:1.7972 x Lambda(10.0)), Vali MSE Loss: 1.2825 Test MSE Loss: 0.9657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.4425272941589355
Epoch: 9, Steps: 59 Train Loss: 18.9936 (Forecasting Loss:0.9931 + XiCon Loss:1.8001 x Lambda(10.0)), Vali MSE Loss: 1.2886 Test MSE Loss: 0.9657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.5189440250396729
Epoch: 10, Steps: 59 Train Loss: 18.9516 (Forecasting Loss:0.9923 + XiCon Loss:1.7959 x Lambda(10.0)), Vali MSE Loss: 1.2792 Test MSE Loss: 0.9657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.5059716701507568
Epoch: 11, Steps: 59 Train Loss: 19.0020 (Forecasting Loss:0.9928 + XiCon Loss:1.8009 x Lambda(10.0)), Vali MSE Loss: 1.2748 Test MSE Loss: 0.9657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.5253934860229492
Epoch: 12, Steps: 59 Train Loss: 18.8930 (Forecasting Loss:0.9934 + XiCon Loss:1.7900 x Lambda(10.0)), Vali MSE Loss: 1.2767 Test MSE Loss: 0.9657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.3265330791473389
Epoch: 13, Steps: 59 Train Loss: 18.9739 (Forecasting Loss:0.9922 + XiCon Loss:1.7982 x Lambda(10.0)), Vali MSE Loss: 1.2820 Test MSE Loss: 0.9657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1936936378479004
Epoch: 14, Steps: 59 Train Loss: 19.0606 (Forecasting Loss:0.9917 + XiCon Loss:1.8069 x Lambda(10.0)), Vali MSE Loss: 1.2818 Test MSE Loss: 0.9657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.937108039855957
Epoch: 15, Steps: 59 Train Loss: 18.9416 (Forecasting Loss:0.9928 + XiCon Loss:1.7949 x Lambda(10.0)), Vali MSE Loss: 1.2801 Test MSE Loss: 0.9657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206090450286865, mae:0.8108485341072083, mape:0.7731263041496277, mspe:1.7925655841827393 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00778, MSPE:1.8320+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.8959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 2.215869188308716
Epoch: 1, Steps: 53 Train Loss: 1.6682 (Forecasting Loss:1.4862 + XiCon Loss:1.8198 x Lambda(0.1)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858724).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.54604172706604
Epoch: 2, Steps: 53 Train Loss: 1.6613 (Forecasting Loss:1.4798 + XiCon Loss:1.8151 x Lambda(0.1)), Vali MSE Loss: 1.8414 Test MSE Loss: 0.9182
Validation loss decreased (1.858724 --> 1.841439).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5207183361053467
Epoch: 3, Steps: 53 Train Loss: 1.6553 (Forecasting Loss:1.4737 + XiCon Loss:1.8161 x Lambda(0.1)), Vali MSE Loss: 1.8450 Test MSE Loss: 0.9228
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5614278316497803
Epoch: 4, Steps: 53 Train Loss: 1.6535 (Forecasting Loss:1.4717 + XiCon Loss:1.8180 x Lambda(0.1)), Vali MSE Loss: 1.8424 Test MSE Loss: 0.9250
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.785735845565796
Epoch: 5, Steps: 53 Train Loss: 1.6494 (Forecasting Loss:1.4674 + XiCon Loss:1.8206 x Lambda(0.1)), Vali MSE Loss: 1.8229 Test MSE Loss: 0.9260
Validation loss decreased (1.841439 --> 1.822855).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.8177061080932617
Epoch: 6, Steps: 53 Train Loss: 1.6518 (Forecasting Loss:1.4701 + XiCon Loss:1.8170 x Lambda(0.1)), Vali MSE Loss: 1.8259 Test MSE Loss: 0.9266
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.760909080505371
Epoch: 7, Steps: 53 Train Loss: 1.6484 (Forecasting Loss:1.4667 + XiCon Loss:1.8161 x Lambda(0.1)), Vali MSE Loss: 1.7963 Test MSE Loss: 0.9269
Validation loss decreased (1.822855 --> 1.796343).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.8615827560424805
Epoch: 8, Steps: 53 Train Loss: 1.6467 (Forecasting Loss:1.4657 + XiCon Loss:1.8108 x Lambda(0.1)), Vali MSE Loss: 1.8524 Test MSE Loss: 0.9270
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.9759585857391357
Epoch: 9, Steps: 53 Train Loss: 1.6478 (Forecasting Loss:1.4667 + XiCon Loss:1.8111 x Lambda(0.1)), Vali MSE Loss: 1.8147 Test MSE Loss: 0.9271
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.8043837547302246
Epoch: 10, Steps: 53 Train Loss: 1.6498 (Forecasting Loss:1.4682 + XiCon Loss:1.8162 x Lambda(0.1)), Vali MSE Loss: 1.8543 Test MSE Loss: 0.9271
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.8729932308197021
Epoch: 11, Steps: 53 Train Loss: 1.6465 (Forecasting Loss:1.4649 + XiCon Loss:1.8159 x Lambda(0.1)), Vali MSE Loss: 1.8365 Test MSE Loss: 0.9271
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.8739092350006104
Epoch: 12, Steps: 53 Train Loss: 1.6472 (Forecasting Loss:1.4660 + XiCon Loss:1.8124 x Lambda(0.1)), Vali MSE Loss: 1.8127 Test MSE Loss: 0.9271
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.849412202835083
Epoch: 13, Steps: 53 Train Loss: 1.6488 (Forecasting Loss:1.4667 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 1.8496 Test MSE Loss: 0.9271
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.8632185459136963
Epoch: 14, Steps: 53 Train Loss: 1.6494 (Forecasting Loss:1.4679 + XiCon Loss:1.8155 x Lambda(0.1)), Vali MSE Loss: 1.8041 Test MSE Loss: 0.9271
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.8188660144805908
Epoch: 15, Steps: 53 Train Loss: 1.6462 (Forecasting Loss:1.4647 + XiCon Loss:1.8147 x Lambda(0.1)), Vali MSE Loss: 1.8463 Test MSE Loss: 0.9271
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.7872986793518066
Epoch: 16, Steps: 53 Train Loss: 1.6465 (Forecasting Loss:1.4655 + XiCon Loss:1.8104 x Lambda(0.1)), Vali MSE Loss: 1.8264 Test MSE Loss: 0.9271
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.8258452415466309
Epoch: 17, Steps: 53 Train Loss: 1.6484 (Forecasting Loss:1.4672 + XiCon Loss:1.8121 x Lambda(0.1)), Vali MSE Loss: 1.8433 Test MSE Loss: 0.9271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0581363439559937, mae:0.7955690026283264, mape:0.7948124408721924, mspe:1.7963992357254028 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7409
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.7741692066192627
Epoch: 1, Steps: 53 Train Loss: 1.6648 (Forecasting Loss:1.4830 + XiCon Loss:1.8177 x Lambda(0.1)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828228).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.8573029041290283
Epoch: 2, Steps: 53 Train Loss: 1.6605 (Forecasting Loss:1.4788 + XiCon Loss:1.8170 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9332
Validation loss decreased (1.828228 --> 1.821747).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.7864413261413574
Epoch: 3, Steps: 53 Train Loss: 1.6550 (Forecasting Loss:1.4730 + XiCon Loss:1.8191 x Lambda(0.1)), Vali MSE Loss: 1.7989 Test MSE Loss: 0.9348
Validation loss decreased (1.821747 --> 1.798851).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.7918674945831299
Epoch: 4, Steps: 53 Train Loss: 1.6540 (Forecasting Loss:1.4713 + XiCon Loss:1.8274 x Lambda(0.1)), Vali MSE Loss: 1.8007 Test MSE Loss: 0.9356
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.9265263080596924
Epoch: 5, Steps: 53 Train Loss: 1.6562 (Forecasting Loss:1.4741 + XiCon Loss:1.8203 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9360
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.8141698837280273
Epoch: 6, Steps: 53 Train Loss: 1.6510 (Forecasting Loss:1.4691 + XiCon Loss:1.8195 x Lambda(0.1)), Vali MSE Loss: 1.8084 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.837005376815796
Epoch: 7, Steps: 53 Train Loss: 1.6498 (Forecasting Loss:1.4677 + XiCon Loss:1.8204 x Lambda(0.1)), Vali MSE Loss: 1.7827 Test MSE Loss: 0.9364
Validation loss decreased (1.798851 --> 1.782690).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.7878913879394531
Epoch: 8, Steps: 53 Train Loss: 1.6512 (Forecasting Loss:1.4690 + XiCon Loss:1.8223 x Lambda(0.1)), Vali MSE Loss: 1.8251 Test MSE Loss: 0.9364
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.8717467784881592
Epoch: 9, Steps: 53 Train Loss: 1.6468 (Forecasting Loss:1.4651 + XiCon Loss:1.8167 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9364
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.8842904567718506
Epoch: 10, Steps: 53 Train Loss: 1.6526 (Forecasting Loss:1.4705 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 1.8325 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.8352572917938232
Epoch: 11, Steps: 53 Train Loss: 1.6511 (Forecasting Loss:1.4694 + XiCon Loss:1.8174 x Lambda(0.1)), Vali MSE Loss: 1.8406 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.9582266807556152
Epoch: 12, Steps: 53 Train Loss: 1.6513 (Forecasting Loss:1.4688 + XiCon Loss:1.8251 x Lambda(0.1)), Vali MSE Loss: 1.7661 Test MSE Loss: 0.9365
Validation loss decreased (1.782690 --> 1.766081).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.8592355251312256
Epoch: 13, Steps: 53 Train Loss: 1.6521 (Forecasting Loss:1.4697 + XiCon Loss:1.8232 x Lambda(0.1)), Vali MSE Loss: 1.8091 Test MSE Loss: 0.9365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.8651106357574463
Epoch: 14, Steps: 53 Train Loss: 1.6520 (Forecasting Loss:1.4703 + XiCon Loss:1.8175 x Lambda(0.1)), Vali MSE Loss: 1.8040 Test MSE Loss: 0.9365
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.7951102256774902
Epoch: 15, Steps: 53 Train Loss: 1.6486 (Forecasting Loss:1.4668 + XiCon Loss:1.8176 x Lambda(0.1)), Vali MSE Loss: 1.7980 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.838989019393921
Epoch: 16, Steps: 53 Train Loss: 1.6525 (Forecasting Loss:1.4705 + XiCon Loss:1.8193 x Lambda(0.1)), Vali MSE Loss: 1.7910 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.7489426136016846
Epoch: 17, Steps: 53 Train Loss: 1.6499 (Forecasting Loss:1.4679 + XiCon Loss:1.8199 x Lambda(0.1)), Vali MSE Loss: 1.8299 Test MSE Loss: 0.9365
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.8645305633544922
Epoch: 18, Steps: 53 Train Loss: 1.6505 (Forecasting Loss:1.4684 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 1.8234 Test MSE Loss: 0.9365
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.864640235900879
Epoch: 19, Steps: 53 Train Loss: 1.6537 (Forecasting Loss:1.4716 + XiCon Loss:1.8212 x Lambda(0.1)), Vali MSE Loss: 1.8128 Test MSE Loss: 0.9365
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.8042271137237549
Epoch: 20, Steps: 53 Train Loss: 1.6493 (Forecasting Loss:1.4675 + XiCon Loss:1.8184 x Lambda(0.1)), Vali MSE Loss: 1.8118 Test MSE Loss: 0.9365
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.8797218799591064
Epoch: 21, Steps: 53 Train Loss: 1.6506 (Forecasting Loss:1.4688 + XiCon Loss:1.8176 x Lambda(0.1)), Vali MSE Loss: 1.8081 Test MSE Loss: 0.9365
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.7919018268585205
Epoch: 22, Steps: 53 Train Loss: 1.6525 (Forecasting Loss:1.4704 + XiCon Loss:1.8211 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0729526281356812, mae:0.7999791502952576, mape:0.8005002737045288, mspe:1.8210194110870361 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7328
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.8289241790771484
Epoch: 1, Steps: 53 Train Loss: 1.6682 (Forecasting Loss:1.4859 + XiCon Loss:1.8225 x Lambda(0.1)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899225).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.89459228515625
Epoch: 2, Steps: 53 Train Loss: 1.6658 (Forecasting Loss:1.4836 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 1.8448 Test MSE Loss: 0.9161
Validation loss decreased (1.899225 --> 1.844773).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 2.063692092895508
Epoch: 3, Steps: 53 Train Loss: 1.6621 (Forecasting Loss:1.4805 + XiCon Loss:1.8161 x Lambda(0.1)), Vali MSE Loss: 1.8756 Test MSE Loss: 0.9186
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.9967868328094482
Epoch: 4, Steps: 53 Train Loss: 1.6508 (Forecasting Loss:1.4686 + XiCon Loss:1.8225 x Lambda(0.1)), Vali MSE Loss: 1.8565 Test MSE Loss: 0.9199
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.824615716934204
Epoch: 5, Steps: 53 Train Loss: 1.6547 (Forecasting Loss:1.4727 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 1.8090 Test MSE Loss: 0.9206
Validation loss decreased (1.844773 --> 1.809019).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.8962428569793701
Epoch: 6, Steps: 53 Train Loss: 1.6550 (Forecasting Loss:1.4731 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 1.8717 Test MSE Loss: 0.9210
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.8201942443847656
Epoch: 7, Steps: 53 Train Loss: 1.6569 (Forecasting Loss:1.4745 + XiCon Loss:1.8234 x Lambda(0.1)), Vali MSE Loss: 1.8674 Test MSE Loss: 0.9212
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.8461875915527344
Epoch: 8, Steps: 53 Train Loss: 1.6541 (Forecasting Loss:1.4725 + XiCon Loss:1.8160 x Lambda(0.1)), Vali MSE Loss: 1.8521 Test MSE Loss: 0.9213
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.8844609260559082
Epoch: 9, Steps: 53 Train Loss: 1.6535 (Forecasting Loss:1.4719 + XiCon Loss:1.8159 x Lambda(0.1)), Vali MSE Loss: 1.8343 Test MSE Loss: 0.9213
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.8593735694885254
Epoch: 10, Steps: 53 Train Loss: 1.6506 (Forecasting Loss:1.4682 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 1.8585 Test MSE Loss: 0.9214
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.8645803928375244
Epoch: 11, Steps: 53 Train Loss: 1.6553 (Forecasting Loss:1.4731 + XiCon Loss:1.8219 x Lambda(0.1)), Vali MSE Loss: 1.8447 Test MSE Loss: 0.9214
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.884526014328003
Epoch: 12, Steps: 53 Train Loss: 1.6507 (Forecasting Loss:1.4690 + XiCon Loss:1.8172 x Lambda(0.1)), Vali MSE Loss: 1.8314 Test MSE Loss: 0.9214
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.8100028038024902
Epoch: 13, Steps: 53 Train Loss: 1.6504 (Forecasting Loss:1.4682 + XiCon Loss:1.8213 x Lambda(0.1)), Vali MSE Loss: 1.8584 Test MSE Loss: 0.9214
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.796018362045288
Epoch: 14, Steps: 53 Train Loss: 1.6512 (Forecasting Loss:1.4690 + XiCon Loss:1.8224 x Lambda(0.1)), Vali MSE Loss: 1.8336 Test MSE Loss: 0.9214
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.7982962131500244
Epoch: 15, Steps: 53 Train Loss: 1.6511 (Forecasting Loss:1.4694 + XiCon Loss:1.8172 x Lambda(0.1)), Vali MSE Loss: 1.8907 Test MSE Loss: 0.9214
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0489192008972168, mae:0.7923364043235779, mape:0.7911292314529419, mspe:1.7799880504608154 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7376
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.8261806964874268
Epoch: 1, Steps: 53 Train Loss: 1.6819 (Forecasting Loss:1.4999 + XiCon Loss:1.8202 x Lambda(0.1)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995501).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.8544509410858154
Epoch: 2, Steps: 53 Train Loss: 1.6797 (Forecasting Loss:1.4971 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.9517 Test MSE Loss: 0.8742
Validation loss decreased (1.995501 --> 1.951692).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.8442752361297607
Epoch: 3, Steps: 53 Train Loss: 1.6719 (Forecasting Loss:1.4898 + XiCon Loss:1.8213 x Lambda(0.1)), Vali MSE Loss: 1.9641 Test MSE Loss: 0.8828
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.780407428741455
Epoch: 4, Steps: 53 Train Loss: 1.6628 (Forecasting Loss:1.4809 + XiCon Loss:1.8193 x Lambda(0.1)), Vali MSE Loss: 1.9472 Test MSE Loss: 0.8887
Validation loss decreased (1.951692 --> 1.947206).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.8370752334594727
Epoch: 5, Steps: 53 Train Loss: 1.6564 (Forecasting Loss:1.4745 + XiCon Loss:1.8189 x Lambda(0.1)), Vali MSE Loss: 1.9098 Test MSE Loss: 0.8922
Validation loss decreased (1.947206 --> 1.909780).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.9406514167785645
Epoch: 6, Steps: 53 Train Loss: 1.6571 (Forecasting Loss:1.4753 + XiCon Loss:1.8181 x Lambda(0.1)), Vali MSE Loss: 1.9527 Test MSE Loss: 0.8941
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.8437268733978271
Epoch: 7, Steps: 53 Train Loss: 1.6603 (Forecasting Loss:1.4776 + XiCon Loss:1.8266 x Lambda(0.1)), Vali MSE Loss: 1.9023 Test MSE Loss: 0.8950
Validation loss decreased (1.909780 --> 1.902345).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.8030574321746826
Epoch: 8, Steps: 53 Train Loss: 1.6558 (Forecasting Loss:1.4737 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 1.9123 Test MSE Loss: 0.8955
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.8534839153289795
Epoch: 9, Steps: 53 Train Loss: 1.6559 (Forecasting Loss:1.4738 + XiCon Loss:1.8208 x Lambda(0.1)), Vali MSE Loss: 1.9145 Test MSE Loss: 0.8957
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.830198049545288
Epoch: 10, Steps: 53 Train Loss: 1.6573 (Forecasting Loss:1.4750 + XiCon Loss:1.8234 x Lambda(0.1)), Vali MSE Loss: 1.8911 Test MSE Loss: 0.8958
Validation loss decreased (1.902345 --> 1.891083).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.8315939903259277
Epoch: 11, Steps: 53 Train Loss: 1.6563 (Forecasting Loss:1.4746 + XiCon Loss:1.8175 x Lambda(0.1)), Vali MSE Loss: 1.9052 Test MSE Loss: 0.8958
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.8459110260009766
Epoch: 12, Steps: 53 Train Loss: 1.6556 (Forecasting Loss:1.4740 + XiCon Loss:1.8164 x Lambda(0.1)), Vali MSE Loss: 1.8725 Test MSE Loss: 0.8959
Validation loss decreased (1.891083 --> 1.872452).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.828556776046753
Epoch: 13, Steps: 53 Train Loss: 1.6573 (Forecasting Loss:1.4749 + XiCon Loss:1.8239 x Lambda(0.1)), Vali MSE Loss: 1.9037 Test MSE Loss: 0.8959
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.7663547992706299
Epoch: 14, Steps: 53 Train Loss: 1.6585 (Forecasting Loss:1.4768 + XiCon Loss:1.8171 x Lambda(0.1)), Vali MSE Loss: 1.9079 Test MSE Loss: 0.8959
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.8417465686798096
Epoch: 15, Steps: 53 Train Loss: 1.6586 (Forecasting Loss:1.4767 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 1.9071 Test MSE Loss: 0.8959
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.8599042892456055
Epoch: 16, Steps: 53 Train Loss: 1.6554 (Forecasting Loss:1.4735 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 1.8976 Test MSE Loss: 0.8959
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.8402159214019775
Epoch: 17, Steps: 53 Train Loss: 1.6541 (Forecasting Loss:1.4723 + XiCon Loss:1.8179 x Lambda(0.1)), Vali MSE Loss: 1.9175 Test MSE Loss: 0.8959
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.8088133335113525
Epoch: 18, Steps: 53 Train Loss: 1.6557 (Forecasting Loss:1.4730 + XiCon Loss:1.8271 x Lambda(0.1)), Vali MSE Loss: 1.9320 Test MSE Loss: 0.8959
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.8179972171783447
Epoch: 19, Steps: 53 Train Loss: 1.6527 (Forecasting Loss:1.4701 + XiCon Loss:1.8255 x Lambda(0.1)), Vali MSE Loss: 1.8960 Test MSE Loss: 0.8959
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.888322353363037
Epoch: 20, Steps: 53 Train Loss: 1.6583 (Forecasting Loss:1.4763 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 1.9134 Test MSE Loss: 0.8959
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.8713011741638184
Epoch: 21, Steps: 53 Train Loss: 1.6555 (Forecasting Loss:1.4730 + XiCon Loss:1.8241 x Lambda(0.1)), Vali MSE Loss: 1.8795 Test MSE Loss: 0.8959
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.842787265777588
Epoch: 22, Steps: 53 Train Loss: 1.6577 (Forecasting Loss:1.4752 + XiCon Loss:1.8241 x Lambda(0.1)), Vali MSE Loss: 1.9073 Test MSE Loss: 0.8959
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0116140842437744, mae:0.7801244854927063, mape:0.7760117053985596, mspe:1.7186472415924072 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7815
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.8199641704559326
Epoch: 1, Steps: 53 Train Loss: 1.6582 (Forecasting Loss:1.4763 + XiCon Loss:1.8182 x Lambda(0.1)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740655).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.9425203800201416
Epoch: 2, Steps: 53 Train Loss: 1.6552 (Forecasting Loss:1.4731 + XiCon Loss:1.8202 x Lambda(0.1)), Vali MSE Loss: 1.7205 Test MSE Loss: 0.9607
Validation loss decreased (1.740655 --> 1.720537).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.8408350944519043
Epoch: 3, Steps: 53 Train Loss: 1.6474 (Forecasting Loss:1.4659 + XiCon Loss:1.8157 x Lambda(0.1)), Vali MSE Loss: 1.7406 Test MSE Loss: 0.9645
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.9601247310638428
Epoch: 4, Steps: 53 Train Loss: 1.6454 (Forecasting Loss:1.4635 + XiCon Loss:1.8191 x Lambda(0.1)), Vali MSE Loss: 1.7426 Test MSE Loss: 0.9665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.8476858139038086
Epoch: 5, Steps: 53 Train Loss: 1.6440 (Forecasting Loss:1.4618 + XiCon Loss:1.8221 x Lambda(0.1)), Vali MSE Loss: 1.7446 Test MSE Loss: 0.9676
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.9053001403808594
Epoch: 6, Steps: 53 Train Loss: 1.6437 (Forecasting Loss:1.4617 + XiCon Loss:1.8201 x Lambda(0.1)), Vali MSE Loss: 1.7540 Test MSE Loss: 0.9681
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.876830816268921
Epoch: 7, Steps: 53 Train Loss: 1.6447 (Forecasting Loss:1.4631 + XiCon Loss:1.8157 x Lambda(0.1)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9683
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.8704698085784912
Epoch: 8, Steps: 53 Train Loss: 1.6422 (Forecasting Loss:1.4604 + XiCon Loss:1.8179 x Lambda(0.1)), Vali MSE Loss: 1.7245 Test MSE Loss: 0.9685
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 2.1310598850250244
Epoch: 9, Steps: 53 Train Loss: 1.6441 (Forecasting Loss:1.4620 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 1.7699 Test MSE Loss: 0.9686
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.960402011871338
Epoch: 10, Steps: 53 Train Loss: 1.6410 (Forecasting Loss:1.4593 + XiCon Loss:1.8176 x Lambda(0.1)), Vali MSE Loss: 1.7455 Test MSE Loss: 0.9686
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.8027324676513672
Epoch: 11, Steps: 53 Train Loss: 1.6440 (Forecasting Loss:1.4618 + XiCon Loss:1.8223 x Lambda(0.1)), Vali MSE Loss: 1.7521 Test MSE Loss: 0.9686
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.7894375324249268
Epoch: 12, Steps: 53 Train Loss: 1.6413 (Forecasting Loss:1.4584 + XiCon Loss:1.8297 x Lambda(0.1)), Vali MSE Loss: 1.7510 Test MSE Loss: 0.9686
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1089534759521484, mae:0.8124946355819702, mape:0.8144644498825073, mspe:1.8785148859024048 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0601+-0.04404, MAE:0.7961+-0.01461, MAPE:0.7954+-0.01738, MSPE:1.7989+-0.07249, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.8279
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.9036197
	speed: 0.0224s/iter; left time: 1090.2550s
	iters: 200, epoch: 1 | loss: 0.8161189
	speed: 0.0189s/iter; left time: 915.4192s
	iters: 300, epoch: 1 | loss: 0.5739712
	speed: 0.0162s/iter; left time: 786.0851s
	iters: 400, epoch: 1 | loss: 0.6299307
	speed: 0.0168s/iter; left time: 811.9195s
Epoch: 1 cost time: 8.971567153930664
Epoch: 1, Steps: 487 Train Loss: 0.7633 (Forecasting Loss:0.7417 + XiCon Loss:2.1602 x Lambda(0.01)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036695).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5213712
	speed: 0.0192s/iter; left time: 924.4082s
	iters: 200, epoch: 2 | loss: 0.4794555
	speed: 0.0173s/iter; left time: 830.4903s
	iters: 300, epoch: 2 | loss: 0.5227622
	speed: 0.0162s/iter; left time: 776.6114s
	iters: 400, epoch: 2 | loss: 0.4268671
	speed: 0.0176s/iter; left time: 839.5851s
Epoch: 2 cost time: 8.61007022857666
Epoch: 2, Steps: 487 Train Loss: 0.4561 (Forecasting Loss:0.4346 + XiCon Loss:2.1573 x Lambda(0.01)), Vali MSE Loss: 0.7455 Test MSE Loss: 0.5269
Validation loss decreased (1.036695 --> 0.745488).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.3380231
	speed: 0.0187s/iter; left time: 889.7875s
	iters: 200, epoch: 3 | loss: 0.4450181
	speed: 0.0165s/iter; left time: 781.9562s
	iters: 300, epoch: 3 | loss: 0.5220261
	speed: 0.0164s/iter; left time: 778.6770s
	iters: 400, epoch: 3 | loss: 0.3733153
	speed: 0.0170s/iter; left time: 805.3728s
Epoch: 3 cost time: 8.296252965927124
Epoch: 3, Steps: 487 Train Loss: 0.4264 (Forecasting Loss:0.4049 + XiCon Loss:2.1538 x Lambda(0.01)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5205
Validation loss decreased (0.745488 --> 0.738508).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4984451
	speed: 0.0200s/iter; left time: 942.5117s
	iters: 200, epoch: 4 | loss: 0.4309104
	speed: 0.0162s/iter; left time: 760.6626s
	iters: 300, epoch: 4 | loss: 0.4658310
	speed: 0.0175s/iter; left time: 822.8319s
	iters: 400, epoch: 4 | loss: 0.3420300
	speed: 0.0178s/iter; left time: 833.0509s
Epoch: 4 cost time: 8.679718255996704
Epoch: 4, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3993 + XiCon Loss:2.1593 x Lambda(0.01)), Vali MSE Loss: 0.7318 Test MSE Loss: 0.5150
Validation loss decreased (0.738508 --> 0.731843).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4447641
	speed: 0.0206s/iter; left time: 961.0864s
	iters: 200, epoch: 5 | loss: 0.5348161
	speed: 0.0174s/iter; left time: 808.3656s
	iters: 300, epoch: 5 | loss: 0.3891469
	speed: 0.0165s/iter; left time: 767.2551s
	iters: 400, epoch: 5 | loss: 0.3894567
	speed: 0.0169s/iter; left time: 784.8936s
Epoch: 5 cost time: 8.63204312324524
Epoch: 5, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3968 + XiCon Loss:2.1568 x Lambda(0.01)), Vali MSE Loss: 0.7294 Test MSE Loss: 0.5107
Validation loss decreased (0.731843 --> 0.729397).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4302475
	speed: 0.0194s/iter; left time: 895.6022s
	iters: 200, epoch: 6 | loss: 0.4561649
	speed: 0.0178s/iter; left time: 820.7416s
	iters: 300, epoch: 6 | loss: 0.4425543
	speed: 0.0183s/iter; left time: 839.4047s
	iters: 400, epoch: 6 | loss: 0.3834464
	speed: 0.0168s/iter; left time: 770.5099s
Epoch: 6 cost time: 8.747166156768799
Epoch: 6, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3959 + XiCon Loss:2.1565 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5131
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4233266
	speed: 0.0196s/iter; left time: 897.3859s
	iters: 200, epoch: 7 | loss: 0.3209094
	speed: 0.0164s/iter; left time: 746.2896s
	iters: 300, epoch: 7 | loss: 0.4732240
	speed: 0.0176s/iter; left time: 799.5329s
	iters: 400, epoch: 7 | loss: 0.4011638
	speed: 0.0157s/iter; left time: 714.1646s
Epoch: 7 cost time: 8.500996589660645
Epoch: 7, Steps: 487 Train Loss: 0.4169 (Forecasting Loss:0.3954 + XiCon Loss:2.1560 x Lambda(0.01)), Vali MSE Loss: 0.7291 Test MSE Loss: 0.5121
Validation loss decreased (0.729397 --> 0.729105).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3936389
	speed: 0.0183s/iter; left time: 827.6608s
	iters: 200, epoch: 8 | loss: 0.3469277
	speed: 0.0172s/iter; left time: 776.0284s
	iters: 300, epoch: 8 | loss: 0.4080392
	speed: 0.0180s/iter; left time: 810.5158s
	iters: 400, epoch: 8 | loss: 0.4647414
	speed: 0.0175s/iter; left time: 786.5008s
Epoch: 8 cost time: 8.450439929962158
Epoch: 8, Steps: 487 Train Loss: 0.4167 (Forecasting Loss:0.3951 + XiCon Loss:2.1556 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5118
Validation loss decreased (0.729105 --> 0.728974).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5648412
	speed: 0.0198s/iter; left time: 886.3295s
	iters: 200, epoch: 9 | loss: 0.3525908
	speed: 0.0163s/iter; left time: 727.5619s
	iters: 300, epoch: 9 | loss: 0.4530954
	speed: 0.0165s/iter; left time: 734.8074s
	iters: 400, epoch: 9 | loss: 0.4269743
	speed: 0.0166s/iter; left time: 738.8080s
Epoch: 9 cost time: 8.326278924942017
Epoch: 9, Steps: 487 Train Loss: 0.4165 (Forecasting Loss:0.3949 + XiCon Loss:2.1567 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
Validation loss decreased (0.728974 --> 0.728702).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3620842
	speed: 0.0188s/iter; left time: 830.8351s
	iters: 200, epoch: 10 | loss: 0.3972824
	speed: 0.0166s/iter; left time: 731.8526s
	iters: 300, epoch: 10 | loss: 0.3745680
	speed: 0.0179s/iter; left time: 787.9732s
	iters: 400, epoch: 10 | loss: 0.3305393
	speed: 0.0174s/iter; left time: 764.9817s
Epoch: 10 cost time: 8.506781101226807
Epoch: 10, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3948 + XiCon Loss:2.1572 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3742889
	speed: 0.0172s/iter; left time: 751.8587s
	iters: 200, epoch: 11 | loss: 0.3457915
	speed: 0.0151s/iter; left time: 658.8077s
	iters: 300, epoch: 11 | loss: 0.4384805
	speed: 0.0165s/iter; left time: 716.6966s
	iters: 400, epoch: 11 | loss: 0.3913268
	speed: 0.0176s/iter; left time: 763.8669s
Epoch: 11 cost time: 8.186978578567505
Epoch: 11, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3948 + XiCon Loss:2.1572 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5116
Validation loss decreased (0.728702 --> 0.728425).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4446486
	speed: 0.0193s/iter; left time: 835.0639s
	iters: 200, epoch: 12 | loss: 0.3725688
	speed: 0.0160s/iter; left time: 691.7577s
	iters: 300, epoch: 12 | loss: 0.3789817
	speed: 0.0170s/iter; left time: 731.3710s
	iters: 400, epoch: 12 | loss: 0.3892590
	speed: 0.0183s/iter; left time: 783.8612s
Epoch: 12 cost time: 8.543214082717896
Epoch: 12, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3946 + XiCon Loss:2.1555 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5541338
	speed: 0.0192s/iter; left time: 818.8632s
	iters: 200, epoch: 13 | loss: 0.4083244
	speed: 0.0173s/iter; left time: 738.9065s
	iters: 300, epoch: 13 | loss: 0.3879945
	speed: 0.0167s/iter; left time: 711.6086s
	iters: 400, epoch: 13 | loss: 0.3237053
	speed: 0.0168s/iter; left time: 712.5669s
Epoch: 13 cost time: 8.491371154785156
Epoch: 13, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3946 + XiCon Loss:2.1530 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4553832
	speed: 0.0201s/iter; left time: 849.1889s
	iters: 200, epoch: 14 | loss: 0.4797968
	speed: 0.0160s/iter; left time: 674.6986s
	iters: 300, epoch: 14 | loss: 0.3540972
	speed: 0.0167s/iter; left time: 704.2378s
	iters: 400, epoch: 14 | loss: 0.3437826
	speed: 0.0183s/iter; left time: 766.5401s
Epoch: 14 cost time: 8.636985301971436
Epoch: 14, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3948 + XiCon Loss:2.1567 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3926133
	speed: 0.0208s/iter; left time: 868.0753s
	iters: 200, epoch: 15 | loss: 0.4091199
	speed: 0.0165s/iter; left time: 689.8128s
	iters: 300, epoch: 15 | loss: 0.4568999
	speed: 0.0180s/iter; left time: 747.4186s
	iters: 400, epoch: 15 | loss: 0.4209968
	speed: 0.0170s/iter; left time: 704.0096s
Epoch: 15 cost time: 8.672627449035645
Epoch: 15, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3946 + XiCon Loss:2.1583 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4723581
	speed: 0.0185s/iter; left time: 763.2187s
	iters: 200, epoch: 16 | loss: 0.4957767
	speed: 0.0162s/iter; left time: 666.9497s
	iters: 300, epoch: 16 | loss: 0.4028968
	speed: 0.0180s/iter; left time: 741.7489s
	iters: 400, epoch: 16 | loss: 0.4357382
	speed: 0.0170s/iter; left time: 697.7839s
Epoch: 16 cost time: 8.607214212417603
Epoch: 16, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3947 + XiCon Loss:2.1524 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3914690
	speed: 0.0198s/iter; left time: 806.4486s
	iters: 200, epoch: 17 | loss: 0.3903117
	speed: 0.0188s/iter; left time: 764.8737s
	iters: 300, epoch: 17 | loss: 0.4757988
	speed: 0.0178s/iter; left time: 721.7847s
	iters: 400, epoch: 17 | loss: 0.4523895
	speed: 0.0167s/iter; left time: 677.2822s
Epoch: 17 cost time: 8.784278631210327
Epoch: 17, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3947 + XiCon Loss:2.1543 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3610067
	speed: 0.0190s/iter; left time: 767.5766s
	iters: 200, epoch: 18 | loss: 0.4380881
	speed: 0.0166s/iter; left time: 668.3472s
	iters: 300, epoch: 18 | loss: 0.3615696
	speed: 0.0166s/iter; left time: 666.8335s
	iters: 400, epoch: 18 | loss: 0.3382115
	speed: 0.0186s/iter; left time: 744.6941s
Epoch: 18 cost time: 8.533272743225098
Epoch: 18, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3945 + XiCon Loss:2.1586 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5116
Validation loss decreased (0.728425 --> 0.728253).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3961333
	speed: 0.0153s/iter; left time: 609.0248s
	iters: 200, epoch: 19 | loss: 0.4101646
	speed: 0.0132s/iter; left time: 523.7550s
	iters: 300, epoch: 19 | loss: 0.4064320
	speed: 0.0143s/iter; left time: 566.8670s
	iters: 400, epoch: 19 | loss: 0.4319123
	speed: 0.0128s/iter; left time: 507.5618s
Epoch: 19 cost time: 6.845662593841553
Epoch: 19, Steps: 487 Train Loss: 0.4160 (Forecasting Loss:0.3944 + XiCon Loss:2.1550 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4119509
	speed: 0.0141s/iter; left time: 555.5511s
	iters: 200, epoch: 20 | loss: 0.4064369
	speed: 0.0137s/iter; left time: 535.9068s
	iters: 300, epoch: 20 | loss: 0.3406677
	speed: 0.0134s/iter; left time: 526.0779s
	iters: 400, epoch: 20 | loss: 0.3820386
	speed: 0.0135s/iter; left time: 525.9483s
Epoch: 20 cost time: 6.760488033294678
Epoch: 20, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3946 + XiCon Loss:2.1575 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.3250797
	speed: 0.0148s/iter; left time: 574.4279s
	iters: 200, epoch: 21 | loss: 0.3987075
	speed: 0.0157s/iter; left time: 609.5985s
	iters: 300, epoch: 21 | loss: 0.3443131
	speed: 0.0285s/iter; left time: 1102.3253s
	iters: 400, epoch: 21 | loss: 0.4239434
	speed: 0.0130s/iter; left time: 502.7866s
Epoch: 21 cost time: 8.350083112716675
Epoch: 21, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3948 + XiCon Loss:2.1556 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4177981
	speed: 0.0164s/iter; left time: 627.4745s
	iters: 200, epoch: 22 | loss: 0.4688951
	speed: 0.0151s/iter; left time: 577.7133s
	iters: 300, epoch: 22 | loss: 0.4843265
	speed: 0.0152s/iter; left time: 578.9973s
	iters: 400, epoch: 22 | loss: 0.3792337
	speed: 0.0157s/iter; left time: 597.5893s
Epoch: 22 cost time: 7.656950950622559
Epoch: 22, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3948 + XiCon Loss:2.1585 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4948852
	speed: 0.0157s/iter; left time: 595.3875s
	iters: 200, epoch: 23 | loss: 0.3754026
	speed: 0.0151s/iter; left time: 569.2790s
	iters: 300, epoch: 23 | loss: 0.3863836
	speed: 0.0159s/iter; left time: 598.3127s
	iters: 400, epoch: 23 | loss: 0.4616270
	speed: 0.0163s/iter; left time: 610.7997s
Epoch: 23 cost time: 7.6823859214782715
Epoch: 23, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3946 + XiCon Loss:2.1557 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.5015783
	speed: 0.0158s/iter; left time: 589.2276s
	iters: 200, epoch: 24 | loss: 0.4011762
	speed: 0.0149s/iter; left time: 556.6589s
	iters: 300, epoch: 24 | loss: 0.4538853
	speed: 0.0153s/iter; left time: 569.8994s
	iters: 400, epoch: 24 | loss: 0.3439422
	speed: 0.0155s/iter; left time: 575.4687s
Epoch: 24 cost time: 7.502568006515503
Epoch: 24, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3945 + XiCon Loss:2.1574 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4105424
	speed: 0.0170s/iter; left time: 626.7179s
	iters: 200, epoch: 25 | loss: 0.4308158
	speed: 0.0144s/iter; left time: 531.4941s
	iters: 300, epoch: 25 | loss: 0.3783056
	speed: 0.0158s/iter; left time: 579.1320s
	iters: 400, epoch: 25 | loss: 0.4239948
	speed: 0.0160s/iter; left time: 586.5535s
Epoch: 25 cost time: 7.7338738441467285
Epoch: 25, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3945 + XiCon Loss:2.1564 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5116
Validation loss decreased (0.728253 --> 0.728158).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3850375
	speed: 0.0175s/iter; left time: 639.0348s
	iters: 200, epoch: 26 | loss: 0.3859943
	speed: 0.0138s/iter; left time: 500.8881s
	iters: 300, epoch: 26 | loss: 0.5117442
	speed: 0.0157s/iter; left time: 567.6791s
	iters: 400, epoch: 26 | loss: 0.3493244
	speed: 0.0226s/iter; left time: 816.9484s
Epoch: 26 cost time: 8.356279373168945
Epoch: 26, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3947 + XiCon Loss:2.1575 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3968069
	speed: 0.0175s/iter; left time: 629.7543s
	iters: 200, epoch: 27 | loss: 0.4210466
	speed: 0.0143s/iter; left time: 512.8292s
	iters: 300, epoch: 27 | loss: 0.3507600
	speed: 0.0159s/iter; left time: 567.9150s
	iters: 400, epoch: 27 | loss: 0.3651068
	speed: 0.0163s/iter; left time: 580.3563s
Epoch: 27 cost time: 7.735521078109741
Epoch: 27, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3948 + XiCon Loss:2.1560 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5116
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4172147
	speed: 0.0182s/iter; left time: 643.8965s
	iters: 200, epoch: 28 | loss: 0.4213185
	speed: 0.0139s/iter; left time: 490.6270s
	iters: 300, epoch: 28 | loss: 0.4254759
	speed: 0.0150s/iter; left time: 527.6351s
	iters: 400, epoch: 28 | loss: 0.3937117
	speed: 0.0161s/iter; left time: 566.5297s
Epoch: 28 cost time: 7.719606399536133
Epoch: 28, Steps: 487 Train Loss: 0.4160 (Forecasting Loss:0.3944 + XiCon Loss:2.1557 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3624222
	speed: 0.0176s/iter; left time: 614.3996s
	iters: 200, epoch: 29 | loss: 0.4653793
	speed: 0.0149s/iter; left time: 520.1721s
	iters: 300, epoch: 29 | loss: 0.4360389
	speed: 0.0152s/iter; left time: 526.7894s
	iters: 400, epoch: 29 | loss: 0.4253282
	speed: 0.0180s/iter; left time: 622.3388s
Epoch: 29 cost time: 7.900260925292969
Epoch: 29, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3948 + XiCon Loss:2.1584 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5116
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3887993
	speed: 0.0192s/iter; left time: 660.9961s
	iters: 200, epoch: 30 | loss: 0.4145989
	speed: 0.0157s/iter; left time: 538.8723s
	iters: 300, epoch: 30 | loss: 0.4550975
	speed: 0.0142s/iter; left time: 487.9466s
	iters: 400, epoch: 30 | loss: 0.4005126
	speed: 0.0164s/iter; left time: 562.2212s
Epoch: 30 cost time: 7.958636999130249
Epoch: 30, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3945 + XiCon Loss:2.1583 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5116
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.5054904
	speed: 0.0173s/iter; left time: 587.7257s
	iters: 200, epoch: 31 | loss: 0.3303019
	speed: 0.0149s/iter; left time: 505.4924s
	iters: 300, epoch: 31 | loss: 0.4245015
	speed: 0.0150s/iter; left time: 508.3963s
	iters: 400, epoch: 31 | loss: 0.3475271
	speed: 0.0150s/iter; left time: 506.1719s
Epoch: 31 cost time: 7.641967296600342
Epoch: 31, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3945 + XiCon Loss:2.1571 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5116
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4085116
	speed: 0.0157s/iter; left time: 526.6461s
	iters: 200, epoch: 32 | loss: 0.4912114
	speed: 0.0132s/iter; left time: 440.6226s
	iters: 300, epoch: 32 | loss: 0.3621540
	speed: 0.0133s/iter; left time: 441.6927s
	iters: 400, epoch: 32 | loss: 0.3250124
	speed: 0.0132s/iter; left time: 437.1015s
Epoch: 32 cost time: 6.674381256103516
Epoch: 32, Steps: 487 Train Loss: 0.4159 (Forecasting Loss:0.3943 + XiCon Loss:2.1569 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3767504
	speed: 0.0176s/iter; left time: 581.6633s
	iters: 200, epoch: 33 | loss: 0.3353030
	speed: 0.0153s/iter; left time: 503.6674s
	iters: 300, epoch: 33 | loss: 0.4265200
	speed: 0.0163s/iter; left time: 536.4457s
	iters: 400, epoch: 33 | loss: 0.4967348
	speed: 0.0147s/iter; left time: 480.2896s
Epoch: 33 cost time: 7.76880407333374
Epoch: 33, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3947 + XiCon Loss:2.1590 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5116
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4191809
	speed: 0.0182s/iter; left time: 592.0910s
	iters: 200, epoch: 34 | loss: 0.4577887
	speed: 0.0154s/iter; left time: 498.9362s
	iters: 300, epoch: 34 | loss: 0.3741761
	speed: 0.0157s/iter; left time: 508.8301s
	iters: 400, epoch: 34 | loss: 0.3885056
	speed: 0.0150s/iter; left time: 482.6701s
Epoch: 34 cost time: 7.747711658477783
Epoch: 34, Steps: 487 Train Loss: 0.4160 (Forecasting Loss:0.3945 + XiCon Loss:2.1550 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5116
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4018537
	speed: 0.0187s/iter; left time: 600.3502s
	iters: 200, epoch: 35 | loss: 0.3356579
	speed: 0.0150s/iter; left time: 479.7021s
	iters: 300, epoch: 35 | loss: 0.4173566
	speed: 0.0156s/iter; left time: 496.8424s
	iters: 400, epoch: 35 | loss: 0.4291660
	speed: 0.0153s/iter; left time: 484.3712s
Epoch: 35 cost time: 7.7567057609558105
Epoch: 35, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3946 + XiCon Loss:2.1598 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5116
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182303786277771, mae:0.5050171613693237, mape:3.533581495285034, mspe:1158.8846435546875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5413
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.6958525
	speed: 0.0174s/iter; left time: 845.0119s
	iters: 200, epoch: 1 | loss: 0.8875882
	speed: 0.0146s/iter; left time: 709.9494s
	iters: 300, epoch: 1 | loss: 0.5799236
	speed: 0.0163s/iter; left time: 786.9920s
	iters: 400, epoch: 1 | loss: 0.5117748
	speed: 0.0148s/iter; left time: 716.6844s
Epoch: 1 cost time: 7.621530055999756
Epoch: 1, Steps: 487 Train Loss: 0.7563 (Forecasting Loss:0.7348 + XiCon Loss:2.1450 x Lambda(0.01)), Vali MSE Loss: 1.0307 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030659).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5116912
	speed: 0.0172s/iter; left time: 828.0462s
	iters: 200, epoch: 2 | loss: 0.5074482
	speed: 0.0147s/iter; left time: 703.5523s
	iters: 300, epoch: 2 | loss: 0.4147299
	speed: 0.0146s/iter; left time: 697.2179s
	iters: 400, epoch: 2 | loss: 0.4962856
	speed: 0.0158s/iter; left time: 753.5914s
Epoch: 2 cost time: 7.4707746505737305
Epoch: 2, Steps: 487 Train Loss: 0.4598 (Forecasting Loss:0.4383 + XiCon Loss:2.1554 x Lambda(0.01)), Vali MSE Loss: 0.7327 Test MSE Loss: 0.5270
Validation loss decreased (1.030659 --> 0.732738).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4422794
	speed: 0.0186s/iter; left time: 885.7206s
	iters: 200, epoch: 3 | loss: 0.4095314
	speed: 0.0149s/iter; left time: 710.0181s
	iters: 300, epoch: 3 | loss: 0.4320357
	speed: 0.0151s/iter; left time: 714.4570s
	iters: 400, epoch: 3 | loss: 0.3796633
	speed: 0.0158s/iter; left time: 749.5089s
Epoch: 3 cost time: 7.839978933334351
Epoch: 3, Steps: 487 Train Loss: 0.4264 (Forecasting Loss:0.4049 + XiCon Loss:2.1465 x Lambda(0.01)), Vali MSE Loss: 0.7178 Test MSE Loss: 0.5186
Validation loss decreased (0.732738 --> 0.717839).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5423424
	speed: 0.0177s/iter; left time: 835.3236s
	iters: 200, epoch: 4 | loss: 0.3867139
	speed: 0.0151s/iter; left time: 711.1726s
	iters: 300, epoch: 4 | loss: 0.5334565
	speed: 0.0155s/iter; left time: 728.1130s
	iters: 400, epoch: 4 | loss: 0.5191494
	speed: 0.0164s/iter; left time: 765.8797s
Epoch: 4 cost time: 7.939508438110352
Epoch: 4, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3989 + XiCon Loss:2.1440 x Lambda(0.01)), Vali MSE Loss: 0.7115 Test MSE Loss: 0.5165
Validation loss decreased (0.717839 --> 0.711547).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3813673
	speed: 0.0177s/iter; left time: 825.4492s
	iters: 200, epoch: 5 | loss: 0.4391342
	speed: 0.0163s/iter; left time: 756.5799s
	iters: 300, epoch: 5 | loss: 0.3918213
	speed: 0.0167s/iter; left time: 775.3508s
	iters: 400, epoch: 5 | loss: 0.3231925
	speed: 0.0161s/iter; left time: 745.4976s
Epoch: 5 cost time: 8.029354333877563
Epoch: 5, Steps: 487 Train Loss: 0.4181 (Forecasting Loss:0.3966 + XiCon Loss:2.1493 x Lambda(0.01)), Vali MSE Loss: 0.7101 Test MSE Loss: 0.5146
Validation loss decreased (0.711547 --> 0.710051).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3599932
	speed: 0.0184s/iter; left time: 851.6353s
	iters: 200, epoch: 6 | loss: 0.3893173
	speed: 0.0157s/iter; left time: 725.0959s
	iters: 300, epoch: 6 | loss: 0.3248919
	speed: 0.0150s/iter; left time: 690.4131s
	iters: 400, epoch: 6 | loss: 0.4452345
	speed: 0.0156s/iter; left time: 717.2077s
Epoch: 6 cost time: 7.891672134399414
Epoch: 6, Steps: 487 Train Loss: 0.4170 (Forecasting Loss:0.3955 + XiCon Loss:2.1494 x Lambda(0.01)), Vali MSE Loss: 0.7074 Test MSE Loss: 0.5133
Validation loss decreased (0.710051 --> 0.707412).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3727493
	speed: 0.0180s/iter; left time: 821.6973s
	iters: 200, epoch: 7 | loss: 0.3718240
	speed: 0.0146s/iter; left time: 666.4193s
	iters: 300, epoch: 7 | loss: 0.4910538
	speed: 0.0163s/iter; left time: 739.2622s
	iters: 400, epoch: 7 | loss: 0.3820670
	speed: 0.0154s/iter; left time: 700.6391s
Epoch: 7 cost time: 7.815300464630127
Epoch: 7, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3948 + XiCon Loss:2.1456 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5133
Validation loss decreased (0.707412 --> 0.706872).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4552157
	speed: 0.0183s/iter; left time: 825.2416s
	iters: 200, epoch: 8 | loss: 0.4358087
	speed: 0.0154s/iter; left time: 695.2210s
	iters: 300, epoch: 8 | loss: 0.3780586
	speed: 0.0143s/iter; left time: 641.3817s
	iters: 400, epoch: 8 | loss: 0.3236193
	speed: 0.0136s/iter; left time: 612.0688s
Epoch: 8 cost time: 7.3372437953948975
Epoch: 8, Steps: 487 Train Loss: 0.4159 (Forecasting Loss:0.3944 + XiCon Loss:2.1454 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5132
Validation loss decreased (0.706872 --> 0.706673).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3928375
	speed: 0.0179s/iter; left time: 798.2891s
	iters: 200, epoch: 9 | loss: 0.4069004
	speed: 0.0157s/iter; left time: 699.3037s
	iters: 300, epoch: 9 | loss: 0.3979875
	speed: 0.0159s/iter; left time: 709.1970s
	iters: 400, epoch: 9 | loss: 0.4953077
	speed: 0.0153s/iter; left time: 680.4671s
Epoch: 9 cost time: 7.886849641799927
Epoch: 9, Steps: 487 Train Loss: 0.4156 (Forecasting Loss:0.3942 + XiCon Loss:2.1451 x Lambda(0.01)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5130
Validation loss decreased (0.706673 --> 0.706007).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4158393
	speed: 0.0170s/iter; left time: 749.7906s
	iters: 200, epoch: 10 | loss: 0.4136016
	speed: 0.0152s/iter; left time: 672.2381s
	iters: 300, epoch: 10 | loss: 0.2897479
	speed: 0.0158s/iter; left time: 697.3215s
	iters: 400, epoch: 10 | loss: 0.4249782
	speed: 0.0165s/iter; left time: 725.0247s
Epoch: 10 cost time: 7.853996515274048
Epoch: 10, Steps: 487 Train Loss: 0.4157 (Forecasting Loss:0.3942 + XiCon Loss:2.1480 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3338158
	speed: 0.0154s/iter; left time: 674.6348s
	iters: 200, epoch: 11 | loss: 0.3759410
	speed: 0.0146s/iter; left time: 638.0060s
	iters: 300, epoch: 11 | loss: 0.3819275
	speed: 0.0152s/iter; left time: 661.8553s
	iters: 400, epoch: 11 | loss: 0.5339079
	speed: 0.0161s/iter; left time: 698.5723s
Epoch: 11 cost time: 7.5387468338012695
Epoch: 11, Steps: 487 Train Loss: 0.4153 (Forecasting Loss:0.3939 + XiCon Loss:2.1396 x Lambda(0.01)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5130
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3912813
	speed: 0.0167s/iter; left time: 724.1551s
	iters: 200, epoch: 12 | loss: 0.4204468
	speed: 0.0147s/iter; left time: 634.9232s
	iters: 300, epoch: 12 | loss: 0.4484750
	speed: 0.0161s/iter; left time: 692.5578s
	iters: 400, epoch: 12 | loss: 0.4324695
	speed: 0.0160s/iter; left time: 687.2619s
Epoch: 12 cost time: 7.7644944190979
Epoch: 12, Steps: 487 Train Loss: 0.4157 (Forecasting Loss:0.3943 + XiCon Loss:2.1442 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4252752
	speed: 0.0183s/iter; left time: 784.0878s
	iters: 200, epoch: 13 | loss: 0.4890106
	speed: 0.0146s/iter; left time: 624.6785s
	iters: 300, epoch: 13 | loss: 0.3805144
	speed: 0.0150s/iter; left time: 640.4504s
	iters: 400, epoch: 13 | loss: 0.3863854
	speed: 0.0169s/iter; left time: 717.5381s
Epoch: 13 cost time: 7.900819778442383
Epoch: 13, Steps: 487 Train Loss: 0.4157 (Forecasting Loss:0.3942 + XiCon Loss:2.1478 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5130
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3950662
	speed: 0.0175s/iter; left time: 740.8078s
	iters: 200, epoch: 14 | loss: 0.4278670
	speed: 0.0135s/iter; left time: 567.8806s
	iters: 300, epoch: 14 | loss: 0.3834049
	speed: 0.0158s/iter; left time: 662.8597s
	iters: 400, epoch: 14 | loss: 0.4120196
	speed: 0.0159s/iter; left time: 667.6553s
Epoch: 14 cost time: 7.611163854598999
Epoch: 14, Steps: 487 Train Loss: 0.4156 (Forecasting Loss:0.3941 + XiCon Loss:2.1485 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5130
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4686974
	speed: 0.0176s/iter; left time: 736.5713s
	iters: 200, epoch: 15 | loss: 0.4316198
	speed: 0.0142s/iter; left time: 593.8309s
	iters: 300, epoch: 15 | loss: 0.4332147
	speed: 0.0150s/iter; left time: 623.0352s
	iters: 400, epoch: 15 | loss: 0.3937657
	speed: 0.0169s/iter; left time: 702.1770s
Epoch: 15 cost time: 7.756266832351685
Epoch: 15, Steps: 487 Train Loss: 0.4152 (Forecasting Loss:0.3938 + XiCon Loss:2.1412 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5130
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4373170
	speed: 0.0170s/iter; left time: 702.6207s
	iters: 200, epoch: 16 | loss: 0.4608271
	speed: 0.0143s/iter; left time: 590.1925s
	iters: 300, epoch: 16 | loss: 0.3938633
	speed: 0.0150s/iter; left time: 618.0011s
	iters: 400, epoch: 16 | loss: 0.4763999
	speed: 0.0163s/iter; left time: 667.8081s
Epoch: 16 cost time: 7.719308853149414
Epoch: 16, Steps: 487 Train Loss: 0.4154 (Forecasting Loss:0.3939 + XiCon Loss:2.1440 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5130
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4116567
	speed: 0.0175s/iter; left time: 715.0742s
	iters: 200, epoch: 17 | loss: 0.4587280
	speed: 0.0141s/iter; left time: 576.0170s
	iters: 300, epoch: 17 | loss: 0.4291256
	speed: 0.0143s/iter; left time: 579.9305s
	iters: 400, epoch: 17 | loss: 0.4622455
	speed: 0.0136s/iter; left time: 552.7539s
Epoch: 17 cost time: 7.212176561355591
Epoch: 17, Steps: 487 Train Loss: 0.4157 (Forecasting Loss:0.3942 + XiCon Loss:2.1465 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5130
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4516886
	speed: 0.0148s/iter; left time: 596.0410s
	iters: 200, epoch: 18 | loss: 0.4328193
	speed: 0.0127s/iter; left time: 509.9487s
	iters: 300, epoch: 18 | loss: 0.5976291
	speed: 0.0315s/iter; left time: 1263.9029s
	iters: 400, epoch: 18 | loss: 0.4159111
	speed: 0.0138s/iter; left time: 551.2866s
Epoch: 18 cost time: 8.47039246559143
Epoch: 18, Steps: 487 Train Loss: 0.4154 (Forecasting Loss:0.3939 + XiCon Loss:2.1443 x Lambda(0.01)), Vali MSE Loss: 0.7063 Test MSE Loss: 0.5130
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3149286
	speed: 0.0174s/iter; left time: 691.4138s
	iters: 200, epoch: 19 | loss: 0.4838852
	speed: 0.0191s/iter; left time: 759.2802s
	iters: 300, epoch: 19 | loss: 0.4404624
	speed: 0.0180s/iter; left time: 713.6407s
	iters: 400, epoch: 19 | loss: 0.3652564
	speed: 0.0170s/iter; left time: 671.1673s
Epoch: 19 cost time: 8.604249477386475
Epoch: 19, Steps: 487 Train Loss: 0.4157 (Forecasting Loss:0.3942 + XiCon Loss:2.1460 x Lambda(0.01)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5130
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5197134613990784, mae:0.5063633918762207, mape:3.4446232318878174, mspe:1084.371826171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.9342
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1354859
	speed: 0.0199s/iter; left time: 965.1308s
	iters: 200, epoch: 1 | loss: 0.7889680
	speed: 0.0166s/iter; left time: 804.4538s
	iters: 300, epoch: 1 | loss: 0.7028813
	speed: 0.0171s/iter; left time: 825.6144s
	iters: 400, epoch: 1 | loss: 0.7543358
	speed: 0.0168s/iter; left time: 810.5959s
Epoch: 1 cost time: 8.438435316085815
Epoch: 1, Steps: 487 Train Loss: 0.8626 (Forecasting Loss:0.8409 + XiCon Loss:2.1669 x Lambda(0.01)), Vali MSE Loss: 1.1923 Test MSE Loss: 0.6744
Validation loss decreased (inf --> 1.192290).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4650046
	speed: 0.0192s/iter; left time: 922.9077s
	iters: 200, epoch: 2 | loss: 0.4411695
	speed: 0.0209s/iter; left time: 1004.5355s
	iters: 300, epoch: 2 | loss: 0.3909967
	speed: 0.0169s/iter; left time: 809.3333s
	iters: 400, epoch: 2 | loss: 0.5333445
	speed: 0.0165s/iter; left time: 791.1936s
Epoch: 2 cost time: 8.772418737411499
Epoch: 2, Steps: 487 Train Loss: 0.4742 (Forecasting Loss:0.4526 + XiCon Loss:2.1600 x Lambda(0.01)), Vali MSE Loss: 0.7521 Test MSE Loss: 0.5336
Validation loss decreased (1.192290 --> 0.752058).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4761019
	speed: 0.0190s/iter; left time: 905.9252s
	iters: 200, epoch: 3 | loss: 0.4094883
	speed: 0.0170s/iter; left time: 808.4331s
	iters: 300, epoch: 3 | loss: 0.3511208
	speed: 0.0165s/iter; left time: 782.8826s
	iters: 400, epoch: 3 | loss: 0.4074694
	speed: 0.0165s/iter; left time: 779.2384s
Epoch: 3 cost time: 8.358344554901123
Epoch: 3, Steps: 487 Train Loss: 0.4297 (Forecasting Loss:0.4081 + XiCon Loss:2.1574 x Lambda(0.01)), Vali MSE Loss: 0.7397 Test MSE Loss: 0.5303
Validation loss decreased (0.752058 --> 0.739691).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.3995382
	speed: 0.0191s/iter; left time: 902.7287s
	iters: 200, epoch: 4 | loss: 0.3693955
	speed: 0.0163s/iter; left time: 766.8662s
	iters: 300, epoch: 4 | loss: 0.4257593
	speed: 0.0164s/iter; left time: 768.1910s
	iters: 400, epoch: 4 | loss: 0.4889927
	speed: 0.0165s/iter; left time: 771.2146s
Epoch: 4 cost time: 8.260038375854492
Epoch: 4, Steps: 487 Train Loss: 0.4239 (Forecasting Loss:0.4024 + XiCon Loss:2.1507 x Lambda(0.01)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5268
Validation loss decreased (0.739691 --> 0.731930).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4035465
	speed: 0.0190s/iter; left time: 886.2324s
	iters: 200, epoch: 5 | loss: 0.3847708
	speed: 0.0164s/iter; left time: 763.1730s
	iters: 300, epoch: 5 | loss: 0.4144033
	speed: 0.0163s/iter; left time: 757.7796s
	iters: 400, epoch: 5 | loss: 0.4460372
	speed: 0.0170s/iter; left time: 788.9891s
Epoch: 5 cost time: 8.300028324127197
Epoch: 5, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3999 + XiCon Loss:2.1519 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5230
Validation loss decreased (0.731930 --> 0.730145).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4074926
	speed: 0.0190s/iter; left time: 876.7647s
	iters: 200, epoch: 6 | loss: 0.3941149
	speed: 0.0161s/iter; left time: 741.0808s
	iters: 300, epoch: 6 | loss: 0.4063795
	speed: 0.0158s/iter; left time: 727.5862s
	iters: 400, epoch: 6 | loss: 0.3956568
	speed: 0.0166s/iter; left time: 759.7455s
Epoch: 6 cost time: 8.270003318786621
Epoch: 6, Steps: 487 Train Loss: 0.4200 (Forecasting Loss:0.3985 + XiCon Loss:2.1523 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5221
Validation loss decreased (0.730145 --> 0.728193).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3940041
	speed: 0.0202s/iter; left time: 922.7998s
	iters: 200, epoch: 7 | loss: 0.4091799
	speed: 0.0167s/iter; left time: 761.5429s
	iters: 300, epoch: 7 | loss: 0.4690957
	speed: 0.0182s/iter; left time: 827.8560s
	iters: 400, epoch: 7 | loss: 0.4348315
	speed: 0.0173s/iter; left time: 782.9377s
Epoch: 7 cost time: 8.611838102340698
Epoch: 7, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3980 + XiCon Loss:2.1502 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5215
Validation loss decreased (0.728193 --> 0.727829).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4378898
	speed: 0.0185s/iter; left time: 837.5806s
	iters: 200, epoch: 8 | loss: 0.3922009
	speed: 0.0163s/iter; left time: 736.4174s
	iters: 300, epoch: 8 | loss: 0.4229282
	speed: 0.0165s/iter; left time: 740.1730s
	iters: 400, epoch: 8 | loss: 0.3659427
	speed: 0.0169s/iter; left time: 759.7400s
Epoch: 8 cost time: 8.342734336853027
Epoch: 8, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3977 + XiCon Loss:2.1473 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4920521
	speed: 0.0188s/iter; left time: 839.3716s
	iters: 200, epoch: 9 | loss: 0.4107295
	speed: 0.0170s/iter; left time: 759.6438s
	iters: 300, epoch: 9 | loss: 0.4738252
	speed: 0.0156s/iter; left time: 692.9314s
	iters: 400, epoch: 9 | loss: 0.3377742
	speed: 0.0172s/iter; left time: 762.8015s
Epoch: 9 cost time: 8.381025314331055
Epoch: 9, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3975 + XiCon Loss:2.1536 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.5157959
	speed: 0.0195s/iter; left time: 861.8889s
	iters: 200, epoch: 10 | loss: 0.4300817
	speed: 0.0167s/iter; left time: 737.6159s
	iters: 300, epoch: 10 | loss: 0.3735875
	speed: 0.0170s/iter; left time: 748.7078s
	iters: 400, epoch: 10 | loss: 0.3603181
	speed: 0.0164s/iter; left time: 721.7316s
Epoch: 10 cost time: 8.457903861999512
Epoch: 10, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3973 + XiCon Loss:2.1519 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
Validation loss decreased (0.727829 --> 0.727828).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4310031
	speed: 0.0189s/iter; left time: 827.5960s
	iters: 200, epoch: 11 | loss: 0.3913399
	speed: 0.0175s/iter; left time: 762.3515s
	iters: 300, epoch: 11 | loss: 0.4368996
	speed: 0.0172s/iter; left time: 747.5810s
	iters: 400, epoch: 11 | loss: 0.3758361
	speed: 0.0162s/iter; left time: 703.4428s
Epoch: 11 cost time: 8.41243839263916
Epoch: 11, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3973 + XiCon Loss:2.1522 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3876642
	speed: 0.0172s/iter; left time: 742.1724s
	iters: 200, epoch: 12 | loss: 0.5104666
	speed: 0.0140s/iter; left time: 604.3709s
	iters: 300, epoch: 12 | loss: 0.3776425
	speed: 0.0146s/iter; left time: 629.7633s
	iters: 400, epoch: 12 | loss: 0.4693570
	speed: 0.0149s/iter; left time: 639.9965s
Epoch: 12 cost time: 7.3088531494140625
Epoch: 12, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3975 + XiCon Loss:2.1529 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
Validation loss decreased (0.727828 --> 0.727688).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3522469
	speed: 0.0198s/iter; left time: 846.0488s
	iters: 200, epoch: 13 | loss: 0.4536840
	speed: 0.0158s/iter; left time: 673.8333s
	iters: 300, epoch: 13 | loss: 0.4514071
	speed: 0.0162s/iter; left time: 691.2253s
	iters: 400, epoch: 13 | loss: 0.3415421
	speed: 0.0170s/iter; left time: 722.6697s
Epoch: 13 cost time: 8.342663526535034
Epoch: 13, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3973 + XiCon Loss:2.1488 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4333757
	speed: 0.0192s/iter; left time: 811.9268s
	iters: 200, epoch: 14 | loss: 0.4941458
	speed: 0.0166s/iter; left time: 700.9704s
	iters: 300, epoch: 14 | loss: 0.3621957
	speed: 0.0163s/iter; left time: 687.4417s
	iters: 400, epoch: 14 | loss: 0.5804840
	speed: 0.0166s/iter; left time: 695.3992s
Epoch: 14 cost time: 8.322375297546387
Epoch: 14, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1487 x Lambda(0.01)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5213
Validation loss decreased (0.727688 --> 0.727283).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3893495
	speed: 0.0194s/iter; left time: 812.0531s
	iters: 200, epoch: 15 | loss: 0.4482179
	speed: 0.0168s/iter; left time: 701.4639s
	iters: 300, epoch: 15 | loss: 0.4354857
	speed: 0.0164s/iter; left time: 680.9927s
	iters: 400, epoch: 15 | loss: 0.3364218
	speed: 0.0177s/iter; left time: 735.6527s
Epoch: 15 cost time: 8.62371563911438
Epoch: 15, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3975 + XiCon Loss:2.1518 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3461514
	speed: 0.0192s/iter; left time: 794.0168s
	iters: 200, epoch: 16 | loss: 0.3981256
	speed: 0.0161s/iter; left time: 662.4504s
	iters: 300, epoch: 16 | loss: 0.3899104
	speed: 0.0175s/iter; left time: 718.8574s
	iters: 400, epoch: 16 | loss: 0.4547190
	speed: 0.0167s/iter; left time: 685.4894s
Epoch: 16 cost time: 8.387636423110962
Epoch: 16, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3971 + XiCon Loss:2.1545 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3983618
	speed: 0.0184s/iter; left time: 752.3133s
	iters: 200, epoch: 17 | loss: 0.4565507
	speed: 0.0172s/iter; left time: 701.0982s
	iters: 300, epoch: 17 | loss: 0.4478506
	speed: 0.0167s/iter; left time: 680.1609s
	iters: 400, epoch: 17 | loss: 0.3412465
	speed: 0.0174s/iter; left time: 706.1324s
Epoch: 17 cost time: 8.502019882202148
Epoch: 17, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3974 + XiCon Loss:2.1559 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3775654
	speed: 0.0201s/iter; left time: 811.3230s
	iters: 200, epoch: 18 | loss: 0.5193591
	speed: 0.0172s/iter; left time: 691.9250s
	iters: 300, epoch: 18 | loss: 0.4253992
	speed: 0.0165s/iter; left time: 660.0171s
	iters: 400, epoch: 18 | loss: 0.4855776
	speed: 0.0166s/iter; left time: 662.6202s
Epoch: 18 cost time: 8.623547792434692
Epoch: 18, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1498 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3416529
	speed: 0.0193s/iter; left time: 767.8036s
	iters: 200, epoch: 19 | loss: 0.3995869
	speed: 0.0168s/iter; left time: 669.3513s
	iters: 300, epoch: 19 | loss: 0.4240969
	speed: 0.0160s/iter; left time: 632.9718s
	iters: 400, epoch: 19 | loss: 0.4992244
	speed: 0.0172s/iter; left time: 680.7720s
Epoch: 19 cost time: 8.424070835113525
Epoch: 19, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1493 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3529522
	speed: 0.0200s/iter; left time: 787.9243s
	iters: 200, epoch: 20 | loss: 0.4480352
	speed: 0.0165s/iter; left time: 648.3381s
	iters: 300, epoch: 20 | loss: 0.3865179
	speed: 0.0172s/iter; left time: 674.7558s
	iters: 400, epoch: 20 | loss: 0.4227353
	speed: 0.0170s/iter; left time: 664.3241s
Epoch: 20 cost time: 9.073874711990356
Epoch: 20, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3973 + XiCon Loss:2.1533 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4592814
	speed: 0.0183s/iter; left time: 710.6828s
	iters: 200, epoch: 21 | loss: 0.4122624
	speed: 0.0154s/iter; left time: 598.4572s
	iters: 300, epoch: 21 | loss: 0.4456648
	speed: 0.0160s/iter; left time: 618.9636s
	iters: 400, epoch: 21 | loss: 0.4446011
	speed: 0.0169s/iter; left time: 651.2032s
Epoch: 21 cost time: 8.162951469421387
Epoch: 21, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1536 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4912083
	speed: 0.0191s/iter; left time: 731.7664s
	iters: 200, epoch: 22 | loss: 0.4095303
	speed: 0.0172s/iter; left time: 658.9910s
	iters: 300, epoch: 22 | loss: 0.4607004
	speed: 0.0167s/iter; left time: 639.2809s
	iters: 400, epoch: 22 | loss: 0.3851086
	speed: 0.0167s/iter; left time: 635.4500s
Epoch: 22 cost time: 8.384658575057983
Epoch: 22, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1538 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5213
Validation loss decreased (0.727283 --> 0.727138).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4160112
	speed: 0.0186s/iter; left time: 706.0193s
	iters: 200, epoch: 23 | loss: 0.4223434
	speed: 0.0161s/iter; left time: 609.9451s
	iters: 300, epoch: 23 | loss: 0.3813738
	speed: 0.0164s/iter; left time: 617.8542s
	iters: 400, epoch: 23 | loss: 0.4052238
	speed: 0.0171s/iter; left time: 641.8785s
Epoch: 23 cost time: 8.22659969329834
Epoch: 23, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3971 + XiCon Loss:2.1563 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.3981148
	speed: 0.0190s/iter; left time: 711.2889s
	iters: 200, epoch: 24 | loss: 0.3873960
	speed: 0.0160s/iter; left time: 595.1836s
	iters: 300, epoch: 24 | loss: 0.3905401
	speed: 0.0158s/iter; left time: 587.6090s
	iters: 400, epoch: 24 | loss: 0.4818909
	speed: 0.0170s/iter; left time: 629.8402s
Epoch: 24 cost time: 8.19797396659851
Epoch: 24, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3971 + XiCon Loss:2.1555 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4593816
	speed: 0.0186s/iter; left time: 686.7655s
	iters: 200, epoch: 25 | loss: 0.3154266
	speed: 0.0163s/iter; left time: 600.2065s
	iters: 300, epoch: 25 | loss: 0.3796483
	speed: 0.0169s/iter; left time: 619.8422s
	iters: 400, epoch: 25 | loss: 0.3926114
	speed: 0.0168s/iter; left time: 613.3096s
Epoch: 25 cost time: 8.254654169082642
Epoch: 25, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1510 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3953591
	speed: 0.0192s/iter; left time: 699.9630s
	iters: 200, epoch: 26 | loss: 0.4242800
	speed: 0.0175s/iter; left time: 634.1662s
	iters: 300, epoch: 26 | loss: 0.3864968
	speed: 0.0173s/iter; left time: 628.4852s
	iters: 400, epoch: 26 | loss: 0.4389702
	speed: 0.0175s/iter; left time: 633.9182s
Epoch: 26 cost time: 8.622829675674438
Epoch: 26, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1563 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3702660
	speed: 0.0199s/iter; left time: 714.0779s
	iters: 200, epoch: 27 | loss: 0.3878050
	speed: 0.0172s/iter; left time: 615.0635s
	iters: 300, epoch: 27 | loss: 0.4716998
	speed: 0.0168s/iter; left time: 600.7739s
	iters: 400, epoch: 27 | loss: 0.4686287
	speed: 0.0168s/iter; left time: 600.0806s
Epoch: 27 cost time: 8.528602838516235
Epoch: 27, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1485 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4243073
	speed: 0.0186s/iter; left time: 659.0453s
	iters: 200, epoch: 28 | loss: 0.4369322
	speed: 0.0157s/iter; left time: 555.8625s
	iters: 300, epoch: 28 | loss: 0.4028343
	speed: 0.0161s/iter; left time: 568.5675s
	iters: 400, epoch: 28 | loss: 0.3843088
	speed: 0.0163s/iter; left time: 571.6775s
Epoch: 28 cost time: 8.083721160888672
Epoch: 28, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3975 + XiCon Loss:2.1568 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4435459
	speed: 0.0186s/iter; left time: 649.5724s
	iters: 200, epoch: 29 | loss: 0.4114297
	speed: 0.0162s/iter; left time: 563.7282s
	iters: 300, epoch: 29 | loss: 0.4953105
	speed: 0.0168s/iter; left time: 582.7123s
	iters: 400, epoch: 29 | loss: 0.4909590
	speed: 0.0166s/iter; left time: 574.4645s
Epoch: 29 cost time: 8.28785490989685
Epoch: 29, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3973 + XiCon Loss:2.1534 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4854186
	speed: 0.0185s/iter; left time: 639.4026s
	iters: 200, epoch: 30 | loss: 0.4275019
	speed: 0.0151s/iter; left time: 519.6487s
	iters: 300, epoch: 30 | loss: 0.5038516
	speed: 0.0145s/iter; left time: 497.0568s
	iters: 400, epoch: 30 | loss: 0.4316147
	speed: 0.0137s/iter; left time: 467.6997s
Epoch: 30 cost time: 7.417600631713867
Epoch: 30, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1461 x Lambda(0.01)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4277029
	speed: 0.0184s/iter; left time: 623.9448s
	iters: 200, epoch: 31 | loss: 0.3229060
	speed: 0.0166s/iter; left time: 562.8945s
	iters: 300, epoch: 31 | loss: 0.3782373
	speed: 0.0168s/iter; left time: 568.2549s
	iters: 400, epoch: 31 | loss: 0.4461494
	speed: 0.0162s/iter; left time: 545.1928s
Epoch: 31 cost time: 8.209041357040405
Epoch: 31, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3972 + XiCon Loss:2.1577 x Lambda(0.01)), Vali MSE Loss: 0.7270 Test MSE Loss: 0.5213
Validation loss decreased (0.727138 --> 0.726987).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4007234
	speed: 0.0194s/iter; left time: 650.8212s
	iters: 200, epoch: 32 | loss: 0.3965778
	speed: 0.0167s/iter; left time: 558.4837s
	iters: 300, epoch: 32 | loss: 0.3356456
	speed: 0.0163s/iter; left time: 541.1927s
	iters: 400, epoch: 32 | loss: 0.3145943
	speed: 0.0170s/iter; left time: 563.4769s
Epoch: 32 cost time: 8.32071828842163
Epoch: 32, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1466 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3648649
	speed: 0.0205s/iter; left time: 677.2821s
	iters: 200, epoch: 33 | loss: 0.4455959
	speed: 0.0167s/iter; left time: 549.7070s
	iters: 300, epoch: 33 | loss: 0.4221318
	speed: 0.0156s/iter; left time: 510.3525s
	iters: 400, epoch: 33 | loss: 0.3799641
	speed: 0.0164s/iter; left time: 537.8063s
Epoch: 33 cost time: 8.429137468338013
Epoch: 33, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3973 + XiCon Loss:2.1499 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4453923
	speed: 0.0194s/iter; left time: 630.4184s
	iters: 200, epoch: 34 | loss: 0.4915499
	speed: 0.0164s/iter; left time: 532.2234s
	iters: 300, epoch: 34 | loss: 0.3864647
	speed: 0.0158s/iter; left time: 510.5915s
	iters: 400, epoch: 34 | loss: 0.4219682
	speed: 0.0162s/iter; left time: 522.4532s
Epoch: 34 cost time: 8.23208236694336
Epoch: 34, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3973 + XiCon Loss:2.1541 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3666490
	speed: 0.0191s/iter; left time: 613.3318s
	iters: 200, epoch: 35 | loss: 0.3568072
	speed: 0.0163s/iter; left time: 519.1813s
	iters: 300, epoch: 35 | loss: 0.3551445
	speed: 0.0168s/iter; left time: 534.2301s
	iters: 400, epoch: 35 | loss: 0.3922425
	speed: 0.0170s/iter; left time: 538.4820s
Epoch: 35 cost time: 8.347554445266724
Epoch: 35, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3973 + XiCon Loss:2.1541 x Lambda(0.01)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4632289
	speed: 0.0194s/iter; left time: 612.5470s
	iters: 200, epoch: 36 | loss: 0.4680898
	speed: 0.0165s/iter; left time: 517.4891s
	iters: 300, epoch: 36 | loss: 0.3808555
	speed: 0.0159s/iter; left time: 498.3642s
	iters: 400, epoch: 36 | loss: 0.4682145
	speed: 0.0166s/iter; left time: 519.5852s
Epoch: 36 cost time: 8.314461469650269
Epoch: 36, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1486 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4049789
	speed: 0.0200s/iter; left time: 622.1220s
	iters: 200, epoch: 37 | loss: 0.3468440
	speed: 0.0161s/iter; left time: 497.1482s
	iters: 300, epoch: 37 | loss: 0.4121760
	speed: 0.0169s/iter; left time: 520.5798s
	iters: 400, epoch: 37 | loss: 0.4666598
	speed: 0.0170s/iter; left time: 522.6687s
Epoch: 37 cost time: 8.503107786178589
Epoch: 37, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1524 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3926781
	speed: 0.0204s/iter; left time: 624.8014s
	iters: 200, epoch: 38 | loss: 0.4202883
	speed: 0.0219s/iter; left time: 667.8694s
	iters: 300, epoch: 38 | loss: 0.4269181
	speed: 0.0167s/iter; left time: 507.4127s
	iters: 400, epoch: 38 | loss: 0.3657360
	speed: 0.0168s/iter; left time: 509.4142s
Epoch: 38 cost time: 9.04336166381836
Epoch: 38, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1534 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.3784133
	speed: 0.0191s/iter; left time: 576.2305s
	iters: 200, epoch: 39 | loss: 0.3851609
	speed: 0.0170s/iter; left time: 510.7932s
	iters: 300, epoch: 39 | loss: 0.4201181
	speed: 0.0177s/iter; left time: 529.0087s
	iters: 400, epoch: 39 | loss: 0.4147758
	speed: 0.0166s/iter; left time: 495.5351s
Epoch: 39 cost time: 8.518226861953735
Epoch: 39, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3972 + XiCon Loss:2.1483 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4708873
	speed: 0.0191s/iter; left time: 564.4768s
	iters: 200, epoch: 40 | loss: 0.4095353
	speed: 0.0169s/iter; left time: 498.2554s
	iters: 300, epoch: 40 | loss: 0.4292238
	speed: 0.0179s/iter; left time: 525.2575s
	iters: 400, epoch: 40 | loss: 0.3247654
	speed: 0.0162s/iter; left time: 476.0751s
Epoch: 40 cost time: 8.38644790649414
Epoch: 40, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3974 + XiCon Loss:2.1483 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4632149
	speed: 0.0207s/iter; left time: 601.8709s
	iters: 200, epoch: 41 | loss: 0.3505651
	speed: 0.0161s/iter; left time: 467.9356s
	iters: 300, epoch: 41 | loss: 0.3951583
	speed: 0.0169s/iter; left time: 488.5576s
	iters: 400, epoch: 41 | loss: 0.3926768
	speed: 0.0167s/iter; left time: 480.0066s
Epoch: 41 cost time: 8.491114854812622
Epoch: 41, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3973 + XiCon Loss:2.1520 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5305889844894409, mae:0.5119473934173584, mape:3.598691463470459, mspe:1208.4034423828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.9516
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1034476
	speed: 0.0223s/iter; left time: 1082.0188s
	iters: 200, epoch: 1 | loss: 0.8647388
	speed: 0.0154s/iter; left time: 748.6859s
	iters: 300, epoch: 1 | loss: 0.7688710
	speed: 0.0159s/iter; left time: 768.6527s
	iters: 400, epoch: 1 | loss: 0.8321429
	speed: 0.0157s/iter; left time: 760.3725s
Epoch: 1 cost time: 8.356483221054077
Epoch: 1, Steps: 487 Train Loss: 0.8222 (Forecasting Loss:0.8010 + XiCon Loss:2.1217 x Lambda(0.01)), Vali MSE Loss: 1.0984 Test MSE Loss: 0.6609
Validation loss decreased (inf --> 1.098367).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5723265
	speed: 0.0177s/iter; left time: 851.9429s
	iters: 200, epoch: 2 | loss: 0.4339778
	speed: 0.0156s/iter; left time: 747.6853s
	iters: 300, epoch: 2 | loss: 0.4267800
	speed: 0.0162s/iter; left time: 776.0101s
	iters: 400, epoch: 2 | loss: 0.3897847
	speed: 0.0165s/iter; left time: 789.0266s
Epoch: 2 cost time: 8.071365594863892
Epoch: 2, Steps: 487 Train Loss: 0.4564 (Forecasting Loss:0.4353 + XiCon Loss:2.1179 x Lambda(0.01)), Vali MSE Loss: 0.7548 Test MSE Loss: 0.5192
Validation loss decreased (1.098367 --> 0.754786).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4344006
	speed: 0.0166s/iter; left time: 791.0313s
	iters: 200, epoch: 3 | loss: 0.4455384
	speed: 0.0139s/iter; left time: 661.2300s
	iters: 300, epoch: 3 | loss: 0.4253455
	speed: 0.0135s/iter; left time: 639.3631s
	iters: 400, epoch: 3 | loss: 0.4604684
	speed: 0.0141s/iter; left time: 666.2889s
Epoch: 3 cost time: 7.107794761657715
Epoch: 3, Steps: 487 Train Loss: 0.4234 (Forecasting Loss:0.4023 + XiCon Loss:2.1156 x Lambda(0.01)), Vali MSE Loss: 0.7486 Test MSE Loss: 0.5120
Validation loss decreased (0.754786 --> 0.748640).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4101491
	speed: 0.0181s/iter; left time: 852.8205s
	iters: 200, epoch: 4 | loss: 0.4229792
	speed: 0.0160s/iter; left time: 753.0288s
	iters: 300, epoch: 4 | loss: 0.4932885
	speed: 0.0170s/iter; left time: 800.2520s
	iters: 400, epoch: 4 | loss: 0.3578038
	speed: 0.0172s/iter; left time: 803.4937s
Epoch: 4 cost time: 8.262237548828125
Epoch: 4, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3973 + XiCon Loss:2.1181 x Lambda(0.01)), Vali MSE Loss: 0.7408 Test MSE Loss: 0.5092
Validation loss decreased (0.748640 --> 0.740823).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3951508
	speed: 0.0181s/iter; left time: 845.6456s
	iters: 200, epoch: 5 | loss: 0.4462497
	speed: 0.0156s/iter; left time: 727.4990s
	iters: 300, epoch: 5 | loss: 0.4393778
	speed: 0.0162s/iter; left time: 750.3132s
	iters: 400, epoch: 5 | loss: 0.4249678
	speed: 0.0173s/iter; left time: 799.9461s
Epoch: 5 cost time: 8.142380237579346
Epoch: 5, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3951 + XiCon Loss:2.1162 x Lambda(0.01)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5092
Validation loss decreased (0.740823 --> 0.738968).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4306854
	speed: 0.0182s/iter; left time: 838.9225s
	iters: 200, epoch: 6 | loss: 0.3811371
	speed: 0.0169s/iter; left time: 776.4228s
	iters: 300, epoch: 6 | loss: 0.4806046
	speed: 0.0164s/iter; left time: 753.4033s
	iters: 400, epoch: 6 | loss: 0.5258071
	speed: 0.0163s/iter; left time: 748.4206s
Epoch: 6 cost time: 8.161935567855835
Epoch: 6, Steps: 487 Train Loss: 0.4153 (Forecasting Loss:0.3941 + XiCon Loss:2.1183 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5086
Validation loss decreased (0.738968 --> 0.737601).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4019343
	speed: 0.0181s/iter; left time: 826.4113s
	iters: 200, epoch: 7 | loss: 0.3762366
	speed: 0.0158s/iter; left time: 720.4926s
	iters: 300, epoch: 7 | loss: 0.3995838
	speed: 0.0159s/iter; left time: 722.5738s
	iters: 400, epoch: 7 | loss: 0.4059222
	speed: 0.0163s/iter; left time: 741.6042s
Epoch: 7 cost time: 8.000272274017334
Epoch: 7, Steps: 487 Train Loss: 0.4147 (Forecasting Loss:0.3936 + XiCon Loss:2.1144 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5082
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4467619
	speed: 0.0174s/iter; left time: 786.0791s
	iters: 200, epoch: 8 | loss: 0.4754101
	speed: 0.0153s/iter; left time: 688.1912s
	iters: 300, epoch: 8 | loss: 0.4045048
	speed: 0.0162s/iter; left time: 727.5763s
	iters: 400, epoch: 8 | loss: 0.3673010
	speed: 0.0167s/iter; left time: 747.6868s
Epoch: 8 cost time: 8.006523609161377
Epoch: 8, Steps: 487 Train Loss: 0.4144 (Forecasting Loss:0.3932 + XiCon Loss:2.1125 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
Validation loss decreased (0.737601 --> 0.737137).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4051371
	speed: 0.0185s/iter; left time: 825.6388s
	iters: 200, epoch: 9 | loss: 0.4019805
	speed: 0.0157s/iter; left time: 700.6233s
	iters: 300, epoch: 9 | loss: 0.4429654
	speed: 0.0160s/iter; left time: 710.5611s
	iters: 400, epoch: 9 | loss: 0.4479060
	speed: 0.0176s/iter; left time: 779.6864s
Epoch: 9 cost time: 8.214102506637573
Epoch: 9, Steps: 487 Train Loss: 0.4145 (Forecasting Loss:0.3933 + XiCon Loss:2.1168 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5080
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4302120
	speed: 0.0182s/iter; left time: 806.2380s
	iters: 200, epoch: 10 | loss: 0.4168226
	speed: 0.0153s/iter; left time: 675.1115s
	iters: 300, epoch: 10 | loss: 0.4924855
	speed: 0.0168s/iter; left time: 737.5177s
	iters: 400, epoch: 10 | loss: 0.4421744
	speed: 0.0189s/iter; left time: 828.1760s
Epoch: 10 cost time: 8.32669186592102
Epoch: 10, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1151 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4043739
	speed: 0.0178s/iter; left time: 776.4825s
	iters: 200, epoch: 11 | loss: 0.3529288
	speed: 0.0154s/iter; left time: 671.0582s
	iters: 300, epoch: 11 | loss: 0.3769862
	speed: 0.0158s/iter; left time: 686.5074s
	iters: 400, epoch: 11 | loss: 0.3587872
	speed: 0.0166s/iter; left time: 720.6284s
Epoch: 11 cost time: 8.035174369812012
Epoch: 11, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1171 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
Validation loss decreased (0.737137 --> 0.736975).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.5050910
	speed: 0.0181s/iter; left time: 781.9598s
	iters: 200, epoch: 12 | loss: 0.4172325
	speed: 0.0149s/iter; left time: 643.4084s
	iters: 300, epoch: 12 | loss: 0.4836984
	speed: 0.0203s/iter; left time: 871.6862s
	iters: 400, epoch: 12 | loss: 0.3734777
	speed: 0.0163s/iter; left time: 700.6160s
Epoch: 12 cost time: 8.506193399429321
Epoch: 12, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3931 + XiCon Loss:2.1176 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4465736
	speed: 0.0181s/iter; left time: 772.1956s
	iters: 200, epoch: 13 | loss: 0.4126754
	speed: 0.0136s/iter; left time: 579.1432s
	iters: 300, epoch: 13 | loss: 0.3426920
	speed: 0.0137s/iter; left time: 581.3205s
	iters: 400, epoch: 13 | loss: 0.4137671
	speed: 0.0140s/iter; left time: 594.2871s
Epoch: 13 cost time: 7.20280647277832
Epoch: 13, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1143 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3803899
	speed: 0.0177s/iter; left time: 748.0287s
	iters: 200, epoch: 14 | loss: 0.3364747
	speed: 0.0167s/iter; left time: 702.6030s
	iters: 300, epoch: 14 | loss: 0.3546135
	speed: 0.0176s/iter; left time: 739.4860s
	iters: 400, epoch: 14 | loss: 0.4096429
	speed: 0.0164s/iter; left time: 689.6728s
Epoch: 14 cost time: 8.264133930206299
Epoch: 14, Steps: 487 Train Loss: 0.4139 (Forecasting Loss:0.3928 + XiCon Loss:2.1139 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4362735
	speed: 0.0186s/iter; left time: 778.7446s
	iters: 200, epoch: 15 | loss: 0.4111940
	speed: 0.0145s/iter; left time: 605.3007s
	iters: 300, epoch: 15 | loss: 0.5389318
	speed: 0.0135s/iter; left time: 563.0554s
	iters: 400, epoch: 15 | loss: 0.3597772
	speed: 0.0146s/iter; left time: 607.1681s
Epoch: 15 cost time: 7.32632303237915
Epoch: 15, Steps: 487 Train Loss: 0.4145 (Forecasting Loss:0.3934 + XiCon Loss:2.1130 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736975 --> 0.736924).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3719813
	speed: 0.0184s/iter; left time: 759.2607s
	iters: 200, epoch: 16 | loss: 0.3544693
	speed: 0.0159s/iter; left time: 656.2041s
	iters: 300, epoch: 16 | loss: 0.4038943
	speed: 0.0153s/iter; left time: 629.3749s
	iters: 400, epoch: 16 | loss: 0.3944268
	speed: 0.0167s/iter; left time: 686.1618s
Epoch: 16 cost time: 8.01113247871399
Epoch: 16, Steps: 487 Train Loss: 0.4140 (Forecasting Loss:0.3928 + XiCon Loss:2.1133 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3983059
	speed: 0.0188s/iter; left time: 765.6685s
	iters: 200, epoch: 17 | loss: 0.3954839
	speed: 0.0163s/iter; left time: 662.8369s
	iters: 300, epoch: 17 | loss: 0.4203096
	speed: 0.0167s/iter; left time: 676.3494s
	iters: 400, epoch: 17 | loss: 0.4243404
	speed: 0.0167s/iter; left time: 675.7604s
Epoch: 17 cost time: 8.272198915481567
Epoch: 17, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1209 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5014030
	speed: 0.0179s/iter; left time: 721.0908s
	iters: 200, epoch: 18 | loss: 0.4331326
	speed: 0.0152s/iter; left time: 609.6172s
	iters: 300, epoch: 18 | loss: 0.3715838
	speed: 0.0157s/iter; left time: 631.8085s
	iters: 400, epoch: 18 | loss: 0.3469264
	speed: 0.0171s/iter; left time: 685.4150s
Epoch: 18 cost time: 8.05938172340393
Epoch: 18, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1162 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4351928
	speed: 0.0181s/iter; left time: 720.5552s
	iters: 200, epoch: 19 | loss: 0.4150829
	speed: 0.0159s/iter; left time: 630.1186s
	iters: 300, epoch: 19 | loss: 0.3229305
	speed: 0.0159s/iter; left time: 628.9143s
	iters: 400, epoch: 19 | loss: 0.4624239
	speed: 0.0168s/iter; left time: 662.3127s
Epoch: 19 cost time: 8.088104009628296
Epoch: 19, Steps: 487 Train Loss: 0.4143 (Forecasting Loss:0.3931 + XiCon Loss:2.1173 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4301364
	speed: 0.0183s/iter; left time: 719.2534s
	iters: 200, epoch: 20 | loss: 0.3842415
	speed: 0.0137s/iter; left time: 538.7559s
	iters: 300, epoch: 20 | loss: 0.3742217
	speed: 0.0135s/iter; left time: 527.3024s
	iters: 400, epoch: 20 | loss: 0.3506281
	speed: 0.0146s/iter; left time: 570.8070s
Epoch: 20 cost time: 7.196669340133667
Epoch: 20, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3931 + XiCon Loss:2.1183 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736924 --> 0.736922).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4347319
	speed: 0.0177s/iter; left time: 687.0936s
	iters: 200, epoch: 21 | loss: 0.4264758
	speed: 0.0148s/iter; left time: 572.5300s
	iters: 300, epoch: 21 | loss: 0.3478179
	speed: 0.0162s/iter; left time: 624.4461s
	iters: 400, epoch: 21 | loss: 0.3739417
	speed: 0.0164s/iter; left time: 633.3178s
Epoch: 21 cost time: 7.968919277191162
Epoch: 21, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1209 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4179560
	speed: 0.0186s/iter; left time: 714.6733s
	iters: 200, epoch: 22 | loss: 0.4297737
	speed: 0.0153s/iter; left time: 584.9935s
	iters: 300, epoch: 22 | loss: 0.4415321
	speed: 0.0146s/iter; left time: 558.9523s
	iters: 400, epoch: 22 | loss: 0.3896948
	speed: 0.0139s/iter; left time: 530.8132s
Epoch: 22 cost time: 7.508542776107788
Epoch: 22, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1186 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3577394
	speed: 0.0182s/iter; left time: 690.5000s
	iters: 200, epoch: 23 | loss: 0.3826653
	speed: 0.0151s/iter; left time: 570.8136s
	iters: 300, epoch: 23 | loss: 0.4707361
	speed: 0.0160s/iter; left time: 601.9250s
	iters: 400, epoch: 23 | loss: 0.4238588
	speed: 0.0171s/iter; left time: 643.2492s
Epoch: 23 cost time: 8.08112096786499
Epoch: 23, Steps: 487 Train Loss: 0.4140 (Forecasting Loss:0.3929 + XiCon Loss:2.1163 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4334779
	speed: 0.0184s/iter; left time: 686.3296s
	iters: 200, epoch: 24 | loss: 0.4624477
	speed: 0.0156s/iter; left time: 580.0531s
	iters: 300, epoch: 24 | loss: 0.3389598
	speed: 0.0169s/iter; left time: 627.6731s
	iters: 400, epoch: 24 | loss: 0.4460301
	speed: 0.0170s/iter; left time: 630.5152s
Epoch: 24 cost time: 8.229475975036621
Epoch: 24, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1136 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4005414
	speed: 0.0186s/iter; left time: 686.6805s
	iters: 200, epoch: 25 | loss: 0.3603221
	speed: 0.0156s/iter; left time: 575.9413s
	iters: 300, epoch: 25 | loss: 0.4088161
	speed: 0.0175s/iter; left time: 643.2233s
	iters: 400, epoch: 25 | loss: 0.4415504
	speed: 0.0161s/iter; left time: 590.1125s
Epoch: 25 cost time: 8.19911527633667
Epoch: 25, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1170 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5079
Validation loss decreased (0.736922 --> 0.736582).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4119600
	speed: 0.0186s/iter; left time: 677.7316s
	iters: 200, epoch: 26 | loss: 0.3663858
	speed: 0.0163s/iter; left time: 593.7674s
	iters: 300, epoch: 26 | loss: 0.4414790
	speed: 0.0164s/iter; left time: 593.7927s
	iters: 400, epoch: 26 | loss: 0.4661757
	speed: 0.0169s/iter; left time: 610.5073s
Epoch: 26 cost time: 8.347683906555176
Epoch: 26, Steps: 487 Train Loss: 0.4140 (Forecasting Loss:0.3928 + XiCon Loss:2.1142 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4124088
	speed: 0.0171s/iter; left time: 613.6451s
	iters: 200, epoch: 27 | loss: 0.4545445
	speed: 0.0154s/iter; left time: 550.6784s
	iters: 300, epoch: 27 | loss: 0.3631487
	speed: 0.0166s/iter; left time: 593.6956s
	iters: 400, epoch: 27 | loss: 0.4151521
	speed: 0.0159s/iter; left time: 566.6901s
Epoch: 27 cost time: 8.013875246047974
Epoch: 27, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1183 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3865499
	speed: 0.0185s/iter; left time: 654.1488s
	iters: 200, epoch: 28 | loss: 0.3818145
	speed: 0.0151s/iter; left time: 533.1884s
	iters: 300, epoch: 28 | loss: 0.3738221
	speed: 0.0155s/iter; left time: 547.6832s
	iters: 400, epoch: 28 | loss: 0.4378627
	speed: 0.0162s/iter; left time: 569.9616s
Epoch: 28 cost time: 7.93367862701416
Epoch: 28, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3931 + XiCon Loss:2.1157 x Lambda(0.01)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5079
Validation loss decreased (0.736582 --> 0.736480).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4692852
	speed: 0.0181s/iter; left time: 632.5326s
	iters: 200, epoch: 29 | loss: 0.4215671
	speed: 0.0157s/iter; left time: 545.8592s
	iters: 300, epoch: 29 | loss: 0.3785169
	speed: 0.0164s/iter; left time: 570.6998s
	iters: 400, epoch: 29 | loss: 0.4143297
	speed: 0.0158s/iter; left time: 548.7078s
Epoch: 29 cost time: 8.055263042449951
Epoch: 29, Steps: 487 Train Loss: 0.4140 (Forecasting Loss:0.3929 + XiCon Loss:2.1122 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4709803
	speed: 0.0178s/iter; left time: 614.5743s
	iters: 200, epoch: 30 | loss: 0.4476805
	speed: 0.0155s/iter; left time: 534.0455s
	iters: 300, epoch: 30 | loss: 0.4038261
	speed: 0.0161s/iter; left time: 550.2132s
	iters: 400, epoch: 30 | loss: 0.3793458
	speed: 0.0169s/iter; left time: 577.4030s
Epoch: 30 cost time: 8.09765100479126
Epoch: 30, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3930 + XiCon Loss:2.1181 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3696403
	speed: 0.0183s/iter; left time: 623.3362s
	iters: 200, epoch: 31 | loss: 0.3257067
	speed: 0.0155s/iter; left time: 524.6470s
	iters: 300, epoch: 31 | loss: 0.4513795
	speed: 0.0152s/iter; left time: 514.6346s
	iters: 400, epoch: 31 | loss: 0.4057516
	speed: 0.0158s/iter; left time: 532.0022s
Epoch: 31 cost time: 7.931714057922363
Epoch: 31, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1151 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4616357
	speed: 0.0184s/iter; left time: 617.7350s
	iters: 200, epoch: 32 | loss: 0.4816166
	speed: 0.0165s/iter; left time: 551.9753s
	iters: 300, epoch: 32 | loss: 0.3972187
	speed: 0.0165s/iter; left time: 550.7632s
	iters: 400, epoch: 32 | loss: 0.4235477
	speed: 0.0173s/iter; left time: 574.4081s
Epoch: 32 cost time: 8.315372943878174
Epoch: 32, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3930 + XiCon Loss:2.1162 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4436257
	speed: 0.0191s/iter; left time: 629.0021s
	iters: 200, epoch: 33 | loss: 0.4373419
	speed: 0.0147s/iter; left time: 483.3115s
	iters: 300, epoch: 33 | loss: 0.3734390
	speed: 0.0156s/iter; left time: 513.5757s
	iters: 400, epoch: 33 | loss: 0.3623692
	speed: 0.0163s/iter; left time: 532.5470s
Epoch: 33 cost time: 8.057680130004883
Epoch: 33, Steps: 487 Train Loss: 0.4140 (Forecasting Loss:0.3929 + XiCon Loss:2.1128 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3733407
	speed: 0.0175s/iter; left time: 568.9663s
	iters: 200, epoch: 34 | loss: 0.4209028
	speed: 0.0157s/iter; left time: 509.6143s
	iters: 300, epoch: 34 | loss: 0.3297457
	speed: 0.0150s/iter; left time: 484.9910s
	iters: 400, epoch: 34 | loss: 0.3625869
	speed: 0.0164s/iter; left time: 529.2781s
Epoch: 34 cost time: 7.887612819671631
Epoch: 34, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1156 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4054411
	speed: 0.0190s/iter; left time: 610.2907s
	iters: 200, epoch: 35 | loss: 0.4387921
	speed: 0.0129s/iter; left time: 411.1757s
	iters: 300, epoch: 35 | loss: 0.3633247
	speed: 0.0159s/iter; left time: 506.9285s
	iters: 400, epoch: 35 | loss: 0.3551299
	speed: 0.0147s/iter; left time: 467.0820s
Epoch: 35 cost time: 7.487945318222046
Epoch: 35, Steps: 487 Train Loss: 0.4144 (Forecasting Loss:0.3932 + XiCon Loss:2.1150 x Lambda(0.01)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5079
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.3866475
	speed: 0.0335s/iter; left time: 1057.7914s
	iters: 200, epoch: 36 | loss: 0.5022215
	speed: 0.0133s/iter; left time: 417.6757s
	iters: 300, epoch: 36 | loss: 0.3721836
	speed: 0.0125s/iter; left time: 391.7230s
	iters: 400, epoch: 36 | loss: 0.4644906
	speed: 0.0133s/iter; left time: 416.0581s
Epoch: 36 cost time: 8.450770616531372
Epoch: 36, Steps: 487 Train Loss: 0.4139 (Forecasting Loss:0.3928 + XiCon Loss:2.1155 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3896119
	speed: 0.0198s/iter; left time: 616.4357s
	iters: 200, epoch: 37 | loss: 0.4232340
	speed: 0.0170s/iter; left time: 527.3744s
	iters: 300, epoch: 37 | loss: 0.4666882
	speed: 0.0166s/iter; left time: 511.0823s
	iters: 400, epoch: 37 | loss: 0.4098474
	speed: 0.0165s/iter; left time: 507.0831s
Epoch: 37 cost time: 8.506669998168945
Epoch: 37, Steps: 487 Train Loss: 0.4142 (Forecasting Loss:0.3930 + XiCon Loss:2.1125 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3602618
	speed: 0.0186s/iter; left time: 568.6269s
	iters: 200, epoch: 38 | loss: 0.3539632
	speed: 0.0155s/iter; left time: 471.0350s
	iters: 300, epoch: 38 | loss: 0.4376167
	speed: 0.0157s/iter; left time: 476.1141s
	iters: 400, epoch: 38 | loss: 0.4433477
	speed: 0.0166s/iter; left time: 503.5906s
Epoch: 38 cost time: 8.11871337890625
Epoch: 38, Steps: 487 Train Loss: 0.4141 (Forecasting Loss:0.3929 + XiCon Loss:2.1206 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5079
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5129415392875671, mae:0.5028875470161438, mape:3.570399761199951, mspe:1174.88037109375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 19.1052
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8708423
	speed: 0.0192s/iter; left time: 934.2016s
	iters: 200, epoch: 1 | loss: 0.8372383
	speed: 0.0150s/iter; left time: 725.8614s
	iters: 300, epoch: 1 | loss: 0.7381250
	speed: 0.0133s/iter; left time: 643.9387s
	iters: 400, epoch: 1 | loss: 0.6586806
	speed: 0.0167s/iter; left time: 804.3924s
Epoch: 1 cost time: 7.667816400527954
Epoch: 1, Steps: 487 Train Loss: 0.7744 (Forecasting Loss:0.7529 + XiCon Loss:2.1566 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005157).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5190452
	speed: 0.0195s/iter; left time: 938.0515s
	iters: 200, epoch: 2 | loss: 0.4308125
	speed: 0.0162s/iter; left time: 778.6728s
	iters: 300, epoch: 2 | loss: 0.5732974
	speed: 0.0177s/iter; left time: 848.9711s
	iters: 400, epoch: 2 | loss: 0.4182225
	speed: 0.0162s/iter; left time: 772.8085s
Epoch: 2 cost time: 8.482007503509521
Epoch: 2, Steps: 487 Train Loss: 0.4576 (Forecasting Loss:0.4361 + XiCon Loss:2.1489 x Lambda(0.01)), Vali MSE Loss: 0.7607 Test MSE Loss: 0.5392
Validation loss decreased (1.005157 --> 0.760651).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4735796
	speed: 0.0195s/iter; left time: 927.2107s
	iters: 200, epoch: 3 | loss: 0.4015005
	speed: 0.0164s/iter; left time: 778.2736s
	iters: 300, epoch: 3 | loss: 0.5013934
	speed: 0.0168s/iter; left time: 799.1231s
	iters: 400, epoch: 3 | loss: 0.3764846
	speed: 0.0167s/iter; left time: 788.2835s
Epoch: 3 cost time: 8.421371459960938
Epoch: 3, Steps: 487 Train Loss: 0.4276 (Forecasting Loss:0.4061 + XiCon Loss:2.1467 x Lambda(0.01)), Vali MSE Loss: 0.7459 Test MSE Loss: 0.5194
Validation loss decreased (0.760651 --> 0.745925).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5065281
	speed: 0.0200s/iter; left time: 942.6565s
	iters: 200, epoch: 4 | loss: 0.4207722
	speed: 0.0172s/iter; left time: 808.3762s
	iters: 300, epoch: 4 | loss: 0.4127567
	speed: 0.0183s/iter; left time: 860.1515s
	iters: 400, epoch: 4 | loss: 0.3124319
	speed: 0.0166s/iter; left time: 776.3627s
Epoch: 4 cost time: 8.66720175743103
Epoch: 4, Steps: 487 Train Loss: 0.4217 (Forecasting Loss:0.4003 + XiCon Loss:2.1426 x Lambda(0.01)), Vali MSE Loss: 0.7463 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3802041
	speed: 0.0203s/iter; left time: 946.1268s
	iters: 200, epoch: 5 | loss: 0.4815086
	speed: 0.0173s/iter; left time: 805.1645s
	iters: 300, epoch: 5 | loss: 0.4018733
	speed: 0.0166s/iter; left time: 770.4420s
	iters: 400, epoch: 5 | loss: 0.4664667
	speed: 0.0171s/iter; left time: 791.1841s
Epoch: 5 cost time: 8.608343839645386
Epoch: 5, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3982 + XiCon Loss:2.1425 x Lambda(0.01)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5126
Validation loss decreased (0.745925 --> 0.739132).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4656377
	speed: 0.0199s/iter; left time: 917.8123s
	iters: 200, epoch: 6 | loss: 0.4416223
	speed: 0.0173s/iter; left time: 799.2328s
	iters: 300, epoch: 6 | loss: 0.5902132
	speed: 0.0161s/iter; left time: 741.2760s
	iters: 400, epoch: 6 | loss: 0.4851271
	speed: 0.0147s/iter; left time: 672.7872s
Epoch: 6 cost time: 8.063067436218262
Epoch: 6, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3969 + XiCon Loss:2.1481 x Lambda(0.01)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5117
Validation loss decreased (0.739132 --> 0.738565).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3471262
	speed: 0.0195s/iter; left time: 888.9421s
	iters: 200, epoch: 7 | loss: 0.3795186
	speed: 0.0165s/iter; left time: 752.1007s
	iters: 300, epoch: 7 | loss: 0.3390152
	speed: 0.0178s/iter; left time: 809.3086s
	iters: 400, epoch: 7 | loss: 0.3715622
	speed: 0.0164s/iter; left time: 743.1709s
Epoch: 7 cost time: 8.45201587677002
Epoch: 7, Steps: 487 Train Loss: 0.4179 (Forecasting Loss:0.3965 + XiCon Loss:2.1388 x Lambda(0.01)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5126
Validation loss decreased (0.738565 --> 0.738327).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3751009
	speed: 0.0190s/iter; left time: 860.3417s
	iters: 200, epoch: 8 | loss: 0.4062166
	speed: 0.0169s/iter; left time: 759.8805s
	iters: 300, epoch: 8 | loss: 0.5672870
	speed: 0.0173s/iter; left time: 778.0616s
	iters: 400, epoch: 8 | loss: 0.4491956
	speed: 0.0171s/iter; left time: 766.6182s
Epoch: 8 cost time: 8.586842060089111
Epoch: 8, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3961 + XiCon Loss:2.1427 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5118
Validation loss decreased (0.738327 --> 0.737791).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3772641
	speed: 0.0197s/iter; left time: 882.0768s
	iters: 200, epoch: 9 | loss: 0.5046366
	speed: 0.0169s/iter; left time: 755.9229s
	iters: 300, epoch: 9 | loss: 0.4900227
	speed: 0.0164s/iter; left time: 728.4310s
	iters: 400, epoch: 9 | loss: 0.4250601
	speed: 0.0161s/iter; left time: 714.8947s
Epoch: 9 cost time: 8.135153532028198
Epoch: 9, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3960 + XiCon Loss:2.1430 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5119
Validation loss decreased (0.737791 --> 0.737715).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3846055
	speed: 0.0192s/iter; left time: 850.7147s
	iters: 200, epoch: 10 | loss: 0.4802875
	speed: 0.0168s/iter; left time: 740.8625s
	iters: 300, epoch: 10 | loss: 0.4008430
	speed: 0.0166s/iter; left time: 729.9923s
	iters: 400, epoch: 10 | loss: 0.4283021
	speed: 0.0170s/iter; left time: 744.7359s
Epoch: 10 cost time: 8.406199216842651
Epoch: 10, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3958 + XiCon Loss:2.1475 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
Validation loss decreased (0.737715 --> 0.737678).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3977202
	speed: 0.0187s/iter; left time: 818.9410s
	iters: 200, epoch: 11 | loss: 0.4266796
	speed: 0.0167s/iter; left time: 728.1253s
	iters: 300, epoch: 11 | loss: 0.3590543
	speed: 0.0169s/iter; left time: 735.4836s
	iters: 400, epoch: 11 | loss: 0.4172400
	speed: 0.0139s/iter; left time: 604.8129s
Epoch: 11 cost time: 7.840790033340454
Epoch: 11, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1434 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4583880
	speed: 0.0199s/iter; left time: 860.3029s
	iters: 200, epoch: 12 | loss: 0.2905469
	speed: 0.0162s/iter; left time: 699.7946s
	iters: 300, epoch: 12 | loss: 0.4232191
	speed: 0.0173s/iter; left time: 742.7839s
	iters: 400, epoch: 12 | loss: 0.4554237
	speed: 0.0169s/iter; left time: 723.8765s
Epoch: 12 cost time: 8.483476638793945
Epoch: 12, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1387 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
Validation loss decreased (0.737678 --> 0.737359).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3905198
	speed: 0.0202s/iter; left time: 862.0966s
	iters: 200, epoch: 13 | loss: 0.3415851
	speed: 0.0171s/iter; left time: 728.8609s
	iters: 300, epoch: 13 | loss: 0.4095379
	speed: 0.0174s/iter; left time: 742.0071s
	iters: 400, epoch: 13 | loss: 0.4024855
	speed: 0.0166s/iter; left time: 704.5551s
Epoch: 13 cost time: 8.52802038192749
Epoch: 13, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1426 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3725155
	speed: 0.0188s/iter; left time: 794.2729s
	iters: 200, epoch: 14 | loss: 0.3644098
	speed: 0.0151s/iter; left time: 635.9551s
	iters: 300, epoch: 14 | loss: 0.3998604
	speed: 0.0138s/iter; left time: 582.5543s
	iters: 400, epoch: 14 | loss: 0.3847217
	speed: 0.0146s/iter; left time: 613.9757s
Epoch: 14 cost time: 7.372011423110962
Epoch: 14, Steps: 487 Train Loss: 0.4170 (Forecasting Loss:0.3956 + XiCon Loss:2.1446 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4128631
	speed: 0.0193s/iter; left time: 806.8539s
	iters: 200, epoch: 15 | loss: 0.3969410
	speed: 0.0172s/iter; left time: 715.2259s
	iters: 300, epoch: 15 | loss: 0.4156266
	speed: 0.0159s/iter; left time: 660.5432s
	iters: 400, epoch: 15 | loss: 0.4617425
	speed: 0.0148s/iter; left time: 615.2180s
Epoch: 15 cost time: 8.08367133140564
Epoch: 15, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3959 + XiCon Loss:2.1474 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4435956
	speed: 0.0149s/iter; left time: 617.1639s
	iters: 200, epoch: 16 | loss: 0.3879873
	speed: 0.0186s/iter; left time: 766.5434s
	iters: 300, epoch: 16 | loss: 0.4855736
	speed: 0.0263s/iter; left time: 1079.2202s
	iters: 400, epoch: 16 | loss: 0.4249105
	speed: 0.0137s/iter; left time: 563.6859s
Epoch: 16 cost time: 8.61934208869934
Epoch: 16, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3960 + XiCon Loss:2.1380 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3314266
	speed: 0.0183s/iter; left time: 747.0738s
	iters: 200, epoch: 17 | loss: 0.3996540
	speed: 0.0159s/iter; left time: 648.6928s
	iters: 300, epoch: 17 | loss: 0.3658165
	speed: 0.0145s/iter; left time: 588.5205s
	iters: 400, epoch: 17 | loss: 0.3396399
	speed: 0.0147s/iter; left time: 594.9149s
Epoch: 17 cost time: 7.599041938781738
Epoch: 17, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1401 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4258496
	speed: 0.0184s/iter; left time: 740.3699s
	iters: 200, epoch: 18 | loss: 0.4107574
	speed: 0.0169s/iter; left time: 678.8309s
	iters: 300, epoch: 18 | loss: 0.4306723
	speed: 0.0171s/iter; left time: 686.9356s
	iters: 400, epoch: 18 | loss: 0.3412756
	speed: 0.0161s/iter; left time: 643.3011s
Epoch: 18 cost time: 8.291462659835815
Epoch: 18, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1409 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4413030
	speed: 0.0201s/iter; left time: 798.8966s
	iters: 200, epoch: 19 | loss: 0.4639251
	speed: 0.0171s/iter; left time: 677.5962s
	iters: 300, epoch: 19 | loss: 0.3506436
	speed: 0.0163s/iter; left time: 646.3163s
	iters: 400, epoch: 19 | loss: 0.4930766
	speed: 0.0169s/iter; left time: 666.5065s
Epoch: 19 cost time: 8.495831727981567
Epoch: 19, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3957 + XiCon Loss:2.1423 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4113755
	speed: 0.0193s/iter; left time: 760.4136s
	iters: 200, epoch: 20 | loss: 0.3536024
	speed: 0.0172s/iter; left time: 673.9949s
	iters: 300, epoch: 20 | loss: 0.5513583
	speed: 0.0164s/iter; left time: 643.2780s
	iters: 400, epoch: 20 | loss: 0.4347253
	speed: 0.0171s/iter; left time: 665.9539s
Epoch: 20 cost time: 8.434467315673828
Epoch: 20, Steps: 487 Train Loss: 0.4171 (Forecasting Loss:0.3957 + XiCon Loss:2.1434 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
Validation loss decreased (0.737359 --> 0.737054).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4380675
	speed: 0.0187s/iter; left time: 725.3502s
	iters: 200, epoch: 21 | loss: 0.3614423
	speed: 0.0165s/iter; left time: 640.1379s
	iters: 300, epoch: 21 | loss: 0.3600606
	speed: 0.0171s/iter; left time: 662.0014s
	iters: 400, epoch: 21 | loss: 0.4108467
	speed: 0.0166s/iter; left time: 639.2653s
Epoch: 21 cost time: 8.304744005203247
Epoch: 21, Steps: 487 Train Loss: 0.4171 (Forecasting Loss:0.3957 + XiCon Loss:2.1444 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4213882
	speed: 0.0192s/iter; left time: 738.5716s
	iters: 200, epoch: 22 | loss: 0.3948847
	speed: 0.0167s/iter; left time: 639.5517s
	iters: 300, epoch: 22 | loss: 0.4018745
	speed: 0.0156s/iter; left time: 593.6363s
	iters: 400, epoch: 22 | loss: 0.4173954
	speed: 0.0171s/iter; left time: 650.5134s
Epoch: 22 cost time: 8.371720790863037
Epoch: 22, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1417 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4258071
	speed: 0.0199s/iter; left time: 755.7618s
	iters: 200, epoch: 23 | loss: 0.4744723
	speed: 0.0171s/iter; left time: 645.2084s
	iters: 300, epoch: 23 | loss: 0.4444454
	speed: 0.0169s/iter; left time: 637.7272s
	iters: 400, epoch: 23 | loss: 0.4459882
	speed: 0.0167s/iter; left time: 626.7729s
Epoch: 23 cost time: 8.577524900436401
Epoch: 23, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1434 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4596817
	speed: 0.0198s/iter; left time: 741.5385s
	iters: 200, epoch: 24 | loss: 0.4443053
	speed: 0.0163s/iter; left time: 608.0255s
	iters: 300, epoch: 24 | loss: 0.4232590
	speed: 0.0172s/iter; left time: 638.7001s
	iters: 400, epoch: 24 | loss: 0.3792926
	speed: 0.0169s/iter; left time: 625.7024s
Epoch: 24 cost time: 8.513493299484253
Epoch: 24, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3960 + XiCon Loss:2.1420 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5117
Validation loss decreased (0.737054 --> 0.736936).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4485478
	speed: 0.0195s/iter; left time: 718.3849s
	iters: 200, epoch: 25 | loss: 0.4428316
	speed: 0.0162s/iter; left time: 595.7121s
	iters: 300, epoch: 25 | loss: 0.4218039
	speed: 0.0171s/iter; left time: 626.0208s
	iters: 400, epoch: 25 | loss: 0.4751296
	speed: 0.0172s/iter; left time: 629.0707s
Epoch: 25 cost time: 8.46895170211792
Epoch: 25, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3960 + XiCon Loss:2.1446 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4938704
	speed: 0.0188s/iter; left time: 684.9435s
	iters: 200, epoch: 26 | loss: 0.4371005
	speed: 0.0168s/iter; left time: 609.1380s
	iters: 300, epoch: 26 | loss: 0.3626057
	speed: 0.0177s/iter; left time: 642.8499s
	iters: 400, epoch: 26 | loss: 0.3951000
	speed: 0.0169s/iter; left time: 610.8797s
Epoch: 26 cost time: 8.468928813934326
Epoch: 26, Steps: 487 Train Loss: 0.4171 (Forecasting Loss:0.3957 + XiCon Loss:2.1423 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4493336
	speed: 0.0202s/iter; left time: 725.8477s
	iters: 200, epoch: 27 | loss: 0.5597741
	speed: 0.0170s/iter; left time: 609.3197s
	iters: 300, epoch: 27 | loss: 0.3983565
	speed: 0.0186s/iter; left time: 664.9487s
	iters: 400, epoch: 27 | loss: 0.3584919
	speed: 0.0167s/iter; left time: 594.0804s
Epoch: 27 cost time: 8.727939367294312
Epoch: 27, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1404 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3540404
	speed: 0.0188s/iter; left time: 667.0576s
	iters: 200, epoch: 28 | loss: 0.3657805
	speed: 0.0168s/iter; left time: 593.9469s
	iters: 300, epoch: 28 | loss: 0.4418126
	speed: 0.0170s/iter; left time: 597.6874s
	iters: 400, epoch: 28 | loss: 0.4339615
	speed: 0.0167s/iter; left time: 585.9825s
Epoch: 28 cost time: 8.416362047195435
Epoch: 28, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1425 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3753636
	speed: 0.0188s/iter; left time: 656.5927s
	iters: 200, epoch: 29 | loss: 0.3964391
	speed: 0.0170s/iter; left time: 594.1879s
	iters: 300, epoch: 29 | loss: 0.4469175
	speed: 0.0168s/iter; left time: 585.1687s
	iters: 400, epoch: 29 | loss: 0.3838726
	speed: 0.0170s/iter; left time: 590.2760s
Epoch: 29 cost time: 8.429729223251343
Epoch: 29, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1424 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3837205
	speed: 0.0208s/iter; left time: 718.7888s
	iters: 200, epoch: 30 | loss: 0.3929859
	speed: 0.0166s/iter; left time: 572.3115s
	iters: 300, epoch: 30 | loss: 0.3370550
	speed: 0.0172s/iter; left time: 589.2489s
	iters: 400, epoch: 30 | loss: 0.3717803
	speed: 0.0174s/iter; left time: 595.8001s
Epoch: 30 cost time: 8.709014177322388
Epoch: 30, Steps: 487 Train Loss: 0.4170 (Forecasting Loss:0.3956 + XiCon Loss:2.1467 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3984515
	speed: 0.0194s/iter; left time: 659.7644s
	iters: 200, epoch: 31 | loss: 0.4163486
	speed: 0.0176s/iter; left time: 596.6316s
	iters: 300, epoch: 31 | loss: 0.3179346
	speed: 0.0170s/iter; left time: 573.5417s
	iters: 400, epoch: 31 | loss: 0.3713351
	speed: 0.0173s/iter; left time: 584.3901s
Epoch: 31 cost time: 8.621659517288208
Epoch: 31, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3958 + XiCon Loss:2.1471 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4290497
	speed: 0.0189s/iter; left time: 634.0487s
	iters: 200, epoch: 32 | loss: 0.4455266
	speed: 0.0162s/iter; left time: 541.5073s
	iters: 300, epoch: 32 | loss: 0.3626320
	speed: 0.0166s/iter; left time: 553.6020s
	iters: 400, epoch: 32 | loss: 0.4437557
	speed: 0.0169s/iter; left time: 562.3670s
Epoch: 32 cost time: 8.37695050239563
Epoch: 32, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1477 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4047653
	speed: 0.0220s/iter; left time: 727.0897s
	iters: 200, epoch: 33 | loss: 0.4772950
	speed: 0.0158s/iter; left time: 521.5594s
	iters: 300, epoch: 33 | loss: 0.3703941
	speed: 0.0153s/iter; left time: 500.6955s
	iters: 400, epoch: 33 | loss: 0.4712760
	speed: 0.0142s/iter; left time: 465.7473s
Epoch: 33 cost time: 7.974263429641724
Epoch: 33, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3959 + XiCon Loss:2.1422 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4101216
	speed: 0.0150s/iter; left time: 486.6981s
	iters: 200, epoch: 34 | loss: 0.4721070
	speed: 0.0236s/iter; left time: 763.8537s
	iters: 300, epoch: 34 | loss: 0.4315664
	speed: 0.0135s/iter; left time: 437.6298s
	iters: 400, epoch: 34 | loss: 0.4131175
	speed: 0.0139s/iter; left time: 449.3670s
Epoch: 34 cost time: 7.777650594711304
Epoch: 34, Steps: 487 Train Loss: 0.4170 (Forecasting Loss:0.3956 + XiCon Loss:2.1422 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5117
Validation loss decreased (0.736936 --> 0.736619).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3932294
	speed: 0.0181s/iter; left time: 581.1841s
	iters: 200, epoch: 35 | loss: 0.3913360
	speed: 0.0157s/iter; left time: 502.5666s
	iters: 300, epoch: 35 | loss: 0.4499349
	speed: 0.0160s/iter; left time: 508.6042s
	iters: 400, epoch: 35 | loss: 0.3664087
	speed: 0.0145s/iter; left time: 460.6440s
Epoch: 35 cost time: 7.830039739608765
Epoch: 35, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1474 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4887842
	speed: 0.0181s/iter; left time: 570.5235s
	iters: 200, epoch: 36 | loss: 0.3399749
	speed: 0.0144s/iter; left time: 454.0429s
	iters: 300, epoch: 36 | loss: 0.3627229
	speed: 0.0153s/iter; left time: 478.6685s
	iters: 400, epoch: 36 | loss: 0.4179481
	speed: 0.0195s/iter; left time: 610.1618s
Epoch: 36 cost time: 8.2105131149292
Epoch: 36, Steps: 487 Train Loss: 0.4170 (Forecasting Loss:0.3956 + XiCon Loss:2.1445 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4612820
	speed: 0.0183s/iter; left time: 567.6432s
	iters: 200, epoch: 37 | loss: 0.3911945
	speed: 0.0152s/iter; left time: 470.8126s
	iters: 300, epoch: 37 | loss: 0.3939561
	speed: 0.0161s/iter; left time: 497.7527s
	iters: 400, epoch: 37 | loss: 0.5085043
	speed: 0.0157s/iter; left time: 482.3615s
Epoch: 37 cost time: 7.889291048049927
Epoch: 37, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3958 + XiCon Loss:2.1451 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3885270
	speed: 0.0192s/iter; left time: 588.5568s
	iters: 200, epoch: 38 | loss: 0.4265117
	speed: 0.0151s/iter; left time: 461.6127s
	iters: 300, epoch: 38 | loss: 0.4027528
	speed: 0.0157s/iter; left time: 475.7718s
	iters: 400, epoch: 38 | loss: 0.4503228
	speed: 0.0172s/iter; left time: 521.4918s
Epoch: 38 cost time: 8.179232835769653
Epoch: 38, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1442 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.4897459
	speed: 0.0178s/iter; left time: 536.2527s
	iters: 200, epoch: 39 | loss: 0.3640255
	speed: 0.0163s/iter; left time: 490.3218s
	iters: 300, epoch: 39 | loss: 0.4677545
	speed: 0.0156s/iter; left time: 467.0180s
	iters: 400, epoch: 39 | loss: 0.4194808
	speed: 0.0156s/iter; left time: 464.4388s
Epoch: 39 cost time: 7.934683561325073
Epoch: 39, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1433 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4863647
	speed: 0.0184s/iter; left time: 545.0078s
	iters: 200, epoch: 40 | loss: 0.4350528
	speed: 0.0170s/iter; left time: 500.8387s
	iters: 300, epoch: 40 | loss: 0.4017524
	speed: 0.0164s/iter; left time: 482.8915s
	iters: 400, epoch: 40 | loss: 0.4655264
	speed: 0.0164s/iter; left time: 480.8363s
Epoch: 40 cost time: 8.275177001953125
Epoch: 40, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3960 + XiCon Loss:2.1427 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.3973245
	speed: 0.0177s/iter; left time: 516.0294s
	iters: 200, epoch: 41 | loss: 0.3963706
	speed: 0.0150s/iter; left time: 436.4259s
	iters: 300, epoch: 41 | loss: 0.4459484
	speed: 0.0153s/iter; left time: 443.8211s
	iters: 400, epoch: 41 | loss: 0.4201690
	speed: 0.0169s/iter; left time: 487.7653s
Epoch: 41 cost time: 7.983668565750122
Epoch: 41, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1431 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.3575379
	speed: 0.0185s/iter; left time: 531.0221s
	iters: 200, epoch: 42 | loss: 0.3897420
	speed: 0.0157s/iter; left time: 449.2990s
	iters: 300, epoch: 42 | loss: 0.4509234
	speed: 0.0158s/iter; left time: 449.5439s
	iters: 400, epoch: 42 | loss: 0.4886038
	speed: 0.0156s/iter; left time: 441.3755s
Epoch: 42 cost time: 7.925671577453613
Epoch: 42, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3958 + XiCon Loss:2.1444 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.3764120
	speed: 0.0178s/iter; left time: 501.2361s
	iters: 200, epoch: 43 | loss: 0.4783755
	speed: 0.0150s/iter; left time: 419.9718s
	iters: 300, epoch: 43 | loss: 0.4175308
	speed: 0.0161s/iter; left time: 449.7344s
	iters: 400, epoch: 43 | loss: 0.4284194
	speed: 0.0165s/iter; left time: 458.1570s
Epoch: 43 cost time: 7.960387468338013
Epoch: 43, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3959 + XiCon Loss:2.1480 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.4178039
	speed: 0.0163s/iter; left time: 449.5533s
	iters: 200, epoch: 44 | loss: 0.4633483
	speed: 0.0125s/iter; left time: 345.4721s
	iters: 300, epoch: 44 | loss: 0.5270395
	speed: 0.0152s/iter; left time: 417.7447s
	iters: 400, epoch: 44 | loss: 0.4705788
	speed: 0.0171s/iter; left time: 467.1088s
Epoch: 44 cost time: 7.452435493469238
Epoch: 44, Steps: 487 Train Loss: 0.4171 (Forecasting Loss:0.3957 + XiCon Loss:2.1426 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182315111160278, mae:0.5052385330200195, mape:3.478569984436035, mspe:1099.1409912109375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5199+-0.00805, MAE:0.5063+-0.00423, MAPE:3.5252+-0.07897, MSPE:1145.1362+-64.77021, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.3368
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9560112
	speed: 0.0346s/iter; left time: 819.7807s
	iters: 200, epoch: 1 | loss: 0.9788318
	speed: 0.0318s/iter; left time: 750.1712s
Epoch: 1 cost time: 7.700525760650635
Epoch: 1, Steps: 238 Train Loss: 1.0060 (Forecasting Loss:0.9803 + XiCon Loss:2.5649 x Lambda(0.01)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755403).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6333610
	speed: 0.0312s/iter; left time: 732.8145s
	iters: 200, epoch: 2 | loss: 0.6096785
	speed: 0.0271s/iter; left time: 634.0013s
Epoch: 2 cost time: 6.8925676345825195
Epoch: 2, Steps: 238 Train Loss: 0.6426 (Forecasting Loss:0.6169 + XiCon Loss:2.5619 x Lambda(0.01)), Vali MSE Loss: 1.0368 Test MSE Loss: 0.8580
Validation loss decreased (1.755403 --> 1.036811).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5839309
	speed: 0.0299s/iter; left time: 695.3117s
	iters: 200, epoch: 3 | loss: 0.5906892
	speed: 0.0276s/iter; left time: 638.3502s
Epoch: 3 cost time: 6.841531753540039
Epoch: 3, Steps: 238 Train Loss: 0.5783 (Forecasting Loss:0.5527 + XiCon Loss:2.5632 x Lambda(0.01)), Vali MSE Loss: 1.0179 Test MSE Loss: 0.8515
Validation loss decreased (1.036811 --> 1.017889).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5637790
	speed: 0.0289s/iter; left time: 664.6236s
	iters: 200, epoch: 4 | loss: 0.5302951
	speed: 0.0312s/iter; left time: 713.9408s
Epoch: 4 cost time: 7.067483425140381
Epoch: 4, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5446 + XiCon Loss:2.5589 x Lambda(0.01)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8494
Validation loss decreased (1.017889 --> 1.010512).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5472994
	speed: 0.0309s/iter; left time: 703.7254s
	iters: 200, epoch: 5 | loss: 0.5934781
	speed: 0.0290s/iter; left time: 657.4590s
Epoch: 5 cost time: 7.003807306289673
Epoch: 5, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5414 + XiCon Loss:2.5603 x Lambda(0.01)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8491
Validation loss decreased (1.010512 --> 1.007478).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5547434
	speed: 0.0311s/iter; left time: 699.8500s
	iters: 200, epoch: 6 | loss: 0.5675212
	speed: 0.0278s/iter; left time: 623.7791s
Epoch: 6 cost time: 6.945133686065674
Epoch: 6, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5399 + XiCon Loss:2.5565 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8487
Validation loss decreased (1.007478 --> 1.006162).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5560622
	speed: 0.0325s/iter; left time: 723.0684s
	iters: 200, epoch: 7 | loss: 0.5672180
	speed: 0.0279s/iter; left time: 619.1839s
Epoch: 7 cost time: 7.1648173332214355
Epoch: 7, Steps: 238 Train Loss: 0.5647 (Forecasting Loss:0.5391 + XiCon Loss:2.5610 x Lambda(0.01)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8487
Validation loss decreased (1.006162 --> 1.004476).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5187629
	speed: 0.0282s/iter; left time: 622.3426s
	iters: 200, epoch: 8 | loss: 0.5912377
	speed: 0.0291s/iter; left time: 639.3892s
Epoch: 8 cost time: 6.798947334289551
Epoch: 8, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5387 + XiCon Loss:2.5559 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8486
Validation loss decreased (1.004476 --> 1.004408).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5951267
	speed: 0.0307s/iter; left time: 669.3886s
	iters: 200, epoch: 9 | loss: 0.6134791
	speed: 0.0293s/iter; left time: 636.2227s
Epoch: 9 cost time: 7.085843801498413
Epoch: 9, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5386 + XiCon Loss:2.5608 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8486
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5534377
	speed: 0.0317s/iter; left time: 683.8892s
	iters: 200, epoch: 10 | loss: 0.5834002
	speed: 0.0265s/iter; left time: 569.1363s
Epoch: 10 cost time: 6.807368516921997
Epoch: 10, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5385 + XiCon Loss:2.5632 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8486
Validation loss decreased (1.004408 --> 1.004348).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5225056
	speed: 0.0280s/iter; left time: 597.6244s
	iters: 200, epoch: 11 | loss: 0.5834516
	speed: 0.0233s/iter; left time: 495.3354s
Epoch: 11 cost time: 6.181170463562012
Epoch: 11, Steps: 238 Train Loss: 0.5638 (Forecasting Loss:0.5382 + XiCon Loss:2.5580 x Lambda(0.01)), Vali MSE Loss: 1.0036 Test MSE Loss: 0.8486
Validation loss decreased (1.004348 --> 1.003571).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5832257
	speed: 0.0323s/iter; left time: 682.0333s
	iters: 200, epoch: 12 | loss: 0.5337923
	speed: 0.0282s/iter; left time: 590.8242s
Epoch: 12 cost time: 7.14976954460144
Epoch: 12, Steps: 238 Train Loss: 0.5638 (Forecasting Loss:0.5382 + XiCon Loss:2.5598 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5667265
	speed: 0.0284s/iter; left time: 592.1940s
	iters: 200, epoch: 13 | loss: 0.5566377
	speed: 0.0293s/iter; left time: 606.8805s
Epoch: 13 cost time: 6.905438184738159
Epoch: 13, Steps: 238 Train Loss: 0.5639 (Forecasting Loss:0.5383 + XiCon Loss:2.5591 x Lambda(0.01)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8485
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4771017
	speed: 0.0323s/iter; left time: 666.5750s
	iters: 200, epoch: 14 | loss: 0.5599898
	speed: 0.0279s/iter; left time: 571.6292s
Epoch: 14 cost time: 7.0262908935546875
Epoch: 14, Steps: 238 Train Loss: 0.5637 (Forecasting Loss:0.5381 + XiCon Loss:2.5561 x Lambda(0.01)), Vali MSE Loss: 1.0042 Test MSE Loss: 0.8485
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5657310
	speed: 0.0325s/iter; left time: 662.0957s
	iters: 200, epoch: 15 | loss: 0.5656785
	speed: 0.0266s/iter; left time: 538.7976s
Epoch: 15 cost time: 7.022234201431274
Epoch: 15, Steps: 238 Train Loss: 0.5637 (Forecasting Loss:0.5382 + XiCon Loss:2.5528 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5267640
	speed: 0.0305s/iter; left time: 613.2136s
	iters: 200, epoch: 16 | loss: 0.5569471
	speed: 0.0263s/iter; left time: 527.5881s
Epoch: 16 cost time: 6.7632458209991455
Epoch: 16, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5385 + XiCon Loss:2.5551 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8485
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5562027
	speed: 0.0287s/iter; left time: 571.2608s
	iters: 200, epoch: 17 | loss: 0.5633096
	speed: 0.0294s/iter; left time: 581.0527s
Epoch: 17 cost time: 6.889521598815918
Epoch: 17, Steps: 238 Train Loss: 0.5636 (Forecasting Loss:0.5380 + XiCon Loss:2.5632 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8485
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5287322
	speed: 0.0320s/iter; left time: 628.0191s
	iters: 200, epoch: 18 | loss: 0.4987301
	speed: 0.0292s/iter; left time: 571.1538s
Epoch: 18 cost time: 7.222037315368652
Epoch: 18, Steps: 238 Train Loss: 0.5638 (Forecasting Loss:0.5382 + XiCon Loss:2.5575 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5667396
	speed: 0.0319s/iter; left time: 619.3861s
	iters: 200, epoch: 19 | loss: 0.5588559
	speed: 0.0287s/iter; left time: 554.9934s
Epoch: 19 cost time: 7.103241920471191
Epoch: 19, Steps: 238 Train Loss: 0.5639 (Forecasting Loss:0.5384 + XiCon Loss:2.5573 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5420576
	speed: 0.0314s/iter; left time: 602.8869s
	iters: 200, epoch: 20 | loss: 0.5740140
	speed: 0.0261s/iter; left time: 498.1061s
Epoch: 20 cost time: 6.959670066833496
Epoch: 20, Steps: 238 Train Loss: 0.5637 (Forecasting Loss:0.5381 + XiCon Loss:2.5623 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5188389
	speed: 0.0294s/iter; left time: 557.2671s
	iters: 200, epoch: 21 | loss: 0.5752149
	speed: 0.0292s/iter; left time: 549.5766s
Epoch: 21 cost time: 6.965333938598633
Epoch: 21, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5384 + XiCon Loss:2.5590 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9777277112007141, mae:0.7193755507469177, mape:4.778810501098633, mspe:2691.455322265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.9225
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1103225
	speed: 0.0303s/iter; left time: 717.4121s
	iters: 200, epoch: 1 | loss: 1.1841800
	speed: 0.0298s/iter; left time: 702.3301s
Epoch: 1 cost time: 7.141093969345093
Epoch: 1, Steps: 238 Train Loss: 1.1248 (Forecasting Loss:1.0993 + XiCon Loss:2.5557 x Lambda(0.01)), Vali MSE Loss: 1.9677 Test MSE Loss: 1.0361
Validation loss decreased (inf --> 1.967725).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6511839
	speed: 0.0332s/iter; left time: 778.1474s
	iters: 200, epoch: 2 | loss: 0.5669563
	speed: 0.0287s/iter; left time: 671.4358s
Epoch: 2 cost time: 7.22633171081543
Epoch: 2, Steps: 238 Train Loss: 0.6568 (Forecasting Loss:0.6313 + XiCon Loss:2.5496 x Lambda(0.01)), Vali MSE Loss: 1.0219 Test MSE Loss: 0.8588
Validation loss decreased (1.967725 --> 1.021883).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5670763
	speed: 0.0326s/iter; left time: 757.7349s
	iters: 200, epoch: 3 | loss: 0.5500051
	speed: 0.0270s/iter; left time: 625.3446s
Epoch: 3 cost time: 7.102035760879517
Epoch: 3, Steps: 238 Train Loss: 0.5771 (Forecasting Loss:0.5516 + XiCon Loss:2.5453 x Lambda(0.01)), Vali MSE Loss: 1.0006 Test MSE Loss: 0.8528
Validation loss decreased (1.021883 --> 1.000556).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5022925
	speed: 0.0301s/iter; left time: 692.3458s
	iters: 200, epoch: 4 | loss: 0.5866126
	speed: 0.0290s/iter; left time: 663.4480s
Epoch: 4 cost time: 7.043919801712036
Epoch: 4, Steps: 238 Train Loss: 0.5687 (Forecasting Loss:0.5432 + XiCon Loss:2.5458 x Lambda(0.01)), Vali MSE Loss: 0.9941 Test MSE Loss: 0.8515
Validation loss decreased (1.000556 --> 0.994079).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5923939
	speed: 0.0307s/iter; left time: 699.1926s
	iters: 200, epoch: 5 | loss: 0.5498903
	speed: 0.0298s/iter; left time: 675.7486s
Epoch: 5 cost time: 7.140493392944336
Epoch: 5, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5399 + XiCon Loss:2.5410 x Lambda(0.01)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8508
Validation loss decreased (0.994079 --> 0.989113).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5414957
	speed: 0.0334s/iter; left time: 751.1708s
	iters: 200, epoch: 6 | loss: 0.5744497
	speed: 0.0290s/iter; left time: 650.1748s
Epoch: 6 cost time: 7.276601791381836
Epoch: 6, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5387 + XiCon Loss:2.5440 x Lambda(0.01)), Vali MSE Loss: 0.9880 Test MSE Loss: 0.8507
Validation loss decreased (0.989113 --> 0.988033).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5651720
	speed: 0.0308s/iter; left time: 686.5696s
	iters: 200, epoch: 7 | loss: 0.5350778
	speed: 0.0285s/iter; left time: 632.9335s
Epoch: 7 cost time: 7.065718650817871
Epoch: 7, Steps: 238 Train Loss: 0.5631 (Forecasting Loss:0.5377 + XiCon Loss:2.5403 x Lambda(0.01)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8505
Validation loss decreased (0.988033 --> 0.987057).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5700595
	speed: 0.0306s/iter; left time: 673.1968s
	iters: 200, epoch: 8 | loss: 0.5304078
	speed: 0.0300s/iter; left time: 658.2592s
Epoch: 8 cost time: 7.218061447143555
Epoch: 8, Steps: 238 Train Loss: 0.5630 (Forecasting Loss:0.5376 + XiCon Loss:2.5406 x Lambda(0.01)), Vali MSE Loss: 0.9870 Test MSE Loss: 0.8505
Validation loss decreased (0.987057 --> 0.986959).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5488204
	speed: 0.0314s/iter; left time: 685.0450s
	iters: 200, epoch: 9 | loss: 0.6005069
	speed: 0.0288s/iter; left time: 624.9112s
Epoch: 9 cost time: 7.034647464752197
Epoch: 9, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5372 + XiCon Loss:2.5423 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
Validation loss decreased (0.986959 --> 0.985942).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5592034
	speed: 0.0330s/iter; left time: 711.9789s
	iters: 200, epoch: 10 | loss: 0.6277286
	speed: 0.0267s/iter; left time: 572.9816s
Epoch: 10 cost time: 7.075973749160767
Epoch: 10, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5401 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985942 --> 0.985581).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5665084
	speed: 0.0311s/iter; left time: 663.2212s
	iters: 200, epoch: 11 | loss: 0.5979749
	speed: 0.0293s/iter; left time: 621.2066s
Epoch: 11 cost time: 7.191421270370483
Epoch: 11, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5396 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5708566
	speed: 0.0316s/iter; left time: 666.7122s
	iters: 200, epoch: 12 | loss: 0.5230694
	speed: 0.0305s/iter; left time: 640.3024s
Epoch: 12 cost time: 7.355090141296387
Epoch: 12, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5386 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5374801
	speed: 0.0332s/iter; left time: 691.6077s
	iters: 200, epoch: 13 | loss: 0.5585815
	speed: 0.0284s/iter; left time: 589.7324s
Epoch: 13 cost time: 7.204720735549927
Epoch: 13, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5431 x Lambda(0.01)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5096666
	speed: 0.0315s/iter; left time: 648.2007s
	iters: 200, epoch: 14 | loss: 0.5493089
	speed: 0.0282s/iter; left time: 577.9899s
Epoch: 14 cost time: 7.102451801300049
Epoch: 14, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5454 x Lambda(0.01)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5542651
	speed: 0.0299s/iter; left time: 609.2822s
	iters: 200, epoch: 15 | loss: 0.4887519
	speed: 0.0297s/iter; left time: 601.3311s
Epoch: 15 cost time: 7.079505443572998
Epoch: 15, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5368 + XiCon Loss:2.5432 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5901549
	speed: 0.0319s/iter; left time: 642.5656s
	iters: 200, epoch: 16 | loss: 0.5844690
	speed: 0.0293s/iter; left time: 587.2889s
Epoch: 16 cost time: 7.183812379837036
Epoch: 16, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5433 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5431513
	speed: 0.0334s/iter; left time: 664.3347s
	iters: 200, epoch: 17 | loss: 0.5933193
	speed: 0.0271s/iter; left time: 535.7208s
Epoch: 17 cost time: 7.195274829864502
Epoch: 17, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5371 + XiCon Loss:2.5369 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5822646
	speed: 0.0311s/iter; left time: 611.4916s
	iters: 200, epoch: 18 | loss: 0.6585995
	speed: 0.0288s/iter; left time: 562.5202s
Epoch: 18 cost time: 7.224267482757568
Epoch: 18, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5372 + XiCon Loss:2.5391 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5575020
	speed: 0.0301s/iter; left time: 584.2940s
	iters: 200, epoch: 19 | loss: 0.5601079
	speed: 0.0304s/iter; left time: 587.3503s
Epoch: 19 cost time: 7.13359808921814
Epoch: 19, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5454 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5710634
	speed: 0.0323s/iter; left time: 620.1106s
	iters: 200, epoch: 20 | loss: 0.5792785
	speed: 0.0286s/iter; left time: 546.3986s
Epoch: 20 cost time: 7.134704113006592
Epoch: 20, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5416 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985581 --> 0.985550).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5189121
	speed: 0.0340s/iter; left time: 644.4773s
	iters: 200, epoch: 21 | loss: 0.5338954
	speed: 0.0280s/iter; left time: 526.8573s
Epoch: 21 cost time: 7.321304798126221
Epoch: 21, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5419 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5350782
	speed: 0.0297s/iter; left time: 555.7343s
	iters: 200, epoch: 22 | loss: 0.5587240
	speed: 0.0302s/iter; left time: 561.4011s
Epoch: 22 cost time: 7.12429141998291
Epoch: 22, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5369 + XiCon Loss:2.5437 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5522991
	speed: 0.0321s/iter; left time: 591.9360s
	iters: 200, epoch: 23 | loss: 0.5368876
	speed: 0.0292s/iter; left time: 535.7453s
Epoch: 23 cost time: 7.178972005844116
Epoch: 23, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5371 + XiCon Loss:2.5394 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5759517
	speed: 0.0321s/iter; left time: 585.2836s
	iters: 200, epoch: 24 | loss: 0.5533935
	speed: 0.0278s/iter; left time: 503.4331s
Epoch: 24 cost time: 7.037745952606201
Epoch: 24, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5385 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5592802
	speed: 0.0316s/iter; left time: 568.3752s
	iters: 200, epoch: 25 | loss: 0.5698251
	speed: 0.0288s/iter; left time: 515.3339s
Epoch: 25 cost time: 7.178860902786255
Epoch: 25, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5443 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5819834
	speed: 0.0300s/iter; left time: 532.1621s
	iters: 200, epoch: 26 | loss: 0.5402268
	speed: 0.0298s/iter; left time: 525.1552s
Epoch: 26 cost time: 7.1013407707214355
Epoch: 26, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5407 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6058344
	speed: 0.0310s/iter; left time: 543.1222s
	iters: 200, epoch: 27 | loss: 0.6014017
	speed: 0.0299s/iter; left time: 520.2522s
Epoch: 27 cost time: 7.164218425750732
Epoch: 27, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5371 + XiCon Loss:2.5415 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5378551
	speed: 0.0324s/iter; left time: 559.1072s
	iters: 200, epoch: 28 | loss: 0.5353101
	speed: 0.0289s/iter; left time: 496.7327s
Epoch: 28 cost time: 7.204318523406982
Epoch: 28, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5406 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4905787
	speed: 0.0311s/iter; left time: 529.4763s
	iters: 200, epoch: 29 | loss: 0.5547163
	speed: 0.0298s/iter; left time: 504.4376s
Epoch: 29 cost time: 7.24568510055542
Epoch: 29, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5368 + XiCon Loss:2.5393 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5052062
	speed: 0.0300s/iter; left time: 503.5183s
	iters: 200, epoch: 30 | loss: 0.5733696
	speed: 0.0291s/iter; left time: 485.5372s
Epoch: 30 cost time: 7.022220134735107
Epoch: 30, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5397 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985550 --> 0.985466).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5611588
	speed: 0.0323s/iter; left time: 534.7857s
	iters: 200, epoch: 31 | loss: 0.5192951
	speed: 0.0290s/iter; left time: 476.6311s
Epoch: 31 cost time: 7.1147401332855225
Epoch: 31, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5416 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5809916
	speed: 0.0343s/iter; left time: 559.3682s
	iters: 200, epoch: 32 | loss: 0.6061977
	speed: 0.0277s/iter; left time: 448.6935s
Epoch: 32 cost time: 7.3339903354644775
Epoch: 32, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5400 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5494724
	speed: 0.0314s/iter; left time: 504.3583s
	iters: 200, epoch: 33 | loss: 0.5419744
	speed: 0.0290s/iter; left time: 463.0977s
Epoch: 33 cost time: 7.143040895462036
Epoch: 33, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5353 x Lambda(0.01)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8504
Validation loss decreased (0.985466 --> 0.985427).  Saving model ...
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5396038
	speed: 0.0313s/iter; left time: 495.8588s
	iters: 200, epoch: 34 | loss: 0.5412514
	speed: 0.0299s/iter; left time: 470.5993s
Epoch: 34 cost time: 7.248367071151733
Epoch: 34, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5376 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5475374
	speed: 0.0332s/iter; left time: 518.7313s
	iters: 200, epoch: 35 | loss: 0.5995361
	speed: 0.0291s/iter; left time: 451.3598s
Epoch: 35 cost time: 7.276485204696655
Epoch: 35, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5420 x Lambda(0.01)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5351017
	speed: 0.0325s/iter; left time: 499.4591s
	iters: 200, epoch: 36 | loss: 0.5477428
	speed: 0.0279s/iter; left time: 425.3190s
Epoch: 36 cost time: 7.169290542602539
Epoch: 36, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5368 + XiCon Loss:2.5443 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5174819
	speed: 0.0294s/iter; left time: 444.7684s
	iters: 200, epoch: 37 | loss: 0.6168357
	speed: 0.0299s/iter; left time: 449.9102s
Epoch: 37 cost time: 7.124683618545532
Epoch: 37, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5406 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5926049
	speed: 0.0326s/iter; left time: 485.6586s
	iters: 200, epoch: 38 | loss: 0.5945521
	speed: 0.0296s/iter; left time: 438.1283s
Epoch: 38 cost time: 7.248733997344971
Epoch: 38, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5367 + XiCon Loss:2.5421 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5613988
	speed: 0.0336s/iter; left time: 492.7599s
	iters: 200, epoch: 39 | loss: 0.5943244
	speed: 0.0279s/iter; left time: 406.5663s
Epoch: 39 cost time: 7.317128658294678
Epoch: 39, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5368 + XiCon Loss:2.5449 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.5962180
	speed: 0.0316s/iter; left time: 456.0986s
	iters: 200, epoch: 40 | loss: 0.5882842
	speed: 0.0298s/iter; left time: 426.6993s
Epoch: 40 cost time: 7.317084312438965
Epoch: 40, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5436 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.6039783
	speed: 0.0315s/iter; left time: 446.8741s
	iters: 200, epoch: 41 | loss: 0.5367386
	speed: 0.0301s/iter; left time: 423.5324s
Epoch: 41 cost time: 7.267686367034912
Epoch: 41, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5424 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.5467386
	speed: 0.0340s/iter; left time: 474.4851s
	iters: 200, epoch: 42 | loss: 0.5615348
	speed: 0.0287s/iter; left time: 396.9953s
Epoch: 42 cost time: 7.410160541534424
Epoch: 42, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5369 + XiCon Loss:2.5424 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.5772917
	speed: 0.0336s/iter; left time: 460.4595s
	iters: 200, epoch: 43 | loss: 0.5697950
	speed: 0.0294s/iter; left time: 400.5754s
Epoch: 43 cost time: 7.57281494140625
Epoch: 43, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5370 + XiCon Loss:2.5407 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9793246388435364, mae:0.7214687466621399, mape:4.789201736450195, mspe:2695.4228515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8699
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1409380
	speed: 0.0333s/iter; left time: 788.2402s
	iters: 200, epoch: 1 | loss: 1.0555220
	speed: 0.0287s/iter; left time: 678.2230s
Epoch: 1 cost time: 7.359132528305054
Epoch: 1, Steps: 238 Train Loss: 1.1226 (Forecasting Loss:1.0971 + XiCon Loss:2.5568 x Lambda(0.01)), Vali MSE Loss: 1.9328 Test MSE Loss: 1.0252
Validation loss decreased (inf --> 1.932776).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6219376
	speed: 0.0319s/iter; left time: 748.4761s
	iters: 200, epoch: 2 | loss: 0.6011521
	speed: 0.0295s/iter; left time: 690.1175s
Epoch: 2 cost time: 7.216782808303833
Epoch: 2, Steps: 238 Train Loss: 0.6490 (Forecasting Loss:0.6235 + XiCon Loss:2.5528 x Lambda(0.01)), Vali MSE Loss: 1.0344 Test MSE Loss: 0.8764
Validation loss decreased (1.932776 --> 1.034353).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5467837
	speed: 0.0325s/iter; left time: 753.7155s
	iters: 200, epoch: 3 | loss: 0.6277690
	speed: 0.0300s/iter; left time: 692.7765s
Epoch: 3 cost time: 7.338923215866089
Epoch: 3, Steps: 238 Train Loss: 0.5779 (Forecasting Loss:0.5523 + XiCon Loss:2.5549 x Lambda(0.01)), Vali MSE Loss: 1.0101 Test MSE Loss: 0.8681
Validation loss decreased (1.034353 --> 1.010064).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5526540
	speed: 0.0327s/iter; left time: 751.9015s
	iters: 200, epoch: 4 | loss: 0.6243100
	speed: 0.0285s/iter; left time: 652.9092s
Epoch: 4 cost time: 7.269510269165039
Epoch: 4, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5435 + XiCon Loss:2.5614 x Lambda(0.01)), Vali MSE Loss: 1.0028 Test MSE Loss: 0.8657
Validation loss decreased (1.010064 --> 1.002818).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5602770
	speed: 0.0314s/iter; left time: 714.4739s
	iters: 200, epoch: 5 | loss: 0.5957751
	speed: 0.0281s/iter; left time: 637.2358s
Epoch: 5 cost time: 7.118056774139404
Epoch: 5, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5400 + XiCon Loss:2.5540 x Lambda(0.01)), Vali MSE Loss: 0.9986 Test MSE Loss: 0.8647
Validation loss decreased (1.002818 --> 0.998576).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5849993
	speed: 0.0326s/iter; left time: 733.0908s
	iters: 200, epoch: 6 | loss: 0.5293891
	speed: 0.0298s/iter; left time: 667.0542s
Epoch: 6 cost time: 7.4360949993133545
Epoch: 6, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5384 + XiCon Loss:2.5581 x Lambda(0.01)), Vali MSE Loss: 0.9977 Test MSE Loss: 0.8649
Validation loss decreased (0.998576 --> 0.997698).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5629146
	speed: 0.0324s/iter; left time: 722.3340s
	iters: 200, epoch: 7 | loss: 0.5912035
	speed: 0.0286s/iter; left time: 633.6078s
Epoch: 7 cost time: 7.147073984146118
Epoch: 7, Steps: 238 Train Loss: 0.5630 (Forecasting Loss:0.5375 + XiCon Loss:2.5504 x Lambda(0.01)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8646
Validation loss decreased (0.997698 --> 0.996984).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5623029
	speed: 0.0327s/iter; left time: 720.2873s
	iters: 200, epoch: 8 | loss: 0.5338421
	speed: 0.0285s/iter; left time: 625.9590s
Epoch: 8 cost time: 7.220592021942139
Epoch: 8, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5371 + XiCon Loss:2.5550 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
Validation loss decreased (0.996984 --> 0.996197).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5882474
	speed: 0.0306s/iter; left time: 667.4637s
	iters: 200, epoch: 9 | loss: 0.5515161
	speed: 0.0283s/iter; left time: 613.3129s
Epoch: 9 cost time: 7.002916574478149
Epoch: 9, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5369 + XiCon Loss:2.5528 x Lambda(0.01)), Vali MSE Loss: 0.9969 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5626093
	speed: 0.0313s/iter; left time: 674.1228s
	iters: 200, epoch: 10 | loss: 0.5618135
	speed: 0.0285s/iter; left time: 611.9682s
Epoch: 10 cost time: 7.106295824050903
Epoch: 10, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5365 + XiCon Loss:2.5564 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
Validation loss decreased (0.996197 --> 0.995978).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5601699
	speed: 0.0316s/iter; left time: 674.4797s
	iters: 200, epoch: 11 | loss: 0.5293154
	speed: 0.0289s/iter; left time: 612.2797s
Epoch: 11 cost time: 7.444321870803833
Epoch: 11, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5368 + XiCon Loss:2.5567 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5474035
	speed: 0.0303s/iter; left time: 639.5261s
	iters: 200, epoch: 12 | loss: 0.5470907
	speed: 0.0294s/iter; left time: 616.8421s
Epoch: 12 cost time: 7.080794334411621
Epoch: 12, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5368 + XiCon Loss:2.5528 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5301517
	speed: 0.0320s/iter; left time: 666.8020s
	iters: 200, epoch: 13 | loss: 0.5108997
	speed: 0.0291s/iter; left time: 604.5422s
Epoch: 13 cost time: 7.328976631164551
Epoch: 13, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5368 + XiCon Loss:2.5558 x Lambda(0.01)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
Validation loss decreased (0.995978 --> 0.995914).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5866765
	speed: 0.0322s/iter; left time: 663.3834s
	iters: 200, epoch: 14 | loss: 0.6535605
	speed: 0.0292s/iter; left time: 599.6164s
Epoch: 14 cost time: 7.239543676376343
Epoch: 14, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5366 + XiCon Loss:2.5568 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5369350
	speed: 0.0311s/iter; left time: 633.9487s
	iters: 200, epoch: 15 | loss: 0.5422547
	speed: 0.0335s/iter; left time: 678.8135s
Epoch: 15 cost time: 7.6613874435424805
Epoch: 15, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5366 + XiCon Loss:2.5621 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995914 --> 0.995525).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5862564
	speed: 0.0327s/iter; left time: 658.8058s
	iters: 200, epoch: 16 | loss: 0.5344629
	speed: 0.0291s/iter; left time: 583.5089s
Epoch: 16 cost time: 7.323688507080078
Epoch: 16, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5594 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995525 --> 0.995514).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5301241
	speed: 0.0320s/iter; left time: 636.0009s
	iters: 200, epoch: 17 | loss: 0.5838503
	speed: 0.0286s/iter; left time: 566.1447s
Epoch: 17 cost time: 7.173206090927124
Epoch: 17, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5368 + XiCon Loss:2.5572 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5586641
	speed: 0.0322s/iter; left time: 631.9281s
	iters: 200, epoch: 18 | loss: 0.5403053
	speed: 0.0305s/iter; left time: 595.8069s
Epoch: 18 cost time: 7.431241512298584
Epoch: 18, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5591 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5562510
	speed: 0.0344s/iter; left time: 667.8396s
	iters: 200, epoch: 19 | loss: 0.5617462
	speed: 0.0304s/iter; left time: 587.1628s
Epoch: 19 cost time: 7.601101875305176
Epoch: 19, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5579 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995514 --> 0.995508).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5379663
	speed: 0.0320s/iter; left time: 614.6288s
	iters: 200, epoch: 20 | loss: 0.5709992
	speed: 0.0296s/iter; left time: 564.2228s
Epoch: 20 cost time: 7.253284692764282
Epoch: 20, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5366 + XiCon Loss:2.5579 x Lambda(0.01)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5781367
	speed: 0.0321s/iter; left time: 608.1828s
	iters: 200, epoch: 21 | loss: 0.5502198
	speed: 0.0300s/iter; left time: 565.9827s
Epoch: 21 cost time: 7.307923078536987
Epoch: 21, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5549 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5139838
	speed: 0.0320s/iter; left time: 598.3966s
	iters: 200, epoch: 22 | loss: 0.5558109
	speed: 0.0284s/iter; left time: 527.4612s
Epoch: 22 cost time: 7.126291751861572
Epoch: 22, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5365 + XiCon Loss:2.5612 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5863588
	speed: 0.0328s/iter; left time: 605.0524s
	iters: 200, epoch: 23 | loss: 0.5894856
	speed: 0.0294s/iter; left time: 539.7581s
Epoch: 23 cost time: 7.306256294250488
Epoch: 23, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5584 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5311999
	speed: 0.0313s/iter; left time: 570.8363s
	iters: 200, epoch: 24 | loss: 0.5789980
	speed: 0.0305s/iter; left time: 552.0635s
Epoch: 24 cost time: 7.314860820770264
Epoch: 24, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5596 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5935912
	speed: 0.0323s/iter; left time: 580.6852s
	iters: 200, epoch: 25 | loss: 0.5787386
	speed: 0.0292s/iter; left time: 521.5296s
Epoch: 25 cost time: 7.217353820800781
Epoch: 25, Steps: 238 Train Loss: 0.5620 (Forecasting Loss:0.5364 + XiCon Loss:2.5613 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5543499
	speed: 0.0320s/iter; left time: 568.7337s
	iters: 200, epoch: 26 | loss: 0.6037688
	speed: 0.0279s/iter; left time: 492.3219s
Epoch: 26 cost time: 7.079150676727295
Epoch: 26, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5570 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5802852
	speed: 0.0307s/iter; left time: 537.4791s
	iters: 200, epoch: 27 | loss: 0.5662051
	speed: 0.0314s/iter; left time: 547.1624s
Epoch: 27 cost time: 7.308202266693115
Epoch: 27, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5367 + XiCon Loss:2.5520 x Lambda(0.01)), Vali MSE Loss: 0.9950 Test MSE Loss: 0.8645
Validation loss decreased (0.995508 --> 0.995036).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5866345
	speed: 0.0325s/iter; left time: 561.1506s
	iters: 200, epoch: 28 | loss: 0.5504546
	speed: 0.0300s/iter; left time: 515.0003s
Epoch: 28 cost time: 7.350266695022583
Epoch: 28, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5366 + XiCon Loss:2.5599 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5885840
	speed: 0.0332s/iter; left time: 565.8913s
	iters: 200, epoch: 29 | loss: 0.5652145
	speed: 0.0287s/iter; left time: 486.2232s
Epoch: 29 cost time: 7.3633058071136475
Epoch: 29, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5367 + XiCon Loss:2.5528 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5947668
	speed: 0.0322s/iter; left time: 541.4940s
	iters: 200, epoch: 30 | loss: 0.5636737
	speed: 0.0294s/iter; left time: 491.1759s
Epoch: 30 cost time: 7.33948540687561
Epoch: 30, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5600 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5575436
	speed: 0.0323s/iter; left time: 534.9025s
	iters: 200, epoch: 31 | loss: 0.5604056
	speed: 0.0300s/iter; left time: 493.3253s
Epoch: 31 cost time: 7.377568244934082
Epoch: 31, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5366 + XiCon Loss:2.5563 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5757605
	speed: 0.0327s/iter; left time: 533.2765s
	iters: 200, epoch: 32 | loss: 0.5354810
	speed: 0.0280s/iter; left time: 454.5947s
Epoch: 32 cost time: 7.150304794311523
Epoch: 32, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5616 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6229867
	speed: 0.0322s/iter; left time: 517.7950s
	iters: 200, epoch: 33 | loss: 0.5541443
	speed: 0.0304s/iter; left time: 485.9134s
Epoch: 33 cost time: 7.381852865219116
Epoch: 33, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5570 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5292999
	speed: 0.0325s/iter; left time: 515.1578s
	iters: 200, epoch: 34 | loss: 0.5935130
	speed: 0.0283s/iter; left time: 445.6381s
Epoch: 34 cost time: 7.207085609436035
Epoch: 34, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5524 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5878019
	speed: 0.0336s/iter; left time: 525.1398s
	iters: 200, epoch: 35 | loss: 0.5420958
	speed: 0.0290s/iter; left time: 449.2774s
Epoch: 35 cost time: 7.47357964515686
Epoch: 35, Steps: 238 Train Loss: 0.5621 (Forecasting Loss:0.5366 + XiCon Loss:2.5525 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5091074
	speed: 0.0313s/iter; left time: 480.6454s
	iters: 200, epoch: 36 | loss: 0.5533946
	speed: 0.0298s/iter; left time: 454.3463s
Epoch: 36 cost time: 7.1846373081207275
Epoch: 36, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5584 x Lambda(0.01)), Vali MSE Loss: 0.9967 Test MSE Loss: 0.8645
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5244303
	speed: 0.0322s/iter; left time: 486.8227s
	iters: 200, epoch: 37 | loss: 0.5683904
	speed: 0.0287s/iter; left time: 431.4085s
Epoch: 37 cost time: 7.219513416290283
Epoch: 37, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5568 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9971219897270203, mae:0.7319390773773193, mape:5.079910755157471, mspe:3079.962890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.9388
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0921233
	speed: 0.0343s/iter; left time: 814.0423s
	iters: 200, epoch: 1 | loss: 1.1195551
	speed: 0.0310s/iter; left time: 732.3162s
Epoch: 1 cost time: 7.767319202423096
Epoch: 1, Steps: 238 Train Loss: 1.2219 (Forecasting Loss:1.1962 + XiCon Loss:2.5655 x Lambda(0.01)), Vali MSE Loss: 2.1664 Test MSE Loss: 1.1068
Validation loss decreased (inf --> 2.166445).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7998650
	speed: 0.0347s/iter; left time: 813.5378s
	iters: 200, epoch: 2 | loss: 0.5953333
	speed: 0.0322s/iter; left time: 752.7308s
Epoch: 2 cost time: 7.88703179359436
Epoch: 2, Steps: 238 Train Loss: 0.7539 (Forecasting Loss:0.7283 + XiCon Loss:2.5613 x Lambda(0.01)), Vali MSE Loss: 1.0373 Test MSE Loss: 0.8756
Validation loss decreased (2.166445 --> 1.037332).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6228834
	speed: 0.0359s/iter; left time: 833.6346s
	iters: 200, epoch: 3 | loss: 0.6099987
	speed: 0.0309s/iter; left time: 714.9549s
Epoch: 3 cost time: 7.935995101928711
Epoch: 3, Steps: 238 Train Loss: 0.5862 (Forecasting Loss:0.5606 + XiCon Loss:2.5606 x Lambda(0.01)), Vali MSE Loss: 1.0330 Test MSE Loss: 0.8586
Validation loss decreased (1.037332 --> 1.033033).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5930693
	speed: 0.0348s/iter; left time: 799.9909s
	iters: 200, epoch: 4 | loss: 0.5961155
	speed: 0.0316s/iter; left time: 723.3508s
Epoch: 4 cost time: 7.8667614459991455
Epoch: 4, Steps: 238 Train Loss: 0.5737 (Forecasting Loss:0.5480 + XiCon Loss:2.5685 x Lambda(0.01)), Vali MSE Loss: 1.0257 Test MSE Loss: 0.8553
Validation loss decreased (1.033033 --> 1.025670).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5548435
	speed: 0.0354s/iter; left time: 804.4795s
	iters: 200, epoch: 5 | loss: 0.5351265
	speed: 0.0301s/iter; left time: 682.4939s
Epoch: 5 cost time: 7.717225551605225
Epoch: 5, Steps: 238 Train Loss: 0.5704 (Forecasting Loss:0.5447 + XiCon Loss:2.5684 x Lambda(0.01)), Vali MSE Loss: 1.0208 Test MSE Loss: 0.8542
Validation loss decreased (1.025670 --> 1.020786).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5725807
	speed: 0.0353s/iter; left time: 795.7632s
	iters: 200, epoch: 6 | loss: 0.5497944
	speed: 0.0321s/iter; left time: 719.0716s
Epoch: 6 cost time: 7.996986150741577
Epoch: 6, Steps: 238 Train Loss: 0.5687 (Forecasting Loss:0.5431 + XiCon Loss:2.5663 x Lambda(0.01)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8539
Validation loss decreased (1.020786 --> 1.020279).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5983221
	speed: 0.0346s/iter; left time: 770.3974s
	iters: 200, epoch: 7 | loss: 0.5147746
	speed: 0.0354s/iter; left time: 783.9491s
Epoch: 7 cost time: 8.13027310371399
Epoch: 7, Steps: 238 Train Loss: 0.5676 (Forecasting Loss:0.5419 + XiCon Loss:2.5636 x Lambda(0.01)), Vali MSE Loss: 1.0209 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5829757
	speed: 0.0334s/iter; left time: 736.2085s
	iters: 200, epoch: 8 | loss: 0.6395013
	speed: 0.0309s/iter; left time: 678.5157s
Epoch: 8 cost time: 7.629896879196167
Epoch: 8, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5417 + XiCon Loss:2.5712 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8536
Validation loss decreased (1.020279 --> 1.019085).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5767280
	speed: 0.0343s/iter; left time: 748.2432s
	iters: 200, epoch: 9 | loss: 0.5600654
	speed: 0.0331s/iter; left time: 717.9559s
Epoch: 9 cost time: 7.953160524368286
Epoch: 9, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5415 + XiCon Loss:2.5670 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5800449
	speed: 0.0345s/iter; left time: 743.9486s
	iters: 200, epoch: 10 | loss: 0.5889745
	speed: 0.0302s/iter; left time: 648.8471s
Epoch: 10 cost time: 7.632215738296509
Epoch: 10, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5415 + XiCon Loss:2.5700 x Lambda(0.01)), Vali MSE Loss: 1.0197 Test MSE Loss: 0.8536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5448443
	speed: 0.0348s/iter; left time: 743.0000s
	iters: 200, epoch: 11 | loss: 0.5421777
	speed: 0.0303s/iter; left time: 643.3939s
Epoch: 11 cost time: 7.723766088485718
Epoch: 11, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5414 + XiCon Loss:2.5631 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019085 --> 1.019023).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5554793
	speed: 0.0358s/iter; left time: 754.8671s
	iters: 200, epoch: 12 | loss: 0.5479266
	speed: 0.0319s/iter; left time: 669.7996s
Epoch: 12 cost time: 7.963245630264282
Epoch: 12, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5412 + XiCon Loss:2.5635 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019023 --> 1.019002).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5514563
	speed: 0.0336s/iter; left time: 699.9403s
	iters: 200, epoch: 13 | loss: 0.6266088
	speed: 0.0307s/iter; left time: 636.8001s
Epoch: 13 cost time: 7.613725423812866
Epoch: 13, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5414 + XiCon Loss:2.5635 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6242579
	speed: 0.0341s/iter; left time: 703.5940s
	iters: 200, epoch: 14 | loss: 0.5770897
	speed: 0.0314s/iter; left time: 644.0153s
Epoch: 14 cost time: 7.731820106506348
Epoch: 14, Steps: 238 Train Loss: 0.5667 (Forecasting Loss:0.5411 + XiCon Loss:2.5662 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5590430
	speed: 0.0344s/iter; left time: 700.0475s
	iters: 200, epoch: 15 | loss: 0.5859486
	speed: 0.0319s/iter; left time: 645.9750s
Epoch: 15 cost time: 7.830142498016357
Epoch: 15, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5414 + XiCon Loss:2.5626 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5564004
	speed: 0.0348s/iter; left time: 701.4639s
	iters: 200, epoch: 16 | loss: 0.5465816
	speed: 0.0320s/iter; left time: 640.2862s
Epoch: 16 cost time: 7.938720226287842
Epoch: 16, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5414 + XiCon Loss:2.5657 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
Validation loss decreased (1.019002 --> 1.018896).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5623159
	speed: 0.0351s/iter; left time: 698.8071s
	iters: 200, epoch: 17 | loss: 0.5589539
	speed: 0.0319s/iter; left time: 630.4865s
Epoch: 17 cost time: 7.85730504989624
Epoch: 17, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5412 + XiCon Loss:2.5636 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5481184
	speed: 0.0348s/iter; left time: 684.6119s
	iters: 200, epoch: 18 | loss: 0.6173295
	speed: 0.0306s/iter; left time: 598.1656s
Epoch: 18 cost time: 7.732031583786011
Epoch: 18, Steps: 238 Train Loss: 0.5663 (Forecasting Loss:0.5407 + XiCon Loss:2.5647 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6280461
	speed: 0.0337s/iter; left time: 653.8254s
	iters: 200, epoch: 19 | loss: 0.6024528
	speed: 0.0317s/iter; left time: 612.8932s
Epoch: 19 cost time: 7.738089084625244
Epoch: 19, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5411 + XiCon Loss:2.5672 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6048283
	speed: 0.0343s/iter; left time: 657.7166s
	iters: 200, epoch: 20 | loss: 0.5934901
	speed: 0.0315s/iter; left time: 600.1459s
Epoch: 20 cost time: 7.749107122421265
Epoch: 20, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5413 + XiCon Loss:2.5672 x Lambda(0.01)), Vali MSE Loss: 1.0201 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6189837
	speed: 0.0341s/iter; left time: 646.8177s
	iters: 200, epoch: 21 | loss: 0.5249578
	speed: 0.0305s/iter; left time: 575.3994s
Epoch: 21 cost time: 7.657283306121826
Epoch: 21, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5413 + XiCon Loss:2.5688 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5499840
	speed: 0.0325s/iter; left time: 608.7572s
	iters: 200, epoch: 22 | loss: 0.5791514
	speed: 0.0309s/iter; left time: 574.7501s
Epoch: 22 cost time: 7.5817975997924805
Epoch: 22, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5412 + XiCon Loss:2.5689 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6123495
	speed: 0.0359s/iter; left time: 663.4411s
	iters: 200, epoch: 23 | loss: 0.5873381
	speed: 0.0303s/iter; left time: 557.3767s
Epoch: 23 cost time: 7.7781455516815186
Epoch: 23, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5412 + XiCon Loss:2.5646 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5908899
	speed: 0.0342s/iter; left time: 622.6758s
	iters: 200, epoch: 24 | loss: 0.5538480
	speed: 0.0325s/iter; left time: 589.6489s
Epoch: 24 cost time: 7.914246082305908
Epoch: 24, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5411 + XiCon Loss:2.5683 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5710775
	speed: 0.0363s/iter; left time: 652.8886s
	iters: 200, epoch: 25 | loss: 0.5883257
	speed: 0.0318s/iter; left time: 569.0289s
Epoch: 25 cost time: 7.932721376419067
Epoch: 25, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5417 + XiCon Loss:2.5613 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5535820
	speed: 0.0341s/iter; left time: 606.1250s
	iters: 200, epoch: 26 | loss: 0.5915430
	speed: 0.0321s/iter; left time: 566.2277s
Epoch: 26 cost time: 7.850085496902466
Epoch: 26, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5413 + XiCon Loss:2.5663 x Lambda(0.01)), Vali MSE Loss: 1.0185 Test MSE Loss: 0.8535
Validation loss decreased (1.018896 --> 1.018509).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5508334
	speed: 0.0343s/iter; left time: 600.6700s
	iters: 200, epoch: 27 | loss: 0.5537012
	speed: 0.0312s/iter; left time: 543.0274s
Epoch: 27 cost time: 7.787073850631714
Epoch: 27, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5413 + XiCon Loss:2.5654 x Lambda(0.01)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8535
Validation loss decreased (1.018509 --> 1.018093).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6169664
	speed: 0.0357s/iter; left time: 615.8950s
	iters: 200, epoch: 28 | loss: 0.5518875
	speed: 0.0320s/iter; left time: 549.2562s
Epoch: 28 cost time: 7.9666547775268555
Epoch: 28, Steps: 238 Train Loss: 0.5663 (Forecasting Loss:0.5407 + XiCon Loss:2.5660 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5678384
	speed: 0.0340s/iter; left time: 578.7372s
	iters: 200, epoch: 29 | loss: 0.5690428
	speed: 0.0306s/iter; left time: 517.7194s
Epoch: 29 cost time: 7.622943878173828
Epoch: 29, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5412 + XiCon Loss:2.5610 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5647205
	speed: 0.0348s/iter; left time: 584.5284s
	iters: 200, epoch: 30 | loss: 0.5501903
	speed: 0.0299s/iter; left time: 499.2856s
Epoch: 30 cost time: 7.572449445724487
Epoch: 30, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5412 + XiCon Loss:2.5696 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5823663
	speed: 0.0322s/iter; left time: 533.9975s
	iters: 200, epoch: 31 | loss: 0.5639775
	speed: 0.0308s/iter; left time: 506.5985s
Epoch: 31 cost time: 7.459067106246948
Epoch: 31, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5414 + XiCon Loss:2.5686 x Lambda(0.01)), Vali MSE Loss: 1.0202 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5207385
	speed: 0.0349s/iter; left time: 569.9137s
	iters: 200, epoch: 32 | loss: 0.6061240
	speed: 0.0309s/iter; left time: 501.5224s
Epoch: 32 cost time: 7.677929401397705
Epoch: 32, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5415 + XiCon Loss:2.5623 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5039012
	speed: 0.0347s/iter; left time: 557.5473s
	iters: 200, epoch: 33 | loss: 0.5379267
	speed: 0.0310s/iter; left time: 495.2077s
Epoch: 33 cost time: 7.745218276977539
Epoch: 33, Steps: 238 Train Loss: 0.5665 (Forecasting Loss:0.5408 + XiCon Loss:2.5694 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5657816
	speed: 0.0350s/iter; left time: 553.9036s
	iters: 200, epoch: 34 | loss: 0.5599157
	speed: 0.0262s/iter; left time: 411.9535s
Epoch: 34 cost time: 7.111644744873047
Epoch: 34, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5413 + XiCon Loss:2.5690 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5560355
	speed: 0.0339s/iter; left time: 528.6008s
	iters: 200, epoch: 35 | loss: 0.5840654
	speed: 0.0279s/iter; left time: 431.9306s
Epoch: 35 cost time: 7.106301307678223
Epoch: 35, Steps: 238 Train Loss: 0.5667 (Forecasting Loss:0.5411 + XiCon Loss:2.5664 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5748332
	speed: 0.0310s/iter; left time: 476.2589s
	iters: 200, epoch: 36 | loss: 0.5755532
	speed: 0.0306s/iter; left time: 467.3972s
Epoch: 36 cost time: 7.316137790679932
Epoch: 36, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5412 + XiCon Loss:2.5644 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5564300
	speed: 0.0349s/iter; left time: 528.1428s
	iters: 200, epoch: 37 | loss: 0.5934751
	speed: 0.0305s/iter; left time: 458.8953s
Epoch: 37 cost time: 7.70448899269104
Epoch: 37, Steps: 238 Train Loss: 0.5667 (Forecasting Loss:0.5411 + XiCon Loss:2.5644 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9859688878059387, mae:0.7210714817047119, mape:4.676888942718506, mspe:2546.556396484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.9973
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9709483
	speed: 0.0394s/iter; left time: 934.6939s
	iters: 200, epoch: 1 | loss: 1.0246128
	speed: 0.0309s/iter; left time: 729.1995s
Epoch: 1 cost time: 8.247293472290039
Epoch: 1, Steps: 238 Train Loss: 1.0524 (Forecasting Loss:1.0271 + XiCon Loss:2.5303 x Lambda(0.01)), Vali MSE Loss: 1.8388 Test MSE Loss: 0.9830
Validation loss decreased (inf --> 1.838782).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6500444
	speed: 0.0359s/iter; left time: 841.9663s
	iters: 200, epoch: 2 | loss: 0.5381918
	speed: 0.0321s/iter; left time: 750.0175s
Epoch: 2 cost time: 8.033738136291504
Epoch: 2, Steps: 238 Train Loss: 0.6486 (Forecasting Loss:0.6233 + XiCon Loss:2.5286 x Lambda(0.01)), Vali MSE Loss: 1.0469 Test MSE Loss: 0.8597
Validation loss decreased (1.838782 --> 1.046910).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5967349
	speed: 0.0352s/iter; left time: 818.5483s
	iters: 200, epoch: 3 | loss: 0.6066833
	speed: 0.0329s/iter; left time: 760.8100s
Epoch: 3 cost time: 8.034913301467896
Epoch: 3, Steps: 238 Train Loss: 0.5798 (Forecasting Loss:0.5546 + XiCon Loss:2.5212 x Lambda(0.01)), Vali MSE Loss: 1.0221 Test MSE Loss: 0.8525
Validation loss decreased (1.046910 --> 1.022089).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5970947
	speed: 0.0331s/iter; left time: 761.7207s
	iters: 200, epoch: 4 | loss: 0.6113593
	speed: 0.0309s/iter; left time: 706.5127s
Epoch: 4 cost time: 7.573091268539429
Epoch: 4, Steps: 238 Train Loss: 0.5711 (Forecasting Loss:0.5459 + XiCon Loss:2.5218 x Lambda(0.01)), Vali MSE Loss: 1.0136 Test MSE Loss: 0.8513
Validation loss decreased (1.022089 --> 1.013552).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5904098
	speed: 0.0345s/iter; left time: 783.9364s
	iters: 200, epoch: 5 | loss: 0.5938994
	speed: 0.0311s/iter; left time: 704.8994s
Epoch: 5 cost time: 7.734087705612183
Epoch: 5, Steps: 238 Train Loss: 0.5676 (Forecasting Loss:0.5424 + XiCon Loss:2.5214 x Lambda(0.01)), Vali MSE Loss: 1.0108 Test MSE Loss: 0.8508
Validation loss decreased (1.013552 --> 1.010783).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5441098
	speed: 0.0343s/iter; left time: 771.0538s
	iters: 200, epoch: 6 | loss: 0.5518777
	speed: 0.0320s/iter; left time: 716.6555s
Epoch: 6 cost time: 7.837341785430908
Epoch: 6, Steps: 238 Train Loss: 0.5660 (Forecasting Loss:0.5408 + XiCon Loss:2.5179 x Lambda(0.01)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8504
Validation loss decreased (1.010783 --> 1.008179).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5937585
	speed: 0.0391s/iter; left time: 870.0991s
	iters: 200, epoch: 7 | loss: 0.5843658
	speed: 0.0314s/iter; left time: 696.8857s
Epoch: 7 cost time: 8.294587135314941
Epoch: 7, Steps: 238 Train Loss: 0.5652 (Forecasting Loss:0.5400 + XiCon Loss:2.5231 x Lambda(0.01)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8503
Validation loss decreased (1.008179 --> 1.007903).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6236980
	speed: 0.0339s/iter; left time: 746.2371s
	iters: 200, epoch: 8 | loss: 0.5442001
	speed: 0.0311s/iter; left time: 681.4508s
Epoch: 8 cost time: 7.719421148300171
Epoch: 8, Steps: 238 Train Loss: 0.5647 (Forecasting Loss:0.5395 + XiCon Loss:2.5208 x Lambda(0.01)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8503
Validation loss decreased (1.007903 --> 1.006860).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5410418
	speed: 0.0340s/iter; left time: 740.0820s
	iters: 200, epoch: 9 | loss: 0.5267297
	speed: 0.0308s/iter; left time: 668.0266s
Epoch: 9 cost time: 7.663812160491943
Epoch: 9, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5394 + XiCon Loss:2.5228 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
Validation loss decreased (1.006860 --> 1.006314).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5367422
	speed: 0.0341s/iter; left time: 735.7962s
	iters: 200, epoch: 10 | loss: 0.5720779
	speed: 0.0311s/iter; left time: 667.0444s
Epoch: 10 cost time: 7.696991920471191
Epoch: 10, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5391 + XiCon Loss:2.5227 x Lambda(0.01)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.8502
Validation loss decreased (1.006314 --> 1.005902).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6374871
	speed: 0.0343s/iter; left time: 731.6937s
	iters: 200, epoch: 11 | loss: 0.5558655
	speed: 0.0313s/iter; left time: 663.8932s
Epoch: 11 cost time: 7.782782554626465
Epoch: 11, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5388 + XiCon Loss:2.5206 x Lambda(0.01)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5574379
	speed: 0.0344s/iter; left time: 725.5535s
	iters: 200, epoch: 12 | loss: 0.5493481
	speed: 0.0326s/iter; left time: 683.3288s
Epoch: 12 cost time: 7.977053642272949
Epoch: 12, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5392 + XiCon Loss:2.5268 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6075210
	speed: 0.0348s/iter; left time: 724.6342s
	iters: 200, epoch: 13 | loss: 0.5931509
	speed: 0.0311s/iter; left time: 644.9552s
Epoch: 13 cost time: 7.788501501083374
Epoch: 13, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5391 + XiCon Loss:2.5253 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5909833
	speed: 0.0347s/iter; left time: 715.1190s
	iters: 200, epoch: 14 | loss: 0.5267596
	speed: 0.0317s/iter; left time: 649.6989s
Epoch: 14 cost time: 7.807122468948364
Epoch: 14, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5391 + XiCon Loss:2.5268 x Lambda(0.01)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5479400
	speed: 0.0342s/iter; left time: 697.3730s
	iters: 200, epoch: 15 | loss: 0.6094862
	speed: 0.0309s/iter; left time: 626.3424s
Epoch: 15 cost time: 7.640909910202026
Epoch: 15, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5389 + XiCon Loss:2.5196 x Lambda(0.01)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5425572
	speed: 0.0349s/iter; left time: 701.8036s
	iters: 200, epoch: 16 | loss: 0.5440921
	speed: 0.0319s/iter; left time: 638.9317s
Epoch: 16 cost time: 7.8704633712768555
Epoch: 16, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5391 + XiCon Loss:2.5240 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
Validation loss decreased (1.005902 --> 1.005728).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5720416
	speed: 0.0340s/iter; left time: 676.1316s
	iters: 200, epoch: 17 | loss: 0.5286387
	speed: 0.0317s/iter; left time: 627.5406s
Epoch: 17 cost time: 7.759734869003296
Epoch: 17, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5389 + XiCon Loss:2.5173 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8502
Validation loss decreased (1.005728 --> 1.004932).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5197104
	speed: 0.0359s/iter; left time: 706.3154s
	iters: 200, epoch: 18 | loss: 0.6392666
	speed: 0.0328s/iter; left time: 641.1178s
Epoch: 18 cost time: 8.093494415283203
Epoch: 18, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5391 + XiCon Loss:2.5266 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5366912
	speed: 0.0353s/iter; left time: 685.9335s
	iters: 200, epoch: 19 | loss: 0.5246401
	speed: 0.0320s/iter; left time: 617.8174s
Epoch: 19 cost time: 7.940713882446289
Epoch: 19, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5388 + XiCon Loss:2.5206 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6178457
	speed: 0.0353s/iter; left time: 676.7763s
	iters: 200, epoch: 20 | loss: 0.5457900
	speed: 0.0305s/iter; left time: 581.8191s
Epoch: 20 cost time: 7.805022239685059
Epoch: 20, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5391 + XiCon Loss:2.5221 x Lambda(0.01)), Vali MSE Loss: 1.0060 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5431573
	speed: 0.0335s/iter; left time: 633.6706s
	iters: 200, epoch: 21 | loss: 0.6070454
	speed: 0.0309s/iter; left time: 583.0520s
Epoch: 21 cost time: 7.581625699996948
Epoch: 21, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5392 + XiCon Loss:2.5210 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6012083
	speed: 0.0363s/iter; left time: 678.5912s
	iters: 200, epoch: 22 | loss: 0.5938153
	speed: 0.0310s/iter; left time: 576.0743s
Epoch: 22 cost time: 7.907549858093262
Epoch: 22, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5390 + XiCon Loss:2.5207 x Lambda(0.01)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5672286
	speed: 0.0334s/iter; left time: 616.5485s
	iters: 200, epoch: 23 | loss: 0.6083633
	speed: 0.0309s/iter; left time: 568.3829s
Epoch: 23 cost time: 7.607809066772461
Epoch: 23, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5390 + XiCon Loss:2.5259 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4930339
	speed: 0.0360s/iter; left time: 655.2802s
	iters: 200, epoch: 24 | loss: 0.5287669
	speed: 0.0328s/iter; left time: 595.3864s
Epoch: 24 cost time: 8.131094932556152
Epoch: 24, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5391 + XiCon Loss:2.5230 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5880225
	speed: 0.0365s/iter; left time: 657.4155s
	iters: 200, epoch: 25 | loss: 0.5553849
	speed: 0.0334s/iter; left time: 597.8515s
Epoch: 25 cost time: 8.200507879257202
Epoch: 25, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5391 + XiCon Loss:2.5225 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5454301
	speed: 0.0350s/iter; left time: 621.2567s
	iters: 200, epoch: 26 | loss: 0.5873474
	speed: 0.0313s/iter; left time: 552.3733s
Epoch: 26 cost time: 7.865213632583618
Epoch: 26, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5390 + XiCon Loss:2.5260 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5624218
	speed: 0.0326s/iter; left time: 571.7345s
	iters: 200, epoch: 27 | loss: 0.5340796
	speed: 0.0312s/iter; left time: 543.6631s
Epoch: 27 cost time: 7.538227796554565
Epoch: 27, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5391 + XiCon Loss:2.5240 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9806092977523804, mae:0.7197743058204651, mape:4.739068031311035, mspe:2656.359130859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9842+-0.00979, MAE:0.7227+-0.00649, MAPE:4.8128+-0.19333, MSPE:2733.9514+-251.53410, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0882
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 0.9907328
	speed: 0.0405s/iter; left time: 940.1418s
	iters: 200, epoch: 1 | loss: 0.9437439
	speed: 0.0343s/iter; left time: 791.5580s
Epoch: 1 cost time: 8.56650161743164
Epoch: 1, Steps: 233 Train Loss: 1.0439 (Forecasting Loss:1.0189 + XiCon Loss:2.5013 x Lambda(0.01)), Vali MSE Loss: 1.8606 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860586).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6257202
	speed: 0.0368s/iter; left time: 846.2007s
	iters: 200, epoch: 2 | loss: 0.6887940
	speed: 0.0411s/iter; left time: 940.6069s
Epoch: 2 cost time: 9.029746294021606
Epoch: 2, Steps: 233 Train Loss: 0.6772 (Forecasting Loss:0.6522 + XiCon Loss:2.4959 x Lambda(0.01)), Vali MSE Loss: 1.1270 Test MSE Loss: 1.1495
Validation loss decreased (1.860586 --> 1.126961).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6528785
	speed: 0.0378s/iter; left time: 858.6530s
	iters: 200, epoch: 3 | loss: 0.5956280
	speed: 0.0340s/iter; left time: 769.2021s
Epoch: 3 cost time: 8.30013108253479
Epoch: 3, Steps: 233 Train Loss: 0.6130 (Forecasting Loss:0.5881 + XiCon Loss:2.4905 x Lambda(0.01)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1437
Validation loss decreased (1.126961 --> 1.104185).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6204693
	speed: 0.0368s/iter; left time: 828.6993s
	iters: 200, epoch: 4 | loss: 0.6191115
	speed: 0.0367s/iter; left time: 821.1576s
Epoch: 4 cost time: 8.472619533538818
Epoch: 4, Steps: 233 Train Loss: 0.6048 (Forecasting Loss:0.5799 + XiCon Loss:2.4872 x Lambda(0.01)), Vali MSE Loss: 1.0969 Test MSE Loss: 1.1410
Validation loss decreased (1.104185 --> 1.096883).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5938278
	speed: 0.0365s/iter; left time: 813.1450s
	iters: 200, epoch: 5 | loss: 0.5907947
	speed: 0.0342s/iter; left time: 759.2068s
Epoch: 5 cost time: 8.215717077255249
Epoch: 5, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5767 + XiCon Loss:2.4910 x Lambda(0.01)), Vali MSE Loss: 1.0935 Test MSE Loss: 1.1402
Validation loss decreased (1.096883 --> 1.093455).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6144601
	speed: 0.0370s/iter; left time: 814.7002s
	iters: 200, epoch: 6 | loss: 0.6246123
	speed: 0.0354s/iter; left time: 776.2467s
Epoch: 6 cost time: 8.373881340026855
Epoch: 6, Steps: 233 Train Loss: 0.6001 (Forecasting Loss:0.5752 + XiCon Loss:2.4926 x Lambda(0.01)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1398
Validation loss decreased (1.093455 --> 1.091761).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5901792
	speed: 0.0375s/iter; left time: 817.3004s
	iters: 200, epoch: 7 | loss: 0.6456123
	speed: 0.0378s/iter; left time: 820.3974s
Epoch: 7 cost time: 8.649671077728271
Epoch: 7, Steps: 233 Train Loss: 0.5993 (Forecasting Loss:0.5744 + XiCon Loss:2.4899 x Lambda(0.01)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1398
Validation loss decreased (1.091761 --> 1.090916).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5679722
	speed: 0.0378s/iter; left time: 816.1710s
	iters: 200, epoch: 8 | loss: 0.6116414
	speed: 0.0343s/iter; left time: 737.4314s
Epoch: 8 cost time: 8.339191436767578
Epoch: 8, Steps: 233 Train Loss: 0.5989 (Forecasting Loss:0.5740 + XiCon Loss:2.4944 x Lambda(0.01)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1397
Validation loss decreased (1.090916 --> 1.090774).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6445001
	speed: 0.0359s/iter; left time: 765.3730s
	iters: 200, epoch: 9 | loss: 0.6435265
	speed: 0.0333s/iter; left time: 708.1583s
Epoch: 9 cost time: 8.084348201751709
Epoch: 9, Steps: 233 Train Loss: 0.5987 (Forecasting Loss:0.5738 + XiCon Loss:2.4951 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
Validation loss decreased (1.090774 --> 1.090312).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5659842
	speed: 0.0367s/iter; left time: 774.4396s
	iters: 200, epoch: 10 | loss: 0.5889227
	speed: 0.0339s/iter; left time: 711.9019s
Epoch: 10 cost time: 8.17690658569336
Epoch: 10, Steps: 233 Train Loss: 0.5986 (Forecasting Loss:0.5737 + XiCon Loss:2.4914 x Lambda(0.01)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5845679
	speed: 0.0360s/iter; left time: 750.6613s
	iters: 200, epoch: 11 | loss: 0.6093820
	speed: 0.0341s/iter; left time: 708.5456s
Epoch: 11 cost time: 8.139081954956055
Epoch: 11, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4885 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
Validation loss decreased (1.090312 --> 1.090100).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6114729
	speed: 0.0381s/iter; left time: 786.1221s
	iters: 200, epoch: 12 | loss: 0.5990584
	speed: 0.0338s/iter; left time: 693.2796s
Epoch: 12 cost time: 8.316651344299316
Epoch: 12, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4885 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.090100 --> 1.089939).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5861303
	speed: 0.0365s/iter; left time: 743.8870s
	iters: 200, epoch: 13 | loss: 0.6105042
	speed: 0.0345s/iter; left time: 699.9902s
Epoch: 13 cost time: 8.20913052558899
Epoch: 13, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4926 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.089939 --> 1.089881).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6100771
	speed: 0.0372s/iter; left time: 751.3848s
	iters: 200, epoch: 14 | loss: 0.5920355
	speed: 0.0338s/iter; left time: 678.8884s
Epoch: 14 cost time: 8.267120122909546
Epoch: 14, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4854 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5815682
	speed: 0.0363s/iter; left time: 724.0055s
	iters: 200, epoch: 15 | loss: 0.6349131
	speed: 0.0359s/iter; left time: 711.7154s
Epoch: 15 cost time: 8.372220039367676
Epoch: 15, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4898 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6142118
	speed: 0.0371s/iter; left time: 732.0452s
	iters: 200, epoch: 16 | loss: 0.6252272
	speed: 0.0344s/iter; left time: 673.7044s
Epoch: 16 cost time: 8.29028058052063
Epoch: 16, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4888 x Lambda(0.01)), Vali MSE Loss: 1.0895 Test MSE Loss: 1.1396
Validation loss decreased (1.089881 --> 1.089470).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5914656
	speed: 0.0360s/iter; left time: 701.9748s
	iters: 200, epoch: 17 | loss: 0.5834908
	speed: 0.0348s/iter; left time: 673.9673s
Epoch: 17 cost time: 8.204875230789185
Epoch: 17, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4854 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6349322
	speed: 0.0383s/iter; left time: 737.3556s
	iters: 200, epoch: 18 | loss: 0.6049845
	speed: 0.0359s/iter; left time: 687.5083s
Epoch: 18 cost time: 8.601671695709229
Epoch: 18, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4901 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5876718
	speed: 0.0338s/iter; left time: 641.8806s
	iters: 200, epoch: 19 | loss: 0.6775909
	speed: 0.0336s/iter; left time: 635.3614s
Epoch: 19 cost time: 7.98396897315979
Epoch: 19, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4920 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5705617
	speed: 0.0374s/iter; left time: 702.6494s
	iters: 200, epoch: 20 | loss: 0.5772635
	speed: 0.0346s/iter; left time: 645.8705s
Epoch: 20 cost time: 8.361684083938599
Epoch: 20, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4893 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5983383
	speed: 0.0372s/iter; left time: 688.8580s
	iters: 200, epoch: 21 | loss: 0.5791814
	speed: 0.0348s/iter; left time: 640.8437s
Epoch: 21 cost time: 8.274306297302246
Epoch: 21, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4906 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5714374
	speed: 0.0353s/iter; left time: 646.4634s
	iters: 200, epoch: 22 | loss: 0.5734826
	speed: 0.0345s/iter; left time: 627.9543s
Epoch: 22 cost time: 8.126830101013184
Epoch: 22, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4896 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5418093
	speed: 0.0370s/iter; left time: 669.5538s
	iters: 200, epoch: 23 | loss: 0.5988031
	speed: 0.0340s/iter; left time: 610.8382s
Epoch: 23 cost time: 8.246776342391968
Epoch: 23, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4867 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5875416
	speed: 0.0401s/iter; left time: 714.8582s
	iters: 200, epoch: 24 | loss: 0.5708526
	speed: 0.0357s/iter; left time: 632.7912s
Epoch: 24 cost time: 8.705461978912354
Epoch: 24, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5735 + XiCon Loss:2.4894 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5955822
	speed: 0.0372s/iter; left time: 655.4858s
	iters: 200, epoch: 25 | loss: 0.5734051
	speed: 0.0337s/iter; left time: 589.5562s
Epoch: 25 cost time: 8.24717116355896
Epoch: 25, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5736 + XiCon Loss:2.4951 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5725808
	speed: 0.0359s/iter; left time: 624.4325s
	iters: 200, epoch: 26 | loss: 0.6411562
	speed: 0.0339s/iter; left time: 585.7877s
Epoch: 26 cost time: 8.172515153884888
Epoch: 26, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5736 + XiCon Loss:2.4839 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3994585275650024, mae:0.8796746134757996, mape:6.137362003326416, mspe:4545.66650390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0868
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1749576
	speed: 0.0382s/iter; left time: 887.0729s
	iters: 200, epoch: 1 | loss: 1.1366837
	speed: 0.0324s/iter; left time: 749.1082s
Epoch: 1 cost time: 8.130714893341064
Epoch: 1, Steps: 233 Train Loss: 1.1593 (Forecasting Loss:1.1341 + XiCon Loss:2.5226 x Lambda(0.01)), Vali MSE Loss: 2.0405 Test MSE Loss: 1.3313
Validation loss decreased (inf --> 2.040481).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7054217
	speed: 0.0347s/iter; left time: 797.2526s
	iters: 200, epoch: 2 | loss: 0.6204114
	speed: 0.0349s/iter; left time: 798.3393s
Epoch: 2 cost time: 8.218800067901611
Epoch: 2, Steps: 233 Train Loss: 0.6851 (Forecasting Loss:0.6598 + XiCon Loss:2.5224 x Lambda(0.01)), Vali MSE Loss: 1.1148 Test MSE Loss: 1.1427
Validation loss decreased (2.040481 --> 1.114843).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5985988
	speed: 0.0378s/iter; left time: 860.2272s
	iters: 200, epoch: 3 | loss: 0.5892430
	speed: 0.0319s/iter; left time: 721.6818s
Epoch: 3 cost time: 8.029029130935669
Epoch: 3, Steps: 233 Train Loss: 0.6126 (Forecasting Loss:0.5874 + XiCon Loss:2.5266 x Lambda(0.01)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1376
Validation loss decreased (1.114843 --> 1.091929).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6544731
	speed: 0.0361s/iter; left time: 812.1992s
	iters: 200, epoch: 4 | loss: 0.5826864
	speed: 0.0328s/iter; left time: 733.7512s
Epoch: 4 cost time: 7.9140870571136475
Epoch: 4, Steps: 233 Train Loss: 0.6042 (Forecasting Loss:0.5790 + XiCon Loss:2.5251 x Lambda(0.01)), Vali MSE Loss: 1.0846 Test MSE Loss: 1.1360
Validation loss decreased (1.091929 --> 1.084650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6748358
	speed: 0.0378s/iter; left time: 842.6109s
	iters: 200, epoch: 5 | loss: 0.5668543
	speed: 0.0328s/iter; left time: 727.5144s
Epoch: 5 cost time: 8.095231771469116
Epoch: 5, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5756 + XiCon Loss:2.5288 x Lambda(0.01)), Vali MSE Loss: 1.0800 Test MSE Loss: 1.1359
Validation loss decreased (1.084650 --> 1.079988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6608457
	speed: 0.0355s/iter; left time: 783.0060s
	iters: 200, epoch: 6 | loss: 0.6387755
	speed: 0.0328s/iter; left time: 719.8197s
Epoch: 6 cost time: 7.91256308555603
Epoch: 6, Steps: 233 Train Loss: 0.5993 (Forecasting Loss:0.5740 + XiCon Loss:2.5293 x Lambda(0.01)), Vali MSE Loss: 1.0789 Test MSE Loss: 1.1350
Validation loss decreased (1.079988 --> 1.078879).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6007952
	speed: 0.0378s/iter; left time: 823.6640s
	iters: 200, epoch: 7 | loss: 0.5866864
	speed: 0.0312s/iter; left time: 677.5400s
Epoch: 7 cost time: 7.799243927001953
Epoch: 7, Steps: 233 Train Loss: 0.5986 (Forecasting Loss:0.5733 + XiCon Loss:2.5253 x Lambda(0.01)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1352
Validation loss decreased (1.078879 --> 1.077416).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5942357
	speed: 0.0298s/iter; left time: 641.8132s
	iters: 200, epoch: 8 | loss: 0.6485287
	speed: 0.0352s/iter; left time: 754.7289s
Epoch: 8 cost time: 7.35089635848999
Epoch: 8, Steps: 233 Train Loss: 0.5980 (Forecasting Loss:0.5728 + XiCon Loss:2.5263 x Lambda(0.01)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1352
Validation loss decreased (1.077416 --> 1.076862).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5758518
	speed: 0.0310s/iter; left time: 662.0628s
	iters: 200, epoch: 9 | loss: 0.5818223
	speed: 0.0335s/iter; left time: 711.4288s
Epoch: 9 cost time: 7.515059471130371
Epoch: 9, Steps: 233 Train Loss: 0.5978 (Forecasting Loss:0.5726 + XiCon Loss:2.5205 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1352
Validation loss decreased (1.076862 --> 1.076508).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6062418
	speed: 0.0378s/iter; left time: 796.9814s
	iters: 200, epoch: 10 | loss: 0.6038871
	speed: 0.0319s/iter; left time: 669.7190s
Epoch: 10 cost time: 8.233174562454224
Epoch: 10, Steps: 233 Train Loss: 0.5979 (Forecasting Loss:0.5726 + XiCon Loss:2.5322 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5380457
	speed: 0.0349s/iter; left time: 728.2733s
	iters: 200, epoch: 11 | loss: 0.5999429
	speed: 0.0317s/iter; left time: 658.1632s
Epoch: 11 cost time: 7.74937891960144
Epoch: 11, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5206 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5795939
	speed: 0.0369s/iter; left time: 762.4625s
	iters: 200, epoch: 12 | loss: 0.5867985
	speed: 0.0328s/iter; left time: 674.5164s
Epoch: 12 cost time: 8.093411922454834
Epoch: 12, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5724 + XiCon Loss:2.5220 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076508 --> 1.076444).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6148642
	speed: 0.0378s/iter; left time: 771.4961s
	iters: 200, epoch: 13 | loss: 0.6130651
	speed: 0.0318s/iter; left time: 646.7015s
Epoch: 13 cost time: 8.117394208908081
Epoch: 13, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5724 + XiCon Loss:2.5244 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5834520
	speed: 0.0382s/iter; left time: 770.6062s
	iters: 200, epoch: 14 | loss: 0.5910178
	speed: 0.0338s/iter; left time: 679.4214s
Epoch: 14 cost time: 8.282093286514282
Epoch: 14, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5195 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076444 --> 1.076410).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6081169
	speed: 0.0370s/iter; left time: 737.1229s
	iters: 200, epoch: 15 | loss: 0.5698543
	speed: 0.0319s/iter; left time: 632.6787s
Epoch: 15 cost time: 7.936136722564697
Epoch: 15, Steps: 233 Train Loss: 0.5975 (Forecasting Loss:0.5723 + XiCon Loss:2.5205 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6043198
	speed: 0.0377s/iter; left time: 742.6530s
	iters: 200, epoch: 16 | loss: 0.6303043
	speed: 0.0328s/iter; left time: 643.0690s
Epoch: 16 cost time: 8.122754335403442
Epoch: 16, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5235 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5762320
	speed: 0.0350s/iter; left time: 681.7295s
	iters: 200, epoch: 17 | loss: 0.5532119
	speed: 0.0321s/iter; left time: 621.5225s
Epoch: 17 cost time: 7.782784461975098
Epoch: 17, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5723 + XiCon Loss:2.5233 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6397592
	speed: 0.0370s/iter; left time: 712.5242s
	iters: 200, epoch: 18 | loss: 0.5716727
	speed: 0.0322s/iter; left time: 616.6749s
Epoch: 18 cost time: 8.008606195449829
Epoch: 18, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5724 + XiCon Loss:2.5272 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5662065
	speed: 0.0372s/iter; left time: 706.4160s
	iters: 200, epoch: 19 | loss: 0.5925740
	speed: 0.0338s/iter; left time: 638.6445s
Epoch: 19 cost time: 8.142188787460327
Epoch: 19, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5269 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6370178
	speed: 0.0358s/iter; left time: 671.6921s
	iters: 200, epoch: 20 | loss: 0.5698473
	speed: 0.0343s/iter; left time: 640.6207s
Epoch: 20 cost time: 8.078438997268677
Epoch: 20, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5724 + XiCon Loss:2.5196 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5719815
	speed: 0.0372s/iter; left time: 690.6422s
	iters: 200, epoch: 21 | loss: 0.5929685
	speed: 0.0327s/iter; left time: 603.3237s
Epoch: 21 cost time: 8.092740058898926
Epoch: 21, Steps: 233 Train Loss: 0.5979 (Forecasting Loss:0.5726 + XiCon Loss:2.5247 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
Validation loss decreased (1.076410 --> 1.076267).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6289800
	speed: 0.0383s/iter; left time: 701.0265s
	iters: 200, epoch: 22 | loss: 0.6147747
	speed: 0.0316s/iter; left time: 575.5983s
Epoch: 22 cost time: 8.063838720321655
Epoch: 22, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5724 + XiCon Loss:2.5210 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5814266
	speed: 0.0363s/iter; left time: 655.8212s
	iters: 200, epoch: 23 | loss: 0.6197501
	speed: 0.0339s/iter; left time: 609.5071s
Epoch: 23 cost time: 8.055519580841064
Epoch: 23, Steps: 233 Train Loss: 0.5978 (Forecasting Loss:0.5725 + XiCon Loss:2.5272 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5798168
	speed: 0.0368s/iter; left time: 656.3438s
	iters: 200, epoch: 24 | loss: 0.5654432
	speed: 0.0350s/iter; left time: 621.1617s
Epoch: 24 cost time: 8.250754833221436
Epoch: 24, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5723 + XiCon Loss:2.5279 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6668273
	speed: 0.0392s/iter; left time: 690.5782s
	iters: 200, epoch: 25 | loss: 0.6135111
	speed: 0.0329s/iter; left time: 576.3503s
Epoch: 25 cost time: 8.337879419326782
Epoch: 25, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5723 + XiCon Loss:2.5259 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
Validation loss decreased (1.076267 --> 1.076179).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6137900
	speed: 0.0379s/iter; left time: 658.3321s
	iters: 200, epoch: 26 | loss: 0.5734292
	speed: 0.0345s/iter; left time: 595.2370s
Epoch: 26 cost time: 8.31894302368164
Epoch: 26, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5724 + XiCon Loss:2.5226 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5883530
	speed: 0.0371s/iter; left time: 635.1736s
	iters: 200, epoch: 27 | loss: 0.6405798
	speed: 0.0343s/iter; left time: 584.1925s
Epoch: 27 cost time: 8.276123046875
Epoch: 27, Steps: 233 Train Loss: 0.5979 (Forecasting Loss:0.5726 + XiCon Loss:2.5274 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5355240
	speed: 0.0384s/iter; left time: 649.7941s
	iters: 200, epoch: 28 | loss: 0.6028931
	speed: 0.0341s/iter; left time: 572.9239s
Epoch: 28 cost time: 8.29333782196045
Epoch: 28, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5724 + XiCon Loss:2.5246 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.6100239
	speed: 0.0363s/iter; left time: 606.1782s
	iters: 200, epoch: 29 | loss: 0.5897361
	speed: 0.0360s/iter; left time: 596.0621s
Epoch: 29 cost time: 8.219352006912231
Epoch: 29, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5724 + XiCon Loss:2.5251 x Lambda(0.01)), Vali MSE Loss: 1.0768 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6177625
	speed: 0.0351s/iter; left time: 577.0826s
	iters: 200, epoch: 30 | loss: 0.6259088
	speed: 0.0334s/iter; left time: 546.4129s
Epoch: 30 cost time: 7.866567611694336
Epoch: 30, Steps: 233 Train Loss: 0.5978 (Forecasting Loss:0.5725 + XiCon Loss:2.5220 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5747654
	speed: 0.0367s/iter; left time: 594.4896s
	iters: 200, epoch: 31 | loss: 0.5925185
	speed: 0.0368s/iter; left time: 592.3986s
Epoch: 31 cost time: 8.442550659179688
Epoch: 31, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5723 + XiCon Loss:2.5234 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6155861
	speed: 0.0354s/iter; left time: 564.9552s
	iters: 200, epoch: 32 | loss: 0.6244191
	speed: 0.0332s/iter; left time: 527.1460s
Epoch: 32 cost time: 8.020204544067383
Epoch: 32, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5724 + XiCon Loss:2.5227 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5629460
	speed: 0.0374s/iter; left time: 589.5887s
	iters: 200, epoch: 33 | loss: 0.6195680
	speed: 0.0338s/iter; left time: 528.5958s
Epoch: 33 cost time: 8.248414754867554
Epoch: 33, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5201 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5724221
	speed: 0.0357s/iter; left time: 553.8616s
	iters: 200, epoch: 34 | loss: 0.5735034
	speed: 0.0333s/iter; left time: 513.3696s
Epoch: 34 cost time: 7.924781560897827
Epoch: 34, Steps: 233 Train Loss: 0.5977 (Forecasting Loss:0.5725 + XiCon Loss:2.5227 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5969738
	speed: 0.0375s/iter; left time: 572.2979s
	iters: 200, epoch: 35 | loss: 0.6134766
	speed: 0.0342s/iter; left time: 519.1147s
Epoch: 35 cost time: 8.134392261505127
Epoch: 35, Steps: 233 Train Loss: 0.5976 (Forecasting Loss:0.5723 + XiCon Loss:2.5273 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3928502798080444, mae:0.8773874640464783, mape:6.102173805236816, mspe:4463.18701171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.3671
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1685188
	speed: 0.0362s/iter; left time: 838.8724s
	iters: 200, epoch: 1 | loss: 0.9863208
	speed: 0.0312s/iter; left time: 720.6030s
Epoch: 1 cost time: 7.80528712272644
Epoch: 1, Steps: 233 Train Loss: 1.0390 (Forecasting Loss:1.0137 + XiCon Loss:2.5309 x Lambda(0.01)), Vali MSE Loss: 1.8333 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833311).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6685172
	speed: 0.0356s/iter; left time: 818.7741s
	iters: 200, epoch: 2 | loss: 0.5753137
	speed: 0.0302s/iter; left time: 690.4150s
Epoch: 2 cost time: 7.607457876205444
Epoch: 2, Steps: 233 Train Loss: 0.6777 (Forecasting Loss:0.6525 + XiCon Loss:2.5252 x Lambda(0.01)), Vali MSE Loss: 1.1219 Test MSE Loss: 1.1452
Validation loss decreased (1.833311 --> 1.121893).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6058751
	speed: 0.0339s/iter; left time: 769.8143s
	iters: 200, epoch: 3 | loss: 0.5924972
	speed: 0.0311s/iter; left time: 702.8533s
Epoch: 3 cost time: 7.551098108291626
Epoch: 3, Steps: 233 Train Loss: 0.6134 (Forecasting Loss:0.5883 + XiCon Loss:2.5131 x Lambda(0.01)), Vali MSE Loss: 1.0998 Test MSE Loss: 1.1377
Validation loss decreased (1.121893 --> 1.099817).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6419787
	speed: 0.0356s/iter; left time: 801.6130s
	iters: 200, epoch: 4 | loss: 0.6196500
	speed: 0.0301s/iter; left time: 674.6120s
Epoch: 4 cost time: 7.5628252029418945
Epoch: 4, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.5797 + XiCon Loss:2.5154 x Lambda(0.01)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1365
Validation loss decreased (1.099817 --> 1.090934).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5711347
	speed: 0.0355s/iter; left time: 791.6338s
	iters: 200, epoch: 5 | loss: 0.5602704
	speed: 0.0314s/iter; left time: 695.6033s
Epoch: 5 cost time: 7.678037405014038
Epoch: 5, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5762 + XiCon Loss:2.5109 x Lambda(0.01)), Vali MSE Loss: 1.0870 Test MSE Loss: 1.1360
Validation loss decreased (1.090934 --> 1.086953).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6102988
	speed: 0.0349s/iter; left time: 769.0180s
	iters: 200, epoch: 6 | loss: 0.6133628
	speed: 0.0311s/iter; left time: 681.8992s
Epoch: 6 cost time: 7.63100790977478
Epoch: 6, Steps: 233 Train Loss: 0.5998 (Forecasting Loss:0.5746 + XiCon Loss:2.5189 x Lambda(0.01)), Vali MSE Loss: 1.0853 Test MSE Loss: 1.1358
Validation loss decreased (1.086953 --> 1.085317).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5471285
	speed: 0.0354s/iter; left time: 771.7134s
	iters: 200, epoch: 7 | loss: 0.6485708
	speed: 0.0301s/iter; left time: 652.6765s
Epoch: 7 cost time: 7.574185371398926
Epoch: 7, Steps: 233 Train Loss: 0.5989 (Forecasting Loss:0.5738 + XiCon Loss:2.5134 x Lambda(0.01)), Vali MSE Loss: 1.0845 Test MSE Loss: 1.1357
Validation loss decreased (1.085317 --> 1.084497).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5975258
	speed: 0.0351s/iter; left time: 757.5567s
	iters: 200, epoch: 8 | loss: 0.5819617
	speed: 0.0302s/iter; left time: 648.3966s
Epoch: 8 cost time: 7.583392858505249
Epoch: 8, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.5733 + XiCon Loss:2.5116 x Lambda(0.01)), Vali MSE Loss: 1.0841 Test MSE Loss: 1.1356
Validation loss decreased (1.084497 --> 1.084090).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6256727
	speed: 0.0355s/iter; left time: 757.4530s
	iters: 200, epoch: 9 | loss: 0.5780533
	speed: 0.0298s/iter; left time: 633.6205s
Epoch: 9 cost time: 7.569239377975464
Epoch: 9, Steps: 233 Train Loss: 0.5984 (Forecasting Loss:0.5731 + XiCon Loss:2.5221 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1356
Validation loss decreased (1.084090 --> 1.083751).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5681485
	speed: 0.0334s/iter; left time: 705.2478s
	iters: 200, epoch: 10 | loss: 0.5998658
	speed: 0.0318s/iter; left time: 668.2980s
Epoch: 10 cost time: 7.490913391113281
Epoch: 10, Steps: 233 Train Loss: 0.5982 (Forecasting Loss:0.5731 + XiCon Loss:2.5170 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6002755
	speed: 0.0365s/iter; left time: 760.7870s
	iters: 200, epoch: 11 | loss: 0.6048634
	speed: 0.0310s/iter; left time: 643.7607s
Epoch: 11 cost time: 7.724165916442871
Epoch: 11, Steps: 233 Train Loss: 0.5982 (Forecasting Loss:0.5731 + XiCon Loss:2.5096 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083751 --> 1.083662).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5621983
	speed: 0.0340s/iter; left time: 702.5614s
	iters: 200, epoch: 12 | loss: 0.5633331
	speed: 0.0320s/iter; left time: 656.9339s
Epoch: 12 cost time: 7.579135179519653
Epoch: 12, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5140 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6440544
	speed: 0.0343s/iter; left time: 700.5095s
	iters: 200, epoch: 13 | loss: 0.5954293
	speed: 0.0298s/iter; left time: 605.4734s
Epoch: 13 cost time: 7.424148797988892
Epoch: 13, Steps: 233 Train Loss: 0.5982 (Forecasting Loss:0.5731 + XiCon Loss:2.5153 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6023805
	speed: 0.0353s/iter; left time: 712.5213s
	iters: 200, epoch: 14 | loss: 0.6156196
	speed: 0.0304s/iter; left time: 610.7509s
Epoch: 14 cost time: 7.546018600463867
Epoch: 14, Steps: 233 Train Loss: 0.5980 (Forecasting Loss:0.5729 + XiCon Loss:2.5109 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5555557
	speed: 0.0344s/iter; left time: 685.4954s
	iters: 200, epoch: 15 | loss: 0.6064776
	speed: 0.0318s/iter; left time: 630.4123s
Epoch: 15 cost time: 7.573321104049683
Epoch: 15, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5124 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6011329
	speed: 0.0365s/iter; left time: 718.9956s
	iters: 200, epoch: 16 | loss: 0.5865275
	speed: 0.0298s/iter; left time: 583.5616s
Epoch: 16 cost time: 7.643882751464844
Epoch: 16, Steps: 233 Train Loss: 0.5982 (Forecasting Loss:0.5730 + XiCon Loss:2.5153 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5438246
	speed: 0.0358s/iter; left time: 696.6240s
	iters: 200, epoch: 17 | loss: 0.5709715
	speed: 0.0324s/iter; left time: 627.6436s
Epoch: 17 cost time: 7.80889892578125
Epoch: 17, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5154 x Lambda(0.01)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
Validation loss decreased (1.083662 --> 1.083636).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6079767
	speed: 0.0348s/iter; left time: 669.0572s
	iters: 200, epoch: 18 | loss: 0.5820056
	speed: 0.0304s/iter; left time: 581.4930s
Epoch: 18 cost time: 7.591513633728027
Epoch: 18, Steps: 233 Train Loss: 0.5980 (Forecasting Loss:0.5729 + XiCon Loss:2.5095 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5848230
	speed: 0.0367s/iter; left time: 698.1492s
	iters: 200, epoch: 19 | loss: 0.6117011
	speed: 0.0310s/iter; left time: 585.3201s
Epoch: 19 cost time: 7.774024963378906
Epoch: 19, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5729 + XiCon Loss:2.5140 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6209561
	speed: 0.0364s/iter; left time: 682.7877s
	iters: 200, epoch: 20 | loss: 0.5687689
	speed: 0.0303s/iter; left time: 565.2660s
Epoch: 20 cost time: 8.002102613449097
Epoch: 20, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5138 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6733774
	speed: 0.0345s/iter; left time: 638.8336s
	iters: 200, epoch: 21 | loss: 0.5355418
	speed: 0.0302s/iter; left time: 556.5958s
Epoch: 21 cost time: 7.424813508987427
Epoch: 21, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5729 + XiCon Loss:2.5192 x Lambda(0.01)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
Validation loss decreased (1.083636 --> 1.083508).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5506949
	speed: 0.0344s/iter; left time: 630.5937s
	iters: 200, epoch: 22 | loss: 0.5827687
	speed: 0.0311s/iter; left time: 566.4245s
Epoch: 22 cost time: 7.5441811084747314
Epoch: 22, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5729 + XiCon Loss:2.5144 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5884003
	speed: 0.0362s/iter; left time: 654.2553s
	iters: 200, epoch: 23 | loss: 0.6457633
	speed: 0.0311s/iter; left time: 559.2944s
Epoch: 23 cost time: 7.668588161468506
Epoch: 23, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5729 + XiCon Loss:2.5123 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5540122
	speed: 0.0348s/iter; left time: 620.0348s
	iters: 200, epoch: 24 | loss: 0.6162824
	speed: 0.0314s/iter; left time: 556.7235s
Epoch: 24 cost time: 7.611535549163818
Epoch: 24, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5155 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6571233
	speed: 0.0360s/iter; left time: 634.1192s
	iters: 200, epoch: 25 | loss: 0.5205154
	speed: 0.0300s/iter; left time: 525.0890s
Epoch: 25 cost time: 7.6232383251190186
Epoch: 25, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5122 x Lambda(0.01)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6229427
	speed: 0.0346s/iter; left time: 600.4427s
	iters: 200, epoch: 26 | loss: 0.6051008
	speed: 0.0305s/iter; left time: 527.5169s
Epoch: 26 cost time: 7.49867844581604
Epoch: 26, Steps: 233 Train Loss: 0.5980 (Forecasting Loss:0.5730 + XiCon Loss:2.5091 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5948562
	speed: 0.0349s/iter; left time: 598.0091s
	iters: 200, epoch: 27 | loss: 0.6366602
	speed: 0.0298s/iter; left time: 508.5504s
Epoch: 27 cost time: 7.454881906509399
Epoch: 27, Steps: 233 Train Loss: 0.5979 (Forecasting Loss:0.5729 + XiCon Loss:2.5050 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5933135
	speed: 0.0355s/iter; left time: 599.8620s
	iters: 200, epoch: 28 | loss: 0.6044535
	speed: 0.0311s/iter; left time: 522.1666s
Epoch: 28 cost time: 7.678377151489258
Epoch: 28, Steps: 233 Train Loss: 0.5980 (Forecasting Loss:0.5729 + XiCon Loss:2.5138 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5765083
	speed: 0.0363s/iter; left time: 606.1964s
	iters: 200, epoch: 29 | loss: 0.5973262
	speed: 0.0303s/iter; left time: 502.2626s
Epoch: 29 cost time: 7.891486883163452
Epoch: 29, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5156 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6034682
	speed: 0.0345s/iter; left time: 567.5623s
	iters: 200, epoch: 30 | loss: 0.5552195
	speed: 0.0303s/iter; left time: 495.3714s
Epoch: 30 cost time: 7.4472739696502686
Epoch: 30, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5729 + XiCon Loss:2.5147 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5496796
	speed: 0.0339s/iter; left time: 549.7474s
	iters: 200, epoch: 31 | loss: 0.5863414
	speed: 0.0306s/iter; left time: 493.5178s
Epoch: 31 cost time: 7.461670160293579
Epoch: 31, Steps: 233 Train Loss: 0.5981 (Forecasting Loss:0.5730 + XiCon Loss:2.5138 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.391672968864441, mae:0.8793894052505493, mape:6.166054725646973, mspe:4547.52099609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 19.0754
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0462980
	speed: 0.0369s/iter; left time: 855.3487s
	iters: 200, epoch: 1 | loss: 1.0131258
	speed: 0.0335s/iter; left time: 773.6687s
Epoch: 1 cost time: 8.14765477180481
Epoch: 1, Steps: 233 Train Loss: 1.0532 (Forecasting Loss:1.0277 + XiCon Loss:2.5486 x Lambda(0.01)), Vali MSE Loss: 1.8645 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864499).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6499609
	speed: 0.0374s/iter; left time: 859.6692s
	iters: 200, epoch: 2 | loss: 0.6234713
	speed: 0.0308s/iter; left time: 703.9871s
Epoch: 2 cost time: 7.64893913269043
Epoch: 2, Steps: 233 Train Loss: 0.6800 (Forecasting Loss:0.6545 + XiCon Loss:2.5457 x Lambda(0.01)), Vali MSE Loss: 1.1221 Test MSE Loss: 1.1462
Validation loss decreased (1.864499 --> 1.122148).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6307809
	speed: 0.0355s/iter; left time: 807.4917s
	iters: 200, epoch: 3 | loss: 0.6648307
	speed: 0.0786s/iter; left time: 1779.6967s
Epoch: 3 cost time: 12.88123631477356
Epoch: 3, Steps: 233 Train Loss: 0.6147 (Forecasting Loss:0.5893 + XiCon Loss:2.5382 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1399
Validation loss decreased (1.122148 --> 1.102640).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5676661
	speed: 0.0312s/iter; left time: 702.2394s
	iters: 200, epoch: 4 | loss: 0.6261705
	speed: 0.0266s/iter; left time: 596.6992s
Epoch: 4 cost time: 6.664453983306885
Epoch: 4, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5810 + XiCon Loss:2.5340 x Lambda(0.01)), Vali MSE Loss: 1.0940 Test MSE Loss: 1.1380
Validation loss decreased (1.102640 --> 1.094023).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5833904
	speed: 0.0544s/iter; left time: 1211.1372s
	iters: 200, epoch: 5 | loss: 0.5834543
	speed: 0.0702s/iter; left time: 1556.0619s
Epoch: 5 cost time: 13.562474727630615
Epoch: 5, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5776 + XiCon Loss:2.5328 x Lambda(0.01)), Vali MSE Loss: 1.0906 Test MSE Loss: 1.1375
Validation loss decreased (1.094023 --> 1.090556).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5848878
	speed: 0.0308s/iter; left time: 678.2100s
	iters: 200, epoch: 6 | loss: 0.6239528
	speed: 0.0274s/iter; left time: 600.9480s
Epoch: 6 cost time: 6.776007413864136
Epoch: 6, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5760 + XiCon Loss:2.5402 x Lambda(0.01)), Vali MSE Loss: 1.0885 Test MSE Loss: 1.1374
Validation loss decreased (1.090556 --> 1.088468).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6064823
	speed: 0.0860s/iter; left time: 1874.2411s
	iters: 200, epoch: 7 | loss: 0.6249771
	speed: 0.0406s/iter; left time: 880.1803s
Epoch: 7 cost time: 13.549773216247559
Epoch: 7, Steps: 233 Train Loss: 0.6004 (Forecasting Loss:0.5751 + XiCon Loss:2.5332 x Lambda(0.01)), Vali MSE Loss: 1.0874 Test MSE Loss: 1.1374
Validation loss decreased (1.088468 --> 1.087436).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6283888
	speed: 0.0298s/iter; left time: 643.3136s
	iters: 200, epoch: 8 | loss: 0.5850875
	speed: 0.0268s/iter; left time: 575.4877s
Epoch: 8 cost time: 6.5401952266693115
Epoch: 8, Steps: 233 Train Loss: 0.6000 (Forecasting Loss:0.5747 + XiCon Loss:2.5313 x Lambda(0.01)), Vali MSE Loss: 1.0871 Test MSE Loss: 1.1373
Validation loss decreased (1.087436 --> 1.087101).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6188501
	speed: 0.0537s/iter; left time: 1145.2902s
	iters: 200, epoch: 9 | loss: 0.6567004
	speed: 0.0266s/iter; left time: 565.7221s
Epoch: 9 cost time: 8.880543947219849
Epoch: 9, Steps: 233 Train Loss: 0.5998 (Forecasting Loss:0.5744 + XiCon Loss:2.5325 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
Validation loss decreased (1.087101 --> 1.086620).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6146851
	speed: 0.0307s/iter; left time: 648.1900s
	iters: 200, epoch: 10 | loss: 0.5777599
	speed: 0.0262s/iter; left time: 550.4007s
Epoch: 10 cost time: 6.583515405654907
Epoch: 10, Steps: 233 Train Loss: 0.5996 (Forecasting Loss:0.5743 + XiCon Loss:2.5353 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
Validation loss decreased (1.086620 --> 1.086476).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5954061
	speed: 0.0292s/iter; left time: 610.2031s
	iters: 200, epoch: 11 | loss: 0.6021330
	speed: 0.0258s/iter; left time: 535.6290s
Epoch: 11 cost time: 6.3986546993255615
Epoch: 11, Steps: 233 Train Loss: 0.5996 (Forecasting Loss:0.5743 + XiCon Loss:2.5359 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
Validation loss decreased (1.086476 --> 1.086384).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6287464
	speed: 0.0303s/iter; left time: 625.0676s
	iters: 200, epoch: 12 | loss: 0.5554157
	speed: 0.0266s/iter; left time: 545.6233s
Epoch: 12 cost time: 6.561814069747925
Epoch: 12, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5368 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6226439
	speed: 0.0296s/iter; left time: 603.6039s
	iters: 200, epoch: 13 | loss: 0.5834891
	speed: 0.0258s/iter; left time: 523.6775s
Epoch: 13 cost time: 6.38512110710144
Epoch: 13, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5291 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5894840
	speed: 0.0297s/iter; left time: 598.9527s
	iters: 200, epoch: 14 | loss: 0.6511657
	speed: 0.0268s/iter; left time: 537.0175s
Epoch: 14 cost time: 6.546585559844971
Epoch: 14, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5339 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6262674
	speed: 0.0295s/iter; left time: 588.9380s
	iters: 200, epoch: 15 | loss: 0.6082012
	speed: 0.0258s/iter; left time: 512.7822s
Epoch: 15 cost time: 6.415818214416504
Epoch: 15, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5350 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6120597
	speed: 0.0293s/iter; left time: 577.5240s
	iters: 200, epoch: 16 | loss: 0.6142296
	speed: 0.0248s/iter; left time: 485.6707s
Epoch: 16 cost time: 6.268883228302002
Epoch: 16, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5741 + XiCon Loss:2.5341 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086384 --> 1.086117).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5135904
	speed: 0.0296s/iter; left time: 576.2473s
	iters: 200, epoch: 17 | loss: 0.6838893
	speed: 0.0258s/iter; left time: 500.5049s
Epoch: 17 cost time: 6.374225854873657
Epoch: 17, Steps: 233 Train Loss: 0.5996 (Forecasting Loss:0.5742 + XiCon Loss:2.5367 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6066020
	speed: 0.0304s/iter; left time: 584.7210s
	iters: 200, epoch: 18 | loss: 0.5880323
	speed: 0.0265s/iter; left time: 507.1640s
Epoch: 18 cost time: 6.574017524719238
Epoch: 18, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5352 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6128606
	speed: 0.0292s/iter; left time: 555.9135s
	iters: 200, epoch: 19 | loss: 0.6633863
	speed: 0.0271s/iter; left time: 512.5974s
Epoch: 19 cost time: 6.499898195266724
Epoch: 19, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5334 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086117 --> 1.086107).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6572108
	speed: 0.0300s/iter; left time: 563.8859s
	iters: 200, epoch: 20 | loss: 0.6190668
	speed: 0.0260s/iter; left time: 485.6511s
Epoch: 20 cost time: 6.46858549118042
Epoch: 20, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5741 + XiCon Loss:2.5378 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5783292
	speed: 0.0295s/iter; left time: 546.8343s
	iters: 200, epoch: 21 | loss: 0.5890563
	speed: 0.0254s/iter; left time: 469.1717s
Epoch: 21 cost time: 6.339930534362793
Epoch: 21, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5741 + XiCon Loss:2.5273 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6112573
	speed: 0.0292s/iter; left time: 535.0166s
	iters: 200, epoch: 22 | loss: 0.5534106
	speed: 0.0267s/iter; left time: 486.5062s
Epoch: 22 cost time: 6.466229200363159
Epoch: 22, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5742 + XiCon Loss:2.5291 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5639732
	speed: 0.0301s/iter; left time: 543.4248s
	iters: 200, epoch: 23 | loss: 0.6070560
	speed: 0.0262s/iter; left time: 471.7107s
Epoch: 23 cost time: 6.474975824356079
Epoch: 23, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5741 + XiCon Loss:2.5319 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5924430
	speed: 0.0297s/iter; left time: 529.2667s
	iters: 200, epoch: 24 | loss: 0.6220918
	speed: 0.0256s/iter; left time: 455.0106s
Epoch: 24 cost time: 6.366175413131714
Epoch: 24, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5273 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5640566
	speed: 0.0296s/iter; left time: 521.9677s
	iters: 200, epoch: 25 | loss: 0.6013560
	speed: 0.0262s/iter; left time: 459.3198s
Epoch: 25 cost time: 6.4576849937438965
Epoch: 25, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5329 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6438227
	speed: 0.0293s/iter; left time: 508.3823s
	iters: 200, epoch: 26 | loss: 0.6122639
	speed: 0.0257s/iter; left time: 444.5109s
Epoch: 26 cost time: 6.362167119979858
Epoch: 26, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5741 + XiCon Loss:2.5387 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6296930
	speed: 0.0298s/iter; left time: 511.1308s
	iters: 200, epoch: 27 | loss: 0.5659419
	speed: 0.0261s/iter; left time: 444.2960s
Epoch: 27 cost time: 6.442170143127441
Epoch: 27, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5741 + XiCon Loss:2.5283 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6221223
	speed: 0.0295s/iter; left time: 498.5167s
	iters: 200, epoch: 28 | loss: 0.6068847
	speed: 0.0257s/iter; left time: 432.1804s
Epoch: 28 cost time: 6.378319978713989
Epoch: 28, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5342 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5818582
	speed: 0.0293s/iter; left time: 488.6303s
	iters: 200, epoch: 29 | loss: 0.6194577
	speed: 0.0253s/iter; left time: 418.9792s
Epoch: 29 cost time: 6.329113483428955
Epoch: 29, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5740 + XiCon Loss:2.5331 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086107 --> 1.086054).  Saving model ...
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5725626
	speed: 0.0295s/iter; left time: 485.8177s
	iters: 200, epoch: 30 | loss: 0.5516704
	speed: 0.0252s/iter; left time: 411.2215s
Epoch: 30 cost time: 6.300407886505127
Epoch: 30, Steps: 233 Train Loss: 0.5996 (Forecasting Loss:0.5742 + XiCon Loss:2.5387 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5791023
	speed: 0.0294s/iter; left time: 476.0224s
	iters: 200, epoch: 31 | loss: 0.6014964
	speed: 0.0255s/iter; left time: 410.8964s
Epoch: 31 cost time: 6.353413820266724
Epoch: 31, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5301 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5840766
	speed: 0.0296s/iter; left time: 472.2662s
	iters: 200, epoch: 32 | loss: 0.5767910
	speed: 0.0259s/iter; left time: 411.4944s
Epoch: 32 cost time: 6.4135026931762695
Epoch: 32, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5297 x Lambda(0.01)), Vali MSE Loss: 1.0868 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5552862
	speed: 0.0295s/iter; left time: 464.7699s
	iters: 200, epoch: 33 | loss: 0.6555136
	speed: 0.0256s/iter; left time: 400.1829s
Epoch: 33 cost time: 6.361771583557129
Epoch: 33, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5741 + XiCon Loss:2.5392 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5778247
	speed: 0.0297s/iter; left time: 461.4672s
	iters: 200, epoch: 34 | loss: 0.5677928
	speed: 0.0259s/iter; left time: 399.1475s
Epoch: 34 cost time: 6.4265992641448975
Epoch: 34, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5740 + XiCon Loss:2.5318 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5681512
	speed: 0.0303s/iter; left time: 463.6997s
	iters: 200, epoch: 35 | loss: 0.6229935
	speed: 0.0262s/iter; left time: 398.0915s
Epoch: 35 cost time: 6.535410642623901
Epoch: 35, Steps: 233 Train Loss: 0.5994 (Forecasting Loss:0.5741 + XiCon Loss:2.5280 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6237769
	speed: 0.0290s/iter; left time: 437.0214s
	iters: 200, epoch: 36 | loss: 0.5680729
	speed: 0.0257s/iter; left time: 384.0126s
Epoch: 36 cost time: 6.3008527755737305
Epoch: 36, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5312 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5728017
	speed: 0.0301s/iter; left time: 446.3377s
	iters: 200, epoch: 37 | loss: 0.6164243
	speed: 0.0256s/iter; left time: 376.8100s
Epoch: 37 cost time: 6.4281392097473145
Epoch: 37, Steps: 233 Train Loss: 0.5996 (Forecasting Loss:0.5742 + XiCon Loss:2.5343 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5907166
	speed: 0.0292s/iter; left time: 426.1849s
	iters: 200, epoch: 38 | loss: 0.5799338
	speed: 0.0261s/iter; left time: 378.0560s
Epoch: 38 cost time: 6.342058897018433
Epoch: 38, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5345 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.6040348
	speed: 0.0295s/iter; left time: 423.4122s
	iters: 200, epoch: 39 | loss: 0.5773852
	speed: 0.0255s/iter; left time: 363.6142s
Epoch: 39 cost time: 6.345011472702026
Epoch: 39, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.5742 + XiCon Loss:2.5319 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3957276344299316, mae:0.8788092136383057, mape:6.1555070877075195, mspe:4558.2578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.2871
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0381668
	speed: 0.0281s/iter; left time: 652.0035s
	iters: 200, epoch: 1 | loss: 0.9827362
	speed: 0.0235s/iter; left time: 541.7389s
Epoch: 1 cost time: 5.968350410461426
Epoch: 1, Steps: 233 Train Loss: 1.0530 (Forecasting Loss:1.0279 + XiCon Loss:2.5066 x Lambda(0.01)), Vali MSE Loss: 1.8929 Test MSE Loss: 1.2473
Validation loss decreased (inf --> 1.892942).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6856059
	speed: 0.0274s/iter; left time: 628.3120s
	iters: 200, epoch: 2 | loss: 0.6056979
	speed: 0.0236s/iter; left time: 540.4852s
Epoch: 2 cost time: 5.913821697235107
Epoch: 2, Steps: 233 Train Loss: 0.6821 (Forecasting Loss:0.6569 + XiCon Loss:2.5188 x Lambda(0.01)), Vali MSE Loss: 1.1382 Test MSE Loss: 1.1436
Validation loss decreased (1.892942 --> 1.138162).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6472797
	speed: 0.0276s/iter; left time: 628.1840s
	iters: 200, epoch: 3 | loss: 0.5815500
	speed: 0.0238s/iter; left time: 538.2966s
Epoch: 3 cost time: 5.940117359161377
Epoch: 3, Steps: 233 Train Loss: 0.6172 (Forecasting Loss:0.5921 + XiCon Loss:2.5130 x Lambda(0.01)), Vali MSE Loss: 1.1169 Test MSE Loss: 1.1349
Validation loss decreased (1.138162 --> 1.116900).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6523920
	speed: 0.0278s/iter; left time: 624.7256s
	iters: 200, epoch: 4 | loss: 0.6031359
	speed: 0.0242s/iter; left time: 541.2196s
Epoch: 4 cost time: 5.995903491973877
Epoch: 4, Steps: 233 Train Loss: 0.6092 (Forecasting Loss:0.5840 + XiCon Loss:2.5194 x Lambda(0.01)), Vali MSE Loss: 1.1090 Test MSE Loss: 1.1334
Validation loss decreased (1.116900 --> 1.108986).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6206821
	speed: 0.0274s/iter; left time: 610.5050s
	iters: 200, epoch: 5 | loss: 0.6034207
	speed: 0.0236s/iter; left time: 523.3383s
Epoch: 5 cost time: 5.895261764526367
Epoch: 5, Steps: 233 Train Loss: 0.6059 (Forecasting Loss:0.5808 + XiCon Loss:2.5114 x Lambda(0.01)), Vali MSE Loss: 1.1057 Test MSE Loss: 1.1327
Validation loss decreased (1.108986 --> 1.105669).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6008627
	speed: 0.0272s/iter; left time: 598.9424s
	iters: 200, epoch: 6 | loss: 0.6571704
	speed: 0.0235s/iter; left time: 515.3320s
Epoch: 6 cost time: 5.898416519165039
Epoch: 6, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5794 + XiCon Loss:2.5137 x Lambda(0.01)), Vali MSE Loss: 1.1043 Test MSE Loss: 1.1324
Validation loss decreased (1.105669 --> 1.104314).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6132613
	speed: 0.0275s/iter; left time: 600.2657s
	iters: 200, epoch: 7 | loss: 0.6064554
	speed: 0.0235s/iter; left time: 509.5178s
Epoch: 7 cost time: 5.9162702560424805
Epoch: 7, Steps: 233 Train Loss: 0.6038 (Forecasting Loss:0.5786 + XiCon Loss:2.5162 x Lambda(0.01)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1323
Validation loss decreased (1.104314 --> 1.103105).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5754592
	speed: 0.0272s/iter; left time: 587.3103s
	iters: 200, epoch: 8 | loss: 0.6406614
	speed: 0.0235s/iter; left time: 503.9922s
Epoch: 8 cost time: 5.879417419433594
Epoch: 8, Steps: 233 Train Loss: 0.6033 (Forecasting Loss:0.5782 + XiCon Loss:2.5103 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1323
Validation loss decreased (1.103105 --> 1.102554).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5907261
	speed: 0.0274s/iter; left time: 585.3866s
	iters: 200, epoch: 9 | loss: 0.6243189
	speed: 0.0240s/iter; left time: 509.6623s
Epoch: 9 cost time: 5.96961236000061
Epoch: 9, Steps: 233 Train Loss: 0.6032 (Forecasting Loss:0.5781 + XiCon Loss:2.5180 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5774794
	speed: 0.0278s/iter; left time: 587.5582s
	iters: 200, epoch: 10 | loss: 0.6023152
	speed: 0.0235s/iter; left time: 494.1661s
Epoch: 10 cost time: 5.95711612701416
Epoch: 10, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5779 + XiCon Loss:2.5121 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5649334
	speed: 0.0270s/iter; left time: 564.3112s
	iters: 200, epoch: 11 | loss: 0.5750963
	speed: 0.0236s/iter; left time: 489.4803s
Epoch: 11 cost time: 5.853125810623169
Epoch: 11, Steps: 233 Train Loss: 0.6031 (Forecasting Loss:0.5779 + XiCon Loss:2.5188 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102554 --> 1.102218).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5774848
	speed: 0.0287s/iter; left time: 592.8394s
	iters: 200, epoch: 12 | loss: 0.6392323
	speed: 0.0235s/iter; left time: 482.4483s
Epoch: 12 cost time: 6.025380849838257
Epoch: 12, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5120 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6182761
	speed: 0.0274s/iter; left time: 559.3553s
	iters: 200, epoch: 13 | loss: 0.5943919
	speed: 0.0236s/iter; left time: 480.1699s
Epoch: 13 cost time: 5.909607648849487
Epoch: 13, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5177 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5650925
	speed: 0.0278s/iter; left time: 559.7781s
	iters: 200, epoch: 14 | loss: 0.5892661
	speed: 0.0235s/iter; left time: 472.5445s
Epoch: 14 cost time: 5.929812669754028
Epoch: 14, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5176 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5910618
	speed: 0.0274s/iter; left time: 546.7111s
	iters: 200, epoch: 15 | loss: 0.6222965
	speed: 0.0242s/iter; left time: 480.4376s
Epoch: 15 cost time: 5.963840007781982
Epoch: 15, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5189 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102218 --> 1.102171).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6351850
	speed: 0.0276s/iter; left time: 543.0822s
	iters: 200, epoch: 16 | loss: 0.5870531
	speed: 0.0241s/iter; left time: 472.3994s
Epoch: 16 cost time: 5.971283674240112
Epoch: 16, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5168 x Lambda(0.01)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1322
Validation loss decreased (1.102171 --> 1.102003).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6042264
	speed: 0.0273s/iter; left time: 530.7150s
	iters: 200, epoch: 17 | loss: 0.6272163
	speed: 0.0233s/iter; left time: 452.0044s
Epoch: 17 cost time: 5.861226797103882
Epoch: 17, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5100 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6263602
	speed: 0.0279s/iter; left time: 536.3618s
	iters: 200, epoch: 18 | loss: 0.6122155
	speed: 0.0236s/iter; left time: 451.3468s
Epoch: 18 cost time: 5.960834264755249
Epoch: 18, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5183 x Lambda(0.01)), Vali MSE Loss: 1.1019 Test MSE Loss: 1.1322
Validation loss decreased (1.102003 --> 1.101871).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5829521
	speed: 0.0274s/iter; left time: 521.0473s
	iters: 200, epoch: 19 | loss: 0.6567649
	speed: 0.0236s/iter; left time: 446.7498s
Epoch: 19 cost time: 5.900028228759766
Epoch: 19, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5777 + XiCon Loss:2.5141 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6049538
	speed: 0.0269s/iter; left time: 504.4138s
	iters: 200, epoch: 20 | loss: 0.5778956
	speed: 0.0235s/iter; left time: 439.6191s
Epoch: 20 cost time: 5.84971022605896
Epoch: 20, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5777 + XiCon Loss:2.5130 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6223869
	speed: 0.0276s/iter; left time: 512.5793s
	iters: 200, epoch: 21 | loss: 0.6147419
	speed: 0.0238s/iter; left time: 438.5615s
Epoch: 21 cost time: 5.945704936981201
Epoch: 21, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5777 + XiCon Loss:2.5151 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6228039
	speed: 0.0275s/iter; left time: 503.9046s
	iters: 200, epoch: 22 | loss: 0.5776449
	speed: 0.0235s/iter; left time: 428.1893s
Epoch: 22 cost time: 5.897676944732666
Epoch: 22, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5159 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6232967
	speed: 0.0276s/iter; left time: 497.9859s
	iters: 200, epoch: 23 | loss: 0.6015908
	speed: 0.0238s/iter; left time: 427.1182s
Epoch: 23 cost time: 5.948807239532471
Epoch: 23, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5096 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6293508
	speed: 0.0266s/iter; left time: 474.4550s
	iters: 200, epoch: 24 | loss: 0.5550776
	speed: 0.0238s/iter; left time: 423.1418s
Epoch: 24 cost time: 5.846863031387329
Epoch: 24, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5778 + XiCon Loss:2.5084 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6466830
	speed: 0.0269s/iter; left time: 473.2840s
	iters: 200, epoch: 25 | loss: 0.5918967
	speed: 0.0239s/iter; left time: 418.6973s
Epoch: 25 cost time: 5.904027223587036
Epoch: 25, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5181 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6062043
	speed: 0.0274s/iter; left time: 476.7649s
	iters: 200, epoch: 26 | loss: 0.6261571
	speed: 0.0235s/iter; left time: 406.1834s
Epoch: 26 cost time: 5.9086689949035645
Epoch: 26, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.5778 + XiCon Loss:2.5206 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6418841
	speed: 0.0275s/iter; left time: 471.9065s
	iters: 200, epoch: 27 | loss: 0.5686104
	speed: 0.0236s/iter; left time: 402.3963s
Epoch: 27 cost time: 5.915369510650635
Epoch: 27, Steps: 233 Train Loss: 0.6031 (Forecasting Loss:0.5779 + XiCon Loss:2.5116 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5381055
	speed: 0.0275s/iter; left time: 465.4738s
	iters: 200, epoch: 28 | loss: 0.5687312
	speed: 0.0232s/iter; left time: 390.3823s
Epoch: 28 cost time: 5.865338087081909
Epoch: 28, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5776 + XiCon Loss:2.5153 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3892154693603516, mae:0.8751672506332397, mape:6.027161598205566, mspe:4359.59423828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3938+-0.00490, MAE:0.8781+-0.00230, MAPE:6.1177+-0.06967, MSPE:4494.8452+-105.12753, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.2754
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 26.9939556
	speed: 0.0511s/iter; left time: 1155.2461s
	iters: 200, epoch: 1 | loss: 25.4240971
	speed: 0.0471s/iter; left time: 1059.9076s
Epoch: 1 cost time: 11.082536220550537
Epoch: 1, Steps: 227 Train Loss: 26.1625 (Forecasting Loss:1.0262 + XiCon Loss:2.5136 x Lambda(10.0)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936044).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 25.8012161
	speed: 0.0480s/iter; left time: 1074.5866s
	iters: 200, epoch: 2 | loss: 25.9321804
	speed: 0.0463s/iter; left time: 1030.7144s
Epoch: 2 cost time: 10.752798557281494
Epoch: 2, Steps: 227 Train Loss: 25.6984 (Forecasting Loss:0.6690 + XiCon Loss:2.5029 x Lambda(10.0)), Vali MSE Loss: 1.2115 Test MSE Loss: 1.2840
Validation loss decreased (1.936044 --> 1.211508).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 24.9187374
	speed: 0.0489s/iter; left time: 1082.8571s
	iters: 200, epoch: 3 | loss: 25.6298866
	speed: 0.0470s/iter; left time: 1036.0997s
Epoch: 3 cost time: 10.863906145095825
Epoch: 3, Steps: 227 Train Loss: 25.3213 (Forecasting Loss:0.6065 + XiCon Loss:2.4715 x Lambda(10.0)), Vali MSE Loss: 1.1896 Test MSE Loss: 1.2753
Validation loss decreased (1.211508 --> 1.189579).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 24.3566284
	speed: 0.0491s/iter; left time: 1076.4203s
	iters: 200, epoch: 4 | loss: 24.4838905
	speed: 0.0473s/iter; left time: 1031.3176s
Epoch: 4 cost time: 10.973049402236938
Epoch: 4, Steps: 227 Train Loss: 25.0085 (Forecasting Loss:0.5991 + XiCon Loss:2.4409 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2736
Validation loss decreased (1.189579 --> 1.184363).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 24.1426411
	speed: 0.0490s/iter; left time: 1062.8557s
	iters: 200, epoch: 5 | loss: 25.2953777
	speed: 0.0475s/iter; left time: 1025.9200s
Epoch: 5 cost time: 10.963553667068481
Epoch: 5, Steps: 227 Train Loss: 24.8702 (Forecasting Loss:0.5963 + XiCon Loss:2.4274 x Lambda(10.0)), Vali MSE Loss: 1.1820 Test MSE Loss: 1.2727
Validation loss decreased (1.184363 --> 1.181983).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 24.4737244
	speed: 0.0489s/iter; left time: 1048.8802s
	iters: 200, epoch: 6 | loss: 24.7466602
	speed: 0.0470s/iter; left time: 1003.4989s
Epoch: 6 cost time: 10.897180795669556
Epoch: 6, Steps: 227 Train Loss: 24.7175 (Forecasting Loss:0.5950 + XiCon Loss:2.4123 x Lambda(10.0)), Vali MSE Loss: 1.1804 Test MSE Loss: 1.2724
Validation loss decreased (1.181983 --> 1.180440).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.8192272
	speed: 0.0488s/iter; left time: 1035.6325s
	iters: 200, epoch: 7 | loss: 24.5515327
	speed: 0.0475s/iter; left time: 1004.9250s
Epoch: 7 cost time: 10.95235800743103
Epoch: 7, Steps: 227 Train Loss: 24.7377 (Forecasting Loss:0.5942 + XiCon Loss:2.4144 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2722
Validation loss decreased (1.180440 --> 1.179924).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.0481396
	speed: 0.0492s/iter; left time: 1033.5056s
	iters: 200, epoch: 8 | loss: 25.2560883
	speed: 0.0475s/iter; left time: 994.3419s
Epoch: 8 cost time: 11.034544706344604
Epoch: 8, Steps: 227 Train Loss: 24.6865 (Forecasting Loss:0.5939 + XiCon Loss:2.4093 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2721
Validation loss decreased (1.179924 --> 1.179122).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 24.7715721
	speed: 0.0506s/iter; left time: 1051.8282s
	iters: 200, epoch: 9 | loss: 24.4296684
	speed: 0.0476s/iter; left time: 985.1626s
Epoch: 9 cost time: 11.168314456939697
Epoch: 9, Steps: 227 Train Loss: 24.7242 (Forecasting Loss:0.5937 + XiCon Loss:2.4131 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2721
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 24.8015594
	speed: 0.0490s/iter; left time: 1007.1869s
	iters: 200, epoch: 10 | loss: 25.0969105
	speed: 0.0478s/iter; left time: 977.6921s
Epoch: 10 cost time: 11.002831935882568
Epoch: 10, Steps: 227 Train Loss: 24.6762 (Forecasting Loss:0.5937 + XiCon Loss:2.4083 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2721
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 24.9865932
	speed: 0.0484s/iter; left time: 983.3970s
	iters: 200, epoch: 11 | loss: 24.2914352
	speed: 0.0469s/iter; left time: 948.6718s
Epoch: 11 cost time: 10.864946126937866
Epoch: 11, Steps: 227 Train Loss: 24.6961 (Forecasting Loss:0.5934 + XiCon Loss:2.4103 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2721
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 24.7466545
	speed: 0.0495s/iter; left time: 994.8083s
	iters: 200, epoch: 12 | loss: 25.0320129
	speed: 0.0472s/iter; left time: 944.5828s
Epoch: 12 cost time: 10.998265266418457
Epoch: 12, Steps: 227 Train Loss: 24.6820 (Forecasting Loss:0.5935 + XiCon Loss:2.4088 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
Validation loss decreased (1.179122 --> 1.178934).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 23.9023514
	speed: 0.0479s/iter; left time: 951.9878s
	iters: 200, epoch: 13 | loss: 24.9417114
	speed: 0.0478s/iter; left time: 945.5211s
Epoch: 13 cost time: 10.886601686477661
Epoch: 13, Steps: 227 Train Loss: 24.6723 (Forecasting Loss:0.5937 + XiCon Loss:2.4079 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 24.9736786
	speed: 0.0494s/iter; left time: 971.0100s
	iters: 200, epoch: 14 | loss: 24.3449936
	speed: 0.0475s/iter; left time: 929.2338s
Epoch: 14 cost time: 11.066572427749634
Epoch: 14, Steps: 227 Train Loss: 24.6714 (Forecasting Loss:0.5936 + XiCon Loss:2.4078 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.4827099
	speed: 0.0486s/iter; left time: 944.2577s
	iters: 200, epoch: 15 | loss: 24.6271362
	speed: 0.0484s/iter; left time: 934.6095s
Epoch: 15 cost time: 11.051159143447876
Epoch: 15, Steps: 227 Train Loss: 24.6602 (Forecasting Loss:0.5937 + XiCon Loss:2.4067 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 23.8184738
	speed: 0.0486s/iter; left time: 932.3000s
	iters: 200, epoch: 16 | loss: 24.8999844
	speed: 0.0443s/iter; left time: 845.7987s
Epoch: 16 cost time: 10.465028047561646
Epoch: 16, Steps: 227 Train Loss: 24.7246 (Forecasting Loss:0.5934 + XiCon Loss:2.4131 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 25.4794025
	speed: 0.0488s/iter; left time: 925.9963s
	iters: 200, epoch: 17 | loss: 25.3911324
	speed: 0.0475s/iter; left time: 895.5955s
Epoch: 17 cost time: 10.93734335899353
Epoch: 17, Steps: 227 Train Loss: 24.6420 (Forecasting Loss:0.5935 + XiCon Loss:2.4048 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 24.5067215
	speed: 0.0504s/iter; left time: 944.6371s
	iters: 200, epoch: 18 | loss: 25.0606842
	speed: 0.0479s/iter; left time: 893.7983s
Epoch: 18 cost time: 11.19069218635559
Epoch: 18, Steps: 227 Train Loss: 24.6721 (Forecasting Loss:0.5936 + XiCon Loss:2.4078 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
Validation loss decreased (1.178934 --> 1.178779).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 24.7861576
	speed: 0.0494s/iter; left time: 914.2785s
	iters: 200, epoch: 19 | loss: 24.8302727
	speed: 0.0472s/iter; left time: 869.1166s
Epoch: 19 cost time: 11.034455060958862
Epoch: 19, Steps: 227 Train Loss: 24.7230 (Forecasting Loss:0.5935 + XiCon Loss:2.4130 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 24.4859962
	speed: 0.0489s/iter; left time: 893.7339s
	iters: 200, epoch: 20 | loss: 24.1756668
	speed: 0.0483s/iter; left time: 878.9828s
Epoch: 20 cost time: 11.02112603187561
Epoch: 20, Steps: 227 Train Loss: 24.7204 (Forecasting Loss:0.5936 + XiCon Loss:2.4127 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 24.5274982
	speed: 0.0491s/iter; left time: 887.4308s
	iters: 200, epoch: 21 | loss: 25.1739883
	speed: 0.0482s/iter; left time: 865.0698s
Epoch: 21 cost time: 11.108399391174316
Epoch: 21, Steps: 227 Train Loss: 24.7189 (Forecasting Loss:0.5936 + XiCon Loss:2.4125 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 24.5442295
	speed: 0.0491s/iter; left time: 876.0387s
	iters: 200, epoch: 22 | loss: 25.6025391
	speed: 0.0482s/iter; left time: 855.2471s
Epoch: 22 cost time: 11.038400650024414
Epoch: 22, Steps: 227 Train Loss: 24.6969 (Forecasting Loss:0.5936 + XiCon Loss:2.4103 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.9428921
	speed: 0.0486s/iter; left time: 855.0649s
	iters: 200, epoch: 23 | loss: 24.3786011
	speed: 0.0475s/iter; left time: 831.6836s
Epoch: 23 cost time: 10.985631227493286
Epoch: 23, Steps: 227 Train Loss: 24.7256 (Forecasting Loss:0.5935 + XiCon Loss:2.4132 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 24.5837383
	speed: 0.0498s/iter; left time: 864.8125s
	iters: 200, epoch: 24 | loss: 24.5879784
	speed: 0.0478s/iter; left time: 825.7477s
Epoch: 24 cost time: 11.086450815200806
Epoch: 24, Steps: 227 Train Loss: 24.7080 (Forecasting Loss:0.5936 + XiCon Loss:2.4114 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 24.4456425
	speed: 0.0489s/iter; left time: 839.1024s
	iters: 200, epoch: 25 | loss: 24.9278049
	speed: 0.0479s/iter; left time: 816.8166s
Epoch: 25 cost time: 11.033735990524292
Epoch: 25, Steps: 227 Train Loss: 24.7105 (Forecasting Loss:0.5935 + XiCon Loss:2.4117 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 25.0723343
	speed: 0.0502s/iter; left time: 850.0149s
	iters: 200, epoch: 26 | loss: 24.5413914
	speed: 0.0473s/iter; left time: 795.3217s
Epoch: 26 cost time: 11.135737419128418
Epoch: 26, Steps: 227 Train Loss: 24.6811 (Forecasting Loss:0.5934 + XiCon Loss:2.4088 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 25.1533718
	speed: 0.0486s/iter; left time: 811.2458s
	iters: 200, epoch: 27 | loss: 24.6746140
	speed: 0.0465s/iter; left time: 771.7038s
Epoch: 27 cost time: 10.847622394561768
Epoch: 27, Steps: 227 Train Loss: 24.7167 (Forecasting Loss:0.5935 + XiCon Loss:2.4123 x Lambda(10.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
Validation loss decreased (1.178779 --> 1.178242).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 24.2275715
	speed: 0.0494s/iter; left time: 813.7211s
	iters: 200, epoch: 28 | loss: 25.5145378
	speed: 0.0477s/iter; left time: 780.3658s
Epoch: 28 cost time: 10.985493659973145
Epoch: 28, Steps: 227 Train Loss: 24.7339 (Forecasting Loss:0.5935 + XiCon Loss:2.4140 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 25.2158546
	speed: 0.0486s/iter; left time: 788.7204s
	iters: 200, epoch: 29 | loss: 24.9576950
	speed: 0.0481s/iter; left time: 777.0836s
Epoch: 29 cost time: 11.031720399856567
Epoch: 29, Steps: 227 Train Loss: 24.6664 (Forecasting Loss:0.5937 + XiCon Loss:2.4073 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 24.1785736
	speed: 0.0485s/iter; left time: 777.0720s
	iters: 200, epoch: 30 | loss: 24.7669678
	speed: 0.0480s/iter; left time: 763.5229s
Epoch: 30 cost time: 10.97971224784851
Epoch: 30, Steps: 227 Train Loss: 24.6385 (Forecasting Loss:0.5935 + XiCon Loss:2.4045 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 24.7268200
	speed: 0.0485s/iter; left time: 766.3355s
	iters: 200, epoch: 31 | loss: 25.2554436
	speed: 0.0467s/iter; left time: 733.5455s
Epoch: 31 cost time: 10.86617112159729
Epoch: 31, Steps: 227 Train Loss: 24.6921 (Forecasting Loss:0.5937 + XiCon Loss:2.4098 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 23.9029465
	speed: 0.0492s/iter; left time: 766.1490s
	iters: 200, epoch: 32 | loss: 25.0458164
	speed: 0.0480s/iter; left time: 742.9503s
Epoch: 32 cost time: 11.101665019989014
Epoch: 32, Steps: 227 Train Loss: 24.6741 (Forecasting Loss:0.5936 + XiCon Loss:2.4081 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 24.3119202
	speed: 0.0490s/iter; left time: 752.2646s
	iters: 200, epoch: 33 | loss: 24.5892715
	speed: 0.0493s/iter; left time: 750.7693s
Epoch: 33 cost time: 11.16317892074585
Epoch: 33, Steps: 227 Train Loss: 24.6629 (Forecasting Loss:0.5936 + XiCon Loss:2.4069 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 24.9161949
	speed: 0.0512s/iter; left time: 773.1856s
	iters: 200, epoch: 34 | loss: 24.1631508
	speed: 0.0480s/iter; left time: 720.2347s
Epoch: 34 cost time: 11.212293863296509
Epoch: 34, Steps: 227 Train Loss: 24.7183 (Forecasting Loss:0.5935 + XiCon Loss:2.4125 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 24.5612144
	speed: 0.0489s/iter; left time: 728.2496s
	iters: 200, epoch: 35 | loss: 23.7762928
	speed: 0.0479s/iter; left time: 708.6889s
Epoch: 35 cost time: 11.037904977798462
Epoch: 35, Steps: 227 Train Loss: 24.6930 (Forecasting Loss:0.5935 + XiCon Loss:2.4099 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 24.9137688
	speed: 0.0483s/iter; left time: 708.5805s
	iters: 200, epoch: 36 | loss: 25.6469173
	speed: 0.0477s/iter; left time: 694.8019s
Epoch: 36 cost time: 10.93014669418335
Epoch: 36, Steps: 227 Train Loss: 24.7073 (Forecasting Loss:0.5937 + XiCon Loss:2.4114 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 24.8295422
	speed: 0.0491s/iter; left time: 709.1766s
	iters: 200, epoch: 37 | loss: 24.4948616
	speed: 0.0471s/iter; left time: 674.7239s
Epoch: 37 cost time: 10.908672094345093
Epoch: 37, Steps: 227 Train Loss: 24.7108 (Forecasting Loss:0.5935 + XiCon Loss:2.4117 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5893751382827759, mae:0.9547151923179626, mape:6.267134189605713, mspe:4855.1982421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.6802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 26.7922249
	speed: 0.0464s/iter; left time: 1048.9696s
	iters: 200, epoch: 1 | loss: 26.6870422
	speed: 0.0419s/iter; left time: 943.0026s
Epoch: 1 cost time: 9.998880624771118
Epoch: 1, Steps: 227 Train Loss: 26.2981 (Forecasting Loss:1.0243 + XiCon Loss:2.5274 x Lambda(10.0)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932089).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 25.1637154
	speed: 0.0444s/iter; left time: 993.4683s
	iters: 200, epoch: 2 | loss: 26.0304565
	speed: 0.0413s/iter; left time: 920.0609s
Epoch: 2 cost time: 9.729374885559082
Epoch: 2, Steps: 227 Train Loss: 25.9357 (Forecasting Loss:0.6694 + XiCon Loss:2.5266 x Lambda(10.0)), Vali MSE Loss: 1.2131 Test MSE Loss: 1.2808
Validation loss decreased (1.932089 --> 1.213115).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.4623871
	speed: 0.0449s/iter; left time: 995.0365s
	iters: 200, epoch: 3 | loss: 25.9579926
	speed: 0.0416s/iter; left time: 917.1013s
Epoch: 3 cost time: 9.848369121551514
Epoch: 3, Steps: 227 Train Loss: 25.7025 (Forecasting Loss:0.6076 + XiCon Loss:2.5095 x Lambda(10.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2731
Validation loss decreased (1.213115 --> 1.194205).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.6129990
	speed: 0.0450s/iter; left time: 987.3481s
	iters: 200, epoch: 4 | loss: 24.8453121
	speed: 0.0416s/iter; left time: 908.1607s
Epoch: 4 cost time: 9.846093893051147
Epoch: 4, Steps: 227 Train Loss: 25.5994 (Forecasting Loss:0.6004 + XiCon Loss:2.4999 x Lambda(10.0)), Vali MSE Loss: 1.1884 Test MSE Loss: 1.2712
Validation loss decreased (1.194205 --> 1.188446).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.0821381
	speed: 0.0450s/iter; left time: 975.1816s
	iters: 200, epoch: 5 | loss: 25.5603809
	speed: 0.0426s/iter; left time: 919.3576s
Epoch: 5 cost time: 9.953110456466675
Epoch: 5, Steps: 227 Train Loss: 25.5536 (Forecasting Loss:0.5976 + XiCon Loss:2.4956 x Lambda(10.0)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2705
Validation loss decreased (1.188446 --> 1.185829).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 25.8225880
	speed: 0.0455s/iter; left time: 976.0811s
	iters: 200, epoch: 6 | loss: 25.1964226
	speed: 0.0424s/iter; left time: 906.1146s
Epoch: 6 cost time: 9.96985673904419
Epoch: 6, Steps: 227 Train Loss: 25.4893 (Forecasting Loss:0.5962 + XiCon Loss:2.4893 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2701
Validation loss decreased (1.185829 --> 1.184113).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.2290211
	speed: 0.0464s/iter; left time: 984.5334s
	iters: 200, epoch: 7 | loss: 25.9887123
	speed: 0.0428s/iter; left time: 904.8312s
Epoch: 7 cost time: 10.102927446365356
Epoch: 7, Steps: 227 Train Loss: 25.5184 (Forecasting Loss:0.5955 + XiCon Loss:2.4923 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2700
Validation loss decreased (1.184113 --> 1.183841).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.3926029
	speed: 0.0453s/iter; left time: 952.0615s
	iters: 200, epoch: 8 | loss: 25.6848698
	speed: 0.0422s/iter; left time: 881.9114s
Epoch: 8 cost time: 9.972501039505005
Epoch: 8, Steps: 227 Train Loss: 25.5562 (Forecasting Loss:0.5953 + XiCon Loss:2.4961 x Lambda(10.0)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2699
Validation loss decreased (1.183841 --> 1.183420).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 24.7554398
	speed: 0.0460s/iter; left time: 956.7833s
	iters: 200, epoch: 9 | loss: 25.0623817
	speed: 0.0428s/iter; left time: 884.8572s
Epoch: 9 cost time: 10.039539337158203
Epoch: 9, Steps: 227 Train Loss: 25.4974 (Forecasting Loss:0.5950 + XiCon Loss:2.4902 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2699
Validation loss decreased (1.183420 --> 1.182179).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 24.9627895
	speed: 0.0445s/iter; left time: 915.3325s
	iters: 200, epoch: 10 | loss: 25.7294426
	speed: 0.0430s/iter; left time: 879.7650s
Epoch: 10 cost time: 9.925289392471313
Epoch: 10, Steps: 227 Train Loss: 25.5356 (Forecasting Loss:0.5949 + XiCon Loss:2.4941 x Lambda(10.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 24.8017063
	speed: 0.0452s/iter; left time: 919.7641s
	iters: 200, epoch: 11 | loss: 26.8930836
	speed: 0.0429s/iter; left time: 867.0000s
Epoch: 11 cost time: 10.038102149963379
Epoch: 11, Steps: 227 Train Loss: 25.5135 (Forecasting Loss:0.5948 + XiCon Loss:2.4919 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 25.5845108
	speed: 0.0450s/iter; left time: 905.0979s
	iters: 200, epoch: 12 | loss: 25.6929474
	speed: 0.0419s/iter; left time: 837.6428s
Epoch: 12 cost time: 9.934523582458496
Epoch: 12, Steps: 227 Train Loss: 25.5245 (Forecasting Loss:0.5948 + XiCon Loss:2.4930 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 25.1822834
	speed: 0.0455s/iter; left time: 903.6989s
	iters: 200, epoch: 13 | loss: 25.2959900
	speed: 0.0421s/iter; left time: 833.0995s
Epoch: 13 cost time: 9.9653639793396
Epoch: 13, Steps: 227 Train Loss: 25.5157 (Forecasting Loss:0.5949 + XiCon Loss:2.4921 x Lambda(10.0)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.1837578
	speed: 0.0460s/iter; left time: 904.3106s
	iters: 200, epoch: 14 | loss: 26.0851002
	speed: 0.0434s/iter; left time: 848.4979s
Epoch: 14 cost time: 10.123787879943848
Epoch: 14, Steps: 227 Train Loss: 25.4899 (Forecasting Loss:0.5949 + XiCon Loss:2.4895 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.5785809
	speed: 0.0451s/iter; left time: 876.4259s
	iters: 200, epoch: 15 | loss: 26.3172169
	speed: 0.0422s/iter; left time: 815.0744s
Epoch: 15 cost time: 9.946376323699951
Epoch: 15, Steps: 227 Train Loss: 25.5353 (Forecasting Loss:0.5947 + XiCon Loss:2.4941 x Lambda(10.0)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2698
Validation loss decreased (1.182179 --> 1.181905).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.0050716
	speed: 0.0457s/iter; left time: 877.7566s
	iters: 200, epoch: 16 | loss: 25.5390968
	speed: 0.0424s/iter; left time: 808.8345s
Epoch: 16 cost time: 9.978939294815063
Epoch: 16, Steps: 227 Train Loss: 25.5321 (Forecasting Loss:0.5947 + XiCon Loss:2.4937 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 25.1029892
	speed: 0.0466s/iter; left time: 883.1049s
	iters: 200, epoch: 17 | loss: 25.4377880
	speed: 0.0423s/iter; left time: 797.8696s
Epoch: 17 cost time: 10.119051933288574
Epoch: 17, Steps: 227 Train Loss: 25.5226 (Forecasting Loss:0.5948 + XiCon Loss:2.4928 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.0925045
	speed: 0.0464s/iter; left time: 868.7059s
	iters: 200, epoch: 18 | loss: 24.8185444
	speed: 0.0427s/iter; left time: 796.2865s
Epoch: 18 cost time: 10.08434534072876
Epoch: 18, Steps: 227 Train Loss: 25.4803 (Forecasting Loss:0.5948 + XiCon Loss:2.4886 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 24.9534626
	speed: 0.0463s/iter; left time: 856.6112s
	iters: 200, epoch: 19 | loss: 25.2979450
	speed: 0.0417s/iter; left time: 768.2448s
Epoch: 19 cost time: 9.961095333099365
Epoch: 19, Steps: 227 Train Loss: 25.5210 (Forecasting Loss:0.5947 + XiCon Loss:2.4926 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.0755367
	speed: 0.0465s/iter; left time: 849.6008s
	iters: 200, epoch: 20 | loss: 25.6913548
	speed: 0.0435s/iter; left time: 790.7081s
Epoch: 20 cost time: 10.192018508911133
Epoch: 20, Steps: 227 Train Loss: 25.5424 (Forecasting Loss:0.5948 + XiCon Loss:2.4948 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 25.5422592
	speed: 0.0453s/iter; left time: 817.4808s
	iters: 200, epoch: 21 | loss: 24.9345074
	speed: 0.0422s/iter; left time: 758.4987s
Epoch: 21 cost time: 9.91585087776184
Epoch: 21, Steps: 227 Train Loss: 25.4902 (Forecasting Loss:0.5948 + XiCon Loss:2.4895 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 25.0770226
	speed: 0.0458s/iter; left time: 816.0160s
	iters: 200, epoch: 22 | loss: 25.1098976
	speed: 0.0418s/iter; left time: 741.2921s
Epoch: 22 cost time: 9.925755739212036
Epoch: 22, Steps: 227 Train Loss: 25.5258 (Forecasting Loss:0.5947 + XiCon Loss:2.4931 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.0413322
	speed: 0.0458s/iter; left time: 806.1195s
	iters: 200, epoch: 23 | loss: 25.2641506
	speed: 0.0426s/iter; left time: 746.1112s
Epoch: 23 cost time: 10.018694877624512
Epoch: 23, Steps: 227 Train Loss: 25.4594 (Forecasting Loss:0.5948 + XiCon Loss:2.4865 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 25.6319771
	speed: 0.0448s/iter; left time: 779.2633s
	iters: 200, epoch: 24 | loss: 26.1026440
	speed: 0.0430s/iter; left time: 743.5082s
Epoch: 24 cost time: 10.009121656417847
Epoch: 24, Steps: 227 Train Loss: 25.4807 (Forecasting Loss:0.5946 + XiCon Loss:2.4886 x Lambda(10.0)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 25.7613087
	speed: 0.0447s/iter; left time: 767.5477s
	iters: 200, epoch: 25 | loss: 24.8110847
	speed: 0.0422s/iter; left time: 720.0766s
Epoch: 25 cost time: 9.903428316116333
Epoch: 25, Steps: 227 Train Loss: 25.4956 (Forecasting Loss:0.5948 + XiCon Loss:2.4901 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5867584943771362, mae:0.9528761506080627, mape:6.204370975494385, mspe:4736.49755859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9616
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 27.0327816
	speed: 0.0455s/iter; left time: 1027.3608s
	iters: 200, epoch: 1 | loss: 27.1961823
	speed: 0.0410s/iter; left time: 923.0483s
Epoch: 1 cost time: 9.78943419456482
Epoch: 1, Steps: 227 Train Loss: 26.4261 (Forecasting Loss:1.0400 + XiCon Loss:2.5386 x Lambda(10.0)), Vali MSE Loss: 1.9473 Test MSE Loss: 1.3972
Validation loss decreased (inf --> 1.947252).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 24.9049435
	speed: 0.0443s/iter; left time: 991.6204s
	iters: 200, epoch: 2 | loss: 25.6298866
	speed: 0.0417s/iter; left time: 927.7443s
Epoch: 2 cost time: 9.762564420700073
Epoch: 2, Steps: 227 Train Loss: 25.8656 (Forecasting Loss:0.6718 + XiCon Loss:2.5194 x Lambda(10.0)), Vali MSE Loss: 1.2059 Test MSE Loss: 1.2763
Validation loss decreased (1.947252 --> 1.205903).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 24.8475704
	speed: 0.0447s/iter; left time: 989.1031s
	iters: 200, epoch: 3 | loss: 24.1473808
	speed: 0.0416s/iter; left time: 916.7668s
Epoch: 3 cost time: 9.77420973777771
Epoch: 3, Steps: 227 Train Loss: 25.3681 (Forecasting Loss:0.6077 + XiCon Loss:2.4760 x Lambda(10.0)), Vali MSE Loss: 1.1886 Test MSE Loss: 1.2694
Validation loss decreased (1.205903 --> 1.188645).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 24.9237804
	speed: 0.0445s/iter; left time: 975.8582s
	iters: 200, epoch: 4 | loss: 25.5336304
	speed: 0.0417s/iter; left time: 910.4418s
Epoch: 4 cost time: 9.78199291229248
Epoch: 4, Steps: 227 Train Loss: 24.9243 (Forecasting Loss:0.6006 + XiCon Loss:2.4324 x Lambda(10.0)), Vali MSE Loss: 1.1852 Test MSE Loss: 1.2681
Validation loss decreased (1.188645 --> 1.185180).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 24.5406570
	speed: 0.0459s/iter; left time: 996.4656s
	iters: 200, epoch: 5 | loss: 24.4577560
	speed: 0.0425s/iter; left time: 917.3154s
Epoch: 5 cost time: 10.04449200630188
Epoch: 5, Steps: 227 Train Loss: 24.6603 (Forecasting Loss:0.5977 + XiCon Loss:2.4063 x Lambda(10.0)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2674
Validation loss decreased (1.185180 --> 1.181697).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 24.4923382
	speed: 0.0461s/iter; left time: 989.0092s
	iters: 200, epoch: 6 | loss: 23.9954300
	speed: 0.0416s/iter; left time: 889.4288s
Epoch: 6 cost time: 9.952413558959961
Epoch: 6, Steps: 227 Train Loss: 24.5491 (Forecasting Loss:0.5965 + XiCon Loss:2.3953 x Lambda(10.0)), Vali MSE Loss: 1.1813 Test MSE Loss: 1.2670
Validation loss decreased (1.181697 --> 1.181253).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 24.0184765
	speed: 0.0448s/iter; left time: 951.9896s
	iters: 200, epoch: 7 | loss: 23.6481781
	speed: 0.0426s/iter; left time: 900.9510s
Epoch: 7 cost time: 9.956860303878784
Epoch: 7, Steps: 227 Train Loss: 24.4678 (Forecasting Loss:0.5958 + XiCon Loss:2.3872 x Lambda(10.0)), Vali MSE Loss: 1.1809 Test MSE Loss: 1.2668
Validation loss decreased (1.181253 --> 1.180904).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.3078632
	speed: 0.0464s/iter; left time: 975.0317s
	iters: 200, epoch: 8 | loss: 23.8701496
	speed: 0.0428s/iter; left time: 894.7062s
Epoch: 8 cost time: 10.096558809280396
Epoch: 8, Steps: 227 Train Loss: 24.4217 (Forecasting Loss:0.5955 + XiCon Loss:2.3826 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2668
Validation loss decreased (1.180904 --> 1.180115).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 24.3983707
	speed: 0.0460s/iter; left time: 956.8374s
	iters: 200, epoch: 9 | loss: 23.6332932
	speed: 0.0427s/iter; left time: 882.8604s
Epoch: 9 cost time: 10.119620323181152
Epoch: 9, Steps: 227 Train Loss: 24.4458 (Forecasting Loss:0.5955 + XiCon Loss:2.3850 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 23.9486370
	speed: 0.0452s/iter; left time: 928.4417s
	iters: 200, epoch: 10 | loss: 24.9145756
	speed: 0.0424s/iter; left time: 866.4504s
Epoch: 10 cost time: 9.947364807128906
Epoch: 10, Steps: 227 Train Loss: 24.4186 (Forecasting Loss:0.5953 + XiCon Loss:2.3823 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 23.9820290
	speed: 0.0451s/iter; left time: 915.9603s
	iters: 200, epoch: 11 | loss: 24.3325310
	speed: 0.0429s/iter; left time: 868.1554s
Epoch: 11 cost time: 9.997779846191406
Epoch: 11, Steps: 227 Train Loss: 24.4663 (Forecasting Loss:0.5951 + XiCon Loss:2.3871 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 23.8569927
	speed: 0.0461s/iter; left time: 926.7312s
	iters: 200, epoch: 12 | loss: 24.1142521
	speed: 0.0421s/iter; left time: 841.8350s
Epoch: 12 cost time: 10.062788963317871
Epoch: 12, Steps: 227 Train Loss: 24.4671 (Forecasting Loss:0.5951 + XiCon Loss:2.3872 x Lambda(10.0)), Vali MSE Loss: 1.1804 Test MSE Loss: 1.2667
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 24.0009098
	speed: 0.0450s/iter; left time: 893.8965s
	iters: 200, epoch: 13 | loss: 24.2829075
	speed: 0.0418s/iter; left time: 825.7915s
Epoch: 13 cost time: 9.833443403244019
Epoch: 13, Steps: 227 Train Loss: 24.4471 (Forecasting Loss:0.5950 + XiCon Loss:2.3852 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 23.7236080
	speed: 0.0459s/iter; left time: 902.4195s
	iters: 200, epoch: 14 | loss: 24.3310070
	speed: 0.0420s/iter; left time: 820.5974s
Epoch: 14 cost time: 9.986562490463257
Epoch: 14, Steps: 227 Train Loss: 24.3853 (Forecasting Loss:0.5952 + XiCon Loss:2.3790 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
Validation loss decreased (1.180115 --> 1.179875).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.0441017
	speed: 0.0456s/iter; left time: 885.5258s
	iters: 200, epoch: 15 | loss: 23.9433441
	speed: 0.0420s/iter; left time: 812.1646s
Epoch: 15 cost time: 9.962425947189331
Epoch: 15, Steps: 227 Train Loss: 24.3952 (Forecasting Loss:0.5950 + XiCon Loss:2.3800 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2667
Validation loss decreased (1.179875 --> 1.179639).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 24.5716248
	speed: 0.0468s/iter; left time: 898.1977s
	iters: 200, epoch: 16 | loss: 24.1956825
	speed: 0.0427s/iter; left time: 816.0591s
Epoch: 16 cost time: 10.190359830856323
Epoch: 16, Steps: 227 Train Loss: 24.4370 (Forecasting Loss:0.5951 + XiCon Loss:2.3842 x Lambda(10.0)), Vali MSE Loss: 1.1805 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 24.8604927
	speed: 0.0451s/iter; left time: 855.3562s
	iters: 200, epoch: 17 | loss: 24.4986725
	speed: 0.0425s/iter; left time: 801.2670s
Epoch: 17 cost time: 9.961095809936523
Epoch: 17, Steps: 227 Train Loss: 24.4131 (Forecasting Loss:0.5951 + XiCon Loss:2.3818 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 24.3102627
	speed: 0.0476s/iter; left time: 892.1383s
	iters: 200, epoch: 18 | loss: 24.6634007
	speed: 0.0427s/iter; left time: 795.8854s
Epoch: 18 cost time: 10.238752603530884
Epoch: 18, Steps: 227 Train Loss: 24.3856 (Forecasting Loss:0.5951 + XiCon Loss:2.3790 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2667
Validation loss decreased (1.179639 --> 1.179599).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 24.3688507
	speed: 0.0447s/iter; left time: 827.4612s
	iters: 200, epoch: 19 | loss: 24.2592468
	speed: 0.0426s/iter; left time: 784.9491s
Epoch: 19 cost time: 9.944835901260376
Epoch: 19, Steps: 227 Train Loss: 24.4613 (Forecasting Loss:0.5953 + XiCon Loss:2.3866 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 24.1244583
	speed: 0.0455s/iter; left time: 831.4441s
	iters: 200, epoch: 20 | loss: 24.6791630
	speed: 0.0433s/iter; left time: 786.6958s
Epoch: 20 cost time: 10.070760488510132
Epoch: 20, Steps: 227 Train Loss: 24.4294 (Forecasting Loss:0.5951 + XiCon Loss:2.3834 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 24.2659512
	speed: 0.0456s/iter; left time: 823.4209s
	iters: 200, epoch: 21 | loss: 23.5244865
	speed: 0.0445s/iter; left time: 798.8339s
Epoch: 21 cost time: 10.17917513847351
Epoch: 21, Steps: 227 Train Loss: 24.4123 (Forecasting Loss:0.5950 + XiCon Loss:2.3817 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2667
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 25.0462780
	speed: 0.0454s/iter; left time: 809.0613s
	iters: 200, epoch: 22 | loss: 25.1747475
	speed: 0.0424s/iter; left time: 752.3504s
Epoch: 22 cost time: 9.964383125305176
Epoch: 22, Steps: 227 Train Loss: 24.4111 (Forecasting Loss:0.5952 + XiCon Loss:2.3816 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2667
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 24.7886486
	speed: 0.0466s/iter; left time: 820.6910s
	iters: 200, epoch: 23 | loss: 25.0085640
	speed: 0.0424s/iter; left time: 741.8152s
Epoch: 23 cost time: 10.082733631134033
Epoch: 23, Steps: 227 Train Loss: 24.4321 (Forecasting Loss:0.5951 + XiCon Loss:2.3837 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 24.5691490
	speed: 0.0451s/iter; left time: 784.2346s
	iters: 200, epoch: 24 | loss: 24.4320812
	speed: 0.0423s/iter; left time: 731.1064s
Epoch: 24 cost time: 9.934081315994263
Epoch: 24, Steps: 227 Train Loss: 24.4210 (Forecasting Loss:0.5951 + XiCon Loss:2.3826 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 24.4596119
	speed: 0.0460s/iter; left time: 789.5090s
	iters: 200, epoch: 25 | loss: 23.6554489
	speed: 0.0424s/iter; left time: 723.7593s
Epoch: 25 cost time: 10.016103267669678
Epoch: 25, Steps: 227 Train Loss: 24.4282 (Forecasting Loss:0.5952 + XiCon Loss:2.3833 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2667
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 24.1444244
	speed: 0.0457s/iter; left time: 773.1420s
	iters: 200, epoch: 26 | loss: 24.8118725
	speed: 0.0438s/iter; left time: 736.2215s
Epoch: 26 cost time: 10.132461309432983
Epoch: 26, Steps: 227 Train Loss: 24.4454 (Forecasting Loss:0.5951 + XiCon Loss:2.3850 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 24.3559685
	speed: 0.0460s/iter; left time: 768.1613s
	iters: 200, epoch: 27 | loss: 24.0805855
	speed: 0.0422s/iter; left time: 699.7368s
Epoch: 27 cost time: 10.02533769607544
Epoch: 27, Steps: 227 Train Loss: 24.4382 (Forecasting Loss:0.5952 + XiCon Loss:2.3843 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2667
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 23.5240383
	speed: 0.0448s/iter; left time: 738.5562s
	iters: 200, epoch: 28 | loss: 24.2936192
	speed: 0.0421s/iter; left time: 689.5434s
Epoch: 28 cost time: 9.914159297943115
Epoch: 28, Steps: 227 Train Loss: 24.4475 (Forecasting Loss:0.5951 + XiCon Loss:2.3852 x Lambda(10.0)), Vali MSE Loss: 1.1805 Test MSE Loss: 1.2667
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.582638144493103, mae:0.950710117816925, mape:6.100008487701416, mspe:4553.26806640625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9011
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 26.1047764
	speed: 0.0480s/iter; left time: 1084.9023s
	iters: 200, epoch: 1 | loss: 25.4781208
	speed: 0.0411s/iter; left time: 924.8062s
Epoch: 1 cost time: 10.114162683486938
Epoch: 1, Steps: 227 Train Loss: 26.2756 (Forecasting Loss:1.1623 + XiCon Loss:2.5113 x Lambda(10.0)), Vali MSE Loss: 2.2089 Test MSE Loss: 1.4658
Validation loss decreased (inf --> 2.208898).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 25.4223404
	speed: 0.0446s/iter; left time: 998.0713s
	iters: 200, epoch: 2 | loss: 25.7680187
	speed: 0.0411s/iter; left time: 915.7020s
Epoch: 2 cost time: 9.728646516799927
Epoch: 2, Steps: 227 Train Loss: 25.7153 (Forecasting Loss:0.7697 + XiCon Loss:2.4946 x Lambda(10.0)), Vali MSE Loss: 1.3335 Test MSE Loss: 1.3349
Validation loss decreased (2.208898 --> 1.333499).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.1771507
	speed: 0.0444s/iter; left time: 982.8260s
	iters: 200, epoch: 3 | loss: 25.6333122
	speed: 0.0414s/iter; left time: 913.6303s
Epoch: 3 cost time: 9.766573429107666
Epoch: 3, Steps: 227 Train Loss: 25.3733 (Forecasting Loss:0.6528 + XiCon Loss:2.4721 x Lambda(10.0)), Vali MSE Loss: 1.2390 Test MSE Loss: 1.3055
Validation loss decreased (1.333499 --> 1.239012).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.7768192
	speed: 0.0441s/iter; left time: 966.9905s
	iters: 200, epoch: 4 | loss: 24.6571674
	speed: 0.0417s/iter; left time: 910.6365s
Epoch: 4 cost time: 9.807405948638916
Epoch: 4, Steps: 227 Train Loss: 25.1946 (Forecasting Loss:0.6200 + XiCon Loss:2.4575 x Lambda(10.0)), Vali MSE Loss: 1.2036 Test MSE Loss: 1.2940
Validation loss decreased (1.239012 --> 1.203586).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 25.0136719
	speed: 0.0449s/iter; left time: 973.5594s
	iters: 200, epoch: 5 | loss: 25.1311550
	speed: 0.0418s/iter; left time: 901.7107s
Epoch: 5 cost time: 9.82429313659668
Epoch: 5, Steps: 227 Train Loss: 25.0827 (Forecasting Loss:0.6081 + XiCon Loss:2.4475 x Lambda(10.0)), Vali MSE Loss: 1.1934 Test MSE Loss: 1.2898
Validation loss decreased (1.203586 --> 1.193371).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 25.4885368
	speed: 0.0445s/iter; left time: 956.2541s
	iters: 200, epoch: 6 | loss: 25.0666180
	speed: 0.0427s/iter; left time: 912.1474s
Epoch: 6 cost time: 9.922942161560059
Epoch: 6, Steps: 227 Train Loss: 25.0217 (Forecasting Loss:0.6035 + XiCon Loss:2.4418 x Lambda(10.0)), Vali MSE Loss: 1.1884 Test MSE Loss: 1.2877
Validation loss decreased (1.193371 --> 1.188374).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.1911297
	speed: 0.0447s/iter; left time: 949.9322s
	iters: 200, epoch: 7 | loss: 24.4633827
	speed: 0.0422s/iter; left time: 892.4603s
Epoch: 7 cost time: 9.897467613220215
Epoch: 7, Steps: 227 Train Loss: 25.0326 (Forecasting Loss:0.6013 + XiCon Loss:2.4431 x Lambda(10.0)), Vali MSE Loss: 1.1861 Test MSE Loss: 1.2867
Validation loss decreased (1.188374 --> 1.186132).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 24.6955338
	speed: 0.0452s/iter; left time: 949.8493s
	iters: 200, epoch: 8 | loss: 25.1915741
	speed: 0.0422s/iter; left time: 882.6280s
Epoch: 8 cost time: 9.950245380401611
Epoch: 8, Steps: 227 Train Loss: 25.0310 (Forecasting Loss:0.6002 + XiCon Loss:2.4431 x Lambda(10.0)), Vali MSE Loss: 1.1857 Test MSE Loss: 1.2863
Validation loss decreased (1.186132 --> 1.185720).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 24.5224361
	speed: 0.0451s/iter; left time: 937.0341s
	iters: 200, epoch: 9 | loss: 25.3297977
	speed: 0.0429s/iter; left time: 887.0287s
Epoch: 9 cost time: 9.989751100540161
Epoch: 9, Steps: 227 Train Loss: 24.9878 (Forecasting Loss:0.5995 + XiCon Loss:2.4388 x Lambda(10.0)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2860
Validation loss decreased (1.185720 --> 1.184475).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.3540268
	speed: 0.0445s/iter; left time: 914.4318s
	iters: 200, epoch: 10 | loss: 25.3167038
	speed: 0.0414s/iter; left time: 847.2805s
Epoch: 10 cost time: 9.780045509338379
Epoch: 10, Steps: 227 Train Loss: 25.0781 (Forecasting Loss:0.5996 + XiCon Loss:2.4479 x Lambda(10.0)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2859
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 24.7245865
	speed: 0.0461s/iter; left time: 936.6715s
	iters: 200, epoch: 11 | loss: 24.9943333
	speed: 0.0424s/iter; left time: 857.2218s
Epoch: 11 cost time: 10.055148124694824
Epoch: 11, Steps: 227 Train Loss: 25.0074 (Forecasting Loss:0.5995 + XiCon Loss:2.4408 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2859
Validation loss decreased (1.184475 --> 1.183803).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 24.4026527
	speed: 0.0458s/iter; left time: 920.8378s
	iters: 200, epoch: 12 | loss: 25.6318760
	speed: 0.0420s/iter; left time: 840.8906s
Epoch: 12 cost time: 9.937610387802124
Epoch: 12, Steps: 227 Train Loss: 25.0800 (Forecasting Loss:0.5994 + XiCon Loss:2.4481 x Lambda(10.0)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2858
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 24.4025574
	speed: 0.0451s/iter; left time: 895.8416s
	iters: 200, epoch: 13 | loss: 25.0726681
	speed: 0.0427s/iter; left time: 843.5755s
Epoch: 13 cost time: 9.960517406463623
Epoch: 13, Steps: 227 Train Loss: 25.0056 (Forecasting Loss:0.5993 + XiCon Loss:2.4406 x Lambda(10.0)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2858
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.0586796
	speed: 0.0464s/iter; left time: 911.6803s
	iters: 200, epoch: 14 | loss: 24.2759514
	speed: 0.0422s/iter; left time: 825.6569s
Epoch: 14 cost time: 10.028187990188599
Epoch: 14, Steps: 227 Train Loss: 25.0107 (Forecasting Loss:0.5994 + XiCon Loss:2.4411 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2858
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.9141064
	speed: 0.0446s/iter; left time: 865.6074s
	iters: 200, epoch: 15 | loss: 24.8798065
	speed: 0.0419s/iter; left time: 810.1950s
Epoch: 15 cost time: 9.858319997787476
Epoch: 15, Steps: 227 Train Loss: 25.0304 (Forecasting Loss:0.5992 + XiCon Loss:2.4431 x Lambda(10.0)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2858
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 24.1401291
	speed: 0.0458s/iter; left time: 878.4085s
	iters: 200, epoch: 16 | loss: 24.8361263
	speed: 0.0430s/iter; left time: 821.6703s
Epoch: 16 cost time: 10.089375734329224
Epoch: 16, Steps: 227 Train Loss: 24.9975 (Forecasting Loss:0.5993 + XiCon Loss:2.4398 x Lambda(10.0)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2858
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 24.6968594
	speed: 0.0448s/iter; left time: 849.5768s
	iters: 200, epoch: 17 | loss: 26.1754761
	speed: 0.0424s/iter; left time: 799.3373s
Epoch: 17 cost time: 9.915502309799194
Epoch: 17, Steps: 227 Train Loss: 25.0357 (Forecasting Loss:0.5993 + XiCon Loss:2.4436 x Lambda(10.0)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2858
Validation loss decreased (1.183803 --> 1.183715).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 25.6388474
	speed: 0.0451s/iter; left time: 846.0644s
	iters: 200, epoch: 18 | loss: 24.8097706
	speed: 0.0428s/iter; left time: 797.2701s
Epoch: 18 cost time: 9.96496868133545
Epoch: 18, Steps: 227 Train Loss: 25.0525 (Forecasting Loss:0.5995 + XiCon Loss:2.4453 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2858
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 25.1850948
	speed: 0.0448s/iter; left time: 828.9457s
	iters: 200, epoch: 19 | loss: 24.7511616
	speed: 0.0417s/iter; left time: 767.8214s
Epoch: 19 cost time: 9.814134359359741
Epoch: 19, Steps: 227 Train Loss: 24.9965 (Forecasting Loss:0.5992 + XiCon Loss:2.4397 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2858
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.6027718
	speed: 0.0452s/iter; left time: 825.7799s
	iters: 200, epoch: 20 | loss: 24.9391861
	speed: 0.0417s/iter; left time: 759.1137s
Epoch: 20 cost time: 9.866290807723999
Epoch: 20, Steps: 227 Train Loss: 25.0719 (Forecasting Loss:0.5994 + XiCon Loss:2.4472 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2858
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 24.2728863
	speed: 0.0487s/iter; left time: 878.8566s
	iters: 200, epoch: 21 | loss: 24.9941025
	speed: 0.0424s/iter; left time: 761.3687s
Epoch: 21 cost time: 10.306732892990112
Epoch: 21, Steps: 227 Train Loss: 24.9978 (Forecasting Loss:0.5994 + XiCon Loss:2.4398 x Lambda(10.0)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2858
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 25.0920238
	speed: 0.0456s/iter; left time: 813.5012s
	iters: 200, epoch: 22 | loss: 24.7234154
	speed: 0.0419s/iter; left time: 743.7777s
Epoch: 22 cost time: 9.90209674835205
Epoch: 22, Steps: 227 Train Loss: 25.0439 (Forecasting Loss:0.5991 + XiCon Loss:2.4445 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2858
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.0378761
	speed: 0.0444s/iter; left time: 782.2774s
	iters: 200, epoch: 23 | loss: 25.0640469
	speed: 0.0433s/iter; left time: 757.9345s
Epoch: 23 cost time: 9.94306468963623
Epoch: 23, Steps: 227 Train Loss: 25.0215 (Forecasting Loss:0.5992 + XiCon Loss:2.4422 x Lambda(10.0)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2858
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 24.8584843
	speed: 0.0467s/iter; left time: 811.3462s
	iters: 200, epoch: 24 | loss: 25.0376663
	speed: 0.0423s/iter; left time: 730.2350s
Epoch: 24 cost time: 10.056169271469116
Epoch: 24, Steps: 227 Train Loss: 25.0591 (Forecasting Loss:0.5992 + XiCon Loss:2.4460 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2858
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 25.2581768
	speed: 0.0454s/iter; left time: 779.1594s
	iters: 200, epoch: 25 | loss: 24.4528828
	speed: 0.0431s/iter; left time: 734.2026s
Epoch: 25 cost time: 10.001081943511963
Epoch: 25, Steps: 227 Train Loss: 25.0382 (Forecasting Loss:0.5991 + XiCon Loss:2.4439 x Lambda(10.0)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2858
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 25.4399452
	speed: 0.0454s/iter; left time: 768.0794s
	iters: 200, epoch: 26 | loss: 24.7386398
	speed: 0.0427s/iter; left time: 718.5046s
Epoch: 26 cost time: 10.028250932693481
Epoch: 26, Steps: 227 Train Loss: 24.9796 (Forecasting Loss:0.5993 + XiCon Loss:2.4380 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2858
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 25.3464584
	speed: 0.0451s/iter; left time: 752.3971s
	iters: 200, epoch: 27 | loss: 25.1017857
	speed: 0.0423s/iter; left time: 701.5651s
Epoch: 27 cost time: 9.90907597541809
Epoch: 27, Steps: 227 Train Loss: 25.0337 (Forecasting Loss:0.5991 + XiCon Loss:2.4435 x Lambda(10.0)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2858
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.6069068908691406, mae:0.9647260904312134, mape:6.572610378265381, mspe:5368.20703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.6522
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 26.3274193
	speed: 0.0462s/iter; left time: 1044.7661s
	iters: 200, epoch: 1 | loss: 26.1731606
	speed: 0.0421s/iter; left time: 946.4956s
Epoch: 1 cost time: 9.986550092697144
Epoch: 1, Steps: 227 Train Loss: 26.4526 (Forecasting Loss:1.0351 + XiCon Loss:2.5418 x Lambda(10.0)), Vali MSE Loss: 1.9647 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964681).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 25.9302063
	speed: 0.0448s/iter; left time: 1003.4421s
	iters: 200, epoch: 2 | loss: 25.8340607
	speed: 0.0415s/iter; left time: 924.3405s
Epoch: 2 cost time: 9.828703165054321
Epoch: 2, Steps: 227 Train Loss: 25.9329 (Forecasting Loss:0.6716 + XiCon Loss:2.5261 x Lambda(10.0)), Vali MSE Loss: 1.2187 Test MSE Loss: 1.2817
Validation loss decreased (1.964681 --> 1.218735).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.5472183
	speed: 0.0449s/iter; left time: 993.5584s
	iters: 200, epoch: 3 | loss: 25.2665977
	speed: 0.0415s/iter; left time: 914.5981s
Epoch: 3 cost time: 9.78990364074707
Epoch: 3, Steps: 227 Train Loss: 25.6012 (Forecasting Loss:0.6086 + XiCon Loss:2.4993 x Lambda(10.0)), Vali MSE Loss: 1.2000 Test MSE Loss: 1.2742
Validation loss decreased (1.218735 --> 1.200013).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.2370968
	speed: 0.0450s/iter; left time: 986.5332s
	iters: 200, epoch: 4 | loss: 25.4333115
	speed: 0.0420s/iter; left time: 917.2386s
Epoch: 4 cost time: 9.855813264846802
Epoch: 4, Steps: 227 Train Loss: 25.4623 (Forecasting Loss:0.6010 + XiCon Loss:2.4861 x Lambda(10.0)), Vali MSE Loss: 1.1929 Test MSE Loss: 1.2722
Validation loss decreased (1.200013 --> 1.192852).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 25.3913631
	speed: 0.0453s/iter; left time: 983.6108s
	iters: 200, epoch: 5 | loss: 24.8379860
	speed: 0.0420s/iter; left time: 907.6799s
Epoch: 5 cost time: 9.9163978099823
Epoch: 5, Steps: 227 Train Loss: 25.3919 (Forecasting Loss:0.5980 + XiCon Loss:2.4794 x Lambda(10.0)), Vali MSE Loss: 1.1898 Test MSE Loss: 1.2713
Validation loss decreased (1.192852 --> 1.189792).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 25.1045322
	speed: 0.0448s/iter; left time: 962.7205s
	iters: 200, epoch: 6 | loss: 25.6485786
	speed: 0.0437s/iter; left time: 934.7558s
Epoch: 6 cost time: 10.048313617706299
Epoch: 6, Steps: 227 Train Loss: 25.3441 (Forecasting Loss:0.5968 + XiCon Loss:2.4747 x Lambda(10.0)), Vali MSE Loss: 1.1886 Test MSE Loss: 1.2709
Validation loss decreased (1.189792 --> 1.188589).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 24.8762875
	speed: 0.0452s/iter; left time: 961.0434s
	iters: 200, epoch: 7 | loss: 25.5108700
	speed: 0.0414s/iter; left time: 876.1370s
Epoch: 7 cost time: 9.830557823181152
Epoch: 7, Steps: 227 Train Loss: 25.3314 (Forecasting Loss:0.5962 + XiCon Loss:2.4735 x Lambda(10.0)), Vali MSE Loss: 1.1876 Test MSE Loss: 1.2708
Validation loss decreased (1.188589 --> 1.187589).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.0653725
	speed: 0.0449s/iter; left time: 942.8746s
	iters: 200, epoch: 8 | loss: 24.5998745
	speed: 0.0429s/iter; left time: 897.6890s
Epoch: 8 cost time: 9.951372861862183
Epoch: 8, Steps: 227 Train Loss: 25.3216 (Forecasting Loss:0.5959 + XiCon Loss:2.4726 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2707
Validation loss decreased (1.187589 --> 1.187480).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 24.8977871
	speed: 0.0450s/iter; left time: 934.4022s
	iters: 200, epoch: 9 | loss: 25.6557026
	speed: 0.0419s/iter; left time: 865.7758s
Epoch: 9 cost time: 9.884497165679932
Epoch: 9, Steps: 227 Train Loss: 25.3108 (Forecasting Loss:0.5956 + XiCon Loss:2.4715 x Lambda(10.0)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2707
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.7404995
	speed: 0.0444s/iter; left time: 911.8282s
	iters: 200, epoch: 10 | loss: 25.9128628
	speed: 0.0435s/iter; left time: 889.4130s
Epoch: 10 cost time: 9.967161178588867
Epoch: 10, Steps: 227 Train Loss: 25.3312 (Forecasting Loss:0.5953 + XiCon Loss:2.4736 x Lambda(10.0)), Vali MSE Loss: 1.1878 Test MSE Loss: 1.2706
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 25.4107590
	speed: 0.0441s/iter; left time: 897.3290s
	iters: 200, epoch: 11 | loss: 25.0526295
	speed: 0.0419s/iter; left time: 847.3176s
Epoch: 11 cost time: 9.772529363632202
Epoch: 11, Steps: 227 Train Loss: 25.2822 (Forecasting Loss:0.5952 + XiCon Loss:2.4687 x Lambda(10.0)), Vali MSE Loss: 1.1878 Test MSE Loss: 1.2706
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 25.1346092
	speed: 0.0468s/iter; left time: 939.9023s
	iters: 200, epoch: 12 | loss: 24.9693851
	speed: 0.0419s/iter; left time: 838.1695s
Epoch: 12 cost time: 10.035820722579956
Epoch: 12, Steps: 227 Train Loss: 25.2916 (Forecasting Loss:0.5952 + XiCon Loss:2.4696 x Lambda(10.0)), Vali MSE Loss: 1.1879 Test MSE Loss: 1.2706
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 25.0704441
	speed: 0.0443s/iter; left time: 879.6232s
	iters: 200, epoch: 13 | loss: 25.7548714
	speed: 0.0419s/iter; left time: 828.3900s
Epoch: 13 cost time: 9.811270952224731
Epoch: 13, Steps: 227 Train Loss: 25.2917 (Forecasting Loss:0.5952 + XiCon Loss:2.4696 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2706
Validation loss decreased (1.187480 --> 1.187470).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.2891979
	speed: 0.0453s/iter; left time: 889.9363s
	iters: 200, epoch: 14 | loss: 24.9863720
	speed: 0.0433s/iter; left time: 847.4204s
Epoch: 14 cost time: 10.038023471832275
Epoch: 14, Steps: 227 Train Loss: 25.3319 (Forecasting Loss:0.5952 + XiCon Loss:2.4737 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2706
Validation loss decreased (1.187470 --> 1.186687).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.3699646
	speed: 0.0455s/iter; left time: 884.4732s
	iters: 200, epoch: 15 | loss: 25.6123638
	speed: 0.0424s/iter; left time: 819.8032s
Epoch: 15 cost time: 10.022665977478027
Epoch: 15, Steps: 227 Train Loss: 25.3135 (Forecasting Loss:0.5953 + XiCon Loss:2.4718 x Lambda(10.0)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2706
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.4064884
	speed: 0.0451s/iter; left time: 865.4335s
	iters: 200, epoch: 16 | loss: 25.2705650
	speed: 0.0417s/iter; left time: 796.4436s
Epoch: 16 cost time: 9.822752475738525
Epoch: 16, Steps: 227 Train Loss: 25.3277 (Forecasting Loss:0.5952 + XiCon Loss:2.4732 x Lambda(10.0)), Vali MSE Loss: 1.1874 Test MSE Loss: 1.2706
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 24.6373005
	speed: 0.0454s/iter; left time: 862.0867s
	iters: 200, epoch: 17 | loss: 25.5668411
	speed: 0.0416s/iter; left time: 785.4486s
Epoch: 17 cost time: 9.89799165725708
Epoch: 17, Steps: 227 Train Loss: 25.3231 (Forecasting Loss:0.5952 + XiCon Loss:2.4728 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2706
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 25.0193195
	speed: 0.0452s/iter; left time: 848.0099s
	iters: 200, epoch: 18 | loss: 25.1699619
	speed: 0.0420s/iter; left time: 782.5995s
Epoch: 18 cost time: 9.897664070129395
Epoch: 18, Steps: 227 Train Loss: 25.3054 (Forecasting Loss:0.5952 + XiCon Loss:2.4710 x Lambda(10.0)), Vali MSE Loss: 1.1874 Test MSE Loss: 1.2706
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 24.7567215
	speed: 0.0454s/iter; left time: 841.2430s
	iters: 200, epoch: 19 | loss: 25.2583694
	speed: 0.0428s/iter; left time: 788.3560s
Epoch: 19 cost time: 10.033188104629517
Epoch: 19, Steps: 227 Train Loss: 25.3175 (Forecasting Loss:0.5950 + XiCon Loss:2.4722 x Lambda(10.0)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2706
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.2423649
	speed: 0.0445s/iter; left time: 813.7140s
	iters: 200, epoch: 20 | loss: 25.1189537
	speed: 0.0426s/iter; left time: 773.9741s
Epoch: 20 cost time: 9.974109172821045
Epoch: 20, Steps: 227 Train Loss: 25.3277 (Forecasting Loss:0.5951 + XiCon Loss:2.4733 x Lambda(10.0)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2706
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 24.6844311
	speed: 0.0456s/iter; left time: 823.7388s
	iters: 200, epoch: 21 | loss: 25.8499203
	speed: 0.0422s/iter; left time: 757.9794s
Epoch: 21 cost time: 9.962484121322632
Epoch: 21, Steps: 227 Train Loss: 25.3095 (Forecasting Loss:0.5952 + XiCon Loss:2.4714 x Lambda(10.0)), Vali MSE Loss: 1.1876 Test MSE Loss: 1.2706
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 24.7512360
	speed: 0.0444s/iter; left time: 792.2236s
	iters: 200, epoch: 22 | loss: 24.9353428
	speed: 0.0424s/iter; left time: 752.4642s
Epoch: 22 cost time: 9.938872814178467
Epoch: 22, Steps: 227 Train Loss: 25.2946 (Forecasting Loss:0.5953 + XiCon Loss:2.4699 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2706
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.3259449
	speed: 0.0467s/iter; left time: 822.0191s
	iters: 200, epoch: 23 | loss: 25.6930370
	speed: 0.0414s/iter; left time: 723.9806s
Epoch: 23 cost time: 10.017070055007935
Epoch: 23, Steps: 227 Train Loss: 25.3165 (Forecasting Loss:0.5953 + XiCon Loss:2.4721 x Lambda(10.0)), Vali MSE Loss: 1.1876 Test MSE Loss: 1.2706
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 25.4165440
	speed: 0.0454s/iter; left time: 788.6805s
	iters: 200, epoch: 24 | loss: 25.3702965
	speed: 0.0423s/iter; left time: 730.4292s
Epoch: 24 cost time: 9.966337442398071
Epoch: 24, Steps: 227 Train Loss: 25.3116 (Forecasting Loss:0.5953 + XiCon Loss:2.4716 x Lambda(10.0)), Vali MSE Loss: 1.1879 Test MSE Loss: 1.2706
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5883313417434692, mae:0.9529374837875366, mape:6.178913116455078, mspe:4706.89599609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5908+-0.01162, MAE:0.9552+-0.00685, MAPE:6.2646+-0.22636, MSPE:4844.0132+-387.60890, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
