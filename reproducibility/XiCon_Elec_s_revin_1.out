Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2001
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 3.6444461
	speed: 0.0153s/iter; left time: 364.7428s
	iters: 200, epoch: 1 | loss: 3.6045532
	speed: 0.0100s/iter; left time: 236.7332s
Epoch: 1 cost time: 2.9463279247283936
Epoch: 1, Steps: 239 Train Loss: 3.6389 (Forecasting Loss:0.6229 + XiCon Loss:3.0160 x Lambda(1.0)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.4447
Validation loss decreased (inf --> 0.327863).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2266197
	speed: 0.0127s/iter; left time: 300.0126s
	iters: 200, epoch: 2 | loss: 3.1776357
	speed: 0.0103s/iter; left time: 241.0033s
Epoch: 2 cost time: 2.7399024963378906
Epoch: 2, Steps: 239 Train Loss: 3.2468 (Forecasting Loss:0.3121 + XiCon Loss:2.9347 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.2800
Validation loss decreased (0.327863 --> 0.207486).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1456833
	speed: 0.0118s/iter; left time: 275.3848s
	iters: 200, epoch: 3 | loss: 3.1528709
	speed: 0.0095s/iter; left time: 219.6530s
Epoch: 3 cost time: 2.528841257095337
Epoch: 3, Steps: 239 Train Loss: 3.1557 (Forecasting Loss:0.2735 + XiCon Loss:2.8822 x Lambda(1.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.2716
Validation loss decreased (0.207486 --> 0.198618).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1400278
	speed: 0.0121s/iter; left time: 278.3260s
	iters: 200, epoch: 4 | loss: 3.1421971
	speed: 0.0100s/iter; left time: 229.1389s
Epoch: 4 cost time: 2.5997185707092285
Epoch: 4, Steps: 239 Train Loss: 3.1401 (Forecasting Loss:0.2673 + XiCon Loss:2.8728 x Lambda(1.0)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.2693
Validation loss decreased (0.198618 --> 0.196761).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1357872
	speed: 0.0123s/iter; left time: 282.0886s
	iters: 200, epoch: 5 | loss: 3.1039972
	speed: 0.0117s/iter; left time: 265.9062s
Epoch: 5 cost time: 2.8480165004730225
Epoch: 5, Steps: 239 Train Loss: 3.1319 (Forecasting Loss:0.2643 + XiCon Loss:2.8676 x Lambda(1.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.2689
Validation loss decreased (0.196761 --> 0.195084).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1450834
	speed: 0.0128s/iter; left time: 289.7829s
	iters: 200, epoch: 6 | loss: 3.1181953
	speed: 0.0110s/iter; left time: 246.4537s
Epoch: 6 cost time: 2.8202767372131348
Epoch: 6, Steps: 239 Train Loss: 3.1306 (Forecasting Loss:0.2633 + XiCon Loss:2.8673 x Lambda(1.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2667
Validation loss decreased (0.195084 --> 0.194483).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1311874
	speed: 0.0137s/iter; left time: 306.8940s
	iters: 200, epoch: 7 | loss: 3.1570561
	speed: 0.0105s/iter; left time: 234.6507s
Epoch: 7 cost time: 2.851839065551758
Epoch: 7, Steps: 239 Train Loss: 3.1295 (Forecasting Loss:0.2623 + XiCon Loss:2.8672 x Lambda(1.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2668
Validation loss decreased (0.194483 --> 0.193954).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.0613794
	speed: 0.0128s/iter; left time: 283.5145s
	iters: 200, epoch: 8 | loss: 3.1179459
	speed: 0.0103s/iter; left time: 226.0800s
Epoch: 8 cost time: 2.7631587982177734
Epoch: 8, Steps: 239 Train Loss: 3.1281 (Forecasting Loss:0.2620 + XiCon Loss:2.8661 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0743482
	speed: 0.0135s/iter; left time: 295.3656s
	iters: 200, epoch: 9 | loss: 3.1516678
	speed: 0.0106s/iter; left time: 231.7606s
Epoch: 9 cost time: 2.860119581222534
Epoch: 9, Steps: 239 Train Loss: 3.1283 (Forecasting Loss:0.2621 + XiCon Loss:2.8662 x Lambda(1.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2665
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0790083
	speed: 0.0136s/iter; left time: 293.4985s
	iters: 200, epoch: 10 | loss: 3.1365521
	speed: 0.0103s/iter; left time: 221.7961s
Epoch: 10 cost time: 2.817568778991699
Epoch: 10, Steps: 239 Train Loss: 3.1271 (Forecasting Loss:0.2615 + XiCon Loss:2.8656 x Lambda(1.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2663
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1548519
	speed: 0.0132s/iter; left time: 282.4238s
	iters: 200, epoch: 11 | loss: 3.1141922
	speed: 0.0105s/iter; left time: 224.0167s
Epoch: 11 cost time: 2.834893226623535
Epoch: 11, Steps: 239 Train Loss: 3.1270 (Forecasting Loss:0.2616 + XiCon Loss:2.8654 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2663
Validation loss decreased (0.193954 --> 0.193563).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1503866
	speed: 0.0131s/iter; left time: 276.4708s
	iters: 200, epoch: 12 | loss: 3.1328382
	speed: 0.0111s/iter; left time: 234.9285s
Epoch: 12 cost time: 2.882498025894165
Epoch: 12, Steps: 239 Train Loss: 3.1272 (Forecasting Loss:0.2620 + XiCon Loss:2.8653 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1108217
	speed: 0.0133s/iter; left time: 279.0460s
	iters: 200, epoch: 13 | loss: 3.1511993
	speed: 0.0102s/iter; left time: 213.1639s
Epoch: 13 cost time: 2.7972984313964844
Epoch: 13, Steps: 239 Train Loss: 3.1291 (Forecasting Loss:0.2618 + XiCon Loss:2.8673 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.2663
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1593673
	speed: 0.0133s/iter; left time: 274.2666s
	iters: 200, epoch: 14 | loss: 3.1337860
	speed: 0.0120s/iter; left time: 246.6798s
Epoch: 14 cost time: 2.9723398685455322
Epoch: 14, Steps: 239 Train Loss: 3.1278 (Forecasting Loss:0.2617 + XiCon Loss:2.8661 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2663
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1715329
	speed: 0.0138s/iter; left time: 281.9975s
	iters: 200, epoch: 15 | loss: 3.0625632
	speed: 0.0114s/iter; left time: 232.9442s
Epoch: 15 cost time: 2.979562997817993
Epoch: 15, Steps: 239 Train Loss: 3.1272 (Forecasting Loss:0.2620 + XiCon Loss:2.8652 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.2663
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1651030
	speed: 0.0129s/iter; left time: 260.4626s
	iters: 200, epoch: 16 | loss: 3.1151769
	speed: 0.0106s/iter; left time: 213.4759s
Epoch: 16 cost time: 2.855181932449341
Epoch: 16, Steps: 239 Train Loss: 3.1276 (Forecasting Loss:0.2613 + XiCon Loss:2.8663 x Lambda(1.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2663
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0776398
	speed: 0.0131s/iter; left time: 262.3514s
	iters: 200, epoch: 17 | loss: 3.1347332
	speed: 0.0103s/iter; left time: 205.1271s
Epoch: 17 cost time: 2.773003578186035
Epoch: 17, Steps: 239 Train Loss: 3.1264 (Forecasting Loss:0.2615 + XiCon Loss:2.8649 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2663
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1624446
	speed: 0.0138s/iter; left time: 271.7627s
	iters: 200, epoch: 18 | loss: 3.1965656
	speed: 0.0114s/iter; left time: 223.5615s
Epoch: 18 cost time: 2.964158535003662
Epoch: 18, Steps: 239 Train Loss: 3.1284 (Forecasting Loss:0.2616 + XiCon Loss:2.8668 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2663
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.1380587
	speed: 0.0138s/iter; left time: 268.8344s
	iters: 200, epoch: 19 | loss: 3.1205511
	speed: 0.0111s/iter; left time: 215.6833s
Epoch: 19 cost time: 2.994534969329834
Epoch: 19, Steps: 239 Train Loss: 3.1279 (Forecasting Loss:0.2617 + XiCon Loss:2.8662 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2663
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1646404
	speed: 0.0133s/iter; left time: 255.7952s
	iters: 200, epoch: 20 | loss: 3.1593528
	speed: 0.0107s/iter; left time: 205.5238s
Epoch: 20 cost time: 2.9322736263275146
Epoch: 20, Steps: 239 Train Loss: 3.1270 (Forecasting Loss:0.2616 + XiCon Loss:2.8654 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2663
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1085098
	speed: 0.0136s/iter; left time: 258.5607s
	iters: 200, epoch: 21 | loss: 3.0944607
	speed: 0.0110s/iter; left time: 208.6217s
Epoch: 21 cost time: 2.9088692665100098
Epoch: 21, Steps: 239 Train Loss: 3.1269 (Forecasting Loss:0.2615 + XiCon Loss:2.8654 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2663
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20956635475158691, mae:0.323101669549942, mape:2.281149387359619, mspe:2705.105224609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0656
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 3.6057942
	speed: 0.0131s/iter; left time: 311.3488s
	iters: 200, epoch: 1 | loss: 3.4480841
	speed: 0.0108s/iter; left time: 256.7078s
Epoch: 1 cost time: 2.8761789798736572
Epoch: 1, Steps: 239 Train Loss: 3.6181 (Forecasting Loss:0.6126 + XiCon Loss:3.0056 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.4353
Validation loss decreased (inf --> 0.322555).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2694211
	speed: 0.0132s/iter; left time: 311.7710s
	iters: 200, epoch: 2 | loss: 3.2264082
	speed: 0.0103s/iter; left time: 242.4295s
Epoch: 2 cost time: 2.8016555309295654
Epoch: 2, Steps: 239 Train Loss: 3.2703 (Forecasting Loss:0.3146 + XiCon Loss:2.9557 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.2807
Validation loss decreased (0.322555 --> 0.204953).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2087913
	speed: 0.0140s/iter; left time: 326.3281s
	iters: 200, epoch: 3 | loss: 3.1866484
	speed: 0.0108s/iter; left time: 250.3951s
Epoch: 3 cost time: 2.9567525386810303
Epoch: 3, Steps: 239 Train Loss: 3.1931 (Forecasting Loss:0.2787 + XiCon Loss:2.9144 x Lambda(1.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.2760
Validation loss decreased (0.204953 --> 0.199551).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1133215
	speed: 0.0132s/iter; left time: 305.3847s
	iters: 200, epoch: 4 | loss: 3.1137955
	speed: 0.0105s/iter; left time: 242.4518s
Epoch: 4 cost time: 2.8902502059936523
Epoch: 4, Steps: 239 Train Loss: 3.1628 (Forecasting Loss:0.2730 + XiCon Loss:2.8898 x Lambda(1.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.2716
Validation loss decreased (0.199551 --> 0.196441).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1570392
	speed: 0.0132s/iter; left time: 301.8253s
	iters: 200, epoch: 5 | loss: 3.1678057
	speed: 0.0115s/iter; left time: 260.5306s
Epoch: 5 cost time: 2.9460246562957764
Epoch: 5, Steps: 239 Train Loss: 3.1516 (Forecasting Loss:0.2692 + XiCon Loss:2.8824 x Lambda(1.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.2703
Validation loss decreased (0.196441 --> 0.195283).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1239755
	speed: 0.0133s/iter; left time: 300.6599s
	iters: 200, epoch: 6 | loss: 3.2271729
	speed: 0.0107s/iter; left time: 240.1907s
Epoch: 6 cost time: 2.8310799598693848
Epoch: 6, Steps: 239 Train Loss: 3.1432 (Forecasting Loss:0.2681 + XiCon Loss:2.8750 x Lambda(1.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.2694
Validation loss decreased (0.195283 --> 0.194130).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1420088
	speed: 0.0137s/iter; left time: 307.0039s
	iters: 200, epoch: 7 | loss: 3.0973861
	speed: 0.0105s/iter; left time: 234.9104s
Epoch: 7 cost time: 2.936467170715332
Epoch: 7, Steps: 239 Train Loss: 3.1429 (Forecasting Loss:0.2673 + XiCon Loss:2.8756 x Lambda(1.0)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.2686
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1306405
	speed: 0.0137s/iter; left time: 302.8746s
	iters: 200, epoch: 8 | loss: 3.1666017
	speed: 0.0111s/iter; left time: 245.1611s
Epoch: 8 cost time: 2.9185452461242676
Epoch: 8, Steps: 239 Train Loss: 3.1414 (Forecasting Loss:0.2668 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2689
Validation loss decreased (0.194130 --> 0.193416).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1542633
	speed: 0.0135s/iter; left time: 295.2028s
	iters: 200, epoch: 9 | loss: 3.1615167
	speed: 0.0105s/iter; left time: 228.5168s
Epoch: 9 cost time: 2.8259401321411133
Epoch: 9, Steps: 239 Train Loss: 3.1424 (Forecasting Loss:0.2663 + XiCon Loss:2.8762 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2687
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1362941
	speed: 0.0142s/iter; left time: 307.7868s
	iters: 200, epoch: 10 | loss: 3.1566017
	speed: 0.0106s/iter; left time: 228.2286s
Epoch: 10 cost time: 2.996122121810913
Epoch: 10, Steps: 239 Train Loss: 3.1398 (Forecasting Loss:0.2665 + XiCon Loss:2.8733 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2686
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1266530
	speed: 0.0135s/iter; left time: 288.5771s
	iters: 200, epoch: 11 | loss: 3.1583562
	speed: 0.0106s/iter; left time: 226.5169s
Epoch: 11 cost time: 2.89874005317688
Epoch: 11, Steps: 239 Train Loss: 3.1376 (Forecasting Loss:0.2664 + XiCon Loss:2.8712 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2686
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1403749
	speed: 0.0140s/iter; left time: 297.2462s
	iters: 200, epoch: 12 | loss: 3.1348069
	speed: 0.0113s/iter; left time: 237.2111s
Epoch: 12 cost time: 2.9921722412109375
Epoch: 12, Steps: 239 Train Loss: 3.1385 (Forecasting Loss:0.2661 + XiCon Loss:2.8724 x Lambda(1.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2686
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1505268
	speed: 0.0133s/iter; left time: 279.2193s
	iters: 200, epoch: 13 | loss: 3.1455107
	speed: 0.0097s/iter; left time: 202.9567s
Epoch: 13 cost time: 2.774024486541748
Epoch: 13, Steps: 239 Train Loss: 3.1398 (Forecasting Loss:0.2658 + XiCon Loss:2.8739 x Lambda(1.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2686
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1996052
	speed: 0.0133s/iter; left time: 275.7919s
	iters: 200, epoch: 14 | loss: 3.1450448
	speed: 0.0110s/iter; left time: 227.1037s
Epoch: 14 cost time: 2.9120490550994873
Epoch: 14, Steps: 239 Train Loss: 3.1404 (Forecasting Loss:0.2664 + XiCon Loss:2.8740 x Lambda(1.0)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2686
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1689305
	speed: 0.0136s/iter; left time: 278.0678s
	iters: 200, epoch: 15 | loss: 3.1494582
	speed: 0.0111s/iter; left time: 225.9380s
Epoch: 15 cost time: 2.9744479656219482
Epoch: 15, Steps: 239 Train Loss: 3.1398 (Forecasting Loss:0.2658 + XiCon Loss:2.8740 x Lambda(1.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2686
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1253953
	speed: 0.0131s/iter; left time: 265.1561s
	iters: 200, epoch: 16 | loss: 3.1012833
	speed: 0.0116s/iter; left time: 234.2944s
Epoch: 16 cost time: 2.9395861625671387
Epoch: 16, Steps: 239 Train Loss: 3.1414 (Forecasting Loss:0.2661 + XiCon Loss:2.8754 x Lambda(1.0)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2686
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1324930
	speed: 0.0142s/iter; left time: 283.7792s
	iters: 200, epoch: 17 | loss: 3.1692088
	speed: 0.0106s/iter; left time: 209.7560s
Epoch: 17 cost time: 2.979530096054077
Epoch: 17, Steps: 239 Train Loss: 3.1412 (Forecasting Loss:0.2666 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2686
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1157701
	speed: 0.0136s/iter; left time: 268.1240s
	iters: 200, epoch: 18 | loss: 3.1655567
	speed: 0.0110s/iter; left time: 216.1922s
Epoch: 18 cost time: 2.876002550125122
Epoch: 18, Steps: 239 Train Loss: 3.1396 (Forecasting Loss:0.2666 + XiCon Loss:2.8730 x Lambda(1.0)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2686
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21222299337387085, mae:0.32553258538246155, mape:2.3461291790008545, mspe:2902.6796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0038
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 3.6345165
	speed: 0.0130s/iter; left time: 310.1109s
	iters: 200, epoch: 1 | loss: 3.4540489
	speed: 0.0112s/iter; left time: 264.9669s
Epoch: 1 cost time: 2.9027435779571533
Epoch: 1, Steps: 239 Train Loss: 3.6068 (Forecasting Loss:0.6246 + XiCon Loss:2.9822 x Lambda(1.0)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.4434
Validation loss decreased (inf --> 0.329294).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2512925
	speed: 0.0148s/iter; left time: 348.6531s
	iters: 200, epoch: 2 | loss: 3.2342193
	speed: 0.0105s/iter; left time: 245.3122s
Epoch: 2 cost time: 2.9549853801727295
Epoch: 2, Steps: 239 Train Loss: 3.2581 (Forecasting Loss:0.3142 + XiCon Loss:2.9439 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.2844
Validation loss decreased (0.329294 --> 0.207633).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1645195
	speed: 0.0144s/iter; left time: 335.4087s
	iters: 200, epoch: 3 | loss: 3.1580436
	speed: 0.0103s/iter; left time: 238.9350s
Epoch: 3 cost time: 2.92321515083313
Epoch: 3, Steps: 239 Train Loss: 3.1711 (Forecasting Loss:0.2773 + XiCon Loss:2.8938 x Lambda(1.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.2797
Validation loss decreased (0.207633 --> 0.201320).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1592546
	speed: 0.0139s/iter; left time: 321.1003s
	iters: 200, epoch: 4 | loss: 3.1531403
	speed: 0.0107s/iter; left time: 245.0214s
Epoch: 4 cost time: 2.908179759979248
Epoch: 4, Steps: 239 Train Loss: 3.1441 (Forecasting Loss:0.2700 + XiCon Loss:2.8742 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.2746
Validation loss decreased (0.201320 --> 0.197780).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1368203
	speed: 0.0141s/iter; left time: 322.6558s
	iters: 200, epoch: 5 | loss: 3.0823939
	speed: 0.0113s/iter; left time: 257.6336s
Epoch: 5 cost time: 3.0225279331207275
Epoch: 5, Steps: 239 Train Loss: 3.1309 (Forecasting Loss:0.2670 + XiCon Loss:2.8639 x Lambda(1.0)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.2725
Validation loss decreased (0.197780 --> 0.196967).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1217105
	speed: 0.0131s/iter; left time: 296.9951s
	iters: 200, epoch: 6 | loss: 3.0934086
	speed: 0.0104s/iter; left time: 234.4808s
Epoch: 6 cost time: 2.7922112941741943
Epoch: 6, Steps: 239 Train Loss: 3.1326 (Forecasting Loss:0.2653 + XiCon Loss:2.8673 x Lambda(1.0)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.2715
Validation loss decreased (0.196967 --> 0.196897).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0904012
	speed: 0.0134s/iter; left time: 299.6511s
	iters: 200, epoch: 7 | loss: 3.1166713
	speed: 0.0115s/iter; left time: 256.9957s
Epoch: 7 cost time: 2.999114990234375
Epoch: 7, Steps: 239 Train Loss: 3.1253 (Forecasting Loss:0.2644 + XiCon Loss:2.8609 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2710
Validation loss decreased (0.196897 --> 0.196064).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.0897539
	speed: 0.0139s/iter; left time: 308.0186s
	iters: 200, epoch: 8 | loss: 3.1787720
	speed: 0.0107s/iter; left time: 235.6453s
Epoch: 8 cost time: 2.897871971130371
Epoch: 8, Steps: 239 Train Loss: 3.1257 (Forecasting Loss:0.2642 + XiCon Loss:2.8615 x Lambda(1.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.2708
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1382360
	speed: 0.0130s/iter; left time: 284.8070s
	iters: 200, epoch: 9 | loss: 3.1218820
	speed: 0.0107s/iter; left time: 232.4669s
Epoch: 9 cost time: 2.8513166904449463
Epoch: 9, Steps: 239 Train Loss: 3.1279 (Forecasting Loss:0.2639 + XiCon Loss:2.8640 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.2707
Validation loss decreased (0.196064 --> 0.195864).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1531701
	speed: 0.0129s/iter; left time: 280.0321s
	iters: 200, epoch: 10 | loss: 3.1580563
	speed: 0.0117s/iter; left time: 252.2325s
Epoch: 10 cost time: 2.9390575885772705
Epoch: 10, Steps: 239 Train Loss: 3.1254 (Forecasting Loss:0.2636 + XiCon Loss:2.8618 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2707
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1237612
	speed: 0.0140s/iter; left time: 298.9931s
	iters: 200, epoch: 11 | loss: 3.0894279
	speed: 0.0108s/iter; left time: 229.1950s
Epoch: 11 cost time: 3.00595760345459
Epoch: 11, Steps: 239 Train Loss: 3.1282 (Forecasting Loss:0.2633 + XiCon Loss:2.8648 x Lambda(1.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.2707
Validation loss decreased (0.195864 --> 0.195615).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1380229
	speed: 0.0136s/iter; left time: 287.5651s
	iters: 200, epoch: 12 | loss: 3.1585910
	speed: 0.0114s/iter; left time: 240.1782s
Epoch: 12 cost time: 2.954087018966675
Epoch: 12, Steps: 239 Train Loss: 3.1272 (Forecasting Loss:0.2638 + XiCon Loss:2.8634 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.2707
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1399002
	speed: 0.0138s/iter; left time: 288.7697s
	iters: 200, epoch: 13 | loss: 3.0835123
	speed: 0.0108s/iter; left time: 225.1050s
Epoch: 13 cost time: 2.8920788764953613
Epoch: 13, Steps: 239 Train Loss: 3.1263 (Forecasting Loss:0.2637 + XiCon Loss:2.8625 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2707
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.0918190
	speed: 0.0138s/iter; left time: 285.0691s
	iters: 200, epoch: 14 | loss: 3.1143870
	speed: 0.0115s/iter; left time: 235.8366s
Epoch: 14 cost time: 2.96875
Epoch: 14, Steps: 239 Train Loss: 3.1267 (Forecasting Loss:0.2637 + XiCon Loss:2.8630 x Lambda(1.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.2707
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1420925
	speed: 0.0140s/iter; left time: 287.3780s
	iters: 200, epoch: 15 | loss: 3.1653678
	speed: 0.0110s/iter; left time: 224.3666s
Epoch: 15 cost time: 2.951620578765869
Epoch: 15, Steps: 239 Train Loss: 3.1271 (Forecasting Loss:0.2637 + XiCon Loss:2.8634 x Lambda(1.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.2707
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1227329
	speed: 0.0140s/iter; left time: 283.9133s
	iters: 200, epoch: 16 | loss: 3.1274276
	speed: 0.0110s/iter; left time: 221.8145s
Epoch: 16 cost time: 3.003387451171875
Epoch: 16, Steps: 239 Train Loss: 3.1253 (Forecasting Loss:0.2635 + XiCon Loss:2.8618 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.2707
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0699701
	speed: 0.0134s/iter; left time: 268.2027s
	iters: 200, epoch: 17 | loss: 3.1386156
	speed: 0.0119s/iter; left time: 235.6807s
Epoch: 17 cost time: 3.0529186725616455
Epoch: 17, Steps: 239 Train Loss: 3.1279 (Forecasting Loss:0.2633 + XiCon Loss:2.8646 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.2707
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.0917456
	speed: 0.0130s/iter; left time: 257.1222s
	iters: 200, epoch: 18 | loss: 3.1558433
	speed: 0.0111s/iter; left time: 218.2336s
Epoch: 18 cost time: 2.930034875869751
Epoch: 18, Steps: 239 Train Loss: 3.1260 (Forecasting Loss:0.2633 + XiCon Loss:2.8627 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2707
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0454776
	speed: 0.0136s/iter; left time: 264.5754s
	iters: 200, epoch: 19 | loss: 3.0948496
	speed: 0.0108s/iter; left time: 210.1159s
Epoch: 19 cost time: 2.882934331893921
Epoch: 19, Steps: 239 Train Loss: 3.1277 (Forecasting Loss:0.2639 + XiCon Loss:2.8639 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2707
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.0704679
	speed: 0.0132s/iter; left time: 254.9799s
	iters: 200, epoch: 20 | loss: 3.1662526
	speed: 0.0103s/iter; left time: 196.7743s
Epoch: 20 cost time: 2.8665547370910645
Epoch: 20, Steps: 239 Train Loss: 3.1249 (Forecasting Loss:0.2636 + XiCon Loss:2.8613 x Lambda(1.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.2707
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1067622
	speed: 0.0131s/iter; left time: 248.6798s
	iters: 200, epoch: 21 | loss: 3.1372933
	speed: 0.0121s/iter; left time: 228.9187s
Epoch: 21 cost time: 2.9884610176086426
Epoch: 21, Steps: 239 Train Loss: 3.1255 (Forecasting Loss:0.2636 + XiCon Loss:2.8620 x Lambda(1.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.2707
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21425147354602814, mae:0.327208548784256, mape:2.2956254482269287, mspe:2548.468505859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2287
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 3.7102709
	speed: 0.0130s/iter; left time: 309.6437s
	iters: 200, epoch: 1 | loss: 3.5819659
	speed: 0.0097s/iter; left time: 230.9610s
Epoch: 1 cost time: 2.7694356441497803
Epoch: 1, Steps: 239 Train Loss: 3.6900 (Forecasting Loss:0.6348 + XiCon Loss:3.0551 x Lambda(1.0)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.4489
Validation loss decreased (inf --> 0.331271).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2284179
	speed: 0.0141s/iter; left time: 331.2822s
	iters: 200, epoch: 2 | loss: 3.2356098
	speed: 0.0123s/iter; left time: 288.8447s
Epoch: 2 cost time: 3.164365530014038
Epoch: 2, Steps: 239 Train Loss: 3.2368 (Forecasting Loss:0.3174 + XiCon Loss:2.9194 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.2862
Validation loss decreased (0.331271 --> 0.209650).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2201629
	speed: 0.0138s/iter; left time: 322.6542s
	iters: 200, epoch: 3 | loss: 3.1719682
	speed: 0.0106s/iter; left time: 245.0599s
Epoch: 3 cost time: 2.957482099533081
Epoch: 3, Steps: 239 Train Loss: 3.1523 (Forecasting Loss:0.2819 + XiCon Loss:2.8704 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.2737
Validation loss decreased (0.209650 --> 0.199965).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1429229
	speed: 0.0130s/iter; left time: 300.2819s
	iters: 200, epoch: 4 | loss: 3.1117930
	speed: 0.0112s/iter; left time: 257.6423s
Epoch: 4 cost time: 2.9110805988311768
Epoch: 4, Steps: 239 Train Loss: 3.1375 (Forecasting Loss:0.2741 + XiCon Loss:2.8634 x Lambda(1.0)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.2691
Validation loss decreased (0.199965 --> 0.198135).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2052584
	speed: 0.0143s/iter; left time: 327.1209s
	iters: 200, epoch: 5 | loss: 3.1162517
	speed: 0.0106s/iter; left time: 241.0318s
Epoch: 5 cost time: 2.9960668087005615
Epoch: 5, Steps: 239 Train Loss: 3.1308 (Forecasting Loss:0.2707 + XiCon Loss:2.8601 x Lambda(1.0)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.2684
Validation loss decreased (0.198135 --> 0.196693).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1450274
	speed: 0.0135s/iter; left time: 305.2054s
	iters: 200, epoch: 6 | loss: 3.1154149
	speed: 0.0112s/iter; left time: 252.3262s
Epoch: 6 cost time: 2.9140923023223877
Epoch: 6, Steps: 239 Train Loss: 3.1307 (Forecasting Loss:0.2692 + XiCon Loss:2.8614 x Lambda(1.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.2671
Validation loss decreased (0.196693 --> 0.195774).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1685851
	speed: 0.0131s/iter; left time: 293.7891s
	iters: 200, epoch: 7 | loss: 3.0819800
	speed: 0.0110s/iter; left time: 243.8668s
Epoch: 7 cost time: 2.883176803588867
Epoch: 7, Steps: 239 Train Loss: 3.1285 (Forecasting Loss:0.2681 + XiCon Loss:2.8604 x Lambda(1.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2667
Validation loss decreased (0.195774 --> 0.195172).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1139348
	speed: 0.0131s/iter; left time: 290.0477s
	iters: 200, epoch: 8 | loss: 3.1217132
	speed: 0.0112s/iter; left time: 246.0616s
Epoch: 8 cost time: 2.9859821796417236
Epoch: 8, Steps: 239 Train Loss: 3.1265 (Forecasting Loss:0.2672 + XiCon Loss:2.8593 x Lambda(1.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.2667
Validation loss decreased (0.195172 --> 0.195108).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1230421
	speed: 0.0140s/iter; left time: 305.6653s
	iters: 200, epoch: 9 | loss: 3.1363316
	speed: 0.0109s/iter; left time: 236.4512s
Epoch: 9 cost time: 2.974104404449463
Epoch: 9, Steps: 239 Train Loss: 3.1264 (Forecasting Loss:0.2677 + XiCon Loss:2.8587 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2665
Validation loss decreased (0.195108 --> 0.194718).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1061871
	speed: 0.0141s/iter; left time: 304.8991s
	iters: 200, epoch: 10 | loss: 3.1129847
	speed: 0.0111s/iter; left time: 239.8304s
Epoch: 10 cost time: 2.978572130203247
Epoch: 10, Steps: 239 Train Loss: 3.1282 (Forecasting Loss:0.2674 + XiCon Loss:2.8607 x Lambda(1.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1208560
	speed: 0.0129s/iter; left time: 275.8712s
	iters: 200, epoch: 11 | loss: 3.1576540
	speed: 0.0115s/iter; left time: 245.9940s
Epoch: 11 cost time: 2.9295032024383545
Epoch: 11, Steps: 239 Train Loss: 3.1286 (Forecasting Loss:0.2673 + XiCon Loss:2.8614 x Lambda(1.0)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1645727
	speed: 0.0133s/iter; left time: 281.0368s
	iters: 200, epoch: 12 | loss: 3.0784707
	speed: 0.0110s/iter; left time: 231.8372s
Epoch: 12 cost time: 2.8930346965789795
Epoch: 12, Steps: 239 Train Loss: 3.1268 (Forecasting Loss:0.2670 + XiCon Loss:2.8598 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
Validation loss decreased (0.194718 --> 0.194712).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1353834
	speed: 0.0142s/iter; left time: 296.6867s
	iters: 200, epoch: 13 | loss: 3.0841682
	speed: 0.0108s/iter; left time: 224.1373s
Epoch: 13 cost time: 2.9444053173065186
Epoch: 13, Steps: 239 Train Loss: 3.1276 (Forecasting Loss:0.2672 + XiCon Loss:2.8604 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1323023
	speed: 0.0140s/iter; left time: 290.1687s
	iters: 200, epoch: 14 | loss: 3.1085086
	speed: 0.0118s/iter; left time: 242.0333s
Epoch: 14 cost time: 3.059520959854126
Epoch: 14, Steps: 239 Train Loss: 3.1262 (Forecasting Loss:0.2672 + XiCon Loss:2.8590 x Lambda(1.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1364048
	speed: 0.0131s/iter; left time: 268.5337s
	iters: 200, epoch: 15 | loss: 3.1113181
	speed: 0.0115s/iter; left time: 234.2727s
Epoch: 15 cost time: 2.906428337097168
Epoch: 15, Steps: 239 Train Loss: 3.1267 (Forecasting Loss:0.2674 + XiCon Loss:2.8593 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
Validation loss decreased (0.194712 --> 0.194691).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1118889
	speed: 0.0137s/iter; left time: 276.0233s
	iters: 200, epoch: 16 | loss: 3.1543639
	speed: 0.0112s/iter; left time: 226.1785s
Epoch: 16 cost time: 2.942969560623169
Epoch: 16, Steps: 239 Train Loss: 3.1242 (Forecasting Loss:0.2671 + XiCon Loss:2.8571 x Lambda(1.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1167195
	speed: 0.0129s/iter; left time: 257.6091s
	iters: 200, epoch: 17 | loss: 3.1701617
	speed: 0.0106s/iter; left time: 211.1840s
Epoch: 17 cost time: 2.7998456954956055
Epoch: 17, Steps: 239 Train Loss: 3.1267 (Forecasting Loss:0.2673 + XiCon Loss:2.8594 x Lambda(1.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1273007
	speed: 0.0140s/iter; left time: 276.1496s
	iters: 200, epoch: 18 | loss: 3.1292830
	speed: 0.0106s/iter; left time: 208.7316s
Epoch: 18 cost time: 2.924898386001587
Epoch: 18, Steps: 239 Train Loss: 3.1282 (Forecasting Loss:0.2670 + XiCon Loss:2.8612 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2664
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0491567
	speed: 0.0135s/iter; left time: 262.5344s
	iters: 200, epoch: 19 | loss: 3.1854198
	speed: 0.0108s/iter; left time: 210.3863s
Epoch: 19 cost time: 2.8773224353790283
Epoch: 19, Steps: 239 Train Loss: 3.1277 (Forecasting Loss:0.2671 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2664
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1189818
	speed: 0.0142s/iter; left time: 273.7835s
	iters: 200, epoch: 20 | loss: 3.0803425
	speed: 0.0113s/iter; left time: 216.1366s
Epoch: 20 cost time: 3.022775650024414
Epoch: 20, Steps: 239 Train Loss: 3.1269 (Forecasting Loss:0.2675 + XiCon Loss:2.8594 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
Validation loss decreased (0.194691 --> 0.194659).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1586893
	speed: 0.0149s/iter; left time: 282.6142s
	iters: 200, epoch: 21 | loss: 3.0817432
	speed: 0.0114s/iter; left time: 216.1077s
Epoch: 21 cost time: 3.125628709793091
Epoch: 21, Steps: 239 Train Loss: 3.1252 (Forecasting Loss:0.2671 + XiCon Loss:2.8581 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1239667
	speed: 0.0134s/iter; left time: 251.4524s
	iters: 200, epoch: 22 | loss: 3.0737431
	speed: 0.0118s/iter; left time: 221.2514s
Epoch: 22 cost time: 2.983381986618042
Epoch: 22, Steps: 239 Train Loss: 3.1255 (Forecasting Loss:0.2673 + XiCon Loss:2.8582 x Lambda(1.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2664
Validation loss decreased (0.194659 --> 0.194606).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.0683265
	speed: 0.0145s/iter; left time: 268.1953s
	iters: 200, epoch: 23 | loss: 3.1016026
	speed: 0.0110s/iter; left time: 202.8021s
Epoch: 23 cost time: 3.0229594707489014
Epoch: 23, Steps: 239 Train Loss: 3.1296 (Forecasting Loss:0.2673 + XiCon Loss:2.8624 x Lambda(1.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.2664
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.1060610
	speed: 0.0135s/iter; left time: 247.6972s
	iters: 200, epoch: 24 | loss: 3.1289804
	speed: 0.0115s/iter; left time: 210.0174s
Epoch: 24 cost time: 2.977825164794922
Epoch: 24, Steps: 239 Train Loss: 3.1262 (Forecasting Loss:0.2670 + XiCon Loss:2.8592 x Lambda(1.0)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.1643877
	speed: 0.0143s/iter; left time: 258.5967s
	iters: 200, epoch: 25 | loss: 3.1687584
	speed: 0.0108s/iter; left time: 193.2876s
Epoch: 25 cost time: 3.02290415763855
Epoch: 25, Steps: 239 Train Loss: 3.1262 (Forecasting Loss:0.2672 + XiCon Loss:2.8590 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2664
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.1075542
	speed: 0.0133s/iter; left time: 236.2592s
	iters: 200, epoch: 26 | loss: 3.1046979
	speed: 0.0115s/iter; left time: 203.3742s
Epoch: 26 cost time: 2.956002712249756
Epoch: 26, Steps: 239 Train Loss: 3.1284 (Forecasting Loss:0.2670 + XiCon Loss:2.8614 x Lambda(1.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2664
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 3.1710863
	speed: 0.0133s/iter; left time: 233.6475s
	iters: 200, epoch: 27 | loss: 3.0750067
	speed: 0.0115s/iter; left time: 200.7917s
Epoch: 27 cost time: 2.9081263542175293
Epoch: 27, Steps: 239 Train Loss: 3.1287 (Forecasting Loss:0.2671 + XiCon Loss:2.8616 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 3.1289930
	speed: 0.0135s/iter; left time: 234.0656s
	iters: 200, epoch: 28 | loss: 3.1033742
	speed: 0.0107s/iter; left time: 184.2263s
Epoch: 28 cost time: 2.915539026260376
Epoch: 28, Steps: 239 Train Loss: 3.1258 (Forecasting Loss:0.2672 + XiCon Loss:2.8586 x Lambda(1.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.2664
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 3.0875254
	speed: 0.0136s/iter; left time: 232.8352s
	iters: 200, epoch: 29 | loss: 3.1948938
	speed: 0.0106s/iter; left time: 180.5093s
Epoch: 29 cost time: 2.8489670753479004
Epoch: 29, Steps: 239 Train Loss: 3.1276 (Forecasting Loss:0.2670 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2664
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 3.0927308
	speed: 0.0147s/iter; left time: 248.2157s
	iters: 200, epoch: 30 | loss: 3.1189494
	speed: 0.0106s/iter; left time: 177.1045s
Epoch: 30 cost time: 2.9580721855163574
Epoch: 30, Steps: 239 Train Loss: 3.1257 (Forecasting Loss:0.2671 + XiCon Loss:2.8585 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 3.0595987
	speed: 0.0132s/iter; left time: 220.2056s
	iters: 200, epoch: 31 | loss: 3.1600254
	speed: 0.0108s/iter; left time: 178.1868s
Epoch: 31 cost time: 2.9092509746551514
Epoch: 31, Steps: 239 Train Loss: 3.1277 (Forecasting Loss:0.2675 + XiCon Loss:2.8602 x Lambda(1.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2664
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 3.1315575
	speed: 0.0135s/iter; left time: 221.6324s
	iters: 200, epoch: 32 | loss: 3.1102493
	speed: 0.0109s/iter; left time: 177.4903s
Epoch: 32 cost time: 2.8609769344329834
Epoch: 32, Steps: 239 Train Loss: 3.1258 (Forecasting Loss:0.2674 + XiCon Loss:2.8584 x Lambda(1.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2664
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20981380343437195, mae:0.3229467272758484, mape:2.5465569496154785, mspe:4476.4677734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2527
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 3.7234201
	speed: 0.0143s/iter; left time: 339.4051s
	iters: 200, epoch: 1 | loss: 3.5526152
	speed: 0.0113s/iter; left time: 268.9116s
Epoch: 1 cost time: 3.0120773315429688
Epoch: 1, Steps: 239 Train Loss: 3.6798 (Forecasting Loss:0.6360 + XiCon Loss:3.0438 x Lambda(1.0)), Vali MSE Loss: 0.3299 Test MSE Loss: 0.4466
Validation loss decreased (inf --> 0.329877).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1673398
	speed: 0.0142s/iter; left time: 334.6081s
	iters: 200, epoch: 2 | loss: 3.2513568
	speed: 0.0109s/iter; left time: 255.6500s
Epoch: 2 cost time: 2.9738924503326416
Epoch: 2, Steps: 239 Train Loss: 3.2379 (Forecasting Loss:0.3120 + XiCon Loss:2.9259 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.2807
Validation loss decreased (0.329877 --> 0.211949).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1465440
	speed: 0.0134s/iter; left time: 313.2535s
	iters: 200, epoch: 3 | loss: 3.0991955
	speed: 0.0111s/iter; left time: 256.8649s
Epoch: 3 cost time: 2.8913283348083496
Epoch: 3, Steps: 239 Train Loss: 3.1446 (Forecasting Loss:0.2712 + XiCon Loss:2.8733 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.2668
Validation loss decreased (0.211949 --> 0.202291).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1529059
	speed: 0.0142s/iter; left time: 328.0081s
	iters: 200, epoch: 4 | loss: 3.0681093
	speed: 0.0113s/iter; left time: 259.1921s
Epoch: 4 cost time: 3.0297420024871826
Epoch: 4, Steps: 239 Train Loss: 3.1320 (Forecasting Loss:0.2649 + XiCon Loss:2.8671 x Lambda(1.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.2677
Validation loss decreased (0.202291 --> 0.201139).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1566858
	speed: 0.0136s/iter; left time: 311.6494s
	iters: 200, epoch: 5 | loss: 3.1640856
	speed: 0.0105s/iter; left time: 239.4918s
Epoch: 5 cost time: 2.895038604736328
Epoch: 5, Steps: 239 Train Loss: 3.1243 (Forecasting Loss:0.2614 + XiCon Loss:2.8629 x Lambda(1.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.2647
Validation loss decreased (0.201139 --> 0.199573).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1663437
	speed: 0.0134s/iter; left time: 303.3227s
	iters: 200, epoch: 6 | loss: 3.1056526
	speed: 0.0109s/iter; left time: 244.6497s
Epoch: 6 cost time: 2.867170572280884
Epoch: 6, Steps: 239 Train Loss: 3.1244 (Forecasting Loss:0.2602 + XiCon Loss:2.8642 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.2621
Validation loss decreased (0.199573 --> 0.197843).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1260252
	speed: 0.0136s/iter; left time: 305.2596s
	iters: 200, epoch: 7 | loss: 3.0796931
	speed: 0.0108s/iter; left time: 241.5518s
Epoch: 7 cost time: 2.886366605758667
Epoch: 7, Steps: 239 Train Loss: 3.1193 (Forecasting Loss:0.2593 + XiCon Loss:2.8600 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.2633
Validation loss decreased (0.197843 --> 0.197812).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1620250
	speed: 0.0137s/iter; left time: 303.6610s
	iters: 200, epoch: 8 | loss: 3.1225944
	speed: 0.0109s/iter; left time: 240.7681s
Epoch: 8 cost time: 2.9784786701202393
Epoch: 8, Steps: 239 Train Loss: 3.1170 (Forecasting Loss:0.2592 + XiCon Loss:2.8578 x Lambda(1.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.2636
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.0956078
	speed: 0.0135s/iter; left time: 295.4526s
	iters: 200, epoch: 9 | loss: 3.1287260
	speed: 0.0116s/iter; left time: 252.6832s
Epoch: 9 cost time: 2.954240083694458
Epoch: 9, Steps: 239 Train Loss: 3.1187 (Forecasting Loss:0.2586 + XiCon Loss:2.8601 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.2627
Validation loss decreased (0.197812 --> 0.197717).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1215491
	speed: 0.0134s/iter; left time: 291.0932s
	iters: 200, epoch: 10 | loss: 3.0374217
	speed: 0.0105s/iter; left time: 225.9364s
Epoch: 10 cost time: 2.86143159866333
Epoch: 10, Steps: 239 Train Loss: 3.1173 (Forecasting Loss:0.2586 + XiCon Loss:2.8588 x Lambda(1.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.2628
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0956304
	speed: 0.0143s/iter; left time: 306.7628s
	iters: 200, epoch: 11 | loss: 3.1386201
	speed: 0.0114s/iter; left time: 242.9465s
Epoch: 11 cost time: 3.0165345668792725
Epoch: 11, Steps: 239 Train Loss: 3.1194 (Forecasting Loss:0.2585 + XiCon Loss:2.8609 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.2628
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0816844
	speed: 0.0141s/iter; left time: 298.8842s
	iters: 200, epoch: 12 | loss: 3.0997906
	speed: 0.0116s/iter; left time: 243.5237s
Epoch: 12 cost time: 3.0414175987243652
Epoch: 12, Steps: 239 Train Loss: 3.1174 (Forecasting Loss:0.2583 + XiCon Loss:2.8591 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2628
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1481686
	speed: 0.0131s/iter; left time: 273.4398s
	iters: 200, epoch: 13 | loss: 3.1301103
	speed: 0.0107s/iter; left time: 223.0670s
Epoch: 13 cost time: 2.814202308654785
Epoch: 13, Steps: 239 Train Loss: 3.1187 (Forecasting Loss:0.2582 + XiCon Loss:2.8605 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.2628
Validation loss decreased (0.197717 --> 0.197673).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1455872
	speed: 0.0135s/iter; left time: 278.4243s
	iters: 200, epoch: 14 | loss: 3.1039979
	speed: 0.0112s/iter; left time: 229.7517s
Epoch: 14 cost time: 2.927568197250366
Epoch: 14, Steps: 239 Train Loss: 3.1194 (Forecasting Loss:0.2583 + XiCon Loss:2.8610 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.2628
Validation loss decreased (0.197673 --> 0.197660).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1042337
	speed: 0.0136s/iter; left time: 278.1536s
	iters: 200, epoch: 15 | loss: 3.1898477
	speed: 0.0114s/iter; left time: 231.2226s
Epoch: 15 cost time: 2.9314277172088623
Epoch: 15, Steps: 239 Train Loss: 3.1195 (Forecasting Loss:0.2582 + XiCon Loss:2.8612 x Lambda(1.0)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.2628
Validation loss decreased (0.197660 --> 0.197328).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1412001
	speed: 0.0136s/iter; left time: 274.1254s
	iters: 200, epoch: 16 | loss: 3.1936204
	speed: 0.0104s/iter; left time: 209.7554s
Epoch: 16 cost time: 2.8347675800323486
Epoch: 16, Steps: 239 Train Loss: 3.1181 (Forecasting Loss:0.2581 + XiCon Loss:2.8600 x Lambda(1.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.2628
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1115885
	speed: 0.0140s/iter; left time: 279.5005s
	iters: 200, epoch: 17 | loss: 3.1177728
	speed: 0.0105s/iter; left time: 209.3313s
Epoch: 17 cost time: 2.950120210647583
Epoch: 17, Steps: 239 Train Loss: 3.1210 (Forecasting Loss:0.2585 + XiCon Loss:2.8625 x Lambda(1.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.2628
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1072011
	speed: 0.0129s/iter; left time: 255.3144s
	iters: 200, epoch: 18 | loss: 3.1328430
	speed: 0.0103s/iter; left time: 202.5364s
Epoch: 18 cost time: 2.766274929046631
Epoch: 18, Steps: 239 Train Loss: 3.1174 (Forecasting Loss:0.2583 + XiCon Loss:2.8590 x Lambda(1.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.2628
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.1308043
	speed: 0.0137s/iter; left time: 267.9532s
	iters: 200, epoch: 19 | loss: 3.1592495
	speed: 0.0110s/iter; left time: 213.0992s
Epoch: 19 cost time: 2.9727180004119873
Epoch: 19, Steps: 239 Train Loss: 3.1193 (Forecasting Loss:0.2583 + XiCon Loss:2.8610 x Lambda(1.0)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.2628
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1021981
	speed: 0.0138s/iter; left time: 265.7606s
	iters: 200, epoch: 20 | loss: 3.1765008
	speed: 0.0107s/iter; left time: 205.3135s
Epoch: 20 cost time: 2.8986165523529053
Epoch: 20, Steps: 239 Train Loss: 3.1150 (Forecasting Loss:0.2585 + XiCon Loss:2.8565 x Lambda(1.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.2628
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1540000
	speed: 0.0137s/iter; left time: 260.0097s
	iters: 200, epoch: 21 | loss: 3.0687382
	speed: 0.0117s/iter; left time: 221.8650s
Epoch: 21 cost time: 3.022345542907715
Epoch: 21, Steps: 239 Train Loss: 3.1192 (Forecasting Loss:0.2584 + XiCon Loss:2.8608 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.2628
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1032145
	speed: 0.0139s/iter; left time: 261.0563s
	iters: 200, epoch: 22 | loss: 3.1033986
	speed: 0.0106s/iter; left time: 198.0703s
Epoch: 22 cost time: 2.939973831176758
Epoch: 22, Steps: 239 Train Loss: 3.1193 (Forecasting Loss:0.2584 + XiCon Loss:2.8609 x Lambda(1.0)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.2628
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.0648932
	speed: 0.0135s/iter; left time: 250.1311s
	iters: 200, epoch: 23 | loss: 3.1181607
	speed: 0.0106s/iter; left time: 194.7714s
Epoch: 23 cost time: 2.8716466426849365
Epoch: 23, Steps: 239 Train Loss: 3.1184 (Forecasting Loss:0.2585 + XiCon Loss:2.8599 x Lambda(1.0)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.2628
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.0923796
	speed: 0.0134s/iter; left time: 244.5983s
	iters: 200, epoch: 24 | loss: 3.0980833
	speed: 0.0109s/iter; left time: 197.8622s
Epoch: 24 cost time: 2.871274948120117
Epoch: 24, Steps: 239 Train Loss: 3.1205 (Forecasting Loss:0.2584 + XiCon Loss:2.8621 x Lambda(1.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.2628
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.1297584
	speed: 0.0132s/iter; left time: 238.3249s
	iters: 200, epoch: 25 | loss: 3.1275582
	speed: 0.0105s/iter; left time: 188.4179s
Epoch: 25 cost time: 2.795492649078369
Epoch: 25, Steps: 239 Train Loss: 3.1185 (Forecasting Loss:0.2586 + XiCon Loss:2.8599 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2628
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20308485627174377, mae:0.3225591778755188, mape:2.7015068531036377, mspe:5709.74365234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2098+-0.00523, MAE:0.3243+-0.00250, MAPE:2.4342+-0.22765, MSPE:3668.4929+-1710.22801, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2111
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6911650
	speed: 0.0177s/iter; left time: 406.1298s
	iters: 200, epoch: 1 | loss: 3.5976229
	speed: 0.0131s/iter; left time: 299.5580s
Epoch: 1 cost time: 3.4755311012268066
Epoch: 1, Steps: 230 Train Loss: 3.6710 (Forecasting Loss:0.7227 + XiCon Loss:2.9483 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.5301
Validation loss decreased (inf --> 0.330920).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1948469
	speed: 0.0146s/iter; left time: 330.5488s
	iters: 200, epoch: 2 | loss: 3.1336312
	speed: 0.0131s/iter; left time: 296.5373s
Epoch: 2 cost time: 3.178673028945923
Epoch: 2, Steps: 230 Train Loss: 3.2679 (Forecasting Loss:0.4231 + XiCon Loss:2.8447 x Lambda(1.0)), Vali MSE Loss: 0.2160 Test MSE Loss: 0.3764
Validation loss decreased (0.330920 --> 0.216034).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1627738
	speed: 0.0155s/iter; left time: 348.8253s
	iters: 200, epoch: 3 | loss: 3.1498773
	speed: 0.0127s/iter; left time: 284.6603s
Epoch: 3 cost time: 3.2991836071014404
Epoch: 3, Steps: 230 Train Loss: 3.1536 (Forecasting Loss:0.3799 + XiCon Loss:2.7738 x Lambda(1.0)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.3659
Validation loss decreased (0.216034 --> 0.205591).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1181986
	speed: 0.0150s/iter; left time: 332.9042s
	iters: 200, epoch: 4 | loss: 3.1437955
	speed: 0.0126s/iter; left time: 279.1993s
Epoch: 4 cost time: 3.1633055210113525
Epoch: 4, Steps: 230 Train Loss: 3.1348 (Forecasting Loss:0.3715 + XiCon Loss:2.7633 x Lambda(1.0)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.3620
Validation loss decreased (0.205591 --> 0.203771).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2079961
	speed: 0.0154s/iter; left time: 338.3004s
	iters: 200, epoch: 5 | loss: 3.1187186
	speed: 0.0131s/iter; left time: 286.5297s
Epoch: 5 cost time: 3.2513198852539062
Epoch: 5, Steps: 230 Train Loss: 3.1292 (Forecasting Loss:0.3682 + XiCon Loss:2.7610 x Lambda(1.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.3617
Validation loss decreased (0.203771 --> 0.203225).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1668117
	speed: 0.0154s/iter; left time: 335.5886s
	iters: 200, epoch: 6 | loss: 3.1497085
	speed: 0.0125s/iter; left time: 271.7046s
Epoch: 6 cost time: 3.207153797149658
Epoch: 6, Steps: 230 Train Loss: 3.1267 (Forecasting Loss:0.3664 + XiCon Loss:2.7602 x Lambda(1.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.3598
Validation loss decreased (0.203225 --> 0.202685).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1566236
	speed: 0.0153s/iter; left time: 330.1456s
	iters: 200, epoch: 7 | loss: 3.1298914
	speed: 0.0127s/iter; left time: 273.0137s
Epoch: 7 cost time: 3.203219175338745
Epoch: 7, Steps: 230 Train Loss: 3.1241 (Forecasting Loss:0.3654 + XiCon Loss:2.7587 x Lambda(1.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.3587
Validation loss decreased (0.202685 --> 0.202574).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1818550
	speed: 0.0151s/iter; left time: 320.8465s
	iters: 200, epoch: 8 | loss: 3.1403177
	speed: 0.0129s/iter; left time: 273.4083s
Epoch: 8 cost time: 3.2112884521484375
Epoch: 8, Steps: 230 Train Loss: 3.1254 (Forecasting Loss:0.3647 + XiCon Loss:2.7607 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.3580
Validation loss decreased (0.202574 --> 0.202294).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1087883
	speed: 0.0160s/iter; left time: 336.3667s
	iters: 200, epoch: 9 | loss: 3.1446676
	speed: 0.0135s/iter; left time: 282.1221s
Epoch: 9 cost time: 3.3628950119018555
Epoch: 9, Steps: 230 Train Loss: 3.1225 (Forecasting Loss:0.3645 + XiCon Loss:2.7580 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3581
Validation loss decreased (0.202294 --> 0.202097).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0954149
	speed: 0.0152s/iter; left time: 315.9691s
	iters: 200, epoch: 10 | loss: 3.1616859
	speed: 0.0132s/iter; left time: 272.9380s
Epoch: 10 cost time: 3.2476646900177
Epoch: 10, Steps: 230 Train Loss: 3.1221 (Forecasting Loss:0.3643 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3581
Validation loss decreased (0.202097 --> 0.202032).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0707772
	speed: 0.0158s/iter; left time: 325.8067s
	iters: 200, epoch: 11 | loss: 3.1162748
	speed: 0.0130s/iter; left time: 265.6263s
Epoch: 11 cost time: 3.2767653465270996
Epoch: 11, Steps: 230 Train Loss: 3.1202 (Forecasting Loss:0.3639 + XiCon Loss:2.7563 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3580
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0976906
	speed: 0.0149s/iter; left time: 303.2506s
	iters: 200, epoch: 12 | loss: 3.1341913
	speed: 0.0126s/iter; left time: 256.1386s
Epoch: 12 cost time: 3.1809916496276855
Epoch: 12, Steps: 230 Train Loss: 3.1247 (Forecasting Loss:0.3652 + XiCon Loss:2.7596 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1034019
	speed: 0.0163s/iter; left time: 329.1192s
	iters: 200, epoch: 13 | loss: 3.0849817
	speed: 0.0137s/iter; left time: 274.1661s
Epoch: 13 cost time: 3.4554457664489746
Epoch: 13, Steps: 230 Train Loss: 3.1197 (Forecasting Loss:0.3646 + XiCon Loss:2.7551 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1265194
	speed: 0.0154s/iter; left time: 306.0631s
	iters: 200, epoch: 14 | loss: 3.1247826
	speed: 0.0132s/iter; left time: 261.5958s
Epoch: 14 cost time: 3.2574174404144287
Epoch: 14, Steps: 230 Train Loss: 3.1218 (Forecasting Loss:0.3640 + XiCon Loss:2.7577 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1413593
	speed: 0.0155s/iter; left time: 306.0274s
	iters: 200, epoch: 15 | loss: 3.0918946
	speed: 0.0125s/iter; left time: 245.0221s
Epoch: 15 cost time: 3.2275142669677734
Epoch: 15, Steps: 230 Train Loss: 3.1227 (Forecasting Loss:0.3646 + XiCon Loss:2.7581 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3580
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1228478
	speed: 0.0154s/iter; left time: 299.6315s
	iters: 200, epoch: 16 | loss: 3.1007171
	speed: 0.0130s/iter; left time: 252.0301s
Epoch: 16 cost time: 3.2396414279937744
Epoch: 16, Steps: 230 Train Loss: 3.1207 (Forecasting Loss:0.3646 + XiCon Loss:2.7562 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3580
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0835204
	speed: 0.0166s/iter; left time: 319.7631s
	iters: 200, epoch: 17 | loss: 3.1127582
	speed: 0.0133s/iter; left time: 253.8676s
Epoch: 17 cost time: 3.4090147018432617
Epoch: 17, Steps: 230 Train Loss: 3.1229 (Forecasting Loss:0.3641 + XiCon Loss:2.7588 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.0950279
	speed: 0.0155s/iter; left time: 294.9520s
	iters: 200, epoch: 18 | loss: 3.1728270
	speed: 0.0140s/iter; left time: 265.3414s
Epoch: 18 cost time: 3.396939754486084
Epoch: 18, Steps: 230 Train Loss: 3.1222 (Forecasting Loss:0.3640 + XiCon Loss:2.7583 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3580
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0791676
	speed: 0.0154s/iter; left time: 288.2833s
	iters: 200, epoch: 19 | loss: 3.1079245
	speed: 0.0138s/iter; left time: 257.7070s
Epoch: 19 cost time: 3.376659631729126
Epoch: 19, Steps: 230 Train Loss: 3.1219 (Forecasting Loss:0.3644 + XiCon Loss:2.7576 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.0858171
	speed: 0.0155s/iter; left time: 286.3384s
	iters: 200, epoch: 20 | loss: 3.1622450
	speed: 0.0132s/iter; left time: 243.3318s
Epoch: 20 cost time: 3.3184804916381836
Epoch: 20, Steps: 230 Train Loss: 3.1243 (Forecasting Loss:0.3644 + XiCon Loss:2.7599 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.30785536766052246, mae:0.40825504064559937, mape:4.2697343826293945, mspe:28482.875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2805
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.7648876
	speed: 0.0159s/iter; left time: 365.1752s
	iters: 200, epoch: 1 | loss: 3.5402246
	speed: 0.0127s/iter; left time: 289.9141s
Epoch: 1 cost time: 3.2720603942871094
Epoch: 1, Steps: 230 Train Loss: 3.6974 (Forecasting Loss:0.7213 + XiCon Loss:2.9761 x Lambda(1.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.5349
Validation loss decreased (inf --> 0.328931).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3119864
	speed: 0.0154s/iter; left time: 350.2551s
	iters: 200, epoch: 2 | loss: 3.1816170
	speed: 0.0132s/iter; left time: 298.1089s
Epoch: 2 cost time: 3.3302571773529053
Epoch: 2, Steps: 230 Train Loss: 3.2730 (Forecasting Loss:0.4222 + XiCon Loss:2.8509 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.3641
Validation loss decreased (0.328931 --> 0.213139).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1598043
	speed: 0.0157s/iter; left time: 353.1795s
	iters: 200, epoch: 3 | loss: 3.1834557
	speed: 0.0127s/iter; left time: 284.6464s
Epoch: 3 cost time: 3.2502949237823486
Epoch: 3, Steps: 230 Train Loss: 3.1537 (Forecasting Loss:0.3755 + XiCon Loss:2.7782 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.3547
Validation loss decreased (0.213139 --> 0.206394).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1653488
	speed: 0.0150s/iter; left time: 333.8889s
	iters: 200, epoch: 4 | loss: 3.1734526
	speed: 0.0133s/iter; left time: 294.0996s
Epoch: 4 cost time: 3.2456016540527344
Epoch: 4, Steps: 230 Train Loss: 3.1383 (Forecasting Loss:0.3667 + XiCon Loss:2.7716 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.3507
Validation loss decreased (0.206394 --> 0.204687).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1186779
	speed: 0.0160s/iter; left time: 351.9888s
	iters: 200, epoch: 5 | loss: 3.0815594
	speed: 0.0127s/iter; left time: 277.6232s
Epoch: 5 cost time: 3.291931629180908
Epoch: 5, Steps: 230 Train Loss: 3.1314 (Forecasting Loss:0.3628 + XiCon Loss:2.7686 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3484
Validation loss decreased (0.204687 --> 0.204199).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1203043
	speed: 0.0161s/iter; left time: 349.7746s
	iters: 200, epoch: 6 | loss: 3.1073718
	speed: 0.0137s/iter; left time: 295.8531s
Epoch: 6 cost time: 3.3874318599700928
Epoch: 6, Steps: 230 Train Loss: 3.1280 (Forecasting Loss:0.3601 + XiCon Loss:2.7679 x Lambda(1.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.3472
Validation loss decreased (0.204199 --> 0.203571).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1361644
	speed: 0.0146s/iter; left time: 313.9539s
	iters: 200, epoch: 7 | loss: 3.1637356
	speed: 0.0139s/iter; left time: 298.7212s
Epoch: 7 cost time: 3.268005847930908
Epoch: 7, Steps: 230 Train Loss: 3.1257 (Forecasting Loss:0.3594 + XiCon Loss:2.7664 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.3477
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1281879
	speed: 0.0156s/iter; left time: 332.8874s
	iters: 200, epoch: 8 | loss: 3.1427236
	speed: 0.0123s/iter; left time: 261.5867s
Epoch: 8 cost time: 3.249156951904297
Epoch: 8, Steps: 230 Train Loss: 3.1248 (Forecasting Loss:0.3586 + XiCon Loss:2.7662 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.3477
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1035516
	speed: 0.0157s/iter; left time: 331.3371s
	iters: 200, epoch: 9 | loss: 3.0843682
	speed: 0.0132s/iter; left time: 276.5162s
Epoch: 9 cost time: 3.300929307937622
Epoch: 9, Steps: 230 Train Loss: 3.1221 (Forecasting Loss:0.3584 + XiCon Loss:2.7638 x Lambda(1.0)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.3473
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0670805
	speed: 0.0153s/iter; left time: 319.3340s
	iters: 200, epoch: 10 | loss: 3.1178436
	speed: 0.0130s/iter; left time: 269.2754s
Epoch: 10 cost time: 3.2446229457855225
Epoch: 10, Steps: 230 Train Loss: 3.1191 (Forecasting Loss:0.3584 + XiCon Loss:2.7606 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3471
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1164474
	speed: 0.0160s/iter; left time: 328.6852s
	iters: 200, epoch: 11 | loss: 3.1702163
	speed: 0.0130s/iter; left time: 266.7370s
Epoch: 11 cost time: 3.3024802207946777
Epoch: 11, Steps: 230 Train Loss: 3.1205 (Forecasting Loss:0.3577 + XiCon Loss:2.7627 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.3471
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1446753
	speed: 0.0151s/iter; left time: 306.7756s
	iters: 200, epoch: 12 | loss: 3.1274981
	speed: 0.0132s/iter; left time: 268.3586s
Epoch: 12 cost time: 3.233509063720703
Epoch: 12, Steps: 230 Train Loss: 3.1217 (Forecasting Loss:0.3583 + XiCon Loss:2.7634 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.3471
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1183507
	speed: 0.0156s/iter; left time: 314.0355s
	iters: 200, epoch: 13 | loss: 3.1441221
	speed: 0.0130s/iter; left time: 260.8388s
Epoch: 13 cost time: 3.2638814449310303
Epoch: 13, Steps: 230 Train Loss: 3.1222 (Forecasting Loss:0.3581 + XiCon Loss:2.7641 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3471
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1066236
	speed: 0.0150s/iter; left time: 299.4733s
	iters: 200, epoch: 14 | loss: 3.1112547
	speed: 0.0136s/iter; left time: 269.4081s
Epoch: 14 cost time: 3.2790658473968506
Epoch: 14, Steps: 230 Train Loss: 3.1227 (Forecasting Loss:0.3582 + XiCon Loss:2.7644 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.3471
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1208234
	speed: 0.0153s/iter; left time: 300.5290s
	iters: 200, epoch: 15 | loss: 3.1780429
	speed: 0.0125s/iter; left time: 244.2816s
Epoch: 15 cost time: 3.1765401363372803
Epoch: 15, Steps: 230 Train Loss: 3.1238 (Forecasting Loss:0.3584 + XiCon Loss:2.7653 x Lambda(1.0)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.3471
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1684680
	speed: 0.0159s/iter; left time: 309.8224s
	iters: 200, epoch: 16 | loss: 3.0549331
	speed: 0.0132s/iter; left time: 255.1426s
Epoch: 16 cost time: 3.3353848457336426
Epoch: 16, Steps: 230 Train Loss: 3.1236 (Forecasting Loss:0.3584 + XiCon Loss:2.7652 x Lambda(1.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.3471
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.29474079608917236, mae:0.3997308313846588, mape:4.06890344619751, mspe:25983.01171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.3484
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.7361898
	speed: 0.0169s/iter; left time: 388.0551s
	iters: 200, epoch: 1 | loss: 3.5822380
	speed: 0.0126s/iter; left time: 286.4367s
Epoch: 1 cost time: 3.3574154376983643
Epoch: 1, Steps: 230 Train Loss: 3.6818 (Forecasting Loss:0.7257 + XiCon Loss:2.9562 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.5382
Validation loss decreased (inf --> 0.331612).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2464621
	speed: 0.0153s/iter; left time: 346.3838s
	iters: 200, epoch: 2 | loss: 3.1757452
	speed: 0.0126s/iter; left time: 284.5218s
Epoch: 2 cost time: 3.2311739921569824
Epoch: 2, Steps: 230 Train Loss: 3.2716 (Forecasting Loss:0.4349 + XiCon Loss:2.8366 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.3895
Validation loss decreased (0.331612 --> 0.220566).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1137180
	speed: 0.0157s/iter; left time: 352.2075s
	iters: 200, epoch: 3 | loss: 3.1515441
	speed: 0.0138s/iter; left time: 307.5544s
Epoch: 3 cost time: 3.3743369579315186
Epoch: 3, Steps: 230 Train Loss: 3.1647 (Forecasting Loss:0.3945 + XiCon Loss:2.7702 x Lambda(1.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.3802
Validation loss decreased (0.220566 --> 0.215711).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1680131
	speed: 0.0161s/iter; left time: 356.5477s
	iters: 200, epoch: 4 | loss: 3.1373136
	speed: 0.0128s/iter; left time: 283.3173s
Epoch: 4 cost time: 3.339787721633911
Epoch: 4, Steps: 230 Train Loss: 3.1432 (Forecasting Loss:0.3795 + XiCon Loss:2.7637 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3692
Validation loss decreased (0.215711 --> 0.210045).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1315417
	speed: 0.0157s/iter; left time: 344.6489s
	iters: 200, epoch: 5 | loss: 3.1552687
	speed: 0.0130s/iter; left time: 285.1402s
Epoch: 5 cost time: 3.2658746242523193
Epoch: 5, Steps: 230 Train Loss: 3.1329 (Forecasting Loss:0.3704 + XiCon Loss:2.7625 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.3695
Validation loss decreased (0.210045 --> 0.209578).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1334376
	speed: 0.0164s/iter; left time: 355.7995s
	iters: 200, epoch: 6 | loss: 3.1618032
	speed: 0.0125s/iter; left time: 270.0094s
Epoch: 6 cost time: 3.295531988143921
Epoch: 6, Steps: 230 Train Loss: 3.1311 (Forecasting Loss:0.3668 + XiCon Loss:2.7642 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.3672
Validation loss decreased (0.209578 --> 0.208887).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0909400
	speed: 0.0155s/iter; left time: 333.4836s
	iters: 200, epoch: 7 | loss: 3.1580002
	speed: 0.0134s/iter; left time: 287.2399s
Epoch: 7 cost time: 3.3046298027038574
Epoch: 7, Steps: 230 Train Loss: 3.1257 (Forecasting Loss:0.3657 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3671
Validation loss decreased (0.208887 --> 0.208623).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1399639
	speed: 0.0152s/iter; left time: 323.7409s
	iters: 200, epoch: 8 | loss: 3.0943522
	speed: 0.0128s/iter; left time: 271.2933s
Epoch: 8 cost time: 3.211099624633789
Epoch: 8, Steps: 230 Train Loss: 3.1247 (Forecasting Loss:0.3651 + XiCon Loss:2.7596 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3675
Validation loss decreased (0.208623 --> 0.208598).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1736040
	speed: 0.0153s/iter; left time: 322.5960s
	iters: 200, epoch: 9 | loss: 3.1681006
	speed: 0.0130s/iter; left time: 273.2994s
Epoch: 9 cost time: 3.237159490585327
Epoch: 9, Steps: 230 Train Loss: 3.1232 (Forecasting Loss:0.3650 + XiCon Loss:2.7582 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3676
Validation loss decreased (0.208598 --> 0.208549).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1415057
	speed: 0.0158s/iter; left time: 330.1071s
	iters: 200, epoch: 10 | loss: 3.1651962
	speed: 0.0125s/iter; left time: 259.3688s
Epoch: 10 cost time: 3.243030309677124
Epoch: 10, Steps: 230 Train Loss: 3.1252 (Forecasting Loss:0.3643 + XiCon Loss:2.7610 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.3675
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1266451
	speed: 0.0163s/iter; left time: 334.9629s
	iters: 200, epoch: 11 | loss: 3.1067922
	speed: 0.0132s/iter; left time: 269.5953s
Epoch: 11 cost time: 3.3369140625
Epoch: 11, Steps: 230 Train Loss: 3.1218 (Forecasting Loss:0.3642 + XiCon Loss:2.7575 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1801786
	speed: 0.0161s/iter; left time: 328.5791s
	iters: 200, epoch: 12 | loss: 3.1184843
	speed: 0.0131s/iter; left time: 265.5529s
Epoch: 12 cost time: 3.3507516384124756
Epoch: 12, Steps: 230 Train Loss: 3.1235 (Forecasting Loss:0.3645 + XiCon Loss:2.7590 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1298506
	speed: 0.0158s/iter; left time: 317.7332s
	iters: 200, epoch: 13 | loss: 3.1173975
	speed: 0.0126s/iter; left time: 252.9042s
Epoch: 13 cost time: 3.249950885772705
Epoch: 13, Steps: 230 Train Loss: 3.1244 (Forecasting Loss:0.3644 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3673
Validation loss decreased (0.208549 --> 0.208536).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1055639
	speed: 0.0153s/iter; left time: 304.9349s
	iters: 200, epoch: 14 | loss: 3.1109679
	speed: 0.0126s/iter; left time: 249.0878s
Epoch: 14 cost time: 3.2148125171661377
Epoch: 14, Steps: 230 Train Loss: 3.1229 (Forecasting Loss:0.3641 + XiCon Loss:2.7587 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3673
Validation loss decreased (0.208536 --> 0.208411).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1151917
	speed: 0.0163s/iter; left time: 320.0853s
	iters: 200, epoch: 15 | loss: 3.1181071
	speed: 0.0130s/iter; left time: 255.4497s
Epoch: 15 cost time: 3.352030038833618
Epoch: 15, Steps: 230 Train Loss: 3.1246 (Forecasting Loss:0.3638 + XiCon Loss:2.7609 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.0571420
	speed: 0.0168s/iter; left time: 326.4709s
	iters: 200, epoch: 16 | loss: 3.0666542
	speed: 0.0126s/iter; left time: 244.4687s
Epoch: 16 cost time: 3.3566391468048096
Epoch: 16, Steps: 230 Train Loss: 3.1228 (Forecasting Loss:0.3644 + XiCon Loss:2.7584 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0888979
	speed: 0.0153s/iter; left time: 294.0131s
	iters: 200, epoch: 17 | loss: 3.1112199
	speed: 0.0123s/iter; left time: 235.6983s
Epoch: 17 cost time: 3.2021071910858154
Epoch: 17, Steps: 230 Train Loss: 3.1224 (Forecasting Loss:0.3644 + XiCon Loss:2.7581 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.0679877
	speed: 0.0153s/iter; left time: 290.6581s
	iters: 200, epoch: 18 | loss: 3.1042528
	speed: 0.0125s/iter; left time: 237.0227s
Epoch: 18 cost time: 3.183704376220703
Epoch: 18, Steps: 230 Train Loss: 3.1268 (Forecasting Loss:0.3632 + XiCon Loss:2.7635 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3673
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0866220
	speed: 0.0147s/iter; left time: 275.4939s
	iters: 200, epoch: 19 | loss: 3.1635747
	speed: 0.0135s/iter; left time: 252.2397s
Epoch: 19 cost time: 3.2307002544403076
Epoch: 19, Steps: 230 Train Loss: 3.1239 (Forecasting Loss:0.3641 + XiCon Loss:2.7598 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3673
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1153493
	speed: 0.0152s/iter; left time: 282.4517s
	iters: 200, epoch: 20 | loss: 3.1168737
	speed: 0.0130s/iter; left time: 238.8141s
Epoch: 20 cost time: 3.2368967533111572
Epoch: 20, Steps: 230 Train Loss: 3.1217 (Forecasting Loss:0.3642 + XiCon Loss:2.7575 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3673
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1151338
	speed: 0.0154s/iter; left time: 281.9687s
	iters: 200, epoch: 21 | loss: 3.1327634
	speed: 0.0133s/iter; left time: 242.7853s
Epoch: 21 cost time: 3.3218812942504883
Epoch: 21, Steps: 230 Train Loss: 3.1224 (Forecasting Loss:0.3640 + XiCon Loss:2.7584 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3673
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1173551
	speed: 0.0158s/iter; left time: 286.1499s
	iters: 200, epoch: 22 | loss: 3.1012831
	speed: 0.0125s/iter; left time: 223.9694s
Epoch: 22 cost time: 3.2797129154205322
Epoch: 22, Steps: 230 Train Loss: 3.1239 (Forecasting Loss:0.3640 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1162457
	speed: 0.0151s/iter; left time: 269.4324s
	iters: 200, epoch: 23 | loss: 3.1159606
	speed: 0.0126s/iter; left time: 223.7252s
Epoch: 23 cost time: 3.184051990509033
Epoch: 23, Steps: 230 Train Loss: 3.1225 (Forecasting Loss:0.3640 + XiCon Loss:2.7585 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3673
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.1511235
	speed: 0.0157s/iter; left time: 276.8543s
	iters: 200, epoch: 24 | loss: 3.1358397
	speed: 0.0129s/iter; left time: 226.1719s
Epoch: 24 cost time: 3.310667037963867
Epoch: 24, Steps: 230 Train Loss: 3.1243 (Forecasting Loss:0.3642 + XiCon Loss:2.7601 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3189913034439087, mae:0.4156643748283386, mape:3.827754020690918, mspe:19522.962890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9728
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6483619
	speed: 0.0152s/iter; left time: 348.3413s
	iters: 200, epoch: 1 | loss: 3.5119312
	speed: 0.0132s/iter; left time: 301.4390s
Epoch: 1 cost time: 3.271674633026123
Epoch: 1, Steps: 230 Train Loss: 3.6773 (Forecasting Loss:0.7225 + XiCon Loss:2.9548 x Lambda(1.0)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.5303
Validation loss decreased (inf --> 0.329727).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2308674
	speed: 0.0160s/iter; left time: 363.5834s
	iters: 200, epoch: 2 | loss: 3.1468792
	speed: 0.0133s/iter; left time: 299.0686s
Epoch: 2 cost time: 3.3465991020202637
Epoch: 2, Steps: 230 Train Loss: 3.2834 (Forecasting Loss:0.4280 + XiCon Loss:2.8554 x Lambda(1.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.3643
Validation loss decreased (0.329727 --> 0.215639).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1072612
	speed: 0.0159s/iter; left time: 356.2575s
	iters: 200, epoch: 3 | loss: 3.2152040
	speed: 0.0130s/iter; left time: 290.1431s
Epoch: 3 cost time: 3.3316545486450195
Epoch: 3, Steps: 230 Train Loss: 3.1591 (Forecasting Loss:0.3849 + XiCon Loss:2.7742 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.3621
Validation loss decreased (0.215639 --> 0.213311).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2498457
	speed: 0.0151s/iter; left time: 336.1493s
	iters: 200, epoch: 4 | loss: 3.2238672
	speed: 0.0138s/iter; left time: 305.2505s
Epoch: 4 cost time: 3.3069162368774414
Epoch: 4, Steps: 230 Train Loss: 3.1973 (Forecasting Loss:0.3790 + XiCon Loss:2.8182 x Lambda(1.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.3469
Validation loss decreased (0.213311 --> 0.204580).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1436667
	speed: 0.0155s/iter; left time: 340.9633s
	iters: 200, epoch: 5 | loss: 3.1852612
	speed: 0.0130s/iter; left time: 284.8522s
Epoch: 5 cost time: 3.2583556175231934
Epoch: 5, Steps: 230 Train Loss: 3.1910 (Forecasting Loss:0.3707 + XiCon Loss:2.8203 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3427
Validation loss decreased (0.204580 --> 0.202218).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1241724
	speed: 0.0159s/iter; left time: 346.3453s
	iters: 200, epoch: 6 | loss: 3.1690817
	speed: 0.0141s/iter; left time: 304.8852s
Epoch: 6 cost time: 3.4261155128479004
Epoch: 6, Steps: 230 Train Loss: 3.1836 (Forecasting Loss:0.3679 + XiCon Loss:2.8157 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.3410
Validation loss decreased (0.202218 --> 0.200853).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2197299
	speed: 0.0157s/iter; left time: 337.2951s
	iters: 200, epoch: 7 | loss: 3.1302965
	speed: 0.0132s/iter; left time: 283.6792s
Epoch: 7 cost time: 3.3281519412994385
Epoch: 7, Steps: 230 Train Loss: 3.1785 (Forecasting Loss:0.3663 + XiCon Loss:2.8122 x Lambda(1.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.3409
Validation loss decreased (0.200853 --> 0.200394).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1880965
	speed: 0.0163s/iter; left time: 348.0866s
	iters: 200, epoch: 8 | loss: 3.1675034
	speed: 0.0127s/iter; left time: 268.8607s
Epoch: 8 cost time: 3.3071398735046387
Epoch: 8, Steps: 230 Train Loss: 3.1760 (Forecasting Loss:0.3657 + XiCon Loss:2.8103 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.3402
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1378706
	speed: 0.0159s/iter; left time: 334.8368s
	iters: 200, epoch: 9 | loss: 3.2022595
	speed: 0.0133s/iter; left time: 279.2453s
Epoch: 9 cost time: 3.3724098205566406
Epoch: 9, Steps: 230 Train Loss: 3.1796 (Forecasting Loss:0.3654 + XiCon Loss:2.8142 x Lambda(1.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.3401
Validation loss decreased (0.200394 --> 0.200391).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2150602
	speed: 0.0154s/iter; left time: 321.6052s
	iters: 200, epoch: 10 | loss: 3.1096787
	speed: 0.0134s/iter; left time: 277.7219s
Epoch: 10 cost time: 3.313372850418091
Epoch: 10, Steps: 230 Train Loss: 3.1804 (Forecasting Loss:0.3653 + XiCon Loss:2.8151 x Lambda(1.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.3401
Validation loss decreased (0.200391 --> 0.200260).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1462202
	speed: 0.0156s/iter; left time: 322.0435s
	iters: 200, epoch: 11 | loss: 3.2106180
	speed: 0.0125s/iter; left time: 257.1653s
Epoch: 11 cost time: 3.218909740447998
Epoch: 11, Steps: 230 Train Loss: 3.1767 (Forecasting Loss:0.3654 + XiCon Loss:2.8113 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
Validation loss decreased (0.200260 --> 0.200223).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1309381
	speed: 0.0153s/iter; left time: 312.4935s
	iters: 200, epoch: 12 | loss: 3.2082033
	speed: 0.0129s/iter; left time: 260.7159s
Epoch: 12 cost time: 3.237993001937866
Epoch: 12, Steps: 230 Train Loss: 3.1737 (Forecasting Loss:0.3652 + XiCon Loss:2.8085 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
Validation loss decreased (0.200223 --> 0.200191).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1474159
	speed: 0.0155s/iter; left time: 311.8125s
	iters: 200, epoch: 13 | loss: 3.1988006
	speed: 0.0128s/iter; left time: 255.5430s
Epoch: 13 cost time: 3.260439157485962
Epoch: 13, Steps: 230 Train Loss: 3.1771 (Forecasting Loss:0.3653 + XiCon Loss:2.8118 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3400
Validation loss decreased (0.200191 --> 0.200109).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1502690
	speed: 0.0154s/iter; left time: 307.2653s
	iters: 200, epoch: 14 | loss: 3.1531820
	speed: 0.0134s/iter; left time: 265.5955s
Epoch: 14 cost time: 3.2921128273010254
Epoch: 14, Steps: 230 Train Loss: 3.1775 (Forecasting Loss:0.3651 + XiCon Loss:2.8124 x Lambda(1.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.3400
Validation loss decreased (0.200109 --> 0.199789).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1234651
	speed: 0.0157s/iter; left time: 309.9616s
	iters: 200, epoch: 15 | loss: 3.1813312
	speed: 0.0129s/iter; left time: 253.0130s
Epoch: 15 cost time: 3.2978763580322266
Epoch: 15, Steps: 230 Train Loss: 3.1746 (Forecasting Loss:0.3652 + XiCon Loss:2.8094 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3400
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1260870
	speed: 0.0153s/iter; left time: 298.2545s
	iters: 200, epoch: 16 | loss: 3.1832132
	speed: 0.0138s/iter; left time: 266.2166s
Epoch: 16 cost time: 3.3266985416412354
Epoch: 16, Steps: 230 Train Loss: 3.1771 (Forecasting Loss:0.3652 + XiCon Loss:2.8119 x Lambda(1.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.3400
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1930716
	speed: 0.0150s/iter; left time: 289.1853s
	iters: 200, epoch: 17 | loss: 3.1189950
	speed: 0.0134s/iter; left time: 256.9955s
Epoch: 17 cost time: 3.2909064292907715
Epoch: 17, Steps: 230 Train Loss: 3.1774 (Forecasting Loss:0.3653 + XiCon Loss:2.8121 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3400
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1578739
	speed: 0.0159s/iter; left time: 301.7465s
	iters: 200, epoch: 18 | loss: 3.1419747
	speed: 0.0129s/iter; left time: 243.1466s
Epoch: 18 cost time: 3.3024981021881104
Epoch: 18, Steps: 230 Train Loss: 3.1760 (Forecasting Loss:0.3651 + XiCon Loss:2.8110 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2014427
	speed: 0.0154s/iter; left time: 289.5555s
	iters: 200, epoch: 19 | loss: 3.1376019
	speed: 0.0128s/iter; left time: 239.3470s
Epoch: 19 cost time: 3.226999282836914
Epoch: 19, Steps: 230 Train Loss: 3.1770 (Forecasting Loss:0.3652 + XiCon Loss:2.8117 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1486852
	speed: 0.0145s/iter; left time: 268.8003s
	iters: 200, epoch: 20 | loss: 3.2267950
	speed: 0.0133s/iter; left time: 245.4425s
Epoch: 20 cost time: 3.2131729125976562
Epoch: 20, Steps: 230 Train Loss: 3.1785 (Forecasting Loss:0.3651 + XiCon Loss:2.8134 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1610446
	speed: 0.0149s/iter; left time: 272.8307s
	iters: 200, epoch: 21 | loss: 3.2087808
	speed: 0.0125s/iter; left time: 227.6540s
Epoch: 21 cost time: 3.1287519931793213
Epoch: 21, Steps: 230 Train Loss: 3.1766 (Forecasting Loss:0.3652 + XiCon Loss:2.8114 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3400
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1696587
	speed: 0.0158s/iter; left time: 285.2191s
	iters: 200, epoch: 22 | loss: 3.2017663
	speed: 0.0127s/iter; left time: 228.3179s
Epoch: 22 cost time: 3.308396100997925
Epoch: 22, Steps: 230 Train Loss: 3.1785 (Forecasting Loss:0.3653 + XiCon Loss:2.8132 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3400
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1480339
	speed: 0.0170s/iter; left time: 302.9283s
	iters: 200, epoch: 23 | loss: 3.1870096
	speed: 0.0124s/iter; left time: 220.3081s
Epoch: 23 cost time: 3.3506381511688232
Epoch: 23, Steps: 230 Train Loss: 3.1772 (Forecasting Loss:0.3651 + XiCon Loss:2.8121 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.1588330
	speed: 0.0150s/iter; left time: 264.2319s
	iters: 200, epoch: 24 | loss: 3.1869020
	speed: 0.0125s/iter; left time: 218.8112s
Epoch: 24 cost time: 3.148266315460205
Epoch: 24, Steps: 230 Train Loss: 3.1786 (Forecasting Loss:0.3652 + XiCon Loss:2.8135 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3400
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.2869577705860138, mae:0.3929871916770935, mape:3.874569892883301, mspe:20767.14453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.1172
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6293559
	speed: 0.0163s/iter; left time: 373.9482s
	iters: 200, epoch: 1 | loss: 3.5896869
	speed: 0.0127s/iter; left time: 290.0014s
Epoch: 1 cost time: 3.344188690185547
Epoch: 1, Steps: 230 Train Loss: 3.6779 (Forecasting Loss:0.7221 + XiCon Loss:2.9557 x Lambda(1.0)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.5328
Validation loss decreased (inf --> 0.331815).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3019338
	speed: 0.0159s/iter; left time: 360.0281s
	iters: 200, epoch: 2 | loss: 3.2350073
	speed: 0.0131s/iter; left time: 295.7831s
Epoch: 2 cost time: 3.322948694229126
Epoch: 2, Steps: 230 Train Loss: 3.2807 (Forecasting Loss:0.4324 + XiCon Loss:2.8483 x Lambda(1.0)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.3601
Validation loss decreased (0.331815 --> 0.214367).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1940277
	speed: 0.0151s/iter; left time: 338.1454s
	iters: 200, epoch: 3 | loss: 3.0694718
	speed: 0.0133s/iter; left time: 296.6879s
Epoch: 3 cost time: 3.226461410522461
Epoch: 3, Steps: 230 Train Loss: 3.1484 (Forecasting Loss:0.3753 + XiCon Loss:2.7731 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.3599
Validation loss decreased (0.214367 --> 0.206856).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1641738
	speed: 0.0152s/iter; left time: 337.8304s
	iters: 200, epoch: 4 | loss: 3.1262665
	speed: 0.0129s/iter; left time: 285.6367s
Epoch: 4 cost time: 3.199647903442383
Epoch: 4, Steps: 230 Train Loss: 3.1171 (Forecasting Loss:0.3655 + XiCon Loss:2.7516 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.3618
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1370649
	speed: 0.0154s/iter; left time: 338.2851s
	iters: 200, epoch: 5 | loss: 3.1024811
	speed: 0.0129s/iter; left time: 282.4576s
Epoch: 5 cost time: 3.2174148559570312
Epoch: 5, Steps: 230 Train Loss: 3.1348 (Forecasting Loss:0.3664 + XiCon Loss:2.7684 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.3468
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1431422
	speed: 0.0165s/iter; left time: 359.7403s
	iters: 200, epoch: 6 | loss: 3.2207477
	speed: 0.0126s/iter; left time: 273.3153s
Epoch: 6 cost time: 3.3218109607696533
Epoch: 6, Steps: 230 Train Loss: 3.1533 (Forecasting Loss:0.3668 + XiCon Loss:2.7865 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.3471
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1900702
	speed: 0.0153s/iter; left time: 328.6992s
	iters: 200, epoch: 7 | loss: 3.2149963
	speed: 0.0134s/iter; left time: 287.9721s
Epoch: 7 cost time: 3.2832486629486084
Epoch: 7, Steps: 230 Train Loss: 3.1610 (Forecasting Loss:0.3654 + XiCon Loss:2.7956 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3468
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1339896
	speed: 0.0153s/iter; left time: 325.6865s
	iters: 200, epoch: 8 | loss: 3.2470376
	speed: 0.0127s/iter; left time: 268.2998s
Epoch: 8 cost time: 3.204549789428711
Epoch: 8, Steps: 230 Train Loss: 3.1614 (Forecasting Loss:0.3656 + XiCon Loss:2.7959 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3482
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2083824
	speed: 0.0152s/iter; left time: 320.4309s
	iters: 200, epoch: 9 | loss: 3.1226838
	speed: 0.0132s/iter; left time: 275.7487s
Epoch: 9 cost time: 3.2606310844421387
Epoch: 9, Steps: 230 Train Loss: 3.1591 (Forecasting Loss:0.3649 + XiCon Loss:2.7942 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3483
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1393936
	speed: 0.0154s/iter; left time: 320.1006s
	iters: 200, epoch: 10 | loss: 3.1695235
	speed: 0.0124s/iter; left time: 257.2985s
Epoch: 10 cost time: 3.1865580081939697
Epoch: 10, Steps: 230 Train Loss: 3.1608 (Forecasting Loss:0.3644 + XiCon Loss:2.7964 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3482
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1621296
	speed: 0.0149s/iter; left time: 307.7217s
	iters: 200, epoch: 11 | loss: 3.1320240
	speed: 0.0124s/iter; left time: 254.7307s
Epoch: 11 cost time: 3.14555025100708
Epoch: 11, Steps: 230 Train Loss: 3.1599 (Forecasting Loss:0.3644 + XiCon Loss:2.7955 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3483
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1296220
	speed: 0.0151s/iter; left time: 308.3325s
	iters: 200, epoch: 12 | loss: 3.2269690
	speed: 0.0128s/iter; left time: 258.9549s
Epoch: 12 cost time: 3.213146448135376
Epoch: 12, Steps: 230 Train Loss: 3.1628 (Forecasting Loss:0.3645 + XiCon Loss:2.7983 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3483
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1290679
	speed: 0.0154s/iter; left time: 310.9791s
	iters: 200, epoch: 13 | loss: 3.0881920
	speed: 0.0125s/iter; left time: 251.3885s
Epoch: 13 cost time: 3.221994161605835
Epoch: 13, Steps: 230 Train Loss: 3.1593 (Forecasting Loss:0.3637 + XiCon Loss:2.7956 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.3084869086742401, mae:0.4113951623439789, mape:4.091277122497559, mspe:23557.701171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3034+-0.01563, MAE:0.4056+-0.01137, MAPE:4.0264+-0.22189, MSPE:23662.7402+-4568.52322, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9926
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7191629
	speed: 0.0268s/iter; left time: 581.6720s
	iters: 200, epoch: 1 | loss: 3.7735538
	speed: 0.0211s/iter; left time: 456.5180s
Epoch: 1 cost time: 5.157735586166382
Epoch: 1, Steps: 218 Train Loss: 3.8068 (Forecasting Loss:0.8373 + XiCon Loss:2.9695 x Lambda(1.0)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.6849
Validation loss decreased (inf --> 0.336285).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3055766
	speed: 0.0223s/iter; left time: 478.4216s
	iters: 200, epoch: 2 | loss: 3.2609560
	speed: 0.0212s/iter; left time: 453.7749s
Epoch: 2 cost time: 4.755371332168579
Epoch: 2, Steps: 218 Train Loss: 3.3344 (Forecasting Loss:0.4993 + XiCon Loss:2.8351 x Lambda(1.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.4201
Validation loss decreased (0.336285 --> 0.215655).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1720009
	speed: 0.0234s/iter; left time: 497.5294s
	iters: 200, epoch: 3 | loss: 3.1405783
	speed: 0.0207s/iter; left time: 437.1716s
Epoch: 3 cost time: 4.782176733016968
Epoch: 3, Steps: 218 Train Loss: 3.2005 (Forecasting Loss:0.4232 + XiCon Loss:2.7772 x Lambda(1.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.4303
Validation loss decreased (0.215655 --> 0.214878).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2015076
	speed: 0.0231s/iter; left time: 486.7148s
	iters: 200, epoch: 4 | loss: 3.1154006
	speed: 0.0211s/iter; left time: 442.8413s
Epoch: 4 cost time: 4.833451271057129
Epoch: 4, Steps: 218 Train Loss: 3.1530 (Forecasting Loss:0.3986 + XiCon Loss:2.7543 x Lambda(1.0)), Vali MSE Loss: 0.2277 Test MSE Loss: 0.4007
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1777904
	speed: 0.0229s/iter; left time: 477.5706s
	iters: 200, epoch: 5 | loss: 3.1382825
	speed: 0.0203s/iter; left time: 421.7011s
Epoch: 5 cost time: 4.742846965789795
Epoch: 5, Steps: 218 Train Loss: 3.1267 (Forecasting Loss:0.3905 + XiCon Loss:2.7361 x Lambda(1.0)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.3886
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1372318
	speed: 0.0228s/iter; left time: 470.2343s
	iters: 200, epoch: 6 | loss: 3.1673465
	speed: 0.0195s/iter; left time: 400.8027s
Epoch: 6 cost time: 4.583277940750122
Epoch: 6, Steps: 218 Train Loss: 3.1443 (Forecasting Loss:0.3898 + XiCon Loss:2.7545 x Lambda(1.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.3835
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1421680
	speed: 0.0229s/iter; left time: 467.9616s
	iters: 200, epoch: 7 | loss: 3.1850536
	speed: 0.0206s/iter; left time: 418.6971s
Epoch: 7 cost time: 4.741064786911011
Epoch: 7, Steps: 218 Train Loss: 3.1756 (Forecasting Loss:0.3905 + XiCon Loss:2.7852 x Lambda(1.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.3815
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1513860
	speed: 0.0232s/iter; left time: 469.0119s
	iters: 200, epoch: 8 | loss: 3.1957114
	speed: 0.0208s/iter; left time: 418.2149s
Epoch: 8 cost time: 4.823527574539185
Epoch: 8, Steps: 218 Train Loss: 3.1949 (Forecasting Loss:0.3920 + XiCon Loss:2.8029 x Lambda(1.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.3847
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1266520
	speed: 0.0241s/iter; left time: 480.5641s
	iters: 200, epoch: 9 | loss: 3.1755514
	speed: 0.0206s/iter; left time: 409.8819s
Epoch: 9 cost time: 4.864700555801392
Epoch: 9, Steps: 218 Train Loss: 3.2046 (Forecasting Loss:0.3924 + XiCon Loss:2.8121 x Lambda(1.0)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.3812
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2213326
	speed: 0.0231s/iter; left time: 455.1034s
	iters: 200, epoch: 10 | loss: 3.2574556
	speed: 0.0211s/iter; left time: 413.6185s
Epoch: 10 cost time: 4.813262701034546
Epoch: 10, Steps: 218 Train Loss: 3.2044 (Forecasting Loss:0.3920 + XiCon Loss:2.8124 x Lambda(1.0)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.3802
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2218063
	speed: 0.0230s/iter; left time: 449.6927s
	iters: 200, epoch: 11 | loss: 3.2432208
	speed: 0.0208s/iter; left time: 404.4257s
Epoch: 11 cost time: 4.778149127960205
Epoch: 11, Steps: 218 Train Loss: 3.2106 (Forecasting Loss:0.3921 + XiCon Loss:2.8185 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.3808
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2183194
	speed: 0.0232s/iter; left time: 448.4000s
	iters: 200, epoch: 12 | loss: 3.1899567
	speed: 0.0212s/iter; left time: 407.3685s
Epoch: 12 cost time: 4.831115007400513
Epoch: 12, Steps: 218 Train Loss: 3.2065 (Forecasting Loss:0.3920 + XiCon Loss:2.8145 x Lambda(1.0)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.3812
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2038736
	speed: 0.0231s/iter; left time: 441.5000s
	iters: 200, epoch: 13 | loss: 3.2275786
	speed: 0.0214s/iter; left time: 406.0198s
Epoch: 13 cost time: 4.8631415367126465
Epoch: 13, Steps: 218 Train Loss: 3.2081 (Forecasting Loss:0.3918 + XiCon Loss:2.8162 x Lambda(1.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.3811
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3845003545284271, mae:0.4761638343334198, mape:6.032370567321777, mspe:97738.796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0599
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7999287
	speed: 0.0234s/iter; left time: 507.5835s
	iters: 200, epoch: 1 | loss: 3.6442389
	speed: 0.0211s/iter; left time: 455.6091s
Epoch: 1 cost time: 4.844406366348267
Epoch: 1, Steps: 218 Train Loss: 3.7840 (Forecasting Loss:0.8368 + XiCon Loss:2.9472 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.6596
Validation loss decreased (inf --> 0.332856).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2477632
	speed: 0.0232s/iter; left time: 498.7057s
	iters: 200, epoch: 2 | loss: 3.2491574
	speed: 0.0212s/iter; left time: 453.3275s
Epoch: 2 cost time: 4.874094009399414
Epoch: 2, Steps: 218 Train Loss: 3.3263 (Forecasting Loss:0.4737 + XiCon Loss:2.8526 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5176
Validation loss decreased (0.332856 --> 0.219705).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2340345
	speed: 0.0234s/iter; left time: 497.6829s
	iters: 200, epoch: 3 | loss: 3.2461421
	speed: 0.0209s/iter; left time: 442.3651s
Epoch: 3 cost time: 4.8416712284088135
Epoch: 3, Steps: 218 Train Loss: 3.2696 (Forecasting Loss:0.4117 + XiCon Loss:2.8579 x Lambda(1.0)), Vali MSE Loss: 0.2230 Test MSE Loss: 0.4092
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2397320
	speed: 0.0229s/iter; left time: 483.0109s
	iters: 200, epoch: 4 | loss: 3.2885900
	speed: 0.0208s/iter; left time: 435.1843s
Epoch: 4 cost time: 4.78248405456543
Epoch: 4, Steps: 218 Train Loss: 3.2867 (Forecasting Loss:0.3947 + XiCon Loss:2.8920 x Lambda(1.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.4036
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3390472
	speed: 0.0234s/iter; left time: 488.0522s
	iters: 200, epoch: 5 | loss: 3.3460948
	speed: 0.0214s/iter; left time: 443.6793s
Epoch: 5 cost time: 4.881094932556152
Epoch: 5, Steps: 218 Train Loss: 3.2834 (Forecasting Loss:0.3826 + XiCon Loss:2.9007 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.4060
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1862473
	speed: 0.0230s/iter; left time: 473.6298s
	iters: 200, epoch: 6 | loss: 3.1629219
	speed: 0.0206s/iter; left time: 423.4964s
Epoch: 6 cost time: 4.760424852371216
Epoch: 6, Steps: 218 Train Loss: 3.2768 (Forecasting Loss:0.3783 + XiCon Loss:2.8985 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3987
Validation loss decreased (0.219705 --> 0.218305).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2804410
	speed: 0.0233s/iter; left time: 476.1458s
	iters: 200, epoch: 7 | loss: 3.1654661
	speed: 0.0213s/iter; left time: 432.0996s
Epoch: 7 cost time: 4.842108249664307
Epoch: 7, Steps: 218 Train Loss: 3.2725 (Forecasting Loss:0.3764 + XiCon Loss:2.8961 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3982
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3583124
	speed: 0.0230s/iter; left time: 464.6594s
	iters: 200, epoch: 8 | loss: 3.2011478
	speed: 0.0208s/iter; left time: 416.9350s
Epoch: 8 cost time: 4.769261837005615
Epoch: 8, Steps: 218 Train Loss: 3.2714 (Forecasting Loss:0.3756 + XiCon Loss:2.8958 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3981
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2438955
	speed: 0.0236s/iter; left time: 470.9876s
	iters: 200, epoch: 9 | loss: 3.2665277
	speed: 0.0218s/iter; left time: 432.9060s
Epoch: 9 cost time: 4.959449291229248
Epoch: 9, Steps: 218 Train Loss: 3.2684 (Forecasting Loss:0.3748 + XiCon Loss:2.8936 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.3985
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2436869
	speed: 0.0234s/iter; left time: 461.6431s
	iters: 200, epoch: 10 | loss: 3.2104845
	speed: 0.0208s/iter; left time: 409.3877s
Epoch: 10 cost time: 4.843859672546387
Epoch: 10, Steps: 218 Train Loss: 3.2731 (Forecasting Loss:0.3745 + XiCon Loss:2.8986 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3992
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2584610
	speed: 0.0233s/iter; left time: 454.7652s
	iters: 200, epoch: 11 | loss: 3.2699771
	speed: 0.0209s/iter; left time: 405.3899s
Epoch: 11 cost time: 4.823016881942749
Epoch: 11, Steps: 218 Train Loss: 3.2729 (Forecasting Loss:0.3747 + XiCon Loss:2.8982 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3990
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2961988
	speed: 0.0227s/iter; left time: 438.0454s
	iters: 200, epoch: 12 | loss: 3.2618570
	speed: 0.0212s/iter; left time: 407.5659s
Epoch: 12 cost time: 4.795423746109009
Epoch: 12, Steps: 218 Train Loss: 3.2718 (Forecasting Loss:0.3743 + XiCon Loss:2.8976 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3992
Validation loss decreased (0.218305 --> 0.218258).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2740505
	speed: 0.0229s/iter; left time: 437.8876s
	iters: 200, epoch: 13 | loss: 3.3625250
	speed: 0.0216s/iter; left time: 409.2987s
Epoch: 13 cost time: 4.852960586547852
Epoch: 13, Steps: 218 Train Loss: 3.2720 (Forecasting Loss:0.3743 + XiCon Loss:2.8977 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3990
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1737542
	speed: 0.0234s/iter; left time: 441.9328s
	iters: 200, epoch: 14 | loss: 3.2244668
	speed: 0.0206s/iter; left time: 386.7776s
Epoch: 14 cost time: 4.7944252490997314
Epoch: 14, Steps: 218 Train Loss: 3.2745 (Forecasting Loss:0.3746 + XiCon Loss:2.9000 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3991
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2885337
	speed: 0.0235s/iter; left time: 438.6235s
	iters: 200, epoch: 15 | loss: 3.3606434
	speed: 0.0214s/iter; left time: 397.2730s
Epoch: 15 cost time: 4.900643825531006
Epoch: 15, Steps: 218 Train Loss: 3.2689 (Forecasting Loss:0.3748 + XiCon Loss:2.8941 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3991
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1647465
	speed: 0.0232s/iter; left time: 427.4205s
	iters: 200, epoch: 16 | loss: 3.2567854
	speed: 0.0212s/iter; left time: 388.1057s
Epoch: 16 cost time: 4.84386134147644
Epoch: 16, Steps: 218 Train Loss: 3.2691 (Forecasting Loss:0.3745 + XiCon Loss:2.8946 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3991
Validation loss decreased (0.218258 --> 0.218250).  Saving model ...
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2926552
	speed: 0.0242s/iter; left time: 439.9896s
	iters: 200, epoch: 17 | loss: 3.3122211
	speed: 0.0211s/iter; left time: 381.5912s
Epoch: 17 cost time: 4.934923410415649
Epoch: 17, Steps: 218 Train Loss: 3.2698 (Forecasting Loss:0.3744 + XiCon Loss:2.8954 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3991
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.2302535
	speed: 0.0238s/iter; left time: 428.4106s
	iters: 200, epoch: 18 | loss: 3.3330522
	speed: 0.0215s/iter; left time: 384.2906s
Epoch: 18 cost time: 4.9202985763549805
Epoch: 18, Steps: 218 Train Loss: 3.2733 (Forecasting Loss:0.3744 + XiCon Loss:2.8989 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3991
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2218118
	speed: 0.0237s/iter; left time: 420.5731s
	iters: 200, epoch: 19 | loss: 3.2444673
	speed: 0.0207s/iter; left time: 365.5585s
Epoch: 19 cost time: 4.817310094833374
Epoch: 19, Steps: 218 Train Loss: 3.2645 (Forecasting Loss:0.3742 + XiCon Loss:2.8903 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3991
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.3455231
	speed: 0.0231s/iter; left time: 405.4255s
	iters: 200, epoch: 20 | loss: 3.2238679
	speed: 0.0210s/iter; left time: 367.2869s
Epoch: 20 cost time: 4.810359954833984
Epoch: 20, Steps: 218 Train Loss: 3.2705 (Forecasting Loss:0.3742 + XiCon Loss:2.8963 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3991
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.2768297
	speed: 0.0240s/iter; left time: 415.4079s
	iters: 200, epoch: 21 | loss: 3.2222691
	speed: 0.0216s/iter; left time: 372.1603s
Epoch: 21 cost time: 4.993829727172852
Epoch: 21, Steps: 218 Train Loss: 3.2707 (Forecasting Loss:0.3740 + XiCon Loss:2.8967 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3991
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1995575
	speed: 0.0238s/iter; left time: 407.5140s
	iters: 200, epoch: 22 | loss: 3.2571006
	speed: 0.0209s/iter; left time: 355.3481s
Epoch: 22 cost time: 4.881362199783325
Epoch: 22, Steps: 218 Train Loss: 3.2762 (Forecasting Loss:0.3746 + XiCon Loss:2.9016 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3991
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1881173
	speed: 0.0236s/iter; left time: 398.1741s
	iters: 200, epoch: 23 | loss: 3.3186598
	speed: 0.0215s/iter; left time: 360.4904s
Epoch: 23 cost time: 4.894620418548584
Epoch: 23, Steps: 218 Train Loss: 3.2768 (Forecasting Loss:0.3743 + XiCon Loss:2.9024 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3991
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.3352075
	speed: 0.0237s/iter; left time: 395.6333s
	iters: 200, epoch: 24 | loss: 3.1748605
	speed: 0.0209s/iter; left time: 346.4499s
Epoch: 24 cost time: 4.8951640129089355
Epoch: 24, Steps: 218 Train Loss: 3.2724 (Forecasting Loss:0.3745 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3991
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.1871634
	speed: 0.0245s/iter; left time: 403.8496s
	iters: 200, epoch: 25 | loss: 3.2532351
	speed: 0.0216s/iter; left time: 353.6402s
Epoch: 25 cost time: 5.057909965515137
Epoch: 25, Steps: 218 Train Loss: 3.2723 (Forecasting Loss:0.3745 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3991
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.3649175
	speed: 0.0235s/iter; left time: 382.6804s
	iters: 200, epoch: 26 | loss: 3.1950047
	speed: 0.0224s/iter; left time: 362.0211s
Epoch: 26 cost time: 5.014850854873657
Epoch: 26, Steps: 218 Train Loss: 3.2701 (Forecasting Loss:0.3743 + XiCon Loss:2.8958 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3991
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3500363826751709, mae:0.4481147825717926, mape:5.337954044342041, mspe:72825.4453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.2201
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7567444
	speed: 0.0241s/iter; left time: 522.4873s
	iters: 200, epoch: 1 | loss: 3.6121056
	speed: 0.0208s/iter; left time: 449.8803s
Epoch: 1 cost time: 4.866621732711792
Epoch: 1, Steps: 218 Train Loss: 3.7901 (Forecasting Loss:0.8368 + XiCon Loss:2.9533 x Lambda(1.0)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.6606
Validation loss decreased (inf --> 0.334796).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3386667
	speed: 0.0227s/iter; left time: 486.7728s
	iters: 200, epoch: 2 | loss: 3.1854055
	speed: 0.0209s/iter; left time: 447.8432s
Epoch: 2 cost time: 4.753793954849243
Epoch: 2, Steps: 218 Train Loss: 3.2968 (Forecasting Loss:0.4720 + XiCon Loss:2.8247 x Lambda(1.0)), Vali MSE Loss: 0.2175 Test MSE Loss: 0.4548
Validation loss decreased (0.334796 --> 0.217490).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1286130
	speed: 0.0231s/iter; left time: 490.8675s
	iters: 200, epoch: 3 | loss: 3.2719383
	speed: 0.0212s/iter; left time: 447.6605s
Epoch: 3 cost time: 4.822261571884155
Epoch: 3, Steps: 218 Train Loss: 3.2106 (Forecasting Loss:0.4162 + XiCon Loss:2.7944 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.4266
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2626894
	speed: 0.0228s/iter; left time: 480.9100s
	iters: 200, epoch: 4 | loss: 3.2024221
	speed: 0.0208s/iter; left time: 436.7306s
Epoch: 4 cost time: 4.79073429107666
Epoch: 4, Steps: 218 Train Loss: 3.2630 (Forecasting Loss:0.4077 + XiCon Loss:2.8553 x Lambda(1.0)), Vali MSE Loss: 0.2327 Test MSE Loss: 0.4262
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1905775
	speed: 0.0238s/iter; left time: 496.3790s
	iters: 200, epoch: 5 | loss: 3.3030396
	speed: 0.0209s/iter; left time: 433.1667s
Epoch: 5 cost time: 4.895914554595947
Epoch: 5, Steps: 218 Train Loss: 3.2680 (Forecasting Loss:0.4002 + XiCon Loss:2.8678 x Lambda(1.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.4298
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2413766
	speed: 0.0230s/iter; left time: 474.8033s
	iters: 200, epoch: 6 | loss: 3.2076421
	speed: 0.0211s/iter; left time: 433.6234s
Epoch: 6 cost time: 4.82666802406311
Epoch: 6, Steps: 218 Train Loss: 3.2565 (Forecasting Loss:0.3955 + XiCon Loss:2.8610 x Lambda(1.0)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.4227
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.4282904
	speed: 0.0236s/iter; left time: 480.7475s
	iters: 200, epoch: 7 | loss: 3.3286302
	speed: 0.0220s/iter; left time: 446.8117s
Epoch: 7 cost time: 4.944587707519531
Epoch: 7, Steps: 218 Train Loss: 3.2567 (Forecasting Loss:0.3933 + XiCon Loss:2.8634 x Lambda(1.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.4301
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2071257
	speed: 0.0235s/iter; left time: 473.6510s
	iters: 200, epoch: 8 | loss: 3.2013862
	speed: 0.0217s/iter; left time: 435.7941s
Epoch: 8 cost time: 4.923991441726685
Epoch: 8, Steps: 218 Train Loss: 3.2571 (Forecasting Loss:0.3920 + XiCon Loss:2.8651 x Lambda(1.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.4322
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1933217
	speed: 0.0237s/iter; left time: 472.1412s
	iters: 200, epoch: 9 | loss: 3.2234054
	speed: 0.0210s/iter; left time: 417.0685s
Epoch: 9 cost time: 4.857635021209717
Epoch: 9, Steps: 218 Train Loss: 3.2555 (Forecasting Loss:0.3913 + XiCon Loss:2.8642 x Lambda(1.0)), Vali MSE Loss: 0.2286 Test MSE Loss: 0.4293
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.3444290
	speed: 0.0229s/iter; left time: 452.4047s
	iters: 200, epoch: 10 | loss: 3.3022916
	speed: 0.0215s/iter; left time: 422.6387s
Epoch: 10 cost time: 4.853413105010986
Epoch: 10, Steps: 218 Train Loss: 3.2569 (Forecasting Loss:0.3917 + XiCon Loss:2.8652 x Lambda(1.0)), Vali MSE Loss: 0.2286 Test MSE Loss: 0.4308
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.3046551
	speed: 0.0243s/iter; left time: 474.9033s
	iters: 200, epoch: 11 | loss: 3.2262640
	speed: 0.0222s/iter; left time: 430.2177s
Epoch: 11 cost time: 5.0744593143463135
Epoch: 11, Steps: 218 Train Loss: 3.2580 (Forecasting Loss:0.3913 + XiCon Loss:2.8667 x Lambda(1.0)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.4335
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2861023
	speed: 0.0232s/iter; left time: 447.3130s
	iters: 200, epoch: 12 | loss: 3.2636657
	speed: 0.0212s/iter; left time: 407.9462s
Epoch: 12 cost time: 4.856747150421143
Epoch: 12, Steps: 218 Train Loss: 3.2613 (Forecasting Loss:0.3912 + XiCon Loss:2.8701 x Lambda(1.0)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.4331
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.41479507088661194, mae:0.49486374855041504, mape:6.1546244621276855, mspe:100611.203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 5.0046
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.8009167
	speed: 0.0237s/iter; left time: 514.2240s
	iters: 200, epoch: 1 | loss: 3.7292850
	speed: 0.0209s/iter; left time: 451.6944s
Epoch: 1 cost time: 4.834996938705444
Epoch: 1, Steps: 218 Train Loss: 3.7900 (Forecasting Loss:0.8365 + XiCon Loss:2.9535 x Lambda(1.0)), Vali MSE Loss: 0.3346 Test MSE Loss: 0.6676
Validation loss decreased (inf --> 0.334566).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2391372
	speed: 0.0234s/iter; left time: 503.5004s
	iters: 200, epoch: 2 | loss: 3.2455771
	speed: 0.0209s/iter; left time: 447.9604s
Epoch: 2 cost time: 4.851651668548584
Epoch: 2, Steps: 218 Train Loss: 3.3241 (Forecasting Loss:0.4909 + XiCon Loss:2.8332 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.4309
Validation loss decreased (0.334566 --> 0.219505).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1370814
	speed: 0.0233s/iter; left time: 495.8975s
	iters: 200, epoch: 3 | loss: 3.2284682
	speed: 0.0213s/iter; left time: 450.3150s
Epoch: 3 cost time: 4.8676793575286865
Epoch: 3, Steps: 218 Train Loss: 3.2005 (Forecasting Loss:0.4122 + XiCon Loss:2.7882 x Lambda(1.0)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.3992
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2302101
	speed: 0.0235s/iter; left time: 493.9722s
	iters: 200, epoch: 4 | loss: 3.3621786
	speed: 0.0209s/iter; left time: 438.7195s
Epoch: 4 cost time: 4.8426127433776855
Epoch: 4, Steps: 218 Train Loss: 3.2582 (Forecasting Loss:0.4018 + XiCon Loss:2.8564 x Lambda(1.0)), Vali MSE Loss: 0.2411 Test MSE Loss: 0.3879
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2543950
	speed: 0.0234s/iter; left time: 488.3923s
	iters: 200, epoch: 5 | loss: 3.2610765
	speed: 0.0209s/iter; left time: 433.7652s
Epoch: 5 cost time: 4.856447696685791
Epoch: 5, Steps: 218 Train Loss: 3.2579 (Forecasting Loss:0.3898 + XiCon Loss:2.8681 x Lambda(1.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.3937
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2762952
	speed: 0.0238s/iter; left time: 489.8241s
	iters: 200, epoch: 6 | loss: 3.2266884
	speed: 0.0207s/iter; left time: 424.2466s
Epoch: 6 cost time: 4.845948219299316
Epoch: 6, Steps: 218 Train Loss: 3.2579 (Forecasting Loss:0.3842 + XiCon Loss:2.8737 x Lambda(1.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.4073
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.3201609
	speed: 0.0235s/iter; left time: 478.3356s
	iters: 200, epoch: 7 | loss: 3.2378597
	speed: 0.0210s/iter; left time: 427.1206s
Epoch: 7 cost time: 4.859140872955322
Epoch: 7, Steps: 218 Train Loss: 3.2532 (Forecasting Loss:0.3812 + XiCon Loss:2.8720 x Lambda(1.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.4059
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2724905
	speed: 0.0230s/iter; left time: 463.9510s
	iters: 200, epoch: 8 | loss: 3.3079700
	speed: 0.0219s/iter; left time: 440.3133s
Epoch: 8 cost time: 4.8933398723602295
Epoch: 8, Steps: 218 Train Loss: 3.2525 (Forecasting Loss:0.3798 + XiCon Loss:2.8727 x Lambda(1.0)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.4079
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2121072
	speed: 0.0231s/iter; left time: 461.8967s
	iters: 200, epoch: 9 | loss: 3.3041480
	speed: 0.0219s/iter; left time: 435.5362s
Epoch: 9 cost time: 4.937943458557129
Epoch: 9, Steps: 218 Train Loss: 3.2487 (Forecasting Loss:0.3793 + XiCon Loss:2.8694 x Lambda(1.0)), Vali MSE Loss: 0.2248 Test MSE Loss: 0.4064
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2074716
	speed: 0.0228s/iter; left time: 450.9093s
	iters: 200, epoch: 10 | loss: 3.1871011
	speed: 0.0204s/iter; left time: 401.1948s
Epoch: 10 cost time: 4.763337135314941
Epoch: 10, Steps: 218 Train Loss: 3.2589 (Forecasting Loss:0.3790 + XiCon Loss:2.8799 x Lambda(1.0)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.4051
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2570844
	speed: 0.0236s/iter; left time: 459.7632s
	iters: 200, epoch: 11 | loss: 3.3186054
	speed: 0.0212s/iter; left time: 411.4972s
Epoch: 11 cost time: 4.8833537101745605
Epoch: 11, Steps: 218 Train Loss: 3.2542 (Forecasting Loss:0.3790 + XiCon Loss:2.8752 x Lambda(1.0)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.4060
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.3156009
	speed: 0.0239s/iter; left time: 461.0919s
	iters: 200, epoch: 12 | loss: 3.2080250
	speed: 0.0220s/iter; left time: 422.9406s
Epoch: 12 cost time: 4.994119644165039
Epoch: 12, Steps: 218 Train Loss: 3.2578 (Forecasting Loss:0.3790 + XiCon Loss:2.8788 x Lambda(1.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.4063
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.38567280769348145, mae:0.4760682284832001, mape:5.895412445068359, mspe:91908.1015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.9295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7812049
	speed: 0.0241s/iter; left time: 522.7948s
	iters: 200, epoch: 1 | loss: 3.6179197
	speed: 0.0210s/iter; left time: 453.8955s
Epoch: 1 cost time: 4.940511226654053
Epoch: 1, Steps: 218 Train Loss: 3.7801 (Forecasting Loss:0.8309 + XiCon Loss:2.9492 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.6484
Validation loss decreased (inf --> 0.331646).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2975662
	speed: 0.0240s/iter; left time: 515.5017s
	iters: 200, epoch: 2 | loss: 3.2391751
	speed: 0.0204s/iter; left time: 437.0519s
Epoch: 2 cost time: 4.844133377075195
Epoch: 2, Steps: 218 Train Loss: 3.3288 (Forecasting Loss:0.4666 + XiCon Loss:2.8622 x Lambda(1.0)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.4551
Validation loss decreased (0.331646 --> 0.216537).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1091781
	speed: 0.0236s/iter; left time: 500.8266s
	iters: 200, epoch: 3 | loss: 3.3922107
	speed: 0.0208s/iter; left time: 441.0872s
Epoch: 3 cost time: 4.838475465774536
Epoch: 3, Steps: 218 Train Loss: 3.2065 (Forecasting Loss:0.4093 + XiCon Loss:2.7972 x Lambda(1.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.4369
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1828015
	speed: 0.0233s/iter; left time: 489.7305s
	iters: 200, epoch: 4 | loss: 3.3515673
	speed: 0.0210s/iter; left time: 439.8579s
Epoch: 4 cost time: 4.8373260498046875
Epoch: 4, Steps: 218 Train Loss: 3.2487 (Forecasting Loss:0.4035 + XiCon Loss:2.8452 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.4093
Validation loss decreased (0.216537 --> 0.214174).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2302644
	speed: 0.0236s/iter; left time: 490.5664s
	iters: 200, epoch: 5 | loss: 3.2789240
	speed: 0.0212s/iter; left time: 439.2369s
Epoch: 5 cost time: 4.890488386154175
Epoch: 5, Steps: 218 Train Loss: 3.2546 (Forecasting Loss:0.3931 + XiCon Loss:2.8615 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.4065
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2934465
	speed: 0.0234s/iter; left time: 483.1226s
	iters: 200, epoch: 6 | loss: 3.2373910
	speed: 0.0209s/iter; left time: 429.3704s
Epoch: 6 cost time: 4.84955096244812
Epoch: 6, Steps: 218 Train Loss: 3.2525 (Forecasting Loss:0.3885 + XiCon Loss:2.8640 x Lambda(1.0)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.4068
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2100759
	speed: 0.0233s/iter; left time: 475.6566s
	iters: 200, epoch: 7 | loss: 3.1789680
	speed: 0.0209s/iter; left time: 424.4279s
Epoch: 7 cost time: 4.840979099273682
Epoch: 7, Steps: 218 Train Loss: 3.2552 (Forecasting Loss:0.3867 + XiCon Loss:2.8685 x Lambda(1.0)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.4002
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3241916
	speed: 0.0236s/iter; left time: 476.4510s
	iters: 200, epoch: 8 | loss: 3.2386398
	speed: 0.0210s/iter; left time: 421.5645s
Epoch: 8 cost time: 4.8452630043029785
Epoch: 8, Steps: 218 Train Loss: 3.2571 (Forecasting Loss:0.3857 + XiCon Loss:2.8715 x Lambda(1.0)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.4008
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2238750
	speed: 0.0231s/iter; left time: 460.1812s
	iters: 200, epoch: 9 | loss: 3.3788939
	speed: 0.0209s/iter; left time: 415.6612s
Epoch: 9 cost time: 4.807949542999268
Epoch: 9, Steps: 218 Train Loss: 3.2609 (Forecasting Loss:0.3840 + XiCon Loss:2.8769 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.4010
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2818744
	speed: 0.0236s/iter; left time: 465.0994s
	iters: 200, epoch: 10 | loss: 3.3062291
	speed: 0.0213s/iter; left time: 417.5617s
Epoch: 10 cost time: 4.910171270370483
Epoch: 10, Steps: 218 Train Loss: 3.2564 (Forecasting Loss:0.3844 + XiCon Loss:2.8720 x Lambda(1.0)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.4004
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2749851
	speed: 0.0243s/iter; left time: 473.4334s
	iters: 200, epoch: 11 | loss: 3.2026033
	speed: 0.0221s/iter; left time: 429.9570s
Epoch: 11 cost time: 5.076000213623047
Epoch: 11, Steps: 218 Train Loss: 3.2537 (Forecasting Loss:0.3841 + XiCon Loss:2.8696 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.4007
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2664762
	speed: 0.0227s/iter; left time: 438.4864s
	iters: 200, epoch: 12 | loss: 3.2394233
	speed: 0.0216s/iter; left time: 415.4428s
Epoch: 12 cost time: 4.835830926895142
Epoch: 12, Steps: 218 Train Loss: 3.2584 (Forecasting Loss:0.3842 + XiCon Loss:2.8742 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.4007
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2031384
	speed: 0.0236s/iter; left time: 450.5542s
	iters: 200, epoch: 13 | loss: 3.3685629
	speed: 0.0210s/iter; left time: 398.2063s
Epoch: 13 cost time: 4.854250431060791
Epoch: 13, Steps: 218 Train Loss: 3.2520 (Forecasting Loss:0.3835 + XiCon Loss:2.8685 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.4006
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.3051832
	speed: 0.0240s/iter; left time: 452.6884s
	iters: 200, epoch: 14 | loss: 3.2236681
	speed: 0.0211s/iter; left time: 395.4793s
Epoch: 14 cost time: 4.913806915283203
Epoch: 14, Steps: 218 Train Loss: 3.2540 (Forecasting Loss:0.3840 + XiCon Loss:2.8699 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.4006
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.36280107498168945, mae:0.45573684573173523, mape:5.495328903198242, mspe:76629.9453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3796+-0.03077, MAE:0.4702+-0.02302, MAPE:5.7831+-0.43624, MSPE:87942.6953+-15566.53420, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.4051
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 3.3290179
	speed: 0.0209s/iter; left time: 437.3907s
	iters: 200, epoch: 1 | loss: 3.1384220
	speed: 0.0155s/iter; left time: 323.0149s
Epoch: 1 cost time: 3.827847719192505
Epoch: 1, Steps: 210 Train Loss: 3.3033 (Forecasting Loss:0.8331 + XiCon Loss:2.4702 x Lambda(1.0)), Vali MSE Loss: 0.2754 Test MSE Loss: 0.6044
Validation loss decreased (inf --> 0.275436).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 2.9430037
	speed: 0.0178s/iter; left time: 368.1951s
	iters: 200, epoch: 2 | loss: 2.8540347
	speed: 0.0165s/iter; left time: 340.6162s
Epoch: 2 cost time: 3.614902973175049
Epoch: 2, Steps: 210 Train Loss: 2.8773 (Forecasting Loss:0.5415 + XiCon Loss:2.3358 x Lambda(1.0)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.5047
Validation loss decreased (0.275436 --> 0.259858).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.8609455
	speed: 0.0181s/iter; left time: 371.3862s
	iters: 200, epoch: 3 | loss: 2.7647700
	speed: 0.0165s/iter; left time: 336.6128s
Epoch: 3 cost time: 3.6683032512664795
Epoch: 3, Steps: 210 Train Loss: 2.8627 (Forecasting Loss:0.4849 + XiCon Loss:2.3778 x Lambda(1.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.4929
Validation loss decreased (0.259858 --> 0.232845).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.8382082
	speed: 0.0187s/iter; left time: 378.3635s
	iters: 200, epoch: 4 | loss: 2.7887769
	speed: 0.0163s/iter; left time: 328.3573s
Epoch: 4 cost time: 3.670870542526245
Epoch: 4, Steps: 210 Train Loss: 2.8120 (Forecasting Loss:0.4635 + XiCon Loss:2.3484 x Lambda(1.0)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.4955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 2.6339073
	speed: 0.0181s/iter; left time: 362.8618s
	iters: 200, epoch: 5 | loss: 2.8377013
	speed: 0.0155s/iter; left time: 308.4933s
Epoch: 5 cost time: 3.564858913421631
Epoch: 5, Steps: 210 Train Loss: 2.7913 (Forecasting Loss:0.4547 + XiCon Loss:2.3365 x Lambda(1.0)), Vali MSE Loss: 0.2366 Test MSE Loss: 0.5031
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 2.8656583
	speed: 0.0177s/iter; left time: 351.4414s
	iters: 200, epoch: 6 | loss: 2.6797566
	speed: 0.0156s/iter; left time: 307.8612s
Epoch: 6 cost time: 3.4992167949676514
Epoch: 6, Steps: 210 Train Loss: 2.7752 (Forecasting Loss:0.4503 + XiCon Loss:2.3249 x Lambda(1.0)), Vali MSE Loss: 0.2331 Test MSE Loss: 0.4904
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.7565582
	speed: 0.0173s/iter; left time: 340.2161s
	iters: 200, epoch: 7 | loss: 2.7416518
	speed: 0.0157s/iter; left time: 306.7895s
Epoch: 7 cost time: 3.495649576187134
Epoch: 7, Steps: 210 Train Loss: 2.7675 (Forecasting Loss:0.4479 + XiCon Loss:2.3196 x Lambda(1.0)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.4672
Validation loss decreased (0.232845 --> 0.225038).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 2.8520694
	speed: 0.0188s/iter; left time: 366.1401s
	iters: 200, epoch: 8 | loss: 2.9611635
	speed: 0.0156s/iter; left time: 300.6993s
Epoch: 8 cost time: 3.6065216064453125
Epoch: 8, Steps: 210 Train Loss: 2.7649 (Forecasting Loss:0.4460 + XiCon Loss:2.3190 x Lambda(1.0)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.4572
Validation loss decreased (0.225038 --> 0.220937).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.7598114
	speed: 0.0180s/iter; left time: 346.8158s
	iters: 200, epoch: 9 | loss: 2.7170053
	speed: 0.0160s/iter; left time: 305.3787s
Epoch: 9 cost time: 3.606138229370117
Epoch: 9, Steps: 210 Train Loss: 2.7706 (Forecasting Loss:0.4455 + XiCon Loss:2.3250 x Lambda(1.0)), Vali MSE Loss: 0.2231 Test MSE Loss: 0.4594
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 2.7172940
	speed: 0.0185s/iter; left time: 352.3759s
	iters: 200, epoch: 10 | loss: 2.7181315
	speed: 0.0152s/iter; left time: 288.2120s
Epoch: 10 cost time: 3.5494165420532227
Epoch: 10, Steps: 210 Train Loss: 2.7648 (Forecasting Loss:0.4454 + XiCon Loss:2.3194 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.4577
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 2.9162540
	speed: 0.0185s/iter; left time: 347.4656s
	iters: 200, epoch: 11 | loss: 2.7893786
	speed: 0.0156s/iter; left time: 291.7869s
Epoch: 11 cost time: 3.5992023944854736
Epoch: 11, Steps: 210 Train Loss: 2.7734 (Forecasting Loss:0.4452 + XiCon Loss:2.3283 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.4573
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 2.6862273
	speed: 0.0182s/iter; left time: 338.7847s
	iters: 200, epoch: 12 | loss: 2.7893434
	speed: 0.0153s/iter; left time: 283.8048s
Epoch: 12 cost time: 3.5304088592529297
Epoch: 12, Steps: 210 Train Loss: 2.7663 (Forecasting Loss:0.4450 + XiCon Loss:2.3213 x Lambda(1.0)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.4546
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 2.7022152
	speed: 0.0182s/iter; left time: 334.5562s
	iters: 200, epoch: 13 | loss: 2.6956804
	speed: 0.0157s/iter; left time: 287.5330s
Epoch: 13 cost time: 3.5907371044158936
Epoch: 13, Steps: 210 Train Loss: 2.7722 (Forecasting Loss:0.4446 + XiCon Loss:2.3276 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.4572
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 2.9198067
	speed: 0.0185s/iter; left time: 335.7998s
	iters: 200, epoch: 14 | loss: 3.0218325
	speed: 0.0156s/iter; left time: 282.7459s
Epoch: 14 cost time: 3.5853054523468018
Epoch: 14, Steps: 210 Train Loss: 2.7719 (Forecasting Loss:0.4448 + XiCon Loss:2.3272 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.4565
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 2.7458253
	speed: 0.0172s/iter; left time: 309.7169s
	iters: 200, epoch: 15 | loss: 2.8343854
	speed: 0.0156s/iter; left time: 279.3310s
Epoch: 15 cost time: 3.4762017726898193
Epoch: 15, Steps: 210 Train Loss: 2.7769 (Forecasting Loss:0.4454 + XiCon Loss:2.3314 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.4565
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 2.8120255
	speed: 0.0177s/iter; left time: 314.4883s
	iters: 200, epoch: 16 | loss: 2.7050638
	speed: 0.0161s/iter; left time: 284.0454s
Epoch: 16 cost time: 3.6004321575164795
Epoch: 16, Steps: 210 Train Loss: 2.7680 (Forecasting Loss:0.4446 + XiCon Loss:2.3234 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.4567
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 2.6124487
	speed: 0.0180s/iter; left time: 316.1151s
	iters: 200, epoch: 17 | loss: 2.7896981
	speed: 0.0159s/iter; left time: 277.3712s
Epoch: 17 cost time: 3.57936429977417
Epoch: 17, Steps: 210 Train Loss: 2.7735 (Forecasting Loss:0.4452 + XiCon Loss:2.3283 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.4566
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 2.7735839
	speed: 0.0184s/iter; left time: 318.4371s
	iters: 200, epoch: 18 | loss: 2.6568513
	speed: 0.0160s/iter; left time: 276.1405s
Epoch: 18 cost time: 3.612039089202881
Epoch: 18, Steps: 210 Train Loss: 2.7680 (Forecasting Loss:0.4444 + XiCon Loss:2.3236 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.4565
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.4190811216831207, mae:0.4954100549221039, mape:4.216522216796875, mspe:31352.59765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.5350
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 3.3019476
	speed: 0.0182s/iter; left time: 380.0191s
	iters: 200, epoch: 1 | loss: 3.1561539
	speed: 0.0163s/iter; left time: 338.7827s
Epoch: 1 cost time: 3.6287288665771484
Epoch: 1, Steps: 210 Train Loss: 3.3070 (Forecasting Loss:0.8405 + XiCon Loss:2.4665 x Lambda(1.0)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.6684
Validation loss decreased (inf --> 0.278958).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 2.7812586
	speed: 0.0194s/iter; left time: 402.0701s
	iters: 200, epoch: 2 | loss: 2.7787330
	speed: 0.0195s/iter; left time: 402.1472s
Epoch: 2 cost time: 4.133039951324463
Epoch: 2, Steps: 210 Train Loss: 2.8663 (Forecasting Loss:0.5375 + XiCon Loss:2.3288 x Lambda(1.0)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.5243
Validation loss decreased (0.278958 --> 0.240111).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.7438812
	speed: 0.0230s/iter; left time: 471.4767s
	iters: 200, epoch: 3 | loss: 2.8398554
	speed: 0.0204s/iter; left time: 415.4029s
Epoch: 3 cost time: 4.57183837890625
Epoch: 3, Steps: 210 Train Loss: 2.7495 (Forecasting Loss:0.4553 + XiCon Loss:2.2942 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.6229
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.7747695
	speed: 0.0224s/iter; left time: 454.8744s
	iters: 200, epoch: 4 | loss: 2.5918827
	speed: 0.0201s/iter; left time: 405.4748s
Epoch: 4 cost time: 4.472149133682251
Epoch: 4, Steps: 210 Train Loss: 2.7070 (Forecasting Loss:0.4278 + XiCon Loss:2.2792 x Lambda(1.0)), Vali MSE Loss: 0.2386 Test MSE Loss: 0.6509
Validation loss decreased (0.240111 --> 0.238616).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 2.7127705
	speed: 0.0222s/iter; left time: 445.5676s
	iters: 200, epoch: 5 | loss: 2.6242065
	speed: 0.0205s/iter; left time: 408.6456s
Epoch: 5 cost time: 4.4932861328125
Epoch: 5, Steps: 210 Train Loss: 2.6883 (Forecasting Loss:0.4183 + XiCon Loss:2.2699 x Lambda(1.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.6699
Validation loss decreased (0.238616 --> 0.231875).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 2.7014279
	speed: 0.0224s/iter; left time: 445.5546s
	iters: 200, epoch: 6 | loss: 2.7435706
	speed: 0.0198s/iter; left time: 390.9272s
Epoch: 6 cost time: 4.477360725402832
Epoch: 6, Steps: 210 Train Loss: 2.6836 (Forecasting Loss:0.4138 + XiCon Loss:2.2698 x Lambda(1.0)), Vali MSE Loss: 0.2304 Test MSE Loss: 0.7093
Validation loss decreased (0.231875 --> 0.230402).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.6062641
	speed: 0.0224s/iter; left time: 439.5758s
	iters: 200, epoch: 7 | loss: 2.6200070
	speed: 0.0202s/iter; left time: 395.1940s
Epoch: 7 cost time: 4.499932289123535
Epoch: 7, Steps: 210 Train Loss: 2.6747 (Forecasting Loss:0.4119 + XiCon Loss:2.2628 x Lambda(1.0)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.6414
Validation loss decreased (0.230402 --> 0.229324).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 2.5761850
	speed: 0.0220s/iter; left time: 426.6597s
	iters: 200, epoch: 8 | loss: 2.6609144
	speed: 0.0204s/iter; left time: 393.6954s
Epoch: 8 cost time: 4.473875284194946
Epoch: 8, Steps: 210 Train Loss: 2.6728 (Forecasting Loss:0.4101 + XiCon Loss:2.2627 x Lambda(1.0)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.6503
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.6036241
	speed: 0.0222s/iter; left time: 427.2546s
	iters: 200, epoch: 9 | loss: 2.6784594
	speed: 0.0199s/iter; left time: 380.5331s
Epoch: 9 cost time: 4.458642482757568
Epoch: 9, Steps: 210 Train Loss: 2.6726 (Forecasting Loss:0.4095 + XiCon Loss:2.2630 x Lambda(1.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.6651
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 2.6778996
	speed: 0.0226s/iter; left time: 430.4076s
	iters: 200, epoch: 10 | loss: 2.6866255
	speed: 0.0204s/iter; left time: 385.7103s
Epoch: 10 cost time: 4.53234601020813
Epoch: 10, Steps: 210 Train Loss: 2.6706 (Forecasting Loss:0.4094 + XiCon Loss:2.2612 x Lambda(1.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.6652
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 2.5428708
	speed: 0.0223s/iter; left time: 420.1329s
	iters: 200, epoch: 11 | loss: 2.6928976
	speed: 0.0202s/iter; left time: 377.4472s
Epoch: 11 cost time: 4.461810350418091
Epoch: 11, Steps: 210 Train Loss: 2.6663 (Forecasting Loss:0.4093 + XiCon Loss:2.2570 x Lambda(1.0)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.6646
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 2.6157250
	speed: 0.0227s/iter; left time: 421.6191s
	iters: 200, epoch: 12 | loss: 2.6260288
	speed: 0.0203s/iter; left time: 375.3246s
Epoch: 12 cost time: 4.54746150970459
Epoch: 12, Steps: 210 Train Loss: 2.6612 (Forecasting Loss:0.4094 + XiCon Loss:2.2518 x Lambda(1.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.6636
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 2.6491752
	speed: 0.0227s/iter; left time: 417.2157s
	iters: 200, epoch: 13 | loss: 2.6902287
	speed: 0.0203s/iter; left time: 371.5727s
Epoch: 13 cost time: 4.5249247550964355
Epoch: 13, Steps: 210 Train Loss: 2.6609 (Forecasting Loss:0.4088 + XiCon Loss:2.2521 x Lambda(1.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.6626
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 2.7765472
	speed: 0.0223s/iter; left time: 405.3650s
	iters: 200, epoch: 14 | loss: 2.6180308
	speed: 0.0204s/iter; left time: 367.8873s
Epoch: 14 cost time: 4.519620418548584
Epoch: 14, Steps: 210 Train Loss: 2.6658 (Forecasting Loss:0.4089 + XiCon Loss:2.2569 x Lambda(1.0)), Vali MSE Loss: 0.2297 Test MSE Loss: 0.6638
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 2.6363759
	speed: 0.0227s/iter; left time: 407.7068s
	iters: 200, epoch: 15 | loss: 2.7280426
	speed: 0.0207s/iter; left time: 368.9797s
Epoch: 15 cost time: 4.5457892417907715
Epoch: 15, Steps: 210 Train Loss: 2.6686 (Forecasting Loss:0.4092 + XiCon Loss:2.2594 x Lambda(1.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.6640
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 2.7206957
	speed: 0.0226s/iter; left time: 401.2506s
	iters: 200, epoch: 16 | loss: 2.7125096
	speed: 0.0199s/iter; left time: 350.6016s
Epoch: 16 cost time: 4.455054521560669
Epoch: 16, Steps: 210 Train Loss: 2.6739 (Forecasting Loss:0.4090 + XiCon Loss:2.2649 x Lambda(1.0)), Vali MSE Loss: 0.2297 Test MSE Loss: 0.6640
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 2.7354367
	speed: 0.0232s/iter; left time: 406.4955s
	iters: 200, epoch: 17 | loss: 2.5890689
	speed: 0.0206s/iter; left time: 359.0511s
Epoch: 17 cost time: 4.59826922416687
Epoch: 17, Steps: 210 Train Loss: 2.6649 (Forecasting Loss:0.4091 + XiCon Loss:2.2557 x Lambda(1.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.6640
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.6554690599441528, mae:0.6272913217544556, mape:3.953786849975586, mspe:8844.546875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.3651
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 3.2422493
	speed: 0.0193s/iter; left time: 403.8561s
	iters: 200, epoch: 1 | loss: 3.0845451
	speed: 0.0164s/iter; left time: 340.6136s
Epoch: 1 cost time: 3.750946044921875
Epoch: 1, Steps: 210 Train Loss: 3.2916 (Forecasting Loss:0.8410 + XiCon Loss:2.4505 x Lambda(1.0)), Vali MSE Loss: 0.2800 Test MSE Loss: 0.6891
Validation loss decreased (inf --> 0.280005).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 2.8218503
	speed: 0.0207s/iter; left time: 428.1813s
	iters: 200, epoch: 2 | loss: 2.8578036
	speed: 0.0189s/iter; left time: 389.4303s
Epoch: 2 cost time: 4.1804444789886475
Epoch: 2, Steps: 210 Train Loss: 2.9015 (Forecasting Loss:0.5597 + XiCon Loss:2.3418 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.5737
Validation loss decreased (0.280005 --> 0.244927).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.8229597
	speed: 0.0218s/iter; left time: 445.7006s
	iters: 200, epoch: 3 | loss: 2.8726234
	speed: 0.0194s/iter; left time: 395.9651s
Epoch: 3 cost time: 4.335416793823242
Epoch: 3, Steps: 210 Train Loss: 2.8262 (Forecasting Loss:0.4743 + XiCon Loss:2.3519 x Lambda(1.0)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.5704
Validation loss decreased (0.244927 --> 0.234176).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.7311931
	speed: 0.0224s/iter; left time: 454.2750s
	iters: 200, epoch: 4 | loss: 2.7008650
	speed: 0.0199s/iter; left time: 401.4922s
Epoch: 4 cost time: 4.444166660308838
Epoch: 4, Steps: 210 Train Loss: 2.7786 (Forecasting Loss:0.4508 + XiCon Loss:2.3278 x Lambda(1.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.5899
Validation loss decreased (0.234176 --> 0.229879).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 2.7697163
	speed: 0.0219s/iter; left time: 440.1026s
	iters: 200, epoch: 5 | loss: 2.8747997
	speed: 0.0195s/iter; left time: 389.7577s
Epoch: 5 cost time: 4.401102542877197
Epoch: 5, Steps: 210 Train Loss: 2.7564 (Forecasting Loss:0.4397 + XiCon Loss:2.3168 x Lambda(1.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.6033
Validation loss decreased (0.229879 --> 0.226401).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 2.7169592
	speed: 0.0225s/iter; left time: 445.7701s
	iters: 200, epoch: 6 | loss: 2.9073629
	speed: 0.0195s/iter; left time: 385.7721s
Epoch: 6 cost time: 4.454962491989136
Epoch: 6, Steps: 210 Train Loss: 2.7610 (Forecasting Loss:0.4364 + XiCon Loss:2.3246 x Lambda(1.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.5809
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.7851226
	speed: 0.0219s/iter; left time: 430.4731s
	iters: 200, epoch: 7 | loss: 2.8699651
	speed: 0.0196s/iter; left time: 383.7848s
Epoch: 7 cost time: 4.37301778793335
Epoch: 7, Steps: 210 Train Loss: 2.7545 (Forecasting Loss:0.4331 + XiCon Loss:2.3214 x Lambda(1.0)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.5833
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 2.7751949
	speed: 0.0221s/iter; left time: 429.3935s
	iters: 200, epoch: 8 | loss: 2.6788139
	speed: 0.0196s/iter; left time: 379.0109s
Epoch: 8 cost time: 4.405067443847656
Epoch: 8, Steps: 210 Train Loss: 2.7498 (Forecasting Loss:0.4306 + XiCon Loss:2.3192 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.5830
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.7200313
	speed: 0.0224s/iter; left time: 431.1678s
	iters: 200, epoch: 9 | loss: 2.8390219
	speed: 0.0197s/iter; left time: 376.7859s
Epoch: 9 cost time: 4.434325933456421
Epoch: 9, Steps: 210 Train Loss: 2.7486 (Forecasting Loss:0.4299 + XiCon Loss:2.3187 x Lambda(1.0)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.5856
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 2.7947459
	speed: 0.0222s/iter; left time: 421.3632s
	iters: 200, epoch: 10 | loss: 2.7573087
	speed: 0.0194s/iter; left time: 366.2486s
Epoch: 10 cost time: 4.396288633346558
Epoch: 10, Steps: 210 Train Loss: 2.7487 (Forecasting Loss:0.4303 + XiCon Loss:2.3184 x Lambda(1.0)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.5831
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 2.6737890
	speed: 0.0221s/iter; left time: 414.9743s
	iters: 200, epoch: 11 | loss: 2.7685494
	speed: 0.0194s/iter; left time: 362.9526s
Epoch: 11 cost time: 4.370516061782837
Epoch: 11, Steps: 210 Train Loss: 2.7496 (Forecasting Loss:0.4295 + XiCon Loss:2.3201 x Lambda(1.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.5834
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 2.6855240
	speed: 0.0217s/iter; left time: 403.3947s
	iters: 200, epoch: 12 | loss: 2.7661116
	speed: 0.0197s/iter; left time: 364.8148s
Epoch: 12 cost time: 4.370876312255859
Epoch: 12, Steps: 210 Train Loss: 2.7532 (Forecasting Loss:0.4299 + XiCon Loss:2.3233 x Lambda(1.0)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.5831
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 2.8036325
	speed: 0.0221s/iter; left time: 406.9760s
	iters: 200, epoch: 13 | loss: 2.8422711
	speed: 0.0197s/iter; left time: 360.0159s
Epoch: 13 cost time: 4.4188854694366455
Epoch: 13, Steps: 210 Train Loss: 2.7534 (Forecasting Loss:0.4293 + XiCon Loss:2.3241 x Lambda(1.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.5832
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 2.5973492
	speed: 0.0220s/iter; left time: 399.2793s
	iters: 200, epoch: 14 | loss: 2.7730322
	speed: 0.0194s/iter; left time: 350.4139s
Epoch: 14 cost time: 4.347028732299805
Epoch: 14, Steps: 210 Train Loss: 2.7509 (Forecasting Loss:0.4292 + XiCon Loss:2.3217 x Lambda(1.0)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.5829
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 2.7813947
	speed: 0.0219s/iter; left time: 394.0025s
	iters: 200, epoch: 15 | loss: 2.7799797
	speed: 0.0199s/iter; left time: 355.3237s
Epoch: 15 cost time: 4.427983522415161
Epoch: 15, Steps: 210 Train Loss: 2.7466 (Forecasting Loss:0.4294 + XiCon Loss:2.3172 x Lambda(1.0)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.5830
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.6009023189544678, mae:0.6056120991706848, mape:3.405292510986328, mspe:2103.636962890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.3541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 3.3008227
	speed: 0.0191s/iter; left time: 399.8651s
	iters: 200, epoch: 1 | loss: 3.0255351
	speed: 0.0160s/iter; left time: 332.6489s
Epoch: 1 cost time: 3.6834776401519775
Epoch: 1, Steps: 210 Train Loss: 3.2771 (Forecasting Loss:0.8195 + XiCon Loss:2.4575 x Lambda(1.0)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.5521
Validation loss decreased (inf --> 0.267108).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 2.9403381
	speed: 0.0188s/iter; left time: 388.1051s
	iters: 200, epoch: 2 | loss: 2.8402462
	speed: 0.0161s/iter; left time: 331.0732s
Epoch: 2 cost time: 3.6651947498321533
Epoch: 2, Steps: 210 Train Loss: 2.9645 (Forecasting Loss:0.5991 + XiCon Loss:2.3654 x Lambda(1.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.6628
Validation loss decreased (0.267108 --> 0.231649).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.9009764
	speed: 0.0190s/iter; left time: 389.4041s
	iters: 200, epoch: 3 | loss: 2.9214301
	speed: 0.0167s/iter; left time: 339.6758s
Epoch: 3 cost time: 3.7500030994415283
Epoch: 3, Steps: 210 Train Loss: 2.8574 (Forecasting Loss:0.4962 + XiCon Loss:2.3612 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.5427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.9402473
	speed: 0.0191s/iter; left time: 386.9271s
	iters: 200, epoch: 4 | loss: 2.8521192
	speed: 0.0163s/iter; left time: 329.4958s
Epoch: 4 cost time: 3.7299892902374268
Epoch: 4, Steps: 210 Train Loss: 2.8024 (Forecasting Loss:0.4697 + XiCon Loss:2.3326 x Lambda(1.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.6873
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 2.7601511
	speed: 0.0194s/iter; left time: 389.5709s
	iters: 200, epoch: 5 | loss: 2.7191811
	speed: 0.0176s/iter; left time: 350.6996s
Epoch: 5 cost time: 3.926405429840088
Epoch: 5, Steps: 210 Train Loss: 2.7821 (Forecasting Loss:0.4587 + XiCon Loss:2.3234 x Lambda(1.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.6848
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 2.7818894
	speed: 0.0203s/iter; left time: 403.0266s
	iters: 200, epoch: 6 | loss: 2.7627764
	speed: 0.0177s/iter; left time: 348.8199s
Epoch: 6 cost time: 4.029206991195679
Epoch: 6, Steps: 210 Train Loss: 2.7696 (Forecasting Loss:0.4527 + XiCon Loss:2.3170 x Lambda(1.0)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.6482
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.7664094
	speed: 0.0199s/iter; left time: 391.3771s
	iters: 200, epoch: 7 | loss: 2.7102189
	speed: 0.0178s/iter; left time: 348.5752s
Epoch: 7 cost time: 3.973062515258789
Epoch: 7, Steps: 210 Train Loss: 2.7583 (Forecasting Loss:0.4501 + XiCon Loss:2.3081 x Lambda(1.0)), Vali MSE Loss: 0.2344 Test MSE Loss: 0.6536
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 2.7007875
	speed: 0.0203s/iter; left time: 395.4162s
	iters: 200, epoch: 8 | loss: 2.7186642
	speed: 0.0184s/iter; left time: 355.4692s
Epoch: 8 cost time: 4.0731165409088135
Epoch: 8, Steps: 210 Train Loss: 2.7564 (Forecasting Loss:0.4492 + XiCon Loss:2.3072 x Lambda(1.0)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.6527
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.7285748
	speed: 0.0202s/iter; left time: 387.5612s
	iters: 200, epoch: 9 | loss: 2.8090184
	speed: 0.0183s/iter; left time: 350.8176s
Epoch: 9 cost time: 4.062485218048096
Epoch: 9, Steps: 210 Train Loss: 2.7568 (Forecasting Loss:0.4488 + XiCon Loss:2.3080 x Lambda(1.0)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.6496
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 2.7615600
	speed: 0.0204s/iter; left time: 387.8153s
	iters: 200, epoch: 10 | loss: 2.7128003
	speed: 0.0181s/iter; left time: 342.5862s
Epoch: 10 cost time: 4.07184100151062
Epoch: 10, Steps: 210 Train Loss: 2.7612 (Forecasting Loss:0.4478 + XiCon Loss:2.3134 x Lambda(1.0)), Vali MSE Loss: 0.2396 Test MSE Loss: 0.6655
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 2.7040524
	speed: 0.0208s/iter; left time: 390.2122s
	iters: 200, epoch: 11 | loss: 2.7945302
	speed: 0.0183s/iter; left time: 341.3352s
Epoch: 11 cost time: 4.1422905921936035
Epoch: 11, Steps: 210 Train Loss: 2.7573 (Forecasting Loss:0.4477 + XiCon Loss:2.3095 x Lambda(1.0)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.6610
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 2.6952615
	speed: 0.0208s/iter; left time: 387.4394s
	iters: 200, epoch: 12 | loss: 2.8276229
	speed: 0.0182s/iter; left time: 336.6181s
Epoch: 12 cost time: 4.129191637039185
Epoch: 12, Steps: 210 Train Loss: 2.7609 (Forecasting Loss:0.4473 + XiCon Loss:2.3136 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.6584
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.6790749430656433, mae:0.6464905738830566, mape:4.637449741363525, mspe:27533.73828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 5.4056
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 3.3786619
	speed: 0.0188s/iter; left time: 393.2972s
	iters: 200, epoch: 1 | loss: 3.1696153
	speed: 0.0161s/iter; left time: 335.3753s
Epoch: 1 cost time: 3.6771233081817627
Epoch: 1, Steps: 210 Train Loss: 3.2965 (Forecasting Loss:0.8411 + XiCon Loss:2.4554 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.6918
Validation loss decreased (inf --> 0.279577).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 2.9191480
	speed: 0.0200s/iter; left time: 414.7242s
	iters: 200, epoch: 2 | loss: 2.9957833
	speed: 0.0182s/iter; left time: 374.0386s
Epoch: 2 cost time: 4.033620357513428
Epoch: 2, Steps: 210 Train Loss: 2.9572 (Forecasting Loss:0.5928 + XiCon Loss:2.3644 x Lambda(1.0)), Vali MSE Loss: 0.2442 Test MSE Loss: 0.6330
Validation loss decreased (0.279577 --> 0.244211).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.8485060
	speed: 0.0218s/iter; left time: 446.7585s
	iters: 200, epoch: 3 | loss: 2.8589809
	speed: 0.0190s/iter; left time: 386.6147s
Epoch: 3 cost time: 4.307909250259399
Epoch: 3, Steps: 210 Train Loss: 2.8399 (Forecasting Loss:0.4808 + XiCon Loss:2.3590 x Lambda(1.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.6510
Validation loss decreased (0.244211 --> 0.236781).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.7010484
	speed: 0.0211s/iter; left time: 427.4267s
	iters: 200, epoch: 4 | loss: 2.6835876
	speed: 0.0193s/iter; left time: 389.5193s
Epoch: 4 cost time: 4.248591899871826
Epoch: 4, Steps: 210 Train Loss: 2.7637 (Forecasting Loss:0.4431 + XiCon Loss:2.3207 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.6580
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 2.7855203
	speed: 0.0210s/iter; left time: 422.2226s
	iters: 200, epoch: 5 | loss: 2.8364570
	speed: 0.0187s/iter; left time: 373.3602s
Epoch: 5 cost time: 4.176102161407471
Epoch: 5, Steps: 210 Train Loss: 2.7395 (Forecasting Loss:0.4283 + XiCon Loss:2.3112 x Lambda(1.0)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.6455
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 2.7225661
	speed: 0.0209s/iter; left time: 415.3431s
	iters: 200, epoch: 6 | loss: 2.7608716
	speed: 0.0193s/iter; left time: 381.5749s
Epoch: 6 cost time: 4.268388748168945
Epoch: 6, Steps: 210 Train Loss: 2.7380 (Forecasting Loss:0.4222 + XiCon Loss:2.3157 x Lambda(1.0)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.7377
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.6052465
	speed: 0.0213s/iter; left time: 419.0989s
	iters: 200, epoch: 7 | loss: 2.7163000
	speed: 0.0192s/iter; left time: 374.2906s
Epoch: 7 cost time: 4.258390665054321
Epoch: 7, Steps: 210 Train Loss: 2.7247 (Forecasting Loss:0.4174 + XiCon Loss:2.3074 x Lambda(1.0)), Vali MSE Loss: 0.2688 Test MSE Loss: 0.7285
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 2.6766360
	speed: 0.0210s/iter; left time: 408.8559s
	iters: 200, epoch: 8 | loss: 2.6735120
	speed: 0.0190s/iter; left time: 366.8385s
Epoch: 8 cost time: 4.2010674476623535
Epoch: 8, Steps: 210 Train Loss: 2.7270 (Forecasting Loss:0.4159 + XiCon Loss:2.3112 x Lambda(1.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.7174
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.8493776
	speed: 0.0218s/iter; left time: 418.2148s
	iters: 200, epoch: 9 | loss: 2.8669999
	speed: 0.0186s/iter; left time: 356.3830s
Epoch: 9 cost time: 4.277479887008667
Epoch: 9, Steps: 210 Train Loss: 2.7166 (Forecasting Loss:0.4154 + XiCon Loss:2.3011 x Lambda(1.0)), Vali MSE Loss: 0.2668 Test MSE Loss: 0.7282
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 2.6763055
	speed: 0.0216s/iter; left time: 410.6790s
	iters: 200, epoch: 10 | loss: 2.6992900
	speed: 0.0195s/iter; left time: 368.8126s
Epoch: 10 cost time: 4.322218418121338
Epoch: 10, Steps: 210 Train Loss: 2.7154 (Forecasting Loss:0.4143 + XiCon Loss:2.3012 x Lambda(1.0)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.7128
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 2.7735553
	speed: 0.0210s/iter; left time: 394.6632s
	iters: 200, epoch: 11 | loss: 2.7297776
	speed: 0.0192s/iter; left time: 358.9488s
Epoch: 11 cost time: 4.231714725494385
Epoch: 11, Steps: 210 Train Loss: 2.7218 (Forecasting Loss:0.4145 + XiCon Loss:2.3073 x Lambda(1.0)), Vali MSE Loss: 0.2691 Test MSE Loss: 0.7160
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 2.6874299
	speed: 0.0220s/iter; left time: 408.5113s
	iters: 200, epoch: 12 | loss: 2.6815000
	speed: 0.0188s/iter; left time: 347.1292s
Epoch: 12 cost time: 4.291382074356079
Epoch: 12, Steps: 210 Train Loss: 2.7177 (Forecasting Loss:0.4139 + XiCon Loss:2.3038 x Lambda(1.0)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.7190
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 2.6672506
	speed: 0.0216s/iter; left time: 396.2877s
	iters: 200, epoch: 13 | loss: 2.7721112
	speed: 0.0189s/iter; left time: 345.7407s
Epoch: 13 cost time: 4.26927924156189
Epoch: 13, Steps: 210 Train Loss: 2.7207 (Forecasting Loss:0.4142 + XiCon Loss:2.3065 x Lambda(1.0)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.7196
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.6648279428482056, mae:0.6371408700942993, mape:4.34413480758667, mspe:17132.216796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6039+-0.13343, MAE:0.6024+-0.07661, MAPE:4.1114+-0.57753, MSPE:17393.3477+-15265.57012, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
