Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6412
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.2346413135528564
Epoch: 1, Steps: 69 Train Loss: 0.1506 (Forecasting Loss:0.1323 + XiCon Loss:1.8364 x Lambda(0.01)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.1489
Validation loss decreased (inf --> 0.284155).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.0464208126068115
Epoch: 2, Steps: 69 Train Loss: 0.1276 (Forecasting Loss:0.1093 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1199
Validation loss decreased (0.284155 --> 0.210362).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9881668090820312
Epoch: 3, Steps: 69 Train Loss: 0.1189 (Forecasting Loss:0.1005 + XiCon Loss:1.8398 x Lambda(0.01)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.210362 --> 0.203383).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8986673355102539
Epoch: 4, Steps: 69 Train Loss: 0.1167 (Forecasting Loss:0.0984 + XiCon Loss:1.8350 x Lambda(0.01)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1161
Validation loss decreased (0.203383 --> 0.200989).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8792479038238525
Epoch: 5, Steps: 69 Train Loss: 0.1159 (Forecasting Loss:0.0975 + XiCon Loss:1.8371 x Lambda(0.01)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1153
Validation loss decreased (0.200989 --> 0.199818).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.0418236255645752
Epoch: 6, Steps: 69 Train Loss: 0.1156 (Forecasting Loss:0.0973 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1150
Validation loss decreased (0.199818 --> 0.199360).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9290330410003662
Epoch: 7, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8405 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1149
Validation loss decreased (0.199360 --> 0.199019).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.887122392654419
Epoch: 8, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8312 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9838500022888184
Epoch: 9, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.199019 --> 0.198935).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9312231540679932
Epoch: 10, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8383 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198935 --> 0.198903).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.938917875289917
Epoch: 11, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8406 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198903 --> 0.198890).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 1.0040862560272217
Epoch: 12, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8359 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198890 --> 0.198882).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.020679235458374
Epoch: 13, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8376 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198882 --> 0.198878).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9333574771881104
Epoch: 14, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8354 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198878 --> 0.198876).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9487056732177734
Epoch: 15, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8404 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198876 --> 0.198875).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8996634483337402
Epoch: 16, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8360 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198875 --> 0.198875).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.0052249431610107
Epoch: 17, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8340 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198875 --> 0.198875).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9800434112548828
Epoch: 18, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8326 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198875 --> 0.198874).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8314015865325928
Epoch: 19, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8347 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198874 --> 0.198874).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9608166217803955
Epoch: 20, Steps: 69 Train Loss: 0.1156 (Forecasting Loss:0.0972 + XiCon Loss:1.8369 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198874 --> 0.198874).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9487762451171875
Epoch: 21, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0969 + XiCon Loss:1.8295 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8414394855499268
Epoch: 22, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8311 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198874 --> 0.198874).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9799642562866211
Epoch: 23, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8350 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9739673137664795
Epoch: 24, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8336 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198874 --> 0.198874).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8592545986175537
Epoch: 25, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8383 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198874 --> 0.198874).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 1.018078327178955
Epoch: 26, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8344 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9518828392028809
Epoch: 27, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8930940628051758
Epoch: 28, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8361 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8838455677032471
Epoch: 29, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8336 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.9308984279632568
Epoch: 30, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0971 + XiCon Loss:1.8341 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9137978553771973
Epoch: 31, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9350290298461914
Epoch: 32, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8329 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9573588371276855
Epoch: 33, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9138131141662598
Epoch: 34, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8366 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8934884071350098
Epoch: 35, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8363 x Lambda(0.01)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05357600748538971, mae:0.1761290431022644, mape:0.1226235181093216, mspe:0.03547484800219536 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7186
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9333198070526123
Epoch: 1, Steps: 69 Train Loss: 0.1514 (Forecasting Loss:0.1330 + XiCon Loss:1.8407 x Lambda(0.01)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.1497
Validation loss decreased (inf --> 0.285439).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9628293514251709
Epoch: 2, Steps: 69 Train Loss: 0.1279 (Forecasting Loss:0.1096 + XiCon Loss:1.8359 x Lambda(0.01)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1199
Validation loss decreased (0.285439 --> 0.210114).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8788282871246338
Epoch: 3, Steps: 69 Train Loss: 0.1182 (Forecasting Loss:0.0999 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.1163
Validation loss decreased (0.210114 --> 0.203829).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9293529987335205
Epoch: 4, Steps: 69 Train Loss: 0.1162 (Forecasting Loss:0.0977 + XiCon Loss:1.8418 x Lambda(0.01)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1149
Validation loss decreased (0.203829 --> 0.201176).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.947188138961792
Epoch: 5, Steps: 69 Train Loss: 0.1156 (Forecasting Loss:0.0973 + XiCon Loss:1.8344 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1154
Validation loss decreased (0.201176 --> 0.199318).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9115500450134277
Epoch: 6, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0969 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1150
Validation loss decreased (0.199318 --> 0.199138).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9537527561187744
Epoch: 7, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0969 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1149
Validation loss decreased (0.199138 --> 0.199097).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.0189075469970703
Epoch: 8, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1148
Validation loss decreased (0.199097 --> 0.199065).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8622140884399414
Epoch: 9, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8379 x Lambda(0.01)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1148
Validation loss decreased (0.199065 --> 0.199055).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9420673847198486
Epoch: 10, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.199055 --> 0.199008).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.966853141784668
Epoch: 11, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8346 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8775465488433838
Epoch: 12, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8352 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.199008 --> 0.199003).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.0435068607330322
Epoch: 13, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.199003 --> 0.198998).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9383926391601562
Epoch: 14, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8386 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9255220890045166
Epoch: 15, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198998 --> 0.198998).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9444143772125244
Epoch: 16, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8352 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198998 --> 0.198997).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9400520324707031
Epoch: 17, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8383 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.918968677520752
Epoch: 18, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8358 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9785962104797363
Epoch: 19, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8360 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9554204940795898
Epoch: 20, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.964003324508667
Epoch: 21, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8376 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8889243602752686
Epoch: 22, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8377 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9434573650360107
Epoch: 23, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.977064847946167
Epoch: 24, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8336 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8542723655700684
Epoch: 25, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8339 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9410955905914307
Epoch: 26, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8391 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9484617710113525
Epoch: 27, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8346 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8808810710906982
Epoch: 28, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8385 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9098665714263916
Epoch: 29, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8369 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.990839958190918
Epoch: 30, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8350 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9813499450683594
Epoch: 31, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8347 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8472955226898193
Epoch: 32, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8367 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9662637710571289
Epoch: 33, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9769778251647949
Epoch: 34, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8390 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9005253314971924
Epoch: 35, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8351 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.9276847839355469
Epoch: 36, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0961 + XiCon Loss:1.8379 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9333796501159668
Epoch: 37, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8328 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8525238037109375
Epoch: 38, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9182620048522949
Epoch: 39, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9575934410095215
Epoch: 40, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0965 + XiCon Loss:1.8406 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9031774997711182
Epoch: 41, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.9839344024658203
Epoch: 42, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8356 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9780099391937256
Epoch: 43, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8378 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8807780742645264
Epoch: 44, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8340 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.811612606048584
Epoch: 45, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8363 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8773767948150635
Epoch: 46, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8335 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 1.0250742435455322
Epoch: 47, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8340 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.9471566677093506
Epoch: 48, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.977348804473877
Epoch: 49, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8370 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9707217216491699
Epoch: 50, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8359 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9156279563903809
Epoch: 51, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8329 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9457018375396729
Epoch: 52, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8384 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.9160375595092773
Epoch: 53, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8391 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8615460395812988
Epoch: 54, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8379 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9357655048370361
Epoch: 55, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8352 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.9395771026611328
Epoch: 56, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8367 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.9044125080108643
Epoch: 57, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8376 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8753745555877686
Epoch: 58, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.9781184196472168
Epoch: 59, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8343 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.932553768157959
Epoch: 60, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8369 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.8826017379760742
Epoch: 61, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8346 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 1.0171754360198975
Epoch: 62, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8344 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.9091336727142334
Epoch: 63, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.913905143737793
Epoch: 64, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8289 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.9598238468170166
Epoch: 65, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.9837334156036377
Epoch: 66, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.8712072372436523
Epoch: 67, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.9667336940765381
Epoch: 68, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8371 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.9125139713287354
Epoch: 69, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.8363626003265381
Epoch: 70, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8390 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.9504556655883789
Epoch: 71, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.9511833190917969
Epoch: 72, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8385 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.8303968906402588
Epoch: 73, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8384 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.9902734756469727
Epoch: 74, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8361 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.9673631191253662
Epoch: 75, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8364 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.9009201526641846
Epoch: 76, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.9121410846710205
Epoch: 77, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8378 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.9889509677886963
Epoch: 78, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.8794224262237549
Epoch: 79, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8339 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 1.008030891418457
Epoch: 80, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8385 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.9076857566833496
Epoch: 81, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8371 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8801329135894775
Epoch: 82, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8312 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.9878089427947998
Epoch: 83, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 1.0070221424102783
Epoch: 84, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8328 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.8501605987548828
Epoch: 85, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8341 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.9971740245819092
Epoch: 86, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8318 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.9357869625091553
Epoch: 87, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8363 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.8589632511138916
Epoch: 88, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8366 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 0.8996233940124512
Epoch: 89, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8372 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 0.9726772308349609
Epoch: 90, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8394 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 0.8699021339416504
Epoch: 91, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8362 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 0.977849006652832
Epoch: 92, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8377 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 1.0134491920471191
Epoch: 93, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8364 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 0.8344323635101318
Epoch: 94, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8366 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 0.9649636745452881
Epoch: 95, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 0.9296255111694336
Epoch: 96, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
Validation loss decreased (0.198997 --> 0.198997).  Saving model ...
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 0.9018745422363281
Epoch: 97, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 0.9321489334106445
Epoch: 98, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.310887241768095e-33
Epoch: 99 cost time: 0.9767146110534668
Epoch: 99, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8343 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.155443620884047e-33
Epoch: 100 cost time: 0.8884067535400391
Epoch: 100, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8367 x Lambda(0.01)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5777218104420236e-33
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.053614575415849686, mae:0.17595483362674713, mape:0.12210167944431305, mspe:0.03501161187887192 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6869
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.968813419342041
Epoch: 1, Steps: 69 Train Loss: 0.1519 (Forecasting Loss:0.1335 + XiCon Loss:1.8385 x Lambda(0.01)), Vali MSE Loss: 0.2872 Test MSE Loss: 0.1505
Validation loss decreased (inf --> 0.287156).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9703614711761475
Epoch: 2, Steps: 69 Train Loss: 0.1296 (Forecasting Loss:0.1112 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1231
Validation loss decreased (0.287156 --> 0.212795).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8807036876678467
Epoch: 3, Steps: 69 Train Loss: 0.1194 (Forecasting Loss:0.1010 + XiCon Loss:1.8356 x Lambda(0.01)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1174
Validation loss decreased (0.212795 --> 0.203629).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8831961154937744
Epoch: 4, Steps: 69 Train Loss: 0.1166 (Forecasting Loss:0.0982 + XiCon Loss:1.8379 x Lambda(0.01)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1159
Validation loss decreased (0.203629 --> 0.201174).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9629032611846924
Epoch: 5, Steps: 69 Train Loss: 0.1158 (Forecasting Loss:0.0974 + XiCon Loss:1.8348 x Lambda(0.01)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1158
Validation loss decreased (0.201174 --> 0.200024).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9658839702606201
Epoch: 6, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1154
Validation loss decreased (0.200024 --> 0.199625).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8247208595275879
Epoch: 7, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8326 x Lambda(0.01)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1152
Validation loss decreased (0.199625 --> 0.199379).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9558916091918945
Epoch: 8, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8369 x Lambda(0.01)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0210506916046143
Epoch: 9, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0970 + XiCon Loss:1.8364 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1152
Validation loss decreased (0.199379 --> 0.199329).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8567337989807129
Epoch: 10, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8354 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1152
Validation loss decreased (0.199329 --> 0.199301).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9908754825592041
Epoch: 11, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8314 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1152
Validation loss decreased (0.199301 --> 0.199285).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9359142780303955
Epoch: 12, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199285 --> 0.199282).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8519973754882812
Epoch: 13, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0969 + XiCon Loss:1.8341 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199282 --> 0.199279).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.0342442989349365
Epoch: 14, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8354 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199279 --> 0.199278).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9616117477416992
Epoch: 15, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8365 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199278 --> 0.199277).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8938164710998535
Epoch: 16, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0968 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199277 --> 0.199277).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9009578227996826
Epoch: 17, Steps: 69 Train Loss: 0.1153 (Forecasting Loss:0.0969 + XiCon Loss:1.8371 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199277 --> 0.199277).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9794144630432129
Epoch: 18, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8382 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199277 --> 0.199277).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9829025268554688
Epoch: 19, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0968 + XiCon Loss:1.8382 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199277 --> 0.199277).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8299367427825928
Epoch: 20, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8358 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
Validation loss decreased (0.199277 --> 0.199277).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9925436973571777
Epoch: 21, Steps: 69 Train Loss: 0.1152 (Forecasting Loss:0.0969 + XiCon Loss:1.8366 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9349737167358398
Epoch: 22, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8146820068359375
Epoch: 23, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9735803604125977
Epoch: 24, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9506371021270752
Epoch: 25, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8355 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9284012317657471
Epoch: 26, Steps: 69 Train Loss: 0.1151 (Forecasting Loss:0.0967 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.0049495697021484
Epoch: 27, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8353 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.943824291229248
Epoch: 28, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0966 + XiCon Loss:1.8344 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8275406360626221
Epoch: 29, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8346 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.9773919582366943
Epoch: 30, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8368 x Lambda(0.01)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1151
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05395093187689781, mae:0.17633658647537231, mape:0.12250649183988571, mspe:0.03540217876434326 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5847
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9913065433502197
Epoch: 1, Steps: 69 Train Loss: 0.1532 (Forecasting Loss:0.1348 + XiCon Loss:1.8358 x Lambda(0.01)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1543
Validation loss decreased (inf --> 0.290678).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.917304277420044
Epoch: 2, Steps: 69 Train Loss: 0.1306 (Forecasting Loss:0.1122 + XiCon Loss:1.8343 x Lambda(0.01)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1216
Validation loss decreased (0.290678 --> 0.209669).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9251618385314941
Epoch: 3, Steps: 69 Train Loss: 0.1175 (Forecasting Loss:0.0992 + XiCon Loss:1.8353 x Lambda(0.01)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1143
Validation loss decreased (0.209669 --> 0.201604).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.0412335395812988
Epoch: 4, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0970 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1150
Validation loss decreased (0.201604 --> 0.198150).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8997719287872314
Epoch: 5, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1139
Validation loss decreased (0.198150 --> 0.198010).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.882145881652832
Epoch: 6, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1138
Validation loss decreased (0.198010 --> 0.197544).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0066123008728027
Epoch: 7, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1139
Validation loss decreased (0.197544 --> 0.197223).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9314272403717041
Epoch: 8, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8369 x Lambda(0.01)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1139
Validation loss decreased (0.197223 --> 0.197207).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.878371000289917
Epoch: 9, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0957 + XiCon Loss:1.8387 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197207 --> 0.197139).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8626651763916016
Epoch: 10, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8332 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8596935272216797
Epoch: 11, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9041368961334229
Epoch: 12, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0955 + XiCon Loss:1.8352 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197139 --> 0.197136).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8726389408111572
Epoch: 13, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0957 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8337070941925049
Epoch: 14, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8328 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197136 --> 0.197135).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9127523899078369
Epoch: 15, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8627047538757324
Epoch: 16, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8646233081817627
Epoch: 17, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0955 + XiCon Loss:1.8371 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8628280162811279
Epoch: 18, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8310 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8538162708282471
Epoch: 19, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0956 + XiCon Loss:1.8352 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.874542236328125
Epoch: 20, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0959 + XiCon Loss:1.8328 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8487327098846436
Epoch: 21, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0956 + XiCon Loss:1.8390 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8812828063964844
Epoch: 22, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0956 + XiCon Loss:1.8337 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8483600616455078
Epoch: 23, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8320 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8429138660430908
Epoch: 24, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9080824851989746
Epoch: 25, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0955 + XiCon Loss:1.8361 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9663467407226562
Epoch: 26, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8279 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8476028442382812
Epoch: 27, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0956 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8537864685058594
Epoch: 28, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8605995178222656
Epoch: 29, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0955 + XiCon Loss:1.8344 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.9032986164093018
Epoch: 30, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0959 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8813862800598145
Epoch: 31, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8325 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.835500955581665
Epoch: 32, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8308 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8301939964294434
Epoch: 33, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0955 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8950479030609131
Epoch: 34, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8318 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8751113414764404
Epoch: 35, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8306 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.9420912265777588
Epoch: 36, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8304 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9284176826477051
Epoch: 37, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8327 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8888354301452637
Epoch: 38, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8450901508331299
Epoch: 39, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0955 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8746016025543213
Epoch: 40, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8343 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8529675006866455
Epoch: 41, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8306 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8866665363311768
Epoch: 42, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8339 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8539509773254395
Epoch: 43, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8296 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.922208309173584
Epoch: 44, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8335 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8589768409729004
Epoch: 45, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 1.0512816905975342
Epoch: 46, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0959 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.919912576675415
Epoch: 47, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.87227463722229
Epoch: 48, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8312 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.9371762275695801
Epoch: 49, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8283 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 1.0643200874328613
Epoch: 50, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0961 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.8356578350067139
Epoch: 51, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8315 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9363582134246826
Epoch: 52, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0956 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.93113112449646
Epoch: 53, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8358 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.9015004634857178
Epoch: 54, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8314 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9330503940582275
Epoch: 55, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8336 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 1.0245039463043213
Epoch: 56, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.8715226650238037
Epoch: 57, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8363 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.9921154975891113
Epoch: 58, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8306 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.9453945159912109
Epoch: 59, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8363 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.8912718296051025
Epoch: 60, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.9112520217895508
Epoch: 61, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0955 + XiCon Loss:1.8308 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.9465272426605225
Epoch: 62, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0956 + XiCon Loss:1.8380 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.957195520401001
Epoch: 63, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8332 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.9512908458709717
Epoch: 64, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8332 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.9890525341033936
Epoch: 65, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8296 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.892225980758667
Epoch: 66, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8310 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.8972067832946777
Epoch: 67, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8374 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.9725909233093262
Epoch: 68, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0956 + XiCon Loss:1.8314 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.9950876235961914
Epoch: 69, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8310 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.9475512504577637
Epoch: 70, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 1.0314836502075195
Epoch: 71, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8349 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.9252941608428955
Epoch: 72, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8390 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.9082117080688477
Epoch: 73, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0958 + XiCon Loss:1.8327 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.9728233814239502
Epoch: 74, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8329 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.9527053833007812
Epoch: 75, Steps: 69 Train Loss: 0.1138 (Forecasting Loss:0.0954 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.8415505886077881
Epoch: 76, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.9901926517486572
Epoch: 77, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0958 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 1.0412030220031738
Epoch: 78, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8347 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.8676912784576416
Epoch: 79, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8341 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.9766387939453125
Epoch: 80, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8330 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.9956624507904053
Epoch: 81, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8320 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8670287132263184
Epoch: 82, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0957 + XiCon Loss:1.8375 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.9435238838195801
Epoch: 83, Steps: 69 Train Loss: 0.1139 (Forecasting Loss:0.0956 + XiCon Loss:1.8315 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.9869511127471924
Epoch: 84, Steps: 69 Train Loss: 0.1136 (Forecasting Loss:0.0953 + XiCon Loss:1.8339 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.8502039909362793
Epoch: 85, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0959 + XiCon Loss:1.8285 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.9240641593933105
Epoch: 86, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.9499680995941162
Epoch: 87, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8334 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.9598672389984131
Epoch: 88, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8325 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 0.8746078014373779
Epoch: 89, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 0.9572625160217285
Epoch: 90, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8326 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 0.9984250068664551
Epoch: 91, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8309 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 0.8934042453765869
Epoch: 92, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 1.015462875366211
Epoch: 93, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8353 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 0.8930222988128662
Epoch: 94, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8329 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 0.8588058948516846
Epoch: 95, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8325 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 0.9548285007476807
Epoch: 96, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8338 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 0.9442741870880127
Epoch: 97, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8387 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
Validation loss decreased (0.197135 --> 0.197135).  Saving model ...
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 0.8401584625244141
Epoch: 98, Steps: 69 Train Loss: 0.1140 (Forecasting Loss:0.0957 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.310887241768095e-33
Epoch: 99 cost time: 0.9629433155059814
Epoch: 99, Steps: 69 Train Loss: 0.1142 (Forecasting Loss:0.0958 + XiCon Loss:1.8361 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.155443620884047e-33
Epoch: 100 cost time: 0.9202005863189697
Epoch: 100, Steps: 69 Train Loss: 0.1141 (Forecasting Loss:0.0958 + XiCon Loss:1.8313 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5777218104420236e-33
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05286379158496857, mae:0.17478542029857635, mape:0.12121517211198807, mspe:0.034680478274822235 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6263
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8663980960845947
Epoch: 1, Steps: 69 Train Loss: 0.1519 (Forecasting Loss:0.1336 + XiCon Loss:1.8322 x Lambda(0.01)), Vali MSE Loss: 0.2867 Test MSE Loss: 0.1490
Validation loss decreased (inf --> 0.286710).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.0053699016571045
Epoch: 2, Steps: 69 Train Loss: 0.1276 (Forecasting Loss:0.1093 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1189
Validation loss decreased (0.286710 --> 0.205120).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9577662944793701
Epoch: 3, Steps: 69 Train Loss: 0.1170 (Forecasting Loss:0.0987 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1170
Validation loss decreased (0.205120 --> 0.198736).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8696372509002686
Epoch: 4, Steps: 69 Train Loss: 0.1154 (Forecasting Loss:0.0971 + XiCon Loss:1.8356 x Lambda(0.01)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1153
Validation loss decreased (0.198736 --> 0.198475).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.053562879562378
Epoch: 5, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8356 x Lambda(0.01)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1152
Validation loss decreased (0.198475 --> 0.198137).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.907062292098999
Epoch: 6, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0965 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1150
Validation loss decreased (0.198137 --> 0.198018).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8741123676300049
Epoch: 7, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8315 x Lambda(0.01)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1150
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9500865936279297
Epoch: 8, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8340 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.198018 --> 0.197845).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9466712474822998
Epoch: 9, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8275 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197845 --> 0.197825).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8975679874420166
Epoch: 10, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197825 --> 0.197818).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.946037769317627
Epoch: 11, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8349 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9485461711883545
Epoch: 12, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8323 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197818 --> 0.197808).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8696107864379883
Epoch: 13, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8301 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197808 --> 0.197804).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9479753971099854
Epoch: 14, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0966 + XiCon Loss:1.8292 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197804 --> 0.197803).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9094367027282715
Epoch: 15, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8319 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8679959774017334
Epoch: 16, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0962 + XiCon Loss:1.8351 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9919455051422119
Epoch: 17, Steps: 69 Train Loss: 0.1150 (Forecasting Loss:0.0967 + XiCon Loss:1.8356 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9344046115875244
Epoch: 18, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8304 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8700590133666992
Epoch: 19, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9096622467041016
Epoch: 20, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8375 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9512848854064941
Epoch: 21, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8327 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.890892744064331
Epoch: 22, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8284 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9882209300994873
Epoch: 23, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0960 + XiCon Loss:1.8373 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9400599002838135
Epoch: 24, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8296 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9307422637939453
Epoch: 25, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8279 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.899989128112793
Epoch: 26, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8377 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 1.019791603088379
Epoch: 27, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8312 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8927373886108398
Epoch: 28, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8309 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9621381759643555
Epoch: 29, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.0749046802520752
Epoch: 30, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9047493934631348
Epoch: 31, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8342 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9078471660614014
Epoch: 32, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8325 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9570484161376953
Epoch: 33, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8326 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8724944591522217
Epoch: 34, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8321 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.0060582160949707
Epoch: 35, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8328 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.9953012466430664
Epoch: 36, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8287 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9101076126098633
Epoch: 37, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0961 + XiCon Loss:1.8341 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9426100254058838
Epoch: 38, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0965 + XiCon Loss:1.8347 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9476025104522705
Epoch: 39, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8374459743499756
Epoch: 40, Steps: 69 Train Loss: 0.1144 (Forecasting Loss:0.0961 + XiCon Loss:1.8289 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
Validation loss decreased (0.197803 --> 0.197803).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9461538791656494
Epoch: 41, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8324 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.9580223560333252
Epoch: 42, Steps: 69 Train Loss: 0.1146 (Forecasting Loss:0.0963 + XiCon Loss:1.8340 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.925379753112793
Epoch: 43, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8343 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.9779739379882812
Epoch: 44, Steps: 69 Train Loss: 0.1148 (Forecasting Loss:0.0964 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 1.0165584087371826
Epoch: 45, Steps: 69 Train Loss: 0.1143 (Forecasting Loss:0.0960 + XiCon Loss:1.8300 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.82314133644104
Epoch: 46, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8313 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.909947395324707
Epoch: 47, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0963 + XiCon Loss:1.8315 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.9386155605316162
Epoch: 48, Steps: 69 Train Loss: 0.1145 (Forecasting Loss:0.0962 + XiCon Loss:1.8335 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.9445488452911377
Epoch: 49, Steps: 69 Train Loss: 0.1149 (Forecasting Loss:0.0966 + XiCon Loss:1.8327 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9273052215576172
Epoch: 50, Steps: 69 Train Loss: 0.1147 (Forecasting Loss:0.0964 + XiCon Loss:1.8318 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1149
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05368119478225708, mae:0.17611686885356903, mape:0.12273496389389038, mspe:0.03565298765897751 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0535+-0.00050, MAE:0.1759+-0.00077, MAPE:0.1222+-0.00077, MSPE:0.0352+-0.00049, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6487
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.3505494594573975
Epoch: 1, Steps: 64 Train Loss: 0.5210 (Forecasting Loss:0.5015 + XiCon Loss:1.9424 x Lambda(0.01)), Vali MSE Loss: 0.9638 Test MSE Loss: 0.5134
Validation loss decreased (inf --> 0.963818).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9941461086273193
Epoch: 2, Steps: 64 Train Loss: 0.5166 (Forecasting Loss:0.4972 + XiCon Loss:1.9412 x Lambda(0.01)), Vali MSE Loss: 0.9525 Test MSE Loss: 0.5064
Validation loss decreased (0.963818 --> 0.952451).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9381964206695557
Epoch: 3, Steps: 64 Train Loss: 0.5099 (Forecasting Loss:0.4905 + XiCon Loss:1.9408 x Lambda(0.01)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.5035
Validation loss decreased (0.952451 --> 0.941898).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9721193313598633
Epoch: 4, Steps: 64 Train Loss: 0.5077 (Forecasting Loss:0.4883 + XiCon Loss:1.9384 x Lambda(0.01)), Vali MSE Loss: 0.9441 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.0509989261627197
Epoch: 5, Steps: 64 Train Loss: 0.5049 (Forecasting Loss:0.4855 + XiCon Loss:1.9395 x Lambda(0.01)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5013
Validation loss decreased (0.941898 --> 0.937490).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9949450492858887
Epoch: 6, Steps: 64 Train Loss: 0.5041 (Forecasting Loss:0.4847 + XiCon Loss:1.9397 x Lambda(0.01)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.5009
Validation loss decreased (0.937490 --> 0.937430).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9888198375701904
Epoch: 7, Steps: 64 Train Loss: 0.5041 (Forecasting Loss:0.4847 + XiCon Loss:1.9398 x Lambda(0.01)), Vali MSE Loss: 0.9356 Test MSE Loss: 0.5007
Validation loss decreased (0.937430 --> 0.935572).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.013199806213379
Epoch: 8, Steps: 64 Train Loss: 0.5038 (Forecasting Loss:0.4844 + XiCon Loss:1.9412 x Lambda(0.01)), Vali MSE Loss: 0.9353 Test MSE Loss: 0.5006
Validation loss decreased (0.935572 --> 0.935287).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9299905300140381
Epoch: 9, Steps: 64 Train Loss: 0.5030 (Forecasting Loss:0.4836 + XiCon Loss:1.9397 x Lambda(0.01)), Vali MSE Loss: 0.9362 Test MSE Loss: 0.5006
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.0737183094024658
Epoch: 10, Steps: 64 Train Loss: 0.5026 (Forecasting Loss:0.4832 + XiCon Loss:1.9393 x Lambda(0.01)), Vali MSE Loss: 0.9371 Test MSE Loss: 0.5006
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.0708730220794678
Epoch: 11, Steps: 64 Train Loss: 0.5038 (Forecasting Loss:0.4844 + XiCon Loss:1.9384 x Lambda(0.01)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5005
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9600913524627686
Epoch: 12, Steps: 64 Train Loss: 0.5034 (Forecasting Loss:0.4840 + XiCon Loss:1.9422 x Lambda(0.01)), Vali MSE Loss: 0.9365 Test MSE Loss: 0.5005
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.0282390117645264
Epoch: 13, Steps: 64 Train Loss: 0.5037 (Forecasting Loss:0.4843 + XiCon Loss:1.9384 x Lambda(0.01)), Vali MSE Loss: 0.9382 Test MSE Loss: 0.5005
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9978814125061035
Epoch: 14, Steps: 64 Train Loss: 0.5029 (Forecasting Loss:0.4835 + XiCon Loss:1.9397 x Lambda(0.01)), Vali MSE Loss: 0.9372 Test MSE Loss: 0.5005
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9248769283294678
Epoch: 15, Steps: 64 Train Loss: 0.5041 (Forecasting Loss:0.4847 + XiCon Loss:1.9381 x Lambda(0.01)), Vali MSE Loss: 0.9404 Test MSE Loss: 0.5005
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.012115478515625
Epoch: 16, Steps: 64 Train Loss: 0.5031 (Forecasting Loss:0.4837 + XiCon Loss:1.9378 x Lambda(0.01)), Vali MSE Loss: 0.9367 Test MSE Loss: 0.5005
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.0115363597869873
Epoch: 17, Steps: 64 Train Loss: 0.5040 (Forecasting Loss:0.4846 + XiCon Loss:1.9399 x Lambda(0.01)), Vali MSE Loss: 0.9343 Test MSE Loss: 0.5005
Validation loss decreased (0.935287 --> 0.934293).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9114341735839844
Epoch: 18, Steps: 64 Train Loss: 0.5039 (Forecasting Loss:0.4845 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.9360 Test MSE Loss: 0.5005
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.0029253959655762
Epoch: 19, Steps: 64 Train Loss: 0.5039 (Forecasting Loss:0.4845 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.9376 Test MSE Loss: 0.5005
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0631084442138672
Epoch: 20, Steps: 64 Train Loss: 0.5034 (Forecasting Loss:0.4840 + XiCon Loss:1.9380 x Lambda(0.01)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5005
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9711878299713135
Epoch: 21, Steps: 64 Train Loss: 0.5028 (Forecasting Loss:0.4834 + XiCon Loss:1.9402 x Lambda(0.01)), Vali MSE Loss: 0.9352 Test MSE Loss: 0.5005
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.012221097946167
Epoch: 22, Steps: 64 Train Loss: 0.5029 (Forecasting Loss:0.4835 + XiCon Loss:1.9416 x Lambda(0.01)), Vali MSE Loss: 0.9363 Test MSE Loss: 0.5005
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9701211452484131
Epoch: 23, Steps: 64 Train Loss: 0.5027 (Forecasting Loss:0.4833 + XiCon Loss:1.9396 x Lambda(0.01)), Vali MSE Loss: 0.9357 Test MSE Loss: 0.5005
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.0128791332244873
Epoch: 24, Steps: 64 Train Loss: 0.5039 (Forecasting Loss:0.4845 + XiCon Loss:1.9379 x Lambda(0.01)), Vali MSE Loss: 0.9379 Test MSE Loss: 0.5005
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.0299577713012695
Epoch: 25, Steps: 64 Train Loss: 0.5028 (Forecasting Loss:0.4834 + XiCon Loss:1.9399 x Lambda(0.01)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5005
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.0728964805603027
Epoch: 26, Steps: 64 Train Loss: 0.5027 (Forecasting Loss:0.4833 + XiCon Loss:1.9411 x Lambda(0.01)), Vali MSE Loss: 0.9365 Test MSE Loss: 0.5005
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9601283073425293
Epoch: 27, Steps: 64 Train Loss: 0.5033 (Forecasting Loss:0.4840 + XiCon Loss:1.9390 x Lambda(0.01)), Vali MSE Loss: 0.9384 Test MSE Loss: 0.5005
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4687241017818451, mae:0.5323414206504822, mape:0.4484776258468628, mspe:0.5970966219902039 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6910
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.994347095489502
Epoch: 1, Steps: 64 Train Loss: 0.5122 (Forecasting Loss:0.4928 + XiCon Loss:1.9385 x Lambda(0.01)), Vali MSE Loss: 0.9329 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932937).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.0283024311065674
Epoch: 2, Steps: 64 Train Loss: 0.5095 (Forecasting Loss:0.4901 + XiCon Loss:1.9377 x Lambda(0.01)), Vali MSE Loss: 0.9150 Test MSE Loss: 0.5154
Validation loss decreased (0.932937 --> 0.914996).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.0274879932403564
Epoch: 3, Steps: 64 Train Loss: 0.5030 (Forecasting Loss:0.4836 + XiCon Loss:1.9380 x Lambda(0.01)), Vali MSE Loss: 0.9123 Test MSE Loss: 0.5129
Validation loss decreased (0.914996 --> 0.912262).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9722859859466553
Epoch: 4, Steps: 64 Train Loss: 0.4999 (Forecasting Loss:0.4805 + XiCon Loss:1.9402 x Lambda(0.01)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5117
Validation loss decreased (0.912262 --> 0.908622).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.03153395652771
Epoch: 5, Steps: 64 Train Loss: 0.4986 (Forecasting Loss:0.4792 + XiCon Loss:1.9399 x Lambda(0.01)), Vali MSE Loss: 0.9057 Test MSE Loss: 0.5111
Validation loss decreased (0.908622 --> 0.905698).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9495000839233398
Epoch: 6, Steps: 64 Train Loss: 0.4985 (Forecasting Loss:0.4792 + XiCon Loss:1.9374 x Lambda(0.01)), Vali MSE Loss: 0.9078 Test MSE Loss: 0.5108
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.978640079498291
Epoch: 7, Steps: 64 Train Loss: 0.4975 (Forecasting Loss:0.4781 + XiCon Loss:1.9375 x Lambda(0.01)), Vali MSE Loss: 0.9063 Test MSE Loss: 0.5106
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9919123649597168
Epoch: 8, Steps: 64 Train Loss: 0.4970 (Forecasting Loss:0.4776 + XiCon Loss:1.9382 x Lambda(0.01)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5106
Validation loss decreased (0.905698 --> 0.905594).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0136799812316895
Epoch: 9, Steps: 64 Train Loss: 0.4979 (Forecasting Loss:0.4785 + XiCon Loss:1.9391 x Lambda(0.01)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9360594749450684
Epoch: 10, Steps: 64 Train Loss: 0.4974 (Forecasting Loss:0.4780 + XiCon Loss:1.9406 x Lambda(0.01)), Vali MSE Loss: 0.9059 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9954192638397217
Epoch: 11, Steps: 64 Train Loss: 0.4963 (Forecasting Loss:0.4769 + XiCon Loss:1.9393 x Lambda(0.01)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9849414825439453
Epoch: 12, Steps: 64 Train Loss: 0.4977 (Forecasting Loss:0.4783 + XiCon Loss:1.9370 x Lambda(0.01)), Vali MSE Loss: 0.9046 Test MSE Loss: 0.5105
Validation loss decreased (0.905594 --> 0.904618).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9443855285644531
Epoch: 13, Steps: 64 Train Loss: 0.4963 (Forecasting Loss:0.4770 + XiCon Loss:1.9381 x Lambda(0.01)), Vali MSE Loss: 0.9044 Test MSE Loss: 0.5105
Validation loss decreased (0.904618 --> 0.904383).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.059584379196167
Epoch: 14, Steps: 64 Train Loss: 0.4965 (Forecasting Loss:0.4771 + XiCon Loss:1.9392 x Lambda(0.01)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9655954837799072
Epoch: 15, Steps: 64 Train Loss: 0.4985 (Forecasting Loss:0.4792 + XiCon Loss:1.9371 x Lambda(0.01)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9317514896392822
Epoch: 16, Steps: 64 Train Loss: 0.4975 (Forecasting Loss:0.4781 + XiCon Loss:1.9379 x Lambda(0.01)), Vali MSE Loss: 0.9044 Test MSE Loss: 0.5105
Validation loss decreased (0.904383 --> 0.904376).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.072150468826294
Epoch: 17, Steps: 64 Train Loss: 0.4969 (Forecasting Loss:0.4776 + XiCon Loss:1.9389 x Lambda(0.01)), Vali MSE Loss: 0.9017 Test MSE Loss: 0.5105
Validation loss decreased (0.904376 --> 0.901655).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.0086355209350586
Epoch: 18, Steps: 64 Train Loss: 0.4965 (Forecasting Loss:0.4771 + XiCon Loss:1.9396 x Lambda(0.01)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.012418508529663
Epoch: 19, Steps: 64 Train Loss: 0.4974 (Forecasting Loss:0.4781 + XiCon Loss:1.9384 x Lambda(0.01)), Vali MSE Loss: 0.9024 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0337512493133545
Epoch: 20, Steps: 64 Train Loss: 0.4969 (Forecasting Loss:0.4776 + XiCon Loss:1.9375 x Lambda(0.01)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9615919589996338
Epoch: 21, Steps: 64 Train Loss: 0.4966 (Forecasting Loss:0.4772 + XiCon Loss:1.9390 x Lambda(0.01)), Vali MSE Loss: 0.9058 Test MSE Loss: 0.5105
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.015824794769287
Epoch: 22, Steps: 64 Train Loss: 0.4969 (Forecasting Loss:0.4775 + XiCon Loss:1.9379 x Lambda(0.01)), Vali MSE Loss: 0.8994 Test MSE Loss: 0.5105
Validation loss decreased (0.901655 --> 0.899363).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.040332317352295
Epoch: 23, Steps: 64 Train Loss: 0.4966 (Forecasting Loss:0.4772 + XiCon Loss:1.9386 x Lambda(0.01)), Vali MSE Loss: 0.9034 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8853673934936523
Epoch: 24, Steps: 64 Train Loss: 0.4971 (Forecasting Loss:0.4777 + XiCon Loss:1.9382 x Lambda(0.01)), Vali MSE Loss: 0.9046 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.0464251041412354
Epoch: 25, Steps: 64 Train Loss: 0.4962 (Forecasting Loss:0.4768 + XiCon Loss:1.9385 x Lambda(0.01)), Vali MSE Loss: 0.9009 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9934141635894775
Epoch: 26, Steps: 64 Train Loss: 0.4983 (Forecasting Loss:0.4789 + XiCon Loss:1.9382 x Lambda(0.01)), Vali MSE Loss: 0.9032 Test MSE Loss: 0.5105
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9216744899749756
Epoch: 27, Steps: 64 Train Loss: 0.4975 (Forecasting Loss:0.4781 + XiCon Loss:1.9383 x Lambda(0.01)), Vali MSE Loss: 0.9047 Test MSE Loss: 0.5105
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.9740214347839355
Epoch: 28, Steps: 64 Train Loss: 0.4967 (Forecasting Loss:0.4773 + XiCon Loss:1.9379 x Lambda(0.01)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5105
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 1.050394058227539
Epoch: 29, Steps: 64 Train Loss: 0.4971 (Forecasting Loss:0.4777 + XiCon Loss:1.9389 x Lambda(0.01)), Vali MSE Loss: 0.9050 Test MSE Loss: 0.5105
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.9293220043182373
Epoch: 30, Steps: 64 Train Loss: 0.4964 (Forecasting Loss:0.4770 + XiCon Loss:1.9383 x Lambda(0.01)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5105
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.9928610324859619
Epoch: 31, Steps: 64 Train Loss: 0.4978 (Forecasting Loss:0.4784 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.9024 Test MSE Loss: 0.5105
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 1.0622096061706543
Epoch: 32, Steps: 64 Train Loss: 0.4972 (Forecasting Loss:0.4778 + XiCon Loss:1.9375 x Lambda(0.01)), Vali MSE Loss: 0.9060 Test MSE Loss: 0.5105
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.484452486038208, mae:0.5365479588508606, mape:0.4567597210407257, mspe:0.6293842196464539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6306
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9675581455230713
Epoch: 1, Steps: 64 Train Loss: 0.5207 (Forecasting Loss:0.5013 + XiCon Loss:1.9408 x Lambda(0.01)), Vali MSE Loss: 0.9738 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973843).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9869728088378906
Epoch: 2, Steps: 64 Train Loss: 0.5175 (Forecasting Loss:0.4980 + XiCon Loss:1.9442 x Lambda(0.01)), Vali MSE Loss: 0.9555 Test MSE Loss: 0.5003
Validation loss decreased (0.973843 --> 0.955493).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.043269395828247
Epoch: 3, Steps: 64 Train Loss: 0.5095 (Forecasting Loss:0.4901 + XiCon Loss:1.9407 x Lambda(0.01)), Vali MSE Loss: 0.9449 Test MSE Loss: 0.4990
Validation loss decreased (0.955493 --> 0.944916).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.0650477409362793
Epoch: 4, Steps: 64 Train Loss: 0.5071 (Forecasting Loss:0.4876 + XiCon Loss:1.9424 x Lambda(0.01)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.4988
Validation loss decreased (0.944916 --> 0.938545).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9062657356262207
Epoch: 5, Steps: 64 Train Loss: 0.5037 (Forecasting Loss:0.4843 + XiCon Loss:1.9413 x Lambda(0.01)), Vali MSE Loss: 0.9319 Test MSE Loss: 0.4989
Validation loss decreased (0.938545 --> 0.931900).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9234585762023926
Epoch: 6, Steps: 64 Train Loss: 0.5031 (Forecasting Loss:0.4836 + XiCon Loss:1.9406 x Lambda(0.01)), Vali MSE Loss: 0.9337 Test MSE Loss: 0.4990
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9311788082122803
Epoch: 7, Steps: 64 Train Loss: 0.5015 (Forecasting Loss:0.4821 + XiCon Loss:1.9419 x Lambda(0.01)), Vali MSE Loss: 0.9264 Test MSE Loss: 0.4991
Validation loss decreased (0.931900 --> 0.926449).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9111232757568359
Epoch: 8, Steps: 64 Train Loss: 0.5021 (Forecasting Loss:0.4827 + XiCon Loss:1.9404 x Lambda(0.01)), Vali MSE Loss: 0.9285 Test MSE Loss: 0.4991
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9708316326141357
Epoch: 9, Steps: 64 Train Loss: 0.5009 (Forecasting Loss:0.4815 + XiCon Loss:1.9424 x Lambda(0.01)), Vali MSE Loss: 0.9323 Test MSE Loss: 0.4991
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.940232515335083
Epoch: 10, Steps: 64 Train Loss: 0.5007 (Forecasting Loss:0.4813 + XiCon Loss:1.9398 x Lambda(0.01)), Vali MSE Loss: 0.9246 Test MSE Loss: 0.4991
Validation loss decreased (0.926449 --> 0.924554).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9144456386566162
Epoch: 11, Steps: 64 Train Loss: 0.5014 (Forecasting Loss:0.4820 + XiCon Loss:1.9417 x Lambda(0.01)), Vali MSE Loss: 0.9260 Test MSE Loss: 0.4991
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9150843620300293
Epoch: 12, Steps: 64 Train Loss: 0.5020 (Forecasting Loss:0.4826 + XiCon Loss:1.9445 x Lambda(0.01)), Vali MSE Loss: 0.9327 Test MSE Loss: 0.4991
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9475975036621094
Epoch: 13, Steps: 64 Train Loss: 0.5019 (Forecasting Loss:0.4825 + XiCon Loss:1.9396 x Lambda(0.01)), Vali MSE Loss: 0.9287 Test MSE Loss: 0.4991
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9103877544403076
Epoch: 14, Steps: 64 Train Loss: 0.5017 (Forecasting Loss:0.4823 + XiCon Loss:1.9434 x Lambda(0.01)), Vali MSE Loss: 0.9270 Test MSE Loss: 0.4991
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9162337779998779
Epoch: 15, Steps: 64 Train Loss: 0.5010 (Forecasting Loss:0.4816 + XiCon Loss:1.9432 x Lambda(0.01)), Vali MSE Loss: 0.9287 Test MSE Loss: 0.4991
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9099998474121094
Epoch: 16, Steps: 64 Train Loss: 0.5019 (Forecasting Loss:0.4825 + XiCon Loss:1.9420 x Lambda(0.01)), Vali MSE Loss: 0.9305 Test MSE Loss: 0.4991
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9175820350646973
Epoch: 17, Steps: 64 Train Loss: 0.5021 (Forecasting Loss:0.4827 + XiCon Loss:1.9412 x Lambda(0.01)), Vali MSE Loss: 0.9288 Test MSE Loss: 0.4991
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9357216358184814
Epoch: 18, Steps: 64 Train Loss: 0.5007 (Forecasting Loss:0.4813 + XiCon Loss:1.9392 x Lambda(0.01)), Vali MSE Loss: 0.9300 Test MSE Loss: 0.4991
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9026961326599121
Epoch: 19, Steps: 64 Train Loss: 0.5010 (Forecasting Loss:0.4816 + XiCon Loss:1.9412 x Lambda(0.01)), Vali MSE Loss: 0.9264 Test MSE Loss: 0.4991
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9055125713348389
Epoch: 20, Steps: 64 Train Loss: 0.5008 (Forecasting Loss:0.4813 + XiCon Loss:1.9447 x Lambda(0.01)), Vali MSE Loss: 0.9246 Test MSE Loss: 0.4991
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4675029516220093, mae:0.5306618213653564, mape:0.4472774267196655, mspe:0.5963737964630127 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7375
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.927708625793457
Epoch: 1, Steps: 64 Train Loss: 0.5144 (Forecasting Loss:0.4951 + XiCon Loss:1.9398 x Lambda(0.01)), Vali MSE Loss: 0.9333 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933334).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.042222023010254
Epoch: 2, Steps: 64 Train Loss: 0.5094 (Forecasting Loss:0.4901 + XiCon Loss:1.9378 x Lambda(0.01)), Vali MSE Loss: 0.9160 Test MSE Loss: 0.5149
Validation loss decreased (0.933334 --> 0.915999).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9201328754425049
Epoch: 3, Steps: 64 Train Loss: 0.4991 (Forecasting Loss:0.4797 + XiCon Loss:1.9406 x Lambda(0.01)), Vali MSE Loss: 0.9083 Test MSE Loss: 0.5103
Validation loss decreased (0.915999 --> 0.908321).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8959465026855469
Epoch: 4, Steps: 64 Train Loss: 0.4955 (Forecasting Loss:0.4761 + XiCon Loss:1.9397 x Lambda(0.01)), Vali MSE Loss: 0.9019 Test MSE Loss: 0.5079
Validation loss decreased (0.908321 --> 0.901866).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9787070751190186
Epoch: 5, Steps: 64 Train Loss: 0.4931 (Forecasting Loss:0.4737 + XiCon Loss:1.9422 x Lambda(0.01)), Vali MSE Loss: 0.8958 Test MSE Loss: 0.5069
Validation loss decreased (0.901866 --> 0.895770).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9413232803344727
Epoch: 6, Steps: 64 Train Loss: 0.4927 (Forecasting Loss:0.4733 + XiCon Loss:1.9387 x Lambda(0.01)), Vali MSE Loss: 0.8961 Test MSE Loss: 0.5063
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.0013670921325684
Epoch: 7, Steps: 64 Train Loss: 0.4919 (Forecasting Loss:0.4724 + XiCon Loss:1.9412 x Lambda(0.01)), Vali MSE Loss: 0.8982 Test MSE Loss: 0.5061
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9112341403961182
Epoch: 8, Steps: 64 Train Loss: 0.4905 (Forecasting Loss:0.4711 + XiCon Loss:1.9395 x Lambda(0.01)), Vali MSE Loss: 0.8979 Test MSE Loss: 0.5060
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9579010009765625
Epoch: 9, Steps: 64 Train Loss: 0.4897 (Forecasting Loss:0.4703 + XiCon Loss:1.9390 x Lambda(0.01)), Vali MSE Loss: 0.8927 Test MSE Loss: 0.5059
Validation loss decreased (0.895770 --> 0.892724).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.905343770980835
Epoch: 10, Steps: 64 Train Loss: 0.4907 (Forecasting Loss:0.4714 + XiCon Loss:1.9380 x Lambda(0.01)), Vali MSE Loss: 0.8960 Test MSE Loss: 0.5059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9017853736877441
Epoch: 11, Steps: 64 Train Loss: 0.4907 (Forecasting Loss:0.4713 + XiCon Loss:1.9400 x Lambda(0.01)), Vali MSE Loss: 0.8952 Test MSE Loss: 0.5059
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8971965312957764
Epoch: 12, Steps: 64 Train Loss: 0.4906 (Forecasting Loss:0.4712 + XiCon Loss:1.9392 x Lambda(0.01)), Vali MSE Loss: 0.8947 Test MSE Loss: 0.5059
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8881878852844238
Epoch: 13, Steps: 64 Train Loss: 0.4905 (Forecasting Loss:0.4711 + XiCon Loss:1.9429 x Lambda(0.01)), Vali MSE Loss: 0.8948 Test MSE Loss: 0.5059
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9391412734985352
Epoch: 14, Steps: 64 Train Loss: 0.4903 (Forecasting Loss:0.4709 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.8973 Test MSE Loss: 0.5059
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9059758186340332
Epoch: 15, Steps: 64 Train Loss: 0.4911 (Forecasting Loss:0.4717 + XiCon Loss:1.9386 x Lambda(0.01)), Vali MSE Loss: 0.8976 Test MSE Loss: 0.5059
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9167048931121826
Epoch: 16, Steps: 64 Train Loss: 0.4900 (Forecasting Loss:0.4706 + XiCon Loss:1.9396 x Lambda(0.01)), Vali MSE Loss: 0.8902 Test MSE Loss: 0.5059
Validation loss decreased (0.892724 --> 0.890170).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9445722103118896
Epoch: 17, Steps: 64 Train Loss: 0.4902 (Forecasting Loss:0.4708 + XiCon Loss:1.9408 x Lambda(0.01)), Vali MSE Loss: 0.8949 Test MSE Loss: 0.5059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9151735305786133
Epoch: 18, Steps: 64 Train Loss: 0.4916 (Forecasting Loss:0.4722 + XiCon Loss:1.9393 x Lambda(0.01)), Vali MSE Loss: 0.8950 Test MSE Loss: 0.5059
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9119589328765869
Epoch: 19, Steps: 64 Train Loss: 0.4912 (Forecasting Loss:0.4718 + XiCon Loss:1.9405 x Lambda(0.01)), Vali MSE Loss: 0.8971 Test MSE Loss: 0.5059
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8866076469421387
Epoch: 20, Steps: 64 Train Loss: 0.4899 (Forecasting Loss:0.4705 + XiCon Loss:1.9378 x Lambda(0.01)), Vali MSE Loss: 0.8955 Test MSE Loss: 0.5059
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9198365211486816
Epoch: 21, Steps: 64 Train Loss: 0.4910 (Forecasting Loss:0.4716 + XiCon Loss:1.9389 x Lambda(0.01)), Vali MSE Loss: 0.8947 Test MSE Loss: 0.5059
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.0387897491455078
Epoch: 22, Steps: 64 Train Loss: 0.4906 (Forecasting Loss:0.4712 + XiCon Loss:1.9377 x Lambda(0.01)), Vali MSE Loss: 0.8951 Test MSE Loss: 0.5059
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.0158424377441406
Epoch: 23, Steps: 64 Train Loss: 0.4902 (Forecasting Loss:0.4708 + XiCon Loss:1.9381 x Lambda(0.01)), Vali MSE Loss: 0.8933 Test MSE Loss: 0.5059
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9888303279876709
Epoch: 24, Steps: 64 Train Loss: 0.4903 (Forecasting Loss:0.4709 + XiCon Loss:1.9400 x Lambda(0.01)), Vali MSE Loss: 0.8970 Test MSE Loss: 0.5059
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.0846643447875977
Epoch: 25, Steps: 64 Train Loss: 0.4902 (Forecasting Loss:0.4708 + XiCon Loss:1.9401 x Lambda(0.01)), Vali MSE Loss: 0.8937 Test MSE Loss: 0.5059
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.0799884796142578
Epoch: 26, Steps: 64 Train Loss: 0.4900 (Forecasting Loss:0.4707 + XiCon Loss:1.9380 x Lambda(0.01)), Vali MSE Loss: 0.8971 Test MSE Loss: 0.5059
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.47917670011520386, mae:0.5325464010238647, mape:0.4525984525680542, mspe:0.6180096864700317 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6456
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.1188249588012695
Epoch: 1, Steps: 64 Train Loss: 0.5143 (Forecasting Loss:0.4949 + XiCon Loss:1.9398 x Lambda(0.01)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908205).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9893889427185059
Epoch: 2, Steps: 64 Train Loss: 0.5107 (Forecasting Loss:0.4913 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.8919 Test MSE Loss: 0.5397
Validation loss decreased (0.908205 --> 0.891882).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9690952301025391
Epoch: 3, Steps: 64 Train Loss: 0.5055 (Forecasting Loss:0.4861 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.8919 Test MSE Loss: 0.5361
Validation loss decreased (0.891882 --> 0.891854).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.040992021560669
Epoch: 4, Steps: 64 Train Loss: 0.5012 (Forecasting Loss:0.4819 + XiCon Loss:1.9378 x Lambda(0.01)), Vali MSE Loss: 0.8840 Test MSE Loss: 0.5341
Validation loss decreased (0.891854 --> 0.883989).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.033447504043579
Epoch: 5, Steps: 64 Train Loss: 0.5002 (Forecasting Loss:0.4808 + XiCon Loss:1.9383 x Lambda(0.01)), Vali MSE Loss: 0.8822 Test MSE Loss: 0.5332
Validation loss decreased (0.883989 --> 0.882186).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9355072975158691
Epoch: 6, Steps: 64 Train Loss: 0.4983 (Forecasting Loss:0.4789 + XiCon Loss:1.9384 x Lambda(0.01)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5327
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.0612232685089111
Epoch: 7, Steps: 64 Train Loss: 0.4984 (Forecasting Loss:0.4790 + XiCon Loss:1.9409 x Lambda(0.01)), Vali MSE Loss: 0.8862 Test MSE Loss: 0.5325
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.0008397102355957
Epoch: 8, Steps: 64 Train Loss: 0.5008 (Forecasting Loss:0.4814 + XiCon Loss:1.9393 x Lambda(0.01)), Vali MSE Loss: 0.8879 Test MSE Loss: 0.5324
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0134494304656982
Epoch: 9, Steps: 64 Train Loss: 0.4971 (Forecasting Loss:0.4777 + XiCon Loss:1.9392 x Lambda(0.01)), Vali MSE Loss: 0.8837 Test MSE Loss: 0.5323
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.247983455657959
Epoch: 10, Steps: 64 Train Loss: 0.4987 (Forecasting Loss:0.4793 + XiCon Loss:1.9379 x Lambda(0.01)), Vali MSE Loss: 0.8835 Test MSE Loss: 0.5323
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.929389476776123
Epoch: 11, Steps: 64 Train Loss: 0.4992 (Forecasting Loss:0.4798 + XiCon Loss:1.9407 x Lambda(0.01)), Vali MSE Loss: 0.8824 Test MSE Loss: 0.5323
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9901425838470459
Epoch: 12, Steps: 64 Train Loss: 0.4976 (Forecasting Loss:0.4782 + XiCon Loss:1.9394 x Lambda(0.01)), Vali MSE Loss: 0.8833 Test MSE Loss: 0.5323
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.0259013175964355
Epoch: 13, Steps: 64 Train Loss: 0.4992 (Forecasting Loss:0.4798 + XiCon Loss:1.9385 x Lambda(0.01)), Vali MSE Loss: 0.8847 Test MSE Loss: 0.5323
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.002629280090332
Epoch: 14, Steps: 64 Train Loss: 0.4985 (Forecasting Loss:0.4791 + XiCon Loss:1.9401 x Lambda(0.01)), Vali MSE Loss: 0.8830 Test MSE Loss: 0.5323
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.0763206481933594
Epoch: 15, Steps: 64 Train Loss: 0.4992 (Forecasting Loss:0.4798 + XiCon Loss:1.9387 x Lambda(0.01)), Vali MSE Loss: 0.8831 Test MSE Loss: 0.5323
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5163422226905823, mae:0.5500785708427429, mape:0.47475486993789673, mspe:0.6865605711936951 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4832+-0.02462, MAE:0.5364+-0.00984, MAPE:0.4560+-0.01383, MSPE:0.6255+-0.04585, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7350
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.566565990447998
Epoch: 1, Steps: 59 Train Loss: 1.0087 (Forecasting Loss:0.9906 + XiCon Loss:1.8097 x Lambda(0.01)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248618).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.266784906387329
Epoch: 2, Steps: 59 Train Loss: 1.0084 (Forecasting Loss:0.9903 + XiCon Loss:1.8080 x Lambda(0.01)), Vali MSE Loss: 1.2525 Test MSE Loss: 0.9824
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2563207149505615
Epoch: 3, Steps: 59 Train Loss: 1.0072 (Forecasting Loss:0.9891 + XiCon Loss:1.8111 x Lambda(0.01)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2920444011688232
Epoch: 4, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9889 + XiCon Loss:1.8072 x Lambda(0.01)), Vali MSE Loss: 1.2467 Test MSE Loss: 0.9822
Validation loss decreased (1.248618 --> 1.246697).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.3041446208953857
Epoch: 5, Steps: 59 Train Loss: 1.0070 (Forecasting Loss:0.9888 + XiCon Loss:1.8115 x Lambda(0.01)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2699534893035889
Epoch: 6, Steps: 59 Train Loss: 1.0078 (Forecasting Loss:0.9897 + XiCon Loss:1.8072 x Lambda(0.01)), Vali MSE Loss: 1.2458 Test MSE Loss: 0.9821
Validation loss decreased (1.246697 --> 1.245836).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.3280816078186035
Epoch: 7, Steps: 59 Train Loss: 1.0066 (Forecasting Loss:0.9885 + XiCon Loss:1.8095 x Lambda(0.01)), Vali MSE Loss: 1.2448 Test MSE Loss: 0.9821
Validation loss decreased (1.245836 --> 1.244767).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2464752197265625
Epoch: 8, Steps: 59 Train Loss: 1.0061 (Forecasting Loss:0.9879 + XiCon Loss:1.8140 x Lambda(0.01)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2464687824249268
Epoch: 9, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9888 + XiCon Loss:1.8094 x Lambda(0.01)), Vali MSE Loss: 1.2442 Test MSE Loss: 0.9821
Validation loss decreased (1.244767 --> 1.244227).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2674272060394287
Epoch: 10, Steps: 59 Train Loss: 1.0068 (Forecasting Loss:0.9887 + XiCon Loss:1.8102 x Lambda(0.01)), Vali MSE Loss: 1.2552 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.303903579711914
Epoch: 11, Steps: 59 Train Loss: 1.0057 (Forecasting Loss:0.9876 + XiCon Loss:1.8086 x Lambda(0.01)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.3014869689941406
Epoch: 12, Steps: 59 Train Loss: 1.0067 (Forecasting Loss:0.9885 + XiCon Loss:1.8157 x Lambda(0.01)), Vali MSE Loss: 1.2520 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2823772430419922
Epoch: 13, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9888 + XiCon Loss:1.8082 x Lambda(0.01)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.270308494567871
Epoch: 14, Steps: 59 Train Loss: 1.0068 (Forecasting Loss:0.9887 + XiCon Loss:1.8071 x Lambda(0.01)), Vali MSE Loss: 1.2447 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.323575496673584
Epoch: 15, Steps: 59 Train Loss: 1.0068 (Forecasting Loss:0.9887 + XiCon Loss:1.8111 x Lambda(0.01)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.2618317604064941
Epoch: 16, Steps: 59 Train Loss: 1.0074 (Forecasting Loss:0.9893 + XiCon Loss:1.8101 x Lambda(0.01)), Vali MSE Loss: 1.2488 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.2222747802734375
Epoch: 17, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9887 + XiCon Loss:1.8129 x Lambda(0.01)), Vali MSE Loss: 1.2551 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.265653371810913
Epoch: 18, Steps: 59 Train Loss: 1.0076 (Forecasting Loss:0.9895 + XiCon Loss:1.8088 x Lambda(0.01)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2704386711120605
Epoch: 19, Steps: 59 Train Loss: 1.0075 (Forecasting Loss:0.9893 + XiCon Loss:1.8160 x Lambda(0.01)), Vali MSE Loss: 1.2414 Test MSE Loss: 0.9821
Validation loss decreased (1.244227 --> 1.241421).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.2906856536865234
Epoch: 20, Steps: 59 Train Loss: 1.0068 (Forecasting Loss:0.9886 + XiCon Loss:1.8133 x Lambda(0.01)), Vali MSE Loss: 1.2437 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.3206884860992432
Epoch: 21, Steps: 59 Train Loss: 1.0078 (Forecasting Loss:0.9897 + XiCon Loss:1.8116 x Lambda(0.01)), Vali MSE Loss: 1.2511 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.2804148197174072
Epoch: 22, Steps: 59 Train Loss: 1.0082 (Forecasting Loss:0.9901 + XiCon Loss:1.8059 x Lambda(0.01)), Vali MSE Loss: 1.2493 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.2975072860717773
Epoch: 23, Steps: 59 Train Loss: 1.0059 (Forecasting Loss:0.9878 + XiCon Loss:1.8137 x Lambda(0.01)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.283433437347412
Epoch: 24, Steps: 59 Train Loss: 1.0073 (Forecasting Loss:0.9892 + XiCon Loss:1.8084 x Lambda(0.01)), Vali MSE Loss: 1.2545 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.2526907920837402
Epoch: 25, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9888 + XiCon Loss:1.8070 x Lambda(0.01)), Vali MSE Loss: 1.2519 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.2330052852630615
Epoch: 26, Steps: 59 Train Loss: 1.0070 (Forecasting Loss:0.9889 + XiCon Loss:1.8073 x Lambda(0.01)), Vali MSE Loss: 1.2572 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.326888084411621
Epoch: 27, Steps: 59 Train Loss: 1.0066 (Forecasting Loss:0.9885 + XiCon Loss:1.8119 x Lambda(0.01)), Vali MSE Loss: 1.2484 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.28182053565979
Epoch: 28, Steps: 59 Train Loss: 1.0080 (Forecasting Loss:0.9899 + XiCon Loss:1.8055 x Lambda(0.01)), Vali MSE Loss: 1.2506 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.2787542343139648
Epoch: 29, Steps: 59 Train Loss: 1.0065 (Forecasting Loss:0.9884 + XiCon Loss:1.8100 x Lambda(0.01)), Vali MSE Loss: 1.2524 Test MSE Loss: 0.9821
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1454991102218628, mae:0.8186607956886292, mape:0.7821181416511536, mspe:1.830356478691101 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6045
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2731387615203857
Epoch: 1, Steps: 59 Train Loss: 1.0072 (Forecasting Loss:0.9892 + XiCon Loss:1.8061 x Lambda(0.01)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236815).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.3140912055969238
Epoch: 2, Steps: 59 Train Loss: 1.0067 (Forecasting Loss:0.9886 + XiCon Loss:1.8102 x Lambda(0.01)), Vali MSE Loss: 1.2342 Test MSE Loss: 0.9931
Validation loss decreased (1.236815 --> 1.234239).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2648091316223145
Epoch: 3, Steps: 59 Train Loss: 1.0053 (Forecasting Loss:0.9873 + XiCon Loss:1.8037 x Lambda(0.01)), Vali MSE Loss: 1.2389 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2874765396118164
Epoch: 4, Steps: 59 Train Loss: 1.0060 (Forecasting Loss:0.9878 + XiCon Loss:1.8153 x Lambda(0.01)), Vali MSE Loss: 1.2405 Test MSE Loss: 0.9930
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2830383777618408
Epoch: 5, Steps: 59 Train Loss: 1.0066 (Forecasting Loss:0.9885 + XiCon Loss:1.8057 x Lambda(0.01)), Vali MSE Loss: 1.2295 Test MSE Loss: 0.9930
Validation loss decreased (1.234239 --> 1.229471).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2454485893249512
Epoch: 6, Steps: 59 Train Loss: 1.0065 (Forecasting Loss:0.9884 + XiCon Loss:1.8094 x Lambda(0.01)), Vali MSE Loss: 1.2379 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.290658712387085
Epoch: 7, Steps: 59 Train Loss: 1.0039 (Forecasting Loss:0.9858 + XiCon Loss:1.8111 x Lambda(0.01)), Vali MSE Loss: 1.2338 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2843060493469238
Epoch: 8, Steps: 59 Train Loss: 1.0049 (Forecasting Loss:0.9867 + XiCon Loss:1.8128 x Lambda(0.01)), Vali MSE Loss: 1.2317 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.279578447341919
Epoch: 9, Steps: 59 Train Loss: 1.0048 (Forecasting Loss:0.9867 + XiCon Loss:1.8108 x Lambda(0.01)), Vali MSE Loss: 1.2310 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2756531238555908
Epoch: 10, Steps: 59 Train Loss: 1.0059 (Forecasting Loss:0.9879 + XiCon Loss:1.8048 x Lambda(0.01)), Vali MSE Loss: 1.2336 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2632389068603516
Epoch: 11, Steps: 59 Train Loss: 1.0053 (Forecasting Loss:0.9873 + XiCon Loss:1.8078 x Lambda(0.01)), Vali MSE Loss: 1.2397 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2635471820831299
Epoch: 12, Steps: 59 Train Loss: 1.0058 (Forecasting Loss:0.9877 + XiCon Loss:1.8089 x Lambda(0.01)), Vali MSE Loss: 1.2261 Test MSE Loss: 0.9929
Validation loss decreased (1.229471 --> 1.226062).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2885055541992188
Epoch: 13, Steps: 59 Train Loss: 1.0063 (Forecasting Loss:0.9882 + XiCon Loss:1.8134 x Lambda(0.01)), Vali MSE Loss: 1.2304 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.2649328708648682
Epoch: 14, Steps: 59 Train Loss: 1.0058 (Forecasting Loss:0.9877 + XiCon Loss:1.8118 x Lambda(0.01)), Vali MSE Loss: 1.2350 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.3164074420928955
Epoch: 15, Steps: 59 Train Loss: 1.0063 (Forecasting Loss:0.9882 + XiCon Loss:1.8104 x Lambda(0.01)), Vali MSE Loss: 1.2263 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.2904069423675537
Epoch: 16, Steps: 59 Train Loss: 1.0049 (Forecasting Loss:0.9868 + XiCon Loss:1.8104 x Lambda(0.01)), Vali MSE Loss: 1.2417 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.276491641998291
Epoch: 17, Steps: 59 Train Loss: 1.0055 (Forecasting Loss:0.9874 + XiCon Loss:1.8113 x Lambda(0.01)), Vali MSE Loss: 1.2280 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.269967794418335
Epoch: 18, Steps: 59 Train Loss: 1.0060 (Forecasting Loss:0.9880 + XiCon Loss:1.8079 x Lambda(0.01)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2764205932617188
Epoch: 19, Steps: 59 Train Loss: 1.0055 (Forecasting Loss:0.9874 + XiCon Loss:1.8107 x Lambda(0.01)), Vali MSE Loss: 1.2358 Test MSE Loss: 0.9929
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.254244089126587
Epoch: 20, Steps: 59 Train Loss: 1.0055 (Forecasting Loss:0.9874 + XiCon Loss:1.8064 x Lambda(0.01)), Vali MSE Loss: 1.2330 Test MSE Loss: 0.9929
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.2612314224243164
Epoch: 21, Steps: 59 Train Loss: 1.0055 (Forecasting Loss:0.9875 + XiCon Loss:1.8044 x Lambda(0.01)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9929
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.31353759765625
Epoch: 22, Steps: 59 Train Loss: 1.0066 (Forecasting Loss:0.9884 + XiCon Loss:1.8108 x Lambda(0.01)), Vali MSE Loss: 1.2298 Test MSE Loss: 0.9929
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.161369800567627, mae:0.8244867324829102, mape:0.7876993417739868, mspe:1.850974678993225 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5879
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.272413969039917
Epoch: 1, Steps: 59 Train Loss: 1.0082 (Forecasting Loss:0.9902 + XiCon Loss:1.8027 x Lambda(0.01)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247568).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.3392858505249023
Epoch: 2, Steps: 59 Train Loss: 1.0086 (Forecasting Loss:0.9905 + XiCon Loss:1.8124 x Lambda(0.01)), Vali MSE Loss: 1.2353 Test MSE Loss: 0.9843
Validation loss decreased (1.247568 --> 1.235254).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.3501675128936768
Epoch: 3, Steps: 59 Train Loss: 1.0077 (Forecasting Loss:0.9897 + XiCon Loss:1.8024 x Lambda(0.01)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9841
Validation loss decreased (1.235254 --> 1.234320).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.271618366241455
Epoch: 4, Steps: 59 Train Loss: 1.0062 (Forecasting Loss:0.9881 + XiCon Loss:1.8087 x Lambda(0.01)), Vali MSE Loss: 1.2535 Test MSE Loss: 0.9840
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2572658061981201
Epoch: 5, Steps: 59 Train Loss: 1.0064 (Forecasting Loss:0.9883 + XiCon Loss:1.8064 x Lambda(0.01)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9840
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.318244218826294
Epoch: 6, Steps: 59 Train Loss: 1.0072 (Forecasting Loss:0.9891 + XiCon Loss:1.8131 x Lambda(0.01)), Vali MSE Loss: 1.2436 Test MSE Loss: 0.9839
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.33372163772583
Epoch: 7, Steps: 59 Train Loss: 1.0071 (Forecasting Loss:0.9890 + XiCon Loss:1.8049 x Lambda(0.01)), Vali MSE Loss: 1.2493 Test MSE Loss: 0.9839
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.5120289325714111
Epoch: 8, Steps: 59 Train Loss: 1.0060 (Forecasting Loss:0.9879 + XiCon Loss:1.8066 x Lambda(0.01)), Vali MSE Loss: 1.2576 Test MSE Loss: 0.9839
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.3278605937957764
Epoch: 9, Steps: 59 Train Loss: 1.0054 (Forecasting Loss:0.9873 + XiCon Loss:1.8113 x Lambda(0.01)), Vali MSE Loss: 1.2500 Test MSE Loss: 0.9839
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.3299834728240967
Epoch: 10, Steps: 59 Train Loss: 1.0070 (Forecasting Loss:0.9889 + XiCon Loss:1.8092 x Lambda(0.01)), Vali MSE Loss: 1.2532 Test MSE Loss: 0.9839
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.3264126777648926
Epoch: 11, Steps: 59 Train Loss: 1.0056 (Forecasting Loss:0.9875 + XiCon Loss:1.8117 x Lambda(0.01)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9839
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.3542230129241943
Epoch: 12, Steps: 59 Train Loss: 1.0061 (Forecasting Loss:0.9881 + XiCon Loss:1.8018 x Lambda(0.01)), Vali MSE Loss: 1.2405 Test MSE Loss: 0.9839
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.3371226787567139
Epoch: 13, Steps: 59 Train Loss: 1.0066 (Forecasting Loss:0.9885 + XiCon Loss:1.8056 x Lambda(0.01)), Vali MSE Loss: 1.2567 Test MSE Loss: 0.9839
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.147845983505249, mae:0.8203523755073547, mape:0.7830009460449219, mspe:1.8311930894851685 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6122
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.3137352466583252
Epoch: 1, Steps: 59 Train Loss: 1.0071 (Forecasting Loss:0.9890 + XiCon Loss:1.8102 x Lambda(0.01)), Vali MSE Loss: 1.2400 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240047).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.3534026145935059
Epoch: 2, Steps: 59 Train Loss: 1.0079 (Forecasting Loss:0.9898 + XiCon Loss:1.8087 x Lambda(0.01)), Vali MSE Loss: 1.2224 Test MSE Loss: 0.9958
Validation loss decreased (1.240047 --> 1.222438).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.3591337203979492
Epoch: 3, Steps: 59 Train Loss: 1.0058 (Forecasting Loss:0.9878 + XiCon Loss:1.8077 x Lambda(0.01)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9958
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.3453516960144043
Epoch: 4, Steps: 59 Train Loss: 1.0069 (Forecasting Loss:0.9888 + XiCon Loss:1.8078 x Lambda(0.01)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.3558897972106934
Epoch: 5, Steps: 59 Train Loss: 1.0064 (Forecasting Loss:0.9883 + XiCon Loss:1.8094 x Lambda(0.01)), Vali MSE Loss: 1.2231 Test MSE Loss: 0.9957
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.350226879119873
Epoch: 6, Steps: 59 Train Loss: 1.0070 (Forecasting Loss:0.9889 + XiCon Loss:1.8109 x Lambda(0.01)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9957
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.340216875076294
Epoch: 7, Steps: 59 Train Loss: 1.0062 (Forecasting Loss:0.9880 + XiCon Loss:1.8116 x Lambda(0.01)), Vali MSE Loss: 1.2250 Test MSE Loss: 0.9957
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.339524507522583
Epoch: 8, Steps: 59 Train Loss: 1.0054 (Forecasting Loss:0.9873 + XiCon Loss:1.8146 x Lambda(0.01)), Vali MSE Loss: 1.2237 Test MSE Loss: 0.9957
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.3658645153045654
Epoch: 9, Steps: 59 Train Loss: 1.0054 (Forecasting Loss:0.9873 + XiCon Loss:1.8103 x Lambda(0.01)), Vali MSE Loss: 1.2345 Test MSE Loss: 0.9957
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.3842155933380127
Epoch: 10, Steps: 59 Train Loss: 1.0063 (Forecasting Loss:0.9882 + XiCon Loss:1.8046 x Lambda(0.01)), Vali MSE Loss: 1.2326 Test MSE Loss: 0.9957
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.3290338516235352
Epoch: 11, Steps: 59 Train Loss: 1.0045 (Forecasting Loss:0.9864 + XiCon Loss:1.8115 x Lambda(0.01)), Vali MSE Loss: 1.2317 Test MSE Loss: 0.9957
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.364711046218872
Epoch: 12, Steps: 59 Train Loss: 1.0062 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(0.01)), Vali MSE Loss: 1.2321 Test MSE Loss: 0.9957
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1654963493347168, mae:0.8261462450027466, mape:0.789128839969635, mspe:1.8551280498504639 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7177
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2864351272583008
Epoch: 1, Steps: 59 Train Loss: 1.0122 (Forecasting Loss:0.9941 + XiCon Loss:1.8055 x Lambda(0.01)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275606).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.3940954208374023
Epoch: 2, Steps: 59 Train Loss: 1.0109 (Forecasting Loss:0.9928 + XiCon Loss:1.8094 x Lambda(0.01)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9659
Validation loss decreased (1.275606 --> 1.274311).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.3244857788085938
Epoch: 3, Steps: 59 Train Loss: 1.0114 (Forecasting Loss:0.9933 + XiCon Loss:1.8089 x Lambda(0.01)), Vali MSE Loss: 1.2846 Test MSE Loss: 0.9659
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.3369793891906738
Epoch: 4, Steps: 59 Train Loss: 1.0103 (Forecasting Loss:0.9922 + XiCon Loss:1.8026 x Lambda(0.01)), Vali MSE Loss: 1.2800 Test MSE Loss: 0.9659
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.3695106506347656
Epoch: 5, Steps: 59 Train Loss: 1.0108 (Forecasting Loss:0.9927 + XiCon Loss:1.8087 x Lambda(0.01)), Vali MSE Loss: 1.2739 Test MSE Loss: 0.9659
Validation loss decreased (1.274311 --> 1.273914).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2876954078674316
Epoch: 6, Steps: 59 Train Loss: 1.0115 (Forecasting Loss:0.9934 + XiCon Loss:1.8075 x Lambda(0.01)), Vali MSE Loss: 1.2841 Test MSE Loss: 0.9659
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.3696575164794922
Epoch: 7, Steps: 59 Train Loss: 1.0104 (Forecasting Loss:0.9924 + XiCon Loss:1.8066 x Lambda(0.01)), Vali MSE Loss: 1.2772 Test MSE Loss: 0.9659
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.3685007095336914
Epoch: 8, Steps: 59 Train Loss: 1.0100 (Forecasting Loss:0.9920 + XiCon Loss:1.8051 x Lambda(0.01)), Vali MSE Loss: 1.2821 Test MSE Loss: 0.9659
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.28297758102417
Epoch: 9, Steps: 59 Train Loss: 1.0111 (Forecasting Loss:0.9930 + XiCon Loss:1.8081 x Lambda(0.01)), Vali MSE Loss: 1.2883 Test MSE Loss: 0.9659
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.3545691967010498
Epoch: 10, Steps: 59 Train Loss: 1.0103 (Forecasting Loss:0.9923 + XiCon Loss:1.8040 x Lambda(0.01)), Vali MSE Loss: 1.2788 Test MSE Loss: 0.9659
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.3436613082885742
Epoch: 11, Steps: 59 Train Loss: 1.0108 (Forecasting Loss:0.9927 + XiCon Loss:1.8092 x Lambda(0.01)), Vali MSE Loss: 1.2744 Test MSE Loss: 0.9659
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.3769049644470215
Epoch: 12, Steps: 59 Train Loss: 1.0113 (Forecasting Loss:0.9933 + XiCon Loss:1.7984 x Lambda(0.01)), Vali MSE Loss: 1.2764 Test MSE Loss: 0.9659
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.3331866264343262
Epoch: 13, Steps: 59 Train Loss: 1.0102 (Forecasting Loss:0.9921 + XiCon Loss:1.8064 x Lambda(0.01)), Vali MSE Loss: 1.2816 Test MSE Loss: 0.9659
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.328413724899292
Epoch: 14, Steps: 59 Train Loss: 1.0098 (Forecasting Loss:0.9916 + XiCon Loss:1.8148 x Lambda(0.01)), Vali MSE Loss: 1.2814 Test MSE Loss: 0.9659
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.3544352054595947
Epoch: 15, Steps: 59 Train Loss: 1.0107 (Forecasting Loss:0.9927 + XiCon Loss:1.8029 x Lambda(0.01)), Vali MSE Loss: 1.2797 Test MSE Loss: 0.9659
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1208343505859375, mae:0.810918390750885, mape:0.7732071280479431, mspe:1.7929108142852783 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02176, MAE:0.8201+-0.00740, MAPE:0.7830+-0.00776, MSPE:1.8321+-0.03058, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7282
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.970045566558838
Epoch: 1, Steps: 53 Train Loss: 1.5045 (Forecasting Loss:1.4862 + XiCon Loss:1.8276 x Lambda(0.01)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858690).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6631801128387451
Epoch: 2, Steps: 53 Train Loss: 1.4980 (Forecasting Loss:1.4798 + XiCon Loss:1.8232 x Lambda(0.01)), Vali MSE Loss: 1.8409 Test MSE Loss: 0.9185
Validation loss decreased (1.858690 --> 1.840917).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6572484970092773
Epoch: 3, Steps: 53 Train Loss: 1.4917 (Forecasting Loss:1.4735 + XiCon Loss:1.8247 x Lambda(0.01)), Vali MSE Loss: 1.8444 Test MSE Loss: 0.9232
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.652545690536499
Epoch: 4, Steps: 53 Train Loss: 1.4896 (Forecasting Loss:1.4713 + XiCon Loss:1.8265 x Lambda(0.01)), Vali MSE Loss: 1.8418 Test MSE Loss: 0.9255
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.7021758556365967
Epoch: 5, Steps: 53 Train Loss: 1.4852 (Forecasting Loss:1.4669 + XiCon Loss:1.8291 x Lambda(0.01)), Vali MSE Loss: 1.8222 Test MSE Loss: 0.9266
Validation loss decreased (1.840917 --> 1.822192).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.7986314296722412
Epoch: 6, Steps: 53 Train Loss: 1.4878 (Forecasting Loss:1.4695 + XiCon Loss:1.8256 x Lambda(0.01)), Vali MSE Loss: 1.8253 Test MSE Loss: 0.9272
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6697475910186768
Epoch: 7, Steps: 53 Train Loss: 1.4844 (Forecasting Loss:1.4662 + XiCon Loss:1.8247 x Lambda(0.01)), Vali MSE Loss: 1.7958 Test MSE Loss: 0.9275
Validation loss decreased (1.822192 --> 1.795761).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6521990299224854
Epoch: 8, Steps: 53 Train Loss: 1.4833 (Forecasting Loss:1.4651 + XiCon Loss:1.8198 x Lambda(0.01)), Vali MSE Loss: 1.8520 Test MSE Loss: 0.9276
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6566658020019531
Epoch: 9, Steps: 53 Train Loss: 1.4843 (Forecasting Loss:1.4661 + XiCon Loss:1.8198 x Lambda(0.01)), Vali MSE Loss: 1.8137 Test MSE Loss: 0.9277
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.610088586807251
Epoch: 10, Steps: 53 Train Loss: 1.4859 (Forecasting Loss:1.4676 + XiCon Loss:1.8249 x Lambda(0.01)), Vali MSE Loss: 1.8538 Test MSE Loss: 0.9277
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.7075703144073486
Epoch: 11, Steps: 53 Train Loss: 1.4826 (Forecasting Loss:1.4643 + XiCon Loss:1.8248 x Lambda(0.01)), Vali MSE Loss: 1.8357 Test MSE Loss: 0.9277
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.765143632888794
Epoch: 12, Steps: 53 Train Loss: 1.4836 (Forecasting Loss:1.4654 + XiCon Loss:1.8211 x Lambda(0.01)), Vali MSE Loss: 1.8120 Test MSE Loss: 0.9277
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6842436790466309
Epoch: 13, Steps: 53 Train Loss: 1.4844 (Forecasting Loss:1.4661 + XiCon Loss:1.8300 x Lambda(0.01)), Vali MSE Loss: 1.8490 Test MSE Loss: 0.9277
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.6309123039245605
Epoch: 14, Steps: 53 Train Loss: 1.4855 (Forecasting Loss:1.4673 + XiCon Loss:1.8241 x Lambda(0.01)), Vali MSE Loss: 1.8034 Test MSE Loss: 0.9277
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6954717636108398
Epoch: 15, Steps: 53 Train Loss: 1.4823 (Forecasting Loss:1.4641 + XiCon Loss:1.8233 x Lambda(0.01)), Vali MSE Loss: 1.8457 Test MSE Loss: 0.9278
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.633441686630249
Epoch: 16, Steps: 53 Train Loss: 1.4831 (Forecasting Loss:1.4649 + XiCon Loss:1.8192 x Lambda(0.01)), Vali MSE Loss: 1.8259 Test MSE Loss: 0.9278
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.748368263244629
Epoch: 17, Steps: 53 Train Loss: 1.4849 (Forecasting Loss:1.4666 + XiCon Loss:1.8211 x Lambda(0.01)), Vali MSE Loss: 1.8425 Test MSE Loss: 0.9278
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0590051412582397, mae:0.795927882194519, mape:0.7951141595840454, mspe:1.797577977180481 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6512
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6609599590301514
Epoch: 1, Steps: 53 Train Loss: 1.5013 (Forecasting Loss:1.4830 + XiCon Loss:1.8255 x Lambda(0.01)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828222).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6711688041687012
Epoch: 2, Steps: 53 Train Loss: 1.4970 (Forecasting Loss:1.4788 + XiCon Loss:1.8250 x Lambda(0.01)), Vali MSE Loss: 1.8218 Test MSE Loss: 0.9332
Validation loss decreased (1.828222 --> 1.821850).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6404633522033691
Epoch: 3, Steps: 53 Train Loss: 1.4911 (Forecasting Loss:1.4728 + XiCon Loss:1.8270 x Lambda(0.01)), Vali MSE Loss: 1.7993 Test MSE Loss: 0.9347
Validation loss decreased (1.821850 --> 1.799335).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.687171459197998
Epoch: 4, Steps: 53 Train Loss: 1.4891 (Forecasting Loss:1.4708 + XiCon Loss:1.8354 x Lambda(0.01)), Vali MSE Loss: 1.8019 Test MSE Loss: 0.9355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.7483673095703125
Epoch: 5, Steps: 53 Train Loss: 1.4917 (Forecasting Loss:1.4735 + XiCon Loss:1.8283 x Lambda(0.01)), Vali MSE Loss: 1.8231 Test MSE Loss: 0.9359
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.731062412261963
Epoch: 6, Steps: 53 Train Loss: 1.4866 (Forecasting Loss:1.4683 + XiCon Loss:1.8274 x Lambda(0.01)), Vali MSE Loss: 1.8096 Test MSE Loss: 0.9361
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5697267055511475
Epoch: 7, Steps: 53 Train Loss: 1.4852 (Forecasting Loss:1.4669 + XiCon Loss:1.8282 x Lambda(0.01)), Vali MSE Loss: 1.7840 Test MSE Loss: 0.9362
Validation loss decreased (1.799335 --> 1.784004).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6542613506317139
Epoch: 8, Steps: 53 Train Loss: 1.4864 (Forecasting Loss:1.4681 + XiCon Loss:1.8303 x Lambda(0.01)), Vali MSE Loss: 1.8265 Test MSE Loss: 0.9363
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.535135269165039
Epoch: 9, Steps: 53 Train Loss: 1.4825 (Forecasting Loss:1.4643 + XiCon Loss:1.8248 x Lambda(0.01)), Vali MSE Loss: 1.8239 Test MSE Loss: 0.9363
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5440635681152344
Epoch: 10, Steps: 53 Train Loss: 1.4879 (Forecasting Loss:1.4696 + XiCon Loss:1.8288 x Lambda(0.01)), Vali MSE Loss: 1.8337 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5494608879089355
Epoch: 11, Steps: 53 Train Loss: 1.4868 (Forecasting Loss:1.4685 + XiCon Loss:1.8255 x Lambda(0.01)), Vali MSE Loss: 1.8420 Test MSE Loss: 0.9363
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5457727909088135
Epoch: 12, Steps: 53 Train Loss: 1.4863 (Forecasting Loss:1.4680 + XiCon Loss:1.8329 x Lambda(0.01)), Vali MSE Loss: 1.7675 Test MSE Loss: 0.9363
Validation loss decreased (1.784004 --> 1.767495).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5411038398742676
Epoch: 13, Steps: 53 Train Loss: 1.4872 (Forecasting Loss:1.4689 + XiCon Loss:1.8310 x Lambda(0.01)), Vali MSE Loss: 1.8107 Test MSE Loss: 0.9363
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5586607456207275
Epoch: 14, Steps: 53 Train Loss: 1.4877 (Forecasting Loss:1.4694 + XiCon Loss:1.8254 x Lambda(0.01)), Vali MSE Loss: 1.8057 Test MSE Loss: 0.9363
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5449161529541016
Epoch: 15, Steps: 53 Train Loss: 1.4842 (Forecasting Loss:1.4660 + XiCon Loss:1.8255 x Lambda(0.01)), Vali MSE Loss: 1.7997 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5548315048217773
Epoch: 16, Steps: 53 Train Loss: 1.4880 (Forecasting Loss:1.4697 + XiCon Loss:1.8275 x Lambda(0.01)), Vali MSE Loss: 1.7925 Test MSE Loss: 0.9363
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5225563049316406
Epoch: 17, Steps: 53 Train Loss: 1.4853 (Forecasting Loss:1.4670 + XiCon Loss:1.8275 x Lambda(0.01)), Vali MSE Loss: 1.8315 Test MSE Loss: 0.9363
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.535987377166748
Epoch: 18, Steps: 53 Train Loss: 1.4859 (Forecasting Loss:1.4676 + XiCon Loss:1.8290 x Lambda(0.01)), Vali MSE Loss: 1.8246 Test MSE Loss: 0.9363
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.5113179683685303
Epoch: 19, Steps: 53 Train Loss: 1.4890 (Forecasting Loss:1.4707 + XiCon Loss:1.8286 x Lambda(0.01)), Vali MSE Loss: 1.8142 Test MSE Loss: 0.9363
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.5371315479278564
Epoch: 20, Steps: 53 Train Loss: 1.4849 (Forecasting Loss:1.4666 + XiCon Loss:1.8262 x Lambda(0.01)), Vali MSE Loss: 1.8136 Test MSE Loss: 0.9363
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.5246000289916992
Epoch: 21, Steps: 53 Train Loss: 1.4862 (Forecasting Loss:1.4680 + XiCon Loss:1.8257 x Lambda(0.01)), Vali MSE Loss: 1.8098 Test MSE Loss: 0.9363
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.565950632095337
Epoch: 22, Steps: 53 Train Loss: 1.4878 (Forecasting Loss:1.4696 + XiCon Loss:1.8289 x Lambda(0.01)), Vali MSE Loss: 1.8242 Test MSE Loss: 0.9363
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0727204084396362, mae:0.7999356389045715, mape:0.8003542423248291, mspe:1.8203352689743042 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5909
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5643901824951172
Epoch: 1, Steps: 53 Train Loss: 1.5042 (Forecasting Loss:1.4859 + XiCon Loss:1.8300 x Lambda(0.01)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899212).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5666275024414062
Epoch: 2, Steps: 53 Train Loss: 1.5019 (Forecasting Loss:1.4836 + XiCon Loss:1.8292 x Lambda(0.01)), Vali MSE Loss: 1.8446 Test MSE Loss: 0.9162
Validation loss decreased (1.899212 --> 1.844579).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5499651432037354
Epoch: 3, Steps: 53 Train Loss: 1.4985 (Forecasting Loss:1.4802 + XiCon Loss:1.8241 x Lambda(0.01)), Vali MSE Loss: 1.8752 Test MSE Loss: 0.9189
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.547226905822754
Epoch: 4, Steps: 53 Train Loss: 1.4864 (Forecasting Loss:1.4681 + XiCon Loss:1.8304 x Lambda(0.01)), Vali MSE Loss: 1.8558 Test MSE Loss: 0.9203
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5294229984283447
Epoch: 5, Steps: 53 Train Loss: 1.4904 (Forecasting Loss:1.4722 + XiCon Loss:1.8278 x Lambda(0.01)), Vali MSE Loss: 1.8083 Test MSE Loss: 0.9211
Validation loss decreased (1.844579 --> 1.808265).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6474194526672363
Epoch: 6, Steps: 53 Train Loss: 1.4907 (Forecasting Loss:1.4724 + XiCon Loss:1.8270 x Lambda(0.01)), Vali MSE Loss: 1.8711 Test MSE Loss: 0.9215
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5554616451263428
Epoch: 7, Steps: 53 Train Loss: 1.4921 (Forecasting Loss:1.4738 + XiCon Loss:1.8311 x Lambda(0.01)), Vali MSE Loss: 1.8666 Test MSE Loss: 0.9218
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5235755443572998
Epoch: 8, Steps: 53 Train Loss: 1.4900 (Forecasting Loss:1.4718 + XiCon Loss:1.8242 x Lambda(0.01)), Vali MSE Loss: 1.8514 Test MSE Loss: 0.9219
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5540714263916016
Epoch: 9, Steps: 53 Train Loss: 1.4894 (Forecasting Loss:1.4712 + XiCon Loss:1.8236 x Lambda(0.01)), Vali MSE Loss: 1.8339 Test MSE Loss: 0.9219
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5376172065734863
Epoch: 10, Steps: 53 Train Loss: 1.4858 (Forecasting Loss:1.4675 + XiCon Loss:1.8312 x Lambda(0.01)), Vali MSE Loss: 1.8575 Test MSE Loss: 0.9219
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5052776336669922
Epoch: 11, Steps: 53 Train Loss: 1.4906 (Forecasting Loss:1.4723 + XiCon Loss:1.8300 x Lambda(0.01)), Vali MSE Loss: 1.8440 Test MSE Loss: 0.9220
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.532017707824707
Epoch: 12, Steps: 53 Train Loss: 1.4865 (Forecasting Loss:1.4682 + XiCon Loss:1.8249 x Lambda(0.01)), Vali MSE Loss: 1.8308 Test MSE Loss: 0.9220
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.541053056716919
Epoch: 13, Steps: 53 Train Loss: 1.4858 (Forecasting Loss:1.4675 + XiCon Loss:1.8293 x Lambda(0.01)), Vali MSE Loss: 1.8577 Test MSE Loss: 0.9220
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5854485034942627
Epoch: 14, Steps: 53 Train Loss: 1.4866 (Forecasting Loss:1.4683 + XiCon Loss:1.8302 x Lambda(0.01)), Vali MSE Loss: 1.8329 Test MSE Loss: 0.9220
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5008459091186523
Epoch: 15, Steps: 53 Train Loss: 1.4870 (Forecasting Loss:1.4687 + XiCon Loss:1.8253 x Lambda(0.01)), Vali MSE Loss: 1.8899 Test MSE Loss: 0.9220
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0496257543563843, mae:0.7925958037376404, mape:0.7913746237754822, mspe:1.7809683084487915 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7096
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6753621101379395
Epoch: 1, Steps: 53 Train Loss: 1.5181 (Forecasting Loss:1.4999 + XiCon Loss:1.8280 x Lambda(0.01)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995461).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6947481632232666
Epoch: 2, Steps: 53 Train Loss: 1.5153 (Forecasting Loss:1.4969 + XiCon Loss:1.8331 x Lambda(0.01)), Vali MSE Loss: 1.9488 Test MSE Loss: 0.8749
Validation loss decreased (1.995461 --> 1.948821).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6456968784332275
Epoch: 3, Steps: 53 Train Loss: 1.5073 (Forecasting Loss:1.4890 + XiCon Loss:1.8291 x Lambda(0.01)), Vali MSE Loss: 1.9565 Test MSE Loss: 0.8850
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.7345244884490967
Epoch: 4, Steps: 53 Train Loss: 1.4977 (Forecasting Loss:1.4795 + XiCon Loss:1.8271 x Lambda(0.01)), Vali MSE Loss: 1.9365 Test MSE Loss: 0.8922
Validation loss decreased (1.948821 --> 1.936488).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5866637229919434
Epoch: 5, Steps: 53 Train Loss: 1.4910 (Forecasting Loss:1.4728 + XiCon Loss:1.8270 x Lambda(0.01)), Vali MSE Loss: 1.8978 Test MSE Loss: 0.8963
Validation loss decreased (1.936488 --> 1.897799).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6084449291229248
Epoch: 6, Steps: 53 Train Loss: 1.4916 (Forecasting Loss:1.4733 + XiCon Loss:1.8262 x Lambda(0.01)), Vali MSE Loss: 1.9393 Test MSE Loss: 0.8986
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.605565071105957
Epoch: 7, Steps: 53 Train Loss: 1.4939 (Forecasting Loss:1.4756 + XiCon Loss:1.8345 x Lambda(0.01)), Vali MSE Loss: 1.8889 Test MSE Loss: 0.8998
Validation loss decreased (1.897799 --> 1.888945).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6542158126831055
Epoch: 8, Steps: 53 Train Loss: 1.4899 (Forecasting Loss:1.4716 + XiCon Loss:1.8290 x Lambda(0.01)), Vali MSE Loss: 1.8987 Test MSE Loss: 0.9003
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.7004270553588867
Epoch: 9, Steps: 53 Train Loss: 1.4900 (Forecasting Loss:1.4717 + XiCon Loss:1.8286 x Lambda(0.01)), Vali MSE Loss: 1.9002 Test MSE Loss: 0.9006
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6735777854919434
Epoch: 10, Steps: 53 Train Loss: 1.4912 (Forecasting Loss:1.4729 + XiCon Loss:1.8313 x Lambda(0.01)), Vali MSE Loss: 1.8775 Test MSE Loss: 0.9007
Validation loss decreased (1.888945 --> 1.877499).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6016788482666016
Epoch: 11, Steps: 53 Train Loss: 1.4907 (Forecasting Loss:1.4725 + XiCon Loss:1.8256 x Lambda(0.01)), Vali MSE Loss: 1.8915 Test MSE Loss: 0.9008
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.6316797733306885
Epoch: 12, Steps: 53 Train Loss: 1.4901 (Forecasting Loss:1.4718 + XiCon Loss:1.8243 x Lambda(0.01)), Vali MSE Loss: 1.8594 Test MSE Loss: 0.9008
Validation loss decreased (1.877499 --> 1.859378).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.665571928024292
Epoch: 13, Steps: 53 Train Loss: 1.4911 (Forecasting Loss:1.4728 + XiCon Loss:1.8318 x Lambda(0.01)), Vali MSE Loss: 1.8897 Test MSE Loss: 0.9008
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.712524652481079
Epoch: 14, Steps: 53 Train Loss: 1.4929 (Forecasting Loss:1.4746 + XiCon Loss:1.8253 x Lambda(0.01)), Vali MSE Loss: 1.8940 Test MSE Loss: 0.9008
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6047744750976562
Epoch: 15, Steps: 53 Train Loss: 1.4928 (Forecasting Loss:1.4746 + XiCon Loss:1.8270 x Lambda(0.01)), Vali MSE Loss: 1.8932 Test MSE Loss: 0.9008
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.601719856262207
Epoch: 16, Steps: 53 Train Loss: 1.4896 (Forecasting Loss:1.4714 + XiCon Loss:1.8268 x Lambda(0.01)), Vali MSE Loss: 1.8839 Test MSE Loss: 0.9008
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5966167449951172
Epoch: 17, Steps: 53 Train Loss: 1.4884 (Forecasting Loss:1.4702 + XiCon Loss:1.8258 x Lambda(0.01)), Vali MSE Loss: 1.9036 Test MSE Loss: 0.9008
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.6521437168121338
Epoch: 18, Steps: 53 Train Loss: 1.4892 (Forecasting Loss:1.4709 + XiCon Loss:1.8349 x Lambda(0.01)), Vali MSE Loss: 1.9175 Test MSE Loss: 0.9008
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6806342601776123
Epoch: 19, Steps: 53 Train Loss: 1.4863 (Forecasting Loss:1.4680 + XiCon Loss:1.8333 x Lambda(0.01)), Vali MSE Loss: 1.8821 Test MSE Loss: 0.9008
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.6534032821655273
Epoch: 20, Steps: 53 Train Loss: 1.4925 (Forecasting Loss:1.4742 + XiCon Loss:1.8278 x Lambda(0.01)), Vali MSE Loss: 1.8990 Test MSE Loss: 0.9008
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.6129539012908936
Epoch: 21, Steps: 53 Train Loss: 1.4893 (Forecasting Loss:1.4709 + XiCon Loss:1.8320 x Lambda(0.01)), Vali MSE Loss: 1.8658 Test MSE Loss: 0.9008
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.690277099609375
Epoch: 22, Steps: 53 Train Loss: 1.4914 (Forecasting Loss:1.4731 + XiCon Loss:1.8317 x Lambda(0.01)), Vali MSE Loss: 1.8934 Test MSE Loss: 0.9008
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0189931392669678, mae:0.7826160788536072, mape:0.7789807915687561, mspe:1.730864405632019 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6010
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6331727504730225
Epoch: 1, Steps: 53 Train Loss: 1.4946 (Forecasting Loss:1.4763 + XiCon Loss:1.8260 x Lambda(0.01)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740653).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.7074975967407227
Epoch: 2, Steps: 53 Train Loss: 1.4913 (Forecasting Loss:1.4730 + XiCon Loss:1.8280 x Lambda(0.01)), Vali MSE Loss: 1.7201 Test MSE Loss: 0.9609
Validation loss decreased (1.740653 --> 1.720063).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6129295825958252
Epoch: 3, Steps: 53 Train Loss: 1.4837 (Forecasting Loss:1.4655 + XiCon Loss:1.8236 x Lambda(0.01)), Vali MSE Loss: 1.7399 Test MSE Loss: 0.9649
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.586479902267456
Epoch: 4, Steps: 53 Train Loss: 1.4811 (Forecasting Loss:1.4628 + XiCon Loss:1.8270 x Lambda(0.01)), Vali MSE Loss: 1.7421 Test MSE Loss: 0.9670
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6006672382354736
Epoch: 5, Steps: 53 Train Loss: 1.4794 (Forecasting Loss:1.4611 + XiCon Loss:1.8301 x Lambda(0.01)), Vali MSE Loss: 1.7442 Test MSE Loss: 0.9681
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6560959815979004
Epoch: 6, Steps: 53 Train Loss: 1.4792 (Forecasting Loss:1.4610 + XiCon Loss:1.8278 x Lambda(0.01)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9687
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.624326229095459
Epoch: 7, Steps: 53 Train Loss: 1.4806 (Forecasting Loss:1.4624 + XiCon Loss:1.8236 x Lambda(0.01)), Vali MSE Loss: 1.7534 Test MSE Loss: 0.9689
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5898823738098145
Epoch: 8, Steps: 53 Train Loss: 1.4779 (Forecasting Loss:1.4596 + XiCon Loss:1.8263 x Lambda(0.01)), Vali MSE Loss: 1.7241 Test MSE Loss: 0.9691
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5858118534088135
Epoch: 9, Steps: 53 Train Loss: 1.4795 (Forecasting Loss:1.4612 + XiCon Loss:1.8288 x Lambda(0.01)), Vali MSE Loss: 1.7699 Test MSE Loss: 0.9692
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.630579948425293
Epoch: 10, Steps: 53 Train Loss: 1.4768 (Forecasting Loss:1.4585 + XiCon Loss:1.8259 x Lambda(0.01)), Vali MSE Loss: 1.7453 Test MSE Loss: 0.9692
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6536524295806885
Epoch: 11, Steps: 53 Train Loss: 1.4793 (Forecasting Loss:1.4610 + XiCon Loss:1.8304 x Lambda(0.01)), Vali MSE Loss: 1.7519 Test MSE Loss: 0.9692
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.720998764038086
Epoch: 12, Steps: 53 Train Loss: 1.4759 (Forecasting Loss:1.4576 + XiCon Loss:1.8376 x Lambda(0.01)), Vali MSE Loss: 1.7508 Test MSE Loss: 0.9692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1092660427093506, mae:0.8126046657562256, mape:0.8145728707313538, mspe:1.878996729850769 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0619+-0.04100, MAE:0.7967+-0.01359, MAPE:0.7961+-0.01614, MSPE:1.8017+-0.06740, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0740
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.9065580
	speed: 0.0196s/iter; left time: 953.7528s
	iters: 200, epoch: 1 | loss: 0.8199673
	speed: 0.0143s/iter; left time: 694.3769s
	iters: 300, epoch: 1 | loss: 0.5767964
	speed: 0.0137s/iter; left time: 663.9477s
	iters: 400, epoch: 1 | loss: 0.6330042
	speed: 0.0150s/iter; left time: 723.5046s
Epoch: 1 cost time: 7.5214619636535645
Epoch: 1, Steps: 487 Train Loss: 0.7666 (Forecasting Loss:0.7417 + XiCon Loss:2.4909 x Lambda(0.01)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036696).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5248839
	speed: 0.0165s/iter; left time: 794.2817s
	iters: 200, epoch: 2 | loss: 0.4826108
	speed: 0.0137s/iter; left time: 659.1196s
	iters: 300, epoch: 2 | loss: 0.5257450
	speed: 0.0160s/iter; left time: 767.4250s
	iters: 400, epoch: 2 | loss: 0.4305474
	speed: 0.0147s/iter; left time: 704.0026s
Epoch: 2 cost time: 7.462593078613281
Epoch: 2, Steps: 487 Train Loss: 0.4594 (Forecasting Loss:0.4346 + XiCon Loss:2.4890 x Lambda(0.01)), Vali MSE Loss: 0.7456 Test MSE Loss: 0.5269
Validation loss decreased (1.036696 --> 0.745573).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.3418437
	speed: 0.0179s/iter; left time: 852.1137s
	iters: 200, epoch: 3 | loss: 0.4479533
	speed: 0.0147s/iter; left time: 698.6457s
	iters: 300, epoch: 3 | loss: 0.5253108
	speed: 0.0144s/iter; left time: 681.6082s
	iters: 400, epoch: 3 | loss: 0.3766146
	speed: 0.0146s/iter; left time: 691.7996s
Epoch: 3 cost time: 7.416765451431274
Epoch: 3, Steps: 487 Train Loss: 0.4297 (Forecasting Loss:0.4049 + XiCon Loss:2.4861 x Lambda(0.01)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5205
Validation loss decreased (0.745573 --> 0.738534).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5016198
	speed: 0.0164s/iter; left time: 774.5090s
	iters: 200, epoch: 4 | loss: 0.4342175
	speed: 0.0149s/iter; left time: 700.1059s
	iters: 300, epoch: 4 | loss: 0.4689091
	speed: 0.0154s/iter; left time: 724.5201s
	iters: 400, epoch: 4 | loss: 0.3454692
	speed: 0.0146s/iter; left time: 685.7127s
Epoch: 4 cost time: 7.4398133754730225
Epoch: 4, Steps: 487 Train Loss: 0.4242 (Forecasting Loss:0.3993 + XiCon Loss:2.4875 x Lambda(0.01)), Vali MSE Loss: 0.7318 Test MSE Loss: 0.5151
Validation loss decreased (0.738534 --> 0.731845).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4475378
	speed: 0.0162s/iter; left time: 754.7470s
	iters: 200, epoch: 5 | loss: 0.5377484
	speed: 0.0145s/iter; left time: 674.4185s
	iters: 300, epoch: 5 | loss: 0.3926994
	speed: 0.0156s/iter; left time: 722.9057s
	iters: 400, epoch: 5 | loss: 0.3928201
	speed: 0.0157s/iter; left time: 725.5340s
Epoch: 5 cost time: 7.551922798156738
Epoch: 5, Steps: 487 Train Loss: 0.4217 (Forecasting Loss:0.3968 + XiCon Loss:2.4868 x Lambda(0.01)), Vali MSE Loss: 0.7294 Test MSE Loss: 0.5108
Validation loss decreased (0.731845 --> 0.729385).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4330939
	speed: 0.0174s/iter; left time: 804.8945s
	iters: 200, epoch: 6 | loss: 0.4592178
	speed: 0.0153s/iter; left time: 703.7583s
	iters: 300, epoch: 6 | loss: 0.4455690
	speed: 0.0144s/iter; left time: 663.5053s
	iters: 400, epoch: 6 | loss: 0.3865762
	speed: 0.0153s/iter; left time: 699.4833s
Epoch: 6 cost time: 7.561786890029907
Epoch: 6, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3959 + XiCon Loss:2.4855 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5131
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4269046
	speed: 0.0167s/iter; left time: 764.3444s
	iters: 200, epoch: 7 | loss: 0.3241985
	speed: 0.0150s/iter; left time: 682.6543s
	iters: 300, epoch: 7 | loss: 0.4767699
	speed: 0.0144s/iter; left time: 654.3248s
	iters: 400, epoch: 7 | loss: 0.4052621
	speed: 0.0145s/iter; left time: 660.2541s
Epoch: 7 cost time: 7.560527324676514
Epoch: 7, Steps: 487 Train Loss: 0.4202 (Forecasting Loss:0.3954 + XiCon Loss:2.4849 x Lambda(0.01)), Vali MSE Loss: 0.7291 Test MSE Loss: 0.5121
Validation loss decreased (0.729385 --> 0.729083).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3963102
	speed: 0.0162s/iter; left time: 732.3259s
	iters: 200, epoch: 8 | loss: 0.3497555
	speed: 0.0142s/iter; left time: 642.5593s
	iters: 300, epoch: 8 | loss: 0.4111575
	speed: 0.0153s/iter; left time: 688.4003s
	iters: 400, epoch: 8 | loss: 0.4681364
	speed: 0.0151s/iter; left time: 677.8891s
Epoch: 8 cost time: 7.40189003944397
Epoch: 8, Steps: 487 Train Loss: 0.4200 (Forecasting Loss:0.3951 + XiCon Loss:2.4863 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5118
Validation loss decreased (0.729083 --> 0.728950).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5683002
	speed: 0.0179s/iter; left time: 801.8428s
	iters: 200, epoch: 9 | loss: 0.3559270
	speed: 0.0141s/iter; left time: 628.5385s
	iters: 300, epoch: 9 | loss: 0.4568265
	speed: 0.0142s/iter; left time: 633.3656s
	iters: 400, epoch: 9 | loss: 0.4308724
	speed: 0.0143s/iter; left time: 636.8611s
Epoch: 9 cost time: 7.361359596252441
Epoch: 9, Steps: 487 Train Loss: 0.4198 (Forecasting Loss:0.3949 + XiCon Loss:2.4885 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
Validation loss decreased (0.728950 --> 0.728678).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3649289
	speed: 0.0180s/iter; left time: 797.9905s
	iters: 200, epoch: 10 | loss: 0.4002941
	speed: 0.0146s/iter; left time: 643.7261s
	iters: 300, epoch: 10 | loss: 0.3780222
	speed: 0.0148s/iter; left time: 653.6119s
	iters: 400, epoch: 10 | loss: 0.3332019
	speed: 0.0143s/iter; left time: 625.9219s
Epoch: 10 cost time: 7.50009560585022
Epoch: 10, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4891 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3776066
	speed: 0.0162s/iter; left time: 708.1506s
	iters: 200, epoch: 11 | loss: 0.3490871
	speed: 0.0142s/iter; left time: 618.7481s
	iters: 300, epoch: 11 | loss: 0.4418935
	speed: 0.0145s/iter; left time: 632.6288s
	iters: 400, epoch: 11 | loss: 0.3943536
	speed: 0.0153s/iter; left time: 662.4679s
Epoch: 11 cost time: 7.399111986160278
Epoch: 11, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4880 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5117
Validation loss decreased (0.728678 --> 0.728401).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4480077
	speed: 0.0163s/iter; left time: 706.7447s
	iters: 200, epoch: 12 | loss: 0.3753947
	speed: 0.0151s/iter; left time: 650.0917s
	iters: 300, epoch: 12 | loss: 0.3824102
	speed: 0.0158s/iter; left time: 679.5899s
	iters: 400, epoch: 12 | loss: 0.3923312
	speed: 0.0151s/iter; left time: 650.1492s
Epoch: 12 cost time: 7.523218393325806
Epoch: 12, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3946 + XiCon Loss:2.4864 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5576213
	speed: 0.0169s/iter; left time: 723.8170s
	iters: 200, epoch: 13 | loss: 0.4119937
	speed: 0.0157s/iter; left time: 669.4375s
	iters: 300, epoch: 13 | loss: 0.3914248
	speed: 0.0144s/iter; left time: 613.4605s
	iters: 400, epoch: 13 | loss: 0.3272790
	speed: 0.0142s/iter; left time: 600.8182s
Epoch: 13 cost time: 7.4040892124176025
Epoch: 13, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3946 + XiCon Loss:2.4855 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4585963
	speed: 0.0164s/iter; left time: 694.9086s
	iters: 200, epoch: 14 | loss: 0.4831784
	speed: 0.0151s/iter; left time: 635.9037s
	iters: 300, epoch: 14 | loss: 0.3578379
	speed: 0.0147s/iter; left time: 617.6193s
	iters: 400, epoch: 14 | loss: 0.3471933
	speed: 0.0150s/iter; left time: 630.1885s
Epoch: 14 cost time: 7.415066242218018
Epoch: 14, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4885 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3958713
	speed: 0.0166s/iter; left time: 693.6051s
	iters: 200, epoch: 15 | loss: 0.4126853
	speed: 0.0149s/iter; left time: 621.8195s
	iters: 300, epoch: 15 | loss: 0.4605128
	speed: 0.0141s/iter; left time: 587.3490s
	iters: 400, epoch: 15 | loss: 0.4245081
	speed: 0.0146s/iter; left time: 604.6916s
Epoch: 15 cost time: 7.3067920207977295
Epoch: 15, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3946 + XiCon Loss:2.4880 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4754577
	speed: 0.0165s/iter; left time: 682.6254s
	iters: 200, epoch: 16 | loss: 0.4986063
	speed: 0.0142s/iter; left time: 586.7799s
	iters: 300, epoch: 16 | loss: 0.4059310
	speed: 0.0144s/iter; left time: 592.3453s
	iters: 400, epoch: 16 | loss: 0.4393769
	speed: 0.0159s/iter; left time: 652.9290s
Epoch: 16 cost time: 7.3736252784729
Epoch: 16, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3947 + XiCon Loss:2.4834 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3948447
	speed: 0.0167s/iter; left time: 681.2192s
	iters: 200, epoch: 17 | loss: 0.3935427
	speed: 0.0149s/iter; left time: 606.0542s
	iters: 300, epoch: 17 | loss: 0.4791392
	speed: 0.0155s/iter; left time: 631.2020s
	iters: 400, epoch: 17 | loss: 0.4552170
	speed: 0.0151s/iter; left time: 611.4423s
Epoch: 17 cost time: 7.5328285694122314
Epoch: 17, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3947 + XiCon Loss:2.4876 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3643231
	speed: 0.0182s/iter; left time: 733.9588s
	iters: 200, epoch: 18 | loss: 0.4418956
	speed: 0.0144s/iter; left time: 579.4609s
	iters: 300, epoch: 18 | loss: 0.3651951
	speed: 0.0145s/iter; left time: 579.9890s
	iters: 400, epoch: 18 | loss: 0.3415257
	speed: 0.0146s/iter; left time: 584.1202s
Epoch: 18 cost time: 7.498900651931763
Epoch: 18, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3945 + XiCon Loss:2.4889 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5117
Validation loss decreased (0.728401 --> 0.728230).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3992020
	speed: 0.0161s/iter; left time: 639.3676s
	iters: 200, epoch: 19 | loss: 0.4136890
	speed: 0.0144s/iter; left time: 572.8939s
	iters: 300, epoch: 19 | loss: 0.4096431
	speed: 0.0150s/iter; left time: 594.9115s
	iters: 400, epoch: 19 | loss: 0.4350903
	speed: 0.0144s/iter; left time: 570.5460s
Epoch: 19 cost time: 7.300486087799072
Epoch: 19, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3944 + XiCon Loss:2.4858 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4148321
	speed: 0.0159s/iter; left time: 625.0959s
	iters: 200, epoch: 20 | loss: 0.4093146
	speed: 0.0143s/iter; left time: 560.5964s
	iters: 300, epoch: 20 | loss: 0.3440611
	speed: 0.0142s/iter; left time: 555.7319s
	iters: 400, epoch: 20 | loss: 0.3857634
	speed: 0.0144s/iter; left time: 561.1147s
Epoch: 20 cost time: 7.161253929138184
Epoch: 20, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3946 + XiCon Loss:2.4905 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.3278724
	speed: 0.0167s/iter; left time: 649.3995s
	iters: 200, epoch: 21 | loss: 0.4026083
	speed: 0.0136s/iter; left time: 526.1587s
	iters: 300, epoch: 21 | loss: 0.3481246
	speed: 0.0145s/iter; left time: 559.2328s
	iters: 400, epoch: 21 | loss: 0.4272540
	speed: 0.0152s/iter; left time: 587.4234s
Epoch: 21 cost time: 7.247945070266724
Epoch: 21, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4860 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4214287
	speed: 0.0165s/iter; left time: 634.6993s
	iters: 200, epoch: 22 | loss: 0.4721035
	speed: 0.0139s/iter; left time: 533.8831s
	iters: 300, epoch: 22 | loss: 0.4877123
	speed: 0.0135s/iter; left time: 516.8599s
	iters: 400, epoch: 22 | loss: 0.3822583
	speed: 0.0133s/iter; left time: 505.5007s
Epoch: 22 cost time: 6.975437641143799
Epoch: 22, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4913 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4984475
	speed: 0.0147s/iter; left time: 556.0084s
	iters: 200, epoch: 23 | loss: 0.3787939
	speed: 0.0135s/iter; left time: 509.3296s
	iters: 300, epoch: 23 | loss: 0.3896052
	speed: 0.0137s/iter; left time: 515.4008s
	iters: 400, epoch: 23 | loss: 0.4647622
	speed: 0.0136s/iter; left time: 512.2515s
Epoch: 23 cost time: 6.75157356262207
Epoch: 23, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3946 + XiCon Loss:2.4849 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.5048424
	speed: 0.0151s/iter; left time: 562.9839s
	iters: 200, epoch: 24 | loss: 0.4044446
	speed: 0.0130s/iter; left time: 486.6326s
	iters: 300, epoch: 24 | loss: 0.4574865
	speed: 0.0132s/iter; left time: 491.7350s
	iters: 400, epoch: 24 | loss: 0.3474366
	speed: 0.0138s/iter; left time: 510.8195s
Epoch: 24 cost time: 6.708524465560913
Epoch: 24, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3945 + XiCon Loss:2.4886 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4140296
	speed: 0.0174s/iter; left time: 642.4285s
	iters: 200, epoch: 25 | loss: 0.4339676
	speed: 0.0155s/iter; left time: 569.5811s
	iters: 300, epoch: 25 | loss: 0.3815834
	speed: 0.0135s/iter; left time: 495.5842s
	iters: 400, epoch: 25 | loss: 0.4274396
	speed: 0.0143s/iter; left time: 522.9745s
Epoch: 25 cost time: 7.260568857192993
Epoch: 25, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3945 + XiCon Loss:2.4869 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5117
Validation loss decreased (0.728230 --> 0.728134).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3885358
	speed: 0.0158s/iter; left time: 575.1848s
	iters: 200, epoch: 26 | loss: 0.3887998
	speed: 0.0142s/iter; left time: 515.2641s
	iters: 300, epoch: 26 | loss: 0.5154945
	speed: 0.0134s/iter; left time: 486.0144s
	iters: 400, epoch: 26 | loss: 0.3521826
	speed: 0.0134s/iter; left time: 482.8619s
Epoch: 26 cost time: 6.883589744567871
Epoch: 26, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3947 + XiCon Loss:2.4902 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3998840
	speed: 0.0156s/iter; left time: 562.0778s
	iters: 200, epoch: 27 | loss: 0.4238071
	speed: 0.0133s/iter; left time: 476.9499s
	iters: 300, epoch: 27 | loss: 0.3536851
	speed: 0.0138s/iter; left time: 494.2441s
	iters: 400, epoch: 27 | loss: 0.3679451
	speed: 0.0138s/iter; left time: 490.3912s
Epoch: 27 cost time: 6.871834754943848
Epoch: 27, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4866 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4206934
	speed: 0.0155s/iter; left time: 549.1246s
	iters: 200, epoch: 28 | loss: 0.4245408
	speed: 0.0131s/iter; left time: 461.5231s
	iters: 300, epoch: 28 | loss: 0.4286181
	speed: 0.0132s/iter; left time: 464.1853s
	iters: 400, epoch: 28 | loss: 0.3974882
	speed: 0.0133s/iter; left time: 466.2384s
Epoch: 28 cost time: 6.820991039276123
Epoch: 28, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3944 + XiCon Loss:2.4866 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3658793
	speed: 0.0163s/iter; left time: 569.5399s
	iters: 200, epoch: 29 | loss: 0.4686154
	speed: 0.0149s/iter; left time: 520.7774s
	iters: 300, epoch: 29 | loss: 0.4392534
	speed: 0.0144s/iter; left time: 501.3946s
	iters: 400, epoch: 29 | loss: 0.4284742
	speed: 0.0147s/iter; left time: 510.2675s
Epoch: 29 cost time: 7.334928035736084
Epoch: 29, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3948 + XiCon Loss:2.4890 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3925303
	speed: 0.0160s/iter; left time: 551.4809s
	iters: 200, epoch: 30 | loss: 0.4174361
	speed: 0.0144s/iter; left time: 495.7577s
	iters: 300, epoch: 30 | loss: 0.4586070
	speed: 0.0155s/iter; left time: 532.3512s
	iters: 400, epoch: 30 | loss: 0.4040253
	speed: 0.0154s/iter; left time: 525.7292s
Epoch: 30 cost time: 7.541369676589966
Epoch: 30, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3945 + XiCon Loss:2.4904 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.5090549
	speed: 0.0166s/iter; left time: 564.4444s
	iters: 200, epoch: 31 | loss: 0.3337258
	speed: 0.0161s/iter; left time: 544.2583s
	iters: 300, epoch: 31 | loss: 0.4280751
	speed: 0.0148s/iter; left time: 500.6340s
	iters: 400, epoch: 31 | loss: 0.3508880
	speed: 0.0151s/iter; left time: 508.3854s
Epoch: 31 cost time: 7.533453464508057
Epoch: 31, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3945 + XiCon Loss:2.4886 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4117407
	speed: 0.0165s/iter; left time: 553.1508s
	iters: 200, epoch: 32 | loss: 0.4940273
	speed: 0.0153s/iter; left time: 509.8358s
	iters: 300, epoch: 32 | loss: 0.3654072
	speed: 0.0141s/iter; left time: 470.3149s
	iters: 400, epoch: 32 | loss: 0.3278254
	speed: 0.0146s/iter; left time: 486.0814s
Epoch: 32 cost time: 7.378516435623169
Epoch: 32, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3943 + XiCon Loss:2.4863 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3802900
	speed: 0.0170s/iter; left time: 560.7131s
	iters: 200, epoch: 33 | loss: 0.3388812
	speed: 0.0145s/iter; left time: 478.2269s
	iters: 300, epoch: 33 | loss: 0.4297588
	speed: 0.0146s/iter; left time: 479.0253s
	iters: 400, epoch: 33 | loss: 0.4998522
	speed: 0.0155s/iter; left time: 506.7946s
Epoch: 33 cost time: 7.430469989776611
Epoch: 33, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3947 + XiCon Loss:2.4882 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4221462
	speed: 0.0162s/iter; left time: 525.8566s
	iters: 200, epoch: 34 | loss: 0.4609074
	speed: 0.0147s/iter; left time: 476.5644s
	iters: 300, epoch: 34 | loss: 0.3773901
	speed: 0.0162s/iter; left time: 523.0677s
	iters: 400, epoch: 34 | loss: 0.3916365
	speed: 0.0150s/iter; left time: 482.4036s
Epoch: 34 cost time: 7.529452800750732
Epoch: 34, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3945 + XiCon Loss:2.4867 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4058509
	speed: 0.0177s/iter; left time: 568.6480s
	iters: 200, epoch: 35 | loss: 0.3391481
	speed: 0.0150s/iter; left time: 480.2899s
	iters: 300, epoch: 35 | loss: 0.4209530
	speed: 0.0144s/iter; left time: 457.7361s
	iters: 400, epoch: 35 | loss: 0.4319759
	speed: 0.0146s/iter; left time: 464.4131s
Epoch: 35 cost time: 7.508886814117432
Epoch: 35, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3946 + XiCon Loss:2.4902 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.51827472448349, mae:0.5050485134124756, mape:3.533902883529663, mspe:1159.11669921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.3563
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.6991709
	speed: 0.0153s/iter; left time: 745.3438s
	iters: 200, epoch: 1 | loss: 0.8905011
	speed: 0.0137s/iter; left time: 664.4939s
	iters: 300, epoch: 1 | loss: 0.5836747
	speed: 0.0137s/iter; left time: 662.6342s
	iters: 400, epoch: 1 | loss: 0.5149806
	speed: 0.0135s/iter; left time: 650.6923s
Epoch: 1 cost time: 6.719006299972534
Epoch: 1, Steps: 487 Train Loss: 0.7596 (Forecasting Loss:0.7348 + XiCon Loss:2.4791 x Lambda(0.01)), Vali MSE Loss: 1.0307 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030660).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5153008
	speed: 0.0154s/iter; left time: 739.1193s
	iters: 200, epoch: 2 | loss: 0.5108517
	speed: 0.0133s/iter; left time: 640.4679s
	iters: 300, epoch: 2 | loss: 0.4178480
	speed: 0.0125s/iter; left time: 598.8831s
	iters: 400, epoch: 2 | loss: 0.4999195
	speed: 0.0129s/iter; left time: 618.7146s
Epoch: 2 cost time: 6.661103963851929
Epoch: 2, Steps: 487 Train Loss: 0.4632 (Forecasting Loss:0.4383 + XiCon Loss:2.4883 x Lambda(0.01)), Vali MSE Loss: 0.7327 Test MSE Loss: 0.5270
Validation loss decreased (1.030660 --> 0.732745).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4458668
	speed: 0.0153s/iter; left time: 728.8145s
	iters: 200, epoch: 3 | loss: 0.4132200
	speed: 0.0119s/iter; left time: 564.2553s
	iters: 300, epoch: 3 | loss: 0.4356543
	speed: 0.0122s/iter; left time: 579.8134s
	iters: 400, epoch: 3 | loss: 0.3827963
	speed: 0.0127s/iter; left time: 602.4852s
Epoch: 3 cost time: 6.36862325668335
Epoch: 3, Steps: 487 Train Loss: 0.4297 (Forecasting Loss:0.4049 + XiCon Loss:2.4790 x Lambda(0.01)), Vali MSE Loss: 0.7178 Test MSE Loss: 0.5186
Validation loss decreased (0.732745 --> 0.717807).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5457957
	speed: 0.0157s/iter; left time: 739.0722s
	iters: 200, epoch: 4 | loss: 0.3902507
	speed: 0.0130s/iter; left time: 611.1244s
	iters: 300, epoch: 4 | loss: 0.5365595
	speed: 0.0129s/iter; left time: 606.6147s
	iters: 400, epoch: 4 | loss: 0.5226021
	speed: 0.0123s/iter; left time: 576.5665s
Epoch: 4 cost time: 6.536009788513184
Epoch: 4, Steps: 487 Train Loss: 0.4236 (Forecasting Loss:0.3989 + XiCon Loss:2.4754 x Lambda(0.01)), Vali MSE Loss: 0.7115 Test MSE Loss: 0.5165
Validation loss decreased (0.717807 --> 0.711503).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3845815
	speed: 0.0152s/iter; left time: 711.1629s
	iters: 200, epoch: 5 | loss: 0.4416923
	speed: 0.0130s/iter; left time: 604.6409s
	iters: 300, epoch: 5 | loss: 0.3951392
	speed: 0.0126s/iter; left time: 586.5642s
	iters: 400, epoch: 5 | loss: 0.3268175
	speed: 0.0129s/iter; left time: 596.6462s
Epoch: 5 cost time: 6.665332555770874
Epoch: 5, Steps: 487 Train Loss: 0.4214 (Forecasting Loss:0.3966 + XiCon Loss:2.4803 x Lambda(0.01)), Vali MSE Loss: 0.7100 Test MSE Loss: 0.5146
Validation loss decreased (0.711503 --> 0.710013).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3629412
	speed: 0.0159s/iter; left time: 734.5374s
	iters: 200, epoch: 6 | loss: 0.3926999
	speed: 0.0125s/iter; left time: 573.8573s
	iters: 300, epoch: 6 | loss: 0.3279391
	speed: 0.0131s/iter; left time: 600.5435s
	iters: 400, epoch: 6 | loss: 0.4487450
	speed: 0.0125s/iter; left time: 572.5049s
Epoch: 6 cost time: 6.528935432434082
Epoch: 6, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3955 + XiCon Loss:2.4827 x Lambda(0.01)), Vali MSE Loss: 0.7074 Test MSE Loss: 0.5133
Validation loss decreased (0.710013 --> 0.707381).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3764022
	speed: 0.0149s/iter; left time: 681.3961s
	iters: 200, epoch: 7 | loss: 0.3748933
	speed: 0.0125s/iter; left time: 571.6909s
	iters: 300, epoch: 7 | loss: 0.4945189
	speed: 0.0124s/iter; left time: 565.3844s
	iters: 400, epoch: 7 | loss: 0.3853198
	speed: 0.0136s/iter; left time: 616.7443s
Epoch: 7 cost time: 6.520989656448364
Epoch: 7, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3948 + XiCon Loss:2.4761 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5133
Validation loss decreased (0.707381 --> 0.706840).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4581966
	speed: 0.0157s/iter; left time: 707.5812s
	iters: 200, epoch: 8 | loss: 0.4390219
	speed: 0.0131s/iter; left time: 590.9229s
	iters: 300, epoch: 8 | loss: 0.3814339
	speed: 0.0128s/iter; left time: 573.7336s
	iters: 400, epoch: 8 | loss: 0.3272804
	speed: 0.0150s/iter; left time: 671.1427s
Epoch: 8 cost time: 6.9717981815338135
Epoch: 8, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3944 + XiCon Loss:2.4760 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5132
Validation loss decreased (0.706840 --> 0.706639).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3959603
	speed: 0.0158s/iter; left time: 705.6973s
	iters: 200, epoch: 9 | loss: 0.4097012
	speed: 0.0141s/iter; left time: 627.9474s
	iters: 300, epoch: 9 | loss: 0.4002939
	speed: 0.0128s/iter; left time: 570.3299s
	iters: 400, epoch: 9 | loss: 0.4987252
	speed: 0.0122s/iter; left time: 543.5567s
Epoch: 9 cost time: 6.566496849060059
Epoch: 9, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3942 + XiCon Loss:2.4757 x Lambda(0.01)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5130
Validation loss decreased (0.706639 --> 0.705973).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4193287
	speed: 0.0153s/iter; left time: 677.4996s
	iters: 200, epoch: 10 | loss: 0.4169035
	speed: 0.0127s/iter; left time: 560.7718s
	iters: 300, epoch: 10 | loss: 0.2932513
	speed: 0.0126s/iter; left time: 554.2112s
	iters: 400, epoch: 10 | loss: 0.4278843
	speed: 0.0124s/iter; left time: 545.0897s
Epoch: 10 cost time: 6.4272074699401855
Epoch: 10, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3942 + XiCon Loss:2.4761 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3365858
	speed: 0.0165s/iter; left time: 722.3828s
	iters: 200, epoch: 11 | loss: 0.3798767
	speed: 0.0138s/iter; left time: 603.0725s
	iters: 300, epoch: 11 | loss: 0.3847539
	speed: 0.0129s/iter; left time: 562.7867s
	iters: 400, epoch: 11 | loss: 0.5372331
	speed: 0.0135s/iter; left time: 585.1927s
Epoch: 11 cost time: 6.7527430057525635
Epoch: 11, Steps: 487 Train Loss: 0.4186 (Forecasting Loss:0.3939 + XiCon Loss:2.4689 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5130
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3946735
	speed: 0.0158s/iter; left time: 685.4138s
	iters: 200, epoch: 12 | loss: 0.4237793
	speed: 0.0122s/iter; left time: 524.5545s
	iters: 300, epoch: 12 | loss: 0.4517950
	speed: 0.0129s/iter; left time: 555.7607s
	iters: 400, epoch: 12 | loss: 0.4354794
	speed: 0.0131s/iter; left time: 560.5354s
Epoch: 12 cost time: 6.50228476524353
Epoch: 12, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3943 + XiCon Loss:2.4757 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4286707
	speed: 0.0152s/iter; left time: 651.9093s
	iters: 200, epoch: 13 | loss: 0.4917989
	speed: 0.0121s/iter; left time: 514.2211s
	iters: 300, epoch: 13 | loss: 0.3839285
	speed: 0.0124s/iter; left time: 529.4213s
	iters: 400, epoch: 13 | loss: 0.3899277
	speed: 0.0122s/iter; left time: 516.1629s
Epoch: 13 cost time: 6.300869703292847
Epoch: 13, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3942 + XiCon Loss:2.4800 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3984186
	speed: 0.0165s/iter; left time: 698.7552s
	iters: 200, epoch: 14 | loss: 0.4313389
	speed: 0.0129s/iter; left time: 543.8128s
	iters: 300, epoch: 14 | loss: 0.3863444
	speed: 0.0125s/iter; left time: 525.4407s
	iters: 400, epoch: 14 | loss: 0.4152015
	speed: 0.0126s/iter; left time: 528.6082s
Epoch: 14 cost time: 6.5414934158325195
Epoch: 14, Steps: 487 Train Loss: 0.4189 (Forecasting Loss:0.3941 + XiCon Loss:2.4778 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5129
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4722093
	speed: 0.0157s/iter; left time: 654.7522s
	iters: 200, epoch: 15 | loss: 0.4351012
	speed: 0.0130s/iter; left time: 540.7975s
	iters: 300, epoch: 15 | loss: 0.4364878
	speed: 0.0125s/iter; left time: 518.9238s
	iters: 400, epoch: 15 | loss: 0.3973096
	speed: 0.0126s/iter; left time: 524.2706s
Epoch: 15 cost time: 6.462724447250366
Epoch: 15, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3938 + XiCon Loss:2.4719 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4406292
	speed: 0.0165s/iter; left time: 681.4823s
	iters: 200, epoch: 16 | loss: 0.4643972
	speed: 0.0129s/iter; left time: 533.3329s
	iters: 300, epoch: 16 | loss: 0.3979104
	speed: 0.0128s/iter; left time: 527.6649s
	iters: 400, epoch: 16 | loss: 0.4795961
	speed: 0.0124s/iter; left time: 509.4739s
Epoch: 16 cost time: 6.654555559158325
Epoch: 16, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3939 + XiCon Loss:2.4750 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5129
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4148479
	speed: 0.0155s/iter; left time: 632.2722s
	iters: 200, epoch: 17 | loss: 0.4620210
	speed: 0.0123s/iter; left time: 502.6051s
	iters: 300, epoch: 17 | loss: 0.4323143
	speed: 0.0119s/iter; left time: 484.6342s
	iters: 400, epoch: 17 | loss: 0.4658892
	speed: 0.0118s/iter; left time: 479.3906s
Epoch: 17 cost time: 6.330657958984375
Epoch: 17, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3942 + XiCon Loss:2.4770 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4553737
	speed: 0.0150s/iter; left time: 606.7595s
	iters: 200, epoch: 18 | loss: 0.4359097
	speed: 0.0127s/iter; left time: 509.5583s
	iters: 300, epoch: 18 | loss: 0.6005012
	speed: 0.0127s/iter; left time: 509.8110s
	iters: 400, epoch: 18 | loss: 0.4196812
	speed: 0.0124s/iter; left time: 495.6876s
Epoch: 18 cost time: 6.412827014923096
Epoch: 18, Steps: 487 Train Loss: 0.4187 (Forecasting Loss:0.3939 + XiCon Loss:2.4736 x Lambda(0.01)), Vali MSE Loss: 0.7063 Test MSE Loss: 0.5129
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3181745
	speed: 0.0160s/iter; left time: 637.9259s
	iters: 200, epoch: 19 | loss: 0.4872498
	speed: 0.0140s/iter; left time: 554.8317s
	iters: 300, epoch: 19 | loss: 0.4439414
	speed: 0.0142s/iter; left time: 564.7544s
	iters: 400, epoch: 19 | loss: 0.3681081
	speed: 0.0151s/iter; left time: 598.1527s
Epoch: 19 cost time: 7.25423526763916
Epoch: 19, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3942 + XiCon Loss:2.4756 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5129
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5196760892868042, mae:0.506333589553833, mape:3.444836139678955, mspe:1084.5816650390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8146
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1390973
	speed: 0.0171s/iter; left time: 831.9879s
	iters: 200, epoch: 1 | loss: 0.7923874
	speed: 0.0148s/iter; left time: 715.7005s
	iters: 300, epoch: 1 | loss: 0.7064413
	speed: 0.0142s/iter; left time: 685.2117s
	iters: 400, epoch: 1 | loss: 0.7580535
	speed: 0.0148s/iter; left time: 715.7961s
Epoch: 1 cost time: 7.3652119636535645
Epoch: 1, Steps: 487 Train Loss: 0.8659 (Forecasting Loss:0.8409 + XiCon Loss:2.4978 x Lambda(0.01)), Vali MSE Loss: 1.1923 Test MSE Loss: 0.6744
Validation loss decreased (inf --> 1.192289).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4683447
	speed: 0.0175s/iter; left time: 839.8337s
	iters: 200, epoch: 2 | loss: 0.4451858
	speed: 0.0153s/iter; left time: 734.0101s
	iters: 300, epoch: 2 | loss: 0.3943605
	speed: 0.0146s/iter; left time: 700.8627s
	iters: 400, epoch: 2 | loss: 0.5366714
	speed: 0.0145s/iter; left time: 691.6829s
Epoch: 2 cost time: 7.5364990234375
Epoch: 2, Steps: 487 Train Loss: 0.4775 (Forecasting Loss:0.4526 + XiCon Loss:2.4908 x Lambda(0.01)), Vali MSE Loss: 0.7520 Test MSE Loss: 0.5336
Validation loss decreased (1.192289 --> 0.752046).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4792329
	speed: 0.0176s/iter; left time: 837.1166s
	iters: 200, epoch: 3 | loss: 0.4122031
	speed: 0.0143s/iter; left time: 679.5896s
	iters: 300, epoch: 3 | loss: 0.3547154
	speed: 0.0143s/iter; left time: 676.3320s
	iters: 400, epoch: 3 | loss: 0.4106175
	speed: 0.0152s/iter; left time: 718.5460s
Epoch: 3 cost time: 7.454899549484253
Epoch: 3, Steps: 487 Train Loss: 0.4330 (Forecasting Loss:0.4081 + XiCon Loss:2.4894 x Lambda(0.01)), Vali MSE Loss: 0.7396 Test MSE Loss: 0.5304
Validation loss decreased (0.752046 --> 0.739586).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4027773
	speed: 0.0167s/iter; left time: 785.1529s
	iters: 200, epoch: 4 | loss: 0.3722405
	speed: 0.0157s/iter; left time: 738.5632s
	iters: 300, epoch: 4 | loss: 0.4290040
	speed: 0.0135s/iter; left time: 634.5440s
	iters: 400, epoch: 4 | loss: 0.4923641
	speed: 0.0135s/iter; left time: 631.7544s
Epoch: 4 cost time: 7.130813837051392
Epoch: 4, Steps: 487 Train Loss: 0.4272 (Forecasting Loss:0.4024 + XiCon Loss:2.4813 x Lambda(0.01)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5268
Validation loss decreased (0.739586 --> 0.731946).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4067679
	speed: 0.0161s/iter; left time: 750.6740s
	iters: 200, epoch: 5 | loss: 0.3881371
	speed: 0.0134s/iter; left time: 621.5060s
	iters: 300, epoch: 5 | loss: 0.4179056
	speed: 0.0129s/iter; left time: 598.7420s
	iters: 400, epoch: 5 | loss: 0.4494132
	speed: 0.0116s/iter; left time: 535.8935s
Epoch: 5 cost time: 6.421878814697266
Epoch: 5, Steps: 487 Train Loss: 0.4247 (Forecasting Loss:0.3999 + XiCon Loss:2.4832 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5230
Validation loss decreased (0.731946 --> 0.730058).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4109989
	speed: 0.0155s/iter; left time: 714.7781s
	iters: 200, epoch: 6 | loss: 0.3972942
	speed: 0.0137s/iter; left time: 631.8280s
	iters: 300, epoch: 6 | loss: 0.4098296
	speed: 0.0135s/iter; left time: 619.5005s
	iters: 400, epoch: 6 | loss: 0.3991532
	speed: 0.0138s/iter; left time: 633.2255s
Epoch: 6 cost time: 6.885079622268677
Epoch: 6, Steps: 487 Train Loss: 0.4233 (Forecasting Loss:0.3985 + XiCon Loss:2.4820 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5222
Validation loss decreased (0.730058 --> 0.728152).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3971825
	speed: 0.0157s/iter; left time: 715.8859s
	iters: 200, epoch: 7 | loss: 0.4127825
	speed: 0.0131s/iter; left time: 597.1146s
	iters: 300, epoch: 7 | loss: 0.4726774
	speed: 0.0135s/iter; left time: 613.4565s
	iters: 400, epoch: 7 | loss: 0.4382444
	speed: 0.0134s/iter; left time: 609.5679s
Epoch: 7 cost time: 6.80613374710083
Epoch: 7, Steps: 487 Train Loss: 0.4228 (Forecasting Loss:0.3980 + XiCon Loss:2.4840 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5216
Validation loss decreased (0.728152 --> 0.727782).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4403252
	speed: 0.0161s/iter; left time: 728.4783s
	iters: 200, epoch: 8 | loss: 0.3956849
	speed: 0.0131s/iter; left time: 592.1636s
	iters: 300, epoch: 8 | loss: 0.4264223
	speed: 0.0136s/iter; left time: 611.7163s
	iters: 400, epoch: 8 | loss: 0.3693370
	speed: 0.0138s/iter; left time: 620.3824s
Epoch: 8 cost time: 6.93403697013855
Epoch: 8, Steps: 487 Train Loss: 0.4225 (Forecasting Loss:0.3977 + XiCon Loss:2.4813 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5215
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4946539
	speed: 0.0160s/iter; left time: 716.1132s
	iters: 200, epoch: 9 | loss: 0.4140633
	speed: 0.0135s/iter; left time: 600.9690s
	iters: 300, epoch: 9 | loss: 0.4774179
	speed: 0.0137s/iter; left time: 610.7128s
	iters: 400, epoch: 9 | loss: 0.3417672
	speed: 0.0138s/iter; left time: 611.3498s
Epoch: 9 cost time: 6.94137167930603
Epoch: 9, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3975 + XiCon Loss:2.4834 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5215
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.5192804
	speed: 0.0161s/iter; left time: 713.6580s
	iters: 200, epoch: 10 | loss: 0.4336912
	speed: 0.0139s/iter; left time: 612.8523s
	iters: 300, epoch: 10 | loss: 0.3764935
	speed: 0.0137s/iter; left time: 602.3789s
	iters: 400, epoch: 10 | loss: 0.3634598
	speed: 0.0135s/iter; left time: 592.3276s
Epoch: 10 cost time: 6.950342893600464
Epoch: 10, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4811 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
Validation loss decreased (0.727782 --> 0.727778).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4342743
	speed: 0.0155s/iter; left time: 678.0696s
	iters: 200, epoch: 11 | loss: 0.3948014
	speed: 0.0136s/iter; left time: 593.3307s
	iters: 300, epoch: 11 | loss: 0.4403934
	speed: 0.0149s/iter; left time: 647.7584s
	iters: 400, epoch: 11 | loss: 0.3791023
	speed: 0.0171s/iter; left time: 741.4245s
Epoch: 11 cost time: 7.411607265472412
Epoch: 11, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3973 + XiCon Loss:2.4820 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3912732
	speed: 0.0174s/iter; left time: 752.8731s
	iters: 200, epoch: 12 | loss: 0.5138043
	speed: 0.0150s/iter; left time: 648.4344s
	iters: 300, epoch: 12 | loss: 0.3812597
	speed: 0.0153s/iter; left time: 658.4434s
	iters: 400, epoch: 12 | loss: 0.4729612
	speed: 0.0151s/iter; left time: 649.1585s
Epoch: 12 cost time: 7.607367277145386
Epoch: 12, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3975 + XiCon Loss:2.4813 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5214
Validation loss decreased (0.727778 --> 0.727638).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3549819
	speed: 0.0177s/iter; left time: 755.4991s
	iters: 200, epoch: 13 | loss: 0.4569252
	speed: 0.0147s/iter; left time: 626.0960s
	iters: 300, epoch: 13 | loss: 0.4545955
	speed: 0.0147s/iter; left time: 625.9924s
	iters: 400, epoch: 13 | loss: 0.3449982
	speed: 0.0149s/iter; left time: 634.0905s
Epoch: 13 cost time: 7.492618560791016
Epoch: 13, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4808 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4357742
	speed: 0.0163s/iter; left time: 688.1874s
	iters: 200, epoch: 14 | loss: 0.4975327
	speed: 0.0154s/iter; left time: 649.6266s
	iters: 300, epoch: 14 | loss: 0.3654091
	speed: 0.0148s/iter; left time: 621.9282s
	iters: 400, epoch: 14 | loss: 0.5843331
	speed: 0.0145s/iter; left time: 607.3045s
Epoch: 14 cost time: 7.521361351013184
Epoch: 14, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3974 + XiCon Loss:2.4775 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
Validation loss decreased (0.727638 --> 0.727232).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3926144
	speed: 0.0170s/iter; left time: 711.2095s
	iters: 200, epoch: 15 | loss: 0.4511036
	speed: 0.0164s/iter; left time: 683.7110s
	iters: 300, epoch: 15 | loss: 0.4382078
	speed: 0.0146s/iter; left time: 607.5384s
	iters: 400, epoch: 15 | loss: 0.3389953
	speed: 0.0150s/iter; left time: 624.2648s
Epoch: 15 cost time: 7.68274188041687
Epoch: 15, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3975 + XiCon Loss:2.4796 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3494589
	speed: 0.0167s/iter; left time: 690.5401s
	iters: 200, epoch: 16 | loss: 0.4009560
	speed: 0.0141s/iter; left time: 579.2754s
	iters: 300, epoch: 16 | loss: 0.3930531
	speed: 0.0147s/iter; left time: 604.4289s
	iters: 400, epoch: 16 | loss: 0.4580168
	speed: 0.0149s/iter; left time: 611.8470s
Epoch: 16 cost time: 7.368916749954224
Epoch: 16, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3971 + XiCon Loss:2.4827 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4016400
	speed: 0.0167s/iter; left time: 679.5900s
	iters: 200, epoch: 17 | loss: 0.4599483
	speed: 0.0151s/iter; left time: 612.9509s
	iters: 300, epoch: 17 | loss: 0.4509159
	speed: 0.0142s/iter; left time: 576.8353s
	iters: 400, epoch: 17 | loss: 0.3445587
	speed: 0.0163s/iter; left time: 658.6382s
Epoch: 17 cost time: 7.516122341156006
Epoch: 17, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3974 + XiCon Loss:2.4841 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3811937
	speed: 0.0170s/iter; left time: 684.6163s
	iters: 200, epoch: 18 | loss: 0.5229365
	speed: 0.0150s/iter; left time: 602.4505s
	iters: 300, epoch: 18 | loss: 0.4282743
	speed: 0.0155s/iter; left time: 621.0656s
	iters: 400, epoch: 18 | loss: 0.4885396
	speed: 0.0151s/iter; left time: 603.0708s
Epoch: 18 cost time: 7.5709147453308105
Epoch: 18, Steps: 487 Train Loss: 0.4219 (Forecasting Loss:0.3971 + XiCon Loss:2.4783 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3447809
	speed: 0.0176s/iter; left time: 701.9791s
	iters: 200, epoch: 19 | loss: 0.4029398
	speed: 0.0149s/iter; left time: 591.8717s
	iters: 300, epoch: 19 | loss: 0.4273748
	speed: 0.0145s/iter; left time: 573.2966s
	iters: 400, epoch: 19 | loss: 0.5027559
	speed: 0.0145s/iter; left time: 574.5068s
Epoch: 19 cost time: 7.528936386108398
Epoch: 19, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3974 + XiCon Loss:2.4779 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3555620
	speed: 0.0159s/iter; left time: 624.6517s
	iters: 200, epoch: 20 | loss: 0.4515902
	speed: 0.0140s/iter; left time: 550.7452s
	iters: 300, epoch: 20 | loss: 0.3900363
	speed: 0.0150s/iter; left time: 586.0928s
	iters: 400, epoch: 20 | loss: 0.4261863
	speed: 0.0151s/iter; left time: 589.7672s
Epoch: 20 cost time: 7.392980575561523
Epoch: 20, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3973 + XiCon Loss:2.4821 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4626262
	speed: 0.0169s/iter; left time: 658.4033s
	iters: 200, epoch: 21 | loss: 0.4159185
	speed: 0.0148s/iter; left time: 575.3446s
	iters: 300, epoch: 21 | loss: 0.4483228
	speed: 0.0161s/iter; left time: 624.0893s
	iters: 400, epoch: 21 | loss: 0.4479514
	speed: 0.0150s/iter; left time: 577.5351s
Epoch: 21 cost time: 7.634796380996704
Epoch: 21, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4834 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4944770
	speed: 0.0188s/iter; left time: 722.3341s
	iters: 200, epoch: 22 | loss: 0.4131191
	speed: 0.0141s/iter; left time: 539.1659s
	iters: 300, epoch: 22 | loss: 0.4639454
	speed: 0.0146s/iter; left time: 557.0662s
	iters: 400, epoch: 22 | loss: 0.3886458
	speed: 0.0147s/iter; left time: 559.8342s
Epoch: 22 cost time: 7.534940242767334
Epoch: 22, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4824 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5213
Validation loss decreased (0.727232 --> 0.727087).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4195411
	speed: 0.0170s/iter; left time: 642.8138s
	iters: 200, epoch: 23 | loss: 0.4261732
	speed: 0.0147s/iter; left time: 556.2854s
	iters: 300, epoch: 23 | loss: 0.3840029
	speed: 0.0144s/iter; left time: 542.1672s
	iters: 400, epoch: 23 | loss: 0.4084232
	speed: 0.0144s/iter; left time: 541.8570s
Epoch: 23 cost time: 7.37133264541626
Epoch: 23, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3971 + XiCon Loss:2.4860 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4014488
	speed: 0.0163s/iter; left time: 607.9997s
	iters: 200, epoch: 24 | loss: 0.3906271
	speed: 0.0145s/iter; left time: 541.5465s
	iters: 300, epoch: 24 | loss: 0.3937733
	speed: 0.0150s/iter; left time: 559.6883s
	iters: 400, epoch: 24 | loss: 0.4851406
	speed: 0.0156s/iter; left time: 578.9831s
Epoch: 24 cost time: 7.492257833480835
Epoch: 24, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3971 + XiCon Loss:2.4832 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4626198
	speed: 0.0170s/iter; left time: 626.7831s
	iters: 200, epoch: 25 | loss: 0.3185710
	speed: 0.0142s/iter; left time: 522.2198s
	iters: 300, epoch: 25 | loss: 0.3830210
	speed: 0.0148s/iter; left time: 544.8823s
	iters: 400, epoch: 25 | loss: 0.3959489
	speed: 0.0153s/iter; left time: 561.6041s
Epoch: 25 cost time: 7.413769245147705
Epoch: 25, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3974 + XiCon Loss:2.4820 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3990933
	speed: 0.0165s/iter; left time: 599.8917s
	iters: 200, epoch: 26 | loss: 0.4273993
	speed: 0.0147s/iter; left time: 535.4488s
	iters: 300, epoch: 26 | loss: 0.3893955
	speed: 0.0147s/iter; left time: 532.1142s
	iters: 400, epoch: 26 | loss: 0.4422850
	speed: 0.0142s/iter; left time: 514.3485s
Epoch: 26 cost time: 7.360442399978638
Epoch: 26, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3971 + XiCon Loss:2.4867 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3739112
	speed: 0.0167s/iter; left time: 601.1818s
	iters: 200, epoch: 27 | loss: 0.3907931
	speed: 0.0146s/iter; left time: 525.0381s
	iters: 300, epoch: 27 | loss: 0.4747282
	speed: 0.0144s/iter; left time: 514.2175s
	iters: 400, epoch: 27 | loss: 0.4717203
	speed: 0.0145s/iter; left time: 515.7383s
Epoch: 27 cost time: 7.3227057456970215
Epoch: 27, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4797 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4280109
	speed: 0.0171s/iter; left time: 605.9137s
	iters: 200, epoch: 28 | loss: 0.4395438
	speed: 0.0142s/iter; left time: 503.1765s
	iters: 300, epoch: 28 | loss: 0.4062647
	speed: 0.0137s/iter; left time: 484.0907s
	iters: 400, epoch: 28 | loss: 0.3876615
	speed: 0.0150s/iter; left time: 525.7593s
Epoch: 28 cost time: 7.335437536239624
Epoch: 28, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3975 + XiCon Loss:2.4866 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4470620
	speed: 0.0163s/iter; left time: 570.3897s
	iters: 200, epoch: 29 | loss: 0.4147157
	speed: 0.0142s/iter; left time: 495.5920s
	iters: 300, epoch: 29 | loss: 0.4983407
	speed: 0.0144s/iter; left time: 499.1065s
	iters: 400, epoch: 29 | loss: 0.4942810
	speed: 0.0161s/iter; left time: 558.3461s
Epoch: 29 cost time: 7.427031517028809
Epoch: 29, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3973 + XiCon Loss:2.4830 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4887391
	speed: 0.0176s/iter; left time: 607.4393s
	iters: 200, epoch: 30 | loss: 0.4304059
	speed: 0.0147s/iter; left time: 504.0644s
	iters: 300, epoch: 30 | loss: 0.5072429
	speed: 0.0117s/iter; left time: 400.0588s
	iters: 400, epoch: 30 | loss: 0.4347239
	speed: 0.0127s/iter; left time: 434.4148s
Epoch: 30 cost time: 6.8101348876953125
Epoch: 30, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4773 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4317796
	speed: 0.0174s/iter; left time: 592.0229s
	iters: 200, epoch: 31 | loss: 0.3258032
	speed: 0.0141s/iter; left time: 476.2577s
	iters: 300, epoch: 31 | loss: 0.3815443
	speed: 0.0140s/iter; left time: 471.8645s
	iters: 400, epoch: 31 | loss: 0.4490390
	speed: 0.0157s/iter; left time: 527.6867s
Epoch: 31 cost time: 7.527292728424072
Epoch: 31, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3972 + XiCon Loss:2.4863 x Lambda(0.01)), Vali MSE Loss: 0.7269 Test MSE Loss: 0.5213
Validation loss decreased (0.727087 --> 0.726935).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4039456
	speed: 0.0166s/iter; left time: 554.9308s
	iters: 200, epoch: 32 | loss: 0.3996740
	speed: 0.0145s/iter; left time: 483.6097s
	iters: 300, epoch: 32 | loss: 0.3388903
	speed: 0.0160s/iter; left time: 532.7661s
	iters: 400, epoch: 32 | loss: 0.3181911
	speed: 0.0144s/iter; left time: 478.9599s
Epoch: 32 cost time: 7.431612730026245
Epoch: 32, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4747 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3676134
	speed: 0.0169s/iter; left time: 558.1633s
	iters: 200, epoch: 33 | loss: 0.4491231
	speed: 0.0156s/iter; left time: 514.0707s
	iters: 300, epoch: 33 | loss: 0.4252748
	speed: 0.0148s/iter; left time: 484.3822s
	iters: 400, epoch: 33 | loss: 0.3835830
	speed: 0.0150s/iter; left time: 490.4371s
Epoch: 33 cost time: 7.504256248474121
Epoch: 33, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4823 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4486343
	speed: 0.0164s/iter; left time: 533.0396s
	iters: 200, epoch: 34 | loss: 0.4949720
	speed: 0.0149s/iter; left time: 482.0199s
	iters: 300, epoch: 34 | loss: 0.3902383
	speed: 0.0144s/iter; left time: 464.5401s
	iters: 400, epoch: 34 | loss: 0.4251546
	speed: 0.0145s/iter; left time: 468.5985s
Epoch: 34 cost time: 7.363681316375732
Epoch: 34, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4847 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3699645
	speed: 0.0177s/iter; left time: 568.1039s
	iters: 200, epoch: 35 | loss: 0.3597252
	speed: 0.0153s/iter; left time: 487.9852s
	iters: 300, epoch: 35 | loss: 0.3588104
	speed: 0.0152s/iter; left time: 482.5818s
	iters: 400, epoch: 35 | loss: 0.3958198
	speed: 0.0155s/iter; left time: 490.9022s
Epoch: 35 cost time: 7.702251434326172
Epoch: 35, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4841 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4670663
	speed: 0.0174s/iter; left time: 549.5893s
	iters: 200, epoch: 36 | loss: 0.4711742
	speed: 0.0145s/iter; left time: 454.6957s
	iters: 300, epoch: 36 | loss: 0.3836966
	speed: 0.0142s/iter; left time: 444.4649s
	iters: 400, epoch: 36 | loss: 0.4715259
	speed: 0.0149s/iter; left time: 465.5581s
Epoch: 36 cost time: 7.418814420700073
Epoch: 36, Steps: 487 Train Loss: 0.4223 (Forecasting Loss:0.3974 + XiCon Loss:2.4806 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4081670
	speed: 0.0170s/iter; left time: 529.4364s
	iters: 200, epoch: 37 | loss: 0.3499412
	speed: 0.0148s/iter; left time: 456.8242s
	iters: 300, epoch: 37 | loss: 0.4153995
	speed: 0.0147s/iter; left time: 455.1222s
	iters: 400, epoch: 37 | loss: 0.4699347
	speed: 0.0153s/iter; left time: 471.5875s
Epoch: 37 cost time: 7.504440546035767
Epoch: 37, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3974 + XiCon Loss:2.4845 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3964185
	speed: 0.0163s/iter; left time: 499.5644s
	iters: 200, epoch: 38 | loss: 0.4238099
	speed: 0.0146s/iter; left time: 444.8946s
	iters: 300, epoch: 38 | loss: 0.4301278
	speed: 0.0142s/iter; left time: 430.2003s
	iters: 400, epoch: 38 | loss: 0.3692343
	speed: 0.0155s/iter; left time: 470.3951s
Epoch: 38 cost time: 7.408573389053345
Epoch: 38, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3974 + XiCon Loss:2.4852 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.3814983
	speed: 0.0166s/iter; left time: 499.4669s
	iters: 200, epoch: 39 | loss: 0.3884592
	speed: 0.0158s/iter; left time: 473.9123s
	iters: 300, epoch: 39 | loss: 0.4235361
	speed: 0.0151s/iter; left time: 452.2100s
	iters: 400, epoch: 39 | loss: 0.4184310
	speed: 0.0139s/iter; left time: 415.5421s
Epoch: 39 cost time: 7.452429294586182
Epoch: 39, Steps: 487 Train Loss: 0.4220 (Forecasting Loss:0.3972 + XiCon Loss:2.4784 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4739850
	speed: 0.0181s/iter; left time: 534.7059s
	iters: 200, epoch: 40 | loss: 0.4127643
	speed: 0.0147s/iter; left time: 434.8905s
	iters: 300, epoch: 40 | loss: 0.4324619
	speed: 0.0142s/iter; left time: 417.5702s
	iters: 400, epoch: 40 | loss: 0.3276632
	speed: 0.0153s/iter; left time: 448.0615s
Epoch: 40 cost time: 7.602450370788574
Epoch: 40, Steps: 487 Train Loss: 0.4222 (Forecasting Loss:0.3974 + XiCon Loss:2.4787 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4666050
	speed: 0.0167s/iter; left time: 485.8457s
	iters: 200, epoch: 41 | loss: 0.3532649
	speed: 0.0143s/iter; left time: 416.0861s
	iters: 300, epoch: 41 | loss: 0.3982742
	speed: 0.0153s/iter; left time: 443.3303s
	iters: 400, epoch: 41 | loss: 0.3963165
	speed: 0.0160s/iter; left time: 460.1326s
Epoch: 41 cost time: 7.622779846191406
Epoch: 41, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3973 + XiCon Loss:2.4795 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5306769013404846, mae:0.5120173096656799, mape:3.6041815280914307, mspe:1211.9580078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0481
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1073363
	speed: 0.0153s/iter; left time: 742.0937s
	iters: 200, epoch: 1 | loss: 0.8682826
	speed: 0.0137s/iter; left time: 664.9120s
	iters: 300, epoch: 1 | loss: 0.7722226
	speed: 0.0140s/iter; left time: 679.9542s
	iters: 400, epoch: 1 | loss: 0.8352637
	speed: 0.0136s/iter; left time: 656.4243s
Epoch: 1 cost time: 6.930206775665283
Epoch: 1, Steps: 487 Train Loss: 0.8255 (Forecasting Loss:0.8010 + XiCon Loss:2.4509 x Lambda(0.01)), Vali MSE Loss: 1.0984 Test MSE Loss: 0.6609
Validation loss decreased (inf --> 1.098370).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5754266
	speed: 0.0159s/iter; left time: 763.4670s
	iters: 200, epoch: 2 | loss: 0.4373757
	speed: 0.0127s/iter; left time: 609.4329s
	iters: 300, epoch: 2 | loss: 0.4296268
	speed: 0.0136s/iter; left time: 652.7132s
	iters: 400, epoch: 2 | loss: 0.3924105
	speed: 0.0134s/iter; left time: 640.0347s
Epoch: 2 cost time: 6.818022727966309
Epoch: 2, Steps: 487 Train Loss: 0.4598 (Forecasting Loss:0.4353 + XiCon Loss:2.4480 x Lambda(0.01)), Vali MSE Loss: 0.7548 Test MSE Loss: 0.5191
Validation loss decreased (1.098370 --> 0.754793).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4379721
	speed: 0.0163s/iter; left time: 777.4703s
	iters: 200, epoch: 3 | loss: 0.4489759
	speed: 0.0143s/iter; left time: 677.5994s
	iters: 300, epoch: 3 | loss: 0.4286613
	speed: 0.0160s/iter; left time: 760.6683s
	iters: 400, epoch: 3 | loss: 0.4636852
	speed: 0.0133s/iter; left time: 630.2567s
Epoch: 3 cost time: 7.217418670654297
Epoch: 3, Steps: 487 Train Loss: 0.4268 (Forecasting Loss:0.4023 + XiCon Loss:2.4478 x Lambda(0.01)), Vali MSE Loss: 0.7487 Test MSE Loss: 0.5120
Validation loss decreased (0.754793 --> 0.748652).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4138458
	speed: 0.0159s/iter; left time: 750.3989s
	iters: 200, epoch: 4 | loss: 0.4257514
	speed: 0.0134s/iter; left time: 629.2913s
	iters: 300, epoch: 4 | loss: 0.4969741
	speed: 0.0141s/iter; left time: 660.4422s
	iters: 400, epoch: 4 | loss: 0.3614916
	speed: 0.0133s/iter; left time: 624.7541s
Epoch: 4 cost time: 6.942633867263794
Epoch: 4, Steps: 487 Train Loss: 0.4218 (Forecasting Loss:0.3973 + XiCon Loss:2.4487 x Lambda(0.01)), Vali MSE Loss: 0.7408 Test MSE Loss: 0.5092
Validation loss decreased (0.748652 --> 0.740813).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3986542
	speed: 0.0165s/iter; left time: 769.5513s
	iters: 200, epoch: 5 | loss: 0.4496757
	speed: 0.0141s/iter; left time: 657.3065s
	iters: 300, epoch: 5 | loss: 0.4424874
	speed: 0.0145s/iter; left time: 674.6022s
	iters: 400, epoch: 5 | loss: 0.4283144
	speed: 0.0146s/iter; left time: 675.6404s
Epoch: 5 cost time: 7.201140403747559
Epoch: 5, Steps: 487 Train Loss: 0.4197 (Forecasting Loss:0.3951 + XiCon Loss:2.4505 x Lambda(0.01)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5092
Validation loss decreased (0.740813 --> 0.738959).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4339985
	speed: 0.0157s/iter; left time: 722.6229s
	iters: 200, epoch: 6 | loss: 0.3843530
	speed: 0.0136s/iter; left time: 627.7508s
	iters: 300, epoch: 6 | loss: 0.4838925
	speed: 0.0133s/iter; left time: 612.9432s
	iters: 400, epoch: 6 | loss: 0.5288223
	speed: 0.0135s/iter; left time: 617.0477s
Epoch: 6 cost time: 6.836873531341553
Epoch: 6, Steps: 487 Train Loss: 0.4186 (Forecasting Loss:0.3941 + XiCon Loss:2.4485 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5086
Validation loss decreased (0.738959 --> 0.737590).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4053516
	speed: 0.0161s/iter; left time: 734.4567s
	iters: 200, epoch: 7 | loss: 0.3790732
	speed: 0.0150s/iter; left time: 681.6236s
	iters: 300, epoch: 7 | loss: 0.4031416
	speed: 0.0143s/iter; left time: 651.1726s
	iters: 400, epoch: 7 | loss: 0.4090344
	speed: 0.0148s/iter; left time: 669.8434s
Epoch: 7 cost time: 7.304922103881836
Epoch: 7, Steps: 487 Train Loss: 0.4180 (Forecasting Loss:0.3936 + XiCon Loss:2.4430 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5082
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4502375
	speed: 0.0169s/iter; left time: 762.1277s
	iters: 200, epoch: 8 | loss: 0.4789333
	speed: 0.0141s/iter; left time: 637.0553s
	iters: 300, epoch: 8 | loss: 0.4075641
	speed: 0.0143s/iter; left time: 644.3850s
	iters: 400, epoch: 8 | loss: 0.3709517
	speed: 0.0153s/iter; left time: 687.5299s
Epoch: 8 cost time: 7.325862407684326
Epoch: 8, Steps: 487 Train Loss: 0.4177 (Forecasting Loss:0.3932 + XiCon Loss:2.4436 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
Validation loss decreased (0.737590 --> 0.737127).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4083425
	speed: 0.0167s/iter; left time: 747.3512s
	iters: 200, epoch: 9 | loss: 0.4055358
	speed: 0.0140s/iter; left time: 625.4114s
	iters: 300, epoch: 9 | loss: 0.4461886
	speed: 0.0150s/iter; left time: 668.2855s
	iters: 400, epoch: 9 | loss: 0.4507622
	speed: 0.0154s/iter; left time: 685.2918s
Epoch: 9 cost time: 7.366635799407959
Epoch: 9, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3933 + XiCon Loss:2.4476 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5080
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4340048
	speed: 0.0166s/iter; left time: 735.6234s
	iters: 200, epoch: 10 | loss: 0.4204833
	speed: 0.0159s/iter; left time: 700.7282s
	iters: 300, epoch: 10 | loss: 0.4960898
	speed: 0.0144s/iter; left time: 633.6818s
	iters: 400, epoch: 10 | loss: 0.4453264
	speed: 0.0143s/iter; left time: 628.5062s
Epoch: 10 cost time: 7.452646732330322
Epoch: 10, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4436 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4070440
	speed: 0.0172s/iter; left time: 753.8892s
	iters: 200, epoch: 11 | loss: 0.3563439
	speed: 0.0142s/iter; left time: 620.1760s
	iters: 300, epoch: 11 | loss: 0.3802072
	speed: 0.0144s/iter; left time: 628.7329s
	iters: 400, epoch: 11 | loss: 0.3625672
	speed: 0.0153s/iter; left time: 665.2154s
Epoch: 11 cost time: 7.437593460083008
Epoch: 11, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4447 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
Validation loss decreased (0.737127 --> 0.736964).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.5080969
	speed: 0.0167s/iter; left time: 722.7175s
	iters: 200, epoch: 12 | loss: 0.4204016
	speed: 0.0144s/iter; left time: 622.9103s
	iters: 300, epoch: 12 | loss: 0.4866180
	speed: 0.0139s/iter; left time: 599.5407s
	iters: 400, epoch: 12 | loss: 0.3771087
	speed: 0.0160s/iter; left time: 685.0616s
Epoch: 12 cost time: 7.51112174987793
Epoch: 12, Steps: 487 Train Loss: 0.4176 (Forecasting Loss:0.3931 + XiCon Loss:2.4491 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4501380
	speed: 0.0169s/iter; left time: 723.3307s
	iters: 200, epoch: 13 | loss: 0.4158900
	speed: 0.0143s/iter; left time: 610.0034s
	iters: 300, epoch: 13 | loss: 0.3463803
	speed: 0.0147s/iter; left time: 624.4322s
	iters: 400, epoch: 13 | loss: 0.4174442
	speed: 0.0146s/iter; left time: 617.8540s
Epoch: 13 cost time: 7.25147271156311
Epoch: 13, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4439 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3843402
	speed: 0.0175s/iter; left time: 738.8338s
	iters: 200, epoch: 14 | loss: 0.3397115
	speed: 0.0152s/iter; left time: 642.3959s
	iters: 300, epoch: 14 | loss: 0.3577507
	speed: 0.0153s/iter; left time: 644.5197s
	iters: 400, epoch: 14 | loss: 0.4131025
	speed: 0.0167s/iter; left time: 699.7404s
Epoch: 14 cost time: 7.760554313659668
Epoch: 14, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3928 + XiCon Loss:2.4445 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4392836
	speed: 0.0180s/iter; left time: 753.8023s
	iters: 200, epoch: 15 | loss: 0.4138396
	speed: 0.0143s/iter; left time: 596.9094s
	iters: 300, epoch: 15 | loss: 0.5425352
	speed: 0.0144s/iter; left time: 599.9650s
	iters: 400, epoch: 15 | loss: 0.3629279
	speed: 0.0152s/iter; left time: 630.7975s
Epoch: 15 cost time: 7.543723106384277
Epoch: 15, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3934 + XiCon Loss:2.4423 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736964 --> 0.736913).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3747486
	speed: 0.0163s/iter; left time: 673.1948s
	iters: 200, epoch: 16 | loss: 0.3578133
	speed: 0.0146s/iter; left time: 602.1227s
	iters: 300, epoch: 16 | loss: 0.4068647
	speed: 0.0150s/iter; left time: 614.8894s
	iters: 400, epoch: 16 | loss: 0.3971249
	speed: 0.0152s/iter; left time: 624.2224s
Epoch: 16 cost time: 7.434024095535278
Epoch: 16, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3928 + XiCon Loss:2.4406 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4016127
	speed: 0.0169s/iter; left time: 689.3590s
	iters: 200, epoch: 17 | loss: 0.3989907
	speed: 0.0144s/iter; left time: 587.8768s
	iters: 300, epoch: 17 | loss: 0.4237907
	speed: 0.0144s/iter; left time: 586.6665s
	iters: 400, epoch: 17 | loss: 0.4275205
	speed: 0.0148s/iter; left time: 600.9535s
Epoch: 17 cost time: 7.292066335678101
Epoch: 17, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4511 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5050049
	speed: 0.0170s/iter; left time: 685.4183s
	iters: 200, epoch: 18 | loss: 0.4363695
	speed: 0.0140s/iter; left time: 563.8953s
	iters: 300, epoch: 18 | loss: 0.3747919
	speed: 0.0152s/iter; left time: 607.9589s
	iters: 400, epoch: 18 | loss: 0.3503361
	speed: 0.0172s/iter; left time: 687.7624s
Epoch: 18 cost time: 7.675536632537842
Epoch: 18, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4461 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4382010
	speed: 0.0164s/iter; left time: 654.1701s
	iters: 200, epoch: 19 | loss: 0.4182390
	speed: 0.0152s/iter; left time: 605.1344s
	iters: 300, epoch: 19 | loss: 0.3260966
	speed: 0.0156s/iter; left time: 617.1187s
	iters: 400, epoch: 19 | loss: 0.4658836
	speed: 0.0142s/iter; left time: 562.6937s
Epoch: 19 cost time: 7.486454248428345
Epoch: 19, Steps: 487 Train Loss: 0.4176 (Forecasting Loss:0.3931 + XiCon Loss:2.4475 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4339090
	speed: 0.0174s/iter; left time: 685.6970s
	iters: 200, epoch: 20 | loss: 0.3880247
	speed: 0.0143s/iter; left time: 559.3125s
	iters: 300, epoch: 20 | loss: 0.3768822
	speed: 0.0150s/iter; left time: 588.4986s
	iters: 400, epoch: 20 | loss: 0.3543931
	speed: 0.0144s/iter; left time: 562.1922s
Epoch: 20 cost time: 7.4068169593811035
Epoch: 20, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3931 + XiCon Loss:2.4460 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736913 --> 0.736911).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4382172
	speed: 0.0166s/iter; left time: 644.3623s
	iters: 200, epoch: 21 | loss: 0.4294742
	speed: 0.0152s/iter; left time: 589.0923s
	iters: 300, epoch: 21 | loss: 0.3511352
	speed: 0.0146s/iter; left time: 563.5288s
	iters: 400, epoch: 21 | loss: 0.3772449
	speed: 0.0148s/iter; left time: 569.6943s
Epoch: 21 cost time: 7.49699592590332
Epoch: 21, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4507 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4211006
	speed: 0.0171s/iter; left time: 654.7295s
	iters: 200, epoch: 22 | loss: 0.4333244
	speed: 0.0148s/iter; left time: 567.8287s
	iters: 300, epoch: 22 | loss: 0.4450340
	speed: 0.0156s/iter; left time: 595.4270s
	iters: 400, epoch: 22 | loss: 0.3930128
	speed: 0.0155s/iter; left time: 591.9820s
Epoch: 22 cost time: 7.613644599914551
Epoch: 22, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4491 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3610410
	speed: 0.0174s/iter; left time: 659.3870s
	iters: 200, epoch: 23 | loss: 0.3863989
	speed: 0.0155s/iter; left time: 585.4811s
	iters: 300, epoch: 23 | loss: 0.4745156
	speed: 0.0153s/iter; left time: 577.0371s
	iters: 400, epoch: 23 | loss: 0.4274451
	speed: 0.0148s/iter; left time: 556.1343s
Epoch: 23 cost time: 7.6716930866241455
Epoch: 23, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4476 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4369171
	speed: 0.0168s/iter; left time: 630.0794s
	iters: 200, epoch: 24 | loss: 0.4657088
	speed: 0.0148s/iter; left time: 553.4444s
	iters: 300, epoch: 24 | loss: 0.3425876
	speed: 0.0143s/iter; left time: 533.3686s
	iters: 400, epoch: 24 | loss: 0.4495121
	speed: 0.0161s/iter; left time: 596.0665s
Epoch: 24 cost time: 7.631921052932739
Epoch: 24, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3930 + XiCon Loss:2.4428 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4040896
	speed: 0.0175s/iter; left time: 645.4492s
	iters: 200, epoch: 25 | loss: 0.3633836
	speed: 0.0162s/iter; left time: 597.2452s
	iters: 300, epoch: 25 | loss: 0.4124775
	speed: 0.0146s/iter; left time: 536.7190s
	iters: 400, epoch: 25 | loss: 0.4451638
	speed: 0.0146s/iter; left time: 534.1251s
Epoch: 25 cost time: 7.674968957901001
Epoch: 25, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4492 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5079
Validation loss decreased (0.736911 --> 0.736570).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4152539
	speed: 0.0176s/iter; left time: 641.8731s
	iters: 200, epoch: 26 | loss: 0.3697678
	speed: 0.0148s/iter; left time: 538.3742s
	iters: 300, epoch: 26 | loss: 0.4448394
	speed: 0.0145s/iter; left time: 523.6366s
	iters: 400, epoch: 26 | loss: 0.4695900
	speed: 0.0148s/iter; left time: 533.9229s
Epoch: 26 cost time: 7.481168985366821
Epoch: 26, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3928 + XiCon Loss:2.4443 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4157558
	speed: 0.0178s/iter; left time: 639.6432s
	iters: 200, epoch: 27 | loss: 0.4583013
	speed: 0.0147s/iter; left time: 525.0915s
	iters: 300, epoch: 27 | loss: 0.3664005
	speed: 0.0149s/iter; left time: 531.6836s
	iters: 400, epoch: 27 | loss: 0.4187021
	speed: 0.0148s/iter; left time: 526.0734s
Epoch: 27 cost time: 7.51270318031311
Epoch: 27, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4487 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3901732
	speed: 0.0166s/iter; left time: 587.3119s
	iters: 200, epoch: 28 | loss: 0.3851845
	speed: 0.0143s/iter; left time: 504.2433s
	iters: 300, epoch: 28 | loss: 0.3767410
	speed: 0.0154s/iter; left time: 542.9295s
	iters: 400, epoch: 28 | loss: 0.4411859
	speed: 0.0151s/iter; left time: 532.0119s
Epoch: 28 cost time: 7.40911865234375
Epoch: 28, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3931 + XiCon Loss:2.4453 x Lambda(0.01)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5079
Validation loss decreased (0.736570 --> 0.736469).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4724751
	speed: 0.0171s/iter; left time: 598.2131s
	iters: 200, epoch: 29 | loss: 0.4250548
	speed: 0.0145s/iter; left time: 505.8502s
	iters: 300, epoch: 29 | loss: 0.3820252
	speed: 0.0152s/iter; left time: 527.1760s
	iters: 400, epoch: 29 | loss: 0.4181671
	speed: 0.0153s/iter; left time: 529.2921s
Epoch: 29 cost time: 7.554531574249268
Epoch: 29, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4455 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4748617
	speed: 0.0180s/iter; left time: 620.3127s
	iters: 200, epoch: 30 | loss: 0.4508358
	speed: 0.0146s/iter; left time: 502.1429s
	iters: 300, epoch: 30 | loss: 0.4068352
	speed: 0.0151s/iter; left time: 518.2506s
	iters: 400, epoch: 30 | loss: 0.3827056
	speed: 0.0148s/iter; left time: 504.9684s
Epoch: 30 cost time: 7.658696413040161
Epoch: 30, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4496 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3727805
	speed: 0.0172s/iter; left time: 583.3722s
	iters: 200, epoch: 31 | loss: 0.3288935
	speed: 0.0147s/iter; left time: 499.5524s
	iters: 300, epoch: 31 | loss: 0.4542896
	speed: 0.0161s/iter; left time: 542.5255s
	iters: 400, epoch: 31 | loss: 0.4093383
	speed: 0.0159s/iter; left time: 534.4987s
Epoch: 31 cost time: 7.733245134353638
Epoch: 31, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4451 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4651626
	speed: 0.0174s/iter; left time: 584.1100s
	iters: 200, epoch: 32 | loss: 0.4849512
	speed: 0.0143s/iter; left time: 477.7069s
	iters: 300, epoch: 32 | loss: 0.4006813
	speed: 0.0143s/iter; left time: 476.3177s
	iters: 400, epoch: 32 | loss: 0.4258298
	speed: 0.0147s/iter; left time: 487.9509s
Epoch: 32 cost time: 7.364980220794678
Epoch: 32, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4467 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4468407
	speed: 0.0175s/iter; left time: 577.3509s
	iters: 200, epoch: 33 | loss: 0.4411075
	speed: 0.0154s/iter; left time: 506.4866s
	iters: 300, epoch: 33 | loss: 0.3767391
	speed: 0.0146s/iter; left time: 479.9183s
	iters: 400, epoch: 33 | loss: 0.3650525
	speed: 0.0148s/iter; left time: 485.4721s
Epoch: 33 cost time: 7.589928388595581
Epoch: 33, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3929 + XiCon Loss:2.4429 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3768753
	speed: 0.0169s/iter; left time: 549.7289s
	iters: 200, epoch: 34 | loss: 0.4241650
	speed: 0.0155s/iter; left time: 504.1954s
	iters: 300, epoch: 34 | loss: 0.3327492
	speed: 0.0157s/iter; left time: 509.0326s
	iters: 400, epoch: 34 | loss: 0.3659490
	speed: 0.0141s/iter; left time: 455.1869s
Epoch: 34 cost time: 7.5387327671051025
Epoch: 34, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4448 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4090910
	speed: 0.0175s/iter; left time: 560.0947s
	iters: 200, epoch: 35 | loss: 0.4421387
	speed: 0.0143s/iter; left time: 458.0840s
	iters: 300, epoch: 35 | loss: 0.3664152
	speed: 0.0149s/iter; left time: 474.8101s
	iters: 400, epoch: 35 | loss: 0.3585155
	speed: 0.0146s/iter; left time: 463.4465s
Epoch: 35 cost time: 7.4221837520599365
Epoch: 35, Steps: 487 Train Loss: 0.4177 (Forecasting Loss:0.3932 + XiCon Loss:2.4441 x Lambda(0.01)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5079
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.3898724
	speed: 0.0167s/iter; left time: 528.4744s
	iters: 200, epoch: 36 | loss: 0.5055661
	speed: 0.0143s/iter; left time: 450.4185s
	iters: 300, epoch: 36 | loss: 0.3756580
	speed: 0.0138s/iter; left time: 432.7300s
	iters: 400, epoch: 36 | loss: 0.4677856
	speed: 0.0146s/iter; left time: 456.6619s
Epoch: 36 cost time: 7.223491907119751
Epoch: 36, Steps: 487 Train Loss: 0.4172 (Forecasting Loss:0.3928 + XiCon Loss:2.4456 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3924707
	speed: 0.0157s/iter; left time: 486.8838s
	iters: 200, epoch: 37 | loss: 0.4268518
	speed: 0.0139s/iter; left time: 431.3540s
	iters: 300, epoch: 37 | loss: 0.4692422
	speed: 0.0148s/iter; left time: 457.0441s
	iters: 400, epoch: 37 | loss: 0.4129028
	speed: 0.0156s/iter; left time: 481.4049s
Epoch: 37 cost time: 7.341721296310425
Epoch: 37, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3930 + XiCon Loss:2.4431 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3638370
	speed: 0.0165s/iter; left time: 505.1598s
	iters: 200, epoch: 38 | loss: 0.3572200
	speed: 0.0148s/iter; left time: 452.2761s
	iters: 300, epoch: 38 | loss: 0.4407979
	speed: 0.0156s/iter; left time: 473.1578s
	iters: 400, epoch: 38 | loss: 0.4466976
	speed: 0.0139s/iter; left time: 419.5172s
Epoch: 38 cost time: 7.282079696655273
Epoch: 38, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3929 + XiCon Loss:2.4511 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5129395723342896, mae:0.5028845071792603, mape:3.57037615776062, mspe:1174.896240234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2585
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8741651
	speed: 0.0166s/iter; left time: 809.0730s
	iters: 200, epoch: 1 | loss: 0.8401116
	speed: 0.0139s/iter; left time: 673.2849s
	iters: 300, epoch: 1 | loss: 0.7413554
	speed: 0.0141s/iter; left time: 682.9844s
	iters: 400, epoch: 1 | loss: 0.6621601
	speed: 0.0136s/iter; left time: 657.4447s
Epoch: 1 cost time: 7.0784807205200195
Epoch: 1, Steps: 487 Train Loss: 0.7777 (Forecasting Loss:0.7529 + XiCon Loss:2.4877 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005157).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5222169
	speed: 0.0151s/iter; left time: 726.3868s
	iters: 200, epoch: 2 | loss: 0.4344152
	speed: 0.0132s/iter; left time: 631.8994s
	iters: 300, epoch: 2 | loss: 0.5762453
	speed: 0.0134s/iter; left time: 642.3782s
	iters: 400, epoch: 2 | loss: 0.4214232
	speed: 0.0141s/iter; left time: 674.7259s
Epoch: 2 cost time: 6.832731008529663
Epoch: 2, Steps: 487 Train Loss: 0.4610 (Forecasting Loss:0.4361 + XiCon Loss:2.4819 x Lambda(0.01)), Vali MSE Loss: 0.7607 Test MSE Loss: 0.5392
Validation loss decreased (1.005157 --> 0.760660).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4774577
	speed: 0.0152s/iter; left time: 722.8537s
	iters: 200, epoch: 3 | loss: 0.4045754
	speed: 0.0136s/iter; left time: 647.4622s
	iters: 300, epoch: 3 | loss: 0.5044466
	speed: 0.0137s/iter; left time: 647.9913s
	iters: 400, epoch: 3 | loss: 0.3798938
	speed: 0.0135s/iter; left time: 640.2405s
Epoch: 3 cost time: 6.8645339012146
Epoch: 3, Steps: 487 Train Loss: 0.4309 (Forecasting Loss:0.4061 + XiCon Loss:2.4781 x Lambda(0.01)), Vali MSE Loss: 0.7459 Test MSE Loss: 0.5193
Validation loss decreased (0.760660 --> 0.745916).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5095187
	speed: 0.0156s/iter; left time: 734.5398s
	iters: 200, epoch: 4 | loss: 0.4238605
	speed: 0.0133s/iter; left time: 627.9263s
	iters: 300, epoch: 4 | loss: 0.4156868
	speed: 0.0142s/iter; left time: 667.0409s
	iters: 400, epoch: 4 | loss: 0.3158491
	speed: 0.0138s/iter; left time: 648.5364s
Epoch: 4 cost time: 6.900303602218628
Epoch: 4, Steps: 487 Train Loss: 0.4250 (Forecasting Loss:0.4003 + XiCon Loss:2.4718 x Lambda(0.01)), Vali MSE Loss: 0.7463 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3839092
	speed: 0.0164s/iter; left time: 764.5383s
	iters: 200, epoch: 5 | loss: 0.4844799
	speed: 0.0133s/iter; left time: 618.6441s
	iters: 300, epoch: 5 | loss: 0.4052196
	speed: 0.0164s/iter; left time: 760.3505s
	iters: 400, epoch: 5 | loss: 0.4699220
	speed: 0.0156s/iter; left time: 723.4939s
Epoch: 5 cost time: 7.50944972038269
Epoch: 5, Steps: 487 Train Loss: 0.4229 (Forecasting Loss:0.3982 + XiCon Loss:2.4739 x Lambda(0.01)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5126
Validation loss decreased (0.745916 --> 0.739132).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4693368
	speed: 0.0171s/iter; left time: 790.7887s
	iters: 200, epoch: 6 | loss: 0.4456139
	speed: 0.0136s/iter; left time: 624.9343s
	iters: 300, epoch: 6 | loss: 0.5930948
	speed: 0.0141s/iter; left time: 649.2158s
	iters: 400, epoch: 6 | loss: 0.4883824
	speed: 0.0139s/iter; left time: 639.6232s
Epoch: 6 cost time: 7.196203708648682
Epoch: 6, Steps: 487 Train Loss: 0.4217 (Forecasting Loss:0.3969 + XiCon Loss:2.4773 x Lambda(0.01)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5117
Validation loss decreased (0.739132 --> 0.738566).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3505903
	speed: 0.0176s/iter; left time: 802.7853s
	iters: 200, epoch: 7 | loss: 0.3831241
	speed: 0.0136s/iter; left time: 618.7920s
	iters: 300, epoch: 7 | loss: 0.3424731
	speed: 0.0140s/iter; left time: 634.6103s
	iters: 400, epoch: 7 | loss: 0.3752238
	speed: 0.0144s/iter; left time: 653.8948s
Epoch: 7 cost time: 7.195160150527954
Epoch: 7, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3965 + XiCon Loss:2.4718 x Lambda(0.01)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5126
Validation loss decreased (0.738566 --> 0.738328).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3779528
	speed: 0.0159s/iter; left time: 716.6235s
	iters: 200, epoch: 8 | loss: 0.4096937
	speed: 0.0133s/iter; left time: 598.4770s
	iters: 300, epoch: 8 | loss: 0.5705231
	speed: 0.0139s/iter; left time: 626.4531s
	iters: 400, epoch: 8 | loss: 0.4520940
	speed: 0.0150s/iter; left time: 672.1307s
Epoch: 8 cost time: 7.1183247566223145
Epoch: 8, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3961 + XiCon Loss:2.4735 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5118
Validation loss decreased (0.738328 --> 0.737791).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3803712
	speed: 0.0169s/iter; left time: 755.9674s
	iters: 200, epoch: 9 | loss: 0.5081484
	speed: 0.0141s/iter; left time: 627.3029s
	iters: 300, epoch: 9 | loss: 0.4935566
	speed: 0.0143s/iter; left time: 634.5899s
	iters: 400, epoch: 9 | loss: 0.4289545
	speed: 0.0145s/iter; left time: 641.8473s
Epoch: 9 cost time: 7.276100158691406
Epoch: 9, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3960 + XiCon Loss:2.4746 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5119
Validation loss decreased (0.737791 --> 0.737716).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3875025
	speed: 0.0164s/iter; left time: 723.2691s
	iters: 200, epoch: 10 | loss: 0.4839105
	speed: 0.0153s/iter; left time: 675.0798s
	iters: 300, epoch: 10 | loss: 0.4035909
	speed: 0.0146s/iter; left time: 642.9836s
	iters: 400, epoch: 10 | loss: 0.4317114
	speed: 0.0145s/iter; left time: 635.0001s
Epoch: 10 cost time: 7.4151482582092285
Epoch: 10, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4770 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
Validation loss decreased (0.737716 --> 0.737679).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4010566
	speed: 0.0161s/iter; left time: 705.6349s
	iters: 200, epoch: 11 | loss: 0.4299564
	speed: 0.0140s/iter; left time: 608.6981s
	iters: 300, epoch: 11 | loss: 0.3623249
	speed: 0.0149s/iter; left time: 649.4666s
	iters: 400, epoch: 11 | loss: 0.4212307
	speed: 0.0138s/iter; left time: 600.7441s
Epoch: 11 cost time: 7.218276500701904
Epoch: 11, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3958 + XiCon Loss:2.4728 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4621106
	speed: 0.0153s/iter; left time: 661.5311s
	iters: 200, epoch: 12 | loss: 0.2938864
	speed: 0.0142s/iter; left time: 611.2003s
	iters: 300, epoch: 12 | loss: 0.4261825
	speed: 0.0144s/iter; left time: 620.0719s
	iters: 400, epoch: 12 | loss: 0.4584178
	speed: 0.0144s/iter; left time: 617.5123s
Epoch: 12 cost time: 7.117941379547119
Epoch: 12, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4693 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
Validation loss decreased (0.737679 --> 0.737359).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3944537
	speed: 0.0166s/iter; left time: 709.4335s
	iters: 200, epoch: 13 | loss: 0.3446620
	speed: 0.0131s/iter; left time: 556.7519s
	iters: 300, epoch: 13 | loss: 0.4120819
	speed: 0.0136s/iter; left time: 579.8181s
	iters: 400, epoch: 13 | loss: 0.4056197
	speed: 0.0144s/iter; left time: 612.0668s
Epoch: 13 cost time: 7.222588300704956
Epoch: 13, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4762 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3757710
	speed: 0.0161s/iter; left time: 678.4459s
	iters: 200, epoch: 14 | loss: 0.3675208
	speed: 0.0144s/iter; left time: 607.6343s
	iters: 300, epoch: 14 | loss: 0.4039192
	speed: 0.0148s/iter; left time: 621.1689s
	iters: 400, epoch: 14 | loss: 0.3878877
	speed: 0.0146s/iter; left time: 614.2265s
Epoch: 14 cost time: 7.343979835510254
Epoch: 14, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3956 + XiCon Loss:2.4760 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4165371
	speed: 0.0166s/iter; left time: 693.2375s
	iters: 200, epoch: 15 | loss: 0.4004024
	speed: 0.0132s/iter; left time: 548.9669s
	iters: 300, epoch: 15 | loss: 0.4188527
	speed: 0.0148s/iter; left time: 614.6121s
	iters: 400, epoch: 15 | loss: 0.4650148
	speed: 0.0151s/iter; left time: 627.2364s
Epoch: 15 cost time: 7.288832426071167
Epoch: 15, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3959 + XiCon Loss:2.4775 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4470219
	speed: 0.0177s/iter; left time: 731.9760s
	iters: 200, epoch: 16 | loss: 0.3911371
	speed: 0.0140s/iter; left time: 577.4315s
	iters: 300, epoch: 16 | loss: 0.4885990
	speed: 0.0140s/iter; left time: 576.6104s
	iters: 400, epoch: 16 | loss: 0.4281289
	speed: 0.0143s/iter; left time: 587.8998s
Epoch: 16 cost time: 7.3575944900512695
Epoch: 16, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3960 + XiCon Loss:2.4714 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3350466
	speed: 0.0170s/iter; left time: 694.1387s
	iters: 200, epoch: 17 | loss: 0.4030071
	speed: 0.0138s/iter; left time: 560.3316s
	iters: 300, epoch: 17 | loss: 0.3687201
	speed: 0.0142s/iter; left time: 577.1354s
	iters: 400, epoch: 17 | loss: 0.3422466
	speed: 0.0141s/iter; left time: 569.1980s
Epoch: 17 cost time: 7.20467734336853
Epoch: 17, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3958 + XiCon Loss:2.4721 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4294553
	speed: 0.0171s/iter; left time: 691.0846s
	iters: 200, epoch: 18 | loss: 0.4139111
	speed: 0.0147s/iter; left time: 592.2054s
	iters: 300, epoch: 18 | loss: 0.4334314
	speed: 0.0145s/iter; left time: 582.8285s
	iters: 400, epoch: 18 | loss: 0.3442535
	speed: 0.0152s/iter; left time: 606.7598s
Epoch: 18 cost time: 7.48117208480835
Epoch: 18, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4737 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4446270
	speed: 0.0158s/iter; left time: 628.8959s
	iters: 200, epoch: 19 | loss: 0.4673949
	speed: 0.0131s/iter; left time: 522.1372s
	iters: 300, epoch: 19 | loss: 0.3541471
	speed: 0.0144s/iter; left time: 570.7327s
	iters: 400, epoch: 19 | loss: 0.4966547
	speed: 0.0142s/iter; left time: 561.8802s
Epoch: 19 cost time: 7.097171068191528
Epoch: 19, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3957 + XiCon Loss:2.4724 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4141063
	speed: 0.0164s/iter; left time: 647.1897s
	iters: 200, epoch: 20 | loss: 0.3567608
	speed: 0.0134s/iter; left time: 524.6227s
	iters: 300, epoch: 20 | loss: 0.5549120
	speed: 0.0146s/iter; left time: 569.9604s
	iters: 400, epoch: 20 | loss: 0.4384995
	speed: 0.0144s/iter; left time: 562.8274s
Epoch: 20 cost time: 7.229630470275879
Epoch: 20, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3957 + XiCon Loss:2.4747 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
Validation loss decreased (0.737359 --> 0.737054).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4413488
	speed: 0.0160s/iter; left time: 623.3911s
	iters: 200, epoch: 21 | loss: 0.3650435
	speed: 0.0137s/iter; left time: 529.5504s
	iters: 300, epoch: 21 | loss: 0.3631853
	speed: 0.0142s/iter; left time: 547.1919s
	iters: 400, epoch: 21 | loss: 0.4140962
	speed: 0.0160s/iter; left time: 616.9066s
Epoch: 21 cost time: 7.366312026977539
Epoch: 21, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3957 + XiCon Loss:2.4731 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4242336
	speed: 0.0159s/iter; left time: 610.1627s
	iters: 200, epoch: 22 | loss: 0.3980637
	speed: 0.0133s/iter; left time: 508.6809s
	iters: 300, epoch: 22 | loss: 0.4043001
	speed: 0.0138s/iter; left time: 525.3620s
	iters: 400, epoch: 22 | loss: 0.4202255
	speed: 0.0146s/iter; left time: 554.6098s
Epoch: 22 cost time: 7.055751085281372
Epoch: 22, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4714 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4284552
	speed: 0.0156s/iter; left time: 591.2018s
	iters: 200, epoch: 23 | loss: 0.4779028
	speed: 0.0140s/iter; left time: 528.2633s
	iters: 300, epoch: 23 | loss: 0.4479230
	speed: 0.0145s/iter; left time: 547.1257s
	iters: 400, epoch: 23 | loss: 0.4491576
	speed: 0.0157s/iter; left time: 590.5983s
Epoch: 23 cost time: 7.308744192123413
Epoch: 23, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4720 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4622568
	speed: 0.0167s/iter; left time: 623.9204s
	iters: 200, epoch: 24 | loss: 0.4475904
	speed: 0.0144s/iter; left time: 537.6713s
	iters: 300, epoch: 24 | loss: 0.4267673
	speed: 0.0141s/iter; left time: 523.6488s
	iters: 400, epoch: 24 | loss: 0.3832668
	speed: 0.0160s/iter; left time: 595.3665s
Epoch: 24 cost time: 7.476303339004517
Epoch: 24, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3960 + XiCon Loss:2.4706 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5117
Validation loss decreased (0.737054 --> 0.736937).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4521872
	speed: 0.0166s/iter; left time: 612.9072s
	iters: 200, epoch: 25 | loss: 0.4462147
	speed: 0.0138s/iter; left time: 508.3028s
	iters: 300, epoch: 25 | loss: 0.4250116
	speed: 0.0126s/iter; left time: 464.4012s
	iters: 400, epoch: 25 | loss: 0.4784779
	speed: 0.0124s/iter; left time: 455.4812s
Epoch: 25 cost time: 6.718140363693237
Epoch: 25, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3960 + XiCon Loss:2.4762 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4970768
	speed: 0.0156s/iter; left time: 568.8458s
	iters: 200, epoch: 26 | loss: 0.4404122
	speed: 0.0141s/iter; left time: 512.9545s
	iters: 300, epoch: 26 | loss: 0.3660003
	speed: 0.0142s/iter; left time: 512.9469s
	iters: 400, epoch: 26 | loss: 0.3988473
	speed: 0.0152s/iter; left time: 550.0770s
Epoch: 26 cost time: 7.222113132476807
Epoch: 26, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3957 + XiCon Loss:2.4729 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4531252
	speed: 0.0172s/iter; left time: 617.9309s
	iters: 200, epoch: 27 | loss: 0.5634339
	speed: 0.0136s/iter; left time: 488.0967s
	iters: 300, epoch: 27 | loss: 0.4015593
	speed: 0.0137s/iter; left time: 490.4968s
	iters: 400, epoch: 27 | loss: 0.3611188
	speed: 0.0157s/iter; left time: 559.2766s
Epoch: 27 cost time: 7.355272054672241
Epoch: 27, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4730 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3573613
	speed: 0.0171s/iter; left time: 605.9378s
	iters: 200, epoch: 28 | loss: 0.3689910
	speed: 0.0150s/iter; left time: 531.5405s
	iters: 300, epoch: 28 | loss: 0.4449822
	speed: 0.0145s/iter; left time: 510.8730s
	iters: 400, epoch: 28 | loss: 0.4379988
	speed: 0.0143s/iter; left time: 503.4111s
Epoch: 28 cost time: 7.452320098876953
Epoch: 28, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3958 + XiCon Loss:2.4719 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3786240
	speed: 0.0162s/iter; left time: 566.7497s
	iters: 200, epoch: 29 | loss: 0.3997688
	speed: 0.0137s/iter; left time: 477.2294s
	iters: 300, epoch: 29 | loss: 0.4499491
	speed: 0.0140s/iter; left time: 485.0261s
	iters: 400, epoch: 29 | loss: 0.3871140
	speed: 0.0144s/iter; left time: 500.2204s
Epoch: 29 cost time: 7.216843366622925
Epoch: 29, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3958 + XiCon Loss:2.4743 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3868829
	speed: 0.0166s/iter; left time: 574.0432s
	iters: 200, epoch: 30 | loss: 0.3965679
	speed: 0.0152s/iter; left time: 522.8198s
	iters: 300, epoch: 30 | loss: 0.3403316
	speed: 0.0140s/iter; left time: 478.8968s
	iters: 400, epoch: 30 | loss: 0.3750252
	speed: 0.0140s/iter; left time: 478.6865s
Epoch: 30 cost time: 7.26287317276001
Epoch: 30, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3956 + XiCon Loss:2.4773 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4015469
	speed: 0.0165s/iter; left time: 562.2689s
	iters: 200, epoch: 31 | loss: 0.4197857
	speed: 0.0138s/iter; left time: 467.7093s
	iters: 300, epoch: 31 | loss: 0.3213839
	speed: 0.0148s/iter; left time: 501.4271s
	iters: 400, epoch: 31 | loss: 0.3743417
	speed: 0.0152s/iter; left time: 510.6623s
Epoch: 31 cost time: 7.438880681991577
Epoch: 31, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4768 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4318740
	speed: 0.0174s/iter; left time: 583.3970s
	iters: 200, epoch: 32 | loss: 0.4487227
	speed: 0.0138s/iter; left time: 460.4741s
	iters: 300, epoch: 32 | loss: 0.3658208
	speed: 0.0140s/iter; left time: 466.7751s
	iters: 400, epoch: 32 | loss: 0.4470429
	speed: 0.0145s/iter; left time: 482.4627s
Epoch: 32 cost time: 7.299768686294556
Epoch: 32, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4785 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4078676
	speed: 0.0164s/iter; left time: 540.4176s
	iters: 200, epoch: 33 | loss: 0.4806620
	speed: 0.0138s/iter; left time: 455.0642s
	iters: 300, epoch: 33 | loss: 0.3740389
	speed: 0.0143s/iter; left time: 468.5748s
	iters: 400, epoch: 33 | loss: 0.4751747
	speed: 0.0142s/iter; left time: 463.0223s
Epoch: 33 cost time: 7.191245079040527
Epoch: 33, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3959 + XiCon Loss:2.4726 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4130921
	speed: 0.0161s/iter; left time: 524.5680s
	iters: 200, epoch: 34 | loss: 0.4754280
	speed: 0.0140s/iter; left time: 453.5779s
	iters: 300, epoch: 34 | loss: 0.4349990
	speed: 0.0146s/iter; left time: 471.6963s
	iters: 400, epoch: 34 | loss: 0.4163806
	speed: 0.0141s/iter; left time: 455.3190s
Epoch: 34 cost time: 7.212738513946533
Epoch: 34, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3956 + XiCon Loss:2.4742 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5117
Validation loss decreased (0.736937 --> 0.736620).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3968076
	speed: 0.0153s/iter; left time: 488.9151s
	iters: 200, epoch: 35 | loss: 0.3943718
	speed: 0.0139s/iter; left time: 442.6008s
	iters: 300, epoch: 35 | loss: 0.4531382
	speed: 0.0135s/iter; left time: 430.7403s
	iters: 400, epoch: 35 | loss: 0.3694701
	speed: 0.0145s/iter; left time: 459.0660s
Epoch: 35 cost time: 7.022662162780762
Epoch: 35, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4791 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4919684
	speed: 0.0156s/iter; left time: 492.9264s
	iters: 200, epoch: 36 | loss: 0.3435535
	speed: 0.0136s/iter; left time: 428.5337s
	iters: 300, epoch: 36 | loss: 0.3656256
	speed: 0.0134s/iter; left time: 420.9759s
	iters: 400, epoch: 36 | loss: 0.4212609
	speed: 0.0145s/iter; left time: 452.5095s
Epoch: 36 cost time: 7.025885105133057
Epoch: 36, Steps: 487 Train Loss: 0.4203 (Forecasting Loss:0.3956 + XiCon Loss:2.4738 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4640808
	speed: 0.0163s/iter; left time: 506.2790s
	iters: 200, epoch: 37 | loss: 0.3943880
	speed: 0.0137s/iter; left time: 425.2929s
	iters: 300, epoch: 37 | loss: 0.3976106
	speed: 0.0140s/iter; left time: 433.0494s
	iters: 400, epoch: 37 | loss: 0.5115466
	speed: 0.0152s/iter; left time: 467.9300s
Epoch: 37 cost time: 7.264557123184204
Epoch: 37, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4750 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3920092
	speed: 0.0157s/iter; left time: 480.5699s
	iters: 200, epoch: 38 | loss: 0.4298360
	speed: 0.0130s/iter; left time: 397.4181s
	iters: 300, epoch: 38 | loss: 0.4061759
	speed: 0.0127s/iter; left time: 384.6894s
	iters: 400, epoch: 38 | loss: 0.4539048
	speed: 0.0135s/iter; left time: 408.6418s
Epoch: 38 cost time: 6.699666261672974
Epoch: 38, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4786 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.4926736
	speed: 0.0157s/iter; left time: 471.9676s
	iters: 200, epoch: 39 | loss: 0.3671795
	speed: 0.0126s/iter; left time: 378.9144s
	iters: 300, epoch: 39 | loss: 0.4711255
	speed: 0.0134s/iter; left time: 400.1690s
	iters: 400, epoch: 39 | loss: 0.4224207
	speed: 0.0140s/iter; left time: 417.1888s
Epoch: 39 cost time: 6.822252988815308
Epoch: 39, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4756 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4894144
	speed: 0.0154s/iter; left time: 455.3235s
	iters: 200, epoch: 40 | loss: 0.4382611
	speed: 0.0130s/iter; left time: 384.8356s
	iters: 300, epoch: 40 | loss: 0.4049038
	speed: 0.0128s/iter; left time: 376.6526s
	iters: 400, epoch: 40 | loss: 0.4688374
	speed: 0.0144s/iter; left time: 421.2497s
Epoch: 40 cost time: 6.846071004867554
Epoch: 40, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3960 + XiCon Loss:2.4719 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4004903
	speed: 0.0157s/iter; left time: 456.0605s
	iters: 200, epoch: 41 | loss: 0.3998006
	speed: 0.0138s/iter; left time: 399.2010s
	iters: 300, epoch: 41 | loss: 0.4495015
	speed: 0.0144s/iter; left time: 415.7846s
	iters: 400, epoch: 41 | loss: 0.4232295
	speed: 0.0135s/iter; left time: 387.7822s
Epoch: 41 cost time: 6.9770872592926025
Epoch: 41, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3958 + XiCon Loss:2.4721 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.3608496
	speed: 0.0148s/iter; left time: 422.8811s
	iters: 200, epoch: 42 | loss: 0.3922253
	speed: 0.0124s/iter; left time: 354.3293s
	iters: 300, epoch: 42 | loss: 0.4543075
	speed: 0.0131s/iter; left time: 372.8983s
	iters: 400, epoch: 42 | loss: 0.4916659
	speed: 0.0136s/iter; left time: 385.6662s
Epoch: 42 cost time: 6.548837661743164
Epoch: 42, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3958 + XiCon Loss:2.4751 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.3792045
	speed: 0.0149s/iter; left time: 419.4439s
	iters: 200, epoch: 43 | loss: 0.4813115
	speed: 0.0134s/iter; left time: 374.5452s
	iters: 300, epoch: 43 | loss: 0.4211085
	speed: 0.0136s/iter; left time: 380.1990s
	iters: 400, epoch: 43 | loss: 0.4323876
	speed: 0.0134s/iter; left time: 372.1578s
Epoch: 43 cost time: 6.790371894836426
Epoch: 43, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3959 + XiCon Loss:2.4803 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.4209839
	speed: 0.0143s/iter; left time: 396.2448s
	iters: 200, epoch: 44 | loss: 0.4673173
	speed: 0.0132s/iter; left time: 365.0778s
	iters: 300, epoch: 44 | loss: 0.5305054
	speed: 0.0132s/iter; left time: 362.9646s
	iters: 400, epoch: 44 | loss: 0.4733704
	speed: 0.0134s/iter; left time: 367.7909s
Epoch: 44 cost time: 6.676117658615112
Epoch: 44, Steps: 487 Train Loss: 0.4204 (Forecasting Loss:0.3957 + XiCon Loss:2.4744 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182396173477173, mae:0.5052428245544434, mape:3.4785523414611816, mspe:1099.116455078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5200+-0.00810, MAE:0.5063+-0.00426, MAPE:3.5264+-0.08090, MSPE:1145.9338+-66.07635, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8203
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9562331
	speed: 0.0316s/iter; left time: 748.8384s
	iters: 200, epoch: 1 | loss: 0.9790311
	speed: 0.0259s/iter; left time: 610.1416s
Epoch: 1 cost time: 6.777501344680786
Epoch: 1, Steps: 238 Train Loss: 1.0062 (Forecasting Loss:0.9803 + XiCon Loss:2.5862 x Lambda(0.01)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755403).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6335347
	speed: 0.0288s/iter; left time: 675.6565s
	iters: 200, epoch: 2 | loss: 0.6098732
	speed: 0.0246s/iter; left time: 575.7876s
Epoch: 2 cost time: 6.29588508605957
Epoch: 2, Steps: 238 Train Loss: 0.6428 (Forecasting Loss:0.6169 + XiCon Loss:2.5834 x Lambda(0.01)), Vali MSE Loss: 1.0368 Test MSE Loss: 0.8580
Validation loss decreased (1.755403 --> 1.036811).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5841401
	speed: 0.0277s/iter; left time: 644.2480s
	iters: 200, epoch: 3 | loss: 0.5909018
	speed: 0.0263s/iter; left time: 608.9998s
Epoch: 3 cost time: 6.369454622268677
Epoch: 3, Steps: 238 Train Loss: 0.5786 (Forecasting Loss:0.5527 + XiCon Loss:2.5843 x Lambda(0.01)), Vali MSE Loss: 1.0179 Test MSE Loss: 0.8515
Validation loss decreased (1.036811 --> 1.017889).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5640026
	speed: 0.0278s/iter; left time: 639.2797s
	iters: 200, epoch: 4 | loss: 0.5304917
	speed: 0.0258s/iter; left time: 590.4341s
Epoch: 4 cost time: 6.346591472625732
Epoch: 4, Steps: 238 Train Loss: 0.5704 (Forecasting Loss:0.5446 + XiCon Loss:2.5801 x Lambda(0.01)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8494
Validation loss decreased (1.017889 --> 1.010513).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5474986
	speed: 0.0270s/iter; left time: 615.2381s
	iters: 200, epoch: 5 | loss: 0.5936734
	speed: 0.0252s/iter; left time: 571.7197s
Epoch: 5 cost time: 6.268630504608154
Epoch: 5, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5414 + XiCon Loss:2.5817 x Lambda(0.01)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8491
Validation loss decreased (1.010513 --> 1.007478).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5549526
	speed: 0.0287s/iter; left time: 646.5842s
	iters: 200, epoch: 6 | loss: 0.5677171
	speed: 0.0259s/iter; left time: 580.5037s
Epoch: 6 cost time: 6.4033448696136475
Epoch: 6, Steps: 238 Train Loss: 0.5657 (Forecasting Loss:0.5399 + XiCon Loss:2.5779 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8487
Validation loss decreased (1.007478 --> 1.006162).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5562903
	speed: 0.0273s/iter; left time: 608.2721s
	iters: 200, epoch: 7 | loss: 0.5674569
	speed: 0.0249s/iter; left time: 551.7238s
Epoch: 7 cost time: 6.178657531738281
Epoch: 7, Steps: 238 Train Loss: 0.5650 (Forecasting Loss:0.5391 + XiCon Loss:2.5826 x Lambda(0.01)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8487
Validation loss decreased (1.006162 --> 1.004477).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5189847
	speed: 0.0273s/iter; left time: 600.6617s
	iters: 200, epoch: 8 | loss: 0.5914539
	speed: 0.0264s/iter; left time: 578.0048s
Epoch: 8 cost time: 6.4534149169921875
Epoch: 8, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5387 + XiCon Loss:2.5773 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8486
Validation loss decreased (1.004477 --> 1.004409).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5953403
	speed: 0.0277s/iter; left time: 603.5401s
	iters: 200, epoch: 9 | loss: 0.6136765
	speed: 0.0251s/iter; left time: 545.4170s
Epoch: 9 cost time: 6.300139665603638
Epoch: 9, Steps: 238 Train Loss: 0.5645 (Forecasting Loss:0.5386 + XiCon Loss:2.5821 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8486
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5536588
	speed: 0.0285s/iter; left time: 615.4652s
	iters: 200, epoch: 10 | loss: 0.5836116
	speed: 0.0251s/iter; left time: 537.6464s
Epoch: 10 cost time: 6.390408754348755
Epoch: 10, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5385 + XiCon Loss:2.5844 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8486
Validation loss decreased (1.004409 --> 1.004348).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5227122
	speed: 0.0290s/iter; left time: 619.3140s
	iters: 200, epoch: 11 | loss: 0.5836641
	speed: 0.0262s/iter; left time: 555.8976s
Epoch: 11 cost time: 6.53558874130249
Epoch: 11, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5382 + XiCon Loss:2.5792 x Lambda(0.01)), Vali MSE Loss: 1.0036 Test MSE Loss: 0.8486
Validation loss decreased (1.004348 --> 1.003572).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5834599
	speed: 0.0273s/iter; left time: 575.3525s
	iters: 200, epoch: 12 | loss: 0.5340019
	speed: 0.0259s/iter; left time: 543.5338s
Epoch: 12 cost time: 6.33957314491272
Epoch: 12, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5382 + XiCon Loss:2.5810 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5669551
	speed: 0.0273s/iter; left time: 569.1020s
	iters: 200, epoch: 13 | loss: 0.5568591
	speed: 0.0249s/iter; left time: 516.9447s
Epoch: 13 cost time: 6.232342481613159
Epoch: 13, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5383 + XiCon Loss:2.5806 x Lambda(0.01)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8485
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4773172
	speed: 0.0284s/iter; left time: 585.1046s
	iters: 200, epoch: 14 | loss: 0.5601976
	speed: 0.0258s/iter; left time: 529.6158s
Epoch: 14 cost time: 6.49882960319519
Epoch: 14, Steps: 238 Train Loss: 0.5639 (Forecasting Loss:0.5381 + XiCon Loss:2.5774 x Lambda(0.01)), Vali MSE Loss: 1.0042 Test MSE Loss: 0.8485
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5659332
	speed: 0.0293s/iter; left time: 596.5670s
	iters: 200, epoch: 15 | loss: 0.5659003
	speed: 0.0253s/iter; left time: 512.7105s
Epoch: 15 cost time: 6.429820537567139
Epoch: 15, Steps: 238 Train Loss: 0.5639 (Forecasting Loss:0.5382 + XiCon Loss:2.5742 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5269955
	speed: 0.0277s/iter; left time: 556.8838s
	iters: 200, epoch: 16 | loss: 0.5571213
	speed: 0.0265s/iter; left time: 530.2497s
Epoch: 16 cost time: 6.442535400390625
Epoch: 16, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5385 + XiCon Loss:2.5765 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8485
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5564423
	speed: 0.0275s/iter; left time: 546.9695s
	iters: 200, epoch: 17 | loss: 0.5635075
	speed: 0.0263s/iter; left time: 520.6196s
Epoch: 17 cost time: 6.38250994682312
Epoch: 17, Steps: 238 Train Loss: 0.5638 (Forecasting Loss:0.5380 + XiCon Loss:2.5847 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8485
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5289310
	speed: 0.0292s/iter; left time: 574.8969s
	iters: 200, epoch: 18 | loss: 0.4989594
	speed: 0.0257s/iter; left time: 501.6150s
Epoch: 18 cost time: 6.470003604888916
Epoch: 18, Steps: 238 Train Loss: 0.5640 (Forecasting Loss:0.5382 + XiCon Loss:2.5787 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5669420
	speed: 0.0278s/iter; left time: 540.3475s
	iters: 200, epoch: 19 | loss: 0.5590940
	speed: 0.0260s/iter; left time: 503.0564s
Epoch: 19 cost time: 6.433903217315674
Epoch: 19, Steps: 238 Train Loss: 0.5641 (Forecasting Loss:0.5384 + XiCon Loss:2.5786 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5422893
	speed: 0.0276s/iter; left time: 529.3402s
	iters: 200, epoch: 20 | loss: 0.5742236
	speed: 0.0259s/iter; left time: 494.9236s
Epoch: 20 cost time: 6.384037733078003
Epoch: 20, Steps: 238 Train Loss: 0.5639 (Forecasting Loss:0.5381 + XiCon Loss:2.5836 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5190305
	speed: 0.0282s/iter; left time: 533.6077s
	iters: 200, epoch: 21 | loss: 0.5754074
	speed: 0.0250s/iter; left time: 471.3708s
Epoch: 21 cost time: 6.372662305831909
Epoch: 21, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5384 + XiCon Loss:2.5806 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9777290225028992, mae:0.7193759083747864, mape:4.778804302215576, mspe:2691.446533203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.3566
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1105217
	speed: 0.0278s/iter; left time: 658.5388s
	iters: 200, epoch: 1 | loss: 1.1843697
	speed: 0.0230s/iter; left time: 541.7911s
Epoch: 1 cost time: 5.951528310775757
Epoch: 1, Steps: 238 Train Loss: 1.1250 (Forecasting Loss:1.0993 + XiCon Loss:2.5769 x Lambda(0.01)), Vali MSE Loss: 1.9677 Test MSE Loss: 1.0361
Validation loss decreased (inf --> 1.967725).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6513908
	speed: 0.0255s/iter; left time: 598.0604s
	iters: 200, epoch: 2 | loss: 0.5671437
	speed: 0.0232s/iter; left time: 543.1153s
Epoch: 2 cost time: 5.661405086517334
Epoch: 2, Steps: 238 Train Loss: 0.6570 (Forecasting Loss:0.6313 + XiCon Loss:2.5710 x Lambda(0.01)), Vali MSE Loss: 1.0219 Test MSE Loss: 0.8588
Validation loss decreased (1.967725 --> 1.021883).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5673181
	speed: 0.0261s/iter; left time: 605.7861s
	iters: 200, epoch: 3 | loss: 0.5502123
	speed: 0.0216s/iter; left time: 500.2727s
Epoch: 3 cost time: 5.674764394760132
Epoch: 3, Steps: 238 Train Loss: 0.5773 (Forecasting Loss:0.5516 + XiCon Loss:2.5667 x Lambda(0.01)), Vali MSE Loss: 1.0006 Test MSE Loss: 0.8528
Validation loss decreased (1.021883 --> 1.000557).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5024807
	speed: 0.0266s/iter; left time: 611.1402s
	iters: 200, epoch: 4 | loss: 0.5867983
	speed: 0.0235s/iter; left time: 538.3507s
Epoch: 4 cost time: 5.93074369430542
Epoch: 4, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5432 + XiCon Loss:2.5672 x Lambda(0.01)), Vali MSE Loss: 0.9941 Test MSE Loss: 0.8515
Validation loss decreased (1.000557 --> 0.994079).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5926060
	speed: 0.0259s/iter; left time: 589.5666s
	iters: 200, epoch: 5 | loss: 0.5500944
	speed: 0.0227s/iter; left time: 514.8894s
Epoch: 5 cost time: 5.659189462661743
Epoch: 5, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5399 + XiCon Loss:2.5623 x Lambda(0.01)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8508
Validation loss decreased (0.994079 --> 0.989113).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5416717
	speed: 0.0265s/iter; left time: 595.8462s
	iters: 200, epoch: 6 | loss: 0.5746343
	speed: 0.0215s/iter; left time: 482.2341s
Epoch: 6 cost time: 5.734360933303833
Epoch: 6, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5387 + XiCon Loss:2.5651 x Lambda(0.01)), Vali MSE Loss: 0.9880 Test MSE Loss: 0.8507
Validation loss decreased (0.989113 --> 0.988034).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5653887
	speed: 0.0254s/iter; left time: 566.7575s
	iters: 200, epoch: 7 | loss: 0.5353087
	speed: 0.0233s/iter; left time: 517.4900s
Epoch: 7 cost time: 5.778823137283325
Epoch: 7, Steps: 238 Train Loss: 0.5633 (Forecasting Loss:0.5377 + XiCon Loss:2.5617 x Lambda(0.01)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8505
Validation loss decreased (0.988034 --> 0.987057).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5702989
	speed: 0.0260s/iter; left time: 572.8416s
	iters: 200, epoch: 8 | loss: 0.5305883
	speed: 0.0223s/iter; left time: 488.2664s
Epoch: 8 cost time: 5.6556384563446045
Epoch: 8, Steps: 238 Train Loss: 0.5632 (Forecasting Loss:0.5376 + XiCon Loss:2.5619 x Lambda(0.01)), Vali MSE Loss: 0.9870 Test MSE Loss: 0.8505
Validation loss decreased (0.987057 --> 0.986960).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5490594
	speed: 0.0253s/iter; left time: 550.4743s
	iters: 200, epoch: 9 | loss: 0.6007475
	speed: 0.0215s/iter; left time: 466.7341s
Epoch: 9 cost time: 5.618192195892334
Epoch: 9, Steps: 238 Train Loss: 0.5628 (Forecasting Loss:0.5372 + XiCon Loss:2.5636 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
Validation loss decreased (0.986960 --> 0.985942).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5593864
	speed: 0.0259s/iter; left time: 559.1134s
	iters: 200, epoch: 10 | loss: 0.6279649
	speed: 0.0228s/iter; left time: 488.5447s
Epoch: 10 cost time: 5.773592233657837
Epoch: 10, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5614 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985942 --> 0.985582).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5667519
	speed: 0.0252s/iter; left time: 536.9196s
	iters: 200, epoch: 11 | loss: 0.5981706
	speed: 0.0230s/iter; left time: 487.9720s
Epoch: 11 cost time: 5.589655637741089
Epoch: 11, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5609 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5710727
	speed: 0.0271s/iter; left time: 571.4419s
	iters: 200, epoch: 12 | loss: 0.5232850
	speed: 0.0226s/iter; left time: 473.6752s
Epoch: 12 cost time: 5.786736249923706
Epoch: 12, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5600 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5376905
	speed: 0.0245s/iter; left time: 510.9004s
	iters: 200, epoch: 13 | loss: 0.5587844
	speed: 0.0204s/iter; left time: 423.1780s
Epoch: 13 cost time: 5.304894924163818
Epoch: 13, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5367 + XiCon Loss:2.5644 x Lambda(0.01)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5098813
	speed: 0.0250s/iter; left time: 516.1266s
	iters: 200, epoch: 14 | loss: 0.5494942
	speed: 0.0212s/iter; left time: 433.7587s
Epoch: 14 cost time: 5.445352554321289
Epoch: 14, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5666 x Lambda(0.01)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5544609
	speed: 0.0244s/iter; left time: 497.3435s
	iters: 200, epoch: 15 | loss: 0.4889508
	speed: 0.0207s/iter; left time: 419.0877s
Epoch: 15 cost time: 5.290109395980835
Epoch: 15, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5646 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5903203
	speed: 0.0240s/iter; left time: 482.6099s
	iters: 200, epoch: 16 | loss: 0.5846868
	speed: 0.0210s/iter; left time: 419.7105s
Epoch: 16 cost time: 5.336739540100098
Epoch: 16, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5645 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5433783
	speed: 0.0246s/iter; left time: 488.5688s
	iters: 200, epoch: 17 | loss: 0.5935317
	speed: 0.0206s/iter; left time: 408.1155s
Epoch: 17 cost time: 5.336609601974487
Epoch: 17, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5371 + XiCon Loss:2.5582 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5824797
	speed: 0.0245s/iter; left time: 481.1790s
	iters: 200, epoch: 18 | loss: 0.6587836
	speed: 0.0205s/iter; left time: 400.4033s
Epoch: 18 cost time: 5.302380084991455
Epoch: 18, Steps: 238 Train Loss: 0.5628 (Forecasting Loss:0.5372 + XiCon Loss:2.5603 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5576951
	speed: 0.0245s/iter; left time: 476.2757s
	iters: 200, epoch: 19 | loss: 0.5603286
	speed: 0.0207s/iter; left time: 400.1807s
Epoch: 19 cost time: 5.360522985458374
Epoch: 19, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5666 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5712727
	speed: 0.0244s/iter; left time: 468.5190s
	iters: 200, epoch: 20 | loss: 0.5795007
	speed: 0.0206s/iter; left time: 392.4460s
Epoch: 20 cost time: 5.325128793716431
Epoch: 20, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5629 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985582 --> 0.985551).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5191300
	speed: 0.0253s/iter; left time: 478.4059s
	iters: 200, epoch: 21 | loss: 0.5341099
	speed: 0.0243s/iter; left time: 457.9304s
Epoch: 21 cost time: 5.760479211807251
Epoch: 21, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5367 + XiCon Loss:2.5632 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5352976
	speed: 0.0266s/iter; left time: 497.1158s
	iters: 200, epoch: 22 | loss: 0.5588949
	speed: 0.0220s/iter; left time: 409.7290s
Epoch: 22 cost time: 5.842473268508911
Epoch: 22, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5369 + XiCon Loss:2.5650 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5524967
	speed: 0.0257s/iter; left time: 474.1592s
	iters: 200, epoch: 23 | loss: 0.5370921
	speed: 0.0228s/iter; left time: 418.4702s
Epoch: 23 cost time: 5.738186597824097
Epoch: 23, Steps: 238 Train Loss: 0.5627 (Forecasting Loss:0.5371 + XiCon Loss:2.5607 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5761769
	speed: 0.0262s/iter; left time: 476.6508s
	iters: 200, epoch: 24 | loss: 0.5536035
	speed: 0.0217s/iter; left time: 393.7237s
Epoch: 24 cost time: 5.705364465713501
Epoch: 24, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5599 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5594683
	speed: 0.0265s/iter; left time: 476.3041s
	iters: 200, epoch: 25 | loss: 0.5700329
	speed: 0.0230s/iter; left time: 411.5161s
Epoch: 25 cost time: 5.847252130508423
Epoch: 25, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5655 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5821705
	speed: 0.0264s/iter; left time: 468.1986s
	iters: 200, epoch: 26 | loss: 0.5404658
	speed: 0.0232s/iter; left time: 409.5837s
Epoch: 26 cost time: 5.827385663986206
Epoch: 26, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5620 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6060210
	speed: 0.0262s/iter; left time: 458.1110s
	iters: 200, epoch: 27 | loss: 0.6016107
	speed: 0.0235s/iter; left time: 408.4381s
Epoch: 27 cost time: 5.758559942245483
Epoch: 27, Steps: 238 Train Loss: 0.5628 (Forecasting Loss:0.5371 + XiCon Loss:2.5626 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5380290
	speed: 0.0270s/iter; left time: 466.2773s
	iters: 200, epoch: 28 | loss: 0.5355277
	speed: 0.0216s/iter; left time: 371.5230s
Epoch: 28 cost time: 5.81153416633606
Epoch: 28, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5619 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4907583
	speed: 0.0259s/iter; left time: 441.5598s
	iters: 200, epoch: 29 | loss: 0.5549030
	speed: 0.0230s/iter; left time: 389.0250s
Epoch: 29 cost time: 5.7870728969573975
Epoch: 29, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5606 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5054105
	speed: 0.0260s/iter; left time: 437.4514s
	iters: 200, epoch: 30 | loss: 0.5735980
	speed: 0.0227s/iter; left time: 379.2627s
Epoch: 30 cost time: 5.678640842437744
Epoch: 30, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5612 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985551 --> 0.985466).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5613523
	speed: 0.0254s/iter; left time: 419.9193s
	iters: 200, epoch: 31 | loss: 0.5194971
	speed: 0.0215s/iter; left time: 353.2912s
Epoch: 31 cost time: 5.614200115203857
Epoch: 31, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5627 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5812057
	speed: 0.0268s/iter; left time: 436.6969s
	iters: 200, epoch: 32 | loss: 0.6064416
	speed: 0.0234s/iter; left time: 379.4376s
Epoch: 32 cost time: 5.919350862503052
Epoch: 32, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5613 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5497106
	speed: 0.0273s/iter; left time: 439.1490s
	iters: 200, epoch: 33 | loss: 0.5422037
	speed: 0.0241s/iter; left time: 384.9701s
Epoch: 33 cost time: 6.03264856338501
Epoch: 33, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5566 x Lambda(0.01)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8504
Validation loss decreased (0.985466 --> 0.985428).  Saving model ...
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5398173
	speed: 0.0262s/iter; left time: 414.5617s
	iters: 200, epoch: 34 | loss: 0.5414459
	speed: 0.0230s/iter; left time: 361.8152s
Epoch: 34 cost time: 5.8280415534973145
Epoch: 34, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5590 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5477632
	speed: 0.0261s/iter; left time: 407.1635s
	iters: 200, epoch: 35 | loss: 0.5997435
	speed: 0.0227s/iter; left time: 351.4971s
Epoch: 35 cost time: 5.663508892059326
Epoch: 35, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5633 x Lambda(0.01)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5353144
	speed: 0.0252s/iter; left time: 386.6523s
	iters: 200, epoch: 36 | loss: 0.5479623
	speed: 0.0215s/iter; left time: 328.2049s
Epoch: 36 cost time: 5.552730083465576
Epoch: 36, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5368 + XiCon Loss:2.5656 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5176864
	speed: 0.0266s/iter; left time: 402.5303s
	iters: 200, epoch: 37 | loss: 0.6170641
	speed: 0.0226s/iter; left time: 339.0367s
Epoch: 37 cost time: 5.759694576263428
Epoch: 37, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5619 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5928233
	speed: 0.0267s/iter; left time: 396.9851s
	iters: 200, epoch: 38 | loss: 0.5947652
	speed: 0.0219s/iter; left time: 323.4490s
Epoch: 38 cost time: 5.70254921913147
Epoch: 38, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5367 + XiCon Loss:2.5632 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5616048
	speed: 0.0278s/iter; left time: 407.7767s
	iters: 200, epoch: 39 | loss: 0.5944998
	speed: 0.0219s/iter; left time: 318.5572s
Epoch: 39 cost time: 5.89240837097168
Epoch: 39, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5368 + XiCon Loss:2.5659 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.5964298
	speed: 0.0255s/iter; left time: 368.1608s
	iters: 200, epoch: 40 | loss: 0.5884789
	speed: 0.0230s/iter; left time: 328.9815s
Epoch: 40 cost time: 5.784618139266968
Epoch: 40, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5651 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.6041903
	speed: 0.0267s/iter; left time: 379.2000s
	iters: 200, epoch: 41 | loss: 0.5369538
	speed: 0.0233s/iter; left time: 328.6338s
Epoch: 41 cost time: 5.816910028457642
Epoch: 41, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5369 + XiCon Loss:2.5637 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.5469325
	speed: 0.0266s/iter; left time: 371.5451s
	iters: 200, epoch: 42 | loss: 0.5617303
	speed: 0.0217s/iter; left time: 300.7798s
Epoch: 42 cost time: 5.703019142150879
Epoch: 42, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5369 + XiCon Loss:2.5636 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.5775177
	speed: 0.0256s/iter; left time: 350.2236s
	iters: 200, epoch: 43 | loss: 0.5699984
	speed: 0.0225s/iter; left time: 306.3490s
Epoch: 43 cost time: 5.7156593799591064
Epoch: 43, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5370 + XiCon Loss:2.5622 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9793247580528259, mae:0.7214688062667847, mape:4.789211750030518, mspe:2695.433349609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7951
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1411610
	speed: 0.0285s/iter; left time: 676.2065s
	iters: 200, epoch: 1 | loss: 1.0557518
	speed: 0.0257s/iter; left time: 605.3976s
Epoch: 1 cost time: 6.4409544467926025
Epoch: 1, Steps: 238 Train Loss: 1.1228 (Forecasting Loss:1.0971 + XiCon Loss:2.5780 x Lambda(0.01)), Vali MSE Loss: 1.9328 Test MSE Loss: 1.0252
Validation loss decreased (inf --> 1.932776).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6221353
	speed: 0.0277s/iter; left time: 649.7248s
	iters: 200, epoch: 2 | loss: 0.6013476
	speed: 0.0245s/iter; left time: 572.9930s
Epoch: 2 cost time: 6.18668007850647
Epoch: 2, Steps: 238 Train Loss: 0.6492 (Forecasting Loss:0.6235 + XiCon Loss:2.5742 x Lambda(0.01)), Vali MSE Loss: 1.0344 Test MSE Loss: 0.8764
Validation loss decreased (1.932776 --> 1.034353).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5469634
	speed: 0.0280s/iter; left time: 650.7174s
	iters: 200, epoch: 3 | loss: 0.6279804
	speed: 0.0242s/iter; left time: 559.7992s
Epoch: 3 cost time: 6.167738437652588
Epoch: 3, Steps: 238 Train Loss: 0.5781 (Forecasting Loss:0.5523 + XiCon Loss:2.5763 x Lambda(0.01)), Vali MSE Loss: 1.0101 Test MSE Loss: 0.8681
Validation loss decreased (1.034353 --> 1.010064).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5528780
	speed: 0.0278s/iter; left time: 639.2301s
	iters: 200, epoch: 4 | loss: 0.6245117
	speed: 0.0248s/iter; left time: 566.5248s
Epoch: 4 cost time: 6.114583730697632
Epoch: 4, Steps: 238 Train Loss: 0.5693 (Forecasting Loss:0.5435 + XiCon Loss:2.5826 x Lambda(0.01)), Vali MSE Loss: 1.0028 Test MSE Loss: 0.8657
Validation loss decreased (1.010064 --> 1.002818).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5604831
	speed: 0.0279s/iter; left time: 634.5122s
	iters: 200, epoch: 5 | loss: 0.5960035
	speed: 0.0248s/iter; left time: 560.6431s
Epoch: 5 cost time: 6.204745769500732
Epoch: 5, Steps: 238 Train Loss: 0.5657 (Forecasting Loss:0.5400 + XiCon Loss:2.5752 x Lambda(0.01)), Vali MSE Loss: 0.9986 Test MSE Loss: 0.8647
Validation loss decreased (1.002818 --> 0.998575).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5852066
	speed: 0.0269s/iter; left time: 605.3947s
	iters: 200, epoch: 6 | loss: 0.5295929
	speed: 0.0249s/iter; left time: 558.6113s
Epoch: 6 cost time: 6.1486594676971436
Epoch: 6, Steps: 238 Train Loss: 0.5642 (Forecasting Loss:0.5384 + XiCon Loss:2.5796 x Lambda(0.01)), Vali MSE Loss: 0.9977 Test MSE Loss: 0.8649
Validation loss decreased (0.998575 --> 0.997698).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5631270
	speed: 0.0275s/iter; left time: 613.1258s
	iters: 200, epoch: 7 | loss: 0.5914155
	speed: 0.0245s/iter; left time: 542.8332s
Epoch: 7 cost time: 6.210341930389404
Epoch: 7, Steps: 238 Train Loss: 0.5632 (Forecasting Loss:0.5375 + XiCon Loss:2.5718 x Lambda(0.01)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8646
Validation loss decreased (0.997698 --> 0.996983).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5625324
	speed: 0.0278s/iter; left time: 611.5102s
	iters: 200, epoch: 8 | loss: 0.5340604
	speed: 0.0248s/iter; left time: 543.6597s
Epoch: 8 cost time: 6.211479187011719
Epoch: 8, Steps: 238 Train Loss: 0.5629 (Forecasting Loss:0.5371 + XiCon Loss:2.5762 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
Validation loss decreased (0.996983 --> 0.996197).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5884717
	speed: 0.0277s/iter; left time: 603.9206s
	iters: 200, epoch: 9 | loss: 0.5517121
	speed: 0.0259s/iter; left time: 562.4709s
Epoch: 9 cost time: 6.3761680126190186
Epoch: 9, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5369 + XiCon Loss:2.5741 x Lambda(0.01)), Vali MSE Loss: 0.9969 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5628422
	speed: 0.0269s/iter; left time: 579.3803s
	iters: 200, epoch: 10 | loss: 0.5620731
	speed: 0.0246s/iter; left time: 528.0688s
Epoch: 10 cost time: 6.118448257446289
Epoch: 10, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5365 + XiCon Loss:2.5780 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
Validation loss decreased (0.996197 --> 0.995978).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5603772
	speed: 0.0287s/iter; left time: 612.6601s
	iters: 200, epoch: 11 | loss: 0.5295497
	speed: 0.0252s/iter; left time: 535.4316s
Epoch: 11 cost time: 6.351232051849365
Epoch: 11, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5368 + XiCon Loss:2.5781 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5475917
	speed: 0.0287s/iter; left time: 605.8599s
	iters: 200, epoch: 12 | loss: 0.5473369
	speed: 0.0237s/iter; left time: 498.1510s
Epoch: 12 cost time: 6.1499106884002686
Epoch: 12, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5368 + XiCon Loss:2.5739 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5303738
	speed: 0.0282s/iter; left time: 586.8275s
	iters: 200, epoch: 13 | loss: 0.5110777
	speed: 0.0239s/iter; left time: 495.7205s
Epoch: 13 cost time: 6.10896635055542
Epoch: 13, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5368 + XiCon Loss:2.5770 x Lambda(0.01)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
Validation loss decreased (0.995978 --> 0.995914).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5868899
	speed: 0.0280s/iter; left time: 576.2490s
	iters: 200, epoch: 14 | loss: 0.6537573
	speed: 0.0238s/iter; left time: 488.4057s
Epoch: 14 cost time: 6.108003854751587
Epoch: 14, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5366 + XiCon Loss:2.5780 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5371221
	speed: 0.0264s/iter; left time: 537.1108s
	iters: 200, epoch: 15 | loss: 0.5424891
	speed: 0.0236s/iter; left time: 477.7110s
Epoch: 15 cost time: 5.878472566604614
Epoch: 15, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5366 + XiCon Loss:2.5834 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995914 --> 0.995525).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5864357
	speed: 0.0265s/iter; left time: 533.7723s
	iters: 200, epoch: 16 | loss: 0.5346777
	speed: 0.0228s/iter; left time: 456.5899s
Epoch: 16 cost time: 5.813321828842163
Epoch: 16, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5368 + XiCon Loss:2.5810 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995525 --> 0.995513).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5303875
	speed: 0.0255s/iter; left time: 506.9512s
	iters: 200, epoch: 17 | loss: 0.5840485
	speed: 0.0225s/iter; left time: 446.1504s
Epoch: 17 cost time: 5.688149690628052
Epoch: 17, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5368 + XiCon Loss:2.5786 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5588812
	speed: 0.0259s/iter; left time: 508.5484s
	iters: 200, epoch: 18 | loss: 0.5405477
	speed: 0.0229s/iter; left time: 447.1586s
Epoch: 18 cost time: 5.764614105224609
Epoch: 18, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5804 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5564852
	speed: 0.0277s/iter; left time: 538.2214s
	iters: 200, epoch: 19 | loss: 0.5619441
	speed: 0.0228s/iter; left time: 440.6853s
Epoch: 19 cost time: 5.920506238937378
Epoch: 19, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5792 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995513 --> 0.995508).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5382223
	speed: 0.0264s/iter; left time: 505.4426s
	iters: 200, epoch: 20 | loss: 0.5711910
	speed: 0.0232s/iter; left time: 441.8170s
Epoch: 20 cost time: 5.854182243347168
Epoch: 20, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5366 + XiCon Loss:2.5793 x Lambda(0.01)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5783557
	speed: 0.0255s/iter; left time: 482.8310s
	iters: 200, epoch: 21 | loss: 0.5504365
	speed: 0.0224s/iter; left time: 421.4083s
Epoch: 21 cost time: 5.643397331237793
Epoch: 21, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5764 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5141987
	speed: 0.0260s/iter; left time: 487.1122s
	iters: 200, epoch: 22 | loss: 0.5560288
	speed: 0.0223s/iter; left time: 414.8933s
Epoch: 22 cost time: 5.694570541381836
Epoch: 22, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5365 + XiCon Loss:2.5827 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5865779
	speed: 0.0264s/iter; left time: 486.6680s
	iters: 200, epoch: 23 | loss: 0.5897092
	speed: 0.0225s/iter; left time: 413.8326s
Epoch: 23 cost time: 5.779696226119995
Epoch: 23, Steps: 238 Train Loss: 0.5627 (Forecasting Loss:0.5369 + XiCon Loss:2.5798 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5314268
	speed: 0.0265s/iter; left time: 483.8093s
	iters: 200, epoch: 24 | loss: 0.5791999
	speed: 0.0246s/iter; left time: 446.4224s
Epoch: 24 cost time: 6.0235981941223145
Epoch: 24, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5368 + XiCon Loss:2.5809 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5938374
	speed: 0.0279s/iter; left time: 502.1126s
	iters: 200, epoch: 25 | loss: 0.5789998
	speed: 0.0249s/iter; left time: 445.8490s
Epoch: 25 cost time: 6.269745826721191
Epoch: 25, Steps: 238 Train Loss: 0.5622 (Forecasting Loss:0.5364 + XiCon Loss:2.5825 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5545886
	speed: 0.0277s/iter; left time: 491.0255s
	iters: 200, epoch: 26 | loss: 0.6040127
	speed: 0.0245s/iter; left time: 432.5676s
Epoch: 26 cost time: 6.2064032554626465
Epoch: 26, Steps: 238 Train Loss: 0.5626 (Forecasting Loss:0.5368 + XiCon Loss:2.5783 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5804957
	speed: 0.0281s/iter; left time: 491.8401s
	iters: 200, epoch: 27 | loss: 0.5664164
	speed: 0.0245s/iter; left time: 427.1340s
Epoch: 27 cost time: 6.219630241394043
Epoch: 27, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5367 + XiCon Loss:2.5733 x Lambda(0.01)), Vali MSE Loss: 0.9950 Test MSE Loss: 0.8645
Validation loss decreased (0.995508 --> 0.995035).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5868490
	speed: 0.0277s/iter; left time: 478.9157s
	iters: 200, epoch: 28 | loss: 0.5506358
	speed: 0.0250s/iter; left time: 429.4435s
Epoch: 28 cost time: 6.193181991577148
Epoch: 28, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5366 + XiCon Loss:2.5811 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5887575
	speed: 0.0269s/iter; left time: 458.9257s
	iters: 200, epoch: 29 | loss: 0.5654262
	speed: 0.0246s/iter; left time: 417.2930s
Epoch: 29 cost time: 6.014222145080566
Epoch: 29, Steps: 238 Train Loss: 0.5624 (Forecasting Loss:0.5367 + XiCon Loss:2.5743 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5949562
	speed: 0.0279s/iter; left time: 469.2823s
	iters: 200, epoch: 30 | loss: 0.5638751
	speed: 0.0250s/iter; left time: 417.8730s
Epoch: 30 cost time: 6.225863218307495
Epoch: 30, Steps: 238 Train Loss: 0.5627 (Forecasting Loss:0.5369 + XiCon Loss:2.5814 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5577453
	speed: 0.0273s/iter; left time: 452.6539s
	iters: 200, epoch: 31 | loss: 0.5606337
	speed: 0.0249s/iter; left time: 410.0189s
Epoch: 31 cost time: 6.160939693450928
Epoch: 31, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5366 + XiCon Loss:2.5776 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5759677
	speed: 0.0270s/iter; left time: 441.3505s
	iters: 200, epoch: 32 | loss: 0.5357029
	speed: 0.0249s/iter; left time: 403.9693s
Epoch: 32 cost time: 6.144858121871948
Epoch: 32, Steps: 238 Train Loss: 0.5627 (Forecasting Loss:0.5369 + XiCon Loss:2.5829 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6231627
	speed: 0.0274s/iter; left time: 441.4141s
	iters: 200, epoch: 33 | loss: 0.5543612
	speed: 0.0248s/iter; left time: 396.7220s
Epoch: 33 cost time: 6.209039688110352
Epoch: 33, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5785 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5295292
	speed: 0.0279s/iter; left time: 442.8793s
	iters: 200, epoch: 34 | loss: 0.5937184
	speed: 0.0247s/iter; left time: 388.2981s
Epoch: 34 cost time: 6.2539238929748535
Epoch: 34, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5737 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5879915
	speed: 0.0288s/iter; left time: 448.9645s
	iters: 200, epoch: 35 | loss: 0.5423338
	speed: 0.0250s/iter; left time: 387.4912s
Epoch: 35 cost time: 6.356634855270386
Epoch: 35, Steps: 238 Train Loss: 0.5623 (Forecasting Loss:0.5366 + XiCon Loss:2.5741 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5092743
	speed: 0.0271s/iter; left time: 417.1196s
	iters: 200, epoch: 36 | loss: 0.5536318
	speed: 0.0249s/iter; left time: 381.0063s
Epoch: 36 cost time: 6.204359769821167
Epoch: 36, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5797 x Lambda(0.01)), Vali MSE Loss: 0.9967 Test MSE Loss: 0.8645
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5246610
	speed: 0.0272s/iter; left time: 411.7069s
	iters: 200, epoch: 37 | loss: 0.5685713
	speed: 0.0247s/iter; left time: 371.4945s
Epoch: 37 cost time: 6.161414384841919
Epoch: 37, Steps: 238 Train Loss: 0.5625 (Forecasting Loss:0.5367 + XiCon Loss:2.5784 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9971221685409546, mae:0.7319389581680298, mape:5.0799078941345215, mspe:3079.959716796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8244
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0923418
	speed: 0.0300s/iter; left time: 711.5188s
	iters: 200, epoch: 1 | loss: 1.1197699
	speed: 0.0275s/iter; left time: 649.5042s
Epoch: 1 cost time: 6.854246616363525
Epoch: 1, Steps: 238 Train Loss: 1.2221 (Forecasting Loss:1.1962 + XiCon Loss:2.5869 x Lambda(0.01)), Vali MSE Loss: 2.1664 Test MSE Loss: 1.1068
Validation loss decreased (inf --> 2.166445).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8000675
	speed: 0.0306s/iter; left time: 716.9563s
	iters: 200, epoch: 2 | loss: 0.5955736
	speed: 0.0265s/iter; left time: 619.3461s
Epoch: 2 cost time: 6.783706903457642
Epoch: 2, Steps: 238 Train Loss: 0.7541 (Forecasting Loss:0.7283 + XiCon Loss:2.5827 x Lambda(0.01)), Vali MSE Loss: 1.0373 Test MSE Loss: 0.8756
Validation loss decreased (2.166445 --> 1.037334).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6231009
	speed: 0.0293s/iter; left time: 680.3256s
	iters: 200, epoch: 3 | loss: 0.6102344
	speed: 0.0258s/iter; left time: 597.3947s
Epoch: 3 cost time: 6.56492018699646
Epoch: 3, Steps: 238 Train Loss: 0.5864 (Forecasting Loss:0.5606 + XiCon Loss:2.5817 x Lambda(0.01)), Vali MSE Loss: 1.0330 Test MSE Loss: 0.8586
Validation loss decreased (1.037334 --> 1.033034).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5932769
	speed: 0.0299s/iter; left time: 687.4223s
	iters: 200, epoch: 4 | loss: 0.5963247
	speed: 0.0269s/iter; left time: 616.2597s
Epoch: 4 cost time: 6.7546093463897705
Epoch: 4, Steps: 238 Train Loss: 0.5739 (Forecasting Loss:0.5480 + XiCon Loss:2.5899 x Lambda(0.01)), Vali MSE Loss: 1.0257 Test MSE Loss: 0.8553
Validation loss decreased (1.033034 --> 1.025672).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5550631
	speed: 0.0300s/iter; left time: 682.2933s
	iters: 200, epoch: 5 | loss: 0.5353404
	speed: 0.0266s/iter; left time: 603.4891s
Epoch: 5 cost time: 6.721416234970093
Epoch: 5, Steps: 238 Train Loss: 0.5706 (Forecasting Loss:0.5447 + XiCon Loss:2.5899 x Lambda(0.01)), Vali MSE Loss: 1.0208 Test MSE Loss: 0.8542
Validation loss decreased (1.025672 --> 1.020788).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5727882
	speed: 0.0297s/iter; left time: 669.2771s
	iters: 200, epoch: 6 | loss: 0.5500156
	speed: 0.0273s/iter; left time: 612.8466s
Epoch: 6 cost time: 6.761331796646118
Epoch: 6, Steps: 238 Train Loss: 0.5689 (Forecasting Loss:0.5431 + XiCon Loss:2.5877 x Lambda(0.01)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8539
Validation loss decreased (1.020788 --> 1.020281).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5985558
	speed: 0.0299s/iter; left time: 664.8526s
	iters: 200, epoch: 7 | loss: 0.5150059
	speed: 0.0280s/iter; left time: 619.9568s
Epoch: 7 cost time: 6.786736249923706
Epoch: 7, Steps: 238 Train Loss: 0.5678 (Forecasting Loss:0.5419 + XiCon Loss:2.5851 x Lambda(0.01)), Vali MSE Loss: 1.0209 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5831656
	speed: 0.0292s/iter; left time: 643.9563s
	iters: 200, epoch: 8 | loss: 0.6397052
	speed: 0.0265s/iter; left time: 581.2686s
Epoch: 8 cost time: 6.6307995319366455
Epoch: 8, Steps: 238 Train Loss: 0.5676 (Forecasting Loss:0.5417 + XiCon Loss:2.5926 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8536
Validation loss decreased (1.020281 --> 1.019088).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5769461
	speed: 0.0295s/iter; left time: 643.6874s
	iters: 200, epoch: 9 | loss: 0.5602819
	speed: 0.0267s/iter; left time: 579.1572s
Epoch: 9 cost time: 6.701719284057617
Epoch: 9, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5415 + XiCon Loss:2.5882 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5802571
	speed: 0.0295s/iter; left time: 634.9598s
	iters: 200, epoch: 10 | loss: 0.5891838
	speed: 0.0275s/iter; left time: 590.0404s
Epoch: 10 cost time: 6.703217267990112
Epoch: 10, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5415 + XiCon Loss:2.5912 x Lambda(0.01)), Vali MSE Loss: 1.0197 Test MSE Loss: 0.8536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5450282
	speed: 0.0285s/iter; left time: 608.1238s
	iters: 200, epoch: 11 | loss: 0.5424125
	speed: 0.0258s/iter; left time: 547.2797s
Epoch: 11 cost time: 6.473801136016846
Epoch: 11, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5414 + XiCon Loss:2.5845 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019088 --> 1.019025).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5556958
	speed: 0.0305s/iter; left time: 643.2065s
	iters: 200, epoch: 12 | loss: 0.5481265
	speed: 0.0265s/iter; left time: 556.4545s
Epoch: 12 cost time: 6.7204365730285645
Epoch: 12, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5412 + XiCon Loss:2.5848 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019025 --> 1.019004).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5516582
	speed: 0.0284s/iter; left time: 591.4215s
	iters: 200, epoch: 13 | loss: 0.6268163
	speed: 0.0260s/iter; left time: 538.9124s
Epoch: 13 cost time: 6.546802282333374
Epoch: 13, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5414 + XiCon Loss:2.5848 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6244730
	speed: 0.0295s/iter; left time: 608.2584s
	iters: 200, epoch: 14 | loss: 0.5773181
	speed: 0.0262s/iter; left time: 537.9946s
Epoch: 14 cost time: 6.65686559677124
Epoch: 14, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5411 + XiCon Loss:2.5875 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5592101
	speed: 0.0294s/iter; left time: 598.3011s
	iters: 200, epoch: 15 | loss: 0.5861689
	speed: 0.0266s/iter; left time: 540.0500s
Epoch: 15 cost time: 6.6751039028167725
Epoch: 15, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5414 + XiCon Loss:2.5840 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5566068
	speed: 0.0311s/iter; left time: 626.7289s
	iters: 200, epoch: 16 | loss: 0.5467601
	speed: 0.0264s/iter; left time: 528.1252s
Epoch: 16 cost time: 6.7993199825286865
Epoch: 16, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5414 + XiCon Loss:2.5870 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
Validation loss decreased (1.019004 --> 1.018898).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5625387
	speed: 0.0288s/iter; left time: 573.1771s
	iters: 200, epoch: 17 | loss: 0.5591660
	speed: 0.0265s/iter; left time: 525.4097s
Epoch: 17 cost time: 6.625103950500488
Epoch: 17, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5412 + XiCon Loss:2.5848 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5483221
	speed: 0.0299s/iter; left time: 587.6633s
	iters: 200, epoch: 18 | loss: 0.6175534
	speed: 0.0262s/iter; left time: 511.6573s
Epoch: 18 cost time: 6.603480100631714
Epoch: 18, Steps: 238 Train Loss: 0.5665 (Forecasting Loss:0.5407 + XiCon Loss:2.5862 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6282516
	speed: 0.0298s/iter; left time: 579.4603s
	iters: 200, epoch: 19 | loss: 0.6026660
	speed: 0.0264s/iter; left time: 510.8118s
Epoch: 19 cost time: 6.65839958190918
Epoch: 19, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5411 + XiCon Loss:2.5885 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6050394
	speed: 0.0306s/iter; left time: 587.1719s
	iters: 200, epoch: 20 | loss: 0.5936974
	speed: 0.0260s/iter; left time: 495.4808s
Epoch: 20 cost time: 6.717305898666382
Epoch: 20, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5413 + XiCon Loss:2.5885 x Lambda(0.01)), Vali MSE Loss: 1.0201 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6192480
	speed: 0.0267s/iter; left time: 505.1078s
	iters: 200, epoch: 21 | loss: 0.5251951
	speed: 0.0240s/iter; left time: 452.8081s
Epoch: 21 cost time: 6.070611953735352
Epoch: 21, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5413 + XiCon Loss:2.5900 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5501879
	speed: 0.0271s/iter; left time: 507.4740s
	iters: 200, epoch: 22 | loss: 0.5793656
	speed: 0.0246s/iter; left time: 457.0685s
Epoch: 22 cost time: 6.166746139526367
Epoch: 22, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5412 + XiCon Loss:2.5903 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6125771
	speed: 0.0274s/iter; left time: 506.1791s
	iters: 200, epoch: 23 | loss: 0.5875558
	speed: 0.0245s/iter; left time: 450.7908s
Epoch: 23 cost time: 6.1623148918151855
Epoch: 23, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5412 + XiCon Loss:2.5858 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5911202
	speed: 0.0274s/iter; left time: 499.6313s
	iters: 200, epoch: 24 | loss: 0.5540580
	speed: 0.0255s/iter; left time: 462.3145s
Epoch: 24 cost time: 6.365770101547241
Epoch: 24, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5411 + XiCon Loss:2.5897 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5712938
	speed: 0.0273s/iter; left time: 491.9113s
	iters: 200, epoch: 25 | loss: 0.5885632
	speed: 0.0246s/iter; left time: 440.5372s
Epoch: 25 cost time: 6.166626691818237
Epoch: 25, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5417 + XiCon Loss:2.5830 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5537953
	speed: 0.0275s/iter; left time: 488.4532s
	iters: 200, epoch: 26 | loss: 0.5917420
	speed: 0.0245s/iter; left time: 433.2965s
Epoch: 26 cost time: 6.146775722503662
Epoch: 26, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5413 + XiCon Loss:2.5878 x Lambda(0.01)), Vali MSE Loss: 1.0185 Test MSE Loss: 0.8535
Validation loss decreased (1.018898 --> 1.018511).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5510449
	speed: 0.0276s/iter; left time: 483.6826s
	iters: 200, epoch: 27 | loss: 0.5538891
	speed: 0.0244s/iter; left time: 424.6589s
Epoch: 27 cost time: 6.169541358947754
Epoch: 27, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5413 + XiCon Loss:2.5866 x Lambda(0.01)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8535
Validation loss decreased (1.018511 --> 1.018095).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6171453
	speed: 0.0270s/iter; left time: 466.5669s
	iters: 200, epoch: 28 | loss: 0.5521107
	speed: 0.0236s/iter; left time: 405.6886s
Epoch: 28 cost time: 6.12508487701416
Epoch: 28, Steps: 238 Train Loss: 0.5666 (Forecasting Loss:0.5407 + XiCon Loss:2.5874 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5680243
	speed: 0.0296s/iter; left time: 504.0462s
	iters: 200, epoch: 29 | loss: 0.5692592
	speed: 0.0268s/iter; left time: 453.3666s
Epoch: 29 cost time: 6.682947158813477
Epoch: 29, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5412 + XiCon Loss:2.5823 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5649347
	speed: 0.0286s/iter; left time: 480.2285s
	iters: 200, epoch: 30 | loss: 0.5503935
	speed: 0.0269s/iter; left time: 448.6115s
Epoch: 30 cost time: 6.58684778213501
Epoch: 30, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5412 + XiCon Loss:2.5909 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5825770
	speed: 0.0306s/iter; left time: 506.6827s
	iters: 200, epoch: 31 | loss: 0.5642093
	speed: 0.0269s/iter; left time: 443.1856s
Epoch: 31 cost time: 6.81144380569458
Epoch: 31, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5414 + XiCon Loss:2.5895 x Lambda(0.01)), Vali MSE Loss: 1.0202 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5209545
	speed: 0.0291s/iter; left time: 475.1470s
	iters: 200, epoch: 32 | loss: 0.6063154
	speed: 0.0273s/iter; left time: 442.9808s
Epoch: 32 cost time: 6.6963324546813965
Epoch: 32, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5415 + XiCon Loss:2.5836 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5040970
	speed: 0.0291s/iter; left time: 467.9264s
	iters: 200, epoch: 33 | loss: 0.5381818
	speed: 0.0266s/iter; left time: 424.6155s
Epoch: 33 cost time: 6.624125242233276
Epoch: 33, Steps: 238 Train Loss: 0.5667 (Forecasting Loss:0.5408 + XiCon Loss:2.5907 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5659742
	speed: 0.0295s/iter; left time: 467.5139s
	iters: 200, epoch: 34 | loss: 0.5601397
	speed: 0.0268s/iter; left time: 421.7457s
Epoch: 34 cost time: 6.5929577350616455
Epoch: 34, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5413 + XiCon Loss:2.5905 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5562460
	speed: 0.0288s/iter; left time: 449.7426s
	iters: 200, epoch: 35 | loss: 0.5842846
	speed: 0.0261s/iter; left time: 405.3388s
Epoch: 35 cost time: 6.549401044845581
Epoch: 35, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5411 + XiCon Loss:2.5877 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5750458
	speed: 0.0296s/iter; left time: 455.5919s
	iters: 200, epoch: 36 | loss: 0.5757855
	speed: 0.0267s/iter; left time: 407.2201s
Epoch: 36 cost time: 6.6898112297058105
Epoch: 36, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5412 + XiCon Loss:2.5858 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5566306
	speed: 0.0286s/iter; left time: 432.3960s
	iters: 200, epoch: 37 | loss: 0.5937331
	speed: 0.0272s/iter; left time: 408.3211s
Epoch: 37 cost time: 6.65094518661499
Epoch: 37, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5411 + XiCon Loss:2.5856 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.985970675945282, mae:0.721071720123291, mape:4.676875114440918, mspe:2546.53564453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.4435
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9711922
	speed: 0.0299s/iter; left time: 708.0066s
	iters: 200, epoch: 1 | loss: 1.0248021
	speed: 0.0264s/iter; left time: 623.7456s
Epoch: 1 cost time: 6.662732124328613
Epoch: 1, Steps: 238 Train Loss: 1.0526 (Forecasting Loss:1.0271 + XiCon Loss:2.5517 x Lambda(0.01)), Vali MSE Loss: 1.8388 Test MSE Loss: 0.9830
Validation loss decreased (inf --> 1.838782).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6502518
	speed: 0.0290s/iter; left time: 679.3414s
	iters: 200, epoch: 2 | loss: 0.5383935
	speed: 0.0263s/iter; left time: 615.5260s
Epoch: 2 cost time: 6.595797061920166
Epoch: 2, Steps: 238 Train Loss: 0.6488 (Forecasting Loss:0.6233 + XiCon Loss:2.5499 x Lambda(0.01)), Vali MSE Loss: 1.0469 Test MSE Loss: 0.8597
Validation loss decreased (1.838782 --> 1.046910).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5969785
	speed: 0.0287s/iter; left time: 666.1985s
	iters: 200, epoch: 3 | loss: 0.6068723
	speed: 0.0259s/iter; left time: 598.0030s
Epoch: 3 cost time: 6.505643606185913
Epoch: 3, Steps: 238 Train Loss: 0.5800 (Forecasting Loss:0.5546 + XiCon Loss:2.5426 x Lambda(0.01)), Vali MSE Loss: 1.0221 Test MSE Loss: 0.8525
Validation loss decreased (1.046910 --> 1.022088).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5973236
	speed: 0.0302s/iter; left time: 694.2045s
	iters: 200, epoch: 4 | loss: 0.6115141
	speed: 0.0262s/iter; left time: 600.2434s
Epoch: 4 cost time: 6.6489527225494385
Epoch: 4, Steps: 238 Train Loss: 0.5713 (Forecasting Loss:0.5459 + XiCon Loss:2.5431 x Lambda(0.01)), Vali MSE Loss: 1.0136 Test MSE Loss: 0.8513
Validation loss decreased (1.022088 --> 1.013552).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5905930
	speed: 0.0283s/iter; left time: 643.5004s
	iters: 200, epoch: 5 | loss: 0.5941088
	speed: 0.0253s/iter; left time: 572.0059s
Epoch: 5 cost time: 6.4108216762542725
Epoch: 5, Steps: 238 Train Loss: 0.5678 (Forecasting Loss:0.5424 + XiCon Loss:2.5426 x Lambda(0.01)), Vali MSE Loss: 1.0108 Test MSE Loss: 0.8508
Validation loss decreased (1.013552 --> 1.010783).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5443012
	speed: 0.0299s/iter; left time: 674.1371s
	iters: 200, epoch: 6 | loss: 0.5521069
	speed: 0.0280s/iter; left time: 627.1356s
Epoch: 6 cost time: 6.758042335510254
Epoch: 6, Steps: 238 Train Loss: 0.5662 (Forecasting Loss:0.5408 + XiCon Loss:2.5394 x Lambda(0.01)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8504
Validation loss decreased (1.010783 --> 1.008179).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5939524
	speed: 0.0301s/iter; left time: 671.3785s
	iters: 200, epoch: 7 | loss: 0.5845403
	speed: 0.0260s/iter; left time: 576.4200s
Epoch: 7 cost time: 6.641499042510986
Epoch: 7, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5400 + XiCon Loss:2.5446 x Lambda(0.01)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8503
Validation loss decreased (1.008179 --> 1.007903).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6239161
	speed: 0.0282s/iter; left time: 620.4098s
	iters: 200, epoch: 8 | loss: 0.5444039
	speed: 0.0274s/iter; left time: 601.8708s
Epoch: 8 cost time: 6.577347755432129
Epoch: 8, Steps: 238 Train Loss: 0.5650 (Forecasting Loss:0.5395 + XiCon Loss:2.5421 x Lambda(0.01)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8503
Validation loss decreased (1.007903 --> 1.006860).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5412245
	speed: 0.0298s/iter; left time: 649.0166s
	iters: 200, epoch: 9 | loss: 0.5269266
	speed: 0.0268s/iter; left time: 581.7265s
Epoch: 9 cost time: 6.741144418716431
Epoch: 9, Steps: 238 Train Loss: 0.5649 (Forecasting Loss:0.5394 + XiCon Loss:2.5442 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
Validation loss decreased (1.006860 --> 1.006314).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5369573
	speed: 0.0295s/iter; left time: 636.1067s
	iters: 200, epoch: 10 | loss: 0.5723197
	speed: 0.0267s/iter; left time: 573.4460s
Epoch: 10 cost time: 6.618820667266846
Epoch: 10, Steps: 238 Train Loss: 0.5645 (Forecasting Loss:0.5391 + XiCon Loss:2.5440 x Lambda(0.01)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.8502
Validation loss decreased (1.006314 --> 1.005902).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6377221
	speed: 0.0291s/iter; left time: 620.6577s
	iters: 200, epoch: 11 | loss: 0.5560513
	speed: 0.0257s/iter; left time: 545.7634s
Epoch: 11 cost time: 6.5022242069244385
Epoch: 11, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5388 + XiCon Loss:2.5421 x Lambda(0.01)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5576449
	speed: 0.0294s/iter; left time: 619.3086s
	iters: 200, epoch: 12 | loss: 0.5495638
	speed: 0.0279s/iter; left time: 584.4761s
Epoch: 12 cost time: 6.669236421585083
Epoch: 12, Steps: 238 Train Loss: 0.5647 (Forecasting Loss:0.5392 + XiCon Loss:2.5479 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6077255
	speed: 0.0298s/iter; left time: 620.1897s
	iters: 200, epoch: 13 | loss: 0.5933440
	speed: 0.0260s/iter; left time: 539.9544s
Epoch: 13 cost time: 6.602768421173096
Epoch: 13, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5464 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5911896
	speed: 0.0298s/iter; left time: 614.9620s
	iters: 200, epoch: 14 | loss: 0.5269542
	speed: 0.0273s/iter; left time: 559.3465s
Epoch: 14 cost time: 6.684075593948364
Epoch: 14, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5480 x Lambda(0.01)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5481225
	speed: 0.0291s/iter; left time: 592.7841s
	iters: 200, epoch: 15 | loss: 0.6097077
	speed: 0.0276s/iter; left time: 559.5724s
Epoch: 15 cost time: 6.729491949081421
Epoch: 15, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5389 + XiCon Loss:2.5409 x Lambda(0.01)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5427581
	speed: 0.0310s/iter; left time: 623.3096s
	iters: 200, epoch: 16 | loss: 0.5442914
	speed: 0.0273s/iter; left time: 546.0813s
Epoch: 16 cost time: 6.881743431091309
Epoch: 16, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5453 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
Validation loss decreased (1.005902 --> 1.005728).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5722815
	speed: 0.0292s/iter; left time: 580.5006s
	iters: 200, epoch: 17 | loss: 0.5288360
	speed: 0.0284s/iter; left time: 562.5855s
Epoch: 17 cost time: 6.7648444175720215
Epoch: 17, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5389 + XiCon Loss:2.5389 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8502
Validation loss decreased (1.005728 --> 1.004932).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5199036
	speed: 0.0286s/iter; left time: 561.3716s
	iters: 200, epoch: 18 | loss: 0.6395094
	speed: 0.0263s/iter; left time: 514.7848s
Epoch: 18 cost time: 6.53645920753479
Epoch: 18, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5478 x Lambda(0.01)), Vali MSE Loss: 1.0061 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5368545
	speed: 0.0290s/iter; left time: 562.8370s
	iters: 200, epoch: 19 | loss: 0.5248271
	speed: 0.0268s/iter; left time: 517.1255s
Epoch: 19 cost time: 6.684071063995361
Epoch: 19, Steps: 238 Train Loss: 0.5643 (Forecasting Loss:0.5388 + XiCon Loss:2.5417 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6180606
	speed: 0.0296s/iter; left time: 567.7382s
	iters: 200, epoch: 20 | loss: 0.5460346
	speed: 0.0266s/iter; left time: 506.8260s
Epoch: 20 cost time: 6.714560031890869
Epoch: 20, Steps: 238 Train Loss: 0.5645 (Forecasting Loss:0.5391 + XiCon Loss:2.5432 x Lambda(0.01)), Vali MSE Loss: 1.0060 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5433514
	speed: 0.0291s/iter; left time: 550.5395s
	iters: 200, epoch: 21 | loss: 0.6073111
	speed: 0.0269s/iter; left time: 506.6639s
Epoch: 21 cost time: 6.6920318603515625
Epoch: 21, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5392 + XiCon Loss:2.5423 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6014038
	speed: 0.0290s/iter; left time: 542.2268s
	iters: 200, epoch: 22 | loss: 0.5940002
	speed: 0.0267s/iter; left time: 497.4908s
Epoch: 22 cost time: 6.611917495727539
Epoch: 22, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5390 + XiCon Loss:2.5420 x Lambda(0.01)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5674410
	speed: 0.0296s/iter; left time: 546.4318s
	iters: 200, epoch: 23 | loss: 0.6085689
	speed: 0.0262s/iter; left time: 481.8164s
Epoch: 23 cost time: 6.645515203475952
Epoch: 23, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5390 + XiCon Loss:2.5472 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4932477
	speed: 0.0288s/iter; left time: 525.0231s
	iters: 200, epoch: 24 | loss: 0.5289921
	speed: 0.0273s/iter; left time: 494.3089s
Epoch: 24 cost time: 6.642189264297485
Epoch: 24, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5444 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5882197
	speed: 0.0274s/iter; left time: 493.5193s
	iters: 200, epoch: 25 | loss: 0.5555748
	speed: 0.0251s/iter; left time: 449.2970s
Epoch: 25 cost time: 6.235125303268433
Epoch: 25, Steps: 238 Train Loss: 0.5645 (Forecasting Loss:0.5391 + XiCon Loss:2.5440 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5456309
	speed: 0.0276s/iter; left time: 489.5517s
	iters: 200, epoch: 26 | loss: 0.5875705
	speed: 0.0254s/iter; left time: 448.0926s
Epoch: 26 cost time: 6.278856992721558
Epoch: 26, Steps: 238 Train Loss: 0.5644 (Forecasting Loss:0.5390 + XiCon Loss:2.5472 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5626428
	speed: 0.0268s/iter; left time: 469.5906s
	iters: 200, epoch: 27 | loss: 0.5342394
	speed: 0.0250s/iter; left time: 435.0050s
Epoch: 27 cost time: 6.164946556091309
Epoch: 27, Steps: 238 Train Loss: 0.5646 (Forecasting Loss:0.5391 + XiCon Loss:2.5455 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9806095957756042, mae:0.7197746634483337, mape:4.739065647125244, mspe:2656.35986328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9842+-0.00979, MAE:0.7227+-0.00649, MAPE:4.8128+-0.19333, MSPE:2733.9468+-251.53825, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.7931
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 0.9936880
	speed: 0.0359s/iter; left time: 833.1422s
	iters: 200, epoch: 1 | loss: 0.9471508
	speed: 0.0283s/iter; left time: 652.9024s
Epoch: 1 cost time: 7.415998458862305
Epoch: 1, Steps: 233 Train Loss: 1.0471 (Forecasting Loss:1.0189 + XiCon Loss:2.8191 x Lambda(0.01)), Vali MSE Loss: 1.8606 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860587).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6290566
	speed: 0.0320s/iter; left time: 734.6742s
	iters: 200, epoch: 2 | loss: 0.6917337
	speed: 0.0301s/iter; left time: 687.3206s
Epoch: 2 cost time: 7.256101608276367
Epoch: 2, Steps: 233 Train Loss: 0.6804 (Forecasting Loss:0.6522 + XiCon Loss:2.8144 x Lambda(0.01)), Vali MSE Loss: 1.1270 Test MSE Loss: 1.1495
Validation loss decreased (1.860587 --> 1.126961).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6560236
	speed: 0.0344s/iter; left time: 781.8824s
	iters: 200, epoch: 3 | loss: 0.5987808
	speed: 0.0315s/iter; left time: 712.8184s
Epoch: 3 cost time: 7.6662070751190186
Epoch: 3, Steps: 233 Train Loss: 0.6162 (Forecasting Loss:0.5881 + XiCon Loss:2.8081 x Lambda(0.01)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1437
Validation loss decreased (1.126961 --> 1.104182).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6235246
	speed: 0.0332s/iter; left time: 747.9497s
	iters: 200, epoch: 4 | loss: 0.6221098
	speed: 0.0314s/iter; left time: 702.4734s
Epoch: 4 cost time: 7.540534496307373
Epoch: 4, Steps: 233 Train Loss: 0.6080 (Forecasting Loss:0.5799 + XiCon Loss:2.8061 x Lambda(0.01)), Vali MSE Loss: 1.0969 Test MSE Loss: 1.1410
Validation loss decreased (1.104182 --> 1.096879).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5966830
	speed: 0.0340s/iter; left time: 756.7808s
	iters: 200, epoch: 5 | loss: 0.5937693
	speed: 0.0319s/iter; left time: 706.9208s
Epoch: 5 cost time: 7.703531503677368
Epoch: 5, Steps: 233 Train Loss: 0.6047 (Forecasting Loss:0.5767 + XiCon Loss:2.8077 x Lambda(0.01)), Vali MSE Loss: 1.0935 Test MSE Loss: 1.1402
Validation loss decreased (1.096879 --> 1.093452).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6177443
	speed: 0.0321s/iter; left time: 707.3054s
	iters: 200, epoch: 6 | loss: 0.6279908
	speed: 0.0298s/iter; left time: 652.9015s
Epoch: 6 cost time: 7.281522750854492
Epoch: 6, Steps: 233 Train Loss: 0.6033 (Forecasting Loss:0.5752 + XiCon Loss:2.8100 x Lambda(0.01)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1398
Validation loss decreased (1.093452 --> 1.091759).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5933388
	speed: 0.0339s/iter; left time: 739.2079s
	iters: 200, epoch: 7 | loss: 0.6489984
	speed: 0.0317s/iter; left time: 687.8995s
Epoch: 7 cost time: 7.643877267837524
Epoch: 7, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5744 + XiCon Loss:2.8063 x Lambda(0.01)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1398
Validation loss decreased (1.091759 --> 1.090914).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5712497
	speed: 0.0346s/iter; left time: 746.6867s
	iters: 200, epoch: 8 | loss: 0.6145636
	speed: 0.0310s/iter; left time: 666.6410s
Epoch: 8 cost time: 7.617204427719116
Epoch: 8, Steps: 233 Train Loss: 0.6021 (Forecasting Loss:0.5740 + XiCon Loss:2.8099 x Lambda(0.01)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1397
Validation loss decreased (1.090914 --> 1.090772).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6477105
	speed: 0.0304s/iter; left time: 648.4270s
	iters: 200, epoch: 9 | loss: 0.6466975
	speed: 0.0273s/iter; left time: 578.9799s
Epoch: 9 cost time: 6.6786277294158936
Epoch: 9, Steps: 233 Train Loss: 0.6019 (Forecasting Loss:0.5738 + XiCon Loss:2.8112 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
Validation loss decreased (1.090772 --> 1.090310).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5695022
	speed: 0.0334s/iter; left time: 704.6550s
	iters: 200, epoch: 10 | loss: 0.5919985
	speed: 0.0304s/iter; left time: 639.4934s
Epoch: 10 cost time: 7.468742609024048
Epoch: 10, Steps: 233 Train Loss: 0.6018 (Forecasting Loss:0.5737 + XiCon Loss:2.8079 x Lambda(0.01)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5879731
	speed: 0.0336s/iter; left time: 700.5427s
	iters: 200, epoch: 11 | loss: 0.6125221
	speed: 0.0316s/iter; left time: 655.9641s
Epoch: 11 cost time: 7.601907730102539
Epoch: 11, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8056 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
Validation loss decreased (1.090310 --> 1.090098).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6148531
	speed: 0.0339s/iter; left time: 699.9427s
	iters: 200, epoch: 12 | loss: 0.6019027
	speed: 0.0310s/iter; left time: 636.2118s
Epoch: 12 cost time: 7.618778944015503
Epoch: 12, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8045 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.090098 --> 1.089937).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5893894
	speed: 0.0350s/iter; left time: 714.5785s
	iters: 200, epoch: 13 | loss: 0.6137028
	speed: 0.0320s/iter; left time: 649.4358s
Epoch: 13 cost time: 7.751309633255005
Epoch: 13, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8084 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.089937 --> 1.089879).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6132528
	speed: 0.0347s/iter; left time: 699.8175s
	iters: 200, epoch: 14 | loss: 0.5950214
	speed: 0.0310s/iter; left time: 622.8864s
Epoch: 14 cost time: 7.60285758972168
Epoch: 14, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8036 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5848419
	speed: 0.0339s/iter; left time: 676.7773s
	iters: 200, epoch: 15 | loss: 0.6379386
	speed: 0.0313s/iter; left time: 621.3818s
Epoch: 15 cost time: 7.59607720375061
Epoch: 15, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8059 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6177086
	speed: 0.0350s/iter; left time: 690.0481s
	iters: 200, epoch: 16 | loss: 0.6286022
	speed: 0.0323s/iter; left time: 633.4212s
Epoch: 16 cost time: 7.74024772644043
Epoch: 16, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8055 x Lambda(0.01)), Vali MSE Loss: 1.0895 Test MSE Loss: 1.1396
Validation loss decreased (1.089879 --> 1.089468).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5947022
	speed: 0.0331s/iter; left time: 643.7614s
	iters: 200, epoch: 17 | loss: 0.5868692
	speed: 0.0312s/iter; left time: 605.1589s
Epoch: 17 cost time: 7.534985303878784
Epoch: 17, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8034 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6380962
	speed: 0.0331s/iter; left time: 637.3502s
	iters: 200, epoch: 18 | loss: 0.6084454
	speed: 0.0312s/iter; left time: 597.3684s
Epoch: 18 cost time: 7.546360969543457
Epoch: 18, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8068 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5910422
	speed: 0.0334s/iter; left time: 634.4102s
	iters: 200, epoch: 19 | loss: 0.6809225
	speed: 0.0322s/iter; left time: 607.9607s
Epoch: 19 cost time: 7.6700873374938965
Epoch: 19, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8080 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5739216
	speed: 0.0346s/iter; left time: 649.1695s
	iters: 200, epoch: 20 | loss: 0.5807082
	speed: 0.0310s/iter; left time: 578.9892s
Epoch: 20 cost time: 7.653477668762207
Epoch: 20, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8062 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6013101
	speed: 0.0335s/iter; left time: 621.9202s
	iters: 200, epoch: 21 | loss: 0.5821166
	speed: 0.0329s/iter; left time: 607.0091s
Epoch: 21 cost time: 7.69245719909668
Epoch: 21, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8073 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5747752
	speed: 0.0348s/iter; left time: 637.5408s
	iters: 200, epoch: 22 | loss: 0.5767455
	speed: 0.0311s/iter; left time: 566.8893s
Epoch: 22 cost time: 7.704672574996948
Epoch: 22, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8082 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5450916
	speed: 0.0346s/iter; left time: 625.5930s
	iters: 200, epoch: 23 | loss: 0.6018607
	speed: 0.0308s/iter; left time: 553.8492s
Epoch: 23 cost time: 7.638082027435303
Epoch: 23, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8039 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5906722
	speed: 0.0343s/iter; left time: 611.9007s
	iters: 200, epoch: 24 | loss: 0.5742178
	speed: 0.0310s/iter; left time: 550.0028s
Epoch: 24 cost time: 7.628695249557495
Epoch: 24, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8080 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5985199
	speed: 0.0334s/iter; left time: 587.6952s
	iters: 200, epoch: 25 | loss: 0.5764410
	speed: 0.0316s/iter; left time: 552.9231s
Epoch: 25 cost time: 7.565361022949219
Epoch: 25, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8112 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5759081
	speed: 0.0349s/iter; left time: 607.2822s
	iters: 200, epoch: 26 | loss: 0.6444759
	speed: 0.0314s/iter; left time: 542.6177s
Epoch: 26 cost time: 7.722541093826294
Epoch: 26, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8012 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3994561433792114, mae:0.8796807527542114, mape:6.137732982635498, mspe:4546.10693359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0862
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1782428
	speed: 0.0327s/iter; left time: 758.9865s
	iters: 200, epoch: 1 | loss: 1.1397628
	speed: 0.0273s/iter; left time: 629.5311s
Epoch: 1 cost time: 6.936830043792725
Epoch: 1, Steps: 233 Train Loss: 1.1625 (Forecasting Loss:1.1341 + XiCon Loss:2.8418 x Lambda(0.01)), Vali MSE Loss: 2.0405 Test MSE Loss: 1.3313
Validation loss decreased (inf --> 2.040482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7085614
	speed: 0.0317s/iter; left time: 728.7278s
	iters: 200, epoch: 2 | loss: 0.6237829
	speed: 0.0272s/iter; left time: 622.9163s
Epoch: 2 cost time: 6.746626853942871
Epoch: 2, Steps: 233 Train Loss: 0.6883 (Forecasting Loss:0.6598 + XiCon Loss:2.8417 x Lambda(0.01)), Vali MSE Loss: 1.1148 Test MSE Loss: 1.1427
Validation loss decreased (2.040482 --> 1.114843).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6014542
	speed: 0.0315s/iter; left time: 717.2689s
	iters: 200, epoch: 3 | loss: 0.5923413
	speed: 0.0291s/iter; left time: 658.2368s
Epoch: 3 cost time: 6.912122011184692
Epoch: 3, Steps: 233 Train Loss: 0.6158 (Forecasting Loss:0.5874 + XiCon Loss:2.8441 x Lambda(0.01)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1376
Validation loss decreased (1.114843 --> 1.091930).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6577317
	speed: 0.0304s/iter; left time: 683.1498s
	iters: 200, epoch: 4 | loss: 0.5858312
	speed: 0.0271s/iter; left time: 607.0238s
Epoch: 4 cost time: 6.711294412612915
Epoch: 4, Steps: 233 Train Loss: 0.6074 (Forecasting Loss:0.5790 + XiCon Loss:2.8412 x Lambda(0.01)), Vali MSE Loss: 1.0847 Test MSE Loss: 1.1360
Validation loss decreased (1.091930 --> 1.084650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6780871
	speed: 0.0316s/iter; left time: 702.6478s
	iters: 200, epoch: 5 | loss: 0.5701274
	speed: 0.0280s/iter; left time: 621.2129s
Epoch: 5 cost time: 7.003262519836426
Epoch: 5, Steps: 233 Train Loss: 0.6041 (Forecasting Loss:0.5756 + XiCon Loss:2.8459 x Lambda(0.01)), Vali MSE Loss: 1.0800 Test MSE Loss: 1.1359
Validation loss decreased (1.084650 --> 1.079988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6639608
	speed: 0.0299s/iter; left time: 659.7990s
	iters: 200, epoch: 6 | loss: 0.6420057
	speed: 0.0251s/iter; left time: 549.8515s
Epoch: 6 cost time: 6.386281967163086
Epoch: 6, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5740 + XiCon Loss:2.8462 x Lambda(0.01)), Vali MSE Loss: 1.0789 Test MSE Loss: 1.1350
Validation loss decreased (1.079988 --> 1.078879).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6037022
	speed: 0.0291s/iter; left time: 633.9772s
	iters: 200, epoch: 7 | loss: 0.5898914
	speed: 0.0253s/iter; left time: 550.0538s
Epoch: 7 cost time: 6.324482679367065
Epoch: 7, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5733 + XiCon Loss:2.8429 x Lambda(0.01)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1352
Validation loss decreased (1.078879 --> 1.077416).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5973014
	speed: 0.0292s/iter; left time: 630.3585s
	iters: 200, epoch: 8 | loss: 0.6514864
	speed: 0.0251s/iter; left time: 539.2514s
Epoch: 8 cost time: 6.276797533035278
Epoch: 8, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5728 + XiCon Loss:2.8432 x Lambda(0.01)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1352
Validation loss decreased (1.077416 --> 1.076862).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5788916
	speed: 0.0292s/iter; left time: 623.2101s
	iters: 200, epoch: 9 | loss: 0.5851058
	speed: 0.0270s/iter; left time: 573.1391s
Epoch: 9 cost time: 6.496618747711182
Epoch: 9, Steps: 233 Train Loss: 0.6010 (Forecasting Loss:0.5726 + XiCon Loss:2.8391 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1352
Validation loss decreased (1.076862 --> 1.076508).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6091461
	speed: 0.0288s/iter; left time: 607.5680s
	iters: 200, epoch: 10 | loss: 0.6067740
	speed: 0.0261s/iter; left time: 548.3612s
Epoch: 10 cost time: 6.3716957569122314
Epoch: 10, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5726 + XiCon Loss:2.8494 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5411271
	speed: 0.0292s/iter; left time: 608.7075s
	iters: 200, epoch: 11 | loss: 0.6034074
	speed: 0.0260s/iter; left time: 539.3108s
Epoch: 11 cost time: 6.383068799972534
Epoch: 11, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8389 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5828609
	speed: 0.0288s/iter; left time: 594.6152s
	iters: 200, epoch: 12 | loss: 0.5901908
	speed: 0.0251s/iter; left time: 515.3329s
Epoch: 12 cost time: 6.233128786087036
Epoch: 12, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8406 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076508 --> 1.076444).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6180601
	speed: 0.0297s/iter; left time: 606.7138s
	iters: 200, epoch: 13 | loss: 0.6164789
	speed: 0.0290s/iter; left time: 588.2768s
Epoch: 13 cost time: 6.73443078994751
Epoch: 13, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8406 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5869644
	speed: 0.0310s/iter; left time: 625.6404s
	iters: 200, epoch: 14 | loss: 0.5943110
	speed: 0.0277s/iter; left time: 556.2061s
Epoch: 14 cost time: 6.854013681411743
Epoch: 14, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8373 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076444 --> 1.076410).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6112831
	speed: 0.0319s/iter; left time: 636.5941s
	iters: 200, epoch: 15 | loss: 0.5730461
	speed: 0.0274s/iter; left time: 542.7049s
Epoch: 15 cost time: 6.809783935546875
Epoch: 15, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8403 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6071646
	speed: 0.0313s/iter; left time: 617.0394s
	iters: 200, epoch: 16 | loss: 0.6332904
	speed: 0.0279s/iter; left time: 546.0938s
Epoch: 16 cost time: 6.772749900817871
Epoch: 16, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8417 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5794505
	speed: 0.0324s/iter; left time: 630.7324s
	iters: 200, epoch: 17 | loss: 0.5563366
	speed: 0.0285s/iter; left time: 551.5946s
Epoch: 17 cost time: 6.998114824295044
Epoch: 17, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8424 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6427764
	speed: 0.0313s/iter; left time: 601.9100s
	iters: 200, epoch: 18 | loss: 0.5750536
	speed: 0.0278s/iter; left time: 531.3858s
Epoch: 18 cost time: 6.916402101516724
Epoch: 18, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5696352
	speed: 0.0317s/iter; left time: 601.8487s
	iters: 200, epoch: 19 | loss: 0.5961110
	speed: 0.0274s/iter; left time: 517.3748s
Epoch: 19 cost time: 6.899881601333618
Epoch: 19, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8444 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6400145
	speed: 0.0311s/iter; left time: 584.2902s
	iters: 200, epoch: 20 | loss: 0.5733916
	speed: 0.0273s/iter; left time: 510.5960s
Epoch: 20 cost time: 6.762661457061768
Epoch: 20, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8389 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5752984
	speed: 0.0318s/iter; left time: 589.9089s
	iters: 200, epoch: 21 | loss: 0.5962430
	speed: 0.0267s/iter; left time: 491.9824s
Epoch: 21 cost time: 6.793652534484863
Epoch: 21, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5726 + XiCon Loss:2.8427 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
Validation loss decreased (1.076410 --> 1.076267).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6321951
	speed: 0.0324s/iter; left time: 592.2717s
	iters: 200, epoch: 22 | loss: 0.6179971
	speed: 0.0275s/iter; left time: 501.4847s
Epoch: 22 cost time: 6.890091896057129
Epoch: 22, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8403 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5845656
	speed: 0.0304s/iter; left time: 550.2763s
	iters: 200, epoch: 23 | loss: 0.6226885
	speed: 0.0280s/iter; left time: 503.7015s
Epoch: 23 cost time: 6.773653984069824
Epoch: 23, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8427 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5831106
	speed: 0.0312s/iter; left time: 555.9453s
	iters: 200, epoch: 24 | loss: 0.5685750
	speed: 0.0281s/iter; left time: 498.5304s
Epoch: 24 cost time: 6.959068298339844
Epoch: 24, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8449 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6701859
	speed: 0.0313s/iter; left time: 551.2240s
	iters: 200, epoch: 25 | loss: 0.6169471
	speed: 0.0276s/iter; left time: 483.7170s
Epoch: 25 cost time: 6.92348575592041
Epoch: 25, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8425 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
Validation loss decreased (1.076267 --> 1.076179).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6168907
	speed: 0.0314s/iter; left time: 544.7842s
	iters: 200, epoch: 26 | loss: 0.5768008
	speed: 0.0280s/iter; left time: 482.9067s
Epoch: 26 cost time: 6.907165050506592
Epoch: 26, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8414 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5914466
	speed: 0.0309s/iter; left time: 529.5920s
	iters: 200, epoch: 27 | loss: 0.6436061
	speed: 0.0278s/iter; left time: 473.7430s
Epoch: 27 cost time: 6.812194347381592
Epoch: 27, Steps: 233 Train Loss: 0.6010 (Forecasting Loss:0.5726 + XiCon Loss:2.8440 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5386907
	speed: 0.0308s/iter; left time: 521.0121s
	iters: 200, epoch: 28 | loss: 0.6060435
	speed: 0.0273s/iter; left time: 459.1077s
Epoch: 28 cost time: 6.74836802482605
Epoch: 28, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8409 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.6132254
	speed: 0.0319s/iter; left time: 531.5716s
	iters: 200, epoch: 29 | loss: 0.5930225
	speed: 0.0275s/iter; left time: 456.6253s
Epoch: 29 cost time: 6.903172969818115
Epoch: 29, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.0768 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6209957
	speed: 0.0320s/iter; left time: 526.2206s
	iters: 200, epoch: 30 | loss: 0.6290488
	speed: 0.0272s/iter; left time: 445.0522s
Epoch: 30 cost time: 6.852993965148926
Epoch: 30, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8408 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5779387
	speed: 0.0330s/iter; left time: 534.4784s
	iters: 200, epoch: 31 | loss: 0.5957848
	speed: 0.0274s/iter; left time: 441.8643s
Epoch: 31 cost time: 6.943731069564819
Epoch: 31, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8409 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6190468
	speed: 0.0311s/iter; left time: 496.6740s
	iters: 200, epoch: 32 | loss: 0.6276860
	speed: 0.0288s/iter; left time: 457.0551s
Epoch: 32 cost time: 6.857614278793335
Epoch: 32, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8413 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5661827
	speed: 0.0308s/iter; left time: 485.5688s
	iters: 200, epoch: 33 | loss: 0.6230910
	speed: 0.0268s/iter; left time: 419.0599s
Epoch: 33 cost time: 6.7306342124938965
Epoch: 33, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8399 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5755153
	speed: 0.0316s/iter; left time: 490.7888s
	iters: 200, epoch: 34 | loss: 0.5765260
	speed: 0.0272s/iter; left time: 419.1571s
Epoch: 34 cost time: 6.8767547607421875
Epoch: 34, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8401 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5998564
	speed: 0.0312s/iter; left time: 476.0987s
	iters: 200, epoch: 35 | loss: 0.6167544
	speed: 0.0276s/iter; left time: 419.0566s
Epoch: 35 cost time: 6.847233533859253
Epoch: 35, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8441 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.392856240272522, mae:0.8773899078369141, mape:6.102227687835693, mspe:4463.2802734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.1984
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1714249
	speed: 0.0319s/iter; left time: 739.2135s
	iters: 200, epoch: 1 | loss: 0.9895965
	speed: 0.0273s/iter; left time: 630.3810s
Epoch: 1 cost time: 6.852595090866089
Epoch: 1, Steps: 233 Train Loss: 1.0421 (Forecasting Loss:1.0137 + XiCon Loss:2.8476 x Lambda(0.01)), Vali MSE Loss: 1.8333 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833312).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6720341
	speed: 0.0309s/iter; left time: 709.0726s
	iters: 200, epoch: 2 | loss: 0.5786502
	speed: 0.0271s/iter; left time: 618.6577s
Epoch: 2 cost time: 6.65504789352417
Epoch: 2, Steps: 233 Train Loss: 0.6809 (Forecasting Loss:0.6525 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.1219 Test MSE Loss: 1.1452
Validation loss decreased (1.833312 --> 1.121906).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6091601
	speed: 0.0298s/iter; left time: 678.0426s
	iters: 200, epoch: 3 | loss: 0.5955121
	speed: 0.0269s/iter; left time: 608.6815s
Epoch: 3 cost time: 6.611919641494751
Epoch: 3, Steps: 233 Train Loss: 0.6166 (Forecasting Loss:0.5883 + XiCon Loss:2.8320 x Lambda(0.01)), Vali MSE Loss: 1.0999 Test MSE Loss: 1.1377
Validation loss decreased (1.121906 --> 1.099850).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6451733
	speed: 0.0306s/iter; left time: 689.5168s
	iters: 200, epoch: 4 | loss: 0.6228047
	speed: 0.0273s/iter; left time: 610.7875s
Epoch: 4 cost time: 6.730899095535278
Epoch: 4, Steps: 233 Train Loss: 0.6081 (Forecasting Loss:0.5797 + XiCon Loss:2.8319 x Lambda(0.01)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1365
Validation loss decreased (1.099850 --> 1.090969).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5743116
	speed: 0.0307s/iter; left time: 683.6783s
	iters: 200, epoch: 5 | loss: 0.5634343
	speed: 0.0268s/iter; left time: 594.3935s
Epoch: 5 cost time: 6.588223695755005
Epoch: 5, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5762 + XiCon Loss:2.8295 x Lambda(0.01)), Vali MSE Loss: 1.0870 Test MSE Loss: 1.1360
Validation loss decreased (1.090969 --> 1.086988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6134941
	speed: 0.0301s/iter; left time: 663.5045s
	iters: 200, epoch: 6 | loss: 0.6163032
	speed: 0.0269s/iter; left time: 589.4146s
Epoch: 6 cost time: 6.655951976776123
Epoch: 6, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5746 + XiCon Loss:2.8349 x Lambda(0.01)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1358
Validation loss decreased (1.086988 --> 1.085351).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5502841
	speed: 0.0305s/iter; left time: 664.2158s
	iters: 200, epoch: 7 | loss: 0.6519260
	speed: 0.0265s/iter; left time: 574.5057s
Epoch: 7 cost time: 6.674170970916748
Epoch: 7, Steps: 233 Train Loss: 0.6021 (Forecasting Loss:0.5738 + XiCon Loss:2.8300 x Lambda(0.01)), Vali MSE Loss: 1.0845 Test MSE Loss: 1.1357
Validation loss decreased (1.085351 --> 1.084530).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6007841
	speed: 0.0305s/iter; left time: 657.0581s
	iters: 200, epoch: 8 | loss: 0.5855168
	speed: 0.0273s/iter; left time: 586.7687s
Epoch: 8 cost time: 6.6134607791900635
Epoch: 8, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5733 + XiCon Loss:2.8293 x Lambda(0.01)), Vali MSE Loss: 1.0841 Test MSE Loss: 1.1356
Validation loss decreased (1.084530 --> 1.084123).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6287997
	speed: 0.0306s/iter; left time: 652.3918s
	iters: 200, epoch: 9 | loss: 0.5809449
	speed: 0.0278s/iter; left time: 589.3468s
Epoch: 9 cost time: 6.813406229019165
Epoch: 9, Steps: 233 Train Loss: 0.6015 (Forecasting Loss:0.5732 + XiCon Loss:2.8387 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1356
Validation loss decreased (1.084123 --> 1.083783).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5714104
	speed: 0.0283s/iter; left time: 596.2595s
	iters: 200, epoch: 10 | loss: 0.6032358
	speed: 0.0253s/iter; left time: 531.4110s
Epoch: 10 cost time: 6.208905458450317
Epoch: 10, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8339 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6035779
	speed: 0.0283s/iter; left time: 589.6159s
	iters: 200, epoch: 11 | loss: 0.6080403
	speed: 0.0251s/iter; left time: 521.5029s
Epoch: 11 cost time: 6.195077657699585
Epoch: 11, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8293 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083783 --> 1.083694).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5650230
	speed: 0.0287s/iter; left time: 592.5045s
	iters: 200, epoch: 12 | loss: 0.5662060
	speed: 0.0248s/iter; left time: 509.0746s
Epoch: 12 cost time: 6.201461315155029
Epoch: 12, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8301 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6472184
	speed: 0.0276s/iter; left time: 562.7281s
	iters: 200, epoch: 13 | loss: 0.5984371
	speed: 0.0264s/iter; left time: 536.6149s
Epoch: 13 cost time: 6.2583794593811035
Epoch: 13, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8322 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6058311
	speed: 0.0284s/iter; left time: 573.5587s
	iters: 200, epoch: 14 | loss: 0.6189322
	speed: 0.0254s/iter; left time: 508.9366s
Epoch: 14 cost time: 6.238443374633789
Epoch: 14, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8290 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5586150
	speed: 0.0283s/iter; left time: 564.0909s
	iters: 200, epoch: 15 | loss: 0.6096204
	speed: 0.0249s/iter; left time: 494.9336s
Epoch: 15 cost time: 6.200801134109497
Epoch: 15, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8302 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6041607
	speed: 0.0288s/iter; left time: 568.0998s
	iters: 200, epoch: 16 | loss: 0.5898481
	speed: 0.0254s/iter; left time: 498.2996s
Epoch: 16 cost time: 6.291446924209595
Epoch: 16, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8320 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5470075
	speed: 0.0294s/iter; left time: 571.6656s
	iters: 200, epoch: 17 | loss: 0.5743650
	speed: 0.0278s/iter; left time: 537.7462s
Epoch: 17 cost time: 6.621670961380005
Epoch: 17, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8321 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083694 --> 1.083669).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6113573
	speed: 0.0309s/iter; left time: 594.5587s
	iters: 200, epoch: 18 | loss: 0.5851607
	speed: 0.0272s/iter; left time: 519.8965s
Epoch: 18 cost time: 6.719835042953491
Epoch: 18, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8276 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5879814
	speed: 0.0304s/iter; left time: 576.8995s
	iters: 200, epoch: 19 | loss: 0.6146640
	speed: 0.0273s/iter; left time: 515.8165s
Epoch: 19 cost time: 6.6929497718811035
Epoch: 19, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5729 + XiCon Loss:2.8329 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6238567
	speed: 0.0302s/iter; left time: 567.4330s
	iters: 200, epoch: 20 | loss: 0.5718002
	speed: 0.0275s/iter; left time: 513.4397s
Epoch: 20 cost time: 6.687319993972778
Epoch: 20, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8303 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6763183
	speed: 0.0313s/iter; left time: 580.1200s
	iters: 200, epoch: 21 | loss: 0.5388624
	speed: 0.0270s/iter; left time: 498.1586s
Epoch: 21 cost time: 6.682875871658325
Epoch: 21, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5729 + XiCon Loss:2.8361 x Lambda(0.01)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
Validation loss decreased (1.083669 --> 1.083540).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5538362
	speed: 0.0306s/iter; left time: 560.5474s
	iters: 200, epoch: 22 | loss: 0.5861415
	speed: 0.0288s/iter; left time: 523.7071s
Epoch: 22 cost time: 6.856279373168945
Epoch: 22, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8330 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5919078
	speed: 0.0307s/iter; left time: 554.3551s
	iters: 200, epoch: 23 | loss: 0.6487213
	speed: 0.0269s/iter; left time: 484.0738s
Epoch: 23 cost time: 6.712514638900757
Epoch: 23, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8287 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5571628
	speed: 0.0303s/iter; left time: 540.3940s
	iters: 200, epoch: 24 | loss: 0.6195236
	speed: 0.0270s/iter; left time: 479.5599s
Epoch: 24 cost time: 6.610864162445068
Epoch: 24, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8314 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6602533
	speed: 0.0305s/iter; left time: 536.7087s
	iters: 200, epoch: 25 | loss: 0.5236300
	speed: 0.0274s/iter; left time: 480.2640s
Epoch: 25 cost time: 6.75394344329834
Epoch: 25, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8287 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6257904
	speed: 0.0305s/iter; left time: 530.1534s
	iters: 200, epoch: 26 | loss: 0.6082669
	speed: 0.0270s/iter; left time: 466.1260s
Epoch: 26 cost time: 6.689730405807495
Epoch: 26, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8272 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5979536
	speed: 0.0316s/iter; left time: 542.0657s
	iters: 200, epoch: 27 | loss: 0.6400971
	speed: 0.0273s/iter; left time: 465.0463s
Epoch: 27 cost time: 6.816791772842407
Epoch: 27, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5729 + XiCon Loss:2.8239 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5966337
	speed: 0.0310s/iter; left time: 523.4493s
	iters: 200, epoch: 28 | loss: 0.6077265
	speed: 0.0277s/iter; left time: 466.4102s
Epoch: 28 cost time: 6.703074932098389
Epoch: 28, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8319 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5797757
	speed: 0.0304s/iter; left time: 507.2435s
	iters: 200, epoch: 29 | loss: 0.6001810
	speed: 0.0273s/iter; left time: 452.9197s
Epoch: 29 cost time: 6.7549402713775635
Epoch: 29, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8351 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6065677
	speed: 0.0304s/iter; left time: 499.1641s
	iters: 200, epoch: 30 | loss: 0.5588173
	speed: 0.0279s/iter; left time: 456.5860s
Epoch: 30 cost time: 6.737194299697876
Epoch: 30, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8311 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5526617
	speed: 0.0313s/iter; left time: 507.2816s
	iters: 200, epoch: 31 | loss: 0.5893019
	speed: 0.0267s/iter; left time: 430.4618s
Epoch: 31 cost time: 6.6743409633636475
Epoch: 31, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8318 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.391650676727295, mae:0.8793810606002808, mape:6.1659674644470215, mspe:4547.36474609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5466
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0496676
	speed: 0.0322s/iter; left time: 746.7507s
	iters: 200, epoch: 1 | loss: 1.0161712
	speed: 0.0276s/iter; left time: 638.6262s
Epoch: 1 cost time: 6.96030855178833
Epoch: 1, Steps: 233 Train Loss: 1.0564 (Forecasting Loss:1.0277 + XiCon Loss:2.8675 x Lambda(0.01)), Vali MSE Loss: 1.8645 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864499).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6534232
	speed: 0.0309s/iter; left time: 709.1066s
	iters: 200, epoch: 2 | loss: 0.6267546
	speed: 0.0270s/iter; left time: 616.7731s
Epoch: 2 cost time: 6.652374505996704
Epoch: 2, Steps: 233 Train Loss: 0.6831 (Forecasting Loss:0.6545 + XiCon Loss:2.8627 x Lambda(0.01)), Vali MSE Loss: 1.1221 Test MSE Loss: 1.1462
Validation loss decreased (1.864499 --> 1.122147).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6340885
	speed: 0.0311s/iter; left time: 706.4636s
	iters: 200, epoch: 3 | loss: 0.6678904
	speed: 0.0268s/iter; left time: 606.8595s
Epoch: 3 cost time: 6.768538475036621
Epoch: 3, Steps: 233 Train Loss: 0.6179 (Forecasting Loss:0.5893 + XiCon Loss:2.8582 x Lambda(0.01)), Vali MSE Loss: 1.1027 Test MSE Loss: 1.1399
Validation loss decreased (1.122147 --> 1.102651).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5703903
	speed: 0.0304s/iter; left time: 685.1092s
	iters: 200, epoch: 4 | loss: 0.6290452
	speed: 0.0273s/iter; left time: 611.0445s
Epoch: 4 cost time: 6.743506908416748
Epoch: 4, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5810 + XiCon Loss:2.8524 x Lambda(0.01)), Vali MSE Loss: 1.0940 Test MSE Loss: 1.1380
Validation loss decreased (1.102651 --> 1.094047).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5866316
	speed: 0.0308s/iter; left time: 685.7281s
	iters: 200, epoch: 5 | loss: 0.5867913
	speed: 0.0272s/iter; left time: 602.8231s
Epoch: 5 cost time: 6.7458062171936035
Epoch: 5, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5776 + XiCon Loss:2.8516 x Lambda(0.01)), Vali MSE Loss: 1.0906 Test MSE Loss: 1.1375
Validation loss decreased (1.094047 --> 1.090586).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5883380
	speed: 0.0303s/iter; left time: 667.8622s
	iters: 200, epoch: 6 | loss: 0.6272047
	speed: 0.0271s/iter; left time: 594.0759s
Epoch: 6 cost time: 6.654405832290649
Epoch: 6, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5760 + XiCon Loss:2.8568 x Lambda(0.01)), Vali MSE Loss: 1.0885 Test MSE Loss: 1.1374
Validation loss decreased (1.090586 --> 1.088503).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6096584
	speed: 0.0303s/iter; left time: 661.0177s
	iters: 200, epoch: 7 | loss: 0.6282198
	speed: 0.0273s/iter; left time: 591.9375s
Epoch: 7 cost time: 6.651130676269531
Epoch: 7, Steps: 233 Train Loss: 0.6036 (Forecasting Loss:0.5751 + XiCon Loss:2.8514 x Lambda(0.01)), Vali MSE Loss: 1.0875 Test MSE Loss: 1.1374
Validation loss decreased (1.088503 --> 1.087472).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6315080
	speed: 0.0301s/iter; left time: 648.2157s
	iters: 200, epoch: 8 | loss: 0.5880308
	speed: 0.0276s/iter; left time: 591.7701s
Epoch: 8 cost time: 6.730157852172852
Epoch: 8, Steps: 233 Train Loss: 0.6032 (Forecasting Loss:0.5747 + XiCon Loss:2.8504 x Lambda(0.01)), Vali MSE Loss: 1.0871 Test MSE Loss: 1.1373
Validation loss decreased (1.087472 --> 1.087138).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6220391
	speed: 0.0299s/iter; left time: 637.4119s
	iters: 200, epoch: 9 | loss: 0.6599571
	speed: 0.0272s/iter; left time: 577.1378s
Epoch: 9 cost time: 6.633883714675903
Epoch: 9, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5744 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0867 Test MSE Loss: 1.1373
Validation loss decreased (1.087138 --> 1.086657).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6179556
	speed: 0.0298s/iter; left time: 628.6427s
	iters: 200, epoch: 10 | loss: 0.5808643
	speed: 0.0272s/iter; left time: 571.8571s
Epoch: 10 cost time: 6.633906126022339
Epoch: 10, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5743 + XiCon Loss:2.8538 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
Validation loss decreased (1.086657 --> 1.086514).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5985767
	speed: 0.0308s/iter; left time: 642.6668s
	iters: 200, epoch: 11 | loss: 0.6054538
	speed: 0.0267s/iter; left time: 553.6818s
Epoch: 11 cost time: 6.6137611865997314
Epoch: 11, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5743 + XiCon Loss:2.8538 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
Validation loss decreased (1.086514 --> 1.086421).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6320177
	speed: 0.0299s/iter; left time: 617.2153s
	iters: 200, epoch: 12 | loss: 0.5586712
	speed: 0.0269s/iter; left time: 552.3556s
Epoch: 12 cost time: 6.661471128463745
Epoch: 12, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8555 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6261222
	speed: 0.0300s/iter; left time: 612.2148s
	iters: 200, epoch: 13 | loss: 0.5866951
	speed: 0.0274s/iter; left time: 556.1134s
Epoch: 13 cost time: 6.672513484954834
Epoch: 13, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8491 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5929219
	speed: 0.0308s/iter; left time: 620.7605s
	iters: 200, epoch: 14 | loss: 0.6543794
	speed: 0.0271s/iter; left time: 544.6013s
Epoch: 14 cost time: 6.718664169311523
Epoch: 14, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8518 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6293719
	speed: 0.0304s/iter; left time: 606.8108s
	iters: 200, epoch: 15 | loss: 0.6115752
	speed: 0.0270s/iter; left time: 534.9635s
Epoch: 15 cost time: 6.612873792648315
Epoch: 15, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8526 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6153459
	speed: 0.0297s/iter; left time: 584.4124s
	iters: 200, epoch: 16 | loss: 0.6174459
	speed: 0.0268s/iter; left time: 525.3126s
Epoch: 16 cost time: 6.5854809284210205
Epoch: 16, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8529 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
Validation loss decreased (1.086421 --> 1.086154).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5168749
	speed: 0.0299s/iter; left time: 581.3968s
	iters: 200, epoch: 17 | loss: 0.6870386
	speed: 0.0270s/iter; left time: 523.3769s
Epoch: 17 cost time: 6.5966408252716064
Epoch: 17, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8546 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6099573
	speed: 0.0303s/iter; left time: 583.8823s
	iters: 200, epoch: 18 | loss: 0.5911243
	speed: 0.0253s/iter; left time: 484.8845s
Epoch: 18 cost time: 6.444441795349121
Epoch: 18, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8533 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6158949
	speed: 0.0281s/iter; left time: 534.5363s
	iters: 200, epoch: 19 | loss: 0.6664442
	speed: 0.0250s/iter; left time: 473.4009s
Epoch: 19 cost time: 6.16733193397522
Epoch: 19, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8528 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086154 --> 1.086145).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6603298
	speed: 0.0277s/iter; left time: 520.8743s
	iters: 200, epoch: 20 | loss: 0.6222275
	speed: 0.0251s/iter; left time: 468.9177s
Epoch: 20 cost time: 6.16781759262085
Epoch: 20, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8548 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5815513
	speed: 0.0279s/iter; left time: 517.2889s
	iters: 200, epoch: 21 | loss: 0.5918990
	speed: 0.0251s/iter; left time: 462.9580s
Epoch: 21 cost time: 6.1433961391448975
Epoch: 21, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8462 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6145840
	speed: 0.0294s/iter; left time: 537.3745s
	iters: 200, epoch: 22 | loss: 0.5564036
	speed: 0.0255s/iter; left time: 464.8560s
Epoch: 22 cost time: 6.35909366607666
Epoch: 22, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8504 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5674047
	speed: 0.0280s/iter; left time: 505.8419s
	iters: 200, epoch: 23 | loss: 0.6103236
	speed: 0.0250s/iter; left time: 448.7232s
Epoch: 23 cost time: 6.172970533370972
Epoch: 23, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5955753
	speed: 0.0284s/iter; left time: 506.9063s
	iters: 200, epoch: 24 | loss: 0.6253070
	speed: 0.0252s/iter; left time: 446.5812s
Epoch: 24 cost time: 6.199297189712524
Epoch: 24, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8460 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5674109
	speed: 0.0281s/iter; left time: 494.8809s
	iters: 200, epoch: 25 | loss: 0.6047082
	speed: 0.0252s/iter; left time: 441.6415s
Epoch: 25 cost time: 6.17140531539917
Epoch: 25, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8522 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6470995
	speed: 0.0305s/iter; left time: 529.8106s
	iters: 200, epoch: 26 | loss: 0.6154068
	speed: 0.0265s/iter; left time: 457.7010s
Epoch: 26 cost time: 6.680464744567871
Epoch: 26, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8552 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6329345
	speed: 0.0293s/iter; left time: 502.9948s
	iters: 200, epoch: 27 | loss: 0.5690459
	speed: 0.0273s/iter; left time: 465.7141s
Epoch: 27 cost time: 6.578648328781128
Epoch: 27, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8492 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6248965
	speed: 0.0306s/iter; left time: 516.8590s
	iters: 200, epoch: 28 | loss: 0.6097899
	speed: 0.0277s/iter; left time: 465.1173s
Epoch: 28 cost time: 6.674902439117432
Epoch: 28, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8513 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5848969
	speed: 0.0298s/iter; left time: 496.2334s
	iters: 200, epoch: 29 | loss: 0.6224576
	speed: 0.0272s/iter; left time: 450.7013s
Epoch: 29 cost time: 6.678509950637817
Epoch: 29, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5740 + XiCon Loss:2.8516 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086145 --> 1.086091).  Saving model ...
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5753884
	speed: 0.0301s/iter; left time: 494.3792s
	iters: 200, epoch: 30 | loss: 0.5546747
	speed: 0.0277s/iter; left time: 452.7717s
Epoch: 30 cost time: 6.689419507980347
Epoch: 30, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8550 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5821471
	speed: 0.0308s/iter; left time: 499.7229s
	iters: 200, epoch: 31 | loss: 0.6048759
	speed: 0.0280s/iter; left time: 451.1419s
Epoch: 31 cost time: 6.787132501602173
Epoch: 31, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8483 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5874636
	speed: 0.0298s/iter; left time: 476.9258s
	iters: 200, epoch: 32 | loss: 0.5801301
	speed: 0.0271s/iter; left time: 430.6467s
Epoch: 32 cost time: 6.661322355270386
Epoch: 32, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8482 x Lambda(0.01)), Vali MSE Loss: 1.0868 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5585869
	speed: 0.0307s/iter; left time: 484.1465s
	iters: 200, epoch: 33 | loss: 0.6584328
	speed: 0.0270s/iter; left time: 421.7737s
Epoch: 33 cost time: 6.7270262241363525
Epoch: 33, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8558 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5811053
	speed: 0.0311s/iter; left time: 482.1900s
	iters: 200, epoch: 34 | loss: 0.5709287
	speed: 0.0267s/iter; left time: 412.2654s
Epoch: 34 cost time: 6.754170656204224
Epoch: 34, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5741 + XiCon Loss:2.8498 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5713642
	speed: 0.0303s/iter; left time: 462.4640s
	iters: 200, epoch: 35 | loss: 0.6260404
	speed: 0.0278s/iter; left time: 421.6362s
Epoch: 35 cost time: 6.670464515686035
Epoch: 35, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8467 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6271227
	speed: 0.0300s/iter; left time: 451.7517s
	iters: 200, epoch: 36 | loss: 0.5714674
	speed: 0.0274s/iter; left time: 409.0558s
Epoch: 36 cost time: 6.7196526527404785
Epoch: 36, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8490 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5759268
	speed: 0.0300s/iter; left time: 444.3827s
	iters: 200, epoch: 37 | loss: 0.6195455
	speed: 0.0279s/iter; left time: 411.1167s
Epoch: 37 cost time: 6.735597133636475
Epoch: 37, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8532 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5937718
	speed: 0.0300s/iter; left time: 437.5717s
	iters: 200, epoch: 38 | loss: 0.5829413
	speed: 0.0271s/iter; left time: 392.4109s
Epoch: 38 cost time: 6.60469388961792
Epoch: 38, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8531 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.6070929
	speed: 0.0301s/iter; left time: 431.4647s
	iters: 200, epoch: 39 | loss: 0.5807859
	speed: 0.0286s/iter; left time: 407.1119s
Epoch: 39 cost time: 6.789475202560425
Epoch: 39, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3957111835479736, mae:0.8787950873374939, mape:6.154982089996338, mspe:4557.46875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0718
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0413216
	speed: 0.0318s/iter; left time: 736.7985s
	iters: 200, epoch: 1 | loss: 0.9861708
	speed: 0.0276s/iter; left time: 636.5469s
Epoch: 1 cost time: 6.868630647659302
Epoch: 1, Steps: 233 Train Loss: 1.0562 (Forecasting Loss:1.0279 + XiCon Loss:2.8258 x Lambda(0.01)), Vali MSE Loss: 1.8929 Test MSE Loss: 1.2473
Validation loss decreased (inf --> 1.892945).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6888902
	speed: 0.0312s/iter; left time: 717.3062s
	iters: 200, epoch: 2 | loss: 0.6088138
	speed: 0.0281s/iter; left time: 641.6116s
Epoch: 2 cost time: 6.771590232849121
Epoch: 2, Steps: 233 Train Loss: 0.6853 (Forecasting Loss:0.6569 + XiCon Loss:2.8355 x Lambda(0.01)), Vali MSE Loss: 1.1382 Test MSE Loss: 1.1436
Validation loss decreased (1.892945 --> 1.138160).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6504736
	speed: 0.0305s/iter; left time: 694.5347s
	iters: 200, epoch: 3 | loss: 0.5844799
	speed: 0.0274s/iter; left time: 620.1605s
Epoch: 3 cost time: 6.726415395736694
Epoch: 3, Steps: 233 Train Loss: 0.6204 (Forecasting Loss:0.5921 + XiCon Loss:2.8309 x Lambda(0.01)), Vali MSE Loss: 1.1169 Test MSE Loss: 1.1349
Validation loss decreased (1.138160 --> 1.116902).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6555698
	speed: 0.0320s/iter; left time: 720.7636s
	iters: 200, epoch: 4 | loss: 0.6061963
	speed: 0.0287s/iter; left time: 643.7857s
Epoch: 4 cost time: 7.056766748428345
Epoch: 4, Steps: 233 Train Loss: 0.6124 (Forecasting Loss:0.5840 + XiCon Loss:2.8357 x Lambda(0.01)), Vali MSE Loss: 1.1090 Test MSE Loss: 1.1334
Validation loss decreased (1.116902 --> 1.108989).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6236994
	speed: 0.0313s/iter; left time: 697.3046s
	iters: 200, epoch: 5 | loss: 0.6067202
	speed: 0.0279s/iter; left time: 618.0373s
Epoch: 5 cost time: 6.9375669956207275
Epoch: 5, Steps: 233 Train Loss: 0.6091 (Forecasting Loss:0.5808 + XiCon Loss:2.8295 x Lambda(0.01)), Vali MSE Loss: 1.1057 Test MSE Loss: 1.1327
Validation loss decreased (1.108989 --> 1.105673).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6039370
	speed: 0.0320s/iter; left time: 705.9732s
	iters: 200, epoch: 6 | loss: 0.6603553
	speed: 0.0278s/iter; left time: 610.6865s
Epoch: 6 cost time: 6.993528366088867
Epoch: 6, Steps: 233 Train Loss: 0.6077 (Forecasting Loss:0.5794 + XiCon Loss:2.8325 x Lambda(0.01)), Vali MSE Loss: 1.1043 Test MSE Loss: 1.1324
Validation loss decreased (1.105673 --> 1.104317).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6161928
	speed: 0.0311s/iter; left time: 677.9553s
	iters: 200, epoch: 7 | loss: 0.6094625
	speed: 0.0288s/iter; left time: 625.8096s
Epoch: 7 cost time: 6.911748647689819
Epoch: 7, Steps: 233 Train Loss: 0.6070 (Forecasting Loss:0.5786 + XiCon Loss:2.8338 x Lambda(0.01)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1323
Validation loss decreased (1.104317 --> 1.103109).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5786451
	speed: 0.0307s/iter; left time: 662.4422s
	iters: 200, epoch: 8 | loss: 0.6439432
	speed: 0.0275s/iter; left time: 591.4293s
Epoch: 8 cost time: 6.834045886993408
Epoch: 8, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5782 + XiCon Loss:2.8285 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1323
Validation loss decreased (1.103109 --> 1.102558).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5940909
	speed: 0.0309s/iter; left time: 659.8659s
	iters: 200, epoch: 9 | loss: 0.6275589
	speed: 0.0274s/iter; left time: 582.6012s
Epoch: 9 cost time: 6.8049156665802
Epoch: 9, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5781 + XiCon Loss:2.8341 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5806111
	speed: 0.0322s/iter; left time: 678.5984s
	iters: 200, epoch: 10 | loss: 0.6052958
	speed: 0.0274s/iter; left time: 574.5663s
Epoch: 10 cost time: 6.888445854187012
Epoch: 10, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5779 + XiCon Loss:2.8306 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5680168
	speed: 0.0318s/iter; left time: 663.2690s
	iters: 200, epoch: 11 | loss: 0.5781316
	speed: 0.0285s/iter; left time: 591.6796s
Epoch: 11 cost time: 7.006416320800781
Epoch: 11, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5779 + XiCon Loss:2.8352 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102558 --> 1.102221).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5802798
	speed: 0.0319s/iter; left time: 657.7848s
	iters: 200, epoch: 12 | loss: 0.6426473
	speed: 0.0277s/iter; left time: 569.8476s
Epoch: 12 cost time: 6.9106526374816895
Epoch: 12, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8313 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6214004
	speed: 0.0325s/iter; left time: 663.1205s
	iters: 200, epoch: 13 | loss: 0.5975249
	speed: 0.0274s/iter; left time: 555.8204s
Epoch: 13 cost time: 6.939186096191406
Epoch: 13, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5683733
	speed: 0.0312s/iter; left time: 629.0352s
	iters: 200, epoch: 14 | loss: 0.5923156
	speed: 0.0273s/iter; left time: 548.7431s
Epoch: 14 cost time: 6.708374261856079
Epoch: 14, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8340 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5943081
	speed: 0.0306s/iter; left time: 609.9488s
	iters: 200, epoch: 15 | loss: 0.6254752
	speed: 0.0274s/iter; left time: 544.2894s
Epoch: 15 cost time: 6.771958351135254
Epoch: 15, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102221 --> 1.102175).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6384771
	speed: 0.0309s/iter; left time: 608.4499s
	iters: 200, epoch: 16 | loss: 0.5900980
	speed: 0.0269s/iter; left time: 528.1996s
Epoch: 16 cost time: 6.710161924362183
Epoch: 16, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8353 x Lambda(0.01)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1322
Validation loss decreased (1.102175 --> 1.102007).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6076787
	speed: 0.0320s/iter; left time: 623.5864s
	iters: 200, epoch: 17 | loss: 0.6305854
	speed: 0.0276s/iter; left time: 535.0027s
Epoch: 17 cost time: 6.959107398986816
Epoch: 17, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8276 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6296722
	speed: 0.0311s/iter; left time: 598.2036s
	iters: 200, epoch: 18 | loss: 0.6149481
	speed: 0.0265s/iter; left time: 506.2987s
Epoch: 18 cost time: 6.626345872879028
Epoch: 18, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8358 x Lambda(0.01)), Vali MSE Loss: 1.1019 Test MSE Loss: 1.1322
Validation loss decreased (1.102007 --> 1.101875).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5860016
	speed: 0.0299s/iter; left time: 567.4016s
	iters: 200, epoch: 19 | loss: 0.6599480
	speed: 0.0257s/iter; left time: 485.9134s
Epoch: 19 cost time: 6.419501066207886
Epoch: 19, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5777 + XiCon Loss:2.8318 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6081274
	speed: 0.0299s/iter; left time: 560.9403s
	iters: 200, epoch: 20 | loss: 0.5809803
	speed: 0.0253s/iter; left time: 473.2618s
Epoch: 20 cost time: 6.375448942184448
Epoch: 20, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5777 + XiCon Loss:2.8313 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6256302
	speed: 0.0300s/iter; left time: 555.7313s
	iters: 200, epoch: 21 | loss: 0.6178707
	speed: 0.0254s/iter; left time: 467.8674s
Epoch: 21 cost time: 6.371280908584595
Epoch: 21, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5777 + XiCon Loss:2.8334 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6259816
	speed: 0.0313s/iter; left time: 572.9731s
	iters: 200, epoch: 22 | loss: 0.5811324
	speed: 0.0260s/iter; left time: 472.5013s
Epoch: 22 cost time: 6.599977016448975
Epoch: 22, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8335 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6264582
	speed: 0.0299s/iter; left time: 540.6495s
	iters: 200, epoch: 23 | loss: 0.6047463
	speed: 0.0253s/iter; left time: 454.8146s
Epoch: 23 cost time: 6.39056921005249
Epoch: 23, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8298 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6326255
	speed: 0.0298s/iter; left time: 532.3556s
	iters: 200, epoch: 24 | loss: 0.5580654
	speed: 0.0254s/iter; left time: 451.0410s
Epoch: 24 cost time: 6.397588729858398
Epoch: 24, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8261 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6500501
	speed: 0.0294s/iter; left time: 518.3616s
	iters: 200, epoch: 25 | loss: 0.5952626
	speed: 0.0256s/iter; left time: 447.7485s
Epoch: 25 cost time: 6.456233024597168
Epoch: 25, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8365 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6094379
	speed: 0.0312s/iter; left time: 541.2636s
	iters: 200, epoch: 26 | loss: 0.6293295
	speed: 0.0274s/iter; left time: 472.6510s
Epoch: 26 cost time: 6.79538631439209
Epoch: 26, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6452216
	speed: 0.0312s/iter; left time: 534.0468s
	iters: 200, epoch: 27 | loss: 0.5714726
	speed: 0.0276s/iter; left time: 470.0294s
Epoch: 27 cost time: 6.798346519470215
Epoch: 27, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5780 + XiCon Loss:2.8302 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5414517
	speed: 0.0313s/iter; left time: 529.7039s
	iters: 200, epoch: 28 | loss: 0.5717974
	speed: 0.0273s/iter; left time: 458.2327s
Epoch: 28 cost time: 6.73880410194397
Epoch: 28, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5776 + XiCon Loss:2.8330 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.389219880104065, mae:0.8751696348190308, mape:6.027244567871094, mspe:4359.69970703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3938+-0.00489, MAE:0.8781+-0.00230, MAPE:6.1176+-0.06953, MSPE:4494.7842+-104.93421, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.1228353
	speed: 0.0569s/iter; left time: 1285.0233s
	iters: 200, epoch: 1 | loss: 1.0329202
	speed: 0.0511s/iter; left time: 1150.5162s
Epoch: 1 cost time: 12.174059391021729
Epoch: 1, Steps: 227 Train Loss: 1.0531 (Forecasting Loss:1.0262 + XiCon Loss:2.6947 x Lambda(0.01)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.935983).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6556941
	speed: 0.0530s/iter; left time: 1186.7725s
	iters: 200, epoch: 2 | loss: 0.6381084
	speed: 0.0498s/iter; left time: 1108.2824s
Epoch: 2 cost time: 11.629560947418213
Epoch: 2, Steps: 227 Train Loss: 0.6958 (Forecasting Loss:0.6689 + XiCon Loss:2.6908 x Lambda(0.01)), Vali MSE Loss: 1.2109 Test MSE Loss: 1.2835
Validation loss decreased (1.935983 --> 1.210935).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6475431
	speed: 0.0530s/iter; left time: 1172.7071s
	iters: 200, epoch: 3 | loss: 0.6496229
	speed: 0.0503s/iter; left time: 1109.2063s
Epoch: 3 cost time: 11.735588073730469
Epoch: 3, Steps: 227 Train Loss: 0.6326 (Forecasting Loss:0.6058 + XiCon Loss:2.6835 x Lambda(0.01)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2756
Validation loss decreased (1.210935 --> 1.187705).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6149346
	speed: 0.0524s/iter; left time: 1149.1894s
	iters: 200, epoch: 4 | loss: 0.6032540
	speed: 0.0505s/iter; left time: 1101.3752s
Epoch: 4 cost time: 11.686210870742798
Epoch: 4, Steps: 227 Train Loss: 0.6247 (Forecasting Loss:0.5979 + XiCon Loss:2.6816 x Lambda(0.01)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2735
Validation loss decreased (1.187705 --> 1.181765).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6133398
	speed: 0.0543s/iter; left time: 1176.9256s
	iters: 200, epoch: 5 | loss: 0.6527630
	speed: 0.0529s/iter; left time: 1143.1617s
Epoch: 5 cost time: 12.17723536491394
Epoch: 5, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5947 + XiCon Loss:2.6822 x Lambda(0.01)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2724
Validation loss decreased (1.181765 --> 1.179006).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6119237
	speed: 0.0557s/iter; left time: 1194.8486s
	iters: 200, epoch: 6 | loss: 0.6345823
	speed: 0.0520s/iter; left time: 1110.6268s
Epoch: 6 cost time: 12.157280683517456
Epoch: 6, Steps: 227 Train Loss: 0.6200 (Forecasting Loss:0.5932 + XiCon Loss:2.6752 x Lambda(0.01)), Vali MSE Loss: 1.1771 Test MSE Loss: 1.2721
Validation loss decreased (1.179006 --> 1.177054).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5643040
	speed: 0.0541s/iter; left time: 1149.1372s
	iters: 200, epoch: 7 | loss: 0.5906338
	speed: 0.0550s/iter; left time: 1162.8978s
Epoch: 7 cost time: 12.306679010391235
Epoch: 7, Steps: 227 Train Loss: 0.6192 (Forecasting Loss:0.5924 + XiCon Loss:2.6791 x Lambda(0.01)), Vali MSE Loss: 1.1765 Test MSE Loss: 1.2718
Validation loss decreased (1.177054 --> 1.176488).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6419063
	speed: 0.0552s/iter; left time: 1160.5304s
	iters: 200, epoch: 8 | loss: 0.6842192
	speed: 0.0499s/iter; left time: 1043.5182s
Epoch: 8 cost time: 11.91607403755188
Epoch: 8, Steps: 227 Train Loss: 0.6188 (Forecasting Loss:0.5920 + XiCon Loss:2.6780 x Lambda(0.01)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2717
Validation loss decreased (1.176488 --> 1.175587).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6094388
	speed: 0.0532s/iter; left time: 1106.2261s
	iters: 200, epoch: 9 | loss: 0.6433517
	speed: 0.0536s/iter; left time: 1107.9449s
Epoch: 9 cost time: 12.120027780532837
Epoch: 9, Steps: 227 Train Loss: 0.6186 (Forecasting Loss:0.5918 + XiCon Loss:2.6806 x Lambda(0.01)), Vali MSE Loss: 1.1760 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5785246
	speed: 0.0540s/iter; left time: 1109.9787s
	iters: 200, epoch: 10 | loss: 0.6142206
	speed: 0.0521s/iter; left time: 1066.2166s
Epoch: 10 cost time: 12.03062129020691
Epoch: 10, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5918 + XiCon Loss:2.6772 x Lambda(0.01)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2716
Validation loss decreased (1.175587 --> 1.175567).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6130515
	speed: 0.0572s/iter; left time: 1162.3478s
	iters: 200, epoch: 11 | loss: 0.6418457
	speed: 0.0508s/iter; left time: 1027.3869s
Epoch: 11 cost time: 12.211246490478516
Epoch: 11, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5915 + XiCon Loss:2.6805 x Lambda(0.01)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2716
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6126820
	speed: 0.0549s/iter; left time: 1104.3235s
	iters: 200, epoch: 12 | loss: 0.6089808
	speed: 0.0518s/iter; left time: 1037.0157s
Epoch: 12 cost time: 12.081745147705078
Epoch: 12, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5916 + XiCon Loss:2.6780 x Lambda(0.01)), Vali MSE Loss: 1.1752 Test MSE Loss: 1.2716
Validation loss decreased (1.175567 --> 1.175192).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5737608
	speed: 0.0537s/iter; left time: 1067.5111s
	iters: 200, epoch: 13 | loss: 0.5995390
	speed: 0.0512s/iter; left time: 1012.3137s
Epoch: 13 cost time: 11.925689935684204
Epoch: 13, Steps: 227 Train Loss: 0.6186 (Forecasting Loss:0.5918 + XiCon Loss:2.6771 x Lambda(0.01)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2716
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6330369
	speed: 0.0551s/iter; left time: 1082.4975s
	iters: 200, epoch: 14 | loss: 0.6024890
	speed: 0.0510s/iter; left time: 997.2082s
Epoch: 14 cost time: 12.029297828674316
Epoch: 14, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5917 + XiCon Loss:2.6765 x Lambda(0.01)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2716
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5653640
	speed: 0.0548s/iter; left time: 1064.1843s
	iters: 200, epoch: 15 | loss: 0.6145359
	speed: 0.0513s/iter; left time: 991.3902s
Epoch: 15 cost time: 11.972363948822021
Epoch: 15, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5917 + XiCon Loss:2.6751 x Lambda(0.01)), Vali MSE Loss: 1.1762 Test MSE Loss: 1.2716
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6252919
	speed: 0.0531s/iter; left time: 1019.6951s
	iters: 200, epoch: 16 | loss: 0.6166793
	speed: 0.0541s/iter; left time: 1033.7317s
Epoch: 16 cost time: 12.117019891738892
Epoch: 16, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5915 + XiCon Loss:2.6808 x Lambda(0.01)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2716
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6417646
	speed: 0.0550s/iter; left time: 1043.1352s
	iters: 200, epoch: 17 | loss: 0.5881543
	speed: 0.0512s/iter; left time: 966.5775s
Epoch: 17 cost time: 12.03352975845337
Epoch: 17, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5916 + XiCon Loss:2.6739 x Lambda(0.01)), Vali MSE Loss: 1.1759 Test MSE Loss: 1.2716
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6001108
	speed: 0.0510s/iter; left time: 955.8487s
	iters: 200, epoch: 18 | loss: 0.6340860
	speed: 0.0481s/iter; left time: 896.4113s
Epoch: 18 cost time: 11.249257326126099
Epoch: 18, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5917 + XiCon Loss:2.6777 x Lambda(0.01)), Vali MSE Loss: 1.1751 Test MSE Loss: 1.2716
Validation loss decreased (1.175192 --> 1.175080).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6623322
	speed: 0.0534s/iter; left time: 988.9824s
	iters: 200, epoch: 19 | loss: 0.6472021
	speed: 0.0499s/iter; left time: 919.2193s
Epoch: 19 cost time: 11.689581632614136
Epoch: 19, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6819 x Lambda(0.01)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2716
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5686123
	speed: 0.0525s/iter; left time: 960.7280s
	iters: 200, epoch: 20 | loss: 0.5779613
	speed: 0.0502s/iter; left time: 912.2738s
Epoch: 20 cost time: 11.589172601699829
Epoch: 20, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6804 x Lambda(0.01)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2716
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6340499
	speed: 0.0512s/iter; left time: 924.9680s
	iters: 200, epoch: 21 | loss: 0.6046800
	speed: 0.0518s/iter; left time: 930.4666s
Epoch: 21 cost time: 11.70526909828186
Epoch: 21, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6805 x Lambda(0.01)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2716
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6093879
	speed: 0.0564s/iter; left time: 1005.5526s
	iters: 200, epoch: 22 | loss: 0.6590722
	speed: 0.0505s/iter; left time: 895.1646s
Epoch: 22 cost time: 12.295121431350708
Epoch: 22, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5917 + XiCon Loss:2.6786 x Lambda(0.01)), Vali MSE Loss: 1.1750 Test MSE Loss: 1.2716
Validation loss decreased (1.175080 --> 1.175007).  Saving model ...
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6594877
	speed: 0.0553s/iter; left time: 972.9159s
	iters: 200, epoch: 23 | loss: 0.6185299
	speed: 0.0513s/iter; left time: 898.0480s
Epoch: 23 cost time: 12.151273965835571
Epoch: 23, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6819 x Lambda(0.01)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2716
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6119215
	speed: 0.0534s/iter; left time: 928.7099s
	iters: 200, epoch: 24 | loss: 0.6338341
	speed: 0.0508s/iter; left time: 878.6549s
Epoch: 24 cost time: 11.844193935394287
Epoch: 24, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5917 + XiCon Loss:2.6793 x Lambda(0.01)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2716
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5940600
	speed: 0.0530s/iter; left time: 909.5184s
	iters: 200, epoch: 25 | loss: 0.6512436
	speed: 0.0536s/iter; left time: 913.5997s
Epoch: 25 cost time: 12.087942361831665
Epoch: 25, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6800 x Lambda(0.01)), Vali MSE Loss: 1.1758 Test MSE Loss: 1.2716
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6229742
	speed: 0.0558s/iter; left time: 944.4135s
	iters: 200, epoch: 26 | loss: 0.5938474
	speed: 0.0507s/iter; left time: 853.3396s
Epoch: 26 cost time: 12.02627682685852
Epoch: 26, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5915 + XiCon Loss:2.6773 x Lambda(0.01)), Vali MSE Loss: 1.1759 Test MSE Loss: 1.2716
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6364115
	speed: 0.0531s/iter; left time: 886.4628s
	iters: 200, epoch: 27 | loss: 0.6168989
	speed: 0.0526s/iter; left time: 873.3452s
Epoch: 27 cost time: 11.968289136886597
Epoch: 27, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5915 + XiCon Loss:2.6800 x Lambda(0.01)), Vali MSE Loss: 1.1745 Test MSE Loss: 1.2716
Validation loss decreased (1.175007 --> 1.174528).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6337384
	speed: 0.0564s/iter; left time: 929.7297s
	iters: 200, epoch: 28 | loss: 0.6552808
	speed: 0.0532s/iter; left time: 871.3421s
Epoch: 28 cost time: 12.336870908737183
Epoch: 28, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5917 + XiCon Loss:2.6819 x Lambda(0.01)), Vali MSE Loss: 1.1751 Test MSE Loss: 1.2716
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5854505
	speed: 0.0539s/iter; left time: 876.2064s
	iters: 200, epoch: 29 | loss: 0.6385555
	speed: 0.0506s/iter; left time: 816.3147s
Epoch: 29 cost time: 11.844327449798584
Epoch: 29, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5918 + XiCon Loss:2.6763 x Lambda(0.01)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2716
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6433369
	speed: 0.0546s/iter; left time: 874.0960s
	iters: 200, epoch: 30 | loss: 0.6049084
	speed: 0.0527s/iter; left time: 838.2084s
Epoch: 30 cost time: 12.158238410949707
Epoch: 30, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5916 + XiCon Loss:2.6744 x Lambda(0.01)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2716
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.6029801
	speed: 0.0535s/iter; left time: 844.7365s
	iters: 200, epoch: 31 | loss: 0.6313829
	speed: 0.0521s/iter; left time: 817.8014s
Epoch: 31 cost time: 12.033411502838135
Epoch: 31, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5918 + XiCon Loss:2.6783 x Lambda(0.01)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2716
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6343111
	speed: 0.0536s/iter; left time: 834.5980s
	iters: 200, epoch: 32 | loss: 0.5909784
	speed: 0.0511s/iter; left time: 790.7886s
Epoch: 32 cost time: 11.933324813842773
Epoch: 32, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6768 x Lambda(0.01)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2716
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6216635
	speed: 0.0540s/iter; left time: 827.9141s
	iters: 200, epoch: 33 | loss: 0.6409419
	speed: 0.0507s/iter; left time: 773.0303s
Epoch: 33 cost time: 11.833574533462524
Epoch: 33, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6766 x Lambda(0.01)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2716
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5928955
	speed: 0.0543s/iter; left time: 820.8994s
	iters: 200, epoch: 34 | loss: 0.5991431
	speed: 0.0523s/iter; left time: 784.5016s
Epoch: 34 cost time: 12.066688060760498
Epoch: 34, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6803 x Lambda(0.01)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2716
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.6103834
	speed: 0.0529s/iter; left time: 786.5825s
	iters: 200, epoch: 35 | loss: 0.6060929
	speed: 0.0518s/iter; left time: 765.3319s
Epoch: 35 cost time: 11.880197048187256
Epoch: 35, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6784 x Lambda(0.01)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2716
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6085628
	speed: 0.0552s/iter; left time: 808.8664s
	iters: 200, epoch: 36 | loss: 0.5796123
	speed: 0.0531s/iter; left time: 772.4113s
Epoch: 36 cost time: 12.332300186157227
Epoch: 36, Steps: 227 Train Loss: 0.6186 (Forecasting Loss:0.5918 + XiCon Loss:2.6807 x Lambda(0.01)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2716
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.6313497
	speed: 0.0544s/iter; left time: 784.8293s
	iters: 200, epoch: 37 | loss: 0.6253749
	speed: 0.0511s/iter; left time: 732.0439s
Epoch: 37 cost time: 12.02206039428711
Epoch: 37, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5916 + XiCon Loss:2.6816 x Lambda(0.01)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2716
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.589242696762085, mae:0.9539823532104492, mape:6.223217964172363, mspe:4799.02783203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7432
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0597441
	speed: 0.0505s/iter; left time: 1141.9767s
	iters: 200, epoch: 1 | loss: 1.0270556
	speed: 0.0470s/iter; left time: 1056.9253s
Epoch: 1 cost time: 11.012742757797241
Epoch: 1, Steps: 227 Train Loss: 1.0514 (Forecasting Loss:1.0243 + XiCon Loss:2.7093 x Lambda(0.01)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932084).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6382889
	speed: 0.0530s/iter; left time: 1186.7991s
	iters: 200, epoch: 2 | loss: 0.6237532
	speed: 0.0509s/iter; left time: 1133.8673s
Epoch: 2 cost time: 11.769668102264404
Epoch: 2, Steps: 227 Train Loss: 0.6963 (Forecasting Loss:0.6692 + XiCon Loss:2.7110 x Lambda(0.01)), Vali MSE Loss: 1.2130 Test MSE Loss: 1.2803
Validation loss decreased (1.932084 --> 1.212983).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6503147
	speed: 0.0523s/iter; left time: 1157.7157s
	iters: 200, epoch: 3 | loss: 0.6332941
	speed: 0.0483s/iter; left time: 1065.3763s
Epoch: 3 cost time: 11.396726369857788
Epoch: 3, Steps: 227 Train Loss: 0.6343 (Forecasting Loss:0.6072 + XiCon Loss:2.7054 x Lambda(0.01)), Vali MSE Loss: 1.1939 Test MSE Loss: 1.2731
Validation loss decreased (1.212983 --> 1.193880).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6089734
	speed: 0.0479s/iter; left time: 1049.7327s
	iters: 200, epoch: 4 | loss: 0.5697562
	speed: 0.0439s/iter; left time: 958.6534s
Epoch: 4 cost time: 10.41210651397705
Epoch: 4, Steps: 227 Train Loss: 0.6268 (Forecasting Loss:0.5998 + XiCon Loss:2.7013 x Lambda(0.01)), Vali MSE Loss: 1.1878 Test MSE Loss: 1.2714
Validation loss decreased (1.193880 --> 1.187786).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6086447
	speed: 0.0521s/iter; left time: 1130.2229s
	iters: 200, epoch: 5 | loss: 0.6692653
	speed: 0.0456s/iter; left time: 983.6176s
Epoch: 5 cost time: 11.01334023475647
Epoch: 5, Steps: 227 Train Loss: 0.6238 (Forecasting Loss:0.5968 + XiCon Loss:2.7006 x Lambda(0.01)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2707
Validation loss decreased (1.187786 --> 1.185028).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6080252
	speed: 0.0523s/iter; left time: 1122.0178s
	iters: 200, epoch: 6 | loss: 0.6015201
	speed: 0.0496s/iter; left time: 1060.3930s
Epoch: 6 cost time: 11.64464783668518
Epoch: 6, Steps: 227 Train Loss: 0.6224 (Forecasting Loss:0.5954 + XiCon Loss:2.6974 x Lambda(0.01)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2704
Validation loss decreased (1.185028 --> 1.183184).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6158414
	speed: 0.0497s/iter; left time: 1054.5590s
	iters: 200, epoch: 7 | loss: 0.6371207
	speed: 0.0492s/iter; left time: 1039.3793s
Epoch: 7 cost time: 11.269262075424194
Epoch: 7, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5946 + XiCon Loss:2.7010 x Lambda(0.01)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2703
Validation loss decreased (1.183184 --> 1.182866).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6294540
	speed: 0.0504s/iter; left time: 1058.8418s
	iters: 200, epoch: 8 | loss: 0.6630049
	speed: 0.0475s/iter; left time: 994.2763s
Epoch: 8 cost time: 11.13094425201416
Epoch: 8, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5943 + XiCon Loss:2.7042 x Lambda(0.01)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2702
Validation loss decreased (1.182866 --> 1.182413).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6043847
	speed: 0.0531s/iter; left time: 1104.5072s
	iters: 200, epoch: 9 | loss: 0.6233094
	speed: 0.0506s/iter; left time: 1045.8692s
Epoch: 9 cost time: 11.849993467330933
Epoch: 9, Steps: 227 Train Loss: 0.6211 (Forecasting Loss:0.5941 + XiCon Loss:2.6985 x Lambda(0.01)), Vali MSE Loss: 1.1812 Test MSE Loss: 1.2702
Validation loss decreased (1.182413 --> 1.181201).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5696455
	speed: 0.0503s/iter; left time: 1034.9415s
	iters: 200, epoch: 10 | loss: 0.6138400
	speed: 0.0481s/iter; left time: 984.2132s
Epoch: 10 cost time: 11.138111352920532
Epoch: 10, Steps: 227 Train Loss: 0.6210 (Forecasting Loss:0.5940 + XiCon Loss:2.7024 x Lambda(0.01)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2701
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6212773
	speed: 0.0518s/iter; left time: 1053.6076s
	iters: 200, epoch: 11 | loss: 0.6301941
	speed: 0.0487s/iter; left time: 984.4527s
Epoch: 11 cost time: 11.387209177017212
Epoch: 11, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5939 + XiCon Loss:2.7000 x Lambda(0.01)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2701
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6463959
	speed: 0.0544s/iter; left time: 1092.7332s
	iters: 200, epoch: 12 | loss: 0.5949907
	speed: 0.0478s/iter; left time: 956.2095s
Epoch: 12 cost time: 11.526349782943726
Epoch: 12, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5939 + XiCon Loss:2.7011 x Lambda(0.01)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2701
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6346058
	speed: 0.0514s/iter; left time: 1021.6410s
	iters: 200, epoch: 13 | loss: 0.5876067
	speed: 0.0490s/iter; left time: 969.5013s
Epoch: 13 cost time: 11.362133264541626
Epoch: 13, Steps: 227 Train Loss: 0.6210 (Forecasting Loss:0.5940 + XiCon Loss:2.7004 x Lambda(0.01)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2701
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6403445
	speed: 0.0511s/iter; left time: 1004.5006s
	iters: 200, epoch: 14 | loss: 0.6444921
	speed: 0.0471s/iter; left time: 920.7363s
Epoch: 14 cost time: 11.115625143051147
Epoch: 14, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5939 + XiCon Loss:2.6976 x Lambda(0.01)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2701
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6236410
	speed: 0.0512s/iter; left time: 994.4704s
	iters: 200, epoch: 15 | loss: 0.6550488
	speed: 0.0474s/iter; left time: 914.9622s
Epoch: 15 cost time: 11.365691423416138
Epoch: 15, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5938 + XiCon Loss:2.7020 x Lambda(0.01)), Vali MSE Loss: 1.1809 Test MSE Loss: 1.2701
Validation loss decreased (1.181201 --> 1.180902).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6250234
	speed: 0.0532s/iter; left time: 1021.1378s
	iters: 200, epoch: 16 | loss: 0.6089881
	speed: 0.0471s/iter; left time: 899.3327s
Epoch: 16 cost time: 11.255552291870117
Epoch: 16, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5937 + XiCon Loss:2.7020 x Lambda(0.01)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2701
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6295636
	speed: 0.0523s/iter; left time: 991.1328s
	iters: 200, epoch: 17 | loss: 0.6310077
	speed: 0.0487s/iter; left time: 919.4261s
Epoch: 17 cost time: 11.423404932022095
Epoch: 17, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5939 + XiCon Loss:2.7023 x Lambda(0.01)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2701
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6344951
	speed: 0.0517s/iter; left time: 968.9949s
	iters: 200, epoch: 18 | loss: 0.6013483
	speed: 0.0488s/iter; left time: 910.0398s
Epoch: 18 cost time: 11.377578735351562
Epoch: 18, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5938 + XiCon Loss:2.6972 x Lambda(0.01)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2701
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6499538
	speed: 0.0513s/iter; left time: 950.1367s
	iters: 200, epoch: 19 | loss: 0.6177288
	speed: 0.0468s/iter; left time: 861.3422s
Epoch: 19 cost time: 11.111856460571289
Epoch: 19, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5938 + XiCon Loss:2.7017 x Lambda(0.01)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2701
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5963526
	speed: 0.0487s/iter; left time: 890.5022s
	iters: 200, epoch: 20 | loss: 0.6356294
	speed: 0.0496s/iter; left time: 901.2230s
Epoch: 20 cost time: 11.150873184204102
Epoch: 20, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5938 + XiCon Loss:2.7028 x Lambda(0.01)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2701
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6111588
	speed: 0.0513s/iter; left time: 925.9285s
	iters: 200, epoch: 21 | loss: 0.6211728
	speed: 0.0492s/iter; left time: 883.6491s
Epoch: 21 cost time: 11.369349956512451
Epoch: 21, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5939 + XiCon Loss:2.6988 x Lambda(0.01)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2701
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6387603
	speed: 0.0536s/iter; left time: 955.9408s
	iters: 200, epoch: 22 | loss: 0.6104172
	speed: 0.0502s/iter; left time: 889.8891s
Epoch: 22 cost time: 11.720858335494995
Epoch: 22, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5938 + XiCon Loss:2.7022 x Lambda(0.01)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2701
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6437538
	speed: 0.0509s/iter; left time: 896.1988s
	iters: 200, epoch: 23 | loss: 0.6379120
	speed: 0.0481s/iter; left time: 841.9509s
Epoch: 23 cost time: 11.21149206161499
Epoch: 23, Steps: 227 Train Loss: 0.6208 (Forecasting Loss:0.5938 + XiCon Loss:2.6960 x Lambda(0.01)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2701
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6305350
	speed: 0.0528s/iter; left time: 918.1045s
	iters: 200, epoch: 24 | loss: 0.6130855
	speed: 0.0473s/iter; left time: 816.8736s
Epoch: 24 cost time: 11.33582353591919
Epoch: 24, Steps: 227 Train Loss: 0.6207 (Forecasting Loss:0.5937 + XiCon Loss:2.6970 x Lambda(0.01)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2701
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5977249
	speed: 0.0503s/iter; left time: 861.9455s
	iters: 200, epoch: 25 | loss: 0.6209877
	speed: 0.0495s/iter; left time: 844.3838s
Epoch: 25 cost time: 11.328190803527832
Epoch: 25, Steps: 227 Train Loss: 0.6209 (Forecasting Loss:0.5939 + XiCon Loss:2.6989 x Lambda(0.01)), Vali MSE Loss: 1.1812 Test MSE Loss: 1.2701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5874056816101074, mae:0.9528291821479797, mape:6.2044196128845215, mspe:4747.80322265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0572
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0639488
	speed: 0.0493s/iter; left time: 1115.2795s
	iters: 200, epoch: 1 | loss: 1.0833371
	speed: 0.0454s/iter; left time: 1022.5760s
Epoch: 1 cost time: 10.751837015151978
Epoch: 1, Steps: 227 Train Loss: 1.0670 (Forecasting Loss:1.0398 + XiCon Loss:2.7211 x Lambda(0.01)), Vali MSE Loss: 1.9462 Test MSE Loss: 1.3968
Validation loss decreased (inf --> 1.946192).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6196640
	speed: 0.0463s/iter; left time: 1035.2984s
	iters: 200, epoch: 2 | loss: 0.6306112
	speed: 0.0431s/iter; left time: 960.8955s
Epoch: 2 cost time: 10.169607400894165
Epoch: 2, Steps: 227 Train Loss: 0.6975 (Forecasting Loss:0.6703 + XiCon Loss:2.7227 x Lambda(0.01)), Vali MSE Loss: 1.2033 Test MSE Loss: 1.2776
Validation loss decreased (1.946192 --> 1.203251).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6619056
	speed: 0.0479s/iter; left time: 1060.0981s
	iters: 200, epoch: 3 | loss: 0.6422378
	speed: 0.0434s/iter; left time: 956.5015s
Epoch: 3 cost time: 10.340848445892334
Epoch: 3, Steps: 227 Train Loss: 0.6329 (Forecasting Loss:0.6057 + XiCon Loss:2.7192 x Lambda(0.01)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2713
Validation loss decreased (1.203251 --> 1.181595).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6168073
	speed: 0.0494s/iter; left time: 1083.4842s
	iters: 200, epoch: 4 | loss: 0.6250374
	speed: 0.0441s/iter; left time: 962.1371s
Epoch: 4 cost time: 10.571883916854858
Epoch: 4, Steps: 227 Train Loss: 0.6247 (Forecasting Loss:0.5976 + XiCon Loss:2.7154 x Lambda(0.01)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2707
Validation loss decreased (1.181595 --> 1.175411).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5880154
	speed: 0.0464s/iter; left time: 1005.6831s
	iters: 200, epoch: 5 | loss: 0.6440020
	speed: 0.0433s/iter; left time: 935.2417s
Epoch: 5 cost time: 10.208791017532349
Epoch: 5, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5943 + XiCon Loss:2.7151 x Lambda(0.01)), Vali MSE Loss: 1.1711 Test MSE Loss: 1.2701
Validation loss decreased (1.175411 --> 1.171070).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6481251
	speed: 0.0476s/iter; left time: 1021.0318s
	iters: 200, epoch: 6 | loss: 0.6412402
	speed: 0.0479s/iter; left time: 1023.3658s
Epoch: 6 cost time: 11.034716606140137
Epoch: 6, Steps: 227 Train Loss: 0.6200 (Forecasting Loss:0.5929 + XiCon Loss:2.7160 x Lambda(0.01)), Vali MSE Loss: 1.1700 Test MSE Loss: 1.2697
Validation loss decreased (1.171070 --> 1.170010).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6266012
	speed: 0.0520s/iter; left time: 1103.8815s
	iters: 200, epoch: 7 | loss: 0.5962703
	speed: 0.0472s/iter; left time: 998.4243s
Epoch: 7 cost time: 11.191662311553955
Epoch: 7, Steps: 227 Train Loss: 0.6192 (Forecasting Loss:0.5921 + XiCon Loss:2.7146 x Lambda(0.01)), Vali MSE Loss: 1.1690 Test MSE Loss: 1.2697
Validation loss decreased (1.170010 --> 1.168981).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6528820
	speed: 0.0485s/iter; left time: 1018.3447s
	iters: 200, epoch: 8 | loss: 0.6076007
	speed: 0.0476s/iter; left time: 994.4465s
Epoch: 8 cost time: 11.045827150344849
Epoch: 8, Steps: 227 Train Loss: 0.6188 (Forecasting Loss:0.5917 + XiCon Loss:2.7125 x Lambda(0.01)), Vali MSE Loss: 1.1682 Test MSE Loss: 1.2697
Validation loss decreased (1.168981 --> 1.168168).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6119340
	speed: 0.0523s/iter; left time: 1086.1114s
	iters: 200, epoch: 9 | loss: 0.5749100
	speed: 0.0474s/iter; left time: 980.2589s
Epoch: 9 cost time: 11.231351613998413
Epoch: 9, Steps: 227 Train Loss: 0.6188 (Forecasting Loss:0.5917 + XiCon Loss:2.7157 x Lambda(0.01)), Vali MSE Loss: 1.1682 Test MSE Loss: 1.2697
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6085399
	speed: 0.0521s/iter; left time: 1071.6051s
	iters: 200, epoch: 10 | loss: 0.6524532
	speed: 0.0477s/iter; left time: 976.6335s
Epoch: 10 cost time: 11.272178649902344
Epoch: 10, Steps: 227 Train Loss: 0.6186 (Forecasting Loss:0.5914 + XiCon Loss:2.7136 x Lambda(0.01)), Vali MSE Loss: 1.1682 Test MSE Loss: 1.2696
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5928694
	speed: 0.0518s/iter; left time: 1052.5874s
	iters: 200, epoch: 11 | loss: 0.6016076
	speed: 0.0482s/iter; left time: 975.3620s
Epoch: 11 cost time: 11.313056468963623
Epoch: 11, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7186 x Lambda(0.01)), Vali MSE Loss: 1.1681 Test MSE Loss: 1.2696
Validation loss decreased (1.168168 --> 1.168115).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6129687
	speed: 0.0513s/iter; left time: 1031.6903s
	iters: 200, epoch: 12 | loss: 0.6257136
	speed: 0.0474s/iter; left time: 948.0855s
Epoch: 12 cost time: 11.1957106590271
Epoch: 12, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5913 + XiCon Loss:2.7186 x Lambda(0.01)), Vali MSE Loss: 1.1682 Test MSE Loss: 1.2696
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6171179
	speed: 0.0503s/iter; left time: 998.9213s
	iters: 200, epoch: 13 | loss: 0.6558126
	speed: 0.0476s/iter; left time: 941.4454s
Epoch: 13 cost time: 11.055391073226929
Epoch: 13, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5911 + XiCon Loss:2.7180 x Lambda(0.01)), Vali MSE Loss: 1.1682 Test MSE Loss: 1.2696
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6265138
	speed: 0.0505s/iter; left time: 991.7176s
	iters: 200, epoch: 14 | loss: 0.6459100
	speed: 0.0479s/iter; left time: 936.6634s
Epoch: 14 cost time: 11.120050191879272
Epoch: 14, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5914 + XiCon Loss:2.7113 x Lambda(0.01)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2696
Validation loss decreased (1.168115 --> 1.167718).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6367677
	speed: 0.0514s/iter; left time: 998.6330s
	iters: 200, epoch: 15 | loss: 0.6388468
	speed: 0.0476s/iter; left time: 920.7137s
Epoch: 15 cost time: 11.249248743057251
Epoch: 15, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7122 x Lambda(0.01)), Vali MSE Loss: 1.1675 Test MSE Loss: 1.2696
Validation loss decreased (1.167718 --> 1.167514).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6116211
	speed: 0.0509s/iter; left time: 977.8178s
	iters: 200, epoch: 16 | loss: 0.5861800
	speed: 0.0482s/iter; left time: 919.9005s
Epoch: 16 cost time: 11.219240188598633
Epoch: 16, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7162 x Lambda(0.01)), Vali MSE Loss: 1.1683 Test MSE Loss: 1.2696
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6714950
	speed: 0.0508s/iter; left time: 963.5180s
	iters: 200, epoch: 17 | loss: 0.5940121
	speed: 0.0454s/iter; left time: 856.7050s
Epoch: 17 cost time: 10.930407762527466
Epoch: 17, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5913 + XiCon Loss:2.7146 x Lambda(0.01)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2696
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6388671
	speed: 0.0519s/iter; left time: 973.3312s
	iters: 200, epoch: 18 | loss: 0.6206290
	speed: 0.0471s/iter; left time: 878.9242s
Epoch: 18 cost time: 11.257680177688599
Epoch: 18, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5913 + XiCon Loss:2.7112 x Lambda(0.01)), Vali MSE Loss: 1.1675 Test MSE Loss: 1.2696
Validation loss decreased (1.167514 --> 1.167510).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6058381
	speed: 0.0515s/iter; left time: 953.4811s
	iters: 200, epoch: 19 | loss: 0.6371893
	speed: 0.0468s/iter; left time: 861.5042s
Epoch: 19 cost time: 11.331881999969482
Epoch: 19, Steps: 227 Train Loss: 0.6186 (Forecasting Loss:0.5914 + XiCon Loss:2.7175 x Lambda(0.01)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2696
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5546721
	speed: 0.0489s/iter; left time: 894.8869s
	iters: 200, epoch: 20 | loss: 0.6300150
	speed: 0.0468s/iter; left time: 851.5230s
Epoch: 20 cost time: 10.88906455039978
Epoch: 20, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5913 + XiCon Loss:2.7155 x Lambda(0.01)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2696
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6245554
	speed: 0.0504s/iter; left time: 909.7474s
	iters: 200, epoch: 21 | loss: 0.6462193
	speed: 0.0487s/iter; left time: 874.9201s
Epoch: 21 cost time: 11.229691982269287
Epoch: 21, Steps: 227 Train Loss: 0.6183 (Forecasting Loss:0.5911 + XiCon Loss:2.7140 x Lambda(0.01)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2696
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6540837
	speed: 0.0496s/iter; left time: 885.3099s
	iters: 200, epoch: 22 | loss: 0.6311681
	speed: 0.0480s/iter; left time: 851.7095s
Epoch: 22 cost time: 11.033405065536499
Epoch: 22, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5913 + XiCon Loss:2.7136 x Lambda(0.01)), Vali MSE Loss: 1.1680 Test MSE Loss: 1.2696
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5983282
	speed: 0.0515s/iter; left time: 907.5836s
	iters: 200, epoch: 23 | loss: 0.6384318
	speed: 0.0459s/iter; left time: 804.0762s
Epoch: 23 cost time: 10.99248194694519
Epoch: 23, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7152 x Lambda(0.01)), Vali MSE Loss: 1.1678 Test MSE Loss: 1.2696
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5861428
	speed: 0.0514s/iter; left time: 893.3712s
	iters: 200, epoch: 24 | loss: 0.6411620
	speed: 0.0476s/iter; left time: 822.8389s
Epoch: 24 cost time: 11.27977466583252
Epoch: 24, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7145 x Lambda(0.01)), Vali MSE Loss: 1.1678 Test MSE Loss: 1.2696
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5970370
	speed: 0.0488s/iter; left time: 837.6652s
	iters: 200, epoch: 25 | loss: 0.6261630
	speed: 0.0470s/iter; left time: 801.5397s
Epoch: 25 cost time: 10.881651401519775
Epoch: 25, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5913 + XiCon Loss:2.7144 x Lambda(0.01)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2696
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6144633
	speed: 0.0507s/iter; left time: 858.8262s
	iters: 200, epoch: 26 | loss: 0.6143934
	speed: 0.0493s/iter; left time: 828.9151s
Epoch: 26 cost time: 11.296911478042603
Epoch: 26, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5913 + XiCon Loss:2.7172 x Lambda(0.01)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2696
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6081218
	speed: 0.0504s/iter; left time: 841.2301s
	iters: 200, epoch: 27 | loss: 0.6116105
	speed: 0.0465s/iter; left time: 771.3009s
Epoch: 27 cost time: 10.973414421081543
Epoch: 27, Steps: 227 Train Loss: 0.6185 (Forecasting Loss:0.5913 + XiCon Loss:2.7152 x Lambda(0.01)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2696
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6432352
	speed: 0.0464s/iter; left time: 765.0748s
	iters: 200, epoch: 28 | loss: 0.6064855
	speed: 0.0442s/iter; left time: 724.1036s
Epoch: 28 cost time: 10.322287559509277
Epoch: 28, Steps: 227 Train Loss: 0.6184 (Forecasting Loss:0.5912 + XiCon Loss:2.7169 x Lambda(0.01)), Vali MSE Loss: 1.1683 Test MSE Loss: 1.2696
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5857045650482178, mae:0.9535809755325317, mape:6.230398178100586, mspe:4780.0029296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.0857
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.1818856
	speed: 0.0469s/iter; left time: 1059.2907s
	iters: 200, epoch: 1 | loss: 1.2561628
	speed: 0.0433s/iter; left time: 973.4272s
Epoch: 1 cost time: 10.219336032867432
Epoch: 1, Steps: 227 Train Loss: 1.1890 (Forecasting Loss:1.1621 + XiCon Loss:2.6922 x Lambda(0.01)), Vali MSE Loss: 2.2071 Test MSE Loss: 1.4654
Validation loss decreased (inf --> 2.207131).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7853016
	speed: 0.0461s/iter; left time: 1032.4642s
	iters: 200, epoch: 2 | loss: 0.6865972
	speed: 0.0435s/iter; left time: 969.9423s
Epoch: 2 cost time: 10.240440845489502
Epoch: 2, Steps: 227 Train Loss: 0.7630 (Forecasting Loss:0.7361 + XiCon Loss:2.6910 x Lambda(0.01)), Vali MSE Loss: 1.2345 Test MSE Loss: 1.3039
Validation loss decreased (2.207131 --> 1.234507).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6687285
	speed: 0.0461s/iter; left time: 1021.7662s
	iters: 200, epoch: 3 | loss: 0.6374254
	speed: 0.0434s/iter; left time: 957.7633s
Epoch: 3 cost time: 10.158590316772461
Epoch: 3, Steps: 227 Train Loss: 0.6444 (Forecasting Loss:0.6174 + XiCon Loss:2.7000 x Lambda(0.01)), Vali MSE Loss: 1.1966 Test MSE Loss: 1.2880
Validation loss decreased (1.234507 --> 1.196588).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5942407
	speed: 0.0472s/iter; left time: 1035.2919s
	iters: 200, epoch: 4 | loss: 0.6728697
	speed: 0.0435s/iter; left time: 948.0849s
Epoch: 4 cost time: 10.26438283920288
Epoch: 4, Steps: 227 Train Loss: 0.6286 (Forecasting Loss:0.6016 + XiCon Loss:2.7033 x Lambda(0.01)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2848
Validation loss decreased (1.196588 --> 1.187704).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6176199
	speed: 0.0490s/iter; left time: 1061.8747s
	iters: 200, epoch: 5 | loss: 0.5834436
	speed: 0.0443s/iter; left time: 957.3023s
Epoch: 5 cost time: 10.660447359085083
Epoch: 5, Steps: 227 Train Loss: 0.6247 (Forecasting Loss:0.5977 + XiCon Loss:2.7011 x Lambda(0.01)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2838
Validation loss decreased (1.187704 --> 1.184492).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6121288
	speed: 0.0970s/iter; left time: 2081.3507s
	iters: 200, epoch: 6 | loss: 0.6203333
	speed: 0.1028s/iter; left time: 2196.8941s
Epoch: 6 cost time: 22.66109538078308
Epoch: 6, Steps: 227 Train Loss: 0.6230 (Forecasting Loss:0.5960 + XiCon Loss:2.6996 x Lambda(0.01)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2831
Validation loss decreased (1.184492 --> 1.182133).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5948770
	speed: 0.1143s/iter; left time: 2428.2182s
	iters: 200, epoch: 7 | loss: 0.6174870
	speed: 0.1063s/iter; left time: 2247.3814s
Epoch: 7 cost time: 25.24284815788269
Epoch: 7, Steps: 227 Train Loss: 0.6222 (Forecasting Loss:0.5951 + XiCon Loss:2.7026 x Lambda(0.01)), Vali MSE Loss: 1.1806 Test MSE Loss: 1.2829
Validation loss decreased (1.182133 --> 1.180632).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6192760
	speed: 0.1082s/iter; left time: 2273.8385s
	iters: 200, epoch: 8 | loss: 0.6620661
	speed: 0.1044s/iter; left time: 2183.3495s
Epoch: 8 cost time: 23.92241668701172
Epoch: 8, Steps: 227 Train Loss: 0.6217 (Forecasting Loss:0.5946 + XiCon Loss:2.7031 x Lambda(0.01)), Vali MSE Loss: 1.1806 Test MSE Loss: 1.2827
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6397209
	speed: 0.1125s/iter; left time: 2337.5954s
	iters: 200, epoch: 9 | loss: 0.6098626
	speed: 0.1073s/iter; left time: 2219.7133s
Epoch: 9 cost time: 24.75835657119751
Epoch: 9, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5943 + XiCon Loss:2.6995 x Lambda(0.01)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2826
Validation loss decreased (1.180632 --> 1.179848).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6547217
	speed: 0.1080s/iter; left time: 2219.4970s
	iters: 200, epoch: 10 | loss: 0.6128355
	speed: 0.1043s/iter; left time: 2133.9852s
Epoch: 10 cost time: 24.061915636062622
Epoch: 10, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5943 + XiCon Loss:2.7080 x Lambda(0.01)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6397518
	speed: 0.1010s/iter; left time: 2054.3548s
	iters: 200, epoch: 11 | loss: 0.5954251
	speed: 0.0953s/iter; left time: 1928.7099s
Epoch: 11 cost time: 22.202388286590576
Epoch: 11, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5943 + XiCon Loss:2.7015 x Lambda(0.01)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
Validation loss decreased (1.179848 --> 1.179575).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5918522
	speed: 0.1038s/iter; left time: 2087.4352s
	iters: 200, epoch: 12 | loss: 0.6274412
	speed: 0.0994s/iter; left time: 1989.3021s
Epoch: 12 cost time: 23.005824327468872
Epoch: 12, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5942 + XiCon Loss:2.7083 x Lambda(0.01)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6023228
	speed: 0.1068s/iter; left time: 2122.8202s
	iters: 200, epoch: 13 | loss: 0.6141936
	speed: 0.0937s/iter; left time: 1853.8830s
Epoch: 13 cost time: 22.732306480407715
Epoch: 13, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5942 + XiCon Loss:2.7014 x Lambda(0.01)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2826
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6283020
	speed: 0.1196s/iter; left time: 2349.7838s
	iters: 200, epoch: 14 | loss: 0.6304570
	speed: 0.1164s/iter; left time: 2275.9222s
Epoch: 14 cost time: 26.980092525482178
Epoch: 14, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5943 + XiCon Loss:2.7025 x Lambda(0.01)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6069317
	speed: 0.1257s/iter; left time: 2441.3539s
	iters: 200, epoch: 15 | loss: 0.6178974
	speed: 0.1193s/iter; left time: 2305.9602s
Epoch: 15 cost time: 27.93668246269226
Epoch: 15, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5943 + XiCon Loss:2.7027 x Lambda(0.01)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6126060
	speed: 0.1210s/iter; left time: 2322.1893s
	iters: 200, epoch: 16 | loss: 0.6182219
	speed: 0.1159s/iter; left time: 2212.6266s
Epoch: 16 cost time: 26.848586559295654
Epoch: 16, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5942 + XiCon Loss:2.6998 x Lambda(0.01)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2826
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5905648
	speed: 0.1222s/iter; left time: 2318.5711s
	iters: 200, epoch: 17 | loss: 0.6228223
	speed: 0.1154s/iter; left time: 2177.4999s
Epoch: 17 cost time: 26.967491626739502
Epoch: 17, Steps: 227 Train Loss: 0.6211 (Forecasting Loss:0.5941 + XiCon Loss:2.7039 x Lambda(0.01)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2826
Validation loss decreased (1.179575 --> 1.179261).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6303072
	speed: 0.1271s/iter; left time: 2382.1680s
	iters: 200, epoch: 18 | loss: 0.6039364
	speed: 0.1178s/iter; left time: 2196.0999s
Epoch: 18 cost time: 27.492655038833618
Epoch: 18, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5943 + XiCon Loss:2.7057 x Lambda(0.01)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6070259
	speed: 0.1162s/iter; left time: 2151.0901s
	iters: 200, epoch: 19 | loss: 0.6123013
	speed: 0.1120s/iter; left time: 2061.9118s
Epoch: 19 cost time: 25.888309001922607
Epoch: 19, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5942 + XiCon Loss:2.7005 x Lambda(0.01)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6286202
	speed: 0.1153s/iter; left time: 2108.4601s
	iters: 200, epoch: 20 | loss: 0.6520799
	speed: 0.1089s/iter; left time: 1981.1641s
Epoch: 20 cost time: 25.42786693572998
Epoch: 20, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5942 + XiCon Loss:2.7067 x Lambda(0.01)), Vali MSE Loss: 1.1805 Test MSE Loss: 1.2826
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6239243
	speed: 0.1053s/iter; left time: 1901.0877s
	iters: 200, epoch: 21 | loss: 0.6302871
	speed: 0.0987s/iter; left time: 1772.1287s
Epoch: 21 cost time: 22.978878259658813
Epoch: 21, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5942 + XiCon Loss:2.7010 x Lambda(0.01)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6499320
	speed: 0.1049s/iter; left time: 1871.5116s
	iters: 200, epoch: 22 | loss: 0.6369932
	speed: 0.0947s/iter; left time: 1679.9778s
Epoch: 22 cost time: 22.47465944290161
Epoch: 22, Steps: 227 Train Loss: 0.6210 (Forecasting Loss:0.5940 + XiCon Loss:2.7055 x Lambda(0.01)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6309526
	speed: 0.0966s/iter; left time: 1701.1253s
	iters: 200, epoch: 23 | loss: 0.5931621
	speed: 0.0971s/iter; left time: 1700.4679s
Epoch: 23 cost time: 21.774022102355957
Epoch: 23, Steps: 227 Train Loss: 0.6211 (Forecasting Loss:0.5941 + XiCon Loss:2.7025 x Lambda(0.01)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2826
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5466686
	speed: 0.0900s/iter; left time: 1564.7608s
	iters: 200, epoch: 24 | loss: 0.6277617
	speed: 0.0859s/iter; left time: 1484.1002s
Epoch: 24 cost time: 19.961870908737183
Epoch: 24, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5941 + XiCon Loss:2.7049 x Lambda(0.01)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6494849
	speed: 0.0899s/iter; left time: 1542.7129s
	iters: 200, epoch: 25 | loss: 0.5951806
	speed: 0.0855s/iter; left time: 1458.3165s
Epoch: 25 cost time: 20.112951278686523
Epoch: 25, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5941 + XiCon Loss:2.7043 x Lambda(0.01)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6253278
	speed: 0.0888s/iter; left time: 1502.7223s
	iters: 200, epoch: 26 | loss: 0.5598644
	speed: 0.0785s/iter; left time: 1320.2164s
Epoch: 26 cost time: 18.918864488601685
Epoch: 26, Steps: 227 Train Loss: 0.6212 (Forecasting Loss:0.5942 + XiCon Loss:2.6992 x Lambda(0.01)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6023683
	speed: 0.0841s/iter; left time: 1405.0428s
	iters: 200, epoch: 27 | loss: 0.6020685
	speed: 0.0797s/iter; left time: 1322.1714s
Epoch: 27 cost time: 18.504486083984375
Epoch: 27, Steps: 227 Train Loss: 0.6211 (Forecasting Loss:0.5941 + XiCon Loss:2.7039 x Lambda(0.01)), Vali MSE Loss: 1.1804 Test MSE Loss: 1.2826
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.6069562435150146, mae:0.9582083821296692, mape:6.243926525115967, mspe:4864.228515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 24.2686
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.1006556
	speed: 0.0850s/iter; left time: 1921.2119s
	iters: 200, epoch: 1 | loss: 0.9675983
	speed: 0.0593s/iter; left time: 1333.4458s
Epoch: 1 cost time: 15.942182302474976
Epoch: 1, Steps: 227 Train Loss: 1.0623 (Forecasting Loss:1.0350 + XiCon Loss:2.7229 x Lambda(0.01)), Vali MSE Loss: 1.9641 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964107).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6261376
	speed: 0.0563s/iter; left time: 1259.0351s
	iters: 200, epoch: 2 | loss: 0.6661655
	speed: 0.0517s/iter; left time: 1152.2474s
Epoch: 2 cost time: 12.184399843215942
Epoch: 2, Steps: 227 Train Loss: 0.6985 (Forecasting Loss:0.6713 + XiCon Loss:2.7223 x Lambda(0.01)), Vali MSE Loss: 1.2173 Test MSE Loss: 1.2827
Validation loss decreased (1.964107 --> 1.217315).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6426593
	speed: 0.0576s/iter; left time: 1275.9836s
	iters: 200, epoch: 3 | loss: 0.5884993
	speed: 0.0601s/iter; left time: 1325.8000s
Epoch: 3 cost time: 13.639429330825806
Epoch: 3, Steps: 227 Train Loss: 0.6353 (Forecasting Loss:0.6082 + XiCon Loss:2.7151 x Lambda(0.01)), Vali MSE Loss: 1.1981 Test MSE Loss: 1.2763
Validation loss decreased (1.217315 --> 1.198084).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6216091
	speed: 0.0571s/iter; left time: 1252.0876s
	iters: 200, epoch: 4 | loss: 0.6145486
	speed: 0.0526s/iter; left time: 1148.0729s
Epoch: 4 cost time: 12.331270694732666
Epoch: 4, Steps: 227 Train Loss: 0.6275 (Forecasting Loss:0.6004 + XiCon Loss:2.7127 x Lambda(0.01)), Vali MSE Loss: 1.1901 Test MSE Loss: 1.2747
Validation loss decreased (1.198084 --> 1.190072).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6239266
	speed: 0.0595s/iter; left time: 1290.8088s
	iters: 200, epoch: 5 | loss: 0.6232136
	speed: 0.0542s/iter; left time: 1170.8538s
Epoch: 5 cost time: 12.77087950706482
Epoch: 5, Steps: 227 Train Loss: 0.6243 (Forecasting Loss:0.5973 + XiCon Loss:2.7093 x Lambda(0.01)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2739
Validation loss decreased (1.190072 --> 1.186620).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6479577
	speed: 0.0622s/iter; left time: 1334.4643s
	iters: 200, epoch: 6 | loss: 0.6499868
	speed: 0.0534s/iter; left time: 1141.0530s
Epoch: 6 cost time: 12.94492483139038
Epoch: 6, Steps: 227 Train Loss: 0.6231 (Forecasting Loss:0.5960 + XiCon Loss:2.7087 x Lambda(0.01)), Vali MSE Loss: 1.1851 Test MSE Loss: 1.2735
Validation loss decreased (1.186620 --> 1.185060).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6247682
	speed: 0.0484s/iter; left time: 1028.1079s
	iters: 200, epoch: 7 | loss: 0.6930197
	speed: 0.0452s/iter; left time: 954.5473s
Epoch: 7 cost time: 10.642043590545654
Epoch: 7, Steps: 227 Train Loss: 0.6225 (Forecasting Loss:0.5954 + XiCon Loss:2.7085 x Lambda(0.01)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2734
Validation loss decreased (1.185060 --> 1.183906).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5951800
	speed: 0.0482s/iter; left time: 1012.6070s
	iters: 200, epoch: 8 | loss: 0.6622786
	speed: 0.0444s/iter; left time: 928.4026s
Epoch: 8 cost time: 10.507412433624268
Epoch: 8, Steps: 227 Train Loss: 0.6221 (Forecasting Loss:0.5950 + XiCon Loss:2.7090 x Lambda(0.01)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2733
Validation loss decreased (1.183906 --> 1.183730).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6292612
	speed: 0.0491s/iter; left time: 1020.1027s
	iters: 200, epoch: 9 | loss: 0.6066275
	speed: 0.0463s/iter; left time: 958.1736s
Epoch: 9 cost time: 10.831398487091064
Epoch: 9, Steps: 227 Train Loss: 0.6218 (Forecasting Loss:0.5948 + XiCon Loss:2.7068 x Lambda(0.01)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2733
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6069739
	speed: 0.0481s/iter; left time: 989.4115s
	iters: 200, epoch: 10 | loss: 0.6141348
	speed: 0.0462s/iter; left time: 945.5986s
Epoch: 10 cost time: 10.684217691421509
Epoch: 10, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5945 + XiCon Loss:2.7093 x Lambda(0.01)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2733
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6728088
	speed: 0.0478s/iter; left time: 972.5722s
	iters: 200, epoch: 11 | loss: 0.6231921
	speed: 0.0463s/iter; left time: 936.3490s
Epoch: 11 cost time: 10.671239137649536
Epoch: 11, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5944 + XiCon Loss:2.7050 x Lambda(0.01)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2733
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6462956
	speed: 0.0482s/iter; left time: 969.3952s
	iters: 200, epoch: 12 | loss: 0.6422282
	speed: 0.0452s/iter; left time: 903.9318s
Epoch: 12 cost time: 10.589229822158813
Epoch: 12, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5944 + XiCon Loss:2.7058 x Lambda(0.01)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2733
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6128526
	speed: 0.0473s/iter; left time: 940.0185s
	iters: 200, epoch: 13 | loss: 0.5592604
	speed: 0.0444s/iter; left time: 877.6230s
Epoch: 13 cost time: 10.392997026443481
Epoch: 13, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5944 + XiCon Loss:2.7069 x Lambda(0.01)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2733
Validation loss decreased (1.183730 --> 1.183726).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6460425
	speed: 0.0473s/iter; left time: 930.0556s
	iters: 200, epoch: 14 | loss: 0.6333293
	speed: 0.0443s/iter; left time: 866.2882s
Epoch: 14 cost time: 10.428083419799805
Epoch: 14, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5944 + XiCon Loss:2.7091 x Lambda(0.01)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2733
Validation loss decreased (1.183726 --> 1.182896).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6073380
	speed: 0.0469s/iter; left time: 911.6761s
	iters: 200, epoch: 15 | loss: 0.6174716
	speed: 0.0447s/iter; left time: 863.7001s
Epoch: 15 cost time: 10.413924932479858
Epoch: 15, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5945 + XiCon Loss:2.7085 x Lambda(0.01)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2733
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6089308
	speed: 0.0468s/iter; left time: 898.8386s
	iters: 200, epoch: 16 | loss: 0.6028886
	speed: 0.0442s/iter; left time: 844.2674s
Epoch: 16 cost time: 10.353108882904053
Epoch: 16, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5944 + XiCon Loss:2.7091 x Lambda(0.01)), Vali MSE Loss: 1.1836 Test MSE Loss: 1.2733
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6063421
	speed: 0.0470s/iter; left time: 891.5729s
	iters: 200, epoch: 17 | loss: 0.6405640
	speed: 0.0437s/iter; left time: 824.1469s
Epoch: 17 cost time: 10.294297218322754
Epoch: 17, Steps: 227 Train Loss: 0.6215 (Forecasting Loss:0.5944 + XiCon Loss:2.7069 x Lambda(0.01)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2733
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6285000
	speed: 0.0465s/iter; left time: 871.9701s
	iters: 200, epoch: 18 | loss: 0.5959970
	speed: 0.0429s/iter; left time: 800.2459s
Epoch: 18 cost time: 10.167050123214722
Epoch: 18, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5944 + XiCon Loss:2.7068 x Lambda(0.01)), Vali MSE Loss: 1.1836 Test MSE Loss: 1.2733
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5935372
	speed: 0.0462s/iter; left time: 856.0215s
	iters: 200, epoch: 19 | loss: 0.6068707
	speed: 0.0429s/iter; left time: 789.3221s
Epoch: 19 cost time: 10.131863594055176
Epoch: 19, Steps: 227 Train Loss: 0.6213 (Forecasting Loss:0.5942 + XiCon Loss:2.7087 x Lambda(0.01)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2733
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5647961
	speed: 0.0460s/iter; left time: 841.1194s
	iters: 200, epoch: 20 | loss: 0.6482868
	speed: 0.0431s/iter; left time: 783.6992s
Epoch: 20 cost time: 10.12546992301941
Epoch: 20, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5943 + XiCon Loss:2.7095 x Lambda(0.01)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2733
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6202222
	speed: 0.0472s/iter; left time: 852.2898s
	iters: 200, epoch: 21 | loss: 0.6633802
	speed: 0.0428s/iter; left time: 769.0146s
Epoch: 21 cost time: 10.253739356994629
Epoch: 21, Steps: 227 Train Loss: 0.6214 (Forecasting Loss:0.5944 + XiCon Loss:2.7074 x Lambda(0.01)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2733
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6261375
	speed: 0.0465s/iter; left time: 829.4630s
	iters: 200, epoch: 22 | loss: 0.6130112
	speed: 0.0442s/iter; left time: 784.4799s
Epoch: 22 cost time: 10.3339262008667
Epoch: 22, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5945 + XiCon Loss:2.7062 x Lambda(0.01)), Vali MSE Loss: 1.1835 Test MSE Loss: 1.2733
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5982987
	speed: 0.0466s/iter; left time: 821.0215s
	iters: 200, epoch: 23 | loss: 0.6544155
	speed: 0.0434s/iter; left time: 760.1575s
Epoch: 23 cost time: 10.264718055725098
Epoch: 23, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5945 + XiCon Loss:2.7080 x Lambda(0.01)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2733
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6072763
	speed: 0.0457s/iter; left time: 794.3091s
	iters: 200, epoch: 24 | loss: 0.6444881
	speed: 0.0427s/iter; left time: 738.4375s
Epoch: 24 cost time: 10.048801183700562
Epoch: 24, Steps: 227 Train Loss: 0.6216 (Forecasting Loss:0.5945 + XiCon Loss:2.7082 x Lambda(0.01)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2733
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.591982126235962, mae:0.9545974731445312, mape:6.223587512969971, mspe:4787.23095703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5923+-0.01060, MAE:0.9546+-0.00260, MAPE:6.2251+-0.01773, MSPE:4795.6587+-53.11452, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
