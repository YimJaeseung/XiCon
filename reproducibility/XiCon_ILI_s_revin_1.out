Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2714
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.9511396884918213
Epoch: 1, Steps: 38 Train Loss: 2.0263 (Forecasting Loss:0.4215 + XiCon Loss:1.6048 x Lambda(1.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 1.0816
Validation loss decreased (inf --> 0.264299).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6940450668334961
Epoch: 2, Steps: 38 Train Loss: 1.8039 (Forecasting Loss:0.2610 + XiCon Loss:1.5429 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.5787
Validation loss decreased (0.264299 --> 0.163133).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7157211303710938
Epoch: 3, Steps: 38 Train Loss: 1.6356 (Forecasting Loss:0.1658 + XiCon Loss:1.4698 x Lambda(1.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6157
Validation loss decreased (0.163133 --> 0.117890).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7239620685577393
Epoch: 4, Steps: 38 Train Loss: 1.5984 (Forecasting Loss:0.1349 + XiCon Loss:1.4635 x Lambda(1.0)), Vali MSE Loss: 0.1122 Test MSE Loss: 0.5917
Validation loss decreased (0.117890 --> 0.112156).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7291524410247803
Epoch: 5, Steps: 38 Train Loss: 1.5791 (Forecasting Loss:0.1298 + XiCon Loss:1.4494 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.5995
Validation loss decreased (0.112156 --> 0.108052).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7338471412658691
Epoch: 6, Steps: 38 Train Loss: 1.5834 (Forecasting Loss:0.1262 + XiCon Loss:1.4572 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.5879
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7242982387542725
Epoch: 7, Steps: 38 Train Loss: 1.5795 (Forecasting Loss:0.1261 + XiCon Loss:1.4534 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.5855
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7199103832244873
Epoch: 8, Steps: 38 Train Loss: 1.5661 (Forecasting Loss:0.1245 + XiCon Loss:1.4416 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.5862
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6654365062713623
Epoch: 9, Steps: 38 Train Loss: 1.5716 (Forecasting Loss:0.1250 + XiCon Loss:1.4467 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.5868
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6462597846984863
Epoch: 10, Steps: 38 Train Loss: 1.5597 (Forecasting Loss:0.1245 + XiCon Loss:1.4353 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.5869
Validation loss decreased (0.108052 --> 0.107953).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6865456104278564
Epoch: 11, Steps: 38 Train Loss: 1.5681 (Forecasting Loss:0.1239 + XiCon Loss:1.4442 x Lambda(1.0)), Vali MSE Loss: 0.1067 Test MSE Loss: 0.5868
Validation loss decreased (0.107953 --> 0.106700).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7601263523101807
Epoch: 12, Steps: 38 Train Loss: 1.5717 (Forecasting Loss:0.1237 + XiCon Loss:1.4480 x Lambda(1.0)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.5869
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.8166742324829102
Epoch: 13, Steps: 38 Train Loss: 1.5592 (Forecasting Loss:0.1242 + XiCon Loss:1.4350 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5869
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7797055244445801
Epoch: 14, Steps: 38 Train Loss: 1.5644 (Forecasting Loss:0.1242 + XiCon Loss:1.4402 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5869
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7089805603027344
Epoch: 15, Steps: 38 Train Loss: 1.5701 (Forecasting Loss:0.1241 + XiCon Loss:1.4460 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5870
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7369999885559082
Epoch: 16, Steps: 38 Train Loss: 1.5705 (Forecasting Loss:0.1243 + XiCon Loss:1.4462 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.5870
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.730644941329956
Epoch: 17, Steps: 38 Train Loss: 1.5742 (Forecasting Loss:0.1239 + XiCon Loss:1.4503 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5870
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7214467525482178
Epoch: 18, Steps: 38 Train Loss: 1.5659 (Forecasting Loss:0.1230 + XiCon Loss:1.4430 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5870
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7260522842407227
Epoch: 19, Steps: 38 Train Loss: 1.5632 (Forecasting Loss:0.1237 + XiCon Loss:1.4396 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5870
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7568509578704834
Epoch: 20, Steps: 38 Train Loss: 1.5564 (Forecasting Loss:0.1243 + XiCon Loss:1.4321 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.5870
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6684515476226807
Epoch: 21, Steps: 38 Train Loss: 1.5704 (Forecasting Loss:0.1240 + XiCon Loss:1.4464 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.5870
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6356686949729919, mae:0.5379935503005981, mape:0.21036556363105774, mspe:0.17992185056209564 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3659
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7492251396179199
Epoch: 1, Steps: 38 Train Loss: 2.0971 (Forecasting Loss:0.4884 + XiCon Loss:1.6087 x Lambda(1.0)), Vali MSE Loss: 0.3031 Test MSE Loss: 1.2880
Validation loss decreased (inf --> 0.303072).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7304306030273438
Epoch: 2, Steps: 38 Train Loss: 1.8276 (Forecasting Loss:0.2651 + XiCon Loss:1.5625 x Lambda(1.0)), Vali MSE Loss: 0.1555 Test MSE Loss: 0.6452
Validation loss decreased (0.303072 --> 0.155472).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6862912178039551
Epoch: 3, Steps: 38 Train Loss: 1.6469 (Forecasting Loss:0.1651 + XiCon Loss:1.4818 x Lambda(1.0)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6351
Validation loss decreased (0.155472 --> 0.114265).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7130558490753174
Epoch: 4, Steps: 38 Train Loss: 1.5870 (Forecasting Loss:0.1357 + XiCon Loss:1.4513 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6094
Validation loss decreased (0.114265 --> 0.108156).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7561285495758057
Epoch: 5, Steps: 38 Train Loss: 1.5766 (Forecasting Loss:0.1285 + XiCon Loss:1.4481 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.6058
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7321286201477051
Epoch: 6, Steps: 38 Train Loss: 1.5627 (Forecasting Loss:0.1246 + XiCon Loss:1.4381 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.6060
Validation loss decreased (0.108156 --> 0.107683).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7469847202301025
Epoch: 7, Steps: 38 Train Loss: 1.5627 (Forecasting Loss:0.1243 + XiCon Loss:1.4384 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.6098
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7611021995544434
Epoch: 8, Steps: 38 Train Loss: 1.5536 (Forecasting Loss:0.1231 + XiCon Loss:1.4305 x Lambda(1.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.6110
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7405660152435303
Epoch: 9, Steps: 38 Train Loss: 1.5645 (Forecasting Loss:0.1214 + XiCon Loss:1.4431 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.6114
Validation loss decreased (0.107683 --> 0.107548).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.769061803817749
Epoch: 10, Steps: 38 Train Loss: 1.5526 (Forecasting Loss:0.1220 + XiCon Loss:1.4307 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6112
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7377219200134277
Epoch: 11, Steps: 38 Train Loss: 1.5455 (Forecasting Loss:0.1227 + XiCon Loss:1.4228 x Lambda(1.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.6112
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7509799003601074
Epoch: 12, Steps: 38 Train Loss: 1.5627 (Forecasting Loss:0.1220 + XiCon Loss:1.4408 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.6114
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7349796295166016
Epoch: 13, Steps: 38 Train Loss: 1.5565 (Forecasting Loss:0.1222 + XiCon Loss:1.4343 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.6114
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7446904182434082
Epoch: 14, Steps: 38 Train Loss: 1.5574 (Forecasting Loss:0.1218 + XiCon Loss:1.4356 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.6114
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.676011323928833
Epoch: 15, Steps: 38 Train Loss: 1.5560 (Forecasting Loss:0.1216 + XiCon Loss:1.4344 x Lambda(1.0)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.6114
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7441165447235107
Epoch: 16, Steps: 38 Train Loss: 1.5574 (Forecasting Loss:0.1215 + XiCon Loss:1.4358 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.6114
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7373647689819336
Epoch: 17, Steps: 38 Train Loss: 1.5615 (Forecasting Loss:0.1228 + XiCon Loss:1.4386 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6114
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7953805923461914
Epoch: 18, Steps: 38 Train Loss: 1.5537 (Forecasting Loss:0.1229 + XiCon Loss:1.4308 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6114
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7201573848724365
Epoch: 19, Steps: 38 Train Loss: 1.5472 (Forecasting Loss:0.1220 + XiCon Loss:1.4252 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.6114
Validation loss decreased (0.107548 --> 0.107267).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7634143829345703
Epoch: 20, Steps: 38 Train Loss: 1.5612 (Forecasting Loss:0.1218 + XiCon Loss:1.4394 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6114
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7120730876922607
Epoch: 21, Steps: 38 Train Loss: 1.5451 (Forecasting Loss:0.1222 + XiCon Loss:1.4229 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.6114
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.755047082901001
Epoch: 22, Steps: 38 Train Loss: 1.5600 (Forecasting Loss:0.1226 + XiCon Loss:1.4374 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6114
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7416751384735107
Epoch: 23, Steps: 38 Train Loss: 1.5449 (Forecasting Loss:0.1208 + XiCon Loss:1.4241 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6114
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7721998691558838
Epoch: 24, Steps: 38 Train Loss: 1.5656 (Forecasting Loss:0.1228 + XiCon Loss:1.4427 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.6114
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6970827579498291
Epoch: 25, Steps: 38 Train Loss: 1.5643 (Forecasting Loss:0.1228 + XiCon Loss:1.4415 x Lambda(1.0)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.6114
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7712960243225098
Epoch: 26, Steps: 38 Train Loss: 1.5551 (Forecasting Loss:0.1230 + XiCon Loss:1.4320 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.6114
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7892518043518066
Epoch: 27, Steps: 38 Train Loss: 1.5679 (Forecasting Loss:0.1226 + XiCon Loss:1.4453 x Lambda(1.0)), Vali MSE Loss: 0.1071 Test MSE Loss: 0.6114
Validation loss decreased (0.107267 --> 0.107145).  Saving model ...
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.6537232398986816
Epoch: 28, Steps: 38 Train Loss: 1.5510 (Forecasting Loss:0.1230 + XiCon Loss:1.4279 x Lambda(1.0)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.6114
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7079496383666992
Epoch: 29, Steps: 38 Train Loss: 1.5553 (Forecasting Loss:0.1226 + XiCon Loss:1.4327 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6114
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.6777937412261963
Epoch: 30, Steps: 38 Train Loss: 1.5619 (Forecasting Loss:0.1224 + XiCon Loss:1.4395 x Lambda(1.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.6114
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7065634727478027
Epoch: 31, Steps: 38 Train Loss: 1.5584 (Forecasting Loss:0.1208 + XiCon Loss:1.4376 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.6114
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.6297883987426758
Epoch: 32, Steps: 38 Train Loss: 1.5751 (Forecasting Loss:0.1208 + XiCon Loss:1.4543 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.6114
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.6853330135345459
Epoch: 33, Steps: 38 Train Loss: 1.5589 (Forecasting Loss:0.1220 + XiCon Loss:1.4369 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.6114
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.6319608688354492
Epoch: 34, Steps: 38 Train Loss: 1.5630 (Forecasting Loss:0.1231 + XiCon Loss:1.4399 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6114
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.6550350189208984
Epoch: 35, Steps: 38 Train Loss: 1.5692 (Forecasting Loss:0.1228 + XiCon Loss:1.4464 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6114
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.7404360771179199
Epoch: 36, Steps: 38 Train Loss: 1.5618 (Forecasting Loss:0.1232 + XiCon Loss:1.4386 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.6114
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.710554838180542
Epoch: 37, Steps: 38 Train Loss: 1.5513 (Forecasting Loss:0.1218 + XiCon Loss:1.4295 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.6114
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6802215576171875, mae:0.5424862504005432, mape:0.2157679796218872, mspe:0.19756393134593964 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3512
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7381870746612549
Epoch: 1, Steps: 38 Train Loss: 2.0146 (Forecasting Loss:0.4233 + XiCon Loss:1.5913 x Lambda(1.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 1.1638
Validation loss decreased (inf --> 0.254916).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6726133823394775
Epoch: 2, Steps: 38 Train Loss: 1.7952 (Forecasting Loss:0.2523 + XiCon Loss:1.5429 x Lambda(1.0)), Vali MSE Loss: 0.1558 Test MSE Loss: 0.5467
Validation loss decreased (0.254916 --> 0.155847).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7332746982574463
Epoch: 3, Steps: 38 Train Loss: 1.6356 (Forecasting Loss:0.1531 + XiCon Loss:1.4825 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.6073
Validation loss decreased (0.155847 --> 0.109693).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8023147583007812
Epoch: 4, Steps: 38 Train Loss: 1.5829 (Forecasting Loss:0.1301 + XiCon Loss:1.4528 x Lambda(1.0)), Vali MSE Loss: 0.1035 Test MSE Loss: 0.6135
Validation loss decreased (0.109693 --> 0.103454).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6249785423278809
Epoch: 5, Steps: 38 Train Loss: 1.5682 (Forecasting Loss:0.1248 + XiCon Loss:1.4434 x Lambda(1.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5837
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7001137733459473
Epoch: 6, Steps: 38 Train Loss: 1.5731 (Forecasting Loss:0.1202 + XiCon Loss:1.4529 x Lambda(1.0)), Vali MSE Loss: 0.1031 Test MSE Loss: 0.5765
Validation loss decreased (0.103454 --> 0.103106).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6545281410217285
Epoch: 7, Steps: 38 Train Loss: 1.5579 (Forecasting Loss:0.1189 + XiCon Loss:1.4390 x Lambda(1.0)), Vali MSE Loss: 0.1026 Test MSE Loss: 0.5771
Validation loss decreased (0.103106 --> 0.102645).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7903892993927002
Epoch: 8, Steps: 38 Train Loss: 1.5522 (Forecasting Loss:0.1175 + XiCon Loss:1.4347 x Lambda(1.0)), Vali MSE Loss: 0.1019 Test MSE Loss: 0.5814
Validation loss decreased (0.102645 --> 0.101889).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7624571323394775
Epoch: 9, Steps: 38 Train Loss: 1.5539 (Forecasting Loss:0.1182 + XiCon Loss:1.4357 x Lambda(1.0)), Vali MSE Loss: 0.1027 Test MSE Loss: 0.5805
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7474703788757324
Epoch: 10, Steps: 38 Train Loss: 1.5575 (Forecasting Loss:0.1173 + XiCon Loss:1.4403 x Lambda(1.0)), Vali MSE Loss: 0.1021 Test MSE Loss: 0.5812
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7141249179840088
Epoch: 11, Steps: 38 Train Loss: 1.5680 (Forecasting Loss:0.1165 + XiCon Loss:1.4515 x Lambda(1.0)), Vali MSE Loss: 0.1026 Test MSE Loss: 0.5809
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7409806251525879
Epoch: 12, Steps: 38 Train Loss: 1.5580 (Forecasting Loss:0.1182 + XiCon Loss:1.4397 x Lambda(1.0)), Vali MSE Loss: 0.1027 Test MSE Loss: 0.5808
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7208380699157715
Epoch: 13, Steps: 38 Train Loss: 1.5552 (Forecasting Loss:0.1166 + XiCon Loss:1.4386 x Lambda(1.0)), Vali MSE Loss: 0.1021 Test MSE Loss: 0.5807
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.685096263885498
Epoch: 14, Steps: 38 Train Loss: 1.5605 (Forecasting Loss:0.1169 + XiCon Loss:1.4436 x Lambda(1.0)), Vali MSE Loss: 0.1025 Test MSE Loss: 0.5807
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.8228754997253418
Epoch: 15, Steps: 38 Train Loss: 1.5507 (Forecasting Loss:0.1175 + XiCon Loss:1.4333 x Lambda(1.0)), Vali MSE Loss: 0.1020 Test MSE Loss: 0.5807
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7304902076721191
Epoch: 16, Steps: 38 Train Loss: 1.5552 (Forecasting Loss:0.1170 + XiCon Loss:1.4383 x Lambda(1.0)), Vali MSE Loss: 0.1027 Test MSE Loss: 0.5807
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7306599617004395
Epoch: 17, Steps: 38 Train Loss: 1.5492 (Forecasting Loss:0.1158 + XiCon Loss:1.4334 x Lambda(1.0)), Vali MSE Loss: 0.1024 Test MSE Loss: 0.5807
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7984757423400879
Epoch: 18, Steps: 38 Train Loss: 1.5486 (Forecasting Loss:0.1161 + XiCon Loss:1.4325 x Lambda(1.0)), Vali MSE Loss: 0.1024 Test MSE Loss: 0.5807
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6326507329940796, mae:0.5301033854484558, mape:0.20804463326931, mspe:0.17961406707763672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3638
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7212092876434326
Epoch: 1, Steps: 38 Train Loss: 2.0915 (Forecasting Loss:0.5041 + XiCon Loss:1.5874 x Lambda(1.0)), Vali MSE Loss: 0.3097 Test MSE Loss: 1.2896
Validation loss decreased (inf --> 0.309676).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7748360633850098
Epoch: 2, Steps: 38 Train Loss: 1.8527 (Forecasting Loss:0.2895 + XiCon Loss:1.5632 x Lambda(1.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.5686
Validation loss decreased (0.309676 --> 0.167949).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7387180328369141
Epoch: 3, Steps: 38 Train Loss: 1.6375 (Forecasting Loss:0.1691 + XiCon Loss:1.4683 x Lambda(1.0)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6512
Validation loss decreased (0.167949 --> 0.118127).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7435290813446045
Epoch: 4, Steps: 38 Train Loss: 1.5692 (Forecasting Loss:0.1415 + XiCon Loss:1.4276 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.5809
Validation loss decreased (0.118127 --> 0.111019).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7026419639587402
Epoch: 5, Steps: 38 Train Loss: 1.5495 (Forecasting Loss:0.1322 + XiCon Loss:1.4174 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.5821
Validation loss decreased (0.111019 --> 0.108791).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7111785411834717
Epoch: 6, Steps: 38 Train Loss: 1.5458 (Forecasting Loss:0.1294 + XiCon Loss:1.4164 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5850
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6935420036315918
Epoch: 7, Steps: 38 Train Loss: 1.5276 (Forecasting Loss:0.1280 + XiCon Loss:1.3995 x Lambda(1.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.5818
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7356045246124268
Epoch: 8, Steps: 38 Train Loss: 1.5291 (Forecasting Loss:0.1277 + XiCon Loss:1.4014 x Lambda(1.0)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.5819
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6809937953948975
Epoch: 9, Steps: 38 Train Loss: 1.5344 (Forecasting Loss:0.1266 + XiCon Loss:1.4077 x Lambda(1.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.5802
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7161195278167725
Epoch: 10, Steps: 38 Train Loss: 1.5313 (Forecasting Loss:0.1273 + XiCon Loss:1.4040 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.5803
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.746476411819458
Epoch: 11, Steps: 38 Train Loss: 1.5153 (Forecasting Loss:0.1265 + XiCon Loss:1.3888 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.5798
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6540780067443848
Epoch: 12, Steps: 38 Train Loss: 1.5455 (Forecasting Loss:0.1253 + XiCon Loss:1.4202 x Lambda(1.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.5797
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7290201187133789
Epoch: 13, Steps: 38 Train Loss: 1.5247 (Forecasting Loss:0.1271 + XiCon Loss:1.3976 x Lambda(1.0)), Vali MSE Loss: 0.1085 Test MSE Loss: 0.5797
Validation loss decreased (0.108791 --> 0.108510).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7059836387634277
Epoch: 14, Steps: 38 Train Loss: 1.5353 (Forecasting Loss:0.1275 + XiCon Loss:1.4078 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.5797
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7131261825561523
Epoch: 15, Steps: 38 Train Loss: 1.5359 (Forecasting Loss:0.1265 + XiCon Loss:1.4094 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5797
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7470963001251221
Epoch: 16, Steps: 38 Train Loss: 1.5202 (Forecasting Loss:0.1267 + XiCon Loss:1.3935 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.5796
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6887180805206299
Epoch: 17, Steps: 38 Train Loss: 1.5200 (Forecasting Loss:0.1278 + XiCon Loss:1.3922 x Lambda(1.0)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.5796
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7850379943847656
Epoch: 18, Steps: 38 Train Loss: 1.5376 (Forecasting Loss:0.1273 + XiCon Loss:1.4102 x Lambda(1.0)), Vali MSE Loss: 0.1094 Test MSE Loss: 0.5796
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7127461433410645
Epoch: 19, Steps: 38 Train Loss: 1.5486 (Forecasting Loss:0.1266 + XiCon Loss:1.4220 x Lambda(1.0)), Vali MSE Loss: 0.1093 Test MSE Loss: 0.5796
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6912515163421631
Epoch: 20, Steps: 38 Train Loss: 1.5208 (Forecasting Loss:0.1272 + XiCon Loss:1.3936 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5796
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7336158752441406
Epoch: 21, Steps: 38 Train Loss: 1.5352 (Forecasting Loss:0.1279 + XiCon Loss:1.4072 x Lambda(1.0)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.5796
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.8115115165710449
Epoch: 22, Steps: 38 Train Loss: 1.5358 (Forecasting Loss:0.1275 + XiCon Loss:1.4083 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.5796
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7680301666259766
Epoch: 23, Steps: 38 Train Loss: 1.5145 (Forecasting Loss:0.1265 + XiCon Loss:1.3880 x Lambda(1.0)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.5796
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6195985078811646, mae:0.5397089719772339, mape:0.21255265176296234, mspe:0.18149696290493011 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3478
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.6519348621368408
Epoch: 1, Steps: 38 Train Loss: 2.0642 (Forecasting Loss:0.4563 + XiCon Loss:1.6079 x Lambda(1.0)), Vali MSE Loss: 0.2734 Test MSE Loss: 1.2483
Validation loss decreased (inf --> 0.273430).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7796595096588135
Epoch: 2, Steps: 38 Train Loss: 1.8356 (Forecasting Loss:0.2795 + XiCon Loss:1.5561 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.5984
Validation loss decreased (0.273430 --> 0.165590).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6714520454406738
Epoch: 3, Steps: 38 Train Loss: 1.6342 (Forecasting Loss:0.1618 + XiCon Loss:1.4724 x Lambda(1.0)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6261
Validation loss decreased (0.165590 --> 0.114627).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7015266418457031
Epoch: 4, Steps: 38 Train Loss: 1.5675 (Forecasting Loss:0.1325 + XiCon Loss:1.4350 x Lambda(1.0)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.6017
Validation loss decreased (0.114627 --> 0.108945).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7895412445068359
Epoch: 5, Steps: 38 Train Loss: 1.5741 (Forecasting Loss:0.1274 + XiCon Loss:1.4466 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6114
Validation loss decreased (0.108945 --> 0.108001).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7197906970977783
Epoch: 6, Steps: 38 Train Loss: 1.5628 (Forecasting Loss:0.1247 + XiCon Loss:1.4380 x Lambda(1.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.6083
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6882519721984863
Epoch: 7, Steps: 38 Train Loss: 1.5498 (Forecasting Loss:0.1232 + XiCon Loss:1.4265 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6061
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7394461631774902
Epoch: 8, Steps: 38 Train Loss: 1.5588 (Forecasting Loss:0.1226 + XiCon Loss:1.4361 x Lambda(1.0)), Vali MSE Loss: 0.1092 Test MSE Loss: 0.6026
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7727429866790771
Epoch: 9, Steps: 38 Train Loss: 1.5543 (Forecasting Loss:0.1217 + XiCon Loss:1.4326 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.6020
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6251218318939209
Epoch: 10, Steps: 38 Train Loss: 1.5717 (Forecasting Loss:0.1226 + XiCon Loss:1.4490 x Lambda(1.0)), Vali MSE Loss: 0.1094 Test MSE Loss: 0.6028
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7867584228515625
Epoch: 11, Steps: 38 Train Loss: 1.5624 (Forecasting Loss:0.1219 + XiCon Loss:1.4405 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6028
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6669769287109375
Epoch: 12, Steps: 38 Train Loss: 1.5695 (Forecasting Loss:0.1220 + XiCon Loss:1.4475 x Lambda(1.0)), Vali MSE Loss: 0.1093 Test MSE Loss: 0.6030
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7264881134033203
Epoch: 13, Steps: 38 Train Loss: 1.5652 (Forecasting Loss:0.1230 + XiCon Loss:1.4422 x Lambda(1.0)), Vali MSE Loss: 0.1092 Test MSE Loss: 0.6030
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7533633708953857
Epoch: 14, Steps: 38 Train Loss: 1.5617 (Forecasting Loss:0.1212 + XiCon Loss:1.4405 x Lambda(1.0)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.6030
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7840960025787354
Epoch: 15, Steps: 38 Train Loss: 1.5585 (Forecasting Loss:0.1221 + XiCon Loss:1.4364 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.6030
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6722615361213684, mae:0.5505079627037048, mape:0.2166886329650879, mspe:0.1906389445066452 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6481+-0.03298, MAE:0.5402+-0.00918, MAPE:0.2127+-0.00450, MSPE:0.1858+-0.00988, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2570
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.9689018726348877
Epoch: 1, Steps: 37 Train Loss: 2.1029 (Forecasting Loss:0.4932 + XiCon Loss:1.6097 x Lambda(1.0)), Vali MSE Loss: 0.3094 Test MSE Loss: 1.2591
Validation loss decreased (inf --> 0.309436).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7291479110717773
Epoch: 2, Steps: 37 Train Loss: 1.8416 (Forecasting Loss:0.3026 + XiCon Loss:1.5390 x Lambda(1.0)), Vali MSE Loss: 0.1906 Test MSE Loss: 0.6997
Validation loss decreased (0.309436 --> 0.190592).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6384255886077881
Epoch: 3, Steps: 37 Train Loss: 1.6675 (Forecasting Loss:0.1954 + XiCon Loss:1.4721 x Lambda(1.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.7260
Validation loss decreased (0.190592 --> 0.123619).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6963121891021729
Epoch: 4, Steps: 37 Train Loss: 1.6150 (Forecasting Loss:0.1528 + XiCon Loss:1.4622 x Lambda(1.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6731
Validation loss decreased (0.123619 --> 0.116354).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6674332618713379
Epoch: 5, Steps: 37 Train Loss: 1.6110 (Forecasting Loss:0.1474 + XiCon Loss:1.4637 x Lambda(1.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6756
Validation loss decreased (0.116354 --> 0.114838).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7590343952178955
Epoch: 6, Steps: 37 Train Loss: 1.5993 (Forecasting Loss:0.1451 + XiCon Loss:1.4542 x Lambda(1.0)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6667
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7303464412689209
Epoch: 7, Steps: 37 Train Loss: 1.5927 (Forecasting Loss:0.1431 + XiCon Loss:1.4496 x Lambda(1.0)), Vali MSE Loss: 0.1127 Test MSE Loss: 0.6713
Validation loss decreased (0.114838 --> 0.112722).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.8515489101409912
Epoch: 8, Steps: 37 Train Loss: 1.5958 (Forecasting Loss:0.1441 + XiCon Loss:1.4517 x Lambda(1.0)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.6725
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6711223125457764
Epoch: 9, Steps: 37 Train Loss: 1.5902 (Forecasting Loss:0.1426 + XiCon Loss:1.4476 x Lambda(1.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6723
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7290618419647217
Epoch: 10, Steps: 37 Train Loss: 1.5966 (Forecasting Loss:0.1431 + XiCon Loss:1.4535 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6727
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6710050106048584
Epoch: 11, Steps: 37 Train Loss: 1.5895 (Forecasting Loss:0.1427 + XiCon Loss:1.4469 x Lambda(1.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6726
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7038040161132812
Epoch: 12, Steps: 37 Train Loss: 1.5929 (Forecasting Loss:0.1432 + XiCon Loss:1.4497 x Lambda(1.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6726
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7174522876739502
Epoch: 13, Steps: 37 Train Loss: 1.5888 (Forecasting Loss:0.1422 + XiCon Loss:1.4467 x Lambda(1.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6726
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.716137170791626
Epoch: 14, Steps: 37 Train Loss: 1.5971 (Forecasting Loss:0.1426 + XiCon Loss:1.4544 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6726
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6517455577850342
Epoch: 15, Steps: 37 Train Loss: 1.5933 (Forecasting Loss:0.1432 + XiCon Loss:1.4501 x Lambda(1.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6726
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6430552005767822
Epoch: 16, Steps: 37 Train Loss: 1.5919 (Forecasting Loss:0.1414 + XiCon Loss:1.4505 x Lambda(1.0)), Vali MSE Loss: 0.1135 Test MSE Loss: 0.6726
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6959962844848633
Epoch: 17, Steps: 37 Train Loss: 1.5894 (Forecasting Loss:0.1416 + XiCon Loss:1.4478 x Lambda(1.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6726
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.724537193775177, mae:0.6180058121681213, mape:0.24362999200820923, mspe:0.20326530933380127 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3333
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7041351795196533
Epoch: 1, Steps: 37 Train Loss: 2.1338 (Forecasting Loss:0.5245 + XiCon Loss:1.6093 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 1.2530
Validation loss decreased (inf --> 0.292722).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7147190570831299
Epoch: 2, Steps: 37 Train Loss: 1.8821 (Forecasting Loss:0.3018 + XiCon Loss:1.5803 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.7072
Validation loss decreased (0.292722 --> 0.166639).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7247469425201416
Epoch: 3, Steps: 37 Train Loss: 1.6739 (Forecasting Loss:0.1790 + XiCon Loss:1.4949 x Lambda(1.0)), Vali MSE Loss: 0.1337 Test MSE Loss: 0.7228
Validation loss decreased (0.166639 --> 0.133724).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7300918102264404
Epoch: 4, Steps: 37 Train Loss: 1.6184 (Forecasting Loss:0.1543 + XiCon Loss:1.4641 x Lambda(1.0)), Vali MSE Loss: 0.1286 Test MSE Loss: 0.6645
Validation loss decreased (0.133724 --> 0.128643).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7873871326446533
Epoch: 5, Steps: 37 Train Loss: 1.6118 (Forecasting Loss:0.1488 + XiCon Loss:1.4630 x Lambda(1.0)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.7044
Validation loss decreased (0.128643 --> 0.115879).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6779367923736572
Epoch: 6, Steps: 37 Train Loss: 1.5937 (Forecasting Loss:0.1441 + XiCon Loss:1.4495 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6948
Validation loss decreased (0.115879 --> 0.115232).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6970655918121338
Epoch: 7, Steps: 37 Train Loss: 1.5896 (Forecasting Loss:0.1432 + XiCon Loss:1.4464 x Lambda(1.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.7030
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.674839973449707
Epoch: 8, Steps: 37 Train Loss: 1.5898 (Forecasting Loss:0.1429 + XiCon Loss:1.4469 x Lambda(1.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.7001
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6414055824279785
Epoch: 9, Steps: 37 Train Loss: 1.5940 (Forecasting Loss:0.1424 + XiCon Loss:1.4516 x Lambda(1.0)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.7000
Validation loss decreased (0.115232 --> 0.114298).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6511242389678955
Epoch: 10, Steps: 37 Train Loss: 1.5952 (Forecasting Loss:0.1420 + XiCon Loss:1.4532 x Lambda(1.0)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.7017
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6209969520568848
Epoch: 11, Steps: 37 Train Loss: 1.5946 (Forecasting Loss:0.1421 + XiCon Loss:1.4525 x Lambda(1.0)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.7009
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6279051303863525
Epoch: 12, Steps: 37 Train Loss: 1.5796 (Forecasting Loss:0.1404 + XiCon Loss:1.4391 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.7009
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7182860374450684
Epoch: 13, Steps: 37 Train Loss: 1.5916 (Forecasting Loss:0.1413 + XiCon Loss:1.4503 x Lambda(1.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.7007
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6633853912353516
Epoch: 14, Steps: 37 Train Loss: 1.6017 (Forecasting Loss:0.1423 + XiCon Loss:1.4595 x Lambda(1.0)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.7006
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6976861953735352
Epoch: 15, Steps: 37 Train Loss: 1.5915 (Forecasting Loss:0.1403 + XiCon Loss:1.4512 x Lambda(1.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.7006
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7145824432373047
Epoch: 16, Steps: 37 Train Loss: 1.5883 (Forecasting Loss:0.1419 + XiCon Loss:1.4463 x Lambda(1.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.7006
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6772518157958984
Epoch: 17, Steps: 37 Train Loss: 1.5862 (Forecasting Loss:0.1421 + XiCon Loss:1.4440 x Lambda(1.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.7006
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.737943172454834
Epoch: 18, Steps: 37 Train Loss: 1.5907 (Forecasting Loss:0.1427 + XiCon Loss:1.4480 x Lambda(1.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.7006
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7466320991516113
Epoch: 19, Steps: 37 Train Loss: 1.5891 (Forecasting Loss:0.1420 + XiCon Loss:1.4471 x Lambda(1.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.7006
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7590395212173462, mae:0.640933632850647, mape:0.2511182129383087, mspe:0.20561206340789795 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7138454914093018
Epoch: 1, Steps: 37 Train Loss: 2.0627 (Forecasting Loss:0.4560 + XiCon Loss:1.6066 x Lambda(1.0)), Vali MSE Loss: 0.2863 Test MSE Loss: 1.1832
Validation loss decreased (inf --> 0.286261).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6184885501861572
Epoch: 2, Steps: 37 Train Loss: 1.8505 (Forecasting Loss:0.2946 + XiCon Loss:1.5558 x Lambda(1.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.7039
Validation loss decreased (0.286261 --> 0.186069).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.785775899887085
Epoch: 3, Steps: 37 Train Loss: 1.6668 (Forecasting Loss:0.1936 + XiCon Loss:1.4732 x Lambda(1.0)), Vali MSE Loss: 0.1285 Test MSE Loss: 0.6841
Validation loss decreased (0.186069 --> 0.128535).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8061339855194092
Epoch: 4, Steps: 37 Train Loss: 1.6249 (Forecasting Loss:0.1555 + XiCon Loss:1.4693 x Lambda(1.0)), Vali MSE Loss: 0.1218 Test MSE Loss: 0.6310
Validation loss decreased (0.128535 --> 0.121791).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.744642972946167
Epoch: 5, Steps: 37 Train Loss: 1.6096 (Forecasting Loss:0.1476 + XiCon Loss:1.4620 x Lambda(1.0)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6500
Validation loss decreased (0.121791 --> 0.117417).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.727996826171875
Epoch: 6, Steps: 37 Train Loss: 1.6063 (Forecasting Loss:0.1454 + XiCon Loss:1.4609 x Lambda(1.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6482
Validation loss decreased (0.117417 --> 0.115347).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7427937984466553
Epoch: 7, Steps: 37 Train Loss: 1.5928 (Forecasting Loss:0.1430 + XiCon Loss:1.4498 x Lambda(1.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6486
Validation loss decreased (0.115347 --> 0.115326).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6838390827178955
Epoch: 8, Steps: 37 Train Loss: 1.5973 (Forecasting Loss:0.1442 + XiCon Loss:1.4531 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6493
Validation loss decreased (0.115326 --> 0.115080).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7490191459655762
Epoch: 9, Steps: 37 Train Loss: 1.5925 (Forecasting Loss:0.1434 + XiCon Loss:1.4491 x Lambda(1.0)), Vali MSE Loss: 0.1155 Test MSE Loss: 0.6496
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.672781229019165
Epoch: 10, Steps: 37 Train Loss: 1.5984 (Forecasting Loss:0.1431 + XiCon Loss:1.4553 x Lambda(1.0)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6492
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6467406749725342
Epoch: 11, Steps: 37 Train Loss: 1.5992 (Forecasting Loss:0.1437 + XiCon Loss:1.4555 x Lambda(1.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6494
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6732442378997803
Epoch: 12, Steps: 37 Train Loss: 1.6023 (Forecasting Loss:0.1429 + XiCon Loss:1.4593 x Lambda(1.0)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6493
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.728459358215332
Epoch: 13, Steps: 37 Train Loss: 1.5951 (Forecasting Loss:0.1430 + XiCon Loss:1.4521 x Lambda(1.0)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6492
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7741906642913818
Epoch: 14, Steps: 37 Train Loss: 1.6077 (Forecasting Loss:0.1432 + XiCon Loss:1.4645 x Lambda(1.0)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.6492
Validation loss decreased (0.115080 --> 0.115006).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.710639476776123
Epoch: 15, Steps: 37 Train Loss: 1.5983 (Forecasting Loss:0.1432 + XiCon Loss:1.4551 x Lambda(1.0)), Vali MSE Loss: 0.1172 Test MSE Loss: 0.6492
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6768889427185059
Epoch: 16, Steps: 37 Train Loss: 1.5990 (Forecasting Loss:0.1431 + XiCon Loss:1.4559 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6492
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7352476119995117
Epoch: 17, Steps: 37 Train Loss: 1.5981 (Forecasting Loss:0.1432 + XiCon Loss:1.4549 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6492
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7229716777801514
Epoch: 18, Steps: 37 Train Loss: 1.5918 (Forecasting Loss:0.1429 + XiCon Loss:1.4489 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6492
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7330009937286377
Epoch: 19, Steps: 37 Train Loss: 1.5970 (Forecasting Loss:0.1428 + XiCon Loss:1.4543 x Lambda(1.0)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.6492
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7531704902648926
Epoch: 20, Steps: 37 Train Loss: 1.5955 (Forecasting Loss:0.1431 + XiCon Loss:1.4524 x Lambda(1.0)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6492
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7337112426757812
Epoch: 21, Steps: 37 Train Loss: 1.5904 (Forecasting Loss:0.1434 + XiCon Loss:1.4470 x Lambda(1.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6492
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7038805484771729
Epoch: 22, Steps: 37 Train Loss: 1.5944 (Forecasting Loss:0.1433 + XiCon Loss:1.4511 x Lambda(1.0)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6492
Validation loss decreased (0.115006 --> 0.114636).  Saving model ...
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6273584365844727
Epoch: 23, Steps: 37 Train Loss: 1.5967 (Forecasting Loss:0.1434 + XiCon Loss:1.4533 x Lambda(1.0)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.6492
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6949179172515869
Epoch: 24, Steps: 37 Train Loss: 1.6016 (Forecasting Loss:0.1417 + XiCon Loss:1.4599 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6492
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6835794448852539
Epoch: 25, Steps: 37 Train Loss: 1.5977 (Forecasting Loss:0.1433 + XiCon Loss:1.4544 x Lambda(1.0)), Vali MSE Loss: 0.1165 Test MSE Loss: 0.6492
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.727794885635376
Epoch: 26, Steps: 37 Train Loss: 1.6079 (Forecasting Loss:0.1420 + XiCon Loss:1.4659 x Lambda(1.0)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.6492
Validation loss decreased (0.114636 --> 0.114402).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7213385105133057
Epoch: 27, Steps: 37 Train Loss: 1.6043 (Forecasting Loss:0.1434 + XiCon Loss:1.4609 x Lambda(1.0)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.6492
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7006604671478271
Epoch: 28, Steps: 37 Train Loss: 1.5916 (Forecasting Loss:0.1424 + XiCon Loss:1.4492 x Lambda(1.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6492
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.6629610061645508
Epoch: 29, Steps: 37 Train Loss: 1.5946 (Forecasting Loss:0.1428 + XiCon Loss:1.4518 x Lambda(1.0)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.6492
Validation loss decreased (0.114402 --> 0.113350).  Saving model ...
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.6686503887176514
Epoch: 30, Steps: 37 Train Loss: 1.5978 (Forecasting Loss:0.1430 + XiCon Loss:1.4548 x Lambda(1.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6492
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.6839091777801514
Epoch: 31, Steps: 37 Train Loss: 1.6011 (Forecasting Loss:0.1424 + XiCon Loss:1.4588 x Lambda(1.0)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.6492
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.6904609203338623
Epoch: 32, Steps: 37 Train Loss: 1.6018 (Forecasting Loss:0.1429 + XiCon Loss:1.4588 x Lambda(1.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6492
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.74700927734375
Epoch: 33, Steps: 37 Train Loss: 1.6066 (Forecasting Loss:0.1433 + XiCon Loss:1.4633 x Lambda(1.0)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6492
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.66629958152771
Epoch: 34, Steps: 37 Train Loss: 1.5955 (Forecasting Loss:0.1429 + XiCon Loss:1.4526 x Lambda(1.0)), Vali MSE Loss: 0.1144 Test MSE Loss: 0.6492
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.7462191581726074
Epoch: 35, Steps: 37 Train Loss: 1.6041 (Forecasting Loss:0.1432 + XiCon Loss:1.4609 x Lambda(1.0)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6492
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.7418081760406494
Epoch: 36, Steps: 37 Train Loss: 1.5997 (Forecasting Loss:0.1424 + XiCon Loss:1.4573 x Lambda(1.0)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6492
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.6766800880432129
Epoch: 37, Steps: 37 Train Loss: 1.6011 (Forecasting Loss:0.1435 + XiCon Loss:1.4577 x Lambda(1.0)), Vali MSE Loss: 0.1168 Test MSE Loss: 0.6492
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
Epoch: 38 cost time: 0.6704120635986328
Epoch: 38, Steps: 37 Train Loss: 1.6001 (Forecasting Loss:0.1433 + XiCon Loss:1.4568 x Lambda(1.0)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.6492
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
Epoch: 39 cost time: 0.7032763957977295
Epoch: 39, Steps: 37 Train Loss: 1.6000 (Forecasting Loss:0.1434 + XiCon Loss:1.4567 x Lambda(1.0)), Vali MSE Loss: 0.1155 Test MSE Loss: 0.6492
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.6915582418441772, mae:0.6068810820579529, mape:0.24044828116893768, mspe:0.20205965638160706 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3504
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7015347480773926
Epoch: 1, Steps: 37 Train Loss: 2.1322 (Forecasting Loss:0.5362 + XiCon Loss:1.5960 x Lambda(1.0)), Vali MSE Loss: 0.3159 Test MSE Loss: 1.4363
Validation loss decreased (inf --> 0.315914).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7029976844787598
Epoch: 2, Steps: 37 Train Loss: 1.8317 (Forecasting Loss:0.3138 + XiCon Loss:1.5179 x Lambda(1.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.7326
Validation loss decreased (0.315914 --> 0.172673).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.690040111541748
Epoch: 3, Steps: 37 Train Loss: 1.6484 (Forecasting Loss:0.1876 + XiCon Loss:1.4608 x Lambda(1.0)), Vali MSE Loss: 0.1313 Test MSE Loss: 0.6866
Validation loss decreased (0.172673 --> 0.131257).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6664562225341797
Epoch: 4, Steps: 37 Train Loss: 1.5864 (Forecasting Loss:0.1561 + XiCon Loss:1.4303 x Lambda(1.0)), Vali MSE Loss: 0.1186 Test MSE Loss: 0.6643
Validation loss decreased (0.131257 --> 0.118564).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.683232307434082
Epoch: 5, Steps: 37 Train Loss: 1.5635 (Forecasting Loss:0.1466 + XiCon Loss:1.4169 x Lambda(1.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6590
Validation loss decreased (0.118564 --> 0.116942).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6866552829742432
Epoch: 6, Steps: 37 Train Loss: 1.5459 (Forecasting Loss:0.1425 + XiCon Loss:1.4035 x Lambda(1.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6664
Validation loss decreased (0.116942 --> 0.115616).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7412805557250977
Epoch: 7, Steps: 37 Train Loss: 1.5556 (Forecasting Loss:0.1420 + XiCon Loss:1.4136 x Lambda(1.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6781
Validation loss decreased (0.115616 --> 0.112765).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6869168281555176
Epoch: 8, Steps: 37 Train Loss: 1.5489 (Forecasting Loss:0.1421 + XiCon Loss:1.4068 x Lambda(1.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6800
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6653182506561279
Epoch: 9, Steps: 37 Train Loss: 1.5535 (Forecasting Loss:0.1412 + XiCon Loss:1.4123 x Lambda(1.0)), Vali MSE Loss: 0.1135 Test MSE Loss: 0.6756
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6694920063018799
Epoch: 10, Steps: 37 Train Loss: 1.5372 (Forecasting Loss:0.1404 + XiCon Loss:1.3968 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6746
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6763932704925537
Epoch: 11, Steps: 37 Train Loss: 1.5417 (Forecasting Loss:0.1403 + XiCon Loss:1.4014 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6749
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6584641933441162
Epoch: 12, Steps: 37 Train Loss: 1.5450 (Forecasting Loss:0.1411 + XiCon Loss:1.4039 x Lambda(1.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6746
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7035892009735107
Epoch: 13, Steps: 37 Train Loss: 1.5418 (Forecasting Loss:0.1392 + XiCon Loss:1.4025 x Lambda(1.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6744
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7188067436218262
Epoch: 14, Steps: 37 Train Loss: 1.5478 (Forecasting Loss:0.1400 + XiCon Loss:1.4078 x Lambda(1.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.6744
Validation loss decreased (0.112765 --> 0.111710).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7402498722076416
Epoch: 15, Steps: 37 Train Loss: 1.5464 (Forecasting Loss:0.1401 + XiCon Loss:1.4063 x Lambda(1.0)), Vali MSE Loss: 0.1119 Test MSE Loss: 0.6744
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6715211868286133
Epoch: 16, Steps: 37 Train Loss: 1.5323 (Forecasting Loss:0.1397 + XiCon Loss:1.3925 x Lambda(1.0)), Vali MSE Loss: 0.1119 Test MSE Loss: 0.6744
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.723966121673584
Epoch: 17, Steps: 37 Train Loss: 1.5472 (Forecasting Loss:0.1403 + XiCon Loss:1.4068 x Lambda(1.0)), Vali MSE Loss: 0.1127 Test MSE Loss: 0.6744
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7189452648162842
Epoch: 18, Steps: 37 Train Loss: 1.5454 (Forecasting Loss:0.1407 + XiCon Loss:1.4047 x Lambda(1.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6744
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6559431552886963
Epoch: 19, Steps: 37 Train Loss: 1.5451 (Forecasting Loss:0.1414 + XiCon Loss:1.4037 x Lambda(1.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6744
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7503206729888916
Epoch: 20, Steps: 37 Train Loss: 1.5404 (Forecasting Loss:0.1401 + XiCon Loss:1.4004 x Lambda(1.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6744
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7149827480316162
Epoch: 21, Steps: 37 Train Loss: 1.5419 (Forecasting Loss:0.1403 + XiCon Loss:1.4016 x Lambda(1.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6744
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6726589202880859
Epoch: 22, Steps: 37 Train Loss: 1.5520 (Forecasting Loss:0.1414 + XiCon Loss:1.4106 x Lambda(1.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6744
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7674176692962646
Epoch: 23, Steps: 37 Train Loss: 1.5453 (Forecasting Loss:0.1404 + XiCon Loss:1.4048 x Lambda(1.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6744
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6547501087188721
Epoch: 24, Steps: 37 Train Loss: 1.5382 (Forecasting Loss:0.1403 + XiCon Loss:1.3979 x Lambda(1.0)), Vali MSE Loss: 0.1120 Test MSE Loss: 0.6744
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7321193814277649, mae:0.6166402101516724, mape:0.24342340230941772, mspe:0.20856322348117828 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3526
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7223694324493408
Epoch: 1, Steps: 37 Train Loss: 2.1153 (Forecasting Loss:0.5088 + XiCon Loss:1.6065 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 1.3121
Validation loss decreased (inf --> 0.312568).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6651496887207031
Epoch: 2, Steps: 37 Train Loss: 1.8399 (Forecasting Loss:0.2815 + XiCon Loss:1.5584 x Lambda(1.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.6643
Validation loss decreased (0.312568 --> 0.184367).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7268612384796143
Epoch: 3, Steps: 37 Train Loss: 1.6784 (Forecasting Loss:0.1838 + XiCon Loss:1.4945 x Lambda(1.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.6879
Validation loss decreased (0.184367 --> 0.144915).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7673828601837158
Epoch: 4, Steps: 37 Train Loss: 1.6054 (Forecasting Loss:0.1494 + XiCon Loss:1.4560 x Lambda(1.0)), Vali MSE Loss: 0.1304 Test MSE Loss: 0.6619
Validation loss decreased (0.144915 --> 0.130401).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7443675994873047
Epoch: 5, Steps: 37 Train Loss: 1.5862 (Forecasting Loss:0.1390 + XiCon Loss:1.4472 x Lambda(1.0)), Vali MSE Loss: 0.1261 Test MSE Loss: 0.6648
Validation loss decreased (0.130401 --> 0.126107).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6946001052856445
Epoch: 6, Steps: 37 Train Loss: 1.5770 (Forecasting Loss:0.1323 + XiCon Loss:1.4447 x Lambda(1.0)), Vali MSE Loss: 0.1242 Test MSE Loss: 0.6567
Validation loss decreased (0.126107 --> 0.124172).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7105927467346191
Epoch: 7, Steps: 37 Train Loss: 1.5782 (Forecasting Loss:0.1315 + XiCon Loss:1.4467 x Lambda(1.0)), Vali MSE Loss: 0.1274 Test MSE Loss: 0.6446
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7409849166870117
Epoch: 8, Steps: 37 Train Loss: 1.5744 (Forecasting Loss:0.1289 + XiCon Loss:1.4455 x Lambda(1.0)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6528
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6762335300445557
Epoch: 9, Steps: 37 Train Loss: 1.5812 (Forecasting Loss:0.1263 + XiCon Loss:1.4550 x Lambda(1.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6520
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6810882091522217
Epoch: 10, Steps: 37 Train Loss: 1.5737 (Forecasting Loss:0.1281 + XiCon Loss:1.4456 x Lambda(1.0)), Vali MSE Loss: 0.1250 Test MSE Loss: 0.6513
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7172963619232178
Epoch: 11, Steps: 37 Train Loss: 1.5764 (Forecasting Loss:0.1276 + XiCon Loss:1.4488 x Lambda(1.0)), Vali MSE Loss: 0.1229 Test MSE Loss: 0.6522
Validation loss decreased (0.124172 --> 0.122939).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7245113849639893
Epoch: 12, Steps: 37 Train Loss: 1.5648 (Forecasting Loss:0.1269 + XiCon Loss:1.4380 x Lambda(1.0)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6525
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7057816982269287
Epoch: 13, Steps: 37 Train Loss: 1.5762 (Forecasting Loss:0.1276 + XiCon Loss:1.4486 x Lambda(1.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6527
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6960759162902832
Epoch: 14, Steps: 37 Train Loss: 1.5691 (Forecasting Loss:0.1275 + XiCon Loss:1.4416 x Lambda(1.0)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.6529
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7024407386779785
Epoch: 15, Steps: 37 Train Loss: 1.5628 (Forecasting Loss:0.1296 + XiCon Loss:1.4333 x Lambda(1.0)), Vali MSE Loss: 0.1253 Test MSE Loss: 0.6530
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.669377326965332
Epoch: 16, Steps: 37 Train Loss: 1.5670 (Forecasting Loss:0.1279 + XiCon Loss:1.4391 x Lambda(1.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6530
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7482821941375732
Epoch: 17, Steps: 37 Train Loss: 1.5628 (Forecasting Loss:0.1291 + XiCon Loss:1.4337 x Lambda(1.0)), Vali MSE Loss: 0.1239 Test MSE Loss: 0.6530
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6644077301025391
Epoch: 18, Steps: 37 Train Loss: 1.5576 (Forecasting Loss:0.1259 + XiCon Loss:1.4317 x Lambda(1.0)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.6530
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6115658283233643
Epoch: 19, Steps: 37 Train Loss: 1.5813 (Forecasting Loss:0.1268 + XiCon Loss:1.4545 x Lambda(1.0)), Vali MSE Loss: 0.1256 Test MSE Loss: 0.6530
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.631216287612915
Epoch: 20, Steps: 37 Train Loss: 1.5712 (Forecasting Loss:0.1271 + XiCon Loss:1.4441 x Lambda(1.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6530
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.734715461730957
Epoch: 21, Steps: 37 Train Loss: 1.5577 (Forecasting Loss:0.1270 + XiCon Loss:1.4307 x Lambda(1.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7045177817344666, mae:0.599795937538147, mape:0.23491837084293365, mspe:0.19810421764850616 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7224+-0.03233, MAE:0.6165+-0.01934, MAPE:0.2427+-0.00729, MSPE:0.2035+-0.00486, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2560
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.9703340530395508
Epoch: 1, Steps: 35 Train Loss: 2.0863 (Forecasting Loss:0.4920 + XiCon Loss:1.5943 x Lambda(1.0)), Vali MSE Loss: 0.3090 Test MSE Loss: 1.2109
Validation loss decreased (inf --> 0.309040).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7051918506622314
Epoch: 2, Steps: 35 Train Loss: 1.7534 (Forecasting Loss:0.3167 + XiCon Loss:1.4367 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.7111
Validation loss decreased (0.309040 --> 0.210139).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7396881580352783
Epoch: 3, Steps: 35 Train Loss: 1.6551 (Forecasting Loss:0.1986 + XiCon Loss:1.4565 x Lambda(1.0)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.7068
Validation loss decreased (0.210139 --> 0.142895).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6727547645568848
Epoch: 4, Steps: 35 Train Loss: 1.9514 (Forecasting Loss:0.1696 + XiCon Loss:1.7817 x Lambda(1.0)), Vali MSE Loss: 0.1364 Test MSE Loss: 0.6483
Validation loss decreased (0.142895 --> 0.136358).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6876921653747559
Epoch: 5, Steps: 35 Train Loss: 2.1887 (Forecasting Loss:0.1692 + XiCon Loss:2.0196 x Lambda(1.0)), Vali MSE Loss: 0.1246 Test MSE Loss: 0.8330
Validation loss decreased (0.136358 --> 0.124629).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7403171062469482
Epoch: 6, Steps: 35 Train Loss: 2.2075 (Forecasting Loss:0.1496 + XiCon Loss:2.0579 x Lambda(1.0)), Vali MSE Loss: 0.1397 Test MSE Loss: 0.7637
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7273235321044922
Epoch: 7, Steps: 35 Train Loss: 2.3962 (Forecasting Loss:0.1492 + XiCon Loss:2.2469 x Lambda(1.0)), Vali MSE Loss: 0.1351 Test MSE Loss: 0.7992
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6946513652801514
Epoch: 8, Steps: 35 Train Loss: 2.2540 (Forecasting Loss:0.1414 + XiCon Loss:2.1126 x Lambda(1.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.7831
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6789000034332275
Epoch: 9, Steps: 35 Train Loss: 2.2459 (Forecasting Loss:0.1320 + XiCon Loss:2.1139 x Lambda(1.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.7899
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7291696071624756
Epoch: 10, Steps: 35 Train Loss: 2.2520 (Forecasting Loss:0.1298 + XiCon Loss:2.1222 x Lambda(1.0)), Vali MSE Loss: 0.1331 Test MSE Loss: 0.8149
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6291944980621338
Epoch: 11, Steps: 35 Train Loss: 2.3446 (Forecasting Loss:0.1331 + XiCon Loss:2.2115 x Lambda(1.0)), Vali MSE Loss: 0.1370 Test MSE Loss: 0.8131
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6982381343841553
Epoch: 12, Steps: 35 Train Loss: 2.3843 (Forecasting Loss:0.1323 + XiCon Loss:2.2520 x Lambda(1.0)), Vali MSE Loss: 0.1386 Test MSE Loss: 0.8107
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6696910858154297
Epoch: 13, Steps: 35 Train Loss: 2.3564 (Forecasting Loss:0.1313 + XiCon Loss:2.2251 x Lambda(1.0)), Vali MSE Loss: 0.1378 Test MSE Loss: 0.8117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6656296253204346
Epoch: 14, Steps: 35 Train Loss: 2.2657 (Forecasting Loss:0.1295 + XiCon Loss:2.1362 x Lambda(1.0)), Vali MSE Loss: 0.1346 Test MSE Loss: 0.8123
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7326164245605469
Epoch: 15, Steps: 35 Train Loss: 2.3335 (Forecasting Loss:0.1313 + XiCon Loss:2.2023 x Lambda(1.0)), Vali MSE Loss: 0.1379 Test MSE Loss: 0.8124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.8945579528808594, mae:0.7713915109634399, mape:0.28704068064689636, mspe:0.1898719221353531 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3333
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7088515758514404
Epoch: 1, Steps: 35 Train Loss: 2.0566 (Forecasting Loss:0.4626 + XiCon Loss:1.5940 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 1.1206
Validation loss decreased (inf --> 0.310670).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7479057312011719
Epoch: 2, Steps: 35 Train Loss: 1.7510 (Forecasting Loss:0.3224 + XiCon Loss:1.4286 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.7290
Validation loss decreased (0.310670 --> 0.204333).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7263424396514893
Epoch: 3, Steps: 35 Train Loss: 1.7298 (Forecasting Loss:0.2265 + XiCon Loss:1.5033 x Lambda(1.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.7037
Validation loss decreased (0.204333 --> 0.142415).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7187597751617432
Epoch: 4, Steps: 35 Train Loss: 2.0118 (Forecasting Loss:0.1870 + XiCon Loss:1.8248 x Lambda(1.0)), Vali MSE Loss: 0.1286 Test MSE Loss: 0.6847
Validation loss decreased (0.142415 --> 0.128556).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.705963134765625
Epoch: 5, Steps: 35 Train Loss: 1.9737 (Forecasting Loss:0.1824 + XiCon Loss:1.7913 x Lambda(1.0)), Vali MSE Loss: 0.1278 Test MSE Loss: 0.6896
Validation loss decreased (0.128556 --> 0.127804).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6939651966094971
Epoch: 6, Steps: 35 Train Loss: 2.3278 (Forecasting Loss:0.1879 + XiCon Loss:2.1399 x Lambda(1.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6744
Validation loss decreased (0.127804 --> 0.125899).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6310184001922607
Epoch: 7, Steps: 35 Train Loss: 2.3235 (Forecasting Loss:0.1734 + XiCon Loss:2.1500 x Lambda(1.0)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6688
Validation loss decreased (0.125899 --> 0.124917).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6001324653625488
Epoch: 8, Steps: 35 Train Loss: 2.2114 (Forecasting Loss:0.1696 + XiCon Loss:2.0418 x Lambda(1.0)), Vali MSE Loss: 0.1277 Test MSE Loss: 0.6689
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6377058029174805
Epoch: 9, Steps: 35 Train Loss: 2.1089 (Forecasting Loss:0.1687 + XiCon Loss:1.9402 x Lambda(1.0)), Vali MSE Loss: 0.1275 Test MSE Loss: 0.6687
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6405255794525146
Epoch: 10, Steps: 35 Train Loss: 2.2453 (Forecasting Loss:0.1681 + XiCon Loss:2.0772 x Lambda(1.0)), Vali MSE Loss: 0.1264 Test MSE Loss: 0.6695
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6856098175048828
Epoch: 11, Steps: 35 Train Loss: 2.2027 (Forecasting Loss:0.1688 + XiCon Loss:2.0339 x Lambda(1.0)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.6692
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6059303283691406
Epoch: 12, Steps: 35 Train Loss: 2.3052 (Forecasting Loss:0.1688 + XiCon Loss:2.1365 x Lambda(1.0)), Vali MSE Loss: 0.1264 Test MSE Loss: 0.6695
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6000211238861084
Epoch: 13, Steps: 35 Train Loss: 2.2481 (Forecasting Loss:0.1672 + XiCon Loss:2.0810 x Lambda(1.0)), Vali MSE Loss: 0.1277 Test MSE Loss: 0.6696
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7056591510772705
Epoch: 14, Steps: 35 Train Loss: 2.1752 (Forecasting Loss:0.1686 + XiCon Loss:2.0066 x Lambda(1.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6697
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6848244667053223
Epoch: 15, Steps: 35 Train Loss: 2.2524 (Forecasting Loss:0.1683 + XiCon Loss:2.0840 x Lambda(1.0)), Vali MSE Loss: 0.1267 Test MSE Loss: 0.6697
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6293909549713135
Epoch: 16, Steps: 35 Train Loss: 2.1437 (Forecasting Loss:0.1689 + XiCon Loss:1.9748 x Lambda(1.0)), Vali MSE Loss: 0.1270 Test MSE Loss: 0.6697
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7040908336639404
Epoch: 17, Steps: 35 Train Loss: 2.1412 (Forecasting Loss:0.1685 + XiCon Loss:1.9727 x Lambda(1.0)), Vali MSE Loss: 0.1276 Test MSE Loss: 0.6697
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6944547295570374, mae:0.6432120203971863, mape:0.2573161721229553, mspe:0.2013852447271347 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3474
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7158317565917969
Epoch: 1, Steps: 35 Train Loss: 2.0978 (Forecasting Loss:0.5178 + XiCon Loss:1.5800 x Lambda(1.0)), Vali MSE Loss: 0.3065 Test MSE Loss: 1.3207
Validation loss decreased (inf --> 0.306540).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7219998836517334
Epoch: 2, Steps: 35 Train Loss: 1.7748 (Forecasting Loss:0.3313 + XiCon Loss:1.4435 x Lambda(1.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.7180
Validation loss decreased (0.306540 --> 0.198642).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6288421154022217
Epoch: 3, Steps: 35 Train Loss: 1.7161 (Forecasting Loss:0.2334 + XiCon Loss:1.4827 x Lambda(1.0)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.7124
Validation loss decreased (0.198642 --> 0.157906).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.674647331237793
Epoch: 4, Steps: 35 Train Loss: 1.8645 (Forecasting Loss:0.1971 + XiCon Loss:1.6674 x Lambda(1.0)), Vali MSE Loss: 0.1313 Test MSE Loss: 0.6893
Validation loss decreased (0.157906 --> 0.131322).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7050619125366211
Epoch: 5, Steps: 35 Train Loss: 2.0994 (Forecasting Loss:0.1741 + XiCon Loss:1.9253 x Lambda(1.0)), Vali MSE Loss: 0.1276 Test MSE Loss: 0.7132
Validation loss decreased (0.131322 --> 0.127600).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6933660507202148
Epoch: 6, Steps: 35 Train Loss: 2.1664 (Forecasting Loss:0.1724 + XiCon Loss:1.9941 x Lambda(1.0)), Vali MSE Loss: 0.1288 Test MSE Loss: 0.7063
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6599667072296143
Epoch: 7, Steps: 35 Train Loss: 2.1151 (Forecasting Loss:0.1650 + XiCon Loss:1.9502 x Lambda(1.0)), Vali MSE Loss: 0.1308 Test MSE Loss: 0.6986
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6770691871643066
Epoch: 8, Steps: 35 Train Loss: 2.2199 (Forecasting Loss:0.1665 + XiCon Loss:2.0533 x Lambda(1.0)), Vali MSE Loss: 0.1245 Test MSE Loss: 0.6990
Validation loss decreased (0.127600 --> 0.124466).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6903271675109863
Epoch: 9, Steps: 35 Train Loss: 2.2602 (Forecasting Loss:0.1621 + XiCon Loss:2.0981 x Lambda(1.0)), Vali MSE Loss: 0.1276 Test MSE Loss: 0.6995
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6564376354217529
Epoch: 10, Steps: 35 Train Loss: 2.2192 (Forecasting Loss:0.1646 + XiCon Loss:2.0546 x Lambda(1.0)), Vali MSE Loss: 0.1281 Test MSE Loss: 0.6990
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.687647819519043
Epoch: 11, Steps: 35 Train Loss: 2.2317 (Forecasting Loss:0.1632 + XiCon Loss:2.0685 x Lambda(1.0)), Vali MSE Loss: 0.1283 Test MSE Loss: 0.7002
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7161719799041748
Epoch: 12, Steps: 35 Train Loss: 2.0430 (Forecasting Loss:0.1626 + XiCon Loss:1.8804 x Lambda(1.0)), Vali MSE Loss: 0.1277 Test MSE Loss: 0.6999
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7192747592926025
Epoch: 13, Steps: 35 Train Loss: 2.2127 (Forecasting Loss:0.1639 + XiCon Loss:2.0488 x Lambda(1.0)), Vali MSE Loss: 0.1272 Test MSE Loss: 0.6999
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7031731605529785
Epoch: 14, Steps: 35 Train Loss: 2.1933 (Forecasting Loss:0.1620 + XiCon Loss:2.0314 x Lambda(1.0)), Vali MSE Loss: 0.1281 Test MSE Loss: 0.6998
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6188063621520996
Epoch: 15, Steps: 35 Train Loss: 2.0878 (Forecasting Loss:0.1640 + XiCon Loss:1.9238 x Lambda(1.0)), Vali MSE Loss: 0.1279 Test MSE Loss: 0.6999
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6364192962646484
Epoch: 16, Steps: 35 Train Loss: 2.2807 (Forecasting Loss:0.1623 + XiCon Loss:2.1184 x Lambda(1.0)), Vali MSE Loss: 0.1273 Test MSE Loss: 0.6999
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6218147277832031
Epoch: 17, Steps: 35 Train Loss: 2.0781 (Forecasting Loss:0.1635 + XiCon Loss:1.9146 x Lambda(1.0)), Vali MSE Loss: 0.1281 Test MSE Loss: 0.6999
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6096482276916504
Epoch: 18, Steps: 35 Train Loss: 2.2874 (Forecasting Loss:0.1629 + XiCon Loss:2.1245 x Lambda(1.0)), Vali MSE Loss: 0.1266 Test MSE Loss: 0.6999
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7191959619522095, mae:0.6788175702095032, mape:0.2628019154071808, mspe:0.18766599893569946 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3516
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7078750133514404
Epoch: 1, Steps: 35 Train Loss: 2.0813 (Forecasting Loss:0.4846 + XiCon Loss:1.5967 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 1.1580
Validation loss decreased (inf --> 0.333738).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6951491832733154
Epoch: 2, Steps: 35 Train Loss: 1.7843 (Forecasting Loss:0.3277 + XiCon Loss:1.4566 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.7372
Validation loss decreased (0.333738 --> 0.198923).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6538844108581543
Epoch: 3, Steps: 35 Train Loss: 1.6677 (Forecasting Loss:0.2109 + XiCon Loss:1.4567 x Lambda(1.0)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.7124
Validation loss decreased (0.198923 --> 0.156942).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6464018821716309
Epoch: 4, Steps: 35 Train Loss: 1.9341 (Forecasting Loss:0.1937 + XiCon Loss:1.7404 x Lambda(1.0)), Vali MSE Loss: 0.1531 Test MSE Loss: 0.7486
Validation loss decreased (0.156942 --> 0.153122).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6734969615936279
Epoch: 5, Steps: 35 Train Loss: 2.0736 (Forecasting Loss:0.1801 + XiCon Loss:1.8935 x Lambda(1.0)), Vali MSE Loss: 0.1519 Test MSE Loss: 0.6721
Validation loss decreased (0.153122 --> 0.151919).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7182044982910156
Epoch: 6, Steps: 35 Train Loss: 2.2928 (Forecasting Loss:0.1762 + XiCon Loss:2.1166 x Lambda(1.0)), Vali MSE Loss: 0.1532 Test MSE Loss: 0.6507
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.718364953994751
Epoch: 7, Steps: 35 Train Loss: 2.2120 (Forecasting Loss:0.1662 + XiCon Loss:2.0459 x Lambda(1.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.6690
Validation loss decreased (0.151919 --> 0.142458).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7197980880737305
Epoch: 8, Steps: 35 Train Loss: 2.0393 (Forecasting Loss:0.1651 + XiCon Loss:1.8741 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.6599
Validation loss decreased (0.142458 --> 0.141625).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6881656646728516
Epoch: 9, Steps: 35 Train Loss: 2.1627 (Forecasting Loss:0.1619 + XiCon Loss:2.0008 x Lambda(1.0)), Vali MSE Loss: 0.1393 Test MSE Loss: 0.6588
Validation loss decreased (0.141625 --> 0.139327).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6470859050750732
Epoch: 10, Steps: 35 Train Loss: 2.1861 (Forecasting Loss:0.1582 + XiCon Loss:2.0279 x Lambda(1.0)), Vali MSE Loss: 0.1399 Test MSE Loss: 0.6535
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6592450141906738
Epoch: 11, Steps: 35 Train Loss: 2.1779 (Forecasting Loss:0.1627 + XiCon Loss:2.0152 x Lambda(1.0)), Vali MSE Loss: 0.1395 Test MSE Loss: 0.6521
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7247231006622314
Epoch: 12, Steps: 35 Train Loss: 1.9797 (Forecasting Loss:0.1594 + XiCon Loss:1.8204 x Lambda(1.0)), Vali MSE Loss: 0.1408 Test MSE Loss: 0.6505
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.686180591583252
Epoch: 13, Steps: 35 Train Loss: 2.2337 (Forecasting Loss:0.1612 + XiCon Loss:2.0725 x Lambda(1.0)), Vali MSE Loss: 0.1393 Test MSE Loss: 0.6504
Validation loss decreased (0.139327 --> 0.139268).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6796588897705078
Epoch: 14, Steps: 35 Train Loss: 2.1705 (Forecasting Loss:0.1642 + XiCon Loss:2.0063 x Lambda(1.0)), Vali MSE Loss: 0.1407 Test MSE Loss: 0.6503
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6582040786743164
Epoch: 15, Steps: 35 Train Loss: 2.1521 (Forecasting Loss:0.1621 + XiCon Loss:1.9900 x Lambda(1.0)), Vali MSE Loss: 0.1370 Test MSE Loss: 0.6502
Validation loss decreased (0.139268 --> 0.137013).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6874508857727051
Epoch: 16, Steps: 35 Train Loss: 2.1287 (Forecasting Loss:0.1595 + XiCon Loss:1.9692 x Lambda(1.0)), Vali MSE Loss: 0.1407 Test MSE Loss: 0.6502
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.632340669631958
Epoch: 17, Steps: 35 Train Loss: 2.1905 (Forecasting Loss:0.1602 + XiCon Loss:2.0303 x Lambda(1.0)), Vali MSE Loss: 0.1392 Test MSE Loss: 0.6502
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6520795822143555
Epoch: 18, Steps: 35 Train Loss: 2.2863 (Forecasting Loss:0.1615 + XiCon Loss:2.1248 x Lambda(1.0)), Vali MSE Loss: 0.1412 Test MSE Loss: 0.6502
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.5951876640319824
Epoch: 19, Steps: 35 Train Loss: 2.0483 (Forecasting Loss:0.1602 + XiCon Loss:1.8881 x Lambda(1.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.6502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7053468227386475
Epoch: 20, Steps: 35 Train Loss: 2.0725 (Forecasting Loss:0.1630 + XiCon Loss:1.9095 x Lambda(1.0)), Vali MSE Loss: 0.1410 Test MSE Loss: 0.6502
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6750593185424805
Epoch: 21, Steps: 35 Train Loss: 2.0484 (Forecasting Loss:0.1667 + XiCon Loss:1.8817 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.6502
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6992580890655518
Epoch: 22, Steps: 35 Train Loss: 2.2557 (Forecasting Loss:0.1630 + XiCon Loss:2.0927 x Lambda(1.0)), Vali MSE Loss: 0.1400 Test MSE Loss: 0.6502
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6434900760650635
Epoch: 23, Steps: 35 Train Loss: 1.9845 (Forecasting Loss:0.1577 + XiCon Loss:1.8267 x Lambda(1.0)), Vali MSE Loss: 0.1403 Test MSE Loss: 0.6502
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6818380355834961
Epoch: 24, Steps: 35 Train Loss: 2.0427 (Forecasting Loss:0.1611 + XiCon Loss:1.8816 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.6502
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6953034400939941
Epoch: 25, Steps: 35 Train Loss: 2.1546 (Forecasting Loss:0.1620 + XiCon Loss:1.9926 x Lambda(1.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.6502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6891989707946777, mae:0.6112431883811951, mape:0.2523275911808014, mspe:0.22208081185817719 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3387
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7170522212982178
Epoch: 1, Steps: 35 Train Loss: 2.0897 (Forecasting Loss:0.4961 + XiCon Loss:1.5936 x Lambda(1.0)), Vali MSE Loss: 0.3409 Test MSE Loss: 1.1637
Validation loss decreased (inf --> 0.340914).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7144079208374023
Epoch: 2, Steps: 35 Train Loss: 1.8338 (Forecasting Loss:0.3470 + XiCon Loss:1.4868 x Lambda(1.0)), Vali MSE Loss: 0.1886 Test MSE Loss: 0.7423
Validation loss decreased (0.340914 --> 0.188564).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6974263191223145
Epoch: 3, Steps: 35 Train Loss: 1.6796 (Forecasting Loss:0.2263 + XiCon Loss:1.4533 x Lambda(1.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.7017
Validation loss decreased (0.188564 --> 0.144856).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6803798675537109
Epoch: 4, Steps: 35 Train Loss: 1.6146 (Forecasting Loss:0.1882 + XiCon Loss:1.4263 x Lambda(1.0)), Vali MSE Loss: 0.1283 Test MSE Loss: 0.6847
Validation loss decreased (0.144856 --> 0.128291).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5948853492736816
Epoch: 5, Steps: 35 Train Loss: 1.5401 (Forecasting Loss:0.1772 + XiCon Loss:1.3630 x Lambda(1.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6871
Validation loss decreased (0.128291 --> 0.126048).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6689393520355225
Epoch: 6, Steps: 35 Train Loss: 1.5430 (Forecasting Loss:0.1732 + XiCon Loss:1.3698 x Lambda(1.0)), Vali MSE Loss: 0.1245 Test MSE Loss: 0.6823
Validation loss decreased (0.126048 --> 0.124515).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6499688625335693
Epoch: 7, Steps: 35 Train Loss: 1.5739 (Forecasting Loss:0.1702 + XiCon Loss:1.4037 x Lambda(1.0)), Vali MSE Loss: 0.1244 Test MSE Loss: 0.6720
Validation loss decreased (0.124515 --> 0.124380).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6084773540496826
Epoch: 8, Steps: 35 Train Loss: 1.6226 (Forecasting Loss:0.1692 + XiCon Loss:1.4534 x Lambda(1.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.6810
Validation loss decreased (0.124380 --> 0.123607).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7189621925354004
Epoch: 9, Steps: 35 Train Loss: 1.6306 (Forecasting Loss:0.1690 + XiCon Loss:1.4616 x Lambda(1.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.6774
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6408786773681641
Epoch: 10, Steps: 35 Train Loss: 1.6186 (Forecasting Loss:0.1679 + XiCon Loss:1.4507 x Lambda(1.0)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.6768
Validation loss decreased (0.123607 --> 0.123472).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6268277168273926
Epoch: 11, Steps: 35 Train Loss: 1.6463 (Forecasting Loss:0.1669 + XiCon Loss:1.4794 x Lambda(1.0)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.6761
Validation loss decreased (0.123472 --> 0.122114).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.590836763381958
Epoch: 12, Steps: 35 Train Loss: 1.6187 (Forecasting Loss:0.1669 + XiCon Loss:1.4518 x Lambda(1.0)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.6759
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6725945472717285
Epoch: 13, Steps: 35 Train Loss: 1.6309 (Forecasting Loss:0.1673 + XiCon Loss:1.4636 x Lambda(1.0)), Vali MSE Loss: 0.1229 Test MSE Loss: 0.6760
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6812114715576172
Epoch: 14, Steps: 35 Train Loss: 1.6110 (Forecasting Loss:0.1667 + XiCon Loss:1.4443 x Lambda(1.0)), Vali MSE Loss: 0.1230 Test MSE Loss: 0.6758
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6207799911499023
Epoch: 15, Steps: 35 Train Loss: 1.6226 (Forecasting Loss:0.1668 + XiCon Loss:1.4558 x Lambda(1.0)), Vali MSE Loss: 0.1231 Test MSE Loss: 0.6757
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6853904724121094
Epoch: 16, Steps: 35 Train Loss: 1.6286 (Forecasting Loss:0.1667 + XiCon Loss:1.4619 x Lambda(1.0)), Vali MSE Loss: 0.1237 Test MSE Loss: 0.6756
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6225917339324951
Epoch: 17, Steps: 35 Train Loss: 1.5932 (Forecasting Loss:0.1664 + XiCon Loss:1.4267 x Lambda(1.0)), Vali MSE Loss: 0.1238 Test MSE Loss: 0.6756
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6404280662536621
Epoch: 18, Steps: 35 Train Loss: 1.6384 (Forecasting Loss:0.1671 + XiCon Loss:1.4714 x Lambda(1.0)), Vali MSE Loss: 0.1242 Test MSE Loss: 0.6756
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.57769775390625
Epoch: 19, Steps: 35 Train Loss: 1.6573 (Forecasting Loss:0.1664 + XiCon Loss:1.4908 x Lambda(1.0)), Vali MSE Loss: 0.1231 Test MSE Loss: 0.6756
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.5799314975738525
Epoch: 20, Steps: 35 Train Loss: 1.6185 (Forecasting Loss:0.1669 + XiCon Loss:1.4516 x Lambda(1.0)), Vali MSE Loss: 0.1226 Test MSE Loss: 0.6756
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6420760154724121
Epoch: 21, Steps: 35 Train Loss: 1.6352 (Forecasting Loss:0.1668 + XiCon Loss:1.4684 x Lambda(1.0)), Vali MSE Loss: 0.1231 Test MSE Loss: 0.6756
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6978898048400879, mae:0.654323935508728, mape:0.25883105397224426, mspe:0.19480788707733154 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7391+-0.10886, MAE:0.6718+-0.07542, MAPE:0.2637+-0.01688, MSPE:0.1992+-0.01720, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.95, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2661
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.8946144580841064
Epoch: 1, Steps: 30 Train Loss: 2.2833 (Forecasting Loss:0.6884 + XiCon Loss:1.5949 x Lambda(1.0)), Vali MSE Loss: 0.6302 Test MSE Loss: 1.2587
Validation loss decreased (inf --> 0.630231).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5856044292449951
Epoch: 2, Steps: 30 Train Loss: 1.8806 (Forecasting Loss:0.4258 + XiCon Loss:1.4548 x Lambda(1.0)), Vali MSE Loss: 0.3648 Test MSE Loss: 1.0033
Validation loss decreased (0.630231 --> 0.364774).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6445989608764648
Epoch: 3, Steps: 30 Train Loss: 1.6796 (Forecasting Loss:0.2478 + XiCon Loss:1.4318 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.9147
Validation loss decreased (0.364774 --> 0.355311).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.593346118927002
Epoch: 4, Steps: 30 Train Loss: 1.7604 (Forecasting Loss:0.2096 + XiCon Loss:1.5507 x Lambda(1.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 1.2918
Validation loss decreased (0.355311 --> 0.199326).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5975708961486816
Epoch: 5, Steps: 30 Train Loss: 1.9634 (Forecasting Loss:0.2127 + XiCon Loss:1.7508 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 1.1504
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6031842231750488
Epoch: 6, Steps: 30 Train Loss: 1.7930 (Forecasting Loss:0.1961 + XiCon Loss:1.5969 x Lambda(1.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 1.1076
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6007089614868164
Epoch: 7, Steps: 30 Train Loss: 2.0205 (Forecasting Loss:0.1946 + XiCon Loss:1.8259 x Lambda(1.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 1.1545
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6484043598175049
Epoch: 8, Steps: 30 Train Loss: 2.0633 (Forecasting Loss:0.1957 + XiCon Loss:1.8676 x Lambda(1.0)), Vali MSE Loss: 0.2561 Test MSE Loss: 1.1012
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.605349063873291
Epoch: 9, Steps: 30 Train Loss: 2.1057 (Forecasting Loss:0.1925 + XiCon Loss:1.9132 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 1.0984
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5736174583435059
Epoch: 10, Steps: 30 Train Loss: 2.0627 (Forecasting Loss:0.1922 + XiCon Loss:1.8705 x Lambda(1.0)), Vali MSE Loss: 0.2400 Test MSE Loss: 1.0979
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6280035972595215
Epoch: 11, Steps: 30 Train Loss: 2.1542 (Forecasting Loss:0.1923 + XiCon Loss:1.9619 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 1.1004
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5847821235656738
Epoch: 12, Steps: 30 Train Loss: 2.0941 (Forecasting Loss:0.1938 + XiCon Loss:1.9003 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 1.0919
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5790112018585205
Epoch: 13, Steps: 30 Train Loss: 2.0045 (Forecasting Loss:0.1943 + XiCon Loss:1.8102 x Lambda(1.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 1.0899
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6738250255584717
Epoch: 14, Steps: 30 Train Loss: 2.1362 (Forecasting Loss:0.1929 + XiCon Loss:1.9433 x Lambda(1.0)), Vali MSE Loss: 0.2447 Test MSE Loss: 1.0898
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.5372036695480347, mae:1.0463275909423828, mape:0.3371923267841339, mspe:0.16840794682502747 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3395
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6024396419525146
Epoch: 1, Steps: 30 Train Loss: 2.3060 (Forecasting Loss:0.7207 + XiCon Loss:1.5853 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 2.2117
Validation loss decreased (inf --> 0.322257).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.590829610824585
Epoch: 2, Steps: 30 Train Loss: 1.9307 (Forecasting Loss:0.4306 + XiCon Loss:1.5001 x Lambda(1.0)), Vali MSE Loss: 0.4200 Test MSE Loss: 0.9356
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5904901027679443
Epoch: 3, Steps: 30 Train Loss: 1.7649 (Forecasting Loss:0.3068 + XiCon Loss:1.4582 x Lambda(1.0)), Vali MSE Loss: 0.3388 Test MSE Loss: 1.0257
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6642687320709229
Epoch: 4, Steps: 30 Train Loss: 1.6682 (Forecasting Loss:0.2250 + XiCon Loss:1.4433 x Lambda(1.0)), Vali MSE Loss: 0.3754 Test MSE Loss: 1.0407
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6383671760559082
Epoch: 5, Steps: 30 Train Loss: 1.6205 (Forecasting Loss:0.1973 + XiCon Loss:1.4231 x Lambda(1.0)), Vali MSE Loss: 0.3903 Test MSE Loss: 1.0313
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5694899559020996
Epoch: 6, Steps: 30 Train Loss: 1.6047 (Forecasting Loss:0.1833 + XiCon Loss:1.4214 x Lambda(1.0)), Vali MSE Loss: 0.3189 Test MSE Loss: 1.1054
Validation loss decreased (0.322257 --> 0.318868).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.605262279510498
Epoch: 7, Steps: 30 Train Loss: 1.5745 (Forecasting Loss:0.1791 + XiCon Loss:1.3953 x Lambda(1.0)), Vali MSE Loss: 0.3587 Test MSE Loss: 1.1275
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5785346031188965
Epoch: 8, Steps: 30 Train Loss: 1.5612 (Forecasting Loss:0.1692 + XiCon Loss:1.3919 x Lambda(1.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 1.0987
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6411600112915039
Epoch: 9, Steps: 30 Train Loss: 1.5672 (Forecasting Loss:0.1624 + XiCon Loss:1.4048 x Lambda(1.0)), Vali MSE Loss: 0.3256 Test MSE Loss: 1.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.570479154586792
Epoch: 10, Steps: 30 Train Loss: 1.5558 (Forecasting Loss:0.1626 + XiCon Loss:1.3932 x Lambda(1.0)), Vali MSE Loss: 0.3085 Test MSE Loss: 1.1028
Validation loss decreased (0.318868 --> 0.308474).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6350140571594238
Epoch: 11, Steps: 30 Train Loss: 1.5591 (Forecasting Loss:0.1618 + XiCon Loss:1.3973 x Lambda(1.0)), Vali MSE Loss: 0.3493 Test MSE Loss: 1.1036
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.612037181854248
Epoch: 12, Steps: 30 Train Loss: 1.5582 (Forecasting Loss:0.1606 + XiCon Loss:1.3977 x Lambda(1.0)), Vali MSE Loss: 0.3326 Test MSE Loss: 1.1043
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5350761413574219
Epoch: 13, Steps: 30 Train Loss: 1.5505 (Forecasting Loss:0.1609 + XiCon Loss:1.3896 x Lambda(1.0)), Vali MSE Loss: 0.3257 Test MSE Loss: 1.1065
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5612428188323975
Epoch: 14, Steps: 30 Train Loss: 1.5651 (Forecasting Loss:0.1625 + XiCon Loss:1.4026 x Lambda(1.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 1.1061
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5793259143829346
Epoch: 15, Steps: 30 Train Loss: 1.5433 (Forecasting Loss:0.1646 + XiCon Loss:1.3787 x Lambda(1.0)), Vali MSE Loss: 0.3404 Test MSE Loss: 1.1056
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6394176483154297
Epoch: 16, Steps: 30 Train Loss: 1.5666 (Forecasting Loss:0.1624 + XiCon Loss:1.4042 x Lambda(1.0)), Vali MSE Loss: 0.3414 Test MSE Loss: 1.1054
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6088747978210449
Epoch: 17, Steps: 30 Train Loss: 1.5787 (Forecasting Loss:0.1636 + XiCon Loss:1.4150 x Lambda(1.0)), Vali MSE Loss: 0.3364 Test MSE Loss: 1.1054
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6404998302459717
Epoch: 18, Steps: 30 Train Loss: 1.5626 (Forecasting Loss:0.1612 + XiCon Loss:1.4014 x Lambda(1.0)), Vali MSE Loss: 0.3408 Test MSE Loss: 1.1054
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6128897666931152
Epoch: 19, Steps: 30 Train Loss: 1.5467 (Forecasting Loss:0.1600 + XiCon Loss:1.3868 x Lambda(1.0)), Vali MSE Loss: 0.3349 Test MSE Loss: 1.1053
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6047646999359131
Epoch: 20, Steps: 30 Train Loss: 1.5606 (Forecasting Loss:0.1619 + XiCon Loss:1.3987 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 1.1053
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.240256428718567, mae:0.9653081297874451, mape:0.3091999292373657, mspe:0.1361209750175476 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3306
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6019554138183594
Epoch: 1, Steps: 30 Train Loss: 2.2316 (Forecasting Loss:0.6289 + XiCon Loss:1.6026 x Lambda(1.0)), Vali MSE Loss: 0.3559 Test MSE Loss: 1.8090
Validation loss decreased (inf --> 0.355923).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5539877414703369
Epoch: 2, Steps: 30 Train Loss: 1.8638 (Forecasting Loss:0.4044 + XiCon Loss:1.4594 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 1.2500
Validation loss decreased (0.355923 --> 0.332862).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6269910335540771
Epoch: 3, Steps: 30 Train Loss: 1.7042 (Forecasting Loss:0.2519 + XiCon Loss:1.4523 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 1.2200
Validation loss decreased (0.332862 --> 0.310705).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6227717399597168
Epoch: 4, Steps: 30 Train Loss: 1.7607 (Forecasting Loss:0.2049 + XiCon Loss:1.5559 x Lambda(1.0)), Vali MSE Loss: 0.2177 Test MSE Loss: 1.1935
Validation loss decreased (0.310705 --> 0.217697).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.618858814239502
Epoch: 5, Steps: 30 Train Loss: 1.8348 (Forecasting Loss:0.1798 + XiCon Loss:1.6550 x Lambda(1.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 1.0918
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5981943607330322
Epoch: 6, Steps: 30 Train Loss: 1.9016 (Forecasting Loss:0.1679 + XiCon Loss:1.7337 x Lambda(1.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 1.2717
Validation loss decreased (0.217697 --> 0.200675).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6307389736175537
Epoch: 7, Steps: 30 Train Loss: 1.9923 (Forecasting Loss:0.1673 + XiCon Loss:1.8250 x Lambda(1.0)), Vali MSE Loss: 0.3588 Test MSE Loss: 0.9980
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.63260817527771
Epoch: 8, Steps: 30 Train Loss: 2.0699 (Forecasting Loss:0.1622 + XiCon Loss:1.9077 x Lambda(1.0)), Vali MSE Loss: 0.3472 Test MSE Loss: 1.0123
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5845389366149902
Epoch: 9, Steps: 30 Train Loss: 2.0277 (Forecasting Loss:0.1586 + XiCon Loss:1.8691 x Lambda(1.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 1.1556
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.614635705947876
Epoch: 10, Steps: 30 Train Loss: 2.0345 (Forecasting Loss:0.1593 + XiCon Loss:1.8752 x Lambda(1.0)), Vali MSE Loss: 0.3074 Test MSE Loss: 1.0923
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.603975772857666
Epoch: 11, Steps: 30 Train Loss: 1.9859 (Forecasting Loss:0.1578 + XiCon Loss:1.8281 x Lambda(1.0)), Vali MSE Loss: 0.3168 Test MSE Loss: 1.0873
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6095430850982666
Epoch: 12, Steps: 30 Train Loss: 1.9006 (Forecasting Loss:0.1579 + XiCon Loss:1.7427 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 1.0891
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5577151775360107
Epoch: 13, Steps: 30 Train Loss: 2.0404 (Forecasting Loss:0.1571 + XiCon Loss:1.8833 x Lambda(1.0)), Vali MSE Loss: 0.3115 Test MSE Loss: 1.0907
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6414752006530762
Epoch: 14, Steps: 30 Train Loss: 1.9989 (Forecasting Loss:0.1565 + XiCon Loss:1.8424 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 1.0943
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6818761825561523
Epoch: 15, Steps: 30 Train Loss: 1.9537 (Forecasting Loss:0.1577 + XiCon Loss:1.7960 x Lambda(1.0)), Vali MSE Loss: 0.3030 Test MSE Loss: 1.0953
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.5677852630615234
Epoch: 16, Steps: 30 Train Loss: 1.9048 (Forecasting Loss:0.1577 + XiCon Loss:1.7470 x Lambda(1.0)), Vali MSE Loss: 0.3082 Test MSE Loss: 1.0950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.4769924879074097, mae:1.0663093328475952, mape:0.3401561975479126, mspe:0.15427128970623016 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3260
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.603776216506958
Epoch: 1, Steps: 30 Train Loss: 2.1672 (Forecasting Loss:0.5713 + XiCon Loss:1.5959 x Lambda(1.0)), Vali MSE Loss: 0.3703 Test MSE Loss: 1.6689
Validation loss decreased (inf --> 0.370300).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6062610149383545
Epoch: 2, Steps: 30 Train Loss: 1.8931 (Forecasting Loss:0.4227 + XiCon Loss:1.4705 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 1.2019
Validation loss decreased (0.370300 --> 0.320230).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5960814952850342
Epoch: 3, Steps: 30 Train Loss: 1.6698 (Forecasting Loss:0.2566 + XiCon Loss:1.4131 x Lambda(1.0)), Vali MSE Loss: 0.3311 Test MSE Loss: 1.0953
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6745002269744873
Epoch: 4, Steps: 30 Train Loss: 1.6878 (Forecasting Loss:0.2107 + XiCon Loss:1.4772 x Lambda(1.0)), Vali MSE Loss: 0.3526 Test MSE Loss: 1.0250
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5716204643249512
Epoch: 5, Steps: 30 Train Loss: 1.8123 (Forecasting Loss:0.1978 + XiCon Loss:1.6144 x Lambda(1.0)), Vali MSE Loss: 0.3712 Test MSE Loss: 1.1091
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6172337532043457
Epoch: 6, Steps: 30 Train Loss: 1.8703 (Forecasting Loss:0.1905 + XiCon Loss:1.6797 x Lambda(1.0)), Vali MSE Loss: 0.4371 Test MSE Loss: 0.9958
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6008837223052979
Epoch: 7, Steps: 30 Train Loss: 1.9521 (Forecasting Loss:0.1854 + XiCon Loss:1.7667 x Lambda(1.0)), Vali MSE Loss: 0.4287 Test MSE Loss: 1.0128
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.63303542137146
Epoch: 8, Steps: 30 Train Loss: 1.9510 (Forecasting Loss:0.1783 + XiCon Loss:1.7726 x Lambda(1.0)), Vali MSE Loss: 0.4105 Test MSE Loss: 1.0201
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6280472278594971
Epoch: 9, Steps: 30 Train Loss: 1.9526 (Forecasting Loss:0.1797 + XiCon Loss:1.7729 x Lambda(1.0)), Vali MSE Loss: 0.3984 Test MSE Loss: 1.0195
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6077253818511963
Epoch: 10, Steps: 30 Train Loss: 1.9716 (Forecasting Loss:0.1794 + XiCon Loss:1.7921 x Lambda(1.0)), Vali MSE Loss: 0.4157 Test MSE Loss: 1.0206
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5728163719177246
Epoch: 11, Steps: 30 Train Loss: 1.9889 (Forecasting Loss:0.1785 + XiCon Loss:1.8104 x Lambda(1.0)), Vali MSE Loss: 0.4247 Test MSE Loss: 1.0188
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6245772838592529
Epoch: 12, Steps: 30 Train Loss: 2.0450 (Forecasting Loss:0.1782 + XiCon Loss:1.8667 x Lambda(1.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 1.0181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.396651268005371, mae:1.007172703742981, mape:0.3235262334346771, mspe:0.15084785223007202 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3269
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6340069770812988
Epoch: 1, Steps: 30 Train Loss: 2.1988 (Forecasting Loss:0.6068 + XiCon Loss:1.5919 x Lambda(1.0)), Vali MSE Loss: 0.4746 Test MSE Loss: 1.3835
Validation loss decreased (inf --> 0.474602).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6792776584625244
Epoch: 2, Steps: 30 Train Loss: 1.8867 (Forecasting Loss:0.4178 + XiCon Loss:1.4689 x Lambda(1.0)), Vali MSE Loss: 0.3332 Test MSE Loss: 1.0314
Validation loss decreased (0.474602 --> 0.333233).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6590240001678467
Epoch: 3, Steps: 30 Train Loss: 1.6700 (Forecasting Loss:0.2492 + XiCon Loss:1.4208 x Lambda(1.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 1.1774
Validation loss decreased (0.333233 --> 0.225600).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5945484638214111
Epoch: 4, Steps: 30 Train Loss: 1.7739 (Forecasting Loss:0.2187 + XiCon Loss:1.5552 x Lambda(1.0)), Vali MSE Loss: 0.2426 Test MSE Loss: 1.1023
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6376509666442871
Epoch: 5, Steps: 30 Train Loss: 1.9824 (Forecasting Loss:0.2068 + XiCon Loss:1.7757 x Lambda(1.0)), Vali MSE Loss: 0.2176 Test MSE Loss: 1.1383
Validation loss decreased (0.225600 --> 0.217619).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5541229248046875
Epoch: 6, Steps: 30 Train Loss: 2.0095 (Forecasting Loss:0.1994 + XiCon Loss:1.8101 x Lambda(1.0)), Vali MSE Loss: 0.3265 Test MSE Loss: 1.0169
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6522078514099121
Epoch: 7, Steps: 30 Train Loss: 2.2886 (Forecasting Loss:0.1955 + XiCon Loss:2.0931 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 1.0466
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.600675106048584
Epoch: 8, Steps: 30 Train Loss: 2.0982 (Forecasting Loss:0.1925 + XiCon Loss:1.9058 x Lambda(1.0)), Vali MSE Loss: 0.2794 Test MSE Loss: 1.0851
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5896096229553223
Epoch: 9, Steps: 30 Train Loss: 2.0843 (Forecasting Loss:0.1900 + XiCon Loss:1.8943 x Lambda(1.0)), Vali MSE Loss: 0.2987 Test MSE Loss: 1.0596
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6504335403442383
Epoch: 10, Steps: 30 Train Loss: 2.1204 (Forecasting Loss:0.1877 + XiCon Loss:1.9326 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 1.0784
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5958149433135986
Epoch: 11, Steps: 30 Train Loss: 2.2167 (Forecasting Loss:0.1883 + XiCon Loss:2.0284 x Lambda(1.0)), Vali MSE Loss: 0.2828 Test MSE Loss: 1.0754
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6034080982208252
Epoch: 12, Steps: 30 Train Loss: 2.1586 (Forecasting Loss:0.1886 + XiCon Loss:1.9700 x Lambda(1.0)), Vali MSE Loss: 0.2825 Test MSE Loss: 1.0737
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6371142864227295
Epoch: 13, Steps: 30 Train Loss: 2.1926 (Forecasting Loss:0.1901 + XiCon Loss:2.0024 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 1.0762
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5907137393951416
Epoch: 14, Steps: 30 Train Loss: 2.0661 (Forecasting Loss:0.1884 + XiCon Loss:1.8777 x Lambda(1.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 1.0768
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6838493347167969
Epoch: 15, Steps: 30 Train Loss: 2.1511 (Forecasting Loss:0.1878 + XiCon Loss:1.9633 x Lambda(1.0)), Vali MSE Loss: 0.2830 Test MSE Loss: 1.0770
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.29114830493927, mae:0.9853531718254089, mape:0.3198833763599396, mspe:0.15072274208068848 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3885+-0.15392, MAE:1.0141+-0.05201, MAPE:0.3260+-0.01585, MSPE:0.1521+-0.01429, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
