Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4922
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2735628
	speed: 0.0237s/iter; left time: 300.6158s
Epoch: 1 cost time: 3.041212558746338
Epoch: 1, Steps: 128 Train Loss: 0.2752 (Forecasting Loss:0.2439 + XiCon Loss:3.1275 x Lambda(0.01)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1209
Validation loss decreased (inf --> 0.173819).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2711875
	speed: 0.0193s/iter; left time: 242.6234s
Epoch: 2 cost time: 2.439661979675293
Epoch: 2, Steps: 128 Train Loss: 0.2641 (Forecasting Loss:0.2331 + XiCon Loss:3.0979 x Lambda(0.01)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1620
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1930454
	speed: 0.0177s/iter; left time: 220.0338s
Epoch: 3 cost time: 2.1706175804138184
Epoch: 3, Steps: 128 Train Loss: 0.2280 (Forecasting Loss:0.1973 + XiCon Loss:3.0656 x Lambda(0.01)), Vali MSE Loss: 0.1545 Test MSE Loss: 0.1433
Validation loss decreased (0.173819 --> 0.154489).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1773192
	speed: 0.0202s/iter; left time: 249.1139s
Epoch: 4 cost time: 2.6104722023010254
Epoch: 4, Steps: 128 Train Loss: 0.1978 (Forecasting Loss:0.1673 + XiCon Loss:3.0484 x Lambda(0.01)), Vali MSE Loss: 0.1519 Test MSE Loss: 0.1554
Validation loss decreased (0.154489 --> 0.151896).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1764073
	speed: 0.0200s/iter; left time: 243.5778s
Epoch: 5 cost time: 2.4750664234161377
Epoch: 5, Steps: 128 Train Loss: 0.1821 (Forecasting Loss:0.1517 + XiCon Loss:3.0391 x Lambda(0.01)), Vali MSE Loss: 0.1548 Test MSE Loss: 0.1661
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1714868
	speed: 0.0182s/iter; left time: 219.6598s
Epoch: 6 cost time: 2.3006978034973145
Epoch: 6, Steps: 128 Train Loss: 0.1741 (Forecasting Loss:0.1438 + XiCon Loss:3.0314 x Lambda(0.01)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1672
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1580331
	speed: 0.0191s/iter; left time: 227.6807s
Epoch: 7 cost time: 2.3962953090667725
Epoch: 7, Steps: 128 Train Loss: 0.1704 (Forecasting Loss:0.1401 + XiCon Loss:3.0313 x Lambda(0.01)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1718
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1719141
	speed: 0.0208s/iter; left time: 245.7107s
Epoch: 8 cost time: 2.6376631259918213
Epoch: 8, Steps: 128 Train Loss: 0.1689 (Forecasting Loss:0.1386 + XiCon Loss:3.0298 x Lambda(0.01)), Vali MSE Loss: 0.1615 Test MSE Loss: 0.1710
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1885448
	speed: 0.0217s/iter; left time: 253.3365s
Epoch: 9 cost time: 2.6263065338134766
Epoch: 9, Steps: 128 Train Loss: 0.1677 (Forecasting Loss:0.1374 + XiCon Loss:3.0276 x Lambda(0.01)), Vali MSE Loss: 0.1614 Test MSE Loss: 0.1715
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1648155
	speed: 0.0180s/iter; left time: 207.6606s
Epoch: 10 cost time: 2.267587900161743
Epoch: 10, Steps: 128 Train Loss: 0.1675 (Forecasting Loss:0.1373 + XiCon Loss:3.0242 x Lambda(0.01)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1713
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1645158
	speed: 0.0196s/iter; left time: 223.5135s
Epoch: 11 cost time: 2.5429728031158447
Epoch: 11, Steps: 128 Train Loss: 0.1672 (Forecasting Loss:0.1370 + XiCon Loss:3.0272 x Lambda(0.01)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1714
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1810653
	speed: 0.0204s/iter; left time: 230.2653s
Epoch: 12 cost time: 2.5241565704345703
Epoch: 12, Steps: 128 Train Loss: 0.1671 (Forecasting Loss:0.1368 + XiCon Loss:3.0317 x Lambda(0.01)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1715
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1689810
	speed: 0.0205s/iter; left time: 228.5147s
Epoch: 13 cost time: 2.4955878257751465
Epoch: 13, Steps: 128 Train Loss: 0.1672 (Forecasting Loss:0.1369 + XiCon Loss:3.0305 x Lambda(0.01)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1716
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1676165
	speed: 0.0203s/iter; left time: 224.1880s
Epoch: 14 cost time: 2.484248161315918
Epoch: 14, Steps: 128 Train Loss: 0.1669 (Forecasting Loss:0.1366 + XiCon Loss:3.0268 x Lambda(0.01)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1716
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0844121128320694, mae:0.22631116211414337, mape:0.18534858524799347, mspe:0.07425837218761444 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4938
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2762163
	speed: 0.0191s/iter; left time: 242.8605s
Epoch: 1 cost time: 2.307749032974243
Epoch: 1, Steps: 128 Train Loss: 0.2761 (Forecasting Loss:0.2451 + XiCon Loss:3.1036 x Lambda(0.01)), Vali MSE Loss: 0.1758 Test MSE Loss: 0.1220
Validation loss decreased (inf --> 0.175796).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2732267
	speed: 0.0192s/iter; left time: 240.9388s
Epoch: 2 cost time: 2.4006783962249756
Epoch: 2, Steps: 128 Train Loss: 0.2697 (Forecasting Loss:0.2386 + XiCon Loss:3.1079 x Lambda(0.01)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1284
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2544702
	speed: 0.0197s/iter; left time: 245.7133s
Epoch: 3 cost time: 2.5320663452148438
Epoch: 3, Steps: 128 Train Loss: 0.2259 (Forecasting Loss:0.1953 + XiCon Loss:3.0652 x Lambda(0.01)), Vali MSE Loss: 0.1875 Test MSE Loss: 0.1348
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1945186
	speed: 0.0220s/iter; left time: 270.6834s
Epoch: 4 cost time: 2.7875423431396484
Epoch: 4, Steps: 128 Train Loss: 0.1973 (Forecasting Loss:0.1665 + XiCon Loss:3.0787 x Lambda(0.01)), Vali MSE Loss: 0.1872 Test MSE Loss: 0.1479
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1938521
	speed: 0.0197s/iter; left time: 240.0119s
Epoch: 5 cost time: 2.453805923461914
Epoch: 5, Steps: 128 Train Loss: 0.1796 (Forecasting Loss:0.1487 + XiCon Loss:3.0873 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1524
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1646962
	speed: 0.0200s/iter; left time: 240.9566s
Epoch: 6 cost time: 2.4946727752685547
Epoch: 6, Steps: 128 Train Loss: 0.1717 (Forecasting Loss:0.1408 + XiCon Loss:3.0843 x Lambda(0.01)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1549
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1645779
	speed: 0.0211s/iter; left time: 252.3635s
Epoch: 7 cost time: 2.593722343444824
Epoch: 7, Steps: 128 Train Loss: 0.1678 (Forecasting Loss:0.1369 + XiCon Loss:3.0898 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1548
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1752898
	speed: 0.0186s/iter; left time: 219.2679s
Epoch: 8 cost time: 2.3774168491363525
Epoch: 8, Steps: 128 Train Loss: 0.1660 (Forecasting Loss:0.1351 + XiCon Loss:3.0879 x Lambda(0.01)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1553
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1708577
	speed: 0.0202s/iter; left time: 235.5295s
Epoch: 9 cost time: 2.4570767879486084
Epoch: 9, Steps: 128 Train Loss: 0.1652 (Forecasting Loss:0.1343 + XiCon Loss:3.0877 x Lambda(0.01)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1555
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1564588
	speed: 0.0221s/iter; left time: 254.8142s
Epoch: 10 cost time: 2.6924259662628174
Epoch: 10, Steps: 128 Train Loss: 0.1647 (Forecasting Loss:0.1338 + XiCon Loss:3.0887 x Lambda(0.01)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1558
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1667071
	speed: 0.0220s/iter; left time: 251.6042s
Epoch: 11 cost time: 2.6350064277648926
Epoch: 11, Steps: 128 Train Loss: 0.1644 (Forecasting Loss:0.1335 + XiCon Loss:3.0930 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1560
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05806589499115944, mae:0.18588504195213318, mape:0.14769409596920013, mspe:0.04061318561434746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5263
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2690727
	speed: 0.0189s/iter; left time: 239.7252s
Epoch: 1 cost time: 2.348234176635742
Epoch: 1, Steps: 128 Train Loss: 0.2745 (Forecasting Loss:0.2434 + XiCon Loss:3.1145 x Lambda(0.01)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1219
Validation loss decreased (inf --> 0.176339).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2727986
	speed: 0.0208s/iter; left time: 261.1860s
Epoch: 2 cost time: 2.490903615951538
Epoch: 2, Steps: 128 Train Loss: 0.2710 (Forecasting Loss:0.2403 + XiCon Loss:3.0666 x Lambda(0.01)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1339
Validation loss decreased (0.176339 --> 0.173241).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2330610
	speed: 0.0190s/iter; left time: 236.6092s
Epoch: 3 cost time: 2.455626964569092
Epoch: 3, Steps: 128 Train Loss: 0.2349 (Forecasting Loss:0.2045 + XiCon Loss:3.0433 x Lambda(0.01)), Vali MSE Loss: 0.1915 Test MSE Loss: 0.1320
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2333575
	speed: 0.0218s/iter; left time: 267.9077s
Epoch: 4 cost time: 2.67838191986084
Epoch: 4, Steps: 128 Train Loss: 0.2148 (Forecasting Loss:0.1844 + XiCon Loss:3.0366 x Lambda(0.01)), Vali MSE Loss: 0.1806 Test MSE Loss: 0.1356
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2331922
	speed: 0.0191s/iter; left time: 232.2914s
Epoch: 5 cost time: 2.318575143814087
Epoch: 5, Steps: 128 Train Loss: 0.2020 (Forecasting Loss:0.1716 + XiCon Loss:3.0453 x Lambda(0.01)), Vali MSE Loss: 0.1905 Test MSE Loss: 0.1418
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1817188
	speed: 0.0219s/iter; left time: 264.5965s
Epoch: 6 cost time: 2.614626169204712
Epoch: 6, Steps: 128 Train Loss: 0.1952 (Forecasting Loss:0.1646 + XiCon Loss:3.0615 x Lambda(0.01)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1415
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1932175
	speed: 0.0190s/iter; left time: 226.3900s
Epoch: 7 cost time: 2.3651514053344727
Epoch: 7, Steps: 128 Train Loss: 0.1924 (Forecasting Loss:0.1618 + XiCon Loss:3.0513 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.1421
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1953828
	speed: 0.0190s/iter; left time: 224.5029s
Epoch: 8 cost time: 2.3634188175201416
Epoch: 8, Steps: 128 Train Loss: 0.1904 (Forecasting Loss:0.1598 + XiCon Loss:3.0554 x Lambda(0.01)), Vali MSE Loss: 0.1875 Test MSE Loss: 0.1441
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1936071
	speed: 0.0219s/iter; left time: 255.3274s
Epoch: 9 cost time: 2.683074951171875
Epoch: 9, Steps: 128 Train Loss: 0.1896 (Forecasting Loss:0.1590 + XiCon Loss:3.0605 x Lambda(0.01)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.1457
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2114229
	speed: 0.0203s/iter; left time: 234.5433s
Epoch: 10 cost time: 2.525043249130249
Epoch: 10, Steps: 128 Train Loss: 0.1897 (Forecasting Loss:0.1592 + XiCon Loss:3.0559 x Lambda(0.01)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1454
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2005352
	speed: 0.0235s/iter; left time: 268.8570s
Epoch: 11 cost time: 2.9401588439941406
Epoch: 11, Steps: 128 Train Loss: 0.1894 (Forecasting Loss:0.1588 + XiCon Loss:3.0557 x Lambda(0.01)), Vali MSE Loss: 0.1890 Test MSE Loss: 0.1457
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1906982
	speed: 0.0223s/iter; left time: 251.8375s
Epoch: 12 cost time: 2.761242151260376
Epoch: 12, Steps: 128 Train Loss: 0.1889 (Forecasting Loss:0.1583 + XiCon Loss:3.0588 x Lambda(0.01)), Vali MSE Loss: 0.1889 Test MSE Loss: 0.1457
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.06792981922626495, mae:0.19996261596679688, mape:0.16066794097423553, mspe:0.05178557336330414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5374
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2562837
	speed: 0.0200s/iter; left time: 253.5015s
Epoch: 1 cost time: 2.6537222862243652
Epoch: 1, Steps: 128 Train Loss: 0.2749 (Forecasting Loss:0.2437 + XiCon Loss:3.1240 x Lambda(0.01)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1197
Validation loss decreased (inf --> 0.170156).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2474194
	speed: 0.0199s/iter; left time: 250.0577s
Epoch: 2 cost time: 2.7766895294189453
Epoch: 2, Steps: 128 Train Loss: 0.2731 (Forecasting Loss:0.2422 + XiCon Loss:3.0876 x Lambda(0.01)), Vali MSE Loss: 0.1820 Test MSE Loss: 0.1280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2290304
	speed: 0.0197s/iter; left time: 245.0729s
Epoch: 3 cost time: 2.401047706604004
Epoch: 3, Steps: 128 Train Loss: 0.2366 (Forecasting Loss:0.2063 + XiCon Loss:3.0297 x Lambda(0.01)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1307
Validation loss decreased (0.170156 --> 0.163098).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2070836
	speed: 0.0193s/iter; left time: 237.7047s
Epoch: 4 cost time: 2.377286434173584
Epoch: 4, Steps: 128 Train Loss: 0.2088 (Forecasting Loss:0.1784 + XiCon Loss:3.0399 x Lambda(0.01)), Vali MSE Loss: 0.1751 Test MSE Loss: 0.1347
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2028543
	speed: 0.0228s/iter; left time: 277.8421s
Epoch: 5 cost time: 2.7704403400421143
Epoch: 5, Steps: 128 Train Loss: 0.1948 (Forecasting Loss:0.1642 + XiCon Loss:3.0579 x Lambda(0.01)), Vali MSE Loss: 0.1746 Test MSE Loss: 0.1402
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1961626
	speed: 0.0226s/iter; left time: 272.0668s
Epoch: 6 cost time: 2.832195520401001
Epoch: 6, Steps: 128 Train Loss: 0.1879 (Forecasting Loss:0.1573 + XiCon Loss:3.0614 x Lambda(0.01)), Vali MSE Loss: 0.1784 Test MSE Loss: 0.1478
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1815268
	speed: 0.0185s/iter; left time: 220.4759s
Epoch: 7 cost time: 2.292477607727051
Epoch: 7, Steps: 128 Train Loss: 0.1851 (Forecasting Loss:0.1545 + XiCon Loss:3.0690 x Lambda(0.01)), Vali MSE Loss: 0.1799 Test MSE Loss: 0.1508
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1936989
	speed: 0.0204s/iter; left time: 241.3845s
Epoch: 8 cost time: 2.573294162750244
Epoch: 8, Steps: 128 Train Loss: 0.1835 (Forecasting Loss:0.1529 + XiCon Loss:3.0671 x Lambda(0.01)), Vali MSE Loss: 0.1804 Test MSE Loss: 0.1520
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1758083
	speed: 0.0210s/iter; left time: 245.4093s
Epoch: 9 cost time: 2.5932867527008057
Epoch: 9, Steps: 128 Train Loss: 0.1825 (Forecasting Loss:0.1519 + XiCon Loss:3.0655 x Lambda(0.01)), Vali MSE Loss: 0.1794 Test MSE Loss: 0.1511
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1791165
	speed: 0.0209s/iter; left time: 241.1318s
Epoch: 10 cost time: 2.507234811782837
Epoch: 10, Steps: 128 Train Loss: 0.1823 (Forecasting Loss:0.1517 + XiCon Loss:3.0662 x Lambda(0.01)), Vali MSE Loss: 0.1799 Test MSE Loss: 0.1521
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1812132
	speed: 0.0200s/iter; left time: 228.2946s
Epoch: 11 cost time: 2.6867682933807373
Epoch: 11, Steps: 128 Train Loss: 0.1819 (Forecasting Loss:0.1513 + XiCon Loss:3.0666 x Lambda(0.01)), Vali MSE Loss: 0.1800 Test MSE Loss: 0.1521
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1734273
	speed: 0.0183s/iter; left time: 206.5299s
Epoch: 12 cost time: 2.278559446334839
Epoch: 12, Steps: 128 Train Loss: 0.1820 (Forecasting Loss:0.1513 + XiCon Loss:3.0696 x Lambda(0.01)), Vali MSE Loss: 0.1803 Test MSE Loss: 0.1523
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1983568
	speed: 0.0197s/iter; left time: 220.3142s
Epoch: 13 cost time: 2.4595513343811035
Epoch: 13, Steps: 128 Train Loss: 0.1818 (Forecasting Loss:0.1512 + XiCon Loss:3.0661 x Lambda(0.01)), Vali MSE Loss: 0.1797 Test MSE Loss: 0.1522
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0651046559214592, mae:0.19628514349460602, mape:0.1658296138048172, mspe:0.06610802561044693 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4326
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2320354
	speed: 0.0206s/iter; left time: 261.3343s
Epoch: 1 cost time: 2.5525100231170654
Epoch: 1, Steps: 128 Train Loss: 0.2744 (Forecasting Loss:0.2431 + XiCon Loss:3.1274 x Lambda(0.01)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.173628).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2931433
	speed: 0.0187s/iter; left time: 235.3914s
Epoch: 2 cost time: 2.3359718322753906
Epoch: 2, Steps: 128 Train Loss: 0.2775 (Forecasting Loss:0.2461 + XiCon Loss:3.1457 x Lambda(0.01)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1252
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2415968
	speed: 0.0187s/iter; left time: 233.0458s
Epoch: 3 cost time: 2.249722957611084
Epoch: 3, Steps: 128 Train Loss: 0.2480 (Forecasting Loss:0.2175 + XiCon Loss:3.0470 x Lambda(0.01)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1333
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2198942
	speed: 0.0217s/iter; left time: 267.6926s
Epoch: 4 cost time: 2.666127920150757
Epoch: 4, Steps: 128 Train Loss: 0.2158 (Forecasting Loss:0.1855 + XiCon Loss:3.0239 x Lambda(0.01)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1460
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2128126
	speed: 0.0213s/iter; left time: 259.7385s
Epoch: 5 cost time: 2.549128293991089
Epoch: 5, Steps: 128 Train Loss: 0.1966 (Forecasting Loss:0.1664 + XiCon Loss:3.0237 x Lambda(0.01)), Vali MSE Loss: 0.1905 Test MSE Loss: 0.1523
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1857609
	speed: 0.0195s/iter; left time: 234.6137s
Epoch: 6 cost time: 2.3899903297424316
Epoch: 6, Steps: 128 Train Loss: 0.1865 (Forecasting Loss:0.1562 + XiCon Loss:3.0321 x Lambda(0.01)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1605
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1798557
	speed: 0.0184s/iter; left time: 219.9658s
Epoch: 7 cost time: 2.3810625076293945
Epoch: 7, Steps: 128 Train Loss: 0.1820 (Forecasting Loss:0.1517 + XiCon Loss:3.0356 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.1614
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1757071
	speed: 0.0196s/iter; left time: 230.8067s
Epoch: 8 cost time: 2.4748291969299316
Epoch: 8, Steps: 128 Train Loss: 0.1802 (Forecasting Loss:0.1498 + XiCon Loss:3.0366 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1658
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1818394
	speed: 0.0215s/iter; left time: 251.3482s
Epoch: 9 cost time: 2.6002821922302246
Epoch: 9, Steps: 128 Train Loss: 0.1792 (Forecasting Loss:0.1488 + XiCon Loss:3.0353 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.1630
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1817774
	speed: 0.0190s/iter; left time: 218.9082s
Epoch: 10 cost time: 2.321063756942749
Epoch: 10, Steps: 128 Train Loss: 0.1783 (Forecasting Loss:0.1479 + XiCon Loss:3.0370 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1630
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1931906
	speed: 0.0196s/iter; left time: 224.3128s
Epoch: 11 cost time: 2.3563926219940186
Epoch: 11, Steps: 128 Train Loss: 0.1779 (Forecasting Loss:0.1475 + XiCon Loss:3.0370 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.1644
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.057980503886938095, mae:0.1850932538509369, mape:0.14719641208648682, mspe:0.04044714197516441 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0667+-0.01344, MAE:0.1987+-0.02077, MAPE:0.1613+-0.01947, MSPE:0.0546+-0.01886, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4264
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3627818
	speed: 0.0371s/iter; left time: 434.3522s
Epoch: 1 cost time: 4.246106863021851
Epoch: 1, Steps: 118 Train Loss: 0.3983 (Forecasting Loss:0.3668 + XiCon Loss:3.1485 x Lambda(0.01)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1729
Validation loss decreased (inf --> 0.265896).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2726181
	speed: 0.0414s/iter; left time: 479.6411s
Epoch: 2 cost time: 4.967101573944092
Epoch: 2, Steps: 118 Train Loss: 0.3020 (Forecasting Loss:0.2709 + XiCon Loss:3.1041 x Lambda(0.01)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.1464
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2572035
	speed: 0.0425s/iter; left time: 487.6616s
Epoch: 3 cost time: 4.939936637878418
Epoch: 3, Steps: 118 Train Loss: 0.2613 (Forecasting Loss:0.2308 + XiCon Loss:3.0488 x Lambda(0.01)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.1393
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2448244
	speed: 0.0426s/iter; left time: 483.2252s
Epoch: 4 cost time: 4.940927267074585
Epoch: 4, Steps: 118 Train Loss: 0.2507 (Forecasting Loss:0.2204 + XiCon Loss:3.0393 x Lambda(0.01)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1394
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2457844
	speed: 0.0432s/iter; left time: 484.9584s
Epoch: 5 cost time: 5.20188045501709
Epoch: 5, Steps: 118 Train Loss: 0.2446 (Forecasting Loss:0.2143 + XiCon Loss:3.0344 x Lambda(0.01)), Vali MSE Loss: 0.2874 Test MSE Loss: 0.1388
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2501961
	speed: 0.0414s/iter; left time: 460.1209s
Epoch: 6 cost time: 4.757641077041626
Epoch: 6, Steps: 118 Train Loss: 0.2424 (Forecasting Loss:0.2122 + XiCon Loss:3.0282 x Lambda(0.01)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2479560
	speed: 0.0431s/iter; left time: 473.3075s
Epoch: 7 cost time: 5.169706106185913
Epoch: 7, Steps: 118 Train Loss: 0.2411 (Forecasting Loss:0.2108 + XiCon Loss:3.0307 x Lambda(0.01)), Vali MSE Loss: 0.2933 Test MSE Loss: 0.1398
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2381214
	speed: 0.0420s/iter; left time: 456.6451s
Epoch: 8 cost time: 5.083320379257202
Epoch: 8, Steps: 118 Train Loss: 0.2404 (Forecasting Loss:0.2101 + XiCon Loss:3.0302 x Lambda(0.01)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1400
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2451388
	speed: 0.0430s/iter; left time: 462.1673s
Epoch: 9 cost time: 4.921505928039551
Epoch: 9, Steps: 118 Train Loss: 0.2400 (Forecasting Loss:0.2097 + XiCon Loss:3.0260 x Lambda(0.01)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.1404
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2613769
	speed: 0.0428s/iter; left time: 455.3810s
Epoch: 10 cost time: 5.126216650009155
Epoch: 10, Steps: 118 Train Loss: 0.2398 (Forecasting Loss:0.2096 + XiCon Loss:3.0249 x Lambda(0.01)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.1403
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2380511
	speed: 0.0409s/iter; left time: 430.3754s
Epoch: 11 cost time: 4.967669486999512
Epoch: 11, Steps: 118 Train Loss: 0.2398 (Forecasting Loss:0.2095 + XiCon Loss:3.0270 x Lambda(0.01)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.1403
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09852844476699829, mae:0.24731947481632233, mape:0.17980127036571503, mspe:0.051644522696733475 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4795
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3482740
	speed: 0.0345s/iter; left time: 403.8957s
Epoch: 1 cost time: 4.115925073623657
Epoch: 1, Steps: 118 Train Loss: 0.4003 (Forecasting Loss:0.3688 + XiCon Loss:3.1547 x Lambda(0.01)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.1673
Validation loss decreased (inf --> 0.258092).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2875725
	speed: 0.0356s/iter; left time: 412.5905s
Epoch: 2 cost time: 4.347818613052368
Epoch: 2, Steps: 118 Train Loss: 0.3058 (Forecasting Loss:0.2745 + XiCon Loss:3.1278 x Lambda(0.01)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.1400
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2576905
	speed: 0.0394s/iter; left time: 451.2623s
Epoch: 3 cost time: 4.633227825164795
Epoch: 3, Steps: 118 Train Loss: 0.2601 (Forecasting Loss:0.2291 + XiCon Loss:3.0984 x Lambda(0.01)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1341
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2413665
	speed: 0.0412s/iter; left time: 467.1035s
Epoch: 4 cost time: 4.897379398345947
Epoch: 4, Steps: 118 Train Loss: 0.2482 (Forecasting Loss:0.2173 + XiCon Loss:3.0909 x Lambda(0.01)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.1356
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2507612
	speed: 0.0388s/iter; left time: 436.0651s
Epoch: 5 cost time: 4.711593151092529
Epoch: 5, Steps: 118 Train Loss: 0.2436 (Forecasting Loss:0.2128 + XiCon Loss:3.0829 x Lambda(0.01)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.1332
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2369093
	speed: 0.0416s/iter; left time: 462.1102s
Epoch: 6 cost time: 4.754788160324097
Epoch: 6, Steps: 118 Train Loss: 0.2406 (Forecasting Loss:0.2098 + XiCon Loss:3.0812 x Lambda(0.01)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.1324
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2519041
	speed: 0.0395s/iter; left time: 434.2612s
Epoch: 7 cost time: 4.751240253448486
Epoch: 7, Steps: 118 Train Loss: 0.2394 (Forecasting Loss:0.2086 + XiCon Loss:3.0797 x Lambda(0.01)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1323
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2464724
	speed: 0.0400s/iter; left time: 434.4569s
Epoch: 8 cost time: 4.597519159317017
Epoch: 8, Steps: 118 Train Loss: 0.2385 (Forecasting Loss:0.2078 + XiCon Loss:3.0747 x Lambda(0.01)), Vali MSE Loss: 0.2738 Test MSE Loss: 0.1327
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2330690
	speed: 0.0395s/iter; left time: 424.7171s
Epoch: 9 cost time: 4.777721166610718
Epoch: 9, Steps: 118 Train Loss: 0.2382 (Forecasting Loss:0.2074 + XiCon Loss:3.0765 x Lambda(0.01)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.1327
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2289485
	speed: 0.0391s/iter; left time: 416.4459s
Epoch: 10 cost time: 4.5970330238342285
Epoch: 10, Steps: 118 Train Loss: 0.2382 (Forecasting Loss:0.2074 + XiCon Loss:3.0759 x Lambda(0.01)), Vali MSE Loss: 0.2673 Test MSE Loss: 0.1329
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2488732
	speed: 0.0389s/iter; left time: 408.7819s
Epoch: 11 cost time: 4.697283506393433
Epoch: 11, Steps: 118 Train Loss: 0.2379 (Forecasting Loss:0.2071 + XiCon Loss:3.0762 x Lambda(0.01)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.1328
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09321366250514984, mae:0.2413567304611206, mape:0.17685672640800476, mspe:0.05047585815191269 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5038
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3637370
	speed: 0.0315s/iter; left time: 368.2349s
Epoch: 1 cost time: 3.881770133972168
Epoch: 1, Steps: 118 Train Loss: 0.3823 (Forecasting Loss:0.3509 + XiCon Loss:3.1457 x Lambda(0.01)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.1575
Validation loss decreased (inf --> 0.247154).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3136007
	speed: 0.0312s/iter; left time: 361.8170s
Epoch: 2 cost time: 3.6797685623168945
Epoch: 2, Steps: 118 Train Loss: 0.3283 (Forecasting Loss:0.2972 + XiCon Loss:3.1141 x Lambda(0.01)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1587
Validation loss decreased (0.247154 --> 0.226216).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2577193
	speed: 0.0303s/iter; left time: 347.6621s
Epoch: 3 cost time: 3.772321939468384
Epoch: 3, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2382 + XiCon Loss:3.0876 x Lambda(0.01)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1439
Validation loss decreased (0.226216 --> 0.220668).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2488112
	speed: 0.0318s/iter; left time: 360.8444s
Epoch: 4 cost time: 3.903855323791504
Epoch: 4, Steps: 118 Train Loss: 0.2523 (Forecasting Loss:0.2215 + XiCon Loss:3.0809 x Lambda(0.01)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1409
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2526123
	speed: 0.0352s/iter; left time: 395.2832s
Epoch: 5 cost time: 4.066046953201294
Epoch: 5, Steps: 118 Train Loss: 0.2470 (Forecasting Loss:0.2163 + XiCon Loss:3.0784 x Lambda(0.01)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2467932
	speed: 0.0313s/iter; left time: 347.6597s
Epoch: 6 cost time: 3.729869842529297
Epoch: 6, Steps: 118 Train Loss: 0.2449 (Forecasting Loss:0.2141 + XiCon Loss:3.0785 x Lambda(0.01)), Vali MSE Loss: 0.2243 Test MSE Loss: 0.1402
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2586828
	speed: 0.0347s/iter; left time: 381.7033s
Epoch: 7 cost time: 4.119181871414185
Epoch: 7, Steps: 118 Train Loss: 0.2437 (Forecasting Loss:0.2130 + XiCon Loss:3.0764 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1411
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2559178
	speed: 0.0348s/iter; left time: 377.9302s
Epoch: 8 cost time: 3.9627676010131836
Epoch: 8, Steps: 118 Train Loss: 0.2431 (Forecasting Loss:0.2124 + XiCon Loss:3.0745 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.1408
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2434321
	speed: 0.0328s/iter; left time: 353.2427s
Epoch: 9 cost time: 3.949706554412842
Epoch: 9, Steps: 118 Train Loss: 0.2427 (Forecasting Loss:0.2119 + XiCon Loss:3.0737 x Lambda(0.01)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1405
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2529881
	speed: 0.0333s/iter; left time: 354.0555s
Epoch: 10 cost time: 3.9820151329040527
Epoch: 10, Steps: 118 Train Loss: 0.2427 (Forecasting Loss:0.2120 + XiCon Loss:3.0747 x Lambda(0.01)), Vali MSE Loss: 0.2253 Test MSE Loss: 0.1404
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2397636
	speed: 0.0350s/iter; left time: 368.6559s
Epoch: 11 cost time: 3.995002508163452
Epoch: 11, Steps: 118 Train Loss: 0.2425 (Forecasting Loss:0.2117 + XiCon Loss:3.0744 x Lambda(0.01)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1407
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2442836
	speed: 0.0326s/iter; left time: 339.5186s
Epoch: 12 cost time: 4.0401904582977295
Epoch: 12, Steps: 118 Train Loss: 0.2424 (Forecasting Loss:0.2116 + XiCon Loss:3.0753 x Lambda(0.01)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1407
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2463573
	speed: 0.0338s/iter; left time: 347.2341s
Epoch: 13 cost time: 3.9847922325134277
Epoch: 13, Steps: 118 Train Loss: 0.2423 (Forecasting Loss:0.2116 + XiCon Loss:3.0738 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.1408
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0723438560962677, mae:0.2154361605644226, mape:0.16335654258728027, mspe:0.046303801238536835 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4746
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3609468
	speed: 0.0332s/iter; left time: 388.9517s
Epoch: 1 cost time: 3.928649663925171
Epoch: 1, Steps: 118 Train Loss: 0.3826 (Forecasting Loss:0.3511 + XiCon Loss:3.1477 x Lambda(0.01)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.1661
Validation loss decreased (inf --> 0.253547).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3041826
	speed: 0.0387s/iter; left time: 448.3323s
Epoch: 2 cost time: 4.672944068908691
Epoch: 2, Steps: 118 Train Loss: 0.3423 (Forecasting Loss:0.3107 + XiCon Loss:3.1540 x Lambda(0.01)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.1523
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2500689
	speed: 0.0437s/iter; left time: 501.4478s
Epoch: 3 cost time: 5.00784969329834
Epoch: 3, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2371 + XiCon Loss:3.0928 x Lambda(0.01)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1420
Validation loss decreased (0.253547 --> 0.252877).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2730446
	speed: 0.0419s/iter; left time: 475.5475s
Epoch: 4 cost time: 5.048546075820923
Epoch: 4, Steps: 118 Train Loss: 0.2525 (Forecasting Loss:0.2217 + XiCon Loss:3.0743 x Lambda(0.01)), Vali MSE Loss: 0.2721 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2275489
	speed: 0.0412s/iter; left time: 463.1603s
Epoch: 5 cost time: 4.807570695877075
Epoch: 5, Steps: 118 Train Loss: 0.2464 (Forecasting Loss:0.2157 + XiCon Loss:3.0664 x Lambda(0.01)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.1441
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2412435
	speed: 0.0401s/iter; left time: 445.2178s
Epoch: 6 cost time: 4.764105796813965
Epoch: 6, Steps: 118 Train Loss: 0.2429 (Forecasting Loss:0.2123 + XiCon Loss:3.0611 x Lambda(0.01)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.1439
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2355321
	speed: 0.0419s/iter; left time: 460.1410s
Epoch: 7 cost time: 5.012624025344849
Epoch: 7, Steps: 118 Train Loss: 0.2415 (Forecasting Loss:0.2109 + XiCon Loss:3.0602 x Lambda(0.01)), Vali MSE Loss: 0.2700 Test MSE Loss: 0.1436
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2437841
	speed: 0.0415s/iter; left time: 451.2491s
Epoch: 8 cost time: 4.745508193969727
Epoch: 8, Steps: 118 Train Loss: 0.2407 (Forecasting Loss:0.2102 + XiCon Loss:3.0580 x Lambda(0.01)), Vali MSE Loss: 0.2674 Test MSE Loss: 0.1440
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2261262
	speed: 0.0401s/iter; left time: 431.0266s
Epoch: 9 cost time: 4.884185075759888
Epoch: 9, Steps: 118 Train Loss: 0.2404 (Forecasting Loss:0.2098 + XiCon Loss:3.0584 x Lambda(0.01)), Vali MSE Loss: 0.2676 Test MSE Loss: 0.1443
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2361297
	speed: 0.0416s/iter; left time: 442.4038s
Epoch: 10 cost time: 4.78863263130188
Epoch: 10, Steps: 118 Train Loss: 0.2402 (Forecasting Loss:0.2096 + XiCon Loss:3.0606 x Lambda(0.01)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.1443
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2369589
	speed: 0.0404s/iter; left time: 425.5109s
Epoch: 11 cost time: 4.883384704589844
Epoch: 11, Steps: 118 Train Loss: 0.2399 (Forecasting Loss:0.2093 + XiCon Loss:3.0582 x Lambda(0.01)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.1444
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2369628
	speed: 0.0409s/iter; left time: 425.5108s
Epoch: 12 cost time: 4.887548208236694
Epoch: 12, Steps: 118 Train Loss: 0.2401 (Forecasting Loss:0.2095 + XiCon Loss:3.0572 x Lambda(0.01)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.1444
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2456939
	speed: 0.0429s/iter; left time: 441.1767s
Epoch: 13 cost time: 4.944634914398193
Epoch: 13, Steps: 118 Train Loss: 0.2402 (Forecasting Loss:0.2096 + XiCon Loss:3.0587 x Lambda(0.01)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0712740570306778, mae:0.2126905918121338, mape:0.16050481796264648, mspe:0.04487147554755211 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5953
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3671787
	speed: 0.0350s/iter; left time: 408.9757s
Epoch: 1 cost time: 4.072149991989136
Epoch: 1, Steps: 118 Train Loss: 0.3844 (Forecasting Loss:0.3531 + XiCon Loss:3.1367 x Lambda(0.01)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1612
Validation loss decreased (inf --> 0.247733).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2934436
	speed: 0.0339s/iter; left time: 392.6760s
Epoch: 2 cost time: 4.041301488876343
Epoch: 2, Steps: 118 Train Loss: 0.3218 (Forecasting Loss:0.2911 + XiCon Loss:3.0676 x Lambda(0.01)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.1430
Validation loss decreased (0.247733 --> 0.230928).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2597793
	speed: 0.0337s/iter; left time: 386.0182s
Epoch: 3 cost time: 4.068258762359619
Epoch: 3, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2388 + XiCon Loss:3.0279 x Lambda(0.01)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1399
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2594461
	speed: 0.0347s/iter; left time: 393.3847s
Epoch: 4 cost time: 4.071469068527222
Epoch: 4, Steps: 118 Train Loss: 0.2518 (Forecasting Loss:0.2215 + XiCon Loss:3.0257 x Lambda(0.01)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.1360
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2413315
	speed: 0.0335s/iter; left time: 376.0589s
Epoch: 5 cost time: 4.0004658699035645
Epoch: 5, Steps: 118 Train Loss: 0.2445 (Forecasting Loss:0.2143 + XiCon Loss:3.0275 x Lambda(0.01)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2419341
	speed: 0.0352s/iter; left time: 390.9272s
Epoch: 6 cost time: 4.099843978881836
Epoch: 6, Steps: 118 Train Loss: 0.2415 (Forecasting Loss:0.2112 + XiCon Loss:3.0286 x Lambda(0.01)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1357
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2442549
	speed: 0.0339s/iter; left time: 372.4758s
Epoch: 7 cost time: 4.062896728515625
Epoch: 7, Steps: 118 Train Loss: 0.2401 (Forecasting Loss:0.2098 + XiCon Loss:3.0308 x Lambda(0.01)), Vali MSE Loss: 0.2560 Test MSE Loss: 0.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2460112
	speed: 0.0357s/iter; left time: 388.5425s
Epoch: 8 cost time: 4.110509634017944
Epoch: 8, Steps: 118 Train Loss: 0.2394 (Forecasting Loss:0.2091 + XiCon Loss:3.0310 x Lambda(0.01)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1356
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2454652
	speed: 0.0335s/iter; left time: 360.0623s
Epoch: 9 cost time: 3.9862756729125977
Epoch: 9, Steps: 118 Train Loss: 0.2388 (Forecasting Loss:0.2085 + XiCon Loss:3.0329 x Lambda(0.01)), Vali MSE Loss: 0.2571 Test MSE Loss: 0.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2327798
	speed: 0.0350s/iter; left time: 372.5749s
Epoch: 10 cost time: 4.156611919403076
Epoch: 10, Steps: 118 Train Loss: 0.2388 (Forecasting Loss:0.2085 + XiCon Loss:3.0319 x Lambda(0.01)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.1353
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2299436
	speed: 0.0358s/iter; left time: 377.0334s
Epoch: 11 cost time: 4.14255690574646
Epoch: 11, Steps: 118 Train Loss: 0.2386 (Forecasting Loss:0.2082 + XiCon Loss:3.0332 x Lambda(0.01)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.1353
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2539790
	speed: 0.0324s/iter; left time: 337.1581s
Epoch: 12 cost time: 3.899691343307495
Epoch: 12, Steps: 118 Train Loss: 0.2385 (Forecasting Loss:0.2082 + XiCon Loss:3.0329 x Lambda(0.01)), Vali MSE Loss: 0.2561 Test MSE Loss: 0.1353
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07276830077171326, mae:0.21325965225696564, mape:0.15811070799827576, mspe:0.042253363877534866 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0816+-0.01633, MAE:0.2260+-0.02097, MAPE:0.1677+-0.01231, MSPE:0.0471+-0.00485, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4211
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5177831
	speed: 0.0632s/iter; left time: 669.9914s
Epoch: 1 cost time: 6.768553018569946
Epoch: 1, Steps: 107 Train Loss: 0.5598 (Forecasting Loss:0.5283 + XiCon Loss:3.1517 x Lambda(0.01)), Vali MSE Loss: 0.3391 Test MSE Loss: 0.1931
Validation loss decreased (inf --> 0.339114).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3321940
	speed: 0.0613s/iter; left time: 643.3203s
Epoch: 2 cost time: 6.5656678676605225
Epoch: 2, Steps: 107 Train Loss: 0.4183 (Forecasting Loss:0.3869 + XiCon Loss:3.1378 x Lambda(0.01)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1443
Validation loss decreased (0.339114 --> 0.240433).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2980163
	speed: 0.0619s/iter; left time: 642.7585s
Epoch: 3 cost time: 6.630366563796997
Epoch: 3, Steps: 107 Train Loss: 0.3058 (Forecasting Loss:0.2745 + XiCon Loss:3.1250 x Lambda(0.01)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1349
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2907453
	speed: 0.0634s/iter; left time: 652.0729s
Epoch: 4 cost time: 6.7815101146698
Epoch: 4, Steps: 107 Train Loss: 0.2888 (Forecasting Loss:0.2576 + XiCon Loss:3.1168 x Lambda(0.01)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2778161
	speed: 0.0625s/iter; left time: 636.1069s
Epoch: 5 cost time: 6.697049856185913
Epoch: 5, Steps: 107 Train Loss: 0.2804 (Forecasting Loss:0.2493 + XiCon Loss:3.1104 x Lambda(0.01)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1371
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2765501
	speed: 0.0626s/iter; left time: 630.4466s
Epoch: 6 cost time: 6.738269090652466
Epoch: 6, Steps: 107 Train Loss: 0.2770 (Forecasting Loss:0.2460 + XiCon Loss:3.1077 x Lambda(0.01)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1363
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2527801
	speed: 0.0629s/iter; left time: 625.9995s
Epoch: 7 cost time: 6.720270395278931
Epoch: 7, Steps: 107 Train Loss: 0.2755 (Forecasting Loss:0.2445 + XiCon Loss:3.1063 x Lambda(0.01)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2816294
	speed: 0.0617s/iter; left time: 607.3889s
Epoch: 8 cost time: 6.645252466201782
Epoch: 8, Steps: 107 Train Loss: 0.2743 (Forecasting Loss:0.2433 + XiCon Loss:3.1041 x Lambda(0.01)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1376
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2864517
	speed: 0.0624s/iter; left time: 607.7680s
Epoch: 9 cost time: 6.670032262802124
Epoch: 9, Steps: 107 Train Loss: 0.2738 (Forecasting Loss:0.2428 + XiCon Loss:3.1049 x Lambda(0.01)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1380
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2851515
	speed: 0.0634s/iter; left time: 611.1353s
Epoch: 10 cost time: 6.816608190536499
Epoch: 10, Steps: 107 Train Loss: 0.2735 (Forecasting Loss:0.2424 + XiCon Loss:3.1041 x Lambda(0.01)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1376
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2739043
	speed: 0.0644s/iter; left time: 613.5906s
Epoch: 11 cost time: 6.933139085769653
Epoch: 11, Steps: 107 Train Loss: 0.2733 (Forecasting Loss:0.2422 + XiCon Loss:3.1051 x Lambda(0.01)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2777272
	speed: 0.0620s/iter; left time: 584.6174s
Epoch: 12 cost time: 6.777688503265381
Epoch: 12, Steps: 107 Train Loss: 0.2733 (Forecasting Loss:0.2422 + XiCon Loss:3.1053 x Lambda(0.01)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07333703339099884, mae:0.21532511711120605, mape:0.15630368888378143, mspe:0.03924732282757759 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4984
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5451248
	speed: 0.0627s/iter; left time: 664.2534s
Epoch: 1 cost time: 6.7171690464019775
Epoch: 1, Steps: 107 Train Loss: 0.5803 (Forecasting Loss:0.5487 + XiCon Loss:3.1556 x Lambda(0.01)), Vali MSE Loss: 0.3628 Test MSE Loss: 0.2238
Validation loss decreased (inf --> 0.362849).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3224592
	speed: 0.0674s/iter; left time: 707.4646s
Epoch: 2 cost time: 7.251093149185181
Epoch: 2, Steps: 107 Train Loss: 0.4294 (Forecasting Loss:0.3978 + XiCon Loss:3.1529 x Lambda(0.01)), Vali MSE Loss: 0.2961 Test MSE Loss: 0.1540
Validation loss decreased (0.362849 --> 0.296137).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2876899
	speed: 0.0732s/iter; left time: 760.3510s
Epoch: 3 cost time: 7.953653335571289
Epoch: 3, Steps: 107 Train Loss: 0.2979 (Forecasting Loss:0.2666 + XiCon Loss:3.1306 x Lambda(0.01)), Vali MSE Loss: 0.2807 Test MSE Loss: 0.1576
Validation loss decreased (0.296137 --> 0.280734).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2889229
	speed: 0.0755s/iter; left time: 776.2041s
Epoch: 4 cost time: 8.131078004837036
Epoch: 4, Steps: 107 Train Loss: 0.2816 (Forecasting Loss:0.2506 + XiCon Loss:3.1019 x Lambda(0.01)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.1501
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2803935
	speed: 0.0731s/iter; left time: 743.9371s
Epoch: 5 cost time: 7.819630861282349
Epoch: 5, Steps: 107 Train Loss: 0.2741 (Forecasting Loss:0.2432 + XiCon Loss:3.0917 x Lambda(0.01)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.1506
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2804221
	speed: 0.0740s/iter; left time: 744.8119s
Epoch: 6 cost time: 7.960221290588379
Epoch: 6, Steps: 107 Train Loss: 0.2706 (Forecasting Loss:0.2397 + XiCon Loss:3.0874 x Lambda(0.01)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.1485
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2623665
	speed: 0.0770s/iter; left time: 766.5561s
Epoch: 7 cost time: 8.28364109992981
Epoch: 7, Steps: 107 Train Loss: 0.2693 (Forecasting Loss:0.2384 + XiCon Loss:3.0879 x Lambda(0.01)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.1488
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2613590
	speed: 0.0744s/iter; left time: 733.4749s
Epoch: 8 cost time: 8.021795988082886
Epoch: 8, Steps: 107 Train Loss: 0.2683 (Forecasting Loss:0.2375 + XiCon Loss:3.0862 x Lambda(0.01)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1484
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2623880
	speed: 0.0637s/iter; left time: 620.6737s
Epoch: 9 cost time: 7.017858505249023
Epoch: 9, Steps: 107 Train Loss: 0.2682 (Forecasting Loss:0.2373 + XiCon Loss:3.0867 x Lambda(0.01)), Vali MSE Loss: 0.2978 Test MSE Loss: 0.1487
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2517349
	speed: 0.0729s/iter; left time: 702.4384s
Epoch: 10 cost time: 7.784914255142212
Epoch: 10, Steps: 107 Train Loss: 0.2672 (Forecasting Loss:0.2363 + XiCon Loss:3.0854 x Lambda(0.01)), Vali MSE Loss: 0.2966 Test MSE Loss: 0.1496
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2608837
	speed: 0.0734s/iter; left time: 699.3167s
Epoch: 11 cost time: 7.806835174560547
Epoch: 11, Steps: 107 Train Loss: 0.2674 (Forecasting Loss:0.2366 + XiCon Loss:3.0866 x Lambda(0.01)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.1491
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2689258
	speed: 0.0693s/iter; left time: 653.0142s
Epoch: 12 cost time: 7.531332969665527
Epoch: 12, Steps: 107 Train Loss: 0.2673 (Forecasting Loss:0.2364 + XiCon Loss:3.0868 x Lambda(0.01)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.1492
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2576041
	speed: 0.0775s/iter; left time: 722.1407s
Epoch: 13 cost time: 8.305837631225586
Epoch: 13, Steps: 107 Train Loss: 0.2673 (Forecasting Loss:0.2364 + XiCon Loss:3.0873 x Lambda(0.01)), Vali MSE Loss: 0.2954 Test MSE Loss: 0.1493
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08514193445444107, mae:0.22997653484344482, mape:0.16499589383602142, mspe:0.04418676719069481 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4652
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5373549
	speed: 0.0628s/iter; left time: 665.8654s
Epoch: 1 cost time: 6.783127546310425
Epoch: 1, Steps: 107 Train Loss: 0.5717 (Forecasting Loss:0.5402 + XiCon Loss:3.1466 x Lambda(0.01)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.2031
Validation loss decreased (inf --> 0.333697).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3173967
	speed: 0.0637s/iter; left time: 668.8018s
Epoch: 2 cost time: 6.8083741664886475
Epoch: 2, Steps: 107 Train Loss: 0.4269 (Forecasting Loss:0.3958 + XiCon Loss:3.1090 x Lambda(0.01)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.1493
Validation loss decreased (0.333697 --> 0.278368).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3139398
	speed: 0.0637s/iter; left time: 661.4360s
Epoch: 3 cost time: 6.934913396835327
Epoch: 3, Steps: 107 Train Loss: 0.3027 (Forecasting Loss:0.2718 + XiCon Loss:3.0876 x Lambda(0.01)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1412
Validation loss decreased (0.278368 --> 0.251836).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2838911
	speed: 0.0627s/iter; left time: 644.2286s
Epoch: 4 cost time: 6.755910873413086
Epoch: 4, Steps: 107 Train Loss: 0.2811 (Forecasting Loss:0.2504 + XiCon Loss:3.0687 x Lambda(0.01)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1329
Validation loss decreased (0.251836 --> 0.248744).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2812199
	speed: 0.0667s/iter; left time: 678.3874s
Epoch: 5 cost time: 7.12227988243103
Epoch: 5, Steps: 107 Train Loss: 0.2745 (Forecasting Loss:0.2439 + XiCon Loss:3.0603 x Lambda(0.01)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1328
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2761514
	speed: 0.0629s/iter; left time: 633.3603s
Epoch: 6 cost time: 6.825088977813721
Epoch: 6, Steps: 107 Train Loss: 0.2719 (Forecasting Loss:0.2414 + XiCon Loss:3.0550 x Lambda(0.01)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1326
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2689502
	speed: 0.0628s/iter; left time: 625.4069s
Epoch: 7 cost time: 6.755388259887695
Epoch: 7, Steps: 107 Train Loss: 0.2700 (Forecasting Loss:0.2395 + XiCon Loss:3.0548 x Lambda(0.01)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.1330
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2709069
	speed: 0.0631s/iter; left time: 621.4489s
Epoch: 8 cost time: 6.794533967971802
Epoch: 8, Steps: 107 Train Loss: 0.2691 (Forecasting Loss:0.2385 + XiCon Loss:3.0528 x Lambda(0.01)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1336
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2606475
	speed: 0.0627s/iter; left time: 610.7255s
Epoch: 9 cost time: 6.768063545227051
Epoch: 9, Steps: 107 Train Loss: 0.2686 (Forecasting Loss:0.2381 + XiCon Loss:3.0526 x Lambda(0.01)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1335
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2731432
	speed: 0.0639s/iter; left time: 615.9326s
Epoch: 10 cost time: 6.864043712615967
Epoch: 10, Steps: 107 Train Loss: 0.2684 (Forecasting Loss:0.2378 + XiCon Loss:3.0534 x Lambda(0.01)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1331
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2690493
	speed: 0.0630s/iter; left time: 600.3744s
Epoch: 11 cost time: 6.73335337638855
Epoch: 11, Steps: 107 Train Loss: 0.2682 (Forecasting Loss:0.2377 + XiCon Loss:3.0516 x Lambda(0.01)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1336
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2663474
	speed: 0.0622s/iter; left time: 586.4943s
Epoch: 12 cost time: 6.773871421813965
Epoch: 12, Steps: 107 Train Loss: 0.2681 (Forecasting Loss:0.2376 + XiCon Loss:3.0508 x Lambda(0.01)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1332
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2734175
	speed: 0.0634s/iter; left time: 590.9446s
Epoch: 13 cost time: 6.8064727783203125
Epoch: 13, Steps: 107 Train Loss: 0.2681 (Forecasting Loss:0.2376 + XiCon Loss:3.0525 x Lambda(0.01)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1332
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2600563
	speed: 0.0651s/iter; left time: 599.5623s
Epoch: 14 cost time: 7.034799098968506
Epoch: 14, Steps: 107 Train Loss: 0.2682 (Forecasting Loss:0.2377 + XiCon Loss:3.0527 x Lambda(0.01)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1332
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06519918888807297, mae:0.20057301223278046, mape:0.14720827341079712, mspe:0.03744988888502121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4391
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5428375
	speed: 0.0632s/iter; left time: 670.2678s
Epoch: 1 cost time: 6.878669738769531
Epoch: 1, Steps: 107 Train Loss: 0.5719 (Forecasting Loss:0.5404 + XiCon Loss:3.1509 x Lambda(0.01)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.2199
Validation loss decreased (inf --> 0.371608).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2950675
	speed: 0.0878s/iter; left time: 920.8546s
Epoch: 2 cost time: 9.552050590515137
Epoch: 2, Steps: 107 Train Loss: 0.3547 (Forecasting Loss:0.3237 + XiCon Loss:3.1034 x Lambda(0.01)), Vali MSE Loss: 0.4415 Test MSE Loss: 0.1432
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2760442
	speed: 0.0935s/iter; left time: 971.1455s
Epoch: 3 cost time: 10.113423824310303
Epoch: 3, Steps: 107 Train Loss: 0.2768 (Forecasting Loss:0.2461 + XiCon Loss:3.0719 x Lambda(0.01)), Vali MSE Loss: 0.3660 Test MSE Loss: 0.1487
Validation loss decreased (0.371608 --> 0.365974).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2669205
	speed: 0.0899s/iter; left time: 924.3688s
Epoch: 4 cost time: 9.728988647460938
Epoch: 4, Steps: 107 Train Loss: 0.2634 (Forecasting Loss:0.2327 + XiCon Loss:3.0671 x Lambda(0.01)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.1473
Validation loss decreased (0.365974 --> 0.339872).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2623941
	speed: 0.0921s/iter; left time: 936.4751s
Epoch: 5 cost time: 9.943379640579224
Epoch: 5, Steps: 107 Train Loss: 0.2593 (Forecasting Loss:0.2286 + XiCon Loss:3.0690 x Lambda(0.01)), Vali MSE Loss: 0.3607 Test MSE Loss: 0.1478
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2579822
	speed: 0.0864s/iter; left time: 869.9360s
Epoch: 6 cost time: 9.309197902679443
Epoch: 6, Steps: 107 Train Loss: 0.2563 (Forecasting Loss:0.2256 + XiCon Loss:3.0683 x Lambda(0.01)), Vali MSE Loss: 0.3692 Test MSE Loss: 0.1459
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2506294
	speed: 0.0873s/iter; left time: 869.5338s
Epoch: 7 cost time: 9.357069492340088
Epoch: 7, Steps: 107 Train Loss: 0.2550 (Forecasting Loss:0.2243 + XiCon Loss:3.0668 x Lambda(0.01)), Vali MSE Loss: 0.3555 Test MSE Loss: 0.1452
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2542045
	speed: 0.0908s/iter; left time: 894.9154s
Epoch: 8 cost time: 9.724271774291992
Epoch: 8, Steps: 107 Train Loss: 0.2544 (Forecasting Loss:0.2237 + XiCon Loss:3.0696 x Lambda(0.01)), Vali MSE Loss: 0.3560 Test MSE Loss: 0.1451
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2545433
	speed: 0.0888s/iter; left time: 865.3844s
Epoch: 9 cost time: 9.54149603843689
Epoch: 9, Steps: 107 Train Loss: 0.2540 (Forecasting Loss:0.2233 + XiCon Loss:3.0704 x Lambda(0.01)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.1459
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2438356
	speed: 0.0856s/iter; left time: 824.6769s
Epoch: 10 cost time: 9.258387804031372
Epoch: 10, Steps: 107 Train Loss: 0.2536 (Forecasting Loss:0.2229 + XiCon Loss:3.0685 x Lambda(0.01)), Vali MSE Loss: 0.3606 Test MSE Loss: 0.1459
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2543549
	speed: 0.0865s/iter; left time: 824.7848s
Epoch: 11 cost time: 9.35024905204773
Epoch: 11, Steps: 107 Train Loss: 0.2536 (Forecasting Loss:0.2230 + XiCon Loss:3.0643 x Lambda(0.01)), Vali MSE Loss: 0.3593 Test MSE Loss: 0.1457
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2585619
	speed: 0.0863s/iter; left time: 812.9620s
Epoch: 12 cost time: 9.2721107006073
Epoch: 12, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2230 + XiCon Loss:3.0687 x Lambda(0.01)), Vali MSE Loss: 0.3595 Test MSE Loss: 0.1456
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2519133
	speed: 0.0889s/iter; left time: 828.0674s
Epoch: 13 cost time: 9.690014362335205
Epoch: 13, Steps: 107 Train Loss: 0.2538 (Forecasting Loss:0.2231 + XiCon Loss:3.0672 x Lambda(0.01)), Vali MSE Loss: 0.3597 Test MSE Loss: 0.1457
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2598749
	speed: 0.0877s/iter; left time: 807.3084s
Epoch: 14 cost time: 9.373846292495728
Epoch: 14, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2230 + XiCon Loss:3.0697 x Lambda(0.01)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.1457
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07619212567806244, mae:0.21844901144504547, mape:0.16284672915935516, mspe:0.04914890229701996 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5167
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5537530
	speed: 0.0625s/iter; left time: 663.0267s
Epoch: 1 cost time: 6.670718193054199
Epoch: 1, Steps: 107 Train Loss: 0.5590 (Forecasting Loss:0.5275 + XiCon Loss:3.1484 x Lambda(0.01)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2056
Validation loss decreased (inf --> 0.352817).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2928540
	speed: 0.0824s/iter; left time: 864.8291s
Epoch: 2 cost time: 9.129802942276001
Epoch: 2, Steps: 107 Train Loss: 0.3476 (Forecasting Loss:0.3162 + XiCon Loss:3.1351 x Lambda(0.01)), Vali MSE Loss: 0.4155 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2642382
	speed: 0.0925s/iter; left time: 960.7432s
Epoch: 3 cost time: 10.01485300064087
Epoch: 3, Steps: 107 Train Loss: 0.2757 (Forecasting Loss:0.2445 + XiCon Loss:3.1170 x Lambda(0.01)), Vali MSE Loss: 0.4206 Test MSE Loss: 0.1623
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2693177
	speed: 0.0910s/iter; left time: 935.8578s
Epoch: 4 cost time: 9.886045694351196
Epoch: 4, Steps: 107 Train Loss: 0.2665 (Forecasting Loss:0.2354 + XiCon Loss:3.1099 x Lambda(0.01)), Vali MSE Loss: 0.4372 Test MSE Loss: 0.1486
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2645285
	speed: 0.0927s/iter; left time: 942.8773s
Epoch: 5 cost time: 10.088036298751831
Epoch: 5, Steps: 107 Train Loss: 0.2619 (Forecasting Loss:0.2308 + XiCon Loss:3.1046 x Lambda(0.01)), Vali MSE Loss: 0.4308 Test MSE Loss: 0.1476
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2624296
	speed: 0.0910s/iter; left time: 915.5555s
Epoch: 6 cost time: 9.899807453155518
Epoch: 6, Steps: 107 Train Loss: 0.2597 (Forecasting Loss:0.2287 + XiCon Loss:3.1014 x Lambda(0.01)), Vali MSE Loss: 0.4464 Test MSE Loss: 0.1519
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2688902
	speed: 0.0873s/iter; left time: 869.3867s
Epoch: 7 cost time: 9.570897102355957
Epoch: 7, Steps: 107 Train Loss: 0.2587 (Forecasting Loss:0.2277 + XiCon Loss:3.0989 x Lambda(0.01)), Vali MSE Loss: 0.4467 Test MSE Loss: 0.1494
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2621162
	speed: 0.0867s/iter; left time: 854.4981s
Epoch: 8 cost time: 9.394798994064331
Epoch: 8, Steps: 107 Train Loss: 0.2580 (Forecasting Loss:0.2270 + XiCon Loss:3.0999 x Lambda(0.01)), Vali MSE Loss: 0.4366 Test MSE Loss: 0.1493
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2533768
	speed: 0.0868s/iter; left time: 845.6148s
Epoch: 9 cost time: 9.44945478439331
Epoch: 9, Steps: 107 Train Loss: 0.2574 (Forecasting Loss:0.2265 + XiCon Loss:3.0977 x Lambda(0.01)), Vali MSE Loss: 0.4383 Test MSE Loss: 0.1492
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2583110
	speed: 0.0884s/iter; left time: 852.0269s
Epoch: 10 cost time: 9.494296312332153
Epoch: 10, Steps: 107 Train Loss: 0.2578 (Forecasting Loss:0.2268 + XiCon Loss:3.0989 x Lambda(0.01)), Vali MSE Loss: 0.4393 Test MSE Loss: 0.1492
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2651738
	speed: 0.0903s/iter; left time: 860.8324s
Epoch: 11 cost time: 9.662790775299072
Epoch: 11, Steps: 107 Train Loss: 0.2574 (Forecasting Loss:0.2264 + XiCon Loss:3.0973 x Lambda(0.01)), Vali MSE Loss: 0.4426 Test MSE Loss: 0.1492
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1272738128900528, mae:0.28400909900665283, mape:0.20308342576026917, mspe:0.06364443153142929 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0854+-0.03036, MAE:0.2297+-0.03990, MAPE:0.1669+-0.02655, MSPE:0.0467+-0.01303, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4149
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.168916463851929
Epoch: 1, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.7425 + XiCon Loss:3.1650 x Lambda(0.01)), Vali MSE Loss: 0.4346 Test MSE Loss: 0.2914
Validation loss decreased (inf --> 0.434560).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 12.92126727104187
Epoch: 2, Steps: 96 Train Loss: 0.5703 (Forecasting Loss:0.5388 + XiCon Loss:3.1556 x Lambda(0.01)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.2066
Validation loss decreased (0.434560 --> 0.264603).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.823173761367798
Epoch: 3, Steps: 96 Train Loss: 0.3134 (Forecasting Loss:0.2819 + XiCon Loss:3.1488 x Lambda(0.01)), Vali MSE Loss: 0.2831 Test MSE Loss: 0.1565
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.141952276229858
Epoch: 4, Steps: 96 Train Loss: 0.2876 (Forecasting Loss:0.2561 + XiCon Loss:3.1496 x Lambda(0.01)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.1668
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.383992671966553
Epoch: 5, Steps: 96 Train Loss: 0.2812 (Forecasting Loss:0.2497 + XiCon Loss:3.1502 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.1674
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.153649806976318
Epoch: 6, Steps: 96 Train Loss: 0.2779 (Forecasting Loss:0.2465 + XiCon Loss:3.1468 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.1647
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.157105207443237
Epoch: 7, Steps: 96 Train Loss: 0.2763 (Forecasting Loss:0.2448 + XiCon Loss:3.1479 x Lambda(0.01)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.1685
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.306541204452515
Epoch: 8, Steps: 96 Train Loss: 0.2754 (Forecasting Loss:0.2440 + XiCon Loss:3.1464 x Lambda(0.01)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.1645
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.320423603057861
Epoch: 9, Steps: 96 Train Loss: 0.2751 (Forecasting Loss:0.2436 + XiCon Loss:3.1473 x Lambda(0.01)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.1665
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.40131139755249
Epoch: 10, Steps: 96 Train Loss: 0.2745 (Forecasting Loss:0.2431 + XiCon Loss:3.1465 x Lambda(0.01)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.1658
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 12.911418914794922
Epoch: 11, Steps: 96 Train Loss: 0.2748 (Forecasting Loss:0.2433 + XiCon Loss:3.1458 x Lambda(0.01)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.1654
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.336171865463257
Epoch: 12, Steps: 96 Train Loss: 0.2744 (Forecasting Loss:0.2430 + XiCon Loss:3.1447 x Lambda(0.01)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.1654
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.12711156904697418, mae:0.28610458970069885, mape:0.19804486632347107, mspe:0.05586976930499077 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5342
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.059810638427734
Epoch: 1, Steps: 96 Train Loss: 0.7527 (Forecasting Loss:0.7212 + XiCon Loss:3.1574 x Lambda(0.01)), Vali MSE Loss: 0.4319 Test MSE Loss: 0.2623
Validation loss decreased (inf --> 0.431888).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.134809732437134
Epoch: 2, Steps: 96 Train Loss: 0.5189 (Forecasting Loss:0.4876 + XiCon Loss:3.1242 x Lambda(0.01)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.1499
Validation loss decreased (0.431888 --> 0.302931).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.563126564025879
Epoch: 3, Steps: 96 Train Loss: 0.3080 (Forecasting Loss:0.2770 + XiCon Loss:3.1027 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.1404
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.21682620048523
Epoch: 4, Steps: 96 Train Loss: 0.2860 (Forecasting Loss:0.2551 + XiCon Loss:3.0931 x Lambda(0.01)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1423
Validation loss decreased (0.302931 --> 0.302704).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.668934106826782
Epoch: 5, Steps: 96 Train Loss: 0.2789 (Forecasting Loss:0.2480 + XiCon Loss:3.0899 x Lambda(0.01)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.1424
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.276228427886963
Epoch: 6, Steps: 96 Train Loss: 0.2752 (Forecasting Loss:0.2443 + XiCon Loss:3.0857 x Lambda(0.01)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.1417
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.229198217391968
Epoch: 7, Steps: 96 Train Loss: 0.2733 (Forecasting Loss:0.2425 + XiCon Loss:3.0831 x Lambda(0.01)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.1412
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.276847124099731
Epoch: 8, Steps: 96 Train Loss: 0.2723 (Forecasting Loss:0.2415 + XiCon Loss:3.0836 x Lambda(0.01)), Vali MSE Loss: 0.3145 Test MSE Loss: 0.1414
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.857261180877686
Epoch: 9, Steps: 96 Train Loss: 0.2720 (Forecasting Loss:0.2412 + XiCon Loss:3.0825 x Lambda(0.01)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.1421
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 12.924887895584106
Epoch: 10, Steps: 96 Train Loss: 0.2717 (Forecasting Loss:0.2408 + XiCon Loss:3.0822 x Lambda(0.01)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.1417
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 12.806893110275269
Epoch: 11, Steps: 96 Train Loss: 0.2717 (Forecasting Loss:0.2409 + XiCon Loss:3.0825 x Lambda(0.01)), Vali MSE Loss: 0.3124 Test MSE Loss: 0.1416
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.258895874023438
Epoch: 12, Steps: 96 Train Loss: 0.2715 (Forecasting Loss:0.2407 + XiCon Loss:3.0822 x Lambda(0.01)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.1417
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 12.667787551879883
Epoch: 13, Steps: 96 Train Loss: 0.2716 (Forecasting Loss:0.2408 + XiCon Loss:3.0805 x Lambda(0.01)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.1416
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 12.480144023895264
Epoch: 14, Steps: 96 Train Loss: 0.2714 (Forecasting Loss:0.2406 + XiCon Loss:3.0810 x Lambda(0.01)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.1416
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07236691564321518, mae:0.21232612431049347, mape:0.15795308351516724, mspe:0.04279503971338272 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5090
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.448360204696655
Epoch: 1, Steps: 96 Train Loss: 0.8219 (Forecasting Loss:0.7902 + XiCon Loss:3.1647 x Lambda(0.01)), Vali MSE Loss: 0.5260 Test MSE Loss: 0.3335
Validation loss decreased (inf --> 0.526026).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 14.477662086486816
Epoch: 2, Steps: 96 Train Loss: 0.5742 (Forecasting Loss:0.5429 + XiCon Loss:3.1346 x Lambda(0.01)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1807
Validation loss decreased (0.526026 --> 0.302602).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 15.254008531570435
Epoch: 3, Steps: 96 Train Loss: 0.3292 (Forecasting Loss:0.2984 + XiCon Loss:3.0798 x Lambda(0.01)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1830
Validation loss decreased (0.302602 --> 0.298365).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.589168071746826
Epoch: 4, Steps: 96 Train Loss: 0.3006 (Forecasting Loss:0.2700 + XiCon Loss:3.0558 x Lambda(0.01)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.1868
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.786410093307495
Epoch: 5, Steps: 96 Train Loss: 0.2883 (Forecasting Loss:0.2577 + XiCon Loss:3.0529 x Lambda(0.01)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1789
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.258807897567749
Epoch: 6, Steps: 96 Train Loss: 0.2832 (Forecasting Loss:0.2527 + XiCon Loss:3.0491 x Lambda(0.01)), Vali MSE Loss: 0.3038 Test MSE Loss: 0.1844
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.688183546066284
Epoch: 7, Steps: 96 Train Loss: 0.2806 (Forecasting Loss:0.2502 + XiCon Loss:3.0491 x Lambda(0.01)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.1896
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.959107637405396
Epoch: 8, Steps: 96 Train Loss: 0.2795 (Forecasting Loss:0.2490 + XiCon Loss:3.0481 x Lambda(0.01)), Vali MSE Loss: 0.3044 Test MSE Loss: 0.1862
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.006884813308716
Epoch: 9, Steps: 96 Train Loss: 0.2784 (Forecasting Loss:0.2479 + XiCon Loss:3.0450 x Lambda(0.01)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1843
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.760562658309937
Epoch: 10, Steps: 96 Train Loss: 0.2780 (Forecasting Loss:0.2476 + XiCon Loss:3.0468 x Lambda(0.01)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1847
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.40572738647461
Epoch: 11, Steps: 96 Train Loss: 0.2780 (Forecasting Loss:0.2476 + XiCon Loss:3.0460 x Lambda(0.01)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1851
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.67442536354065
Epoch: 12, Steps: 96 Train Loss: 0.2777 (Forecasting Loss:0.2472 + XiCon Loss:3.0466 x Lambda(0.01)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.1853
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 15.844197511672974
Epoch: 13, Steps: 96 Train Loss: 0.2775 (Forecasting Loss:0.2470 + XiCon Loss:3.0485 x Lambda(0.01)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.1850
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.10660966485738754, mae:0.25943389534950256, mape:0.18421435356140137, mspe:0.0527719222009182 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4751
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 12.980994939804077
Epoch: 1, Steps: 96 Train Loss: 0.7426 (Forecasting Loss:0.7110 + XiCon Loss:3.1629 x Lambda(0.01)), Vali MSE Loss: 0.4293 Test MSE Loss: 0.2659
Validation loss decreased (inf --> 0.429259).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.218928575515747
Epoch: 2, Steps: 96 Train Loss: 0.5465 (Forecasting Loss:0.5151 + XiCon Loss:3.1452 x Lambda(0.01)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.1652
Validation loss decreased (0.429259 --> 0.319148).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.621213912963867
Epoch: 3, Steps: 96 Train Loss: 0.3714 (Forecasting Loss:0.3401 + XiCon Loss:3.1288 x Lambda(0.01)), Vali MSE Loss: 0.3007 Test MSE Loss: 0.1481
Validation loss decreased (0.319148 --> 0.300719).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.817640542984009
Epoch: 4, Steps: 96 Train Loss: 0.3297 (Forecasting Loss:0.2985 + XiCon Loss:3.1177 x Lambda(0.01)), Vali MSE Loss: 0.2724 Test MSE Loss: 0.1467
Validation loss decreased (0.300719 --> 0.272352).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.122559785842896
Epoch: 5, Steps: 96 Train Loss: 0.3161 (Forecasting Loss:0.2849 + XiCon Loss:3.1128 x Lambda(0.01)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1550
Validation loss decreased (0.272352 --> 0.246277).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.015259027481079
Epoch: 6, Steps: 96 Train Loss: 0.3081 (Forecasting Loss:0.2770 + XiCon Loss:3.1106 x Lambda(0.01)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1429
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.05825161933899
Epoch: 7, Steps: 96 Train Loss: 0.3037 (Forecasting Loss:0.2726 + XiCon Loss:3.1108 x Lambda(0.01)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.1435
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.527906656265259
Epoch: 8, Steps: 96 Train Loss: 0.3018 (Forecasting Loss:0.2707 + XiCon Loss:3.1087 x Lambda(0.01)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1439
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.76328730583191
Epoch: 9, Steps: 96 Train Loss: 0.3008 (Forecasting Loss:0.2697 + XiCon Loss:3.1084 x Lambda(0.01)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1421
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.060908079147339
Epoch: 10, Steps: 96 Train Loss: 0.3004 (Forecasting Loss:0.2693 + XiCon Loss:3.1074 x Lambda(0.01)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1433
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 12.79051423072815
Epoch: 11, Steps: 96 Train Loss: 0.3005 (Forecasting Loss:0.2694 + XiCon Loss:3.1100 x Lambda(0.01)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.1426
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 12.99272108078003
Epoch: 12, Steps: 96 Train Loss: 0.3011 (Forecasting Loss:0.2700 + XiCon Loss:3.1077 x Lambda(0.01)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1431
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.009394884109497
Epoch: 13, Steps: 96 Train Loss: 0.3011 (Forecasting Loss:0.2700 + XiCon Loss:3.1075 x Lambda(0.01)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1430
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 13.020439147949219
Epoch: 14, Steps: 96 Train Loss: 0.3005 (Forecasting Loss:0.2694 + XiCon Loss:3.1107 x Lambda(0.01)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1430
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 12.753941297531128
Epoch: 15, Steps: 96 Train Loss: 0.3003 (Forecasting Loss:0.2692 + XiCon Loss:3.1091 x Lambda(0.01)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1429
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08129746466875076, mae:0.2287381887435913, mape:0.17652501165866852, mspe:0.05456802248954773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5683
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.04377555847168
Epoch: 1, Steps: 96 Train Loss: 0.7427 (Forecasting Loss:0.7112 + XiCon Loss:3.1502 x Lambda(0.01)), Vali MSE Loss: 0.4270 Test MSE Loss: 0.2673
Validation loss decreased (inf --> 0.426974).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.37386703491211
Epoch: 2, Steps: 96 Train Loss: 0.5349 (Forecasting Loss:0.5036 + XiCon Loss:3.1269 x Lambda(0.01)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.1523
Validation loss decreased (0.426974 --> 0.310708).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.015239715576172
Epoch: 3, Steps: 96 Train Loss: 0.3271 (Forecasting Loss:0.2960 + XiCon Loss:3.1087 x Lambda(0.01)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.1464
Validation loss decreased (0.310708 --> 0.274231).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.260992050170898
Epoch: 4, Steps: 96 Train Loss: 0.2939 (Forecasting Loss:0.2629 + XiCon Loss:3.1067 x Lambda(0.01)), Vali MSE Loss: 0.2961 Test MSE Loss: 0.1377
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.046082973480225
Epoch: 5, Steps: 96 Train Loss: 0.2858 (Forecasting Loss:0.2548 + XiCon Loss:3.1049 x Lambda(0.01)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.1359
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.350072622299194
Epoch: 6, Steps: 96 Train Loss: 0.2812 (Forecasting Loss:0.2502 + XiCon Loss:3.1023 x Lambda(0.01)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.1361
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.344520330429077
Epoch: 7, Steps: 96 Train Loss: 0.2792 (Forecasting Loss:0.2482 + XiCon Loss:3.1009 x Lambda(0.01)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.1361
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.418720960617065
Epoch: 8, Steps: 96 Train Loss: 0.2778 (Forecasting Loss:0.2468 + XiCon Loss:3.1012 x Lambda(0.01)), Vali MSE Loss: 0.2917 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.146848678588867
Epoch: 9, Steps: 96 Train Loss: 0.2776 (Forecasting Loss:0.2466 + XiCon Loss:3.1010 x Lambda(0.01)), Vali MSE Loss: 0.2915 Test MSE Loss: 0.1365
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.373051643371582
Epoch: 10, Steps: 96 Train Loss: 0.2773 (Forecasting Loss:0.2462 + XiCon Loss:3.1024 x Lambda(0.01)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.1360
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.049394369125366
Epoch: 11, Steps: 96 Train Loss: 0.2771 (Forecasting Loss:0.2461 + XiCon Loss:3.1004 x Lambda(0.01)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.1361
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.382083654403687
Epoch: 12, Steps: 96 Train Loss: 0.2773 (Forecasting Loss:0.2463 + XiCon Loss:3.1028 x Lambda(0.01)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.1360
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.43772578239441
Epoch: 13, Steps: 96 Train Loss: 0.2770 (Forecasting Loss:0.2460 + XiCon Loss:3.1002 x Lambda(0.01)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1360
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07627736777067184, mae:0.2165215015411377, mape:0.15631474554538727, mspe:0.03942273184657097 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0927+-0.02906, MAE:0.2406+-0.03900, MAPE:0.1746+-0.02201, MSPE:0.0491+-0.00926, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4212
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2646844
	speed: 0.0218s/iter; left time: 276.5816s
Epoch: 1 cost time: 2.6809792518615723
Epoch: 1, Steps: 128 Train Loss: 0.3233 (Forecasting Loss:0.2922 + XiCon Loss:3.1106 x Lambda(0.01)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.2309
Validation loss decreased (inf --> 0.274898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2376791
	speed: 0.0213s/iter; left time: 267.8194s
Epoch: 2 cost time: 2.5898234844207764
Epoch: 2, Steps: 128 Train Loss: 0.2658 (Forecasting Loss:0.2352 + XiCon Loss:3.0609 x Lambda(0.01)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.2727
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2082075
	speed: 0.0219s/iter; left time: 272.7454s
Epoch: 3 cost time: 2.6238694190979004
Epoch: 3, Steps: 128 Train Loss: 0.2140 (Forecasting Loss:0.1837 + XiCon Loss:3.0285 x Lambda(0.01)), Vali MSE Loss: 0.3089 Test MSE Loss: 0.3034
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1814113
	speed: 0.0198s/iter; left time: 243.6313s
Epoch: 4 cost time: 2.5700392723083496
Epoch: 4, Steps: 128 Train Loss: 0.1895 (Forecasting Loss:0.1594 + XiCon Loss:3.0130 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3179
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1853441
	speed: 0.0213s/iter; left time: 259.6677s
Epoch: 5 cost time: 2.697815418243408
Epoch: 5, Steps: 128 Train Loss: 0.1803 (Forecasting Loss:0.1502 + XiCon Loss:3.0034 x Lambda(0.01)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.3244
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1810334
	speed: 0.0196s/iter; left time: 236.3428s
Epoch: 6 cost time: 2.6293179988861084
Epoch: 6, Steps: 128 Train Loss: 0.1756 (Forecasting Loss:0.1456 + XiCon Loss:2.9980 x Lambda(0.01)), Vali MSE Loss: 0.3189 Test MSE Loss: 0.3252
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1829294
	speed: 0.0192s/iter; left time: 228.7524s
Epoch: 7 cost time: 2.5149753093719482
Epoch: 7, Steps: 128 Train Loss: 0.1732 (Forecasting Loss:0.1433 + XiCon Loss:2.9960 x Lambda(0.01)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.3252
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1768937
	speed: 0.0204s/iter; left time: 240.2580s
Epoch: 8 cost time: 2.688678503036499
Epoch: 8, Steps: 128 Train Loss: 0.1725 (Forecasting Loss:0.1425 + XiCon Loss:2.9951 x Lambda(0.01)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.3268
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1694238
	speed: 0.0197s/iter; left time: 230.3368s
Epoch: 9 cost time: 2.504546642303467
Epoch: 9, Steps: 128 Train Loss: 0.1717 (Forecasting Loss:0.1417 + XiCon Loss:2.9962 x Lambda(0.01)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.3271
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1602415
	speed: 0.0205s/iter; left time: 236.4410s
Epoch: 10 cost time: 2.612501859664917
Epoch: 10, Steps: 128 Train Loss: 0.1713 (Forecasting Loss:0.1414 + XiCon Loss:2.9959 x Lambda(0.01)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.3273
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1742912
	speed: 0.0191s/iter; left time: 218.0454s
Epoch: 11 cost time: 2.355342149734497
Epoch: 11, Steps: 128 Train Loss: 0.1714 (Forecasting Loss:0.1415 + XiCon Loss:2.9944 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.3277
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1532350778579712, mae:0.3085482716560364, mape:0.7093964219093323, mspe:22.0687255859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4343
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3162101
	speed: 0.0247s/iter; left time: 314.1968s
Epoch: 1 cost time: 2.921694755554199
Epoch: 1, Steps: 128 Train Loss: 0.3223 (Forecasting Loss:0.2913 + XiCon Loss:3.1053 x Lambda(0.01)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2238
Validation loss decreased (inf --> 0.278699).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2517867
	speed: 0.0196s/iter; left time: 246.5880s
Epoch: 2 cost time: 2.6222875118255615
Epoch: 2, Steps: 128 Train Loss: 0.2683 (Forecasting Loss:0.2377 + XiCon Loss:3.0609 x Lambda(0.01)), Vali MSE Loss: 0.2868 Test MSE Loss: 0.2531
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2135595
	speed: 0.0227s/iter; left time: 282.3558s
Epoch: 3 cost time: 2.791123867034912
Epoch: 3, Steps: 128 Train Loss: 0.2239 (Forecasting Loss:0.1934 + XiCon Loss:3.0460 x Lambda(0.01)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2560
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1775482
	speed: 0.0224s/iter; left time: 275.4807s
Epoch: 4 cost time: 2.84802508354187
Epoch: 4, Steps: 128 Train Loss: 0.1956 (Forecasting Loss:0.1654 + XiCon Loss:3.0194 x Lambda(0.01)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.2910
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2047626
	speed: 0.0254s/iter; left time: 309.9712s
Epoch: 5 cost time: 2.9911065101623535
Epoch: 5, Steps: 128 Train Loss: 0.1829 (Forecasting Loss:0.1527 + XiCon Loss:3.0140 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.3078
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1636071
	speed: 0.0244s/iter; left time: 294.6495s
Epoch: 6 cost time: 3.041800022125244
Epoch: 6, Steps: 128 Train Loss: 0.1778 (Forecasting Loss:0.1477 + XiCon Loss:3.0109 x Lambda(0.01)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.3137
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1650666
	speed: 0.0219s/iter; left time: 260.9056s
Epoch: 7 cost time: 2.6310365200042725
Epoch: 7, Steps: 128 Train Loss: 0.1755 (Forecasting Loss:0.1454 + XiCon Loss:3.0094 x Lambda(0.01)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.3124
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1810854
	speed: 0.0225s/iter; left time: 265.1337s
Epoch: 8 cost time: 2.681126117706299
Epoch: 8, Steps: 128 Train Loss: 0.1738 (Forecasting Loss:0.1438 + XiCon Loss:3.0076 x Lambda(0.01)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.3140
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1735043
	speed: 0.0242s/iter; left time: 282.6420s
Epoch: 9 cost time: 2.8399412631988525
Epoch: 9, Steps: 128 Train Loss: 0.1736 (Forecasting Loss:0.1435 + XiCon Loss:3.0075 x Lambda(0.01)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.3146
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1683245
	speed: 0.0202s/iter; left time: 232.7455s
Epoch: 10 cost time: 2.4999842643737793
Epoch: 10, Steps: 128 Train Loss: 0.1735 (Forecasting Loss:0.1434 + XiCon Loss:3.0089 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3139
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1650316
	speed: 0.0197s/iter; left time: 225.0455s
Epoch: 11 cost time: 2.525449514389038
Epoch: 11, Steps: 128 Train Loss: 0.1732 (Forecasting Loss:0.1431 + XiCon Loss:3.0075 x Lambda(0.01)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.3148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.14576774835586548, mae:0.3018505275249481, mape:0.7110899686813354, mspe:22.301603317260742 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4368
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2968102
	speed: 0.0233s/iter; left time: 296.3402s
Epoch: 1 cost time: 2.746957778930664
Epoch: 1, Steps: 128 Train Loss: 0.3230 (Forecasting Loss:0.2919 + XiCon Loss:3.1131 x Lambda(0.01)), Vali MSE Loss: 0.2758 Test MSE Loss: 0.2240
Validation loss decreased (inf --> 0.275824).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2764419
	speed: 0.0235s/iter; left time: 294.8531s
Epoch: 2 cost time: 2.7615694999694824
Epoch: 2, Steps: 128 Train Loss: 0.2686 (Forecasting Loss:0.2378 + XiCon Loss:3.0749 x Lambda(0.01)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2279
Validation loss decreased (0.275824 --> 0.258117).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2113144
	speed: 0.0217s/iter; left time: 270.3535s
Epoch: 3 cost time: 2.694601058959961
Epoch: 3, Steps: 128 Train Loss: 0.2337 (Forecasting Loss:0.2032 + XiCon Loss:3.0483 x Lambda(0.01)), Vali MSE Loss: 0.2873 Test MSE Loss: 0.2441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2016808
	speed: 0.0223s/iter; left time: 274.0661s
Epoch: 4 cost time: 2.7188570499420166
Epoch: 4, Steps: 128 Train Loss: 0.2116 (Forecasting Loss:0.1813 + XiCon Loss:3.0329 x Lambda(0.01)), Vali MSE Loss: 0.3056 Test MSE Loss: 0.2489
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2025350
	speed: 0.0219s/iter; left time: 266.7121s
Epoch: 5 cost time: 2.8367347717285156
Epoch: 5, Steps: 128 Train Loss: 0.1974 (Forecasting Loss:0.1671 + XiCon Loss:3.0273 x Lambda(0.01)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.2582
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1763569
	speed: 0.0205s/iter; left time: 247.7847s
Epoch: 6 cost time: 2.5288662910461426
Epoch: 6, Steps: 128 Train Loss: 0.1916 (Forecasting Loss:0.1614 + XiCon Loss:3.0237 x Lambda(0.01)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.2618
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1828354
	speed: 0.0209s/iter; left time: 249.2132s
Epoch: 7 cost time: 2.735565185546875
Epoch: 7, Steps: 128 Train Loss: 0.1890 (Forecasting Loss:0.1588 + XiCon Loss:3.0209 x Lambda(0.01)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1865382
	speed: 0.0196s/iter; left time: 231.5359s
Epoch: 8 cost time: 2.476436138153076
Epoch: 8, Steps: 128 Train Loss: 0.1877 (Forecasting Loss:0.1575 + XiCon Loss:3.0214 x Lambda(0.01)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2626
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1984699
	speed: 0.0213s/iter; left time: 248.9497s
Epoch: 9 cost time: 2.64640212059021
Epoch: 9, Steps: 128 Train Loss: 0.1870 (Forecasting Loss:0.1568 + XiCon Loss:3.0225 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2635
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1875452
	speed: 0.0209s/iter; left time: 241.7672s
Epoch: 10 cost time: 2.582026720046997
Epoch: 10, Steps: 128 Train Loss: 0.1867 (Forecasting Loss:0.1565 + XiCon Loss:3.0210 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2638
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1783836
	speed: 0.0203s/iter; left time: 232.3280s
Epoch: 11 cost time: 2.5673298835754395
Epoch: 11, Steps: 128 Train Loss: 0.1865 (Forecasting Loss:0.1563 + XiCon Loss:3.0215 x Lambda(0.01)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2633
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1840891
	speed: 0.0229s/iter; left time: 258.0703s
Epoch: 12 cost time: 2.7929463386535645
Epoch: 12, Steps: 128 Train Loss: 0.1864 (Forecasting Loss:0.1562 + XiCon Loss:3.0213 x Lambda(0.01)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.2633
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15199297666549683, mae:0.30381423234939575, mape:0.7687588334083557, mspe:26.85730743408203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5611
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2484150
	speed: 0.0212s/iter; left time: 269.1997s
Epoch: 1 cost time: 2.718986988067627
Epoch: 1, Steps: 128 Train Loss: 0.3263 (Forecasting Loss:0.2953 + XiCon Loss:3.0994 x Lambda(0.01)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.2279
Validation loss decreased (inf --> 0.271536).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2769954
	speed: 0.0249s/iter; left time: 313.5149s
Epoch: 2 cost time: 3.063654899597168
Epoch: 2, Steps: 128 Train Loss: 0.2733 (Forecasting Loss:0.2421 + XiCon Loss:3.1169 x Lambda(0.01)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.2526
Validation loss decreased (0.271536 --> 0.259747).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2244183
	speed: 0.0211s/iter; left time: 262.8683s
Epoch: 3 cost time: 2.628478527069092
Epoch: 3, Steps: 128 Train Loss: 0.2277 (Forecasting Loss:0.1970 + XiCon Loss:3.0759 x Lambda(0.01)), Vali MSE Loss: 0.2756 Test MSE Loss: 0.3390
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1911124
	speed: 0.0177s/iter; left time: 217.6348s
Epoch: 4 cost time: 2.2832629680633545
Epoch: 4, Steps: 128 Train Loss: 0.1975 (Forecasting Loss:0.1670 + XiCon Loss:3.0527 x Lambda(0.01)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.3474
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1704661
	speed: 0.0177s/iter; left time: 215.9471s
Epoch: 5 cost time: 2.133742570877075
Epoch: 5, Steps: 128 Train Loss: 0.1841 (Forecasting Loss:0.1536 + XiCon Loss:3.0440 x Lambda(0.01)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.3561
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1695037
	speed: 0.0235s/iter; left time: 283.5122s
Epoch: 6 cost time: 2.723158359527588
Epoch: 6, Steps: 128 Train Loss: 0.1792 (Forecasting Loss:0.1488 + XiCon Loss:3.0393 x Lambda(0.01)), Vali MSE Loss: 0.2680 Test MSE Loss: 0.3708
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1834080
	speed: 0.0230s/iter; left time: 274.0110s
Epoch: 7 cost time: 2.7975661754608154
Epoch: 7, Steps: 128 Train Loss: 0.1767 (Forecasting Loss:0.1463 + XiCon Loss:3.0357 x Lambda(0.01)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.3696
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1830876
	speed: 0.0221s/iter; left time: 260.5542s
Epoch: 8 cost time: 2.7750940322875977
Epoch: 8, Steps: 128 Train Loss: 0.1754 (Forecasting Loss:0.1451 + XiCon Loss:3.0340 x Lambda(0.01)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.3798
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1859060
	speed: 0.0181s/iter; left time: 211.9357s
Epoch: 9 cost time: 2.326540946960449
Epoch: 9, Steps: 128 Train Loss: 0.1748 (Forecasting Loss:0.1445 + XiCon Loss:3.0351 x Lambda(0.01)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.3776
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1803351
	speed: 0.0193s/iter; left time: 222.9140s
Epoch: 10 cost time: 2.4225878715515137
Epoch: 10, Steps: 128 Train Loss: 0.1747 (Forecasting Loss:0.1444 + XiCon Loss:3.0356 x Lambda(0.01)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.3781
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1699853
	speed: 0.0203s/iter; left time: 232.2418s
Epoch: 11 cost time: 2.5933117866516113
Epoch: 11, Steps: 128 Train Loss: 0.1746 (Forecasting Loss:0.1443 + XiCon Loss:3.0341 x Lambda(0.01)), Vali MSE Loss: 0.2709 Test MSE Loss: 0.3799
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1706782
	speed: 0.0193s/iter; left time: 218.0349s
Epoch: 12 cost time: 2.457839250564575
Epoch: 12, Steps: 128 Train Loss: 0.1745 (Forecasting Loss:0.1442 + XiCon Loss:3.0353 x Lambda(0.01)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.3790
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1747506856918335, mae:0.3304835557937622, mape:0.7928066849708557, mspe:25.029855728149414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4807
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2714483
	speed: 0.0239s/iter; left time: 303.4575s
Epoch: 1 cost time: 2.9767487049102783
Epoch: 1, Steps: 128 Train Loss: 0.3257 (Forecasting Loss:0.2948 + XiCon Loss:3.0953 x Lambda(0.01)), Vali MSE Loss: 0.2737 Test MSE Loss: 0.2262
Validation loss decreased (inf --> 0.273719).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2342063
	speed: 0.0234s/iter; left time: 294.5149s
Epoch: 2 cost time: 2.7514100074768066
Epoch: 2, Steps: 128 Train Loss: 0.2759 (Forecasting Loss:0.2453 + XiCon Loss:3.0626 x Lambda(0.01)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2673
Validation loss decreased (0.273719 --> 0.248573).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2461912
	speed: 0.0195s/iter; left time: 242.7859s
Epoch: 3 cost time: 2.5856688022613525
Epoch: 3, Steps: 128 Train Loss: 0.2342 (Forecasting Loss:0.2038 + XiCon Loss:3.0452 x Lambda(0.01)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.2742
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2037135
	speed: 0.0222s/iter; left time: 273.3196s
Epoch: 4 cost time: 2.718827962875366
Epoch: 4, Steps: 128 Train Loss: 0.2054 (Forecasting Loss:0.1751 + XiCon Loss:3.0352 x Lambda(0.01)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.3010
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2002242
	speed: 0.0229s/iter; left time: 278.6280s
Epoch: 5 cost time: 2.772343635559082
Epoch: 5, Steps: 128 Train Loss: 0.1916 (Forecasting Loss:0.1612 + XiCon Loss:3.0323 x Lambda(0.01)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2902
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1872501
	speed: 0.0200s/iter; left time: 241.5348s
Epoch: 6 cost time: 2.480902671813965
Epoch: 6, Steps: 128 Train Loss: 0.1854 (Forecasting Loss:0.1551 + XiCon Loss:3.0285 x Lambda(0.01)), Vali MSE Loss: 0.2857 Test MSE Loss: 0.3118
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1888734
	speed: 0.0204s/iter; left time: 242.8605s
Epoch: 7 cost time: 2.5785555839538574
Epoch: 7, Steps: 128 Train Loss: 0.1824 (Forecasting Loss:0.1521 + XiCon Loss:3.0272 x Lambda(0.01)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.3093
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1817806
	speed: 0.0214s/iter; left time: 253.2037s
Epoch: 8 cost time: 2.716108798980713
Epoch: 8, Steps: 128 Train Loss: 0.1808 (Forecasting Loss:0.1505 + XiCon Loss:3.0270 x Lambda(0.01)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.3155
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1935449
	speed: 0.0201s/iter; left time: 235.1788s
Epoch: 9 cost time: 2.8111371994018555
Epoch: 9, Steps: 128 Train Loss: 0.1803 (Forecasting Loss:0.1500 + XiCon Loss:3.0282 x Lambda(0.01)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.3150
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1783164
	speed: 0.0233s/iter; left time: 268.7894s
Epoch: 10 cost time: 2.9111275672912598
Epoch: 10, Steps: 128 Train Loss: 0.1798 (Forecasting Loss:0.1495 + XiCon Loss:3.0280 x Lambda(0.01)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.3126
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1738579
	speed: 0.0224s/iter; left time: 255.4952s
Epoch: 11 cost time: 2.7322986125946045
Epoch: 11, Steps: 128 Train Loss: 0.1795 (Forecasting Loss:0.1492 + XiCon Loss:3.0304 x Lambda(0.01)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.3121
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1900201
	speed: 0.0235s/iter; left time: 265.1711s
Epoch: 12 cost time: 2.9109668731689453
Epoch: 12, Steps: 128 Train Loss: 0.1797 (Forecasting Loss:0.1494 + XiCon Loss:3.0254 x Lambda(0.01)), Vali MSE Loss: 0.2912 Test MSE Loss: 0.3120
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.20337718725204468, mae:0.33129575848579407, mape:0.7058175206184387, mspe:18.872594833374023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1658+-0.02940, MAE:0.3152+-0.01804, MAPE:0.7376+-0.05016, MSPE:23.0260+-3.79603, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4405628
	speed: 0.0379s/iter; left time: 443.3244s
Epoch: 1 cost time: 4.292541742324829
Epoch: 1, Steps: 118 Train Loss: 0.4452 (Forecasting Loss:0.4140 + XiCon Loss:3.1217 x Lambda(0.01)), Vali MSE Loss: 0.4300 Test MSE Loss: 0.3241
Validation loss decreased (inf --> 0.429967).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3047175
	speed: 0.0420s/iter; left time: 486.0269s
Epoch: 2 cost time: 5.097628593444824
Epoch: 2, Steps: 118 Train Loss: 0.3321 (Forecasting Loss:0.3008 + XiCon Loss:3.1361 x Lambda(0.01)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.2752
Validation loss decreased (0.429967 --> 0.368397).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3006367
	speed: 0.0407s/iter; left time: 466.2988s
Epoch: 3 cost time: 4.946611166000366
Epoch: 3, Steps: 118 Train Loss: 0.2885 (Forecasting Loss:0.2576 + XiCon Loss:3.0838 x Lambda(0.01)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.2654
Validation loss decreased (0.368397 --> 0.316982).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2931218
	speed: 0.0394s/iter; left time: 446.8960s
Epoch: 4 cost time: 4.580560922622681
Epoch: 4, Steps: 118 Train Loss: 0.2747 (Forecasting Loss:0.2440 + XiCon Loss:3.0664 x Lambda(0.01)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2521
Validation loss decreased (0.316982 --> 0.313107).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2578871
	speed: 0.0422s/iter; left time: 474.3289s
Epoch: 5 cost time: 4.857510805130005
Epoch: 5, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2387 + XiCon Loss:3.0553 x Lambda(0.01)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.2518
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2547590
	speed: 0.0398s/iter; left time: 442.0260s
Epoch: 6 cost time: 4.831043004989624
Epoch: 6, Steps: 118 Train Loss: 0.2663 (Forecasting Loss:0.2358 + XiCon Loss:3.0477 x Lambda(0.01)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2474
Validation loss decreased (0.313107 --> 0.307409).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2714735
	speed: 0.0403s/iter; left time: 442.4715s
Epoch: 7 cost time: 4.74797511100769
Epoch: 7, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2343 + XiCon Loss:3.0438 x Lambda(0.01)), Vali MSE Loss: 0.3105 Test MSE Loss: 0.2471
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2433690
	speed: 0.0410s/iter; left time: 445.3685s
Epoch: 8 cost time: 4.6708221435546875
Epoch: 8, Steps: 118 Train Loss: 0.2640 (Forecasting Loss:0.2336 + XiCon Loss:3.0416 x Lambda(0.01)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.2469
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2572519
	speed: 0.0410s/iter; left time: 441.0999s
Epoch: 9 cost time: 4.918348789215088
Epoch: 9, Steps: 118 Train Loss: 0.2635 (Forecasting Loss:0.2331 + XiCon Loss:3.0415 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.2453
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2596570
	speed: 0.0390s/iter; left time: 415.1958s
Epoch: 10 cost time: 4.706382989883423
Epoch: 10, Steps: 118 Train Loss: 0.2634 (Forecasting Loss:0.2330 + XiCon Loss:3.0394 x Lambda(0.01)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2459
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2609803
	speed: 0.0423s/iter; left time: 444.6186s
Epoch: 11 cost time: 4.780943155288696
Epoch: 11, Steps: 118 Train Loss: 0.2631 (Forecasting Loss:0.2327 + XiCon Loss:3.0396 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2452
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2623849
	speed: 0.0405s/iter; left time: 421.7849s
Epoch: 12 cost time: 4.900614261627197
Epoch: 12, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0397 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2455
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2619769
	speed: 0.0396s/iter; left time: 407.6053s
Epoch: 13 cost time: 4.8397862911224365
Epoch: 13, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2325 + XiCon Loss:3.0409 x Lambda(0.01)), Vali MSE Loss: 0.3088 Test MSE Loss: 0.2454
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2671677
	speed: 0.0392s/iter; left time: 399.0527s
Epoch: 14 cost time: 4.5056562423706055
Epoch: 14, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2325 + XiCon Loss:3.0399 x Lambda(0.01)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2454
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2411303
	speed: 0.0410s/iter; left time: 411.8318s
Epoch: 15 cost time: 4.915067911148071
Epoch: 15, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0374 x Lambda(0.01)), Vali MSE Loss: 0.3097 Test MSE Loss: 0.2454
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2734219
	speed: 0.0406s/iter; left time: 403.2956s
Epoch: 16 cost time: 4.862342357635498
Epoch: 16, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0382 x Lambda(0.01)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.2454
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1650843769311905, mae:0.32978230714797974, mape:0.6829966902732849, mspe:21.367393493652344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4867
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4133497
	speed: 0.0351s/iter; left time: 410.8023s
Epoch: 1 cost time: 4.218125581741333
Epoch: 1, Steps: 118 Train Loss: 0.4392 (Forecasting Loss:0.4081 + XiCon Loss:3.1107 x Lambda(0.01)), Vali MSE Loss: 0.4202 Test MSE Loss: 0.3056
Validation loss decreased (inf --> 0.420221).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3357653
	speed: 0.0358s/iter; left time: 415.1682s
Epoch: 2 cost time: 4.112440586090088
Epoch: 2, Steps: 118 Train Loss: 0.3625 (Forecasting Loss:0.3313 + XiCon Loss:3.1150 x Lambda(0.01)), Vali MSE Loss: 0.3665 Test MSE Loss: 0.2794
Validation loss decreased (0.420221 --> 0.366526).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2882906
	speed: 0.0339s/iter; left time: 388.1621s
Epoch: 3 cost time: 4.0439722537994385
Epoch: 3, Steps: 118 Train Loss: 0.3107 (Forecasting Loss:0.2798 + XiCon Loss:3.0903 x Lambda(0.01)), Vali MSE Loss: 0.3739 Test MSE Loss: 0.2652
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2775315
	speed: 0.0354s/iter; left time: 401.4802s
Epoch: 4 cost time: 4.102280616760254
Epoch: 4, Steps: 118 Train Loss: 0.2877 (Forecasting Loss:0.2570 + XiCon Loss:3.0641 x Lambda(0.01)), Vali MSE Loss: 0.3324 Test MSE Loss: 0.2545
Validation loss decreased (0.366526 --> 0.332430).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2823214
	speed: 0.0359s/iter; left time: 403.0848s
Epoch: 5 cost time: 4.305710315704346
Epoch: 5, Steps: 118 Train Loss: 0.2780 (Forecasting Loss:0.2475 + XiCon Loss:3.0496 x Lambda(0.01)), Vali MSE Loss: 0.3425 Test MSE Loss: 0.2634
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3043094
	speed: 0.0366s/iter; left time: 407.0178s
Epoch: 6 cost time: 4.168447732925415
Epoch: 6, Steps: 118 Train Loss: 0.2736 (Forecasting Loss:0.2431 + XiCon Loss:3.0438 x Lambda(0.01)), Vali MSE Loss: 0.3517 Test MSE Loss: 0.2617
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2645233
	speed: 0.0334s/iter; left time: 367.0749s
Epoch: 7 cost time: 4.027052402496338
Epoch: 7, Steps: 118 Train Loss: 0.2716 (Forecasting Loss:0.2412 + XiCon Loss:3.0377 x Lambda(0.01)), Vali MSE Loss: 0.3491 Test MSE Loss: 0.2700
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2720357
	speed: 0.0337s/iter; left time: 366.5221s
Epoch: 8 cost time: 3.917327642440796
Epoch: 8, Steps: 118 Train Loss: 0.2708 (Forecasting Loss:0.2404 + XiCon Loss:3.0350 x Lambda(0.01)), Vali MSE Loss: 0.3447 Test MSE Loss: 0.2669
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2746261
	speed: 0.0341s/iter; left time: 367.0638s
Epoch: 9 cost time: 4.123553514480591
Epoch: 9, Steps: 118 Train Loss: 0.2702 (Forecasting Loss:0.2398 + XiCon Loss:3.0345 x Lambda(0.01)), Vali MSE Loss: 0.3445 Test MSE Loss: 0.2612
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2684875
	speed: 0.0338s/iter; left time: 359.7723s
Epoch: 10 cost time: 4.04555869102478
Epoch: 10, Steps: 118 Train Loss: 0.2695 (Forecasting Loss:0.2392 + XiCon Loss:3.0324 x Lambda(0.01)), Vali MSE Loss: 0.3458 Test MSE Loss: 0.2600
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2756660
	speed: 0.0337s/iter; left time: 354.3389s
Epoch: 11 cost time: 4.0687291622161865
Epoch: 11, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2389 + XiCon Loss:3.0347 x Lambda(0.01)), Vali MSE Loss: 0.3462 Test MSE Loss: 0.2636
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2671920
	speed: 0.0345s/iter; left time: 359.2629s
Epoch: 12 cost time: 4.169373512268066
Epoch: 12, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2393 + XiCon Loss:3.0313 x Lambda(0.01)), Vali MSE Loss: 0.3462 Test MSE Loss: 0.2629
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2742814
	speed: 0.0344s/iter; left time: 353.6875s
Epoch: 13 cost time: 4.171386480331421
Epoch: 13, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2389 + XiCon Loss:3.0317 x Lambda(0.01)), Vali MSE Loss: 0.3475 Test MSE Loss: 0.2628
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2671980
	speed: 0.0342s/iter; left time: 347.7875s
Epoch: 14 cost time: 4.132231950759888
Epoch: 14, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2390 + XiCon Loss:3.0301 x Lambda(0.01)), Vali MSE Loss: 0.3474 Test MSE Loss: 0.2623
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17295557260513306, mae:0.3360919952392578, mape:0.6305581331253052, mspe:16.058401107788086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4457
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3545002
	speed: 0.0336s/iter; left time: 392.8569s
Epoch: 1 cost time: 4.046138763427734
Epoch: 1, Steps: 118 Train Loss: 0.4187 (Forecasting Loss:0.3874 + XiCon Loss:3.1282 x Lambda(0.01)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2897
Validation loss decreased (inf --> 0.386271).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3295774
	speed: 0.0345s/iter; left time: 399.4088s
Epoch: 2 cost time: 4.3020758628845215
Epoch: 2, Steps: 118 Train Loss: 0.3566 (Forecasting Loss:0.3257 + XiCon Loss:3.0896 x Lambda(0.01)), Vali MSE Loss: 0.3425 Test MSE Loss: 0.2894
Validation loss decreased (0.386271 --> 0.342464).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3066424
	speed: 0.0346s/iter; left time: 396.5632s
Epoch: 3 cost time: 4.03577733039856
Epoch: 3, Steps: 118 Train Loss: 0.3008 (Forecasting Loss:0.2705 + XiCon Loss:3.0331 x Lambda(0.01)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2832
Validation loss decreased (0.342464 --> 0.323360).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2620455
	speed: 0.0327s/iter; left time: 370.5974s
Epoch: 4 cost time: 3.9170944690704346
Epoch: 4, Steps: 118 Train Loss: 0.2827 (Forecasting Loss:0.2526 + XiCon Loss:3.0120 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2585722
	speed: 0.0328s/iter; left time: 368.5459s
Epoch: 5 cost time: 4.003315687179565
Epoch: 5, Steps: 118 Train Loss: 0.2755 (Forecasting Loss:0.2455 + XiCon Loss:3.0036 x Lambda(0.01)), Vali MSE Loss: 0.3302 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2751866
	speed: 0.0337s/iter; left time: 374.1899s
Epoch: 6 cost time: 4.000530242919922
Epoch: 6, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2420 + XiCon Loss:3.0018 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2753
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2592349
	speed: 0.0331s/iter; left time: 363.6819s
Epoch: 7 cost time: 4.075508117675781
Epoch: 7, Steps: 118 Train Loss: 0.2697 (Forecasting Loss:0.2397 + XiCon Loss:2.9995 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2796
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2732528
	speed: 0.0349s/iter; left time: 379.2411s
Epoch: 8 cost time: 4.350367546081543
Epoch: 8, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2389 + XiCon Loss:3.0019 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2758
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2828690
	speed: 0.0358s/iter; left time: 385.0940s
Epoch: 9 cost time: 4.046670913696289
Epoch: 9, Steps: 118 Train Loss: 0.2684 (Forecasting Loss:0.2384 + XiCon Loss:3.0029 x Lambda(0.01)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2770
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2491027
	speed: 0.0356s/iter; left time: 378.9181s
Epoch: 10 cost time: 4.233292102813721
Epoch: 10, Steps: 118 Train Loss: 0.2684 (Forecasting Loss:0.2383 + XiCon Loss:3.0007 x Lambda(0.01)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2756
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2734933
	speed: 0.0344s/iter; left time: 362.2354s
Epoch: 11 cost time: 3.967758893966675
Epoch: 11, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2381 + XiCon Loss:3.0018 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2761
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2579716
	speed: 0.0349s/iter; left time: 363.4039s
Epoch: 12 cost time: 4.171389579772949
Epoch: 12, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2382 + XiCon Loss:3.0015 x Lambda(0.01)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2768
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2664119
	speed: 0.0346s/iter; left time: 356.2083s
Epoch: 13 cost time: 4.030129909515381
Epoch: 13, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2382 + XiCon Loss:3.0005 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2764
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20536792278289795, mae:0.3610754907131195, mape:0.6175006628036499, mspe:14.306506156921387 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4817
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3688754
	speed: 0.0348s/iter; left time: 407.2168s
Epoch: 1 cost time: 4.027263164520264
Epoch: 1, Steps: 118 Train Loss: 0.4388 (Forecasting Loss:0.4076 + XiCon Loss:3.1177 x Lambda(0.01)), Vali MSE Loss: 0.4253 Test MSE Loss: 0.3139
Validation loss decreased (inf --> 0.425332).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2986998
	speed: 0.0409s/iter; left time: 473.9883s
Epoch: 2 cost time: 4.973924398422241
Epoch: 2, Steps: 118 Train Loss: 0.3227 (Forecasting Loss:0.2917 + XiCon Loss:3.0951 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2714
Validation loss decreased (0.425332 --> 0.325228).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3035188
	speed: 0.0418s/iter; left time: 479.2354s
Epoch: 3 cost time: 5.051368713378906
Epoch: 3, Steps: 118 Train Loss: 0.2819 (Forecasting Loss:0.2513 + XiCon Loss:3.0537 x Lambda(0.01)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2523
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2797498
	speed: 0.0411s/iter; left time: 466.0318s
Epoch: 4 cost time: 4.685408115386963
Epoch: 4, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2386 + XiCon Loss:3.0351 x Lambda(0.01)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.2526
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2603030
	speed: 0.0279s/iter; left time: 313.6677s
Epoch: 5 cost time: 3.779478073120117
Epoch: 5, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2326 + XiCon Loss:3.0267 x Lambda(0.01)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.2459
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2788196
	speed: 0.0410s/iter; left time: 455.7935s
Epoch: 6 cost time: 4.992929935455322
Epoch: 6, Steps: 118 Train Loss: 0.2606 (Forecasting Loss:0.2304 + XiCon Loss:3.0186 x Lambda(0.01)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.2459
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2605604
	speed: 0.0425s/iter; left time: 467.3741s
Epoch: 7 cost time: 4.994220972061157
Epoch: 7, Steps: 118 Train Loss: 0.2591 (Forecasting Loss:0.2290 + XiCon Loss:3.0141 x Lambda(0.01)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2468
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2563053
	speed: 0.0417s/iter; left time: 453.6836s
Epoch: 8 cost time: 5.035641193389893
Epoch: 8, Steps: 118 Train Loss: 0.2585 (Forecasting Loss:0.2284 + XiCon Loss:3.0115 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2474
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2543643
	speed: 0.0425s/iter; left time: 456.7240s
Epoch: 9 cost time: 4.929887294769287
Epoch: 9, Steps: 118 Train Loss: 0.2581 (Forecasting Loss:0.2280 + XiCon Loss:3.0101 x Lambda(0.01)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.2470
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2677006
	speed: 0.0423s/iter; left time: 450.1751s
Epoch: 10 cost time: 5.074159383773804
Epoch: 10, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0092 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2464
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2445617
	speed: 0.0427s/iter; left time: 449.6065s
Epoch: 11 cost time: 4.962305307388306
Epoch: 11, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0114 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2468
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2436481
	speed: 0.0426s/iter; left time: 442.8200s
Epoch: 12 cost time: 5.111258268356323
Epoch: 12, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0122 x Lambda(0.01)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2470
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19070352613925934, mae:0.35201308131217957, mape:0.7517504096031189, mspe:22.81319236755371 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5075
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4100092
	speed: 0.0358s/iter; left time: 418.6546s
Epoch: 1 cost time: 4.095202445983887
Epoch: 1, Steps: 118 Train Loss: 0.4339 (Forecasting Loss:0.4027 + XiCon Loss:3.1168 x Lambda(0.01)), Vali MSE Loss: 0.4264 Test MSE Loss: 0.3147
Validation loss decreased (inf --> 0.426355).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3400102
	speed: 0.0347s/iter; left time: 402.2971s
Epoch: 2 cost time: 4.3140549659729
Epoch: 2, Steps: 118 Train Loss: 0.3476 (Forecasting Loss:0.3167 + XiCon Loss:3.0886 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2712
Validation loss decreased (0.426355 --> 0.329714).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2958357
	speed: 0.0341s/iter; left time: 390.5380s
Epoch: 3 cost time: 4.155766725540161
Epoch: 3, Steps: 118 Train Loss: 0.2985 (Forecasting Loss:0.2682 + XiCon Loss:3.0292 x Lambda(0.01)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.2611
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2812607
	speed: 0.0354s/iter; left time: 402.1032s
Epoch: 4 cost time: 4.048035383224487
Epoch: 4, Steps: 118 Train Loss: 0.2823 (Forecasting Loss:0.2519 + XiCon Loss:3.0347 x Lambda(0.01)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2609
Validation loss decreased (0.329714 --> 0.322603).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2719037
	speed: 0.0337s/iter; left time: 377.9284s
Epoch: 5 cost time: 4.11285400390625
Epoch: 5, Steps: 118 Train Loss: 0.2728 (Forecasting Loss:0.2424 + XiCon Loss:3.0412 x Lambda(0.01)), Vali MSE Loss: 0.3482 Test MSE Loss: 0.2709
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2716928
	speed: 0.0341s/iter; left time: 378.3830s
Epoch: 6 cost time: 4.16933536529541
Epoch: 6, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2387 + XiCon Loss:3.0486 x Lambda(0.01)), Vali MSE Loss: 0.3256 Test MSE Loss: 0.2579
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2870926
	speed: 0.0370s/iter; left time: 406.4559s
Epoch: 7 cost time: 4.210218667984009
Epoch: 7, Steps: 118 Train Loss: 0.2663 (Forecasting Loss:0.2358 + XiCon Loss:3.0512 x Lambda(0.01)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.2623
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2673965
	speed: 0.0341s/iter; left time: 370.5400s
Epoch: 8 cost time: 3.9427661895751953
Epoch: 8, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2351 + XiCon Loss:3.0540 x Lambda(0.01)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2599
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2666754
	speed: 0.0358s/iter; left time: 385.3605s
Epoch: 9 cost time: 4.275266647338867
Epoch: 9, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2343 + XiCon Loss:3.0515 x Lambda(0.01)), Vali MSE Loss: 0.3311 Test MSE Loss: 0.2607
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2586102
	speed: 0.0377s/iter; left time: 400.8919s
Epoch: 10 cost time: 4.26932430267334
Epoch: 10, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2342 + XiCon Loss:3.0544 x Lambda(0.01)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2608716
	speed: 0.0337s/iter; left time: 354.7649s
Epoch: 11 cost time: 4.091466903686523
Epoch: 11, Steps: 118 Train Loss: 0.2644 (Forecasting Loss:0.2339 + XiCon Loss:3.0549 x Lambda(0.01)), Vali MSE Loss: 0.3359 Test MSE Loss: 0.2607
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2641588
	speed: 0.0346s/iter; left time: 359.4406s
Epoch: 12 cost time: 4.159400224685669
Epoch: 12, Steps: 118 Train Loss: 0.2642 (Forecasting Loss:0.2337 + XiCon Loss:3.0541 x Lambda(0.01)), Vali MSE Loss: 0.3371 Test MSE Loss: 0.2608
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2718700
	speed: 0.0361s/iter; left time: 371.2989s
Epoch: 13 cost time: 4.252307415008545
Epoch: 13, Steps: 118 Train Loss: 0.2646 (Forecasting Loss:0.2340 + XiCon Loss:3.0542 x Lambda(0.01)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2611
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2508161
	speed: 0.0355s/iter; left time: 360.4560s
Epoch: 14 cost time: 4.041553735733032
Epoch: 14, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2336 + XiCon Loss:3.0512 x Lambda(0.01)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.2611
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17769427597522736, mae:0.34417247772216797, mape:0.6463844776153564, mspe:17.145233154296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1824+-0.01971, MAE:0.3446+-0.01544, MAPE:0.6658+-0.06697, MSPE:18.3381+-4.48019, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4558
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6119814
	speed: 0.0480s/iter; left time: 508.3201s
Epoch: 1 cost time: 5.234801292419434
Epoch: 1, Steps: 107 Train Loss: 0.6653 (Forecasting Loss:0.6340 + XiCon Loss:3.1356 x Lambda(0.01)), Vali MSE Loss: 0.5970 Test MSE Loss: 0.4677
Validation loss decreased (inf --> 0.597029).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3291260
	speed: 0.0562s/iter; left time: 589.5460s
Epoch: 2 cost time: 6.054135322570801
Epoch: 2, Steps: 107 Train Loss: 0.3855 (Forecasting Loss:0.3540 + XiCon Loss:3.1483 x Lambda(0.01)), Vali MSE Loss: 0.3594 Test MSE Loss: 0.2592
Validation loss decreased (0.597029 --> 0.359415).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2889241
	speed: 0.0595s/iter; left time: 618.1726s
Epoch: 3 cost time: 6.45633864402771
Epoch: 3, Steps: 107 Train Loss: 0.2992 (Forecasting Loss:0.2684 + XiCon Loss:3.0849 x Lambda(0.01)), Vali MSE Loss: 0.3441 Test MSE Loss: 0.2632
Validation loss decreased (0.359415 --> 0.344131).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2849057
	speed: 0.0605s/iter; left time: 621.5488s
Epoch: 4 cost time: 6.523606300354004
Epoch: 4, Steps: 107 Train Loss: 0.2880 (Forecasting Loss:0.2574 + XiCon Loss:3.0603 x Lambda(0.01)), Vali MSE Loss: 0.3431 Test MSE Loss: 0.2430
Validation loss decreased (0.344131 --> 0.343115).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2924465
	speed: 0.0595s/iter; left time: 605.0383s
Epoch: 5 cost time: 6.47160005569458
Epoch: 5, Steps: 107 Train Loss: 0.2832 (Forecasting Loss:0.2527 + XiCon Loss:3.0511 x Lambda(0.01)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2464
Validation loss decreased (0.343115 --> 0.336065).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2697885
	speed: 0.0569s/iter; left time: 573.1190s
Epoch: 6 cost time: 6.111035108566284
Epoch: 6, Steps: 107 Train Loss: 0.2806 (Forecasting Loss:0.2501 + XiCon Loss:3.0465 x Lambda(0.01)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2491
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2832836
	speed: 0.0580s/iter; left time: 577.9003s
Epoch: 7 cost time: 6.26569676399231
Epoch: 7, Steps: 107 Train Loss: 0.2790 (Forecasting Loss:0.2486 + XiCon Loss:3.0433 x Lambda(0.01)), Vali MSE Loss: 0.3328 Test MSE Loss: 0.2517
Validation loss decreased (0.336065 --> 0.332768).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2782467
	speed: 0.0590s/iter; left time: 581.5972s
Epoch: 8 cost time: 6.380566120147705
Epoch: 8, Steps: 107 Train Loss: 0.2786 (Forecasting Loss:0.2482 + XiCon Loss:3.0423 x Lambda(0.01)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.2521
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2795055
	speed: 0.0568s/iter; left time: 553.4710s
Epoch: 9 cost time: 6.117914915084839
Epoch: 9, Steps: 107 Train Loss: 0.2782 (Forecasting Loss:0.2478 + XiCon Loss:3.0398 x Lambda(0.01)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2503
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2750200
	speed: 0.0576s/iter; left time: 555.3511s
Epoch: 10 cost time: 6.17538857460022
Epoch: 10, Steps: 107 Train Loss: 0.2780 (Forecasting Loss:0.2476 + XiCon Loss:3.0394 x Lambda(0.01)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2494
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2775882
	speed: 0.0573s/iter; left time: 546.1043s
Epoch: 11 cost time: 6.199067115783691
Epoch: 11, Steps: 107 Train Loss: 0.2779 (Forecasting Loss:0.2475 + XiCon Loss:3.0392 x Lambda(0.01)), Vali MSE Loss: 0.3364 Test MSE Loss: 0.2485
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2746459
	speed: 0.0581s/iter; left time: 547.7554s
Epoch: 12 cost time: 6.367515325546265
Epoch: 12, Steps: 107 Train Loss: 0.2779 (Forecasting Loss:0.2475 + XiCon Loss:3.0407 x Lambda(0.01)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.2490
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2750071
	speed: 0.0554s/iter; left time: 516.5368s
Epoch: 13 cost time: 5.990501165390015
Epoch: 13, Steps: 107 Train Loss: 0.2778 (Forecasting Loss:0.2474 + XiCon Loss:3.0397 x Lambda(0.01)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.2492
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2760890
	speed: 0.0585s/iter; left time: 538.6846s
Epoch: 14 cost time: 6.252908706665039
Epoch: 14, Steps: 107 Train Loss: 0.2777 (Forecasting Loss:0.2473 + XiCon Loss:3.0407 x Lambda(0.01)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2494
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2872119
	speed: 0.0584s/iter; left time: 531.4904s
Epoch: 15 cost time: 6.318863391876221
Epoch: 15, Steps: 107 Train Loss: 0.2779 (Forecasting Loss:0.2475 + XiCon Loss:3.0387 x Lambda(0.01)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2493
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2797911
	speed: 0.0583s/iter; left time: 524.7539s
Epoch: 16 cost time: 6.322997331619263
Epoch: 16, Steps: 107 Train Loss: 0.2779 (Forecasting Loss:0.2475 + XiCon Loss:3.0399 x Lambda(0.01)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2493
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2776922
	speed: 0.0559s/iter; left time: 496.6046s
Epoch: 17 cost time: 5.980475902557373
Epoch: 17, Steps: 107 Train Loss: 0.2776 (Forecasting Loss:0.2472 + XiCon Loss:3.0380 x Lambda(0.01)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.2493
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.16910460591316223, mae:0.33428895473480225, mape:0.6347940564155579, mspe:16.18403434753418 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5247
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6379382
	speed: 0.0453s/iter; left time: 480.3664s
Epoch: 1 cost time: 4.8923914432525635
Epoch: 1, Steps: 107 Train Loss: 0.6496 (Forecasting Loss:0.6183 + XiCon Loss:3.1253 x Lambda(0.01)), Vali MSE Loss: 0.5548 Test MSE Loss: 0.4209
Validation loss decreased (inf --> 0.554757).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3491007
	speed: 0.0434s/iter; left time: 455.8694s
Epoch: 2 cost time: 4.75286078453064
Epoch: 2, Steps: 107 Train Loss: 0.4482 (Forecasting Loss:0.4173 + XiCon Loss:3.0911 x Lambda(0.01)), Vali MSE Loss: 0.4100 Test MSE Loss: 0.2836
Validation loss decreased (0.554757 --> 0.410024).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3148049
	speed: 0.0442s/iter; left time: 459.2509s
Epoch: 3 cost time: 4.825127363204956
Epoch: 3, Steps: 107 Train Loss: 0.3231 (Forecasting Loss:0.2926 + XiCon Loss:3.0511 x Lambda(0.01)), Vali MSE Loss: 0.3549 Test MSE Loss: 0.2651
Validation loss decreased (0.410024 --> 0.354901).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3057745
	speed: 0.0459s/iter; left time: 471.7924s
Epoch: 4 cost time: 4.885763168334961
Epoch: 4, Steps: 107 Train Loss: 0.2986 (Forecasting Loss:0.2683 + XiCon Loss:3.0268 x Lambda(0.01)), Vali MSE Loss: 0.3445 Test MSE Loss: 0.3289
Validation loss decreased (0.354901 --> 0.344505).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2769885
	speed: 0.0447s/iter; left time: 455.1411s
Epoch: 5 cost time: 4.813636779785156
Epoch: 5, Steps: 107 Train Loss: 0.2906 (Forecasting Loss:0.2604 + XiCon Loss:3.0192 x Lambda(0.01)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2871
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2873549
	speed: 0.0453s/iter; left time: 456.0174s
Epoch: 6 cost time: 4.814965486526489
Epoch: 6, Steps: 107 Train Loss: 0.2852 (Forecasting Loss:0.2550 + XiCon Loss:3.0151 x Lambda(0.01)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2901
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2672364
	speed: 0.0440s/iter; left time: 438.0762s
Epoch: 7 cost time: 4.7806620597839355
Epoch: 7, Steps: 107 Train Loss: 0.2834 (Forecasting Loss:0.2533 + XiCon Loss:3.0135 x Lambda(0.01)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2751
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2839401
	speed: 0.0448s/iter; left time: 440.9725s
Epoch: 8 cost time: 4.8599653244018555
Epoch: 8, Steps: 107 Train Loss: 0.2825 (Forecasting Loss:0.2524 + XiCon Loss:3.0125 x Lambda(0.01)), Vali MSE Loss: 0.3481 Test MSE Loss: 0.3038
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2877114
	speed: 0.0441s/iter; left time: 429.5788s
Epoch: 9 cost time: 4.767523288726807
Epoch: 9, Steps: 107 Train Loss: 0.2823 (Forecasting Loss:0.2521 + XiCon Loss:3.0134 x Lambda(0.01)), Vali MSE Loss: 0.3461 Test MSE Loss: 0.2968
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2743450
	speed: 0.0443s/iter; left time: 426.7258s
Epoch: 10 cost time: 4.772345781326294
Epoch: 10, Steps: 107 Train Loss: 0.2815 (Forecasting Loss:0.2513 + XiCon Loss:3.0137 x Lambda(0.01)), Vali MSE Loss: 0.3453 Test MSE Loss: 0.2947
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2688314
	speed: 0.0440s/iter; left time: 419.3932s
Epoch: 11 cost time: 4.675204277038574
Epoch: 11, Steps: 107 Train Loss: 0.2815 (Forecasting Loss:0.2513 + XiCon Loss:3.0141 x Lambda(0.01)), Vali MSE Loss: 0.3467 Test MSE Loss: 0.2924
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2824597
	speed: 0.0440s/iter; left time: 414.4690s
Epoch: 12 cost time: 4.805551052093506
Epoch: 12, Steps: 107 Train Loss: 0.2810 (Forecasting Loss:0.2509 + XiCon Loss:3.0143 x Lambda(0.01)), Vali MSE Loss: 0.3462 Test MSE Loss: 0.2924
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2830606
	speed: 0.0431s/iter; left time: 401.5352s
Epoch: 13 cost time: 4.666828393936157
Epoch: 13, Steps: 107 Train Loss: 0.2813 (Forecasting Loss:0.2511 + XiCon Loss:3.0142 x Lambda(0.01)), Vali MSE Loss: 0.3459 Test MSE Loss: 0.2936
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2862170
	speed: 0.0439s/iter; left time: 404.0595s
Epoch: 14 cost time: 4.703259706497192
Epoch: 14, Steps: 107 Train Loss: 0.2811 (Forecasting Loss:0.2510 + XiCon Loss:3.0127 x Lambda(0.01)), Vali MSE Loss: 0.3467 Test MSE Loss: 0.2934
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.25260812044143677, mae:0.4051869213581085, mape:0.558535099029541, mspe:8.695837020874023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4523
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5495407
	speed: 0.0454s/iter; left time: 480.7952s
Epoch: 1 cost time: 4.81462836265564
Epoch: 1, Steps: 107 Train Loss: 0.6456 (Forecasting Loss:0.6141 + XiCon Loss:3.1554 x Lambda(0.01)), Vali MSE Loss: 0.5219 Test MSE Loss: 0.3888
Validation loss decreased (inf --> 0.521855).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3994122
	speed: 0.0459s/iter; left time: 481.6536s
Epoch: 2 cost time: 5.000304460525513
Epoch: 2, Steps: 107 Train Loss: 0.4584 (Forecasting Loss:0.4271 + XiCon Loss:3.1299 x Lambda(0.01)), Vali MSE Loss: 0.4130 Test MSE Loss: 0.2919
Validation loss decreased (0.521855 --> 0.413013).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3111931
	speed: 0.0453s/iter; left time: 470.0323s
Epoch: 3 cost time: 4.788561820983887
Epoch: 3, Steps: 107 Train Loss: 0.3372 (Forecasting Loss:0.3063 + XiCon Loss:3.0946 x Lambda(0.01)), Vali MSE Loss: 0.3524 Test MSE Loss: 0.2511
Validation loss decreased (0.413013 --> 0.352390).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3023733
	speed: 0.0455s/iter; left time: 467.6277s
Epoch: 4 cost time: 4.936706304550171
Epoch: 4, Steps: 107 Train Loss: 0.3050 (Forecasting Loss:0.2741 + XiCon Loss:3.0899 x Lambda(0.01)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.2780
Validation loss decreased (0.352390 --> 0.333374).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2858958
	speed: 0.0450s/iter; left time: 457.9592s
Epoch: 5 cost time: 4.846113443374634
Epoch: 5, Steps: 107 Train Loss: 0.2951 (Forecasting Loss:0.2642 + XiCon Loss:3.0865 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2752
Validation loss decreased (0.333374 --> 0.328961).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3010061
	speed: 0.0445s/iter; left time: 447.6272s
Epoch: 6 cost time: 4.882229328155518
Epoch: 6, Steps: 107 Train Loss: 0.2911 (Forecasting Loss:0.2603 + XiCon Loss:3.0848 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2872
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2869352
	speed: 0.0466s/iter; left time: 464.5170s
Epoch: 7 cost time: 5.05241322517395
Epoch: 7, Steps: 107 Train Loss: 0.2890 (Forecasting Loss:0.2582 + XiCon Loss:3.0845 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.2769
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2791656
	speed: 0.0455s/iter; left time: 448.0147s
Epoch: 8 cost time: 4.9280383586883545
Epoch: 8, Steps: 107 Train Loss: 0.2882 (Forecasting Loss:0.2573 + XiCon Loss:3.0843 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2892
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2855965
	speed: 0.0440s/iter; left time: 428.3493s
Epoch: 9 cost time: 4.785962343215942
Epoch: 9, Steps: 107 Train Loss: 0.2874 (Forecasting Loss:0.2566 + XiCon Loss:3.0823 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2886
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2879921
	speed: 0.0466s/iter; left time: 449.3973s
Epoch: 10 cost time: 5.014034986495972
Epoch: 10, Steps: 107 Train Loss: 0.2873 (Forecasting Loss:0.2565 + XiCon Loss:3.0820 x Lambda(0.01)), Vali MSE Loss: 0.3283 Test MSE Loss: 0.2866
Validation loss decreased (0.328961 --> 0.328296).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2780805
	speed: 0.0461s/iter; left time: 439.3684s
Epoch: 11 cost time: 5.0001866817474365
Epoch: 11, Steps: 107 Train Loss: 0.2871 (Forecasting Loss:0.2563 + XiCon Loss:3.0819 x Lambda(0.01)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.2876
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2863999
	speed: 0.0443s/iter; left time: 417.2409s
Epoch: 12 cost time: 4.815819501876831
Epoch: 12, Steps: 107 Train Loss: 0.2871 (Forecasting Loss:0.2563 + XiCon Loss:3.0806 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2886
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2866650
	speed: 0.0441s/iter; left time: 410.4631s
Epoch: 13 cost time: 4.7486841678619385
Epoch: 13, Steps: 107 Train Loss: 0.2871 (Forecasting Loss:0.2563 + XiCon Loss:3.0839 x Lambda(0.01)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.2881
Validation loss decreased (0.328296 --> 0.327925).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2816609
	speed: 0.0461s/iter; left time: 424.4968s
Epoch: 14 cost time: 5.000138282775879
Epoch: 14, Steps: 107 Train Loss: 0.2870 (Forecasting Loss:0.2561 + XiCon Loss:3.0817 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2879
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2786562
	speed: 0.0439s/iter; left time: 399.6233s
Epoch: 15 cost time: 4.65670371055603
Epoch: 15, Steps: 107 Train Loss: 0.2869 (Forecasting Loss:0.2561 + XiCon Loss:3.0813 x Lambda(0.01)), Vali MSE Loss: 0.3287 Test MSE Loss: 0.2878
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2796696
	speed: 0.0444s/iter; left time: 399.7148s
Epoch: 16 cost time: 4.846233606338501
Epoch: 16, Steps: 107 Train Loss: 0.2870 (Forecasting Loss:0.2562 + XiCon Loss:3.0817 x Lambda(0.01)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.2878
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2812174
	speed: 0.0450s/iter; left time: 399.8414s
Epoch: 17 cost time: 4.920874357223511
Epoch: 17, Steps: 107 Train Loss: 0.2868 (Forecasting Loss:0.2559 + XiCon Loss:3.0833 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2878
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2872242
	speed: 0.0467s/iter; left time: 410.1677s
Epoch: 18 cost time: 5.062129735946655
Epoch: 18, Steps: 107 Train Loss: 0.2870 (Forecasting Loss:0.2562 + XiCon Loss:3.0807 x Lambda(0.01)), Vali MSE Loss: 0.3287 Test MSE Loss: 0.2878
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2880383
	speed: 0.0454s/iter; left time: 393.8721s
Epoch: 19 cost time: 4.9015302658081055
Epoch: 19, Steps: 107 Train Loss: 0.2868 (Forecasting Loss:0.2560 + XiCon Loss:3.0797 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2878
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.2924265
	speed: 0.0440s/iter; left time: 376.7529s
Epoch: 20 cost time: 4.718338489532471
Epoch: 20, Steps: 107 Train Loss: 0.2866 (Forecasting Loss:0.2558 + XiCon Loss:3.0803 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2878
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.2784288
	speed: 0.0447s/iter; left time: 378.3371s
Epoch: 21 cost time: 4.940553665161133
Epoch: 21, Steps: 107 Train Loss: 0.2867 (Forecasting Loss:0.2559 + XiCon Loss:3.0800 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2878
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.2701687
	speed: 0.0454s/iter; left time: 379.5110s
Epoch: 22 cost time: 4.895320653915405
Epoch: 22, Steps: 107 Train Loss: 0.2868 (Forecasting Loss:0.2560 + XiCon Loss:3.0827 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2878
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.2794607
	speed: 0.0449s/iter; left time: 370.0780s
Epoch: 23 cost time: 4.884413003921509
Epoch: 23, Steps: 107 Train Loss: 0.2870 (Forecasting Loss:0.2562 + XiCon Loss:3.0793 x Lambda(0.01)), Vali MSE Loss: 0.3283 Test MSE Loss: 0.2878
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.2070074826478958, mae:0.3691878020763397, mape:0.5656614303588867, mspe:10.955427169799805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4847
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5831764
	speed: 0.0462s/iter; left time: 489.7061s
Epoch: 1 cost time: 4.937966585159302
Epoch: 1, Steps: 107 Train Loss: 0.6373 (Forecasting Loss:0.6060 + XiCon Loss:3.1304 x Lambda(0.01)), Vali MSE Loss: 0.5106 Test MSE Loss: 0.3621
Validation loss decreased (inf --> 0.510619).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3843352
	speed: 0.0440s/iter; left time: 461.8417s
Epoch: 2 cost time: 4.802804231643677
Epoch: 2, Steps: 107 Train Loss: 0.4724 (Forecasting Loss:0.4414 + XiCon Loss:3.1017 x Lambda(0.01)), Vali MSE Loss: 0.4368 Test MSE Loss: 0.3021
Validation loss decreased (0.510619 --> 0.436790).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3098565
	speed: 0.0459s/iter; left time: 476.3450s
Epoch: 3 cost time: 4.980005502700806
Epoch: 3, Steps: 107 Train Loss: 0.3408 (Forecasting Loss:0.3099 + XiCon Loss:3.0838 x Lambda(0.01)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2646
Validation loss decreased (0.436790 --> 0.375167).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3039643
	speed: 0.0450s/iter; left time: 462.5223s
Epoch: 4 cost time: 4.9263832569122314
Epoch: 4, Steps: 107 Train Loss: 0.3100 (Forecasting Loss:0.2792 + XiCon Loss:3.0834 x Lambda(0.01)), Vali MSE Loss: 0.3807 Test MSE Loss: 0.2793
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3050014
	speed: 0.0465s/iter; left time: 473.4690s
Epoch: 5 cost time: 5.038433074951172
Epoch: 5, Steps: 107 Train Loss: 0.3003 (Forecasting Loss:0.2695 + XiCon Loss:3.0833 x Lambda(0.01)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.2793
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2959799
	speed: 0.0454s/iter; left time: 456.5844s
Epoch: 6 cost time: 4.896203279495239
Epoch: 6, Steps: 107 Train Loss: 0.2958 (Forecasting Loss:0.2650 + XiCon Loss:3.0795 x Lambda(0.01)), Vali MSE Loss: 0.3790 Test MSE Loss: 0.2499
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2769326
	speed: 0.0444s/iter; left time: 442.4924s
Epoch: 7 cost time: 4.796570777893066
Epoch: 7, Steps: 107 Train Loss: 0.2922 (Forecasting Loss:0.2614 + XiCon Loss:3.0795 x Lambda(0.01)), Vali MSE Loss: 0.3813 Test MSE Loss: 0.2493
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2868880
	speed: 0.0446s/iter; left time: 439.8144s
Epoch: 8 cost time: 4.741928815841675
Epoch: 8, Steps: 107 Train Loss: 0.2910 (Forecasting Loss:0.2602 + XiCon Loss:3.0780 x Lambda(0.01)), Vali MSE Loss: 0.3816 Test MSE Loss: 0.2488
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2873937
	speed: 0.0442s/iter; left time: 430.5013s
Epoch: 9 cost time: 4.827664852142334
Epoch: 9, Steps: 107 Train Loss: 0.2904 (Forecasting Loss:0.2596 + XiCon Loss:3.0764 x Lambda(0.01)), Vali MSE Loss: 0.3819 Test MSE Loss: 0.2505
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2967691
	speed: 0.0445s/iter; left time: 428.7719s
Epoch: 10 cost time: 4.836313962936401
Epoch: 10, Steps: 107 Train Loss: 0.2903 (Forecasting Loss:0.2595 + XiCon Loss:3.0778 x Lambda(0.01)), Vali MSE Loss: 0.3829 Test MSE Loss: 0.2504
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.3088879
	speed: 0.0450s/iter; left time: 428.8700s
Epoch: 11 cost time: 4.842729806900024
Epoch: 11, Steps: 107 Train Loss: 0.2900 (Forecasting Loss:0.2592 + XiCon Loss:3.0792 x Lambda(0.01)), Vali MSE Loss: 0.3848 Test MSE Loss: 0.2499
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2938748
	speed: 0.0447s/iter; left time: 420.8022s
Epoch: 12 cost time: 4.822926044464111
Epoch: 12, Steps: 107 Train Loss: 0.2899 (Forecasting Loss:0.2592 + XiCon Loss:3.0763 x Lambda(0.01)), Vali MSE Loss: 0.3843 Test MSE Loss: 0.2498
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2844833
	speed: 0.0435s/iter; left time: 405.0369s
Epoch: 13 cost time: 4.705794095993042
Epoch: 13, Steps: 107 Train Loss: 0.2901 (Forecasting Loss:0.2593 + XiCon Loss:3.0775 x Lambda(0.01)), Vali MSE Loss: 0.3836 Test MSE Loss: 0.2502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1831403374671936, mae:0.34604084491729736, mape:0.6168602108955383, mspe:15.089006423950195 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4419
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5801979
	speed: 0.0441s/iter; left time: 467.1718s
Epoch: 1 cost time: 4.821886301040649
Epoch: 1, Steps: 107 Train Loss: 0.6542 (Forecasting Loss:0.6230 + XiCon Loss:3.1271 x Lambda(0.01)), Vali MSE Loss: 0.5828 Test MSE Loss: 0.4430
Validation loss decreased (inf --> 0.582755).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3138858
	speed: 0.0545s/iter; left time: 572.2175s
Epoch: 2 cost time: 5.8811023235321045
Epoch: 2, Steps: 107 Train Loss: 0.3698 (Forecasting Loss:0.3388 + XiCon Loss:3.1033 x Lambda(0.01)), Vali MSE Loss: 0.4560 Test MSE Loss: 0.2552
Validation loss decreased (0.582755 --> 0.455984).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2880471
	speed: 0.0595s/iter; left time: 618.4318s
Epoch: 3 cost time: 6.343484401702881
Epoch: 3, Steps: 107 Train Loss: 0.2955 (Forecasting Loss:0.2649 + XiCon Loss:3.0670 x Lambda(0.01)), Vali MSE Loss: 0.3775 Test MSE Loss: 0.2488
Validation loss decreased (0.455984 --> 0.377476).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2857929
	speed: 0.0594s/iter; left time: 611.0681s
Epoch: 4 cost time: 6.48685884475708
Epoch: 4, Steps: 107 Train Loss: 0.2847 (Forecasting Loss:0.2542 + XiCon Loss:3.0461 x Lambda(0.01)), Vali MSE Loss: 0.3775 Test MSE Loss: 0.2426
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2854790
	speed: 0.0570s/iter; left time: 579.7211s
Epoch: 5 cost time: 6.210737943649292
Epoch: 5, Steps: 107 Train Loss: 0.2797 (Forecasting Loss:0.2493 + XiCon Loss:3.0349 x Lambda(0.01)), Vali MSE Loss: 0.3666 Test MSE Loss: 0.2530
Validation loss decreased (0.377476 --> 0.366558).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2697630
	speed: 0.0580s/iter; left time: 584.3279s
Epoch: 6 cost time: 6.2141032218933105
Epoch: 6, Steps: 107 Train Loss: 0.2769 (Forecasting Loss:0.2466 + XiCon Loss:3.0292 x Lambda(0.01)), Vali MSE Loss: 0.3643 Test MSE Loss: 0.2541
Validation loss decreased (0.366558 --> 0.364297).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2685920
	speed: 0.0586s/iter; left time: 583.5140s
Epoch: 7 cost time: 6.339977264404297
Epoch: 7, Steps: 107 Train Loss: 0.2756 (Forecasting Loss:0.2453 + XiCon Loss:3.0275 x Lambda(0.01)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.2482
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2636858
	speed: 0.0573s/iter; left time: 564.5341s
Epoch: 8 cost time: 6.198663949966431
Epoch: 8, Steps: 107 Train Loss: 0.2749 (Forecasting Loss:0.2447 + XiCon Loss:3.0222 x Lambda(0.01)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2536
Validation loss decreased (0.364297 --> 0.363676).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2726855
	speed: 0.0582s/iter; left time: 566.7557s
Epoch: 9 cost time: 6.247385501861572
Epoch: 9, Steps: 107 Train Loss: 0.2743 (Forecasting Loss:0.2441 + XiCon Loss:3.0242 x Lambda(0.01)), Vali MSE Loss: 0.3678 Test MSE Loss: 0.2511
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2660227
	speed: 0.0591s/iter; left time: 569.6085s
Epoch: 10 cost time: 6.311880826950073
Epoch: 10, Steps: 107 Train Loss: 0.2744 (Forecasting Loss:0.2442 + XiCon Loss:3.0219 x Lambda(0.01)), Vali MSE Loss: 0.3660 Test MSE Loss: 0.2510
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2840357
	speed: 0.0582s/iter; left time: 554.4595s
Epoch: 11 cost time: 6.268605947494507
Epoch: 11, Steps: 107 Train Loss: 0.2741 (Forecasting Loss:0.2438 + XiCon Loss:3.0232 x Lambda(0.01)), Vali MSE Loss: 0.3652 Test MSE Loss: 0.2534
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2765354
	speed: 0.0559s/iter; left time: 526.6681s
Epoch: 12 cost time: 6.01261830329895
Epoch: 12, Steps: 107 Train Loss: 0.2741 (Forecasting Loss:0.2439 + XiCon Loss:3.0206 x Lambda(0.01)), Vali MSE Loss: 0.3651 Test MSE Loss: 0.2521
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2797595
	speed: 0.0580s/iter; left time: 540.5769s
Epoch: 13 cost time: 6.22587251663208
Epoch: 13, Steps: 107 Train Loss: 0.2741 (Forecasting Loss:0.2439 + XiCon Loss:3.0220 x Lambda(0.01)), Vali MSE Loss: 0.3650 Test MSE Loss: 0.2523
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2857808
	speed: 0.0590s/iter; left time: 543.7900s
Epoch: 14 cost time: 6.362126588821411
Epoch: 14, Steps: 107 Train Loss: 0.2741 (Forecasting Loss:0.2439 + XiCon Loss:3.0251 x Lambda(0.01)), Vali MSE Loss: 0.3656 Test MSE Loss: 0.2522
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2831753
	speed: 0.0572s/iter; left time: 520.8926s
Epoch: 15 cost time: 6.218876838684082
Epoch: 15, Steps: 107 Train Loss: 0.2739 (Forecasting Loss:0.2437 + XiCon Loss:3.0230 x Lambda(0.01)), Vali MSE Loss: 0.3667 Test MSE Loss: 0.2521
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2585035
	speed: 0.0576s/iter; left time: 517.9848s
Epoch: 16 cost time: 6.201374053955078
Epoch: 16, Steps: 107 Train Loss: 0.2739 (Forecasting Loss:0.2437 + XiCon Loss:3.0223 x Lambda(0.01)), Vali MSE Loss: 0.3660 Test MSE Loss: 0.2521
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2751494
	speed: 0.0587s/iter; left time: 522.1215s
Epoch: 17 cost time: 6.331194877624512
Epoch: 17, Steps: 107 Train Loss: 0.2740 (Forecasting Loss:0.2438 + XiCon Loss:3.0228 x Lambda(0.01)), Vali MSE Loss: 0.3657 Test MSE Loss: 0.2521
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2711704
	speed: 0.0588s/iter; left time: 516.6003s
Epoch: 18 cost time: 6.379191160202026
Epoch: 18, Steps: 107 Train Loss: 0.2742 (Forecasting Loss:0.2440 + XiCon Loss:3.0230 x Lambda(0.01)), Vali MSE Loss: 0.3654 Test MSE Loss: 0.2521
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17006754875183105, mae:0.3370611071586609, mape:0.6477203965187073, mspe:18.024349212646484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1964+-0.04340, MAE:0.3584+-0.03670, MAPE:0.6047+-0.05028, MSPE:13.7897+-4.78217, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4333
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.146376848220825
Epoch: 1, Steps: 96 Train Loss: 1.0055 (Forecasting Loss:0.9738 + XiCon Loss:3.1663 x Lambda(0.01)), Vali MSE Loss: 0.6588 Test MSE Loss: 0.9128
Validation loss decreased (inf --> 0.658783).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.8714325428009033
Epoch: 2, Steps: 96 Train Loss: 0.7819 (Forecasting Loss:0.7503 + XiCon Loss:3.1598 x Lambda(0.01)), Vali MSE Loss: 0.6163 Test MSE Loss: 0.2827
Validation loss decreased (0.658783 --> 0.616314).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.860786199569702
Epoch: 3, Steps: 96 Train Loss: 0.5929 (Forecasting Loss:0.5612 + XiCon Loss:3.1690 x Lambda(0.01)), Vali MSE Loss: 0.5608 Test MSE Loss: 0.2558
Validation loss decreased (0.616314 --> 0.560773).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.677415609359741
Epoch: 4, Steps: 96 Train Loss: 0.5583 (Forecasting Loss:0.5266 + XiCon Loss:3.1639 x Lambda(0.01)), Vali MSE Loss: 0.5149 Test MSE Loss: 0.2542
Validation loss decreased (0.560773 --> 0.514861).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.893754482269287
Epoch: 5, Steps: 96 Train Loss: 0.5440 (Forecasting Loss:0.5124 + XiCon Loss:3.1631 x Lambda(0.01)), Vali MSE Loss: 0.5014 Test MSE Loss: 0.2528
Validation loss decreased (0.514861 --> 0.501421).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.803659200668335
Epoch: 6, Steps: 96 Train Loss: 0.5373 (Forecasting Loss:0.5057 + XiCon Loss:3.1635 x Lambda(0.01)), Vali MSE Loss: 0.4891 Test MSE Loss: 0.2563
Validation loss decreased (0.501421 --> 0.489060).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.949747323989868
Epoch: 7, Steps: 96 Train Loss: 0.5339 (Forecasting Loss:0.5023 + XiCon Loss:3.1612 x Lambda(0.01)), Vali MSE Loss: 0.4932 Test MSE Loss: 0.2529
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.972090482711792
Epoch: 8, Steps: 96 Train Loss: 0.5314 (Forecasting Loss:0.4998 + XiCon Loss:3.1609 x Lambda(0.01)), Vali MSE Loss: 0.4878 Test MSE Loss: 0.2544
Validation loss decreased (0.489060 --> 0.487820).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.185307025909424
Epoch: 9, Steps: 96 Train Loss: 0.5307 (Forecasting Loss:0.4991 + XiCon Loss:3.1603 x Lambda(0.01)), Vali MSE Loss: 0.4884 Test MSE Loss: 0.2540
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.9554216861724854
Epoch: 10, Steps: 96 Train Loss: 0.5309 (Forecasting Loss:0.4993 + XiCon Loss:3.1606 x Lambda(0.01)), Vali MSE Loss: 0.4883 Test MSE Loss: 0.2539
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 3.7356631755828857
Epoch: 11, Steps: 96 Train Loss: 0.5306 (Forecasting Loss:0.4990 + XiCon Loss:3.1614 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2540
Validation loss decreased (0.487820 --> 0.487649).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.705206871032715
Epoch: 12, Steps: 96 Train Loss: 0.5301 (Forecasting Loss:0.4985 + XiCon Loss:3.1607 x Lambda(0.01)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.2541
Validation loss decreased (0.487649 --> 0.487234).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.7541003227233887
Epoch: 13, Steps: 96 Train Loss: 0.5296 (Forecasting Loss:0.4980 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2541
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 3.7326040267944336
Epoch: 14, Steps: 96 Train Loss: 0.5295 (Forecasting Loss:0.4979 + XiCon Loss:3.1612 x Lambda(0.01)), Vali MSE Loss: 0.4870 Test MSE Loss: 0.2541
Validation loss decreased (0.487234 --> 0.487034).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 3.525609016418457
Epoch: 15, Steps: 96 Train Loss: 0.5296 (Forecasting Loss:0.4980 + XiCon Loss:3.1618 x Lambda(0.01)), Vali MSE Loss: 0.4868 Test MSE Loss: 0.2541
Validation loss decreased (0.487034 --> 0.486849).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 3.8549842834472656
Epoch: 16, Steps: 96 Train Loss: 0.5292 (Forecasting Loss:0.4976 + XiCon Loss:3.1613 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2541
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 3.704636335372925
Epoch: 17, Steps: 96 Train Loss: 0.5301 (Forecasting Loss:0.4985 + XiCon Loss:3.1606 x Lambda(0.01)), Vali MSE Loss: 0.4867 Test MSE Loss: 0.2541
Validation loss decreased (0.486849 --> 0.486672).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 3.9270434379577637
Epoch: 18, Steps: 96 Train Loss: 0.5290 (Forecasting Loss:0.4973 + XiCon Loss:3.1620 x Lambda(0.01)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.2541
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 3.8314049243927
Epoch: 19, Steps: 96 Train Loss: 0.5298 (Forecasting Loss:0.4982 + XiCon Loss:3.1603 x Lambda(0.01)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2541
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 3.978602886199951
Epoch: 20, Steps: 96 Train Loss: 0.5293 (Forecasting Loss:0.4977 + XiCon Loss:3.1600 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2541
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.046560287475586
Epoch: 21, Steps: 96 Train Loss: 0.5293 (Forecasting Loss:0.4977 + XiCon Loss:3.1608 x Lambda(0.01)), Vali MSE Loss: 0.4874 Test MSE Loss: 0.2541
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 3.901939630508423
Epoch: 22, Steps: 96 Train Loss: 0.5303 (Forecasting Loss:0.4987 + XiCon Loss:3.1616 x Lambda(0.01)), Vali MSE Loss: 0.4866 Test MSE Loss: 0.2541
Validation loss decreased (0.486672 --> 0.486637).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.062063694000244
Epoch: 23, Steps: 96 Train Loss: 0.5298 (Forecasting Loss:0.4982 + XiCon Loss:3.1619 x Lambda(0.01)), Vali MSE Loss: 0.4869 Test MSE Loss: 0.2541
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 3.8323845863342285
Epoch: 24, Steps: 96 Train Loss: 0.5304 (Forecasting Loss:0.4988 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2541
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 3.8951938152313232
Epoch: 25, Steps: 96 Train Loss: 0.5293 (Forecasting Loss:0.4977 + XiCon Loss:3.1619 x Lambda(0.01)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2541
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 3.833691120147705
Epoch: 26, Steps: 96 Train Loss: 0.5291 (Forecasting Loss:0.4975 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 0.4870 Test MSE Loss: 0.2541
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 3.7147889137268066
Epoch: 27, Steps: 96 Train Loss: 0.5287 (Forecasting Loss:0.4971 + XiCon Loss:3.1601 x Lambda(0.01)), Vali MSE Loss: 0.4876 Test MSE Loss: 0.2541
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 3.87021803855896
Epoch: 28, Steps: 96 Train Loss: 0.5303 (Forecasting Loss:0.4987 + XiCon Loss:3.1615 x Lambda(0.01)), Vali MSE Loss: 0.4869 Test MSE Loss: 0.2541
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 3.8811874389648438
Epoch: 29, Steps: 96 Train Loss: 0.5296 (Forecasting Loss:0.4980 + XiCon Loss:3.1603 x Lambda(0.01)), Vali MSE Loss: 0.4874 Test MSE Loss: 0.2541
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 3.884326219558716
Epoch: 30, Steps: 96 Train Loss: 0.5288 (Forecasting Loss:0.4971 + XiCon Loss:3.1614 x Lambda(0.01)), Vali MSE Loss: 0.4870 Test MSE Loss: 0.2541
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 3.787616491317749
Epoch: 31, Steps: 96 Train Loss: 0.5300 (Forecasting Loss:0.4984 + XiCon Loss:3.1605 x Lambda(0.01)), Vali MSE Loss: 0.4873 Test MSE Loss: 0.2541
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 3.719722270965576
Epoch: 32, Steps: 96 Train Loss: 0.5292 (Forecasting Loss:0.4976 + XiCon Loss:3.1618 x Lambda(0.01)), Vali MSE Loss: 0.4872 Test MSE Loss: 0.2541
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.175351083278656, mae:0.3328389823436737, mape:0.653592050075531, mspe:19.17681884765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5068
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 3.7364015579223633
Epoch: 1, Steps: 96 Train Loss: 1.0005 (Forecasting Loss:0.9688 + XiCon Loss:3.1697 x Lambda(0.01)), Vali MSE Loss: 0.6801 Test MSE Loss: 0.9331
Validation loss decreased (inf --> 0.680106).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.77190899848938
Epoch: 2, Steps: 96 Train Loss: 0.8379 (Forecasting Loss:0.8062 + XiCon Loss:3.1682 x Lambda(0.01)), Vali MSE Loss: 0.6282 Test MSE Loss: 0.5758
Validation loss decreased (0.680106 --> 0.628218).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.7135188579559326
Epoch: 3, Steps: 96 Train Loss: 0.6440 (Forecasting Loss:0.6124 + XiCon Loss:3.1609 x Lambda(0.01)), Vali MSE Loss: 0.4955 Test MSE Loss: 0.2723
Validation loss decreased (0.628218 --> 0.495460).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.923402786254883
Epoch: 4, Steps: 96 Train Loss: 0.5460 (Forecasting Loss:0.5144 + XiCon Loss:3.1585 x Lambda(0.01)), Vali MSE Loss: 0.4918 Test MSE Loss: 0.3157
Validation loss decreased (0.495460 --> 0.491754).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.867910146713257
Epoch: 5, Steps: 96 Train Loss: 0.5245 (Forecasting Loss:0.4930 + XiCon Loss:3.1528 x Lambda(0.01)), Vali MSE Loss: 0.4928 Test MSE Loss: 0.3222
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.691467523574829
Epoch: 6, Steps: 96 Train Loss: 0.5157 (Forecasting Loss:0.4842 + XiCon Loss:3.1527 x Lambda(0.01)), Vali MSE Loss: 0.4851 Test MSE Loss: 0.3377
Validation loss decreased (0.491754 --> 0.485086).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.8460853099823
Epoch: 7, Steps: 96 Train Loss: 0.5131 (Forecasting Loss:0.4816 + XiCon Loss:3.1475 x Lambda(0.01)), Vali MSE Loss: 0.4871 Test MSE Loss: 0.3307
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.8721811771392822
Epoch: 8, Steps: 96 Train Loss: 0.5096 (Forecasting Loss:0.4781 + XiCon Loss:3.1477 x Lambda(0.01)), Vali MSE Loss: 0.4843 Test MSE Loss: 0.3375
Validation loss decreased (0.485086 --> 0.484334).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.949949264526367
Epoch: 9, Steps: 96 Train Loss: 0.5078 (Forecasting Loss:0.4763 + XiCon Loss:3.1481 x Lambda(0.01)), Vali MSE Loss: 0.4844 Test MSE Loss: 0.3407
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.9655368328094482
Epoch: 10, Steps: 96 Train Loss: 0.5085 (Forecasting Loss:0.4770 + XiCon Loss:3.1483 x Lambda(0.01)), Vali MSE Loss: 0.4848 Test MSE Loss: 0.3336
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.013642311096191
Epoch: 11, Steps: 96 Train Loss: 0.5055 (Forecasting Loss:0.4740 + XiCon Loss:3.1488 x Lambda(0.01)), Vali MSE Loss: 0.4860 Test MSE Loss: 0.3357
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.8891162872314453
Epoch: 12, Steps: 96 Train Loss: 0.5090 (Forecasting Loss:0.4775 + XiCon Loss:3.1491 x Lambda(0.01)), Vali MSE Loss: 0.4844 Test MSE Loss: 0.3361
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.8028674125671387
Epoch: 13, Steps: 96 Train Loss: 0.5075 (Forecasting Loss:0.4760 + XiCon Loss:3.1480 x Lambda(0.01)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3366
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 3.7600855827331543
Epoch: 14, Steps: 96 Train Loss: 0.5070 (Forecasting Loss:0.4755 + XiCon Loss:3.1478 x Lambda(0.01)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3366
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 3.727713108062744
Epoch: 15, Steps: 96 Train Loss: 0.5077 (Forecasting Loss:0.4762 + XiCon Loss:3.1504 x Lambda(0.01)), Vali MSE Loss: 0.4851 Test MSE Loss: 0.3368
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.015471935272217
Epoch: 16, Steps: 96 Train Loss: 0.5070 (Forecasting Loss:0.4755 + XiCon Loss:3.1487 x Lambda(0.01)), Vali MSE Loss: 0.4852 Test MSE Loss: 0.3368
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 3.774237632751465
Epoch: 17, Steps: 96 Train Loss: 0.5079 (Forecasting Loss:0.4764 + XiCon Loss:3.1489 x Lambda(0.01)), Vali MSE Loss: 0.4845 Test MSE Loss: 0.3368
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 3.668940544128418
Epoch: 18, Steps: 96 Train Loss: 0.5080 (Forecasting Loss:0.4765 + XiCon Loss:3.1484 x Lambda(0.01)), Vali MSE Loss: 0.4849 Test MSE Loss: 0.3368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.26921460032463074, mae:0.40570467710494995, mape:0.7902379035949707, mspe:29.199487686157227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4373
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 3.9825594425201416
Epoch: 1, Steps: 96 Train Loss: 0.9484 (Forecasting Loss:0.9168 + XiCon Loss:3.1580 x Lambda(0.01)), Vali MSE Loss: 0.6296 Test MSE Loss: 0.8200
Validation loss decreased (inf --> 0.629586).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.139821290969849
Epoch: 2, Steps: 96 Train Loss: 0.8456 (Forecasting Loss:0.8141 + XiCon Loss:3.1582 x Lambda(0.01)), Vali MSE Loss: 0.6435 Test MSE Loss: 0.6148
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 3.9731884002685547
Epoch: 3, Steps: 96 Train Loss: 0.6990 (Forecasting Loss:0.6676 + XiCon Loss:3.1455 x Lambda(0.01)), Vali MSE Loss: 0.5569 Test MSE Loss: 0.5210
Validation loss decreased (0.629586 --> 0.556871).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.8719048500061035
Epoch: 4, Steps: 96 Train Loss: 0.4740 (Forecasting Loss:0.4427 + XiCon Loss:3.1238 x Lambda(0.01)), Vali MSE Loss: 0.4962 Test MSE Loss: 0.5462
Validation loss decreased (0.556871 --> 0.496218).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.31274151802063
Epoch: 5, Steps: 96 Train Loss: 0.3985 (Forecasting Loss:0.3674 + XiCon Loss:3.1102 x Lambda(0.01)), Vali MSE Loss: 0.4796 Test MSE Loss: 0.5781
Validation loss decreased (0.496218 --> 0.479640).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.29751992225647
Epoch: 6, Steps: 96 Train Loss: 0.3759 (Forecasting Loss:0.3448 + XiCon Loss:3.1092 x Lambda(0.01)), Vali MSE Loss: 0.4658 Test MSE Loss: 0.5894
Validation loss decreased (0.479640 --> 0.465831).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.364945888519287
Epoch: 7, Steps: 96 Train Loss: 0.3673 (Forecasting Loss:0.3362 + XiCon Loss:3.1088 x Lambda(0.01)), Vali MSE Loss: 0.4579 Test MSE Loss: 0.5582
Validation loss decreased (0.465831 --> 0.457866).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.450744867324829
Epoch: 8, Steps: 96 Train Loss: 0.3633 (Forecasting Loss:0.3322 + XiCon Loss:3.1068 x Lambda(0.01)), Vali MSE Loss: 0.4593 Test MSE Loss: 0.5846
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.224837779998779
Epoch: 9, Steps: 96 Train Loss: 0.3612 (Forecasting Loss:0.3301 + XiCon Loss:3.1072 x Lambda(0.01)), Vali MSE Loss: 0.4556 Test MSE Loss: 0.5847
Validation loss decreased (0.457866 --> 0.455616).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.37789249420166
Epoch: 10, Steps: 96 Train Loss: 0.3606 (Forecasting Loss:0.3295 + XiCon Loss:3.1067 x Lambda(0.01)), Vali MSE Loss: 0.4548 Test MSE Loss: 0.5789
Validation loss decreased (0.455616 --> 0.454825).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.232359886169434
Epoch: 11, Steps: 96 Train Loss: 0.3594 (Forecasting Loss:0.3284 + XiCon Loss:3.1057 x Lambda(0.01)), Vali MSE Loss: 0.4561 Test MSE Loss: 0.5784
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.29392409324646
Epoch: 12, Steps: 96 Train Loss: 0.3598 (Forecasting Loss:0.3287 + XiCon Loss:3.1071 x Lambda(0.01)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.5790
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.2570412158966064
Epoch: 13, Steps: 96 Train Loss: 0.3589 (Forecasting Loss:0.3279 + XiCon Loss:3.1057 x Lambda(0.01)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.5792
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.07578182220459
Epoch: 14, Steps: 96 Train Loss: 0.3595 (Forecasting Loss:0.3285 + XiCon Loss:3.1036 x Lambda(0.01)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.5792
Validation loss decreased (0.454825 --> 0.454734).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.252248048782349
Epoch: 15, Steps: 96 Train Loss: 0.3598 (Forecasting Loss:0.3288 + XiCon Loss:3.1048 x Lambda(0.01)), Vali MSE Loss: 0.4556 Test MSE Loss: 0.5793
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.217526435852051
Epoch: 16, Steps: 96 Train Loss: 0.3594 (Forecasting Loss:0.3283 + XiCon Loss:3.1070 x Lambda(0.01)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.5793
Validation loss decreased (0.454734 --> 0.454695).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.507762670516968
Epoch: 17, Steps: 96 Train Loss: 0.3592 (Forecasting Loss:0.3282 + XiCon Loss:3.1066 x Lambda(0.01)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.5792
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.376698732376099
Epoch: 18, Steps: 96 Train Loss: 0.3594 (Forecasting Loss:0.3283 + XiCon Loss:3.1054 x Lambda(0.01)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.5792
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.275931119918823
Epoch: 19, Steps: 96 Train Loss: 0.3594 (Forecasting Loss:0.3283 + XiCon Loss:3.1057 x Lambda(0.01)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.5792
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.4263129234313965
Epoch: 20, Steps: 96 Train Loss: 0.3598 (Forecasting Loss:0.3287 + XiCon Loss:3.1051 x Lambda(0.01)), Vali MSE Loss: 0.4539 Test MSE Loss: 0.5792
Validation loss decreased (0.454695 --> 0.453932).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.3613269329071045
Epoch: 21, Steps: 96 Train Loss: 0.3591 (Forecasting Loss:0.3280 + XiCon Loss:3.1081 x Lambda(0.01)), Vali MSE Loss: 0.4542 Test MSE Loss: 0.5792
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.187822103500366
Epoch: 22, Steps: 96 Train Loss: 0.3595 (Forecasting Loss:0.3285 + XiCon Loss:3.1065 x Lambda(0.01)), Vali MSE Loss: 0.4559 Test MSE Loss: 0.5792
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.471789360046387
Epoch: 23, Steps: 96 Train Loss: 0.3590 (Forecasting Loss:0.3280 + XiCon Loss:3.1055 x Lambda(0.01)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.5792
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.280883073806763
Epoch: 24, Steps: 96 Train Loss: 0.3597 (Forecasting Loss:0.3286 + XiCon Loss:3.1059 x Lambda(0.01)), Vali MSE Loss: 0.4542 Test MSE Loss: 0.5792
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.429077863693237
Epoch: 25, Steps: 96 Train Loss: 0.3596 (Forecasting Loss:0.3285 + XiCon Loss:3.1070 x Lambda(0.01)), Vali MSE Loss: 0.4550 Test MSE Loss: 0.5792
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.3751678466796875
Epoch: 26, Steps: 96 Train Loss: 0.3591 (Forecasting Loss:0.3280 + XiCon Loss:3.1065 x Lambda(0.01)), Vali MSE Loss: 0.4545 Test MSE Loss: 0.5792
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 4.270562410354614
Epoch: 27, Steps: 96 Train Loss: 0.3596 (Forecasting Loss:0.3285 + XiCon Loss:3.1054 x Lambda(0.01)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.5792
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 4.43485164642334
Epoch: 28, Steps: 96 Train Loss: 0.3592 (Forecasting Loss:0.3281 + XiCon Loss:3.1053 x Lambda(0.01)), Vali MSE Loss: 0.4535 Test MSE Loss: 0.5792
Validation loss decreased (0.453932 --> 0.453533).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 4.370657682418823
Epoch: 29, Steps: 96 Train Loss: 0.3592 (Forecasting Loss:0.3282 + XiCon Loss:3.1070 x Lambda(0.01)), Vali MSE Loss: 0.4538 Test MSE Loss: 0.5792
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.171128034591675
Epoch: 30, Steps: 96 Train Loss: 0.3589 (Forecasting Loss:0.3278 + XiCon Loss:3.1046 x Lambda(0.01)), Vali MSE Loss: 0.4552 Test MSE Loss: 0.5792
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 4.301029443740845
Epoch: 31, Steps: 96 Train Loss: 0.3593 (Forecasting Loss:0.3282 + XiCon Loss:3.1068 x Lambda(0.01)), Vali MSE Loss: 0.4547 Test MSE Loss: 0.5792
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 4.48326301574707
Epoch: 32, Steps: 96 Train Loss: 0.3594 (Forecasting Loss:0.3283 + XiCon Loss:3.1056 x Lambda(0.01)), Vali MSE Loss: 0.4542 Test MSE Loss: 0.5792
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 4.244562387466431
Epoch: 33, Steps: 96 Train Loss: 0.3592 (Forecasting Loss:0.3282 + XiCon Loss:3.1067 x Lambda(0.01)), Vali MSE Loss: 0.4546 Test MSE Loss: 0.5792
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 4.318687438964844
Epoch: 34, Steps: 96 Train Loss: 0.3598 (Forecasting Loss:0.3287 + XiCon Loss:3.1078 x Lambda(0.01)), Vali MSE Loss: 0.4539 Test MSE Loss: 0.5792
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 4.294518947601318
Epoch: 35, Steps: 96 Train Loss: 0.3595 (Forecasting Loss:0.3285 + XiCon Loss:3.1056 x Lambda(0.01)), Vali MSE Loss: 0.4548 Test MSE Loss: 0.5792
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 4.133489608764648
Epoch: 36, Steps: 96 Train Loss: 0.3590 (Forecasting Loss:0.3279 + XiCon Loss:3.1050 x Lambda(0.01)), Vali MSE Loss: 0.4549 Test MSE Loss: 0.5792
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 4.191607236862183
Epoch: 37, Steps: 96 Train Loss: 0.3592 (Forecasting Loss:0.3282 + XiCon Loss:3.1068 x Lambda(0.01)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.5792
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 4.18366551399231
Epoch: 38, Steps: 96 Train Loss: 0.3591 (Forecasting Loss:0.3280 + XiCon Loss:3.1070 x Lambda(0.01)), Vali MSE Loss: 0.4551 Test MSE Loss: 0.5792
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.5484858751296997, mae:0.609986424446106, mape:0.6602498888969421, mspe:4.017434597015381 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3926
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.009583950042725
Epoch: 1, Steps: 96 Train Loss: 0.9550 (Forecasting Loss:0.9236 + XiCon Loss:3.1440 x Lambda(0.01)), Vali MSE Loss: 0.6486 Test MSE Loss: 0.8009
Validation loss decreased (inf --> 0.648616).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.9799561500549316
Epoch: 2, Steps: 96 Train Loss: 0.8275 (Forecasting Loss:0.7960 + XiCon Loss:3.1501 x Lambda(0.01)), Vali MSE Loss: 0.6276 Test MSE Loss: 0.4465
Validation loss decreased (0.648616 --> 0.627560).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.0027854442596436
Epoch: 3, Steps: 96 Train Loss: 0.5978 (Forecasting Loss:0.5661 + XiCon Loss:3.1684 x Lambda(0.01)), Vali MSE Loss: 0.5642 Test MSE Loss: 0.2787
Validation loss decreased (0.627560 --> 0.564210).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.7686004638671875
Epoch: 4, Steps: 96 Train Loss: 0.5348 (Forecasting Loss:0.5032 + XiCon Loss:3.1619 x Lambda(0.01)), Vali MSE Loss: 0.5457 Test MSE Loss: 0.2857
Validation loss decreased (0.564210 --> 0.545675).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.869196891784668
Epoch: 5, Steps: 96 Train Loss: 0.5152 (Forecasting Loss:0.4836 + XiCon Loss:3.1600 x Lambda(0.01)), Vali MSE Loss: 0.5599 Test MSE Loss: 0.2831
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.756864309310913
Epoch: 6, Steps: 96 Train Loss: 0.5078 (Forecasting Loss:0.4762 + XiCon Loss:3.1591 x Lambda(0.01)), Vali MSE Loss: 0.5616 Test MSE Loss: 0.2828
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.7928619384765625
Epoch: 7, Steps: 96 Train Loss: 0.5025 (Forecasting Loss:0.4709 + XiCon Loss:3.1604 x Lambda(0.01)), Vali MSE Loss: 0.5484 Test MSE Loss: 0.2879
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 3.9700779914855957
Epoch: 8, Steps: 96 Train Loss: 0.5004 (Forecasting Loss:0.4688 + XiCon Loss:3.1584 x Lambda(0.01)), Vali MSE Loss: 0.5497 Test MSE Loss: 0.2879
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.9333770275115967
Epoch: 9, Steps: 96 Train Loss: 0.4997 (Forecasting Loss:0.4681 + XiCon Loss:3.1581 x Lambda(0.01)), Vali MSE Loss: 0.5459 Test MSE Loss: 0.2900
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.954125165939331
Epoch: 10, Steps: 96 Train Loss: 0.5001 (Forecasting Loss:0.4685 + XiCon Loss:3.1593 x Lambda(0.01)), Vali MSE Loss: 0.5450 Test MSE Loss: 0.2906
Validation loss decreased (0.545675 --> 0.545025).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.094837665557861
Epoch: 11, Steps: 96 Train Loss: 0.5009 (Forecasting Loss:0.4693 + XiCon Loss:3.1577 x Lambda(0.01)), Vali MSE Loss: 0.5462 Test MSE Loss: 0.2900
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.957904100418091
Epoch: 12, Steps: 96 Train Loss: 0.4996 (Forecasting Loss:0.4680 + XiCon Loss:3.1577 x Lambda(0.01)), Vali MSE Loss: 0.5466 Test MSE Loss: 0.2898
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.8389668464660645
Epoch: 13, Steps: 96 Train Loss: 0.4991 (Forecasting Loss:0.4675 + XiCon Loss:3.1584 x Lambda(0.01)), Vali MSE Loss: 0.5456 Test MSE Loss: 0.2897
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 3.800072431564331
Epoch: 14, Steps: 96 Train Loss: 0.4979 (Forecasting Loss:0.4663 + XiCon Loss:3.1594 x Lambda(0.01)), Vali MSE Loss: 0.5457 Test MSE Loss: 0.2898
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 3.8197860717773438
Epoch: 15, Steps: 96 Train Loss: 0.5017 (Forecasting Loss:0.4702 + XiCon Loss:3.1586 x Lambda(0.01)), Vali MSE Loss: 0.5473 Test MSE Loss: 0.2898
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 3.7407751083374023
Epoch: 16, Steps: 96 Train Loss: 0.4988 (Forecasting Loss:0.4672 + XiCon Loss:3.1597 x Lambda(0.01)), Vali MSE Loss: 0.5475 Test MSE Loss: 0.2898
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 3.966846227645874
Epoch: 17, Steps: 96 Train Loss: 0.4992 (Forecasting Loss:0.4676 + XiCon Loss:3.1600 x Lambda(0.01)), Vali MSE Loss: 0.5464 Test MSE Loss: 0.2898
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 3.830564260482788
Epoch: 18, Steps: 96 Train Loss: 0.4994 (Forecasting Loss:0.4678 + XiCon Loss:3.1593 x Lambda(0.01)), Vali MSE Loss: 0.5473 Test MSE Loss: 0.2898
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 3.9804484844207764
Epoch: 19, Steps: 96 Train Loss: 0.4986 (Forecasting Loss:0.4670 + XiCon Loss:3.1592 x Lambda(0.01)), Vali MSE Loss: 0.5464 Test MSE Loss: 0.2898
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 3.6846048831939697
Epoch: 20, Steps: 96 Train Loss: 0.4988 (Forecasting Loss:0.4672 + XiCon Loss:3.1597 x Lambda(0.01)), Vali MSE Loss: 0.5474 Test MSE Loss: 0.2898
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.214335635304451, mae:0.36683231592178345, mape:0.6890561580657959, mspe:21.40003204345703 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4095
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 3.8607373237609863
Epoch: 1, Steps: 96 Train Loss: 0.9335 (Forecasting Loss:0.9021 + XiCon Loss:3.1386 x Lambda(0.01)), Vali MSE Loss: 0.6036 Test MSE Loss: 0.7177
Validation loss decreased (inf --> 0.603594).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 3.902155876159668
Epoch: 2, Steps: 96 Train Loss: 0.7685 (Forecasting Loss:0.7370 + XiCon Loss:3.1524 x Lambda(0.01)), Vali MSE Loss: 0.5588 Test MSE Loss: 0.3195
Validation loss decreased (0.603594 --> 0.558802).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.010272026062012
Epoch: 3, Steps: 96 Train Loss: 0.5381 (Forecasting Loss:0.5064 + XiCon Loss:3.1657 x Lambda(0.01)), Vali MSE Loss: 0.5347 Test MSE Loss: 0.3424
Validation loss decreased (0.558802 --> 0.534671).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.9376368522644043
Epoch: 4, Steps: 96 Train Loss: 0.4914 (Forecasting Loss:0.4600 + XiCon Loss:3.1466 x Lambda(0.01)), Vali MSE Loss: 0.5255 Test MSE Loss: 0.3145
Validation loss decreased (0.534671 --> 0.525476).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 3.8048174381256104
Epoch: 5, Steps: 96 Train Loss: 0.4758 (Forecasting Loss:0.4444 + XiCon Loss:3.1359 x Lambda(0.01)), Vali MSE Loss: 0.5210 Test MSE Loss: 0.3167
Validation loss decreased (0.525476 --> 0.521033).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.9766743183135986
Epoch: 6, Steps: 96 Train Loss: 0.4706 (Forecasting Loss:0.4393 + XiCon Loss:3.1333 x Lambda(0.01)), Vali MSE Loss: 0.5119 Test MSE Loss: 0.3068
Validation loss decreased (0.521033 --> 0.511862).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.883793830871582
Epoch: 7, Steps: 96 Train Loss: 0.4676 (Forecasting Loss:0.4363 + XiCon Loss:3.1326 x Lambda(0.01)), Vali MSE Loss: 0.5155 Test MSE Loss: 0.3001
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.067906379699707
Epoch: 8, Steps: 96 Train Loss: 0.4655 (Forecasting Loss:0.4342 + XiCon Loss:3.1349 x Lambda(0.01)), Vali MSE Loss: 0.5121 Test MSE Loss: 0.3030
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 3.8595921993255615
Epoch: 9, Steps: 96 Train Loss: 0.4665 (Forecasting Loss:0.4352 + XiCon Loss:3.1317 x Lambda(0.01)), Vali MSE Loss: 0.5129 Test MSE Loss: 0.3031
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 3.9619829654693604
Epoch: 10, Steps: 96 Train Loss: 0.4666 (Forecasting Loss:0.4353 + XiCon Loss:3.1319 x Lambda(0.01)), Vali MSE Loss: 0.5138 Test MSE Loss: 0.3008
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 3.8647522926330566
Epoch: 11, Steps: 96 Train Loss: 0.4636 (Forecasting Loss:0.4323 + XiCon Loss:3.1314 x Lambda(0.01)), Vali MSE Loss: 0.5128 Test MSE Loss: 0.3021
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.7523725032806396
Epoch: 12, Steps: 96 Train Loss: 0.4649 (Forecasting Loss:0.4336 + XiCon Loss:3.1336 x Lambda(0.01)), Vali MSE Loss: 0.5127 Test MSE Loss: 0.3019
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.729814052581787
Epoch: 13, Steps: 96 Train Loss: 0.4655 (Forecasting Loss:0.4342 + XiCon Loss:3.1323 x Lambda(0.01)), Vali MSE Loss: 0.5122 Test MSE Loss: 0.3021
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 3.9939017295837402
Epoch: 14, Steps: 96 Train Loss: 0.4640 (Forecasting Loss:0.4327 + XiCon Loss:3.1330 x Lambda(0.01)), Vali MSE Loss: 0.5127 Test MSE Loss: 0.3020
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.107433319091797
Epoch: 15, Steps: 96 Train Loss: 0.4631 (Forecasting Loss:0.4318 + XiCon Loss:3.1314 x Lambda(0.01)), Vali MSE Loss: 0.5125 Test MSE Loss: 0.3020
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 3.919428586959839
Epoch: 16, Steps: 96 Train Loss: 0.4650 (Forecasting Loss:0.4337 + XiCon Loss:3.1334 x Lambda(0.01)), Vali MSE Loss: 0.5131 Test MSE Loss: 0.3020
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.23317168653011322, mae:0.38038384914398193, mape:0.721819281578064, mspe:23.96976089477539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2881+-0.18555, MAE:0.4191+-0.13643, MAPE:0.7030+-0.06921, MSPE:19.5527+-11.73798, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.1911
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2164923
	speed: 0.0574s/iter; left time: 1514.7311s
	iters: 200, epoch: 1 | loss: 0.2430843
	speed: 0.0504s/iter; left time: 1324.4538s
Epoch: 1 cost time: 13.93489122390747
Epoch: 1, Steps: 265 Train Loss: 0.2413 (Forecasting Loss:0.2078 + XiCon Loss:3.3523 x Lambda(0.01)), Vali MSE Loss: 0.1496 Test MSE Loss: 0.1003
Validation loss decreased (inf --> 0.149630).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2152309
	speed: 0.0526s/iter; left time: 1373.5181s
	iters: 200, epoch: 2 | loss: 0.1976346
	speed: 0.0492s/iter; left time: 1281.0900s
Epoch: 2 cost time: 13.534048318862915
Epoch: 2, Steps: 265 Train Loss: 0.2159 (Forecasting Loss:0.1830 + XiCon Loss:3.2892 x Lambda(0.01)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1137
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1885221
	speed: 0.0540s/iter; left time: 1396.8033s
	iters: 200, epoch: 3 | loss: 0.1605689
	speed: 0.0522s/iter; left time: 1345.2269s
Epoch: 3 cost time: 13.926239013671875
Epoch: 3, Steps: 265 Train Loss: 0.1757 (Forecasting Loss:0.1423 + XiCon Loss:3.3363 x Lambda(0.01)), Vali MSE Loss: 0.1574 Test MSE Loss: 0.1202
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1594730
	speed: 0.0535s/iter; left time: 1370.7210s
	iters: 200, epoch: 4 | loss: 0.1622100
	speed: 0.0513s/iter; left time: 1307.4184s
Epoch: 4 cost time: 13.872442722320557
Epoch: 4, Steps: 265 Train Loss: 0.1516 (Forecasting Loss:0.1179 + XiCon Loss:3.3712 x Lambda(0.01)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1217
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1398995
	speed: 0.0543s/iter; left time: 1377.2329s
	iters: 200, epoch: 5 | loss: 0.1375686
	speed: 0.0514s/iter; left time: 1296.4838s
Epoch: 5 cost time: 14.128861427307129
Epoch: 5, Steps: 265 Train Loss: 0.1415 (Forecasting Loss:0.1076 + XiCon Loss:3.3925 x Lambda(0.01)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1259
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1278830
	speed: 0.0537s/iter; left time: 1347.3274s
	iters: 200, epoch: 6 | loss: 0.1392175
	speed: 0.0521s/iter; left time: 1301.6055s
Epoch: 6 cost time: 13.730266332626343
Epoch: 6, Steps: 265 Train Loss: 0.1371 (Forecasting Loss:0.1031 + XiCon Loss:3.3997 x Lambda(0.01)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1263
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1360237
	speed: 0.0534s/iter; left time: 1325.7436s
	iters: 200, epoch: 7 | loss: 0.1369350
	speed: 0.0515s/iter; left time: 1271.8499s
Epoch: 7 cost time: 14.038413047790527
Epoch: 7, Steps: 265 Train Loss: 0.1351 (Forecasting Loss:0.1010 + XiCon Loss:3.4080 x Lambda(0.01)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1270
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1331978
	speed: 0.0543s/iter; left time: 1332.4990s
	iters: 200, epoch: 8 | loss: 0.1354890
	speed: 0.0506s/iter; left time: 1237.2615s
Epoch: 8 cost time: 13.888482570648193
Epoch: 8, Steps: 265 Train Loss: 0.1339 (Forecasting Loss:0.0998 + XiCon Loss:3.4099 x Lambda(0.01)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1275
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1362049
	speed: 0.0541s/iter; left time: 1314.5239s
	iters: 200, epoch: 9 | loss: 0.1332898
	speed: 0.0533s/iter; left time: 1287.8272s
Epoch: 9 cost time: 13.97415804862976
Epoch: 9, Steps: 265 Train Loss: 0.1335 (Forecasting Loss:0.0994 + XiCon Loss:3.4144 x Lambda(0.01)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1262
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1366811
	speed: 0.0536s/iter; left time: 1288.2109s
	iters: 200, epoch: 10 | loss: 0.1290747
	speed: 0.0515s/iter; left time: 1230.9014s
Epoch: 10 cost time: 14.005302429199219
Epoch: 10, Steps: 265 Train Loss: 0.1332 (Forecasting Loss:0.0990 + XiCon Loss:3.4150 x Lambda(0.01)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1275
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1353655
	speed: 0.0556s/iter; left time: 1321.7056s
	iters: 200, epoch: 11 | loss: 0.1294282
	speed: 0.0509s/iter; left time: 1203.1482s
Epoch: 11 cost time: 13.933403253555298
Epoch: 11, Steps: 265 Train Loss: 0.1331 (Forecasting Loss:0.0990 + XiCon Loss:3.4117 x Lambda(0.01)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04259415715932846, mae:0.15793824195861816, mape:0.1266399323940277, mspe:0.03006143867969513 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.8930
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3152651
	speed: 0.0522s/iter; left time: 1377.4860s
	iters: 200, epoch: 1 | loss: 0.2121787
	speed: 0.0522s/iter; left time: 1372.6101s
Epoch: 1 cost time: 13.786835432052612
Epoch: 1, Steps: 265 Train Loss: 0.2405 (Forecasting Loss:0.2071 + XiCon Loss:3.3458 x Lambda(0.01)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.0964
Validation loss decreased (inf --> 0.147867).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2321728
	speed: 0.0543s/iter; left time: 1419.0487s
	iters: 200, epoch: 2 | loss: 0.1991634
	speed: 0.0529s/iter; left time: 1377.9394s
Epoch: 2 cost time: 14.369058609008789
Epoch: 2, Steps: 265 Train Loss: 0.2229 (Forecasting Loss:0.1897 + XiCon Loss:3.3209 x Lambda(0.01)), Vali MSE Loss: 0.1575 Test MSE Loss: 0.1113
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1885737
	speed: 0.0560s/iter; left time: 1448.4929s
	iters: 200, epoch: 3 | loss: 0.1774950
	speed: 0.0543s/iter; left time: 1399.2032s
Epoch: 3 cost time: 14.589442014694214
Epoch: 3, Steps: 265 Train Loss: 0.1826 (Forecasting Loss:0.1498 + XiCon Loss:3.2835 x Lambda(0.01)), Vali MSE Loss: 0.1607 Test MSE Loss: 0.1229
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1575431
	speed: 0.0564s/iter; left time: 1443.8455s
	iters: 200, epoch: 4 | loss: 0.1413697
	speed: 0.0552s/iter; left time: 1408.9766s
Epoch: 4 cost time: 14.665582656860352
Epoch: 4, Steps: 265 Train Loss: 0.1524 (Forecasting Loss:0.1198 + XiCon Loss:3.2545 x Lambda(0.01)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1362
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1391003
	speed: 0.0554s/iter; left time: 1404.6855s
	iters: 200, epoch: 5 | loss: 0.1459792
	speed: 0.0549s/iter; left time: 1385.6743s
Epoch: 5 cost time: 14.653299570083618
Epoch: 5, Steps: 265 Train Loss: 0.1404 (Forecasting Loss:0.1080 + XiCon Loss:3.2368 x Lambda(0.01)), Vali MSE Loss: 0.1765 Test MSE Loss: 0.1413
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1400692
	speed: 0.0561s/iter; left time: 1407.4454s
	iters: 200, epoch: 6 | loss: 0.1418920
	speed: 0.0536s/iter; left time: 1338.4966s
Epoch: 6 cost time: 14.472612857818604
Epoch: 6, Steps: 265 Train Loss: 0.1359 (Forecasting Loss:0.1037 + XiCon Loss:3.2275 x Lambda(0.01)), Vali MSE Loss: 0.1773 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1357314
	speed: 0.0581s/iter; left time: 1441.0250s
	iters: 200, epoch: 7 | loss: 0.1278447
	speed: 0.0529s/iter; left time: 1308.3540s
Epoch: 7 cost time: 14.672950983047485
Epoch: 7, Steps: 265 Train Loss: 0.1339 (Forecasting Loss:0.1017 + XiCon Loss:3.2221 x Lambda(0.01)), Vali MSE Loss: 0.1790 Test MSE Loss: 0.1437
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1317436
	speed: 0.0555s/iter; left time: 1362.9851s
	iters: 200, epoch: 8 | loss: 0.1339478
	speed: 0.0529s/iter; left time: 1292.9735s
Epoch: 8 cost time: 14.307348012924194
Epoch: 8, Steps: 265 Train Loss: 0.1331 (Forecasting Loss:0.1009 + XiCon Loss:3.2191 x Lambda(0.01)), Vali MSE Loss: 0.1792 Test MSE Loss: 0.1455
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1387487
	speed: 0.0556s/iter; left time: 1350.1496s
	iters: 200, epoch: 9 | loss: 0.1372595
	speed: 0.0550s/iter; left time: 1330.7768s
Epoch: 9 cost time: 14.599225044250488
Epoch: 9, Steps: 265 Train Loss: 0.1325 (Forecasting Loss:0.1004 + XiCon Loss:3.2180 x Lambda(0.01)), Vali MSE Loss: 0.1798 Test MSE Loss: 0.1457
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1283041
	speed: 0.0566s/iter; left time: 1358.8730s
	iters: 200, epoch: 10 | loss: 0.1321456
	speed: 0.0539s/iter; left time: 1289.8090s
Epoch: 10 cost time: 14.778856754302979
Epoch: 10, Steps: 265 Train Loss: 0.1323 (Forecasting Loss:0.1002 + XiCon Loss:3.2164 x Lambda(0.01)), Vali MSE Loss: 0.1794 Test MSE Loss: 0.1449
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1263501
	speed: 0.0569s/iter; left time: 1352.4571s
	iters: 200, epoch: 11 | loss: 0.1389027
	speed: 0.0516s/iter; left time: 1220.5926s
Epoch: 11 cost time: 14.481999397277832
Epoch: 11, Steps: 265 Train Loss: 0.1322 (Forecasting Loss:0.1000 + XiCon Loss:3.2173 x Lambda(0.01)), Vali MSE Loss: 0.1796 Test MSE Loss: 0.1451
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0403432659804821, mae:0.15243130922317505, mape:0.12094969302415848, mspe:0.026999710127711296 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.6736
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2171147
	speed: 0.0535s/iter; left time: 1412.0097s
	iters: 200, epoch: 1 | loss: 0.1994451
	speed: 0.0517s/iter; left time: 1360.8644s
Epoch: 1 cost time: 13.80158805847168
Epoch: 1, Steps: 265 Train Loss: 0.2397 (Forecasting Loss:0.2063 + XiCon Loss:3.3453 x Lambda(0.01)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0965
Validation loss decreased (inf --> 0.144010).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2123430
	speed: 0.0540s/iter; left time: 1410.7076s
	iters: 200, epoch: 2 | loss: 0.2076408
	speed: 0.0525s/iter; left time: 1366.4509s
Epoch: 2 cost time: 14.34204363822937
Epoch: 2, Steps: 265 Train Loss: 0.2172 (Forecasting Loss:0.1844 + XiCon Loss:3.2766 x Lambda(0.01)), Vali MSE Loss: 0.1557 Test MSE Loss: 0.1102
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1868631
	speed: 0.0560s/iter; left time: 1449.7366s
	iters: 200, epoch: 3 | loss: 0.1743137
	speed: 0.0554s/iter; left time: 1428.2356s
Epoch: 3 cost time: 14.711881160736084
Epoch: 3, Steps: 265 Train Loss: 0.1773 (Forecasting Loss:0.1452 + XiCon Loss:3.2093 x Lambda(0.01)), Vali MSE Loss: 0.1578 Test MSE Loss: 0.1230
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1584488
	speed: 0.0559s/iter; left time: 1430.1164s
	iters: 200, epoch: 4 | loss: 0.1659662
	speed: 0.0510s/iter; left time: 1300.9837s
Epoch: 4 cost time: 14.144916534423828
Epoch: 4, Steps: 265 Train Loss: 0.1524 (Forecasting Loss:0.1202 + XiCon Loss:3.2257 x Lambda(0.01)), Vali MSE Loss: 0.1612 Test MSE Loss: 0.1257
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1435972
	speed: 0.0555s/iter; left time: 1406.2289s
	iters: 200, epoch: 5 | loss: 0.1388243
	speed: 0.0521s/iter; left time: 1314.6045s
Epoch: 5 cost time: 14.160637378692627
Epoch: 5, Steps: 265 Train Loss: 0.1411 (Forecasting Loss:0.1087 + XiCon Loss:3.2490 x Lambda(0.01)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1342
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1452236
	speed: 0.0546s/iter; left time: 1368.4979s
	iters: 200, epoch: 6 | loss: 0.1446969
	speed: 0.0528s/iter; left time: 1317.6301s
Epoch: 6 cost time: 14.169432163238525
Epoch: 6, Steps: 265 Train Loss: 0.1364 (Forecasting Loss:0.1038 + XiCon Loss:3.2619 x Lambda(0.01)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1321
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1388647
	speed: 0.0544s/iter; left time: 1350.7815s
	iters: 200, epoch: 7 | loss: 0.1284051
	speed: 0.0543s/iter; left time: 1341.3584s
Epoch: 7 cost time: 14.260565757751465
Epoch: 7, Steps: 265 Train Loss: 0.1341 (Forecasting Loss:0.1014 + XiCon Loss:3.2687 x Lambda(0.01)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1337
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1323903
	speed: 0.0547s/iter; left time: 1342.0347s
	iters: 200, epoch: 8 | loss: 0.1329010
	speed: 0.0519s/iter; left time: 1267.5672s
Epoch: 8 cost time: 14.104640007019043
Epoch: 8, Steps: 265 Train Loss: 0.1331 (Forecasting Loss:0.1004 + XiCon Loss:3.2693 x Lambda(0.01)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1326
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1285634
	speed: 0.0569s/iter; left time: 1382.6070s
	iters: 200, epoch: 9 | loss: 0.1303726
	speed: 0.0524s/iter; left time: 1266.1987s
Epoch: 9 cost time: 14.300315380096436
Epoch: 9, Steps: 265 Train Loss: 0.1326 (Forecasting Loss:0.0999 + XiCon Loss:3.2703 x Lambda(0.01)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1331
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1272937
	speed: 0.0566s/iter; left time: 1358.2415s
	iters: 200, epoch: 10 | loss: 0.1304575
	speed: 0.0535s/iter; left time: 1280.1018s
Epoch: 10 cost time: 14.492760181427002
Epoch: 10, Steps: 265 Train Loss: 0.1323 (Forecasting Loss:0.0996 + XiCon Loss:3.2715 x Lambda(0.01)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1322
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1320204
	speed: 0.0565s/iter; left time: 1342.6193s
	iters: 200, epoch: 11 | loss: 0.1262771
	speed: 0.0541s/iter; left time: 1279.8149s
Epoch: 11 cost time: 14.549251079559326
Epoch: 11, Steps: 265 Train Loss: 0.1321 (Forecasting Loss:0.0994 + XiCon Loss:3.2713 x Lambda(0.01)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1327
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.040195390582084656, mae:0.15284612774848938, mape:0.12183917313814163, mspe:0.027481116354465485 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.9904
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2012291
	speed: 0.0527s/iter; left time: 1391.2006s
	iters: 200, epoch: 1 | loss: 0.2350611
	speed: 0.0505s/iter; left time: 1328.7811s
Epoch: 1 cost time: 13.537396669387817
Epoch: 1, Steps: 265 Train Loss: 0.2424 (Forecasting Loss:0.2093 + XiCon Loss:3.3070 x Lambda(0.01)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.0968
Validation loss decreased (inf --> 0.145051).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2651384
	speed: 0.0551s/iter; left time: 1439.7911s
	iters: 200, epoch: 2 | loss: 0.2134153
	speed: 0.0536s/iter; left time: 1395.1980s
Epoch: 2 cost time: 14.350325584411621
Epoch: 2, Steps: 265 Train Loss: 0.2259 (Forecasting Loss:0.1935 + XiCon Loss:3.2397 x Lambda(0.01)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.1067
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1900378
	speed: 0.0557s/iter; left time: 1440.4565s
	iters: 200, epoch: 3 | loss: 0.1789130
	speed: 0.0540s/iter; left time: 1392.4934s
Epoch: 3 cost time: 14.532358884811401
Epoch: 3, Steps: 265 Train Loss: 0.1885 (Forecasting Loss:0.1573 + XiCon Loss:3.1239 x Lambda(0.01)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.1321
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1533367
	speed: 0.0571s/iter; left time: 1462.8927s
	iters: 200, epoch: 4 | loss: 0.1451739
	speed: 0.0542s/iter; left time: 1381.1951s
Epoch: 4 cost time: 14.593058109283447
Epoch: 4, Steps: 265 Train Loss: 0.1541 (Forecasting Loss:0.1227 + XiCon Loss:3.1369 x Lambda(0.01)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1429
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1452271
	speed: 0.0570s/iter; left time: 1444.9565s
	iters: 200, epoch: 5 | loss: 0.1429162
	speed: 0.0530s/iter; left time: 1338.8704s
Epoch: 5 cost time: 14.39480447769165
Epoch: 5, Steps: 265 Train Loss: 0.1417 (Forecasting Loss:0.1100 + XiCon Loss:3.1769 x Lambda(0.01)), Vali MSE Loss: 0.1750 Test MSE Loss: 0.1444
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1378103
	speed: 0.0568s/iter; left time: 1425.0164s
	iters: 200, epoch: 6 | loss: 0.1400230
	speed: 0.0520s/iter; left time: 1298.1287s
Epoch: 6 cost time: 14.270025968551636
Epoch: 6, Steps: 265 Train Loss: 0.1376 (Forecasting Loss:0.1055 + XiCon Loss:3.2033 x Lambda(0.01)), Vali MSE Loss: 0.1746 Test MSE Loss: 0.1482
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1375445
	speed: 0.0549s/iter; left time: 1362.9099s
	iters: 200, epoch: 7 | loss: 0.1351917
	speed: 0.0525s/iter; left time: 1297.0056s
Epoch: 7 cost time: 14.209443807601929
Epoch: 7, Steps: 265 Train Loss: 0.1355 (Forecasting Loss:0.1034 + XiCon Loss:3.2128 x Lambda(0.01)), Vali MSE Loss: 0.1777 Test MSE Loss: 0.1502
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1360851
	speed: 0.0561s/iter; left time: 1378.2370s
	iters: 200, epoch: 8 | loss: 0.1384879
	speed: 0.0524s/iter; left time: 1280.4016s
Epoch: 8 cost time: 14.331385850906372
Epoch: 8, Steps: 265 Train Loss: 0.1347 (Forecasting Loss:0.1025 + XiCon Loss:3.2206 x Lambda(0.01)), Vali MSE Loss: 0.1793 Test MSE Loss: 0.1508
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1280846
	speed: 0.0566s/iter; left time: 1373.3269s
	iters: 200, epoch: 9 | loss: 0.1414249
	speed: 0.0532s/iter; left time: 1286.7200s
Epoch: 9 cost time: 14.460196733474731
Epoch: 9, Steps: 265 Train Loss: 0.1342 (Forecasting Loss:0.1020 + XiCon Loss:3.2217 x Lambda(0.01)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1507
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1345835
	speed: 0.0562s/iter; left time: 1349.6625s
	iters: 200, epoch: 10 | loss: 0.1392078
	speed: 0.0529s/iter; left time: 1264.3400s
Epoch: 10 cost time: 14.291732549667358
Epoch: 10, Steps: 265 Train Loss: 0.1339 (Forecasting Loss:0.1017 + XiCon Loss:3.2216 x Lambda(0.01)), Vali MSE Loss: 0.1789 Test MSE Loss: 0.1511
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1316834
	speed: 0.0535s/iter; left time: 1270.1018s
	iters: 200, epoch: 11 | loss: 0.1250395
	speed: 0.0540s/iter; left time: 1277.7162s
Epoch: 11 cost time: 14.341142177581787
Epoch: 11, Steps: 265 Train Loss: 0.1338 (Forecasting Loss:0.1016 + XiCon Loss:3.2230 x Lambda(0.01)), Vali MSE Loss: 0.1788 Test MSE Loss: 0.1514
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.040697839111089706, mae:0.15283088386058807, mape:0.12186680734157562, mspe:0.02822752110660076 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.8360
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2460146
	speed: 0.0529s/iter; left time: 1395.4246s
	iters: 200, epoch: 1 | loss: 0.2600815
	speed: 0.0492s/iter; left time: 1294.7001s
Epoch: 1 cost time: 13.568464994430542
Epoch: 1, Steps: 265 Train Loss: 0.2380 (Forecasting Loss:0.2046 + XiCon Loss:3.3455 x Lambda(0.01)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.0976
Validation loss decreased (inf --> 0.146995).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2424526
	speed: 0.0539s/iter; left time: 1408.6921s
	iters: 200, epoch: 2 | loss: 0.2143406
	speed: 0.0508s/iter; left time: 1322.5829s
Epoch: 2 cost time: 13.67215347290039
Epoch: 2, Steps: 265 Train Loss: 0.2328 (Forecasting Loss:0.1994 + XiCon Loss:3.3407 x Lambda(0.01)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0973
Validation loss decreased (0.146995 --> 0.145935).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2204405
	speed: 0.0535s/iter; left time: 1383.4257s
	iters: 200, epoch: 3 | loss: 0.2345252
	speed: 0.0517s/iter; left time: 1332.0139s
Epoch: 3 cost time: 13.919508695602417
Epoch: 3, Steps: 265 Train Loss: 0.2256 (Forecasting Loss:0.1931 + XiCon Loss:3.2452 x Lambda(0.01)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0955
Validation loss decreased (0.145935 --> 0.143757).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2144462
	speed: 0.0547s/iter; left time: 1400.9514s
	iters: 200, epoch: 4 | loss: 0.2185466
	speed: 0.0516s/iter; left time: 1314.9219s
Epoch: 4 cost time: 14.013183116912842
Epoch: 4, Steps: 265 Train Loss: 0.2231 (Forecasting Loss:0.1912 + XiCon Loss:3.1926 x Lambda(0.01)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0950
Validation loss decreased (0.143757 --> 0.142426).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2444822
	speed: 0.0546s/iter; left time: 1384.2581s
	iters: 200, epoch: 5 | loss: 0.2470818
	speed: 0.0504s/iter; left time: 1272.1046s
Epoch: 5 cost time: 13.90401005744934
Epoch: 5, Steps: 265 Train Loss: 0.2221 (Forecasting Loss:0.1903 + XiCon Loss:3.1708 x Lambda(0.01)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
Validation loss decreased (0.142426 --> 0.141853).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2294735
	speed: 0.0562s/iter; left time: 1409.2109s
	iters: 200, epoch: 6 | loss: 0.2087086
	speed: 0.0473s/iter; left time: 1181.1329s
Epoch: 6 cost time: 13.38097357749939
Epoch: 6, Steps: 265 Train Loss: 0.2214 (Forecasting Loss:0.1898 + XiCon Loss:3.1584 x Lambda(0.01)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2393407
	speed: 0.0549s/iter; left time: 1362.7933s
	iters: 200, epoch: 7 | loss: 0.2246675
	speed: 0.0499s/iter; left time: 1233.7191s
Epoch: 7 cost time: 13.806368112564087
Epoch: 7, Steps: 265 Train Loss: 0.2210 (Forecasting Loss:0.1896 + XiCon Loss:3.1462 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141853 --> 0.141634).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2013530
	speed: 0.0552s/iter; left time: 1355.6483s
	iters: 200, epoch: 8 | loss: 0.2107622
	speed: 0.0495s/iter; left time: 1210.4839s
Epoch: 8 cost time: 13.790985822677612
Epoch: 8, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1423 x Lambda(0.01)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1948278
	speed: 0.0549s/iter; left time: 1332.1877s
	iters: 200, epoch: 9 | loss: 0.2393392
	speed: 0.0519s/iter; left time: 1253.9549s
Epoch: 9 cost time: 14.093201637268066
Epoch: 9, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1412 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141634 --> 0.141609).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2157796
	speed: 0.0533s/iter; left time: 1280.6697s
	iters: 200, epoch: 10 | loss: 0.2062605
	speed: 0.0528s/iter; left time: 1262.2334s
Epoch: 10 cost time: 14.04177451133728
Epoch: 10, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1407 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2026951
	speed: 0.0552s/iter; left time: 1311.8791s
	iters: 200, epoch: 11 | loss: 0.2160146
	speed: 0.0525s/iter; left time: 1241.7439s
Epoch: 11 cost time: 14.129917860031128
Epoch: 11, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1402 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2191677
	speed: 0.0538s/iter; left time: 1263.4847s
	iters: 200, epoch: 12 | loss: 0.2225038
	speed: 0.0521s/iter; left time: 1218.2886s
Epoch: 12 cost time: 13.890840291976929
Epoch: 12, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1411 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2200139
	speed: 0.0542s/iter; left time: 1258.7584s
	iters: 200, epoch: 13 | loss: 0.2309877
	speed: 0.0516s/iter; left time: 1193.0412s
Epoch: 13 cost time: 14.038772106170654
Epoch: 13, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1410 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141609 --> 0.141597).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.1992242
	speed: 0.0531s/iter; left time: 1219.1919s
	iters: 200, epoch: 14 | loss: 0.2080044
	speed: 0.0506s/iter; left time: 1157.0603s
Epoch: 14 cost time: 13.866443872451782
Epoch: 14, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1401 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2350064
	speed: 0.0563s/iter; left time: 1277.1560s
	iters: 200, epoch: 15 | loss: 0.2149475
	speed: 0.0502s/iter; left time: 1134.1461s
Epoch: 15 cost time: 14.053088188171387
Epoch: 15, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1409 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2294477
	speed: 0.0541s/iter; left time: 1212.7902s
	iters: 200, epoch: 16 | loss: 0.2104137
	speed: 0.0518s/iter; left time: 1157.0123s
Epoch: 16 cost time: 13.982136249542236
Epoch: 16, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1413 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2857043
	speed: 0.0545s/iter; left time: 1207.2334s
	iters: 200, epoch: 17 | loss: 0.2095601
	speed: 0.0526s/iter; left time: 1160.8352s
Epoch: 17 cost time: 14.06856918334961
Epoch: 17, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1385 x Lambda(0.01)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2038426
	speed: 0.0535s/iter; left time: 1172.2113s
	iters: 200, epoch: 18 | loss: 0.2212991
	speed: 0.0504s/iter; left time: 1098.2282s
Epoch: 18 cost time: 13.712891340255737
Epoch: 18, Steps: 265 Train Loss: 0.2205 (Forecasting Loss:0.1891 + XiCon Loss:3.1392 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2363925
	speed: 0.0549s/iter; left time: 1186.5931s
	iters: 200, epoch: 19 | loss: 0.2258835
	speed: 0.0526s/iter; left time: 1131.4838s
Epoch: 19 cost time: 14.27187442779541
Epoch: 19, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1893 + XiCon Loss:3.1400 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141597 --> 0.141590).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.2143412
	speed: 0.0567s/iter; left time: 1211.0640s
	iters: 200, epoch: 20 | loss: 0.2213658
	speed: 0.0523s/iter; left time: 1111.4389s
Epoch: 20 cost time: 14.32183837890625
Epoch: 20, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1417 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.2327778
	speed: 0.0541s/iter; left time: 1142.3534s
	iters: 200, epoch: 21 | loss: 0.2340145
	speed: 0.0521s/iter; left time: 1093.3456s
Epoch: 21 cost time: 14.000797510147095
Epoch: 21, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1893 + XiCon Loss:3.1390 x Lambda(0.01)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141590 --> 0.141470).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.2395837
	speed: 0.0545s/iter; left time: 1136.2313s
	iters: 200, epoch: 22 | loss: 0.2129375
	speed: 0.0520s/iter; left time: 1077.4370s
Epoch: 22 cost time: 13.889269351959229
Epoch: 22, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1389 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.2365630
	speed: 0.0541s/iter; left time: 1112.3302s
	iters: 200, epoch: 23 | loss: 0.2024435
	speed: 0.0516s/iter; left time: 1056.4454s
Epoch: 23 cost time: 13.914246320724487
Epoch: 23, Steps: 265 Train Loss: 0.2207 (Forecasting Loss:0.1892 + XiCon Loss:3.1409 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.2247747
	speed: 0.0550s/iter; left time: 1116.8404s
	iters: 200, epoch: 24 | loss: 0.2412384
	speed: 0.0503s/iter; left time: 1016.6856s
Epoch: 24 cost time: 14.13395619392395
Epoch: 24, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1403 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.2227965
	speed: 0.0548s/iter; left time: 1098.3579s
	iters: 200, epoch: 25 | loss: 0.2180133
	speed: 0.0514s/iter; left time: 1025.6053s
Epoch: 25 cost time: 14.060783863067627
Epoch: 25, Steps: 265 Train Loss: 0.2205 (Forecasting Loss:0.1891 + XiCon Loss:3.1403 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.2318690
	speed: 0.0539s/iter; left time: 1065.3141s
	iters: 200, epoch: 26 | loss: 0.2059556
	speed: 0.0523s/iter; left time: 1028.1392s
Epoch: 26 cost time: 14.075947046279907
Epoch: 26, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1891 + XiCon Loss:3.1408 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.2531499
	speed: 0.0548s/iter; left time: 1069.6381s
	iters: 200, epoch: 27 | loss: 0.2042646
	speed: 0.0511s/iter; left time: 991.3009s
Epoch: 27 cost time: 13.958019733428955
Epoch: 27, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1411 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.2109517
	speed: 0.0547s/iter; left time: 1052.3354s
	iters: 200, epoch: 28 | loss: 0.1960164
	speed: 0.0510s/iter; left time: 977.2198s
Epoch: 28 cost time: 14.180734157562256
Epoch: 28, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1892 + XiCon Loss:3.1409 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.2332291
	speed: 0.0532s/iter; left time: 1010.0162s
	iters: 200, epoch: 29 | loss: 0.2152200
	speed: 0.0530s/iter; left time: 1001.3673s
Epoch: 29 cost time: 13.940548419952393
Epoch: 29, Steps: 265 Train Loss: 0.2205 (Forecasting Loss:0.1891 + XiCon Loss:3.1402 x Lambda(0.01)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.1988386
	speed: 0.0534s/iter; left time: 999.0448s
	iters: 200, epoch: 30 | loss: 0.2140789
	speed: 0.0504s/iter; left time: 937.4782s
Epoch: 30 cost time: 13.80470061302185
Epoch: 30, Steps: 265 Train Loss: 0.2205 (Forecasting Loss:0.1891 + XiCon Loss:3.1398 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.2335626
	speed: 0.0548s/iter; left time: 1011.2825s
	iters: 200, epoch: 31 | loss: 0.2433090
	speed: 0.0518s/iter; left time: 949.7204s
Epoch: 31 cost time: 13.985270500183105
Epoch: 31, Steps: 265 Train Loss: 0.2205 (Forecasting Loss:0.1891 + XiCon Loss:3.1390 x Lambda(0.01)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039332833141088486, mae:0.14944347739219666, mape:0.1185971274971962, mspe:0.026300782337784767 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0406+-0.00150, MAE:0.1531+-0.00379, MAPE:0.1220+-0.00363, MSPE:0.0278+-0.00179, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.5185
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3459423
	speed: 0.1026s/iter; left time: 2617.1099s
	iters: 200, epoch: 1 | loss: 0.3113701
	speed: 0.0959s/iter; left time: 2436.0684s
Epoch: 1 cost time: 25.480154514312744
Epoch: 1, Steps: 256 Train Loss: 0.3314 (Forecasting Loss:0.2981 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1593
Validation loss decreased (inf --> 0.209139).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2903230
	speed: 0.1280s/iter; left time: 3231.7563s
	iters: 200, epoch: 2 | loss: 0.2609741
	speed: 0.1286s/iter; left time: 3234.3268s
Epoch: 2 cost time: 33.455811977386475
Epoch: 2, Steps: 256 Train Loss: 0.2793 (Forecasting Loss:0.2467 + XiCon Loss:3.2600 x Lambda(0.01)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1835
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2353593
	speed: 0.1373s/iter; left time: 3431.4661s
	iters: 200, epoch: 3 | loss: 0.2299148
	speed: 0.1379s/iter; left time: 3432.3339s
Epoch: 3 cost time: 35.124701738357544
Epoch: 3, Steps: 256 Train Loss: 0.2276 (Forecasting Loss:0.1958 + XiCon Loss:3.1798 x Lambda(0.01)), Vali MSE Loss: 0.2344 Test MSE Loss: 0.2012
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2158191
	speed: 0.1381s/iter; left time: 3416.1174s
	iters: 200, epoch: 4 | loss: 0.2017549
	speed: 0.1353s/iter; left time: 3332.9865s
Epoch: 4 cost time: 35.157763719558716
Epoch: 4, Steps: 256 Train Loss: 0.2061 (Forecasting Loss:0.1746 + XiCon Loss:3.1464 x Lambda(0.01)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.2009
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1914748
	speed: 0.1375s/iter; left time: 3366.1072s
	iters: 200, epoch: 5 | loss: 0.1897389
	speed: 0.1362s/iter; left time: 3320.1253s
Epoch: 5 cost time: 35.059529542922974
Epoch: 5, Steps: 256 Train Loss: 0.1944 (Forecasting Loss:0.1631 + XiCon Loss:3.1315 x Lambda(0.01)), Vali MSE Loss: 0.2381 Test MSE Loss: 0.1985
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1978590
	speed: 0.1359s/iter; left time: 3291.0201s
	iters: 200, epoch: 6 | loss: 0.1863596
	speed: 0.1336s/iter; left time: 3222.2651s
Epoch: 6 cost time: 34.489073038101196
Epoch: 6, Steps: 256 Train Loss: 0.1885 (Forecasting Loss:0.1572 + XiCon Loss:3.1281 x Lambda(0.01)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.2030
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1897216
	speed: 0.1329s/iter; left time: 3185.2493s
	iters: 200, epoch: 7 | loss: 0.1849189
	speed: 0.1383s/iter; left time: 3299.9760s
Epoch: 7 cost time: 34.83236837387085
Epoch: 7, Steps: 256 Train Loss: 0.1854 (Forecasting Loss:0.1541 + XiCon Loss:3.1266 x Lambda(0.01)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.2052
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1898347
	speed: 0.1371s/iter; left time: 3251.4729s
	iters: 200, epoch: 8 | loss: 0.1868478
	speed: 0.1368s/iter; left time: 3228.8325s
Epoch: 8 cost time: 34.935067892074585
Epoch: 8, Steps: 256 Train Loss: 0.1840 (Forecasting Loss:0.1527 + XiCon Loss:3.1256 x Lambda(0.01)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.2044
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1887562
	speed: 0.1354s/iter; left time: 3174.8506s
	iters: 200, epoch: 9 | loss: 0.1749210
	speed: 0.1341s/iter; left time: 3130.5606s
Epoch: 9 cost time: 34.413538217544556
Epoch: 9, Steps: 256 Train Loss: 0.1833 (Forecasting Loss:0.1520 + XiCon Loss:3.1237 x Lambda(0.01)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.2056
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1794244
	speed: 0.1357s/iter; left time: 3147.7151s
	iters: 200, epoch: 10 | loss: 0.1863329
	speed: 0.1348s/iter; left time: 3114.5826s
Epoch: 10 cost time: 34.589142084121704
Epoch: 10, Steps: 256 Train Loss: 0.1828 (Forecasting Loss:0.1515 + XiCon Loss:3.1242 x Lambda(0.01)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.2046
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1851178
	speed: 0.1335s/iter; left time: 3062.8920s
	iters: 200, epoch: 11 | loss: 0.1793428
	speed: 0.1328s/iter; left time: 3033.7328s
Epoch: 11 cost time: 34.251396894454956
Epoch: 11, Steps: 256 Train Loss: 0.1826 (Forecasting Loss:0.1514 + XiCon Loss:3.1243 x Lambda(0.01)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.2050
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08754757046699524, mae:0.23110181093215942, mape:0.17006470263004303, mspe:0.04572523012757301 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.6676
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3398229
	speed: 0.1013s/iter; left time: 2583.2969s
	iters: 200, epoch: 1 | loss: 0.3063340
	speed: 0.0972s/iter; left time: 2468.9280s
Epoch: 1 cost time: 25.301257371902466
Epoch: 1, Steps: 256 Train Loss: 0.3225 (Forecasting Loss:0.2889 + XiCon Loss:3.3545 x Lambda(0.01)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1548
Validation loss decreased (inf --> 0.204329).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3163093
	speed: 0.0991s/iter; left time: 2501.1782s
	iters: 200, epoch: 2 | loss: 0.2662058
	speed: 0.0990s/iter; left time: 2489.3550s
Epoch: 2 cost time: 25.583369255065918
Epoch: 2, Steps: 256 Train Loss: 0.2964 (Forecasting Loss:0.2637 + XiCon Loss:3.2658 x Lambda(0.01)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1689
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2274195
	speed: 0.1023s/iter; left time: 2556.2714s
	iters: 200, epoch: 3 | loss: 0.2201267
	speed: 0.1002s/iter; left time: 2494.6908s
Epoch: 3 cost time: 26.172951459884644
Epoch: 3, Steps: 256 Train Loss: 0.2325 (Forecasting Loss:0.1999 + XiCon Loss:3.2605 x Lambda(0.01)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1888
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2091212
	speed: 0.1049s/iter; left time: 2594.3471s
	iters: 200, epoch: 4 | loss: 0.1985701
	speed: 0.1031s/iter; left time: 2539.0196s
Epoch: 4 cost time: 26.95845365524292
Epoch: 4, Steps: 256 Train Loss: 0.2089 (Forecasting Loss:0.1759 + XiCon Loss:3.2959 x Lambda(0.01)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.1820
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2006696
	speed: 0.1044s/iter; left time: 2555.5601s
	iters: 200, epoch: 5 | loss: 0.1844008
	speed: 0.1036s/iter; left time: 2526.3789s
Epoch: 5 cost time: 26.720729112625122
Epoch: 5, Steps: 256 Train Loss: 0.1966 (Forecasting Loss:0.1634 + XiCon Loss:3.3232 x Lambda(0.01)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.1900
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1873668
	speed: 0.1066s/iter; left time: 2582.4386s
	iters: 200, epoch: 6 | loss: 0.1870186
	speed: 0.1050s/iter; left time: 2531.7850s
Epoch: 6 cost time: 27.20596671104431
Epoch: 6, Steps: 256 Train Loss: 0.1901 (Forecasting Loss:0.1568 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.2238 Test MSE Loss: 0.1934
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1903931
	speed: 0.1089s/iter; left time: 2609.9085s
	iters: 200, epoch: 7 | loss: 0.1822192
	speed: 0.1075s/iter; left time: 2564.7393s
Epoch: 7 cost time: 27.51964545249939
Epoch: 7, Steps: 256 Train Loss: 0.1870 (Forecasting Loss:0.1536 + XiCon Loss:3.3377 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1924
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1823494
	speed: 0.1086s/iter; left time: 2575.5735s
	iters: 200, epoch: 8 | loss: 0.1795751
	speed: 0.1049s/iter; left time: 2477.6713s
Epoch: 8 cost time: 27.314846992492676
Epoch: 8, Steps: 256 Train Loss: 0.1855 (Forecasting Loss:0.1521 + XiCon Loss:3.3427 x Lambda(0.01)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.1913
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1857824
	speed: 0.1070s/iter; left time: 2508.8225s
	iters: 200, epoch: 9 | loss: 0.1853210
	speed: 0.1070s/iter; left time: 2499.1473s
Epoch: 9 cost time: 27.396039247512817
Epoch: 9, Steps: 256 Train Loss: 0.1847 (Forecasting Loss:0.1513 + XiCon Loss:3.3460 x Lambda(0.01)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1919
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1880735
	speed: 0.1071s/iter; left time: 2484.3503s
	iters: 200, epoch: 10 | loss: 0.1834404
	speed: 0.1069s/iter; left time: 2468.5442s
Epoch: 10 cost time: 27.239761114120483
Epoch: 10, Steps: 256 Train Loss: 0.1843 (Forecasting Loss:0.1509 + XiCon Loss:3.3437 x Lambda(0.01)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1935
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1916046
	speed: 0.1092s/iter; left time: 2505.5924s
	iters: 200, epoch: 11 | loss: 0.1880342
	speed: 0.1055s/iter; left time: 2409.6376s
Epoch: 11 cost time: 27.50299859046936
Epoch: 11, Steps: 256 Train Loss: 0.1842 (Forecasting Loss:0.1507 + XiCon Loss:3.3467 x Lambda(0.01)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.1926
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0844721719622612, mae:0.22520823776721954, mape:0.16652809083461761, mspe:0.044974248856306076 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.4302
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3142152
	speed: 0.0978s/iter; left time: 2495.1565s
	iters: 200, epoch: 1 | loss: 0.3326552
	speed: 0.0941s/iter; left time: 2391.1092s
Epoch: 1 cost time: 24.806679487228394
Epoch: 1, Steps: 256 Train Loss: 0.3206 (Forecasting Loss:0.2872 + XiCon Loss:3.3356 x Lambda(0.01)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1526
Validation loss decreased (inf --> 0.198350).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2932319
	speed: 0.1309s/iter; left time: 3305.7500s
	iters: 200, epoch: 2 | loss: 0.2936361
	speed: 0.1368s/iter; left time: 3440.6676s
Epoch: 2 cost time: 34.660109519958496
Epoch: 2, Steps: 256 Train Loss: 0.3075 (Forecasting Loss:0.2742 + XiCon Loss:3.3280 x Lambda(0.01)), Vali MSE Loss: 0.2213 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2414178
	speed: 0.1380s/iter; left time: 3447.5593s
	iters: 200, epoch: 3 | loss: 0.2497635
	speed: 0.1389s/iter; left time: 3456.2117s
Epoch: 3 cost time: 35.72660708427429
Epoch: 3, Steps: 256 Train Loss: 0.2529 (Forecasting Loss:0.2201 + XiCon Loss:3.2798 x Lambda(0.01)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1787
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2344057
	speed: 0.1399s/iter; left time: 3460.5847s
	iters: 200, epoch: 4 | loss: 0.2422829
	speed: 0.1367s/iter; left time: 3367.5076s
Epoch: 4 cost time: 35.132155656814575
Epoch: 4, Steps: 256 Train Loss: 0.2372 (Forecasting Loss:0.2044 + XiCon Loss:3.2824 x Lambda(0.01)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1792
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2251512
	speed: 0.1360s/iter; left time: 3327.8948s
	iters: 200, epoch: 5 | loss: 0.2442815
	speed: 0.1326s/iter; left time: 3233.0400s
Epoch: 5 cost time: 34.364925384521484
Epoch: 5, Steps: 256 Train Loss: 0.2323 (Forecasting Loss:0.1994 + XiCon Loss:3.2920 x Lambda(0.01)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.1861
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2363052
	speed: 0.1359s/iter; left time: 3292.2861s
	iters: 200, epoch: 6 | loss: 0.2255861
	speed: 0.1346s/iter; left time: 3247.4544s
Epoch: 6 cost time: 34.654703855514526
Epoch: 6, Steps: 256 Train Loss: 0.2297 (Forecasting Loss:0.1967 + XiCon Loss:3.3015 x Lambda(0.01)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1879
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2316174
	speed: 0.1352s/iter; left time: 3239.0625s
	iters: 200, epoch: 7 | loss: 0.2329763
	speed: 0.1357s/iter; left time: 3239.2736s
Epoch: 7 cost time: 34.84064054489136
Epoch: 7, Steps: 256 Train Loss: 0.2283 (Forecasting Loss:0.1952 + XiCon Loss:3.3029 x Lambda(0.01)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1837
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2305747
	speed: 0.1383s/iter; left time: 3280.0975s
	iters: 200, epoch: 8 | loss: 0.2346310
	speed: 0.1370s/iter; left time: 3234.5818s
Epoch: 8 cost time: 35.25043869018555
Epoch: 8, Steps: 256 Train Loss: 0.2274 (Forecasting Loss:0.1944 + XiCon Loss:3.3069 x Lambda(0.01)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1860
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2320557
	speed: 0.1353s/iter; left time: 3174.2529s
	iters: 200, epoch: 9 | loss: 0.2224425
	speed: 0.1386s/iter; left time: 3235.6659s
Epoch: 9 cost time: 35.05707311630249
Epoch: 9, Steps: 256 Train Loss: 0.2271 (Forecasting Loss:0.1940 + XiCon Loss:3.3075 x Lambda(0.01)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1862
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2289704
	speed: 0.1382s/iter; left time: 3206.4300s
	iters: 200, epoch: 10 | loss: 0.2227226
	speed: 0.1368s/iter; left time: 3159.5214s
Epoch: 10 cost time: 35.429505586624146
Epoch: 10, Steps: 256 Train Loss: 0.2268 (Forecasting Loss:0.1937 + XiCon Loss:3.3075 x Lambda(0.01)), Vali MSE Loss: 0.2365 Test MSE Loss: 0.1864
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2246980
	speed: 0.1368s/iter; left time: 3137.9737s
	iters: 200, epoch: 11 | loss: 0.2250609
	speed: 0.1342s/iter; left time: 3064.4298s
Epoch: 11 cost time: 34.692301750183105
Epoch: 11, Steps: 256 Train Loss: 0.2266 (Forecasting Loss:0.1935 + XiCon Loss:3.3108 x Lambda(0.01)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.1867
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08258839696645737, mae:0.2226991355419159, mape:0.16562923789024353, mspe:0.04482172802090645 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.3745
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3152196
	speed: 0.0983s/iter; left time: 2506.2153s
	iters: 200, epoch: 1 | loss: 0.3097856
	speed: 0.0979s/iter; left time: 2487.4225s
Epoch: 1 cost time: 24.924084663391113
Epoch: 1, Steps: 256 Train Loss: 0.3272 (Forecasting Loss:0.2939 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1599
Validation loss decreased (inf --> 0.205946).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2723706
	speed: 0.1046s/iter; left time: 2639.3679s
	iters: 200, epoch: 2 | loss: 0.2517545
	speed: 0.1078s/iter; left time: 2709.4249s
Epoch: 2 cost time: 27.672841787338257
Epoch: 2, Steps: 256 Train Loss: 0.2750 (Forecasting Loss:0.2423 + XiCon Loss:3.2714 x Lambda(0.01)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.1810
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2230060
	speed: 0.1155s/iter; left time: 2885.5885s
	iters: 200, epoch: 3 | loss: 0.2055295
	speed: 0.1148s/iter; left time: 2857.4798s
Epoch: 3 cost time: 29.77270483970642
Epoch: 3, Steps: 256 Train Loss: 0.2200 (Forecasting Loss:0.1866 + XiCon Loss:3.3435 x Lambda(0.01)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.1947
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1948334
	speed: 0.1218s/iter; left time: 3012.5543s
	iters: 200, epoch: 4 | loss: 0.1892580
	speed: 0.1221s/iter; left time: 3008.0763s
Epoch: 4 cost time: 31.06643581390381
Epoch: 4, Steps: 256 Train Loss: 0.1970 (Forecasting Loss:0.1633 + XiCon Loss:3.3762 x Lambda(0.01)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1942
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1848117
	speed: 0.1203s/iter; left time: 2945.0884s
	iters: 200, epoch: 5 | loss: 0.1848334
	speed: 0.1232s/iter; left time: 3004.1639s
Epoch: 5 cost time: 31.018245697021484
Epoch: 5, Steps: 256 Train Loss: 0.1862 (Forecasting Loss:0.1523 + XiCon Loss:3.3881 x Lambda(0.01)), Vali MSE Loss: 0.2217 Test MSE Loss: 0.1997
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1912997
	speed: 0.1241s/iter; left time: 3006.2623s
	iters: 200, epoch: 6 | loss: 0.1792990
	speed: 0.1227s/iter; left time: 2960.3496s
Epoch: 6 cost time: 31.434020280838013
Epoch: 6, Steps: 256 Train Loss: 0.1812 (Forecasting Loss:0.1473 + XiCon Loss:3.3937 x Lambda(0.01)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.2025
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1734908
	speed: 0.1250s/iter; left time: 2996.0335s
	iters: 200, epoch: 7 | loss: 0.1807103
	speed: 0.1216s/iter; left time: 2903.1281s
Epoch: 7 cost time: 31.557719230651855
Epoch: 7, Steps: 256 Train Loss: 0.1789 (Forecasting Loss:0.1449 + XiCon Loss:3.3982 x Lambda(0.01)), Vali MSE Loss: 0.2240 Test MSE Loss: 0.2024
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1806100
	speed: 0.1231s/iter; left time: 2918.4429s
	iters: 200, epoch: 8 | loss: 0.1712265
	speed: 0.1183s/iter; left time: 2792.9349s
Epoch: 8 cost time: 31.26463222503662
Epoch: 8, Steps: 256 Train Loss: 0.1776 (Forecasting Loss:0.1435 + XiCon Loss:3.4025 x Lambda(0.01)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.2042
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1773618
	speed: 0.1218s/iter; left time: 2857.6082s
	iters: 200, epoch: 9 | loss: 0.1780585
	speed: 0.1219s/iter; left time: 2847.5527s
Epoch: 9 cost time: 31.140503883361816
Epoch: 9, Steps: 256 Train Loss: 0.1771 (Forecasting Loss:0.1431 + XiCon Loss:3.4030 x Lambda(0.01)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.2039
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1678364
	speed: 0.1256s/iter; left time: 2914.6261s
	iters: 200, epoch: 10 | loss: 0.1785265
	speed: 0.1202s/iter; left time: 2776.9346s
Epoch: 10 cost time: 31.624363660812378
Epoch: 10, Steps: 256 Train Loss: 0.1767 (Forecasting Loss:0.1427 + XiCon Loss:3.4002 x Lambda(0.01)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.2043
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1783684
	speed: 0.1235s/iter; left time: 2832.2150s
	iters: 200, epoch: 11 | loss: 0.1707461
	speed: 0.1226s/iter; left time: 2801.1465s
Epoch: 11 cost time: 31.34877061843872
Epoch: 11, Steps: 256 Train Loss: 0.1767 (Forecasting Loss:0.1427 + XiCon Loss:3.4040 x Lambda(0.01)), Vali MSE Loss: 0.2251 Test MSE Loss: 0.2040
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08769427239894867, mae:0.2321099191904068, mape:0.17227889597415924, mspe:0.04760314151644707 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.7394
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3196924
	speed: 0.1003s/iter; left time: 2558.7800s
	iters: 200, epoch: 1 | loss: 0.3120880
	speed: 0.0996s/iter; left time: 2529.8480s
Epoch: 1 cost time: 25.646830320358276
Epoch: 1, Steps: 256 Train Loss: 0.3210 (Forecasting Loss:0.2875 + XiCon Loss:3.3507 x Lambda(0.01)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1517
Validation loss decreased (inf --> 0.200647).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2942033
	speed: 0.1133s/iter; left time: 2859.6471s
	iters: 200, epoch: 2 | loss: 0.2730077
	speed: 0.1111s/iter; left time: 2793.2642s
Epoch: 2 cost time: 29.872912168502808
Epoch: 2, Steps: 256 Train Loss: 0.2973 (Forecasting Loss:0.2640 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.2277 Test MSE Loss: 0.1688
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2468060
	speed: 0.1339s/iter; left time: 3345.0744s
	iters: 200, epoch: 3 | loss: 0.2346954
	speed: 0.1334s/iter; left time: 3319.2309s
Epoch: 3 cost time: 34.046931982040405
Epoch: 3, Steps: 256 Train Loss: 0.2426 (Forecasting Loss:0.2090 + XiCon Loss:3.3549 x Lambda(0.01)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1810
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2171810
	speed: 0.1314s/iter; left time: 3248.8189s
	iters: 200, epoch: 4 | loss: 0.2219800
	speed: 0.1300s/iter; left time: 3201.1841s
Epoch: 4 cost time: 33.534528493881226
Epoch: 4, Steps: 256 Train Loss: 0.2253 (Forecasting Loss:0.1914 + XiCon Loss:3.3929 x Lambda(0.01)), Vali MSE Loss: 0.2332 Test MSE Loss: 0.1855
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2095448
	speed: 0.1318s/iter; left time: 3226.0607s
	iters: 200, epoch: 5 | loss: 0.2182759
	speed: 0.1314s/iter; left time: 3202.0340s
Epoch: 5 cost time: 33.56748723983765
Epoch: 5, Steps: 256 Train Loss: 0.2148 (Forecasting Loss:0.1806 + XiCon Loss:3.4215 x Lambda(0.01)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.1881
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2062413
	speed: 0.1366s/iter; left time: 3309.6817s
	iters: 200, epoch: 6 | loss: 0.2108560
	speed: 0.1287s/iter; left time: 3104.9687s
Epoch: 6 cost time: 33.8969624042511
Epoch: 6, Steps: 256 Train Loss: 0.2093 (Forecasting Loss:0.1750 + XiCon Loss:3.4344 x Lambda(0.01)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1919
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2000369
	speed: 0.1330s/iter; left time: 3186.5440s
	iters: 200, epoch: 7 | loss: 0.2081009
	speed: 0.1308s/iter; left time: 3122.6078s
Epoch: 7 cost time: 34.1160101890564
Epoch: 7, Steps: 256 Train Loss: 0.2062 (Forecasting Loss:0.1719 + XiCon Loss:3.4325 x Lambda(0.01)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1947
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2123990
	speed: 0.1338s/iter; left time: 3171.2568s
	iters: 200, epoch: 8 | loss: 0.2046407
	speed: 0.1301s/iter; left time: 3071.9139s
Epoch: 8 cost time: 33.78260898590088
Epoch: 8, Steps: 256 Train Loss: 0.2047 (Forecasting Loss:0.1702 + XiCon Loss:3.4488 x Lambda(0.01)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1966
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1987367
	speed: 0.1353s/iter; left time: 3173.6486s
	iters: 200, epoch: 9 | loss: 0.2054111
	speed: 0.1309s/iter; left time: 3056.3642s
Epoch: 9 cost time: 34.017900228500366
Epoch: 9, Steps: 256 Train Loss: 0.2037 (Forecasting Loss:0.1693 + XiCon Loss:3.4395 x Lambda(0.01)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1952
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1970985
	speed: 0.1327s/iter; left time: 3078.1481s
	iters: 200, epoch: 10 | loss: 0.2063179
	speed: 0.1339s/iter; left time: 3091.6494s
Epoch: 10 cost time: 33.980276346206665
Epoch: 10, Steps: 256 Train Loss: 0.2033 (Forecasting Loss:0.1689 + XiCon Loss:3.4386 x Lambda(0.01)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.1951
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2089372
	speed: 0.1327s/iter; left time: 3044.4756s
	iters: 200, epoch: 11 | loss: 0.2059892
	speed: 0.1296s/iter; left time: 2960.2082s
Epoch: 11 cost time: 33.9995539188385
Epoch: 11, Steps: 256 Train Loss: 0.2031 (Forecasting Loss:0.1687 + XiCon Loss:3.4419 x Lambda(0.01)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.1950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08145822584629059, mae:0.2218971699476242, mape:0.16583338379859924, mspe:0.045162975788116455 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0848+-0.00352, MAE:0.2266+-0.00589, MAPE:0.1681+-0.00367, MSPE:0.0457+-0.00142, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.9950
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3738959
	speed: 0.1295s/iter; left time: 3147.1903s
	iters: 200, epoch: 1 | loss: 0.3424534
	speed: 0.1285s/iter; left time: 3109.7873s
Epoch: 1 cost time: 32.60933232307434
Epoch: 1, Steps: 244 Train Loss: 0.3808 (Forecasting Loss:0.3471 + XiCon Loss:3.3722 x Lambda(0.01)), Vali MSE Loss: 0.2389 Test MSE Loss: 0.1571
Validation loss decreased (inf --> 0.238905).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3603354
	speed: 0.1708s/iter; left time: 4109.4666s
	iters: 200, epoch: 2 | loss: 0.3209004
	speed: 0.1630s/iter; left time: 3904.1916s
Epoch: 2 cost time: 40.37523078918457
Epoch: 2, Steps: 244 Train Loss: 0.3455 (Forecasting Loss:0.3125 + XiCon Loss:3.2988 x Lambda(0.01)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1535
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2870578
	speed: 0.1651s/iter; left time: 3930.8009s
	iters: 200, epoch: 3 | loss: 0.2806351
	speed: 0.1640s/iter; left time: 3887.9126s
Epoch: 3 cost time: 39.933926820755005
Epoch: 3, Steps: 244 Train Loss: 0.2913 (Forecasting Loss:0.2587 + XiCon Loss:3.2561 x Lambda(0.01)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.1550
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2739378
	speed: 0.1676s/iter; left time: 3950.9377s
	iters: 200, epoch: 4 | loss: 0.2756292
	speed: 0.1640s/iter; left time: 3848.3394s
Epoch: 4 cost time: 40.884023904800415
Epoch: 4, Steps: 244 Train Loss: 0.2755 (Forecasting Loss:0.2430 + XiCon Loss:3.2558 x Lambda(0.01)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.1534
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2677245
	speed: 0.1647s/iter; left time: 3841.1687s
	iters: 200, epoch: 5 | loss: 0.2663788
	speed: 0.1710s/iter; left time: 3970.9324s
Epoch: 5 cost time: 41.37301802635193
Epoch: 5, Steps: 244 Train Loss: 0.2671 (Forecasting Loss:0.2346 + XiCon Loss:3.2574 x Lambda(0.01)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2582394
	speed: 0.1697s/iter; left time: 3916.5922s
	iters: 200, epoch: 6 | loss: 0.2691817
	speed: 0.1673s/iter; left time: 3845.6932s
Epoch: 6 cost time: 41.24858999252319
Epoch: 6, Steps: 244 Train Loss: 0.2625 (Forecasting Loss:0.2300 + XiCon Loss:3.2554 x Lambda(0.01)), Vali MSE Loss: 0.3057 Test MSE Loss: 0.1640
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2483251
	speed: 0.1713s/iter; left time: 3912.7602s
	iters: 200, epoch: 7 | loss: 0.2564682
	speed: 0.1640s/iter; left time: 3729.8062s
Epoch: 7 cost time: 40.653424978256226
Epoch: 7, Steps: 244 Train Loss: 0.2601 (Forecasting Loss:0.2276 + XiCon Loss:3.2553 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.1698
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2710294
	speed: 0.1753s/iter; left time: 3959.8615s
	iters: 200, epoch: 8 | loss: 0.2597017
	speed: 0.1640s/iter; left time: 3688.3184s
Epoch: 8 cost time: 41.147403955459595
Epoch: 8, Steps: 244 Train Loss: 0.2589 (Forecasting Loss:0.2264 + XiCon Loss:3.2524 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.1678
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2465563
	speed: 0.1740s/iter; left time: 3889.3752s
	iters: 200, epoch: 9 | loss: 0.2557970
	speed: 0.1682s/iter; left time: 3741.8075s
Epoch: 9 cost time: 41.50705814361572
Epoch: 9, Steps: 244 Train Loss: 0.2581 (Forecasting Loss:0.2256 + XiCon Loss:3.2513 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.1658
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2616802
	speed: 0.1721s/iter; left time: 3804.7013s
	iters: 200, epoch: 10 | loss: 0.2511795
	speed: 0.1671s/iter; left time: 3677.8548s
Epoch: 10 cost time: 41.28736114501953
Epoch: 10, Steps: 244 Train Loss: 0.2579 (Forecasting Loss:0.2254 + XiCon Loss:3.2521 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.1654
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2431124
	speed: 0.1692s/iter; left time: 3698.8977s
	iters: 200, epoch: 11 | loss: 0.2514544
	speed: 0.1651s/iter; left time: 3592.4166s
Epoch: 11 cost time: 40.69057822227478
Epoch: 11, Steps: 244 Train Loss: 0.2576 (Forecasting Loss:0.2251 + XiCon Loss:3.2520 x Lambda(0.01)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.1665
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08522641658782959, mae:0.22893500328063965, mape:0.16247253119945526, mspe:0.04039248079061508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0136
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3646045
	speed: 0.1171s/iter; left time: 2846.2621s
	iters: 200, epoch: 1 | loss: 0.3690978
	speed: 0.1091s/iter; left time: 2639.2527s
Epoch: 1 cost time: 27.77553105354309
Epoch: 1, Steps: 244 Train Loss: 0.3716 (Forecasting Loss:0.3378 + XiCon Loss:3.3807 x Lambda(0.01)), Vali MSE Loss: 0.2312 Test MSE Loss: 0.1646
Validation loss decreased (inf --> 0.231245).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3255425
	speed: 0.1223s/iter; left time: 2941.8741s
	iters: 200, epoch: 2 | loss: 0.3090701
	speed: 0.1153s/iter; left time: 2762.9923s
Epoch: 2 cost time: 28.648168802261353
Epoch: 2, Steps: 244 Train Loss: 0.3329 (Forecasting Loss:0.2998 + XiCon Loss:3.3125 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.1576
Validation loss decreased (0.231245 --> 0.226027).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2807530
	speed: 0.1199s/iter; left time: 2854.6283s
	iters: 200, epoch: 3 | loss: 0.2679680
	speed: 0.1209s/iter; left time: 2866.2725s
Epoch: 3 cost time: 29.512410640716553
Epoch: 3, Steps: 244 Train Loss: 0.2795 (Forecasting Loss:0.2468 + XiCon Loss:3.2711 x Lambda(0.01)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.1639
Validation loss decreased (0.226027 --> 0.221132).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2540480
	speed: 0.1236s/iter; left time: 2913.2789s
	iters: 200, epoch: 4 | loss: 0.2451390
	speed: 0.1160s/iter; left time: 2721.4317s
Epoch: 4 cost time: 29.600990533828735
Epoch: 4, Steps: 244 Train Loss: 0.2610 (Forecasting Loss:0.2280 + XiCon Loss:3.2914 x Lambda(0.01)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2634001
	speed: 0.1210s/iter; left time: 2822.5728s
	iters: 200, epoch: 5 | loss: 0.2524621
	speed: 0.1206s/iter; left time: 2800.1038s
Epoch: 5 cost time: 29.304486989974976
Epoch: 5, Steps: 244 Train Loss: 0.2534 (Forecasting Loss:0.2204 + XiCon Loss:3.2991 x Lambda(0.01)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.1639
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2503537
	speed: 0.1220s/iter; left time: 2815.8129s
	iters: 200, epoch: 6 | loss: 0.2560212
	speed: 0.1215s/iter; left time: 2793.0133s
Epoch: 6 cost time: 29.773576736450195
Epoch: 6, Steps: 244 Train Loss: 0.2499 (Forecasting Loss:0.2169 + XiCon Loss:3.3017 x Lambda(0.01)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1612
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2525399
	speed: 0.1251s/iter; left time: 2857.8344s
	iters: 200, epoch: 7 | loss: 0.2504354
	speed: 0.1208s/iter; left time: 2746.9624s
Epoch: 7 cost time: 30.050918102264404
Epoch: 7, Steps: 244 Train Loss: 0.2481 (Forecasting Loss:0.2151 + XiCon Loss:3.3038 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1610
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2485733
	speed: 0.1216s/iter; left time: 2748.0698s
	iters: 200, epoch: 8 | loss: 0.2418722
	speed: 0.1201s/iter; left time: 2701.2419s
Epoch: 8 cost time: 29.402430295944214
Epoch: 8, Steps: 244 Train Loss: 0.2473 (Forecasting Loss:0.2142 + XiCon Loss:3.3057 x Lambda(0.01)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.1609
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2477021
	speed: 0.1201s/iter; left time: 2684.4487s
	iters: 200, epoch: 9 | loss: 0.2496819
	speed: 0.1212s/iter; left time: 2696.6720s
Epoch: 9 cost time: 29.40317940711975
Epoch: 9, Steps: 244 Train Loss: 0.2468 (Forecasting Loss:0.2137 + XiCon Loss:3.3081 x Lambda(0.01)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1602
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2517699
	speed: 0.1262s/iter; left time: 2788.6108s
	iters: 200, epoch: 10 | loss: 0.2498978
	speed: 0.1193s/iter; left time: 2625.1632s
Epoch: 10 cost time: 30.1723051071167
Epoch: 10, Steps: 244 Train Loss: 0.2464 (Forecasting Loss:0.2134 + XiCon Loss:3.3070 x Lambda(0.01)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1601
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2436127
	speed: 0.1223s/iter; left time: 2673.9449s
	iters: 200, epoch: 11 | loss: 0.2523369
	speed: 0.1136s/iter; left time: 2471.9952s
Epoch: 11 cost time: 28.668937921524048
Epoch: 11, Steps: 244 Train Loss: 0.2462 (Forecasting Loss:0.2132 + XiCon Loss:3.3076 x Lambda(0.01)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1597
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.2444289
	speed: 0.1205s/iter; left time: 2604.5718s
	iters: 200, epoch: 12 | loss: 0.2476383
	speed: 0.1103s/iter; left time: 2373.8450s
Epoch: 12 cost time: 28.01175856590271
Epoch: 12, Steps: 244 Train Loss: 0.2461 (Forecasting Loss:0.2130 + XiCon Loss:3.3092 x Lambda(0.01)), Vali MSE Loss: 0.2218 Test MSE Loss: 0.1600
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.2489123
	speed: 0.1169s/iter; left time: 2498.5806s
	iters: 200, epoch: 13 | loss: 0.2407342
	speed: 0.1138s/iter; left time: 2420.5787s
Epoch: 13 cost time: 28.31824278831482
Epoch: 13, Steps: 244 Train Loss: 0.2461 (Forecasting Loss:0.2130 + XiCon Loss:3.3083 x Lambda(0.01)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1598
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09118296951055527, mae:0.23658610880374908, mape:0.1743943691253662, mspe:0.050195809453725815 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.3685
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3556194
	speed: 0.1157s/iter; left time: 2811.1839s
	iters: 200, epoch: 1 | loss: 0.3505454
	speed: 0.1171s/iter; left time: 2834.1408s
Epoch: 1 cost time: 28.3077175617218
Epoch: 1, Steps: 244 Train Loss: 0.3708 (Forecasting Loss:0.3369 + XiCon Loss:3.3972 x Lambda(0.01)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1605
Validation loss decreased (inf --> 0.231264).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3560376
	speed: 0.1618s/iter; left time: 3893.1509s
	iters: 200, epoch: 2 | loss: 0.3325446
	speed: 0.1902s/iter; left time: 4555.6490s
Epoch: 2 cost time: 43.648659467697144
Epoch: 2, Steps: 244 Train Loss: 0.3538 (Forecasting Loss:0.3206 + XiCon Loss:3.3170 x Lambda(0.01)), Vali MSE Loss: 0.2752 Test MSE Loss: 0.1635
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2758621
	speed: 0.1822s/iter; left time: 4337.9428s
	iters: 200, epoch: 3 | loss: 0.2748878
	speed: 0.1820s/iter; left time: 4315.4536s
Epoch: 3 cost time: 44.37614727020264
Epoch: 3, Steps: 244 Train Loss: 0.2819 (Forecasting Loss:0.2491 + XiCon Loss:3.2794 x Lambda(0.01)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.1647
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2689920
	speed: 0.1846s/iter; left time: 4349.6791s
	iters: 200, epoch: 4 | loss: 0.2517992
	speed: 0.1851s/iter; left time: 4344.2864s
Epoch: 4 cost time: 45.180548906326294
Epoch: 4, Steps: 244 Train Loss: 0.2632 (Forecasting Loss:0.2303 + XiCon Loss:3.2843 x Lambda(0.01)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.1684
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2687488
	speed: 0.1849s/iter; left time: 4312.1295s
	iters: 200, epoch: 5 | loss: 0.2552367
	speed: 0.1845s/iter; left time: 4285.0496s
Epoch: 5 cost time: 45.050148010253906
Epoch: 5, Steps: 244 Train Loss: 0.2556 (Forecasting Loss:0.2227 + XiCon Loss:3.2879 x Lambda(0.01)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.1642
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2478233
	speed: 0.1784s/iter; left time: 4116.5558s
	iters: 200, epoch: 6 | loss: 0.2495755
	speed: 0.1939s/iter; left time: 4455.0567s
Epoch: 6 cost time: 45.73417782783508
Epoch: 6, Steps: 244 Train Loss: 0.2524 (Forecasting Loss:0.2195 + XiCon Loss:3.2886 x Lambda(0.01)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.1609
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2546248
	speed: 0.1933s/iter; left time: 4415.3132s
	iters: 200, epoch: 7 | loss: 0.2474723
	speed: 0.1818s/iter; left time: 4134.0592s
Epoch: 7 cost time: 46.01810121536255
Epoch: 7, Steps: 244 Train Loss: 0.2507 (Forecasting Loss:0.2178 + XiCon Loss:3.2895 x Lambda(0.01)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.1651
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2497842
	speed: 0.1893s/iter; left time: 4276.0146s
	iters: 200, epoch: 8 | loss: 0.2533191
	speed: 0.1783s/iter; left time: 4010.3224s
Epoch: 8 cost time: 45.38794493675232
Epoch: 8, Steps: 244 Train Loss: 0.2497 (Forecasting Loss:0.2168 + XiCon Loss:3.2891 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.1630
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2529598
	speed: 0.1855s/iter; left time: 4144.7725s
	iters: 200, epoch: 9 | loss: 0.2469168
	speed: 0.1841s/iter; left time: 4095.3167s
Epoch: 9 cost time: 45.48025941848755
Epoch: 9, Steps: 244 Train Loss: 0.2492 (Forecasting Loss:0.2163 + XiCon Loss:3.2897 x Lambda(0.01)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.1621
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2481163
	speed: 0.1918s/iter; left time: 4240.4610s
	iters: 200, epoch: 10 | loss: 0.2446635
	speed: 0.1878s/iter; left time: 4132.8167s
Epoch: 10 cost time: 46.45914578437805
Epoch: 10, Steps: 244 Train Loss: 0.2491 (Forecasting Loss:0.2161 + XiCon Loss:3.2902 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.1631
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2476281
	speed: 0.1887s/iter; left time: 4124.5629s
	iters: 200, epoch: 11 | loss: 0.2481426
	speed: 0.1897s/iter; left time: 4128.2303s
Epoch: 11 cost time: 46.3049533367157
Epoch: 11, Steps: 244 Train Loss: 0.2488 (Forecasting Loss:0.2159 + XiCon Loss:3.2896 x Lambda(0.01)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.1633
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.0875089094042778, mae:0.23341618478298187, mape:0.1681283563375473, mspe:0.04364517703652382 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.9979
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4288515
	speed: 0.1167s/iter; left time: 2835.5655s
	iters: 200, epoch: 1 | loss: 0.3431031
	speed: 0.1167s/iter; left time: 2824.7827s
Epoch: 1 cost time: 29.492827653884888
Epoch: 1, Steps: 244 Train Loss: 0.3737 (Forecasting Loss:0.3404 + XiCon Loss:3.3295 x Lambda(0.01)), Vali MSE Loss: 0.2378 Test MSE Loss: 0.1543
Validation loss decreased (inf --> 0.237775).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.4029035
	speed: 0.1532s/iter; left time: 3684.6648s
	iters: 200, epoch: 2 | loss: 0.4033917
	speed: 0.1508s/iter; left time: 3613.4204s
Epoch: 2 cost time: 37.02503848075867
Epoch: 2, Steps: 244 Train Loss: 0.4137 (Forecasting Loss:0.3789 + XiCon Loss:3.4771 x Lambda(0.01)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.1799
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.4079255
	speed: 0.1497s/iter; left time: 3565.0826s
	iters: 200, epoch: 3 | loss: 0.4062869
	speed: 0.1547s/iter; left time: 3668.0443s
Epoch: 3 cost time: 37.025739669799805
Epoch: 3, Steps: 244 Train Loss: 0.4022 (Forecasting Loss:0.3676 + XiCon Loss:3.4594 x Lambda(0.01)), Vali MSE Loss: 0.2710 Test MSE Loss: 0.1762
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.4064827
	speed: 0.1559s/iter; left time: 3674.6997s
	iters: 200, epoch: 4 | loss: 0.3946958
	speed: 0.1481s/iter; left time: 3476.3879s
Epoch: 4 cost time: 36.8988721370697
Epoch: 4, Steps: 244 Train Loss: 0.3972 (Forecasting Loss:0.3631 + XiCon Loss:3.4049 x Lambda(0.01)), Vali MSE Loss: 0.2642 Test MSE Loss: 0.1721
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.3948939
	speed: 0.1530s/iter; left time: 3568.6266s
	iters: 200, epoch: 5 | loss: 0.3812886
	speed: 0.1525s/iter; left time: 3541.2388s
Epoch: 5 cost time: 37.12210941314697
Epoch: 5, Steps: 244 Train Loss: 0.3941 (Forecasting Loss:0.3611 + XiCon Loss:3.3052 x Lambda(0.01)), Vali MSE Loss: 0.2652 Test MSE Loss: 0.1725
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.3925816
	speed: 0.1400s/iter; left time: 3231.9537s
	iters: 200, epoch: 6 | loss: 0.4088368
	speed: 0.1435s/iter; left time: 3298.8278s
Epoch: 6 cost time: 34.57471942901611
Epoch: 6, Steps: 244 Train Loss: 0.3921 (Forecasting Loss:0.3597 + XiCon Loss:3.2461 x Lambda(0.01)), Vali MSE Loss: 0.2648 Test MSE Loss: 0.1724
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.3951344
	speed: 0.1447s/iter; left time: 3303.6174s
	iters: 200, epoch: 7 | loss: 0.3699065
	speed: 0.1491s/iter; left time: 3389.8696s
Epoch: 7 cost time: 36.08789563179016
Epoch: 7, Steps: 244 Train Loss: 0.3915 (Forecasting Loss:0.3591 + XiCon Loss:3.2423 x Lambda(0.01)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1718
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.4005611
	speed: 0.1549s/iter; left time: 3500.4190s
	iters: 200, epoch: 8 | loss: 0.3996250
	speed: 0.1517s/iter; left time: 3411.1041s
Epoch: 8 cost time: 37.27932667732239
Epoch: 8, Steps: 244 Train Loss: 0.3912 (Forecasting Loss:0.3588 + XiCon Loss:3.2387 x Lambda(0.01)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1716
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4129598
	speed: 0.1495s/iter; left time: 3340.3128s
	iters: 200, epoch: 9 | loss: 0.3827681
	speed: 0.1563s/iter; left time: 3477.0403s
Epoch: 9 cost time: 37.313544273376465
Epoch: 9, Steps: 244 Train Loss: 0.3909 (Forecasting Loss:0.3585 + XiCon Loss:3.2361 x Lambda(0.01)), Vali MSE Loss: 0.2638 Test MSE Loss: 0.1715
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.3842281
	speed: 0.1510s/iter; left time: 3337.8670s
	iters: 200, epoch: 10 | loss: 0.3800119
	speed: 0.1458s/iter; left time: 3208.0837s
Epoch: 10 cost time: 36.01269888877869
Epoch: 10, Steps: 244 Train Loss: 0.3908 (Forecasting Loss:0.3584 + XiCon Loss:3.2331 x Lambda(0.01)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.1714
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.3865871
	speed: 0.1544s/iter; left time: 3376.3823s
	iters: 200, epoch: 11 | loss: 0.3952034
	speed: 0.1547s/iter; left time: 3366.3343s
Epoch: 11 cost time: 37.284672021865845
Epoch: 11, Steps: 244 Train Loss: 0.3906 (Forecasting Loss:0.3583 + XiCon Loss:3.2296 x Lambda(0.01)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.1716
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08236640691757202, mae:0.22615788877010345, mape:0.1620151251554489, mspe:0.04041030630469322 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0639
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3918905
	speed: 0.1207s/iter; left time: 2931.9696s
	iters: 200, epoch: 1 | loss: 0.3903156
	speed: 0.1121s/iter; left time: 2712.3582s
Epoch: 1 cost time: 28.827598810195923
Epoch: 1, Steps: 244 Train Loss: 0.3815 (Forecasting Loss:0.3479 + XiCon Loss:3.3521 x Lambda(0.01)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1559
Validation loss decreased (inf --> 0.230549).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3580495
	speed: 0.1709s/iter; left time: 4111.3558s
	iters: 200, epoch: 2 | loss: 0.3258259
	speed: 0.1648s/iter; left time: 3947.4966s
Epoch: 2 cost time: 40.32503414154053
Epoch: 2, Steps: 244 Train Loss: 0.3442 (Forecasting Loss:0.3112 + XiCon Loss:3.3033 x Lambda(0.01)), Vali MSE Loss: 0.2850 Test MSE Loss: 0.1593
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2996436
	speed: 0.1641s/iter; left time: 3906.7837s
	iters: 200, epoch: 3 | loss: 0.2946655
	speed: 0.1667s/iter; left time: 3953.6552s
Epoch: 3 cost time: 40.07313060760498
Epoch: 3, Steps: 244 Train Loss: 0.2955 (Forecasting Loss:0.2628 + XiCon Loss:3.2705 x Lambda(0.01)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.1586
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2899798
	speed: 0.1684s/iter; left time: 3969.9150s
	iters: 200, epoch: 4 | loss: 0.2748161
	speed: 0.1590s/iter; left time: 3730.5963s
Epoch: 4 cost time: 40.2122802734375
Epoch: 4, Steps: 244 Train Loss: 0.2819 (Forecasting Loss:0.2492 + XiCon Loss:3.2705 x Lambda(0.01)), Vali MSE Loss: 0.3009 Test MSE Loss: 0.1606
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2676869
	speed: 0.1598s/iter; left time: 3727.0086s
	iters: 200, epoch: 5 | loss: 0.2713978
	speed: 0.1658s/iter; left time: 3851.2727s
Epoch: 5 cost time: 40.14276194572449
Epoch: 5, Steps: 244 Train Loss: 0.2756 (Forecasting Loss:0.2429 + XiCon Loss:3.2763 x Lambda(0.01)), Vali MSE Loss: 0.2813 Test MSE Loss: 0.1635
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2751613
	speed: 0.1711s/iter; left time: 3948.6688s
	iters: 200, epoch: 6 | loss: 0.2624980
	speed: 0.1681s/iter; left time: 3862.8290s
Epoch: 6 cost time: 41.59616780281067
Epoch: 6, Steps: 244 Train Loss: 0.2712 (Forecasting Loss:0.2384 + XiCon Loss:3.2814 x Lambda(0.01)), Vali MSE Loss: 0.2979 Test MSE Loss: 0.1659
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2689722
	speed: 0.1719s/iter; left time: 3926.2862s
	iters: 200, epoch: 7 | loss: 0.2707470
	speed: 0.1670s/iter; left time: 3796.9611s
Epoch: 7 cost time: 41.69689416885376
Epoch: 7, Steps: 244 Train Loss: 0.2679 (Forecasting Loss:0.2350 + XiCon Loss:3.2851 x Lambda(0.01)), Vali MSE Loss: 0.3038 Test MSE Loss: 0.1689
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2691625
	speed: 0.1696s/iter; left time: 3832.5756s
	iters: 200, epoch: 8 | loss: 0.2617963
	speed: 0.1676s/iter; left time: 3770.2263s
Epoch: 8 cost time: 41.77461528778076
Epoch: 8, Steps: 244 Train Loss: 0.2656 (Forecasting Loss:0.2327 + XiCon Loss:3.2844 x Lambda(0.01)), Vali MSE Loss: 0.3141 Test MSE Loss: 0.1704
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2733929
	speed: 0.1746s/iter; left time: 3902.1923s
	iters: 200, epoch: 9 | loss: 0.2686340
	speed: 0.1681s/iter; left time: 3741.1655s
Epoch: 9 cost time: 42.20529866218567
Epoch: 9, Steps: 244 Train Loss: 0.2646 (Forecasting Loss:0.2317 + XiCon Loss:3.2863 x Lambda(0.01)), Vali MSE Loss: 0.3109 Test MSE Loss: 0.1701
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2650808
	speed: 0.1693s/iter; left time: 3741.6458s
	iters: 200, epoch: 10 | loss: 0.2704186
	speed: 0.1713s/iter; left time: 3770.0050s
Epoch: 10 cost time: 41.659684896469116
Epoch: 10, Steps: 244 Train Loss: 0.2641 (Forecasting Loss:0.2312 + XiCon Loss:3.2857 x Lambda(0.01)), Vali MSE Loss: 0.3077 Test MSE Loss: 0.1695
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2681555
	speed: 0.1662s/iter; left time: 3633.2446s
	iters: 200, epoch: 11 | loss: 0.2667619
	speed: 0.1691s/iter; left time: 3680.0561s
Epoch: 11 cost time: 41.101080656051636
Epoch: 11, Steps: 244 Train Loss: 0.2638 (Forecasting Loss:0.2309 + XiCon Loss:3.2882 x Lambda(0.01)), Vali MSE Loss: 0.3094 Test MSE Loss: 0.1701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08426139503717422, mae:0.22748339176177979, mape:0.1616469919681549, mspe:0.040065519511699677 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0861+-0.00421, MAE:0.2305+-0.00541, MAPE:0.1657+-0.00685, MSPE:0.0429+-0.00535, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.7665
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4628658
	speed: 0.1106s/iter; left time: 2566.3734s
	iters: 200, epoch: 1 | loss: 0.4441319
	speed: 0.1039s/iter; left time: 2400.1169s
Epoch: 1 cost time: 24.985417366027832
Epoch: 1, Steps: 233 Train Loss: 0.4637 (Forecasting Loss:0.4295 + XiCon Loss:3.4188 x Lambda(0.01)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.1699
Validation loss decreased (inf --> 0.298868).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3835622
	speed: 0.1050s/iter; left time: 2412.4176s
	iters: 200, epoch: 2 | loss: 0.3315798
	speed: 0.1055s/iter; left time: 2413.7107s
Epoch: 2 cost time: 24.678478479385376
Epoch: 2, Steps: 233 Train Loss: 0.3696 (Forecasting Loss:0.3359 + XiCon Loss:3.3717 x Lambda(0.01)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1675
Validation loss decreased (0.298868 --> 0.222248).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3171974
	speed: 0.1133s/iter; left time: 2574.7591s
	iters: 200, epoch: 3 | loss: 0.3125321
	speed: 0.1071s/iter; left time: 2423.8500s
Epoch: 3 cost time: 25.644832849502563
Epoch: 3, Steps: 233 Train Loss: 0.3148 (Forecasting Loss:0.2814 + XiCon Loss:3.3391 x Lambda(0.01)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.1626
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3030568
	speed: 0.1124s/iter; left time: 2528.2281s
	iters: 200, epoch: 4 | loss: 0.2978129
	speed: 0.1090s/iter; left time: 2442.3633s
Epoch: 4 cost time: 25.876530647277832
Epoch: 4, Steps: 233 Train Loss: 0.3025 (Forecasting Loss:0.2695 + XiCon Loss:3.3092 x Lambda(0.01)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1644
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2930879
	speed: 0.1138s/iter; left time: 2533.7188s
	iters: 200, epoch: 5 | loss: 0.2936549
	speed: 0.1133s/iter; left time: 2512.0827s
Epoch: 5 cost time: 26.757440090179443
Epoch: 5, Steps: 233 Train Loss: 0.2972 (Forecasting Loss:0.2642 + XiCon Loss:3.3012 x Lambda(0.01)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1650
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3079357
	speed: 0.1174s/iter; left time: 2587.1049s
	iters: 200, epoch: 6 | loss: 0.2929648
	speed: 0.1113s/iter; left time: 2440.5348s
Epoch: 6 cost time: 26.488709449768066
Epoch: 6, Steps: 233 Train Loss: 0.2946 (Forecasting Loss:0.2616 + XiCon Loss:3.2975 x Lambda(0.01)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1686
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.3030935
	speed: 0.1167s/iter; left time: 2544.1264s
	iters: 200, epoch: 7 | loss: 0.3051183
	speed: 0.1119s/iter; left time: 2427.6920s
Epoch: 7 cost time: 26.590144395828247
Epoch: 7, Steps: 233 Train Loss: 0.2928 (Forecasting Loss:0.2599 + XiCon Loss:3.2957 x Lambda(0.01)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1670
Validation loss decreased (0.222248 --> 0.220167).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2888260
	speed: 0.1130s/iter; left time: 2438.2808s
	iters: 200, epoch: 8 | loss: 0.3000336
	speed: 0.1111s/iter; left time: 2385.4221s
Epoch: 8 cost time: 25.975504398345947
Epoch: 8, Steps: 233 Train Loss: 0.2920 (Forecasting Loss:0.2591 + XiCon Loss:3.2937 x Lambda(0.01)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.1681
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2850214
	speed: 0.1146s/iter; left time: 2445.4428s
	iters: 200, epoch: 9 | loss: 0.2978669
	speed: 0.1119s/iter; left time: 2377.1889s
Epoch: 9 cost time: 26.29229974746704
Epoch: 9, Steps: 233 Train Loss: 0.2917 (Forecasting Loss:0.2587 + XiCon Loss:3.2940 x Lambda(0.01)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2882342
	speed: 0.1140s/iter; left time: 2406.0049s
	iters: 200, epoch: 10 | loss: 0.2879207
	speed: 0.1130s/iter; left time: 2372.8693s
Epoch: 10 cost time: 26.568661212921143
Epoch: 10, Steps: 233 Train Loss: 0.2913 (Forecasting Loss:0.2584 + XiCon Loss:3.2948 x Lambda(0.01)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1674
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.3047912
	speed: 0.1125s/iter; left time: 2347.0091s
	iters: 200, epoch: 11 | loss: 0.2916435
	speed: 0.1082s/iter; left time: 2247.2679s
Epoch: 11 cost time: 25.78334379196167
Epoch: 11, Steps: 233 Train Loss: 0.2915 (Forecasting Loss:0.2585 + XiCon Loss:3.2962 x Lambda(0.01)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1685
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2925258
	speed: 0.1118s/iter; left time: 2307.3373s
	iters: 200, epoch: 12 | loss: 0.2784337
	speed: 0.1101s/iter; left time: 2261.8981s
Epoch: 12 cost time: 25.90601086616516
Epoch: 12, Steps: 233 Train Loss: 0.2913 (Forecasting Loss:0.2584 + XiCon Loss:3.2935 x Lambda(0.01)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1689
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2960792
	speed: 0.1112s/iter; left time: 2269.6580s
	iters: 200, epoch: 13 | loss: 0.2981630
	speed: 0.1112s/iter; left time: 2258.0590s
Epoch: 13 cost time: 25.802309274673462
Epoch: 13, Steps: 233 Train Loss: 0.2913 (Forecasting Loss:0.2584 + XiCon Loss:3.2918 x Lambda(0.01)), Vali MSE Loss: 0.2228 Test MSE Loss: 0.1689
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2855314
	speed: 0.1136s/iter; left time: 2292.4683s
	iters: 200, epoch: 14 | loss: 0.2837595
	speed: 0.1082s/iter; left time: 2172.0222s
Epoch: 14 cost time: 25.65337038040161
Epoch: 14, Steps: 233 Train Loss: 0.2911 (Forecasting Loss:0.2581 + XiCon Loss:3.2943 x Lambda(0.01)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1690
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2954088
	speed: 0.1146s/iter; left time: 2285.1310s
	iters: 200, epoch: 15 | loss: 0.2890583
	speed: 0.1109s/iter; left time: 2199.8969s
Epoch: 15 cost time: 26.393693447113037
Epoch: 15, Steps: 233 Train Loss: 0.2914 (Forecasting Loss:0.2584 + XiCon Loss:3.2950 x Lambda(0.01)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1690
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2857895
	speed: 0.1131s/iter; left time: 2228.7660s
	iters: 200, epoch: 16 | loss: 0.2961682
	speed: 0.1095s/iter; left time: 2146.8911s
Epoch: 16 cost time: 26.239436864852905
Epoch: 16, Steps: 233 Train Loss: 0.2913 (Forecasting Loss:0.2583 + XiCon Loss:3.2940 x Lambda(0.01)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1690
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2878991
	speed: 0.1120s/iter; left time: 2180.2360s
	iters: 200, epoch: 17 | loss: 0.2872517
	speed: 0.1131s/iter; left time: 2191.8159s
Epoch: 17 cost time: 26.179797410964966
Epoch: 17, Steps: 233 Train Loss: 0.2911 (Forecasting Loss:0.2581 + XiCon Loss:3.2940 x Lambda(0.01)), Vali MSE Loss: 0.2228 Test MSE Loss: 0.1690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09285520762205124, mae:0.24107511341571808, mape:0.17129011452198029, mspe:0.045074574649333954 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.1641
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4835106
	speed: 0.1019s/iter; left time: 2364.9937s
	iters: 200, epoch: 1 | loss: 0.4897040
	speed: 0.0995s/iter; left time: 2299.4508s
Epoch: 1 cost time: 23.562440872192383
Epoch: 1, Steps: 233 Train Loss: 0.4823 (Forecasting Loss:0.4482 + XiCon Loss:3.4117 x Lambda(0.01)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1873
Validation loss decreased (inf --> 0.290636).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3634328
	speed: 0.1189s/iter; left time: 2730.3808s
	iters: 200, epoch: 2 | loss: 0.3231082
	speed: 0.1395s/iter; left time: 3190.3858s
Epoch: 2 cost time: 30.560635328292847
Epoch: 2, Steps: 233 Train Loss: 0.3608 (Forecasting Loss:0.3274 + XiCon Loss:3.3358 x Lambda(0.01)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.1614
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3133777
	speed: 0.1387s/iter; left time: 3152.3168s
	iters: 200, epoch: 3 | loss: 0.2997721
	speed: 0.1376s/iter; left time: 3113.5295s
Epoch: 3 cost time: 32.11128282546997
Epoch: 3, Steps: 233 Train Loss: 0.3096 (Forecasting Loss:0.2766 + XiCon Loss:3.3012 x Lambda(0.01)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.1556
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2805995
	speed: 0.1374s/iter; left time: 3092.6013s
	iters: 200, epoch: 4 | loss: 0.3056849
	speed: 0.1390s/iter; left time: 3114.3469s
Epoch: 4 cost time: 31.970526933670044
Epoch: 4, Steps: 233 Train Loss: 0.2999 (Forecasting Loss:0.2670 + XiCon Loss:3.2951 x Lambda(0.01)), Vali MSE Loss: 0.2921 Test MSE Loss: 0.1539
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2955068
	speed: 0.1360s/iter; left time: 3029.4171s
	iters: 200, epoch: 5 | loss: 0.2899067
	speed: 0.1328s/iter; left time: 2944.7891s
Epoch: 5 cost time: 31.56298851966858
Epoch: 5, Steps: 233 Train Loss: 0.2945 (Forecasting Loss:0.2616 + XiCon Loss:3.2904 x Lambda(0.01)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1549
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2972931
	speed: 0.1384s/iter; left time: 3050.6666s
	iters: 200, epoch: 6 | loss: 0.2909240
	speed: 0.1334s/iter; left time: 2926.3740s
Epoch: 6 cost time: 31.93631339073181
Epoch: 6, Steps: 233 Train Loss: 0.2924 (Forecasting Loss:0.2595 + XiCon Loss:3.2873 x Lambda(0.01)), Vali MSE Loss: 0.2945 Test MSE Loss: 0.1562
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.3002006
	speed: 0.1339s/iter; left time: 2919.8758s
	iters: 200, epoch: 7 | loss: 0.2862555
	speed: 0.1364s/iter; left time: 2960.5886s
Epoch: 7 cost time: 31.620509386062622
Epoch: 7, Steps: 233 Train Loss: 0.2908 (Forecasting Loss:0.2579 + XiCon Loss:3.2887 x Lambda(0.01)), Vali MSE Loss: 0.2973 Test MSE Loss: 0.1575
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2917353
	speed: 0.1369s/iter; left time: 2952.7105s
	iters: 200, epoch: 8 | loss: 0.2817329
	speed: 0.1326s/iter; left time: 2847.5534s
Epoch: 8 cost time: 31.22815990447998
Epoch: 8, Steps: 233 Train Loss: 0.2901 (Forecasting Loss:0.2573 + XiCon Loss:3.2885 x Lambda(0.01)), Vali MSE Loss: 0.2964 Test MSE Loss: 0.1577
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2952989
	speed: 0.1334s/iter; left time: 2846.0222s
	iters: 200, epoch: 9 | loss: 0.2925848
	speed: 0.1298s/iter; left time: 2756.0049s
Epoch: 9 cost time: 30.883910417556763
Epoch: 9, Steps: 233 Train Loss: 0.2895 (Forecasting Loss:0.2566 + XiCon Loss:3.2892 x Lambda(0.01)), Vali MSE Loss: 0.2977 Test MSE Loss: 0.1581
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2857168
	speed: 0.1362s/iter; left time: 2874.2003s
	iters: 200, epoch: 10 | loss: 0.2888256
	speed: 0.1349s/iter; left time: 2832.9452s
Epoch: 10 cost time: 31.588874340057373
Epoch: 10, Steps: 233 Train Loss: 0.2893 (Forecasting Loss:0.2564 + XiCon Loss:3.2899 x Lambda(0.01)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1579
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2841013
	speed: 0.1403s/iter; left time: 2928.7715s
	iters: 200, epoch: 11 | loss: 0.2995943
	speed: 0.1345s/iter; left time: 2793.2859s
Epoch: 11 cost time: 32.28508234024048
Epoch: 11, Steps: 233 Train Loss: 0.2894 (Forecasting Loss:0.2565 + XiCon Loss:3.2893 x Lambda(0.01)), Vali MSE Loss: 0.2983 Test MSE Loss: 0.1579
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11003375798463821, mae:0.2645743489265442, mape:0.18660342693328857, mspe:0.052072957158088684 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0166
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4715099
	speed: 0.1019s/iter; left time: 2363.6060s
	iters: 200, epoch: 1 | loss: 0.4671713
	speed: 0.0958s/iter; left time: 2213.6208s
Epoch: 1 cost time: 23.072673797607422
Epoch: 1, Steps: 233 Train Loss: 0.4748 (Forecasting Loss:0.4408 + XiCon Loss:3.4070 x Lambda(0.01)), Vali MSE Loss: 0.2969 Test MSE Loss: 0.1906
Validation loss decreased (inf --> 0.296949).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3446069
	speed: 0.1237s/iter; left time: 2840.1592s
	iters: 200, epoch: 2 | loss: 0.3224047
	speed: 0.1356s/iter; left time: 3101.5305s
Epoch: 2 cost time: 30.2646586894989
Epoch: 2, Steps: 233 Train Loss: 0.3507 (Forecasting Loss:0.3175 + XiCon Loss:3.3272 x Lambda(0.01)), Vali MSE Loss: 0.2933 Test MSE Loss: 0.1679
Validation loss decreased (0.296949 --> 0.293307).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2967844
	speed: 0.1346s/iter; left time: 3059.1032s
	iters: 200, epoch: 3 | loss: 0.3057275
	speed: 0.1316s/iter; left time: 2978.0653s
Epoch: 3 cost time: 30.949681043624878
Epoch: 3, Steps: 233 Train Loss: 0.3112 (Forecasting Loss:0.2783 + XiCon Loss:3.2970 x Lambda(0.01)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1668
Validation loss decreased (0.293307 --> 0.261645).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2972856
	speed: 0.1347s/iter; left time: 3031.5543s
	iters: 200, epoch: 4 | loss: 0.3185534
	speed: 0.1352s/iter; left time: 3028.7973s
Epoch: 4 cost time: 31.685375690460205
Epoch: 4, Steps: 233 Train Loss: 0.3015 (Forecasting Loss:0.2687 + XiCon Loss:3.2809 x Lambda(0.01)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.1483
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3016709
	speed: 0.1389s/iter; left time: 3093.0014s
	iters: 200, epoch: 5 | loss: 0.2996423
	speed: 0.1372s/iter; left time: 3042.2825s
Epoch: 5 cost time: 32.016714334487915
Epoch: 5, Steps: 233 Train Loss: 0.2966 (Forecasting Loss:0.2639 + XiCon Loss:3.2696 x Lambda(0.01)), Vali MSE Loss: 0.2686 Test MSE Loss: 0.1497
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2968870
	speed: 0.1440s/iter; left time: 3172.6495s
	iters: 200, epoch: 6 | loss: 0.2910475
	speed: 0.1398s/iter; left time: 3065.8367s
Epoch: 6 cost time: 32.840797662734985
Epoch: 6, Steps: 233 Train Loss: 0.2938 (Forecasting Loss:0.2611 + XiCon Loss:3.2641 x Lambda(0.01)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1524
Validation loss decreased (0.261645 --> 0.260303).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.3009568
	speed: 0.1379s/iter; left time: 3007.3807s
	iters: 200, epoch: 7 | loss: 0.2874176
	speed: 0.1366s/iter; left time: 2965.1079s
Epoch: 7 cost time: 32.81536889076233
Epoch: 7, Steps: 233 Train Loss: 0.2925 (Forecasting Loss:0.2599 + XiCon Loss:3.2619 x Lambda(0.01)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.1514
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.3070078
	speed: 0.1406s/iter; left time: 3033.3995s
	iters: 200, epoch: 8 | loss: 0.2889859
	speed: 0.1531s/iter; left time: 3286.8154s
Epoch: 8 cost time: 34.331058979034424
Epoch: 8, Steps: 233 Train Loss: 0.2918 (Forecasting Loss:0.2592 + XiCon Loss:3.2599 x Lambda(0.01)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1526
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2832435
	speed: 0.1564s/iter; left time: 3337.0575s
	iters: 200, epoch: 9 | loss: 0.2846207
	speed: 0.1590s/iter; left time: 3377.1789s
Epoch: 9 cost time: 36.82394289970398
Epoch: 9, Steps: 233 Train Loss: 0.2911 (Forecasting Loss:0.2585 + XiCon Loss:3.2584 x Lambda(0.01)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1524
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2829025
	speed: 0.1597s/iter; left time: 3370.9671s
	iters: 200, epoch: 10 | loss: 0.2914146
	speed: 0.1533s/iter; left time: 3220.4159s
Epoch: 10 cost time: 36.484243392944336
Epoch: 10, Steps: 233 Train Loss: 0.2912 (Forecasting Loss:0.2586 + XiCon Loss:3.2592 x Lambda(0.01)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1524
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2934645
	speed: 0.1598s/iter; left time: 3335.5416s
	iters: 200, epoch: 11 | loss: 0.2815968
	speed: 0.1557s/iter; left time: 3233.8546s
Epoch: 11 cost time: 36.84767293930054
Epoch: 11, Steps: 233 Train Loss: 0.2908 (Forecasting Loss:0.2582 + XiCon Loss:3.2587 x Lambda(0.01)), Vali MSE Loss: 0.2630 Test MSE Loss: 0.1521
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2986691
	speed: 0.1579s/iter; left time: 3258.8818s
	iters: 200, epoch: 12 | loss: 0.2971690
	speed: 0.1532s/iter; left time: 3145.4576s
Epoch: 12 cost time: 36.36175036430359
Epoch: 12, Steps: 233 Train Loss: 0.2905 (Forecasting Loss:0.2579 + XiCon Loss:3.2599 x Lambda(0.01)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1523
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.3025515
	speed: 0.1624s/iter; left time: 3313.5740s
	iters: 200, epoch: 13 | loss: 0.2804890
	speed: 0.1552s/iter; left time: 3150.6910s
Epoch: 13 cost time: 36.965171337127686
Epoch: 13, Steps: 233 Train Loss: 0.2912 (Forecasting Loss:0.2586 + XiCon Loss:3.2590 x Lambda(0.01)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1524
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.3032722
	speed: 0.1585s/iter; left time: 3197.8925s
	iters: 200, epoch: 14 | loss: 0.2932242
	speed: 0.1547s/iter; left time: 3105.3787s
Epoch: 14 cost time: 36.68119931221008
Epoch: 14, Steps: 233 Train Loss: 0.2910 (Forecasting Loss:0.2584 + XiCon Loss:3.2576 x Lambda(0.01)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.1524
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.3115183
	speed: 0.1607s/iter; left time: 3204.9236s
	iters: 200, epoch: 15 | loss: 0.2860526
	speed: 0.1547s/iter; left time: 3069.6862s
Epoch: 15 cost time: 37.18453884124756
Epoch: 15, Steps: 233 Train Loss: 0.2910 (Forecasting Loss:0.2584 + XiCon Loss:3.2582 x Lambda(0.01)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1524
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.3004439
	speed: 0.1611s/iter; left time: 3175.4674s
	iters: 200, epoch: 16 | loss: 0.2855471
	speed: 0.1583s/iter; left time: 3102.7161s
Epoch: 16 cost time: 37.18845844268799
Epoch: 16, Steps: 233 Train Loss: 0.2911 (Forecasting Loss:0.2585 + XiCon Loss:3.2582 x Lambda(0.01)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.1524
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08036454766988754, mae:0.22448773682117462, mape:0.16084431111812592, mspe:0.040373463183641434 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.0093
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4971336
	speed: 0.1126s/iter; left time: 2611.5939s
	iters: 200, epoch: 1 | loss: 0.4144067
	speed: 0.1061s/iter; left time: 2450.9544s
Epoch: 1 cost time: 25.671048879623413
Epoch: 1, Steps: 233 Train Loss: 0.4600 (Forecasting Loss:0.4259 + XiCon Loss:3.4172 x Lambda(0.01)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1636
Validation loss decreased (inf --> 0.265374).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3630275
	speed: 0.1211s/iter; left time: 2780.3088s
	iters: 200, epoch: 2 | loss: 0.3603157
	speed: 0.1091s/iter; left time: 2494.0227s
Epoch: 2 cost time: 26.89845871925354
Epoch: 2, Steps: 233 Train Loss: 0.3687 (Forecasting Loss:0.3349 + XiCon Loss:3.3834 x Lambda(0.01)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.1723
Validation loss decreased (0.265374 --> 0.224907).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3214036
	speed: 0.1243s/iter; left time: 2826.0504s
	iters: 200, epoch: 3 | loss: 0.3016300
	speed: 0.1110s/iter; left time: 2513.0769s
Epoch: 3 cost time: 27.56247353553772
Epoch: 3, Steps: 233 Train Loss: 0.3166 (Forecasting Loss:0.2831 + XiCon Loss:3.3550 x Lambda(0.01)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1558
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2950762
	speed: 0.1169s/iter; left time: 2630.4205s
	iters: 200, epoch: 4 | loss: 0.3033385
	speed: 0.1125s/iter; left time: 2520.0118s
Epoch: 4 cost time: 26.601611137390137
Epoch: 4, Steps: 233 Train Loss: 0.3053 (Forecasting Loss:0.2717 + XiCon Loss:3.3560 x Lambda(0.01)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.1559
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2837135
	speed: 0.1324s/iter; left time: 2948.0789s
	iters: 200, epoch: 5 | loss: 0.2907529
	speed: 0.0826s/iter; left time: 1830.9126s
Epoch: 5 cost time: 24.747554063796997
Epoch: 5, Steps: 233 Train Loss: 0.3005 (Forecasting Loss:0.2670 + XiCon Loss:3.3530 x Lambda(0.01)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.1663
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2953098
	speed: 0.1161s/iter; left time: 2558.5335s
	iters: 200, epoch: 6 | loss: 0.2831707
	speed: 0.1078s/iter; left time: 2365.3428s
Epoch: 6 cost time: 25.932358026504517
Epoch: 6, Steps: 233 Train Loss: 0.2978 (Forecasting Loss:0.2642 + XiCon Loss:3.3549 x Lambda(0.01)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1609
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2897421
	speed: 0.1121s/iter; left time: 2443.8574s
	iters: 200, epoch: 7 | loss: 0.2915249
	speed: 0.1089s/iter; left time: 2362.9414s
Epoch: 7 cost time: 25.757384061813354
Epoch: 7, Steps: 233 Train Loss: 0.2962 (Forecasting Loss:0.2626 + XiCon Loss:3.3522 x Lambda(0.01)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1619
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.3035115
	speed: 0.1238s/iter; left time: 2671.4264s
	iters: 200, epoch: 8 | loss: 0.3169146
	speed: 0.1233s/iter; left time: 2647.4681s
Epoch: 8 cost time: 29.010218381881714
Epoch: 8, Steps: 233 Train Loss: 0.2954 (Forecasting Loss:0.2619 + XiCon Loss:3.3517 x Lambda(0.01)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1607
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2884358
	speed: 0.1236s/iter; left time: 2637.6942s
	iters: 200, epoch: 9 | loss: 0.2884008
	speed: 0.1236s/iter; left time: 2625.4243s
Epoch: 9 cost time: 28.96075987815857
Epoch: 9, Steps: 233 Train Loss: 0.2950 (Forecasting Loss:0.2615 + XiCon Loss:3.3519 x Lambda(0.01)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1619
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2877241
	speed: 0.1239s/iter; left time: 2615.7445s
	iters: 200, epoch: 10 | loss: 0.2969693
	speed: 0.1213s/iter; left time: 2548.0498s
Epoch: 10 cost time: 28.913570642471313
Epoch: 10, Steps: 233 Train Loss: 0.2949 (Forecasting Loss:0.2614 + XiCon Loss:3.3523 x Lambda(0.01)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1634
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2967759
	speed: 0.1262s/iter; left time: 2634.8938s
	iters: 200, epoch: 11 | loss: 0.2932191
	speed: 0.1248s/iter; left time: 2592.7949s
Epoch: 11 cost time: 29.201126098632812
Epoch: 11, Steps: 233 Train Loss: 0.2945 (Forecasting Loss:0.2610 + XiCon Loss:3.3502 x Lambda(0.01)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.1630
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2819847
	speed: 0.1255s/iter; left time: 2590.8973s
	iters: 200, epoch: 12 | loss: 0.2887958
	speed: 0.1308s/iter; left time: 2685.7704s
Epoch: 12 cost time: 29.658050775527954
Epoch: 12, Steps: 233 Train Loss: 0.2946 (Forecasting Loss:0.2610 + XiCon Loss:3.3521 x Lambda(0.01)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1625
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09751605242490768, mae:0.2470998764038086, mape:0.1729508489370346, mspe:0.04482191801071167 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.8369
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.4626483
	speed: 0.1245s/iter; left time: 2887.5514s
	iters: 200, epoch: 1 | loss: 0.4684812
	speed: 0.1213s/iter; left time: 2802.0177s
Epoch: 1 cost time: 28.421313524246216
Epoch: 1, Steps: 233 Train Loss: 0.4775 (Forecasting Loss:0.4435 + XiCon Loss:3.4019 x Lambda(0.01)), Vali MSE Loss: 0.3001 Test MSE Loss: 0.1959
Validation loss decreased (inf --> 0.300059).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3341733
	speed: 0.1340s/iter; left time: 3078.2528s
	iters: 200, epoch: 2 | loss: 0.3211515
	speed: 0.1399s/iter; left time: 3200.3288s
Epoch: 2 cost time: 32.22797346115112
Epoch: 2, Steps: 233 Train Loss: 0.3528 (Forecasting Loss:0.3197 + XiCon Loss:3.3081 x Lambda(0.01)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.1472
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3178662
	speed: 0.1548s/iter; left time: 3519.7390s
	iters: 200, epoch: 3 | loss: 0.3137639
	speed: 0.1559s/iter; left time: 3527.8990s
Epoch: 3 cost time: 36.26637935638428
Epoch: 3, Steps: 233 Train Loss: 0.3037 (Forecasting Loss:0.2707 + XiCon Loss:3.2999 x Lambda(0.01)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.1501
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2971359
	speed: 0.1530s/iter; left time: 3442.8258s
	iters: 200, epoch: 4 | loss: 0.2721269
	speed: 0.1542s/iter; left time: 3454.7049s
Epoch: 4 cost time: 36.22020983695984
Epoch: 4, Steps: 233 Train Loss: 0.2922 (Forecasting Loss:0.2591 + XiCon Loss:3.3091 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.1480
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2874689
	speed: 0.1589s/iter; left time: 3538.0935s
	iters: 200, epoch: 5 | loss: 0.3006729
	speed: 0.1538s/iter; left time: 3410.1202s
Epoch: 5 cost time: 36.36219048500061
Epoch: 5, Steps: 233 Train Loss: 0.2871 (Forecasting Loss:0.2539 + XiCon Loss:3.3142 x Lambda(0.01)), Vali MSE Loss: 0.2964 Test MSE Loss: 0.1423
Validation loss decreased (0.300059 --> 0.296399).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2873347
	speed: 0.1545s/iter; left time: 3405.5259s
	iters: 200, epoch: 6 | loss: 0.2865887
	speed: 0.1556s/iter; left time: 3413.7019s
Epoch: 6 cost time: 36.01004099845886
Epoch: 6, Steps: 233 Train Loss: 0.2847 (Forecasting Loss:0.2515 + XiCon Loss:3.3153 x Lambda(0.01)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.1439
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2847317
	speed: 0.1544s/iter; left time: 3365.8857s
	iters: 200, epoch: 7 | loss: 0.2852447
	speed: 0.1535s/iter; left time: 3331.8721s
Epoch: 7 cost time: 36.12389326095581
Epoch: 7, Steps: 233 Train Loss: 0.2835 (Forecasting Loss:0.2503 + XiCon Loss:3.3169 x Lambda(0.01)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2837896
	speed: 0.1533s/iter; left time: 3306.9514s
	iters: 200, epoch: 8 | loss: 0.2789371
	speed: 0.1518s/iter; left time: 3258.8576s
Epoch: 8 cost time: 35.584614515304565
Epoch: 8, Steps: 233 Train Loss: 0.2828 (Forecasting Loss:0.2496 + XiCon Loss:3.3172 x Lambda(0.01)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.1430
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2733662
	speed: 0.1529s/iter; left time: 3261.6818s
	iters: 200, epoch: 9 | loss: 0.2802324
	speed: 0.1522s/iter; left time: 3232.6003s
Epoch: 9 cost time: 35.533594846725464
Epoch: 9, Steps: 233 Train Loss: 0.2823 (Forecasting Loss:0.2491 + XiCon Loss:3.3155 x Lambda(0.01)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.1431
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2794375
	speed: 0.1588s/iter; left time: 3351.7112s
	iters: 200, epoch: 10 | loss: 0.2835006
	speed: 0.1543s/iter; left time: 3240.8060s
Epoch: 10 cost time: 36.40931010246277
Epoch: 10, Steps: 233 Train Loss: 0.2820 (Forecasting Loss:0.2488 + XiCon Loss:3.3174 x Lambda(0.01)), Vali MSE Loss: 0.3102 Test MSE Loss: 0.1429
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2850627
	speed: 0.1503s/iter; left time: 3136.0304s
	iters: 200, epoch: 11 | loss: 0.2906681
	speed: 0.1656s/iter; left time: 3439.4279s
Epoch: 11 cost time: 35.59087824821472
Epoch: 11, Steps: 233 Train Loss: 0.2821 (Forecasting Loss:0.2490 + XiCon Loss:3.3147 x Lambda(0.01)), Vali MSE Loss: 0.3103 Test MSE Loss: 0.1430
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2836603
	speed: 0.1537s/iter; left time: 3171.6347s
	iters: 200, epoch: 12 | loss: 0.2918381
	speed: 0.1565s/iter; left time: 3213.4503s
Epoch: 12 cost time: 36.00645327568054
Epoch: 12, Steps: 233 Train Loss: 0.2818 (Forecasting Loss:0.2486 + XiCon Loss:3.3190 x Lambda(0.01)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.1429
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2812153
	speed: 0.1556s/iter; left time: 3174.2785s
	iters: 200, epoch: 13 | loss: 0.2833662
	speed: 0.1536s/iter; left time: 3119.6028s
Epoch: 13 cost time: 36.173895835876465
Epoch: 13, Steps: 233 Train Loss: 0.2818 (Forecasting Loss:0.2486 + XiCon Loss:3.3167 x Lambda(0.01)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.1429
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2817948
	speed: 0.1534s/iter; left time: 3093.8784s
	iters: 200, epoch: 14 | loss: 0.2918103
	speed: 0.1530s/iter; left time: 3071.3518s
Epoch: 14 cost time: 36.02081561088562
Epoch: 14, Steps: 233 Train Loss: 0.2819 (Forecasting Loss:0.2487 + XiCon Loss:3.3175 x Lambda(0.01)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.1429
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2795405
	speed: 0.1539s/iter; left time: 3067.7000s
	iters: 200, epoch: 15 | loss: 0.2890056
	speed: 0.1544s/iter; left time: 3063.8504s
Epoch: 15 cost time: 36.05181050300598
Epoch: 15, Steps: 233 Train Loss: 0.2820 (Forecasting Loss:0.2488 + XiCon Loss:3.3193 x Lambda(0.01)), Vali MSE Loss: 0.3110 Test MSE Loss: 0.1429
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.0717204213142395, mae:0.212917298078537, mape:0.15469440817832947, mspe:0.03829410299658775 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0905+-0.01854, MAE:0.2380+-0.02491, MAPE:0.1693+-0.01523, MSPE:0.0441+-0.00659, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.3610
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2442722
	speed: 0.0689s/iter; left time: 1819.0244s
	iters: 200, epoch: 1 | loss: 0.2646144
	speed: 0.0611s/iter; left time: 1606.5715s
Epoch: 1 cost time: 17.157480716705322
Epoch: 1, Steps: 265 Train Loss: 0.2597 (Forecasting Loss:0.2261 + XiCon Loss:3.3552 x Lambda(0.01)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1679
Validation loss decreased (inf --> 0.207745).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2248907
	speed: 0.0680s/iter; left time: 1776.4475s
	iters: 200, epoch: 2 | loss: 0.2446640
	speed: 0.0611s/iter; left time: 1589.7383s
Epoch: 2 cost time: 17.17199158668518
Epoch: 2, Steps: 265 Train Loss: 0.2337 (Forecasting Loss:0.2012 + XiCon Loss:3.2528 x Lambda(0.01)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1886
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1901360
	speed: 0.0651s/iter; left time: 1684.6339s
	iters: 200, epoch: 3 | loss: 0.1913668
	speed: 0.0641s/iter; left time: 1651.4763s
Epoch: 3 cost time: 17.086490631103516
Epoch: 3, Steps: 265 Train Loss: 0.1991 (Forecasting Loss:0.1670 + XiCon Loss:3.2134 x Lambda(0.01)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.2175
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1657352
	speed: 0.0649s/iter; left time: 1662.2084s
	iters: 200, epoch: 4 | loss: 0.1728956
	speed: 0.0629s/iter; left time: 1603.1256s
Epoch: 4 cost time: 17.031858921051025
Epoch: 4, Steps: 265 Train Loss: 0.1750 (Forecasting Loss:0.1429 + XiCon Loss:3.2135 x Lambda(0.01)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.2380
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1712308
	speed: 0.0675s/iter; left time: 1711.2364s
	iters: 200, epoch: 5 | loss: 0.1512497
	speed: 0.0635s/iter; left time: 1603.2772s
Epoch: 5 cost time: 17.788825750350952
Epoch: 5, Steps: 265 Train Loss: 0.1639 (Forecasting Loss:0.1318 + XiCon Loss:3.2110 x Lambda(0.01)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.2545
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1590253
	speed: 0.0731s/iter; left time: 1831.9560s
	iters: 200, epoch: 6 | loss: 0.1583546
	speed: 0.0752s/iter; left time: 1877.1150s
Epoch: 6 cost time: 19.312714099884033
Epoch: 6, Steps: 265 Train Loss: 0.1593 (Forecasting Loss:0.1271 + XiCon Loss:3.2122 x Lambda(0.01)), Vali MSE Loss: 0.2419 Test MSE Loss: 0.2566
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1545214
	speed: 0.0755s/iter; left time: 1873.3591s
	iters: 200, epoch: 7 | loss: 0.1665148
	speed: 0.0684s/iter; left time: 1689.8052s
Epoch: 7 cost time: 19.100775718688965
Epoch: 7, Steps: 265 Train Loss: 0.1571 (Forecasting Loss:0.1250 + XiCon Loss:3.2124 x Lambda(0.01)), Vali MSE Loss: 0.2433 Test MSE Loss: 0.2633
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1527314
	speed: 0.0722s/iter; left time: 1773.3712s
	iters: 200, epoch: 8 | loss: 0.1767806
	speed: 0.0704s/iter; left time: 1720.0157s
Epoch: 8 cost time: 18.534146547317505
Epoch: 8, Steps: 265 Train Loss: 0.1562 (Forecasting Loss:0.1241 + XiCon Loss:3.2103 x Lambda(0.01)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.2721
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1622393
	speed: 0.0746s/iter; left time: 1811.4978s
	iters: 200, epoch: 9 | loss: 0.1479616
	speed: 0.0724s/iter; left time: 1749.8749s
Epoch: 9 cost time: 19.37701439857483
Epoch: 9, Steps: 265 Train Loss: 0.1556 (Forecasting Loss:0.1235 + XiCon Loss:3.2104 x Lambda(0.01)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.2703
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1585371
	speed: 0.0734s/iter; left time: 1762.7654s
	iters: 200, epoch: 10 | loss: 0.1532743
	speed: 0.0737s/iter; left time: 1761.5627s
Epoch: 10 cost time: 19.415173768997192
Epoch: 10, Steps: 265 Train Loss: 0.1553 (Forecasting Loss:0.1232 + XiCon Loss:3.2099 x Lambda(0.01)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.2706
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1501106
	speed: 0.0793s/iter; left time: 1884.6345s
	iters: 200, epoch: 11 | loss: 0.1418950
	speed: 0.0719s/iter; left time: 1701.4193s
Epoch: 11 cost time: 19.586328268051147
Epoch: 11, Steps: 265 Train Loss: 0.1552 (Forecasting Loss:0.1231 + XiCon Loss:3.2117 x Lambda(0.01)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.2712
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09786616265773773, mae:0.23790982365608215, mape:0.5715989470481873, mspe:11.855196952819824 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.4668
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2535385
	speed: 0.0743s/iter; left time: 1961.1808s
	iters: 200, epoch: 1 | loss: 0.2441193
	speed: 0.0723s/iter; left time: 1901.7413s
Epoch: 1 cost time: 19.573825120925903
Epoch: 1, Steps: 265 Train Loss: 0.2573 (Forecasting Loss:0.2235 + XiCon Loss:3.3787 x Lambda(0.01)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1693
Validation loss decreased (inf --> 0.211387).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2584754
	speed: 0.0779s/iter; left time: 2034.9598s
	iters: 200, epoch: 2 | loss: 0.2171261
	speed: 0.0743s/iter; left time: 1934.9350s
Epoch: 2 cost time: 20.252052068710327
Epoch: 2, Steps: 265 Train Loss: 0.2328 (Forecasting Loss:0.2000 + XiCon Loss:3.2788 x Lambda(0.01)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1917
Validation loss decreased (0.211387 --> 0.210771).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2094739
	speed: 0.0708s/iter; left time: 1831.7644s
	iters: 200, epoch: 3 | loss: 0.1874574
	speed: 0.0668s/iter; left time: 1720.5590s
Epoch: 3 cost time: 18.020723342895508
Epoch: 3, Steps: 265 Train Loss: 0.1959 (Forecasting Loss:0.1636 + XiCon Loss:3.2242 x Lambda(0.01)), Vali MSE Loss: 0.2171 Test MSE Loss: 0.2156
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1631687
	speed: 0.0716s/iter; left time: 1833.3937s
	iters: 200, epoch: 4 | loss: 0.1603980
	speed: 0.0656s/iter; left time: 1674.4434s
Epoch: 4 cost time: 18.029666900634766
Epoch: 4, Steps: 265 Train Loss: 0.1722 (Forecasting Loss:0.1399 + XiCon Loss:3.2286 x Lambda(0.01)), Vali MSE Loss: 0.2238 Test MSE Loss: 0.2433
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1766113
	speed: 0.0729s/iter; left time: 1846.1243s
	iters: 200, epoch: 5 | loss: 0.1538260
	speed: 0.0645s/iter; left time: 1628.9964s
Epoch: 5 cost time: 17.989285945892334
Epoch: 5, Steps: 265 Train Loss: 0.1617 (Forecasting Loss:0.1294 + XiCon Loss:3.2332 x Lambda(0.01)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.2448
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1509521
	speed: 0.0686s/iter; left time: 1721.0485s
	iters: 200, epoch: 6 | loss: 0.1606234
	speed: 0.0652s/iter; left time: 1629.0635s
Epoch: 6 cost time: 17.941513061523438
Epoch: 6, Steps: 265 Train Loss: 0.1570 (Forecasting Loss:0.1246 + XiCon Loss:3.2350 x Lambda(0.01)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.2532
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1594583
	speed: 0.0711s/iter; left time: 1764.6254s
	iters: 200, epoch: 7 | loss: 0.1542703
	speed: 0.0649s/iter; left time: 1603.7248s
Epoch: 7 cost time: 17.879452228546143
Epoch: 7, Steps: 265 Train Loss: 0.1548 (Forecasting Loss:0.1224 + XiCon Loss:3.2383 x Lambda(0.01)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.2574
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1409175
	speed: 0.0696s/iter; left time: 1708.0797s
	iters: 200, epoch: 8 | loss: 0.1554738
	speed: 0.0686s/iter; left time: 1676.7409s
Epoch: 8 cost time: 18.236071586608887
Epoch: 8, Steps: 265 Train Loss: 0.1536 (Forecasting Loss:0.1212 + XiCon Loss:3.2375 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.2532
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1581353
	speed: 0.0686s/iter; left time: 1666.4189s
	iters: 200, epoch: 9 | loss: 0.1509322
	speed: 0.0664s/iter; left time: 1606.2422s
Epoch: 9 cost time: 18.07142472267151
Epoch: 9, Steps: 265 Train Loss: 0.1532 (Forecasting Loss:0.1208 + XiCon Loss:3.2393 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.2528
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1526515
	speed: 0.0717s/iter; left time: 1722.1554s
	iters: 200, epoch: 10 | loss: 0.1574578
	speed: 0.0641s/iter; left time: 1532.4391s
Epoch: 10 cost time: 17.900107383728027
Epoch: 10, Steps: 265 Train Loss: 0.1528 (Forecasting Loss:0.1204 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.2537
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1692487
	speed: 0.0687s/iter; left time: 1631.7382s
	iters: 200, epoch: 11 | loss: 0.1543607
	speed: 0.0672s/iter; left time: 1589.5358s
Epoch: 11 cost time: 17.83259916305542
Epoch: 11, Steps: 265 Train Loss: 0.1528 (Forecasting Loss:0.1204 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.2533
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1538248
	speed: 0.0677s/iter; left time: 1589.5863s
	iters: 200, epoch: 12 | loss: 0.1477001
	speed: 0.0648s/iter; left time: 1514.6609s
Epoch: 12 cost time: 17.660470008850098
Epoch: 12, Steps: 265 Train Loss: 0.1528 (Forecasting Loss:0.1204 + XiCon Loss:3.2391 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.2531
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.1203266829252243, mae:0.26311415433883667, mape:0.644489586353302, mspe:15.31207275390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.4120
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2548758
	speed: 0.0702s/iter; left time: 1854.3323s
	iters: 200, epoch: 1 | loss: 0.2258083
	speed: 0.0697s/iter; left time: 1832.8289s
Epoch: 1 cost time: 18.04112410545349
Epoch: 1, Steps: 265 Train Loss: 0.2563 (Forecasting Loss:0.2228 + XiCon Loss:3.3454 x Lambda(0.01)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1736
Validation loss decreased (inf --> 0.206899).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2285915
	speed: 0.0696s/iter; left time: 1818.6367s
	iters: 200, epoch: 2 | loss: 0.2276244
	speed: 0.0638s/iter; left time: 1659.9190s
Epoch: 2 cost time: 17.401325225830078
Epoch: 2, Steps: 265 Train Loss: 0.2257 (Forecasting Loss:0.1926 + XiCon Loss:3.3060 x Lambda(0.01)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2058888
	speed: 0.0707s/iter; left time: 1829.2882s
	iters: 200, epoch: 3 | loss: 0.1870808
	speed: 0.0644s/iter; left time: 1658.6659s
Epoch: 3 cost time: 17.486239433288574
Epoch: 3, Steps: 265 Train Loss: 0.1952 (Forecasting Loss:0.1625 + XiCon Loss:3.2648 x Lambda(0.01)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.2274
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1598976
	speed: 0.0627s/iter; left time: 1605.5325s
	iters: 200, epoch: 4 | loss: 0.1642217
	speed: 0.0612s/iter; left time: 1560.0452s
Epoch: 4 cost time: 16.412112951278687
Epoch: 4, Steps: 265 Train Loss: 0.1728 (Forecasting Loss:0.1402 + XiCon Loss:3.2581 x Lambda(0.01)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.2602
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1624432
	speed: 0.0658s/iter; left time: 1667.3833s
	iters: 200, epoch: 5 | loss: 0.1614194
	speed: 0.0582s/iter; left time: 1469.3224s
Epoch: 5 cost time: 16.613349199295044
Epoch: 5, Steps: 265 Train Loss: 0.1644 (Forecasting Loss:0.1318 + XiCon Loss:3.2589 x Lambda(0.01)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.2562
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1659417
	speed: 0.0673s/iter; left time: 1687.9753s
	iters: 200, epoch: 6 | loss: 0.1610135
	speed: 0.0619s/iter; left time: 1546.5492s
Epoch: 6 cost time: 17.049957275390625
Epoch: 6, Steps: 265 Train Loss: 0.1605 (Forecasting Loss:0.1279 + XiCon Loss:3.2604 x Lambda(0.01)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.2547
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1598949
	speed: 0.0652s/iter; left time: 1617.4926s
	iters: 200, epoch: 7 | loss: 0.1543766
	speed: 0.0609s/iter; left time: 1505.1018s
Epoch: 7 cost time: 16.853846549987793
Epoch: 7, Steps: 265 Train Loss: 0.1586 (Forecasting Loss:0.1259 + XiCon Loss:3.2608 x Lambda(0.01)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.2616
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1489472
	speed: 0.0635s/iter; left time: 1559.4621s
	iters: 200, epoch: 8 | loss: 0.1669343
	speed: 0.0640s/iter; left time: 1563.4331s
Epoch: 8 cost time: 16.814807415008545
Epoch: 8, Steps: 265 Train Loss: 0.1575 (Forecasting Loss:0.1249 + XiCon Loss:3.2616 x Lambda(0.01)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.2605
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1455083
	speed: 0.0669s/iter; left time: 1625.1219s
	iters: 200, epoch: 9 | loss: 0.1548182
	speed: 0.0634s/iter; left time: 1532.9058s
Epoch: 9 cost time: 17.16333270072937
Epoch: 9, Steps: 265 Train Loss: 0.1570 (Forecasting Loss:0.1244 + XiCon Loss:3.2609 x Lambda(0.01)), Vali MSE Loss: 0.2448 Test MSE Loss: 0.2612
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1669345
	speed: 0.0646s/iter; left time: 1551.7964s
	iters: 200, epoch: 10 | loss: 0.1498747
	speed: 0.0634s/iter; left time: 1517.2043s
Epoch: 10 cost time: 17.03936004638672
Epoch: 10, Steps: 265 Train Loss: 0.1566 (Forecasting Loss:0.1240 + XiCon Loss:3.2603 x Lambda(0.01)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.2618
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1536129
	speed: 0.0636s/iter; left time: 1511.2031s
	iters: 200, epoch: 11 | loss: 0.1418240
	speed: 0.0614s/iter; left time: 1453.2672s
Epoch: 11 cost time: 16.59555459022522
Epoch: 11, Steps: 265 Train Loss: 0.1567 (Forecasting Loss:0.1240 + XiCon Loss:3.2617 x Lambda(0.01)), Vali MSE Loss: 0.2448 Test MSE Loss: 0.2620
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10255708545446396, mae:0.24469999969005585, mape:0.5904030799865723, mspe:12.355189323425293 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.0859
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2351429
	speed: 0.0603s/iter; left time: 1593.0458s
	iters: 200, epoch: 1 | loss: 0.2234423
	speed: 0.0613s/iter; left time: 1612.1268s
Epoch: 1 cost time: 16.05602765083313
Epoch: 1, Steps: 265 Train Loss: 0.2569 (Forecasting Loss:0.2236 + XiCon Loss:3.3266 x Lambda(0.01)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.210801).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2334289
	speed: 0.0642s/iter; left time: 1678.0944s
	iters: 200, epoch: 2 | loss: 0.2230252
	speed: 0.0614s/iter; left time: 1599.2176s
Epoch: 2 cost time: 16.96979784965515
Epoch: 2, Steps: 265 Train Loss: 0.2299 (Forecasting Loss:0.1970 + XiCon Loss:3.2941 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1999
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2003863
	speed: 0.0658s/iter; left time: 1701.2989s
	iters: 200, epoch: 3 | loss: 0.1860104
	speed: 0.0639s/iter; left time: 1648.0193s
Epoch: 3 cost time: 17.254024982452393
Epoch: 3, Steps: 265 Train Loss: 0.1986 (Forecasting Loss:0.1661 + XiCon Loss:3.2542 x Lambda(0.01)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.2303
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1674570
	speed: 0.0618s/iter; left time: 1583.4020s
	iters: 200, epoch: 4 | loss: 0.1703346
	speed: 0.0899s/iter; left time: 2292.4571s
Epoch: 4 cost time: 21.21214246749878
Epoch: 4, Steps: 265 Train Loss: 0.1767 (Forecasting Loss:0.1440 + XiCon Loss:3.2644 x Lambda(0.01)), Vali MSE Loss: 0.2383 Test MSE Loss: 0.2481
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1593072
	speed: 0.0473s/iter; left time: 1198.4205s
	iters: 200, epoch: 5 | loss: 0.1700338
	speed: 0.0585s/iter; left time: 1475.4483s
Epoch: 5 cost time: 14.800580501556396
Epoch: 5, Steps: 265 Train Loss: 0.1672 (Forecasting Loss:0.1345 + XiCon Loss:3.2672 x Lambda(0.01)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.2628
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1595378
	speed: 0.0653s/iter; left time: 1638.6443s
	iters: 200, epoch: 6 | loss: 0.1612836
	speed: 0.0629s/iter; left time: 1572.0940s
Epoch: 6 cost time: 16.637537479400635
Epoch: 6, Steps: 265 Train Loss: 0.1633 (Forecasting Loss:0.1306 + XiCon Loss:3.2728 x Lambda(0.01)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.2667
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1628056
	speed: 0.0655s/iter; left time: 1625.8373s
	iters: 200, epoch: 7 | loss: 0.1601556
	speed: 0.0600s/iter; left time: 1482.7397s
Epoch: 7 cost time: 16.645434856414795
Epoch: 7, Steps: 265 Train Loss: 0.1610 (Forecasting Loss:0.1283 + XiCon Loss:3.2741 x Lambda(0.01)), Vali MSE Loss: 0.2413 Test MSE Loss: 0.2736
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1701076
	speed: 0.0685s/iter; left time: 1681.5818s
	iters: 200, epoch: 8 | loss: 0.1567269
	speed: 0.0616s/iter; left time: 1504.8840s
Epoch: 8 cost time: 17.250494718551636
Epoch: 8, Steps: 265 Train Loss: 0.1603 (Forecasting Loss:0.1275 + XiCon Loss:3.2758 x Lambda(0.01)), Vali MSE Loss: 0.2384 Test MSE Loss: 0.2695
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1626909
	speed: 0.0666s/iter; left time: 1616.4664s
	iters: 200, epoch: 9 | loss: 0.1551418
	speed: 0.0622s/iter; left time: 1503.9094s
Epoch: 9 cost time: 16.80688500404358
Epoch: 9, Steps: 265 Train Loss: 0.1597 (Forecasting Loss:0.1270 + XiCon Loss:3.2736 x Lambda(0.01)), Vali MSE Loss: 0.2389 Test MSE Loss: 0.2700
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1625954
	speed: 0.0672s/iter; left time: 1614.3004s
	iters: 200, epoch: 10 | loss: 0.1540222
	speed: 0.0600s/iter; left time: 1435.8423s
Epoch: 10 cost time: 16.99102282524109
Epoch: 10, Steps: 265 Train Loss: 0.1596 (Forecasting Loss:0.1268 + XiCon Loss:3.2737 x Lambda(0.01)), Vali MSE Loss: 0.2392 Test MSE Loss: 0.2724
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1628903
	speed: 0.0641s/iter; left time: 1523.0220s
	iters: 200, epoch: 11 | loss: 0.1503453
	speed: 0.0663s/iter; left time: 1566.9110s
Epoch: 11 cost time: 17.821016550064087
Epoch: 11, Steps: 265 Train Loss: 0.1595 (Forecasting Loss:0.1267 + XiCon Loss:3.2749 x Lambda(0.01)), Vali MSE Loss: 0.2390 Test MSE Loss: 0.2737
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09902133792638779, mae:0.23915638029575348, mape:0.5788998007774353, mspe:12.196664810180664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.3744
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2413718
	speed: 0.0770s/iter; left time: 2033.4599s
	iters: 200, epoch: 1 | loss: 0.2462737
	speed: 0.0695s/iter; left time: 1826.9237s
Epoch: 1 cost time: 19.25142765045166
Epoch: 1, Steps: 265 Train Loss: 0.2563 (Forecasting Loss:0.2226 + XiCon Loss:3.3695 x Lambda(0.01)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1718
Validation loss decreased (inf --> 0.206843).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2202490
	speed: 0.0794s/iter; left time: 2075.8878s
	iters: 200, epoch: 2 | loss: 0.2113300
	speed: 0.0658s/iter; left time: 1713.7711s
Epoch: 2 cost time: 19.041158437728882
Epoch: 2, Steps: 265 Train Loss: 0.2292 (Forecasting Loss:0.1961 + XiCon Loss:3.3085 x Lambda(0.01)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1964
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1902097
	speed: 0.0777s/iter; left time: 2009.9551s
	iters: 200, epoch: 3 | loss: 0.1992454
	speed: 0.0723s/iter; left time: 1863.6720s
Epoch: 3 cost time: 19.810707092285156
Epoch: 3, Steps: 265 Train Loss: 0.1934 (Forecasting Loss:0.1607 + XiCon Loss:3.2713 x Lambda(0.01)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.2274
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1747581
	speed: 0.0726s/iter; left time: 1858.6720s
	iters: 200, epoch: 4 | loss: 0.1589955
	speed: 0.0682s/iter; left time: 1738.5499s
Epoch: 4 cost time: 18.682539463043213
Epoch: 4, Steps: 265 Train Loss: 0.1711 (Forecasting Loss:0.1386 + XiCon Loss:3.2513 x Lambda(0.01)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.2365
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1734564
	speed: 0.0778s/iter; left time: 1972.7877s
	iters: 200, epoch: 5 | loss: 0.1552814
	speed: 0.0651s/iter; left time: 1642.9318s
Epoch: 5 cost time: 18.841659545898438
Epoch: 5, Steps: 265 Train Loss: 0.1618 (Forecasting Loss:0.1294 + XiCon Loss:3.2415 x Lambda(0.01)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.2459
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1568977
	speed: 0.0772s/iter; left time: 1936.0906s
	iters: 200, epoch: 6 | loss: 0.1575452
	speed: 0.0709s/iter; left time: 1770.5997s
Epoch: 6 cost time: 19.70703935623169
Epoch: 6, Steps: 265 Train Loss: 0.1577 (Forecasting Loss:0.1253 + XiCon Loss:3.2406 x Lambda(0.01)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.2452
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1527546
	speed: 0.0784s/iter; left time: 1945.1718s
	iters: 200, epoch: 7 | loss: 0.1623461
	speed: 0.0742s/iter; left time: 1833.8053s
Epoch: 7 cost time: 20.23342490196228
Epoch: 7, Steps: 265 Train Loss: 0.1558 (Forecasting Loss:0.1234 + XiCon Loss:3.2393 x Lambda(0.01)), Vali MSE Loss: 0.2286 Test MSE Loss: 0.2474
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1490719
	speed: 0.0792s/iter; left time: 1943.4308s
	iters: 200, epoch: 8 | loss: 0.1568992
	speed: 0.0685s/iter; left time: 1675.2907s
Epoch: 8 cost time: 19.42896866798401
Epoch: 8, Steps: 265 Train Loss: 0.1549 (Forecasting Loss:0.1225 + XiCon Loss:3.2401 x Lambda(0.01)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.2482
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1485891
	speed: 0.0770s/iter; left time: 1870.6816s
	iters: 200, epoch: 9 | loss: 0.1739908
	speed: 0.0729s/iter; left time: 1762.4079s
Epoch: 9 cost time: 19.851195335388184
Epoch: 9, Steps: 265 Train Loss: 0.1544 (Forecasting Loss:0.1220 + XiCon Loss:3.2382 x Lambda(0.01)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.2497
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1514574
	speed: 0.0768s/iter; left time: 1844.2640s
	iters: 200, epoch: 10 | loss: 0.1518824
	speed: 0.0716s/iter; left time: 1711.5406s
Epoch: 10 cost time: 19.388506174087524
Epoch: 10, Steps: 265 Train Loss: 0.1542 (Forecasting Loss:0.1218 + XiCon Loss:3.2390 x Lambda(0.01)), Vali MSE Loss: 0.2290 Test MSE Loss: 0.2500
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1534130
	speed: 0.0754s/iter; left time: 1790.2043s
	iters: 200, epoch: 11 | loss: 0.1483510
	speed: 0.0679s/iter; left time: 1606.7577s
Epoch: 11 cost time: 18.988320112228394
Epoch: 11, Steps: 265 Train Loss: 0.1541 (Forecasting Loss:0.1217 + XiCon Loss:3.2389 x Lambda(0.01)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.2497
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10094670951366425, mae:0.24266578257083893, mape:0.5894107222557068, mspe:12.552923202514648 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1041+-0.01145, MAE:0.2455+-0.01267, MAPE:0.5950+-0.03571, MSPE:12.8544+-1.73514, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.9049
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4597937
	speed: 0.0993s/iter; left time: 2532.8024s
	iters: 200, epoch: 1 | loss: 0.4942798
	speed: 0.0858s/iter; left time: 2178.5020s
Epoch: 1 cost time: 23.429824113845825
Epoch: 1, Steps: 256 Train Loss: 0.4681 (Forecasting Loss:0.4343 + XiCon Loss:3.3763 x Lambda(0.01)), Vali MSE Loss: 0.4131 Test MSE Loss: 0.3830
Validation loss decreased (inf --> 0.413082).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3595773
	speed: 0.0880s/iter; left time: 2220.3211s
	iters: 200, epoch: 2 | loss: 0.3664336
	speed: 0.0897s/iter; left time: 2255.2026s
Epoch: 2 cost time: 22.552719593048096
Epoch: 2, Steps: 256 Train Loss: 0.3730 (Forecasting Loss:0.3394 + XiCon Loss:3.3655 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3039
Validation loss decreased (0.413082 --> 0.327803).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3499240
	speed: 0.0924s/iter; left time: 2308.0158s
	iters: 200, epoch: 3 | loss: 0.3556211
	speed: 0.0878s/iter; left time: 2186.4607s
Epoch: 3 cost time: 23.263097047805786
Epoch: 3, Steps: 256 Train Loss: 0.3491 (Forecasting Loss:0.3156 + XiCon Loss:3.3520 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.3006
Validation loss decreased (0.327803 --> 0.320466).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3545968
	speed: 0.0976s/iter; left time: 2413.0862s
	iters: 200, epoch: 4 | loss: 0.3490764
	speed: 0.0812s/iter; left time: 2000.7180s
Epoch: 4 cost time: 22.302197694778442
Epoch: 4, Steps: 256 Train Loss: 0.3465 (Forecasting Loss:0.3130 + XiCon Loss:3.3507 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.3001
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3566171
	speed: 0.0818s/iter; left time: 2001.2681s
	iters: 200, epoch: 5 | loss: 0.3667913
	speed: 0.0788s/iter; left time: 1920.4728s
Epoch: 5 cost time: 20.431337118148804
Epoch: 5, Steps: 256 Train Loss: 0.3455 (Forecasting Loss:0.3120 + XiCon Loss:3.3495 x Lambda(0.01)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3353120
	speed: 0.0833s/iter; left time: 2018.6693s
	iters: 200, epoch: 6 | loss: 0.3198712
	speed: 0.0781s/iter; left time: 1884.8413s
Epoch: 6 cost time: 20.386733531951904
Epoch: 6, Steps: 256 Train Loss: 0.3450 (Forecasting Loss:0.3115 + XiCon Loss:3.3491 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2996
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3633181
	speed: 0.0803s/iter; left time: 1923.6577s
	iters: 200, epoch: 7 | loss: 0.3339209
	speed: 0.0783s/iter; left time: 1869.5647s
Epoch: 7 cost time: 20.112386226654053
Epoch: 7, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3113 + XiCon Loss:3.3493 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3421902
	speed: 0.0828s/iter; left time: 1963.0740s
	iters: 200, epoch: 8 | loss: 0.3270984
	speed: 0.0788s/iter; left time: 1860.5056s
Epoch: 8 cost time: 20.53096318244934
Epoch: 8, Steps: 256 Train Loss: 0.3447 (Forecasting Loss:0.3113 + XiCon Loss:3.3497 x Lambda(0.01)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2996
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3745891
	speed: 0.0818s/iter; left time: 1917.5735s
	iters: 200, epoch: 9 | loss: 0.3463178
	speed: 0.0782s/iter; left time: 1825.2149s
Epoch: 9 cost time: 20.500696182250977
Epoch: 9, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3501 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3491177
	speed: 0.0830s/iter; left time: 1925.3831s
	iters: 200, epoch: 10 | loss: 0.3560654
	speed: 0.0796s/iter; left time: 1838.6502s
Epoch: 10 cost time: 20.8849196434021
Epoch: 10, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3487 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3549280
	speed: 0.0803s/iter; left time: 1841.2685s
	iters: 200, epoch: 11 | loss: 0.3616199
	speed: 0.0793s/iter; left time: 1810.5934s
Epoch: 11 cost time: 20.379332065582275
Epoch: 11, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3501 x Lambda(0.01)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2996
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3509156
	speed: 0.0821s/iter; left time: 1863.3576s
	iters: 200, epoch: 12 | loss: 0.3345410
	speed: 0.0777s/iter; left time: 1755.4278s
Epoch: 12 cost time: 20.393964052200317
Epoch: 12, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3496 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3523008
	speed: 0.0818s/iter; left time: 1834.5939s
	iters: 200, epoch: 13 | loss: 0.3430568
	speed: 0.0761s/iter; left time: 1699.0941s
Epoch: 13 cost time: 20.337932586669922
Epoch: 13, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3503 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2269541323184967, mae:0.3742712438106537, mape:0.7468464970588684, mspe:18.98113441467285 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.9394
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.5325575
	speed: 0.0827s/iter; left time: 2110.1728s
	iters: 200, epoch: 1 | loss: 0.4550280
	speed: 0.0795s/iter; left time: 2018.8130s
Epoch: 1 cost time: 20.65962314605713
Epoch: 1, Steps: 256 Train Loss: 0.4691 (Forecasting Loss:0.4349 + XiCon Loss:3.4199 x Lambda(0.01)), Vali MSE Loss: 0.4158 Test MSE Loss: 0.3855
Validation loss decreased (inf --> 0.415774).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3550091
	speed: 0.0829s/iter; left time: 2092.5294s
	iters: 200, epoch: 2 | loss: 0.3408516
	speed: 0.0785s/iter; left time: 1974.3087s
Epoch: 2 cost time: 20.561752796173096
Epoch: 2, Steps: 256 Train Loss: 0.3798 (Forecasting Loss:0.3460 + XiCon Loss:3.3737 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2977
Validation loss decreased (0.415774 --> 0.316163).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3586736
	speed: 0.0826s/iter; left time: 2062.9078s
	iters: 200, epoch: 3 | loss: 0.3504468
	speed: 0.0758s/iter; left time: 1885.6286s
Epoch: 3 cost time: 22.06974482536316
Epoch: 3, Steps: 256 Train Loss: 0.3509 (Forecasting Loss:0.3174 + XiCon Loss:3.3496 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2951
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3484678
	speed: 0.0619s/iter; left time: 1531.6688s
	iters: 200, epoch: 4 | loss: 0.3509644
	speed: 0.0708s/iter; left time: 1745.0545s
Epoch: 4 cost time: 17.582082748413086
Epoch: 4, Steps: 256 Train Loss: 0.3479 (Forecasting Loss:0.3145 + XiCon Loss:3.3474 x Lambda(0.01)), Vali MSE Loss: 0.3156 Test MSE Loss: 0.2944
Validation loss decreased (0.316163 --> 0.315619).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3901721
	speed: 0.0831s/iter; left time: 2033.7666s
	iters: 200, epoch: 5 | loss: 0.3606284
	speed: 0.0749s/iter; left time: 1826.6776s
Epoch: 5 cost time: 20.73996067047119
Epoch: 5, Steps: 256 Train Loss: 0.3469 (Forecasting Loss:0.3134 + XiCon Loss:3.3468 x Lambda(0.01)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3541721
	speed: 0.0910s/iter; left time: 2204.2326s
	iters: 200, epoch: 6 | loss: 0.3350489
	speed: 0.0874s/iter; left time: 2109.0101s
Epoch: 6 cost time: 23.00162410736084
Epoch: 6, Steps: 256 Train Loss: 0.3464 (Forecasting Loss:0.3129 + XiCon Loss:3.3451 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2940
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3382017
	speed: 0.0944s/iter; left time: 2261.5968s
	iters: 200, epoch: 7 | loss: 0.3496911
	speed: 0.0878s/iter; left time: 2094.9402s
Epoch: 7 cost time: 23.43546199798584
Epoch: 7, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3457 x Lambda(0.01)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2940
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3680489
	speed: 0.0912s/iter; left time: 2161.7586s
	iters: 200, epoch: 8 | loss: 0.3397509
	speed: 0.0936s/iter; left time: 2210.0506s
Epoch: 8 cost time: 23.674835205078125
Epoch: 8, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3451 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3268842
	speed: 0.0952s/iter; left time: 2232.5516s
	iters: 200, epoch: 9 | loss: 0.3670520
	speed: 0.0894s/iter; left time: 2088.0665s
Epoch: 9 cost time: 23.67386555671692
Epoch: 9, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3449 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3760346
	speed: 0.0928s/iter; left time: 2151.7302s
	iters: 200, epoch: 10 | loss: 0.3375864
	speed: 0.0841s/iter; left time: 1943.3811s
Epoch: 10 cost time: 22.638338804244995
Epoch: 10, Steps: 256 Train Loss: 0.3458 (Forecasting Loss:0.3124 + XiCon Loss:3.3455 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3629217
	speed: 0.0967s/iter; left time: 2218.4517s
	iters: 200, epoch: 11 | loss: 0.3477457
	speed: 0.0923s/iter; left time: 2108.8282s
Epoch: 11 cost time: 24.066668033599854
Epoch: 11, Steps: 256 Train Loss: 0.3458 (Forecasting Loss:0.3124 + XiCon Loss:3.3438 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3275628
	speed: 0.0939s/iter; left time: 2129.8890s
	iters: 200, epoch: 12 | loss: 0.3375014
	speed: 0.0900s/iter; left time: 2032.3802s
Epoch: 12 cost time: 23.522507667541504
Epoch: 12, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3452 x Lambda(0.01)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.2939
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3403608
	speed: 0.0895s/iter; left time: 2008.1119s
	iters: 200, epoch: 13 | loss: 0.3806778
	speed: 0.0837s/iter; left time: 1869.7757s
Epoch: 13 cost time: 22.18496084213257
Epoch: 13, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3450 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3473842
	speed: 0.0885s/iter; left time: 1961.3615s
	iters: 200, epoch: 14 | loss: 0.3403091
	speed: 0.0886s/iter; left time: 1955.3549s
Epoch: 14 cost time: 22.35210609436035
Epoch: 14, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3468 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2939
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22010529041290283, mae:0.3687762916088104, mape:0.7495588660240173, mspe:19.5954532623291 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.3821
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4388419
	speed: 0.0760s/iter; left time: 1938.4227s
	iters: 200, epoch: 1 | loss: 0.4396994
	speed: 0.0720s/iter; left time: 1827.8292s
Epoch: 1 cost time: 18.835072994232178
Epoch: 1, Steps: 256 Train Loss: 0.4657 (Forecasting Loss:0.4320 + XiCon Loss:3.3747 x Lambda(0.01)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3812
Validation loss decreased (inf --> 0.411456).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3664501
	speed: 0.0754s/iter; left time: 1904.4897s
	iters: 200, epoch: 2 | loss: 0.3539750
	speed: 0.0773s/iter; left time: 1944.5399s
Epoch: 2 cost time: 19.415165662765503
Epoch: 2, Steps: 256 Train Loss: 0.3771 (Forecasting Loss:0.3436 + XiCon Loss:3.3538 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.3001
Validation loss decreased (0.411456 --> 0.330536).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3473405
	speed: 0.0777s/iter; left time: 1940.8262s
	iters: 200, epoch: 3 | loss: 0.3369035
	speed: 0.0722s/iter; left time: 1797.0314s
Epoch: 3 cost time: 19.030179738998413
Epoch: 3, Steps: 256 Train Loss: 0.3505 (Forecasting Loss:0.3171 + XiCon Loss:3.3410 x Lambda(0.01)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2960
Validation loss decreased (0.330536 --> 0.321183).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3309547
	speed: 0.0761s/iter; left time: 1882.6350s
	iters: 200, epoch: 4 | loss: 0.3603210
	speed: 0.0739s/iter; left time: 1821.5894s
Epoch: 4 cost time: 19.085658073425293
Epoch: 4, Steps: 256 Train Loss: 0.3479 (Forecasting Loss:0.3145 + XiCon Loss:3.3408 x Lambda(0.01)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.2969
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3740544
	speed: 0.0749s/iter; left time: 1833.1686s
	iters: 200, epoch: 5 | loss: 0.3529111
	speed: 0.0743s/iter; left time: 1811.1934s
Epoch: 5 cost time: 19.107597589492798
Epoch: 5, Steps: 256 Train Loss: 0.3469 (Forecasting Loss:0.3135 + XiCon Loss:3.3411 x Lambda(0.01)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2963
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3244809
	speed: 0.0789s/iter; left time: 1912.0987s
	iters: 200, epoch: 6 | loss: 0.3450604
	speed: 0.0701s/iter; left time: 1690.9565s
Epoch: 6 cost time: 18.990966796875
Epoch: 6, Steps: 256 Train Loss: 0.3464 (Forecasting Loss:0.3130 + XiCon Loss:3.3375 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2966
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3382588
	speed: 0.0752s/iter; left time: 1803.3627s
	iters: 200, epoch: 7 | loss: 0.3520673
	speed: 0.0750s/iter; left time: 1789.2685s
Epoch: 7 cost time: 19.221081495285034
Epoch: 7, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3128 + XiCon Loss:3.3401 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2967
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3425137
	speed: 0.0736s/iter; left time: 1744.1418s
	iters: 200, epoch: 8 | loss: 0.3405903
	speed: 0.0705s/iter; left time: 1663.5540s
Epoch: 8 cost time: 18.314512252807617
Epoch: 8, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3378 x Lambda(0.01)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2965
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3355669
	speed: 0.0745s/iter; left time: 1747.5866s
	iters: 200, epoch: 9 | loss: 0.3357329
	speed: 0.0789s/iter; left time: 1843.5875s
Epoch: 9 cost time: 19.781516551971436
Epoch: 9, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3392 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3766266
	speed: 0.0828s/iter; left time: 1920.6420s
	iters: 200, epoch: 10 | loss: 0.3593146
	speed: 0.0775s/iter; left time: 1790.4069s
Epoch: 10 cost time: 20.53360414505005
Epoch: 10, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3390 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2965
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3748458
	speed: 0.0826s/iter; left time: 1894.8325s
	iters: 200, epoch: 11 | loss: 0.3622198
	speed: 0.0764s/iter; left time: 1745.8681s
Epoch: 11 cost time: 20.31676149368286
Epoch: 11, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3403 x Lambda(0.01)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2965
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3191658
	speed: 0.0838s/iter; left time: 1901.1220s
	iters: 200, epoch: 12 | loss: 0.3360858
	speed: 0.0789s/iter; left time: 1782.4837s
Epoch: 12 cost time: 20.811436891555786
Epoch: 12, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3402 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3640258
	speed: 0.0845s/iter; left time: 1895.3144s
	iters: 200, epoch: 13 | loss: 0.3593566
	speed: 0.0790s/iter; left time: 1765.0349s
Epoch: 13 cost time: 20.788288593292236
Epoch: 13, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3400 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22188441455364227, mae:0.37006738781929016, mape:0.7376909255981445, mspe:18.823867797851562 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.0636
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4658884
	speed: 0.0896s/iter; left time: 2284.1257s
	iters: 200, epoch: 1 | loss: 0.4497345
	speed: 0.0895s/iter; left time: 2274.3857s
Epoch: 1 cost time: 22.514445543289185
Epoch: 1, Steps: 256 Train Loss: 0.4657 (Forecasting Loss:0.4319 + XiCon Loss:3.3817 x Lambda(0.01)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3766
Validation loss decreased (inf --> 0.405968).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3620113
	speed: 0.0925s/iter; left time: 2334.0738s
	iters: 200, epoch: 2 | loss: 0.3726895
	speed: 0.0876s/iter; left time: 2203.4499s
Epoch: 2 cost time: 23.019168615341187
Epoch: 2, Steps: 256 Train Loss: 0.3785 (Forecasting Loss:0.3449 + XiCon Loss:3.3532 x Lambda(0.01)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3028
Validation loss decreased (0.405968 --> 0.338513).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3530536
	speed: 0.0858s/iter; left time: 2144.3413s
	iters: 200, epoch: 3 | loss: 0.3483049
	speed: 0.0850s/iter; left time: 2114.4177s
Epoch: 3 cost time: 21.827255964279175
Epoch: 3, Steps: 256 Train Loss: 0.3564 (Forecasting Loss:0.3231 + XiCon Loss:3.3373 x Lambda(0.01)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.2995
Validation loss decreased (0.338513 --> 0.334844).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3656764
	speed: 0.0902s/iter; left time: 2230.7598s
	iters: 200, epoch: 4 | loss: 0.3595840
	speed: 0.0878s/iter; left time: 2161.8930s
Epoch: 4 cost time: 22.63243055343628
Epoch: 4, Steps: 256 Train Loss: 0.3528 (Forecasting Loss:0.3195 + XiCon Loss:3.3301 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2985
Validation loss decreased (0.334844 --> 0.332081).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3502491
	speed: 0.0896s/iter; left time: 2191.9702s
	iters: 200, epoch: 5 | loss: 0.3554369
	speed: 0.0818s/iter; left time: 1994.5896s
Epoch: 5 cost time: 22.03890609741211
Epoch: 5, Steps: 256 Train Loss: 0.3514 (Forecasting Loss:0.3181 + XiCon Loss:3.3271 x Lambda(0.01)), Vali MSE Loss: 0.3302 Test MSE Loss: 0.2977
Validation loss decreased (0.332081 --> 0.330214).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3400292
	speed: 0.0902s/iter; left time: 2185.5729s
	iters: 200, epoch: 6 | loss: 0.3630058
	speed: 0.0843s/iter; left time: 2033.7530s
Epoch: 6 cost time: 22.130436182022095
Epoch: 6, Steps: 256 Train Loss: 0.3507 (Forecasting Loss:0.3175 + XiCon Loss:3.3237 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2976
Validation loss decreased (0.330214 --> 0.329506).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3204943
	speed: 0.0878s/iter; left time: 2103.9502s
	iters: 200, epoch: 7 | loss: 0.3404863
	speed: 0.0829s/iter; left time: 1979.3001s
Epoch: 7 cost time: 21.883582830429077
Epoch: 7, Steps: 256 Train Loss: 0.3505 (Forecasting Loss:0.3172 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3573625
	speed: 0.1159s/iter; left time: 2748.1167s
	iters: 200, epoch: 8 | loss: 0.3497944
	speed: 0.0941s/iter; left time: 2222.3357s
Epoch: 8 cost time: 24.943212270736694
Epoch: 8, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3234 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
Validation loss decreased (0.329506 --> 0.329280).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3360337
	speed: 0.0958s/iter; left time: 2247.1746s
	iters: 200, epoch: 9 | loss: 0.3401926
	speed: 0.0864s/iter; left time: 2018.6881s
Epoch: 9 cost time: 23.357270002365112
Epoch: 9, Steps: 256 Train Loss: 0.3502 (Forecasting Loss:0.3169 + XiCon Loss:3.3234 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
Validation loss decreased (0.329280 --> 0.329170).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3717243
	speed: 0.0919s/iter; left time: 2131.5869s
	iters: 200, epoch: 10 | loss: 0.3374979
	speed: 0.0627s/iter; left time: 1448.3749s
Epoch: 10 cost time: 20.309443950653076
Epoch: 10, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3540396
	speed: 0.0871s/iter; left time: 1999.1247s
	iters: 200, epoch: 11 | loss: 0.3572366
	speed: 0.0838s/iter; left time: 1914.3379s
Epoch: 11 cost time: 21.812085151672363
Epoch: 11, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329170 --> 0.329001).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3290202
	speed: 0.0702s/iter; left time: 1591.9703s
	iters: 200, epoch: 12 | loss: 0.3465213
	speed: 0.0843s/iter; left time: 1903.2441s
Epoch: 12 cost time: 20.10244607925415
Epoch: 12, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3406719
	speed: 0.0849s/iter; left time: 1905.2693s
	iters: 200, epoch: 13 | loss: 0.3673925
	speed: 0.0798s/iter; left time: 1782.7833s
Epoch: 13 cost time: 21.217814445495605
Epoch: 13, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3219 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3565237
	speed: 0.0889s/iter; left time: 1971.0420s
	iters: 200, epoch: 14 | loss: 0.3407328
	speed: 0.0839s/iter; left time: 1851.8489s
Epoch: 14 cost time: 21.690192461013794
Epoch: 14, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3489656
	speed: 0.0837s/iter; left time: 1834.6434s
	iters: 200, epoch: 15 | loss: 0.3449321
	speed: 0.0853s/iter; left time: 1861.6694s
Epoch: 15 cost time: 19.774880170822144
Epoch: 15, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329001 --> 0.328994).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3452477
	speed: 0.0883s/iter; left time: 1913.0259s
	iters: 200, epoch: 16 | loss: 0.3262837
	speed: 0.0847s/iter; left time: 1826.0823s
Epoch: 16 cost time: 21.82958197593689
Epoch: 16, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.328994 --> 0.328957).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3625050
	speed: 0.0846s/iter; left time: 1810.5084s
	iters: 200, epoch: 17 | loss: 0.3503116
	speed: 0.0822s/iter; left time: 1751.1767s
Epoch: 17 cost time: 21.29415464401245
Epoch: 17, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3227 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.3364891
	speed: 0.0878s/iter; left time: 1857.4186s
	iters: 200, epoch: 18 | loss: 0.3304096
	speed: 0.0813s/iter; left time: 1710.5591s
Epoch: 18 cost time: 21.43782949447632
Epoch: 18, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3235 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328957 --> 0.328938).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.3547234
	speed: 0.0894s/iter; left time: 1866.8724s
	iters: 200, epoch: 19 | loss: 0.3417090
	speed: 0.0830s/iter; left time: 1726.4226s
Epoch: 19 cost time: 21.93996572494507
Epoch: 19, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.3390868
	speed: 0.0829s/iter; left time: 1711.1281s
	iters: 200, epoch: 20 | loss: 0.3409250
	speed: 0.0732s/iter; left time: 1503.6759s
Epoch: 20 cost time: 19.898905515670776
Epoch: 20, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.3587425
	speed: 0.0792s/iter; left time: 1614.2763s
	iters: 200, epoch: 21 | loss: 0.3537737
	speed: 0.0819s/iter; left time: 1661.8941s
Epoch: 21 cost time: 20.494159936904907
Epoch: 21, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3233 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328938 --> 0.328892).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.3559005
	speed: 0.0822s/iter; left time: 1654.8393s
	iters: 200, epoch: 22 | loss: 0.3560357
	speed: 0.0781s/iter; left time: 1564.0268s
Epoch: 22 cost time: 20.255239009857178
Epoch: 22, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3167 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.3392791
	speed: 0.0829s/iter; left time: 1648.0680s
	iters: 200, epoch: 23 | loss: 0.3523065
	speed: 0.0766s/iter; left time: 1513.4394s
Epoch: 23 cost time: 20.15528178215027
Epoch: 23, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3218 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.3604488
	speed: 0.0814s/iter; left time: 1596.7665s
	iters: 200, epoch: 24 | loss: 0.3370081
	speed: 0.0771s/iter; left time: 1504.9803s
Epoch: 24 cost time: 20.27163076400757
Epoch: 24, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.3560482
	speed: 0.0786s/iter; left time: 1521.8077s
	iters: 200, epoch: 25 | loss: 0.3849899
	speed: 0.0781s/iter; left time: 1503.7191s
Epoch: 25 cost time: 20.203423976898193
Epoch: 25, Steps: 256 Train Loss: 0.3502 (Forecasting Loss:0.3169 + XiCon Loss:3.3228 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.3553913
	speed: 0.0826s/iter; left time: 1578.4678s
	iters: 200, epoch: 26 | loss: 0.3426819
	speed: 0.0741s/iter; left time: 1408.1875s
Epoch: 26 cost time: 19.775443077087402
Epoch: 26, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3228 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328892 --> 0.328871).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.3648277
	speed: 0.0826s/iter; left time: 1556.1818s
	iters: 200, epoch: 27 | loss: 0.3438714
	speed: 0.0787s/iter; left time: 1475.3441s
Epoch: 27 cost time: 20.64738130569458
Epoch: 27, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3237 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.3459507
	speed: 0.0791s/iter; left time: 1471.0737s
	iters: 200, epoch: 28 | loss: 0.3584677
	speed: 0.0767s/iter; left time: 1418.3454s
Epoch: 28 cost time: 19.829307317733765
Epoch: 28, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3224 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.3475557
	speed: 0.0841s/iter; left time: 1542.5009s
	iters: 200, epoch: 29 | loss: 0.3568515
	speed: 0.0728s/iter; left time: 1327.6582s
Epoch: 29 cost time: 19.944325923919678
Epoch: 29, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3208 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.3813757
	speed: 0.0795s/iter; left time: 1437.1486s
	iters: 200, epoch: 30 | loss: 0.3556789
	speed: 0.0735s/iter; left time: 1321.9996s
Epoch: 30 cost time: 19.77778387069702
Epoch: 30, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3221 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.3435669
	speed: 0.0827s/iter; left time: 1473.3764s
	iters: 200, epoch: 31 | loss: 0.3415793
	speed: 0.0754s/iter; left time: 1336.5501s
Epoch: 31 cost time: 20.166146278381348
Epoch: 31, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3222 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.3466884
	speed: 0.0816s/iter; left time: 1433.4309s
	iters: 200, epoch: 32 | loss: 0.3474199
	speed: 0.0789s/iter; left time: 1377.3184s
Epoch: 32 cost time: 20.239531993865967
Epoch: 32, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3233 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2974
Validation loss decreased (0.328871 --> 0.328776).  Saving model ...
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.3436505
	speed: 0.0807s/iter; left time: 1396.8825s
	iters: 200, epoch: 33 | loss: 0.3431856
	speed: 0.0783s/iter; left time: 1346.6262s
Epoch: 33 cost time: 20.115507125854492
Epoch: 33, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3223 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.3387202
	speed: 0.0820s/iter; left time: 1397.7705s
	iters: 200, epoch: 34 | loss: 0.3207747
	speed: 0.0826s/iter; left time: 1400.7278s
Epoch: 34 cost time: 21.16512894630432
Epoch: 34, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3223 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.3439185
	speed: 0.0879s/iter; left time: 1476.0030s
	iters: 200, epoch: 35 | loss: 0.3434624
	speed: 0.0815s/iter; left time: 1361.3695s
Epoch: 35 cost time: 21.567161321640015
Epoch: 35, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3243 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.3372617
	speed: 0.0837s/iter; left time: 1384.1907s
	iters: 200, epoch: 36 | loss: 0.3293746
	speed: 0.0848s/iter; left time: 1394.6588s
Epoch: 36 cost time: 21.647077560424805
Epoch: 36, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3218 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.3318726
	speed: 0.0857s/iter; left time: 1395.0135s
	iters: 200, epoch: 37 | loss: 0.3298317
	speed: 0.0798s/iter; left time: 1291.8417s
Epoch: 37 cost time: 21.29174017906189
Epoch: 37, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3167 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.3425496
	speed: 0.0891s/iter; left time: 1428.0301s
	iters: 200, epoch: 38 | loss: 0.3564155
	speed: 0.0811s/iter; left time: 1292.0200s
Epoch: 38 cost time: 21.59131908416748
Epoch: 38, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.3442768
	speed: 0.0863s/iter; left time: 1361.1921s
	iters: 200, epoch: 39 | loss: 0.3310622
	speed: 0.0789s/iter; left time: 1237.1525s
Epoch: 39 cost time: 21.097537755966187
Epoch: 39, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.3752119
	speed: 0.0879s/iter; left time: 1364.1124s
	iters: 200, epoch: 40 | loss: 0.3838871
	speed: 0.0832s/iter; left time: 1282.9315s
Epoch: 40 cost time: 21.493678092956543
Epoch: 40, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.3636210
	speed: 0.0870s/iter; left time: 1327.0316s
	iters: 200, epoch: 41 | loss: 0.3533968
	speed: 0.0812s/iter; left time: 1230.9024s
Epoch: 41 cost time: 21.241302251815796
Epoch: 41, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3245 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.3828821
	speed: 0.0859s/iter; left time: 1288.3245s
	iters: 200, epoch: 42 | loss: 0.3358822
	speed: 0.0791s/iter; left time: 1179.4950s
Epoch: 42 cost time: 21.216630458831787
Epoch: 42, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2205573469400406, mae:0.37419793009757996, mape:0.7276210188865662, mspe:18.85359764099121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.7888
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4359719
	speed: 0.0834s/iter; left time: 2126.4366s
	iters: 200, epoch: 1 | loss: 0.4908116
	speed: 0.0803s/iter; left time: 2040.4403s
Epoch: 1 cost time: 20.980607509613037
Epoch: 1, Steps: 256 Train Loss: 0.4719 (Forecasting Loss:0.4380 + XiCon Loss:3.3895 x Lambda(0.01)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.3709
Validation loss decreased (inf --> 0.398278).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3844323
	speed: 0.0859s/iter; left time: 2169.2103s
	iters: 200, epoch: 2 | loss: 0.4056879
	speed: 0.0785s/iter; left time: 1972.7240s
Epoch: 2 cost time: 21.040446281433105
Epoch: 2, Steps: 256 Train Loss: 0.3845 (Forecasting Loss:0.3508 + XiCon Loss:3.3641 x Lambda(0.01)), Vali MSE Loss: 0.3303 Test MSE Loss: 0.3010
Validation loss decreased (0.398278 --> 0.330301).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3532179
	speed: 0.0833s/iter; left time: 2080.4792s
	iters: 200, epoch: 3 | loss: 0.3567603
	speed: 0.0783s/iter; left time: 1948.1788s
Epoch: 3 cost time: 20.61489486694336
Epoch: 3, Steps: 256 Train Loss: 0.3556 (Forecasting Loss:0.3223 + XiCon Loss:3.3311 x Lambda(0.01)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.3015
Validation loss decreased (0.330301 --> 0.311235).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3301519
	speed: 0.0856s/iter; left time: 2117.1423s
	iters: 200, epoch: 4 | loss: 0.3423944
	speed: 0.0731s/iter; left time: 1801.2367s
Epoch: 4 cost time: 20.978264093399048
Epoch: 4, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3144 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.3031
Validation loss decreased (0.311235 --> 0.308481).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3269012
	speed: 0.0587s/iter; left time: 1436.0197s
	iters: 200, epoch: 5 | loss: 0.3303846
	speed: 0.0661s/iter; left time: 1610.1102s
Epoch: 5 cost time: 17.065633058547974
Epoch: 5, Steps: 256 Train Loss: 0.3452 (Forecasting Loss:0.3120 + XiCon Loss:3.3205 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3037
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3411721
	speed: 0.0842s/iter; left time: 2040.2745s
	iters: 200, epoch: 6 | loss: 0.3422557
	speed: 0.0773s/iter; left time: 1864.7927s
Epoch: 6 cost time: 20.583235025405884
Epoch: 6, Steps: 256 Train Loss: 0.3442 (Forecasting Loss:0.3110 + XiCon Loss:3.3197 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3040
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3424236
	speed: 0.0675s/iter; left time: 1617.8322s
	iters: 200, epoch: 7 | loss: 0.3705551
	speed: 0.0806s/iter; left time: 1924.2508s
Epoch: 7 cost time: 19.254775762557983
Epoch: 7, Steps: 256 Train Loss: 0.3436 (Forecasting Loss:0.3104 + XiCon Loss:3.3177 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3417426
	speed: 0.0826s/iter; left time: 1958.2459s
	iters: 200, epoch: 8 | loss: 0.3545329
	speed: 0.0772s/iter; left time: 1823.6689s
Epoch: 8 cost time: 19.619227647781372
Epoch: 8, Steps: 256 Train Loss: 0.3435 (Forecasting Loss:0.3103 + XiCon Loss:3.3193 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3042
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3328263
	speed: 0.0841s/iter; left time: 1971.6442s
	iters: 200, epoch: 9 | loss: 0.3485990
	speed: 0.0802s/iter; left time: 1873.0482s
Epoch: 9 cost time: 21.061606407165527
Epoch: 9, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3170 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3318453
	speed: 0.0843s/iter; left time: 1955.2303s
	iters: 200, epoch: 10 | loss: 0.3350500
	speed: 0.0567s/iter; left time: 1308.8779s
Epoch: 10 cost time: 18.61783003807068
Epoch: 10, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3169 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3472697
	speed: 0.0849s/iter; left time: 1946.7207s
	iters: 200, epoch: 11 | loss: 0.3336698
	speed: 0.0769s/iter; left time: 1757.4896s
Epoch: 11 cost time: 20.857433795928955
Epoch: 11, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3178 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3504198
	speed: 0.0632s/iter; left time: 1433.1363s
	iters: 200, epoch: 12 | loss: 0.3526487
	speed: 0.0781s/iter; left time: 1764.5306s
Epoch: 12 cost time: 18.777174711227417
Epoch: 12, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3100 + XiCon Loss:3.3173 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3043
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3148143
	speed: 0.0862s/iter; left time: 1932.3185s
	iters: 200, epoch: 13 | loss: 0.3615505
	speed: 0.0750s/iter; left time: 1673.6521s
Epoch: 13 cost time: 20.442197799682617
Epoch: 13, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3171 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3564136
	speed: 0.0785s/iter; left time: 1741.1222s
	iters: 200, epoch: 14 | loss: 0.3372966
	speed: 0.0739s/iter; left time: 1630.1197s
Epoch: 14 cost time: 19.59847331047058
Epoch: 14, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3100 + XiCon Loss:3.3184 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2297414392232895, mae:0.37653520703315735, mape:0.7666891813278198, mspe:20.789209365844727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2238+-0.00531, MAE:0.3728+-0.00401, MAPE:0.7457+-0.01808, MSPE:19.4087+-1.03395, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.0660
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4739254
	speed: 0.1192s/iter; left time: 2897.3486s
	iters: 200, epoch: 1 | loss: 0.4434214
	speed: 0.1134s/iter; left time: 2743.8385s
Epoch: 1 cost time: 28.36516761779785
Epoch: 1, Steps: 244 Train Loss: 0.4890 (Forecasting Loss:0.4552 + XiCon Loss:3.3834 x Lambda(0.01)), Vali MSE Loss: 0.4367 Test MSE Loss: 0.3356
Validation loss decreased (inf --> 0.436707).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3808483
	speed: 0.1185s/iter; left time: 2850.0010s
	iters: 200, epoch: 2 | loss: 0.3709663
	speed: 0.1143s/iter; left time: 2738.2329s
Epoch: 2 cost time: 28.44026494026184
Epoch: 2, Steps: 244 Train Loss: 0.3887 (Forecasting Loss:0.3550 + XiCon Loss:3.3700 x Lambda(0.01)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.3266
Validation loss decreased (0.436707 --> 0.376249).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3532239
	speed: 0.1178s/iter; left time: 2804.7051s
	iters: 200, epoch: 3 | loss: 0.3741831
	speed: 0.1203s/iter; left time: 2853.5870s
Epoch: 3 cost time: 29.113038063049316
Epoch: 3, Steps: 244 Train Loss: 0.3737 (Forecasting Loss:0.3402 + XiCon Loss:3.3550 x Lambda(0.01)), Vali MSE Loss: 0.3781 Test MSE Loss: 0.3376
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3537187
	speed: 0.1228s/iter; left time: 2894.5238s
	iters: 200, epoch: 4 | loss: 0.3771894
	speed: 0.1196s/iter; left time: 2807.5360s
Epoch: 4 cost time: 29.527519464492798
Epoch: 4, Steps: 244 Train Loss: 0.3696 (Forecasting Loss:0.3361 + XiCon Loss:3.3511 x Lambda(0.01)), Vali MSE Loss: 0.3660 Test MSE Loss: 0.3346
Validation loss decreased (0.376249 --> 0.366028).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3741719
	speed: 0.1195s/iter; left time: 2787.9500s
	iters: 200, epoch: 5 | loss: 0.3953889
	speed: 0.1185s/iter; left time: 2751.9495s
Epoch: 5 cost time: 29.005442142486572
Epoch: 5, Steps: 244 Train Loss: 0.3674 (Forecasting Loss:0.3339 + XiCon Loss:3.3501 x Lambda(0.01)), Vali MSE Loss: 0.3735 Test MSE Loss: 0.3366
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3636120
	speed: 0.1195s/iter; left time: 2759.2909s
	iters: 200, epoch: 6 | loss: 0.3639883
	speed: 0.1168s/iter; left time: 2684.4570s
Epoch: 6 cost time: 28.722821950912476
Epoch: 6, Steps: 244 Train Loss: 0.3660 (Forecasting Loss:0.3325 + XiCon Loss:3.3479 x Lambda(0.01)), Vali MSE Loss: 0.3782 Test MSE Loss: 0.3393
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3447029
	speed: 0.1195s/iter; left time: 2729.1605s
	iters: 200, epoch: 7 | loss: 0.3437329
	speed: 0.1206s/iter; left time: 2742.1901s
Epoch: 7 cost time: 29.346191883087158
Epoch: 7, Steps: 244 Train Loss: 0.3652 (Forecasting Loss:0.3317 + XiCon Loss:3.3477 x Lambda(0.01)), Vali MSE Loss: 0.3750 Test MSE Loss: 0.3374
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3639645
	speed: 0.1158s/iter; left time: 2615.4313s
	iters: 200, epoch: 8 | loss: 0.3663920
	speed: 0.1161s/iter; left time: 2612.1734s
Epoch: 8 cost time: 28.36224341392517
Epoch: 8, Steps: 244 Train Loss: 0.3650 (Forecasting Loss:0.3315 + XiCon Loss:3.3491 x Lambda(0.01)), Vali MSE Loss: 0.3755 Test MSE Loss: 0.3369
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3612438
	speed: 0.1240s/iter; left time: 2771.4069s
	iters: 200, epoch: 9 | loss: 0.3436965
	speed: 0.1188s/iter; left time: 2643.8752s
Epoch: 9 cost time: 29.62256932258606
Epoch: 9, Steps: 244 Train Loss: 0.3647 (Forecasting Loss:0.3312 + XiCon Loss:3.3488 x Lambda(0.01)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.3367
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3570012
	speed: 0.1208s/iter; left time: 2669.6090s
	iters: 200, epoch: 10 | loss: 0.3533102
	speed: 0.1206s/iter; left time: 2653.4336s
Epoch: 10 cost time: 29.640636920928955
Epoch: 10, Steps: 244 Train Loss: 0.3643 (Forecasting Loss:0.3308 + XiCon Loss:3.3480 x Lambda(0.01)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.3367
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3819301
	speed: 0.1248s/iter; left time: 2727.8419s
	iters: 200, epoch: 11 | loss: 0.3619932
	speed: 0.1201s/iter; left time: 2613.8846s
Epoch: 11 cost time: 29.963783025741577
Epoch: 11, Steps: 244 Train Loss: 0.3646 (Forecasting Loss:0.3311 + XiCon Loss:3.3472 x Lambda(0.01)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3365
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3884697
	speed: 0.1258s/iter; left time: 2720.2523s
	iters: 200, epoch: 12 | loss: 0.3453972
	speed: 0.1237s/iter; left time: 2662.1541s
Epoch: 12 cost time: 30.23260736465454
Epoch: 12, Steps: 244 Train Loss: 0.3644 (Forecasting Loss:0.3309 + XiCon Loss:3.3479 x Lambda(0.01)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3366
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3841670
	speed: 0.1257s/iter; left time: 2686.1388s
	iters: 200, epoch: 13 | loss: 0.3710753
	speed: 0.1220s/iter; left time: 2594.9765s
Epoch: 13 cost time: 30.05270290374756
Epoch: 13, Steps: 244 Train Loss: 0.3643 (Forecasting Loss:0.3309 + XiCon Loss:3.3482 x Lambda(0.01)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3367
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3440527
	speed: 0.1223s/iter; left time: 2584.1172s
	iters: 200, epoch: 14 | loss: 0.3595085
	speed: 0.1218s/iter; left time: 2561.1681s
Epoch: 14 cost time: 29.848591804504395
Epoch: 14, Steps: 244 Train Loss: 0.3643 (Forecasting Loss:0.3309 + XiCon Loss:3.3475 x Lambda(0.01)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3367
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2650173008441925, mae:0.4042392075061798, mape:0.7223983407020569, mspe:19.51006317138672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.6541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.5071895
	speed: 0.1129s/iter; left time: 2744.4710s
	iters: 200, epoch: 1 | loss: 0.4740229
	speed: 0.1079s/iter; left time: 2612.3745s
Epoch: 1 cost time: 26.83022165298462
Epoch: 1, Steps: 244 Train Loss: 0.4913 (Forecasting Loss:0.4575 + XiCon Loss:3.3777 x Lambda(0.01)), Vali MSE Loss: 0.4548 Test MSE Loss: 0.3578
Validation loss decreased (inf --> 0.454789).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3564283
	speed: 0.1162s/iter; left time: 2795.5863s
	iters: 200, epoch: 2 | loss: 0.3557482
	speed: 0.1149s/iter; left time: 2752.9688s
Epoch: 2 cost time: 28.11077380180359
Epoch: 2, Steps: 244 Train Loss: 0.3804 (Forecasting Loss:0.3465 + XiCon Loss:3.3895 x Lambda(0.01)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.3094
Validation loss decreased (0.454789 --> 0.322003).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3323267
	speed: 0.1174s/iter; left time: 2796.6796s
	iters: 200, epoch: 3 | loss: 0.3221733
	speed: 0.1132s/iter; left time: 2684.2320s
Epoch: 3 cost time: 28.308611392974854
Epoch: 3, Steps: 244 Train Loss: 0.3445 (Forecasting Loss:0.3106 + XiCon Loss:3.3869 x Lambda(0.01)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.3034
Validation loss decreased (0.322003 --> 0.311909).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3250508
	speed: 0.1151s/iter; left time: 2712.0607s
	iters: 200, epoch: 4 | loss: 0.3307880
	speed: 0.1207s/iter; left time: 2831.5421s
Epoch: 4 cost time: 28.786422729492188
Epoch: 4, Steps: 244 Train Loss: 0.3393 (Forecasting Loss:0.3054 + XiCon Loss:3.3822 x Lambda(0.01)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.3027
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3461833
	speed: 0.1175s/iter; left time: 2740.2314s
	iters: 200, epoch: 5 | loss: 0.3355858
	speed: 0.1186s/iter; left time: 2755.5466s
Epoch: 5 cost time: 28.79146647453308
Epoch: 5, Steps: 244 Train Loss: 0.3375 (Forecasting Loss:0.3037 + XiCon Loss:3.3814 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.3026
Validation loss decreased (0.311909 --> 0.308536).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3551359
	speed: 0.1263s/iter; left time: 2916.1504s
	iters: 200, epoch: 6 | loss: 0.3344675
	speed: 0.1168s/iter; left time: 2683.7460s
Epoch: 6 cost time: 29.39346671104431
Epoch: 6, Steps: 244 Train Loss: 0.3364 (Forecasting Loss:0.3026 + XiCon Loss:3.3799 x Lambda(0.01)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.3033
Validation loss decreased (0.308536 --> 0.306913).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3470323
	speed: 0.1290s/iter; left time: 2946.9664s
	iters: 200, epoch: 7 | loss: 0.3434117
	speed: 0.0894s/iter; left time: 2033.5188s
Epoch: 7 cost time: 26.83960747718811
Epoch: 7, Steps: 244 Train Loss: 0.3357 (Forecasting Loss:0.3019 + XiCon Loss:3.3804 x Lambda(0.01)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.3030
Validation loss decreased (0.306913 --> 0.306562).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3250021
	speed: 0.1151s/iter; left time: 2600.3303s
	iters: 200, epoch: 8 | loss: 0.3399186
	speed: 0.1132s/iter; left time: 2545.2880s
Epoch: 8 cost time: 27.548313856124878
Epoch: 8, Steps: 244 Train Loss: 0.3354 (Forecasting Loss:0.3016 + XiCon Loss:3.3804 x Lambda(0.01)), Vali MSE Loss: 0.3089 Test MSE Loss: 0.3027
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3339565
	speed: 0.1147s/iter; left time: 2564.4227s
	iters: 200, epoch: 9 | loss: 0.3337894
	speed: 0.1188s/iter; left time: 2643.2089s
Epoch: 9 cost time: 28.643087148666382
Epoch: 9, Steps: 244 Train Loss: 0.3355 (Forecasting Loss:0.3017 + XiCon Loss:3.3797 x Lambda(0.01)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.3030
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3370879
	speed: 0.0985s/iter; left time: 2176.3873s
	iters: 200, epoch: 10 | loss: 0.3370926
	speed: 0.1148s/iter; left time: 2525.3503s
Epoch: 10 cost time: 26.239639282226562
Epoch: 10, Steps: 244 Train Loss: 0.3353 (Forecasting Loss:0.3015 + XiCon Loss:3.3800 x Lambda(0.01)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.3028
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3257312
	speed: 0.1179s/iter; left time: 2576.7174s
	iters: 200, epoch: 11 | loss: 0.3451734
	speed: 0.0971s/iter; left time: 2113.3471s
Epoch: 11 cost time: 26.50675678253174
Epoch: 11, Steps: 244 Train Loss: 0.3351 (Forecasting Loss:0.3013 + XiCon Loss:3.3802 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.3028
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3236128
	speed: 0.1156s/iter; left time: 2499.4904s
	iters: 200, epoch: 12 | loss: 0.3287917
	speed: 0.1116s/iter; left time: 2401.1357s
Epoch: 12 cost time: 27.940403938293457
Epoch: 12, Steps: 244 Train Loss: 0.3352 (Forecasting Loss:0.3014 + XiCon Loss:3.3795 x Lambda(0.01)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.3028
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3464614
	speed: 0.1164s/iter; left time: 2488.4842s
	iters: 200, epoch: 13 | loss: 0.3233363
	speed: 0.1140s/iter; left time: 2425.0738s
Epoch: 13 cost time: 28.219412803649902
Epoch: 13, Steps: 244 Train Loss: 0.3352 (Forecasting Loss:0.3014 + XiCon Loss:3.3798 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.3029
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3192253
	speed: 0.1168s/iter; left time: 2468.7462s
	iters: 200, epoch: 14 | loss: 0.3531558
	speed: 0.1169s/iter; left time: 2458.6840s
Epoch: 14 cost time: 28.3995623588562
Epoch: 14, Steps: 244 Train Loss: 0.3353 (Forecasting Loss:0.3015 + XiCon Loss:3.3792 x Lambda(0.01)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.3029
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3082581
	speed: 0.1127s/iter; left time: 2353.6952s
	iters: 200, epoch: 15 | loss: 0.3614136
	speed: 0.1152s/iter; left time: 2393.5500s
Epoch: 15 cost time: 27.99468469619751
Epoch: 15, Steps: 244 Train Loss: 0.3353 (Forecasting Loss:0.3015 + XiCon Loss:3.3789 x Lambda(0.01)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.3029
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3304581
	speed: 0.1157s/iter; left time: 2387.2107s
	iters: 200, epoch: 16 | loss: 0.3349295
	speed: 0.1125s/iter; left time: 2310.9744s
Epoch: 16 cost time: 28.038074731826782
Epoch: 16, Steps: 244 Train Loss: 0.3353 (Forecasting Loss:0.3015 + XiCon Loss:3.3793 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.3029
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3336616
	speed: 0.1189s/iter; left time: 2426.0039s
	iters: 200, epoch: 17 | loss: 0.3299972
	speed: 0.1146s/iter; left time: 2325.3255s
Epoch: 17 cost time: 28.54712748527527
Epoch: 17, Steps: 244 Train Loss: 0.3351 (Forecasting Loss:0.3013 + XiCon Loss:3.3785 x Lambda(0.01)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.3029
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22483320534229279, mae:0.3811677396297455, mape:0.7061518430709839, mspe:17.569942474365234 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.2714
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4998819
	speed: 0.1084s/iter; left time: 2634.4948s
	iters: 200, epoch: 1 | loss: 0.4915839
	speed: 0.1023s/iter; left time: 2476.5835s
Epoch: 1 cost time: 25.583365201950073
Epoch: 1, Steps: 244 Train Loss: 0.4931 (Forecasting Loss:0.4592 + XiCon Loss:3.3886 x Lambda(0.01)), Vali MSE Loss: 0.4531 Test MSE Loss: 0.3554
Validation loss decreased (inf --> 0.453139).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3854364
	speed: 0.1095s/iter; left time: 2633.0520s
	iters: 200, epoch: 2 | loss: 0.3673539
	speed: 0.1034s/iter; left time: 2477.0036s
Epoch: 2 cost time: 26.283859729766846
Epoch: 2, Steps: 244 Train Loss: 0.3850 (Forecasting Loss:0.3518 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.3203
Validation loss decreased (0.453139 --> 0.311087).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3543289
	speed: 0.1157s/iter; left time: 2756.1674s
	iters: 200, epoch: 3 | loss: 0.3443083
	speed: 0.1165s/iter; left time: 2762.7501s
Epoch: 3 cost time: 28.36189556121826
Epoch: 3, Steps: 244 Train Loss: 0.3425 (Forecasting Loss:0.3094 + XiCon Loss:3.3125 x Lambda(0.01)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.3196
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3335387
	speed: 0.1214s/iter; left time: 2862.1833s
	iters: 200, epoch: 4 | loss: 0.3285058
	speed: 0.1149s/iter; left time: 2696.1188s
Epoch: 4 cost time: 28.643961191177368
Epoch: 4, Steps: 244 Train Loss: 0.3371 (Forecasting Loss:0.3041 + XiCon Loss:3.3077 x Lambda(0.01)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.3217
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3340964
	speed: 0.1227s/iter; left time: 2861.1794s
	iters: 200, epoch: 5 | loss: 0.3261816
	speed: 0.1184s/iter; left time: 2750.4695s
Epoch: 5 cost time: 29.38940191268921
Epoch: 5, Steps: 244 Train Loss: 0.3356 (Forecasting Loss:0.3025 + XiCon Loss:3.3072 x Lambda(0.01)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.3190
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3409125
	speed: 0.1219s/iter; left time: 2814.6405s
	iters: 200, epoch: 6 | loss: 0.3309712
	speed: 0.1211s/iter; left time: 2782.0038s
Epoch: 6 cost time: 29.57557725906372
Epoch: 6, Steps: 244 Train Loss: 0.3344 (Forecasting Loss:0.3013 + XiCon Loss:3.3064 x Lambda(0.01)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.3202
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3258097
	speed: 0.1263s/iter; left time: 2884.7867s
	iters: 200, epoch: 7 | loss: 0.3508723
	speed: 0.1197s/iter; left time: 2720.5546s
Epoch: 7 cost time: 29.680088758468628
Epoch: 7, Steps: 244 Train Loss: 0.3340 (Forecasting Loss:0.3009 + XiCon Loss:3.3047 x Lambda(0.01)), Vali MSE Loss: 0.3136 Test MSE Loss: 0.3230
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3317954
	speed: 0.1053s/iter; left time: 2378.7954s
	iters: 200, epoch: 8 | loss: 0.3239172
	speed: 0.1186s/iter; left time: 2667.7364s
Epoch: 8 cost time: 27.813107013702393
Epoch: 8, Steps: 244 Train Loss: 0.3337 (Forecasting Loss:0.3006 + XiCon Loss:3.3053 x Lambda(0.01)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.3212
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3289973
	speed: 0.1227s/iter; left time: 2741.1217s
	iters: 200, epoch: 9 | loss: 0.3445648
	speed: 0.1199s/iter; left time: 2667.5275s
Epoch: 9 cost time: 29.47513437271118
Epoch: 9, Steps: 244 Train Loss: 0.3337 (Forecasting Loss:0.3007 + XiCon Loss:3.3046 x Lambda(0.01)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.3217
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3533819
	speed: 0.1226s/iter; left time: 2710.5360s
	iters: 200, epoch: 10 | loss: 0.3158789
	speed: 0.1162s/iter; left time: 2557.0989s
Epoch: 10 cost time: 29.278339862823486
Epoch: 10, Steps: 244 Train Loss: 0.3335 (Forecasting Loss:0.3004 + XiCon Loss:3.3045 x Lambda(0.01)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.3222
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3529553
	speed: 0.1194s/iter; left time: 2610.7061s
	iters: 200, epoch: 11 | loss: 0.3428537
	speed: 0.1214s/iter; left time: 2642.0964s
Epoch: 11 cost time: 29.462934494018555
Epoch: 11, Steps: 244 Train Loss: 0.3334 (Forecasting Loss:0.3003 + XiCon Loss:3.3035 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.3216
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3275063
	speed: 0.1237s/iter; left time: 2674.5319s
	iters: 200, epoch: 12 | loss: 0.3273150
	speed: 0.1223s/iter; left time: 2630.6249s
Epoch: 12 cost time: 29.542479991912842
Epoch: 12, Steps: 244 Train Loss: 0.3333 (Forecasting Loss:0.3002 + XiCon Loss:3.3060 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.3218
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.24488884210586548, mae:0.39576011896133423, mape:0.6824864745140076, mspe:15.796046257019043 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.7068
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4748337
	speed: 0.1096s/iter; left time: 2663.5374s
	iters: 200, epoch: 1 | loss: 0.4750277
	speed: 0.1026s/iter; left time: 2482.2746s
Epoch: 1 cost time: 25.835217237472534
Epoch: 1, Steps: 244 Train Loss: 0.4953 (Forecasting Loss:0.4614 + XiCon Loss:3.3909 x Lambda(0.01)), Vali MSE Loss: 0.4616 Test MSE Loss: 0.3649
Validation loss decreased (inf --> 0.461611).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4118218
	speed: 0.1052s/iter; left time: 2531.5569s
	iters: 200, epoch: 2 | loss: 0.3738865
	speed: 0.1105s/iter; left time: 2647.1610s
Epoch: 2 cost time: 26.79238224029541
Epoch: 2, Steps: 244 Train Loss: 0.3890 (Forecasting Loss:0.3554 + XiCon Loss:3.3625 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2981
Validation loss decreased (0.461611 --> 0.320519).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3263665
	speed: 0.1223s/iter; left time: 2912.8448s
	iters: 200, epoch: 3 | loss: 0.3503160
	speed: 0.1177s/iter; left time: 2790.9214s
Epoch: 3 cost time: 29.349167823791504
Epoch: 3, Steps: 244 Train Loss: 0.3379 (Forecasting Loss:0.3045 + XiCon Loss:3.3410 x Lambda(0.01)), Vali MSE Loss: 0.3412 Test MSE Loss: 0.3150
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3323631
	speed: 0.1317s/iter; left time: 3104.2505s
	iters: 200, epoch: 4 | loss: 0.3141034
	speed: 0.1266s/iter; left time: 2971.5622s
Epoch: 4 cost time: 31.19233775138855
Epoch: 4, Steps: 244 Train Loss: 0.3293 (Forecasting Loss:0.2961 + XiCon Loss:3.3233 x Lambda(0.01)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.3129
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3057289
	speed: 0.1245s/iter; left time: 2904.5371s
	iters: 200, epoch: 5 | loss: 0.3202517
	speed: 0.1282s/iter; left time: 2977.8915s
Epoch: 5 cost time: 30.64979600906372
Epoch: 5, Steps: 244 Train Loss: 0.3250 (Forecasting Loss:0.2918 + XiCon Loss:3.3175 x Lambda(0.01)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.3120
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3267687
	speed: 0.1299s/iter; left time: 2998.8349s
	iters: 200, epoch: 6 | loss: 0.3027840
	speed: 0.1256s/iter; left time: 2886.6646s
Epoch: 6 cost time: 31.507963180541992
Epoch: 6, Steps: 244 Train Loss: 0.3231 (Forecasting Loss:0.2899 + XiCon Loss:3.3116 x Lambda(0.01)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.3100
Validation loss decreased (0.320519 --> 0.320407).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3282170
	speed: 0.1295s/iter; left time: 2958.2283s
	iters: 200, epoch: 7 | loss: 0.3231044
	speed: 0.1246s/iter; left time: 2832.7467s
Epoch: 7 cost time: 31.036418914794922
Epoch: 7, Steps: 244 Train Loss: 0.3225 (Forecasting Loss:0.2894 + XiCon Loss:3.3112 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.3124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3169686
	speed: 0.1251s/iter; left time: 2826.2086s
	iters: 200, epoch: 8 | loss: 0.3233579
	speed: 0.1226s/iter; left time: 2757.1709s
Epoch: 8 cost time: 30.431594133377075
Epoch: 8, Steps: 244 Train Loss: 0.3218 (Forecasting Loss:0.2887 + XiCon Loss:3.3098 x Lambda(0.01)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3111
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3343970
	speed: 0.1348s/iter; left time: 3012.5263s
	iters: 200, epoch: 9 | loss: 0.3108672
	speed: 0.1261s/iter; left time: 2806.6819s
Epoch: 9 cost time: 31.728339433670044
Epoch: 9, Steps: 244 Train Loss: 0.3214 (Forecasting Loss:0.2883 + XiCon Loss:3.3094 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.3113
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3230727
	speed: 0.1268s/iter; left time: 2803.6590s
	iters: 200, epoch: 10 | loss: 0.3286781
	speed: 0.1285s/iter; left time: 2826.6873s
Epoch: 10 cost time: 31.02826166152954
Epoch: 10, Steps: 244 Train Loss: 0.3214 (Forecasting Loss:0.2883 + XiCon Loss:3.3094 x Lambda(0.01)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.3114
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3137465
	speed: 0.1303s/iter; left time: 2849.5621s
	iters: 200, epoch: 11 | loss: 0.3072445
	speed: 0.1269s/iter; left time: 2761.5248s
Epoch: 11 cost time: 31.385395526885986
Epoch: 11, Steps: 244 Train Loss: 0.3213 (Forecasting Loss:0.2882 + XiCon Loss:3.3095 x Lambda(0.01)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3114
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3123540
	speed: 0.1300s/iter; left time: 2809.6199s
	iters: 200, epoch: 12 | loss: 0.3179976
	speed: 0.1216s/iter; left time: 2616.6852s
Epoch: 12 cost time: 30.950205326080322
Epoch: 12, Steps: 244 Train Loss: 0.3213 (Forecasting Loss:0.2882 + XiCon Loss:3.3097 x Lambda(0.01)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.3114
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3189365
	speed: 0.1317s/iter; left time: 2813.8159s
	iters: 200, epoch: 13 | loss: 0.3067217
	speed: 0.1257s/iter; left time: 2673.3673s
Epoch: 13 cost time: 31.59756374359131
Epoch: 13, Steps: 244 Train Loss: 0.3212 (Forecasting Loss:0.2881 + XiCon Loss:3.3103 x Lambda(0.01)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.3114
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3313334
	speed: 0.1289s/iter; left time: 2722.5335s
	iters: 200, epoch: 14 | loss: 0.3350337
	speed: 0.1257s/iter; left time: 2643.4770s
Epoch: 14 cost time: 31.076937675476074
Epoch: 14, Steps: 244 Train Loss: 0.3213 (Forecasting Loss:0.2882 + XiCon Loss:3.3089 x Lambda(0.01)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.3114
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3200971
	speed: 0.1284s/iter; left time: 2682.6275s
	iters: 200, epoch: 15 | loss: 0.3140421
	speed: 0.1270s/iter; left time: 2640.0676s
Epoch: 15 cost time: 31.02052927017212
Epoch: 15, Steps: 244 Train Loss: 0.3212 (Forecasting Loss:0.2881 + XiCon Loss:3.3098 x Lambda(0.01)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.3114
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3084948
	speed: 0.1304s/iter; left time: 2692.4058s
	iters: 200, epoch: 16 | loss: 0.3316392
	speed: 0.1305s/iter; left time: 2680.6687s
Epoch: 16 cost time: 31.69396185874939
Epoch: 16, Steps: 244 Train Loss: 0.3214 (Forecasting Loss:0.2883 + XiCon Loss:3.3104 x Lambda(0.01)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.3114
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.23203685879707336, mae:0.3878893256187439, mape:0.7733443975448608, mspe:22.318387985229492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.5898
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.4949823
	speed: 0.0997s/iter; left time: 2423.3973s
	iters: 200, epoch: 1 | loss: 0.4907915
	speed: 0.1318s/iter; left time: 3190.5514s
Epoch: 1 cost time: 27.30047845840454
Epoch: 1, Steps: 244 Train Loss: 0.4943 (Forecasting Loss:0.4603 + XiCon Loss:3.3918 x Lambda(0.01)), Vali MSE Loss: 0.4597 Test MSE Loss: 0.3629
Validation loss decreased (inf --> 0.459682).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3900654
	speed: 0.1019s/iter; left time: 2450.5053s
	iters: 200, epoch: 2 | loss: 0.3611703
	speed: 0.1065s/iter; left time: 2550.7252s
Epoch: 2 cost time: 25.896758794784546
Epoch: 2, Steps: 244 Train Loss: 0.3826 (Forecasting Loss:0.3493 + XiCon Loss:3.3313 x Lambda(0.01)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.3241
Validation loss decreased (0.459682 --> 0.321630).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3587831
	speed: 0.1050s/iter; left time: 2499.3056s
	iters: 200, epoch: 3 | loss: 0.3363169
	speed: 0.1203s/iter; left time: 2852.8955s
Epoch: 3 cost time: 27.887139320373535
Epoch: 3, Steps: 244 Train Loss: 0.3377 (Forecasting Loss:0.3047 + XiCon Loss:3.2946 x Lambda(0.01)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3184
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3237390
	speed: 0.1244s/iter; left time: 2930.8323s
	iters: 200, epoch: 4 | loss: 0.3084111
	speed: 0.1029s/iter; left time: 2415.0580s
Epoch: 4 cost time: 28.431175231933594
Epoch: 4, Steps: 244 Train Loss: 0.3303 (Forecasting Loss:0.2975 + XiCon Loss:3.2838 x Lambda(0.01)), Vali MSE Loss: 0.3532 Test MSE Loss: 0.3266
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3207276
	speed: 0.1252s/iter; left time: 2921.1870s
	iters: 200, epoch: 5 | loss: 0.3290816
	speed: 0.1214s/iter; left time: 2820.6699s
Epoch: 5 cost time: 28.947978019714355
Epoch: 5, Steps: 244 Train Loss: 0.3264 (Forecasting Loss:0.2936 + XiCon Loss:3.2763 x Lambda(0.01)), Vali MSE Loss: 0.3596 Test MSE Loss: 0.3180
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3235053
	speed: 0.1294s/iter; left time: 2986.9357s
	iters: 200, epoch: 6 | loss: 0.3352418
	speed: 0.1266s/iter; left time: 2909.3071s
Epoch: 6 cost time: 31.509268045425415
Epoch: 6, Steps: 244 Train Loss: 0.3247 (Forecasting Loss:0.2920 + XiCon Loss:3.2743 x Lambda(0.01)), Vali MSE Loss: 0.3512 Test MSE Loss: 0.3279
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3240238
	speed: 0.1251s/iter; left time: 2855.7726s
	iters: 200, epoch: 7 | loss: 0.3211069
	speed: 0.1222s/iter; left time: 2778.5515s
Epoch: 7 cost time: 30.476889610290527
Epoch: 7, Steps: 244 Train Loss: 0.3237 (Forecasting Loss:0.2909 + XiCon Loss:3.2739 x Lambda(0.01)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.3280
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3528801
	speed: 0.1276s/iter; left time: 2883.0121s
	iters: 200, epoch: 8 | loss: 0.3198553
	speed: 0.1258s/iter; left time: 2828.8181s
Epoch: 8 cost time: 31.039163827896118
Epoch: 8, Steps: 244 Train Loss: 0.3234 (Forecasting Loss:0.2907 + XiCon Loss:3.2719 x Lambda(0.01)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.3253
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3131536
	speed: 0.1233s/iter; left time: 2755.3373s
	iters: 200, epoch: 9 | loss: 0.3188519
	speed: 0.1228s/iter; left time: 2732.0247s
Epoch: 9 cost time: 30.237348079681396
Epoch: 9, Steps: 244 Train Loss: 0.3230 (Forecasting Loss:0.2903 + XiCon Loss:3.2704 x Lambda(0.01)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.3257
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3177443
	speed: 0.1261s/iter; left time: 2787.5723s
	iters: 200, epoch: 10 | loss: 0.3241659
	speed: 0.1243s/iter; left time: 2736.0170s
Epoch: 10 cost time: 30.796154022216797
Epoch: 10, Steps: 244 Train Loss: 0.3230 (Forecasting Loss:0.2903 + XiCon Loss:3.2712 x Lambda(0.01)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3267
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3206619
	speed: 0.1272s/iter; left time: 2781.6592s
	iters: 200, epoch: 11 | loss: 0.3294505
	speed: 0.1263s/iter; left time: 2748.2082s
Epoch: 11 cost time: 31.01507067680359
Epoch: 11, Steps: 244 Train Loss: 0.3229 (Forecasting Loss:0.2901 + XiCon Loss:3.2723 x Lambda(0.01)), Vali MSE Loss: 0.3541 Test MSE Loss: 0.3268
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3231503
	speed: 0.1261s/iter; left time: 2726.9450s
	iters: 200, epoch: 12 | loss: 0.3305376
	speed: 0.1239s/iter; left time: 2666.9148s
Epoch: 12 cost time: 30.88708734512329
Epoch: 12, Steps: 244 Train Loss: 0.3230 (Forecasting Loss:0.2903 + XiCon Loss:3.2711 x Lambda(0.01)), Vali MSE Loss: 0.3542 Test MSE Loss: 0.3267
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.24953597784042358, mae:0.39873379468917847, mape:0.6686068177223206, mspe:14.99250602722168 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2433+-0.01944, MAE:0.3936+-0.01130, MAPE:0.7106+-0.05063, MSPE:18.0374+-3.67337, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.9268
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5515510
	speed: 0.2071s/iter; left time: 4805.1504s
	iters: 200, epoch: 1 | loss: 0.5744037
	speed: 0.2090s/iter; left time: 4827.4219s
Epoch: 1 cost time: 48.49693512916565
Epoch: 1, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.5433 + XiCon Loss:3.3958 x Lambda(0.01)), Vali MSE Loss: 0.4851 Test MSE Loss: 0.3726
Validation loss decreased (inf --> 0.485081).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4210002
	speed: 0.2205s/iter; left time: 5065.5779s
	iters: 200, epoch: 2 | loss: 0.4110298
	speed: 0.2127s/iter; left time: 4863.8428s
Epoch: 2 cost time: 50.24955940246582
Epoch: 2, Steps: 233 Train Loss: 0.4323 (Forecasting Loss:0.3984 + XiCon Loss:3.3859 x Lambda(0.01)), Vali MSE Loss: 0.3793 Test MSE Loss: 0.3515
Validation loss decreased (0.485081 --> 0.379292).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.4167584
	speed: 0.2114s/iter; left time: 4806.0963s
	iters: 200, epoch: 3 | loss: 0.4093943
	speed: 0.2104s/iter; left time: 4761.5961s
Epoch: 3 cost time: 49.18193030357361
Epoch: 3, Steps: 233 Train Loss: 0.4122 (Forecasting Loss:0.3785 + XiCon Loss:3.3692 x Lambda(0.01)), Vali MSE Loss: 0.3837 Test MSE Loss: 0.3397
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3931447
	speed: 0.2099s/iter; left time: 4722.9774s
	iters: 200, epoch: 4 | loss: 0.3865026
	speed: 0.2086s/iter; left time: 4672.7602s
Epoch: 4 cost time: 48.78428792953491
Epoch: 4, Steps: 233 Train Loss: 0.4058 (Forecasting Loss:0.3721 + XiCon Loss:3.3655 x Lambda(0.01)), Vali MSE Loss: 0.3858 Test MSE Loss: 0.3268
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.4124949
	speed: 0.2114s/iter; left time: 4708.1269s
	iters: 200, epoch: 5 | loss: 0.4014143
	speed: 0.2050s/iter; left time: 4543.6651s
Epoch: 5 cost time: 48.56686758995056
Epoch: 5, Steps: 233 Train Loss: 0.4022 (Forecasting Loss:0.3686 + XiCon Loss:3.3642 x Lambda(0.01)), Vali MSE Loss: 0.3806 Test MSE Loss: 0.3206
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.4000283
	speed: 0.2124s/iter; left time: 4680.6490s
	iters: 200, epoch: 6 | loss: 0.4057915
	speed: 0.2147s/iter; left time: 4710.1614s
Epoch: 6 cost time: 49.77117609977722
Epoch: 6, Steps: 233 Train Loss: 0.4000 (Forecasting Loss:0.3664 + XiCon Loss:3.3639 x Lambda(0.01)), Vali MSE Loss: 0.3839 Test MSE Loss: 0.3210
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.4002755
	speed: 0.2148s/iter; left time: 4683.0421s
	iters: 200, epoch: 7 | loss: 0.4150367
	speed: 0.2158s/iter; left time: 4683.8792s
Epoch: 7 cost time: 50.176997423172
Epoch: 7, Steps: 233 Train Loss: 0.3987 (Forecasting Loss:0.3651 + XiCon Loss:3.3650 x Lambda(0.01)), Vali MSE Loss: 0.3800 Test MSE Loss: 0.3198
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3860259
	speed: 0.2169s/iter; left time: 4679.5128s
	iters: 200, epoch: 8 | loss: 0.3825197
	speed: 0.2124s/iter; left time: 4560.6133s
Epoch: 8 cost time: 49.99624037742615
Epoch: 8, Steps: 233 Train Loss: 0.3982 (Forecasting Loss:0.3646 + XiCon Loss:3.3669 x Lambda(0.01)), Vali MSE Loss: 0.3795 Test MSE Loss: 0.3200
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3857057
	speed: 0.2112s/iter; left time: 4506.2498s
	iters: 200, epoch: 9 | loss: 0.4003383
	speed: 0.2095s/iter; left time: 4449.3484s
Epoch: 9 cost time: 49.158282995224
Epoch: 9, Steps: 233 Train Loss: 0.3977 (Forecasting Loss:0.3641 + XiCon Loss:3.3639 x Lambda(0.01)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.3197
Validation loss decreased (0.379292 --> 0.377362).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.4128934
	speed: 0.2182s/iter; left time: 4604.0360s
	iters: 200, epoch: 10 | loss: 0.4000880
	speed: 0.2093s/iter; left time: 4396.9014s
Epoch: 10 cost time: 49.57765054702759
Epoch: 10, Steps: 233 Train Loss: 0.3977 (Forecasting Loss:0.3640 + XiCon Loss:3.3659 x Lambda(0.01)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.3197
Validation loss decreased (0.377362 --> 0.377189).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.4000219
	speed: 0.2135s/iter; left time: 4456.6955s
	iters: 200, epoch: 11 | loss: 0.3897439
	speed: 0.1785s/iter; left time: 3708.2824s
Epoch: 11 cost time: 46.157171964645386
Epoch: 11, Steps: 233 Train Loss: 0.3976 (Forecasting Loss:0.3639 + XiCon Loss:3.3653 x Lambda(0.01)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3196
Validation loss decreased (0.377189 --> 0.377083).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.4013469
	speed: 0.2095s/iter; left time: 4323.4722s
	iters: 200, epoch: 12 | loss: 0.3861503
	speed: 0.2101s/iter; left time: 4314.2066s
Epoch: 12 cost time: 49.239766359329224
Epoch: 12, Steps: 233 Train Loss: 0.3974 (Forecasting Loss:0.3637 + XiCon Loss:3.3642 x Lambda(0.01)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.3196
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3649144
	speed: 0.2056s/iter; left time: 4194.7730s
	iters: 200, epoch: 13 | loss: 0.3961477
	speed: 0.2143s/iter; left time: 4350.6788s
Epoch: 13 cost time: 49.340197801589966
Epoch: 13, Steps: 233 Train Loss: 0.3976 (Forecasting Loss:0.3639 + XiCon Loss:3.3633 x Lambda(0.01)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.3195
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.4085059
	speed: 0.2178s/iter; left time: 4393.3791s
	iters: 200, epoch: 14 | loss: 0.3922322
	speed: 0.2170s/iter; left time: 4354.7473s
Epoch: 14 cost time: 49.13769054412842
Epoch: 14, Steps: 233 Train Loss: 0.3977 (Forecasting Loss:0.3641 + XiCon Loss:3.3649 x Lambda(0.01)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.3195
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.4061106
	speed: 0.2222s/iter; left time: 4429.6499s
	iters: 200, epoch: 15 | loss: 0.3965540
	speed: 0.2140s/iter; left time: 4244.5747s
Epoch: 15 cost time: 50.56470561027527
Epoch: 15, Steps: 233 Train Loss: 0.3977 (Forecasting Loss:0.3640 + XiCon Loss:3.3641 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.4039990
	speed: 0.2127s/iter; left time: 4191.0407s
	iters: 200, epoch: 16 | loss: 0.3894761
	speed: 0.2059s/iter; left time: 4037.3247s
Epoch: 16 cost time: 48.96486473083496
Epoch: 16, Steps: 233 Train Loss: 0.3978 (Forecasting Loss:0.3641 + XiCon Loss:3.3656 x Lambda(0.01)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.3195
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.4134209
	speed: 0.2176s/iter; left time: 4236.8309s
	iters: 200, epoch: 17 | loss: 0.4229616
	speed: 0.2112s/iter; left time: 4091.6173s
Epoch: 17 cost time: 50.107670545578
Epoch: 17, Steps: 233 Train Loss: 0.3976 (Forecasting Loss:0.3639 + XiCon Loss:3.3657 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3932293
	speed: 0.2129s/iter; left time: 4095.7441s
	iters: 200, epoch: 18 | loss: 0.3892106
	speed: 0.2162s/iter; left time: 4137.1133s
Epoch: 18 cost time: 50.137322664260864
Epoch: 18, Steps: 233 Train Loss: 0.3976 (Forecasting Loss:0.3640 + XiCon Loss:3.3639 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.4209345
	speed: 0.2207s/iter; left time: 4194.7142s
	iters: 200, epoch: 19 | loss: 0.3997298
	speed: 0.2081s/iter; left time: 3934.9664s
Epoch: 19 cost time: 49.779369592666626
Epoch: 19, Steps: 233 Train Loss: 0.3975 (Forecasting Loss:0.3639 + XiCon Loss:3.3650 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.3989036
	speed: 0.2212s/iter; left time: 4153.7034s
	iters: 200, epoch: 20 | loss: 0.3977806
	speed: 0.2079s/iter; left time: 3882.1717s
Epoch: 20 cost time: 49.91330599784851
Epoch: 20, Steps: 233 Train Loss: 0.3976 (Forecasting Loss:0.3640 + XiCon Loss:3.3642 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.3921065
	speed: 0.2143s/iter; left time: 3974.1876s
	iters: 200, epoch: 21 | loss: 0.3762315
	speed: 0.2183s/iter; left time: 4025.5905s
Epoch: 21 cost time: 50.4606876373291
Epoch: 21, Steps: 233 Train Loss: 0.3978 (Forecasting Loss:0.3642 + XiCon Loss:3.3643 x Lambda(0.01)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3195
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.24852760136127472, mae:0.3906194865703583, mape:0.6869946718215942, mspe:19.678495407104492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.3795
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5989732
	speed: 0.2038s/iter; left time: 4728.1253s
	iters: 200, epoch: 1 | loss: 0.5395755
	speed: 0.2088s/iter; left time: 4822.8621s
Epoch: 1 cost time: 48.43264031410217
Epoch: 1, Steps: 233 Train Loss: 0.5839 (Forecasting Loss:0.5501 + XiCon Loss:3.3878 x Lambda(0.01)), Vali MSE Loss: 0.4969 Test MSE Loss: 0.3981
Validation loss decreased (inf --> 0.496942).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4423857
	speed: 0.2140s/iter; left time: 4914.1482s
	iters: 200, epoch: 2 | loss: 0.4287785
	speed: 0.2136s/iter; left time: 4883.6431s
Epoch: 2 cost time: 49.6681444644928
Epoch: 2, Steps: 233 Train Loss: 0.4407 (Forecasting Loss:0.4070 + XiCon Loss:3.3690 x Lambda(0.01)), Vali MSE Loss: 0.3891 Test MSE Loss: 0.3285
Validation loss decreased (0.496942 --> 0.389137).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.4174695
	speed: 0.2159s/iter; left time: 4909.3806s
	iters: 200, epoch: 3 | loss: 0.4217525
	speed: 0.2070s/iter; left time: 4685.1062s
Epoch: 3 cost time: 49.247212648391724
Epoch: 3, Steps: 233 Train Loss: 0.4095 (Forecasting Loss:0.3762 + XiCon Loss:3.3329 x Lambda(0.01)), Vali MSE Loss: 0.3613 Test MSE Loss: 0.3049
Validation loss decreased (0.389137 --> 0.361284).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3997709
	speed: 0.2072s/iter; left time: 4663.4279s
	iters: 200, epoch: 4 | loss: 0.3745674
	speed: 0.2141s/iter; left time: 4795.5240s
Epoch: 4 cost time: 49.16571259498596
Epoch: 4, Steps: 233 Train Loss: 0.3967 (Forecasting Loss:0.3635 + XiCon Loss:3.3194 x Lambda(0.01)), Vali MSE Loss: 0.3504 Test MSE Loss: 0.3082
Validation loss decreased (0.361284 --> 0.350396).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.4002023
	speed: 0.2103s/iter; left time: 4682.4502s
	iters: 200, epoch: 5 | loss: 0.3964972
	speed: 0.2126s/iter; left time: 4713.9799s
Epoch: 5 cost time: 49.257662773132324
Epoch: 5, Steps: 233 Train Loss: 0.3829 (Forecasting Loss:0.3498 + XiCon Loss:3.3145 x Lambda(0.01)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.3147
Validation loss decreased (0.350396 --> 0.339251).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3678522
	speed: 0.2128s/iter; left time: 4688.3421s
	iters: 200, epoch: 6 | loss: 0.3742618
	speed: 0.2085s/iter; left time: 4573.8794s
Epoch: 6 cost time: 49.0595383644104
Epoch: 6, Steps: 233 Train Loss: 0.3740 (Forecasting Loss:0.3409 + XiCon Loss:3.3108 x Lambda(0.01)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3192
Validation loss decreased (0.339251 --> 0.333828).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3672231
	speed: 0.2097s/iter; left time: 4571.9287s
	iters: 200, epoch: 7 | loss: 0.3675917
	speed: 0.2113s/iter; left time: 4585.0295s
Epoch: 7 cost time: 48.964383602142334
Epoch: 7, Steps: 233 Train Loss: 0.3701 (Forecasting Loss:0.3370 + XiCon Loss:3.3070 x Lambda(0.01)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.3234
Validation loss decreased (0.333828 --> 0.332519).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3663446
	speed: 0.2171s/iter; left time: 4682.1739s
	iters: 200, epoch: 8 | loss: 0.3720267
	speed: 0.1945s/iter; left time: 4175.1848s
Epoch: 8 cost time: 48.27832341194153
Epoch: 8, Steps: 233 Train Loss: 0.3685 (Forecasting Loss:0.3355 + XiCon Loss:3.3057 x Lambda(0.01)), Vali MSE Loss: 0.3328 Test MSE Loss: 0.3238
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3737667
	speed: 0.2074s/iter; left time: 4424.2519s
	iters: 200, epoch: 9 | loss: 0.3752859
	speed: 0.2238s/iter; left time: 4752.4489s
Epoch: 9 cost time: 50.10743451118469
Epoch: 9, Steps: 233 Train Loss: 0.3680 (Forecasting Loss:0.3350 + XiCon Loss:3.3054 x Lambda(0.01)), Vali MSE Loss: 0.3326 Test MSE Loss: 0.3256
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3740016
	speed: 0.2101s/iter; left time: 4433.5050s
	iters: 200, epoch: 10 | loss: 0.3443302
	speed: 0.2198s/iter; left time: 4616.2781s
Epoch: 10 cost time: 50.363948583602905
Epoch: 10, Steps: 233 Train Loss: 0.3677 (Forecasting Loss:0.3346 + XiCon Loss:3.3061 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3236
Validation loss decreased (0.332519 --> 0.331509).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3504116
	speed: 0.2169s/iter; left time: 4527.4945s
	iters: 200, epoch: 11 | loss: 0.3656809
	speed: 0.2255s/iter; left time: 4684.5488s
Epoch: 11 cost time: 51.5981981754303
Epoch: 11, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3343 + XiCon Loss:3.3048 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3242
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3810211
	speed: 0.2255s/iter; left time: 4654.7803s
	iters: 200, epoch: 12 | loss: 0.3865843
	speed: 0.2162s/iter; left time: 4441.2848s
Epoch: 12 cost time: 52.06834173202515
Epoch: 12, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3342 + XiCon Loss:3.3053 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3836503
	speed: 0.2290s/iter; left time: 4672.5369s
	iters: 200, epoch: 13 | loss: 0.3759527
	speed: 0.2278s/iter; left time: 4625.1308s
Epoch: 13 cost time: 52.25814342498779
Epoch: 13, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3342 + XiCon Loss:3.3056 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.3240
Validation loss decreased (0.331509 --> 0.331449).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3709463
	speed: 0.2257s/iter; left time: 4553.2055s
	iters: 200, epoch: 14 | loss: 0.3707219
	speed: 0.2265s/iter; left time: 4546.2630s
Epoch: 14 cost time: 52.446349143981934
Epoch: 14, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3340 + XiCon Loss:3.3053 x Lambda(0.01)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.3240
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3539098
	speed: 0.2292s/iter; left time: 4570.1145s
	iters: 200, epoch: 15 | loss: 0.3489008
	speed: 0.1883s/iter; left time: 3735.2153s
Epoch: 15 cost time: 48.70875692367554
Epoch: 15, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3342 + XiCon Loss:3.3054 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3710282
	speed: 0.2282s/iter; left time: 4497.5909s
	iters: 200, epoch: 16 | loss: 0.3651382
	speed: 0.2217s/iter; left time: 4346.1817s
Epoch: 16 cost time: 52.45972299575806
Epoch: 16, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3341 + XiCon Loss:3.3056 x Lambda(0.01)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.3241
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3693045
	speed: 0.2221s/iter; left time: 4324.9376s
	iters: 200, epoch: 17 | loss: 0.3773564
	speed: 0.1929s/iter; left time: 3736.2498s
Epoch: 17 cost time: 48.71002531051636
Epoch: 17, Steps: 233 Train Loss: 0.3674 (Forecasting Loss:0.3344 + XiCon Loss:3.3051 x Lambda(0.01)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.3241
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3692977
	speed: 0.2196s/iter; left time: 4225.0718s
	iters: 200, epoch: 18 | loss: 0.3675500
	speed: 0.2280s/iter; left time: 4364.7545s
Epoch: 18 cost time: 52.21642446517944
Epoch: 18, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3341 + XiCon Loss:3.3039 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.3241
Validation loss decreased (0.331449 --> 0.331369).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3607610
	speed: 0.2227s/iter; left time: 4233.3006s
	iters: 200, epoch: 19 | loss: 0.3807704
	speed: 0.2290s/iter; left time: 4330.1303s
Epoch: 19 cost time: 52.906604051589966
Epoch: 19, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3340 + XiCon Loss:3.3049 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.3241
Validation loss decreased (0.331369 --> 0.331359).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.3667514
	speed: 0.2279s/iter; left time: 4278.1996s
	iters: 200, epoch: 20 | loss: 0.3760843
	speed: 0.2218s/iter; left time: 4142.3848s
Epoch: 20 cost time: 52.56342649459839
Epoch: 20, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3342 + XiCon Loss:3.3055 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.3831698
	speed: 0.2249s/iter; left time: 4170.6799s
	iters: 200, epoch: 21 | loss: 0.3750553
	speed: 0.2192s/iter; left time: 4042.6621s
Epoch: 21 cost time: 51.38368201255798
Epoch: 21, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3342 + XiCon Loss:3.3054 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 0.3657406
	speed: 0.2328s/iter; left time: 4262.2428s
	iters: 200, epoch: 22 | loss: 0.3777930
	speed: 0.2209s/iter; left time: 4022.7481s
Epoch: 22 cost time: 52.546687602996826
Epoch: 22, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3343 + XiCon Loss:3.3064 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.3241
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 0.3624091
	speed: 0.2280s/iter; left time: 4120.7033s
	iters: 200, epoch: 23 | loss: 0.3731535
	speed: 0.2268s/iter; left time: 4076.6839s
Epoch: 23 cost time: 52.825008392333984
Epoch: 23, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3340 + XiCon Loss:3.3052 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 0.3651494
	speed: 0.2214s/iter; left time: 3949.9210s
	iters: 200, epoch: 24 | loss: 0.3801134
	speed: 0.2294s/iter; left time: 4070.8632s
Epoch: 24 cost time: 52.10665822029114
Epoch: 24, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3341 + XiCon Loss:3.3056 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 0.3951680
	speed: 0.2292s/iter; left time: 4036.7324s
	iters: 200, epoch: 25 | loss: 0.3832888
	speed: 0.2197s/iter; left time: 3846.8972s
Epoch: 25 cost time: 52.59047222137451
Epoch: 25, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3341 + XiCon Loss:3.3060 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 0.3681717
	speed: 0.2264s/iter; left time: 3933.8235s
	iters: 200, epoch: 26 | loss: 0.3875015
	speed: 0.2243s/iter; left time: 3874.7945s
Epoch: 26 cost time: 52.51550793647766
Epoch: 26, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3343 + XiCon Loss:3.3040 x Lambda(0.01)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.3241
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 0.3684191
	speed: 0.2281s/iter; left time: 3911.0804s
	iters: 200, epoch: 27 | loss: 0.3517022
	speed: 0.2250s/iter; left time: 3833.9640s
Epoch: 27 cost time: 53.03956866264343
Epoch: 27, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3340 + XiCon Loss:3.3057 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 0.3669746
	speed: 0.2282s/iter; left time: 3859.2182s
	iters: 200, epoch: 28 | loss: 0.3691570
	speed: 0.2294s/iter; left time: 3855.5368s
Epoch: 28 cost time: 53.20895004272461
Epoch: 28, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3341 + XiCon Loss:3.3044 x Lambda(0.01)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.3241
Validation loss decreased (0.331359 --> 0.331302).  Saving model ...
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 0.3865213
	speed: 0.2241s/iter; left time: 3737.3757s
	iters: 200, epoch: 29 | loss: 0.3471530
	speed: 0.2233s/iter; left time: 3702.0085s
Epoch: 29 cost time: 51.961963176727295
Epoch: 29, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3342 + XiCon Loss:3.3053 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 0.3738207
	speed: 0.2182s/iter; left time: 3588.6609s
	iters: 200, epoch: 30 | loss: 0.3769198
	speed: 0.2273s/iter; left time: 3715.1383s
Epoch: 30 cost time: 51.781492471694946
Epoch: 30, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3341 + XiCon Loss:3.3040 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 0.3788026
	speed: 0.2290s/iter; left time: 3712.5254s
	iters: 200, epoch: 31 | loss: 0.3614796
	speed: 0.2271s/iter; left time: 3658.8404s
Epoch: 31 cost time: 52.90012311935425
Epoch: 31, Steps: 233 Train Loss: 0.3670 (Forecasting Loss:0.3340 + XiCon Loss:3.3045 x Lambda(0.01)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.3241
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 0.3925596
	speed: 0.2326s/iter; left time: 3716.2906s
	iters: 200, epoch: 32 | loss: 0.3712987
	speed: 0.2173s/iter; left time: 3450.9654s
Epoch: 32 cost time: 52.82660365104675
Epoch: 32, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3342 + XiCon Loss:3.3059 x Lambda(0.01)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.3241
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 0.3644942
	speed: 0.2281s/iter; left time: 3590.7598s
	iters: 200, epoch: 33 | loss: 0.3780923
	speed: 0.2274s/iter; left time: 3557.3629s
Epoch: 33 cost time: 52.88512396812439
Epoch: 33, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3341 + XiCon Loss:3.3041 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 0.3748051
	speed: 0.2226s/iter; left time: 3452.8703s
	iters: 200, epoch: 34 | loss: 0.3718313
	speed: 0.1971s/iter; left time: 3037.1444s
Epoch: 34 cost time: 47.51374793052673
Epoch: 34, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3341 + XiCon Loss:3.3047 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 35 | loss: 0.3797539
	speed: 0.2273s/iter; left time: 3472.3591s
	iters: 200, epoch: 35 | loss: 0.3903254
	speed: 0.2030s/iter; left time: 3082.0608s
Epoch: 35 cost time: 48.694443225860596
Epoch: 35, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3342 + XiCon Loss:3.3058 x Lambda(0.01)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.3241
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 36 | loss: 0.3532031
	speed: 0.2404s/iter; left time: 3616.7509s
	iters: 200, epoch: 36 | loss: 0.3824552
	speed: 0.1915s/iter; left time: 2861.7725s
Epoch: 36 cost time: 50.56631827354431
Epoch: 36, Steps: 233 Train Loss: 0.3672 (Forecasting Loss:0.3341 + XiCon Loss:3.3053 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 37 | loss: 0.3569614
	speed: 0.2282s/iter; left time: 3379.7613s
	iters: 200, epoch: 37 | loss: 0.3642875
	speed: 0.1909s/iter; left time: 2809.3935s
Epoch: 37 cost time: 49.327574491500854
Epoch: 37, Steps: 233 Train Loss: 0.3671 (Forecasting Loss:0.3341 + XiCon Loss:3.3048 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.3241
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 38 | loss: 0.3694866
	speed: 0.2254s/iter; left time: 3286.3661s
	iters: 200, epoch: 38 | loss: 0.3623264
	speed: 0.1943s/iter; left time: 2812.9220s
Epoch: 38 cost time: 49.40621638298035
Epoch: 38, Steps: 233 Train Loss: 0.3673 (Forecasting Loss:0.3343 + XiCon Loss:3.3046 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3241
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.24702784419059753, mae:0.401103675365448, mape:0.6405348181724548, mspe:14.399235725402832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.5023
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.6370730
	speed: 0.1974s/iter; left time: 4580.0068s
	iters: 200, epoch: 1 | loss: 0.5622987
	speed: 0.2193s/iter; left time: 5066.6260s
Epoch: 1 cost time: 48.783950328826904
Epoch: 1, Steps: 233 Train Loss: 0.5869 (Forecasting Loss:0.5530 + XiCon Loss:3.3893 x Lambda(0.01)), Vali MSE Loss: 0.5084 Test MSE Loss: 0.4158
Validation loss decreased (inf --> 0.508435).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4474024
	speed: 0.2359s/iter; left time: 5418.1976s
	iters: 200, epoch: 2 | loss: 0.4040936
	speed: 0.2301s/iter; left time: 5261.0839s
Epoch: 2 cost time: 54.03078007698059
Epoch: 2, Steps: 233 Train Loss: 0.4507 (Forecasting Loss:0.4170 + XiCon Loss:3.3663 x Lambda(0.01)), Vali MSE Loss: 0.3840 Test MSE Loss: 0.3213
Validation loss decreased (0.508435 --> 0.384014).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.4167624
	speed: 0.2375s/iter; left time: 5400.2471s
	iters: 200, epoch: 3 | loss: 0.4299962
	speed: 0.2278s/iter; left time: 5155.4358s
Epoch: 3 cost time: 52.88698053359985
Epoch: 3, Steps: 233 Train Loss: 0.4093 (Forecasting Loss:0.3758 + XiCon Loss:3.3458 x Lambda(0.01)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3128
Validation loss decreased (0.384014 --> 0.368093).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3914243
	speed: 0.2317s/iter; left time: 5212.9629s
	iters: 200, epoch: 4 | loss: 0.3780479
	speed: 0.2190s/iter; left time: 4906.8464s
Epoch: 4 cost time: 52.55512523651123
Epoch: 4, Steps: 233 Train Loss: 0.3999 (Forecasting Loss:0.3665 + XiCon Loss:3.3359 x Lambda(0.01)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.3034
Validation loss decreased (0.368093 --> 0.354727).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3974008
	speed: 0.2319s/iter; left time: 5164.3318s
	iters: 200, epoch: 5 | loss: 0.3957182
	speed: 0.2236s/iter; left time: 4956.7121s
Epoch: 5 cost time: 53.187143087387085
Epoch: 5, Steps: 233 Train Loss: 0.3896 (Forecasting Loss:0.3563 + XiCon Loss:3.3338 x Lambda(0.01)), Vali MSE Loss: 0.3381 Test MSE Loss: 0.3026
Validation loss decreased (0.354727 --> 0.338070).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3815813
	speed: 0.2195s/iter; left time: 4836.0870s
	iters: 200, epoch: 6 | loss: 0.3727666
	speed: 0.2276s/iter; left time: 4993.0918s
Epoch: 6 cost time: 52.05245661735535
Epoch: 6, Steps: 233 Train Loss: 0.3811 (Forecasting Loss:0.3478 + XiCon Loss:3.3315 x Lambda(0.01)), Vali MSE Loss: 0.3323 Test MSE Loss: 0.3020
Validation loss decreased (0.338070 --> 0.332254).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3709282
	speed: 0.2225s/iter; left time: 4850.7163s
	iters: 200, epoch: 7 | loss: 0.3482496
	speed: 0.2243s/iter; left time: 4867.8561s
Epoch: 7 cost time: 52.34766364097595
Epoch: 7, Steps: 233 Train Loss: 0.3761 (Forecasting Loss:0.3428 + XiCon Loss:3.3316 x Lambda(0.01)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.3036
Validation loss decreased (0.332254 --> 0.329598).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3744059
	speed: 0.2354s/iter; left time: 5078.1755s
	iters: 200, epoch: 8 | loss: 0.3601831
	speed: 0.2306s/iter; left time: 4950.1172s
Epoch: 8 cost time: 53.94517660140991
Epoch: 8, Steps: 233 Train Loss: 0.3741 (Forecasting Loss:0.3408 + XiCon Loss:3.3317 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.3061
Validation loss decreased (0.329598 --> 0.328956).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3892388
	speed: 0.2365s/iter; left time: 5045.2911s
	iters: 200, epoch: 9 | loss: 0.3674424
	speed: 0.2260s/iter; left time: 4799.3010s
Epoch: 9 cost time: 53.868242502212524
Epoch: 9, Steps: 233 Train Loss: 0.3734 (Forecasting Loss:0.3401 + XiCon Loss:3.3322 x Lambda(0.01)), Vali MSE Loss: 0.3281 Test MSE Loss: 0.3074
Validation loss decreased (0.328956 --> 0.328113).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3656201
	speed: 0.2390s/iter; left time: 5044.8929s
	iters: 200, epoch: 10 | loss: 0.4116681
	speed: 0.2225s/iter; left time: 4674.4278s
Epoch: 10 cost time: 53.67777371406555
Epoch: 10, Steps: 233 Train Loss: 0.3728 (Forecasting Loss:0.3395 + XiCon Loss:3.3327 x Lambda(0.01)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.3080
Validation loss decreased (0.328113 --> 0.327982).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3803270
	speed: 0.2296s/iter; left time: 4791.0638s
	iters: 200, epoch: 11 | loss: 0.3907704
	speed: 0.2206s/iter; left time: 4581.8072s
Epoch: 11 cost time: 52.65420413017273
Epoch: 11, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3392 + XiCon Loss:3.3299 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
Validation loss decreased (0.327982 --> 0.327695).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3950922
	speed: 0.2256s/iter; left time: 4656.0895s
	iters: 200, epoch: 12 | loss: 0.3555938
	speed: 0.2243s/iter; left time: 4606.0318s
Epoch: 12 cost time: 52.86636543273926
Epoch: 12, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3392 + XiCon Loss:3.3323 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3076
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3650887
	speed: 0.2285s/iter; left time: 4663.3398s
	iters: 200, epoch: 13 | loss: 0.3626678
	speed: 0.2278s/iter; left time: 4626.1236s
Epoch: 13 cost time: 53.386070728302
Epoch: 13, Steps: 233 Train Loss: 0.3722 (Forecasting Loss:0.3389 + XiCon Loss:3.3311 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3955791
	speed: 0.2265s/iter; left time: 4569.8801s
	iters: 200, epoch: 14 | loss: 0.3811845
	speed: 0.2235s/iter; left time: 4486.2604s
Epoch: 14 cost time: 52.639158964157104
Epoch: 14, Steps: 233 Train Loss: 0.3722 (Forecasting Loss:0.3389 + XiCon Loss:3.3318 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3868072
	speed: 0.2320s/iter; left time: 4625.9132s
	iters: 200, epoch: 15 | loss: 0.3718507
	speed: 0.2248s/iter; left time: 4460.3209s
Epoch: 15 cost time: 53.466755628585815
Epoch: 15, Steps: 233 Train Loss: 0.3724 (Forecasting Loss:0.3391 + XiCon Loss:3.3298 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3619783
	speed: 0.2295s/iter; left time: 4521.6677s
	iters: 200, epoch: 16 | loss: 0.3601611
	speed: 0.2272s/iter; left time: 4455.4273s
Epoch: 16 cost time: 53.68332862854004
Epoch: 16, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3392 + XiCon Loss:3.3331 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
Validation loss decreased (0.327695 --> 0.327674).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3877385
	speed: 0.2279s/iter; left time: 4437.4372s
	iters: 200, epoch: 17 | loss: 0.3801602
	speed: 0.2336s/iter; left time: 4525.1971s
Epoch: 17 cost time: 54.01709604263306
Epoch: 17, Steps: 233 Train Loss: 0.3724 (Forecasting Loss:0.3391 + XiCon Loss:3.3328 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
Validation loss decreased (0.327674 --> 0.327670).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3719642
	speed: 0.2296s/iter; left time: 4417.2370s
	iters: 200, epoch: 18 | loss: 0.3409100
	speed: 0.2380s/iter; left time: 4554.3689s
Epoch: 18 cost time: 54.77805733680725
Epoch: 18, Steps: 233 Train Loss: 0.3721 (Forecasting Loss:0.3388 + XiCon Loss:3.3312 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3878652
	speed: 0.2091s/iter; left time: 3974.8020s
	iters: 200, epoch: 19 | loss: 0.3451740
	speed: 0.2316s/iter; left time: 4377.9760s
Epoch: 19 cost time: 51.82822322845459
Epoch: 19, Steps: 233 Train Loss: 0.3724 (Forecasting Loss:0.3391 + XiCon Loss:3.3307 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.3739946
	speed: 0.2296s/iter; left time: 4311.0804s
	iters: 200, epoch: 20 | loss: 0.3602786
	speed: 0.2239s/iter; left time: 4180.2900s
Epoch: 20 cost time: 52.6556978225708
Epoch: 20, Steps: 233 Train Loss: 0.3721 (Forecasting Loss:0.3388 + XiCon Loss:3.3313 x Lambda(0.01)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3077
Validation loss decreased (0.327670 --> 0.327649).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.3803853
	speed: 0.2286s/iter; left time: 4237.7923s
	iters: 200, epoch: 21 | loss: 0.3735542
	speed: 0.2211s/iter; left time: 4077.6908s
Epoch: 21 cost time: 52.86646747589111
Epoch: 21, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3392 + XiCon Loss:3.3318 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 0.3790547
	speed: 0.2320s/iter; left time: 4246.5610s
	iters: 200, epoch: 22 | loss: 0.3599949
	speed: 0.2211s/iter; left time: 4026.2520s
Epoch: 22 cost time: 52.67775344848633
Epoch: 22, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3390 + XiCon Loss:3.3318 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 0.3833620
	speed: 0.2204s/iter; left time: 3983.4725s
	iters: 200, epoch: 23 | loss: 0.3668479
	speed: 0.2224s/iter; left time: 3997.0596s
Epoch: 23 cost time: 52.19567012786865
Epoch: 23, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3389 + XiCon Loss:3.3316 x Lambda(0.01)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3077
Validation loss decreased (0.327649 --> 0.327609).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 0.3709317
	speed: 0.2250s/iter; left time: 4013.6761s
	iters: 200, epoch: 24 | loss: 0.3472891
	speed: 0.2264s/iter; left time: 4016.0598s
Epoch: 24 cost time: 52.91322660446167
Epoch: 24, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3390 + XiCon Loss:3.3314 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 0.3726591
	speed: 0.2296s/iter; left time: 4043.3736s
	iters: 200, epoch: 25 | loss: 0.3848221
	speed: 0.2317s/iter; left time: 4056.8632s
Epoch: 25 cost time: 53.55832624435425
Epoch: 25, Steps: 233 Train Loss: 0.3722 (Forecasting Loss:0.3389 + XiCon Loss:3.3308 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 0.3901657
	speed: 0.2297s/iter; left time: 3991.7512s
	iters: 200, epoch: 26 | loss: 0.3795571
	speed: 0.2281s/iter; left time: 3939.8233s
Epoch: 26 cost time: 53.42689347267151
Epoch: 26, Steps: 233 Train Loss: 0.3725 (Forecasting Loss:0.3392 + XiCon Loss:3.3326 x Lambda(0.01)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.3077
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 0.3703729
	speed: 0.2305s/iter; left time: 3951.3027s
	iters: 200, epoch: 27 | loss: 0.3894498
	speed: 0.2201s/iter; left time: 3750.9154s
Epoch: 27 cost time: 52.84879183769226
Epoch: 27, Steps: 233 Train Loss: 0.3724 (Forecasting Loss:0.3391 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 0.3758532
	speed: 0.2247s/iter; left time: 3799.4365s
	iters: 200, epoch: 28 | loss: 0.3666317
	speed: 0.2231s/iter; left time: 3749.6309s
Epoch: 28 cost time: 52.74374794960022
Epoch: 28, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3390 + XiCon Loss:3.3326 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3077
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 0.3588514
	speed: 0.2244s/iter; left time: 3742.3892s
	iters: 200, epoch: 29 | loss: 0.3726556
	speed: 0.2271s/iter; left time: 3764.7401s
Epoch: 29 cost time: 52.84364199638367
Epoch: 29, Steps: 233 Train Loss: 0.3721 (Forecasting Loss:0.3388 + XiCon Loss:3.3321 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 0.3599487
	speed: 0.2287s/iter; left time: 3759.9683s
	iters: 200, epoch: 30 | loss: 0.3680600
	speed: 0.2259s/iter; left time: 3692.3374s
Epoch: 30 cost time: 52.62432289123535
Epoch: 30, Steps: 233 Train Loss: 0.3724 (Forecasting Loss:0.3391 + XiCon Loss:3.3311 x Lambda(0.01)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3077
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 0.3647317
	speed: 0.2335s/iter; left time: 3784.6170s
	iters: 200, epoch: 31 | loss: 0.3750959
	speed: 0.2279s/iter; left time: 3671.7047s
Epoch: 31 cost time: 53.620092153549194
Epoch: 31, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3390 + XiCon Loss:3.3311 x Lambda(0.01)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.3077
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 0.3665157
	speed: 0.2300s/iter; left time: 3675.4550s
	iters: 200, epoch: 32 | loss: 0.3682958
	speed: 0.2271s/iter; left time: 3605.3968s
Epoch: 32 cost time: 53.53513050079346
Epoch: 32, Steps: 233 Train Loss: 0.3727 (Forecasting Loss:0.3394 + XiCon Loss:3.3306 x Lambda(0.01)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.3077
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 0.3774455
	speed: 0.2387s/iter; left time: 3757.5705s
	iters: 200, epoch: 33 | loss: 0.3744439
	speed: 0.2177s/iter; left time: 3405.9022s
Epoch: 33 cost time: 53.38799786567688
Epoch: 33, Steps: 233 Train Loss: 0.3723 (Forecasting Loss:0.3390 + XiCon Loss:3.3310 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3077
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2305203676223755, mae:0.384868860244751, mape:0.6397697329521179, mspe:15.615583419799805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.0126
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5489197
	speed: 0.2163s/iter; left time: 5017.8922s
	iters: 200, epoch: 1 | loss: 0.5668355
	speed: 0.2215s/iter; left time: 5117.2105s
Epoch: 1 cost time: 51.144574880599976
Epoch: 1, Steps: 233 Train Loss: 0.5838 (Forecasting Loss:0.5499 + XiCon Loss:3.3937 x Lambda(0.01)), Vali MSE Loss: 0.5217 Test MSE Loss: 0.4283
Validation loss decreased (inf --> 0.521670).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3775420
	speed: 0.2319s/iter; left time: 5325.5107s
	iters: 200, epoch: 2 | loss: 0.3722106
	speed: 0.2429s/iter; left time: 5554.7587s
Epoch: 2 cost time: 56.070008516311646
Epoch: 2, Steps: 233 Train Loss: 0.4103 (Forecasting Loss:0.3767 + XiCon Loss:3.3557 x Lambda(0.01)), Vali MSE Loss: 0.3364 Test MSE Loss: 0.2924
Validation loss decreased (0.521670 --> 0.336424).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3676031
	speed: 0.2924s/iter; left time: 6646.7344s
	iters: 200, epoch: 3 | loss: 0.3501512
	speed: 0.2743s/iter; left time: 6208.4617s
Epoch: 3 cost time: 66.00679731369019
Epoch: 3, Steps: 233 Train Loss: 0.3543 (Forecasting Loss:0.3211 + XiCon Loss:3.3217 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2864
Validation loss decreased (0.336424 --> 0.332144).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3371815
	speed: 0.3081s/iter; left time: 6933.0530s
	iters: 200, epoch: 4 | loss: 0.3489125
	speed: 0.2790s/iter; left time: 6250.9452s
Epoch: 4 cost time: 69.2302474975586
Epoch: 4, Steps: 233 Train Loss: 0.3476 (Forecasting Loss:0.3145 + XiCon Loss:3.3130 x Lambda(0.01)), Vali MSE Loss: 0.3343 Test MSE Loss: 0.2848
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3463053
	speed: 0.2770s/iter; left time: 6167.6041s
	iters: 200, epoch: 5 | loss: 0.3258314
	speed: 0.3099s/iter; left time: 6869.9103s
Epoch: 5 cost time: 68.80356073379517
Epoch: 5, Steps: 233 Train Loss: 0.3448 (Forecasting Loss:0.3117 + XiCon Loss:3.3092 x Lambda(0.01)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.2851
Validation loss decreased (0.332144 --> 0.330370).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3303757
	speed: 0.2965s/iter; left time: 6533.9911s
	iters: 200, epoch: 6 | loss: 0.3473009
	speed: 0.3046s/iter; left time: 6682.6790s
Epoch: 6 cost time: 67.96741056442261
Epoch: 6, Steps: 233 Train Loss: 0.3435 (Forecasting Loss:0.3104 + XiCon Loss:3.3093 x Lambda(0.01)), Vali MSE Loss: 0.3372 Test MSE Loss: 0.2849
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3507310
	speed: 0.3062s/iter; left time: 6676.9207s
	iters: 200, epoch: 7 | loss: 0.3492446
	speed: 0.3026s/iter; left time: 6566.6630s
Epoch: 7 cost time: 71.29314875602722
Epoch: 7, Steps: 233 Train Loss: 0.3428 (Forecasting Loss:0.3097 + XiCon Loss:3.3069 x Lambda(0.01)), Vali MSE Loss: 0.3381 Test MSE Loss: 0.2848
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3603730
	speed: 0.3049s/iter; left time: 6576.1010s
	iters: 200, epoch: 8 | loss: 0.3597006
	speed: 0.3051s/iter; left time: 6551.4636s
Epoch: 8 cost time: 70.77813267707825
Epoch: 8, Steps: 233 Train Loss: 0.3422 (Forecasting Loss:0.3092 + XiCon Loss:3.3073 x Lambda(0.01)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.2846
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3408630
	speed: 0.3077s/iter; left time: 6565.7331s
	iters: 200, epoch: 9 | loss: 0.3639113
	speed: 0.3032s/iter; left time: 6439.4838s
Epoch: 9 cost time: 71.68841886520386
Epoch: 9, Steps: 233 Train Loss: 0.3421 (Forecasting Loss:0.3090 + XiCon Loss:3.3083 x Lambda(0.01)), Vali MSE Loss: 0.3392 Test MSE Loss: 0.2849
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3458603
	speed: 0.3013s/iter; left time: 6357.7549s
	iters: 200, epoch: 10 | loss: 0.3617535
	speed: 0.3074s/iter; left time: 6456.3894s
Epoch: 10 cost time: 71.56554555892944
Epoch: 10, Steps: 233 Train Loss: 0.3420 (Forecasting Loss:0.3090 + XiCon Loss:3.3082 x Lambda(0.01)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.2847
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3301900
	speed: 0.2990s/iter; left time: 6241.4140s
	iters: 200, epoch: 11 | loss: 0.3557512
	speed: 0.3131s/iter; left time: 6503.7621s
Epoch: 11 cost time: 71.17885136604309
Epoch: 11, Steps: 233 Train Loss: 0.3419 (Forecasting Loss:0.3089 + XiCon Loss:3.3086 x Lambda(0.01)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2848
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3569246
	speed: 0.3075s/iter; left time: 6345.8638s
	iters: 200, epoch: 12 | loss: 0.3471561
	speed: 0.3067s/iter; left time: 6298.7537s
Epoch: 12 cost time: 71.48324728012085
Epoch: 12, Steps: 233 Train Loss: 0.3420 (Forecasting Loss:0.3089 + XiCon Loss:3.3074 x Lambda(0.01)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2847
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3391613
	speed: 0.3019s/iter; left time: 6160.7405s
	iters: 200, epoch: 13 | loss: 0.3273783
	speed: 0.3098s/iter; left time: 6290.6620s
Epoch: 13 cost time: 71.47500896453857
Epoch: 13, Steps: 233 Train Loss: 0.3420 (Forecasting Loss:0.3089 + XiCon Loss:3.3080 x Lambda(0.01)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.2847
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3382630
	speed: 0.2996s/iter; left time: 6044.3325s
	iters: 200, epoch: 14 | loss: 0.3171442
	speed: 0.3056s/iter; left time: 6134.1540s
Epoch: 14 cost time: 70.01714992523193
Epoch: 14, Steps: 233 Train Loss: 0.3418 (Forecasting Loss:0.3088 + XiCon Loss:3.3085 x Lambda(0.01)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2847
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3655611
	speed: 0.3025s/iter; left time: 6031.0691s
	iters: 200, epoch: 15 | loss: 0.3330156
	speed: 0.3083s/iter; left time: 6115.9505s
Epoch: 15 cost time: 71.3957736492157
Epoch: 15, Steps: 233 Train Loss: 0.3419 (Forecasting Loss:0.3088 + XiCon Loss:3.3083 x Lambda(0.01)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.2847
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2057320922613144, mae:0.3644256293773651, mape:0.6743756532669067, mspe:18.196382522583008 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.0025
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.5863433
	speed: 0.2115s/iter; left time: 4906.7808s
	iters: 200, epoch: 1 | loss: 0.5457185
	speed: 0.2188s/iter; left time: 5053.7434s
Epoch: 1 cost time: 50.7895450592041
Epoch: 1, Steps: 233 Train Loss: 0.5848 (Forecasting Loss:0.5511 + XiCon Loss:3.3737 x Lambda(0.01)), Vali MSE Loss: 0.5162 Test MSE Loss: 0.4238
Validation loss decreased (inf --> 0.516163).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4087785
	speed: 0.2168s/iter; left time: 4980.1849s
	iters: 200, epoch: 2 | loss: 0.4124867
	speed: 0.2241s/iter; left time: 5123.7890s
Epoch: 2 cost time: 51.86095333099365
Epoch: 2, Steps: 233 Train Loss: 0.4320 (Forecasting Loss:0.3985 + XiCon Loss:3.3495 x Lambda(0.01)), Vali MSE Loss: 0.3437 Test MSE Loss: 0.3224
Validation loss decreased (0.516163 --> 0.343718).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.4077113
	speed: 0.2225s/iter; left time: 5058.4219s
	iters: 200, epoch: 3 | loss: 0.3818868
	speed: 0.2260s/iter; left time: 5114.6124s
Epoch: 3 cost time: 52.348726987838745
Epoch: 3, Steps: 233 Train Loss: 0.3852 (Forecasting Loss:0.3519 + XiCon Loss:3.3360 x Lambda(0.01)), Vali MSE Loss: 0.3339 Test MSE Loss: 0.3331
Validation loss decreased (0.343718 --> 0.333929).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3442180
	speed: 0.2233s/iter; left time: 5024.9684s
	iters: 200, epoch: 4 | loss: 0.3498267
	speed: 0.2198s/iter; left time: 4924.7664s
Epoch: 4 cost time: 51.42479395866394
Epoch: 4, Steps: 233 Train Loss: 0.3761 (Forecasting Loss:0.3428 + XiCon Loss:3.3332 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.3250
Validation loss decreased (0.333929 --> 0.329473).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3787399
	speed: 0.2280s/iter; left time: 5078.1276s
	iters: 200, epoch: 5 | loss: 0.3656686
	speed: 0.2192s/iter; left time: 4859.8884s
Epoch: 5 cost time: 50.99219346046448
Epoch: 5, Steps: 233 Train Loss: 0.3711 (Forecasting Loss:0.3378 + XiCon Loss:3.3294 x Lambda(0.01)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.3273
Validation loss decreased (0.329473 --> 0.326679).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3612314
	speed: 0.1881s/iter; left time: 4145.1110s
	iters: 200, epoch: 6 | loss: 0.3530377
	speed: 0.2237s/iter; left time: 4907.8350s
Epoch: 6 cost time: 48.33801484107971
Epoch: 6, Steps: 233 Train Loss: 0.3683 (Forecasting Loss:0.3350 + XiCon Loss:3.3281 x Lambda(0.01)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.3231
Validation loss decreased (0.326679 --> 0.326448).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3571905
	speed: 0.2025s/iter; left time: 4414.3555s
	iters: 200, epoch: 7 | loss: 0.3858673
	speed: 0.2214s/iter; left time: 4804.0336s
Epoch: 7 cost time: 50.10111927986145
Epoch: 7, Steps: 233 Train Loss: 0.3674 (Forecasting Loss:0.3342 + XiCon Loss:3.3273 x Lambda(0.01)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.3221
Validation loss decreased (0.326448 --> 0.325391).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3780168
	speed: 0.2117s/iter; left time: 4567.2503s
	iters: 200, epoch: 8 | loss: 0.3779722
	speed: 0.2211s/iter; left time: 4746.3147s
Epoch: 8 cost time: 50.62425899505615
Epoch: 8, Steps: 233 Train Loss: 0.3661 (Forecasting Loss:0.3328 + XiCon Loss:3.3267 x Lambda(0.01)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.3151
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3465177
	speed: 0.2132s/iter; left time: 4549.4850s
	iters: 200, epoch: 9 | loss: 0.3657498
	speed: 0.2198s/iter; left time: 4668.4537s
Epoch: 9 cost time: 50.71865653991699
Epoch: 9, Steps: 233 Train Loss: 0.3658 (Forecasting Loss:0.3325 + XiCon Loss:3.3278 x Lambda(0.01)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.3194
Validation loss decreased (0.325391 --> 0.324577).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3444465
	speed: 0.2232s/iter; left time: 4710.7332s
	iters: 200, epoch: 10 | loss: 0.3321870
	speed: 0.2171s/iter; left time: 4560.6080s
Epoch: 10 cost time: 51.35427474975586
Epoch: 10, Steps: 233 Train Loss: 0.3656 (Forecasting Loss:0.3323 + XiCon Loss:3.3259 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3205
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.3411433
	speed: 0.2201s/iter; left time: 4594.3275s
	iters: 200, epoch: 11 | loss: 0.3688915
	speed: 0.2267s/iter; left time: 4708.0858s
Epoch: 11 cost time: 51.933979749679565
Epoch: 11, Steps: 233 Train Loss: 0.3656 (Forecasting Loss:0.3324 + XiCon Loss:3.3270 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3204
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3640815
	speed: 0.2207s/iter; left time: 4555.3961s
	iters: 200, epoch: 12 | loss: 0.3684360
	speed: 0.2142s/iter; left time: 4398.8184s
Epoch: 12 cost time: 48.19404053688049
Epoch: 12, Steps: 233 Train Loss: 0.3658 (Forecasting Loss:0.3325 + XiCon Loss:3.3256 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3198
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3564096
	speed: 0.2271s/iter; left time: 4633.2230s
	iters: 200, epoch: 13 | loss: 0.3656274
	speed: 0.2071s/iter; left time: 4204.8087s
Epoch: 13 cost time: 48.278769731521606
Epoch: 13, Steps: 233 Train Loss: 0.3655 (Forecasting Loss:0.3323 + XiCon Loss:3.3254 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3199
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.3819406
	speed: 0.2241s/iter; left time: 4520.1204s
	iters: 200, epoch: 14 | loss: 0.3569465
	speed: 0.2177s/iter; left time: 4370.2127s
Epoch: 14 cost time: 51.553075075149536
Epoch: 14, Steps: 233 Train Loss: 0.3656 (Forecasting Loss:0.3324 + XiCon Loss:3.3258 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3199
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.3759364
	speed: 0.2234s/iter; left time: 4454.3691s
	iters: 200, epoch: 15 | loss: 0.3754255
	speed: 0.2199s/iter; left time: 4361.8483s
Epoch: 15 cost time: 51.26416730880737
Epoch: 15, Steps: 233 Train Loss: 0.3654 (Forecasting Loss:0.3322 + XiCon Loss:3.3249 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3199
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.3629332
	speed: 0.2247s/iter; left time: 4427.9774s
	iters: 200, epoch: 16 | loss: 0.3652257
	speed: 0.2236s/iter; left time: 4383.6221s
Epoch: 16 cost time: 52.15387582778931
Epoch: 16, Steps: 233 Train Loss: 0.3655 (Forecasting Loss:0.3322 + XiCon Loss:3.3259 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.3199
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.3948961
	speed: 0.2184s/iter; left time: 4252.0902s
	iters: 200, epoch: 17 | loss: 0.3710606
	speed: 0.2208s/iter; left time: 4277.3879s
Epoch: 17 cost time: 51.51825475692749
Epoch: 17, Steps: 233 Train Loss: 0.3655 (Forecasting Loss:0.3323 + XiCon Loss:3.3261 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.3199
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.3664637
	speed: 0.2174s/iter; left time: 4182.3451s
	iters: 200, epoch: 18 | loss: 0.3563106
	speed: 0.2207s/iter; left time: 4224.0015s
Epoch: 18 cost time: 50.93889331817627
Epoch: 18, Steps: 233 Train Loss: 0.3656 (Forecasting Loss:0.3323 + XiCon Loss:3.3253 x Lambda(0.01)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.3199
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.3700347
	speed: 0.2196s/iter; left time: 4174.5400s
	iters: 200, epoch: 19 | loss: 0.3717390
	speed: 0.2200s/iter; left time: 4159.2842s
Epoch: 19 cost time: 51.19529867172241
Epoch: 19, Steps: 233 Train Loss: 0.3656 (Forecasting Loss:0.3324 + XiCon Loss:3.3249 x Lambda(0.01)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.3199
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2436588853597641, mae:0.39514845609664917, mape:0.6285929083824158, mspe:13.545300483703613 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2351+-0.02221, MAE:0.3872+-0.01747, MAPE:0.6541+-0.03125, MSPE:16.2870+-3.20673, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
