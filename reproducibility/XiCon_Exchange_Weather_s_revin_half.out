Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5756
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.0787701606750488
Epoch: 1, Steps: 69 Train Loss: 2.0160 (Forecasting Loss:0.1324 + XiCon Loss:1.8835 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.285084).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7581479549407959
Epoch: 2, Steps: 69 Train Loss: 1.9890 (Forecasting Loss:0.1111 + XiCon Loss:1.8779 x Lambda(1.0)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.1226
Validation loss decreased (0.285084 --> 0.213924).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.858966588973999
Epoch: 3, Steps: 69 Train Loss: 1.9809 (Forecasting Loss:0.1023 + XiCon Loss:1.8786 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1204
Validation loss decreased (0.213924 --> 0.209151).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8074824810028076
Epoch: 4, Steps: 69 Train Loss: 1.9686 (Forecasting Loss:0.1006 + XiCon Loss:1.8679 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1192
Validation loss decreased (0.209151 --> 0.207571).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8201415538787842
Epoch: 5, Steps: 69 Train Loss: 1.9667 (Forecasting Loss:0.1000 + XiCon Loss:1.8667 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1188
Validation loss decreased (0.207571 --> 0.206708).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9326517581939697
Epoch: 6, Steps: 69 Train Loss: 1.9625 (Forecasting Loss:0.0998 + XiCon Loss:1.8627 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1185
Validation loss decreased (0.206708 --> 0.206403).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8261220455169678
Epoch: 7, Steps: 69 Train Loss: 1.9675 (Forecasting Loss:0.0996 + XiCon Loss:1.8679 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1183
Validation loss decreased (0.206403 --> 0.206200).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8611552715301514
Epoch: 8, Steps: 69 Train Loss: 1.9580 (Forecasting Loss:0.0996 + XiCon Loss:1.8584 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1182
Validation loss decreased (0.206200 --> 0.206171).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8353211879730225
Epoch: 9, Steps: 69 Train Loss: 1.9564 (Forecasting Loss:0.0997 + XiCon Loss:1.8568 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206171 --> 0.206127).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8043994903564453
Epoch: 10, Steps: 69 Train Loss: 1.9642 (Forecasting Loss:0.0996 + XiCon Loss:1.8646 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206127 --> 0.206106).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8850703239440918
Epoch: 11, Steps: 69 Train Loss: 1.9629 (Forecasting Loss:0.0996 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206106 --> 0.206097).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8240582942962646
Epoch: 12, Steps: 69 Train Loss: 1.9586 (Forecasting Loss:0.0993 + XiCon Loss:1.8593 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206097 --> 0.206091).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8436160087585449
Epoch: 13, Steps: 69 Train Loss: 1.9623 (Forecasting Loss:0.0994 + XiCon Loss:1.8628 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206091 --> 0.206088).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.840421199798584
Epoch: 14, Steps: 69 Train Loss: 1.9614 (Forecasting Loss:0.0996 + XiCon Loss:1.8618 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206088 --> 0.206087).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8134875297546387
Epoch: 15, Steps: 69 Train Loss: 1.9618 (Forecasting Loss:0.0996 + XiCon Loss:1.8622 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206087 --> 0.206086).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8716781139373779
Epoch: 16, Steps: 69 Train Loss: 1.9604 (Forecasting Loss:0.0995 + XiCon Loss:1.8609 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206086 --> 0.206086).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8603980541229248
Epoch: 17, Steps: 69 Train Loss: 1.9575 (Forecasting Loss:0.0995 + XiCon Loss:1.8580 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206086 --> 0.206085).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9782512187957764
Epoch: 18, Steps: 69 Train Loss: 1.9598 (Forecasting Loss:0.0995 + XiCon Loss:1.8603 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.7939455509185791
Epoch: 19, Steps: 69 Train Loss: 1.9590 (Forecasting Loss:0.0994 + XiCon Loss:1.8596 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8575966358184814
Epoch: 20, Steps: 69 Train Loss: 1.9635 (Forecasting Loss:0.0998 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8418333530426025
Epoch: 21, Steps: 69 Train Loss: 1.9580 (Forecasting Loss:0.0995 + XiCon Loss:1.8584 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8479635715484619
Epoch: 22, Steps: 69 Train Loss: 1.9554 (Forecasting Loss:0.0996 + XiCon Loss:1.8558 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.7789337635040283
Epoch: 23, Steps: 69 Train Loss: 1.9613 (Forecasting Loss:0.0996 + XiCon Loss:1.8617 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9120728969573975
Epoch: 24, Steps: 69 Train Loss: 1.9585 (Forecasting Loss:0.0992 + XiCon Loss:1.8593 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8389153480529785
Epoch: 25, Steps: 69 Train Loss: 1.9638 (Forecasting Loss:0.0995 + XiCon Loss:1.8643 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8225271701812744
Epoch: 26, Steps: 69 Train Loss: 1.9597 (Forecasting Loss:0.0993 + XiCon Loss:1.8604 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
Validation loss decreased (0.206085 --> 0.206085).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8513538837432861
Epoch: 27, Steps: 69 Train Loss: 1.9596 (Forecasting Loss:0.0996 + XiCon Loss:1.8600 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9282619953155518
Epoch: 28, Steps: 69 Train Loss: 1.9614 (Forecasting Loss:0.0995 + XiCon Loss:1.8620 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.898329496383667
Epoch: 29, Steps: 69 Train Loss: 1.9577 (Forecasting Loss:0.0995 + XiCon Loss:1.8582 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.7757542133331299
Epoch: 30, Steps: 69 Train Loss: 1.9586 (Forecasting Loss:0.0996 + XiCon Loss:1.8590 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9009652137756348
Epoch: 31, Steps: 69 Train Loss: 1.9579 (Forecasting Loss:0.0995 + XiCon Loss:1.8584 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9100866317749023
Epoch: 32, Steps: 69 Train Loss: 1.9606 (Forecasting Loss:0.0997 + XiCon Loss:1.8609 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8820667266845703
Epoch: 33, Steps: 69 Train Loss: 1.9588 (Forecasting Loss:0.0996 + XiCon Loss:1.8592 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8219833374023438
Epoch: 34, Steps: 69 Train Loss: 1.9583 (Forecasting Loss:0.0994 + XiCon Loss:1.8589 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8969097137451172
Epoch: 35, Steps: 69 Train Loss: 1.9611 (Forecasting Loss:0.0996 + XiCon Loss:1.8614 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.782198429107666
Epoch: 36, Steps: 69 Train Loss: 1.9561 (Forecasting Loss:0.0995 + XiCon Loss:1.8566 x Lambda(1.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05580645054578781, mae:0.18032574653625488, mape:0.12646125257015228, mspe:0.03769664838910103 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5586
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8663344383239746
Epoch: 1, Steps: 69 Train Loss: 2.0152 (Forecasting Loss:0.1328 + XiCon Loss:1.8824 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.1507
Validation loss decreased (inf --> 0.285211).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.816356897354126
Epoch: 2, Steps: 69 Train Loss: 1.9886 (Forecasting Loss:0.1121 + XiCon Loss:1.8765 x Lambda(1.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1221
Validation loss decreased (0.285211 --> 0.214138).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8572103977203369
Epoch: 3, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1029 + XiCon Loss:1.8653 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1201
Validation loss decreased (0.214138 --> 0.210488).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9059031009674072
Epoch: 4, Steps: 69 Train Loss: 1.9526 (Forecasting Loss:0.1017 + XiCon Loss:1.8509 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1186
Validation loss decreased (0.210488 --> 0.208775).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8496911525726318
Epoch: 5, Steps: 69 Train Loss: 1.9657 (Forecasting Loss:0.1011 + XiCon Loss:1.8646 x Lambda(1.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1183
Validation loss decreased (0.208775 --> 0.208123).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8559732437133789
Epoch: 6, Steps: 69 Train Loss: 1.9789 (Forecasting Loss:0.1009 + XiCon Loss:1.8779 x Lambda(1.0)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1182
Validation loss decreased (0.208123 --> 0.207935).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8553454875946045
Epoch: 7, Steps: 69 Train Loss: 1.9771 (Forecasting Loss:0.1006 + XiCon Loss:1.8765 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1182
Validation loss decreased (0.207935 --> 0.207803).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.796804666519165
Epoch: 8, Steps: 69 Train Loss: 1.9796 (Forecasting Loss:0.1007 + XiCon Loss:1.8789 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1182
Validation loss decreased (0.207803 --> 0.207718).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.884753942489624
Epoch: 9, Steps: 69 Train Loss: 1.9817 (Forecasting Loss:0.1006 + XiCon Loss:1.8811 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1182
Validation loss decreased (0.207718 --> 0.207666).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8105196952819824
Epoch: 10, Steps: 69 Train Loss: 1.9788 (Forecasting Loss:0.1003 + XiCon Loss:1.8786 x Lambda(1.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1182
Validation loss decreased (0.207666 --> 0.207650).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8556795120239258
Epoch: 11, Steps: 69 Train Loss: 1.9799 (Forecasting Loss:0.1006 + XiCon Loss:1.8793 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207650 --> 0.207637).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.853710412979126
Epoch: 12, Steps: 69 Train Loss: 1.9846 (Forecasting Loss:0.1005 + XiCon Loss:1.8841 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207637 --> 0.207628).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8360185623168945
Epoch: 13, Steps: 69 Train Loss: 1.9887 (Forecasting Loss:0.1005 + XiCon Loss:1.8881 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207628 --> 0.207625).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8653237819671631
Epoch: 14, Steps: 69 Train Loss: 1.9883 (Forecasting Loss:0.1006 + XiCon Loss:1.8877 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207625 --> 0.207624).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8379621505737305
Epoch: 15, Steps: 69 Train Loss: 1.9814 (Forecasting Loss:0.1005 + XiCon Loss:1.8808 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207624 --> 0.207623).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9289953708648682
Epoch: 16, Steps: 69 Train Loss: 1.9869 (Forecasting Loss:0.1007 + XiCon Loss:1.8862 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207623 --> 0.207622).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.7914884090423584
Epoch: 17, Steps: 69 Train Loss: 1.9818 (Forecasting Loss:0.1002 + XiCon Loss:1.8816 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8968052864074707
Epoch: 18, Steps: 69 Train Loss: 1.9813 (Forecasting Loss:0.1005 + XiCon Loss:1.8808 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9862463474273682
Epoch: 19, Steps: 69 Train Loss: 1.9871 (Forecasting Loss:0.1005 + XiCon Loss:1.8866 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.85990309715271
Epoch: 20, Steps: 69 Train Loss: 1.9874 (Forecasting Loss:0.1006 + XiCon Loss:1.8868 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8133952617645264
Epoch: 21, Steps: 69 Train Loss: 1.9823 (Forecasting Loss:0.1006 + XiCon Loss:1.8817 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8590397834777832
Epoch: 22, Steps: 69 Train Loss: 1.9829 (Forecasting Loss:0.1006 + XiCon Loss:1.8823 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8411383628845215
Epoch: 23, Steps: 69 Train Loss: 1.9835 (Forecasting Loss:0.1005 + XiCon Loss:1.8830 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8988966941833496
Epoch: 24, Steps: 69 Train Loss: 1.9797 (Forecasting Loss:0.1006 + XiCon Loss:1.8791 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9696230888366699
Epoch: 25, Steps: 69 Train Loss: 1.9832 (Forecasting Loss:0.1007 + XiCon Loss:1.8825 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.7988054752349854
Epoch: 26, Steps: 69 Train Loss: 1.9775 (Forecasting Loss:0.1005 + XiCon Loss:1.8770 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.7883195877075195
Epoch: 27, Steps: 69 Train Loss: 1.9901 (Forecasting Loss:0.1007 + XiCon Loss:1.8894 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8572373390197754
Epoch: 28, Steps: 69 Train Loss: 1.9810 (Forecasting Loss:0.1003 + XiCon Loss:1.8807 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9577183723449707
Epoch: 29, Steps: 69 Train Loss: 1.9835 (Forecasting Loss:0.1006 + XiCon Loss:1.8829 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8012158870697021
Epoch: 30, Steps: 69 Train Loss: 1.9824 (Forecasting Loss:0.1003 + XiCon Loss:1.8821 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8579549789428711
Epoch: 31, Steps: 69 Train Loss: 1.9871 (Forecasting Loss:0.1004 + XiCon Loss:1.8867 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8537781238555908
Epoch: 32, Steps: 69 Train Loss: 1.9802 (Forecasting Loss:0.1005 + XiCon Loss:1.8797 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8848493099212646
Epoch: 33, Steps: 69 Train Loss: 1.9869 (Forecasting Loss:0.1005 + XiCon Loss:1.8864 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8162577152252197
Epoch: 34, Steps: 69 Train Loss: 1.9847 (Forecasting Loss:0.1003 + XiCon Loss:1.8844 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
Validation loss decreased (0.207622 --> 0.207622).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8459136486053467
Epoch: 35, Steps: 69 Train Loss: 1.9856 (Forecasting Loss:0.1002 + XiCon Loss:1.8854 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8484377861022949
Epoch: 36, Steps: 69 Train Loss: 1.9851 (Forecasting Loss:0.1005 + XiCon Loss:1.8846 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8936262130737305
Epoch: 37, Steps: 69 Train Loss: 1.9844 (Forecasting Loss:0.1004 + XiCon Loss:1.8840 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8170731067657471
Epoch: 38, Steps: 69 Train Loss: 1.9855 (Forecasting Loss:0.1006 + XiCon Loss:1.8849 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8303110599517822
Epoch: 39, Steps: 69 Train Loss: 1.9842 (Forecasting Loss:0.1006 + XiCon Loss:1.8835 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8260455131530762
Epoch: 40, Steps: 69 Train Loss: 1.9872 (Forecasting Loss:0.1005 + XiCon Loss:1.8867 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8301336765289307
Epoch: 41, Steps: 69 Train Loss: 1.9857 (Forecasting Loss:0.1004 + XiCon Loss:1.8853 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.877652645111084
Epoch: 42, Steps: 69 Train Loss: 1.9866 (Forecasting Loss:0.1006 + XiCon Loss:1.8860 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9007692337036133
Epoch: 43, Steps: 69 Train Loss: 1.9839 (Forecasting Loss:0.1006 + XiCon Loss:1.8833 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8262555599212646
Epoch: 44, Steps: 69 Train Loss: 1.9906 (Forecasting Loss:0.1005 + XiCon Loss:1.8901 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05586197227239609, mae:0.18042759597301483, mape:0.12635600566864014, mspe:0.03756207600235939 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5727
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8011624813079834
Epoch: 1, Steps: 69 Train Loss: 2.0186 (Forecasting Loss:0.1361 + XiCon Loss:1.8825 x Lambda(1.0)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.1508
Validation loss decreased (inf --> 0.293079).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8296434879302979
Epoch: 2, Steps: 69 Train Loss: 1.9940 (Forecasting Loss:0.1123 + XiCon Loss:1.8816 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1256
Validation loss decreased (0.293079 --> 0.212569).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.841710090637207
Epoch: 3, Steps: 69 Train Loss: 1.9783 (Forecasting Loss:0.1027 + XiCon Loss:1.8756 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1203
Validation loss decreased (0.212569 --> 0.208755).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8502578735351562
Epoch: 4, Steps: 69 Train Loss: 1.9704 (Forecasting Loss:0.1005 + XiCon Loss:1.8698 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1196
Validation loss decreased (0.208755 --> 0.206349).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8549747467041016
Epoch: 5, Steps: 69 Train Loss: 1.9665 (Forecasting Loss:0.0999 + XiCon Loss:1.8666 x Lambda(1.0)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.1190
Validation loss decreased (0.206349 --> 0.205695).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8769149780273438
Epoch: 6, Steps: 69 Train Loss: 1.9614 (Forecasting Loss:0.0995 + XiCon Loss:1.8619 x Lambda(1.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1188
Validation loss decreased (0.205695 --> 0.205346).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.7997262477874756
Epoch: 7, Steps: 69 Train Loss: 1.9661 (Forecasting Loss:0.0993 + XiCon Loss:1.8667 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1187
Validation loss decreased (0.205346 --> 0.205216).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8089754581451416
Epoch: 8, Steps: 69 Train Loss: 1.9625 (Forecasting Loss:0.0993 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1186
Validation loss decreased (0.205216 --> 0.205109).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8621311187744141
Epoch: 9, Steps: 69 Train Loss: 1.9590 (Forecasting Loss:0.0992 + XiCon Loss:1.8597 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1186
Validation loss decreased (0.205109 --> 0.205082).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.7941663265228271
Epoch: 10, Steps: 69 Train Loss: 1.9607 (Forecasting Loss:0.0992 + XiCon Loss:1.8615 x Lambda(1.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1186
Validation loss decreased (0.205082 --> 0.205058).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.7911269664764404
Epoch: 11, Steps: 69 Train Loss: 1.9603 (Forecasting Loss:0.0988 + XiCon Loss:1.8615 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1186
Validation loss decreased (0.205058 --> 0.205047).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8156919479370117
Epoch: 12, Steps: 69 Train Loss: 1.9613 (Forecasting Loss:0.0995 + XiCon Loss:1.8618 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1186
Validation loss decreased (0.205047 --> 0.205040).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8290154933929443
Epoch: 13, Steps: 69 Train Loss: 1.9626 (Forecasting Loss:0.0995 + XiCon Loss:1.8631 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205040 --> 0.205038).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8751399517059326
Epoch: 14, Steps: 69 Train Loss: 1.9593 (Forecasting Loss:0.0994 + XiCon Loss:1.8600 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205038 --> 0.205036).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9207565784454346
Epoch: 15, Steps: 69 Train Loss: 1.9580 (Forecasting Loss:0.0993 + XiCon Loss:1.8587 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205036 --> 0.205036).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8987324237823486
Epoch: 16, Steps: 69 Train Loss: 1.9639 (Forecasting Loss:0.0989 + XiCon Loss:1.8650 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205036 --> 0.205035).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8972141742706299
Epoch: 17, Steps: 69 Train Loss: 1.9618 (Forecasting Loss:0.0992 + XiCon Loss:1.8626 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8148651123046875
Epoch: 18, Steps: 69 Train Loss: 1.9632 (Forecasting Loss:0.0994 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9154791831970215
Epoch: 19, Steps: 69 Train Loss: 1.9626 (Forecasting Loss:0.0992 + XiCon Loss:1.8634 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8271372318267822
Epoch: 20, Steps: 69 Train Loss: 1.9613 (Forecasting Loss:0.0994 + XiCon Loss:1.8619 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8377947807312012
Epoch: 21, Steps: 69 Train Loss: 1.9589 (Forecasting Loss:0.0992 + XiCon Loss:1.8597 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8915159702301025
Epoch: 22, Steps: 69 Train Loss: 1.9581 (Forecasting Loss:0.0991 + XiCon Loss:1.8590 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 1.164741039276123
Epoch: 23, Steps: 69 Train Loss: 1.9599 (Forecasting Loss:0.0993 + XiCon Loss:1.8606 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9085204601287842
Epoch: 24, Steps: 69 Train Loss: 1.9600 (Forecasting Loss:0.0993 + XiCon Loss:1.8607 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8049461841583252
Epoch: 25, Steps: 69 Train Loss: 1.9597 (Forecasting Loss:0.0992 + XiCon Loss:1.8604 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8949542045593262
Epoch: 26, Steps: 69 Train Loss: 1.9598 (Forecasting Loss:0.0992 + XiCon Loss:1.8606 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8742101192474365
Epoch: 27, Steps: 69 Train Loss: 1.9607 (Forecasting Loss:0.0993 + XiCon Loss:1.8613 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9128894805908203
Epoch: 28, Steps: 69 Train Loss: 1.9603 (Forecasting Loss:0.0993 + XiCon Loss:1.8610 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8614315986633301
Epoch: 29, Steps: 69 Train Loss: 1.9607 (Forecasting Loss:0.0993 + XiCon Loss:1.8614 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.796454906463623
Epoch: 30, Steps: 69 Train Loss: 1.9606 (Forecasting Loss:0.0993 + XiCon Loss:1.8613 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8478031158447266
Epoch: 31, Steps: 69 Train Loss: 1.9634 (Forecasting Loss:0.0991 + XiCon Loss:1.8642 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8651173114776611
Epoch: 32, Steps: 69 Train Loss: 1.9628 (Forecasting Loss:0.0992 + XiCon Loss:1.8636 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8104841709136963
Epoch: 33, Steps: 69 Train Loss: 1.9624 (Forecasting Loss:0.0991 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8415060043334961
Epoch: 34, Steps: 69 Train Loss: 1.9633 (Forecasting Loss:0.0996 + XiCon Loss:1.8637 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8708546161651611
Epoch: 35, Steps: 69 Train Loss: 1.9578 (Forecasting Loss:0.0994 + XiCon Loss:1.8584 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8081748485565186
Epoch: 36, Steps: 69 Train Loss: 1.9589 (Forecasting Loss:0.0989 + XiCon Loss:1.8600 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8508336544036865
Epoch: 37, Steps: 69 Train Loss: 1.9598 (Forecasting Loss:0.0993 + XiCon Loss:1.8605 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.817375898361206
Epoch: 38, Steps: 69 Train Loss: 1.9610 (Forecasting Loss:0.0993 + XiCon Loss:1.8617 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8755381107330322
Epoch: 39, Steps: 69 Train Loss: 1.9634 (Forecasting Loss:0.0992 + XiCon Loss:1.8642 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8251917362213135
Epoch: 40, Steps: 69 Train Loss: 1.9623 (Forecasting Loss:0.0992 + XiCon Loss:1.8631 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
Validation loss decreased (0.205035 --> 0.205035).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8592348098754883
Epoch: 41, Steps: 69 Train Loss: 1.9603 (Forecasting Loss:0.0994 + XiCon Loss:1.8609 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.7899625301361084
Epoch: 42, Steps: 69 Train Loss: 1.9623 (Forecasting Loss:0.0990 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8653926849365234
Epoch: 43, Steps: 69 Train Loss: 1.9619 (Forecasting Loss:0.0993 + XiCon Loss:1.8626 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8860998153686523
Epoch: 44, Steps: 69 Train Loss: 1.9607 (Forecasting Loss:0.0994 + XiCon Loss:1.8613 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8603055477142334
Epoch: 45, Steps: 69 Train Loss: 1.9624 (Forecasting Loss:0.0992 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.773411750793457
Epoch: 46, Steps: 69 Train Loss: 1.9582 (Forecasting Loss:0.0990 + XiCon Loss:1.8592 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8528745174407959
Epoch: 47, Steps: 69 Train Loss: 1.9643 (Forecasting Loss:0.0994 + XiCon Loss:1.8649 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8020241260528564
Epoch: 48, Steps: 69 Train Loss: 1.9596 (Forecasting Loss:0.0990 + XiCon Loss:1.8606 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8934319019317627
Epoch: 49, Steps: 69 Train Loss: 1.9597 (Forecasting Loss:0.0992 + XiCon Loss:1.8605 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9304635524749756
Epoch: 50, Steps: 69 Train Loss: 1.9595 (Forecasting Loss:0.0993 + XiCon Loss:1.8602 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1185
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.056178800761699677, mae:0.18091627955436707, mape:0.12686672806739807, mspe:0.03787368908524513 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5757
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9474964141845703
Epoch: 1, Steps: 69 Train Loss: 2.0166 (Forecasting Loss:0.1337 + XiCon Loss:1.8829 x Lambda(1.0)), Vali MSE Loss: 0.2872 Test MSE Loss: 0.1500
Validation loss decreased (inf --> 0.287175).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8376266956329346
Epoch: 2, Steps: 69 Train Loss: 1.9893 (Forecasting Loss:0.1129 + XiCon Loss:1.8764 x Lambda(1.0)), Vali MSE Loss: 0.2176 Test MSE Loss: 0.1241
Validation loss decreased (0.287175 --> 0.217581).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8264656066894531
Epoch: 3, Steps: 69 Train Loss: 1.9742 (Forecasting Loss:0.1037 + XiCon Loss:1.8705 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1214
Validation loss decreased (0.217581 --> 0.213593).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8857707977294922
Epoch: 4, Steps: 69 Train Loss: 1.9699 (Forecasting Loss:0.1019 + XiCon Loss:1.8680 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1202
Validation loss decreased (0.213593 --> 0.211525).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9818437099456787
Epoch: 5, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1017 + XiCon Loss:1.8665 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1196
Validation loss decreased (0.211525 --> 0.210585).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8744754791259766
Epoch: 6, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1014 + XiCon Loss:1.8668 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1193
Validation loss decreased (0.210585 --> 0.210032).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8286316394805908
Epoch: 7, Steps: 69 Train Loss: 1.9753 (Forecasting Loss:0.1011 + XiCon Loss:1.8742 x Lambda(1.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1192
Validation loss decreased (0.210032 --> 0.209859).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8961868286132812
Epoch: 8, Steps: 69 Train Loss: 1.9744 (Forecasting Loss:0.1009 + XiCon Loss:1.8735 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1191
Validation loss decreased (0.209859 --> 0.209690).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0127391815185547
Epoch: 9, Steps: 69 Train Loss: 1.9712 (Forecasting Loss:0.1008 + XiCon Loss:1.8703 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1191
Validation loss decreased (0.209690 --> 0.209619).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8440027236938477
Epoch: 10, Steps: 69 Train Loss: 1.9675 (Forecasting Loss:0.1009 + XiCon Loss:1.8666 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1191
Validation loss decreased (0.209619 --> 0.209576).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9366612434387207
Epoch: 11, Steps: 69 Train Loss: 1.9668 (Forecasting Loss:0.1009 + XiCon Loss:1.8659 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1191
Validation loss decreased (0.209576 --> 0.209557).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8791062831878662
Epoch: 12, Steps: 69 Train Loss: 1.9688 (Forecasting Loss:0.1009 + XiCon Loss:1.8680 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1191
Validation loss decreased (0.209557 --> 0.209548).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.7709810733795166
Epoch: 13, Steps: 69 Train Loss: 1.9768 (Forecasting Loss:0.1010 + XiCon Loss:1.8758 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1191
Validation loss decreased (0.209548 --> 0.209543).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9026010036468506
Epoch: 14, Steps: 69 Train Loss: 1.9721 (Forecasting Loss:0.1011 + XiCon Loss:1.8709 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209543 --> 0.209540).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8506922721862793
Epoch: 15, Steps: 69 Train Loss: 1.9716 (Forecasting Loss:0.1008 + XiCon Loss:1.8707 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209540 --> 0.209539).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8248331546783447
Epoch: 16, Steps: 69 Train Loss: 1.9711 (Forecasting Loss:0.1012 + XiCon Loss:1.8700 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209539 --> 0.209539).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8523368835449219
Epoch: 17, Steps: 69 Train Loss: 1.9708 (Forecasting Loss:0.1009 + XiCon Loss:1.8699 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209539 --> 0.209538).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8533737659454346
Epoch: 18, Steps: 69 Train Loss: 1.9676 (Forecasting Loss:0.1010 + XiCon Loss:1.8666 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209538 --> 0.209538).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.815087080001831
Epoch: 19, Steps: 69 Train Loss: 1.9769 (Forecasting Loss:0.1009 + XiCon Loss:1.8760 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209538 --> 0.209538).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.88869309425354
Epoch: 20, Steps: 69 Train Loss: 1.9709 (Forecasting Loss:0.1009 + XiCon Loss:1.8700 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209538 --> 0.209538).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8179268836975098
Epoch: 21, Steps: 69 Train Loss: 1.9654 (Forecasting Loss:0.1009 + XiCon Loss:1.8644 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209538 --> 0.209538).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8451886177062988
Epoch: 22, Steps: 69 Train Loss: 1.9662 (Forecasting Loss:0.1009 + XiCon Loss:1.8653 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8288018703460693
Epoch: 23, Steps: 69 Train Loss: 1.9716 (Forecasting Loss:0.1011 + XiCon Loss:1.8705 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
Validation loss decreased (0.209538 --> 0.209538).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8170204162597656
Epoch: 24, Steps: 69 Train Loss: 1.9716 (Forecasting Loss:0.1011 + XiCon Loss:1.8705 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8536128997802734
Epoch: 25, Steps: 69 Train Loss: 1.9695 (Forecasting Loss:0.1012 + XiCon Loss:1.8683 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8622653484344482
Epoch: 26, Steps: 69 Train Loss: 1.9721 (Forecasting Loss:0.1010 + XiCon Loss:1.8711 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9331765174865723
Epoch: 27, Steps: 69 Train Loss: 1.9677 (Forecasting Loss:0.1012 + XiCon Loss:1.8665 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9040169715881348
Epoch: 28, Steps: 69 Train Loss: 1.9692 (Forecasting Loss:0.1011 + XiCon Loss:1.8680 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.89335036277771
Epoch: 29, Steps: 69 Train Loss: 1.9684 (Forecasting Loss:0.1009 + XiCon Loss:1.8676 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.831789493560791
Epoch: 30, Steps: 69 Train Loss: 1.9717 (Forecasting Loss:0.1011 + XiCon Loss:1.8706 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8191623687744141
Epoch: 31, Steps: 69 Train Loss: 1.9686 (Forecasting Loss:0.1010 + XiCon Loss:1.8677 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9030241966247559
Epoch: 32, Steps: 69 Train Loss: 1.9665 (Forecasting Loss:0.1011 + XiCon Loss:1.8654 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.806389570236206
Epoch: 33, Steps: 69 Train Loss: 1.9690 (Forecasting Loss:0.1011 + XiCon Loss:1.8679 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1190
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05646821856498718, mae:0.18162834644317627, mape:0.12710824608802795, mspe:0.03775768727064133 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5653
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8915300369262695
Epoch: 1, Steps: 69 Train Loss: 2.0203 (Forecasting Loss:0.1376 + XiCon Loss:1.8828 x Lambda(1.0)), Vali MSE Loss: 0.2971 Test MSE Loss: 0.1523
Validation loss decreased (inf --> 0.297075).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.842170238494873
Epoch: 2, Steps: 69 Train Loss: 1.9916 (Forecasting Loss:0.1143 + XiCon Loss:1.8773 x Lambda(1.0)), Vali MSE Loss: 0.2152 Test MSE Loss: 0.1230
Validation loss decreased (0.297075 --> 0.215205).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8525738716125488
Epoch: 3, Steps: 69 Train Loss: 1.9581 (Forecasting Loss:0.1034 + XiCon Loss:1.8547 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1226
Validation loss decreased (0.215205 --> 0.212910).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.7864828109741211
Epoch: 4, Steps: 69 Train Loss: 1.9502 (Forecasting Loss:0.1021 + XiCon Loss:1.8481 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1214
Validation loss decreased (0.212910 --> 0.212505).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8146817684173584
Epoch: 5, Steps: 69 Train Loss: 1.9573 (Forecasting Loss:0.1016 + XiCon Loss:1.8557 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1208
Validation loss decreased (0.212505 --> 0.211749).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7987356185913086
Epoch: 6, Steps: 69 Train Loss: 1.9659 (Forecasting Loss:0.1013 + XiCon Loss:1.8646 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1204
Validation loss decreased (0.211749 --> 0.211216).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8694260120391846
Epoch: 7, Steps: 69 Train Loss: 1.9638 (Forecasting Loss:0.1012 + XiCon Loss:1.8626 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1201
Validation loss decreased (0.211216 --> 0.210901).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9008305072784424
Epoch: 8, Steps: 69 Train Loss: 1.9637 (Forecasting Loss:0.1011 + XiCon Loss:1.8627 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1201
Validation loss decreased (0.210901 --> 0.210716).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8101603984832764
Epoch: 9, Steps: 69 Train Loss: 1.9615 (Forecasting Loss:0.1010 + XiCon Loss:1.8605 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210716 --> 0.210643).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8744344711303711
Epoch: 10, Steps: 69 Train Loss: 1.9649 (Forecasting Loss:0.1007 + XiCon Loss:1.8642 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210643 --> 0.210618).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8104000091552734
Epoch: 11, Steps: 69 Train Loss: 1.9694 (Forecasting Loss:0.1011 + XiCon Loss:1.8683 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210618 --> 0.210598).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8577284812927246
Epoch: 12, Steps: 69 Train Loss: 1.9703 (Forecasting Loss:0.1007 + XiCon Loss:1.8696 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210598 --> 0.210589).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8293423652648926
Epoch: 13, Steps: 69 Train Loss: 1.9649 (Forecasting Loss:0.1009 + XiCon Loss:1.8640 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210589 --> 0.210585).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8457627296447754
Epoch: 14, Steps: 69 Train Loss: 1.9673 (Forecasting Loss:0.1010 + XiCon Loss:1.8664 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210585 --> 0.210583).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8547248840332031
Epoch: 15, Steps: 69 Train Loss: 1.9734 (Forecasting Loss:0.1009 + XiCon Loss:1.8724 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210583 --> 0.210582).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8752217292785645
Epoch: 16, Steps: 69 Train Loss: 1.9646 (Forecasting Loss:0.1007 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210582 --> 0.210582).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8652493953704834
Epoch: 17, Steps: 69 Train Loss: 1.9654 (Forecasting Loss:0.1010 + XiCon Loss:1.8644 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210582 --> 0.210581).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8353056907653809
Epoch: 18, Steps: 69 Train Loss: 1.9623 (Forecasting Loss:0.1009 + XiCon Loss:1.8614 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8657026290893555
Epoch: 19, Steps: 69 Train Loss: 1.9645 (Forecasting Loss:0.1007 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8238742351531982
Epoch: 20, Steps: 69 Train Loss: 1.9678 (Forecasting Loss:0.1008 + XiCon Loss:1.8670 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9498915672302246
Epoch: 21, Steps: 69 Train Loss: 1.9684 (Forecasting Loss:0.1010 + XiCon Loss:1.8673 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8593943119049072
Epoch: 22, Steps: 69 Train Loss: 1.9745 (Forecasting Loss:0.1007 + XiCon Loss:1.8738 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8250088691711426
Epoch: 23, Steps: 69 Train Loss: 1.9693 (Forecasting Loss:0.1008 + XiCon Loss:1.8684 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8516309261322021
Epoch: 24, Steps: 69 Train Loss: 1.9689 (Forecasting Loss:0.1009 + XiCon Loss:1.8680 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8112473487854004
Epoch: 25, Steps: 69 Train Loss: 1.9703 (Forecasting Loss:0.1009 + XiCon Loss:1.8694 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8043479919433594
Epoch: 26, Steps: 69 Train Loss: 1.9684 (Forecasting Loss:0.1008 + XiCon Loss:1.8676 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9031591415405273
Epoch: 27, Steps: 69 Train Loss: 1.9640 (Forecasting Loss:0.1009 + XiCon Loss:1.8631 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8957457542419434
Epoch: 28, Steps: 69 Train Loss: 1.9647 (Forecasting Loss:0.1008 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.78739333152771
Epoch: 29, Steps: 69 Train Loss: 1.9617 (Forecasting Loss:0.1009 + XiCon Loss:1.8608 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.7953550815582275
Epoch: 30, Steps: 69 Train Loss: 1.9644 (Forecasting Loss:0.1008 + XiCon Loss:1.8636 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8462848663330078
Epoch: 31, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1010 + XiCon Loss:1.8672 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8551578521728516
Epoch: 32, Steps: 69 Train Loss: 1.9765 (Forecasting Loss:0.1011 + XiCon Loss:1.8754 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8528156280517578
Epoch: 33, Steps: 69 Train Loss: 1.9650 (Forecasting Loss:0.1010 + XiCon Loss:1.8641 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8422420024871826
Epoch: 34, Steps: 69 Train Loss: 1.9654 (Forecasting Loss:0.1005 + XiCon Loss:1.8648 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8388350009918213
Epoch: 35, Steps: 69 Train Loss: 1.9677 (Forecasting Loss:0.1010 + XiCon Loss:1.8667 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.011230230331421
Epoch: 36, Steps: 69 Train Loss: 1.9611 (Forecasting Loss:0.1008 + XiCon Loss:1.8603 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.7931244373321533
Epoch: 37, Steps: 69 Train Loss: 1.9637 (Forecasting Loss:0.1004 + XiCon Loss:1.8632 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8498904705047607
Epoch: 38, Steps: 69 Train Loss: 1.9644 (Forecasting Loss:0.1009 + XiCon Loss:1.8635 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9223675727844238
Epoch: 39, Steps: 69 Train Loss: 1.9689 (Forecasting Loss:0.1010 + XiCon Loss:1.8680 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8338582515716553
Epoch: 40, Steps: 69 Train Loss: 1.9709 (Forecasting Loss:0.1008 + XiCon Loss:1.8700 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9478802680969238
Epoch: 41, Steps: 69 Train Loss: 1.9677 (Forecasting Loss:0.1009 + XiCon Loss:1.8668 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.7940568923950195
Epoch: 42, Steps: 69 Train Loss: 1.9673 (Forecasting Loss:0.1008 + XiCon Loss:1.8665 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8572018146514893
Epoch: 43, Steps: 69 Train Loss: 1.9638 (Forecasting Loss:0.1010 + XiCon Loss:1.8629 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8457839488983154
Epoch: 44, Steps: 69 Train Loss: 1.9640 (Forecasting Loss:0.1011 + XiCon Loss:1.8629 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8406863212585449
Epoch: 45, Steps: 69 Train Loss: 1.9658 (Forecasting Loss:0.1009 + XiCon Loss:1.8649 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.9116127490997314
Epoch: 46, Steps: 69 Train Loss: 1.9631 (Forecasting Loss:0.1009 + XiCon Loss:1.8622 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8960967063903809
Epoch: 47, Steps: 69 Train Loss: 1.9701 (Forecasting Loss:0.1009 + XiCon Loss:1.8692 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.9211366176605225
Epoch: 48, Steps: 69 Train Loss: 1.9688 (Forecasting Loss:0.1007 + XiCon Loss:1.8681 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.7812659740447998
Epoch: 49, Steps: 69 Train Loss: 1.9626 (Forecasting Loss:0.1008 + XiCon Loss:1.8618 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8213911056518555
Epoch: 50, Steps: 69 Train Loss: 1.9643 (Forecasting Loss:0.1008 + XiCon Loss:1.8634 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9200608730316162
Epoch: 51, Steps: 69 Train Loss: 1.9672 (Forecasting Loss:0.1009 + XiCon Loss:1.8663 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.8767795562744141
Epoch: 52, Steps: 69 Train Loss: 1.9714 (Forecasting Loss:0.1008 + XiCon Loss:1.8705 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8426344394683838
Epoch: 53, Steps: 69 Train Loss: 1.9722 (Forecasting Loss:0.1011 + XiCon Loss:1.8711 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.856830358505249
Epoch: 54, Steps: 69 Train Loss: 1.9631 (Forecasting Loss:0.1009 + XiCon Loss:1.8622 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.840994119644165
Epoch: 55, Steps: 69 Train Loss: 1.9706 (Forecasting Loss:0.1008 + XiCon Loss:1.8698 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8889815807342529
Epoch: 56, Steps: 69 Train Loss: 1.9634 (Forecasting Loss:0.1009 + XiCon Loss:1.8625 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.8750650882720947
Epoch: 57, Steps: 69 Train Loss: 1.9600 (Forecasting Loss:0.1009 + XiCon Loss:1.8591 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8516530990600586
Epoch: 58, Steps: 69 Train Loss: 1.9687 (Forecasting Loss:0.1008 + XiCon Loss:1.8679 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
Validation loss decreased (0.210581 --> 0.210581).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.8492226600646973
Epoch: 59, Steps: 69 Train Loss: 1.9668 (Forecasting Loss:0.1009 + XiCon Loss:1.8659 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.8690047264099121
Epoch: 60, Steps: 69 Train Loss: 1.9651 (Forecasting Loss:0.1006 + XiCon Loss:1.8644 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.8041043281555176
Epoch: 61, Steps: 69 Train Loss: 1.9696 (Forecasting Loss:0.1008 + XiCon Loss:1.8688 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.8345637321472168
Epoch: 62, Steps: 69 Train Loss: 1.9748 (Forecasting Loss:0.1005 + XiCon Loss:1.8742 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.9086735248565674
Epoch: 63, Steps: 69 Train Loss: 1.9683 (Forecasting Loss:0.1008 + XiCon Loss:1.8675 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.8699843883514404
Epoch: 64, Steps: 69 Train Loss: 1.9712 (Forecasting Loss:0.1010 + XiCon Loss:1.8702 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.8075416088104248
Epoch: 65, Steps: 69 Train Loss: 1.9670 (Forecasting Loss:0.1008 + XiCon Loss:1.8662 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.8250021934509277
Epoch: 66, Steps: 69 Train Loss: 1.9673 (Forecasting Loss:0.1008 + XiCon Loss:1.8664 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.8817131519317627
Epoch: 67, Steps: 69 Train Loss: 1.9651 (Forecasting Loss:0.1008 + XiCon Loss:1.8643 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.8254678249359131
Epoch: 68, Steps: 69 Train Loss: 1.9729 (Forecasting Loss:0.1009 + XiCon Loss:1.8720 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1200
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.057288073003292084, mae:0.1827080100774765, mape:0.12821181118488312, mspe:0.03860503062605858 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0563+-0.00075, MAE:0.1812+-0.00123, MAPE:0.1270+-0.00092, MSPE:0.0379+-0.00051, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5751
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2303924560546875
Epoch: 1, Steps: 64 Train Loss: 19.4751 (Forecasting Loss:0.5016 + XiCon Loss:1.8974 x Lambda(10.0)), Vali MSE Loss: 0.9639 Test MSE Loss: 0.5135
Validation loss decreased (inf --> 0.963855).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9701433181762695
Epoch: 2, Steps: 64 Train Loss: 19.4586 (Forecasting Loss:0.4974 + XiCon Loss:1.8961 x Lambda(10.0)), Vali MSE Loss: 0.9529 Test MSE Loss: 0.5068
Validation loss decreased (0.963855 --> 0.952945).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9319062232971191
Epoch: 3, Steps: 64 Train Loss: 19.4486 (Forecasting Loss:0.4909 + XiCon Loss:1.8958 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.5042
Validation loss decreased (0.952945 --> 0.942600).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.86883544921875
Epoch: 4, Steps: 64 Train Loss: 19.4132 (Forecasting Loss:0.4890 + XiCon Loss:1.8924 x Lambda(10.0)), Vali MSE Loss: 0.9451 Test MSE Loss: 0.5029
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9585216045379639
Epoch: 5, Steps: 64 Train Loss: 19.4268 (Forecasting Loss:0.4864 + XiCon Loss:1.8940 x Lambda(10.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5023
Validation loss decreased (0.942600 --> 0.938758).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8991296291351318
Epoch: 6, Steps: 64 Train Loss: 19.4307 (Forecasting Loss:0.4857 + XiCon Loss:1.8945 x Lambda(10.0)), Vali MSE Loss: 0.9389 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9102261066436768
Epoch: 7, Steps: 64 Train Loss: 19.4299 (Forecasting Loss:0.4858 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5019
Validation loss decreased (0.938758 --> 0.936984).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9112980365753174
Epoch: 8, Steps: 64 Train Loss: 19.4432 (Forecasting Loss:0.4855 + XiCon Loss:1.8958 x Lambda(10.0)), Vali MSE Loss: 0.9368 Test MSE Loss: 0.5018
Validation loss decreased (0.936984 --> 0.936769).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9142677783966064
Epoch: 9, Steps: 64 Train Loss: 19.4358 (Forecasting Loss:0.4848 + XiCon Loss:1.8951 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5018
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9253618717193604
Epoch: 10, Steps: 64 Train Loss: 19.4233 (Forecasting Loss:0.4844 + XiCon Loss:1.8939 x Lambda(10.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.863163948059082
Epoch: 11, Steps: 64 Train Loss: 19.4162 (Forecasting Loss:0.4856 + XiCon Loss:1.8931 x Lambda(10.0)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8767485618591309
Epoch: 12, Steps: 64 Train Loss: 19.4645 (Forecasting Loss:0.4852 + XiCon Loss:1.8979 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8713953495025635
Epoch: 13, Steps: 64 Train Loss: 19.4099 (Forecasting Loss:0.4855 + XiCon Loss:1.8924 x Lambda(10.0)), Vali MSE Loss: 0.9397 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9273736476898193
Epoch: 14, Steps: 64 Train Loss: 19.4264 (Forecasting Loss:0.4847 + XiCon Loss:1.8942 x Lambda(10.0)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9311776161193848
Epoch: 15, Steps: 64 Train Loss: 19.4148 (Forecasting Loss:0.4859 + XiCon Loss:1.8929 x Lambda(10.0)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9021353721618652
Epoch: 16, Steps: 64 Train Loss: 19.4053 (Forecasting Loss:0.4849 + XiCon Loss:1.8920 x Lambda(10.0)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8821666240692139
Epoch: 17, Steps: 64 Train Loss: 19.4333 (Forecasting Loss:0.4858 + XiCon Loss:1.8947 x Lambda(10.0)), Vali MSE Loss: 0.9358 Test MSE Loss: 0.5017
Validation loss decreased (0.936769 --> 0.935775).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9005727767944336
Epoch: 18, Steps: 64 Train Loss: 19.4223 (Forecasting Loss:0.4857 + XiCon Loss:1.8937 x Lambda(10.0)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.893531322479248
Epoch: 19, Steps: 64 Train Loss: 19.4289 (Forecasting Loss:0.4857 + XiCon Loss:1.8943 x Lambda(10.0)), Vali MSE Loss: 0.9390 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8603518009185791
Epoch: 20, Steps: 64 Train Loss: 19.4139 (Forecasting Loss:0.4852 + XiCon Loss:1.8929 x Lambda(10.0)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8773150444030762
Epoch: 21, Steps: 64 Train Loss: 19.4295 (Forecasting Loss:0.4847 + XiCon Loss:1.8945 x Lambda(10.0)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9195539951324463
Epoch: 22, Steps: 64 Train Loss: 19.4544 (Forecasting Loss:0.4847 + XiCon Loss:1.8970 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9260914325714111
Epoch: 23, Steps: 64 Train Loss: 19.4307 (Forecasting Loss:0.4845 + XiCon Loss:1.8946 x Lambda(10.0)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.899024486541748
Epoch: 24, Steps: 64 Train Loss: 19.4073 (Forecasting Loss:0.4857 + XiCon Loss:1.8922 x Lambda(10.0)), Vali MSE Loss: 0.9394 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8891592025756836
Epoch: 25, Steps: 64 Train Loss: 19.4308 (Forecasting Loss:0.4846 + XiCon Loss:1.8946 x Lambda(10.0)), Vali MSE Loss: 0.9402 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9164421558380127
Epoch: 26, Steps: 64 Train Loss: 19.4466 (Forecasting Loss:0.4845 + XiCon Loss:1.8962 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8414428234100342
Epoch: 27, Steps: 64 Train Loss: 19.4165 (Forecasting Loss:0.4851 + XiCon Loss:1.8931 x Lambda(10.0)), Vali MSE Loss: 0.9399 Test MSE Loss: 0.5017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4701686203479767, mae:0.5332624912261963, mape:0.4495932459831238, mspe:0.5999889373779297 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5818
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9076993465423584
Epoch: 1, Steps: 64 Train Loss: 19.4181 (Forecasting Loss:0.4928 + XiCon Loss:1.8925 x Lambda(10.0)), Vali MSE Loss: 0.9330 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932956).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9214611053466797
Epoch: 2, Steps: 64 Train Loss: 19.4045 (Forecasting Loss:0.4901 + XiCon Loss:1.8914 x Lambda(10.0)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932956 --> 0.915082).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9248390197753906
Epoch: 3, Steps: 64 Train Loss: 19.4029 (Forecasting Loss:0.4837 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.9128 Test MSE Loss: 0.5130
Validation loss decreased (0.915082 --> 0.912768).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9446184635162354
Epoch: 4, Steps: 64 Train Loss: 19.4302 (Forecasting Loss:0.4808 + XiCon Loss:1.8949 x Lambda(10.0)), Vali MSE Loss: 0.9097 Test MSE Loss: 0.5118
Validation loss decreased (0.912768 --> 0.909696).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9158499240875244
Epoch: 5, Steps: 64 Train Loss: 19.4220 (Forecasting Loss:0.4798 + XiCon Loss:1.8942 x Lambda(10.0)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5113
Validation loss decreased (0.909696 --> 0.907150).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8629164695739746
Epoch: 6, Steps: 64 Train Loss: 19.3864 (Forecasting Loss:0.4799 + XiCon Loss:1.8907 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5110
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.005845546722412
Epoch: 7, Steps: 64 Train Loss: 19.3855 (Forecasting Loss:0.4789 + XiCon Loss:1.8907 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8776750564575195
Epoch: 8, Steps: 64 Train Loss: 19.4002 (Forecasting Loss:0.4784 + XiCon Loss:1.8922 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5108
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.882976770401001
Epoch: 9, Steps: 64 Train Loss: 19.4100 (Forecasting Loss:0.4793 + XiCon Loss:1.8931 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5108
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9272546768188477
Epoch: 10, Steps: 64 Train Loss: 19.4262 (Forecasting Loss:0.4788 + XiCon Loss:1.8947 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8897075653076172
Epoch: 11, Steps: 64 Train Loss: 19.4179 (Forecasting Loss:0.4778 + XiCon Loss:1.8940 x Lambda(10.0)), Vali MSE Loss: 0.9085 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.911186695098877
Epoch: 12, Steps: 64 Train Loss: 19.3895 (Forecasting Loss:0.4791 + XiCon Loss:1.8910 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
Validation loss decreased (0.907150 --> 0.906442).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9220244884490967
Epoch: 13, Steps: 64 Train Loss: 19.3980 (Forecasting Loss:0.4778 + XiCon Loss:1.8920 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906442 --> 0.906224).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9472751617431641
Epoch: 14, Steps: 64 Train Loss: 19.4073 (Forecasting Loss:0.4780 + XiCon Loss:1.8929 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8945412635803223
Epoch: 15, Steps: 64 Train Loss: 19.3912 (Forecasting Loss:0.4801 + XiCon Loss:1.8911 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8962907791137695
Epoch: 16, Steps: 64 Train Loss: 19.3983 (Forecasting Loss:0.4790 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906224 --> 0.906196).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8763735294342041
Epoch: 17, Steps: 64 Train Loss: 19.4070 (Forecasting Loss:0.4784 + XiCon Loss:1.8929 x Lambda(10.0)), Vali MSE Loss: 0.9035 Test MSE Loss: 0.5107
Validation loss decreased (0.906196 --> 0.903503).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9192678928375244
Epoch: 18, Steps: 64 Train Loss: 19.4222 (Forecasting Loss:0.4780 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9388730525970459
Epoch: 19, Steps: 64 Train Loss: 19.4013 (Forecasting Loss:0.4789 + XiCon Loss:1.8922 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9491596221923828
Epoch: 20, Steps: 64 Train Loss: 19.3930 (Forecasting Loss:0.4784 + XiCon Loss:1.8915 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9097042083740234
Epoch: 21, Steps: 64 Train Loss: 19.4046 (Forecasting Loss:0.4780 + XiCon Loss:1.8927 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.8815710544586182
Epoch: 22, Steps: 64 Train Loss: 19.3958 (Forecasting Loss:0.4784 + XiCon Loss:1.8917 x Lambda(10.0)), Vali MSE Loss: 0.9012 Test MSE Loss: 0.5107
Validation loss decreased (0.903503 --> 0.901209).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9240872859954834
Epoch: 23, Steps: 64 Train Loss: 19.4019 (Forecasting Loss:0.4781 + XiCon Loss:1.8924 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9836125373840332
Epoch: 24, Steps: 64 Train Loss: 19.3985 (Forecasting Loss:0.4786 + XiCon Loss:1.8920 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8485507965087891
Epoch: 25, Steps: 64 Train Loss: 19.4016 (Forecasting Loss:0.4777 + XiCon Loss:1.8924 x Lambda(10.0)), Vali MSE Loss: 0.9028 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.893242597579956
Epoch: 26, Steps: 64 Train Loss: 19.4021 (Forecasting Loss:0.4798 + XiCon Loss:1.8922 x Lambda(10.0)), Vali MSE Loss: 0.9050 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8937814235687256
Epoch: 27, Steps: 64 Train Loss: 19.4049 (Forecasting Loss:0.4790 + XiCon Loss:1.8926 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.923670768737793
Epoch: 28, Steps: 64 Train Loss: 19.3944 (Forecasting Loss:0.4782 + XiCon Loss:1.8916 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 0.9186403751373291
Epoch: 29, Steps: 64 Train Loss: 19.4042 (Forecasting Loss:0.4786 + XiCon Loss:1.8926 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.8927783966064453
Epoch: 30, Steps: 64 Train Loss: 19.3947 (Forecasting Loss:0.4779 + XiCon Loss:1.8917 x Lambda(10.0)), Vali MSE Loss: 0.9104 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.8886847496032715
Epoch: 31, Steps: 64 Train Loss: 19.4115 (Forecasting Loss:0.4793 + XiCon Loss:1.8932 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 0.8830249309539795
Epoch: 32, Steps: 64 Train Loss: 19.3881 (Forecasting Loss:0.4787 + XiCon Loss:1.8909 x Lambda(10.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.48463982343673706, mae:0.5368221998214722, mape:0.45702749490737915, mspe:0.6300171613693237 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5599
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9523983001708984
Epoch: 1, Steps: 64 Train Loss: 19.4473 (Forecasting Loss:0.5013 + XiCon Loss:1.8946 x Lambda(10.0)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973866).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8501958847045898
Epoch: 2, Steps: 64 Train Loss: 19.4881 (Forecasting Loss:0.4983 + XiCon Loss:1.8990 x Lambda(10.0)), Vali MSE Loss: 0.9577 Test MSE Loss: 0.5002
Validation loss decreased (0.973866 --> 0.957696).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9961652755737305
Epoch: 3, Steps: 64 Train Loss: 19.4322 (Forecasting Loss:0.4914 + XiCon Loss:1.8941 x Lambda(10.0)), Vali MSE Loss: 0.9526 Test MSE Loss: 0.4981
Validation loss decreased (0.957696 --> 0.952617).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.994443416595459
Epoch: 4, Steps: 64 Train Loss: 19.4543 (Forecasting Loss:0.4903 + XiCon Loss:1.8964 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4972
Validation loss decreased (0.952617 --> 0.950818).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8696246147155762
Epoch: 5, Steps: 64 Train Loss: 19.4308 (Forecasting Loss:0.4878 + XiCon Loss:1.8943 x Lambda(10.0)), Vali MSE Loss: 0.9474 Test MSE Loss: 0.4968
Validation loss decreased (0.950818 --> 0.947353).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8520886898040771
Epoch: 6, Steps: 64 Train Loss: 19.4313 (Forecasting Loss:0.4877 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9504 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9089021682739258
Epoch: 7, Steps: 64 Train Loss: 19.4394 (Forecasting Loss:0.4863 + XiCon Loss:1.8953 x Lambda(10.0)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.4965
Validation loss decreased (0.947353 --> 0.944017).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9141027927398682
Epoch: 8, Steps: 64 Train Loss: 19.4296 (Forecasting Loss:0.4872 + XiCon Loss:1.8942 x Lambda(10.0)), Vali MSE Loss: 0.9462 Test MSE Loss: 0.4965
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0055837631225586
Epoch: 9, Steps: 64 Train Loss: 19.4477 (Forecasting Loss:0.4860 + XiCon Loss:1.8962 x Lambda(10.0)), Vali MSE Loss: 0.9503 Test MSE Loss: 0.4965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8719890117645264
Epoch: 10, Steps: 64 Train Loss: 19.4219 (Forecasting Loss:0.4859 + XiCon Loss:1.8936 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.4964
Validation loss decreased (0.944017 --> 0.942621).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8835594654083252
Epoch: 11, Steps: 64 Train Loss: 19.4465 (Forecasting Loss:0.4865 + XiCon Loss:1.8960 x Lambda(10.0)), Vali MSE Loss: 0.9441 Test MSE Loss: 0.4964
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8836884498596191
Epoch: 12, Steps: 64 Train Loss: 19.4680 (Forecasting Loss:0.4871 + XiCon Loss:1.8981 x Lambda(10.0)), Vali MSE Loss: 0.9507 Test MSE Loss: 0.4964
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8914237022399902
Epoch: 13, Steps: 64 Train Loss: 19.4140 (Forecasting Loss:0.4871 + XiCon Loss:1.8927 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8589518070220947
Epoch: 14, Steps: 64 Train Loss: 19.4587 (Forecasting Loss:0.4868 + XiCon Loss:1.8972 x Lambda(10.0)), Vali MSE Loss: 0.9449 Test MSE Loss: 0.4964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8854296207427979
Epoch: 15, Steps: 64 Train Loss: 19.4652 (Forecasting Loss:0.4862 + XiCon Loss:1.8979 x Lambda(10.0)), Vali MSE Loss: 0.9466 Test MSE Loss: 0.4964
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.0010509490966797
Epoch: 16, Steps: 64 Train Loss: 19.4458 (Forecasting Loss:0.4870 + XiCon Loss:1.8959 x Lambda(10.0)), Vali MSE Loss: 0.9486 Test MSE Loss: 0.4964
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9206464290618896
Epoch: 17, Steps: 64 Train Loss: 19.4312 (Forecasting Loss:0.4873 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9030478000640869
Epoch: 18, Steps: 64 Train Loss: 19.4166 (Forecasting Loss:0.4859 + XiCon Loss:1.8931 x Lambda(10.0)), Vali MSE Loss: 0.9480 Test MSE Loss: 0.4964
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9031388759613037
Epoch: 19, Steps: 64 Train Loss: 19.4409 (Forecasting Loss:0.4860 + XiCon Loss:1.8955 x Lambda(10.0)), Vali MSE Loss: 0.9445 Test MSE Loss: 0.4964
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8855328559875488
Epoch: 20, Steps: 64 Train Loss: 19.4779 (Forecasting Loss:0.4859 + XiCon Loss:1.8992 x Lambda(10.0)), Vali MSE Loss: 0.9427 Test MSE Loss: 0.4964
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4627159535884857, mae:0.5301709175109863, mape:0.44492459297180176, mspe:0.5856784582138062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5637
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.8924760818481445
Epoch: 1, Steps: 64 Train Loss: 19.4351 (Forecasting Loss:0.4951 + XiCon Loss:1.8940 x Lambda(10.0)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933434).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9308822154998779
Epoch: 2, Steps: 64 Train Loss: 19.4090 (Forecasting Loss:0.4905 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.9194 Test MSE Loss: 0.5152
Validation loss decreased (0.933434 --> 0.919416).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9137959480285645
Epoch: 3, Steps: 64 Train Loss: 19.4337 (Forecasting Loss:0.4821 + XiCon Loss:1.8952 x Lambda(10.0)), Vali MSE Loss: 0.9156 Test MSE Loss: 0.5120
Validation loss decreased (0.919416 --> 0.915638).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9141881465911865
Epoch: 4, Steps: 64 Train Loss: 19.4237 (Forecasting Loss:0.4807 + XiCon Loss:1.8943 x Lambda(10.0)), Vali MSE Loss: 0.9115 Test MSE Loss: 0.5105
Validation loss decreased (0.915638 --> 0.911511).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8705401420593262
Epoch: 5, Steps: 64 Train Loss: 19.4514 (Forecasting Loss:0.4796 + XiCon Loss:1.8972 x Lambda(10.0)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5099
Validation loss decreased (0.911511 --> 0.906587).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9059741497039795
Epoch: 6, Steps: 64 Train Loss: 19.4110 (Forecasting Loss:0.4798 + XiCon Loss:1.8931 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5095
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8826150894165039
Epoch: 7, Steps: 64 Train Loss: 19.4400 (Forecasting Loss:0.4791 + XiCon Loss:1.8961 x Lambda(10.0)), Vali MSE Loss: 0.9099 Test MSE Loss: 0.5093
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9080193042755127
Epoch: 8, Steps: 64 Train Loss: 19.4195 (Forecasting Loss:0.4781 + XiCon Loss:1.8941 x Lambda(10.0)), Vali MSE Loss: 0.9096 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8457481861114502
Epoch: 9, Steps: 64 Train Loss: 19.4116 (Forecasting Loss:0.4773 + XiCon Loss:1.8934 x Lambda(10.0)), Vali MSE Loss: 0.9047 Test MSE Loss: 0.5092
Validation loss decreased (0.906587 --> 0.904669).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9580152034759521
Epoch: 10, Steps: 64 Train Loss: 19.3959 (Forecasting Loss:0.4784 + XiCon Loss:1.8917 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5092
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8871901035308838
Epoch: 11, Steps: 64 Train Loss: 19.4269 (Forecasting Loss:0.4783 + XiCon Loss:1.8949 x Lambda(10.0)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5092
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8748676776885986
Epoch: 12, Steps: 64 Train Loss: 19.4130 (Forecasting Loss:0.4784 + XiCon Loss:1.8935 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8964245319366455
Epoch: 13, Steps: 64 Train Loss: 19.4590 (Forecasting Loss:0.4783 + XiCon Loss:1.8981 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5091
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8832418918609619
Epoch: 14, Steps: 64 Train Loss: 19.4215 (Forecasting Loss:0.4780 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5091
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8534283638000488
Epoch: 15, Steps: 64 Train Loss: 19.4050 (Forecasting Loss:0.4787 + XiCon Loss:1.8926 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9075260162353516
Epoch: 16, Steps: 64 Train Loss: 19.4145 (Forecasting Loss:0.4777 + XiCon Loss:1.8937 x Lambda(10.0)), Vali MSE Loss: 0.9022 Test MSE Loss: 0.5091
Validation loss decreased (0.904669 --> 0.902181).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8909015655517578
Epoch: 17, Steps: 64 Train Loss: 19.4315 (Forecasting Loss:0.4779 + XiCon Loss:1.8954 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5091
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9065032005310059
Epoch: 18, Steps: 64 Train Loss: 19.4175 (Forecasting Loss:0.4792 + XiCon Loss:1.8938 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5091
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9616270065307617
Epoch: 19, Steps: 64 Train Loss: 19.4272 (Forecasting Loss:0.4789 + XiCon Loss:1.8948 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5091
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9082694053649902
Epoch: 20, Steps: 64 Train Loss: 19.3974 (Forecasting Loss:0.4776 + XiCon Loss:1.8920 x Lambda(10.0)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5091
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8963890075683594
Epoch: 21, Steps: 64 Train Loss: 19.4114 (Forecasting Loss:0.4787 + XiCon Loss:1.8933 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5091
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9238858222961426
Epoch: 22, Steps: 64 Train Loss: 19.3907 (Forecasting Loss:0.4784 + XiCon Loss:1.8912 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8594069480895996
Epoch: 23, Steps: 64 Train Loss: 19.3970 (Forecasting Loss:0.4779 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5091
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9037861824035645
Epoch: 24, Steps: 64 Train Loss: 19.4209 (Forecasting Loss:0.4779 + XiCon Loss:1.8943 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5091
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9113898277282715
Epoch: 25, Steps: 64 Train Loss: 19.4279 (Forecasting Loss:0.4779 + XiCon Loss:1.8950 x Lambda(10.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5091
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9529247283935547
Epoch: 26, Steps: 64 Train Loss: 19.3970 (Forecasting Loss:0.4778 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5091
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4827031195163727, mae:0.535589873790741, mape:0.45602911710739136, mspe:0.6265890598297119 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5738
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9145352840423584
Epoch: 1, Steps: 64 Train Loss: 19.4393 (Forecasting Loss:0.4949 + XiCon Loss:1.8944 x Lambda(10.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908222).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.896740198135376
Epoch: 2, Steps: 64 Train Loss: 19.4274 (Forecasting Loss:0.4914 + XiCon Loss:1.8936 x Lambda(10.0)), Vali MSE Loss: 0.8924 Test MSE Loss: 0.5398
Validation loss decreased (0.908222 --> 0.892418).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8830924034118652
Epoch: 3, Steps: 64 Train Loss: 19.4251 (Forecasting Loss:0.4865 + XiCon Loss:1.8939 x Lambda(10.0)), Vali MSE Loss: 0.8930 Test MSE Loss: 0.5365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.939112663269043
Epoch: 4, Steps: 64 Train Loss: 19.3988 (Forecasting Loss:0.4827 + XiCon Loss:1.8916 x Lambda(10.0)), Vali MSE Loss: 0.8856 Test MSE Loss: 0.5349
Validation loss decreased (0.892418 --> 0.885595).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9608805179595947
Epoch: 5, Steps: 64 Train Loss: 19.4010 (Forecasting Loss:0.4819 + XiCon Loss:1.8919 x Lambda(10.0)), Vali MSE Loss: 0.8841 Test MSE Loss: 0.5341
Validation loss decreased (0.885595 --> 0.884079).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8935036659240723
Epoch: 6, Steps: 64 Train Loss: 19.4057 (Forecasting Loss:0.4802 + XiCon Loss:1.8925 x Lambda(10.0)), Vali MSE Loss: 0.8865 Test MSE Loss: 0.5337
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9175796508789062
Epoch: 7, Steps: 64 Train Loss: 19.4333 (Forecasting Loss:0.4804 + XiCon Loss:1.8953 x Lambda(10.0)), Vali MSE Loss: 0.8883 Test MSE Loss: 0.5335
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8889560699462891
Epoch: 8, Steps: 64 Train Loss: 19.4175 (Forecasting Loss:0.4828 + XiCon Loss:1.8935 x Lambda(10.0)), Vali MSE Loss: 0.8900 Test MSE Loss: 0.5334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8791320323944092
Epoch: 9, Steps: 64 Train Loss: 19.4148 (Forecasting Loss:0.4791 + XiCon Loss:1.8936 x Lambda(10.0)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5334
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9363787174224854
Epoch: 10, Steps: 64 Train Loss: 19.4058 (Forecasting Loss:0.4807 + XiCon Loss:1.8925 x Lambda(10.0)), Vali MSE Loss: 0.8857 Test MSE Loss: 0.5334
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8913614749908447
Epoch: 11, Steps: 64 Train Loss: 19.4379 (Forecasting Loss:0.4812 + XiCon Loss:1.8957 x Lambda(10.0)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5334
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9171545505523682
Epoch: 12, Steps: 64 Train Loss: 19.4206 (Forecasting Loss:0.4796 + XiCon Loss:1.8941 x Lambda(10.0)), Vali MSE Loss: 0.8855 Test MSE Loss: 0.5334
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8965928554534912
Epoch: 13, Steps: 64 Train Loss: 19.4090 (Forecasting Loss:0.4812 + XiCon Loss:1.8928 x Lambda(10.0)), Vali MSE Loss: 0.8868 Test MSE Loss: 0.5334
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8928048610687256
Epoch: 14, Steps: 64 Train Loss: 19.4279 (Forecasting Loss:0.4805 + XiCon Loss:1.8947 x Lambda(10.0)), Vali MSE Loss: 0.8851 Test MSE Loss: 0.5334
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9058563709259033
Epoch: 15, Steps: 64 Train Loss: 19.4133 (Forecasting Loss:0.4812 + XiCon Loss:1.8932 x Lambda(10.0)), Vali MSE Loss: 0.8854 Test MSE Loss: 0.5334
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5174526572227478, mae:0.5507436990737915, mape:0.47553741931915283, mspe:0.6888527274131775 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4835+-0.02608, MAE:0.5373+-0.00984, MAPE:0.4566+-0.01449, MSPE:0.6262+-0.04916, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5560
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.4233129024505615
Epoch: 1, Steps: 59 Train Loss: 20.0565 (Forecasting Loss:0.9906 + XiCon Loss:1.9066 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248621).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1311395168304443
Epoch: 2, Steps: 59 Train Loss: 20.0409 (Forecasting Loss:0.9904 + XiCon Loss:1.9051 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1315336227416992
Epoch: 3, Steps: 59 Train Loss: 20.0608 (Forecasting Loss:0.9892 + XiCon Loss:1.9072 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1166877746582031
Epoch: 4, Steps: 59 Train Loss: 20.0290 (Forecasting Loss:0.9890 + XiCon Loss:1.9040 x Lambda(10.0)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9822
Validation loss decreased (1.248621 --> 1.246888).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1282339096069336
Epoch: 5, Steps: 59 Train Loss: 20.0601 (Forecasting Loss:0.9890 + XiCon Loss:1.9071 x Lambda(10.0)), Vali MSE Loss: 1.2510 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1352427005767822
Epoch: 6, Steps: 59 Train Loss: 20.0351 (Forecasting Loss:0.9899 + XiCon Loss:1.9045 x Lambda(10.0)), Vali MSE Loss: 1.2460 Test MSE Loss: 0.9822
Validation loss decreased (1.246888 --> 1.246025).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1442914009094238
Epoch: 7, Steps: 59 Train Loss: 20.0509 (Forecasting Loss:0.9887 + XiCon Loss:1.9062 x Lambda(10.0)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9822
Validation loss decreased (1.246025 --> 1.244972).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.160539150238037
Epoch: 8, Steps: 59 Train Loss: 20.0748 (Forecasting Loss:0.9881 + XiCon Loss:1.9087 x Lambda(10.0)), Vali MSE Loss: 1.2479 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1242647171020508
Epoch: 9, Steps: 59 Train Loss: 20.0499 (Forecasting Loss:0.9890 + XiCon Loss:1.9061 x Lambda(10.0)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9822
Validation loss decreased (1.244972 --> 1.244433).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.0979516506195068
Epoch: 10, Steps: 59 Train Loss: 20.0566 (Forecasting Loss:0.9889 + XiCon Loss:1.9068 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.130835771560669
Epoch: 11, Steps: 59 Train Loss: 20.0410 (Forecasting Loss:0.9878 + XiCon Loss:1.9053 x Lambda(10.0)), Vali MSE Loss: 1.2446 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1271464824676514
Epoch: 12, Steps: 59 Train Loss: 20.0891 (Forecasting Loss:0.9887 + XiCon Loss:1.9100 x Lambda(10.0)), Vali MSE Loss: 1.2523 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1253564357757568
Epoch: 13, Steps: 59 Train Loss: 20.0398 (Forecasting Loss:0.9890 + XiCon Loss:1.9051 x Lambda(10.0)), Vali MSE Loss: 1.2456 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1042964458465576
Epoch: 14, Steps: 59 Train Loss: 20.0301 (Forecasting Loss:0.9889 + XiCon Loss:1.9041 x Lambda(10.0)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1170639991760254
Epoch: 15, Steps: 59 Train Loss: 20.0614 (Forecasting Loss:0.9888 + XiCon Loss:1.9073 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.140167236328125
Epoch: 16, Steps: 59 Train Loss: 20.0502 (Forecasting Loss:0.9894 + XiCon Loss:1.9061 x Lambda(10.0)), Vali MSE Loss: 1.2490 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1319925785064697
Epoch: 17, Steps: 59 Train Loss: 20.0671 (Forecasting Loss:0.9889 + XiCon Loss:1.9078 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1354293823242188
Epoch: 18, Steps: 59 Train Loss: 20.0523 (Forecasting Loss:0.9896 + XiCon Loss:1.9063 x Lambda(10.0)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.1161525249481201
Epoch: 19, Steps: 59 Train Loss: 20.0876 (Forecasting Loss:0.9895 + XiCon Loss:1.9098 x Lambda(10.0)), Vali MSE Loss: 1.2416 Test MSE Loss: 0.9822
Validation loss decreased (1.244433 --> 1.241621).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.126408576965332
Epoch: 20, Steps: 59 Train Loss: 20.0739 (Forecasting Loss:0.9888 + XiCon Loss:1.9085 x Lambda(10.0)), Vali MSE Loss: 1.2439 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1044681072235107
Epoch: 21, Steps: 59 Train Loss: 20.0644 (Forecasting Loss:0.9898 + XiCon Loss:1.9075 x Lambda(10.0)), Vali MSE Loss: 1.2514 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.1135540008544922
Epoch: 22, Steps: 59 Train Loss: 20.0236 (Forecasting Loss:0.9903 + XiCon Loss:1.9033 x Lambda(10.0)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.123133897781372
Epoch: 23, Steps: 59 Train Loss: 20.0803 (Forecasting Loss:0.9880 + XiCon Loss:1.9092 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.1269292831420898
Epoch: 24, Steps: 59 Train Loss: 20.0449 (Forecasting Loss:0.9893 + XiCon Loss:1.9056 x Lambda(10.0)), Vali MSE Loss: 1.2547 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.1271207332611084
Epoch: 25, Steps: 59 Train Loss: 20.0289 (Forecasting Loss:0.9890 + XiCon Loss:1.9040 x Lambda(10.0)), Vali MSE Loss: 1.2521 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.095937967300415
Epoch: 26, Steps: 59 Train Loss: 20.0353 (Forecasting Loss:0.9891 + XiCon Loss:1.9046 x Lambda(10.0)), Vali MSE Loss: 1.2574 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.116070032119751
Epoch: 27, Steps: 59 Train Loss: 20.0670 (Forecasting Loss:0.9887 + XiCon Loss:1.9078 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.1363050937652588
Epoch: 28, Steps: 59 Train Loss: 20.0251 (Forecasting Loss:0.9901 + XiCon Loss:1.9035 x Lambda(10.0)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.1010777950286865
Epoch: 29, Steps: 59 Train Loss: 20.0547 (Forecasting Loss:0.9886 + XiCon Loss:1.9066 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9822
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.145627498626709, mae:0.8187288641929626, mape:0.7821676135063171, mspe:1.830514907836914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6057
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1353981494903564
Epoch: 1, Steps: 59 Train Loss: 20.0284 (Forecasting Loss:0.9892 + XiCon Loss:1.9039 x Lambda(10.0)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236818).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1211035251617432
Epoch: 2, Steps: 59 Train Loss: 20.0530 (Forecasting Loss:0.9886 + XiCon Loss:1.9064 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236818 --> 1.234322).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1124863624572754
Epoch: 3, Steps: 59 Train Loss: 20.0080 (Forecasting Loss:0.9873 + XiCon Loss:1.9021 x Lambda(10.0)), Vali MSE Loss: 1.2391 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1185317039489746
Epoch: 4, Steps: 59 Train Loss: 20.0886 (Forecasting Loss:0.9879 + XiCon Loss:1.9101 x Lambda(10.0)), Vali MSE Loss: 1.2406 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1081626415252686
Epoch: 5, Steps: 59 Train Loss: 20.0232 (Forecasting Loss:0.9886 + XiCon Loss:1.9035 x Lambda(10.0)), Vali MSE Loss: 1.2296 Test MSE Loss: 0.9929
Validation loss decreased (1.234322 --> 1.229633).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.149714708328247
Epoch: 6, Steps: 59 Train Loss: 20.0491 (Forecasting Loss:0.9885 + XiCon Loss:1.9061 x Lambda(10.0)), Vali MSE Loss: 1.2381 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1101677417755127
Epoch: 7, Steps: 59 Train Loss: 20.0580 (Forecasting Loss:0.9858 + XiCon Loss:1.9072 x Lambda(10.0)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1208913326263428
Epoch: 8, Steps: 59 Train Loss: 20.0761 (Forecasting Loss:0.9868 + XiCon Loss:1.9089 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1498994827270508
Epoch: 9, Steps: 59 Train Loss: 20.0562 (Forecasting Loss:0.9868 + XiCon Loss:1.9069 x Lambda(10.0)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1310737133026123
Epoch: 10, Steps: 59 Train Loss: 20.0179 (Forecasting Loss:0.9879 + XiCon Loss:1.9030 x Lambda(10.0)), Vali MSE Loss: 1.2337 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.15031099319458
Epoch: 11, Steps: 59 Train Loss: 20.0404 (Forecasting Loss:0.9873 + XiCon Loss:1.9053 x Lambda(10.0)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1108684539794922
Epoch: 12, Steps: 59 Train Loss: 20.0427 (Forecasting Loss:0.9877 + XiCon Loss:1.9055 x Lambda(10.0)), Vali MSE Loss: 1.2262 Test MSE Loss: 0.9928
Validation loss decreased (1.229633 --> 1.226231).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1545305252075195
Epoch: 13, Steps: 59 Train Loss: 20.0703 (Forecasting Loss:0.9882 + XiCon Loss:1.9082 x Lambda(10.0)), Vali MSE Loss: 1.2306 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1112415790557861
Epoch: 14, Steps: 59 Train Loss: 20.0652 (Forecasting Loss:0.9877 + XiCon Loss:1.9077 x Lambda(10.0)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1247270107269287
Epoch: 15, Steps: 59 Train Loss: 20.0542 (Forecasting Loss:0.9883 + XiCon Loss:1.9066 x Lambda(10.0)), Vali MSE Loss: 1.2265 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.1282813549041748
Epoch: 16, Steps: 59 Train Loss: 20.0502 (Forecasting Loss:0.9869 + XiCon Loss:1.9063 x Lambda(10.0)), Vali MSE Loss: 1.2418 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1605675220489502
Epoch: 17, Steps: 59 Train Loss: 20.0613 (Forecasting Loss:0.9875 + XiCon Loss:1.9074 x Lambda(10.0)), Vali MSE Loss: 1.2282 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1497912406921387
Epoch: 18, Steps: 59 Train Loss: 20.0438 (Forecasting Loss:0.9880 + XiCon Loss:1.9056 x Lambda(10.0)), Vali MSE Loss: 1.2301 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.155752182006836
Epoch: 19, Steps: 59 Train Loss: 20.0556 (Forecasting Loss:0.9874 + XiCon Loss:1.9068 x Lambda(10.0)), Vali MSE Loss: 1.2360 Test MSE Loss: 0.9928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.1327219009399414
Epoch: 20, Steps: 59 Train Loss: 20.0299 (Forecasting Loss:0.9875 + XiCon Loss:1.9042 x Lambda(10.0)), Vali MSE Loss: 1.2332 Test MSE Loss: 0.9928
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1256685256958008
Epoch: 21, Steps: 59 Train Loss: 20.0145 (Forecasting Loss:0.9875 + XiCon Loss:1.9027 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9928
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.155055046081543
Epoch: 22, Steps: 59 Train Loss: 20.0648 (Forecasting Loss:0.9885 + XiCon Loss:1.9076 x Lambda(10.0)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9928
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1612167358398438, mae:0.8244361281394958, mape:0.7876427173614502, mspe:1.8507182598114014 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5592
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.137047529220581
Epoch: 1, Steps: 59 Train Loss: 20.0071 (Forecasting Loss:0.9902 + XiCon Loss:1.9017 x Lambda(10.0)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247579).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1305737495422363
Epoch: 2, Steps: 59 Train Loss: 20.0694 (Forecasting Loss:0.9906 + XiCon Loss:1.9079 x Lambda(10.0)), Vali MSE Loss: 1.2355 Test MSE Loss: 0.9844
Validation loss decreased (1.247579 --> 1.235483).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1266858577728271
Epoch: 3, Steps: 59 Train Loss: 20.0092 (Forecasting Loss:0.9899 + XiCon Loss:1.9019 x Lambda(10.0)), Vali MSE Loss: 1.2347 Test MSE Loss: 0.9842
Validation loss decreased (1.235483 --> 1.234668).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.142045021057129
Epoch: 4, Steps: 59 Train Loss: 20.0449 (Forecasting Loss:0.9884 + XiCon Loss:1.9057 x Lambda(10.0)), Vali MSE Loss: 1.2540 Test MSE Loss: 0.9842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1073427200317383
Epoch: 5, Steps: 59 Train Loss: 20.0296 (Forecasting Loss:0.9886 + XiCon Loss:1.9041 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9842
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1283466815948486
Epoch: 6, Steps: 59 Train Loss: 20.0707 (Forecasting Loss:0.9894 + XiCon Loss:1.9081 x Lambda(10.0)), Vali MSE Loss: 1.2441 Test MSE Loss: 0.9841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1365785598754883
Epoch: 7, Steps: 59 Train Loss: 20.0191 (Forecasting Loss:0.9893 + XiCon Loss:1.9030 x Lambda(10.0)), Vali MSE Loss: 1.2497 Test MSE Loss: 0.9841
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.171354055404663
Epoch: 8, Steps: 59 Train Loss: 20.0278 (Forecasting Loss:0.9882 + XiCon Loss:1.9040 x Lambda(10.0)), Vali MSE Loss: 1.2581 Test MSE Loss: 0.9841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1203551292419434
Epoch: 9, Steps: 59 Train Loss: 20.0634 (Forecasting Loss:0.9876 + XiCon Loss:1.9076 x Lambda(10.0)), Vali MSE Loss: 1.2505 Test MSE Loss: 0.9841
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1267669200897217
Epoch: 10, Steps: 59 Train Loss: 20.0488 (Forecasting Loss:0.9892 + XiCon Loss:1.9060 x Lambda(10.0)), Vali MSE Loss: 1.2537 Test MSE Loss: 0.9841
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.142735481262207
Epoch: 11, Steps: 59 Train Loss: 20.0663 (Forecasting Loss:0.9878 + XiCon Loss:1.9078 x Lambda(10.0)), Vali MSE Loss: 1.2474 Test MSE Loss: 0.9841
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1435132026672363
Epoch: 12, Steps: 59 Train Loss: 19.9996 (Forecasting Loss:0.9884 + XiCon Loss:1.9011 x Lambda(10.0)), Vali MSE Loss: 1.2410 Test MSE Loss: 0.9841
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1140236854553223
Epoch: 13, Steps: 59 Train Loss: 20.0227 (Forecasting Loss:0.9889 + XiCon Loss:1.9034 x Lambda(10.0)), Vali MSE Loss: 1.2571 Test MSE Loss: 0.9841
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.148036241531372, mae:0.8204624652862549, mape:0.783078134059906, mspe:1.8314372301101685 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5747
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1407530307769775
Epoch: 1, Steps: 59 Train Loss: 20.0563 (Forecasting Loss:0.9890 + XiCon Loss:1.9067 x Lambda(10.0)), Vali MSE Loss: 1.2401 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240053).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1283695697784424
Epoch: 2, Steps: 59 Train Loss: 20.0482 (Forecasting Loss:0.9898 + XiCon Loss:1.9058 x Lambda(10.0)), Vali MSE Loss: 1.2226 Test MSE Loss: 0.9957
Validation loss decreased (1.240053 --> 1.222586).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1262717247009277
Epoch: 3, Steps: 59 Train Loss: 20.0385 (Forecasting Loss:0.9878 + XiCon Loss:1.9051 x Lambda(10.0)), Vali MSE Loss: 1.2322 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1067283153533936
Epoch: 4, Steps: 59 Train Loss: 20.0473 (Forecasting Loss:0.9888 + XiCon Loss:1.9059 x Lambda(10.0)), Vali MSE Loss: 1.2315 Test MSE Loss: 0.9956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.148308277130127
Epoch: 5, Steps: 59 Train Loss: 20.0504 (Forecasting Loss:0.9883 + XiCon Loss:1.9062 x Lambda(10.0)), Vali MSE Loss: 1.2234 Test MSE Loss: 0.9956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1264090538024902
Epoch: 6, Steps: 59 Train Loss: 20.0655 (Forecasting Loss:0.9890 + XiCon Loss:1.9076 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1691761016845703
Epoch: 7, Steps: 59 Train Loss: 20.0650 (Forecasting Loss:0.9881 + XiCon Loss:1.9077 x Lambda(10.0)), Vali MSE Loss: 1.2252 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1720857620239258
Epoch: 8, Steps: 59 Train Loss: 20.0860 (Forecasting Loss:0.9873 + XiCon Loss:1.9099 x Lambda(10.0)), Vali MSE Loss: 1.2240 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1445896625518799
Epoch: 9, Steps: 59 Train Loss: 20.0570 (Forecasting Loss:0.9874 + XiCon Loss:1.9070 x Lambda(10.0)), Vali MSE Loss: 1.2348 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1612615585327148
Epoch: 10, Steps: 59 Train Loss: 20.0255 (Forecasting Loss:0.9883 + XiCon Loss:1.9037 x Lambda(10.0)), Vali MSE Loss: 1.2329 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1210217475891113
Epoch: 11, Steps: 59 Train Loss: 20.0588 (Forecasting Loss:0.9864 + XiCon Loss:1.9072 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1126055717468262
Epoch: 12, Steps: 59 Train Loss: 20.0606 (Forecasting Loss:0.9881 + XiCon Loss:1.9072 x Lambda(10.0)), Vali MSE Loss: 1.2323 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1653859615325928, mae:0.8261119723320007, mape:0.7890903353691101, mspe:1.8549638986587524 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7239
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1519527435302734
Epoch: 1, Steps: 59 Train Loss: 20.0191 (Forecasting Loss:0.9941 + XiCon Loss:1.9025 x Lambda(10.0)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275613).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1346499919891357
Epoch: 2, Steps: 59 Train Loss: 20.0427 (Forecasting Loss:0.9928 + XiCon Loss:1.9050 x Lambda(10.0)), Vali MSE Loss: 1.2745 Test MSE Loss: 0.9658
Validation loss decreased (1.275613 --> 1.274494).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.150522232055664
Epoch: 3, Steps: 59 Train Loss: 20.0391 (Forecasting Loss:0.9934 + XiCon Loss:1.9046 x Lambda(10.0)), Vali MSE Loss: 1.2849 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1289279460906982
Epoch: 4, Steps: 59 Train Loss: 19.9933 (Forecasting Loss:0.9923 + XiCon Loss:1.9001 x Lambda(10.0)), Vali MSE Loss: 1.2803 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2104661464691162
Epoch: 5, Steps: 59 Train Loss: 20.0336 (Forecasting Loss:0.9928 + XiCon Loss:1.9041 x Lambda(10.0)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9657
Validation loss decreased (1.274494 --> 1.274269).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1653416156768799
Epoch: 6, Steps: 59 Train Loss: 20.0296 (Forecasting Loss:0.9935 + XiCon Loss:1.9036 x Lambda(10.0)), Vali MSE Loss: 1.2845 Test MSE Loss: 0.9657
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1264941692352295
Epoch: 7, Steps: 59 Train Loss: 20.0212 (Forecasting Loss:0.9924 + XiCon Loss:1.9029 x Lambda(10.0)), Vali MSE Loss: 1.2775 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1114344596862793
Epoch: 8, Steps: 59 Train Loss: 20.0115 (Forecasting Loss:0.9921 + XiCon Loss:1.9019 x Lambda(10.0)), Vali MSE Loss: 1.2825 Test MSE Loss: 0.9657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1191532611846924
Epoch: 9, Steps: 59 Train Loss: 20.0320 (Forecasting Loss:0.9931 + XiCon Loss:1.9039 x Lambda(10.0)), Vali MSE Loss: 1.2886 Test MSE Loss: 0.9657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1221895217895508
Epoch: 10, Steps: 59 Train Loss: 20.0057 (Forecasting Loss:0.9923 + XiCon Loss:1.9013 x Lambda(10.0)), Vali MSE Loss: 1.2792 Test MSE Loss: 0.9657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1131370067596436
Epoch: 11, Steps: 59 Train Loss: 20.0445 (Forecasting Loss:0.9928 + XiCon Loss:1.9052 x Lambda(10.0)), Vali MSE Loss: 1.2748 Test MSE Loss: 0.9657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.117722511291504
Epoch: 12, Steps: 59 Train Loss: 19.9692 (Forecasting Loss:0.9934 + XiCon Loss:1.8976 x Lambda(10.0)), Vali MSE Loss: 1.2767 Test MSE Loss: 0.9657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1256401538848877
Epoch: 13, Steps: 59 Train Loss: 20.0253 (Forecasting Loss:0.9922 + XiCon Loss:1.9033 x Lambda(10.0)), Vali MSE Loss: 1.2820 Test MSE Loss: 0.9657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1242420673370361
Epoch: 14, Steps: 59 Train Loss: 20.0708 (Forecasting Loss:0.9917 + XiCon Loss:1.9079 x Lambda(10.0)), Vali MSE Loss: 1.2818 Test MSE Loss: 0.9657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1238460540771484
Epoch: 15, Steps: 59 Train Loss: 20.0014 (Forecasting Loss:0.9928 + XiCon Loss:1.9009 x Lambda(10.0)), Vali MSE Loss: 1.2801 Test MSE Loss: 0.9657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206092834472656, mae:0.8108486533164978, mape:0.773126482963562, mspe:1.7925660610198975 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00777, MSPE:1.8320+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.7476487159729004
Epoch: 1, Steps: 53 Train Loss: 1.6780 (Forecasting Loss:1.4862 + XiCon Loss:1.9180 x Lambda(0.1)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858726).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5012431144714355
Epoch: 2, Steps: 53 Train Loss: 1.6713 (Forecasting Loss:1.4798 + XiCon Loss:1.9150 x Lambda(0.1)), Vali MSE Loss: 1.8415 Test MSE Loss: 0.9182
Validation loss decreased (1.858726 --> 1.841458).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4716901779174805
Epoch: 3, Steps: 53 Train Loss: 1.6652 (Forecasting Loss:1.4737 + XiCon Loss:1.9150 x Lambda(0.1)), Vali MSE Loss: 1.8451 Test MSE Loss: 0.9228
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.472848653793335
Epoch: 4, Steps: 53 Train Loss: 1.6635 (Forecasting Loss:1.4717 + XiCon Loss:1.9171 x Lambda(0.1)), Vali MSE Loss: 1.8425 Test MSE Loss: 0.9250
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.459733247756958
Epoch: 5, Steps: 53 Train Loss: 1.6592 (Forecasting Loss:1.4674 + XiCon Loss:1.9186 x Lambda(0.1)), Vali MSE Loss: 1.8229 Test MSE Loss: 0.9260
Validation loss decreased (1.841458 --> 1.822869).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5265507698059082
Epoch: 6, Steps: 53 Train Loss: 1.6616 (Forecasting Loss:1.4701 + XiCon Loss:1.9155 x Lambda(0.1)), Vali MSE Loss: 1.8259 Test MSE Loss: 0.9266
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.4593656063079834
Epoch: 7, Steps: 53 Train Loss: 1.6583 (Forecasting Loss:1.4668 + XiCon Loss:1.9150 x Lambda(0.1)), Vali MSE Loss: 1.7964 Test MSE Loss: 0.9268
Validation loss decreased (1.822869 --> 1.796355).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.4797544479370117
Epoch: 8, Steps: 53 Train Loss: 1.6569 (Forecasting Loss:1.4657 + XiCon Loss:1.9121 x Lambda(0.1)), Vali MSE Loss: 1.8524 Test MSE Loss: 0.9270
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.4854435920715332
Epoch: 9, Steps: 53 Train Loss: 1.6579 (Forecasting Loss:1.4667 + XiCon Loss:1.9117 x Lambda(0.1)), Vali MSE Loss: 1.8147 Test MSE Loss: 0.9270
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4743809700012207
Epoch: 10, Steps: 53 Train Loss: 1.6598 (Forecasting Loss:1.4682 + XiCon Loss:1.9154 x Lambda(0.1)), Vali MSE Loss: 1.8543 Test MSE Loss: 0.9271
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4722180366516113
Epoch: 11, Steps: 53 Train Loss: 1.6564 (Forecasting Loss:1.4649 + XiCon Loss:1.9153 x Lambda(0.1)), Vali MSE Loss: 1.8366 Test MSE Loss: 0.9271
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.454392910003662
Epoch: 12, Steps: 53 Train Loss: 1.6573 (Forecasting Loss:1.4660 + XiCon Loss:1.9132 x Lambda(0.1)), Vali MSE Loss: 1.8127 Test MSE Loss: 0.9271
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4849932193756104
Epoch: 13, Steps: 53 Train Loss: 1.6586 (Forecasting Loss:1.4667 + XiCon Loss:1.9192 x Lambda(0.1)), Vali MSE Loss: 1.8496 Test MSE Loss: 0.9271
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4882373809814453
Epoch: 14, Steps: 53 Train Loss: 1.6593 (Forecasting Loss:1.4679 + XiCon Loss:1.9145 x Lambda(0.1)), Vali MSE Loss: 1.8041 Test MSE Loss: 0.9271
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4979133605957031
Epoch: 15, Steps: 53 Train Loss: 1.6561 (Forecasting Loss:1.4647 + XiCon Loss:1.9141 x Lambda(0.1)), Vali MSE Loss: 1.8463 Test MSE Loss: 0.9271
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.479269027709961
Epoch: 16, Steps: 53 Train Loss: 1.6567 (Forecasting Loss:1.4655 + XiCon Loss:1.9122 x Lambda(0.1)), Vali MSE Loss: 1.8265 Test MSE Loss: 0.9271
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.4927988052368164
Epoch: 17, Steps: 53 Train Loss: 1.6586 (Forecasting Loss:1.4673 + XiCon Loss:1.9130 x Lambda(0.1)), Vali MSE Loss: 1.8433 Test MSE Loss: 0.9271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0581144094467163, mae:0.795559823513031, mape:0.7948048710823059, mspe:1.7963703870773315 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5757
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.478485107421875
Epoch: 1, Steps: 53 Train Loss: 1.6747 (Forecasting Loss:1.4830 + XiCon Loss:1.9170 x Lambda(0.1)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828229).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4643266201019287
Epoch: 2, Steps: 53 Train Loss: 1.6706 (Forecasting Loss:1.4788 + XiCon Loss:1.9175 x Lambda(0.1)), Vali MSE Loss: 1.8218 Test MSE Loss: 0.9332
Validation loss decreased (1.828229 --> 1.821754).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5404255390167236
Epoch: 3, Steps: 53 Train Loss: 1.6649 (Forecasting Loss:1.4730 + XiCon Loss:1.9183 x Lambda(0.1)), Vali MSE Loss: 1.7989 Test MSE Loss: 0.9348
Validation loss decreased (1.821754 --> 1.798850).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5635676383972168
Epoch: 4, Steps: 53 Train Loss: 1.6636 (Forecasting Loss:1.4713 + XiCon Loss:1.9233 x Lambda(0.1)), Vali MSE Loss: 1.8007 Test MSE Loss: 0.9356
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4820740222930908
Epoch: 5, Steps: 53 Train Loss: 1.6661 (Forecasting Loss:1.4742 + XiCon Loss:1.9196 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9361
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.4826500415802002
Epoch: 6, Steps: 53 Train Loss: 1.6609 (Forecasting Loss:1.4691 + XiCon Loss:1.9185 x Lambda(0.1)), Vali MSE Loss: 1.8083 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.4747896194458008
Epoch: 7, Steps: 53 Train Loss: 1.6596 (Forecasting Loss:1.4677 + XiCon Loss:1.9191 x Lambda(0.1)), Vali MSE Loss: 1.7827 Test MSE Loss: 0.9364
Validation loss decreased (1.798850 --> 1.782666).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.4787628650665283
Epoch: 8, Steps: 53 Train Loss: 1.6610 (Forecasting Loss:1.4690 + XiCon Loss:1.9202 x Lambda(0.1)), Vali MSE Loss: 1.8251 Test MSE Loss: 0.9364
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5061345100402832
Epoch: 9, Steps: 53 Train Loss: 1.6568 (Forecasting Loss:1.4651 + XiCon Loss:1.9170 x Lambda(0.1)), Vali MSE Loss: 1.8223 Test MSE Loss: 0.9364
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4872090816497803
Epoch: 10, Steps: 53 Train Loss: 1.6626 (Forecasting Loss:1.4705 + XiCon Loss:1.9207 x Lambda(0.1)), Vali MSE Loss: 1.8325 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.501760721206665
Epoch: 11, Steps: 53 Train Loss: 1.6611 (Forecasting Loss:1.4694 + XiCon Loss:1.9172 x Lambda(0.1)), Vali MSE Loss: 1.8406 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.519571304321289
Epoch: 12, Steps: 53 Train Loss: 1.6611 (Forecasting Loss:1.4688 + XiCon Loss:1.9227 x Lambda(0.1)), Vali MSE Loss: 1.7661 Test MSE Loss: 0.9365
Validation loss decreased (1.782666 --> 1.766055).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4652695655822754
Epoch: 13, Steps: 53 Train Loss: 1.6618 (Forecasting Loss:1.4698 + XiCon Loss:1.9209 x Lambda(0.1)), Vali MSE Loss: 1.8091 Test MSE Loss: 0.9365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4831738471984863
Epoch: 14, Steps: 53 Train Loss: 1.6621 (Forecasting Loss:1.4703 + XiCon Loss:1.9177 x Lambda(0.1)), Vali MSE Loss: 1.8040 Test MSE Loss: 0.9365
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.472353219985962
Epoch: 15, Steps: 53 Train Loss: 1.6586 (Forecasting Loss:1.4669 + XiCon Loss:1.9178 x Lambda(0.1)), Vali MSE Loss: 1.7979 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.4576599597930908
Epoch: 16, Steps: 53 Train Loss: 1.6624 (Forecasting Loss:1.4706 + XiCon Loss:1.9182 x Lambda(0.1)), Vali MSE Loss: 1.7909 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.4852023124694824
Epoch: 17, Steps: 53 Train Loss: 1.6598 (Forecasting Loss:1.4679 + XiCon Loss:1.9193 x Lambda(0.1)), Vali MSE Loss: 1.8299 Test MSE Loss: 0.9365
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.4956533908843994
Epoch: 18, Steps: 53 Train Loss: 1.6604 (Forecasting Loss:1.4684 + XiCon Loss:1.9199 x Lambda(0.1)), Vali MSE Loss: 1.8234 Test MSE Loss: 0.9365
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.4783148765563965
Epoch: 19, Steps: 53 Train Loss: 1.6635 (Forecasting Loss:1.4716 + XiCon Loss:1.9195 x Lambda(0.1)), Vali MSE Loss: 1.8128 Test MSE Loss: 0.9365
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.4609498977661133
Epoch: 20, Steps: 53 Train Loss: 1.6592 (Forecasting Loss:1.4675 + XiCon Loss:1.9176 x Lambda(0.1)), Vali MSE Loss: 1.8118 Test MSE Loss: 0.9365
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.4699838161468506
Epoch: 21, Steps: 53 Train Loss: 1.6606 (Forecasting Loss:1.4688 + XiCon Loss:1.9174 x Lambda(0.1)), Vali MSE Loss: 1.8081 Test MSE Loss: 0.9365
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.478440523147583
Epoch: 22, Steps: 53 Train Loss: 1.6624 (Forecasting Loss:1.4704 + XiCon Loss:1.9199 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0729604959487915, mae:0.799981415271759, mape:0.8005040884017944, mspe:1.821036458015442 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5835
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5020270347595215
Epoch: 1, Steps: 53 Train Loss: 1.6780 (Forecasting Loss:1.4859 + XiCon Loss:1.9205 x Lambda(0.1)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899226).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4864451885223389
Epoch: 2, Steps: 53 Train Loss: 1.6757 (Forecasting Loss:1.4836 + XiCon Loss:1.9203 x Lambda(0.1)), Vali MSE Loss: 1.8448 Test MSE Loss: 0.9161
Validation loss decreased (1.899226 --> 1.844776).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4971277713775635
Epoch: 3, Steps: 53 Train Loss: 1.6722 (Forecasting Loss:1.4805 + XiCon Loss:1.9167 x Lambda(0.1)), Vali MSE Loss: 1.8756 Test MSE Loss: 0.9186
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.4906916618347168
Epoch: 4, Steps: 53 Train Loss: 1.6606 (Forecasting Loss:1.4686 + XiCon Loss:1.9203 x Lambda(0.1)), Vali MSE Loss: 1.8565 Test MSE Loss: 0.9199
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4704525470733643
Epoch: 5, Steps: 53 Train Loss: 1.6646 (Forecasting Loss:1.4728 + XiCon Loss:1.9188 x Lambda(0.1)), Vali MSE Loss: 1.8090 Test MSE Loss: 0.9206
Validation loss decreased (1.844776 --> 1.809033).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.482848882675171
Epoch: 6, Steps: 53 Train Loss: 1.6649 (Forecasting Loss:1.4731 + XiCon Loss:1.9181 x Lambda(0.1)), Vali MSE Loss: 1.8718 Test MSE Loss: 0.9210
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.4660139083862305
Epoch: 7, Steps: 53 Train Loss: 1.6666 (Forecasting Loss:1.4745 + XiCon Loss:1.9206 x Lambda(0.1)), Vali MSE Loss: 1.8674 Test MSE Loss: 0.9212
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.473297357559204
Epoch: 8, Steps: 53 Train Loss: 1.6642 (Forecasting Loss:1.4725 + XiCon Loss:1.9166 x Lambda(0.1)), Vali MSE Loss: 1.8521 Test MSE Loss: 0.9213
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.4893229007720947
Epoch: 9, Steps: 53 Train Loss: 1.6635 (Forecasting Loss:1.4719 + XiCon Loss:1.9156 x Lambda(0.1)), Vali MSE Loss: 1.8343 Test MSE Loss: 0.9213
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4958062171936035
Epoch: 10, Steps: 53 Train Loss: 1.6603 (Forecasting Loss:1.4683 + XiCon Loss:1.9206 x Lambda(0.1)), Vali MSE Loss: 1.8585 Test MSE Loss: 0.9214
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5106148719787598
Epoch: 11, Steps: 53 Train Loss: 1.6652 (Forecasting Loss:1.4731 + XiCon Loss:1.9208 x Lambda(0.1)), Vali MSE Loss: 1.8447 Test MSE Loss: 0.9214
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5165157318115234
Epoch: 12, Steps: 53 Train Loss: 1.6607 (Forecasting Loss:1.4690 + XiCon Loss:1.9170 x Lambda(0.1)), Vali MSE Loss: 1.8314 Test MSE Loss: 0.9214
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4717557430267334
Epoch: 13, Steps: 53 Train Loss: 1.6602 (Forecasting Loss:1.4683 + XiCon Loss:1.9197 x Lambda(0.1)), Vali MSE Loss: 1.8585 Test MSE Loss: 0.9214
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4971084594726562
Epoch: 14, Steps: 53 Train Loss: 1.6610 (Forecasting Loss:1.4690 + XiCon Loss:1.9201 x Lambda(0.1)), Vali MSE Loss: 1.8337 Test MSE Loss: 0.9214
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4672574996948242
Epoch: 15, Steps: 53 Train Loss: 1.6612 (Forecasting Loss:1.4694 + XiCon Loss:1.9175 x Lambda(0.1)), Vali MSE Loss: 1.8908 Test MSE Loss: 0.9214
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0489065647125244, mae:0.7923316955566406, mape:0.7911248803138733, mspe:1.7799711227416992 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5665
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.4876689910888672
Epoch: 1, Steps: 53 Train Loss: 1.6919 (Forecasting Loss:1.4999 + XiCon Loss:1.9201 x Lambda(0.1)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995503).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4628963470458984
Epoch: 2, Steps: 53 Train Loss: 1.6894 (Forecasting Loss:1.4971 + XiCon Loss:1.9233 x Lambda(0.1)), Vali MSE Loss: 1.9518 Test MSE Loss: 0.8742
Validation loss decreased (1.995503 --> 1.951814).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4918758869171143
Epoch: 3, Steps: 53 Train Loss: 1.6819 (Forecasting Loss:1.4899 + XiCon Loss:1.9203 x Lambda(0.1)), Vali MSE Loss: 1.9645 Test MSE Loss: 0.8827
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.4925806522369385
Epoch: 4, Steps: 53 Train Loss: 1.6728 (Forecasting Loss:1.4809 + XiCon Loss:1.9189 x Lambda(0.1)), Vali MSE Loss: 1.9477 Test MSE Loss: 0.8886
Validation loss decreased (1.951814 --> 1.947734).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.4963691234588623
Epoch: 5, Steps: 53 Train Loss: 1.6665 (Forecasting Loss:1.4746 + XiCon Loss:1.9192 x Lambda(0.1)), Vali MSE Loss: 1.9104 Test MSE Loss: 0.8920
Validation loss decreased (1.947734 --> 1.910375).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5017893314361572
Epoch: 6, Steps: 53 Train Loss: 1.6672 (Forecasting Loss:1.4754 + XiCon Loss:1.9183 x Lambda(0.1)), Vali MSE Loss: 1.9534 Test MSE Loss: 0.8939
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.4984230995178223
Epoch: 7, Steps: 53 Train Loss: 1.6702 (Forecasting Loss:1.4777 + XiCon Loss:1.9243 x Lambda(0.1)), Vali MSE Loss: 1.9030 Test MSE Loss: 0.8948
Validation loss decreased (1.910375 --> 1.903012).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.468017578125
Epoch: 8, Steps: 53 Train Loss: 1.6659 (Forecasting Loss:1.4738 + XiCon Loss:1.9208 x Lambda(0.1)), Vali MSE Loss: 1.9130 Test MSE Loss: 0.8952
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.4685778617858887
Epoch: 9, Steps: 53 Train Loss: 1.6659 (Forecasting Loss:1.4739 + XiCon Loss:1.9195 x Lambda(0.1)), Vali MSE Loss: 1.9152 Test MSE Loss: 0.8954
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4919147491455078
Epoch: 10, Steps: 53 Train Loss: 1.6673 (Forecasting Loss:1.4751 + XiCon Loss:1.9220 x Lambda(0.1)), Vali MSE Loss: 1.8918 Test MSE Loss: 0.8956
Validation loss decreased (1.903012 --> 1.891760).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5166089534759521
Epoch: 11, Steps: 53 Train Loss: 1.6665 (Forecasting Loss:1.4747 + XiCon Loss:1.9179 x Lambda(0.1)), Vali MSE Loss: 1.9059 Test MSE Loss: 0.8956
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4746134281158447
Epoch: 12, Steps: 53 Train Loss: 1.6658 (Forecasting Loss:1.4741 + XiCon Loss:1.9171 x Lambda(0.1)), Vali MSE Loss: 1.8731 Test MSE Loss: 0.8956
Validation loss decreased (1.891760 --> 1.873104).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.462355375289917
Epoch: 13, Steps: 53 Train Loss: 1.6672 (Forecasting Loss:1.4750 + XiCon Loss:1.9219 x Lambda(0.1)), Vali MSE Loss: 1.9044 Test MSE Loss: 0.8956
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5143327713012695
Epoch: 14, Steps: 53 Train Loss: 1.6687 (Forecasting Loss:1.4769 + XiCon Loss:1.9186 x Lambda(0.1)), Vali MSE Loss: 1.9086 Test MSE Loss: 0.8957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4797000885009766
Epoch: 15, Steps: 53 Train Loss: 1.6687 (Forecasting Loss:1.4768 + XiCon Loss:1.9194 x Lambda(0.1)), Vali MSE Loss: 1.9078 Test MSE Loss: 0.8957
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5033912658691406
Epoch: 16, Steps: 53 Train Loss: 1.6655 (Forecasting Loss:1.4736 + XiCon Loss:1.9185 x Lambda(0.1)), Vali MSE Loss: 1.8983 Test MSE Loss: 0.8957
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.4711637496948242
Epoch: 17, Steps: 53 Train Loss: 1.6642 (Forecasting Loss:1.4724 + XiCon Loss:1.9182 x Lambda(0.1)), Vali MSE Loss: 1.9182 Test MSE Loss: 0.8957
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.476808786392212
Epoch: 18, Steps: 53 Train Loss: 1.6655 (Forecasting Loss:1.4731 + XiCon Loss:1.9240 x Lambda(0.1)), Vali MSE Loss: 1.9328 Test MSE Loss: 0.8957
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.4790239334106445
Epoch: 19, Steps: 53 Train Loss: 1.6625 (Forecasting Loss:1.4702 + XiCon Loss:1.9231 x Lambda(0.1)), Vali MSE Loss: 1.8967 Test MSE Loss: 0.8957
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.4892680644989014
Epoch: 20, Steps: 53 Train Loss: 1.6684 (Forecasting Loss:1.4764 + XiCon Loss:1.9193 x Lambda(0.1)), Vali MSE Loss: 1.9141 Test MSE Loss: 0.8957
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.4616436958312988
Epoch: 21, Steps: 53 Train Loss: 1.6654 (Forecasting Loss:1.4731 + XiCon Loss:1.9222 x Lambda(0.1)), Vali MSE Loss: 1.8802 Test MSE Loss: 0.8957
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.4934911727905273
Epoch: 22, Steps: 53 Train Loss: 1.6676 (Forecasting Loss:1.4754 + XiCon Loss:1.9224 x Lambda(0.1)), Vali MSE Loss: 1.9079 Test MSE Loss: 0.8957
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0112594366073608, mae:0.7800077199935913, mape:0.7758678197860718, mspe:1.7180523872375488 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6039
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5424039363861084
Epoch: 1, Steps: 53 Train Loss: 1.6682 (Forecasting Loss:1.4763 + XiCon Loss:1.9184 x Lambda(0.1)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740656).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4960048198699951
Epoch: 2, Steps: 53 Train Loss: 1.6651 (Forecasting Loss:1.4731 + XiCon Loss:1.9193 x Lambda(0.1)), Vali MSE Loss: 1.7206 Test MSE Loss: 0.9607
Validation loss decreased (1.740656 --> 1.720554).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.484839916229248
Epoch: 3, Steps: 53 Train Loss: 1.6575 (Forecasting Loss:1.4659 + XiCon Loss:1.9167 x Lambda(0.1)), Vali MSE Loss: 1.7406 Test MSE Loss: 0.9644
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.489361047744751
Epoch: 4, Steps: 53 Train Loss: 1.6553 (Forecasting Loss:1.4635 + XiCon Loss:1.9186 x Lambda(0.1)), Vali MSE Loss: 1.7427 Test MSE Loss: 0.9665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.506091594696045
Epoch: 5, Steps: 53 Train Loss: 1.6539 (Forecasting Loss:1.4618 + XiCon Loss:1.9209 x Lambda(0.1)), Vali MSE Loss: 1.7446 Test MSE Loss: 0.9675
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.508270263671875
Epoch: 6, Steps: 53 Train Loss: 1.6537 (Forecasting Loss:1.4618 + XiCon Loss:1.9197 x Lambda(0.1)), Vali MSE Loss: 1.7540 Test MSE Loss: 0.9680
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5109760761260986
Epoch: 7, Steps: 53 Train Loss: 1.6548 (Forecasting Loss:1.4632 + XiCon Loss:1.9162 x Lambda(0.1)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9683
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5099215507507324
Epoch: 8, Steps: 53 Train Loss: 1.6523 (Forecasting Loss:1.4604 + XiCon Loss:1.9187 x Lambda(0.1)), Vali MSE Loss: 1.7245 Test MSE Loss: 0.9684
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5233547687530518
Epoch: 9, Steps: 53 Train Loss: 1.6540 (Forecasting Loss:1.4620 + XiCon Loss:1.9198 x Lambda(0.1)), Vali MSE Loss: 1.7699 Test MSE Loss: 0.9685
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5130810737609863
Epoch: 10, Steps: 53 Train Loss: 1.6510 (Forecasting Loss:1.4593 + XiCon Loss:1.9170 x Lambda(0.1)), Vali MSE Loss: 1.7455 Test MSE Loss: 0.9685
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4678928852081299
Epoch: 11, Steps: 53 Train Loss: 1.6540 (Forecasting Loss:1.4618 + XiCon Loss:1.9213 x Lambda(0.1)), Vali MSE Loss: 1.7521 Test MSE Loss: 0.9686
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4635798931121826
Epoch: 12, Steps: 53 Train Loss: 1.6510 (Forecasting Loss:1.4584 + XiCon Loss:1.9260 x Lambda(0.1)), Vali MSE Loss: 1.7511 Test MSE Loss: 0.9686
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1089411973953247, mae:0.8124903440475464, mape:0.8144602179527283, mspe:1.8784959316253662 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0600+-0.04419, MAE:0.7961+-0.01465, MAPE:0.7954+-0.01744, MSPE:1.7988+-0.07274, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.2419
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.9055033
	speed: 0.0169s/iter; left time: 820.6163s
	iters: 200, epoch: 1 | loss: 0.8186564
	speed: 0.0119s/iter; left time: 579.0595s
	iters: 300, epoch: 1 | loss: 0.5757197
	speed: 0.0109s/iter; left time: 529.5582s
	iters: 400, epoch: 1 | loss: 0.6318685
	speed: 0.0113s/iter; left time: 544.9426s
Epoch: 1 cost time: 6.142946243286133
Epoch: 1, Steps: 487 Train Loss: 0.7654 (Forecasting Loss:0.7417 + XiCon Loss:2.3710 x Lambda(0.01)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036696).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5235546
	speed: 0.0133s/iter; left time: 637.8719s
	iters: 200, epoch: 2 | loss: 0.4814282
	speed: 0.0116s/iter; left time: 558.5716s
	iters: 300, epoch: 2 | loss: 0.5245551
	speed: 0.0109s/iter; left time: 522.2399s
	iters: 400, epoch: 2 | loss: 0.4292782
	speed: 0.0109s/iter; left time: 520.0177s
Epoch: 2 cost time: 5.698908567428589
Epoch: 2, Steps: 487 Train Loss: 0.4582 (Forecasting Loss:0.4346 + XiCon Loss:2.3691 x Lambda(0.01)), Vali MSE Loss: 0.7456 Test MSE Loss: 0.5268
Validation loss decreased (1.036696 --> 0.745611).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.3405773
	speed: 0.0142s/iter; left time: 674.3607s
	iters: 200, epoch: 3 | loss: 0.4468205
	speed: 0.0115s/iter; left time: 548.1855s
	iters: 300, epoch: 3 | loss: 0.5241092
	speed: 0.0115s/iter; left time: 545.5888s
	iters: 400, epoch: 3 | loss: 0.3753462
	speed: 0.0119s/iter; left time: 561.6283s
Epoch: 3 cost time: 5.973687410354614
Epoch: 3, Steps: 487 Train Loss: 0.4285 (Forecasting Loss:0.4049 + XiCon Loss:2.3658 x Lambda(0.01)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5205
Validation loss decreased (0.745611 --> 0.738579).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5003678
	speed: 0.0150s/iter; left time: 706.5611s
	iters: 200, epoch: 4 | loss: 0.4329528
	speed: 0.0123s/iter; left time: 580.6563s
	iters: 300, epoch: 4 | loss: 0.4676881
	speed: 0.0109s/iter; left time: 512.2105s
	iters: 400, epoch: 4 | loss: 0.3442404
	speed: 0.0114s/iter; left time: 535.5013s
Epoch: 4 cost time: 5.963724613189697
Epoch: 4, Steps: 487 Train Loss: 0.4230 (Forecasting Loss:0.3993 + XiCon Loss:2.3681 x Lambda(0.01)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5151
Validation loss decreased (0.738579 --> 0.731864).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4464262
	speed: 0.0141s/iter; left time: 656.4953s
	iters: 200, epoch: 5 | loss: 0.5366035
	speed: 0.0118s/iter; left time: 550.0246s
	iters: 300, epoch: 5 | loss: 0.3914107
	speed: 0.0115s/iter; left time: 532.6086s
	iters: 400, epoch: 5 | loss: 0.3916938
	speed: 0.0120s/iter; left time: 554.0620s
Epoch: 5 cost time: 5.975004196166992
Epoch: 5, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3968 + XiCon Loss:2.3669 x Lambda(0.01)), Vali MSE Loss: 0.7294 Test MSE Loss: 0.5108
Validation loss decreased (0.731864 --> 0.729405).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4319140
	speed: 0.0139s/iter; left time: 642.4679s
	iters: 200, epoch: 6 | loss: 0.4580595
	speed: 0.0119s/iter; left time: 549.4410s
	iters: 300, epoch: 6 | loss: 0.4444002
	speed: 0.0117s/iter; left time: 539.3924s
	iters: 400, epoch: 6 | loss: 0.3854099
	speed: 0.0115s/iter; left time: 526.7347s
Epoch: 6 cost time: 5.944052457809448
Epoch: 6, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3959 + XiCon Loss:2.3660 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5131
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4256865
	speed: 0.0147s/iter; left time: 670.4029s
	iters: 200, epoch: 7 | loss: 0.3229902
	speed: 0.0118s/iter; left time: 539.3623s
	iters: 300, epoch: 7 | loss: 0.4754981
	speed: 0.0114s/iter; left time: 519.8582s
	iters: 400, epoch: 7 | loss: 0.4039108
	speed: 0.0113s/iter; left time: 511.7470s
Epoch: 7 cost time: 5.985529661178589
Epoch: 7, Steps: 487 Train Loss: 0.4190 (Forecasting Loss:0.3954 + XiCon Loss:2.3654 x Lambda(0.01)), Vali MSE Loss: 0.7291 Test MSE Loss: 0.5121
Validation loss decreased (0.729405 --> 0.729107).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3951752
	speed: 0.0143s/iter; left time: 646.7038s
	iters: 200, epoch: 8 | loss: 0.3486075
	speed: 0.0119s/iter; left time: 534.9511s
	iters: 300, epoch: 8 | loss: 0.4099470
	speed: 0.0111s/iter; left time: 498.9710s
	iters: 400, epoch: 8 | loss: 0.4669271
	speed: 0.0123s/iter; left time: 552.4599s
Epoch: 8 cost time: 6.08750319480896
Epoch: 8, Steps: 487 Train Loss: 0.4188 (Forecasting Loss:0.3951 + XiCon Loss:2.3664 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5118
Validation loss decreased (0.729107 --> 0.728972).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5670537
	speed: 0.0141s/iter; left time: 631.7693s
	iters: 200, epoch: 9 | loss: 0.3546448
	speed: 0.0117s/iter; left time: 520.5286s
	iters: 300, epoch: 9 | loss: 0.4555402
	speed: 0.0111s/iter; left time: 494.3195s
	iters: 400, epoch: 9 | loss: 0.4295830
	speed: 0.0122s/iter; left time: 541.6903s
Epoch: 9 cost time: 5.949452638626099
Epoch: 9, Steps: 487 Train Loss: 0.4186 (Forecasting Loss:0.3949 + XiCon Loss:2.3684 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
Validation loss decreased (0.728972 --> 0.728700).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3638722
	speed: 0.0143s/iter; left time: 630.4426s
	iters: 200, epoch: 10 | loss: 0.3991423
	speed: 0.0115s/iter; left time: 507.2058s
	iters: 300, epoch: 10 | loss: 0.3766907
	speed: 0.0114s/iter; left time: 502.5546s
	iters: 400, epoch: 10 | loss: 0.3320716
	speed: 0.0113s/iter; left time: 496.8318s
Epoch: 10 cost time: 5.95262598991394
Epoch: 10, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3692 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3764003
	speed: 0.0136s/iter; left time: 596.1061s
	iters: 200, epoch: 11 | loss: 0.3478432
	speed: 0.0111s/iter; left time: 484.8185s
	iters: 300, epoch: 11 | loss: 0.4406126
	speed: 0.0118s/iter; left time: 515.6462s
	iters: 400, epoch: 11 | loss: 0.3930962
	speed: 0.0114s/iter; left time: 493.1642s
Epoch: 11 cost time: 5.795786142349243
Epoch: 11, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3680 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5117
Validation loss decreased (0.728700 --> 0.728424).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4467686
	speed: 0.0141s/iter; left time: 611.6692s
	iters: 200, epoch: 12 | loss: 0.3743081
	speed: 0.0111s/iter; left time: 480.8580s
	iters: 300, epoch: 12 | loss: 0.3812542
	speed: 0.0116s/iter; left time: 497.4346s
	iters: 400, epoch: 12 | loss: 0.3912097
	speed: 0.0114s/iter; left time: 491.1371s
Epoch: 12 cost time: 5.861251354217529
Epoch: 12, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3946 + XiCon Loss:2.3667 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5562393
	speed: 0.0139s/iter; left time: 594.4268s
	iters: 200, epoch: 13 | loss: 0.4107757
	speed: 0.0113s/iter; left time: 481.3049s
	iters: 300, epoch: 13 | loss: 0.3902473
	speed: 0.0108s/iter; left time: 458.4087s
	iters: 400, epoch: 13 | loss: 0.3260193
	speed: 0.0117s/iter; left time: 497.1940s
Epoch: 13 cost time: 5.822920560836792
Epoch: 13, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3946 + XiCon Loss:2.3655 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4573572
	speed: 0.0142s/iter; left time: 600.4015s
	iters: 200, epoch: 14 | loss: 0.4819692
	speed: 0.0114s/iter; left time: 481.0756s
	iters: 300, epoch: 14 | loss: 0.3565477
	speed: 0.0115s/iter; left time: 481.7657s
	iters: 400, epoch: 14 | loss: 0.3460537
	speed: 0.0117s/iter; left time: 492.7505s
Epoch: 14 cost time: 5.8925909996032715
Epoch: 14, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3682 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3947574
	speed: 0.0143s/iter; left time: 599.1887s
	iters: 200, epoch: 15 | loss: 0.4114608
	speed: 0.0113s/iter; left time: 469.9453s
	iters: 300, epoch: 15 | loss: 0.4592420
	speed: 0.0109s/iter; left time: 452.8843s
	iters: 400, epoch: 15 | loss: 0.4233124
	speed: 0.0109s/iter; left time: 450.3132s
Epoch: 15 cost time: 5.789645195007324
Epoch: 15, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3946 + XiCon Loss:2.3684 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4742060
	speed: 0.0150s/iter; left time: 618.0992s
	iters: 200, epoch: 16 | loss: 0.4975001
	speed: 0.0125s/iter; left time: 516.9914s
	iters: 300, epoch: 16 | loss: 0.4047593
	speed: 0.0118s/iter; left time: 484.5197s
	iters: 400, epoch: 16 | loss: 0.4381535
	speed: 0.0115s/iter; left time: 472.2778s
Epoch: 16 cost time: 6.069235563278198
Epoch: 16, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3947 + XiCon Loss:2.3632 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3936210
	speed: 0.0151s/iter; left time: 617.2189s
	iters: 200, epoch: 17 | loss: 0.3923448
	speed: 0.0118s/iter; left time: 478.5912s
	iters: 300, epoch: 17 | loss: 0.4779667
	speed: 0.0120s/iter; left time: 489.2922s
	iters: 400, epoch: 17 | loss: 0.4540980
	speed: 0.0115s/iter; left time: 466.2270s
Epoch: 17 cost time: 6.00641393661499
Epoch: 17, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3947 + XiCon Loss:2.3674 x Lambda(0.01)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3630883
	speed: 0.0145s/iter; left time: 582.8207s
	iters: 200, epoch: 18 | loss: 0.4405637
	speed: 0.0116s/iter; left time: 467.4676s
	iters: 300, epoch: 18 | loss: 0.3639599
	speed: 0.0115s/iter; left time: 462.4066s
	iters: 400, epoch: 18 | loss: 0.3403343
	speed: 0.0111s/iter; left time: 443.2736s
Epoch: 18 cost time: 5.902742147445679
Epoch: 18, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3945 + XiCon Loss:2.3694 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5117
Validation loss decreased (0.728424 --> 0.728252).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3981002
	speed: 0.0144s/iter; left time: 574.3699s
	iters: 200, epoch: 19 | loss: 0.4124720
	speed: 0.0118s/iter; left time: 467.7861s
	iters: 300, epoch: 19 | loss: 0.4084617
	speed: 0.0117s/iter; left time: 464.2860s
	iters: 400, epoch: 19 | loss: 0.4339840
	speed: 0.0118s/iter; left time: 467.2188s
Epoch: 19 cost time: 6.015961647033691
Epoch: 19, Steps: 487 Train Loss: 0.4181 (Forecasting Loss:0.3944 + XiCon Loss:2.3659 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4135972
	speed: 0.0138s/iter; left time: 544.4909s
	iters: 200, epoch: 20 | loss: 0.4081794
	speed: 0.0122s/iter; left time: 478.8559s
	iters: 300, epoch: 20 | loss: 0.3428916
	speed: 0.0116s/iter; left time: 453.8115s
	iters: 400, epoch: 20 | loss: 0.3845167
	speed: 0.0119s/iter; left time: 465.6690s
Epoch: 20 cost time: 6.101228713989258
Epoch: 20, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3946 + XiCon Loss:2.3703 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.3267980
	speed: 0.0160s/iter; left time: 620.9369s
	iters: 200, epoch: 21 | loss: 0.4013278
	speed: 0.0130s/iter; left time: 505.7106s
	iters: 300, epoch: 21 | loss: 0.3467712
	speed: 0.0127s/iter; left time: 489.3661s
	iters: 400, epoch: 21 | loss: 0.4260986
	speed: 0.0130s/iter; left time: 502.6219s
Epoch: 21 cost time: 6.6109778881073
Epoch: 21, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3661 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4201308
	speed: 0.0146s/iter; left time: 559.0496s
	iters: 200, epoch: 22 | loss: 0.4708596
	speed: 0.0113s/iter; left time: 432.3113s
	iters: 300, epoch: 22 | loss: 0.4864844
	speed: 0.0113s/iter; left time: 429.9040s
	iters: 400, epoch: 22 | loss: 0.3811109
	speed: 0.0112s/iter; left time: 425.1928s
Epoch: 22 cost time: 5.800619840621948
Epoch: 22, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3714 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4971711
	speed: 0.0142s/iter; left time: 537.6376s
	iters: 200, epoch: 23 | loss: 0.3776077
	speed: 0.0116s/iter; left time: 439.1287s
	iters: 300, epoch: 23 | loss: 0.3884124
	speed: 0.0118s/iter; left time: 445.5732s
	iters: 400, epoch: 23 | loss: 0.4635518
	speed: 0.0115s/iter; left time: 433.5953s
Epoch: 23 cost time: 5.959750652313232
Epoch: 23, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3946 + XiCon Loss:2.3654 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.5036275
	speed: 0.0134s/iter; left time: 502.3293s
	iters: 200, epoch: 24 | loss: 0.4032496
	speed: 0.0110s/iter; left time: 409.2874s
	iters: 300, epoch: 24 | loss: 0.4561466
	speed: 0.0110s/iter; left time: 410.4598s
	iters: 400, epoch: 24 | loss: 0.3461611
	speed: 0.0117s/iter; left time: 435.1960s
Epoch: 24 cost time: 5.756200551986694
Epoch: 24, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3945 + XiCon Loss:2.3688 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4127885
	speed: 0.0141s/iter; left time: 519.1143s
	iters: 200, epoch: 25 | loss: 0.4327678
	speed: 0.0124s/iter; left time: 456.2963s
	iters: 300, epoch: 25 | loss: 0.3804491
	speed: 0.0115s/iter; left time: 422.8152s
	iters: 400, epoch: 25 | loss: 0.4262196
	speed: 0.0118s/iter; left time: 432.6529s
Epoch: 25 cost time: 5.985885381698608
Epoch: 25, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3945 + XiCon Loss:2.3671 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5117
Validation loss decreased (0.728252 --> 0.728156).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3873329
	speed: 0.0138s/iter; left time: 503.3945s
	iters: 200, epoch: 26 | loss: 0.3876929
	speed: 0.0118s/iter; left time: 427.6798s
	iters: 300, epoch: 26 | loss: 0.5142304
	speed: 0.0117s/iter; left time: 425.6043s
	iters: 400, epoch: 26 | loss: 0.3509401
	speed: 0.0119s/iter; left time: 430.2900s
Epoch: 26 cost time: 6.044717073440552
Epoch: 26, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3947 + XiCon Loss:2.3700 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3986821
	speed: 0.0153s/iter; left time: 551.4648s
	iters: 200, epoch: 27 | loss: 0.4227785
	speed: 0.0119s/iter; left time: 428.2352s
	iters: 300, epoch: 27 | loss: 0.3526160
	speed: 0.0116s/iter; left time: 414.0350s
	iters: 400, epoch: 27 | loss: 0.3668630
	speed: 0.0108s/iter; left time: 385.1335s
Epoch: 27 cost time: 5.983667612075806
Epoch: 27, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3666 x Lambda(0.01)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4195216
	speed: 0.0142s/iter; left time: 503.6744s
	iters: 200, epoch: 28 | loss: 0.4233175
	speed: 0.0116s/iter; left time: 408.8538s
	iters: 300, epoch: 28 | loss: 0.4274152
	speed: 0.0128s/iter; left time: 451.2385s
	iters: 400, epoch: 28 | loss: 0.3962229
	speed: 0.0118s/iter; left time: 414.4511s
Epoch: 28 cost time: 6.033283710479736
Epoch: 28, Steps: 487 Train Loss: 0.4181 (Forecasting Loss:0.3944 + XiCon Loss:2.3666 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3646748
	speed: 0.0152s/iter; left time: 530.1931s
	iters: 200, epoch: 29 | loss: 0.4674657
	speed: 0.0114s/iter; left time: 397.6068s
	iters: 300, epoch: 29 | loss: 0.4381058
	speed: 0.0109s/iter; left time: 379.1054s
	iters: 400, epoch: 29 | loss: 0.4274422
	speed: 0.0116s/iter; left time: 402.6301s
Epoch: 29 cost time: 5.899338960647583
Epoch: 29, Steps: 487 Train Loss: 0.4185 (Forecasting Loss:0.3948 + XiCon Loss:2.3693 x Lambda(0.01)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3912059
	speed: 0.0144s/iter; left time: 498.0277s
	iters: 200, epoch: 30 | loss: 0.4163764
	speed: 0.0116s/iter; left time: 397.4123s
	iters: 300, epoch: 30 | loss: 0.4574454
	speed: 0.0109s/iter; left time: 373.0408s
	iters: 400, epoch: 30 | loss: 0.4027677
	speed: 0.0115s/iter; left time: 393.0056s
Epoch: 30 cost time: 5.8882222175598145
Epoch: 30, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3945 + XiCon Loss:2.3705 x Lambda(0.01)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.5077955
	speed: 0.0136s/iter; left time: 461.1034s
	iters: 200, epoch: 31 | loss: 0.3325149
	speed: 0.0113s/iter; left time: 382.2023s
	iters: 300, epoch: 31 | loss: 0.4267691
	speed: 0.0115s/iter; left time: 388.1938s
	iters: 400, epoch: 31 | loss: 0.3497324
	speed: 0.0117s/iter; left time: 393.4896s
Epoch: 31 cost time: 5.762603998184204
Epoch: 31, Steps: 487 Train Loss: 0.4182 (Forecasting Loss:0.3945 + XiCon Loss:2.3685 x Lambda(0.01)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4105277
	speed: 0.0143s/iter; left time: 478.8762s
	iters: 200, epoch: 32 | loss: 0.4929276
	speed: 0.0125s/iter; left time: 416.9752s
	iters: 300, epoch: 32 | loss: 0.3641734
	speed: 0.0110s/iter; left time: 366.0944s
	iters: 400, epoch: 32 | loss: 0.3267320
	speed: 0.0116s/iter; left time: 385.2591s
Epoch: 32 cost time: 6.019165754318237
Epoch: 32, Steps: 487 Train Loss: 0.4180 (Forecasting Loss:0.3943 + XiCon Loss:2.3667 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3789596
	speed: 0.0147s/iter; left time: 486.6695s
	iters: 200, epoch: 33 | loss: 0.3376789
	speed: 0.0112s/iter; left time: 368.8429s
	iters: 300, epoch: 33 | loss: 0.4285393
	speed: 0.0111s/iter; left time: 364.5485s
	iters: 400, epoch: 33 | loss: 0.4986399
	speed: 0.0112s/iter; left time: 365.1084s
Epoch: 33 cost time: 5.8795294761657715
Epoch: 33, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3947 + XiCon Loss:2.3688 x Lambda(0.01)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4210198
	speed: 0.0154s/iter; left time: 500.6248s
	iters: 200, epoch: 34 | loss: 0.4597071
	speed: 0.0120s/iter; left time: 389.3972s
	iters: 300, epoch: 34 | loss: 0.3761795
	speed: 0.0122s/iter; left time: 395.9533s
	iters: 400, epoch: 34 | loss: 0.3904716
	speed: 0.0119s/iter; left time: 382.9934s
Epoch: 34 cost time: 6.1829588413238525
Epoch: 34, Steps: 487 Train Loss: 0.4181 (Forecasting Loss:0.3945 + XiCon Loss:2.3664 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4045311
	speed: 0.0141s/iter; left time: 450.8249s
	iters: 200, epoch: 35 | loss: 0.3378875
	speed: 0.0113s/iter; left time: 362.0944s
	iters: 300, epoch: 35 | loss: 0.4196094
	speed: 0.0120s/iter; left time: 381.8357s
	iters: 400, epoch: 35 | loss: 0.4308462
	speed: 0.0118s/iter; left time: 374.0735s
Epoch: 35 cost time: 5.877777338027954
Epoch: 35, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3946 + XiCon Loss:2.3705 x Lambda(0.01)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182838439941406, mae:0.5050514340400696, mape:3.5340683460235596, mspe:1159.177490234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.6661
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.6980203
	speed: 0.0156s/iter; left time: 756.4195s
	iters: 200, epoch: 1 | loss: 0.8893958
	speed: 0.0134s/iter; left time: 647.5846s
	iters: 300, epoch: 1 | loss: 0.5824047
	speed: 0.0138s/iter; left time: 667.9205s
	iters: 400, epoch: 1 | loss: 0.5137993
	speed: 0.0133s/iter; left time: 643.9830s
Epoch: 1 cost time: 6.759093999862671
Epoch: 1, Steps: 487 Train Loss: 0.7584 (Forecasting Loss:0.7348 + XiCon Loss:2.3585 x Lambda(0.01)), Vali MSE Loss: 1.0307 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030659).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5140153
	speed: 0.0149s/iter; left time: 718.0916s
	iters: 200, epoch: 2 | loss: 0.5096046
	speed: 0.0134s/iter; left time: 643.4338s
	iters: 300, epoch: 2 | loss: 0.4167494
	speed: 0.0140s/iter; left time: 668.9351s
	iters: 400, epoch: 2 | loss: 0.4987451
	speed: 0.0126s/iter; left time: 604.6306s
Epoch: 2 cost time: 6.608540773391724
Epoch: 2, Steps: 487 Train Loss: 0.4620 (Forecasting Loss:0.4383 + XiCon Loss:2.3686 x Lambda(0.01)), Vali MSE Loss: 0.7327 Test MSE Loss: 0.5270
Validation loss decreased (1.030659 --> 0.732743).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4446004
	speed: 0.0160s/iter; left time: 762.8762s
	iters: 200, epoch: 3 | loss: 0.4118742
	speed: 0.0130s/iter; left time: 619.8540s
	iters: 300, epoch: 3 | loss: 0.4344455
	speed: 0.0136s/iter; left time: 644.0103s
	iters: 400, epoch: 3 | loss: 0.3815921
	speed: 0.0136s/iter; left time: 642.9004s
Epoch: 3 cost time: 6.7865283489227295
Epoch: 3, Steps: 487 Train Loss: 0.4285 (Forecasting Loss:0.4049 + XiCon Loss:2.3586 x Lambda(0.01)), Vali MSE Loss: 0.7178 Test MSE Loss: 0.5186
Validation loss decreased (0.732743 --> 0.717794).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5445484
	speed: 0.0145s/iter; left time: 682.4967s
	iters: 200, epoch: 4 | loss: 0.3889519
	speed: 0.0128s/iter; left time: 604.1115s
	iters: 300, epoch: 4 | loss: 0.5354218
	speed: 0.0129s/iter; left time: 606.8871s
	iters: 400, epoch: 4 | loss: 0.5214679
	speed: 0.0133s/iter; left time: 623.9141s
Epoch: 4 cost time: 6.579092741012573
Epoch: 4, Steps: 487 Train Loss: 0.4224 (Forecasting Loss:0.3989 + XiCon Loss:2.3553 x Lambda(0.01)), Vali MSE Loss: 0.7115 Test MSE Loss: 0.5165
Validation loss decreased (0.717794 --> 0.711507).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3834035
	speed: 0.0150s/iter; left time: 699.2633s
	iters: 200, epoch: 5 | loss: 0.4405919
	speed: 0.0132s/iter; left time: 613.6487s
	iters: 300, epoch: 5 | loss: 0.3940431
	speed: 0.0131s/iter; left time: 607.5616s
	iters: 400, epoch: 5 | loss: 0.3255877
	speed: 0.0133s/iter; left time: 614.7274s
Epoch: 5 cost time: 6.674343109130859
Epoch: 5, Steps: 487 Train Loss: 0.4202 (Forecasting Loss:0.3966 + XiCon Loss:2.3607 x Lambda(0.01)), Vali MSE Loss: 0.7100 Test MSE Loss: 0.5146
Validation loss decreased (0.711507 --> 0.710018).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3618039
	speed: 0.0143s/iter; left time: 659.6188s
	iters: 200, epoch: 6 | loss: 0.3914796
	speed: 0.0131s/iter; left time: 602.9605s
	iters: 300, epoch: 6 | loss: 0.3268631
	speed: 0.0129s/iter; left time: 594.6499s
	iters: 400, epoch: 6 | loss: 0.4474881
	speed: 0.0130s/iter; left time: 597.6976s
Epoch: 6 cost time: 6.587148427963257
Epoch: 6, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3955 + XiCon Loss:2.3627 x Lambda(0.01)), Vali MSE Loss: 0.7074 Test MSE Loss: 0.5133
Validation loss decreased (0.710018 --> 0.707385).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3752366
	speed: 0.0150s/iter; left time: 686.1360s
	iters: 200, epoch: 7 | loss: 0.3738329
	speed: 0.0130s/iter; left time: 590.8901s
	iters: 300, epoch: 7 | loss: 0.4932646
	speed: 0.0133s/iter; left time: 605.6493s
	iters: 400, epoch: 7 | loss: 0.3841643
	speed: 0.0134s/iter; left time: 606.0935s
Epoch: 7 cost time: 6.6955437660217285
Epoch: 7, Steps: 487 Train Loss: 0.4183 (Forecasting Loss:0.3948 + XiCon Loss:2.3563 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5133
Validation loss decreased (0.707385 --> 0.706842).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4570206
	speed: 0.0149s/iter; left time: 673.7137s
	iters: 200, epoch: 8 | loss: 0.4378895
	speed: 0.0128s/iter; left time: 578.3992s
	iters: 300, epoch: 8 | loss: 0.3801939
	speed: 0.0134s/iter; left time: 604.6651s
	iters: 400, epoch: 8 | loss: 0.3260089
	speed: 0.0132s/iter; left time: 592.6840s
Epoch: 8 cost time: 6.643433094024658
Epoch: 8, Steps: 487 Train Loss: 0.4180 (Forecasting Loss:0.3944 + XiCon Loss:2.3558 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5132
Validation loss decreased (0.706842 --> 0.706643).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3948599
	speed: 0.0152s/iter; left time: 678.6905s
	iters: 200, epoch: 9 | loss: 0.4086088
	speed: 0.0134s/iter; left time: 598.8209s
	iters: 300, epoch: 9 | loss: 0.3992195
	speed: 0.0132s/iter; left time: 589.5767s
	iters: 400, epoch: 9 | loss: 0.4975332
	speed: 0.0138s/iter; left time: 612.2793s
Epoch: 9 cost time: 6.7994935512542725
Epoch: 9, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3942 + XiCon Loss:2.3558 x Lambda(0.01)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5130
Validation loss decreased (0.706643 --> 0.705977).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4180503
	speed: 0.0149s/iter; left time: 659.7876s
	iters: 200, epoch: 10 | loss: 0.4156601
	speed: 0.0134s/iter; left time: 592.9413s
	iters: 300, epoch: 10 | loss: 0.2919908
	speed: 0.0134s/iter; left time: 589.7151s
	iters: 400, epoch: 10 | loss: 0.4266897
	speed: 0.0133s/iter; left time: 584.8790s
Epoch: 10 cost time: 6.75806999206543
Epoch: 10, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3942 + XiCon Loss:2.3569 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3354854
	speed: 0.0161s/iter; left time: 701.9381s
	iters: 200, epoch: 11 | loss: 0.3786016
	speed: 0.0136s/iter; left time: 593.7025s
	iters: 300, epoch: 11 | loss: 0.3835808
	speed: 0.0130s/iter; left time: 567.2569s
	iters: 400, epoch: 11 | loss: 0.5360259
	speed: 0.0125s/iter; left time: 542.7245s
Epoch: 11 cost time: 6.674628734588623
Epoch: 11, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3939 + XiCon Loss:2.3491 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5130
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3934767
	speed: 0.0154s/iter; left time: 663.9172s
	iters: 200, epoch: 12 | loss: 0.4225978
	speed: 0.0124s/iter; left time: 534.9802s
	iters: 300, epoch: 12 | loss: 0.4505407
	speed: 0.0137s/iter; left time: 588.2934s
	iters: 400, epoch: 12 | loss: 0.4343229
	speed: 0.0125s/iter; left time: 537.5286s
Epoch: 12 cost time: 6.536078453063965
Epoch: 12, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3943 + XiCon Loss:2.3558 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5130
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4274731
	speed: 0.0134s/iter; left time: 572.8245s
	iters: 200, epoch: 13 | loss: 0.4907559
	speed: 0.0115s/iter; left time: 492.4029s
	iters: 300, epoch: 13 | loss: 0.3827456
	speed: 0.0113s/iter; left time: 481.9427s
	iters: 400, epoch: 13 | loss: 0.3886930
	speed: 0.0109s/iter; left time: 463.2557s
Epoch: 13 cost time: 5.680100679397583
Epoch: 13, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3942 + XiCon Loss:2.3598 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5130
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3973034
	speed: 0.0151s/iter; left time: 638.6585s
	iters: 200, epoch: 14 | loss: 0.4300584
	speed: 0.0133s/iter; left time: 561.1600s
	iters: 300, epoch: 14 | loss: 0.3852262
	speed: 0.0129s/iter; left time: 542.1548s
	iters: 400, epoch: 14 | loss: 0.4140186
	speed: 0.0132s/iter; left time: 554.8211s
Epoch: 14 cost time: 6.620593547821045
Epoch: 14, Steps: 487 Train Loss: 0.4177 (Forecasting Loss:0.3941 + XiCon Loss:2.3583 x Lambda(0.01)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5129
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4710190
	speed: 0.0154s/iter; left time: 641.9738s
	iters: 200, epoch: 15 | loss: 0.4339049
	speed: 0.0136s/iter; left time: 564.9662s
	iters: 300, epoch: 15 | loss: 0.4352912
	speed: 0.0136s/iter; left time: 566.7721s
	iters: 400, epoch: 15 | loss: 0.3960373
	speed: 0.0138s/iter; left time: 574.5165s
Epoch: 15 cost time: 6.954632520675659
Epoch: 15, Steps: 487 Train Loss: 0.4173 (Forecasting Loss:0.3938 + XiCon Loss:2.3517 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4393526
	speed: 0.0167s/iter; left time: 690.8930s
	iters: 200, epoch: 16 | loss: 0.4630897
	speed: 0.0133s/iter; left time: 547.5645s
	iters: 300, epoch: 16 | loss: 0.3965729
	speed: 0.0133s/iter; left time: 545.7695s
	iters: 400, epoch: 16 | loss: 0.4783705
	speed: 0.0126s/iter; left time: 518.5766s
Epoch: 16 cost time: 6.712295055389404
Epoch: 16, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3939 + XiCon Loss:2.3550 x Lambda(0.01)), Vali MSE Loss: 0.7068 Test MSE Loss: 0.5129
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4135987
	speed: 0.0152s/iter; left time: 619.8941s
	iters: 200, epoch: 17 | loss: 0.4608429
	speed: 0.0124s/iter; left time: 505.9405s
	iters: 300, epoch: 17 | loss: 0.4311308
	speed: 0.0136s/iter; left time: 551.3193s
	iters: 400, epoch: 17 | loss: 0.4646088
	speed: 0.0133s/iter; left time: 538.3473s
Epoch: 17 cost time: 6.652037620544434
Epoch: 17, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3942 + XiCon Loss:2.3571 x Lambda(0.01)), Vali MSE Loss: 0.7066 Test MSE Loss: 0.5129
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4540384
	speed: 0.0155s/iter; left time: 624.7476s
	iters: 200, epoch: 18 | loss: 0.4347265
	speed: 0.0125s/iter; left time: 503.5093s
	iters: 300, epoch: 18 | loss: 0.5993304
	speed: 0.0138s/iter; left time: 552.2374s
	iters: 400, epoch: 18 | loss: 0.4183567
	speed: 0.0138s/iter; left time: 550.9154s
Epoch: 18 cost time: 6.708941459655762
Epoch: 18, Steps: 487 Train Loss: 0.4175 (Forecasting Loss:0.3939 + XiCon Loss:2.3541 x Lambda(0.01)), Vali MSE Loss: 0.7063 Test MSE Loss: 0.5129
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3170206
	speed: 0.0154s/iter; left time: 615.2452s
	iters: 200, epoch: 19 | loss: 0.4860721
	speed: 0.0131s/iter; left time: 521.6408s
	iters: 300, epoch: 19 | loss: 0.4426769
	speed: 0.0133s/iter; left time: 525.3203s
	iters: 400, epoch: 19 | loss: 0.3669423
	speed: 0.0138s/iter; left time: 546.5057s
Epoch: 19 cost time: 6.803045272827148
Epoch: 19, Steps: 487 Train Loss: 0.4178 (Forecasting Loss:0.3942 + XiCon Loss:2.3562 x Lambda(0.01)), Vali MSE Loss: 0.7069 Test MSE Loss: 0.5129
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5196808576583862, mae:0.5063372254371643, mape:3.444826602935791, mspe:1084.57666015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.1815
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1378491
	speed: 0.0151s/iter; left time: 734.7428s
	iters: 200, epoch: 1 | loss: 0.7912088
	speed: 0.0130s/iter; left time: 631.7350s
	iters: 300, epoch: 1 | loss: 0.7052153
	speed: 0.0127s/iter; left time: 614.4354s
	iters: 400, epoch: 1 | loss: 0.7567424
	speed: 0.0121s/iter; left time: 584.9686s
Epoch: 1 cost time: 6.43370246887207
Epoch: 1, Steps: 487 Train Loss: 0.8647 (Forecasting Loss:0.8409 + XiCon Loss:2.3778 x Lambda(0.01)), Vali MSE Loss: 1.1923 Test MSE Loss: 0.6744
Validation loss decreased (inf --> 1.192289).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4670969
	speed: 0.0149s/iter; left time: 714.6383s
	iters: 200, epoch: 2 | loss: 0.4438407
	speed: 0.0134s/iter; left time: 641.3797s
	iters: 300, epoch: 2 | loss: 0.3932156
	speed: 0.0143s/iter; left time: 682.8059s
	iters: 400, epoch: 2 | loss: 0.5354419
	speed: 0.0144s/iter; left time: 686.8621s
Epoch: 2 cost time: 6.908799886703491
Epoch: 2, Steps: 487 Train Loss: 0.4763 (Forecasting Loss:0.4526 + XiCon Loss:2.3711 x Lambda(0.01)), Vali MSE Loss: 0.7521 Test MSE Loss: 0.5336
Validation loss decreased (1.192289 --> 0.752052).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4780317
	speed: 0.0158s/iter; left time: 750.1697s
	iters: 200, epoch: 3 | loss: 0.4110142
	speed: 0.0139s/iter; left time: 659.8626s
	iters: 300, epoch: 3 | loss: 0.3534315
	speed: 0.0132s/iter; left time: 626.0969s
	iters: 400, epoch: 3 | loss: 0.4093746
	speed: 0.0134s/iter; left time: 635.2482s
Epoch: 3 cost time: 6.818093538284302
Epoch: 3, Steps: 487 Train Loss: 0.4318 (Forecasting Loss:0.4081 + XiCon Loss:2.3693 x Lambda(0.01)), Vali MSE Loss: 0.7396 Test MSE Loss: 0.5303
Validation loss decreased (0.752052 --> 0.739607).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4015930
	speed: 0.0153s/iter; left time: 720.7571s
	iters: 200, epoch: 4 | loss: 0.3710400
	speed: 0.0132s/iter; left time: 618.5866s
	iters: 300, epoch: 4 | loss: 0.4277751
	speed: 0.0131s/iter; left time: 614.9965s
	iters: 400, epoch: 4 | loss: 0.4911937
	speed: 0.0127s/iter; left time: 596.3125s
Epoch: 4 cost time: 6.651209592819214
Epoch: 4, Steps: 487 Train Loss: 0.4260 (Forecasting Loss:0.4024 + XiCon Loss:2.3609 x Lambda(0.01)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5268
Validation loss decreased (0.739607 --> 0.731935).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4056123
	speed: 0.0151s/iter; left time: 702.8306s
	iters: 200, epoch: 5 | loss: 0.3869261
	speed: 0.0131s/iter; left time: 609.2686s
	iters: 300, epoch: 5 | loss: 0.4167278
	speed: 0.0125s/iter; left time: 581.4967s
	iters: 400, epoch: 5 | loss: 0.4481609
	speed: 0.0137s/iter; left time: 636.4365s
Epoch: 5 cost time: 6.4663496017456055
Epoch: 5, Steps: 487 Train Loss: 0.4235 (Forecasting Loss:0.3999 + XiCon Loss:2.3631 x Lambda(0.01)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5230
Validation loss decreased (0.731935 --> 0.730066).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4097698
	speed: 0.0153s/iter; left time: 706.5384s
	iters: 200, epoch: 6 | loss: 0.3961028
	speed: 0.0134s/iter; left time: 618.4540s
	iters: 300, epoch: 6 | loss: 0.4085675
	speed: 0.0135s/iter; left time: 619.6145s
	iters: 400, epoch: 6 | loss: 0.3979091
	speed: 0.0135s/iter; left time: 621.2684s
Epoch: 6 cost time: 6.777315616607666
Epoch: 6, Steps: 487 Train Loss: 0.4221 (Forecasting Loss:0.3985 + XiCon Loss:2.3622 x Lambda(0.01)), Vali MSE Loss: 0.7282 Test MSE Loss: 0.5222
Validation loss decreased (0.730066 --> 0.728150).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3960861
	speed: 0.0155s/iter; left time: 708.0744s
	iters: 200, epoch: 7 | loss: 0.4115486
	speed: 0.0134s/iter; left time: 609.0113s
	iters: 300, epoch: 7 | loss: 0.4714600
	speed: 0.0130s/iter; left time: 591.9865s
	iters: 400, epoch: 7 | loss: 0.4370257
	speed: 0.0130s/iter; left time: 591.8589s
Epoch: 7 cost time: 6.672527551651001
Epoch: 7, Steps: 487 Train Loss: 0.4216 (Forecasting Loss:0.3980 + XiCon Loss:2.3633 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5215
Validation loss decreased (0.728150 --> 0.727778).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4393283
	speed: 0.0155s/iter; left time: 699.3704s
	iters: 200, epoch: 8 | loss: 0.3944120
	speed: 0.0136s/iter; left time: 611.6671s
	iters: 300, epoch: 8 | loss: 0.4251865
	speed: 0.0127s/iter; left time: 570.5383s
	iters: 400, epoch: 8 | loss: 0.3680983
	speed: 0.0132s/iter; left time: 593.3721s
Epoch: 8 cost time: 6.7006096839904785
Epoch: 8, Steps: 487 Train Loss: 0.4213 (Forecasting Loss:0.3977 + XiCon Loss:2.3605 x Lambda(0.01)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4935504
	speed: 0.0157s/iter; left time: 702.1110s
	iters: 200, epoch: 9 | loss: 0.4128593
	speed: 0.0126s/iter; left time: 561.5466s
	iters: 300, epoch: 9 | loss: 0.4761629
	speed: 0.0131s/iter; left time: 581.1635s
	iters: 400, epoch: 9 | loss: 0.3404388
	speed: 0.0127s/iter; left time: 562.6023s
Epoch: 9 cost time: 6.609994411468506
Epoch: 9, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3975 + XiCon Loss:2.3638 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5215
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.5180683
	speed: 0.0144s/iter; left time: 635.3056s
	iters: 200, epoch: 10 | loss: 0.4324758
	speed: 0.0123s/iter; left time: 543.7820s
	iters: 300, epoch: 10 | loss: 0.3754704
	speed: 0.0130s/iter; left time: 572.2947s
	iters: 400, epoch: 10 | loss: 0.3622878
	speed: 0.0135s/iter; left time: 591.7899s
Epoch: 10 cost time: 6.4833903312683105
Epoch: 10, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3613 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5214
Validation loss decreased (0.727778 --> 0.727776).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4330945
	speed: 0.0154s/iter; left time: 671.2890s
	iters: 200, epoch: 11 | loss: 0.3935293
	speed: 0.0139s/iter; left time: 605.1256s
	iters: 300, epoch: 11 | loss: 0.4391761
	speed: 0.0124s/iter; left time: 538.5559s
	iters: 400, epoch: 11 | loss: 0.3779705
	speed: 0.0136s/iter; left time: 588.5508s
Epoch: 11 cost time: 6.734823703765869
Epoch: 11, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3973 + XiCon Loss:2.3622 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5214
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3900016
	speed: 0.0150s/iter; left time: 648.4011s
	iters: 200, epoch: 12 | loss: 0.5126183
	speed: 0.0123s/iter; left time: 531.4766s
	iters: 300, epoch: 12 | loss: 0.3800099
	speed: 0.0128s/iter; left time: 550.7775s
	iters: 400, epoch: 12 | loss: 0.4716770
	speed: 0.0128s/iter; left time: 550.5040s
Epoch: 12 cost time: 6.437485456466675
Epoch: 12, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3975 + XiCon Loss:2.3617 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5214
Validation loss decreased (0.727776 --> 0.727636).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3538660
	speed: 0.0150s/iter; left time: 641.2244s
	iters: 200, epoch: 13 | loss: 0.4557742
	speed: 0.0129s/iter; left time: 548.8293s
	iters: 300, epoch: 13 | loss: 0.4534004
	speed: 0.0131s/iter; left time: 558.6478s
	iters: 400, epoch: 13 | loss: 0.3438117
	speed: 0.0134s/iter; left time: 567.2628s
Epoch: 13 cost time: 6.5804362297058105
Epoch: 13, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3604 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4347088
	speed: 0.0156s/iter; left time: 659.7705s
	iters: 200, epoch: 14 | loss: 0.4964010
	speed: 0.0133s/iter; left time: 558.7887s
	iters: 300, epoch: 14 | loss: 0.3642155
	speed: 0.0131s/iter; left time: 550.6192s
	iters: 400, epoch: 14 | loss: 0.5830179
	speed: 0.0128s/iter; left time: 537.7631s
Epoch: 14 cost time: 6.6789655685424805
Epoch: 14, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3974 + XiCon Loss:2.3577 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
Validation loss decreased (0.727636 --> 0.727230).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3913633
	speed: 0.0155s/iter; left time: 648.3817s
	iters: 200, epoch: 15 | loss: 0.4500277
	speed: 0.0129s/iter; left time: 538.4618s
	iters: 300, epoch: 15 | loss: 0.4370867
	speed: 0.0130s/iter; left time: 541.7044s
	iters: 400, epoch: 15 | loss: 0.3378716
	speed: 0.0135s/iter; left time: 558.9177s
Epoch: 15 cost time: 6.652960538864136
Epoch: 15, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3975 + XiCon Loss:2.3601 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3482648
	speed: 0.0153s/iter; left time: 633.5645s
	iters: 200, epoch: 16 | loss: 0.3998363
	speed: 0.0134s/iter; left time: 550.9739s
	iters: 300, epoch: 16 | loss: 0.3919514
	speed: 0.0127s/iter; left time: 521.7111s
	iters: 400, epoch: 16 | loss: 0.4568237
	speed: 0.0135s/iter; left time: 554.0671s
Epoch: 16 cost time: 6.653439044952393
Epoch: 16, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3971 + XiCon Loss:2.3633 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4005122
	speed: 0.0159s/iter; left time: 650.4988s
	iters: 200, epoch: 17 | loss: 0.4587739
	speed: 0.0129s/iter; left time: 523.9408s
	iters: 300, epoch: 17 | loss: 0.4497792
	speed: 0.0127s/iter; left time: 513.9350s
	iters: 400, epoch: 17 | loss: 0.3433158
	speed: 0.0131s/iter; left time: 531.4200s
Epoch: 17 cost time: 6.6218581199646
Epoch: 17, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3974 + XiCon Loss:2.3647 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3799358
	speed: 0.0151s/iter; left time: 610.1993s
	iters: 200, epoch: 18 | loss: 0.5216354
	speed: 0.0131s/iter; left time: 525.0518s
	iters: 300, epoch: 18 | loss: 0.4271041
	speed: 0.0129s/iter; left time: 515.9014s
	iters: 400, epoch: 18 | loss: 0.4873914
	speed: 0.0125s/iter; left time: 501.1290s
Epoch: 18 cost time: 6.5294647216796875
Epoch: 18, Steps: 487 Train Loss: 0.4207 (Forecasting Loss:0.3972 + XiCon Loss:2.3584 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3435866
	speed: 0.0154s/iter; left time: 612.6648s
	iters: 200, epoch: 19 | loss: 0.4016668
	speed: 0.0126s/iter; left time: 501.9310s
	iters: 300, epoch: 19 | loss: 0.4262388
	speed: 0.0133s/iter; left time: 525.4955s
	iters: 400, epoch: 19 | loss: 0.5014644
	speed: 0.0135s/iter; left time: 532.6029s
Epoch: 19 cost time: 6.638582706451416
Epoch: 19, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3974 + XiCon Loss:2.3584 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3545212
	speed: 0.0156s/iter; left time: 612.8688s
	iters: 200, epoch: 20 | loss: 0.4503120
	speed: 0.0133s/iter; left time: 520.5385s
	iters: 300, epoch: 20 | loss: 0.3888186
	speed: 0.0121s/iter; left time: 472.8940s
	iters: 400, epoch: 20 | loss: 0.4249753
	speed: 0.0130s/iter; left time: 506.1897s
Epoch: 20 cost time: 6.511452674865723
Epoch: 20, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3973 + XiCon Loss:2.3625 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4613654
	speed: 0.0159s/iter; left time: 616.6912s
	iters: 200, epoch: 21 | loss: 0.4146263
	speed: 0.0134s/iter; left time: 521.1544s
	iters: 300, epoch: 21 | loss: 0.4471650
	speed: 0.0125s/iter; left time: 485.0686s
	iters: 400, epoch: 21 | loss: 0.4467715
	speed: 0.0133s/iter; left time: 511.2935s
Epoch: 21 cost time: 6.741812467575073
Epoch: 21, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3638 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4932186
	speed: 0.0152s/iter; left time: 583.4183s
	iters: 200, epoch: 22 | loss: 0.4119426
	speed: 0.0139s/iter; left time: 532.8999s
	iters: 300, epoch: 22 | loss: 0.4627079
	speed: 0.0138s/iter; left time: 526.9948s
	iters: 400, epoch: 22 | loss: 0.3874118
	speed: 0.0120s/iter; left time: 456.9917s
Epoch: 22 cost time: 6.61041522026062
Epoch: 22, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3627 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5213
Validation loss decreased (0.727230 --> 0.727085).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4183499
	speed: 0.0156s/iter; left time: 591.4873s
	iters: 200, epoch: 23 | loss: 0.4248334
	speed: 0.0133s/iter; left time: 504.2450s
	iters: 300, epoch: 23 | loss: 0.3830600
	speed: 0.0135s/iter; left time: 508.7766s
	iters: 400, epoch: 23 | loss: 0.4072612
	speed: 0.0135s/iter; left time: 507.2185s
Epoch: 23 cost time: 6.841169834136963
Epoch: 23, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3971 + XiCon Loss:2.3662 x Lambda(0.01)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4002382
	speed: 0.0158s/iter; left time: 589.0626s
	iters: 200, epoch: 24 | loss: 0.3893717
	speed: 0.0132s/iter; left time: 494.1177s
	iters: 300, epoch: 24 | loss: 0.3925457
	speed: 0.0134s/iter; left time: 498.0277s
	iters: 400, epoch: 24 | loss: 0.4839361
	speed: 0.0137s/iter; left time: 507.0738s
Epoch: 24 cost time: 6.755535840988159
Epoch: 24, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3971 + XiCon Loss:2.3640 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4614745
	speed: 0.0157s/iter; left time: 577.9082s
	iters: 200, epoch: 25 | loss: 0.3172974
	speed: 0.0130s/iter; left time: 478.5576s
	iters: 300, epoch: 25 | loss: 0.3818020
	speed: 0.0130s/iter; left time: 476.3792s
	iters: 400, epoch: 25 | loss: 0.3946857
	speed: 0.0131s/iter; left time: 481.2570s
Epoch: 25 cost time: 6.6445066928863525
Epoch: 25, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3974 + XiCon Loss:2.3615 x Lambda(0.01)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3978854
	speed: 0.0151s/iter; left time: 551.6243s
	iters: 200, epoch: 26 | loss: 0.4261998
	speed: 0.0127s/iter; left time: 459.8121s
	iters: 300, epoch: 26 | loss: 0.3882897
	speed: 0.0130s/iter; left time: 470.4027s
	iters: 400, epoch: 26 | loss: 0.4410865
	speed: 0.0127s/iter; left time: 459.1240s
Epoch: 26 cost time: 6.531064987182617
Epoch: 26, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3667 x Lambda(0.01)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3726357
	speed: 0.0152s/iter; left time: 545.8540s
	iters: 200, epoch: 27 | loss: 0.3895823
	speed: 0.0123s/iter; left time: 441.0255s
	iters: 300, epoch: 27 | loss: 0.4735512
	speed: 0.0129s/iter; left time: 462.4812s
	iters: 400, epoch: 27 | loss: 0.4704922
	speed: 0.0132s/iter; left time: 471.8848s
Epoch: 27 cost time: 6.659391164779663
Epoch: 27, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3598 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4267420
	speed: 0.0148s/iter; left time: 524.8203s
	iters: 200, epoch: 28 | loss: 0.4384671
	speed: 0.0130s/iter; left time: 458.1564s
	iters: 300, epoch: 28 | loss: 0.4050317
	speed: 0.0130s/iter; left time: 458.4339s
	iters: 400, epoch: 28 | loss: 0.3864015
	speed: 0.0121s/iter; left time: 426.4840s
Epoch: 28 cost time: 6.497276067733765
Epoch: 28, Steps: 487 Train Loss: 0.4212 (Forecasting Loss:0.3975 + XiCon Loss:2.3671 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4458021
	speed: 0.0149s/iter; left time: 521.9707s
	iters: 200, epoch: 29 | loss: 0.4135740
	speed: 0.0130s/iter; left time: 454.0175s
	iters: 300, epoch: 29 | loss: 0.4972156
	speed: 0.0133s/iter; left time: 462.6385s
	iters: 400, epoch: 29 | loss: 0.4931214
	speed: 0.0133s/iter; left time: 460.9956s
Epoch: 29 cost time: 6.593284368515015
Epoch: 29, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3973 + XiCon Loss:2.3633 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4875657
	speed: 0.0153s/iter; left time: 527.5991s
	iters: 200, epoch: 30 | loss: 0.4292994
	speed: 0.0137s/iter; left time: 471.6630s
	iters: 300, epoch: 30 | loss: 0.5060248
	speed: 0.0134s/iter; left time: 458.0074s
	iters: 400, epoch: 30 | loss: 0.4336070
	speed: 0.0130s/iter; left time: 443.9704s
Epoch: 30 cost time: 6.747996091842651
Epoch: 30, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3568 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4304315
	speed: 0.0149s/iter; left time: 507.6532s
	iters: 200, epoch: 31 | loss: 0.3246384
	speed: 0.0124s/iter; left time: 419.3476s
	iters: 300, epoch: 31 | loss: 0.3804016
	speed: 0.0131s/iter; left time: 442.9283s
	iters: 400, epoch: 31 | loss: 0.4479368
	speed: 0.0134s/iter; left time: 450.6069s
Epoch: 31 cost time: 6.606809139251709
Epoch: 31, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3972 + XiCon Loss:2.3671 x Lambda(0.01)), Vali MSE Loss: 0.7269 Test MSE Loss: 0.5213
Validation loss decreased (0.727085 --> 0.726934).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4026436
	speed: 0.0157s/iter; left time: 525.5186s
	iters: 200, epoch: 32 | loss: 0.3985268
	speed: 0.0135s/iter; left time: 451.1994s
	iters: 300, epoch: 32 | loss: 0.3377500
	speed: 0.0140s/iter; left time: 466.8967s
	iters: 400, epoch: 32 | loss: 0.3169903
	speed: 0.0140s/iter; left time: 463.8939s
Epoch: 32 cost time: 6.886814594268799
Epoch: 32, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3548 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3665696
	speed: 0.0150s/iter; left time: 495.4509s
	iters: 200, epoch: 33 | loss: 0.4479495
	speed: 0.0124s/iter; left time: 408.7896s
	iters: 300, epoch: 33 | loss: 0.4241022
	speed: 0.0135s/iter; left time: 442.1694s
	iters: 400, epoch: 33 | loss: 0.3823016
	speed: 0.0140s/iter; left time: 457.7124s
Epoch: 33 cost time: 6.772207736968994
Epoch: 33, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3619 x Lambda(0.01)), Vali MSE Loss: 0.7280 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4474412
	speed: 0.0161s/iter; left time: 522.4239s
	iters: 200, epoch: 34 | loss: 0.4937465
	speed: 0.0133s/iter; left time: 431.2733s
	iters: 300, epoch: 34 | loss: 0.3889302
	speed: 0.0129s/iter; left time: 415.6550s
	iters: 400, epoch: 34 | loss: 0.4239664
	speed: 0.0134s/iter; left time: 430.6419s
Epoch: 34 cost time: 6.687481164932251
Epoch: 34, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3647 x Lambda(0.01)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5213
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3688191
	speed: 0.0150s/iter; left time: 481.1850s
	iters: 200, epoch: 35 | loss: 0.3585834
	speed: 0.0136s/iter; left time: 433.0228s
	iters: 300, epoch: 35 | loss: 0.3575459
	speed: 0.0126s/iter; left time: 402.5350s
	iters: 400, epoch: 35 | loss: 0.3945872
	speed: 0.0124s/iter; left time: 394.6357s
Epoch: 35 cost time: 6.607716798782349
Epoch: 35, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3643 x Lambda(0.01)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5213
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4657852
	speed: 0.0152s/iter; left time: 479.2844s
	iters: 200, epoch: 36 | loss: 0.4700228
	speed: 0.0131s/iter; left time: 410.6279s
	iters: 300, epoch: 36 | loss: 0.3825923
	speed: 0.0136s/iter; left time: 425.1732s
	iters: 400, epoch: 36 | loss: 0.4703209
	speed: 0.0125s/iter; left time: 389.8330s
Epoch: 36 cost time: 6.604511022567749
Epoch: 36, Steps: 487 Train Loss: 0.4211 (Forecasting Loss:0.3974 + XiCon Loss:2.3602 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4070723
	speed: 0.0141s/iter; left time: 439.4289s
	iters: 200, epoch: 37 | loss: 0.3487801
	speed: 0.0135s/iter; left time: 417.6963s
	iters: 300, epoch: 37 | loss: 0.4142195
	speed: 0.0131s/iter; left time: 404.1568s
	iters: 400, epoch: 37 | loss: 0.4687685
	speed: 0.0123s/iter; left time: 377.3784s
Epoch: 37 cost time: 6.402745962142944
Epoch: 37, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3974 + XiCon Loss:2.3643 x Lambda(0.01)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5213
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3951430
	speed: 0.0156s/iter; left time: 475.6048s
	iters: 200, epoch: 38 | loss: 0.4224985
	speed: 0.0142s/iter; left time: 433.5425s
	iters: 300, epoch: 38 | loss: 0.4289353
	speed: 0.0135s/iter; left time: 408.8751s
	iters: 400, epoch: 38 | loss: 0.3680384
	speed: 0.0139s/iter; left time: 421.1807s
Epoch: 38 cost time: 6.978651523590088
Epoch: 38, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3974 + XiCon Loss:2.3653 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.3804111
	speed: 0.0150s/iter; left time: 450.9999s
	iters: 200, epoch: 39 | loss: 0.3872128
	speed: 0.0131s/iter; left time: 394.2427s
	iters: 300, epoch: 39 | loss: 0.4223270
	speed: 0.0136s/iter; left time: 406.7012s
	iters: 400, epoch: 39 | loss: 0.4171654
	speed: 0.0135s/iter; left time: 403.5142s
Epoch: 39 cost time: 6.658007383346558
Epoch: 39, Steps: 487 Train Loss: 0.4208 (Forecasting Loss:0.3972 + XiCon Loss:2.3584 x Lambda(0.01)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5213
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4729017
	speed: 0.0154s/iter; left time: 455.9957s
	iters: 200, epoch: 40 | loss: 0.4115182
	speed: 0.0130s/iter; left time: 383.7672s
	iters: 300, epoch: 40 | loss: 0.4312386
	speed: 0.0131s/iter; left time: 384.0087s
	iters: 400, epoch: 40 | loss: 0.3265838
	speed: 0.0129s/iter; left time: 377.8424s
Epoch: 40 cost time: 6.603821754455566
Epoch: 40, Steps: 487 Train Loss: 0.4210 (Forecasting Loss:0.3974 + XiCon Loss:2.3586 x Lambda(0.01)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4654706
	speed: 0.0152s/iter; left time: 443.1755s
	iters: 200, epoch: 41 | loss: 0.3521205
	speed: 0.0132s/iter; left time: 384.2864s
	iters: 300, epoch: 41 | loss: 0.3971577
	speed: 0.0131s/iter; left time: 379.8159s
	iters: 400, epoch: 41 | loss: 0.3950987
	speed: 0.0140s/iter; left time: 402.7835s
Epoch: 41 cost time: 6.777090072631836
Epoch: 41, Steps: 487 Train Loss: 0.4209 (Forecasting Loss:0.3973 + XiCon Loss:2.3599 x Lambda(0.01)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5213
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5306589603424072, mae:0.5120019316673279, mape:3.6033365726470947, mspe:1211.4842529296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.1912
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1060132
	speed: 0.0142s/iter; left time: 692.2365s
	iters: 200, epoch: 1 | loss: 0.8669320
	speed: 0.0112s/iter; left time: 543.0733s
	iters: 300, epoch: 1 | loss: 0.7710097
	speed: 0.0114s/iter; left time: 552.5976s
	iters: 400, epoch: 1 | loss: 0.8340319
	speed: 0.0119s/iter; left time: 576.2257s
Epoch: 1 cost time: 5.902790784835815
Epoch: 1, Steps: 487 Train Loss: 0.8243 (Forecasting Loss:0.8010 + XiCon Loss:2.3311 x Lambda(0.01)), Vali MSE Loss: 1.0984 Test MSE Loss: 0.6609
Validation loss decreased (inf --> 1.098369).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5742442
	speed: 0.0136s/iter; left time: 654.0168s
	iters: 200, epoch: 2 | loss: 0.4361661
	speed: 0.0113s/iter; left time: 540.2602s
	iters: 300, epoch: 2 | loss: 0.4284923
	speed: 0.0108s/iter; left time: 519.8597s
	iters: 400, epoch: 2 | loss: 0.3912876
	speed: 0.0109s/iter; left time: 521.2432s
Epoch: 2 cost time: 5.672391891479492
Epoch: 2, Steps: 487 Train Loss: 0.4586 (Forecasting Loss:0.4353 + XiCon Loss:2.3280 x Lambda(0.01)), Vali MSE Loss: 0.7548 Test MSE Loss: 0.5191
Validation loss decreased (1.098369 --> 0.754804).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4367277
	speed: 0.0133s/iter; left time: 633.3573s
	iters: 200, epoch: 3 | loss: 0.4477004
	speed: 0.0111s/iter; left time: 527.0928s
	iters: 300, epoch: 3 | loss: 0.4274355
	speed: 0.0117s/iter; left time: 554.0012s
	iters: 400, epoch: 3 | loss: 0.4625295
	speed: 0.0114s/iter; left time: 539.9835s
Epoch: 3 cost time: 5.772783041000366
Epoch: 3, Steps: 487 Train Loss: 0.4256 (Forecasting Loss:0.4023 + XiCon Loss:2.3278 x Lambda(0.01)), Vali MSE Loss: 0.7487 Test MSE Loss: 0.5120
Validation loss decreased (0.754804 --> 0.748651).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4125864
	speed: 0.0138s/iter; left time: 650.8128s
	iters: 200, epoch: 4 | loss: 0.4246798
	speed: 0.0113s/iter; left time: 533.3823s
	iters: 300, epoch: 4 | loss: 0.4957048
	speed: 0.0117s/iter; left time: 550.5126s
	iters: 400, epoch: 4 | loss: 0.3602485
	speed: 0.0110s/iter; left time: 517.1776s
Epoch: 4 cost time: 5.80888819694519
Epoch: 4, Steps: 487 Train Loss: 0.4206 (Forecasting Loss:0.3973 + XiCon Loss:2.3294 x Lambda(0.01)), Vali MSE Loss: 0.7408 Test MSE Loss: 0.5092
Validation loss decreased (0.748651 --> 0.740819).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3973991
	speed: 0.0137s/iter; left time: 638.6609s
	iters: 200, epoch: 5 | loss: 0.4485470
	speed: 0.0111s/iter; left time: 516.9541s
	iters: 300, epoch: 5 | loss: 0.4413711
	speed: 0.0110s/iter; left time: 510.4180s
	iters: 400, epoch: 5 | loss: 0.4271061
	speed: 0.0107s/iter; left time: 497.6270s
Epoch: 5 cost time: 5.63177752494812
Epoch: 5, Steps: 487 Train Loss: 0.4184 (Forecasting Loss:0.3951 + XiCon Loss:2.3300 x Lambda(0.01)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5092
Validation loss decreased (0.740819 --> 0.738963).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4327949
	speed: 0.0134s/iter; left time: 620.2522s
	iters: 200, epoch: 6 | loss: 0.3831069
	speed: 0.0115s/iter; left time: 528.2444s
	iters: 300, epoch: 6 | loss: 0.4826868
	speed: 0.0114s/iter; left time: 523.6230s
	iters: 400, epoch: 6 | loss: 0.5277733
	speed: 0.0114s/iter; left time: 521.3483s
Epoch: 6 cost time: 5.783783435821533
Epoch: 6, Steps: 487 Train Loss: 0.4174 (Forecasting Loss:0.3941 + XiCon Loss:2.3291 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5086
Validation loss decreased (0.738963 --> 0.737595).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4041178
	speed: 0.0143s/iter; left time: 651.8396s
	iters: 200, epoch: 7 | loss: 0.3779329
	speed: 0.0122s/iter; left time: 556.3785s
	iters: 300, epoch: 7 | loss: 0.4018984
	speed: 0.0106s/iter; left time: 481.3966s
	iters: 400, epoch: 7 | loss: 0.4078134
	speed: 0.0118s/iter; left time: 536.0572s
Epoch: 7 cost time: 5.854257345199585
Epoch: 7, Steps: 487 Train Loss: 0.4168 (Forecasting Loss:0.3936 + XiCon Loss:2.3237 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5082
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4489879
	speed: 0.0140s/iter; left time: 633.6429s
	iters: 200, epoch: 8 | loss: 0.4777519
	speed: 0.0121s/iter; left time: 547.1218s
	iters: 300, epoch: 8 | loss: 0.4064175
	speed: 0.0115s/iter; left time: 516.5585s
	iters: 400, epoch: 8 | loss: 0.3696482
	speed: 0.0107s/iter; left time: 480.8227s
Epoch: 8 cost time: 5.7817323207855225
Epoch: 8, Steps: 487 Train Loss: 0.4165 (Forecasting Loss:0.3932 + XiCon Loss:2.3234 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
Validation loss decreased (0.737595 --> 0.737130).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4071641
	speed: 0.0144s/iter; left time: 644.6659s
	iters: 200, epoch: 9 | loss: 0.4042461
	speed: 0.0119s/iter; left time: 530.2899s
	iters: 300, epoch: 9 | loss: 0.4449849
	speed: 0.0122s/iter; left time: 543.4398s
	iters: 400, epoch: 9 | loss: 0.4495877
	speed: 0.0107s/iter; left time: 473.3284s
Epoch: 9 cost time: 5.9253833293914795
Epoch: 9, Steps: 487 Train Loss: 0.4166 (Forecasting Loss:0.3933 + XiCon Loss:2.3277 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5080
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4327106
	speed: 0.0135s/iter; left time: 597.1195s
	iters: 200, epoch: 10 | loss: 0.4192417
	speed: 0.0110s/iter; left time: 486.6945s
	iters: 300, epoch: 10 | loss: 0.4948769
	speed: 0.0121s/iter; left time: 532.0174s
	iters: 400, epoch: 10 | loss: 0.4441645
	speed: 0.0111s/iter; left time: 487.4044s
Epoch: 10 cost time: 5.738032102584839
Epoch: 10, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3239 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4059580
	speed: 0.0139s/iter; left time: 609.6810s
	iters: 200, epoch: 11 | loss: 0.3551318
	speed: 0.0111s/iter; left time: 483.5111s
	iters: 300, epoch: 11 | loss: 0.3790231
	speed: 0.0108s/iter; left time: 471.6027s
	iters: 400, epoch: 11 | loss: 0.3613155
	speed: 0.0111s/iter; left time: 481.3907s
Epoch: 11 cost time: 5.692229747772217
Epoch: 11, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3254 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
Validation loss decreased (0.737130 --> 0.736968).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.5070375
	speed: 0.0133s/iter; left time: 573.0284s
	iters: 200, epoch: 12 | loss: 0.4192053
	speed: 0.0119s/iter; left time: 515.0274s
	iters: 300, epoch: 12 | loss: 0.4853815
	speed: 0.0116s/iter; left time: 498.8905s
	iters: 400, epoch: 12 | loss: 0.3758375
	speed: 0.0114s/iter; left time: 489.7497s
Epoch: 12 cost time: 5.8558738231658936
Epoch: 12, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3931 + XiCon Loss:2.3295 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4488644
	speed: 0.0134s/iter; left time: 573.7619s
	iters: 200, epoch: 13 | loss: 0.4147141
	speed: 0.0119s/iter; left time: 506.5506s
	iters: 300, epoch: 13 | loss: 0.3450855
	speed: 0.0113s/iter; left time: 481.7732s
	iters: 400, epoch: 13 | loss: 0.4161097
	speed: 0.0110s/iter; left time: 468.8525s
Epoch: 13 cost time: 5.77048397064209
Epoch: 13, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3243 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3830892
	speed: 0.0141s/iter; left time: 597.3401s
	iters: 200, epoch: 14 | loss: 0.3385727
	speed: 0.0110s/iter; left time: 463.7496s
	iters: 300, epoch: 14 | loss: 0.3565092
	speed: 0.0109s/iter; left time: 457.5239s
	iters: 400, epoch: 14 | loss: 0.4118548
	speed: 0.0111s/iter; left time: 467.7955s
Epoch: 14 cost time: 5.740551233291626
Epoch: 14, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3928 + XiCon Loss:2.3247 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4381776
	speed: 0.0139s/iter; left time: 582.7376s
	iters: 200, epoch: 15 | loss: 0.4127531
	speed: 0.0112s/iter; left time: 467.7467s
	iters: 300, epoch: 15 | loss: 0.5412504
	speed: 0.0119s/iter; left time: 493.6746s
	iters: 400, epoch: 15 | loss: 0.3618582
	speed: 0.0108s/iter; left time: 447.0702s
Epoch: 15 cost time: 5.758437633514404
Epoch: 15, Steps: 487 Train Loss: 0.4166 (Forecasting Loss:0.3934 + XiCon Loss:2.3226 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736968 --> 0.736917).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3736325
	speed: 0.0140s/iter; left time: 578.1229s
	iters: 200, epoch: 16 | loss: 0.3565768
	speed: 0.0108s/iter; left time: 442.9568s
	iters: 300, epoch: 16 | loss: 0.4056551
	speed: 0.0120s/iter; left time: 492.7468s
	iters: 400, epoch: 16 | loss: 0.3959847
	speed: 0.0120s/iter; left time: 491.2197s
Epoch: 16 cost time: 5.841453552246094
Epoch: 16, Steps: 487 Train Loss: 0.4160 (Forecasting Loss:0.3928 + XiCon Loss:2.3214 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.4004855
	speed: 0.0140s/iter; left time: 570.9816s
	iters: 200, epoch: 17 | loss: 0.3978169
	speed: 0.0117s/iter; left time: 476.8398s
	iters: 300, epoch: 17 | loss: 0.4225147
	speed: 0.0112s/iter; left time: 455.0729s
	iters: 400, epoch: 17 | loss: 0.4263374
	speed: 0.0113s/iter; left time: 457.0290s
Epoch: 17 cost time: 5.800151586532593
Epoch: 17, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3318 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5037597
	speed: 0.0140s/iter; left time: 565.8259s
	iters: 200, epoch: 18 | loss: 0.4352167
	speed: 0.0110s/iter; left time: 440.4406s
	iters: 300, epoch: 18 | loss: 0.3736153
	speed: 0.0117s/iter; left time: 467.5468s
	iters: 400, epoch: 18 | loss: 0.3491418
	speed: 0.0113s/iter; left time: 451.7133s
Epoch: 18 cost time: 5.79598331451416
Epoch: 18, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3267 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4370498
	speed: 0.0133s/iter; left time: 529.0689s
	iters: 200, epoch: 19 | loss: 0.4169693
	speed: 0.0111s/iter; left time: 441.0718s
	iters: 300, epoch: 19 | loss: 0.3248626
	speed: 0.0114s/iter; left time: 452.4443s
	iters: 400, epoch: 19 | loss: 0.4647202
	speed: 0.0111s/iter; left time: 437.1227s
Epoch: 19 cost time: 5.6757285594940186
Epoch: 19, Steps: 487 Train Loss: 0.4164 (Forecasting Loss:0.3931 + XiCon Loss:2.3279 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4326330
	speed: 0.0137s/iter; left time: 540.9866s
	iters: 200, epoch: 20 | loss: 0.3867823
	speed: 0.0111s/iter; left time: 436.6517s
	iters: 300, epoch: 20 | loss: 0.3757569
	speed: 0.0111s/iter; left time: 435.9004s
	iters: 400, epoch: 20 | loss: 0.3531856
	speed: 0.0109s/iter; left time: 423.9578s
Epoch: 20 cost time: 5.661755084991455
Epoch: 20, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3931 + XiCon Loss:2.3271 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
Validation loss decreased (0.736917 --> 0.736916).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4369780
	speed: 0.0141s/iter; left time: 549.4198s
	iters: 200, epoch: 21 | loss: 0.4283172
	speed: 0.0113s/iter; left time: 439.6470s
	iters: 300, epoch: 21 | loss: 0.3498747
	speed: 0.0114s/iter; left time: 441.0946s
	iters: 400, epoch: 21 | loss: 0.3760980
	speed: 0.0117s/iter; left time: 452.9577s
Epoch: 21 cost time: 5.897444009780884
Epoch: 21, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3313 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4198832
	speed: 0.0142s/iter; left time: 543.2578s
	iters: 200, epoch: 22 | loss: 0.4321311
	speed: 0.0114s/iter; left time: 434.9829s
	iters: 300, epoch: 22 | loss: 0.4438220
	speed: 0.0112s/iter; left time: 426.9017s
	iters: 400, epoch: 22 | loss: 0.3917690
	speed: 0.0110s/iter; left time: 420.2246s
Epoch: 22 cost time: 5.815103769302368
Epoch: 22, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3293 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3598644
	speed: 0.0140s/iter; left time: 530.8831s
	iters: 200, epoch: 23 | loss: 0.3850863
	speed: 0.0112s/iter; left time: 424.4546s
	iters: 300, epoch: 23 | loss: 0.4731635
	speed: 0.0116s/iter; left time: 438.0084s
	iters: 400, epoch: 23 | loss: 0.4262638
	speed: 0.0115s/iter; left time: 431.5260s
Epoch: 23 cost time: 5.853744268417358
Epoch: 23, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3279 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4357136
	speed: 0.0136s/iter; left time: 507.7718s
	iters: 200, epoch: 24 | loss: 0.4644869
	speed: 0.0116s/iter; left time: 430.8699s
	iters: 300, epoch: 24 | loss: 0.3413461
	speed: 0.0115s/iter; left time: 427.7954s
	iters: 400, epoch: 24 | loss: 0.4482648
	speed: 0.0114s/iter; left time: 424.4162s
Epoch: 24 cost time: 5.835538625717163
Epoch: 24, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3930 + XiCon Loss:2.3227 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4028521
	speed: 0.0139s/iter; left time: 513.2682s
	iters: 200, epoch: 25 | loss: 0.3622357
	speed: 0.0110s/iter; left time: 403.5689s
	iters: 300, epoch: 25 | loss: 0.4112235
	speed: 0.0111s/iter; left time: 407.7272s
	iters: 400, epoch: 25 | loss: 0.4439237
	speed: 0.0112s/iter; left time: 411.8543s
Epoch: 25 cost time: 5.6983842849731445
Epoch: 25, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3289 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5079
Validation loss decreased (0.736916 --> 0.736575).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4140726
	speed: 0.0140s/iter; left time: 508.2515s
	iters: 200, epoch: 26 | loss: 0.3685927
	speed: 0.0114s/iter; left time: 412.9682s
	iters: 300, epoch: 26 | loss: 0.4436952
	speed: 0.0111s/iter; left time: 402.1421s
	iters: 400, epoch: 26 | loss: 0.4684407
	speed: 0.0114s/iter; left time: 412.4869s
Epoch: 26 cost time: 5.774718999862671
Epoch: 26, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3928 + XiCon Loss:2.3243 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4145695
	speed: 0.0138s/iter; left time: 497.6634s
	iters: 200, epoch: 27 | loss: 0.4570261
	speed: 0.0110s/iter; left time: 392.7690s
	iters: 300, epoch: 27 | loss: 0.3651927
	speed: 0.0104s/iter; left time: 371.4476s
	iters: 400, epoch: 27 | loss: 0.4174548
	speed: 0.0112s/iter; left time: 398.4431s
Epoch: 27 cost time: 5.671618461608887
Epoch: 27, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3291 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3889377
	speed: 0.0132s/iter; left time: 467.0660s
	iters: 200, epoch: 28 | loss: 0.3839303
	speed: 0.0114s/iter; left time: 403.0069s
	iters: 300, epoch: 28 | loss: 0.3755966
	speed: 0.0115s/iter; left time: 405.3233s
	iters: 400, epoch: 28 | loss: 0.4400105
	speed: 0.0109s/iter; left time: 382.4950s
Epoch: 28 cost time: 5.700903415679932
Epoch: 28, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3931 + XiCon Loss:2.3256 x Lambda(0.01)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5079
Validation loss decreased (0.736575 --> 0.736473).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4712875
	speed: 0.0134s/iter; left time: 469.8456s
	iters: 200, epoch: 29 | loss: 0.4237719
	speed: 0.0111s/iter; left time: 387.2281s
	iters: 300, epoch: 29 | loss: 0.3808109
	speed: 0.0114s/iter; left time: 397.6808s
	iters: 400, epoch: 29 | loss: 0.4168679
	speed: 0.0103s/iter; left time: 358.4555s
Epoch: 29 cost time: 5.574802398681641
Epoch: 29, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3250 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4735357
	speed: 0.0137s/iter; left time: 471.9479s
	iters: 200, epoch: 30 | loss: 0.4496097
	speed: 0.0114s/iter; left time: 391.0712s
	iters: 300, epoch: 30 | loss: 0.4056693
	speed: 0.0115s/iter; left time: 395.1591s
	iters: 400, epoch: 30 | loss: 0.3815089
	speed: 0.0109s/iter; left time: 371.5900s
Epoch: 30 cost time: 5.752729654312134
Epoch: 30, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3301 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5079
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3715501
	speed: 0.0146s/iter; left time: 495.7189s
	iters: 200, epoch: 31 | loss: 0.3276007
	speed: 0.0114s/iter; left time: 387.1493s
	iters: 300, epoch: 31 | loss: 0.4532163
	speed: 0.0108s/iter; left time: 364.9578s
	iters: 400, epoch: 31 | loss: 0.4080988
	speed: 0.0115s/iter; left time: 386.4258s
Epoch: 31 cost time: 5.8330464363098145
Epoch: 31, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3256 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5079
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4639892
	speed: 0.0136s/iter; left time: 454.3618s
	iters: 200, epoch: 32 | loss: 0.4837766
	speed: 0.0108s/iter; left time: 361.8621s
	iters: 300, epoch: 32 | loss: 0.3994094
	speed: 0.0108s/iter; left time: 360.8606s
	iters: 400, epoch: 32 | loss: 0.4247869
	speed: 0.0112s/iter; left time: 370.3004s
Epoch: 32 cost time: 5.610255002975464
Epoch: 32, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3269 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4456143
	speed: 0.0141s/iter; left time: 466.2218s
	iters: 200, epoch: 33 | loss: 0.4398371
	speed: 0.0104s/iter; left time: 340.7670s
	iters: 300, epoch: 33 | loss: 0.3755694
	speed: 0.0105s/iter; left time: 344.2431s
	iters: 400, epoch: 33 | loss: 0.3640615
	speed: 0.0115s/iter; left time: 377.0508s
Epoch: 33 cost time: 5.683791160583496
Epoch: 33, Steps: 487 Train Loss: 0.4161 (Forecasting Loss:0.3929 + XiCon Loss:2.3233 x Lambda(0.01)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5079
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3756107
	speed: 0.0135s/iter; left time: 440.7457s
	iters: 200, epoch: 34 | loss: 0.4230639
	speed: 0.0112s/iter; left time: 364.2078s
	iters: 300, epoch: 34 | loss: 0.3315884
	speed: 0.0117s/iter; left time: 376.9012s
	iters: 400, epoch: 34 | loss: 0.3648979
	speed: 0.0114s/iter; left time: 366.0658s
Epoch: 34 cost time: 5.755537271499634
Epoch: 34, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3257 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5079
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.4078486
	speed: 0.0133s/iter; left time: 425.8000s
	iters: 200, epoch: 35 | loss: 0.4408978
	speed: 0.0111s/iter; left time: 354.9071s
	iters: 300, epoch: 35 | loss: 0.3652945
	speed: 0.0110s/iter; left time: 351.7472s
	iters: 400, epoch: 35 | loss: 0.3573743
	speed: 0.0112s/iter; left time: 356.0241s
Epoch: 35 cost time: 5.665665864944458
Epoch: 35, Steps: 487 Train Loss: 0.4165 (Forecasting Loss:0.3932 + XiCon Loss:2.3246 x Lambda(0.01)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5079
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.3886611
	speed: 0.0128s/iter; left time: 404.2577s
	iters: 200, epoch: 36 | loss: 0.5043389
	speed: 0.0109s/iter; left time: 343.1783s
	iters: 300, epoch: 36 | loss: 0.3743611
	speed: 0.0115s/iter; left time: 360.4096s
	iters: 400, epoch: 36 | loss: 0.4665785
	speed: 0.0117s/iter; left time: 365.6212s
Epoch: 36 cost time: 5.745579481124878
Epoch: 36, Steps: 487 Train Loss: 0.4160 (Forecasting Loss:0.3928 + XiCon Loss:2.3260 x Lambda(0.01)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5079
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3912764
	speed: 0.0133s/iter; left time: 413.4755s
	iters: 200, epoch: 37 | loss: 0.4256127
	speed: 0.0124s/iter; left time: 385.4177s
	iters: 300, epoch: 37 | loss: 0.4681847
	speed: 0.0118s/iter; left time: 363.2612s
	iters: 400, epoch: 37 | loss: 0.4116892
	speed: 0.0117s/iter; left time: 359.0909s
Epoch: 37 cost time: 5.93790602684021
Epoch: 37, Steps: 487 Train Loss: 0.4163 (Forecasting Loss:0.3930 + XiCon Loss:2.3232 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5079
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3626046
	speed: 0.0145s/iter; left time: 443.7722s
	iters: 200, epoch: 38 | loss: 0.3559948
	speed: 0.0116s/iter; left time: 354.3912s
	iters: 300, epoch: 38 | loss: 0.4395973
	speed: 0.0119s/iter; left time: 360.8165s
	iters: 400, epoch: 38 | loss: 0.4455038
	speed: 0.0122s/iter; left time: 368.5273s
Epoch: 38 cost time: 6.101335287094116
Epoch: 38, Steps: 487 Train Loss: 0.4162 (Forecasting Loss:0.3929 + XiCon Loss:2.3316 x Lambda(0.01)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5079
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5129398107528687, mae:0.5028854608535767, mape:3.5703186988830566, mspe:1174.8505859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.1607
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8729548
	speed: 0.0141s/iter; left time: 687.2294s
	iters: 200, epoch: 1 | loss: 0.8390348
	speed: 0.0111s/iter; left time: 536.4801s
	iters: 300, epoch: 1 | loss: 0.7401975
	speed: 0.0110s/iter; left time: 532.9942s
	iters: 400, epoch: 1 | loss: 0.6609592
	speed: 0.0119s/iter; left time: 575.3254s
Epoch: 1 cost time: 5.872440814971924
Epoch: 1, Steps: 487 Train Loss: 0.7765 (Forecasting Loss:0.7529 + XiCon Loss:2.3675 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005157).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5211108
	speed: 0.0141s/iter; left time: 677.9878s
	iters: 200, epoch: 2 | loss: 0.4331432
	speed: 0.0112s/iter; left time: 539.9360s
	iters: 300, epoch: 2 | loss: 0.5751383
	speed: 0.0109s/iter; left time: 523.5859s
	iters: 400, epoch: 2 | loss: 0.4201533
	speed: 0.0109s/iter; left time: 522.8751s
Epoch: 2 cost time: 5.7018232345581055
Epoch: 2, Steps: 487 Train Loss: 0.4598 (Forecasting Loss:0.4361 + XiCon Loss:2.3619 x Lambda(0.01)), Vali MSE Loss: 0.7607 Test MSE Loss: 0.5392
Validation loss decreased (1.005157 --> 0.760653).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4761798
	speed: 0.0149s/iter; left time: 707.4854s
	iters: 200, epoch: 3 | loss: 0.4034790
	speed: 0.0107s/iter; left time: 510.5679s
	iters: 300, epoch: 3 | loss: 0.5033187
	speed: 0.0109s/iter; left time: 518.4615s
	iters: 400, epoch: 3 | loss: 0.3787108
	speed: 0.0113s/iter; left time: 533.0014s
Epoch: 3 cost time: 5.841129541397095
Epoch: 3, Steps: 487 Train Loss: 0.4297 (Forecasting Loss:0.4061 + XiCon Loss:2.3582 x Lambda(0.01)), Vali MSE Loss: 0.7459 Test MSE Loss: 0.5193
Validation loss decreased (0.760653 --> 0.745917).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5084108
	speed: 0.0136s/iter; left time: 642.0676s
	iters: 200, epoch: 4 | loss: 0.4225939
	speed: 0.0107s/iter; left time: 501.0181s
	iters: 300, epoch: 4 | loss: 0.4145516
	speed: 0.0107s/iter; left time: 503.0327s
	iters: 400, epoch: 4 | loss: 0.3146572
	speed: 0.0108s/iter; left time: 507.8905s
Epoch: 4 cost time: 5.550323724746704
Epoch: 4, Steps: 487 Train Loss: 0.4238 (Forecasting Loss:0.4003 + XiCon Loss:2.3522 x Lambda(0.01)), Vali MSE Loss: 0.7463 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3826789
	speed: 0.0142s/iter; left time: 662.2828s
	iters: 200, epoch: 5 | loss: 0.4832881
	speed: 0.0110s/iter; left time: 512.6661s
	iters: 300, epoch: 5 | loss: 0.4041049
	speed: 0.0111s/iter; left time: 517.8165s
	iters: 400, epoch: 5 | loss: 0.4687308
	speed: 0.0105s/iter; left time: 484.4387s
Epoch: 5 cost time: 5.654315948486328
Epoch: 5, Steps: 487 Train Loss: 0.4217 (Forecasting Loss:0.3982 + XiCon Loss:2.3538 x Lambda(0.01)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5126
Validation loss decreased (0.745917 --> 0.739131).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4680839
	speed: 0.0129s/iter; left time: 594.7728s
	iters: 200, epoch: 6 | loss: 0.4443297
	speed: 0.0113s/iter; left time: 522.3941s
	iters: 300, epoch: 6 | loss: 0.5920359
	speed: 0.0106s/iter; left time: 486.0402s
	iters: 400, epoch: 6 | loss: 0.4872159
	speed: 0.0109s/iter; left time: 500.0455s
Epoch: 6 cost time: 5.554555892944336
Epoch: 6, Steps: 487 Train Loss: 0.4205 (Forecasting Loss:0.3969 + XiCon Loss:2.3580 x Lambda(0.01)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5117
Validation loss decreased (0.739131 --> 0.738566).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3493409
	speed: 0.0146s/iter; left time: 668.5255s
	iters: 200, epoch: 7 | loss: 0.3819338
	speed: 0.0118s/iter; left time: 538.0922s
	iters: 300, epoch: 7 | loss: 0.3412213
	speed: 0.0115s/iter; left time: 520.8846s
	iters: 400, epoch: 7 | loss: 0.3740446
	speed: 0.0110s/iter; left time: 497.9307s
Epoch: 7 cost time: 5.879902601242065
Epoch: 7, Steps: 487 Train Loss: 0.4200 (Forecasting Loss:0.3965 + XiCon Loss:2.3515 x Lambda(0.01)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5126
Validation loss decreased (0.738566 --> 0.738326).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3768268
	speed: 0.0146s/iter; left time: 657.9570s
	iters: 200, epoch: 8 | loss: 0.4084696
	speed: 0.0115s/iter; left time: 520.7186s
	iters: 300, epoch: 8 | loss: 0.5692955
	speed: 0.0119s/iter; left time: 535.3234s
	iters: 400, epoch: 8 | loss: 0.4509864
	speed: 0.0111s/iter; left time: 498.0018s
Epoch: 8 cost time: 5.953634023666382
Epoch: 8, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3961 + XiCon Loss:2.3533 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5118
Validation loss decreased (0.738326 --> 0.737789).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3792123
	speed: 0.0151s/iter; left time: 673.7740s
	iters: 200, epoch: 9 | loss: 0.5069141
	speed: 0.0110s/iter; left time: 489.6129s
	iters: 300, epoch: 9 | loss: 0.4923439
	speed: 0.0111s/iter; left time: 494.1571s
	iters: 400, epoch: 9 | loss: 0.4276694
	speed: 0.0118s/iter; left time: 522.0048s
Epoch: 9 cost time: 5.817730903625488
Epoch: 9, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3960 + XiCon Loss:2.3546 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5119
Validation loss decreased (0.737789 --> 0.737714).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3863621
	speed: 0.0143s/iter; left time: 631.6935s
	iters: 200, epoch: 10 | loss: 0.4826244
	speed: 0.0113s/iter; left time: 498.9314s
	iters: 300, epoch: 10 | loss: 0.4024735
	speed: 0.0108s/iter; left time: 475.1135s
	iters: 400, epoch: 10 | loss: 0.4305134
	speed: 0.0109s/iter; left time: 478.6482s
Epoch: 10 cost time: 5.7086920738220215
Epoch: 10, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3576 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
Validation loss decreased (0.737714 --> 0.737677).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3998168
	speed: 0.0144s/iter; left time: 628.8488s
	iters: 200, epoch: 11 | loss: 0.4287753
	speed: 0.0122s/iter; left time: 532.3274s
	iters: 300, epoch: 11 | loss: 0.3610905
	speed: 0.0108s/iter; left time: 471.6570s
	iters: 400, epoch: 11 | loss: 0.4199085
	speed: 0.0110s/iter; left time: 475.9978s
Epoch: 11 cost time: 5.7894697189331055
Epoch: 11, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3958 + XiCon Loss:2.3534 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4607976
	speed: 0.0141s/iter; left time: 609.1047s
	iters: 200, epoch: 12 | loss: 0.2927223
	speed: 0.0112s/iter; left time: 483.2915s
	iters: 300, epoch: 12 | loss: 0.4250439
	speed: 0.0111s/iter; left time: 477.7440s
	iters: 400, epoch: 12 | loss: 0.4573359
	speed: 0.0109s/iter; left time: 468.1519s
Epoch: 12 cost time: 5.7408835887908936
Epoch: 12, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3491 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
Validation loss decreased (0.737677 --> 0.737358).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3931113
	speed: 0.0133s/iter; left time: 568.6630s
	iters: 200, epoch: 13 | loss: 0.3434924
	speed: 0.0111s/iter; left time: 471.6574s
	iters: 300, epoch: 13 | loss: 0.4110192
	speed: 0.0105s/iter; left time: 445.9367s
	iters: 400, epoch: 13 | loss: 0.4044402
	speed: 0.0111s/iter; left time: 470.0962s
Epoch: 13 cost time: 5.57465934753418
Epoch: 13, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3559 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3745983
	speed: 0.0137s/iter; left time: 579.9736s
	iters: 200, epoch: 14 | loss: 0.3662853
	speed: 0.0120s/iter; left time: 507.0191s
	iters: 300, epoch: 14 | loss: 0.4026074
	speed: 0.0112s/iter; left time: 472.5841s
	iters: 400, epoch: 14 | loss: 0.3867510
	speed: 0.0111s/iter; left time: 464.9770s
Epoch: 14 cost time: 5.831002950668335
Epoch: 14, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3956 + XiCon Loss:2.3563 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4152507
	speed: 0.0141s/iter; left time: 589.8976s
	iters: 200, epoch: 15 | loss: 0.3990974
	speed: 0.0108s/iter; left time: 449.0252s
	iters: 300, epoch: 15 | loss: 0.4177299
	speed: 0.0110s/iter; left time: 459.3803s
	iters: 400, epoch: 15 | loss: 0.4638297
	speed: 0.0110s/iter; left time: 456.1973s
Epoch: 15 cost time: 5.67789101600647
Epoch: 15, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3959 + XiCon Loss:2.3576 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4457465
	speed: 0.0139s/iter; left time: 575.9848s
	iters: 200, epoch: 16 | loss: 0.3899545
	speed: 0.0105s/iter; left time: 433.5280s
	iters: 300, epoch: 16 | loss: 0.4874234
	speed: 0.0103s/iter; left time: 423.4192s
	iters: 400, epoch: 16 | loss: 0.4268875
	speed: 0.0115s/iter; left time: 472.7978s
Epoch: 16 cost time: 5.635862350463867
Epoch: 16, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3960 + XiCon Loss:2.3507 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3337831
	speed: 0.0137s/iter; left time: 560.7424s
	iters: 200, epoch: 17 | loss: 0.4018276
	speed: 0.0101s/iter; left time: 411.4260s
	iters: 300, epoch: 17 | loss: 0.3677469
	speed: 0.0110s/iter; left time: 446.9916s
	iters: 400, epoch: 17 | loss: 0.3411303
	speed: 0.0113s/iter; left time: 459.7436s
Epoch: 17 cost time: 5.606360673904419
Epoch: 17, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3958 + XiCon Loss:2.3520 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4282262
	speed: 0.0140s/iter; left time: 565.0986s
	iters: 200, epoch: 18 | loss: 0.4127763
	speed: 0.0123s/iter; left time: 494.4524s
	iters: 300, epoch: 18 | loss: 0.4322662
	speed: 0.0110s/iter; left time: 441.2852s
	iters: 400, epoch: 18 | loss: 0.3430397
	speed: 0.0114s/iter; left time: 455.9024s
Epoch: 18 cost time: 5.866888046264648
Epoch: 18, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3532 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4434672
	speed: 0.0142s/iter; left time: 563.8673s
	iters: 200, epoch: 19 | loss: 0.4661807
	speed: 0.0114s/iter; left time: 452.9822s
	iters: 300, epoch: 19 | loss: 0.3529134
	speed: 0.0110s/iter; left time: 437.8830s
	iters: 400, epoch: 19 | loss: 0.4953601
	speed: 0.0116s/iter; left time: 459.3252s
Epoch: 19 cost time: 5.864295959472656
Epoch: 19, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3957 + XiCon Loss:2.3525 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4129617
	speed: 0.0147s/iter; left time: 576.6201s
	iters: 200, epoch: 20 | loss: 0.3555358
	speed: 0.0116s/iter; left time: 456.8857s
	iters: 300, epoch: 20 | loss: 0.5536580
	speed: 0.0109s/iter; left time: 425.6490s
	iters: 400, epoch: 20 | loss: 0.4371893
	speed: 0.0107s/iter; left time: 417.9008s
Epoch: 20 cost time: 5.7379326820373535
Epoch: 20, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3957 + XiCon Loss:2.3548 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
Validation loss decreased (0.737358 --> 0.737053).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4402498
	speed: 0.0136s/iter; left time: 527.9286s
	iters: 200, epoch: 21 | loss: 0.3637971
	speed: 0.0126s/iter; left time: 487.7369s
	iters: 300, epoch: 21 | loss: 0.3619860
	speed: 0.0117s/iter; left time: 454.2470s
	iters: 400, epoch: 21 | loss: 0.4128851
	speed: 0.0108s/iter; left time: 415.7955s
Epoch: 21 cost time: 5.84297776222229
Epoch: 21, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3957 + XiCon Loss:2.3536 x Lambda(0.01)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4230307
	speed: 0.0141s/iter; left time: 539.1652s
	iters: 200, epoch: 22 | loss: 0.3969157
	speed: 0.0114s/iter; left time: 437.5689s
	iters: 300, epoch: 22 | loss: 0.4031779
	speed: 0.0120s/iter; left time: 456.4233s
	iters: 400, epoch: 22 | loss: 0.4190783
	speed: 0.0119s/iter; left time: 453.4149s
Epoch: 22 cost time: 6.009221315383911
Epoch: 22, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3518 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4274113
	speed: 0.0145s/iter; left time: 551.0652s
	iters: 200, epoch: 23 | loss: 0.4766856
	speed: 0.0110s/iter; left time: 415.4243s
	iters: 300, epoch: 23 | loss: 0.4466885
	speed: 0.0120s/iter; left time: 450.4138s
	iters: 400, epoch: 23 | loss: 0.4479710
	speed: 0.0112s/iter; left time: 419.6722s
Epoch: 23 cost time: 5.922067403793335
Epoch: 23, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3524 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4611160
	speed: 0.0150s/iter; left time: 560.9396s
	iters: 200, epoch: 24 | loss: 0.4463621
	speed: 0.0115s/iter; left time: 428.0898s
	iters: 300, epoch: 24 | loss: 0.4254788
	speed: 0.0117s/iter; left time: 435.7344s
	iters: 400, epoch: 24 | loss: 0.3819898
	speed: 0.0109s/iter; left time: 402.7539s
Epoch: 24 cost time: 5.820604562759399
Epoch: 24, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3960 + XiCon Loss:2.3510 x Lambda(0.01)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5117
Validation loss decreased (0.737053 --> 0.736935).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4509903
	speed: 0.0145s/iter; left time: 536.0942s
	iters: 200, epoch: 25 | loss: 0.4450625
	speed: 0.0107s/iter; left time: 393.9312s
	iters: 300, epoch: 25 | loss: 0.4238358
	speed: 0.0109s/iter; left time: 398.5357s
	iters: 400, epoch: 25 | loss: 0.4772527
	speed: 0.0109s/iter; left time: 398.5731s
Epoch: 25 cost time: 5.693691253662109
Epoch: 25, Steps: 487 Train Loss: 0.4196 (Forecasting Loss:0.3960 + XiCon Loss:2.3563 x Lambda(0.01)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4959490
	speed: 0.0139s/iter; left time: 504.7266s
	iters: 200, epoch: 26 | loss: 0.4392918
	speed: 0.0107s/iter; left time: 389.7737s
	iters: 300, epoch: 26 | loss: 0.3647680
	speed: 0.0105s/iter; left time: 379.7303s
	iters: 400, epoch: 26 | loss: 0.3975900
	speed: 0.0117s/iter; left time: 424.2487s
Epoch: 26 cost time: 5.705738306045532
Epoch: 26, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3957 + XiCon Loss:2.3531 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4518265
	speed: 0.0140s/iter; left time: 503.1546s
	iters: 200, epoch: 27 | loss: 0.5622421
	speed: 0.0106s/iter; left time: 381.2358s
	iters: 300, epoch: 27 | loss: 0.4004217
	speed: 0.0117s/iter; left time: 418.7883s
	iters: 400, epoch: 27 | loss: 0.3599552
	speed: 0.0112s/iter; left time: 398.3376s
Epoch: 27 cost time: 5.7874627113342285
Epoch: 27, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3527 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3560763
	speed: 0.0138s/iter; left time: 490.3936s
	iters: 200, epoch: 28 | loss: 0.3678819
	speed: 0.0115s/iter; left time: 405.7421s
	iters: 300, epoch: 28 | loss: 0.4438200
	speed: 0.0115s/iter; left time: 404.6809s
	iters: 400, epoch: 28 | loss: 0.4367475
	speed: 0.0110s/iter; left time: 387.8619s
Epoch: 28 cost time: 5.745681524276733
Epoch: 28, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3958 + XiCon Loss:2.3522 x Lambda(0.01)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3774185
	speed: 0.0134s/iter; left time: 467.7100s
	iters: 200, epoch: 29 | loss: 0.3985107
	speed: 0.0116s/iter; left time: 404.3785s
	iters: 300, epoch: 29 | loss: 0.4488131
	speed: 0.0119s/iter; left time: 412.1630s
	iters: 400, epoch: 29 | loss: 0.3859316
	speed: 0.0118s/iter; left time: 407.9567s
Epoch: 29 cost time: 5.890283584594727
Epoch: 29, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3958 + XiCon Loss:2.3543 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3857222
	speed: 0.0137s/iter; left time: 471.4868s
	iters: 200, epoch: 30 | loss: 0.3952955
	speed: 0.0117s/iter; left time: 400.9144s
	iters: 300, epoch: 30 | loss: 0.3391427
	speed: 0.0125s/iter; left time: 427.7016s
	iters: 400, epoch: 30 | loss: 0.3738816
	speed: 0.0109s/iter; left time: 371.1063s
Epoch: 30 cost time: 5.805816650390625
Epoch: 30, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3956 + XiCon Loss:2.3577 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4004225
	speed: 0.0146s/iter; left time: 496.6394s
	iters: 200, epoch: 31 | loss: 0.4184929
	speed: 0.0114s/iter; left time: 388.0494s
	iters: 300, epoch: 31 | loss: 0.3201759
	speed: 0.0111s/iter; left time: 373.6502s
	iters: 400, epoch: 31 | loss: 0.3732572
	speed: 0.0115s/iter; left time: 388.4982s
Epoch: 31 cost time: 5.892646074295044
Epoch: 31, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3576 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4307032
	speed: 0.0141s/iter; left time: 471.4225s
	iters: 200, epoch: 32 | loss: 0.4475623
	speed: 0.0106s/iter; left time: 355.0388s
	iters: 300, epoch: 32 | loss: 0.3647016
	speed: 0.0109s/iter; left time: 364.1667s
	iters: 400, epoch: 32 | loss: 0.4458739
	speed: 0.0111s/iter; left time: 368.0086s
Epoch: 32 cost time: 5.686777353286743
Epoch: 32, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3588 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4066748
	speed: 0.0136s/iter; left time: 449.0054s
	iters: 200, epoch: 33 | loss: 0.4794115
	speed: 0.0114s/iter; left time: 374.7073s
	iters: 300, epoch: 33 | loss: 0.3727534
	speed: 0.0109s/iter; left time: 358.4386s
	iters: 400, epoch: 33 | loss: 0.4738719
	speed: 0.0105s/iter; left time: 343.0103s
Epoch: 33 cost time: 5.6608967781066895
Epoch: 33, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3959 + XiCon Loss:2.3528 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4119493
	speed: 0.0136s/iter; left time: 441.0751s
	iters: 200, epoch: 34 | loss: 0.4741612
	speed: 0.0116s/iter; left time: 376.7108s
	iters: 300, epoch: 34 | loss: 0.4337324
	speed: 0.0107s/iter; left time: 345.0675s
	iters: 400, epoch: 34 | loss: 0.4152239
	speed: 0.0116s/iter; left time: 375.1660s
Epoch: 34 cost time: 5.715829610824585
Epoch: 34, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3956 + XiCon Loss:2.3541 x Lambda(0.01)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5117
Validation loss decreased (0.736935 --> 0.736618).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3955692
	speed: 0.0142s/iter; left time: 455.6025s
	iters: 200, epoch: 35 | loss: 0.3932015
	speed: 0.0119s/iter; left time: 380.4795s
	iters: 300, epoch: 35 | loss: 0.4520496
	speed: 0.0110s/iter; left time: 350.4185s
	iters: 400, epoch: 35 | loss: 0.3683469
	speed: 0.0112s/iter; left time: 355.4070s
Epoch: 35 cost time: 5.861877679824829
Epoch: 35, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3595 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4908317
	speed: 0.0136s/iter; left time: 429.8406s
	iters: 200, epoch: 36 | loss: 0.3423155
	speed: 0.0115s/iter; left time: 360.6288s
	iters: 300, epoch: 36 | loss: 0.3645357
	speed: 0.0116s/iter; left time: 363.0005s
	iters: 400, epoch: 36 | loss: 0.4200081
	speed: 0.0108s/iter; left time: 337.9837s
Epoch: 36 cost time: 5.694111347198486
Epoch: 36, Steps: 487 Train Loss: 0.4191 (Forecasting Loss:0.3956 + XiCon Loss:2.3544 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4630429
	speed: 0.0149s/iter; left time: 462.6888s
	iters: 200, epoch: 37 | loss: 0.3931895
	speed: 0.0114s/iter; left time: 352.7357s
	iters: 300, epoch: 37 | loss: 0.3963711
	speed: 0.0105s/iter; left time: 323.6823s
	iters: 400, epoch: 37 | loss: 0.5103710
	speed: 0.0104s/iter; left time: 321.3700s
Epoch: 37 cost time: 5.71011209487915
Epoch: 37, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3552 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3907740
	speed: 0.0140s/iter; left time: 427.6889s
	iters: 200, epoch: 38 | loss: 0.4286599
	speed: 0.0106s/iter; left time: 322.8050s
	iters: 300, epoch: 38 | loss: 0.4049990
	speed: 0.0114s/iter; left time: 345.2356s
	iters: 400, epoch: 38 | loss: 0.4526697
	speed: 0.0118s/iter; left time: 358.4418s
Epoch: 38 cost time: 5.795510768890381
Epoch: 38, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3582 x Lambda(0.01)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.4915114
	speed: 0.0138s/iter; left time: 416.2240s
	iters: 200, epoch: 39 | loss: 0.3660322
	speed: 0.0116s/iter; left time: 348.3823s
	iters: 300, epoch: 39 | loss: 0.4698834
	speed: 0.0115s/iter; left time: 342.9396s
	iters: 400, epoch: 39 | loss: 0.4211967
	speed: 0.0111s/iter; left time: 332.0227s
Epoch: 39 cost time: 5.8027520179748535
Epoch: 39, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3555 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4883032
	speed: 0.0138s/iter; left time: 408.1982s
	iters: 200, epoch: 40 | loss: 0.4371085
	speed: 0.0116s/iter; left time: 341.4349s
	iters: 300, epoch: 40 | loss: 0.4037527
	speed: 0.0115s/iter; left time: 337.8429s
	iters: 400, epoch: 40 | loss: 0.4676477
	speed: 0.0116s/iter; left time: 339.7734s
Epoch: 40 cost time: 5.838667869567871
Epoch: 40, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3960 + XiCon Loss:2.3524 x Lambda(0.01)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.3993160
	speed: 0.0148s/iter; left time: 429.7049s
	iters: 200, epoch: 41 | loss: 0.3985130
	speed: 0.0111s/iter; left time: 322.1046s
	iters: 300, epoch: 41 | loss: 0.4482372
	speed: 0.0109s/iter; left time: 315.0137s
	iters: 400, epoch: 41 | loss: 0.4220226
	speed: 0.0105s/iter; left time: 301.2027s
Epoch: 41 cost time: 5.756357192993164
Epoch: 41, Steps: 487 Train Loss: 0.4193 (Forecasting Loss:0.3958 + XiCon Loss:2.3525 x Lambda(0.01)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.3596563
	speed: 0.0139s/iter; left time: 397.6171s
	iters: 200, epoch: 42 | loss: 0.3911349
	speed: 0.0107s/iter; left time: 305.5700s
	iters: 300, epoch: 42 | loss: 0.4530761
	speed: 0.0113s/iter; left time: 320.5808s
	iters: 400, epoch: 42 | loss: 0.4905457
	speed: 0.0117s/iter; left time: 330.7884s
Epoch: 42 cost time: 5.8434226512908936
Epoch: 42, Steps: 487 Train Loss: 0.4194 (Forecasting Loss:0.3958 + XiCon Loss:2.3552 x Lambda(0.01)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.3781704
	speed: 0.0138s/iter; left time: 388.3460s
	iters: 200, epoch: 43 | loss: 0.4801454
	speed: 0.0109s/iter; left time: 306.6614s
	iters: 300, epoch: 43 | loss: 0.4198863
	speed: 0.0108s/iter; left time: 302.4814s
	iters: 400, epoch: 43 | loss: 0.4310998
	speed: 0.0111s/iter; left time: 308.2034s
Epoch: 43 cost time: 5.755731582641602
Epoch: 43, Steps: 487 Train Loss: 0.4195 (Forecasting Loss:0.3959 + XiCon Loss:2.3604 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.4198578
	speed: 0.0137s/iter; left time: 378.3440s
	iters: 200, epoch: 44 | loss: 0.4659841
	speed: 0.0110s/iter; left time: 304.0254s
	iters: 300, epoch: 44 | loss: 0.5293001
	speed: 0.0111s/iter; left time: 304.4623s
	iters: 400, epoch: 44 | loss: 0.4722547
	speed: 0.0111s/iter; left time: 304.7164s
Epoch: 44 cost time: 5.6794493198394775
Epoch: 44, Steps: 487 Train Loss: 0.4192 (Forecasting Loss:0.3957 + XiCon Loss:2.3544 x Lambda(0.01)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5182334780693054, mae:0.505239725112915, mape:3.4785990715026855, mspe:1099.1531982421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5200+-0.00809, MAE:0.5063+-0.00425, MAPE:3.5262+-0.08058, MSPE:1145.8484+-65.88290, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.4919
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9591542
	speed: 0.0291s/iter; left time: 688.8261s
	iters: 200, epoch: 1 | loss: 0.9818524
	speed: 0.0227s/iter; left time: 535.3905s
Epoch: 1 cost time: 6.038578748703003
Epoch: 1, Steps: 238 Train Loss: 1.0091 (Forecasting Loss:0.9803 + XiCon Loss:2.8801 x Lambda(0.01)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755403).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6362869
	speed: 0.0253s/iter; left time: 594.6394s
	iters: 200, epoch: 2 | loss: 0.6126806
	speed: 0.0227s/iter; left time: 530.7010s
Epoch: 2 cost time: 5.733734846115112
Epoch: 2, Steps: 238 Train Loss: 0.6457 (Forecasting Loss:0.6169 + XiCon Loss:2.8773 x Lambda(0.01)), Vali MSE Loss: 1.0368 Test MSE Loss: 0.8580
Validation loss decreased (1.755403 --> 1.036816).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5869533
	speed: 0.0287s/iter; left time: 667.5242s
	iters: 200, epoch: 3 | loss: 0.5937837
	speed: 0.0264s/iter; left time: 609.9415s
Epoch: 3 cost time: 6.444768905639648
Epoch: 3, Steps: 238 Train Loss: 0.5815 (Forecasting Loss:0.5527 + XiCon Loss:2.8761 x Lambda(0.01)), Vali MSE Loss: 1.0179 Test MSE Loss: 0.8515
Validation loss decreased (1.036816 --> 1.017898).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5671532
	speed: 0.0253s/iter; left time: 582.7074s
	iters: 200, epoch: 4 | loss: 0.5333075
	speed: 0.0237s/iter; left time: 543.0957s
Epoch: 4 cost time: 5.811457395553589
Epoch: 4, Steps: 238 Train Loss: 0.5733 (Forecasting Loss:0.5446 + XiCon Loss:2.8730 x Lambda(0.01)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8494
Validation loss decreased (1.017898 --> 1.010525).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5503465
	speed: 0.0250s/iter; left time: 569.2146s
	iters: 200, epoch: 5 | loss: 0.5967142
	speed: 0.0237s/iter; left time: 536.5678s
Epoch: 5 cost time: 5.7251198291778564
Epoch: 5, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5414 + XiCon Loss:2.8751 x Lambda(0.01)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8490
Validation loss decreased (1.010525 --> 1.007492).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5577763
	speed: 0.0246s/iter; left time: 552.7472s
	iters: 200, epoch: 6 | loss: 0.5706010
	speed: 0.0228s/iter; left time: 510.0499s
Epoch: 6 cost time: 5.654099702835083
Epoch: 6, Steps: 238 Train Loss: 0.5687 (Forecasting Loss:0.5399 + XiCon Loss:2.8711 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8487
Validation loss decreased (1.007492 --> 1.006176).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5592842
	speed: 0.0243s/iter; left time: 541.3639s
	iters: 200, epoch: 7 | loss: 0.5705470
	speed: 0.0223s/iter; left time: 493.4288s
Epoch: 7 cost time: 5.538167715072632
Epoch: 7, Steps: 238 Train Loss: 0.5679 (Forecasting Loss:0.5391 + XiCon Loss:2.8764 x Lambda(0.01)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8487
Validation loss decreased (1.006176 --> 1.004491).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5219111
	speed: 0.0254s/iter; left time: 559.7961s
	iters: 200, epoch: 8 | loss: 0.5945601
	speed: 0.0227s/iter; left time: 498.7872s
Epoch: 8 cost time: 5.738695383071899
Epoch: 8, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5387 + XiCon Loss:2.8726 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8486
Validation loss decreased (1.004491 --> 1.004423).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5982706
	speed: 0.0248s/iter; left time: 540.3712s
	iters: 200, epoch: 9 | loss: 0.6166838
	speed: 0.0224s/iter; left time: 486.7401s
Epoch: 9 cost time: 5.637425661087036
Epoch: 9, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5386 + XiCon Loss:2.8752 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8486
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5565772
	speed: 0.0248s/iter; left time: 535.2114s
	iters: 200, epoch: 10 | loss: 0.5864569
	speed: 0.0228s/iter; left time: 489.6516s
Epoch: 10 cost time: 5.662793159484863
Epoch: 10, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5385 + XiCon Loss:2.8761 x Lambda(0.01)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8485
Validation loss decreased (1.004423 --> 1.004363).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5256627
	speed: 0.0254s/iter; left time: 540.6886s
	iters: 200, epoch: 11 | loss: 0.5864680
	speed: 0.0233s/iter; left time: 493.6963s
Epoch: 11 cost time: 5.78510308265686
Epoch: 11, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5382 + XiCon Loss:2.8716 x Lambda(0.01)), Vali MSE Loss: 1.0036 Test MSE Loss: 0.8485
Validation loss decreased (1.004363 --> 1.003586).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5864930
	speed: 0.0256s/iter; left time: 539.1049s
	iters: 200, epoch: 12 | loss: 0.5369828
	speed: 0.0224s/iter; left time: 469.5355s
Epoch: 12 cost time: 5.7396111488342285
Epoch: 12, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5382 + XiCon Loss:2.8727 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5699040
	speed: 0.0251s/iter; left time: 523.4773s
	iters: 200, epoch: 13 | loss: 0.5599291
	speed: 0.0230s/iter; left time: 477.2783s
Epoch: 13 cost time: 5.718133449554443
Epoch: 13, Steps: 238 Train Loss: 0.5670 (Forecasting Loss:0.5383 + XiCon Loss:2.8744 x Lambda(0.01)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8485
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4804134
	speed: 0.0255s/iter; left time: 524.6143s
	iters: 200, epoch: 14 | loss: 0.5630796
	speed: 0.0236s/iter; left time: 483.8015s
Epoch: 14 cost time: 5.838199138641357
Epoch: 14, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5381 + XiCon Loss:2.8706 x Lambda(0.01)), Vali MSE Loss: 1.0042 Test MSE Loss: 0.8485
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5687779
	speed: 0.0250s/iter; left time: 509.0630s
	iters: 200, epoch: 15 | loss: 0.5689621
	speed: 0.0236s/iter; left time: 477.7277s
Epoch: 15 cost time: 5.775896072387695
Epoch: 15, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5382 + XiCon Loss:2.8688 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5299083
	speed: 0.0256s/iter; left time: 515.6520s
	iters: 200, epoch: 16 | loss: 0.5597802
	speed: 0.0227s/iter; left time: 454.9189s
Epoch: 16 cost time: 5.707648038864136
Epoch: 16, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5385 + XiCon Loss:2.8709 x Lambda(0.01)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8485
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5594760
	speed: 0.0257s/iter; left time: 511.1408s
	iters: 200, epoch: 17 | loss: 0.5664176
	speed: 0.0232s/iter; left time: 460.0626s
Epoch: 17 cost time: 5.797514200210571
Epoch: 17, Steps: 238 Train Loss: 0.5667 (Forecasting Loss:0.5380 + XiCon Loss:2.8782 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8485
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5318574
	speed: 0.0255s/iter; left time: 500.4387s
	iters: 200, epoch: 18 | loss: 0.5020638
	speed: 0.0223s/iter; left time: 436.4275s
Epoch: 18 cost time: 5.70274543762207
Epoch: 18, Steps: 238 Train Loss: 0.5669 (Forecasting Loss:0.5382 + XiCon Loss:2.8715 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8485
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5697416
	speed: 0.0249s/iter; left time: 483.1152s
	iters: 200, epoch: 19 | loss: 0.5620332
	speed: 0.0235s/iter; left time: 453.9811s
Epoch: 19 cost time: 5.720186471939087
Epoch: 19, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5384 + XiCon Loss:2.8726 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5453763
	speed: 0.0252s/iter; left time: 483.3401s
	iters: 200, epoch: 20 | loss: 0.5772400
	speed: 0.0233s/iter; left time: 445.4633s
Epoch: 20 cost time: 5.7735350131988525
Epoch: 20, Steps: 238 Train Loss: 0.5668 (Forecasting Loss:0.5381 + XiCon Loss:2.8754 x Lambda(0.01)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8485
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5215320
	speed: 0.0257s/iter; left time: 487.2448s
	iters: 200, epoch: 21 | loss: 0.5783345
	speed: 0.0231s/iter; left time: 434.6456s
Epoch: 21 cost time: 5.757768154144287
Epoch: 21, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5384 + XiCon Loss:2.8751 x Lambda(0.01)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8485
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.977708101272583, mae:0.7193635702133179, mape:4.778608322143555, mspe:2691.1943359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.3834
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1135365
	speed: 0.0276s/iter; left time: 654.2490s
	iters: 200, epoch: 1 | loss: 1.1873103
	speed: 0.0234s/iter; left time: 551.0890s
Epoch: 1 cost time: 5.967970132827759
Epoch: 1, Steps: 238 Train Loss: 1.1279 (Forecasting Loss:1.0993 + XiCon Loss:2.8686 x Lambda(0.01)), Vali MSE Loss: 1.9677 Test MSE Loss: 1.0361
Validation loss decreased (inf --> 1.967726).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6541791
	speed: 0.0263s/iter; left time: 617.8963s
	iters: 200, epoch: 2 | loss: 0.5700280
	speed: 0.0234s/iter; left time: 547.1495s
Epoch: 2 cost time: 5.882357597351074
Epoch: 2, Steps: 238 Train Loss: 0.6599 (Forecasting Loss:0.6313 + XiCon Loss:2.8646 x Lambda(0.01)), Vali MSE Loss: 1.0219 Test MSE Loss: 0.8588
Validation loss decreased (1.967726 --> 1.021878).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5703246
	speed: 0.0257s/iter; left time: 597.2628s
	iters: 200, epoch: 3 | loss: 0.5531219
	speed: 0.0233s/iter; left time: 538.3628s
Epoch: 3 cost time: 5.8144426345825195
Epoch: 3, Steps: 238 Train Loss: 0.5802 (Forecasting Loss:0.5516 + XiCon Loss:2.8600 x Lambda(0.01)), Vali MSE Loss: 1.0006 Test MSE Loss: 0.8528
Validation loss decreased (1.021878 --> 1.000551).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5051980
	speed: 0.0255s/iter; left time: 585.9423s
	iters: 200, epoch: 4 | loss: 0.5894157
	speed: 0.0227s/iter; left time: 519.4366s
Epoch: 4 cost time: 5.704381942749023
Epoch: 4, Steps: 238 Train Loss: 0.5718 (Forecasting Loss:0.5432 + XiCon Loss:2.8602 x Lambda(0.01)), Vali MSE Loss: 0.9941 Test MSE Loss: 0.8515
Validation loss decreased (1.000551 --> 0.994073).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5957528
	speed: 0.0251s/iter; left time: 571.7579s
	iters: 200, epoch: 5 | loss: 0.5529833
	speed: 0.0230s/iter; left time: 520.2352s
Epoch: 5 cost time: 5.738729238510132
Epoch: 5, Steps: 238 Train Loss: 0.5684 (Forecasting Loss:0.5399 + XiCon Loss:2.8560 x Lambda(0.01)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8508
Validation loss decreased (0.994073 --> 0.989107).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5444778
	speed: 0.0252s/iter; left time: 566.8367s
	iters: 200, epoch: 6 | loss: 0.5772246
	speed: 0.0229s/iter; left time: 512.8108s
Epoch: 6 cost time: 5.699113130569458
Epoch: 6, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5386 + XiCon Loss:2.8561 x Lambda(0.01)), Vali MSE Loss: 0.9880 Test MSE Loss: 0.8507
Validation loss decreased (0.989107 --> 0.988027).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5683935
	speed: 0.0247s/iter; left time: 551.1946s
	iters: 200, epoch: 7 | loss: 0.5384787
	speed: 0.0223s/iter; left time: 494.5498s
Epoch: 7 cost time: 5.582693099975586
Epoch: 7, Steps: 238 Train Loss: 0.5662 (Forecasting Loss:0.5376 + XiCon Loss:2.8553 x Lambda(0.01)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8506
Validation loss decreased (0.988027 --> 0.987051).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5732235
	speed: 0.0257s/iter; left time: 565.9197s
	iters: 200, epoch: 8 | loss: 0.5334330
	speed: 0.0228s/iter; left time: 501.1705s
Epoch: 8 cost time: 5.796262741088867
Epoch: 8, Steps: 238 Train Loss: 0.5661 (Forecasting Loss:0.5376 + XiCon Loss:2.8547 x Lambda(0.01)), Vali MSE Loss: 0.9870 Test MSE Loss: 0.8505
Validation loss decreased (0.987051 --> 0.986953).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5520254
	speed: 0.0253s/iter; left time: 551.6891s
	iters: 200, epoch: 9 | loss: 0.6038935
	speed: 0.0222s/iter; left time: 482.0697s
Epoch: 9 cost time: 5.679635524749756
Epoch: 9, Steps: 238 Train Loss: 0.5658 (Forecasting Loss:0.5372 + XiCon Loss:2.8561 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
Validation loss decreased (0.986953 --> 0.985935).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5621984
	speed: 0.0256s/iter; left time: 550.9741s
	iters: 200, epoch: 10 | loss: 0.6309676
	speed: 0.0227s/iter; left time: 486.2498s
Epoch: 10 cost time: 5.746978759765625
Epoch: 10, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5370 + XiCon Loss:2.8549 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
Validation loss decreased (0.985935 --> 0.985575).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5696903
	speed: 0.0257s/iter; left time: 547.5950s
	iters: 200, epoch: 11 | loss: 0.6009018
	speed: 0.0232s/iter; left time: 491.8402s
Epoch: 11 cost time: 5.762286424636841
Epoch: 11, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8540 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5739297
	speed: 0.0249s/iter; left time: 524.2442s
	iters: 200, epoch: 12 | loss: 0.5262053
	speed: 0.0238s/iter; left time: 500.4051s
Epoch: 12 cost time: 5.762678623199463
Epoch: 12, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8537 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5405902
	speed: 0.0253s/iter; left time: 527.8565s
	iters: 200, epoch: 13 | loss: 0.5617561
	speed: 0.0235s/iter; left time: 487.8859s
Epoch: 13 cost time: 5.805925369262695
Epoch: 13, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5367 + XiCon Loss:2.8572 x Lambda(0.01)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5128548
	speed: 0.0251s/iter; left time: 517.7967s
	iters: 200, epoch: 14 | loss: 0.5523493
	speed: 0.0222s/iter; left time: 455.3165s
Epoch: 14 cost time: 5.588874340057373
Epoch: 14, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8573 x Lambda(0.01)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5572773
	speed: 0.0254s/iter; left time: 516.8826s
	iters: 200, epoch: 15 | loss: 0.4917904
	speed: 0.0229s/iter; left time: 463.9997s
Epoch: 15 cost time: 5.747899293899536
Epoch: 15, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5368 + XiCon Loss:2.8579 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5931051
	speed: 0.0252s/iter; left time: 507.4117s
	iters: 200, epoch: 16 | loss: 0.5875188
	speed: 0.0230s/iter; left time: 459.8446s
Epoch: 16 cost time: 5.694050073623657
Epoch: 16, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5369 + XiCon Loss:2.8568 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5465735
	speed: 0.0265s/iter; left time: 527.1381s
	iters: 200, epoch: 17 | loss: 0.5964481
	speed: 0.0227s/iter; left time: 450.2110s
Epoch: 17 cost time: 5.898955583572388
Epoch: 17, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5371 + XiCon Loss:2.8520 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5853878
	speed: 0.0255s/iter; left time: 502.1156s
	iters: 200, epoch: 18 | loss: 0.6612952
	speed: 0.0230s/iter; left time: 450.1200s
Epoch: 18 cost time: 5.762049198150635
Epoch: 18, Steps: 238 Train Loss: 0.5657 (Forecasting Loss:0.5372 + XiCon Loss:2.8522 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5604296
	speed: 0.0253s/iter; left time: 490.8366s
	iters: 200, epoch: 19 | loss: 0.5634502
	speed: 0.0229s/iter; left time: 443.1550s
Epoch: 19 cost time: 5.724113702774048
Epoch: 19, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8583 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5743523
	speed: 0.0252s/iter; left time: 482.5205s
	iters: 200, epoch: 20 | loss: 0.5825907
	speed: 0.0225s/iter; left time: 428.6472s
Epoch: 20 cost time: 5.641845464706421
Epoch: 20, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8558 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985575 --> 0.985544).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5219530
	speed: 0.0249s/iter; left time: 471.0251s
	iters: 200, epoch: 21 | loss: 0.5369001
	speed: 0.0233s/iter; left time: 439.7695s
Epoch: 21 cost time: 5.749802589416504
Epoch: 21, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5367 + XiCon Loss:2.8553 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5382691
	speed: 0.0257s/iter; left time: 480.7613s
	iters: 200, epoch: 22 | loss: 0.5614031
	speed: 0.0229s/iter; left time: 425.8378s
Epoch: 22 cost time: 5.783471584320068
Epoch: 22, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5369 + XiCon Loss:2.8572 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5552914
	speed: 0.0255s/iter; left time: 469.9765s
	iters: 200, epoch: 23 | loss: 0.5399576
	speed: 0.0228s/iter; left time: 419.5491s
Epoch: 23 cost time: 5.7341225147247314
Epoch: 23, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5371 + XiCon Loss:2.8532 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5791814
	speed: 0.0264s/iter; left time: 481.5974s
	iters: 200, epoch: 24 | loss: 0.5565404
	speed: 0.0235s/iter; left time: 425.8425s
Epoch: 24 cost time: 5.921210289001465
Epoch: 24, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8533 x Lambda(0.01)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5622025
	speed: 0.0266s/iter; left time: 478.0954s
	iters: 200, epoch: 25 | loss: 0.5729945
	speed: 0.0238s/iter; left time: 425.1100s
Epoch: 25 cost time: 5.923076391220093
Epoch: 25, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8567 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5850536
	speed: 0.0257s/iter; left time: 456.0251s
	iters: 200, epoch: 26 | loss: 0.5436963
	speed: 0.0228s/iter; left time: 402.3907s
Epoch: 26 cost time: 5.745714426040649
Epoch: 26, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8544 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6090846
	speed: 0.0253s/iter; left time: 443.6663s
	iters: 200, epoch: 27 | loss: 0.6046229
	speed: 0.0231s/iter; left time: 402.5869s
Epoch: 27 cost time: 5.802533149719238
Epoch: 27, Steps: 238 Train Loss: 0.5657 (Forecasting Loss:0.5371 + XiCon Loss:2.8545 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5407889
	speed: 0.0258s/iter; left time: 446.4613s
	iters: 200, epoch: 28 | loss: 0.5385739
	speed: 0.0229s/iter; left time: 393.6015s
Epoch: 28 cost time: 5.755907297134399
Epoch: 28, Steps: 238 Train Loss: 0.5652 (Forecasting Loss:0.5367 + XiCon Loss:2.8551 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4934391
	speed: 0.0255s/iter; left time: 434.6018s
	iters: 200, epoch: 29 | loss: 0.5577276
	speed: 0.0233s/iter; left time: 394.4106s
Epoch: 29 cost time: 5.792051792144775
Epoch: 29, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5368 + XiCon Loss:2.8525 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5081577
	speed: 0.0257s/iter; left time: 432.2013s
	iters: 200, epoch: 30 | loss: 0.5766962
	speed: 0.0227s/iter; left time: 379.5988s
Epoch: 30 cost time: 5.716058015823364
Epoch: 30, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8544 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
Validation loss decreased (0.985544 --> 0.985460).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5642099
	speed: 0.0251s/iter; left time: 415.2172s
	iters: 200, epoch: 31 | loss: 0.5224057
	speed: 0.0220s/iter; left time: 362.4549s
Epoch: 31 cost time: 5.632701635360718
Epoch: 31, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5367 + XiCon Loss:2.8544 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5843614
	speed: 0.0261s/iter; left time: 426.7342s
	iters: 200, epoch: 32 | loss: 0.6096191
	speed: 0.0228s/iter; left time: 370.0378s
Epoch: 32 cost time: 5.812212228775024
Epoch: 32, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8544 x Lambda(0.01)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5527169
	speed: 0.0251s/iter; left time: 403.4735s
	iters: 200, epoch: 33 | loss: 0.5451896
	speed: 0.0232s/iter; left time: 370.5825s
Epoch: 33 cost time: 5.72808313369751
Epoch: 33, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8492 x Lambda(0.01)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8504
Validation loss decreased (0.985460 --> 0.985421).  Saving model ...
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5427317
	speed: 0.0254s/iter; left time: 402.1232s
	iters: 200, epoch: 34 | loss: 0.5442985
	speed: 0.0234s/iter; left time: 368.2129s
Epoch: 34 cost time: 5.763671159744263
Epoch: 34, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8534 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5508412
	speed: 0.0256s/iter; left time: 398.8554s
	iters: 200, epoch: 35 | loss: 0.6026949
	speed: 0.0231s/iter; left time: 358.9337s
Epoch: 35 cost time: 5.748317241668701
Epoch: 35, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5367 + XiCon Loss:2.8560 x Lambda(0.01)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8504
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5382307
	speed: 0.0252s/iter; left time: 386.6998s
	iters: 200, epoch: 36 | loss: 0.5509908
	speed: 0.0228s/iter; left time: 347.5927s
Epoch: 36 cost time: 5.67252779006958
Epoch: 36, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5368 + XiCon Loss:2.8581 x Lambda(0.01)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8504
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5206041
	speed: 0.0252s/iter; left time: 381.8939s
	iters: 200, epoch: 37 | loss: 0.6202272
	speed: 0.0227s/iter; left time: 341.0401s
Epoch: 37 cost time: 5.683362245559692
Epoch: 37, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5370 + XiCon Loss:2.8550 x Lambda(0.01)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8504
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5956452
	speed: 0.0250s/iter; left time: 372.1892s
	iters: 200, epoch: 38 | loss: 0.5975514
	speed: 0.0225s/iter; left time: 333.4114s
Epoch: 38 cost time: 5.670789480209351
Epoch: 38, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5367 + XiCon Loss:2.8546 x Lambda(0.01)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8504
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5642715
	speed: 0.0254s/iter; left time: 372.6772s
	iters: 200, epoch: 39 | loss: 0.5972767
	speed: 0.0225s/iter; left time: 327.1463s
Epoch: 39 cost time: 5.708105564117432
Epoch: 39, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5368 + XiCon Loss:2.8564 x Lambda(0.01)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8504
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.5993794
	speed: 0.0248s/iter; left time: 357.1575s
	iters: 200, epoch: 40 | loss: 0.5911900
	speed: 0.0238s/iter; left time: 340.3001s
Epoch: 40 cost time: 5.772035598754883
Epoch: 40, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5370 + XiCon Loss:2.8587 x Lambda(0.01)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8504
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.6071664
	speed: 0.0249s/iter; left time: 352.5976s
	iters: 200, epoch: 41 | loss: 0.5398232
	speed: 0.0221s/iter; left time: 310.7254s
Epoch: 41 cost time: 5.605055570602417
Epoch: 41, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5369 + XiCon Loss:2.8570 x Lambda(0.01)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.5497472
	speed: 0.0261s/iter; left time: 364.0825s
	iters: 200, epoch: 42 | loss: 0.5645275
	speed: 0.0231s/iter; left time: 320.0373s
Epoch: 42 cost time: 5.821244239807129
Epoch: 42, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5369 + XiCon Loss:2.8559 x Lambda(0.01)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8504
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.5804025
	speed: 0.0255s/iter; left time: 350.0198s
	iters: 200, epoch: 43 | loss: 0.5728765
	speed: 0.0225s/iter; left time: 305.9030s
Epoch: 43 cost time: 5.6948864459991455
Epoch: 43, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5369 + XiCon Loss:2.8563 x Lambda(0.01)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9793328046798706, mae:0.7214695811271667, mape:4.789102554321289, mspe:2695.31494140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.6584
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1440741
	speed: 0.0275s/iter; left time: 652.8591s
	iters: 200, epoch: 1 | loss: 1.0587325
	speed: 0.0229s/iter; left time: 539.7381s
Epoch: 1 cost time: 5.94305682182312
Epoch: 1, Steps: 238 Train Loss: 1.1258 (Forecasting Loss:1.0971 + XiCon Loss:2.8697 x Lambda(0.01)), Vali MSE Loss: 1.9328 Test MSE Loss: 1.0252
Validation loss decreased (inf --> 1.932777).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6248748
	speed: 0.0249s/iter; left time: 583.4415s
	iters: 200, epoch: 2 | loss: 0.6042141
	speed: 0.0230s/iter; left time: 537.5056s
Epoch: 2 cost time: 5.688590049743652
Epoch: 2, Steps: 238 Train Loss: 0.6522 (Forecasting Loss:0.6235 + XiCon Loss:2.8673 x Lambda(0.01)), Vali MSE Loss: 1.0344 Test MSE Loss: 0.8764
Validation loss decreased (1.932777 --> 1.034353).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5496032
	speed: 0.0255s/iter; left time: 591.1940s
	iters: 200, epoch: 3 | loss: 0.6308452
	speed: 0.0229s/iter; left time: 528.8288s
Epoch: 3 cost time: 5.729983329772949
Epoch: 3, Steps: 238 Train Loss: 0.5810 (Forecasting Loss:0.5523 + XiCon Loss:2.8695 x Lambda(0.01)), Vali MSE Loss: 1.0101 Test MSE Loss: 0.8681
Validation loss decreased (1.034353 --> 1.010062).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5560547
	speed: 0.0267s/iter; left time: 614.0019s
	iters: 200, epoch: 4 | loss: 0.6272681
	speed: 0.0230s/iter; left time: 527.4095s
Epoch: 4 cost time: 5.856984615325928
Epoch: 4, Steps: 238 Train Loss: 0.5723 (Forecasting Loss:0.5435 + XiCon Loss:2.8752 x Lambda(0.01)), Vali MSE Loss: 1.0028 Test MSE Loss: 0.8657
Validation loss decreased (1.010062 --> 1.002817).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5634311
	speed: 0.0260s/iter; left time: 592.1354s
	iters: 200, epoch: 5 | loss: 0.5989984
	speed: 0.0237s/iter; left time: 537.0949s
Epoch: 5 cost time: 5.850669860839844
Epoch: 5, Steps: 238 Train Loss: 0.5686 (Forecasting Loss:0.5400 + XiCon Loss:2.8677 x Lambda(0.01)), Vali MSE Loss: 0.9986 Test MSE Loss: 0.8647
Validation loss decreased (1.002817 --> 0.998574).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5883168
	speed: 0.0245s/iter; left time: 552.4382s
	iters: 200, epoch: 6 | loss: 0.5324470
	speed: 0.0236s/iter; left time: 527.7965s
Epoch: 6 cost time: 5.732910394668579
Epoch: 6, Steps: 238 Train Loss: 0.5671 (Forecasting Loss:0.5384 + XiCon Loss:2.8737 x Lambda(0.01)), Vali MSE Loss: 0.9977 Test MSE Loss: 0.8649
Validation loss decreased (0.998574 --> 0.997696).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5659575
	speed: 0.0259s/iter; left time: 576.1476s
	iters: 200, epoch: 7 | loss: 0.5943670
	speed: 0.0229s/iter; left time: 507.8431s
Epoch: 7 cost time: 5.7457053661346436
Epoch: 7, Steps: 238 Train Loss: 0.5662 (Forecasting Loss:0.5375 + XiCon Loss:2.8666 x Lambda(0.01)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8646
Validation loss decreased (0.997696 --> 0.996982).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5656069
	speed: 0.0258s/iter; left time: 569.0034s
	iters: 200, epoch: 8 | loss: 0.5372080
	speed: 0.0222s/iter; left time: 486.3971s
Epoch: 8 cost time: 5.6821608543396
Epoch: 8, Steps: 238 Train Loss: 0.5658 (Forecasting Loss:0.5371 + XiCon Loss:2.8680 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
Validation loss decreased (0.996982 --> 0.996195).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5913887
	speed: 0.0264s/iter; left time: 576.3844s
	iters: 200, epoch: 9 | loss: 0.5546612
	speed: 0.0233s/iter; left time: 505.2784s
Epoch: 9 cost time: 5.87754225730896
Epoch: 9, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5369 + XiCon Loss:2.8670 x Lambda(0.01)), Vali MSE Loss: 0.9969 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5659575
	speed: 0.0249s/iter; left time: 535.9024s
	iters: 200, epoch: 10 | loss: 0.5652995
	speed: 0.0227s/iter; left time: 487.2680s
Epoch: 10 cost time: 5.657441854476929
Epoch: 10, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5365 + XiCon Loss:2.8728 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
Validation loss decreased (0.996195 --> 0.995976).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5632995
	speed: 0.0250s/iter; left time: 532.0857s
	iters: 200, epoch: 11 | loss: 0.5324892
	speed: 0.0229s/iter; left time: 486.4457s
Epoch: 11 cost time: 5.653977870941162
Epoch: 11, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5368 + XiCon Loss:2.8714 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5504489
	speed: 0.0261s/iter; left time: 549.8102s
	iters: 200, epoch: 12 | loss: 0.5505576
	speed: 0.0237s/iter; left time: 497.0372s
Epoch: 12 cost time: 5.867490768432617
Epoch: 12, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5368 + XiCon Loss:2.8668 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5332906
	speed: 0.0258s/iter; left time: 537.3645s
	iters: 200, epoch: 13 | loss: 0.5137951
	speed: 0.0230s/iter; left time: 477.9785s
Epoch: 13 cost time: 5.793816089630127
Epoch: 13, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5368 + XiCon Loss:2.8687 x Lambda(0.01)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
Validation loss decreased (0.995976 --> 0.995912).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5897679
	speed: 0.0256s/iter; left time: 527.3903s
	iters: 200, epoch: 14 | loss: 0.6566657
	speed: 0.0231s/iter; left time: 474.0109s
Epoch: 14 cost time: 5.8191773891448975
Epoch: 14, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5366 + XiCon Loss:2.8703 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5399063
	speed: 0.0264s/iter; left time: 536.7487s
	iters: 200, epoch: 15 | loss: 0.5456813
	speed: 0.0238s/iter; left time: 481.4219s
Epoch: 15 cost time: 5.910113096237183
Epoch: 15, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5366 + XiCon Loss:2.8762 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995912 --> 0.995523).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5891207
	speed: 0.0249s/iter; left time: 500.9171s
	iters: 200, epoch: 16 | loss: 0.5376678
	speed: 0.0233s/iter; left time: 466.6146s
Epoch: 16 cost time: 5.710330247879028
Epoch: 16, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5368 + XiCon Loss:2.8745 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995523 --> 0.995512).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5336380
	speed: 0.0257s/iter; left time: 511.2201s
	iters: 200, epoch: 17 | loss: 0.5868382
	speed: 0.0233s/iter; left time: 460.3895s
Epoch: 17 cost time: 5.782093286514282
Epoch: 17, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5368 + XiCon Loss:2.8710 x Lambda(0.01)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5617761
	speed: 0.0250s/iter; left time: 491.4712s
	iters: 200, epoch: 18 | loss: 0.5436668
	speed: 0.0230s/iter; left time: 449.0743s
Epoch: 18 cost time: 5.6687235832214355
Epoch: 18, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8726 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5593914
	speed: 0.0259s/iter; left time: 502.1595s
	iters: 200, epoch: 19 | loss: 0.5648643
	speed: 0.0230s/iter; left time: 444.1522s
Epoch: 19 cost time: 5.80139422416687
Epoch: 19, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5367 + XiCon Loss:2.8728 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
Validation loss decreased (0.995512 --> 0.995507).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5413905
	speed: 0.0255s/iter; left time: 489.7279s
	iters: 200, epoch: 20 | loss: 0.5738442
	speed: 0.0227s/iter; left time: 433.6652s
Epoch: 20 cost time: 5.757284879684448
Epoch: 20, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5366 + XiCon Loss:2.8721 x Lambda(0.01)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5812200
	speed: 0.0251s/iter; left time: 474.8219s
	iters: 200, epoch: 21 | loss: 0.5534725
	speed: 0.0225s/iter; left time: 423.4949s
Epoch: 21 cost time: 5.65989875793457
Epoch: 21, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8711 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5171825
	speed: 0.0258s/iter; left time: 482.9193s
	iters: 200, epoch: 22 | loss: 0.5588279
	speed: 0.0235s/iter; left time: 436.3197s
Epoch: 22 cost time: 5.828813076019287
Epoch: 22, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5365 + XiCon Loss:2.8761 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5896206
	speed: 0.0256s/iter; left time: 472.1668s
	iters: 200, epoch: 23 | loss: 0.5926803
	speed: 0.0231s/iter; left time: 424.9028s
Epoch: 23 cost time: 5.726035118103027
Epoch: 23, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5369 + XiCon Loss:2.8734 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5343339
	speed: 0.0259s/iter; left time: 471.4840s
	iters: 200, epoch: 24 | loss: 0.5822160
	speed: 0.0233s/iter; left time: 423.1017s
Epoch: 24 cost time: 5.792029857635498
Epoch: 24, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5368 + XiCon Loss:2.8736 x Lambda(0.01)), Vali MSE Loss: 0.9968 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5969802
	speed: 0.0261s/iter; left time: 469.0369s
	iters: 200, epoch: 25 | loss: 0.5821945
	speed: 0.0230s/iter; left time: 411.8825s
Epoch: 25 cost time: 5.855451583862305
Epoch: 25, Steps: 238 Train Loss: 0.5651 (Forecasting Loss:0.5364 + XiCon Loss:2.8748 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5576882
	speed: 0.0255s/iter; left time: 453.4003s
	iters: 200, epoch: 26 | loss: 0.6071009
	speed: 0.0231s/iter; left time: 408.4848s
Epoch: 26 cost time: 5.7494213581085205
Epoch: 26, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5368 + XiCon Loss:2.8714 x Lambda(0.01)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5833088
	speed: 0.0248s/iter; left time: 435.1772s
	iters: 200, epoch: 27 | loss: 0.5693410
	speed: 0.0232s/iter; left time: 404.1496s
Epoch: 27 cost time: 5.691988468170166
Epoch: 27, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8659 x Lambda(0.01)), Vali MSE Loss: 0.9950 Test MSE Loss: 0.8645
Validation loss decreased (0.995507 --> 0.995034).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5896844
	speed: 0.0257s/iter; left time: 443.3484s
	iters: 200, epoch: 28 | loss: 0.5533283
	speed: 0.0225s/iter; left time: 387.1506s
Epoch: 28 cost time: 5.726147413253784
Epoch: 28, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5366 + XiCon Loss:2.8736 x Lambda(0.01)), Vali MSE Loss: 0.9955 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5914562
	speed: 0.0251s/iter; left time: 428.1953s
	iters: 200, epoch: 29 | loss: 0.5683981
	speed: 0.0231s/iter; left time: 391.8311s
Epoch: 29 cost time: 5.756700754165649
Epoch: 29, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8686 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5975837
	speed: 0.0258s/iter; left time: 432.7445s
	iters: 200, epoch: 30 | loss: 0.5665240
	speed: 0.0226s/iter; left time: 376.7040s
Epoch: 30 cost time: 5.7499589920043945
Epoch: 30, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5369 + XiCon Loss:2.8745 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5604650
	speed: 0.0257s/iter; left time: 426.2671s
	iters: 200, epoch: 31 | loss: 0.5635287
	speed: 0.0231s/iter; left time: 381.0497s
Epoch: 31 cost time: 5.779533624649048
Epoch: 31, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5366 + XiCon Loss:2.8713 x Lambda(0.01)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5788835
	speed: 0.0258s/iter; left time: 421.1018s
	iters: 200, epoch: 32 | loss: 0.5387703
	speed: 0.0230s/iter; left time: 373.1865s
Epoch: 32 cost time: 5.821787118911743
Epoch: 32, Steps: 238 Train Loss: 0.5656 (Forecasting Loss:0.5369 + XiCon Loss:2.8757 x Lambda(0.01)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.6257889
	speed: 0.0258s/iter; left time: 414.2983s
	iters: 200, epoch: 33 | loss: 0.5573832
	speed: 0.0242s/iter; left time: 387.0931s
Epoch: 33 cost time: 5.876463413238525
Epoch: 33, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5367 + XiCon Loss:2.8723 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5325553
	speed: 0.0251s/iter; left time: 397.3676s
	iters: 200, epoch: 34 | loss: 0.5965604
	speed: 0.0238s/iter; left time: 375.4059s
Epoch: 34 cost time: 5.7987611293792725
Epoch: 34, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8673 x Lambda(0.01)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5907238
	speed: 0.0260s/iter; left time: 406.4707s
	iters: 200, epoch: 35 | loss: 0.5454212
	speed: 0.0229s/iter; left time: 355.0451s
Epoch: 35 cost time: 5.7704102993011475
Epoch: 35, Steps: 238 Train Loss: 0.5653 (Forecasting Loss:0.5366 + XiCon Loss:2.8699 x Lambda(0.01)), Vali MSE Loss: 0.9958 Test MSE Loss: 0.8645
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5119039
	speed: 0.0247s/iter; left time: 380.3666s
	iters: 200, epoch: 36 | loss: 0.5568123
	speed: 0.0230s/iter; left time: 351.6453s
Epoch: 36 cost time: 5.687268257141113
Epoch: 36, Steps: 238 Train Loss: 0.5654 (Forecasting Loss:0.5367 + XiCon Loss:2.8729 x Lambda(0.01)), Vali MSE Loss: 0.9967 Test MSE Loss: 0.8645
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5277532
	speed: 0.0250s/iter; left time: 378.5152s
	iters: 200, epoch: 37 | loss: 0.5712970
	speed: 0.0227s/iter; left time: 340.9376s
Epoch: 37 cost time: 5.700251340866089
Epoch: 37, Steps: 238 Train Loss: 0.5655 (Forecasting Loss:0.5367 + XiCon Loss:2.8728 x Lambda(0.01)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9971227645874023, mae:0.7319387793540955, mape:5.07988977432251, mspe:3079.934326171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.7468
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0952971
	speed: 0.0256s/iter; left time: 606.2890s
	iters: 200, epoch: 1 | loss: 1.1228008
	speed: 0.0232s/iter; left time: 546.8734s
Epoch: 1 cost time: 5.796706199645996
Epoch: 1, Steps: 238 Train Loss: 1.2250 (Forecasting Loss:1.1962 + XiCon Loss:2.8802 x Lambda(0.01)), Vali MSE Loss: 2.1664 Test MSE Loss: 1.1068
Validation loss decreased (inf --> 2.166445).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8029009
	speed: 0.0254s/iter; left time: 595.4277s
	iters: 200, epoch: 2 | loss: 0.5987145
	speed: 0.0226s/iter; left time: 529.0547s
Epoch: 2 cost time: 5.691526889801025
Epoch: 2, Steps: 238 Train Loss: 0.7570 (Forecasting Loss:0.7283 + XiCon Loss:2.8759 x Lambda(0.01)), Vali MSE Loss: 1.0373 Test MSE Loss: 0.8756
Validation loss decreased (2.166445 --> 1.037330).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6260339
	speed: 0.0256s/iter; left time: 595.1652s
	iters: 200, epoch: 3 | loss: 0.6132786
	speed: 0.0220s/iter; left time: 508.0438s
Epoch: 3 cost time: 5.735650539398193
Epoch: 3, Steps: 238 Train Loss: 0.5893 (Forecasting Loss:0.5606 + XiCon Loss:2.8752 x Lambda(0.01)), Vali MSE Loss: 1.0330 Test MSE Loss: 0.8586
Validation loss decreased (1.037330 --> 1.033034).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5962701
	speed: 0.0251s/iter; left time: 576.2464s
	iters: 200, epoch: 4 | loss: 0.5993723
	speed: 0.0227s/iter; left time: 520.2702s
Epoch: 4 cost time: 5.6785383224487305
Epoch: 4, Steps: 238 Train Loss: 0.5768 (Forecasting Loss:0.5480 + XiCon Loss:2.8827 x Lambda(0.01)), Vali MSE Loss: 1.0257 Test MSE Loss: 0.8553
Validation loss decreased (1.033034 --> 1.025681).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5578346
	speed: 0.0258s/iter; left time: 586.7670s
	iters: 200, epoch: 5 | loss: 0.5383259
	speed: 0.0225s/iter; left time: 509.5728s
Epoch: 5 cost time: 5.693399429321289
Epoch: 5, Steps: 238 Train Loss: 0.5736 (Forecasting Loss:0.5447 + XiCon Loss:2.8837 x Lambda(0.01)), Vali MSE Loss: 1.0208 Test MSE Loss: 0.8542
Validation loss decreased (1.025681 --> 1.020794).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5756307
	speed: 0.0251s/iter; left time: 564.1097s
	iters: 200, epoch: 6 | loss: 0.5528748
	speed: 0.0233s/iter; left time: 522.7717s
Epoch: 6 cost time: 5.789412498474121
Epoch: 6, Steps: 238 Train Loss: 0.5719 (Forecasting Loss:0.5431 + XiCon Loss:2.8809 x Lambda(0.01)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8539
Validation loss decreased (1.020794 --> 1.020288).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6014898
	speed: 0.0245s/iter; left time: 546.3398s
	iters: 200, epoch: 7 | loss: 0.5180159
	speed: 0.0230s/iter; left time: 510.5765s
Epoch: 7 cost time: 5.624203205108643
Epoch: 7, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5419 + XiCon Loss:2.8799 x Lambda(0.01)), Vali MSE Loss: 1.0209 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5857650
	speed: 0.0250s/iter; left time: 551.7097s
	iters: 200, epoch: 8 | loss: 0.6425453
	speed: 0.0223s/iter; left time: 489.9380s
Epoch: 8 cost time: 5.651510000228882
Epoch: 8, Steps: 238 Train Loss: 0.5706 (Forecasting Loss:0.5417 + XiCon Loss:2.8862 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8536
Validation loss decreased (1.020288 --> 1.019094).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5799016
	speed: 0.0256s/iter; left time: 557.6694s
	iters: 200, epoch: 9 | loss: 0.5633500
	speed: 0.0217s/iter; left time: 470.2584s
Epoch: 9 cost time: 5.6475300788879395
Epoch: 9, Steps: 238 Train Loss: 0.5703 (Forecasting Loss:0.5415 + XiCon Loss:2.8812 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5831878
	speed: 0.0258s/iter; left time: 555.8308s
	iters: 200, epoch: 10 | loss: 0.5920075
	speed: 0.0230s/iter; left time: 492.6808s
Epoch: 10 cost time: 5.741457462310791
Epoch: 10, Steps: 238 Train Loss: 0.5703 (Forecasting Loss:0.5415 + XiCon Loss:2.8836 x Lambda(0.01)), Vali MSE Loss: 1.0197 Test MSE Loss: 0.8536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5478335
	speed: 0.0262s/iter; left time: 557.7970s
	iters: 200, epoch: 11 | loss: 0.5453529
	speed: 0.0235s/iter; left time: 498.6953s
Epoch: 11 cost time: 5.858760833740234
Epoch: 11, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5414 + XiCon Loss:2.8784 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019094 --> 1.019032).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5586243
	speed: 0.0254s/iter; left time: 534.5850s
	iters: 200, epoch: 12 | loss: 0.5510483
	speed: 0.0228s/iter; left time: 478.5319s
Epoch: 12 cost time: 5.7206244468688965
Epoch: 12, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5412 + XiCon Loss:2.8791 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
Validation loss decreased (1.019032 --> 1.019010).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5544755
	speed: 0.0254s/iter; left time: 529.6247s
	iters: 200, epoch: 13 | loss: 0.6297467
	speed: 0.0228s/iter; left time: 472.5587s
Epoch: 13 cost time: 5.730660915374756
Epoch: 13, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5414 + XiCon Loss:2.8785 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6276070
	speed: 0.0250s/iter; left time: 515.5425s
	iters: 200, epoch: 14 | loss: 0.5802508
	speed: 0.0230s/iter; left time: 471.2006s
Epoch: 14 cost time: 5.682175874710083
Epoch: 14, Steps: 238 Train Loss: 0.5699 (Forecasting Loss:0.5411 + XiCon Loss:2.8806 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5618358
	speed: 0.0262s/iter; left time: 533.3357s
	iters: 200, epoch: 15 | loss: 0.5891088
	speed: 0.0227s/iter; left time: 459.6377s
Epoch: 15 cost time: 5.803009271621704
Epoch: 15, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5414 + XiCon Loss:2.8787 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5596241
	speed: 0.0251s/iter; left time: 505.0707s
	iters: 200, epoch: 16 | loss: 0.5492840
	speed: 0.0230s/iter; left time: 459.8231s
Epoch: 16 cost time: 5.729202747344971
Epoch: 16, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5414 + XiCon Loss:2.8799 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
Validation loss decreased (1.019010 --> 1.018904).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5656470
	speed: 0.0261s/iter; left time: 519.5063s
	iters: 200, epoch: 17 | loss: 0.5619970
	speed: 0.0230s/iter; left time: 454.6183s
Epoch: 17 cost time: 5.8246009349823
Epoch: 17, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5412 + XiCon Loss:2.8778 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5511433
	speed: 0.0257s/iter; left time: 504.7656s
	iters: 200, epoch: 18 | loss: 0.6206348
	speed: 0.0228s/iter; left time: 446.2791s
Epoch: 18 cost time: 5.78020453453064
Epoch: 18, Steps: 238 Train Loss: 0.5695 (Forecasting Loss:0.5407 + XiCon Loss:2.8807 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6311030
	speed: 0.0260s/iter; left time: 504.2835s
	iters: 200, epoch: 19 | loss: 0.6054590
	speed: 0.0220s/iter; left time: 424.9504s
Epoch: 19 cost time: 5.686398029327393
Epoch: 19, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5411 + XiCon Loss:2.8818 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6077948
	speed: 0.0247s/iter; left time: 473.0333s
	iters: 200, epoch: 20 | loss: 0.5966123
	speed: 0.0228s/iter; left time: 434.5006s
Epoch: 20 cost time: 5.6348536014556885
Epoch: 20, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5413 + XiCon Loss:2.8812 x Lambda(0.01)), Vali MSE Loss: 1.0201 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6225594
	speed: 0.0251s/iter; left time: 475.4322s
	iters: 200, epoch: 21 | loss: 0.5281534
	speed: 0.0228s/iter; left time: 429.0559s
Epoch: 21 cost time: 5.67939019203186
Epoch: 21, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5413 + XiCon Loss:2.8821 x Lambda(0.01)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5528178
	speed: 0.0253s/iter; left time: 473.7708s
	iters: 200, epoch: 22 | loss: 0.5822601
	speed: 0.0227s/iter; left time: 422.6313s
Epoch: 22 cost time: 5.700620412826538
Epoch: 22, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5412 + XiCon Loss:2.8826 x Lambda(0.01)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6156952
	speed: 0.0253s/iter; left time: 466.4641s
	iters: 200, epoch: 23 | loss: 0.5905112
	speed: 0.0235s/iter; left time: 431.1907s
Epoch: 23 cost time: 5.764909029006958
Epoch: 23, Steps: 238 Train Loss: 0.5699 (Forecasting Loss:0.5412 + XiCon Loss:2.8790 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5940852
	speed: 0.0252s/iter; left time: 458.9662s
	iters: 200, epoch: 24 | loss: 0.5568951
	speed: 0.0228s/iter; left time: 412.7654s
Epoch: 24 cost time: 5.674192667007446
Epoch: 24, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5411 + XiCon Loss:2.8841 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5741090
	speed: 0.0257s/iter; left time: 461.6965s
	iters: 200, epoch: 25 | loss: 0.5916134
	speed: 0.0222s/iter; left time: 396.7828s
Epoch: 25 cost time: 5.680561542510986
Epoch: 25, Steps: 238 Train Loss: 0.5705 (Forecasting Loss:0.5417 + XiCon Loss:2.8784 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5567889
	speed: 0.0260s/iter; left time: 461.9575s
	iters: 200, epoch: 26 | loss: 0.5944813
	speed: 0.0235s/iter; left time: 415.2428s
Epoch: 26 cost time: 5.887953281402588
Epoch: 26, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5413 + XiCon Loss:2.8827 x Lambda(0.01)), Vali MSE Loss: 1.0185 Test MSE Loss: 0.8535
Validation loss decreased (1.018904 --> 1.018517).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5539865
	speed: 0.0259s/iter; left time: 453.0874s
	iters: 200, epoch: 27 | loss: 0.5567304
	speed: 0.0231s/iter; left time: 402.9134s
Epoch: 27 cost time: 5.827451229095459
Epoch: 27, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5413 + XiCon Loss:2.8795 x Lambda(0.01)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8535
Validation loss decreased (1.018517 --> 1.018101).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6199467
	speed: 0.0252s/iter; left time: 434.6107s
	iters: 200, epoch: 28 | loss: 0.5550960
	speed: 0.0235s/iter; left time: 403.2724s
Epoch: 28 cost time: 5.755879878997803
Epoch: 28, Steps: 238 Train Loss: 0.5695 (Forecasting Loss:0.5407 + XiCon Loss:2.8809 x Lambda(0.01)), Vali MSE Loss: 1.0190 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5709592
	speed: 0.0259s/iter; left time: 441.0832s
	iters: 200, epoch: 29 | loss: 0.5722224
	speed: 0.0230s/iter; left time: 389.0149s
Epoch: 29 cost time: 5.776845216751099
Epoch: 29, Steps: 238 Train Loss: 0.5699 (Forecasting Loss:0.5412 + XiCon Loss:2.8753 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5679455
	speed: 0.0258s/iter; left time: 434.2389s
	iters: 200, epoch: 30 | loss: 0.5531991
	speed: 0.0225s/iter; left time: 375.7742s
Epoch: 30 cost time: 5.730436325073242
Epoch: 30, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5412 + XiCon Loss:2.8833 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5854301
	speed: 0.0262s/iter; left time: 434.4854s
	iters: 200, epoch: 31 | loss: 0.5673112
	speed: 0.0224s/iter; left time: 368.4302s
Epoch: 31 cost time: 5.753433465957642
Epoch: 31, Steps: 238 Train Loss: 0.5702 (Forecasting Loss:0.5414 + XiCon Loss:2.8807 x Lambda(0.01)), Vali MSE Loss: 1.0202 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5239459
	speed: 0.0249s/iter; left time: 406.8853s
	iters: 200, epoch: 32 | loss: 0.6092176
	speed: 0.0232s/iter; left time: 376.1600s
Epoch: 32 cost time: 5.693623065948486
Epoch: 32, Steps: 238 Train Loss: 0.5703 (Forecasting Loss:0.5415 + XiCon Loss:2.8768 x Lambda(0.01)), Vali MSE Loss: 1.0192 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5069209
	speed: 0.0245s/iter; left time: 394.6244s
	iters: 200, epoch: 33 | loss: 0.5414032
	speed: 0.0227s/iter; left time: 363.6508s
Epoch: 33 cost time: 5.620047092437744
Epoch: 33, Steps: 238 Train Loss: 0.5696 (Forecasting Loss:0.5408 + XiCon Loss:2.8835 x Lambda(0.01)), Vali MSE Loss: 1.0195 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5686272
	speed: 0.0257s/iter; left time: 407.3163s
	iters: 200, epoch: 34 | loss: 0.5632761
	speed: 0.0226s/iter; left time: 356.3030s
Epoch: 34 cost time: 5.738688945770264
Epoch: 34, Steps: 238 Train Loss: 0.5701 (Forecasting Loss:0.5413 + XiCon Loss:2.8839 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5593303
	speed: 0.0263s/iter; left time: 409.8570s
	iters: 200, epoch: 35 | loss: 0.5872166
	speed: 0.0231s/iter; left time: 358.9490s
Epoch: 35 cost time: 5.835487127304077
Epoch: 35, Steps: 238 Train Loss: 0.5699 (Forecasting Loss:0.5411 + XiCon Loss:2.8812 x Lambda(0.01)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5779278
	speed: 0.0257s/iter; left time: 394.3934s
	iters: 200, epoch: 36 | loss: 0.5787712
	speed: 0.0232s/iter; left time: 353.6470s
Epoch: 36 cost time: 5.8006627559661865
Epoch: 36, Steps: 238 Train Loss: 0.5700 (Forecasting Loss:0.5412 + XiCon Loss:2.8792 x Lambda(0.01)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5594440
	speed: 0.0251s/iter; left time: 379.1457s
	iters: 200, epoch: 37 | loss: 0.5969802
	speed: 0.0224s/iter; left time: 336.5445s
Epoch: 37 cost time: 5.684917688369751
Epoch: 37, Steps: 238 Train Loss: 0.5698 (Forecasting Loss:0.5411 + XiCon Loss:2.8782 x Lambda(0.01)), Vali MSE Loss: 1.0188 Test MSE Loss: 0.8535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9859724640846252, mae:0.7210718393325806, mape:4.676816940307617, mspe:2546.459716796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.0879
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9743266
	speed: 0.0253s/iter; left time: 599.7256s
	iters: 200, epoch: 1 | loss: 1.0275636
	speed: 0.0221s/iter; left time: 521.9722s
Epoch: 1 cost time: 5.6288275718688965
Epoch: 1, Steps: 238 Train Loss: 1.0555 (Forecasting Loss:1.0271 + XiCon Loss:2.8455 x Lambda(0.01)), Vali MSE Loss: 1.8388 Test MSE Loss: 0.9830
Validation loss decreased (inf --> 1.838782).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6529967
	speed: 0.0249s/iter; left time: 583.5434s
	iters: 200, epoch: 2 | loss: 0.5410570
	speed: 0.0226s/iter; left time: 529.0190s
Epoch: 2 cost time: 5.648157835006714
Epoch: 2, Steps: 238 Train Loss: 0.6518 (Forecasting Loss:0.6233 + XiCon Loss:2.8417 x Lambda(0.01)), Vali MSE Loss: 1.0469 Test MSE Loss: 0.8597
Validation loss decreased (1.838782 --> 1.046910).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6001481
	speed: 0.0253s/iter; left time: 588.6279s
	iters: 200, epoch: 3 | loss: 0.6096597
	speed: 0.0217s/iter; left time: 502.2652s
Epoch: 3 cost time: 5.617345571517944
Epoch: 3, Steps: 238 Train Loss: 0.5830 (Forecasting Loss:0.5546 + XiCon Loss:2.8366 x Lambda(0.01)), Vali MSE Loss: 1.0221 Test MSE Loss: 0.8525
Validation loss decreased (1.046910 --> 1.022091).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6001799
	speed: 0.0243s/iter; left time: 559.5230s
	iters: 200, epoch: 4 | loss: 0.6142827
	speed: 0.0223s/iter; left time: 509.9268s
Epoch: 4 cost time: 5.536033630371094
Epoch: 4, Steps: 238 Train Loss: 0.5743 (Forecasting Loss:0.5459 + XiCon Loss:2.8373 x Lambda(0.01)), Vali MSE Loss: 1.0136 Test MSE Loss: 0.8513
Validation loss decreased (1.022091 --> 1.013553).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5934007
	speed: 0.0245s/iter; left time: 557.5576s
	iters: 200, epoch: 5 | loss: 0.5968660
	speed: 0.0218s/iter; left time: 493.8692s
Epoch: 5 cost time: 5.486114978790283
Epoch: 5, Steps: 238 Train Loss: 0.5707 (Forecasting Loss:0.5424 + XiCon Loss:2.8343 x Lambda(0.01)), Vali MSE Loss: 1.0108 Test MSE Loss: 0.8508
Validation loss decreased (1.013553 --> 1.010786).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5470275
	speed: 0.0256s/iter; left time: 577.0996s
	iters: 200, epoch: 6 | loss: 0.5551460
	speed: 0.0228s/iter; left time: 511.8603s
Epoch: 6 cost time: 5.711132526397705
Epoch: 6, Steps: 238 Train Loss: 0.5691 (Forecasting Loss:0.5408 + XiCon Loss:2.8332 x Lambda(0.01)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8504
Validation loss decreased (1.010786 --> 1.008182).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5967749
	speed: 0.0249s/iter; left time: 554.1614s
	iters: 200, epoch: 7 | loss: 0.5872671
	speed: 0.0226s/iter; left time: 501.7093s
Epoch: 7 cost time: 5.636587858200073
Epoch: 7, Steps: 238 Train Loss: 0.5684 (Forecasting Loss:0.5400 + XiCon Loss:2.8381 x Lambda(0.01)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8503
Validation loss decreased (1.008182 --> 1.007907).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6269450
	speed: 0.0246s/iter; left time: 542.6788s
	iters: 200, epoch: 8 | loss: 0.5471188
	speed: 0.0229s/iter; left time: 503.2898s
Epoch: 8 cost time: 5.661803722381592
Epoch: 8, Steps: 238 Train Loss: 0.5679 (Forecasting Loss:0.5395 + XiCon Loss:2.8342 x Lambda(0.01)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8503
Validation loss decreased (1.007907 --> 1.006864).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5441554
	speed: 0.0251s/iter; left time: 546.8794s
	iters: 200, epoch: 9 | loss: 0.5297574
	speed: 0.0227s/iter; left time: 492.8967s
Epoch: 9 cost time: 5.667910575866699
Epoch: 9, Steps: 238 Train Loss: 0.5678 (Forecasting Loss:0.5394 + XiCon Loss:2.8368 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
Validation loss decreased (1.006864 --> 1.006318).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5400204
	speed: 0.0247s/iter; left time: 531.7185s
	iters: 200, epoch: 10 | loss: 0.5753238
	speed: 0.0225s/iter; left time: 481.9728s
Epoch: 10 cost time: 5.605101585388184
Epoch: 10, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5391 + XiCon Loss:2.8367 x Lambda(0.01)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.8502
Validation loss decreased (1.006318 --> 1.005906).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6408206
	speed: 0.0254s/iter; left time: 541.0958s
	iters: 200, epoch: 11 | loss: 0.5588352
	speed: 0.0223s/iter; left time: 473.1529s
Epoch: 11 cost time: 5.645871162414551
Epoch: 11, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5388 + XiCon Loss:2.8361 x Lambda(0.01)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5605531
	speed: 0.0245s/iter; left time: 517.1260s
	iters: 200, epoch: 12 | loss: 0.5524250
	speed: 0.0226s/iter; left time: 474.4733s
Epoch: 12 cost time: 5.575263977050781
Epoch: 12, Steps: 238 Train Loss: 0.5676 (Forecasting Loss:0.5392 + XiCon Loss:2.8382 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6105834
	speed: 0.0257s/iter; left time: 535.5392s
	iters: 200, epoch: 13 | loss: 0.5963081
	speed: 0.0221s/iter; left time: 458.1011s
Epoch: 13 cost time: 5.6680004596710205
Epoch: 13, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8388 x Lambda(0.01)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5940284
	speed: 0.0245s/iter; left time: 505.4344s
	iters: 200, epoch: 14 | loss: 0.5299206
	speed: 0.0227s/iter; left time: 465.4604s
Epoch: 14 cost time: 5.6059730052948
Epoch: 14, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8394 x Lambda(0.01)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5509918
	speed: 0.0245s/iter; left time: 498.5015s
	iters: 200, epoch: 15 | loss: 0.6128579
	speed: 0.0217s/iter; left time: 440.5040s
Epoch: 15 cost time: 5.509166717529297
Epoch: 15, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5389 + XiCon Loss:2.8347 x Lambda(0.01)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5455500
	speed: 0.0247s/iter; left time: 497.2203s
	iters: 200, epoch: 16 | loss: 0.5470769
	speed: 0.0234s/iter; left time: 467.8880s
Epoch: 16 cost time: 5.698802471160889
Epoch: 16, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8383 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
Validation loss decreased (1.005906 --> 1.005732).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5754101
	speed: 0.0245s/iter; left time: 486.8445s
	iters: 200, epoch: 17 | loss: 0.5316449
	speed: 0.0226s/iter; left time: 447.0593s
Epoch: 17 cost time: 5.58331298828125
Epoch: 17, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5389 + XiCon Loss:2.8341 x Lambda(0.01)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8502
Validation loss decreased (1.005732 --> 1.004936).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5225248
	speed: 0.0249s/iter; left time: 489.6023s
	iters: 200, epoch: 18 | loss: 0.6427440
	speed: 0.0218s/iter; left time: 425.3611s
Epoch: 18 cost time: 5.581469297409058
Epoch: 18, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8387 x Lambda(0.01)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5396208
	speed: 0.0250s/iter; left time: 485.5757s
	iters: 200, epoch: 19 | loss: 0.5276843
	speed: 0.0226s/iter; left time: 436.1680s
Epoch: 19 cost time: 5.658348321914673
Epoch: 19, Steps: 238 Train Loss: 0.5672 (Forecasting Loss:0.5388 + XiCon Loss:2.8336 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6210126
	speed: 0.0242s/iter; left time: 464.6579s
	iters: 200, epoch: 20 | loss: 0.5493076
	speed: 0.0229s/iter; left time: 436.3467s
Epoch: 20 cost time: 5.581162452697754
Epoch: 20, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5391 + XiCon Loss:2.8346 x Lambda(0.01)), Vali MSE Loss: 1.0060 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5461623
	speed: 0.0245s/iter; left time: 464.7515s
	iters: 200, epoch: 21 | loss: 0.6106256
	speed: 0.0222s/iter; left time: 417.6113s
Epoch: 21 cost time: 5.537353038787842
Epoch: 21, Steps: 238 Train Loss: 0.5676 (Forecasting Loss:0.5392 + XiCon Loss:2.8360 x Lambda(0.01)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6044231
	speed: 0.0252s/iter; left time: 471.1224s
	iters: 200, epoch: 22 | loss: 0.5967882
	speed: 0.0220s/iter; left time: 408.9389s
Epoch: 22 cost time: 5.632589817047119
Epoch: 22, Steps: 238 Train Loss: 0.5673 (Forecasting Loss:0.5390 + XiCon Loss:2.8344 x Lambda(0.01)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5704349
	speed: 0.0239s/iter; left time: 441.1828s
	iters: 200, epoch: 23 | loss: 0.6113793
	speed: 0.0223s/iter; left time: 410.3755s
Epoch: 23 cost time: 5.519463539123535
Epoch: 23, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5390 + XiCon Loss:2.8396 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4960992
	speed: 0.0251s/iter; left time: 456.6110s
	iters: 200, epoch: 24 | loss: 0.5319512
	speed: 0.0229s/iter; left time: 415.5800s
Epoch: 24 cost time: 5.684905529022217
Epoch: 24, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8375 x Lambda(0.01)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5912500
	speed: 0.0251s/iter; left time: 450.9722s
	iters: 200, epoch: 25 | loss: 0.5584514
	speed: 0.0224s/iter; left time: 400.2534s
Epoch: 25 cost time: 5.627781629562378
Epoch: 25, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5391 + XiCon Loss:2.8370 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5484930
	speed: 0.0249s/iter; left time: 441.6817s
	iters: 200, epoch: 26 | loss: 0.5905071
	speed: 0.0227s/iter; left time: 400.9998s
Epoch: 26 cost time: 5.642045736312866
Epoch: 26, Steps: 238 Train Loss: 0.5674 (Forecasting Loss:0.5390 + XiCon Loss:2.8383 x Lambda(0.01)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5657272
	speed: 0.0254s/iter; left time: 445.5322s
	iters: 200, epoch: 27 | loss: 0.5368126
	speed: 0.0216s/iter; left time: 375.9310s
Epoch: 27 cost time: 5.594774007797241
Epoch: 27, Steps: 238 Train Loss: 0.5675 (Forecasting Loss:0.5391 + XiCon Loss:2.8399 x Lambda(0.01)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9806081056594849, mae:0.7197725772857666, mape:4.739025592803955, mspe:2656.31201171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9841+-0.00979, MAE:0.7227+-0.00649, MAPE:4.8127+-0.19336, MSPE:2733.8430+-251.57570, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.4358
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 0.9936880
	speed: 0.0324s/iter; left time: 751.2173s
	iters: 200, epoch: 1 | loss: 0.9471508
	speed: 0.0274s/iter; left time: 632.8596s
Epoch: 1 cost time: 6.901180267333984
Epoch: 1, Steps: 233 Train Loss: 1.0471 (Forecasting Loss:1.0189 + XiCon Loss:2.8191 x Lambda(0.01)), Vali MSE Loss: 1.8606 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860587).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6290566
	speed: 0.0299s/iter; left time: 686.5082s
	iters: 200, epoch: 2 | loss: 0.6917337
	speed: 0.0278s/iter; left time: 634.6778s
Epoch: 2 cost time: 6.705187082290649
Epoch: 2, Steps: 233 Train Loss: 0.6804 (Forecasting Loss:0.6522 + XiCon Loss:2.8144 x Lambda(0.01)), Vali MSE Loss: 1.1270 Test MSE Loss: 1.1495
Validation loss decreased (1.860587 --> 1.126961).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6560236
	speed: 0.0298s/iter; left time: 677.3273s
	iters: 200, epoch: 3 | loss: 0.5987809
	speed: 0.0284s/iter; left time: 642.1637s
Epoch: 3 cost time: 6.7699830532073975
Epoch: 3, Steps: 233 Train Loss: 0.6162 (Forecasting Loss:0.5881 + XiCon Loss:2.8081 x Lambda(0.01)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1437
Validation loss decreased (1.126961 --> 1.104182).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6235247
	speed: 0.0305s/iter; left time: 685.9489s
	iters: 200, epoch: 4 | loss: 0.6221098
	speed: 0.0275s/iter; left time: 615.0794s
Epoch: 4 cost time: 6.718098163604736
Epoch: 4, Steps: 233 Train Loss: 0.6080 (Forecasting Loss:0.5799 + XiCon Loss:2.8061 x Lambda(0.01)), Vali MSE Loss: 1.0969 Test MSE Loss: 1.1410
Validation loss decreased (1.104182 --> 1.096879).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5966830
	speed: 0.0297s/iter; left time: 660.9222s
	iters: 200, epoch: 5 | loss: 0.5937693
	speed: 0.0281s/iter; left time: 622.3709s
Epoch: 5 cost time: 6.744116544723511
Epoch: 5, Steps: 233 Train Loss: 0.6047 (Forecasting Loss:0.5767 + XiCon Loss:2.8077 x Lambda(0.01)), Vali MSE Loss: 1.0935 Test MSE Loss: 1.1402
Validation loss decreased (1.096879 --> 1.093452).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6177443
	speed: 0.0308s/iter; left time: 678.9073s
	iters: 200, epoch: 6 | loss: 0.6279908
	speed: 0.0277s/iter; left time: 608.3991s
Epoch: 6 cost time: 6.800382852554321
Epoch: 6, Steps: 233 Train Loss: 0.6033 (Forecasting Loss:0.5752 + XiCon Loss:2.8100 x Lambda(0.01)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1398
Validation loss decreased (1.093452 --> 1.091759).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5933388
	speed: 0.0301s/iter; left time: 656.3038s
	iters: 200, epoch: 7 | loss: 0.6489985
	speed: 0.0279s/iter; left time: 604.4684s
Epoch: 7 cost time: 6.7082507610321045
Epoch: 7, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5744 + XiCon Loss:2.8063 x Lambda(0.01)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1398
Validation loss decreased (1.091759 --> 1.090914).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5712497
	speed: 0.0309s/iter; left time: 667.0220s
	iters: 200, epoch: 8 | loss: 0.6145636
	speed: 0.0287s/iter; left time: 616.4696s
Epoch: 8 cost time: 6.908874034881592
Epoch: 8, Steps: 233 Train Loss: 0.6021 (Forecasting Loss:0.5740 + XiCon Loss:2.8099 x Lambda(0.01)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1397
Validation loss decreased (1.090914 --> 1.090772).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6477105
	speed: 0.0308s/iter; left time: 656.7236s
	iters: 200, epoch: 9 | loss: 0.6466975
	speed: 0.0280s/iter; left time: 594.9305s
Epoch: 9 cost time: 6.796567440032959
Epoch: 9, Steps: 233 Train Loss: 0.6019 (Forecasting Loss:0.5738 + XiCon Loss:2.8112 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
Validation loss decreased (1.090772 --> 1.090310).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5695022
	speed: 0.0278s/iter; left time: 586.1130s
	iters: 200, epoch: 10 | loss: 0.5919986
	speed: 0.0238s/iter; left time: 500.0876s
Epoch: 10 cost time: 6.05589747428894
Epoch: 10, Steps: 233 Train Loss: 0.6018 (Forecasting Loss:0.5737 + XiCon Loss:2.8079 x Lambda(0.01)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5879730
	speed: 0.0305s/iter; left time: 636.9151s
	iters: 200, epoch: 11 | loss: 0.6125221
	speed: 0.0282s/iter; left time: 585.0934s
Epoch: 11 cost time: 6.852551460266113
Epoch: 11, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8056 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
Validation loss decreased (1.090310 --> 1.090098).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6148531
	speed: 0.0301s/iter; left time: 621.2736s
	iters: 200, epoch: 12 | loss: 0.6019027
	speed: 0.0280s/iter; left time: 575.1796s
Epoch: 12 cost time: 6.794733047485352
Epoch: 12, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8045 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.090098 --> 1.089937).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5893894
	speed: 0.0292s/iter; left time: 596.1564s
	iters: 200, epoch: 13 | loss: 0.6137028
	speed: 0.0275s/iter; left time: 558.9627s
Epoch: 13 cost time: 6.6410393714904785
Epoch: 13, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8084 x Lambda(0.01)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1396
Validation loss decreased (1.089937 --> 1.089879).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6132529
	speed: 0.0305s/iter; left time: 615.9016s
	iters: 200, epoch: 14 | loss: 0.5950214
	speed: 0.0280s/iter; left time: 562.6027s
Epoch: 14 cost time: 6.785816192626953
Epoch: 14, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8036 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5848419
	speed: 0.0302s/iter; left time: 601.2773s
	iters: 200, epoch: 15 | loss: 0.6379386
	speed: 0.0280s/iter; left time: 556.2001s
Epoch: 15 cost time: 6.767092227935791
Epoch: 15, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8059 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6177087
	speed: 0.0306s/iter; left time: 603.4814s
	iters: 200, epoch: 16 | loss: 0.6286022
	speed: 0.0280s/iter; left time: 549.0157s
Epoch: 16 cost time: 6.808111667633057
Epoch: 16, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8055 x Lambda(0.01)), Vali MSE Loss: 1.0895 Test MSE Loss: 1.1396
Validation loss decreased (1.089879 --> 1.089468).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5947022
	speed: 0.0294s/iter; left time: 572.3741s
	iters: 200, epoch: 17 | loss: 0.5868692
	speed: 0.0279s/iter; left time: 540.7186s
Epoch: 17 cost time: 6.676234245300293
Epoch: 17, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8034 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6380962
	speed: 0.0287s/iter; left time: 552.4732s
	iters: 200, epoch: 18 | loss: 0.6084454
	speed: 0.0275s/iter; left time: 526.8094s
Epoch: 18 cost time: 6.552618741989136
Epoch: 18, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8068 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5910422
	speed: 0.0301s/iter; left time: 572.3647s
	iters: 200, epoch: 19 | loss: 0.6809225
	speed: 0.0281s/iter; left time: 531.2041s
Epoch: 19 cost time: 6.769967079162598
Epoch: 19, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8080 x Lambda(0.01)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1396
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5739216
	speed: 0.0302s/iter; left time: 566.0683s
	iters: 200, epoch: 20 | loss: 0.5807082
	speed: 0.0288s/iter; left time: 538.6002s
Epoch: 20 cost time: 6.851959705352783
Epoch: 20, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8062 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6013101
	speed: 0.0307s/iter; left time: 569.5907s
	iters: 200, epoch: 21 | loss: 0.5821166
	speed: 0.0276s/iter; left time: 508.1496s
Epoch: 21 cost time: 6.775609016418457
Epoch: 21, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8073 x Lambda(0.01)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1396
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5747752
	speed: 0.0298s/iter; left time: 544.9992s
	iters: 200, epoch: 22 | loss: 0.5767455
	speed: 0.0279s/iter; left time: 507.5280s
Epoch: 22 cost time: 6.696165084838867
Epoch: 22, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8082 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5450916
	speed: 0.0291s/iter; left time: 526.0508s
	iters: 200, epoch: 23 | loss: 0.6018607
	speed: 0.0273s/iter; left time: 491.5630s
Epoch: 23 cost time: 6.544850587844849
Epoch: 23, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8039 x Lambda(0.01)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1396
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5906722
	speed: 0.0305s/iter; left time: 544.7602s
	iters: 200, epoch: 24 | loss: 0.5742178
	speed: 0.0280s/iter; left time: 496.6141s
Epoch: 24 cost time: 6.844402074813843
Epoch: 24, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5735 + XiCon Loss:2.8080 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5985199
	speed: 0.0294s/iter; left time: 518.5579s
	iters: 200, epoch: 25 | loss: 0.5764410
	speed: 0.0278s/iter; left time: 486.7236s
Epoch: 25 cost time: 6.660158395767212
Epoch: 25, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5736 + XiCon Loss:2.8112 x Lambda(0.01)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1396
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5759081
	speed: 0.0302s/iter; left time: 525.5575s
	iters: 200, epoch: 26 | loss: 0.6444759
	speed: 0.0284s/iter; left time: 490.3389s
Epoch: 26 cost time: 6.7984442710876465
Epoch: 26, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5736 + XiCon Loss:2.8012 x Lambda(0.01)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1396
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3994559049606323, mae:0.8796807527542114, mape:6.13773250579834, mspe:4546.107421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.5221
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1782428
	speed: 0.0307s/iter; left time: 711.4567s
	iters: 200, epoch: 1 | loss: 1.1397628
	speed: 0.0282s/iter; left time: 651.8576s
Epoch: 1 cost time: 6.850363492965698
Epoch: 1, Steps: 233 Train Loss: 1.1625 (Forecasting Loss:1.1341 + XiCon Loss:2.8418 x Lambda(0.01)), Vali MSE Loss: 2.0405 Test MSE Loss: 1.3313
Validation loss decreased (inf --> 2.040482).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7085614
	speed: 0.0310s/iter; left time: 711.1850s
	iters: 200, epoch: 2 | loss: 0.6237829
	speed: 0.0280s/iter; left time: 640.2074s
Epoch: 2 cost time: 6.834841966629028
Epoch: 2, Steps: 233 Train Loss: 0.6883 (Forecasting Loss:0.6598 + XiCon Loss:2.8417 x Lambda(0.01)), Vali MSE Loss: 1.1148 Test MSE Loss: 1.1427
Validation loss decreased (2.040482 --> 1.114843).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6014542
	speed: 0.0287s/iter; left time: 651.6378s
	iters: 200, epoch: 3 | loss: 0.5923413
	speed: 0.0274s/iter; left time: 621.0690s
Epoch: 3 cost time: 6.559215068817139
Epoch: 3, Steps: 233 Train Loss: 0.6158 (Forecasting Loss:0.5874 + XiCon Loss:2.8441 x Lambda(0.01)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1376
Validation loss decreased (1.114843 --> 1.091930).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6577317
	speed: 0.0306s/iter; left time: 688.9272s
	iters: 200, epoch: 4 | loss: 0.5858311
	speed: 0.0279s/iter; left time: 624.1285s
Epoch: 4 cost time: 6.825892448425293
Epoch: 4, Steps: 233 Train Loss: 0.6074 (Forecasting Loss:0.5790 + XiCon Loss:2.8412 x Lambda(0.01)), Vali MSE Loss: 1.0847 Test MSE Loss: 1.1360
Validation loss decreased (1.091930 --> 1.084650).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6780871
	speed: 0.0303s/iter; left time: 674.5243s
	iters: 200, epoch: 5 | loss: 0.5701274
	speed: 0.0278s/iter; left time: 615.3324s
Epoch: 5 cost time: 6.7473602294921875
Epoch: 5, Steps: 233 Train Loss: 0.6041 (Forecasting Loss:0.5756 + XiCon Loss:2.8459 x Lambda(0.01)), Vali MSE Loss: 1.0800 Test MSE Loss: 1.1359
Validation loss decreased (1.084650 --> 1.079988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6639608
	speed: 0.0301s/iter; left time: 663.3128s
	iters: 200, epoch: 6 | loss: 0.6420057
	speed: 0.0281s/iter; left time: 616.6886s
Epoch: 6 cost time: 6.749643564224243
Epoch: 6, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5740 + XiCon Loss:2.8462 x Lambda(0.01)), Vali MSE Loss: 1.0789 Test MSE Loss: 1.1350
Validation loss decreased (1.079988 --> 1.078879).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6037022
	speed: 0.0293s/iter; left time: 638.1053s
	iters: 200, epoch: 7 | loss: 0.5898914
	speed: 0.0277s/iter; left time: 601.6479s
Epoch: 7 cost time: 6.649153232574463
Epoch: 7, Steps: 233 Train Loss: 0.6017 (Forecasting Loss:0.5733 + XiCon Loss:2.8429 x Lambda(0.01)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1352
Validation loss decreased (1.078879 --> 1.077416).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5973014
	speed: 0.0302s/iter; left time: 650.7192s
	iters: 200, epoch: 8 | loss: 0.6514864
	speed: 0.0280s/iter; left time: 601.6632s
Epoch: 8 cost time: 6.7771525382995605
Epoch: 8, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5728 + XiCon Loss:2.8432 x Lambda(0.01)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1352
Validation loss decreased (1.077416 --> 1.076862).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5788916
	speed: 0.0302s/iter; left time: 644.2820s
	iters: 200, epoch: 9 | loss: 0.5851059
	speed: 0.0277s/iter; left time: 588.5413s
Epoch: 9 cost time: 6.729856252670288
Epoch: 9, Steps: 233 Train Loss: 0.6010 (Forecasting Loss:0.5726 + XiCon Loss:2.8391 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1352
Validation loss decreased (1.076862 --> 1.076508).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6091461
	speed: 0.0297s/iter; left time: 626.6136s
	iters: 200, epoch: 10 | loss: 0.6067740
	speed: 0.0289s/iter; left time: 608.0387s
Epoch: 10 cost time: 6.814283609390259
Epoch: 10, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5726 + XiCon Loss:2.8494 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5411271
	speed: 0.0298s/iter; left time: 622.0044s
	iters: 200, epoch: 11 | loss: 0.6034074
	speed: 0.0286s/iter; left time: 594.7573s
Epoch: 11 cost time: 6.804366111755371
Epoch: 11, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8389 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5828608
	speed: 0.0299s/iter; left time: 616.4016s
	iters: 200, epoch: 12 | loss: 0.5901908
	speed: 0.0279s/iter; left time: 573.9518s
Epoch: 12 cost time: 6.75528621673584
Epoch: 12, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8406 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076508 --> 1.076444).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6180601
	speed: 0.0304s/iter; left time: 619.9727s
	iters: 200, epoch: 13 | loss: 0.6164789
	speed: 0.0288s/iter; left time: 585.3904s
Epoch: 13 cost time: 6.8862011432647705
Epoch: 13, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8406 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5869644
	speed: 0.0300s/iter; left time: 604.8883s
	iters: 200, epoch: 14 | loss: 0.5943110
	speed: 0.0282s/iter; left time: 565.8607s
Epoch: 14 cost time: 6.747504949569702
Epoch: 14, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8373 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
Validation loss decreased (1.076444 --> 1.076410).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6112831
	speed: 0.0313s/iter; left time: 623.1504s
	iters: 200, epoch: 15 | loss: 0.5730461
	speed: 0.0288s/iter; left time: 570.4588s
Epoch: 15 cost time: 6.931627035140991
Epoch: 15, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8403 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6071646
	speed: 0.0297s/iter; left time: 585.5802s
	iters: 200, epoch: 16 | loss: 0.6332905
	speed: 0.0275s/iter; left time: 538.3773s
Epoch: 16 cost time: 6.665511608123779
Epoch: 16, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8417 x Lambda(0.01)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5794505
	speed: 0.0296s/iter; left time: 575.8161s
	iters: 200, epoch: 17 | loss: 0.5563366
	speed: 0.0280s/iter; left time: 542.5850s
Epoch: 17 cost time: 6.675963640213013
Epoch: 17, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8424 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6427764
	speed: 0.0293s/iter; left time: 562.9197s
	iters: 200, epoch: 18 | loss: 0.5750536
	speed: 0.0285s/iter; left time: 545.3572s
Epoch: 18 cost time: 6.721660614013672
Epoch: 18, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5696352
	speed: 0.0299s/iter; left time: 568.1069s
	iters: 200, epoch: 19 | loss: 0.5961110
	speed: 0.0291s/iter; left time: 550.3475s
Epoch: 19 cost time: 6.847695827484131
Epoch: 19, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8444 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6400145
	speed: 0.0289s/iter; left time: 541.8832s
	iters: 200, epoch: 20 | loss: 0.5733916
	speed: 0.0285s/iter; left time: 531.7029s
Epoch: 20 cost time: 6.6558144092559814
Epoch: 20, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8389 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5752984
	speed: 0.0304s/iter; left time: 562.8536s
	iters: 200, epoch: 21 | loss: 0.5962430
	speed: 0.0279s/iter; left time: 513.9216s
Epoch: 21 cost time: 6.792738676071167
Epoch: 21, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5726 + XiCon Loss:2.8427 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
Validation loss decreased (1.076410 --> 1.076267).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6321951
	speed: 0.0306s/iter; left time: 560.8172s
	iters: 200, epoch: 22 | loss: 0.6179971
	speed: 0.0282s/iter; left time: 513.1621s
Epoch: 22 cost time: 6.839449882507324
Epoch: 22, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8403 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5845656
	speed: 0.0308s/iter; left time: 556.2789s
	iters: 200, epoch: 23 | loss: 0.6226885
	speed: 0.0276s/iter; left time: 495.2559s
Epoch: 23 cost time: 6.80693793296814
Epoch: 23, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8427 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5831106
	speed: 0.0301s/iter; left time: 536.1675s
	iters: 200, epoch: 24 | loss: 0.5685750
	speed: 0.0278s/iter; left time: 493.4127s
Epoch: 24 cost time: 6.718348026275635
Epoch: 24, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8449 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6701859
	speed: 0.0302s/iter; left time: 531.1095s
	iters: 200, epoch: 25 | loss: 0.6169471
	speed: 0.0280s/iter; left time: 490.5043s
Epoch: 25 cost time: 6.788665771484375
Epoch: 25, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8425 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
Validation loss decreased (1.076267 --> 1.076179).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6168908
	speed: 0.0304s/iter; left time: 528.4911s
	iters: 200, epoch: 26 | loss: 0.5768008
	speed: 0.0296s/iter; left time: 511.8303s
Epoch: 26 cost time: 6.984398603439331
Epoch: 26, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8414 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5914466
	speed: 0.0292s/iter; left time: 500.6954s
	iters: 200, epoch: 27 | loss: 0.6436061
	speed: 0.0288s/iter; left time: 491.6775s
Epoch: 27 cost time: 6.757243394851685
Epoch: 27, Steps: 233 Train Loss: 0.6010 (Forecasting Loss:0.5726 + XiCon Loss:2.8440 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5386907
	speed: 0.0304s/iter; left time: 514.4011s
	iters: 200, epoch: 28 | loss: 0.6060435
	speed: 0.0276s/iter; left time: 464.7913s
Epoch: 28 cost time: 6.776362180709839
Epoch: 28, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8409 x Lambda(0.01)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.6132254
	speed: 0.0302s/iter; left time: 503.9626s
	iters: 200, epoch: 29 | loss: 0.5930225
	speed: 0.0279s/iter; left time: 462.6272s
Epoch: 29 cost time: 6.787686109542847
Epoch: 29, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.0768 Test MSE Loss: 1.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6209957
	speed: 0.0297s/iter; left time: 488.9776s
	iters: 200, epoch: 30 | loss: 0.6290488
	speed: 0.0276s/iter; left time: 451.6244s
Epoch: 30 cost time: 6.691877365112305
Epoch: 30, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8408 x Lambda(0.01)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5779387
	speed: 0.0300s/iter; left time: 485.5499s
	iters: 200, epoch: 31 | loss: 0.5957848
	speed: 0.0279s/iter; left time: 449.5277s
Epoch: 31 cost time: 6.730936050415039
Epoch: 31, Steps: 233 Train Loss: 0.6007 (Forecasting Loss:0.5723 + XiCon Loss:2.8409 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6190468
	speed: 0.0298s/iter; left time: 476.4661s
	iters: 200, epoch: 32 | loss: 0.6276860
	speed: 0.0282s/iter; left time: 447.5856s
Epoch: 32 cost time: 6.746842622756958
Epoch: 32, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5724 + XiCon Loss:2.8413 x Lambda(0.01)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5661827
	speed: 0.0297s/iter; left time: 468.4112s
	iters: 200, epoch: 33 | loss: 0.6230910
	speed: 0.0282s/iter; left time: 441.1742s
Epoch: 33 cost time: 6.724799633026123
Epoch: 33, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8399 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5755153
	speed: 0.0300s/iter; left time: 464.8538s
	iters: 200, epoch: 34 | loss: 0.5765260
	speed: 0.0279s/iter; left time: 430.1356s
Epoch: 34 cost time: 6.751178741455078
Epoch: 34, Steps: 233 Train Loss: 0.6009 (Forecasting Loss:0.5725 + XiCon Loss:2.8401 x Lambda(0.01)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1351
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5998564
	speed: 0.0291s/iter; left time: 444.7981s
	iters: 200, epoch: 35 | loss: 0.6167544
	speed: 0.0282s/iter; left time: 427.8410s
Epoch: 35 cost time: 6.685603618621826
Epoch: 35, Steps: 233 Train Loss: 0.6008 (Forecasting Loss:0.5723 + XiCon Loss:2.8441 x Lambda(0.01)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1351
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3928560018539429, mae:0.8773898482322693, mape:6.102227687835693, mspe:4463.27978515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9509
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1714249
	speed: 0.0320s/iter; left time: 742.3303s
	iters: 200, epoch: 1 | loss: 0.9895965
	speed: 0.0285s/iter; left time: 657.7149s
Epoch: 1 cost time: 7.035855531692505
Epoch: 1, Steps: 233 Train Loss: 1.0421 (Forecasting Loss:1.0137 + XiCon Loss:2.8476 x Lambda(0.01)), Vali MSE Loss: 1.8333 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833312).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6720341
	speed: 0.0309s/iter; left time: 709.7433s
	iters: 200, epoch: 2 | loss: 0.5786503
	speed: 0.0283s/iter; left time: 646.5990s
Epoch: 2 cost time: 6.901299715042114
Epoch: 2, Steps: 233 Train Loss: 0.6809 (Forecasting Loss:0.6525 + XiCon Loss:2.8436 x Lambda(0.01)), Vali MSE Loss: 1.1219 Test MSE Loss: 1.1452
Validation loss decreased (1.833312 --> 1.121906).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6091601
	speed: 0.0312s/iter; left time: 708.9124s
	iters: 200, epoch: 3 | loss: 0.5955123
	speed: 0.0282s/iter; left time: 637.7664s
Epoch: 3 cost time: 6.86077094078064
Epoch: 3, Steps: 233 Train Loss: 0.6166 (Forecasting Loss:0.5883 + XiCon Loss:2.8320 x Lambda(0.01)), Vali MSE Loss: 1.0999 Test MSE Loss: 1.1377
Validation loss decreased (1.121906 --> 1.099850).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6451733
	speed: 0.0303s/iter; left time: 681.7819s
	iters: 200, epoch: 4 | loss: 0.6228048
	speed: 0.0288s/iter; left time: 644.6713s
Epoch: 4 cost time: 6.910187244415283
Epoch: 4, Steps: 233 Train Loss: 0.6081 (Forecasting Loss:0.5797 + XiCon Loss:2.8319 x Lambda(0.01)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1365
Validation loss decreased (1.099850 --> 1.090969).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5743116
	speed: 0.0304s/iter; left time: 676.1783s
	iters: 200, epoch: 5 | loss: 0.5634343
	speed: 0.0283s/iter; left time: 628.2324s
Epoch: 5 cost time: 6.826903820037842
Epoch: 5, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5762 + XiCon Loss:2.8295 x Lambda(0.01)), Vali MSE Loss: 1.0870 Test MSE Loss: 1.1360
Validation loss decreased (1.090969 --> 1.086988).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6134941
	speed: 0.0310s/iter; left time: 683.6883s
	iters: 200, epoch: 6 | loss: 0.6163030
	speed: 0.0287s/iter; left time: 630.4355s
Epoch: 6 cost time: 6.940101385116577
Epoch: 6, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5746 + XiCon Loss:2.8349 x Lambda(0.01)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1358
Validation loss decreased (1.086988 --> 1.085351).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5502841
	speed: 0.0305s/iter; left time: 664.1379s
	iters: 200, epoch: 7 | loss: 0.6519259
	speed: 0.0286s/iter; left time: 621.6662s
Epoch: 7 cost time: 6.854204893112183
Epoch: 7, Steps: 233 Train Loss: 0.6021 (Forecasting Loss:0.5738 + XiCon Loss:2.8300 x Lambda(0.01)), Vali MSE Loss: 1.0845 Test MSE Loss: 1.1357
Validation loss decreased (1.085351 --> 1.084530).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6007840
	speed: 0.0307s/iter; left time: 662.9876s
	iters: 200, epoch: 8 | loss: 0.5855168
	speed: 0.0281s/iter; left time: 603.0255s
Epoch: 8 cost time: 6.901125431060791
Epoch: 8, Steps: 233 Train Loss: 0.6016 (Forecasting Loss:0.5733 + XiCon Loss:2.8293 x Lambda(0.01)), Vali MSE Loss: 1.0841 Test MSE Loss: 1.1356
Validation loss decreased (1.084530 --> 1.084123).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6287997
	speed: 0.0299s/iter; left time: 638.8908s
	iters: 200, epoch: 9 | loss: 0.5809450
	speed: 0.0286s/iter; left time: 606.4002s
Epoch: 9 cost time: 6.804914236068726
Epoch: 9, Steps: 233 Train Loss: 0.6015 (Forecasting Loss:0.5732 + XiCon Loss:2.8387 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1356
Validation loss decreased (1.084123 --> 1.083783).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5714102
	speed: 0.0308s/iter; left time: 650.7365s
	iters: 200, epoch: 10 | loss: 0.6032358
	speed: 0.0280s/iter; left time: 587.7620s
Epoch: 10 cost time: 6.86421799659729
Epoch: 10, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8339 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6035779
	speed: 0.0314s/iter; left time: 655.1017s
	iters: 200, epoch: 11 | loss: 0.6080402
	speed: 0.0286s/iter; left time: 593.1317s
Epoch: 11 cost time: 6.97532057762146
Epoch: 11, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8293 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083783 --> 1.083694).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5650231
	speed: 0.0311s/iter; left time: 641.3709s
	iters: 200, epoch: 12 | loss: 0.5662059
	speed: 0.0283s/iter; left time: 581.0266s
Epoch: 12 cost time: 6.879293918609619
Epoch: 12, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8301 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6472185
	speed: 0.0310s/iter; left time: 633.3860s
	iters: 200, epoch: 13 | loss: 0.5984371
	speed: 0.0282s/iter; left time: 573.2207s
Epoch: 13 cost time: 6.9112772941589355
Epoch: 13, Steps: 233 Train Loss: 0.6014 (Forecasting Loss:0.5731 + XiCon Loss:2.8322 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6058313
	speed: 0.0291s/iter; left time: 587.7992s
	iters: 200, epoch: 14 | loss: 0.6189321
	speed: 0.0277s/iter; left time: 555.3764s
Epoch: 14 cost time: 6.618921995162964
Epoch: 14, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8290 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5586149
	speed: 0.0310s/iter; left time: 618.6686s
	iters: 200, epoch: 15 | loss: 0.6096204
	speed: 0.0289s/iter; left time: 573.1533s
Epoch: 15 cost time: 6.976952075958252
Epoch: 15, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8302 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6041607
	speed: 0.0306s/iter; left time: 602.8447s
	iters: 200, epoch: 16 | loss: 0.5898480
	speed: 0.0276s/iter; left time: 540.3653s
Epoch: 16 cost time: 6.7629780769348145
Epoch: 16, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8320 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5470076
	speed: 0.0306s/iter; left time: 596.2391s
	iters: 200, epoch: 17 | loss: 0.5743651
	speed: 0.0279s/iter; left time: 539.8593s
Epoch: 17 cost time: 6.8031134605407715
Epoch: 17, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8321 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
Validation loss decreased (1.083694 --> 1.083669).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6113571
	speed: 0.0308s/iter; left time: 593.0161s
	iters: 200, epoch: 18 | loss: 0.5851607
	speed: 0.0286s/iter; left time: 547.0626s
Epoch: 18 cost time: 6.886639833450317
Epoch: 18, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8276 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5879814
	speed: 0.0302s/iter; left time: 573.9159s
	iters: 200, epoch: 19 | loss: 0.6146641
	speed: 0.0280s/iter; left time: 529.2319s
Epoch: 19 cost time: 6.822320938110352
Epoch: 19, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5729 + XiCon Loss:2.8329 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6238567
	speed: 0.0296s/iter; left time: 556.2430s
	iters: 200, epoch: 20 | loss: 0.5718001
	speed: 0.0288s/iter; left time: 538.6479s
Epoch: 20 cost time: 6.785063982009888
Epoch: 20, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8303 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6763182
	speed: 0.0304s/iter; left time: 563.6437s
	iters: 200, epoch: 21 | loss: 0.5388622
	speed: 0.0285s/iter; left time: 524.7996s
Epoch: 21 cost time: 6.85929012298584
Epoch: 21, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5729 + XiCon Loss:2.8361 x Lambda(0.01)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
Validation loss decreased (1.083669 --> 1.083540).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5538362
	speed: 0.0300s/iter; left time: 549.8479s
	iters: 200, epoch: 22 | loss: 0.5861416
	speed: 0.0277s/iter; left time: 505.1611s
Epoch: 22 cost time: 6.7395899295806885
Epoch: 22, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8330 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5919078
	speed: 0.0299s/iter; left time: 541.2936s
	iters: 200, epoch: 23 | loss: 0.6487214
	speed: 0.0290s/iter; left time: 520.4112s
Epoch: 23 cost time: 6.894487380981445
Epoch: 23, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8287 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5571628
	speed: 0.0303s/iter; left time: 540.8709s
	iters: 200, epoch: 24 | loss: 0.6195235
	speed: 0.0281s/iter; left time: 499.2094s
Epoch: 24 cost time: 6.787548780441284
Epoch: 24, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8314 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6602534
	speed: 0.0306s/iter; left time: 538.7363s
	iters: 200, epoch: 25 | loss: 0.5236300
	speed: 0.0282s/iter; left time: 493.0793s
Epoch: 25 cost time: 6.844838619232178
Epoch: 25, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8287 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6257902
	speed: 0.0307s/iter; left time: 532.6368s
	iters: 200, epoch: 26 | loss: 0.6082668
	speed: 0.0279s/iter; left time: 482.4842s
Epoch: 26 cost time: 6.834054708480835
Epoch: 26, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5730 + XiCon Loss:2.8272 x Lambda(0.01)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5979536
	speed: 0.0299s/iter; left time: 511.8892s
	iters: 200, epoch: 27 | loss: 0.6400971
	speed: 0.0277s/iter; left time: 471.2898s
Epoch: 27 cost time: 6.7032246589660645
Epoch: 27, Steps: 233 Train Loss: 0.6011 (Forecasting Loss:0.5729 + XiCon Loss:2.8239 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5966334
	speed: 0.0309s/iter; left time: 522.0364s
	iters: 200, epoch: 28 | loss: 0.6077265
	speed: 0.0282s/iter; left time: 473.9361s
Epoch: 28 cost time: 6.850152492523193
Epoch: 28, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8319 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5797756
	speed: 0.0304s/iter; left time: 507.6023s
	iters: 200, epoch: 29 | loss: 0.6001810
	speed: 0.0279s/iter; left time: 462.5721s
Epoch: 29 cost time: 6.818148136138916
Epoch: 29, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8351 x Lambda(0.01)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6065677
	speed: 0.0312s/iter; left time: 512.8048s
	iters: 200, epoch: 30 | loss: 0.5588172
	speed: 0.0286s/iter; left time: 467.4671s
Epoch: 30 cost time: 6.938470125198364
Epoch: 30, Steps: 233 Train Loss: 0.6012 (Forecasting Loss:0.5729 + XiCon Loss:2.8311 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5526617
	speed: 0.0307s/iter; left time: 497.2627s
	iters: 200, epoch: 31 | loss: 0.5893019
	speed: 0.0291s/iter; left time: 468.3607s
Epoch: 31 cost time: 6.961719036102295
Epoch: 31, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.5730 + XiCon Loss:2.8318 x Lambda(0.01)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3916504383087158, mae:0.8793809413909912, mape:6.165965557098389, mspe:4547.35888671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.4444
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0496676
	speed: 0.0273s/iter; left time: 633.8860s
	iters: 200, epoch: 1 | loss: 1.0161712
	speed: 0.0234s/iter; left time: 539.4925s
Epoch: 1 cost time: 5.88290548324585
Epoch: 1, Steps: 233 Train Loss: 1.0564 (Forecasting Loss:1.0277 + XiCon Loss:2.8675 x Lambda(0.01)), Vali MSE Loss: 1.8645 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864499).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6534233
	speed: 0.0273s/iter; left time: 626.2871s
	iters: 200, epoch: 2 | loss: 0.6267547
	speed: 0.0233s/iter; left time: 533.7490s
Epoch: 2 cost time: 5.8742218017578125
Epoch: 2, Steps: 233 Train Loss: 0.6831 (Forecasting Loss:0.6545 + XiCon Loss:2.8627 x Lambda(0.01)), Vali MSE Loss: 1.1221 Test MSE Loss: 1.1462
Validation loss decreased (1.864499 --> 1.122147).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6340885
	speed: 0.0262s/iter; left time: 595.8696s
	iters: 200, epoch: 3 | loss: 0.6678904
	speed: 0.0234s/iter; left time: 528.7745s
Epoch: 3 cost time: 5.787456274032593
Epoch: 3, Steps: 233 Train Loss: 0.6179 (Forecasting Loss:0.5893 + XiCon Loss:2.8582 x Lambda(0.01)), Vali MSE Loss: 1.1027 Test MSE Loss: 1.1399
Validation loss decreased (1.122147 --> 1.102651).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5703902
	speed: 0.0264s/iter; left time: 593.8964s
	iters: 200, epoch: 4 | loss: 0.6290452
	speed: 0.0242s/iter; left time: 541.6315s
Epoch: 4 cost time: 5.864254474639893
Epoch: 4, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.5810 + XiCon Loss:2.8524 x Lambda(0.01)), Vali MSE Loss: 1.0940 Test MSE Loss: 1.1380
Validation loss decreased (1.102651 --> 1.094047).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5866316
	speed: 0.0268s/iter; left time: 596.5245s
	iters: 200, epoch: 5 | loss: 0.5867913
	speed: 0.0236s/iter; left time: 522.2806s
Epoch: 5 cost time: 5.843935966491699
Epoch: 5, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5776 + XiCon Loss:2.8516 x Lambda(0.01)), Vali MSE Loss: 1.0906 Test MSE Loss: 1.1375
Validation loss decreased (1.094047 --> 1.090586).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5883379
	speed: 0.0269s/iter; left time: 593.8625s
	iters: 200, epoch: 6 | loss: 0.6272047
	speed: 0.0238s/iter; left time: 521.6786s
Epoch: 6 cost time: 5.883473873138428
Epoch: 6, Steps: 233 Train Loss: 0.6045 (Forecasting Loss:0.5760 + XiCon Loss:2.8568 x Lambda(0.01)), Vali MSE Loss: 1.0885 Test MSE Loss: 1.1374
Validation loss decreased (1.090586 --> 1.088503).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6096584
	speed: 0.0265s/iter; left time: 578.0832s
	iters: 200, epoch: 7 | loss: 0.6282198
	speed: 0.0241s/iter; left time: 522.9092s
Epoch: 7 cost time: 5.8716020584106445
Epoch: 7, Steps: 233 Train Loss: 0.6036 (Forecasting Loss:0.5751 + XiCon Loss:2.8514 x Lambda(0.01)), Vali MSE Loss: 1.0875 Test MSE Loss: 1.1374
Validation loss decreased (1.088503 --> 1.087472).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6315080
	speed: 0.0270s/iter; left time: 581.4982s
	iters: 200, epoch: 8 | loss: 0.5880308
	speed: 0.0241s/iter; left time: 516.5151s
Epoch: 8 cost time: 5.899992227554321
Epoch: 8, Steps: 233 Train Loss: 0.6032 (Forecasting Loss:0.5747 + XiCon Loss:2.8504 x Lambda(0.01)), Vali MSE Loss: 1.0871 Test MSE Loss: 1.1373
Validation loss decreased (1.087472 --> 1.087138).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6220391
	speed: 0.0265s/iter; left time: 564.7456s
	iters: 200, epoch: 9 | loss: 0.6599571
	speed: 0.0236s/iter; left time: 501.6133s
Epoch: 9 cost time: 5.816197395324707
Epoch: 9, Steps: 233 Train Loss: 0.6029 (Forecasting Loss:0.5744 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0867 Test MSE Loss: 1.1373
Validation loss decreased (1.087138 --> 1.086657).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6179556
	speed: 0.0295s/iter; left time: 621.5919s
	iters: 200, epoch: 10 | loss: 0.5808643
	speed: 0.0261s/iter; left time: 547.5434s
Epoch: 10 cost time: 6.38809609413147
Epoch: 10, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5743 + XiCon Loss:2.8538 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
Validation loss decreased (1.086657 --> 1.086514).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5985768
	speed: 0.0279s/iter; left time: 581.2890s
	iters: 200, epoch: 11 | loss: 0.6054538
	speed: 0.0240s/iter; left time: 498.9070s
Epoch: 11 cost time: 5.992801189422607
Epoch: 11, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5743 + XiCon Loss:2.8538 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
Validation loss decreased (1.086514 --> 1.086421).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6320177
	speed: 0.0272s/iter; left time: 560.5006s
	iters: 200, epoch: 12 | loss: 0.5586712
	speed: 0.0235s/iter; left time: 481.8186s
Epoch: 12 cost time: 5.878671884536743
Epoch: 12, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8555 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6261222
	speed: 0.0266s/iter; left time: 542.1708s
	iters: 200, epoch: 13 | loss: 0.5866951
	speed: 0.0234s/iter; left time: 476.0251s
Epoch: 13 cost time: 5.798886299133301
Epoch: 13, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8491 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5929219
	speed: 0.0298s/iter; left time: 600.1816s
	iters: 200, epoch: 14 | loss: 0.6543794
	speed: 0.0254s/iter; left time: 509.5013s
Epoch: 14 cost time: 6.336750507354736
Epoch: 14, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8518 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6293719
	speed: 0.0265s/iter; left time: 527.5229s
	iters: 200, epoch: 15 | loss: 0.6115752
	speed: 0.0235s/iter; left time: 466.8379s
Epoch: 15 cost time: 5.795446872711182
Epoch: 15, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8526 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6153459
	speed: 0.0273s/iter; left time: 538.1839s
	iters: 200, epoch: 16 | loss: 0.6174459
	speed: 0.0239s/iter; left time: 467.6778s
Epoch: 16 cost time: 5.921972990036011
Epoch: 16, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8529 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
Validation loss decreased (1.086421 --> 1.086155).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5168749
	speed: 0.0270s/iter; left time: 526.7060s
	iters: 200, epoch: 17 | loss: 0.6870385
	speed: 0.0239s/iter; left time: 463.0778s
Epoch: 17 cost time: 5.914285898208618
Epoch: 17, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8546 x Lambda(0.01)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6099573
	speed: 0.0268s/iter; left time: 515.2275s
	iters: 200, epoch: 18 | loss: 0.5911243
	speed: 0.0233s/iter; left time: 446.3815s
Epoch: 18 cost time: 5.831265449523926
Epoch: 18, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8533 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6158949
	speed: 0.0265s/iter; left time: 503.2140s
	iters: 200, epoch: 19 | loss: 0.6664442
	speed: 0.0233s/iter; left time: 440.0401s
Epoch: 19 cost time: 5.7753520011901855
Epoch: 19, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8528 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086155 --> 1.086145).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6603297
	speed: 0.0267s/iter; left time: 500.8225s
	iters: 200, epoch: 20 | loss: 0.6222276
	speed: 0.0238s/iter; left time: 443.8380s
Epoch: 20 cost time: 5.8756263256073
Epoch: 20, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8548 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5815513
	speed: 0.0265s/iter; left time: 491.2206s
	iters: 200, epoch: 21 | loss: 0.5918990
	speed: 0.0234s/iter; left time: 432.3274s
Epoch: 21 cost time: 5.826725482940674
Epoch: 21, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8462 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6145840
	speed: 0.0267s/iter; left time: 489.3900s
	iters: 200, epoch: 22 | loss: 0.5564036
	speed: 0.0240s/iter; left time: 437.4763s
Epoch: 22 cost time: 5.901979207992554
Epoch: 22, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8504 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5674047
	speed: 0.0271s/iter; left time: 489.5758s
	iters: 200, epoch: 23 | loss: 0.6103236
	speed: 0.0237s/iter; left time: 425.1940s
Epoch: 23 cost time: 5.870877981185913
Epoch: 23, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5955753
	speed: 0.0270s/iter; left time: 481.6017s
	iters: 200, epoch: 24 | loss: 0.6253070
	speed: 0.0237s/iter; left time: 420.0915s
Epoch: 24 cost time: 5.887901067733765
Epoch: 24, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8460 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5674109
	speed: 0.0269s/iter; left time: 474.4411s
	iters: 200, epoch: 25 | loss: 0.6047083
	speed: 0.0235s/iter; left time: 410.6736s
Epoch: 25 cost time: 5.8559346199035645
Epoch: 25, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8522 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6470994
	speed: 0.0267s/iter; left time: 464.5254s
	iters: 200, epoch: 26 | loss: 0.6154068
	speed: 0.0236s/iter; left time: 408.3924s
Epoch: 26 cost time: 5.836292028427124
Epoch: 26, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8552 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6329345
	speed: 0.0269s/iter; left time: 460.9069s
	iters: 200, epoch: 27 | loss: 0.5690459
	speed: 0.0235s/iter; left time: 400.6083s
Epoch: 27 cost time: 5.839636564254761
Epoch: 27, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8492 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6248965
	speed: 0.0265s/iter; left time: 448.7771s
	iters: 200, epoch: 28 | loss: 0.6097900
	speed: 0.0238s/iter; left time: 399.6014s
Epoch: 28 cost time: 5.864365100860596
Epoch: 28, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8513 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5848969
	speed: 0.0266s/iter; left time: 443.0421s
	iters: 200, epoch: 29 | loss: 0.6224577
	speed: 0.0237s/iter; left time: 392.5420s
Epoch: 29 cost time: 5.836359024047852
Epoch: 29, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5740 + XiCon Loss:2.8516 x Lambda(0.01)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1373
Validation loss decreased (1.086145 --> 1.086091).  Saving model ...
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5753884
	speed: 0.0269s/iter; left time: 443.0400s
	iters: 200, epoch: 30 | loss: 0.5546747
	speed: 0.0234s/iter; left time: 382.2808s
Epoch: 30 cost time: 5.818932294845581
Epoch: 30, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8550 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5821471
	speed: 0.0266s/iter; left time: 431.9237s
	iters: 200, epoch: 31 | loss: 0.6048759
	speed: 0.0236s/iter; left time: 380.5696s
Epoch: 31 cost time: 5.852000951766968
Epoch: 31, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8483 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5874636
	speed: 0.0266s/iter; left time: 424.6121s
	iters: 200, epoch: 32 | loss: 0.5801301
	speed: 0.0236s/iter; left time: 373.9926s
Epoch: 32 cost time: 5.817235231399536
Epoch: 32, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8482 x Lambda(0.01)), Vali MSE Loss: 1.0868 Test MSE Loss: 1.1373
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5585869
	speed: 0.0267s/iter; left time: 420.8689s
	iters: 200, epoch: 33 | loss: 0.6584328
	speed: 0.0236s/iter; left time: 369.4326s
Epoch: 33 cost time: 5.840574502944946
Epoch: 33, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5741 + XiCon Loss:2.8558 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5811053
	speed: 0.0266s/iter; left time: 412.9292s
	iters: 200, epoch: 34 | loss: 0.5709287
	speed: 0.0235s/iter; left time: 362.2860s
Epoch: 34 cost time: 5.8268702030181885
Epoch: 34, Steps: 233 Train Loss: 0.6025 (Forecasting Loss:0.5741 + XiCon Loss:2.8498 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5713642
	speed: 0.0288s/iter; left time: 439.4979s
	iters: 200, epoch: 35 | loss: 0.6260404
	speed: 0.0246s/iter; left time: 373.3274s
Epoch: 35 cost time: 6.138996839523315
Epoch: 35, Steps: 233 Train Loss: 0.6026 (Forecasting Loss:0.5741 + XiCon Loss:2.8467 x Lambda(0.01)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6271228
	speed: 0.0267s/iter; left time: 402.4652s
	iters: 200, epoch: 36 | loss: 0.5714675
	speed: 0.0241s/iter; left time: 359.9147s
Epoch: 36 cost time: 5.916076421737671
Epoch: 36, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8490 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5759268
	speed: 0.0263s/iter; left time: 390.0190s
	iters: 200, epoch: 37 | loss: 0.6195455
	speed: 0.0238s/iter; left time: 349.8256s
Epoch: 37 cost time: 5.827113628387451
Epoch: 37, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.5742 + XiCon Loss:2.8532 x Lambda(0.01)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1373
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5937718
	speed: 0.0268s/iter; left time: 391.3177s
	iters: 200, epoch: 38 | loss: 0.5829413
	speed: 0.0235s/iter; left time: 340.0090s
Epoch: 38 cost time: 5.863860130310059
Epoch: 38, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8531 x Lambda(0.01)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1373
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.6070929
	speed: 0.0270s/iter; left time: 387.6364s
	iters: 200, epoch: 39 | loss: 0.5807859
	speed: 0.0238s/iter; left time: 339.6479s
Epoch: 39 cost time: 5.886278390884399
Epoch: 39, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.5742 + XiCon Loss:2.8501 x Lambda(0.01)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1373
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3957109451293945, mae:0.8787949085235596, mape:6.154982566833496, mspe:4557.46826171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.0404
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0413216
	speed: 0.0306s/iter; left time: 710.3487s
	iters: 200, epoch: 1 | loss: 0.9861708
	speed: 0.0273s/iter; left time: 630.0954s
Epoch: 1 cost time: 6.751781702041626
Epoch: 1, Steps: 233 Train Loss: 1.0562 (Forecasting Loss:1.0279 + XiCon Loss:2.8258 x Lambda(0.01)), Vali MSE Loss: 1.8929 Test MSE Loss: 1.2473
Validation loss decreased (inf --> 1.892945).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6888902
	speed: 0.0297s/iter; left time: 682.7919s
	iters: 200, epoch: 2 | loss: 0.6088138
	speed: 0.0281s/iter; left time: 641.7057s
Epoch: 2 cost time: 6.712439298629761
Epoch: 2, Steps: 233 Train Loss: 0.6853 (Forecasting Loss:0.6569 + XiCon Loss:2.8355 x Lambda(0.01)), Vali MSE Loss: 1.1382 Test MSE Loss: 1.1436
Validation loss decreased (1.892945 --> 1.138160).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6504736
	speed: 0.0308s/iter; left time: 700.7224s
	iters: 200, epoch: 3 | loss: 0.5844799
	speed: 0.0282s/iter; left time: 639.1550s
Epoch: 3 cost time: 6.867799282073975
Epoch: 3, Steps: 233 Train Loss: 0.6204 (Forecasting Loss:0.5921 + XiCon Loss:2.8309 x Lambda(0.01)), Vali MSE Loss: 1.1169 Test MSE Loss: 1.1349
Validation loss decreased (1.138160 --> 1.116902).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6555699
	speed: 0.0296s/iter; left time: 666.7855s
	iters: 200, epoch: 4 | loss: 0.6061964
	speed: 0.0279s/iter; left time: 626.1321s
Epoch: 4 cost time: 6.723069906234741
Epoch: 4, Steps: 233 Train Loss: 0.6124 (Forecasting Loss:0.5840 + XiCon Loss:2.8357 x Lambda(0.01)), Vali MSE Loss: 1.1090 Test MSE Loss: 1.1334
Validation loss decreased (1.116902 --> 1.108989).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6236994
	speed: 0.0296s/iter; left time: 660.1408s
	iters: 200, epoch: 5 | loss: 0.6067202
	speed: 0.0283s/iter; left time: 626.4856s
Epoch: 5 cost time: 6.763842344284058
Epoch: 5, Steps: 233 Train Loss: 0.6091 (Forecasting Loss:0.5808 + XiCon Loss:2.8295 x Lambda(0.01)), Vali MSE Loss: 1.1057 Test MSE Loss: 1.1327
Validation loss decreased (1.108989 --> 1.105673).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6039370
	speed: 0.0315s/iter; left time: 693.3092s
	iters: 200, epoch: 6 | loss: 0.6603553
	speed: 0.0280s/iter; left time: 613.9348s
Epoch: 6 cost time: 6.920866012573242
Epoch: 6, Steps: 233 Train Loss: 0.6077 (Forecasting Loss:0.5794 + XiCon Loss:2.8325 x Lambda(0.01)), Vali MSE Loss: 1.1043 Test MSE Loss: 1.1324
Validation loss decreased (1.105673 --> 1.104317).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6161928
	speed: 0.0304s/iter; left time: 663.3634s
	iters: 200, epoch: 7 | loss: 0.6094626
	speed: 0.0273s/iter; left time: 591.6537s
Epoch: 7 cost time: 6.738759517669678
Epoch: 7, Steps: 233 Train Loss: 0.6070 (Forecasting Loss:0.5786 + XiCon Loss:2.8338 x Lambda(0.01)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1323
Validation loss decreased (1.104317 --> 1.103109).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5786451
	speed: 0.0312s/iter; left time: 673.8848s
	iters: 200, epoch: 8 | loss: 0.6439433
	speed: 0.0274s/iter; left time: 588.9990s
Epoch: 8 cost time: 6.842345714569092
Epoch: 8, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5782 + XiCon Loss:2.8285 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1323
Validation loss decreased (1.103109 --> 1.102558).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5940909
	speed: 0.0296s/iter; left time: 631.6161s
	iters: 200, epoch: 9 | loss: 0.6275589
	speed: 0.0283s/iter; left time: 600.3432s
Epoch: 9 cost time: 6.741432189941406
Epoch: 9, Steps: 233 Train Loss: 0.6064 (Forecasting Loss:0.5781 + XiCon Loss:2.8341 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5806111
	speed: 0.0295s/iter; left time: 622.5746s
	iters: 200, epoch: 10 | loss: 0.6052958
	speed: 0.0276s/iter; left time: 580.0217s
Epoch: 10 cost time: 6.700756311416626
Epoch: 10, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5779 + XiCon Loss:2.8306 x Lambda(0.01)), Vali MSE Loss: 1.1026 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5680168
	speed: 0.0306s/iter; left time: 638.4797s
	iters: 200, epoch: 11 | loss: 0.5781316
	speed: 0.0288s/iter; left time: 598.9721s
Epoch: 11 cost time: 6.894170761108398
Epoch: 11, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5779 + XiCon Loss:2.8352 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102558 --> 1.102221).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5802798
	speed: 0.0308s/iter; left time: 635.0093s
	iters: 200, epoch: 12 | loss: 0.6426473
	speed: 0.0275s/iter; left time: 564.9194s
Epoch: 12 cost time: 6.782973289489746
Epoch: 12, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8313 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6214004
	speed: 0.0309s/iter; left time: 630.4522s
	iters: 200, epoch: 13 | loss: 0.5975249
	speed: 0.0280s/iter; left time: 567.6517s
Epoch: 13 cost time: 6.818652868270874
Epoch: 13, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5683733
	speed: 0.0305s/iter; left time: 615.4449s
	iters: 200, epoch: 14 | loss: 0.5923156
	speed: 0.0279s/iter; left time: 560.0469s
Epoch: 14 cost time: 6.81078314781189
Epoch: 14, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8340 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5943081
	speed: 0.0297s/iter; left time: 592.2429s
	iters: 200, epoch: 15 | loss: 0.6254752
	speed: 0.0281s/iter; left time: 557.3266s
Epoch: 15 cost time: 6.748650789260864
Epoch: 15, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
Validation loss decreased (1.102221 --> 1.102175).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6384771
	speed: 0.0309s/iter; left time: 608.7317s
	iters: 200, epoch: 16 | loss: 0.5900980
	speed: 0.0281s/iter; left time: 550.5278s
Epoch: 16 cost time: 6.878055810928345
Epoch: 16, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8353 x Lambda(0.01)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1322
Validation loss decreased (1.102175 --> 1.102007).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6076787
	speed: 0.0303s/iter; left time: 590.4375s
	iters: 200, epoch: 17 | loss: 0.6305854
	speed: 0.0280s/iter; left time: 542.0118s
Epoch: 17 cost time: 6.743521451950073
Epoch: 17, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8276 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6296722
	speed: 0.0299s/iter; left time: 574.6322s
	iters: 200, epoch: 18 | loss: 0.6149480
	speed: 0.0284s/iter; left time: 544.5122s
Epoch: 18 cost time: 6.7911376953125
Epoch: 18, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8358 x Lambda(0.01)), Vali MSE Loss: 1.1019 Test MSE Loss: 1.1322
Validation loss decreased (1.102007 --> 1.101875).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5860016
	speed: 0.0295s/iter; left time: 560.8309s
	iters: 200, epoch: 19 | loss: 0.6599480
	speed: 0.0276s/iter; left time: 520.9873s
Epoch: 19 cost time: 6.659303665161133
Epoch: 19, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5777 + XiCon Loss:2.8318 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6081274
	speed: 0.0306s/iter; left time: 573.9956s
	iters: 200, epoch: 20 | loss: 0.5809803
	speed: 0.0287s/iter; left time: 535.6469s
Epoch: 20 cost time: 6.920542240142822
Epoch: 20, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5777 + XiCon Loss:2.8313 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6256302
	speed: 0.0296s/iter; left time: 548.7545s
	iters: 200, epoch: 21 | loss: 0.6178707
	speed: 0.0277s/iter; left time: 510.4466s
Epoch: 21 cost time: 6.7176833152771
Epoch: 21, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5777 + XiCon Loss:2.8334 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6259816
	speed: 0.0302s/iter; left time: 552.9621s
	iters: 200, epoch: 22 | loss: 0.5811324
	speed: 0.0281s/iter; left time: 511.9087s
Epoch: 22 cost time: 6.792864561080933
Epoch: 22, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8335 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6264582
	speed: 0.0297s/iter; left time: 537.4291s
	iters: 200, epoch: 23 | loss: 0.6047463
	speed: 0.0279s/iter; left time: 502.1571s
Epoch: 23 cost time: 6.696702480316162
Epoch: 23, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8298 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6326255
	speed: 0.0305s/iter; left time: 543.7126s
	iters: 200, epoch: 24 | loss: 0.5580654
	speed: 0.0280s/iter; left time: 496.8131s
Epoch: 24 cost time: 6.787303686141968
Epoch: 24, Steps: 233 Train Loss: 0.6061 (Forecasting Loss:0.5778 + XiCon Loss:2.8261 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6500502
	speed: 0.0304s/iter; left time: 535.6318s
	iters: 200, epoch: 25 | loss: 0.5952626
	speed: 0.0281s/iter; left time: 492.2765s
Epoch: 25 cost time: 6.830148935317993
Epoch: 25, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8365 x Lambda(0.01)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6094380
	speed: 0.0297s/iter; left time: 516.5922s
	iters: 200, epoch: 26 | loss: 0.6293295
	speed: 0.0280s/iter; left time: 484.4254s
Epoch: 26 cost time: 6.733047246932983
Epoch: 26, Steps: 233 Train Loss: 0.6062 (Forecasting Loss:0.5778 + XiCon Loss:2.8371 x Lambda(0.01)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6452216
	speed: 0.0307s/iter; left time: 525.4675s
	iters: 200, epoch: 27 | loss: 0.5714725
	speed: 0.0281s/iter; left time: 479.3035s
Epoch: 27 cost time: 6.83284592628479
Epoch: 27, Steps: 233 Train Loss: 0.6063 (Forecasting Loss:0.5780 + XiCon Loss:2.8302 x Lambda(0.01)), Vali MSE Loss: 1.1025 Test MSE Loss: 1.1322
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5414517
	speed: 0.0303s/iter; left time: 511.9133s
	iters: 200, epoch: 28 | loss: 0.5717974
	speed: 0.0280s/iter; left time: 469.9944s
Epoch: 28 cost time: 6.78894305229187
Epoch: 28, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.5776 + XiCon Loss:2.8330 x Lambda(0.01)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1322
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.389219880104065, mae:0.8751696348190308, mape:6.027244567871094, mspe:4359.70068359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3938+-0.00489, MAE:0.8781+-0.00230, MAPE:6.1176+-0.06953, MSPE:4494.7832+-104.93263, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.0107
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 30.2910442
	speed: 0.0514s/iter; left time: 1161.3327s
	iters: 200, epoch: 1 | loss: 28.8303623
	speed: 0.0460s/iter; left time: 1034.4045s
Epoch: 1 cost time: 11.00969648361206
Epoch: 1, Steps: 227 Train Loss: 29.3733 (Forecasting Loss:1.0262 + XiCon Loss:2.8347 x Lambda(10.0)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936043).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.8424168
	speed: 0.0493s/iter; left time: 1104.0081s
	iters: 200, epoch: 2 | loss: 28.9136829
	speed: 0.0455s/iter; left time: 1013.4804s
Epoch: 2 cost time: 10.759779214859009
Epoch: 2, Steps: 227 Train Loss: 28.9077 (Forecasting Loss:0.6690 + XiCon Loss:2.8239 x Lambda(10.0)), Vali MSE Loss: 1.2116 Test MSE Loss: 1.2841
Validation loss decreased (1.936043 --> 1.211574).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.1800270
	speed: 0.0479s/iter; left time: 1060.7306s
	iters: 200, epoch: 3 | loss: 28.9401760
	speed: 0.0472s/iter; left time: 1039.7953s
Epoch: 3 cost time: 10.846954584121704
Epoch: 3, Steps: 227 Train Loss: 28.5764 (Forecasting Loss:0.6064 + XiCon Loss:2.7970 x Lambda(10.0)), Vali MSE Loss: 1.1894 Test MSE Loss: 1.2755
Validation loss decreased (1.211574 --> 1.189432).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 27.7185421
	speed: 0.0491s/iter; left time: 1075.6179s
	iters: 200, epoch: 4 | loss: 27.8894749
	speed: 0.0466s/iter; left time: 1017.7982s
Epoch: 4 cost time: 10.889157772064209
Epoch: 4, Steps: 227 Train Loss: 28.3185 (Forecasting Loss:0.5990 + XiCon Loss:2.7719 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2737
Validation loss decreased (1.189432 --> 1.184058).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 27.5483456
	speed: 0.0477s/iter; left time: 1035.8106s
	iters: 200, epoch: 5 | loss: 28.5847244
	speed: 0.0466s/iter; left time: 1006.1819s
Epoch: 5 cost time: 10.701777935028076
Epoch: 5, Steps: 227 Train Loss: 28.1846 (Forecasting Loss:0.5962 + XiCon Loss:2.7588 x Lambda(10.0)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2727
Validation loss decreased (1.184058 --> 1.181603).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.8974457
	speed: 0.0489s/iter; left time: 1049.6153s
	iters: 200, epoch: 6 | loss: 27.9352398
	speed: 0.0472s/iter; left time: 1008.7088s
Epoch: 6 cost time: 10.935194492340088
Epoch: 6, Steps: 227 Train Loss: 28.0455 (Forecasting Loss:0.5948 + XiCon Loss:2.7451 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2724
Validation loss decreased (1.181603 --> 1.180011).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.9945354
	speed: 0.0482s/iter; left time: 1022.7113s
	iters: 200, epoch: 7 | loss: 27.9435883
	speed: 0.0474s/iter; left time: 1002.9535s
Epoch: 7 cost time: 10.836888551712036
Epoch: 7, Steps: 227 Train Loss: 28.0434 (Forecasting Loss:0.5941 + XiCon Loss:2.7449 x Lambda(10.0)), Vali MSE Loss: 1.1795 Test MSE Loss: 1.2721
Validation loss decreased (1.180011 --> 1.179479).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.4720936
	speed: 0.0486s/iter; left time: 1021.0326s
	iters: 200, epoch: 8 | loss: 28.5140724
	speed: 0.0468s/iter; left time: 979.7054s
Epoch: 8 cost time: 10.831302404403687
Epoch: 8, Steps: 227 Train Loss: 28.0272 (Forecasting Loss:0.5937 + XiCon Loss:2.7434 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2721
Validation loss decreased (1.179479 --> 1.178676).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 27.9640350
	speed: 0.0483s/iter; left time: 1003.9162s
	iters: 200, epoch: 9 | loss: 27.7566490
	speed: 0.0486s/iter; left time: 1004.6850s
Epoch: 9 cost time: 10.972475290298462
Epoch: 9, Steps: 227 Train Loss: 28.0366 (Forecasting Loss:0.5935 + XiCon Loss:2.7443 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.2547245
	speed: 0.0499s/iter; left time: 1025.3476s
	iters: 200, epoch: 10 | loss: 28.5110722
	speed: 0.0474s/iter; left time: 969.4166s
Epoch: 10 cost time: 11.021068572998047
Epoch: 10, Steps: 227 Train Loss: 28.0008 (Forecasting Loss:0.5935 + XiCon Loss:2.7407 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 28.4138184
	speed: 0.0486s/iter; left time: 988.1129s
	iters: 200, epoch: 11 | loss: 27.9720364
	speed: 0.0468s/iter; left time: 946.7778s
Epoch: 11 cost time: 10.888236045837402
Epoch: 11, Steps: 227 Train Loss: 28.0328 (Forecasting Loss:0.5932 + XiCon Loss:2.7440 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.8942928
	speed: 0.0487s/iter; left time: 978.3508s
	iters: 200, epoch: 12 | loss: 28.1088181
	speed: 0.0472s/iter; left time: 943.9061s
Epoch: 12 cost time: 10.93100118637085
Epoch: 12, Steps: 227 Train Loss: 28.0075 (Forecasting Loss:0.5933 + XiCon Loss:2.7414 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
Validation loss decreased (1.178676 --> 1.178476).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.6682034
	speed: 0.0490s/iter; left time: 974.8279s
	iters: 200, epoch: 13 | loss: 28.2149448
	speed: 0.0482s/iter; left time: 953.4925s
Epoch: 13 cost time: 11.068243741989136
Epoch: 13, Steps: 227 Train Loss: 28.0018 (Forecasting Loss:0.5935 + XiCon Loss:2.7408 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.0518436
	speed: 0.0488s/iter; left time: 959.8354s
	iters: 200, epoch: 14 | loss: 27.8672028
	speed: 0.0468s/iter; left time: 915.5660s
Epoch: 14 cost time: 10.914002895355225
Epoch: 14, Steps: 227 Train Loss: 27.9943 (Forecasting Loss:0.5935 + XiCon Loss:2.7401 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.6326313
	speed: 0.0494s/iter; left time: 958.8965s
	iters: 200, epoch: 15 | loss: 28.1462631
	speed: 0.0468s/iter; left time: 904.3347s
Epoch: 15 cost time: 10.902443647384644
Epoch: 15, Steps: 227 Train Loss: 27.9782 (Forecasting Loss:0.5935 + XiCon Loss:2.7385 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.3806705
	speed: 0.0488s/iter; left time: 936.8032s
	iters: 200, epoch: 16 | loss: 28.5548306
	speed: 0.0474s/iter; left time: 905.1003s
Epoch: 16 cost time: 10.941943645477295
Epoch: 16, Steps: 227 Train Loss: 28.0340 (Forecasting Loss:0.5933 + XiCon Loss:2.7441 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 29.0202312
	speed: 0.0487s/iter; left time: 923.6089s
	iters: 200, epoch: 17 | loss: 28.4830227
	speed: 0.0465s/iter; left time: 876.9389s
Epoch: 17 cost time: 10.861880540847778
Epoch: 17, Steps: 227 Train Loss: 27.9603 (Forecasting Loss:0.5933 + XiCon Loss:2.7367 x Lambda(10.0)), Vali MSE Loss: 1.1792 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.8749065
	speed: 0.0484s/iter; left time: 906.6148s
	iters: 200, epoch: 18 | loss: 28.3490963
	speed: 0.0480s/iter; left time: 895.3511s
Epoch: 18 cost time: 10.948454141616821
Epoch: 18, Steps: 227 Train Loss: 27.9988 (Forecasting Loss:0.5934 + XiCon Loss:2.7405 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
Validation loss decreased (1.178476 --> 1.178325).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 27.9460316
	speed: 0.0496s/iter; left time: 918.4447s
	iters: 200, epoch: 19 | loss: 28.2030869
	speed: 0.0474s/iter; left time: 873.2731s
Epoch: 19 cost time: 11.049701929092407
Epoch: 19, Steps: 227 Train Loss: 28.0433 (Forecasting Loss:0.5933 + XiCon Loss:2.7450 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.7404442
	speed: 0.0483s/iter; left time: 882.9481s
	iters: 200, epoch: 20 | loss: 27.7892532
	speed: 0.0471s/iter; left time: 856.7848s
Epoch: 20 cost time: 10.922412872314453
Epoch: 20, Steps: 227 Train Loss: 28.0245 (Forecasting Loss:0.5934 + XiCon Loss:2.7431 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.8738117
	speed: 0.0480s/iter; left time: 866.1760s
	iters: 200, epoch: 21 | loss: 28.3529835
	speed: 0.0481s/iter; left time: 864.6001s
Epoch: 21 cost time: 10.927420616149902
Epoch: 21, Steps: 227 Train Loss: 28.0309 (Forecasting Loss:0.5934 + XiCon Loss:2.7437 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.0348606
	speed: 0.0494s/iter; left time: 880.1332s
	iters: 200, epoch: 22 | loss: 28.9798107
	speed: 0.0469s/iter; left time: 831.1767s
Epoch: 22 cost time: 10.965370655059814
Epoch: 22, Steps: 227 Train Loss: 28.0139 (Forecasting Loss:0.5935 + XiCon Loss:2.7420 x Lambda(10.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 29.0039558
	speed: 0.0494s/iter; left time: 870.6152s
	iters: 200, epoch: 23 | loss: 27.6088581
	speed: 0.0460s/iter; left time: 805.7572s
Epoch: 23 cost time: 10.82839035987854
Epoch: 23, Steps: 227 Train Loss: 28.0440 (Forecasting Loss:0.5934 + XiCon Loss:2.7451 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.1827526
	speed: 0.0496s/iter; left time: 862.5480s
	iters: 200, epoch: 24 | loss: 28.0484886
	speed: 0.0478s/iter; left time: 825.7528s
Epoch: 24 cost time: 11.074194192886353
Epoch: 24, Steps: 227 Train Loss: 28.0159 (Forecasting Loss:0.5935 + XiCon Loss:2.7422 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.7604961
	speed: 0.0480s/iter; left time: 823.2202s
	iters: 200, epoch: 25 | loss: 28.2827377
	speed: 0.0470s/iter; left time: 801.6044s
Epoch: 25 cost time: 10.815155506134033
Epoch: 25, Steps: 227 Train Loss: 28.0220 (Forecasting Loss:0.5934 + XiCon Loss:2.7429 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 28.1167412
	speed: 0.0484s/iter; left time: 818.8903s
	iters: 200, epoch: 26 | loss: 27.8612309
	speed: 0.0468s/iter; left time: 787.8070s
Epoch: 26 cost time: 10.808886051177979
Epoch: 26, Steps: 227 Train Loss: 28.0032 (Forecasting Loss:0.5933 + XiCon Loss:2.7410 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.5749874
	speed: 0.0490s/iter; left time: 817.9509s
	iters: 200, epoch: 27 | loss: 27.9840546
	speed: 0.0457s/iter; left time: 758.2757s
Epoch: 27 cost time: 10.769804239273071
Epoch: 27, Steps: 227 Train Loss: 28.0210 (Forecasting Loss:0.5933 + XiCon Loss:2.7428 x Lambda(10.0)), Vali MSE Loss: 1.1778 Test MSE Loss: 1.2720
Validation loss decreased (1.178325 --> 1.177786).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 27.7728691
	speed: 0.0497s/iter; left time: 819.0373s
	iters: 200, epoch: 28 | loss: 28.4947033
	speed: 0.0469s/iter; left time: 768.2309s
Epoch: 28 cost time: 11.010003566741943
Epoch: 28, Steps: 227 Train Loss: 28.0384 (Forecasting Loss:0.5934 + XiCon Loss:2.7445 x Lambda(10.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 28.4354725
	speed: 0.0486s/iter; left time: 789.6758s
	iters: 200, epoch: 29 | loss: 28.1630726
	speed: 0.0474s/iter; left time: 765.7473s
Epoch: 29 cost time: 10.907444477081299
Epoch: 29, Steps: 227 Train Loss: 27.9919 (Forecasting Loss:0.5935 + XiCon Loss:2.7398 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 27.7973499
	speed: 0.0478s/iter; left time: 765.0811s
	iters: 200, epoch: 30 | loss: 28.1948490
	speed: 0.0467s/iter; left time: 743.8271s
Epoch: 30 cost time: 10.826397180557251
Epoch: 30, Steps: 227 Train Loss: 27.9797 (Forecasting Loss:0.5934 + XiCon Loss:2.7386 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 28.0430222
	speed: 0.0497s/iter; left time: 784.5142s
	iters: 200, epoch: 31 | loss: 28.4269161
	speed: 0.0464s/iter; left time: 727.4229s
Epoch: 31 cost time: 10.903183221817017
Epoch: 31, Steps: 227 Train Loss: 28.0058 (Forecasting Loss:0.5935 + XiCon Loss:2.7412 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 27.5363960
	speed: 0.0496s/iter; left time: 772.0241s
	iters: 200, epoch: 32 | loss: 28.3301868
	speed: 0.0487s/iter; left time: 753.5821s
Epoch: 32 cost time: 11.172291040420532
Epoch: 32, Steps: 227 Train Loss: 27.9982 (Forecasting Loss:0.5934 + XiCon Loss:2.7405 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 27.7301655
	speed: 0.0494s/iter; left time: 757.6592s
	iters: 200, epoch: 33 | loss: 27.9064369
	speed: 0.0480s/iter; left time: 731.0823s
Epoch: 33 cost time: 11.124114513397217
Epoch: 33, Steps: 227 Train Loss: 27.9992 (Forecasting Loss:0.5934 + XiCon Loss:2.7406 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 28.3258400
	speed: 0.0495s/iter; left time: 747.2708s
	iters: 200, epoch: 34 | loss: 27.6679993
	speed: 0.0462s/iter; left time: 693.5557s
Epoch: 34 cost time: 10.894819736480713
Epoch: 34, Steps: 227 Train Loss: 28.0289 (Forecasting Loss:0.5933 + XiCon Loss:2.7436 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 28.0709400
	speed: 0.0488s/iter; left time: 726.8458s
	iters: 200, epoch: 35 | loss: 27.2532845
	speed: 0.0474s/iter; left time: 701.2947s
Epoch: 35 cost time: 10.910499095916748
Epoch: 35, Steps: 227 Train Loss: 28.0118 (Forecasting Loss:0.5934 + XiCon Loss:2.7418 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 28.1577492
	speed: 0.0475s/iter; left time: 696.6984s
	iters: 200, epoch: 36 | loss: 28.6202602
	speed: 0.0477s/iter; left time: 694.1228s
Epoch: 36 cost time: 10.824006795883179
Epoch: 36, Steps: 227 Train Loss: 28.0323 (Forecasting Loss:0.5936 + XiCon Loss:2.7439 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 28.0573254
	speed: 0.0503s/iter; left time: 725.1761s
	iters: 200, epoch: 37 | loss: 27.9094429
	speed: 0.0460s/iter; left time: 658.5714s
Epoch: 37 cost time: 10.878624200820923
Epoch: 37, Steps: 227 Train Loss: 28.0462 (Forecasting Loss:0.5934 + XiCon Loss:2.7453 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5892889499664307, mae:0.9546433091163635, mape:6.2641730308532715, mspe:4851.42578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.2128
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 29.7612762
	speed: 0.0455s/iter; left time: 1029.0127s
	iters: 200, epoch: 1 | loss: 29.6436749
	speed: 0.0411s/iter; left time: 925.4204s
Epoch: 1 cost time: 9.811569690704346
Epoch: 1, Steps: 227 Train Loss: 29.5221 (Forecasting Loss:1.0243 + XiCon Loss:2.8498 x Lambda(10.0)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932089).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.4533405
	speed: 0.0441s/iter; left time: 985.6878s
	iters: 200, epoch: 2 | loss: 28.9982681
	speed: 0.0412s/iter; left time: 916.6366s
Epoch: 2 cost time: 9.688814401626587
Epoch: 2, Steps: 227 Train Loss: 29.1221 (Forecasting Loss:0.6694 + XiCon Loss:2.8453 x Lambda(10.0)), Vali MSE Loss: 1.2131 Test MSE Loss: 1.2808
Validation loss decreased (1.932089 --> 1.213131).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.9006462
	speed: 0.0448s/iter; left time: 992.2187s
	iters: 200, epoch: 3 | loss: 29.0755711
	speed: 0.0416s/iter; left time: 916.9373s
Epoch: 3 cost time: 9.794429063796997
Epoch: 3, Steps: 227 Train Loss: 28.9240 (Forecasting Loss:0.6076 + XiCon Loss:2.8316 x Lambda(10.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2731
Validation loss decreased (1.213131 --> 1.194225).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.6958408
	speed: 0.0459s/iter; left time: 1006.1526s
	iters: 200, epoch: 4 | loss: 28.3900185
	speed: 0.0422s/iter; left time: 921.7703s
Epoch: 4 cost time: 9.997508764266968
Epoch: 4, Steps: 227 Train Loss: 28.8221 (Forecasting Loss:0.6004 + XiCon Loss:2.8222 x Lambda(10.0)), Vali MSE Loss: 1.1884 Test MSE Loss: 1.2712
Validation loss decreased (1.194225 --> 1.188432).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 29.4629688
	speed: 0.0454s/iter; left time: 984.0302s
	iters: 200, epoch: 5 | loss: 28.9563427
	speed: 0.0422s/iter; left time: 910.5088s
Epoch: 5 cost time: 9.905936002731323
Epoch: 5, Steps: 227 Train Loss: 28.7877 (Forecasting Loss:0.5976 + XiCon Loss:2.8190 x Lambda(10.0)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2705
Validation loss decreased (1.188432 --> 1.185818).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 29.2475033
	speed: 0.0457s/iter; left time: 981.0992s
	iters: 200, epoch: 6 | loss: 28.6694870
	speed: 0.0425s/iter; left time: 907.2573s
Epoch: 6 cost time: 10.001943111419678
Epoch: 6, Steps: 227 Train Loss: 28.7433 (Forecasting Loss:0.5962 + XiCon Loss:2.8147 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2702
Validation loss decreased (1.185818 --> 1.184099).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.4616070
	speed: 0.0455s/iter; left time: 966.2112s
	iters: 200, epoch: 7 | loss: 29.0053425
	speed: 0.0424s/iter; left time: 895.3074s
Epoch: 7 cost time: 9.994678258895874
Epoch: 7, Steps: 227 Train Loss: 28.7675 (Forecasting Loss:0.5955 + XiCon Loss:2.8172 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2700
Validation loss decreased (1.184099 --> 1.183823).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.6626205
	speed: 0.0459s/iter; left time: 965.0463s
	iters: 200, epoch: 8 | loss: 29.1065159
	speed: 0.0416s/iter; left time: 869.4247s
Epoch: 8 cost time: 9.975045204162598
Epoch: 8, Steps: 227 Train Loss: 28.7831 (Forecasting Loss:0.5952 + XiCon Loss:2.8188 x Lambda(10.0)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2699
Validation loss decreased (1.183823 --> 1.183399).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.2708015
	speed: 0.0458s/iter; left time: 951.3631s
	iters: 200, epoch: 9 | loss: 28.3334465
	speed: 0.0421s/iter; left time: 869.9460s
Epoch: 9 cost time: 9.961577892303467
Epoch: 9, Steps: 227 Train Loss: 28.7309 (Forecasting Loss:0.5950 + XiCon Loss:2.8136 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2699
Validation loss decreased (1.183399 --> 1.182158).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.3680630
	speed: 0.0458s/iter; left time: 940.7567s
	iters: 200, epoch: 10 | loss: 28.9015293
	speed: 0.0424s/iter; left time: 867.2969s
Epoch: 10 cost time: 10.01028823852539
Epoch: 10, Steps: 227 Train Loss: 28.7651 (Forecasting Loss:0.5949 + XiCon Loss:2.8170 x Lambda(10.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 28.1412754
	speed: 0.0456s/iter; left time: 926.2280s
	iters: 200, epoch: 11 | loss: 29.9684696
	speed: 0.0425s/iter; left time: 859.8661s
Epoch: 11 cost time: 10.014119625091553
Epoch: 11, Steps: 227 Train Loss: 28.7423 (Forecasting Loss:0.5948 + XiCon Loss:2.8147 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 28.7090473
	speed: 0.0465s/iter; left time: 934.1204s
	iters: 200, epoch: 12 | loss: 28.6953926
	speed: 0.0430s/iter; left time: 859.7276s
Epoch: 12 cost time: 10.091936349868774
Epoch: 12, Steps: 227 Train Loss: 28.7517 (Forecasting Loss:0.5948 + XiCon Loss:2.8157 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 28.6010342
	speed: 0.0455s/iter; left time: 904.3086s
	iters: 200, epoch: 13 | loss: 28.5960732
	speed: 0.0421s/iter; left time: 832.4947s
Epoch: 13 cost time: 9.969628810882568
Epoch: 13, Steps: 227 Train Loss: 28.7445 (Forecasting Loss:0.5949 + XiCon Loss:2.8150 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.4231129
	speed: 0.0461s/iter; left time: 906.6822s
	iters: 200, epoch: 14 | loss: 29.2696667
	speed: 0.0427s/iter; left time: 834.9119s
Epoch: 14 cost time: 10.046410322189331
Epoch: 14, Steps: 227 Train Loss: 28.7220 (Forecasting Loss:0.5948 + XiCon Loss:2.8127 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.9477234
	speed: 0.0458s/iter; left time: 889.0153s
	iters: 200, epoch: 15 | loss: 29.6411266
	speed: 0.0418s/iter; left time: 808.1756s
Epoch: 15 cost time: 9.971102952957153
Epoch: 15, Steps: 227 Train Loss: 28.7600 (Forecasting Loss:0.5947 + XiCon Loss:2.8165 x Lambda(10.0)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2698
Validation loss decreased (1.182158 --> 1.181885).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 28.3175373
	speed: 0.0463s/iter; left time: 888.4809s
	iters: 200, epoch: 16 | loss: 28.7368946
	speed: 0.0427s/iter; left time: 814.6046s
Epoch: 16 cost time: 10.059118747711182
Epoch: 16, Steps: 227 Train Loss: 28.7620 (Forecasting Loss:0.5947 + XiCon Loss:2.8167 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.6169319
	speed: 0.0451s/iter; left time: 854.8123s
	iters: 200, epoch: 17 | loss: 28.7426739
	speed: 0.0434s/iter; left time: 818.1500s
Epoch: 17 cost time: 10.09574580192566
Epoch: 17, Steps: 227 Train Loss: 28.7645 (Forecasting Loss:0.5948 + XiCon Loss:2.8170 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 29.2670860
	speed: 0.0459s/iter; left time: 859.4542s
	iters: 200, epoch: 18 | loss: 28.0603867
	speed: 0.0424s/iter; left time: 790.2646s
Epoch: 18 cost time: 10.015237092971802
Epoch: 18, Steps: 227 Train Loss: 28.7204 (Forecasting Loss:0.5947 + XiCon Loss:2.8126 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.3126869
	speed: 0.0456s/iter; left time: 843.7177s
	iters: 200, epoch: 19 | loss: 28.5857201
	speed: 0.0422s/iter; left time: 777.8798s
Epoch: 19 cost time: 9.990938425064087
Epoch: 19, Steps: 227 Train Loss: 28.7592 (Forecasting Loss:0.5947 + XiCon Loss:2.8164 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.7179241
	speed: 0.0454s/iter; left time: 829.9943s
	iters: 200, epoch: 20 | loss: 28.9283428
	speed: 0.0429s/iter; left time: 780.4309s
Epoch: 20 cost time: 10.01073169708252
Epoch: 20, Steps: 227 Train Loss: 28.7674 (Forecasting Loss:0.5948 + XiCon Loss:2.8173 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 28.5208931
	speed: 0.0460s/iter; left time: 830.2348s
	iters: 200, epoch: 21 | loss: 28.3875961
	speed: 0.0418s/iter; left time: 749.8896s
Epoch: 21 cost time: 9.948737382888794
Epoch: 21, Steps: 227 Train Loss: 28.7359 (Forecasting Loss:0.5947 + XiCon Loss:2.8141 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.0519028
	speed: 0.0452s/iter; left time: 805.6191s
	iters: 200, epoch: 22 | loss: 28.4412079
	speed: 0.0432s/iter; left time: 766.8412s
Epoch: 22 cost time: 10.044163227081299
Epoch: 22, Steps: 227 Train Loss: 28.7619 (Forecasting Loss:0.5947 + XiCon Loss:2.8167 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.4779377
	speed: 0.0470s/iter; left time: 827.5309s
	iters: 200, epoch: 23 | loss: 28.7698555
	speed: 0.0429s/iter; left time: 751.5793s
Epoch: 23 cost time: 10.168606519699097
Epoch: 23, Steps: 227 Train Loss: 28.7035 (Forecasting Loss:0.5947 + XiCon Loss:2.8109 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 29.0108070
	speed: 0.0456s/iter; left time: 792.3329s
	iters: 200, epoch: 24 | loss: 29.2840023
	speed: 0.0425s/iter; left time: 734.7555s
Epoch: 24 cost time: 10.011295795440674
Epoch: 24, Steps: 227 Train Loss: 28.7152 (Forecasting Loss:0.5946 + XiCon Loss:2.8121 x Lambda(10.0)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 29.0976028
	speed: 0.0455s/iter; left time: 780.0896s
	iters: 200, epoch: 25 | loss: 28.1277809
	speed: 0.0424s/iter; left time: 722.8473s
Epoch: 25 cost time: 9.957735061645508
Epoch: 25, Steps: 227 Train Loss: 28.7364 (Forecasting Loss:0.5948 + XiCon Loss:2.8142 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5867717266082764, mae:0.9528710246086121, mape:6.204555511474609, mspe:4737.0537109375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9651
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 30.1442585
	speed: 0.0447s/iter; left time: 1010.6604s
	iters: 200, epoch: 1 | loss: 30.2724113
	speed: 0.0409s/iter; left time: 919.7398s
Epoch: 1 cost time: 9.705975532531738
Epoch: 1, Steps: 227 Train Loss: 29.6569 (Forecasting Loss:1.0400 + XiCon Loss:2.8617 x Lambda(10.0)), Vali MSE Loss: 1.9472 Test MSE Loss: 1.3972
Validation loss decreased (inf --> 1.947248).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.3919563
	speed: 0.0444s/iter; left time: 992.4527s
	iters: 200, epoch: 2 | loss: 28.8397884
	speed: 0.0411s/iter; left time: 916.0874s
Epoch: 2 cost time: 9.72090196609497
Epoch: 2, Steps: 227 Train Loss: 29.0772 (Forecasting Loss:0.6718 + XiCon Loss:2.8405 x Lambda(10.0)), Vali MSE Loss: 1.2059 Test MSE Loss: 1.2763
Validation loss decreased (1.947248 --> 1.205860).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.2800674
	speed: 0.0454s/iter; left time: 1005.6018s
	iters: 200, epoch: 3 | loss: 27.7330532
	speed: 0.0414s/iter; left time: 912.8669s
Epoch: 3 cost time: 9.847273349761963
Epoch: 3, Steps: 227 Train Loss: 28.6307 (Forecasting Loss:0.6077 + XiCon Loss:2.8023 x Lambda(10.0)), Vali MSE Loss: 1.1884 Test MSE Loss: 1.2693
Validation loss decreased (1.205860 --> 1.188386).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.2855530
	speed: 0.0445s/iter; left time: 976.4475s
	iters: 200, epoch: 4 | loss: 28.7134590
	speed: 0.0414s/iter; left time: 903.3063s
Epoch: 4 cost time: 9.764570713043213
Epoch: 4, Steps: 227 Train Loss: 28.2126 (Forecasting Loss:0.6005 + XiCon Loss:2.7612 x Lambda(10.0)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2680
Validation loss decreased (1.188386 --> 1.184832).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 27.9960060
	speed: 0.0449s/iter; left time: 974.3668s
	iters: 200, epoch: 5 | loss: 27.8765869
	speed: 0.0418s/iter; left time: 902.9371s
Epoch: 5 cost time: 9.869304180145264
Epoch: 5, Steps: 227 Train Loss: 27.9648 (Forecasting Loss:0.5977 + XiCon Loss:2.7367 x Lambda(10.0)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2674
Validation loss decreased (1.184832 --> 1.181356).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.8778973
	speed: 0.0446s/iter; left time: 958.2308s
	iters: 200, epoch: 6 | loss: 27.5311127
	speed: 0.0425s/iter; left time: 907.0870s
Epoch: 6 cost time: 9.927182674407959
Epoch: 6, Steps: 227 Train Loss: 27.8511 (Forecasting Loss:0.5965 + XiCon Loss:2.7255 x Lambda(10.0)), Vali MSE Loss: 1.1810 Test MSE Loss: 1.2670
Validation loss decreased (1.181356 --> 1.180975).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 27.2508507
	speed: 0.0449s/iter; left time: 953.5552s
	iters: 200, epoch: 7 | loss: 27.2722187
	speed: 0.0424s/iter; left time: 895.7594s
Epoch: 7 cost time: 9.925659894943237
Epoch: 7, Steps: 227 Train Loss: 27.7876 (Forecasting Loss:0.5957 + XiCon Loss:2.7192 x Lambda(10.0)), Vali MSE Loss: 1.1806 Test MSE Loss: 1.2668
Validation loss decreased (1.180975 --> 1.180635).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.5730057
	speed: 0.0460s/iter; left time: 966.0908s
	iters: 200, epoch: 8 | loss: 27.2410049
	speed: 0.0419s/iter; left time: 877.1425s
Epoch: 8 cost time: 9.992033958435059
Epoch: 8, Steps: 227 Train Loss: 27.7380 (Forecasting Loss:0.5955 + XiCon Loss:2.7143 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
Validation loss decreased (1.180635 --> 1.179856).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 27.7129536
	speed: 0.0450s/iter; left time: 934.4465s
	iters: 200, epoch: 9 | loss: 27.2304821
	speed: 0.0421s/iter; left time: 871.7440s
Epoch: 9 cost time: 9.892806768417358
Epoch: 9, Steps: 227 Train Loss: 27.7559 (Forecasting Loss:0.5954 + XiCon Loss:2.7160 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 27.4918690
	speed: 0.0485s/iter; left time: 996.9733s
	iters: 200, epoch: 10 | loss: 28.1090488
	speed: 0.0421s/iter; left time: 861.7262s
Epoch: 10 cost time: 10.307838439941406
Epoch: 10, Steps: 227 Train Loss: 27.7259 (Forecasting Loss:0.5952 + XiCon Loss:2.7131 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2666
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.4183655
	speed: 0.0445s/iter; left time: 904.9932s
	iters: 200, epoch: 11 | loss: 27.6382790
	speed: 0.0423s/iter; left time: 855.2867s
Epoch: 11 cost time: 9.915100336074829
Epoch: 11, Steps: 227 Train Loss: 27.7748 (Forecasting Loss:0.5950 + XiCon Loss:2.7180 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2666
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.2965527
	speed: 0.0453s/iter; left time: 911.4685s
	iters: 200, epoch: 12 | loss: 27.5215244
	speed: 0.0431s/iter; left time: 861.7436s
Epoch: 12 cost time: 10.034432172775269
Epoch: 12, Steps: 227 Train Loss: 27.7631 (Forecasting Loss:0.5950 + XiCon Loss:2.7168 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2666
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.3158550
	speed: 0.0443s/iter; left time: 881.0283s
	iters: 200, epoch: 13 | loss: 27.4621964
	speed: 0.0429s/iter; left time: 848.1930s
Epoch: 13 cost time: 9.921607971191406
Epoch: 13, Steps: 227 Train Loss: 27.7636 (Forecasting Loss:0.5950 + XiCon Loss:2.7169 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2666
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.9650841
	speed: 0.0460s/iter; left time: 903.7765s
	iters: 200, epoch: 14 | loss: 27.6665325
	speed: 0.0425s/iter; left time: 831.7141s
Epoch: 14 cost time: 10.008047819137573
Epoch: 14, Steps: 227 Train Loss: 27.7021 (Forecasting Loss:0.5951 + XiCon Loss:2.7107 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
Validation loss decreased (1.179856 --> 1.179627).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.4147663
	speed: 0.0452s/iter; left time: 877.6400s
	iters: 200, epoch: 15 | loss: 27.2152538
	speed: 0.0424s/iter; left time: 818.5949s
Epoch: 15 cost time: 10.087672710418701
Epoch: 15, Steps: 227 Train Loss: 27.7060 (Forecasting Loss:0.5950 + XiCon Loss:2.7111 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2666
Validation loss decreased (1.179627 --> 1.179390).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.7248611
	speed: 0.0454s/iter; left time: 871.7529s
	iters: 200, epoch: 16 | loss: 27.5558853
	speed: 0.0424s/iter; left time: 809.8978s
Epoch: 16 cost time: 9.993767261505127
Epoch: 16, Steps: 227 Train Loss: 27.7417 (Forecasting Loss:0.5950 + XiCon Loss:2.7147 x Lambda(10.0)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2666
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.0866013
	speed: 0.0454s/iter; left time: 860.9356s
	iters: 200, epoch: 17 | loss: 27.6805916
	speed: 0.0429s/iter; left time: 808.9107s
Epoch: 17 cost time: 10.009010314941406
Epoch: 17, Steps: 227 Train Loss: 27.7336 (Forecasting Loss:0.5951 + XiCon Loss:2.7139 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2666
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.7489681
	speed: 0.0443s/iter; left time: 830.3553s
	iters: 200, epoch: 18 | loss: 27.6440620
	speed: 0.0421s/iter; left time: 784.3953s
Epoch: 18 cost time: 9.798570156097412
Epoch: 18, Steps: 227 Train Loss: 27.6961 (Forecasting Loss:0.5951 + XiCon Loss:2.7101 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2666
Validation loss decreased (1.179390 --> 1.179349).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 27.7953663
	speed: 0.0443s/iter; left time: 821.0893s
	iters: 200, epoch: 19 | loss: 27.6621513
	speed: 0.0415s/iter; left time: 763.5412s
Epoch: 19 cost time: 9.748907566070557
Epoch: 19, Steps: 227 Train Loss: 27.7522 (Forecasting Loss:0.5952 + XiCon Loss:2.7157 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2666
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.6282139
	speed: 0.0462s/iter; left time: 844.6934s
	iters: 200, epoch: 20 | loss: 28.0433578
	speed: 0.0435s/iter; left time: 791.5899s
Epoch: 20 cost time: 10.157810688018799
Epoch: 20, Steps: 227 Train Loss: 27.7440 (Forecasting Loss:0.5951 + XiCon Loss:2.7149 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2666
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.5713444
	speed: 0.0446s/iter; left time: 805.8657s
	iters: 200, epoch: 21 | loss: 27.0700340
	speed: 0.0422s/iter; left time: 757.2562s
Epoch: 21 cost time: 9.868117094039917
Epoch: 21, Steps: 227 Train Loss: 27.7262 (Forecasting Loss:0.5950 + XiCon Loss:2.7131 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.2846966
	speed: 0.0453s/iter; left time: 807.9948s
	iters: 200, epoch: 22 | loss: 28.1939106
	speed: 0.0424s/iter; left time: 752.0148s
Epoch: 22 cost time: 9.97352147102356
Epoch: 22, Steps: 227 Train Loss: 27.7195 (Forecasting Loss:0.5952 + XiCon Loss:2.7124 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2666
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 27.9912739
	speed: 0.0452s/iter; left time: 795.9690s
	iters: 200, epoch: 23 | loss: 28.1117401
	speed: 0.0426s/iter; left time: 745.3825s
Epoch: 23 cost time: 9.98303747177124
Epoch: 23, Steps: 227 Train Loss: 27.7326 (Forecasting Loss:0.5950 + XiCon Loss:2.7138 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2666
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 27.7313042
	speed: 0.0467s/iter; left time: 811.3219s
	iters: 200, epoch: 24 | loss: 27.9517670
	speed: 0.0418s/iter; left time: 722.6680s
Epoch: 24 cost time: 10.04352068901062
Epoch: 24, Steps: 227 Train Loss: 27.7244 (Forecasting Loss:0.5950 + XiCon Loss:2.7129 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.8593903
	speed: 0.0445s/iter; left time: 764.0602s
	iters: 200, epoch: 25 | loss: 27.3632050
	speed: 0.0418s/iter; left time: 712.2147s
Epoch: 25 cost time: 9.786501169204712
Epoch: 25, Steps: 227 Train Loss: 27.7236 (Forecasting Loss:0.5951 + XiCon Loss:2.7129 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 27.6919003
	speed: 0.0448s/iter; left time: 757.6918s
	iters: 200, epoch: 26 | loss: 27.9546318
	speed: 0.0418s/iter; left time: 704.0094s
Epoch: 26 cost time: 9.884364128112793
Epoch: 26, Steps: 227 Train Loss: 27.7553 (Forecasting Loss:0.5951 + XiCon Loss:2.7160 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 27.6567516
	speed: 0.0449s/iter; left time: 750.4069s
	iters: 200, epoch: 27 | loss: 27.2325668
	speed: 0.0424s/iter; left time: 704.3415s
Epoch: 27 cost time: 9.898110628128052
Epoch: 27, Steps: 227 Train Loss: 27.7302 (Forecasting Loss:0.5952 + XiCon Loss:2.7135 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2666
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 27.0676746
	speed: 0.0449s/iter; left time: 739.2857s
	iters: 200, epoch: 28 | loss: 27.5658073
	speed: 0.0428s/iter; left time: 701.5153s
Epoch: 28 cost time: 9.940725088119507
Epoch: 28, Steps: 227 Train Loss: 27.7465 (Forecasting Loss:0.5951 + XiCon Loss:2.7151 x Lambda(10.0)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2666
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5825611352920532, mae:0.950693666934967, mape:6.098560333251953, mspe:4550.08251953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.4194
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 29.4582844
	speed: 0.0475s/iter; left time: 1073.5874s
	iters: 200, epoch: 1 | loss: 28.8327274
	speed: 0.0436s/iter; left time: 981.1146s
Epoch: 1 cost time: 10.334362506866455
Epoch: 1, Steps: 227 Train Loss: 29.4836 (Forecasting Loss:1.1623 + XiCon Loss:2.8321 x Lambda(10.0)), Vali MSE Loss: 2.2089 Test MSE Loss: 1.4658
Validation loss decreased (inf --> 2.208915).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.7614498
	speed: 0.0474s/iter; left time: 1060.0710s
	iters: 200, epoch: 2 | loss: 28.8147755
	speed: 0.0433s/iter; left time: 963.6518s
Epoch: 2 cost time: 10.304460048675537
Epoch: 2, Steps: 227 Train Loss: 28.9404 (Forecasting Loss:0.7702 + XiCon Loss:2.8170 x Lambda(10.0)), Vali MSE Loss: 1.3371 Test MSE Loss: 1.3357
Validation loss decreased (2.208915 --> 1.337086).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.4939060
	speed: 0.0471s/iter; left time: 1043.0708s
	iters: 200, epoch: 3 | loss: 28.7650757
	speed: 0.0430s/iter; left time: 947.3038s
Epoch: 3 cost time: 10.213274002075195
Epoch: 3, Steps: 227 Train Loss: 28.6010 (Forecasting Loss:0.6546 + XiCon Loss:2.7946 x Lambda(10.0)), Vali MSE Loss: 1.2427 Test MSE Loss: 1.3064
Validation loss decreased (1.337086 --> 1.242676).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.7312489
	speed: 0.0474s/iter; left time: 1038.4603s
	iters: 200, epoch: 4 | loss: 27.9465408
	speed: 0.0442s/iter; left time: 965.0973s
Epoch: 4 cost time: 10.427567720413208
Epoch: 4, Steps: 227 Train Loss: 28.4291 (Forecasting Loss:0.6212 + XiCon Loss:2.7808 x Lambda(10.0)), Vali MSE Loss: 1.2059 Test MSE Loss: 1.2947
Validation loss decreased (1.242676 --> 1.205863).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 28.1106567
	speed: 0.0476s/iter; left time: 1033.5396s
	iters: 200, epoch: 5 | loss: 28.5123959
	speed: 0.0445s/iter; left time: 960.5890s
Epoch: 5 cost time: 10.438576936721802
Epoch: 5, Steps: 227 Train Loss: 28.3193 (Forecasting Loss:0.6089 + XiCon Loss:2.7710 x Lambda(10.0)), Vali MSE Loss: 1.1951 Test MSE Loss: 1.2904
Validation loss decreased (1.205863 --> 1.195062).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 28.7069988
	speed: 0.0470s/iter; left time: 1009.1201s
	iters: 200, epoch: 6 | loss: 28.2387028
	speed: 0.0449s/iter; left time: 959.2058s
Epoch: 6 cost time: 10.401483535766602
Epoch: 6, Steps: 227 Train Loss: 28.2676 (Forecasting Loss:0.6042 + XiCon Loss:2.7663 x Lambda(10.0)), Vali MSE Loss: 1.1898 Test MSE Loss: 1.2882
Validation loss decreased (1.195062 --> 1.189809).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.3007431
	speed: 0.0473s/iter; left time: 1003.7453s
	iters: 200, epoch: 7 | loss: 27.9696255
	speed: 0.0444s/iter; left time: 938.4363s
Epoch: 7 cost time: 10.399197816848755
Epoch: 7, Steps: 227 Train Loss: 28.2709 (Forecasting Loss:0.6019 + XiCon Loss:2.7669 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2872
Validation loss decreased (1.189809 --> 1.187466).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.1293697
	speed: 0.0477s/iter; left time: 1002.6051s
	iters: 200, epoch: 8 | loss: 28.2126865
	speed: 0.0435s/iter; left time: 910.0180s
Epoch: 8 cost time: 10.336942911148071
Epoch: 8, Steps: 227 Train Loss: 28.2696 (Forecasting Loss:0.6007 + XiCon Loss:2.7669 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2868
Validation loss decreased (1.187466 --> 1.186988).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.0275421
	speed: 0.0482s/iter; left time: 1000.9339s
	iters: 200, epoch: 9 | loss: 28.3582172
	speed: 0.0438s/iter; left time: 906.7480s
Epoch: 9 cost time: 10.394045114517212
Epoch: 9, Steps: 227 Train Loss: 28.2361 (Forecasting Loss:0.6001 + XiCon Loss:2.7636 x Lambda(10.0)), Vali MSE Loss: 1.1857 Test MSE Loss: 1.2865
Validation loss decreased (1.186988 --> 1.185709).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.5873871
	speed: 0.0470s/iter; left time: 965.4926s
	iters: 200, epoch: 10 | loss: 28.6192112
	speed: 0.0432s/iter; left time: 884.7088s
Epoch: 10 cost time: 10.165923118591309
Epoch: 10, Steps: 227 Train Loss: 28.3018 (Forecasting Loss:0.6001 + XiCon Loss:2.7702 x Lambda(10.0)), Vali MSE Loss: 1.1860 Test MSE Loss: 1.2864
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.8870621
	speed: 0.0479s/iter; left time: 973.1500s
	iters: 200, epoch: 11 | loss: 28.4021645
	speed: 0.0443s/iter; left time: 896.1744s
Epoch: 11 cost time: 10.453317165374756
Epoch: 11, Steps: 227 Train Loss: 28.2519 (Forecasting Loss:0.6000 + XiCon Loss:2.7652 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2864
Validation loss decreased (1.185709 --> 1.185007).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.9183826
	speed: 0.0473s/iter; left time: 950.2557s
	iters: 200, epoch: 12 | loss: 28.5154228
	speed: 0.0437s/iter; left time: 873.7798s
Epoch: 12 cost time: 10.351207971572876
Epoch: 12, Steps: 227 Train Loss: 28.3118 (Forecasting Loss:0.5999 + XiCon Loss:2.7712 x Lambda(10.0)), Vali MSE Loss: 1.1859 Test MSE Loss: 1.2863
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.7580853
	speed: 0.0499s/iter; left time: 991.2917s
	iters: 200, epoch: 13 | loss: 28.2690487
	speed: 0.0447s/iter; left time: 884.2767s
Epoch: 13 cost time: 10.697311401367188
Epoch: 13, Steps: 227 Train Loss: 28.2465 (Forecasting Loss:0.5999 + XiCon Loss:2.7647 x Lambda(10.0)), Vali MSE Loss: 1.1854 Test MSE Loss: 1.2863
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.0686493
	speed: 0.0486s/iter; left time: 954.4746s
	iters: 200, epoch: 14 | loss: 27.8725796
	speed: 0.0439s/iter; left time: 858.3586s
Epoch: 14 cost time: 10.462544202804565
Epoch: 14, Steps: 227 Train Loss: 28.2598 (Forecasting Loss:0.5999 + XiCon Loss:2.7660 x Lambda(10.0)), Vali MSE Loss: 1.1856 Test MSE Loss: 1.2863
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.8983383
	speed: 0.0478s/iter; left time: 928.1543s
	iters: 200, epoch: 15 | loss: 28.1625938
	speed: 0.0445s/iter; left time: 859.6802s
Epoch: 15 cost time: 10.438718557357788
Epoch: 15, Steps: 227 Train Loss: 28.2538 (Forecasting Loss:0.5997 + XiCon Loss:2.7654 x Lambda(10.0)), Vali MSE Loss: 1.1851 Test MSE Loss: 1.2863
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.4247360
	speed: 0.0472s/iter; left time: 906.0778s
	iters: 200, epoch: 16 | loss: 28.0525894
	speed: 0.0447s/iter; left time: 853.8390s
Epoch: 16 cost time: 10.473726987838745
Epoch: 16, Steps: 227 Train Loss: 28.2318 (Forecasting Loss:0.5998 + XiCon Loss:2.7632 x Lambda(10.0)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2863
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.0598831
	speed: 0.0472s/iter; left time: 896.2153s
	iters: 200, epoch: 17 | loss: 28.9656391
	speed: 0.0443s/iter; left time: 836.4928s
Epoch: 17 cost time: 10.408782958984375
Epoch: 17, Steps: 227 Train Loss: 28.2697 (Forecasting Loss:0.5998 + XiCon Loss:2.7670 x Lambda(10.0)), Vali MSE Loss: 1.1849 Test MSE Loss: 1.2863
Validation loss decreased (1.185007 --> 1.184918).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 28.5986042
	speed: 0.0480s/iter; left time: 900.5020s
	iters: 200, epoch: 18 | loss: 28.1235199
	speed: 0.0442s/iter; left time: 824.6450s
Epoch: 18 cost time: 10.444843530654907
Epoch: 18, Steps: 227 Train Loss: 28.2806 (Forecasting Loss:0.6000 + XiCon Loss:2.7681 x Lambda(10.0)), Vali MSE Loss: 1.1853 Test MSE Loss: 1.2863
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.5148182
	speed: 0.0486s/iter; left time: 899.5658s
	iters: 200, epoch: 19 | loss: 27.8668785
	speed: 0.0441s/iter; left time: 812.7975s
Epoch: 19 cost time: 10.50209355354309
Epoch: 19, Steps: 227 Train Loss: 28.2353 (Forecasting Loss:0.5997 + XiCon Loss:2.7636 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2863
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.5300236
	speed: 0.0478s/iter; left time: 874.2589s
	iters: 200, epoch: 20 | loss: 28.1422997
	speed: 0.0440s/iter; left time: 801.1676s
Epoch: 20 cost time: 10.411261081695557
Epoch: 20, Steps: 227 Train Loss: 28.2959 (Forecasting Loss:0.5999 + XiCon Loss:2.7696 x Lambda(10.0)), Vali MSE Loss: 1.1856 Test MSE Loss: 1.2863
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.4379673
	speed: 0.0491s/iter; left time: 887.0172s
	iters: 200, epoch: 21 | loss: 28.0959682
	speed: 0.0442s/iter; left time: 794.0798s
Epoch: 21 cost time: 10.513554096221924
Epoch: 21, Steps: 227 Train Loss: 28.2491 (Forecasting Loss:0.5999 + XiCon Loss:2.7649 x Lambda(10.0)), Vali MSE Loss: 1.1852 Test MSE Loss: 1.2863
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.4098663
	speed: 0.0468s/iter; left time: 835.3445s
	iters: 200, epoch: 22 | loss: 28.0538712
	speed: 0.0432s/iter; left time: 766.0523s
Epoch: 22 cost time: 10.171664237976074
Epoch: 22, Steps: 227 Train Loss: 28.2855 (Forecasting Loss:0.5996 + XiCon Loss:2.7686 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2863
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.5084457
	speed: 0.0485s/iter; left time: 854.2506s
	iters: 200, epoch: 23 | loss: 28.2375870
	speed: 0.0449s/iter; left time: 785.5949s
Epoch: 23 cost time: 10.59202790260315
Epoch: 23, Steps: 227 Train Loss: 28.2590 (Forecasting Loss:0.5997 + XiCon Loss:2.7659 x Lambda(10.0)), Vali MSE Loss: 1.1854 Test MSE Loss: 1.2863
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.2264805
	speed: 0.0474s/iter; left time: 824.0355s
	iters: 200, epoch: 24 | loss: 28.3478508
	speed: 0.0455s/iter; left time: 786.3193s
Epoch: 24 cost time: 10.507603168487549
Epoch: 24, Steps: 227 Train Loss: 28.2752 (Forecasting Loss:0.5997 + XiCon Loss:2.7676 x Lambda(10.0)), Vali MSE Loss: 1.1856 Test MSE Loss: 1.2863
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 28.6943741
	speed: 0.0479s/iter; left time: 822.1889s
	iters: 200, epoch: 25 | loss: 27.6578465
	speed: 0.0434s/iter; left time: 739.4546s
Epoch: 25 cost time: 10.346277475357056
Epoch: 25, Steps: 227 Train Loss: 28.2695 (Forecasting Loss:0.5996 + XiCon Loss:2.7670 x Lambda(10.0)), Vali MSE Loss: 1.1854 Test MSE Loss: 1.2863
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 28.7205105
	speed: 0.0455s/iter; left time: 770.1546s
	iters: 200, epoch: 26 | loss: 27.9642658
	speed: 0.0425s/iter; left time: 714.4842s
Epoch: 26 cost time: 10.036155700683594
Epoch: 26, Steps: 227 Train Loss: 28.2270 (Forecasting Loss:0.5998 + XiCon Loss:2.7627 x Lambda(10.0)), Vali MSE Loss: 1.1853 Test MSE Loss: 1.2863
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.4499950
	speed: 0.0482s/iter; left time: 804.2868s
	iters: 200, epoch: 27 | loss: 28.2075138
	speed: 0.0441s/iter; left time: 732.1352s
Epoch: 27 cost time: 10.41176962852478
Epoch: 27, Steps: 227 Train Loss: 28.2634 (Forecasting Loss:0.5996 + XiCon Loss:2.7664 x Lambda(10.0)), Vali MSE Loss: 1.1857 Test MSE Loss: 1.2863
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.60744047164917, mae:0.9651823043823242, mape:6.5888237953186035, mspe:5393.302734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.4951
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 29.4810352
	speed: 0.0453s/iter; left time: 1024.9116s
	iters: 200, epoch: 1 | loss: 29.4944572
	speed: 0.0418s/iter; left time: 939.4847s
Epoch: 1 cost time: 9.86466646194458
Epoch: 1, Steps: 227 Train Loss: 29.6596 (Forecasting Loss:1.0351 + XiCon Loss:2.8624 x Lambda(10.0)), Vali MSE Loss: 1.9647 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964682).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.9343052
	speed: 0.0444s/iter; left time: 994.0858s
	iters: 200, epoch: 2 | loss: 28.8707905
	speed: 0.0419s/iter; left time: 934.2418s
Epoch: 2 cost time: 9.785576105117798
Epoch: 2, Steps: 227 Train Loss: 29.1447 (Forecasting Loss:0.6716 + XiCon Loss:2.8473 x Lambda(10.0)), Vali MSE Loss: 1.2187 Test MSE Loss: 1.2818
Validation loss decreased (1.964682 --> 1.218706).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.7531776
	speed: 0.0449s/iter; left time: 994.7138s
	iters: 200, epoch: 3 | loss: 28.6931782
	speed: 0.0415s/iter; left time: 914.7705s
Epoch: 3 cost time: 9.837489366531372
Epoch: 3, Steps: 227 Train Loss: 28.8360 (Forecasting Loss:0.6086 + XiCon Loss:2.8227 x Lambda(10.0)), Vali MSE Loss: 1.1996 Test MSE Loss: 1.2743
Validation loss decreased (1.218706 --> 1.199644).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.3861580
	speed: 0.0451s/iter; left time: 988.7531s
	iters: 200, epoch: 4 | loss: 28.7731647
	speed: 0.0419s/iter; left time: 913.6978s
Epoch: 4 cost time: 9.936949253082275
Epoch: 4, Steps: 227 Train Loss: 28.7200 (Forecasting Loss:0.6010 + XiCon Loss:2.8119 x Lambda(10.0)), Vali MSE Loss: 1.1923 Test MSE Loss: 1.2722
Validation loss decreased (1.199644 --> 1.192337).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 28.2497101
	speed: 0.0458s/iter; left time: 992.4868s
	iters: 200, epoch: 5 | loss: 28.2212963
	speed: 0.0419s/iter; left time: 905.0519s
Epoch: 5 cost time: 9.928095817565918
Epoch: 5, Steps: 227 Train Loss: 28.6330 (Forecasting Loss:0.5980 + XiCon Loss:2.8035 x Lambda(10.0)), Vali MSE Loss: 1.1892 Test MSE Loss: 1.2712
Validation loss decreased (1.192337 --> 1.189184).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 28.5101547
	speed: 0.0453s/iter; left time: 972.4371s
	iters: 200, epoch: 6 | loss: 28.8369274
	speed: 0.0423s/iter; left time: 902.9913s
Epoch: 6 cost time: 9.917720556259155
Epoch: 6, Steps: 227 Train Loss: 28.6033 (Forecasting Loss:0.5967 + XiCon Loss:2.8007 x Lambda(10.0)), Vali MSE Loss: 1.1879 Test MSE Loss: 1.2708
Validation loss decreased (1.189184 --> 1.187930).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.2320900
	speed: 0.0467s/iter; left time: 990.8790s
	iters: 200, epoch: 7 | loss: 28.7262516
	speed: 0.0425s/iter; left time: 897.9043s
Epoch: 7 cost time: 10.106169939041138
Epoch: 7, Steps: 227 Train Loss: 28.5917 (Forecasting Loss:0.5962 + XiCon Loss:2.7995 x Lambda(10.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2706
Validation loss decreased (1.187930 --> 1.186922).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.2559185
	speed: 0.0457s/iter; left time: 959.5410s
	iters: 200, epoch: 8 | loss: 28.1219482
	speed: 0.0441s/iter; left time: 922.1007s
Epoch: 8 cost time: 10.195495367050171
Epoch: 8, Steps: 227 Train Loss: 28.5911 (Forecasting Loss:0.5959 + XiCon Loss:2.7995 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
Validation loss decreased (1.186922 --> 1.186803).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.1505222
	speed: 0.0474s/iter; left time: 985.2411s
	iters: 200, epoch: 9 | loss: 28.8975391
	speed: 0.0427s/iter; left time: 884.0776s
Epoch: 9 cost time: 10.253685235977173
Epoch: 9, Steps: 227 Train Loss: 28.5622 (Forecasting Loss:0.5956 + XiCon Loss:2.7967 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.8830738
	speed: 0.0466s/iter; left time: 958.7475s
	iters: 200, epoch: 10 | loss: 28.8852730
	speed: 0.0429s/iter; left time: 878.6326s
Epoch: 10 cost time: 10.151313066482544
Epoch: 10, Steps: 227 Train Loss: 28.5872 (Forecasting Loss:0.5953 + XiCon Loss:2.7992 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 28.4528542
	speed: 0.0476s/iter; left time: 967.4756s
	iters: 200, epoch: 11 | loss: 28.4541283
	speed: 0.0427s/iter; left time: 864.6975s
Epoch: 11 cost time: 10.252871751785278
Epoch: 11, Steps: 227 Train Loss: 28.5484 (Forecasting Loss:0.5952 + XiCon Loss:2.7953 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 28.3938332
	speed: 0.0457s/iter; left time: 919.2047s
	iters: 200, epoch: 12 | loss: 28.3601036
	speed: 0.0419s/iter; left time: 838.8223s
Epoch: 12 cost time: 9.942165851593018
Epoch: 12, Steps: 227 Train Loss: 28.5529 (Forecasting Loss:0.5952 + XiCon Loss:2.7958 x Lambda(10.0)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 28.3182373
	speed: 0.0446s/iter; left time: 886.1976s
	iters: 200, epoch: 13 | loss: 28.8014240
	speed: 0.0417s/iter; left time: 824.5505s
Epoch: 13 cost time: 9.783422470092773
Epoch: 13, Steps: 227 Train Loss: 28.5716 (Forecasting Loss:0.5952 + XiCon Loss:2.7976 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.5540791
	speed: 0.0459s/iter; left time: 902.7586s
	iters: 200, epoch: 14 | loss: 28.2744331
	speed: 0.0421s/iter; left time: 822.5626s
Epoch: 14 cost time: 9.953198909759521
Epoch: 14, Steps: 227 Train Loss: 28.5834 (Forecasting Loss:0.5952 + XiCon Loss:2.7988 x Lambda(10.0)), Vali MSE Loss: 1.1860 Test MSE Loss: 1.2705
Validation loss decreased (1.186803 --> 1.186014).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.7485390
	speed: 0.0457s/iter; left time: 887.0497s
	iters: 200, epoch: 15 | loss: 28.8557777
	speed: 0.0426s/iter; left time: 822.6356s
Epoch: 15 cost time: 10.006205797195435
Epoch: 15, Steps: 227 Train Loss: 28.5774 (Forecasting Loss:0.5953 + XiCon Loss:2.7982 x Lambda(10.0)), Vali MSE Loss: 1.1865 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 28.7938290
	speed: 0.0455s/iter; left time: 872.8553s
	iters: 200, epoch: 16 | loss: 28.5950451
	speed: 0.0421s/iter; left time: 804.6302s
Epoch: 16 cost time: 9.969356298446655
Epoch: 16, Steps: 227 Train Loss: 28.5852 (Forecasting Loss:0.5952 + XiCon Loss:2.7990 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.2005768
	speed: 0.0462s/iter; left time: 875.8588s
	iters: 200, epoch: 17 | loss: 28.6398087
	speed: 0.0428s/iter; left time: 807.0508s
Epoch: 17 cost time: 10.070844173431396
Epoch: 17, Steps: 227 Train Loss: 28.5599 (Forecasting Loss:0.5952 + XiCon Loss:2.7965 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 28.4819050
	speed: 0.0470s/iter; left time: 881.1565s
	iters: 200, epoch: 18 | loss: 28.4475250
	speed: 0.0436s/iter; left time: 813.2892s
Epoch: 18 cost time: 10.234349012374878
Epoch: 18, Steps: 227 Train Loss: 28.5581 (Forecasting Loss:0.5952 + XiCon Loss:2.7963 x Lambda(10.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.0325489
	speed: 0.0465s/iter; left time: 860.4188s
	iters: 200, epoch: 19 | loss: 28.4128666
	speed: 0.0435s/iter; left time: 800.4440s
Epoch: 19 cost time: 10.211783409118652
Epoch: 19, Steps: 227 Train Loss: 28.5868 (Forecasting Loss:0.5951 + XiCon Loss:2.7992 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.6584301
	speed: 0.0462s/iter; left time: 844.0217s
	iters: 200, epoch: 20 | loss: 28.4806423
	speed: 0.0423s/iter; left time: 768.8317s
Epoch: 20 cost time: 10.035348176956177
Epoch: 20, Steps: 227 Train Loss: 28.5913 (Forecasting Loss:0.5951 + XiCon Loss:2.7996 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.8754272
	speed: 0.0453s/iter; left time: 818.1960s
	iters: 200, epoch: 21 | loss: 29.0604439
	speed: 0.0426s/iter; left time: 765.4137s
Epoch: 21 cost time: 9.953017950057983
Epoch: 21, Steps: 227 Train Loss: 28.5695 (Forecasting Loss:0.5952 + XiCon Loss:2.7974 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.0737324
	speed: 0.0458s/iter; left time: 816.9935s
	iters: 200, epoch: 22 | loss: 28.3743114
	speed: 0.0432s/iter; left time: 765.4923s
Epoch: 22 cost time: 10.08795952796936
Epoch: 22, Steps: 227 Train Loss: 28.5594 (Forecasting Loss:0.5953 + XiCon Loss:2.7964 x Lambda(10.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.5233459
	speed: 0.0448s/iter; left time: 789.3208s
	iters: 200, epoch: 23 | loss: 28.9263992
	speed: 0.0432s/iter; left time: 756.2501s
Epoch: 23 cost time: 9.988645076751709
Epoch: 23, Steps: 227 Train Loss: 28.5717 (Forecasting Loss:0.5953 + XiCon Loss:2.7976 x Lambda(10.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2705
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.4204998
	speed: 0.0449s/iter; left time: 780.4694s
	iters: 200, epoch: 24 | loss: 28.7386684
	speed: 0.0427s/iter; left time: 738.1432s
Epoch: 24 cost time: 9.99157428741455
Epoch: 24, Steps: 227 Train Loss: 28.5763 (Forecasting Loss:0.5953 + XiCon Loss:2.7981 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2705
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.587965965270996, mae:0.9529529213905334, mape:6.185060977935791, mspe:4716.408203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5908+-0.01196, MAE:0.9553+-0.00710, MAPE:6.2682+-0.23441, MSPE:4849.6548+-400.29629, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
