Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4078
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6554928
	speed: 0.0184s/iter; left time: 233.8489s
Epoch: 1 cost time: 2.1846699714660645
Epoch: 1, Steps: 128 Train Loss: 30.8552 (Forecasting Loss:0.2444 + XiCon Loss:3.0611 x Lambda(10.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173658).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.1810608
	speed: 0.0143s/iter; left time: 180.0721s
Epoch: 2 cost time: 1.7635340690612793
Epoch: 2, Steps: 128 Train Loss: 28.8105 (Forecasting Loss:0.2465 + XiCon Loss:2.8564 x Lambda(10.0)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 27.9415169
	speed: 0.0148s/iter; left time: 183.8678s
Epoch: 3 cost time: 1.825455665588379
Epoch: 3, Steps: 128 Train Loss: 28.3638 (Forecasting Loss:0.2304 + XiCon Loss:2.8133 x Lambda(10.0)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1216
Validation loss decreased (0.173658 --> 0.167130).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.0608921
	speed: 0.0143s/iter; left time: 175.5298s
Epoch: 4 cost time: 1.7550723552703857
Epoch: 4, Steps: 128 Train Loss: 27.9352 (Forecasting Loss:0.2178 + XiCon Loss:2.7717 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 27.6322536
	speed: 0.0144s/iter; left time: 175.6524s
Epoch: 5 cost time: 1.7763917446136475
Epoch: 5, Steps: 128 Train Loss: 27.9081 (Forecasting Loss:0.2092 + XiCon Loss:2.7699 x Lambda(10.0)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1197
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 27.1982822
	speed: 0.0139s/iter; left time: 167.1131s
Epoch: 6 cost time: 1.7369575500488281
Epoch: 6, Steps: 128 Train Loss: 27.7687 (Forecasting Loss:0.2052 + XiCon Loss:2.7563 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1172
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 27.7053108
	speed: 0.0148s/iter; left time: 176.2158s
Epoch: 7 cost time: 1.8360371589660645
Epoch: 7, Steps: 128 Train Loss: 27.7092 (Forecasting Loss:0.2034 + XiCon Loss:2.7506 x Lambda(10.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1189
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 27.5984688
	speed: 0.0145s/iter; left time: 171.5058s
Epoch: 8 cost time: 1.8181304931640625
Epoch: 8, Steps: 128 Train Loss: 27.7122 (Forecasting Loss:0.2027 + XiCon Loss:2.7510 x Lambda(10.0)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1190
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 27.4692860
	speed: 0.0135s/iter; left time: 158.0336s
Epoch: 9 cost time: 1.685910940170288
Epoch: 9, Steps: 128 Train Loss: 27.7174 (Forecasting Loss:0.2027 + XiCon Loss:2.7515 x Lambda(10.0)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1182
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 27.7130547
	speed: 0.0134s/iter; left time: 154.9593s
Epoch: 10 cost time: 1.6941733360290527
Epoch: 10, Steps: 128 Train Loss: 27.7221 (Forecasting Loss:0.2021 + XiCon Loss:2.7520 x Lambda(10.0)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1185
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 27.6209679
	speed: 0.0136s/iter; left time: 155.6894s
Epoch: 11 cost time: 1.694598913192749
Epoch: 11, Steps: 128 Train Loss: 27.7207 (Forecasting Loss:0.2023 + XiCon Loss:2.7518 x Lambda(10.0)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1186
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 27.6506195
	speed: 0.0141s/iter; left time: 159.6507s
Epoch: 12 cost time: 1.7599399089813232
Epoch: 12, Steps: 128 Train Loss: 27.7148 (Forecasting Loss:0.2019 + XiCon Loss:2.7513 x Lambda(10.0)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1184
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 27.8503971
	speed: 0.0135s/iter; left time: 150.3622s
Epoch: 13 cost time: 1.710500955581665
Epoch: 13, Steps: 128 Train Loss: 27.7287 (Forecasting Loss:0.2018 + XiCon Loss:2.7527 x Lambda(10.0)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1185
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.0584319606423378, mae:0.18478548526763916, mape:0.14835892617702484, mspe:0.04346870258450508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3549
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.3659515
	speed: 0.0137s/iter; left time: 173.4688s
Epoch: 1 cost time: 1.7369892597198486
Epoch: 1, Steps: 128 Train Loss: 30.6521 (Forecasting Loss:0.2444 + XiCon Loss:3.0408 x Lambda(10.0)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1230
Validation loss decreased (inf --> 0.174171).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 31.6021805
	speed: 0.0134s/iter; left time: 168.7285s
Epoch: 2 cost time: 1.6778573989868164
Epoch: 2, Steps: 128 Train Loss: 30.1526 (Forecasting Loss:0.2498 + XiCon Loss:2.9903 x Lambda(10.0)), Vali MSE Loss: 0.1831 Test MSE Loss: 0.1293
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 30.1607018
	speed: 0.0130s/iter; left time: 162.3556s
Epoch: 3 cost time: 1.6393013000488281
Epoch: 3, Steps: 128 Train Loss: 30.1669 (Forecasting Loss:0.2292 + XiCon Loss:2.9938 x Lambda(10.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1188
Validation loss decreased (0.174171 --> 0.168308).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 30.5485172
	speed: 0.0148s/iter; left time: 181.7904s
Epoch: 4 cost time: 1.8146512508392334
Epoch: 4, Steps: 128 Train Loss: 29.8595 (Forecasting Loss:0.2209 + XiCon Loss:2.9639 x Lambda(10.0)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1195
Validation loss decreased (0.168308 --> 0.166989).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.3847523
	speed: 0.0140s/iter; left time: 170.9679s
Epoch: 5 cost time: 1.7380797863006592
Epoch: 5, Steps: 128 Train Loss: 29.8168 (Forecasting Loss:0.2175 + XiCon Loss:2.9599 x Lambda(10.0)), Vali MSE Loss: 0.1664 Test MSE Loss: 0.1159
Validation loss decreased (0.166989 --> 0.166442).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 29.6769772
	speed: 0.0133s/iter; left time: 160.2759s
Epoch: 6 cost time: 1.6719677448272705
Epoch: 6, Steps: 128 Train Loss: 29.5498 (Forecasting Loss:0.2152 + XiCon Loss:2.9335 x Lambda(10.0)), Vali MSE Loss: 0.1651 Test MSE Loss: 0.1153
Validation loss decreased (0.166442 --> 0.165126).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.8600178
	speed: 0.0159s/iter; left time: 189.4257s
Epoch: 7 cost time: 1.929445505142212
Epoch: 7, Steps: 128 Train Loss: 29.6104 (Forecasting Loss:0.2147 + XiCon Loss:2.9396 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1164
Validation loss decreased (0.165126 --> 0.164303).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.4084377
	speed: 0.0141s/iter; left time: 167.0262s
Epoch: 8 cost time: 1.7696528434753418
Epoch: 8, Steps: 128 Train Loss: 29.6419 (Forecasting Loss:0.2138 + XiCon Loss:2.9428 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1157
Validation loss decreased (0.164303 --> 0.163856).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.8572769
	speed: 0.0135s/iter; left time: 158.1895s
Epoch: 9 cost time: 1.6846363544464111
Epoch: 9, Steps: 128 Train Loss: 29.5657 (Forecasting Loss:0.2134 + XiCon Loss:2.9352 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.7879848
	speed: 0.0133s/iter; left time: 153.6578s
Epoch: 10 cost time: 1.7370290756225586
Epoch: 10, Steps: 128 Train Loss: 29.6326 (Forecasting Loss:0.2133 + XiCon Loss:2.9419 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
Validation loss decreased (0.163856 --> 0.163666).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.0703506
	speed: 0.0138s/iter; left time: 157.5324s
Epoch: 11 cost time: 1.7691490650177002
Epoch: 11, Steps: 128 Train Loss: 29.5619 (Forecasting Loss:0.2130 + XiCon Loss:2.9349 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 29.4009647
	speed: 0.0131s/iter; left time: 147.5641s
Epoch: 12 cost time: 1.6415016651153564
Epoch: 12, Steps: 128 Train Loss: 29.5877 (Forecasting Loss:0.2130 + XiCon Loss:2.9375 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 29.7416553
	speed: 0.0136s/iter; left time: 151.8168s
Epoch: 13 cost time: 1.7108216285705566
Epoch: 13, Steps: 128 Train Loss: 29.6347 (Forecasting Loss:0.2129 + XiCon Loss:2.9422 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 30.1006680
	speed: 0.0151s/iter; left time: 166.8586s
Epoch: 14 cost time: 1.8588716983795166
Epoch: 14, Steps: 128 Train Loss: 29.5800 (Forecasting Loss:0.2130 + XiCon Loss:2.9367 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 30.2404594
	speed: 0.0140s/iter; left time: 153.0651s
Epoch: 15 cost time: 1.763167142868042
Epoch: 15, Steps: 128 Train Loss: 29.5936 (Forecasting Loss:0.2130 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1158
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 28.8058414
	speed: 0.0138s/iter; left time: 148.4067s
Epoch: 16 cost time: 1.8435063362121582
Epoch: 16, Steps: 128 Train Loss: 29.5583 (Forecasting Loss:0.2130 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 29.1070251
	speed: 0.0131s/iter; left time: 139.8826s
Epoch: 17 cost time: 1.6597156524658203
Epoch: 17, Steps: 128 Train Loss: 29.5732 (Forecasting Loss:0.2131 + XiCon Loss:2.9360 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 29.3351269
	speed: 0.0134s/iter; left time: 141.4977s
Epoch: 18 cost time: 1.6979660987854004
Epoch: 18, Steps: 128 Train Loss: 29.5141 (Forecasting Loss:0.2131 + XiCon Loss:2.9301 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 29.3921299
	speed: 0.0138s/iter; left time: 143.6104s
Epoch: 19 cost time: 1.7122933864593506
Epoch: 19, Steps: 128 Train Loss: 29.5578 (Forecasting Loss:0.2129 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 30.1243153
	speed: 0.0149s/iter; left time: 153.0129s
Epoch: 20 cost time: 1.8565716743469238
Epoch: 20, Steps: 128 Train Loss: 29.5375 (Forecasting Loss:0.2130 + XiCon Loss:2.9324 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1158
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054190490394830704, mae:0.17744290828704834, mape:0.14149029552936554, mspe:0.037927523255348206 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3724
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.1752129
	speed: 0.0138s/iter; left time: 175.2575s
Epoch: 1 cost time: 1.724745750427246
Epoch: 1, Steps: 128 Train Loss: 30.5969 (Forecasting Loss:0.2445 + XiCon Loss:3.0352 x Lambda(10.0)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.170877).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.8608742
	speed: 0.0146s/iter; left time: 183.1169s
Epoch: 2 cost time: 1.831958293914795
Epoch: 2, Steps: 128 Train Loss: 29.7576 (Forecasting Loss:0.2506 + XiCon Loss:2.9507 x Lambda(10.0)), Vali MSE Loss: 0.1815 Test MSE Loss: 0.1214
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.9245605
	speed: 0.0134s/iter; left time: 167.3783s
Epoch: 3 cost time: 1.6874973773956299
Epoch: 3, Steps: 128 Train Loss: 29.3145 (Forecasting Loss:0.2320 + XiCon Loss:2.9082 x Lambda(10.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1226
Validation loss decreased (0.170877 --> 0.165833).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.2918358
	speed: 0.0143s/iter; left time: 176.0609s
Epoch: 4 cost time: 1.7688753604888916
Epoch: 4, Steps: 128 Train Loss: 28.8871 (Forecasting Loss:0.2231 + XiCon Loss:2.8664 x Lambda(10.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1235
Validation loss decreased (0.165833 --> 0.165588).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.9990807
	speed: 0.0150s/iter; left time: 182.6169s
Epoch: 5 cost time: 1.8766589164733887
Epoch: 5, Steps: 128 Train Loss: 28.6614 (Forecasting Loss:0.2178 + XiCon Loss:2.8444 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
Validation loss decreased (0.165588 --> 0.163579).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.3185768
	speed: 0.0139s/iter; left time: 168.2082s
Epoch: 6 cost time: 1.7477946281433105
Epoch: 6, Steps: 128 Train Loss: 28.6623 (Forecasting Loss:0.2151 + XiCon Loss:2.8447 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1165
Validation loss decreased (0.163579 --> 0.163509).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.7328491
	speed: 0.0154s/iter; left time: 183.2110s
Epoch: 7 cost time: 1.8633270263671875
Epoch: 7, Steps: 128 Train Loss: 28.6199 (Forecasting Loss:0.2144 + XiCon Loss:2.8405 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 28.8399105
	speed: 0.0148s/iter; left time: 174.7816s
Epoch: 8 cost time: 1.8230669498443604
Epoch: 8, Steps: 128 Train Loss: 28.6568 (Forecasting Loss:0.2139 + XiCon Loss:2.8443 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1170
Validation loss decreased (0.163509 --> 0.163398).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.8948021
	speed: 0.0136s/iter; left time: 158.8013s
Epoch: 9 cost time: 1.7039744853973389
Epoch: 9, Steps: 128 Train Loss: 28.6132 (Forecasting Loss:0.2136 + XiCon Loss:2.8400 x Lambda(10.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1159
Validation loss decreased (0.163398 --> 0.163144).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.1060276
	speed: 0.0141s/iter; left time: 163.3803s
Epoch: 10 cost time: 1.7590291500091553
Epoch: 10, Steps: 128 Train Loss: 28.5261 (Forecasting Loss:0.2134 + XiCon Loss:2.8313 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 28.4612789
	speed: 0.0138s/iter; left time: 157.3325s
Epoch: 11 cost time: 1.71958327293396
Epoch: 11, Steps: 128 Train Loss: 28.6152 (Forecasting Loss:0.2130 + XiCon Loss:2.8402 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 28.8262653
	speed: 0.0141s/iter; left time: 159.3772s
Epoch: 12 cost time: 1.748058557510376
Epoch: 12, Steps: 128 Train Loss: 28.6510 (Forecasting Loss:0.2132 + XiCon Loss:2.8438 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.0629196
	speed: 0.0138s/iter; left time: 154.1690s
Epoch: 13 cost time: 1.7262005805969238
Epoch: 13, Steps: 128 Train Loss: 28.6217 (Forecasting Loss:0.2130 + XiCon Loss:2.8409 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 29.1609554
	speed: 0.0149s/iter; left time: 164.3774s
Epoch: 14 cost time: 1.8271589279174805
Epoch: 14, Steps: 128 Train Loss: 28.6087 (Forecasting Loss:0.2132 + XiCon Loss:2.8396 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.9398632
	speed: 0.0140s/iter; left time: 152.7033s
Epoch: 15 cost time: 1.7944021224975586
Epoch: 15, Steps: 128 Train Loss: 28.6240 (Forecasting Loss:0.2131 + XiCon Loss:2.8411 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 27.9895821
	speed: 0.0137s/iter; left time: 147.5035s
Epoch: 16 cost time: 1.7097089290618896
Epoch: 16, Steps: 128 Train Loss: 28.5355 (Forecasting Loss:0.2130 + XiCon Loss:2.8322 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 28.9541130
	speed: 0.0140s/iter; left time: 148.7332s
Epoch: 17 cost time: 1.7848122119903564
Epoch: 17, Steps: 128 Train Loss: 28.6133 (Forecasting Loss:0.2131 + XiCon Loss:2.8400 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 29.0476894
	speed: 0.0144s/iter; left time: 151.0552s
Epoch: 18 cost time: 1.7794549465179443
Epoch: 18, Steps: 128 Train Loss: 28.6233 (Forecasting Loss:0.2131 + XiCon Loss:2.8410 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.8524704
	speed: 0.0133s/iter; left time: 137.8813s
Epoch: 19 cost time: 1.681380271911621
Epoch: 19, Steps: 128 Train Loss: 28.6025 (Forecasting Loss:0.2132 + XiCon Loss:2.8389 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05441073328256607, mae:0.1774175614118576, mape:0.14097589254379272, mspe:0.037293691188097 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2977
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.4147243
	speed: 0.0151s/iter; left time: 191.6414s
Epoch: 1 cost time: 1.9442048072814941
Epoch: 1, Steps: 128 Train Loss: 30.7256 (Forecasting Loss:0.2423 + XiCon Loss:3.0483 x Lambda(10.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1213
Validation loss decreased (inf --> 0.172454).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.8741322
	speed: 0.0140s/iter; left time: 176.0936s
Epoch: 2 cost time: 1.7631521224975586
Epoch: 2, Steps: 128 Train Loss: 29.3374 (Forecasting Loss:0.2468 + XiCon Loss:2.9091 x Lambda(10.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1278
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.9391880
	speed: 0.0133s/iter; left time: 165.0142s
Epoch: 3 cost time: 1.665426254272461
Epoch: 3, Steps: 128 Train Loss: 29.4569 (Forecasting Loss:0.2299 + XiCon Loss:2.9227 x Lambda(10.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1237
Validation loss decreased (0.172454 --> 0.169743).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.4035149
	speed: 0.0136s/iter; left time: 167.3488s
Epoch: 4 cost time: 1.6864185333251953
Epoch: 4, Steps: 128 Train Loss: 28.8885 (Forecasting Loss:0.2213 + XiCon Loss:2.8667 x Lambda(10.0)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1167
Validation loss decreased (0.169743 --> 0.169415).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.3667221
	speed: 0.0137s/iter; left time: 166.3965s
Epoch: 5 cost time: 1.7373895645141602
Epoch: 5, Steps: 128 Train Loss: 28.8288 (Forecasting Loss:0.2183 + XiCon Loss:2.8610 x Lambda(10.0)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1144
Validation loss decreased (0.169415 --> 0.166989).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.4316082
	speed: 0.0138s/iter; left time: 166.6795s
Epoch: 6 cost time: 1.7215332984924316
Epoch: 6, Steps: 128 Train Loss: 28.7601 (Forecasting Loss:0.2157 + XiCon Loss:2.8544 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1151
Validation loss decreased (0.166989 --> 0.164232).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.5506382
	speed: 0.0139s/iter; left time: 166.0965s
Epoch: 7 cost time: 1.7238821983337402
Epoch: 7, Steps: 128 Train Loss: 28.7315 (Forecasting Loss:0.2147 + XiCon Loss:2.8517 x Lambda(10.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1150
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 27.8871670
	speed: 0.0148s/iter; left time: 174.5254s
Epoch: 8 cost time: 1.866586685180664
Epoch: 8, Steps: 128 Train Loss: 28.7366 (Forecasting Loss:0.2138 + XiCon Loss:2.8523 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1151
Validation loss decreased (0.164232 --> 0.163989).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.8211594
	speed: 0.0144s/iter; left time: 168.2179s
Epoch: 9 cost time: 1.780259132385254
Epoch: 9, Steps: 128 Train Loss: 28.6991 (Forecasting Loss:0.2136 + XiCon Loss:2.8485 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1152
Validation loss decreased (0.163989 --> 0.163623).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.4740791
	speed: 0.0134s/iter; left time: 154.1817s
Epoch: 10 cost time: 1.690469741821289
Epoch: 10, Steps: 128 Train Loss: 28.7172 (Forecasting Loss:0.2134 + XiCon Loss:2.8504 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.3037281
	speed: 0.0130s/iter; left time: 148.4609s
Epoch: 11 cost time: 1.6489694118499756
Epoch: 11, Steps: 128 Train Loss: 28.7257 (Forecasting Loss:0.2132 + XiCon Loss:2.8513 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
Validation loss decreased (0.163623 --> 0.163463).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 29.8871727
	speed: 0.0135s/iter; left time: 152.3524s
Epoch: 12 cost time: 1.7625172138214111
Epoch: 12, Steps: 128 Train Loss: 28.6584 (Forecasting Loss:0.2133 + XiCon Loss:2.8445 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
Validation loss decreased (0.163463 --> 0.163424).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 29.0268116
	speed: 0.0138s/iter; left time: 153.6928s
Epoch: 13 cost time: 1.7497854232788086
Epoch: 13, Steps: 128 Train Loss: 28.7314 (Forecasting Loss:0.2133 + XiCon Loss:2.8518 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.9908028
	speed: 0.0137s/iter; left time: 151.7515s
Epoch: 14 cost time: 1.7148535251617432
Epoch: 14, Steps: 128 Train Loss: 28.6541 (Forecasting Loss:0.2133 + XiCon Loss:2.8441 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 29.5382004
	speed: 0.0146s/iter; left time: 159.1532s
Epoch: 15 cost time: 1.795806646347046
Epoch: 15, Steps: 128 Train Loss: 28.7551 (Forecasting Loss:0.2133 + XiCon Loss:2.8542 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
Validation loss decreased (0.163424 --> 0.163358).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 29.5737209
	speed: 0.0142s/iter; left time: 153.4829s
Epoch: 16 cost time: 1.7779409885406494
Epoch: 16, Steps: 128 Train Loss: 28.7068 (Forecasting Loss:0.2132 + XiCon Loss:2.8494 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1153
Validation loss decreased (0.163358 --> 0.163040).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 28.5802269
	speed: 0.0150s/iter; left time: 159.6565s
Epoch: 17 cost time: 1.8552680015563965
Epoch: 17, Steps: 128 Train Loss: 28.7860 (Forecasting Loss:0.2133 + XiCon Loss:2.8573 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 28.8754463
	speed: 0.0134s/iter; left time: 140.8494s
Epoch: 18 cost time: 1.6841154098510742
Epoch: 18, Steps: 128 Train Loss: 28.7420 (Forecasting Loss:0.2131 + XiCon Loss:2.8529 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.4108582
	speed: 0.0139s/iter; left time: 145.0070s
Epoch: 19 cost time: 1.7468488216400146
Epoch: 19, Steps: 128 Train Loss: 28.6910 (Forecasting Loss:0.2133 + XiCon Loss:2.8478 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1153
Validation loss decreased (0.163040 --> 0.163025).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.4218121
	speed: 0.0130s/iter; left time: 133.5925s
Epoch: 20 cost time: 1.6379361152648926
Epoch: 20, Steps: 128 Train Loss: 28.7276 (Forecasting Loss:0.2133 + XiCon Loss:2.8514 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 28.5650768
	speed: 0.0136s/iter; left time: 138.3453s
Epoch: 21 cost time: 1.6946938037872314
Epoch: 21, Steps: 128 Train Loss: 28.6620 (Forecasting Loss:0.2130 + XiCon Loss:2.8449 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 29.1298923
	speed: 0.0150s/iter; left time: 150.1341s
Epoch: 22 cost time: 1.8814122676849365
Epoch: 22, Steps: 128 Train Loss: 28.7150 (Forecasting Loss:0.2133 + XiCon Loss:2.8502 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 28.1327534
	speed: 0.0138s/iter; left time: 135.9572s
Epoch: 23 cost time: 1.7061080932617188
Epoch: 23, Steps: 128 Train Loss: 28.7615 (Forecasting Loss:0.2133 + XiCon Loss:2.8548 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 28.3335495
	speed: 0.0140s/iter; left time: 136.8500s
Epoch: 24 cost time: 1.7535150051116943
Epoch: 24, Steps: 128 Train Loss: 28.7476 (Forecasting Loss:0.2132 + XiCon Loss:2.8534 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 28.3242035
	speed: 0.0134s/iter; left time: 129.0349s
Epoch: 25 cost time: 1.7060954570770264
Epoch: 25, Steps: 128 Train Loss: 28.6823 (Forecasting Loss:0.2132 + XiCon Loss:2.8469 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 28.1199226
	speed: 0.0144s/iter; left time: 136.5055s
Epoch: 26 cost time: 1.8363358974456787
Epoch: 26, Steps: 128 Train Loss: 28.7666 (Forecasting Loss:0.2131 + XiCon Loss:2.8553 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.2771568
	speed: 0.0137s/iter; left time: 128.0375s
Epoch: 27 cost time: 1.6961591243743896
Epoch: 27, Steps: 128 Train Loss: 28.7005 (Forecasting Loss:0.2133 + XiCon Loss:2.8487 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 29.6264038
	speed: 0.0137s/iter; left time: 126.1986s
Epoch: 28 cost time: 1.7087047100067139
Epoch: 28, Steps: 128 Train Loss: 28.6757 (Forecasting Loss:0.2132 + XiCon Loss:2.8462 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 29.2697220
	speed: 0.0151s/iter; left time: 137.6191s
Epoch: 29 cost time: 1.8482422828674316
Epoch: 29, Steps: 128 Train Loss: 28.7017 (Forecasting Loss:0.2129 + XiCon Loss:2.8489 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05403527244925499, mae:0.1765609085559845, mape:0.1403025984764099, mspe:0.037069279700517654 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2877
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6944313
	speed: 0.0135s/iter; left time: 171.8528s
Epoch: 1 cost time: 1.696357250213623
Epoch: 1, Steps: 128 Train Loss: 30.7158 (Forecasting Loss:0.2449 + XiCon Loss:3.0471 x Lambda(10.0)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1213
Validation loss decreased (inf --> 0.172810).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.4979477
	speed: 0.0138s/iter; left time: 173.8455s
Epoch: 2 cost time: 1.7234079837799072
Epoch: 2, Steps: 128 Train Loss: 29.0446 (Forecasting Loss:0.2469 + XiCon Loss:2.8798 x Lambda(10.0)), Vali MSE Loss: 0.1796 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 29.5123024
	speed: 0.0142s/iter; left time: 177.3320s
Epoch: 3 cost time: 1.7971723079681396
Epoch: 3, Steps: 128 Train Loss: 29.5064 (Forecasting Loss:0.2298 + XiCon Loss:2.9277 x Lambda(10.0)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1207
Validation loss decreased (0.172810 --> 0.169152).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.7914524
	speed: 0.0143s/iter; left time: 176.6016s
Epoch: 4 cost time: 1.8780317306518555
Epoch: 4, Steps: 128 Train Loss: 29.0945 (Forecasting Loss:0.2223 + XiCon Loss:2.8872 x Lambda(10.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1217
Validation loss decreased (0.169152 --> 0.164481).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.4242973
	speed: 0.0145s/iter; left time: 177.1373s
Epoch: 5 cost time: 1.8129162788391113
Epoch: 5, Steps: 128 Train Loss: 29.0150 (Forecasting Loss:0.2182 + XiCon Loss:2.8797 x Lambda(10.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1163
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.4844303
	speed: 0.0147s/iter; left time: 177.6357s
Epoch: 6 cost time: 1.8523190021514893
Epoch: 6, Steps: 128 Train Loss: 28.9375 (Forecasting Loss:0.2152 + XiCon Loss:2.8722 x Lambda(10.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1166
Validation loss decreased (0.164481 --> 0.164424).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.2128963
	speed: 0.0133s/iter; left time: 158.8485s
Epoch: 7 cost time: 1.6752326488494873
Epoch: 7, Steps: 128 Train Loss: 28.8907 (Forecasting Loss:0.2146 + XiCon Loss:2.8676 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1150
Validation loss decreased (0.164424 --> 0.163830).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.2953892
	speed: 0.0144s/iter; left time: 169.8545s
Epoch: 8 cost time: 1.803100824356079
Epoch: 8, Steps: 128 Train Loss: 28.8282 (Forecasting Loss:0.2138 + XiCon Loss:2.8614 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1155
Validation loss decreased (0.163830 --> 0.163828).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.6102715
	speed: 0.0149s/iter; left time: 174.5424s
Epoch: 9 cost time: 1.8365886211395264
Epoch: 9, Steps: 128 Train Loss: 28.8876 (Forecasting Loss:0.2136 + XiCon Loss:2.8674 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.4431438
	speed: 0.0141s/iter; left time: 163.0936s
Epoch: 10 cost time: 1.7589337825775146
Epoch: 10, Steps: 128 Train Loss: 28.9328 (Forecasting Loss:0.2133 + XiCon Loss:2.8720 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.2174854
	speed: 0.0141s/iter; left time: 160.4839s
Epoch: 11 cost time: 1.8285760879516602
Epoch: 11, Steps: 128 Train Loss: 28.8440 (Forecasting Loss:0.2132 + XiCon Loss:2.8631 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1154
Validation loss decreased (0.163828 --> 0.163493).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 29.3520737
	speed: 0.0144s/iter; left time: 162.7171s
Epoch: 12 cost time: 1.860478401184082
Epoch: 12, Steps: 128 Train Loss: 28.8208 (Forecasting Loss:0.2131 + XiCon Loss:2.8608 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 29.0197563
	speed: 0.0140s/iter; left time: 156.6576s
Epoch: 13 cost time: 1.7533202171325684
Epoch: 13, Steps: 128 Train Loss: 28.8399 (Forecasting Loss:0.2133 + XiCon Loss:2.8627 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1154
Validation loss decreased (0.163493 --> 0.163492).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 29.1472187
	speed: 0.0138s/iter; left time: 151.7768s
Epoch: 14 cost time: 1.7193973064422607
Epoch: 14, Steps: 128 Train Loss: 28.8679 (Forecasting Loss:0.2130 + XiCon Loss:2.8655 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 29.0879536
	speed: 0.0141s/iter; left time: 153.6471s
Epoch: 15 cost time: 1.7552032470703125
Epoch: 15, Steps: 128 Train Loss: 28.8540 (Forecasting Loss:0.2131 + XiCon Loss:2.8641 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 30.3283882
	speed: 0.0132s/iter; left time: 141.8164s
Epoch: 16 cost time: 1.6972618103027344
Epoch: 16, Steps: 128 Train Loss: 28.8581 (Forecasting Loss:0.2132 + XiCon Loss:2.8645 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1154
Validation loss decreased (0.163492 --> 0.163472).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 29.0974865
	speed: 0.0133s/iter; left time: 141.2036s
Epoch: 17 cost time: 1.6701853275299072
Epoch: 17, Steps: 128 Train Loss: 28.8728 (Forecasting Loss:0.2132 + XiCon Loss:2.8660 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1154
Validation loss decreased (0.163472 --> 0.163408).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 29.1531506
	speed: 0.0141s/iter; left time: 148.2059s
Epoch: 18 cost time: 1.752145767211914
Epoch: 18, Steps: 128 Train Loss: 28.8261 (Forecasting Loss:0.2133 + XiCon Loss:2.8613 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1154
Validation loss decreased (0.163408 --> 0.163031).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.3579025
	speed: 0.0152s/iter; left time: 158.1279s
Epoch: 19 cost time: 1.9332683086395264
Epoch: 19, Steps: 128 Train Loss: 28.8928 (Forecasting Loss:0.2131 + XiCon Loss:2.8680 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.9421635
	speed: 0.0137s/iter; left time: 141.0313s
Epoch: 20 cost time: 1.7195372581481934
Epoch: 20, Steps: 128 Train Loss: 28.8706 (Forecasting Loss:0.2132 + XiCon Loss:2.8657 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 29.2909012
	speed: 0.0137s/iter; left time: 138.4727s
Epoch: 21 cost time: 1.7304408550262451
Epoch: 21, Steps: 128 Train Loss: 28.8270 (Forecasting Loss:0.2131 + XiCon Loss:2.8614 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 29.4413452
	speed: 0.0136s/iter; left time: 136.1128s
Epoch: 22 cost time: 1.701249599456787
Epoch: 22, Steps: 128 Train Loss: 28.8966 (Forecasting Loss:0.2132 + XiCon Loss:2.8683 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1154
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 28.1939144
	speed: 0.0142s/iter; left time: 140.3892s
Epoch: 23 cost time: 1.7645695209503174
Epoch: 23, Steps: 128 Train Loss: 28.8449 (Forecasting Loss:0.2132 + XiCon Loss:2.8632 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1154
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 30.1064091
	speed: 0.0142s/iter; left time: 138.9020s
Epoch: 24 cost time: 1.7648544311523438
Epoch: 24, Steps: 128 Train Loss: 28.8559 (Forecasting Loss:0.2131 + XiCon Loss:2.8643 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1154
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 29.0890827
	speed: 0.0136s/iter; left time: 130.8003s
Epoch: 25 cost time: 1.6968131065368652
Epoch: 25, Steps: 128 Train Loss: 28.8014 (Forecasting Loss:0.2131 + XiCon Loss:2.8588 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1154
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 28.8238792
	speed: 0.0147s/iter; left time: 139.4001s
Epoch: 26 cost time: 1.8791639804840088
Epoch: 26, Steps: 128 Train Loss: 28.8483 (Forecasting Loss:0.2132 + XiCon Loss:2.8635 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1154
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.5790424
	speed: 0.0141s/iter; left time: 132.1314s
Epoch: 27 cost time: 1.7519598007202148
Epoch: 27, Steps: 128 Train Loss: 28.8509 (Forecasting Loss:0.2131 + XiCon Loss:2.8638 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1154
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 28.9292068
	speed: 0.0138s/iter; left time: 127.8041s
Epoch: 28 cost time: 1.7097773551940918
Epoch: 28, Steps: 128 Train Loss: 28.8186 (Forecasting Loss:0.2133 + XiCon Loss:2.8605 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1154
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05417046323418617, mae:0.17665956914424896, mape:0.14036959409713745, mspe:0.037194252014160156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0550+-0.00235, MAE:0.1786+-0.00434, MAPE:0.1423+-0.00425, MSPE:0.0386+-0.00341, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3875
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.5914631
	speed: 0.0181s/iter; left time: 226.4040s
Epoch: 1 cost time: 2.2187817096710205
Epoch: 1, Steps: 126 Train Loss: 30.7894 (Forecasting Loss:0.2773 + XiCon Loss:3.0512 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1441
Validation loss decreased (inf --> 0.197726).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 27.9867954
	speed: 0.0168s/iter; left time: 207.8511s
Epoch: 2 cost time: 2.121791124343872
Epoch: 2, Steps: 126 Train Loss: 28.7625 (Forecasting Loss:0.2615 + XiCon Loss:2.8501 x Lambda(10.0)), Vali MSE Loss: 0.1915 Test MSE Loss: 0.1407
Validation loss decreased (0.197726 --> 0.191543).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2716084
	speed: 0.0170s/iter; left time: 208.6815s
Epoch: 3 cost time: 2.097776174545288
Epoch: 3, Steps: 126 Train Loss: 29.8912 (Forecasting Loss:0.2532 + XiCon Loss:2.9638 x Lambda(10.0)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.1426
Validation loss decreased (0.191543 --> 0.188090).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.1040668
	speed: 0.0160s/iter; left time: 193.8662s
Epoch: 4 cost time: 1.976301908493042
Epoch: 4, Steps: 126 Train Loss: 29.6216 (Forecasting Loss:0.2473 + XiCon Loss:2.9374 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1396
Validation loss decreased (0.188090 --> 0.186489).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.0293026
	speed: 0.0158s/iter; left time: 190.0796s
Epoch: 5 cost time: 2.0038750171661377
Epoch: 5, Steps: 126 Train Loss: 29.2938 (Forecasting Loss:0.2440 + XiCon Loss:2.9050 x Lambda(10.0)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1367
Validation loss decreased (0.186489 --> 0.184762).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.8752956
	speed: 0.0160s/iter; left time: 189.5497s
Epoch: 6 cost time: 2.042922258377075
Epoch: 6, Steps: 126 Train Loss: 29.3638 (Forecasting Loss:0.2425 + XiCon Loss:2.9121 x Lambda(10.0)), Vali MSE Loss: 0.1855 Test MSE Loss: 0.1361
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9930019
	speed: 0.0164s/iter; left time: 192.7586s
Epoch: 7 cost time: 2.0364742279052734
Epoch: 7, Steps: 126 Train Loss: 29.3502 (Forecasting Loss:0.2413 + XiCon Loss:2.9109 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1372
Validation loss decreased (0.184762 --> 0.184658).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2398777
	speed: 0.0156s/iter; left time: 181.8287s
Epoch: 8 cost time: 1.9284687042236328
Epoch: 8, Steps: 126 Train Loss: 29.2040 (Forecasting Loss:0.2406 + XiCon Loss:2.8963 x Lambda(10.0)), Vali MSE Loss: 0.1849 Test MSE Loss: 0.1369
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.8464909
	speed: 0.0168s/iter; left time: 192.6686s
Epoch: 9 cost time: 2.0451231002807617
Epoch: 9, Steps: 126 Train Loss: 29.1288 (Forecasting Loss:0.2404 + XiCon Loss:2.8888 x Lambda(10.0)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9472580
	speed: 0.0154s/iter; left time: 175.3878s
Epoch: 10 cost time: 1.937483787536621
Epoch: 10, Steps: 126 Train Loss: 29.3988 (Forecasting Loss:0.2404 + XiCon Loss:2.9158 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1368
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8975601
	speed: 0.0162s/iter; left time: 181.6180s
Epoch: 11 cost time: 2.0040547847747803
Epoch: 11, Steps: 126 Train Loss: 29.2891 (Forecasting Loss:0.2403 + XiCon Loss:2.9049 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.8824120
	speed: 0.0159s/iter; left time: 176.8492s
Epoch: 12 cost time: 1.9620442390441895
Epoch: 12, Steps: 126 Train Loss: 29.2829 (Forecasting Loss:0.2402 + XiCon Loss:2.9043 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4938736
	speed: 0.0157s/iter; left time: 172.6043s
Epoch: 13 cost time: 1.9702398777008057
Epoch: 13, Steps: 126 Train Loss: 29.1824 (Forecasting Loss:0.2400 + XiCon Loss:2.8942 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.3099670
	speed: 0.0158s/iter; left time: 172.0898s
Epoch: 14 cost time: 1.9527225494384766
Epoch: 14, Steps: 126 Train Loss: 29.2765 (Forecasting Loss:0.2403 + XiCon Loss:2.9036 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.2774620
	speed: 0.0171s/iter; left time: 183.6394s
Epoch: 15 cost time: 2.200671434402466
Epoch: 15, Steps: 126 Train Loss: 29.2024 (Forecasting Loss:0.2404 + XiCon Loss:2.8962 x Lambda(10.0)), Vali MSE Loss: 0.1846 Test MSE Loss: 0.1367
Validation loss decreased (0.184658 --> 0.184619).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.3386192
	speed: 0.0165s/iter; left time: 174.7252s
Epoch: 16 cost time: 2.0491082668304443
Epoch: 16, Steps: 126 Train Loss: 29.2635 (Forecasting Loss:0.2401 + XiCon Loss:2.9023 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.3971195
	speed: 0.0163s/iter; left time: 170.9771s
Epoch: 17 cost time: 2.0072391033172607
Epoch: 17, Steps: 126 Train Loss: 29.2191 (Forecasting Loss:0.2404 + XiCon Loss:2.8979 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4065819
	speed: 0.0160s/iter; left time: 166.0339s
Epoch: 18 cost time: 2.0235815048217773
Epoch: 18, Steps: 126 Train Loss: 29.1196 (Forecasting Loss:0.2402 + XiCon Loss:2.8879 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.0519428
	speed: 0.0160s/iter; left time: 163.6082s
Epoch: 19 cost time: 1.9830517768859863
Epoch: 19, Steps: 126 Train Loss: 29.2704 (Forecasting Loss:0.2404 + XiCon Loss:2.9030 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.2388172
	speed: 0.0156s/iter; left time: 157.4550s
Epoch: 20 cost time: 1.9554028511047363
Epoch: 20, Steps: 126 Train Loss: 29.2049 (Forecasting Loss:0.2402 + XiCon Loss:2.8965 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.1753578
	speed: 0.0171s/iter; left time: 170.7319s
Epoch: 21 cost time: 2.0952136516571045
Epoch: 21, Steps: 126 Train Loss: 29.2182 (Forecasting Loss:0.2404 + XiCon Loss:2.8978 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.8195114
	speed: 0.0165s/iter; left time: 162.3864s
Epoch: 22 cost time: 2.026116132736206
Epoch: 22, Steps: 126 Train Loss: 29.1881 (Forecasting Loss:0.2401 + XiCon Loss:2.8948 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.6910973
	speed: 0.0162s/iter; left time: 157.6888s
Epoch: 23 cost time: 2.018709659576416
Epoch: 23, Steps: 126 Train Loss: 29.2259 (Forecasting Loss:0.2401 + XiCon Loss:2.8986 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.1105995
	speed: 0.0163s/iter; left time: 156.3920s
Epoch: 24 cost time: 2.0060408115386963
Epoch: 24, Steps: 126 Train Loss: 29.3285 (Forecasting Loss:0.2400 + XiCon Loss:2.9088 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 28.9011002
	speed: 0.0163s/iter; left time: 154.4394s
Epoch: 25 cost time: 2.0000851154327393
Epoch: 25, Steps: 126 Train Loss: 29.1786 (Forecasting Loss:0.2400 + XiCon Loss:2.8939 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1367
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.069675974547863, mae:0.20373521745204926, mape:0.15666259825229645, mspe:0.04256119206547737 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3793
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.4760818
	speed: 0.0153s/iter; left time: 191.8126s
Epoch: 1 cost time: 1.9002685546875
Epoch: 1, Steps: 126 Train Loss: 30.5281 (Forecasting Loss:0.2765 + XiCon Loss:3.0252 x Lambda(10.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1455
Validation loss decreased (inf --> 0.196388).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.3792267
	speed: 0.0179s/iter; left time: 220.9314s
Epoch: 2 cost time: 2.175011396408081
Epoch: 2, Steps: 126 Train Loss: 28.7275 (Forecasting Loss:0.2643 + XiCon Loss:2.8463 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1479
Validation loss decreased (0.196388 --> 0.193110).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 27.7345123
	speed: 0.0160s/iter; left time: 196.3654s
Epoch: 3 cost time: 1.9999332427978516
Epoch: 3, Steps: 126 Train Loss: 28.3658 (Forecasting Loss:0.2519 + XiCon Loss:2.8114 x Lambda(10.0)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.1454
Validation loss decreased (0.193110 --> 0.192271).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9583130
	speed: 0.0163s/iter; left time: 197.8189s
Epoch: 4 cost time: 2.036561965942383
Epoch: 4, Steps: 126 Train Loss: 29.8508 (Forecasting Loss:0.2477 + XiCon Loss:2.9603 x Lambda(10.0)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.1378
Validation loss decreased (0.192271 --> 0.188285).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.6872120
	speed: 0.0168s/iter; left time: 201.6613s
Epoch: 5 cost time: 2.06907057762146
Epoch: 5, Steps: 126 Train Loss: 29.8131 (Forecasting Loss:0.2445 + XiCon Loss:2.9569 x Lambda(10.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1355
Validation loss decreased (0.188285 --> 0.186427).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5953102
	speed: 0.0167s/iter; left time: 198.0845s
Epoch: 6 cost time: 2.0525240898132324
Epoch: 6, Steps: 126 Train Loss: 29.6791 (Forecasting Loss:0.2426 + XiCon Loss:2.9436 x Lambda(10.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1400
Validation loss decreased (0.186427 --> 0.185355).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1408787
	speed: 0.0164s/iter; left time: 192.5470s
Epoch: 7 cost time: 2.019763231277466
Epoch: 7, Steps: 126 Train Loss: 29.4392 (Forecasting Loss:0.2414 + XiCon Loss:2.9198 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1404
Validation loss decreased (0.185355 --> 0.185313).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6061287
	speed: 0.0172s/iter; left time: 200.3016s
Epoch: 8 cost time: 2.1203958988189697
Epoch: 8, Steps: 126 Train Loss: 29.6862 (Forecasting Loss:0.2408 + XiCon Loss:2.9445 x Lambda(10.0)), Vali MSE Loss: 0.1855 Test MSE Loss: 0.1395
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.5395679
	speed: 0.0166s/iter; left time: 190.3164s
Epoch: 9 cost time: 2.034496545791626
Epoch: 9, Steps: 126 Train Loss: 29.6069 (Forecasting Loss:0.2408 + XiCon Loss:2.9366 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1397
Validation loss decreased (0.185313 --> 0.185165).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.5135117
	speed: 0.0170s/iter; left time: 193.3961s
Epoch: 10 cost time: 2.0974998474121094
Epoch: 10, Steps: 126 Train Loss: 29.6980 (Forecasting Loss:0.2406 + XiCon Loss:2.9457 x Lambda(10.0)), Vali MSE Loss: 0.1851 Test MSE Loss: 0.1400
Validation loss decreased (0.185165 --> 0.185139).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.5698376
	speed: 0.0163s/iter; left time: 183.2609s
Epoch: 11 cost time: 2.0551154613494873
Epoch: 11, Steps: 126 Train Loss: 29.4456 (Forecasting Loss:0.2406 + XiCon Loss:2.9205 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1400
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1612358
	speed: 0.0166s/iter; left time: 184.3956s
Epoch: 12 cost time: 2.046070098876953
Epoch: 12, Steps: 126 Train Loss: 29.4922 (Forecasting Loss:0.2404 + XiCon Loss:2.9252 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1400
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3899593
	speed: 0.0163s/iter; left time: 179.4222s
Epoch: 13 cost time: 2.0564897060394287
Epoch: 13, Steps: 126 Train Loss: 29.6101 (Forecasting Loss:0.2404 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1400
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1559849
	speed: 0.0173s/iter; left time: 187.6077s
Epoch: 14 cost time: 2.1141011714935303
Epoch: 14, Steps: 126 Train Loss: 29.4689 (Forecasting Loss:0.2404 + XiCon Loss:2.9228 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.5213966
	speed: 0.0169s/iter; left time: 181.8308s
Epoch: 15 cost time: 2.0799410343170166
Epoch: 15, Steps: 126 Train Loss: 29.5464 (Forecasting Loss:0.2405 + XiCon Loss:2.9306 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.0723476
	speed: 0.0166s/iter; left time: 175.7828s
Epoch: 16 cost time: 2.07657527923584
Epoch: 16, Steps: 126 Train Loss: 29.5592 (Forecasting Loss:0.2404 + XiCon Loss:2.9319 x Lambda(10.0)), Vali MSE Loss: 0.1851 Test MSE Loss: 0.1401
Validation loss decreased (0.185139 --> 0.185090).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5613804
	speed: 0.0163s/iter; left time: 171.3109s
Epoch: 17 cost time: 2.054867744445801
Epoch: 17, Steps: 126 Train Loss: 29.4960 (Forecasting Loss:0.2403 + XiCon Loss:2.9256 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.1109962
	speed: 0.0164s/iter; left time: 169.6605s
Epoch: 18 cost time: 2.0190212726593018
Epoch: 18, Steps: 126 Train Loss: 29.5090 (Forecasting Loss:0.2405 + XiCon Loss:2.9269 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.9042492
	speed: 0.0160s/iter; left time: 164.2242s
Epoch: 19 cost time: 2.002032518386841
Epoch: 19, Steps: 126 Train Loss: 29.4467 (Forecasting Loss:0.2403 + XiCon Loss:2.9206 x Lambda(10.0)), Vali MSE Loss: 0.1851 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.2107868
	speed: 0.0181s/iter; left time: 182.5321s
Epoch: 20 cost time: 2.191115379333496
Epoch: 20, Steps: 126 Train Loss: 29.5233 (Forecasting Loss:0.2403 + XiCon Loss:2.9283 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 28.5414486
	speed: 0.0168s/iter; left time: 167.8518s
Epoch: 21 cost time: 2.091245412826538
Epoch: 21, Steps: 126 Train Loss: 29.6575 (Forecasting Loss:0.2403 + XiCon Loss:2.9417 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.3143024
	speed: 0.0165s/iter; left time: 162.1668s
Epoch: 22 cost time: 2.044602155685425
Epoch: 22, Steps: 126 Train Loss: 29.5198 (Forecasting Loss:0.2403 + XiCon Loss:2.9280 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 27.8405685
	speed: 0.0163s/iter; left time: 158.2007s
Epoch: 23 cost time: 2.023522138595581
Epoch: 23, Steps: 126 Train Loss: 29.4961 (Forecasting Loss:0.2401 + XiCon Loss:2.9256 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 28.2905178
	speed: 0.0164s/iter; left time: 157.3816s
Epoch: 24 cost time: 2.0496325492858887
Epoch: 24, Steps: 126 Train Loss: 29.4284 (Forecasting Loss:0.2403 + XiCon Loss:2.9188 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.3237591
	speed: 0.0171s/iter; left time: 162.1916s
Epoch: 25 cost time: 2.1102514266967773
Epoch: 25, Steps: 126 Train Loss: 29.6622 (Forecasting Loss:0.2404 + XiCon Loss:2.9422 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.6269779
	speed: 0.0182s/iter; left time: 169.9633s
Epoch: 26 cost time: 2.2093589305877686
Epoch: 26, Steps: 126 Train Loss: 29.5501 (Forecasting Loss:0.2403 + XiCon Loss:2.9310 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07233112305402756, mae:0.20777305960655212, mape:0.1591600924730301, mspe:0.04376086965203285 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2906
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.3656483
	speed: 0.0145s/iter; left time: 181.7402s
Epoch: 1 cost time: 1.8035953044891357
Epoch: 1, Steps: 126 Train Loss: 30.6401 (Forecasting Loss:0.2764 + XiCon Loss:3.0364 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1451
Validation loss decreased (inf --> 0.195929).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.0381470
	speed: 0.0170s/iter; left time: 210.3801s
Epoch: 2 cost time: 2.1631321907043457
Epoch: 2, Steps: 126 Train Loss: 28.8155 (Forecasting Loss:0.2632 + XiCon Loss:2.8552 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.1458
Validation loss decreased (0.195929 --> 0.192959).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0643387
	speed: 0.0162s/iter; left time: 198.9037s
Epoch: 3 cost time: 2.005977153778076
Epoch: 3, Steps: 126 Train Loss: 30.2019 (Forecasting Loss:0.2523 + XiCon Loss:2.9950 x Lambda(10.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1446
Validation loss decreased (0.192959 --> 0.189978).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4107285
	speed: 0.0163s/iter; left time: 197.6001s
Epoch: 4 cost time: 2.024501323699951
Epoch: 4, Steps: 126 Train Loss: 29.8828 (Forecasting Loss:0.2484 + XiCon Loss:2.9634 x Lambda(10.0)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.1384
Validation loss decreased (0.189978 --> 0.188133).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1774540
	speed: 0.0171s/iter; left time: 205.2907s
Epoch: 5 cost time: 2.156926393508911
Epoch: 5, Steps: 126 Train Loss: 29.7599 (Forecasting Loss:0.2451 + XiCon Loss:2.9515 x Lambda(10.0)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1349
Validation loss decreased (0.188133 --> 0.186979).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.1546307
	speed: 0.0165s/iter; left time: 196.0154s
Epoch: 6 cost time: 2.060619831085205
Epoch: 6, Steps: 126 Train Loss: 29.4975 (Forecasting Loss:0.2425 + XiCon Loss:2.9255 x Lambda(10.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1352
Validation loss decreased (0.186979 --> 0.186362).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7811699
	speed: 0.0168s/iter; left time: 196.8947s
Epoch: 7 cost time: 2.0831620693206787
Epoch: 7, Steps: 126 Train Loss: 29.3566 (Forecasting Loss:0.2414 + XiCon Loss:2.9115 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1339
Validation loss decreased (0.186362 --> 0.186301).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.5605984
	speed: 0.0164s/iter; left time: 191.0712s
Epoch: 8 cost time: 2.0344700813293457
Epoch: 8, Steps: 126 Train Loss: 29.3286 (Forecasting Loss:0.2407 + XiCon Loss:2.9088 x Lambda(10.0)), Vali MSE Loss: 0.1860 Test MSE Loss: 0.1345
Validation loss decreased (0.186301 --> 0.186049).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0625725
	speed: 0.0164s/iter; left time: 188.6151s
Epoch: 9 cost time: 2.0264828205108643
Epoch: 9, Steps: 126 Train Loss: 29.3784 (Forecasting Loss:0.2407 + XiCon Loss:2.9138 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.6674480
	speed: 0.0156s/iter; left time: 177.3917s
Epoch: 10 cost time: 1.9311819076538086
Epoch: 10, Steps: 126 Train Loss: 29.3378 (Forecasting Loss:0.2403 + XiCon Loss:2.9098 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1918621
	speed: 0.0163s/iter; left time: 183.1259s
Epoch: 11 cost time: 2.0593581199645996
Epoch: 11, Steps: 126 Train Loss: 29.3406 (Forecasting Loss:0.2402 + XiCon Loss:2.9100 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4542370
	speed: 0.0168s/iter; left time: 186.3367s
Epoch: 12 cost time: 2.096400499343872
Epoch: 12, Steps: 126 Train Loss: 29.4307 (Forecasting Loss:0.2400 + XiCon Loss:2.9191 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.0747833
	speed: 0.0169s/iter; left time: 185.3878s
Epoch: 13 cost time: 2.1025898456573486
Epoch: 13, Steps: 126 Train Loss: 29.3345 (Forecasting Loss:0.2403 + XiCon Loss:2.9094 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1312389
	speed: 0.0163s/iter; left time: 177.4270s
Epoch: 14 cost time: 2.033559560775757
Epoch: 14, Steps: 126 Train Loss: 29.3786 (Forecasting Loss:0.2402 + XiCon Loss:2.9138 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.0138474
	speed: 0.0165s/iter; left time: 176.7264s
Epoch: 15 cost time: 2.0239758491516113
Epoch: 15, Steps: 126 Train Loss: 29.2035 (Forecasting Loss:0.2401 + XiCon Loss:2.8963 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 27.8640556
	speed: 0.0162s/iter; left time: 172.0977s
Epoch: 16 cost time: 2.015763282775879
Epoch: 16, Steps: 126 Train Loss: 29.3003 (Forecasting Loss:0.2401 + XiCon Loss:2.9060 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.7513733
	speed: 0.0165s/iter; left time: 172.8953s
Epoch: 17 cost time: 2.1100661754608154
Epoch: 17, Steps: 126 Train Loss: 29.4451 (Forecasting Loss:0.2402 + XiCon Loss:2.9205 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.0673065
	speed: 0.0272s/iter; left time: 282.2612s
Epoch: 18 cost time: 4.009025573730469
Epoch: 18, Steps: 126 Train Loss: 29.4245 (Forecasting Loss:0.2403 + XiCon Loss:2.9184 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1342
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06849633902311325, mae:0.20044583082199097, mape:0.1536547839641571, mspe:0.04145747050642967 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3886
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.1185665
	speed: 0.0133s/iter; left time: 166.7056s
Epoch: 1 cost time: 1.6401898860931396
Epoch: 1, Steps: 126 Train Loss: 30.5521 (Forecasting Loss:0.2755 + XiCon Loss:3.0277 x Lambda(10.0)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1432
Validation loss decreased (inf --> 0.196452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.6465034
	speed: 0.0168s/iter; left time: 207.3429s
Epoch: 2 cost time: 2.1017720699310303
Epoch: 2, Steps: 126 Train Loss: 28.8815 (Forecasting Loss:0.2616 + XiCon Loss:2.8620 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1428
Validation loss decreased (0.196452 --> 0.195382).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.2019749
	speed: 0.0168s/iter; left time: 205.3645s
Epoch: 3 cost time: 2.0921502113342285
Epoch: 3, Steps: 126 Train Loss: 28.4325 (Forecasting Loss:0.2526 + XiCon Loss:2.8180 x Lambda(10.0)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.1450
Validation loss decreased (0.195382 --> 0.190906).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.3422890
	speed: 0.0166s/iter; left time: 201.3164s
Epoch: 4 cost time: 2.0954341888427734
Epoch: 4, Steps: 126 Train Loss: 28.6473 (Forecasting Loss:0.2477 + XiCon Loss:2.8400 x Lambda(10.0)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.1397
Validation loss decreased (0.190906 --> 0.187965).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7967415
	speed: 0.0164s/iter; left time: 197.3484s
Epoch: 5 cost time: 2.0479655265808105
Epoch: 5, Steps: 126 Train Loss: 30.6428 (Forecasting Loss:0.2449 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1867 Test MSE Loss: 0.1391
Validation loss decreased (0.187965 --> 0.186711).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.9586124
	speed: 0.0173s/iter; left time: 205.4304s
Epoch: 6 cost time: 2.1454379558563232
Epoch: 6, Steps: 126 Train Loss: 30.6324 (Forecasting Loss:0.2437 + XiCon Loss:3.0389 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1390
Validation loss decreased (0.186711 --> 0.186116).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.3766937
	speed: 0.0166s/iter; left time: 195.3482s
Epoch: 7 cost time: 2.0793802738189697
Epoch: 7, Steps: 126 Train Loss: 30.3802 (Forecasting Loss:0.2427 + XiCon Loss:3.0138 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1378
Validation loss decreased (0.186116 --> 0.185786).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1040211
	speed: 0.0173s/iter; left time: 201.3297s
Epoch: 8 cost time: 2.1377079486846924
Epoch: 8, Steps: 126 Train Loss: 30.4193 (Forecasting Loss:0.2419 + XiCon Loss:3.0177 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4073048
	speed: 0.0164s/iter; left time: 188.4820s
Epoch: 9 cost time: 2.0583205223083496
Epoch: 9, Steps: 126 Train Loss: 30.4746 (Forecasting Loss:0.2417 + XiCon Loss:3.0233 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1375
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6303272
	speed: 0.0166s/iter; left time: 189.2141s
Epoch: 10 cost time: 2.0670416355133057
Epoch: 10, Steps: 126 Train Loss: 30.4481 (Forecasting Loss:0.2417 + XiCon Loss:3.0206 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1375
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.0263367
	speed: 0.0168s/iter; left time: 189.1611s
Epoch: 11 cost time: 2.087186098098755
Epoch: 11, Steps: 126 Train Loss: 30.3055 (Forecasting Loss:0.2416 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
Validation loss decreased (0.185786 --> 0.185783).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.4189053
	speed: 0.0161s/iter; left time: 179.0332s
Epoch: 12 cost time: 2.022153377532959
Epoch: 12, Steps: 126 Train Loss: 30.2761 (Forecasting Loss:0.2415 + XiCon Loss:3.0035 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
Validation loss decreased (0.185783 --> 0.185783).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4448681
	speed: 0.0173s/iter; left time: 190.2451s
Epoch: 13 cost time: 2.171452045440674
Epoch: 13, Steps: 126 Train Loss: 30.4187 (Forecasting Loss:0.2414 + XiCon Loss:3.0177 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1375
Validation loss decreased (0.185783 --> 0.185722).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4073009
	speed: 0.0178s/iter; left time: 192.8686s
Epoch: 14 cost time: 2.1853861808776855
Epoch: 14, Steps: 126 Train Loss: 30.3518 (Forecasting Loss:0.2413 + XiCon Loss:3.0111 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.4664440
	speed: 0.0169s/iter; left time: 181.6953s
Epoch: 15 cost time: 2.1211047172546387
Epoch: 15, Steps: 126 Train Loss: 30.3617 (Forecasting Loss:0.2416 + XiCon Loss:3.0120 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9169273
	speed: 0.0168s/iter; left time: 178.5250s
Epoch: 16 cost time: 2.1132047176361084
Epoch: 16, Steps: 126 Train Loss: 30.0822 (Forecasting Loss:0.2416 + XiCon Loss:2.9841 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1374
Validation loss decreased (0.185722 --> 0.185703).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.2193527
	speed: 0.0177s/iter; left time: 185.8787s
Epoch: 17 cost time: 2.198514699935913
Epoch: 17, Steps: 126 Train Loss: 30.3947 (Forecasting Loss:0.2415 + XiCon Loss:3.0153 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.0808678
	speed: 0.0163s/iter; left time: 168.8014s
Epoch: 18 cost time: 2.0127456188201904
Epoch: 18, Steps: 126 Train Loss: 30.3253 (Forecasting Loss:0.2412 + XiCon Loss:3.0084 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1374
Validation loss decreased (0.185703 --> 0.185689).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.3056717
	speed: 0.0169s/iter; left time: 172.4560s
Epoch: 19 cost time: 2.13693904876709
Epoch: 19, Steps: 126 Train Loss: 30.2779 (Forecasting Loss:0.2414 + XiCon Loss:3.0036 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.9028111
	speed: 0.0176s/iter; left time: 177.6134s
Epoch: 20 cost time: 2.1970412731170654
Epoch: 20, Steps: 126 Train Loss: 30.2336 (Forecasting Loss:0.2418 + XiCon Loss:2.9992 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.4011784
	speed: 0.0163s/iter; left time: 162.9039s
Epoch: 21 cost time: 2.039492130279541
Epoch: 21, Steps: 126 Train Loss: 30.3689 (Forecasting Loss:0.2414 + XiCon Loss:3.0128 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1374
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.9594784
	speed: 0.0167s/iter; left time: 164.3843s
Epoch: 22 cost time: 2.070033550262451
Epoch: 22, Steps: 126 Train Loss: 30.3482 (Forecasting Loss:0.2412 + XiCon Loss:3.0107 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.0374584
	speed: 0.0175s/iter; left time: 169.9283s
Epoch: 23 cost time: 2.1960837841033936
Epoch: 23, Steps: 126 Train Loss: 30.3467 (Forecasting Loss:0.2416 + XiCon Loss:3.0105 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.0780373
	speed: 0.0168s/iter; left time: 161.4696s
Epoch: 24 cost time: 2.0853891372680664
Epoch: 24, Steps: 126 Train Loss: 30.3897 (Forecasting Loss:0.2412 + XiCon Loss:3.0148 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1374
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.2385044
	speed: 0.0169s/iter; left time: 160.4209s
Epoch: 25 cost time: 2.1712441444396973
Epoch: 25, Steps: 126 Train Loss: 30.2990 (Forecasting Loss:0.2415 + XiCon Loss:3.0057 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.8963833
	speed: 0.0166s/iter; left time: 155.3384s
Epoch: 26 cost time: 2.055818796157837
Epoch: 26, Steps: 126 Train Loss: 30.4268 (Forecasting Loss:0.2413 + XiCon Loss:3.0186 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.5996799
	speed: 0.0165s/iter; left time: 152.6646s
Epoch: 27 cost time: 2.0750949382781982
Epoch: 27, Steps: 126 Train Loss: 30.3144 (Forecasting Loss:0.2414 + XiCon Loss:3.0073 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.5128880
	speed: 0.0166s/iter; left time: 151.1568s
Epoch: 28 cost time: 2.0757906436920166
Epoch: 28, Steps: 126 Train Loss: 30.4190 (Forecasting Loss:0.2413 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07034682482481003, mae:0.2045382559299469, mape:0.15643838047981262, mspe:0.0420999601483345 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3154
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.7282867
	speed: 0.0147s/iter; left time: 184.1390s
Epoch: 1 cost time: 1.8209240436553955
Epoch: 1, Steps: 126 Train Loss: 30.7601 (Forecasting Loss:0.2771 + XiCon Loss:3.0483 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1443
Validation loss decreased (inf --> 0.195530).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1057072
	speed: 0.0154s/iter; left time: 190.5405s
Epoch: 2 cost time: 1.9469780921936035
Epoch: 2, Steps: 126 Train Loss: 30.3759 (Forecasting Loss:0.2632 + XiCon Loss:3.0113 x Lambda(10.0)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1350
Validation loss decreased (0.195530 --> 0.189530).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6764774
	speed: 0.0180s/iter; left time: 219.9875s
Epoch: 3 cost time: 2.258721113204956
Epoch: 3, Steps: 126 Train Loss: 30.5104 (Forecasting Loss:0.2491 + XiCon Loss:3.0261 x Lambda(10.0)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.1382
Validation loss decreased (0.189530 --> 0.187887).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7098866
	speed: 0.0179s/iter; left time: 216.4117s
Epoch: 4 cost time: 2.180859327316284
Epoch: 4, Steps: 126 Train Loss: 29.6984 (Forecasting Loss:0.2435 + XiCon Loss:2.9455 x Lambda(10.0)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1368
Validation loss decreased (0.187887 --> 0.187753).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4880276
	speed: 0.0163s/iter; left time: 195.6148s
Epoch: 5 cost time: 2.0118939876556396
Epoch: 5, Steps: 126 Train Loss: 29.6625 (Forecasting Loss:0.2397 + XiCon Loss:2.9423 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1346
Validation loss decreased (0.187753 --> 0.184692).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.0727348
	speed: 0.0165s/iter; left time: 196.0976s
Epoch: 6 cost time: 2.0409107208251953
Epoch: 6, Steps: 126 Train Loss: 29.3624 (Forecasting Loss:0.2373 + XiCon Loss:2.9125 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1341
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.7905312
	speed: 0.0169s/iter; left time: 197.9123s
Epoch: 7 cost time: 2.0613179206848145
Epoch: 7, Steps: 126 Train Loss: 29.2801 (Forecasting Loss:0.2358 + XiCon Loss:2.9044 x Lambda(10.0)), Vali MSE Loss: 0.1852 Test MSE Loss: 0.1350
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.6395206
	speed: 0.0167s/iter; left time: 193.5205s
Epoch: 8 cost time: 2.0608696937561035
Epoch: 8, Steps: 126 Train Loss: 29.2892 (Forecasting Loss:0.2355 + XiCon Loss:2.9054 x Lambda(10.0)), Vali MSE Loss: 0.1849 Test MSE Loss: 0.1352
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.0899620
	speed: 0.0177s/iter; left time: 203.8886s
Epoch: 9 cost time: 2.2053170204162598
Epoch: 9, Steps: 126 Train Loss: 29.3367 (Forecasting Loss:0.2350 + XiCon Loss:2.9102 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1350
Validation loss decreased (0.184692 --> 0.184425).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.6692181
	speed: 0.0160s/iter; left time: 182.3957s
Epoch: 10 cost time: 2.0093271732330322
Epoch: 10, Steps: 126 Train Loss: 29.3127 (Forecasting Loss:0.2345 + XiCon Loss:2.9078 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5138130
	speed: 0.0165s/iter; left time: 185.0905s
Epoch: 11 cost time: 2.0475800037384033
Epoch: 11, Steps: 126 Train Loss: 29.4153 (Forecasting Loss:0.2346 + XiCon Loss:2.9181 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1843967
	speed: 0.0167s/iter; left time: 186.1583s
Epoch: 12 cost time: 2.079899549484253
Epoch: 12, Steps: 126 Train Loss: 29.3845 (Forecasting Loss:0.2347 + XiCon Loss:2.9150 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.6737270
	speed: 0.0171s/iter; left time: 188.0227s
Epoch: 13 cost time: 2.0877537727355957
Epoch: 13, Steps: 126 Train Loss: 29.4160 (Forecasting Loss:0.2343 + XiCon Loss:2.9182 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.5299091
	speed: 0.0162s/iter; left time: 175.6813s
Epoch: 14 cost time: 2.0107975006103516
Epoch: 14, Steps: 126 Train Loss: 29.3259 (Forecasting Loss:0.2345 + XiCon Loss:2.9091 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5800400
	speed: 0.0172s/iter; left time: 184.6335s
Epoch: 15 cost time: 2.1259236335754395
Epoch: 15, Steps: 126 Train Loss: 29.3824 (Forecasting Loss:0.2344 + XiCon Loss:2.9148 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1352
Validation loss decreased (0.184425 --> 0.184419).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8615608
	speed: 0.0201s/iter; left time: 212.7757s
Epoch: 16 cost time: 2.4096925258636475
Epoch: 16, Steps: 126 Train Loss: 29.2169 (Forecasting Loss:0.2344 + XiCon Loss:2.8983 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.5364571
	speed: 0.0171s/iter; left time: 179.8119s
Epoch: 17 cost time: 2.123173475265503
Epoch: 17, Steps: 126 Train Loss: 29.2654 (Forecasting Loss:0.2343 + XiCon Loss:2.9031 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1352
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.3636570
	speed: 0.0166s/iter; left time: 171.6924s
Epoch: 18 cost time: 2.036254405975342
Epoch: 18, Steps: 126 Train Loss: 29.2156 (Forecasting Loss:0.2342 + XiCon Loss:2.8981 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4745216
	speed: 0.0165s/iter; left time: 169.1593s
Epoch: 19 cost time: 2.0355958938598633
Epoch: 19, Steps: 126 Train Loss: 29.4287 (Forecasting Loss:0.2344 + XiCon Loss:2.9194 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.5687828
	speed: 0.0165s/iter; left time: 166.3710s
Epoch: 20 cost time: 2.0838353633880615
Epoch: 20, Steps: 126 Train Loss: 29.2014 (Forecasting Loss:0.2345 + XiCon Loss:2.8967 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.0806065
	speed: 0.0170s/iter; left time: 170.1632s
Epoch: 21 cost time: 2.187955856323242
Epoch: 21, Steps: 126 Train Loss: 29.2829 (Forecasting Loss:0.2344 + XiCon Loss:2.9048 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1352
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.1520309
	speed: 0.0163s/iter; left time: 160.9180s
Epoch: 22 cost time: 2.0495073795318604
Epoch: 22, Steps: 126 Train Loss: 29.3342 (Forecasting Loss:0.2344 + XiCon Loss:2.9100 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.6127586
	speed: 0.0166s/iter; left time: 161.0677s
Epoch: 23 cost time: 2.0824086666107178
Epoch: 23, Steps: 126 Train Loss: 29.5426 (Forecasting Loss:0.2343 + XiCon Loss:2.9308 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.9310093
	speed: 0.0162s/iter; left time: 155.7115s
Epoch: 24 cost time: 2.0102508068084717
Epoch: 24, Steps: 126 Train Loss: 29.4092 (Forecasting Loss:0.2342 + XiCon Loss:2.9175 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.9359970
	speed: 0.0166s/iter; left time: 157.7317s
Epoch: 25 cost time: 2.0532891750335693
Epoch: 25, Steps: 126 Train Loss: 29.4030 (Forecasting Loss:0.2345 + XiCon Loss:2.9169 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1352
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06886239349842072, mae:0.20148757100105286, mape:0.15472272038459778, mspe:0.04200540482997894 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0699+-0.00188, MAE:0.2036+-0.00355, MAPE:0.1561+-0.00261, MSPE:0.0424+-0.00108, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5238
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.7435265
	speed: 0.0231s/iter; left time: 284.1763s
Epoch: 1 cost time: 2.7445662021636963
Epoch: 1, Steps: 124 Train Loss: 30.7720 (Forecasting Loss:0.2940 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1624
Validation loss decreased (inf --> 0.216348).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.6552200
	speed: 0.0202s/iter; left time: 245.3770s
Epoch: 2 cost time: 2.474562644958496
Epoch: 2, Steps: 124 Train Loss: 28.9088 (Forecasting Loss:0.2813 + XiCon Loss:2.8628 x Lambda(10.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.1495
Validation loss decreased (0.216348 --> 0.214953).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8458996
	speed: 0.0229s/iter; left time: 276.2991s
Epoch: 3 cost time: 2.7749104499816895
Epoch: 3, Steps: 124 Train Loss: 29.4163 (Forecasting Loss:0.2653 + XiCon Loss:2.9151 x Lambda(10.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1457
Validation loss decreased (0.214953 --> 0.211408).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.1154728
	speed: 0.0231s/iter; left time: 276.1363s
Epoch: 4 cost time: 2.8279402256011963
Epoch: 4, Steps: 124 Train Loss: 30.0231 (Forecasting Loss:0.2595 + XiCon Loss:2.9764 x Lambda(10.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.1479
Validation loss decreased (0.211408 --> 0.204771).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.9056797
	speed: 0.0227s/iter; left time: 267.9343s
Epoch: 5 cost time: 2.7666821479797363
Epoch: 5, Steps: 124 Train Loss: 29.6365 (Forecasting Loss:0.2551 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1462
Validation loss decreased (0.204771 --> 0.203075).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.6929741
	speed: 0.0215s/iter; left time: 251.4465s
Epoch: 6 cost time: 2.6249473094940186
Epoch: 6, Steps: 124 Train Loss: 29.7477 (Forecasting Loss:0.2526 + XiCon Loss:2.9495 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1465
Validation loss decreased (0.203075 --> 0.201138).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1179256
	speed: 0.0213s/iter; left time: 246.6328s
Epoch: 7 cost time: 2.631133556365967
Epoch: 7, Steps: 124 Train Loss: 29.5789 (Forecasting Loss:0.2511 + XiCon Loss:2.9328 x Lambda(10.0)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1467
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3200283
	speed: 0.0208s/iter; left time: 238.0423s
Epoch: 8 cost time: 2.5680384635925293
Epoch: 8, Steps: 124 Train Loss: 29.5834 (Forecasting Loss:0.2505 + XiCon Loss:2.9333 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1471
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.8781605
	speed: 0.0215s/iter; left time: 243.6418s
Epoch: 9 cost time: 2.621655225753784
Epoch: 9, Steps: 124 Train Loss: 29.6507 (Forecasting Loss:0.2502 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1476
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.8385506
	speed: 0.0217s/iter; left time: 242.3426s
Epoch: 10 cost time: 2.7022554874420166
Epoch: 10, Steps: 124 Train Loss: 29.5360 (Forecasting Loss:0.2503 + XiCon Loss:2.9286 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1475
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.6287079
	speed: 0.0212s/iter; left time: 234.1022s
Epoch: 11 cost time: 2.5799450874328613
Epoch: 11, Steps: 124 Train Loss: 29.4098 (Forecasting Loss:0.2499 + XiCon Loss:2.9160 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1474
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.4264870
	speed: 0.0213s/iter; left time: 233.4557s
Epoch: 12 cost time: 2.5916340351104736
Epoch: 12, Steps: 124 Train Loss: 29.3292 (Forecasting Loss:0.2498 + XiCon Loss:2.9079 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1474
Validation loss decreased (0.201138 --> 0.201112).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.4663563
	speed: 0.0224s/iter; left time: 242.0311s
Epoch: 13 cost time: 2.7526354789733887
Epoch: 13, Steps: 124 Train Loss: 29.4658 (Forecasting Loss:0.2504 + XiCon Loss:2.9215 x Lambda(10.0)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1474
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1976681
	speed: 0.0216s/iter; left time: 230.8637s
Epoch: 14 cost time: 2.6320953369140625
Epoch: 14, Steps: 124 Train Loss: 29.5709 (Forecasting Loss:0.2501 + XiCon Loss:2.9321 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1474
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3483200
	speed: 0.0216s/iter; left time: 228.0446s
Epoch: 15 cost time: 2.6722121238708496
Epoch: 15, Steps: 124 Train Loss: 29.4234 (Forecasting Loss:0.2498 + XiCon Loss:2.9174 x Lambda(10.0)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1474
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6382408
	speed: 0.0215s/iter; left time: 224.8596s
Epoch: 16 cost time: 2.627490997314453
Epoch: 16, Steps: 124 Train Loss: 29.5007 (Forecasting Loss:0.2499 + XiCon Loss:2.9251 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1474
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.2872601
	speed: 0.0215s/iter; left time: 221.6845s
Epoch: 17 cost time: 2.6223833560943604
Epoch: 17, Steps: 124 Train Loss: 29.5268 (Forecasting Loss:0.2500 + XiCon Loss:2.9277 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1474
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.3039455
	speed: 0.0215s/iter; left time: 219.3526s
Epoch: 18 cost time: 2.651747226715088
Epoch: 18, Steps: 124 Train Loss: 29.4717 (Forecasting Loss:0.2495 + XiCon Loss:2.9222 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1474
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.9551430
	speed: 0.0215s/iter; left time: 216.0732s
Epoch: 19 cost time: 2.6159310340881348
Epoch: 19, Steps: 124 Train Loss: 29.5913 (Forecasting Loss:0.2496 + XiCon Loss:2.9342 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1474
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.6021004
	speed: 0.0214s/iter; left time: 213.2144s
Epoch: 20 cost time: 2.6276824474334717
Epoch: 20, Steps: 124 Train Loss: 29.4370 (Forecasting Loss:0.2498 + XiCon Loss:2.9187 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1474
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 28.5980034
	speed: 0.0214s/iter; left time: 209.6973s
Epoch: 21 cost time: 2.626103639602661
Epoch: 21, Steps: 124 Train Loss: 29.5855 (Forecasting Loss:0.2502 + XiCon Loss:2.9335 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1474
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.1240807
	speed: 0.0214s/iter; left time: 207.5999s
Epoch: 22 cost time: 2.6389451026916504
Epoch: 22, Steps: 124 Train Loss: 29.5556 (Forecasting Loss:0.2503 + XiCon Loss:2.9305 x Lambda(10.0)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1474
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07658719271421432, mae:0.21819326281547546, mape:0.16603030264377594, mspe:0.047357846051454544 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3333
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.5173054
	speed: 0.0197s/iter; left time: 241.7956s
Epoch: 1 cost time: 2.420274019241333
Epoch: 1, Steps: 124 Train Loss: 30.7267 (Forecasting Loss:0.2945 + XiCon Loss:3.0432 x Lambda(10.0)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1619
Validation loss decreased (inf --> 0.215822).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9954052
	speed: 0.0207s/iter; left time: 251.7465s
Epoch: 2 cost time: 2.5293097496032715
Epoch: 2, Steps: 124 Train Loss: 29.6042 (Forecasting Loss:0.2833 + XiCon Loss:2.9321 x Lambda(10.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1504
Validation loss decreased (0.215822 --> 0.211006).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0608521
	speed: 0.0219s/iter; left time: 263.7500s
Epoch: 3 cost time: 2.6568024158477783
Epoch: 3, Steps: 124 Train Loss: 30.0613 (Forecasting Loss:0.2680 + XiCon Loss:2.9793 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1557
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2663746
	speed: 0.0215s/iter; left time: 256.8195s
Epoch: 4 cost time: 2.64188814163208
Epoch: 4, Steps: 124 Train Loss: 29.6980 (Forecasting Loss:0.2607 + XiCon Loss:2.9437 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1511
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6981411
	speed: 0.0217s/iter; left time: 256.2352s
Epoch: 5 cost time: 2.6414220333099365
Epoch: 5, Steps: 124 Train Loss: 29.6197 (Forecasting Loss:0.2572 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1467
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.7430878
	speed: 0.0211s/iter; left time: 246.7982s
Epoch: 6 cost time: 2.5731287002563477
Epoch: 6, Steps: 124 Train Loss: 29.5797 (Forecasting Loss:0.2549 + XiCon Loss:2.9325 x Lambda(10.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1436
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7581234
	speed: 0.0216s/iter; left time: 249.8367s
Epoch: 7 cost time: 2.6938881874084473
Epoch: 7, Steps: 124 Train Loss: 29.4195 (Forecasting Loss:0.2541 + XiCon Loss:2.9165 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1448
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.4363556
	speed: 0.0210s/iter; left time: 240.3598s
Epoch: 8 cost time: 2.5677809715270996
Epoch: 8, Steps: 124 Train Loss: 29.3117 (Forecasting Loss:0.2534 + XiCon Loss:2.9058 x Lambda(10.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1443
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8329144
	speed: 0.0214s/iter; left time: 242.0780s
Epoch: 9 cost time: 2.6452476978302
Epoch: 9, Steps: 124 Train Loss: 29.4515 (Forecasting Loss:0.2533 + XiCon Loss:2.9198 x Lambda(10.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1441
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.9974518
	speed: 0.0214s/iter; left time: 239.1714s
Epoch: 10 cost time: 2.6119675636291504
Epoch: 10, Steps: 124 Train Loss: 29.5119 (Forecasting Loss:0.2530 + XiCon Loss:2.9259 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1441
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3520279
	speed: 0.0217s/iter; left time: 240.4461s
Epoch: 11 cost time: 2.6409876346588135
Epoch: 11, Steps: 124 Train Loss: 29.5056 (Forecasting Loss:0.2529 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1442
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6916313
	speed: 0.0218s/iter; left time: 238.9233s
Epoch: 12 cost time: 2.6607894897460938
Epoch: 12, Steps: 124 Train Loss: 29.5032 (Forecasting Loss:0.2530 + XiCon Loss:2.9250 x Lambda(10.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1442
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07850736379623413, mae:0.22227708995342255, mape:0.16882136464118958, mspe:0.04797009378671646 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3160
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.8016357
	speed: 0.0206s/iter; left time: 253.3815s
Epoch: 1 cost time: 2.504575729370117
Epoch: 1, Steps: 124 Train Loss: 30.7741 (Forecasting Loss:0.2962 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.2176 Test MSE Loss: 0.1642
Validation loss decreased (inf --> 0.217578).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8114319
	speed: 0.0238s/iter; left time: 289.8035s
Epoch: 2 cost time: 2.8936877250671387
Epoch: 2, Steps: 124 Train Loss: 29.1205 (Forecasting Loss:0.2817 + XiCon Loss:2.8839 x Lambda(10.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1624
Validation loss decreased (0.217578 --> 0.216154).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0848732
	speed: 0.0235s/iter; left time: 283.8332s
Epoch: 3 cost time: 2.8963329792022705
Epoch: 3, Steps: 124 Train Loss: 30.1538 (Forecasting Loss:0.2708 + XiCon Loss:2.9883 x Lambda(10.0)), Vali MSE Loss: 0.2079 Test MSE Loss: 0.1507
Validation loss decreased (0.216154 --> 0.207931).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4758644
	speed: 0.0241s/iter; left time: 287.5832s
Epoch: 4 cost time: 2.9527347087860107
Epoch: 4, Steps: 124 Train Loss: 30.5181 (Forecasting Loss:0.2633 + XiCon Loss:3.0255 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1495
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7585850
	speed: 0.0241s/iter; left time: 284.0207s
Epoch: 5 cost time: 2.9474964141845703
Epoch: 5, Steps: 124 Train Loss: 30.2260 (Forecasting Loss:0.2591 + XiCon Loss:2.9967 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1441
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5425186
	speed: 0.0240s/iter; left time: 280.0399s
Epoch: 6 cost time: 2.9311418533325195
Epoch: 6, Steps: 124 Train Loss: 30.1785 (Forecasting Loss:0.2569 + XiCon Loss:2.9922 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1457
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0786037
	speed: 0.0238s/iter; left time: 275.0161s
Epoch: 7 cost time: 2.9145150184631348
Epoch: 7, Steps: 124 Train Loss: 29.8997 (Forecasting Loss:0.2556 + XiCon Loss:2.9644 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1453
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7186337
	speed: 0.0253s/iter; left time: 289.3203s
Epoch: 8 cost time: 3.054309368133545
Epoch: 8, Steps: 124 Train Loss: 29.8751 (Forecasting Loss:0.2551 + XiCon Loss:2.9620 x Lambda(10.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1452
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0074711
	speed: 0.0240s/iter; left time: 271.1376s
Epoch: 9 cost time: 2.9318525791168213
Epoch: 9, Steps: 124 Train Loss: 29.9321 (Forecasting Loss:0.2545 + XiCon Loss:2.9678 x Lambda(10.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1452
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.4592972
	speed: 0.0246s/iter; left time: 275.4102s
Epoch: 10 cost time: 3.0301148891448975
Epoch: 10, Steps: 124 Train Loss: 29.9045 (Forecasting Loss:0.2543 + XiCon Loss:2.9650 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1454
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8405094
	speed: 0.0250s/iter; left time: 276.7010s
Epoch: 11 cost time: 3.0260791778564453
Epoch: 11, Steps: 124 Train Loss: 30.0445 (Forecasting Loss:0.2545 + XiCon Loss:2.9790 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1452
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.7340240
	speed: 0.0251s/iter; left time: 274.2772s
Epoch: 12 cost time: 3.0494208335876465
Epoch: 12, Steps: 124 Train Loss: 30.0021 (Forecasting Loss:0.2546 + XiCon Loss:2.9747 x Lambda(10.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1451
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.1636181
	speed: 0.0245s/iter; left time: 264.8512s
Epoch: 13 cost time: 2.9716057777404785
Epoch: 13, Steps: 124 Train Loss: 30.0013 (Forecasting Loss:0.2540 + XiCon Loss:2.9747 x Lambda(10.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1452
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07872568815946579, mae:0.22261442244052887, mape:0.16887027025222778, mspe:0.047914136201143265 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3531
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.6065311
	speed: 0.0209s/iter; left time: 257.7006s
Epoch: 1 cost time: 2.5438458919525146
Epoch: 1, Steps: 124 Train Loss: 30.8485 (Forecasting Loss:0.2989 + XiCon Loss:3.0550 x Lambda(10.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1590
Validation loss decreased (inf --> 0.216249).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8477802
	speed: 0.0233s/iter; left time: 283.1851s
Epoch: 2 cost time: 2.845385789871216
Epoch: 2, Steps: 124 Train Loss: 29.8354 (Forecasting Loss:0.2856 + XiCon Loss:2.9550 x Lambda(10.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1493
Validation loss decreased (0.216249 --> 0.213339).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.3228149
	speed: 0.0240s/iter; left time: 289.6879s
Epoch: 3 cost time: 2.9438986778259277
Epoch: 3, Steps: 124 Train Loss: 30.4436 (Forecasting Loss:0.2693 + XiCon Loss:3.0174 x Lambda(10.0)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1443
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.1362991
	speed: 0.0245s/iter; left time: 292.4963s
Epoch: 4 cost time: 3.0230929851531982
Epoch: 4, Steps: 124 Train Loss: 30.0622 (Forecasting Loss:0.2624 + XiCon Loss:2.9800 x Lambda(10.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1497
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3765888
	speed: 0.0248s/iter; left time: 292.3734s
Epoch: 5 cost time: 3.032104015350342
Epoch: 5, Steps: 124 Train Loss: 29.9426 (Forecasting Loss:0.2595 + XiCon Loss:2.9683 x Lambda(10.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1471
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4459591
	speed: 0.0253s/iter; left time: 295.5394s
Epoch: 6 cost time: 3.0810697078704834
Epoch: 6, Steps: 124 Train Loss: 29.7805 (Forecasting Loss:0.2573 + XiCon Loss:2.9523 x Lambda(10.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1466
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8034821
	speed: 0.0250s/iter; left time: 289.0995s
Epoch: 7 cost time: 3.050096273422241
Epoch: 7, Steps: 124 Train Loss: 29.7229 (Forecasting Loss:0.2564 + XiCon Loss:2.9466 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1491
Validation loss decreased (0.213339 --> 0.213125).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8540764
	speed: 0.0254s/iter; left time: 290.9152s
Epoch: 8 cost time: 3.113711357116699
Epoch: 8, Steps: 124 Train Loss: 29.7094 (Forecasting Loss:0.2559 + XiCon Loss:2.9453 x Lambda(10.0)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1474
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4009228
	speed: 0.0247s/iter; left time: 279.7233s
Epoch: 9 cost time: 3.007946252822876
Epoch: 9, Steps: 124 Train Loss: 29.7287 (Forecasting Loss:0.2558 + XiCon Loss:2.9473 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1474
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.5257816
	speed: 0.0248s/iter; left time: 276.9304s
Epoch: 10 cost time: 3.0201761722564697
Epoch: 10, Steps: 124 Train Loss: 29.6003 (Forecasting Loss:0.2553 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1474
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.7312832
	speed: 0.0253s/iter; left time: 280.0442s
Epoch: 11 cost time: 3.081402063369751
Epoch: 11, Steps: 124 Train Loss: 29.6997 (Forecasting Loss:0.2554 + XiCon Loss:2.9444 x Lambda(10.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1473
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4127922
	speed: 0.0251s/iter; left time: 274.4865s
Epoch: 12 cost time: 3.0765464305877686
Epoch: 12, Steps: 124 Train Loss: 29.7320 (Forecasting Loss:0.2554 + XiCon Loss:2.9477 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1474
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.1417847
	speed: 0.0241s/iter; left time: 260.2931s
Epoch: 13 cost time: 2.9617807865142822
Epoch: 13, Steps: 124 Train Loss: 29.6733 (Forecasting Loss:0.2549 + XiCon Loss:2.9418 x Lambda(10.0)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1474
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4272518
	speed: 0.0255s/iter; left time: 272.1662s
Epoch: 14 cost time: 3.1075265407562256
Epoch: 14, Steps: 124 Train Loss: 29.6824 (Forecasting Loss:0.2552 + XiCon Loss:2.9427 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1474
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.6771221
	speed: 0.0252s/iter; left time: 266.7535s
Epoch: 15 cost time: 3.0957119464874268
Epoch: 15, Steps: 124 Train Loss: 29.6367 (Forecasting Loss:0.2552 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1474
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6897373
	speed: 0.0243s/iter; left time: 253.6413s
Epoch: 16 cost time: 2.9518563747406006
Epoch: 16, Steps: 124 Train Loss: 29.7351 (Forecasting Loss:0.2553 + XiCon Loss:2.9480 x Lambda(10.0)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1474
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.8416176
	speed: 0.0247s/iter; left time: 254.8935s
Epoch: 17 cost time: 3.0277116298675537
Epoch: 17, Steps: 124 Train Loss: 29.6595 (Forecasting Loss:0.2552 + XiCon Loss:2.9404 x Lambda(10.0)), Vali MSE Loss: 0.2145 Test MSE Loss: 0.1474
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07753420621156693, mae:0.22064179182052612, mape:0.16636285185813904, mspe:0.04566648229956627 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2887
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.8893242
	speed: 0.0207s/iter; left time: 255.2347s
Epoch: 1 cost time: 2.5161283016204834
Epoch: 1, Steps: 124 Train Loss: 30.8127 (Forecasting Loss:0.2992 + XiCon Loss:3.0514 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.1626
Validation loss decreased (inf --> 0.218887).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8824081
	speed: 0.0242s/iter; left time: 294.3796s
Epoch: 2 cost time: 3.0497944355010986
Epoch: 2, Steps: 124 Train Loss: 29.1543 (Forecasting Loss:0.2845 + XiCon Loss:2.8870 x Lambda(10.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.1772
Validation loss decreased (0.218887 --> 0.217799).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.4259605
	speed: 0.0281s/iter; left time: 338.3176s
Epoch: 3 cost time: 3.390045404434204
Epoch: 3, Steps: 124 Train Loss: 28.5067 (Forecasting Loss:0.2732 + XiCon Loss:2.8233 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1570
Validation loss decreased (0.217799 --> 0.208017).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.2785454
	speed: 0.0282s/iter; left time: 335.8535s
Epoch: 4 cost time: 3.4364681243896484
Epoch: 4, Steps: 124 Train Loss: 28.4442 (Forecasting Loss:0.2676 + XiCon Loss:2.8177 x Lambda(10.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1557
Validation loss decreased (0.208017 --> 0.207065).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.4012871
	speed: 0.0277s/iter; left time: 327.2485s
Epoch: 5 cost time: 3.418396234512329
Epoch: 5, Steps: 124 Train Loss: 28.3939 (Forecasting Loss:0.2652 + XiCon Loss:2.8129 x Lambda(10.0)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1516
Validation loss decreased (0.207065 --> 0.205774).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.3047371
	speed: 0.0277s/iter; left time: 324.0871s
Epoch: 6 cost time: 3.3963053226470947
Epoch: 6, Steps: 124 Train Loss: 28.3099 (Forecasting Loss:0.2629 + XiCon Loss:2.8047 x Lambda(10.0)), Vali MSE Loss: 0.2039 Test MSE Loss: 0.1512
Validation loss decreased (0.205774 --> 0.203925).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.0563679
	speed: 0.0281s/iter; left time: 324.3159s
Epoch: 7 cost time: 3.409754753112793
Epoch: 7, Steps: 124 Train Loss: 28.1743 (Forecasting Loss:0.2605 + XiCon Loss:2.7914 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1507
Validation loss decreased (0.203925 --> 0.203548).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 27.8250637
	speed: 0.0271s/iter; left time: 309.6461s
Epoch: 8 cost time: 3.3062798976898193
Epoch: 8, Steps: 124 Train Loss: 28.0554 (Forecasting Loss:0.2593 + XiCon Loss:2.7796 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1505
Validation loss decreased (0.203548 --> 0.203371).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.3032207
	speed: 0.0268s/iter; left time: 302.9829s
Epoch: 9 cost time: 3.299443244934082
Epoch: 9, Steps: 124 Train Loss: 28.0824 (Forecasting Loss:0.2590 + XiCon Loss:2.7823 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1500
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 27.7297325
	speed: 0.0268s/iter; left time: 300.2295s
Epoch: 10 cost time: 3.288051128387451
Epoch: 10, Steps: 124 Train Loss: 28.0704 (Forecasting Loss:0.2585 + XiCon Loss:2.7812 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1492
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 27.8192825
	speed: 0.0268s/iter; left time: 296.0410s
Epoch: 11 cost time: 3.282043695449829
Epoch: 11, Steps: 124 Train Loss: 28.0882 (Forecasting Loss:0.2579 + XiCon Loss:2.7830 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1486
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.0783806
	speed: 0.0271s/iter; left time: 296.3186s
Epoch: 12 cost time: 3.3114962577819824
Epoch: 12, Steps: 124 Train Loss: 28.0860 (Forecasting Loss:0.2577 + XiCon Loss:2.7828 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1482
Validation loss decreased (0.203371 --> 0.203190).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 27.9275990
	speed: 0.0278s/iter; left time: 300.3584s
Epoch: 13 cost time: 3.3739140033721924
Epoch: 13, Steps: 124 Train Loss: 28.1457 (Forecasting Loss:0.2574 + XiCon Loss:2.7888 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1480
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.0209999
	speed: 0.0277s/iter; left time: 296.2926s
Epoch: 14 cost time: 3.3956916332244873
Epoch: 14, Steps: 124 Train Loss: 28.1042 (Forecasting Loss:0.2575 + XiCon Loss:2.7847 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1479
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.3712006
	speed: 0.0274s/iter; left time: 289.9939s
Epoch: 15 cost time: 3.3448221683502197
Epoch: 15, Steps: 124 Train Loss: 28.1107 (Forecasting Loss:0.2579 + XiCon Loss:2.7853 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1479
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.2135792
	speed: 0.0275s/iter; left time: 287.0973s
Epoch: 16 cost time: 3.3879873752593994
Epoch: 16, Steps: 124 Train Loss: 28.1048 (Forecasting Loss:0.2575 + XiCon Loss:2.7847 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1478
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 27.9498940
	speed: 0.0269s/iter; left time: 277.7852s
Epoch: 17 cost time: 3.2868869304656982
Epoch: 17, Steps: 124 Train Loss: 28.1107 (Forecasting Loss:0.2575 + XiCon Loss:2.7853 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1478
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.2993374
	speed: 0.0272s/iter; left time: 276.8275s
Epoch: 18 cost time: 3.3330159187316895
Epoch: 18, Steps: 124 Train Loss: 28.1091 (Forecasting Loss:0.2576 + XiCon Loss:2.7852 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.2865677
	speed: 0.0275s/iter; left time: 277.2546s
Epoch: 19 cost time: 3.338852643966675
Epoch: 19, Steps: 124 Train Loss: 28.1356 (Forecasting Loss:0.2572 + XiCon Loss:2.7878 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1478
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 27.8380146
	speed: 0.0271s/iter; left time: 269.0286s
Epoch: 20 cost time: 3.321530818939209
Epoch: 20, Steps: 124 Train Loss: 28.1184 (Forecasting Loss:0.2576 + XiCon Loss:2.7861 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 27.8983269
	speed: 0.0268s/iter; left time: 263.3314s
Epoch: 21 cost time: 3.274523973464966
Epoch: 21, Steps: 124 Train Loss: 28.1334 (Forecasting Loss:0.2576 + XiCon Loss:2.7876 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 27.8606415
	speed: 0.0269s/iter; left time: 260.3713s
Epoch: 22 cost time: 3.271465539932251
Epoch: 22, Steps: 124 Train Loss: 28.1064 (Forecasting Loss:0.2573 + XiCon Loss:2.7849 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1478
Validation loss decreased (0.203190 --> 0.203058).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.1617374
	speed: 0.0276s/iter; left time: 264.4681s
Epoch: 23 cost time: 3.365752935409546
Epoch: 23, Steps: 124 Train Loss: 28.0802 (Forecasting Loss:0.2576 + XiCon Loss:2.7823 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 27.7864838
	speed: 0.0273s/iter; left time: 257.7294s
Epoch: 24 cost time: 3.34696626663208
Epoch: 24, Steps: 124 Train Loss: 28.1132 (Forecasting Loss:0.2573 + XiCon Loss:2.7856 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 27.7550774
	speed: 0.0273s/iter; left time: 254.6444s
Epoch: 25 cost time: 3.3294785022735596
Epoch: 25, Steps: 124 Train Loss: 28.1095 (Forecasting Loss:0.2577 + XiCon Loss:2.7852 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1478
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.2978764
	speed: 0.0275s/iter; left time: 252.9047s
Epoch: 26 cost time: 3.327854633331299
Epoch: 26, Steps: 124 Train Loss: 28.0575 (Forecasting Loss:0.2575 + XiCon Loss:2.7800 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 28.2812061
	speed: 0.0271s/iter; left time: 245.5333s
Epoch: 27 cost time: 3.30438232421875
Epoch: 27, Steps: 124 Train Loss: 28.1318 (Forecasting Loss:0.2575 + XiCon Loss:2.7874 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 27.7073097
	speed: 0.0267s/iter; left time: 239.2438s
Epoch: 28 cost time: 3.3106720447540283
Epoch: 28, Steps: 124 Train Loss: 28.0900 (Forecasting Loss:0.2577 + XiCon Loss:2.7832 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1478
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 28.4237061
	speed: 0.0265s/iter; left time: 233.7915s
Epoch: 29 cost time: 3.258030891418457
Epoch: 29, Steps: 124 Train Loss: 28.1211 (Forecasting Loss:0.2575 + XiCon Loss:2.7864 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1478
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 28.5279236
	speed: 0.0277s/iter; left time: 241.1335s
Epoch: 30 cost time: 3.368654727935791
Epoch: 30, Steps: 124 Train Loss: 28.1140 (Forecasting Loss:0.2575 + XiCon Loss:2.7856 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1478
Validation loss decreased (0.203058 --> 0.203000).  Saving model ...
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 27.8409767
	speed: 0.0266s/iter; left time: 228.6505s
Epoch: 31 cost time: 3.247474431991577
Epoch: 31, Steps: 124 Train Loss: 28.0988 (Forecasting Loss:0.2575 + XiCon Loss:2.7841 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 28.2103157
	speed: 0.0275s/iter; left time: 232.1494s
Epoch: 32 cost time: 3.35597825050354
Epoch: 32, Steps: 124 Train Loss: 28.1172 (Forecasting Loss:0.2574 + XiCon Loss:2.7860 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1478
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 28.2636833
	speed: 0.0273s/iter; left time: 227.2314s
Epoch: 33 cost time: 3.3474130630493164
Epoch: 33, Steps: 124 Train Loss: 28.0895 (Forecasting Loss:0.2574 + XiCon Loss:2.7832 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 28.4145660
	speed: 0.0274s/iter; left time: 225.1744s
Epoch: 34 cost time: 3.341407537460327
Epoch: 34, Steps: 124 Train Loss: 28.0681 (Forecasting Loss:0.2574 + XiCon Loss:2.7811 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 28.3365726
	speed: 0.0265s/iter; left time: 214.6354s
Epoch: 35 cost time: 3.231541872024536
Epoch: 35, Steps: 124 Train Loss: 28.1024 (Forecasting Loss:0.2576 + XiCon Loss:2.7845 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1478
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 28.0749722
	speed: 0.0269s/iter; left time: 214.1022s
Epoch: 36 cost time: 3.324775218963623
Epoch: 36, Steps: 124 Train Loss: 28.0784 (Forecasting Loss:0.2575 + XiCon Loss:2.7821 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 28.4510612
	speed: 0.0274s/iter; left time: 214.4431s
Epoch: 37 cost time: 3.3736393451690674
Epoch: 37, Steps: 124 Train Loss: 28.0933 (Forecasting Loss:0.2574 + XiCon Loss:2.7836 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1478
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 27.7462387
	speed: 0.0277s/iter; left time: 214.0241s
Epoch: 38 cost time: 3.4140703678131104
Epoch: 38, Steps: 124 Train Loss: 28.0981 (Forecasting Loss:0.2575 + XiCon Loss:2.7841 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1478
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 28.0356884
	speed: 0.0268s/iter; left time: 203.7144s
Epoch: 39 cost time: 3.2888543605804443
Epoch: 39, Steps: 124 Train Loss: 28.0938 (Forecasting Loss:0.2573 + XiCon Loss:2.7836 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1478
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 28.3081169
	speed: 0.0268s/iter; left time: 200.1399s
Epoch: 40 cost time: 3.2960152626037598
Epoch: 40, Steps: 124 Train Loss: 28.1108 (Forecasting Loss:0.2578 + XiCon Loss:2.7853 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1478
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07650642842054367, mae:0.2191123366355896, mape:0.16483715176582336, mspe:0.044609926640987396 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0776+-0.00129, MAE:0.2206+-0.00239, MAPE:0.1670+-0.00222, MSPE:0.0467+-0.00186, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3435
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.5651970
	speed: 0.0483s/iter; left time: 565.0774s
Epoch: 1 cost time: 5.61281681060791
Epoch: 1, Steps: 118 Train Loss: 31.8850 (Forecasting Loss:0.3614 + XiCon Loss:3.1524 x Lambda(10.0)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.1727
Validation loss decreased (inf --> 0.262411).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.5520267
	speed: 0.0477s/iter; left time: 552.6628s
Epoch: 2 cost time: 5.748961687088013
Epoch: 2, Steps: 118 Train Loss: 31.0744 (Forecasting Loss:0.3264 + XiCon Loss:3.0748 x Lambda(10.0)), Vali MSE Loss: 0.2760 Test MSE Loss: 0.1607
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.1970406
	speed: 0.0542s/iter; left time: 621.9405s
Epoch: 3 cost time: 6.457666635513306
Epoch: 3, Steps: 118 Train Loss: 32.6492 (Forecasting Loss:0.3036 + XiCon Loss:3.2346 x Lambda(10.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1609
Validation loss decreased (0.262411 --> 0.242824).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9808884
	speed: 0.0581s/iter; left time: 659.6131s
Epoch: 4 cost time: 6.7670183181762695
Epoch: 4, Steps: 118 Train Loss: 31.9870 (Forecasting Loss:0.2940 + XiCon Loss:3.1693 x Lambda(10.0)), Vali MSE Loss: 0.2395 Test MSE Loss: 0.1579
Validation loss decreased (0.242824 --> 0.239535).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.4140587
	speed: 0.0564s/iter; left time: 633.3822s
Epoch: 5 cost time: 6.640672206878662
Epoch: 5, Steps: 118 Train Loss: 31.7102 (Forecasting Loss:0.2893 + XiCon Loss:3.1421 x Lambda(10.0)), Vali MSE Loss: 0.2372 Test MSE Loss: 0.1555
Validation loss decreased (0.239535 --> 0.237199).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.8638344
	speed: 0.0557s/iter; left time: 619.3501s
Epoch: 6 cost time: 6.622247219085693
Epoch: 6, Steps: 118 Train Loss: 31.6510 (Forecasting Loss:0.2852 + XiCon Loss:3.1366 x Lambda(10.0)), Vali MSE Loss: 0.2382 Test MSE Loss: 0.1562
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1687946
	speed: 0.0548s/iter; left time: 602.2406s
Epoch: 7 cost time: 6.493614196777344
Epoch: 7, Steps: 118 Train Loss: 31.5089 (Forecasting Loss:0.2853 + XiCon Loss:3.1224 x Lambda(10.0)), Vali MSE Loss: 0.2374 Test MSE Loss: 0.1569
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.7649269
	speed: 0.0531s/iter; left time: 577.9856s
Epoch: 8 cost time: 6.271329164505005
Epoch: 8, Steps: 118 Train Loss: 31.5292 (Forecasting Loss:0.2844 + XiCon Loss:3.1245 x Lambda(10.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1560
Validation loss decreased (0.237199 --> 0.236782).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.5014668
	speed: 0.0540s/iter; left time: 581.1293s
Epoch: 9 cost time: 6.36307692527771
Epoch: 9, Steps: 118 Train Loss: 31.5299 (Forecasting Loss:0.2856 + XiCon Loss:3.1244 x Lambda(10.0)), Vali MSE Loss: 0.2361 Test MSE Loss: 0.1563
Validation loss decreased (0.236782 --> 0.236141).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.0179005
	speed: 0.0587s/iter; left time: 624.8951s
Epoch: 10 cost time: 6.980279207229614
Epoch: 10, Steps: 118 Train Loss: 31.4988 (Forecasting Loss:0.2843 + XiCon Loss:3.1214 x Lambda(10.0)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1561
Validation loss decreased (0.236141 --> 0.235613).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.5027428
	speed: 0.0571s/iter; left time: 600.7188s
Epoch: 11 cost time: 6.643796443939209
Epoch: 11, Steps: 118 Train Loss: 31.4761 (Forecasting Loss:0.2851 + XiCon Loss:3.1191 x Lambda(10.0)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1563
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.6016617
	speed: 0.0563s/iter; left time: 586.0170s
Epoch: 12 cost time: 6.560238838195801
Epoch: 12, Steps: 118 Train Loss: 31.4004 (Forecasting Loss:0.2856 + XiCon Loss:3.1115 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.1563
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.4420891
	speed: 0.0554s/iter; left time: 569.3041s
Epoch: 13 cost time: 6.5304412841796875
Epoch: 13, Steps: 118 Train Loss: 31.4895 (Forecasting Loss:0.2844 + XiCon Loss:3.1205 x Lambda(10.0)), Vali MSE Loss: 0.2364 Test MSE Loss: 0.1563
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.8202705
	speed: 0.0575s/iter; left time: 584.3768s
Epoch: 14 cost time: 6.747423410415649
Epoch: 14, Steps: 118 Train Loss: 31.4027 (Forecasting Loss:0.2848 + XiCon Loss:3.1118 x Lambda(10.0)), Vali MSE Loss: 0.2362 Test MSE Loss: 0.1563
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.6023026
	speed: 0.0544s/iter; left time: 546.5586s
Epoch: 15 cost time: 6.502990007400513
Epoch: 15, Steps: 118 Train Loss: 31.4560 (Forecasting Loss:0.2851 + XiCon Loss:3.1171 x Lambda(10.0)), Vali MSE Loss: 0.2362 Test MSE Loss: 0.1563
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0592918
	speed: 0.0591s/iter; left time: 587.0297s
Epoch: 16 cost time: 6.874906063079834
Epoch: 16, Steps: 118 Train Loss: 31.4698 (Forecasting Loss:0.2853 + XiCon Loss:3.1184 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.1563
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.2404060
	speed: 0.0533s/iter; left time: 522.8074s
Epoch: 17 cost time: 6.280534267425537
Epoch: 17, Steps: 118 Train Loss: 31.4898 (Forecasting Loss:0.2860 + XiCon Loss:3.1204 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1563
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.0346355
	speed: 0.0538s/iter; left time: 521.2126s
Epoch: 18 cost time: 6.316766738891602
Epoch: 18, Steps: 118 Train Loss: 31.5794 (Forecasting Loss:0.2847 + XiCon Loss:3.1295 x Lambda(10.0)), Vali MSE Loss: 0.2365 Test MSE Loss: 0.1563
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.3203411
	speed: 0.0585s/iter; left time: 559.9920s
Epoch: 19 cost time: 6.8656275272369385
Epoch: 19, Steps: 118 Train Loss: 31.5604 (Forecasting Loss:0.2862 + XiCon Loss:3.1274 x Lambda(10.0)), Vali MSE Loss: 0.2366 Test MSE Loss: 0.1563
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.7483864
	speed: 0.0541s/iter; left time: 511.6258s
Epoch: 20 cost time: 6.378088474273682
Epoch: 20, Steps: 118 Train Loss: 31.6018 (Forecasting Loss:0.2851 + XiCon Loss:3.1317 x Lambda(10.0)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1563
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08348532021045685, mae:0.22878128290176392, mape:0.16783525049686432, mspe:0.046152397990226746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3610
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.6297169
	speed: 0.0454s/iter; left time: 530.8323s
Epoch: 1 cost time: 5.324347257614136
Epoch: 1, Steps: 118 Train Loss: 31.8377 (Forecasting Loss:0.3607 + XiCon Loss:3.1477 x Lambda(10.0)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.262261).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.2258110
	speed: 0.0551s/iter; left time: 638.0868s
Epoch: 2 cost time: 6.6067588329315186
Epoch: 2, Steps: 118 Train Loss: 30.7608 (Forecasting Loss:0.3384 + XiCon Loss:3.0422 x Lambda(10.0)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.1680
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.1510277
	speed: 0.0610s/iter; left time: 698.8022s
Epoch: 3 cost time: 7.128165245056152
Epoch: 3, Steps: 118 Train Loss: 32.2246 (Forecasting Loss:0.3003 + XiCon Loss:3.1924 x Lambda(10.0)), Vali MSE Loss: 0.2421 Test MSE Loss: 0.1638
Validation loss decreased (0.262261 --> 0.242111).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.4291573
	speed: 0.0586s/iter; left time: 664.4126s
Epoch: 4 cost time: 6.795180797576904
Epoch: 4, Steps: 118 Train Loss: 31.8287 (Forecasting Loss:0.2927 + XiCon Loss:3.1536 x Lambda(10.0)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1586
Validation loss decreased (0.242111 --> 0.238823).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.8094368
	speed: 0.0586s/iter; left time: 658.0370s
Epoch: 5 cost time: 6.825148344039917
Epoch: 5, Steps: 118 Train Loss: 31.6973 (Forecasting Loss:0.2885 + XiCon Loss:3.1409 x Lambda(10.0)), Vali MSE Loss: 0.2333 Test MSE Loss: 0.1558
Validation loss decreased (0.238823 --> 0.233342).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1461430
	speed: 0.0537s/iter; left time: 597.0497s
Epoch: 6 cost time: 6.301306486129761
Epoch: 6, Steps: 118 Train Loss: 31.5294 (Forecasting Loss:0.2884 + XiCon Loss:3.1241 x Lambda(10.0)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1577
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.1525726
	speed: 0.0500s/iter; left time: 549.1371s
Epoch: 7 cost time: 5.853940486907959
Epoch: 7, Steps: 118 Train Loss: 31.3511 (Forecasting Loss:0.2869 + XiCon Loss:3.1064 x Lambda(10.0)), Vali MSE Loss: 0.2364 Test MSE Loss: 0.1564
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.2591248
	speed: 0.0518s/iter; left time: 562.9154s
Epoch: 8 cost time: 6.019691228866577
Epoch: 8, Steps: 118 Train Loss: 31.4309 (Forecasting Loss:0.2847 + XiCon Loss:3.1146 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.1566
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.2597389
	speed: 0.0504s/iter; left time: 541.7176s
Epoch: 9 cost time: 5.935573577880859
Epoch: 9, Steps: 118 Train Loss: 31.4209 (Forecasting Loss:0.2844 + XiCon Loss:3.1137 x Lambda(10.0)), Vali MSE Loss: 0.2364 Test MSE Loss: 0.1567
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4494896
	speed: 0.0505s/iter; left time: 536.9089s
Epoch: 10 cost time: 5.879255294799805
Epoch: 10, Steps: 118 Train Loss: 31.3059 (Forecasting Loss:0.2846 + XiCon Loss:3.1021 x Lambda(10.0)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1567
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.7119064
	speed: 0.0495s/iter; left time: 520.4651s
Epoch: 11 cost time: 5.845321178436279
Epoch: 11, Steps: 118 Train Loss: 31.4625 (Forecasting Loss:0.2845 + XiCon Loss:3.1178 x Lambda(10.0)), Vali MSE Loss: 0.2364 Test MSE Loss: 0.1568
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7543201
	speed: 0.0498s/iter; left time: 517.6352s
Epoch: 12 cost time: 5.834838151931763
Epoch: 12, Steps: 118 Train Loss: 31.4915 (Forecasting Loss:0.2853 + XiCon Loss:3.1206 x Lambda(10.0)), Vali MSE Loss: 0.2370 Test MSE Loss: 0.1568
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7058907
	speed: 0.0510s/iter; left time: 524.6977s
Epoch: 13 cost time: 5.984427213668823
Epoch: 13, Steps: 118 Train Loss: 31.3359 (Forecasting Loss:0.2841 + XiCon Loss:3.1052 x Lambda(10.0)), Vali MSE Loss: 0.2366 Test MSE Loss: 0.1568
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4024258
	speed: 0.0496s/iter; left time: 504.5527s
Epoch: 14 cost time: 5.805354833602905
Epoch: 14, Steps: 118 Train Loss: 31.2669 (Forecasting Loss:0.2853 + XiCon Loss:3.0982 x Lambda(10.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1568
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.4949245
	speed: 0.0493s/iter; left time: 495.6707s
Epoch: 15 cost time: 5.7937798500061035
Epoch: 15, Steps: 118 Train Loss: 31.3656 (Forecasting Loss:0.2846 + XiCon Loss:3.1081 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.1568
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08320407569408417, mae:0.2284148633480072, mape:0.1677841991186142, mspe:0.04628521949052811 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3422
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.4515705
	speed: 0.0463s/iter; left time: 542.1473s
Epoch: 1 cost time: 5.423310041427612
Epoch: 1, Steps: 118 Train Loss: 31.7833 (Forecasting Loss:0.3611 + XiCon Loss:3.1422 x Lambda(10.0)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1649
Validation loss decreased (inf --> 0.256492).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.6239014
	speed: 0.0453s/iter; left time: 524.9344s
Epoch: 2 cost time: 5.346194505691528
Epoch: 2, Steps: 118 Train Loss: 31.5476 (Forecasting Loss:0.3228 + XiCon Loss:3.1225 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1583
Validation loss decreased (0.256492 --> 0.248600).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.0236588
	speed: 0.0563s/iter; left time: 645.9899s
Epoch: 3 cost time: 6.603100299835205
Epoch: 3, Steps: 118 Train Loss: 32.0616 (Forecasting Loss:0.2942 + XiCon Loss:3.1767 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1667
Validation loss decreased (0.248600 --> 0.235489).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.5852032
	speed: 0.0509s/iter; left time: 577.2511s
Epoch: 4 cost time: 5.984913110733032
Epoch: 4, Steps: 118 Train Loss: 31.0022 (Forecasting Loss:0.2832 + XiCon Loss:3.0719 x Lambda(10.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.1601
Validation loss decreased (0.235489 --> 0.231854).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7992306
	speed: 0.0503s/iter; left time: 564.7595s
Epoch: 5 cost time: 5.912643671035767
Epoch: 5, Steps: 118 Train Loss: 30.7855 (Forecasting Loss:0.2806 + XiCon Loss:3.0505 x Lambda(10.0)), Vali MSE Loss: 0.2306 Test MSE Loss: 0.1564
Validation loss decreased (0.231854 --> 0.230566).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1921825
	speed: 0.0539s/iter; left time: 598.8811s
Epoch: 6 cost time: 6.245970726013184
Epoch: 6, Steps: 118 Train Loss: 30.5361 (Forecasting Loss:0.2783 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1576
Validation loss decreased (0.230566 --> 0.230306).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.8939705
	speed: 0.0491s/iter; left time: 540.2082s
Epoch: 7 cost time: 5.7464892864227295
Epoch: 7, Steps: 118 Train Loss: 30.4779 (Forecasting Loss:0.2775 + XiCon Loss:3.0200 x Lambda(10.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.1593
Validation loss decreased (0.230306 --> 0.229903).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1090641
	speed: 0.0495s/iter; left time: 538.3880s
Epoch: 8 cost time: 5.7985570430755615
Epoch: 8, Steps: 118 Train Loss: 30.5903 (Forecasting Loss:0.2764 + XiCon Loss:3.0314 x Lambda(10.0)), Vali MSE Loss: 0.2298 Test MSE Loss: 0.1587
Validation loss decreased (0.229903 --> 0.229817).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.3395767
	speed: 0.0501s/iter; left time: 538.8718s
Epoch: 9 cost time: 5.849621057510376
Epoch: 9, Steps: 118 Train Loss: 30.4805 (Forecasting Loss:0.2764 + XiCon Loss:3.0204 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1578
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.5000191
	speed: 0.0496s/iter; left time: 527.9482s
Epoch: 10 cost time: 6.040465593338013
Epoch: 10, Steps: 118 Train Loss: 30.6043 (Forecasting Loss:0.2766 + XiCon Loss:3.0328 x Lambda(10.0)), Vali MSE Loss: 0.2312 Test MSE Loss: 0.1574
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2189236
	speed: 0.0470s/iter; left time: 494.8039s
Epoch: 11 cost time: 5.581417798995972
Epoch: 11, Steps: 118 Train Loss: 30.3184 (Forecasting Loss:0.2765 + XiCon Loss:3.0042 x Lambda(10.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1578
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0151424
	speed: 0.0515s/iter; left time: 535.4498s
Epoch: 12 cost time: 6.022193193435669
Epoch: 12, Steps: 118 Train Loss: 30.4257 (Forecasting Loss:0.2760 + XiCon Loss:3.0150 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1578
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.0680733
	speed: 0.0485s/iter; left time: 498.3335s
Epoch: 13 cost time: 5.712813377380371
Epoch: 13, Steps: 118 Train Loss: 30.5031 (Forecasting Loss:0.2758 + XiCon Loss:3.0227 x Lambda(10.0)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1578
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.2553730
	speed: 0.0503s/iter; left time: 511.2077s
Epoch: 14 cost time: 5.856877326965332
Epoch: 14, Steps: 118 Train Loss: 30.4580 (Forecasting Loss:0.2761 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1578
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.8912010
	speed: 0.0504s/iter; left time: 506.5587s
Epoch: 15 cost time: 5.935231685638428
Epoch: 15, Steps: 118 Train Loss: 30.4623 (Forecasting Loss:0.2761 + XiCon Loss:3.0186 x Lambda(10.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1578
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6853428
	speed: 0.0498s/iter; left time: 494.8791s
Epoch: 16 cost time: 5.834615230560303
Epoch: 16, Steps: 118 Train Loss: 30.6412 (Forecasting Loss:0.2755 + XiCon Loss:3.0366 x Lambda(10.0)), Vali MSE Loss: 0.2304 Test MSE Loss: 0.1578
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.8012447
	speed: 0.0490s/iter; left time: 480.9846s
Epoch: 17 cost time: 5.744962215423584
Epoch: 17, Steps: 118 Train Loss: 30.4991 (Forecasting Loss:0.2769 + XiCon Loss:3.0222 x Lambda(10.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.1578
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.9919300
	speed: 0.0504s/iter; left time: 488.2145s
Epoch: 18 cost time: 5.938117504119873
Epoch: 18, Steps: 118 Train Loss: 30.4204 (Forecasting Loss:0.2762 + XiCon Loss:3.0144 x Lambda(10.0)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1578
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08604202419519424, mae:0.23133163154125214, mape:0.16872164607048035, mspe:0.04635752737522125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3022
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.5963497
	speed: 0.0453s/iter; left time: 530.4783s
Epoch: 1 cost time: 5.313220500946045
Epoch: 1, Steps: 118 Train Loss: 31.8222 (Forecasting Loss:0.3625 + XiCon Loss:3.1460 x Lambda(10.0)), Vali MSE Loss: 0.2683 Test MSE Loss: 0.1745
Validation loss decreased (inf --> 0.268268).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.3636589
	speed: 0.0577s/iter; left time: 668.8868s
Epoch: 2 cost time: 7.138507843017578
Epoch: 2, Steps: 118 Train Loss: 31.2572 (Forecasting Loss:0.3337 + XiCon Loss:3.0923 x Lambda(10.0)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1609
Validation loss decreased (0.268268 --> 0.259240).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.8743019
	speed: 0.0803s/iter; left time: 920.6797s
Epoch: 3 cost time: 9.39806604385376
Epoch: 3, Steps: 118 Train Loss: 32.7182 (Forecasting Loss:0.3152 + XiCon Loss:3.2403 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1581
Validation loss decreased (0.259240 --> 0.250780).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.8986588
	speed: 0.0756s/iter; left time: 857.8177s
Epoch: 4 cost time: 8.915004253387451
Epoch: 4, Steps: 118 Train Loss: 32.3934 (Forecasting Loss:0.2966 + XiCon Loss:3.2097 x Lambda(10.0)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1607
Validation loss decreased (0.250780 --> 0.240813).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.4913940
	speed: 0.0747s/iter; left time: 838.4557s
Epoch: 5 cost time: 8.8420569896698
Epoch: 5, Steps: 118 Train Loss: 31.7787 (Forecasting Loss:0.2858 + XiCon Loss:3.1493 x Lambda(10.0)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.1594
Validation loss decreased (0.240813 --> 0.235658).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.9863319
	speed: 0.0768s/iter; left time: 853.0645s
Epoch: 6 cost time: 9.028816223144531
Epoch: 6, Steps: 118 Train Loss: 31.5169 (Forecasting Loss:0.2809 + XiCon Loss:3.1236 x Lambda(10.0)), Vali MSE Loss: 0.2359 Test MSE Loss: 0.1584
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0361500
	speed: 0.0777s/iter; left time: 854.1077s
Epoch: 7 cost time: 9.128312349319458
Epoch: 7, Steps: 118 Train Loss: 31.2392 (Forecasting Loss:0.2788 + XiCon Loss:3.0960 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1590
Validation loss decreased (0.235658 --> 0.235182).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1294193
	speed: 0.0802s/iter; left time: 872.4499s
Epoch: 8 cost time: 9.512423992156982
Epoch: 8, Steps: 118 Train Loss: 31.2563 (Forecasting Loss:0.2777 + XiCon Loss:3.0979 x Lambda(10.0)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.1600
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6143646
	speed: 0.0806s/iter; left time: 866.9717s
Epoch: 9 cost time: 9.594314098358154
Epoch: 9, Steps: 118 Train Loss: 31.2104 (Forecasting Loss:0.2778 + XiCon Loss:3.0933 x Lambda(10.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1591
Validation loss decreased (0.235182 --> 0.235097).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.0481625
	speed: 0.0780s/iter; left time: 829.3739s
Epoch: 10 cost time: 9.16263747215271
Epoch: 10, Steps: 118 Train Loss: 31.2729 (Forecasting Loss:0.2780 + XiCon Loss:3.0995 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6768150
	speed: 0.0758s/iter; left time: 797.3158s
Epoch: 11 cost time: 8.934426069259644
Epoch: 11, Steps: 118 Train Loss: 31.1534 (Forecasting Loss:0.2767 + XiCon Loss:3.0877 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1584
Validation loss decreased (0.235097 --> 0.234957).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8279610
	speed: 0.0819s/iter; left time: 851.5051s
Epoch: 12 cost time: 9.605072498321533
Epoch: 12, Steps: 118 Train Loss: 31.1536 (Forecasting Loss:0.2767 + XiCon Loss:3.0877 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1583
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.4147224
	speed: 0.0758s/iter; left time: 780.0928s
Epoch: 13 cost time: 8.902271032333374
Epoch: 13, Steps: 118 Train Loss: 31.1083 (Forecasting Loss:0.2772 + XiCon Loss:3.0831 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1583
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.3624935
	speed: 0.0760s/iter; left time: 772.7601s
Epoch: 14 cost time: 8.948804378509521
Epoch: 14, Steps: 118 Train Loss: 31.1589 (Forecasting Loss:0.2774 + XiCon Loss:3.0881 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1583
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.1076717
	speed: 0.0796s/iter; left time: 799.5807s
Epoch: 15 cost time: 9.352601528167725
Epoch: 15, Steps: 118 Train Loss: 31.2069 (Forecasting Loss:0.2770 + XiCon Loss:3.0930 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6849308
	speed: 0.0774s/iter; left time: 768.3940s
Epoch: 16 cost time: 9.062575101852417
Epoch: 16, Steps: 118 Train Loss: 31.1750 (Forecasting Loss:0.2771 + XiCon Loss:3.0898 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.2399673
	speed: 0.0796s/iter; left time: 781.0050s
Epoch: 17 cost time: 9.324639558792114
Epoch: 17, Steps: 118 Train Loss: 31.1957 (Forecasting Loss:0.2776 + XiCon Loss:3.0918 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.1559353
	speed: 0.0807s/iter; left time: 782.5094s
Epoch: 18 cost time: 9.425674676895142
Epoch: 18, Steps: 118 Train Loss: 31.3041 (Forecasting Loss:0.2773 + XiCon Loss:3.1027 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1584
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.5253220
	speed: 0.0791s/iter; left time: 757.2999s
Epoch: 19 cost time: 9.286286115646362
Epoch: 19, Steps: 118 Train Loss: 31.1411 (Forecasting Loss:0.2769 + XiCon Loss:3.0864 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1584
Validation loss decreased (0.234957 --> 0.234882).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.0417824
	speed: 0.0755s/iter; left time: 714.5576s
Epoch: 20 cost time: 9.015623331069946
Epoch: 20, Steps: 118 Train Loss: 31.2320 (Forecasting Loss:0.2772 + XiCon Loss:3.0955 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.0165386
	speed: 0.0800s/iter; left time: 747.0387s
Epoch: 21 cost time: 9.315378904342651
Epoch: 21, Steps: 118 Train Loss: 31.1233 (Forecasting Loss:0.2779 + XiCon Loss:3.0845 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1584
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.6247978
	speed: 0.0791s/iter; left time: 729.8417s
Epoch: 22 cost time: 9.309118509292603
Epoch: 22, Steps: 118 Train Loss: 31.1817 (Forecasting Loss:0.2777 + XiCon Loss:3.0904 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1584
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.9698296
	speed: 0.0741s/iter; left time: 674.6017s
Epoch: 23 cost time: 8.773761510848999
Epoch: 23, Steps: 118 Train Loss: 31.1665 (Forecasting Loss:0.2774 + XiCon Loss:3.0889 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1584
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.4179249
	speed: 0.0767s/iter; left time: 689.4688s
Epoch: 24 cost time: 9.037590265274048
Epoch: 24, Steps: 118 Train Loss: 31.0825 (Forecasting Loss:0.2776 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1584
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.6642342
	speed: 0.0751s/iter; left time: 666.1129s
Epoch: 25 cost time: 8.962719917297363
Epoch: 25, Steps: 118 Train Loss: 31.1782 (Forecasting Loss:0.2776 + XiCon Loss:3.0901 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.8085537
	speed: 0.0773s/iter; left time: 676.2334s
Epoch: 26 cost time: 9.108034372329712
Epoch: 26, Steps: 118 Train Loss: 31.1069 (Forecasting Loss:0.2771 + XiCon Loss:3.0830 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 32.3125000
	speed: 0.0788s/iter; left time: 680.1281s
Epoch: 27 cost time: 9.302337884902954
Epoch: 27, Steps: 118 Train Loss: 31.2153 (Forecasting Loss:0.2770 + XiCon Loss:3.0938 x Lambda(10.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1584
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.9711151
	speed: 0.0780s/iter; left time: 664.1880s
Epoch: 28 cost time: 9.341444969177246
Epoch: 28, Steps: 118 Train Loss: 31.1524 (Forecasting Loss:0.2773 + XiCon Loss:3.0875 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1584
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 29.9473095
	speed: 0.0775s/iter; left time: 650.8828s
Epoch: 29 cost time: 9.137393474578857
Epoch: 29, Steps: 118 Train Loss: 31.1636 (Forecasting Loss:0.2770 + XiCon Loss:3.0887 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1584
Validation loss decreased (0.234882 --> 0.234880).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.2368889
	speed: 0.0771s/iter; left time: 638.1672s
Epoch: 30 cost time: 9.096245288848877
Epoch: 30, Steps: 118 Train Loss: 31.2012 (Forecasting Loss:0.2782 + XiCon Loss:3.0923 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1584
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.4650326
	speed: 0.0755s/iter; left time: 616.0925s
Epoch: 31 cost time: 8.958855390548706
Epoch: 31, Steps: 118 Train Loss: 31.1976 (Forecasting Loss:0.2771 + XiCon Loss:3.0921 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1584
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.8148804
	speed: 0.0782s/iter; left time: 628.5879s
Epoch: 32 cost time: 9.167695760726929
Epoch: 32, Steps: 118 Train Loss: 31.1986 (Forecasting Loss:0.2777 + XiCon Loss:3.0921 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1584
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 32.4612083
	speed: 0.0768s/iter; left time: 608.2718s
Epoch: 33 cost time: 9.039336204528809
Epoch: 33, Steps: 118 Train Loss: 31.3010 (Forecasting Loss:0.2772 + XiCon Loss:3.1024 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 29.8806019
	speed: 0.0772s/iter; left time: 602.9960s
Epoch: 34 cost time: 9.038636207580566
Epoch: 34, Steps: 118 Train Loss: 31.1888 (Forecasting Loss:0.2771 + XiCon Loss:3.0912 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 30.4562836
	speed: 0.0788s/iter; left time: 606.2605s
Epoch: 35 cost time: 9.292691707611084
Epoch: 35, Steps: 118 Train Loss: 31.2444 (Forecasting Loss:0.2781 + XiCon Loss:3.0966 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 30.0850945
	speed: 0.0774s/iter; left time: 586.0325s
Epoch: 36 cost time: 9.075011968612671
Epoch: 36, Steps: 118 Train Loss: 31.0790 (Forecasting Loss:0.2766 + XiCon Loss:3.0802 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1584
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 33.1738892
	speed: 0.0783s/iter; left time: 583.8228s
Epoch: 37 cost time: 9.279304027557373
Epoch: 37, Steps: 118 Train Loss: 31.1968 (Forecasting Loss:0.2772 + XiCon Loss:3.0920 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1584
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 30.8179874
	speed: 0.0795s/iter; left time: 582.9178s
Epoch: 38 cost time: 9.409804105758667
Epoch: 38, Steps: 118 Train Loss: 31.2390 (Forecasting Loss:0.2771 + XiCon Loss:3.0962 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1584
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 30.3009186
	speed: 0.0784s/iter; left time: 565.8651s
Epoch: 39 cost time: 9.175145626068115
Epoch: 39, Steps: 118 Train Loss: 31.1996 (Forecasting Loss:0.2771 + XiCon Loss:3.0923 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1584
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08568394929170609, mae:0.23104101419448853, mape:0.16833648085594177, mspe:0.04595424607396126 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4126
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3437366
	speed: 0.0454s/iter; left time: 531.6202s
Epoch: 1 cost time: 5.3269617557525635
Epoch: 1, Steps: 118 Train Loss: 31.8424 (Forecasting Loss:0.3603 + XiCon Loss:3.1482 x Lambda(10.0)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1694
Validation loss decreased (inf --> 0.261633).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.7746620
	speed: 0.0640s/iter; left time: 741.1868s
Epoch: 2 cost time: 7.756906509399414
Epoch: 2, Steps: 118 Train Loss: 31.2230 (Forecasting Loss:0.3307 + XiCon Loss:3.0892 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1692
Validation loss decreased (0.261633 --> 0.250703).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 34.6737785
	speed: 0.0832s/iter; left time: 953.5057s
Epoch: 3 cost time: 9.79568338394165
Epoch: 3, Steps: 118 Train Loss: 33.6945 (Forecasting Loss:0.3248 + XiCon Loss:3.3370 x Lambda(10.0)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.1669
Validation loss decreased (0.250703 --> 0.246626).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 34.0247917
	speed: 0.0843s/iter; left time: 956.6765s
Epoch: 4 cost time: 9.890363931655884
Epoch: 4, Steps: 118 Train Loss: 32.9958 (Forecasting Loss:0.3123 + XiCon Loss:3.2683 x Lambda(10.0)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1576
Validation loss decreased (0.246626 --> 0.239697).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7971497
	speed: 0.0811s/iter; left time: 911.1801s
Epoch: 5 cost time: 9.576652526855469
Epoch: 5, Steps: 118 Train Loss: 32.4750 (Forecasting Loss:0.2939 + XiCon Loss:3.2181 x Lambda(10.0)), Vali MSE Loss: 0.2362 Test MSE Loss: 0.1538
Validation loss decreased (0.239697 --> 0.236151).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.5256729
	speed: 0.0807s/iter; left time: 896.1792s
Epoch: 6 cost time: 9.69837212562561
Epoch: 6, Steps: 118 Train Loss: 32.2993 (Forecasting Loss:0.2908 + XiCon Loss:3.2008 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1540
Validation loss decreased (0.236151 --> 0.234831).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.3961945
	speed: 0.0828s/iter; left time: 909.7797s
Epoch: 7 cost time: 9.72198224067688
Epoch: 7, Steps: 118 Train Loss: 32.0094 (Forecasting Loss:0.2892 + XiCon Loss:3.1720 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1544
Validation loss decreased (0.234831 --> 0.234513).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.4895096
	speed: 0.0832s/iter; left time: 904.8091s
Epoch: 8 cost time: 9.810834169387817
Epoch: 8, Steps: 118 Train Loss: 31.8753 (Forecasting Loss:0.2869 + XiCon Loss:3.1588 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1538
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.1695747
	speed: 0.0821s/iter; left time: 882.9556s
Epoch: 9 cost time: 9.735927820205688
Epoch: 9, Steps: 118 Train Loss: 32.0214 (Forecasting Loss:0.2874 + XiCon Loss:3.1734 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1535
Validation loss decreased (0.234513 --> 0.234098).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.5311394
	speed: 0.0829s/iter; left time: 881.5250s
Epoch: 10 cost time: 9.693967580795288
Epoch: 10, Steps: 118 Train Loss: 31.9210 (Forecasting Loss:0.2882 + XiCon Loss:3.1633 x Lambda(10.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1534
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.8794899
	speed: 0.0820s/iter; left time: 862.9691s
Epoch: 11 cost time: 9.61766767501831
Epoch: 11, Steps: 118 Train Loss: 31.8196 (Forecasting Loss:0.2880 + XiCon Loss:3.1532 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1535
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.1001816
	speed: 0.0821s/iter; left time: 854.5915s
Epoch: 12 cost time: 9.716376543045044
Epoch: 12, Steps: 118 Train Loss: 31.8174 (Forecasting Loss:0.2874 + XiCon Loss:3.1530 x Lambda(10.0)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1535
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.5659981
	speed: 0.0810s/iter; left time: 832.8881s
Epoch: 13 cost time: 9.585745573043823
Epoch: 13, Steps: 118 Train Loss: 31.7553 (Forecasting Loss:0.2872 + XiCon Loss:3.1468 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.8401527
	speed: 0.0823s/iter; left time: 836.6846s
Epoch: 14 cost time: 9.744277238845825
Epoch: 14, Steps: 118 Train Loss: 31.8774 (Forecasting Loss:0.2874 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1535
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.3195229
	speed: 0.0836s/iter; left time: 840.5348s
Epoch: 15 cost time: 9.800272941589355
Epoch: 15, Steps: 118 Train Loss: 31.8307 (Forecasting Loss:0.2874 + XiCon Loss:3.1543 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1535
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.6931229
	speed: 0.0851s/iter; left time: 844.8726s
Epoch: 16 cost time: 9.971296310424805
Epoch: 16, Steps: 118 Train Loss: 31.9430 (Forecasting Loss:0.2875 + XiCon Loss:3.1655 x Lambda(10.0)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 34.3307495
	speed: 0.0816s/iter; left time: 800.6370s
Epoch: 17 cost time: 9.620253562927246
Epoch: 17, Steps: 118 Train Loss: 31.7468 (Forecasting Loss:0.2875 + XiCon Loss:3.1459 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1535
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.6302681
	speed: 0.0833s/iter; left time: 807.6552s
Epoch: 18 cost time: 9.840080738067627
Epoch: 18, Steps: 118 Train Loss: 31.8267 (Forecasting Loss:0.2875 + XiCon Loss:3.1539 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1535
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.7001877
	speed: 0.0820s/iter; left time: 785.6541s
Epoch: 19 cost time: 9.66907525062561
Epoch: 19, Steps: 118 Train Loss: 31.8736 (Forecasting Loss:0.2877 + XiCon Loss:3.1586 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0811551883816719, mae:0.22581979632377625, mape:0.16652284562587738, mspe:0.045129913836717606 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0839+-0.00248, MAE:0.2291+-0.00278, MAPE:0.1678+-0.00103, MSPE:0.0460+-0.00062, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5028
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.3704834
	speed: 0.0172s/iter; left time: 218.9427s
Epoch: 1 cost time: 2.077209711074829
Epoch: 1, Steps: 128 Train Loss: 30.7148 (Forecasting Loss:0.2931 + XiCon Loss:3.0422 x Lambda(10.0)), Vali MSE Loss: 0.2773 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.277321).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4939232
	speed: 0.0143s/iter; left time: 179.9882s
Epoch: 2 cost time: 1.7688052654266357
Epoch: 2, Steps: 128 Train Loss: 28.8806 (Forecasting Loss:0.2573 + XiCon Loss:2.8623 x Lambda(10.0)), Vali MSE Loss: 0.2574 Test MSE Loss: 0.2210
Validation loss decreased (0.277321 --> 0.257362).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5248280
	speed: 0.0149s/iter; left time: 185.6946s
Epoch: 3 cost time: 1.9295814037322998
Epoch: 3, Steps: 128 Train Loss: 28.9709 (Forecasting Loss:0.2436 + XiCon Loss:2.8727 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2206
Validation loss decreased (0.257362 --> 0.252859).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.4495392
	speed: 0.0148s/iter; left time: 182.5667s
Epoch: 4 cost time: 1.8651015758514404
Epoch: 4, Steps: 128 Train Loss: 30.5406 (Forecasting Loss:0.2378 + XiCon Loss:3.0303 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1750259
	speed: 0.0141s/iter; left time: 172.3739s
Epoch: 5 cost time: 1.8056676387786865
Epoch: 5, Steps: 128 Train Loss: 30.6371 (Forecasting Loss:0.2349 + XiCon Loss:3.0402 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2079
Validation loss decreased (0.252859 --> 0.250591).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.0344276
	speed: 0.0160s/iter; left time: 192.6451s
Epoch: 6 cost time: 1.9549503326416016
Epoch: 6, Steps: 128 Train Loss: 30.8105 (Forecasting Loss:0.2330 + XiCon Loss:3.0577 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2063
Validation loss decreased (0.250591 --> 0.249729).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7243519
	speed: 0.0146s/iter; left time: 174.3339s
Epoch: 7 cost time: 1.854586124420166
Epoch: 7, Steps: 128 Train Loss: 30.7999 (Forecasting Loss:0.2319 + XiCon Loss:3.0568 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2067
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3229465
	speed: 0.0141s/iter; left time: 166.1568s
Epoch: 8 cost time: 1.787536382675171
Epoch: 8, Steps: 128 Train Loss: 30.8655 (Forecasting Loss:0.2316 + XiCon Loss:3.0634 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2064
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9305859
	speed: 0.0145s/iter; left time: 169.6185s
Epoch: 9 cost time: 1.8447861671447754
Epoch: 9, Steps: 128 Train Loss: 30.8279 (Forecasting Loss:0.2317 + XiCon Loss:3.0596 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2056
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3967705
	speed: 0.0158s/iter; left time: 182.9918s
Epoch: 10 cost time: 1.9741029739379883
Epoch: 10, Steps: 128 Train Loss: 30.8617 (Forecasting Loss:0.2315 + XiCon Loss:3.0630 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2057
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8787651
	speed: 0.0148s/iter; left time: 169.5676s
Epoch: 11 cost time: 1.8835561275482178
Epoch: 11, Steps: 128 Train Loss: 30.8619 (Forecasting Loss:0.2314 + XiCon Loss:3.0631 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9590740
	speed: 0.0147s/iter; left time: 165.6614s
Epoch: 12 cost time: 1.8462154865264893
Epoch: 12, Steps: 128 Train Loss: 30.8719 (Forecasting Loss:0.2313 + XiCon Loss:3.0641 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2056
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.8230553
	speed: 0.0148s/iter; left time: 165.2505s
Epoch: 13 cost time: 1.831418752670288
Epoch: 13, Steps: 128 Train Loss: 30.9537 (Forecasting Loss:0.2313 + XiCon Loss:3.0722 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2057
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2565041
	speed: 0.0140s/iter; left time: 154.8887s
Epoch: 14 cost time: 1.7566535472869873
Epoch: 14, Steps: 128 Train Loss: 30.9350 (Forecasting Loss:0.2311 + XiCon Loss:3.0704 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9214897
	speed: 0.0146s/iter; left time: 158.8039s
Epoch: 15 cost time: 1.8262627124786377
Epoch: 15, Steps: 128 Train Loss: 30.8861 (Forecasting Loss:0.2311 + XiCon Loss:3.0655 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2057
Validation loss decreased (0.249729 --> 0.249591).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6470470
	speed: 0.0148s/iter; left time: 160.0326s
Epoch: 16 cost time: 1.8462388515472412
Epoch: 16, Steps: 128 Train Loss: 30.9088 (Forecasting Loss:0.2313 + XiCon Loss:3.0677 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.1097107
	speed: 0.0155s/iter; left time: 165.4599s
Epoch: 17 cost time: 1.9114935398101807
Epoch: 17, Steps: 128 Train Loss: 31.0038 (Forecasting Loss:0.2313 + XiCon Loss:3.0772 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2057
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6994858
	speed: 0.0140s/iter; left time: 147.6711s
Epoch: 18 cost time: 1.7701561450958252
Epoch: 18, Steps: 128 Train Loss: 30.9287 (Forecasting Loss:0.2314 + XiCon Loss:3.0697 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2057
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.2041740
	speed: 0.0147s/iter; left time: 152.5210s
Epoch: 19 cost time: 1.8195436000823975
Epoch: 19, Steps: 128 Train Loss: 30.7843 (Forecasting Loss:0.2313 + XiCon Loss:3.0553 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2057
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.5350037
	speed: 0.0143s/iter; left time: 146.7101s
Epoch: 20 cost time: 1.8122482299804688
Epoch: 20, Steps: 128 Train Loss: 30.9560 (Forecasting Loss:0.2313 + XiCon Loss:3.0725 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.5333080
	speed: 0.0142s/iter; left time: 144.3441s
Epoch: 21 cost time: 1.7654166221618652
Epoch: 21, Steps: 128 Train Loss: 30.9100 (Forecasting Loss:0.2311 + XiCon Loss:3.0679 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.1105995
	speed: 0.0150s/iter; left time: 150.2062s
Epoch: 22 cost time: 1.8515770435333252
Epoch: 22, Steps: 128 Train Loss: 30.8610 (Forecasting Loss:0.2313 + XiCon Loss:3.0630 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.8146782
	speed: 0.0156s/iter; left time: 154.5844s
Epoch: 23 cost time: 1.9613001346588135
Epoch: 23, Steps: 128 Train Loss: 30.8203 (Forecasting Loss:0.2313 + XiCon Loss:3.0589 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.4438496
	speed: 0.0139s/iter; left time: 135.3065s
Epoch: 24 cost time: 1.7282524108886719
Epoch: 24, Steps: 128 Train Loss: 30.8789 (Forecasting Loss:0.2313 + XiCon Loss:3.0648 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2057
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.3612289
	speed: 0.0147s/iter; left time: 141.7740s
Epoch: 25 cost time: 1.8436787128448486
Epoch: 25, Steps: 128 Train Loss: 30.8485 (Forecasting Loss:0.2313 + XiCon Loss:3.0617 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2057
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13153304159641266, mae:0.2798209488391876, mape:0.6591522097587585, mspe:19.39893913269043 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2589
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.4266281
	speed: 0.0150s/iter; left time: 190.9253s
Epoch: 1 cost time: 1.8597691059112549
Epoch: 1, Steps: 128 Train Loss: 30.7057 (Forecasting Loss:0.2945 + XiCon Loss:3.0411 x Lambda(10.0)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.2300
Validation loss decreased (inf --> 0.276508).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.7004623
	speed: 0.0142s/iter; left time: 178.7304s
Epoch: 2 cost time: 1.8300256729125977
Epoch: 2, Steps: 128 Train Loss: 29.0319 (Forecasting Loss:0.2609 + XiCon Loss:2.8771 x Lambda(10.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.2273
Validation loss decreased (0.276508 --> 0.261186).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.6207695
	speed: 0.0148s/iter; left time: 184.8025s
Epoch: 3 cost time: 1.8447060585021973
Epoch: 3, Steps: 128 Train Loss: 29.5579 (Forecasting Loss:0.2427 + XiCon Loss:2.9315 x Lambda(10.0)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.2087
Validation loss decreased (0.261186 --> 0.260579).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.4073658
	speed: 0.0156s/iter; left time: 191.9231s
Epoch: 4 cost time: 1.9868769645690918
Epoch: 4, Steps: 128 Train Loss: 29.1992 (Forecasting Loss:0.2372 + XiCon Loss:2.8962 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2067
Validation loss decreased (0.260579 --> 0.250264).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4508228
	speed: 0.0139s/iter; left time: 169.3827s
Epoch: 5 cost time: 1.743666648864746
Epoch: 5, Steps: 128 Train Loss: 29.0442 (Forecasting Loss:0.2350 + XiCon Loss:2.8809 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2064
Validation loss decreased (0.250264 --> 0.250197).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2356186
	speed: 0.0148s/iter; left time: 178.2971s
Epoch: 6 cost time: 1.8388051986694336
Epoch: 6, Steps: 128 Train Loss: 28.9446 (Forecasting Loss:0.2331 + XiCon Loss:2.8712 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2072
Validation loss decreased (0.250197 --> 0.250022).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.8153381
	speed: 0.0147s/iter; left time: 175.6444s
Epoch: 7 cost time: 1.8539631366729736
Epoch: 7, Steps: 128 Train Loss: 28.9666 (Forecasting Loss:0.2323 + XiCon Loss:2.8734 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2057
Validation loss decreased (0.250022 --> 0.249388).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.7350693
	speed: 0.0156s/iter; left time: 184.6364s
Epoch: 8 cost time: 1.9537434577941895
Epoch: 8, Steps: 128 Train Loss: 28.9134 (Forecasting Loss:0.2319 + XiCon Loss:2.8682 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2063
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4081821
	speed: 0.0141s/iter; left time: 164.6518s
Epoch: 9 cost time: 1.766211748123169
Epoch: 9, Steps: 128 Train Loss: 28.8580 (Forecasting Loss:0.2317 + XiCon Loss:2.8626 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.3231621
	speed: 0.0148s/iter; left time: 170.9987s
Epoch: 10 cost time: 1.8407297134399414
Epoch: 10, Steps: 128 Train Loss: 28.8489 (Forecasting Loss:0.2317 + XiCon Loss:2.8617 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2060
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.9374771
	speed: 0.0159s/iter; left time: 181.9644s
Epoch: 11 cost time: 1.9492733478546143
Epoch: 11, Steps: 128 Train Loss: 28.9031 (Forecasting Loss:0.2315 + XiCon Loss:2.8672 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6480961
	speed: 0.0146s/iter; left time: 164.8948s
Epoch: 12 cost time: 1.8262760639190674
Epoch: 12, Steps: 128 Train Loss: 28.8295 (Forecasting Loss:0.2315 + XiCon Loss:2.8598 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.1842213
	speed: 0.0145s/iter; left time: 161.7152s
Epoch: 13 cost time: 1.8095488548278809
Epoch: 13, Steps: 128 Train Loss: 28.8952 (Forecasting Loss:0.2315 + XiCon Loss:2.8664 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2669621
	speed: 0.0145s/iter; left time: 159.5362s
Epoch: 14 cost time: 1.8230421543121338
Epoch: 14, Steps: 128 Train Loss: 28.8671 (Forecasting Loss:0.2314 + XiCon Loss:2.8636 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2059
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.7761517
	speed: 0.0148s/iter; left time: 160.9506s
Epoch: 15 cost time: 1.8443126678466797
Epoch: 15, Steps: 128 Train Loss: 28.9046 (Forecasting Loss:0.2314 + XiCon Loss:2.8673 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2059
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.4795933
	speed: 0.0138s/iter; left time: 148.5735s
Epoch: 16 cost time: 1.7295827865600586
Epoch: 16, Steps: 128 Train Loss: 28.8939 (Forecasting Loss:0.2314 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6942959
	speed: 0.0149s/iter; left time: 158.6831s
Epoch: 17 cost time: 1.8795106410980225
Epoch: 17, Steps: 128 Train Loss: 28.8161 (Forecasting Loss:0.2315 + XiCon Loss:2.8585 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2059
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13164468109607697, mae:0.2797880172729492, mape:0.666252613067627, mspe:19.880355834960938 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3414
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6654682
	speed: 0.0141s/iter; left time: 179.1176s
Epoch: 1 cost time: 1.7857160568237305
Epoch: 1, Steps: 128 Train Loss: 30.8937 (Forecasting Loss:0.2964 + XiCon Loss:3.0597 x Lambda(10.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2326
Validation loss decreased (inf --> 0.278841).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.5914211
	speed: 0.0151s/iter; left time: 190.2080s
Epoch: 2 cost time: 1.925870418548584
Epoch: 2, Steps: 128 Train Loss: 28.9917 (Forecasting Loss:0.2577 + XiCon Loss:2.8734 x Lambda(10.0)), Vali MSE Loss: 0.2691 Test MSE Loss: 0.2199
Validation loss decreased (0.278841 --> 0.269106).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.7979774
	speed: 0.0151s/iter; left time: 188.4896s
Epoch: 3 cost time: 1.9275269508361816
Epoch: 3, Steps: 128 Train Loss: 29.8496 (Forecasting Loss:0.2414 + XiCon Loss:2.9608 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2050
Validation loss decreased (0.269106 --> 0.252652).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.0049305
	speed: 0.0150s/iter; left time: 185.1627s
Epoch: 4 cost time: 1.9013659954071045
Epoch: 4, Steps: 128 Train Loss: 30.1409 (Forecasting Loss:0.2355 + XiCon Loss:2.9905 x Lambda(10.0)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.2050
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7483597
	speed: 0.0148s/iter; left time: 180.8753s
Epoch: 5 cost time: 1.891453742980957
Epoch: 5, Steps: 128 Train Loss: 29.7476 (Forecasting Loss:0.2328 + XiCon Loss:2.9515 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2032
Validation loss decreased (0.252652 --> 0.251730).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7192364
	speed: 0.0151s/iter; left time: 181.6931s
Epoch: 6 cost time: 1.9153461456298828
Epoch: 6, Steps: 128 Train Loss: 29.6265 (Forecasting Loss:0.2319 + XiCon Loss:2.9395 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2020
Validation loss decreased (0.251730 --> 0.250468).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.9203796
	speed: 0.0141s/iter; left time: 168.5295s
Epoch: 7 cost time: 1.7616174221038818
Epoch: 7, Steps: 128 Train Loss: 29.5365 (Forecasting Loss:0.2313 + XiCon Loss:2.9305 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.0749245
	speed: 0.0146s/iter; left time: 172.4651s
Epoch: 8 cost time: 1.8737342357635498
Epoch: 8, Steps: 128 Train Loss: 29.5591 (Forecasting Loss:0.2307 + XiCon Loss:2.9328 x Lambda(10.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2015
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1316643
	speed: 0.0148s/iter; left time: 172.2638s
Epoch: 9 cost time: 1.8583924770355225
Epoch: 9, Steps: 128 Train Loss: 29.4637 (Forecasting Loss:0.2307 + XiCon Loss:2.9233 x Lambda(10.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2022
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0839958
	speed: 0.0141s/iter; left time: 162.5325s
Epoch: 10 cost time: 1.7618305683135986
Epoch: 10, Steps: 128 Train Loss: 29.4596 (Forecasting Loss:0.2306 + XiCon Loss:2.9229 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2018
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1692448
	speed: 0.0151s/iter; left time: 172.4777s
Epoch: 11 cost time: 1.8946750164031982
Epoch: 11, Steps: 128 Train Loss: 29.4991 (Forecasting Loss:0.2304 + XiCon Loss:2.9269 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2018
Validation loss decreased (0.250468 --> 0.250226).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1567688
	speed: 0.0151s/iter; left time: 170.5924s
Epoch: 12 cost time: 1.8630061149597168
Epoch: 12, Steps: 128 Train Loss: 29.5145 (Forecasting Loss:0.2304 + XiCon Loss:2.9284 x Lambda(10.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2017
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2964439
	speed: 0.0156s/iter; left time: 174.7144s
Epoch: 13 cost time: 1.9617760181427002
Epoch: 13, Steps: 128 Train Loss: 29.4134 (Forecasting Loss:0.2303 + XiCon Loss:2.9183 x Lambda(10.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2018
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.3538666
	speed: 0.0469s/iter; left time: 517.5722s
Epoch: 14 cost time: 5.287699937820435
Epoch: 14, Steps: 128 Train Loss: 29.5021 (Forecasting Loss:0.2304 + XiCon Loss:2.9272 x Lambda(10.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2018
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.8446751
	speed: 0.0133s/iter; left time: 144.8783s
Epoch: 15 cost time: 1.6993842124938965
Epoch: 15, Steps: 128 Train Loss: 29.4318 (Forecasting Loss:0.2303 + XiCon Loss:2.9202 x Lambda(10.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2018
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.8560772
	speed: 0.0149s/iter; left time: 161.0789s
Epoch: 16 cost time: 1.9066452980041504
Epoch: 16, Steps: 128 Train Loss: 29.4730 (Forecasting Loss:0.2304 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2018
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.1227512
	speed: 0.0141s/iter; left time: 149.8757s
Epoch: 17 cost time: 1.7699036598205566
Epoch: 17, Steps: 128 Train Loss: 29.4816 (Forecasting Loss:0.2304 + XiCon Loss:2.9251 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2018
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0154114
	speed: 0.0142s/iter; left time: 149.2336s
Epoch: 18 cost time: 1.7864360809326172
Epoch: 18, Steps: 128 Train Loss: 29.4833 (Forecasting Loss:0.2304 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2018
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.5884495
	speed: 0.0150s/iter; left time: 155.8264s
Epoch: 19 cost time: 1.8667731285095215
Epoch: 19, Steps: 128 Train Loss: 29.5531 (Forecasting Loss:0.2302 + XiCon Loss:2.9323 x Lambda(10.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2018
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.8642883
	speed: 0.0148s/iter; left time: 151.5545s
Epoch: 20 cost time: 1.8391225337982178
Epoch: 20, Steps: 128 Train Loss: 29.4847 (Forecasting Loss:0.2305 + XiCon Loss:2.9254 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2018
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.7988548
	speed: 0.0140s/iter; left time: 141.6933s
Epoch: 21 cost time: 1.7598106861114502
Epoch: 21, Steps: 128 Train Loss: 29.4689 (Forecasting Loss:0.2303 + XiCon Loss:2.9239 x Lambda(10.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2018
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.12700553238391876, mae:0.2765960991382599, mape:0.6639710068702698, mspe:19.40901756286621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3531
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.5041866
	speed: 0.0152s/iter; left time: 193.6389s
Epoch: 1 cost time: 1.912034034729004
Epoch: 1, Steps: 128 Train Loss: 30.6649 (Forecasting Loss:0.2947 + XiCon Loss:3.0370 x Lambda(10.0)), Vali MSE Loss: 0.2754 Test MSE Loss: 0.2288
Validation loss decreased (inf --> 0.275397).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8399048
	speed: 0.0146s/iter; left time: 183.2729s
Epoch: 2 cost time: 1.8527748584747314
Epoch: 2, Steps: 128 Train Loss: 29.0202 (Forecasting Loss:0.2570 + XiCon Loss:2.8763 x Lambda(10.0)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2163
Validation loss decreased (0.275397 --> 0.258508).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.1815395
	speed: 0.0145s/iter; left time: 180.9599s
Epoch: 3 cost time: 1.8494021892547607
Epoch: 3, Steps: 128 Train Loss: 28.4826 (Forecasting Loss:0.2428 + XiCon Loss:2.8240 x Lambda(10.0)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.2112
Validation loss decreased (0.258508 --> 0.257488).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.2784843
	speed: 0.0139s/iter; left time: 171.1439s
Epoch: 4 cost time: 1.737041711807251
Epoch: 4, Steps: 128 Train Loss: 28.1870 (Forecasting Loss:0.2377 + XiCon Loss:2.7949 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.2128
Validation loss decreased (0.257488 --> 0.247367).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 27.9299393
	speed: 0.0146s/iter; left time: 177.6394s
Epoch: 5 cost time: 1.8548789024353027
Epoch: 5, Steps: 128 Train Loss: 28.5509 (Forecasting Loss:0.2346 + XiCon Loss:2.8316 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.3934422
	speed: 0.0147s/iter; left time: 176.9104s
Epoch: 6 cost time: 1.827894687652588
Epoch: 6, Steps: 128 Train Loss: 28.9305 (Forecasting Loss:0.2330 + XiCon Loss:2.8698 x Lambda(10.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2057
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.0567436
	speed: 0.0141s/iter; left time: 168.3047s
Epoch: 7 cost time: 1.80031156539917
Epoch: 7, Steps: 128 Train Loss: 29.0882 (Forecasting Loss:0.2321 + XiCon Loss:2.8856 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2062
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.2306004
	speed: 0.0140s/iter; left time: 165.6139s
Epoch: 8 cost time: 1.7773902416229248
Epoch: 8, Steps: 128 Train Loss: 29.2677 (Forecasting Loss:0.2317 + XiCon Loss:2.9036 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2055
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.5838394
	speed: 0.0140s/iter; left time: 163.3159s
Epoch: 9 cost time: 1.7723960876464844
Epoch: 9, Steps: 128 Train Loss: 29.1519 (Forecasting Loss:0.2315 + XiCon Loss:2.8920 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2056
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.6101246
	speed: 0.0149s/iter; left time: 172.0933s
Epoch: 10 cost time: 1.8495714664459229
Epoch: 10, Steps: 128 Train Loss: 29.2480 (Forecasting Loss:0.2311 + XiCon Loss:2.9017 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.2733555
	speed: 0.0153s/iter; left time: 174.3690s
Epoch: 11 cost time: 1.9099643230438232
Epoch: 11, Steps: 128 Train Loss: 29.2985 (Forecasting Loss:0.2313 + XiCon Loss:2.9067 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2056
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.5659389
	speed: 0.0138s/iter; left time: 155.8117s
Epoch: 12 cost time: 1.73756742477417
Epoch: 12, Steps: 128 Train Loss: 29.2383 (Forecasting Loss:0.2313 + XiCon Loss:2.9007 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.1502342
	speed: 0.0139s/iter; left time: 154.7975s
Epoch: 13 cost time: 1.7349357604980469
Epoch: 13, Steps: 128 Train Loss: 29.2644 (Forecasting Loss:0.2313 + XiCon Loss:2.9033 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2056
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.9530296
	speed: 0.0158s/iter; left time: 173.8549s
Epoch: 14 cost time: 1.9689719676971436
Epoch: 14, Steps: 128 Train Loss: 29.2169 (Forecasting Loss:0.2311 + XiCon Loss:2.8986 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2056
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1388845443725586, mae:0.28674179315567017, mape:0.6880167126655579, mspe:21.56909942626953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3139
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.4398518
	speed: 0.0149s/iter; left time: 189.0576s
Epoch: 1 cost time: 1.8759393692016602
Epoch: 1, Steps: 128 Train Loss: 30.5402 (Forecasting Loss:0.2910 + XiCon Loss:3.0249 x Lambda(10.0)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.2264
Validation loss decreased (inf --> 0.272691).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4053135
	speed: 0.0148s/iter; left time: 186.1293s
Epoch: 2 cost time: 1.8657112121582031
Epoch: 2, Steps: 128 Train Loss: 28.8696 (Forecasting Loss:0.2582 + XiCon Loss:2.8611 x Lambda(10.0)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.2305
Validation loss decreased (0.272691 --> 0.259253).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.6961021
	speed: 0.0139s/iter; left time: 173.3674s
Epoch: 3 cost time: 1.7972960472106934
Epoch: 3, Steps: 128 Train Loss: 28.9047 (Forecasting Loss:0.2420 + XiCon Loss:2.8663 x Lambda(10.0)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2053
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.1782513
	speed: 0.0145s/iter; left time: 178.1312s
Epoch: 4 cost time: 1.792637586593628
Epoch: 4, Steps: 128 Train Loss: 29.4932 (Forecasting Loss:0.2366 + XiCon Loss:2.9257 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.2152
Validation loss decreased (0.259253 --> 0.253294).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7488804
	speed: 0.0142s/iter; left time: 173.6465s
Epoch: 5 cost time: 1.7922029495239258
Epoch: 5, Steps: 128 Train Loss: 29.7614 (Forecasting Loss:0.2346 + XiCon Loss:2.9527 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2045
Validation loss decreased (0.253294 --> 0.250147).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2266674
	speed: 0.0150s/iter; left time: 180.3586s
Epoch: 6 cost time: 1.931318759918213
Epoch: 6, Steps: 128 Train Loss: 29.8984 (Forecasting Loss:0.2330 + XiCon Loss:2.9665 x Lambda(10.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2092
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6074867
	speed: 0.0140s/iter; left time: 166.8254s
Epoch: 7 cost time: 1.7838459014892578
Epoch: 7, Steps: 128 Train Loss: 29.9047 (Forecasting Loss:0.2321 + XiCon Loss:2.9673 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2052
Validation loss decreased (0.250147 --> 0.249156).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9149666
	speed: 0.0145s/iter; left time: 170.7877s
Epoch: 8 cost time: 1.8178293704986572
Epoch: 8, Steps: 128 Train Loss: 29.7377 (Forecasting Loss:0.2317 + XiCon Loss:2.9506 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3497677
	speed: 0.0148s/iter; left time: 173.3179s
Epoch: 9 cost time: 1.926731824874878
Epoch: 9, Steps: 128 Train Loss: 29.7928 (Forecasting Loss:0.2312 + XiCon Loss:2.9562 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2055
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3051147
	speed: 0.0146s/iter; left time: 168.4749s
Epoch: 10 cost time: 1.833444356918335
Epoch: 10, Steps: 128 Train Loss: 29.8612 (Forecasting Loss:0.2312 + XiCon Loss:2.9630 x Lambda(10.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2054
Validation loss decreased (0.249156 --> 0.248708).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4675732
	speed: 0.0146s/iter; left time: 166.1974s
Epoch: 11 cost time: 1.822429895401001
Epoch: 11, Steps: 128 Train Loss: 29.8395 (Forecasting Loss:0.2313 + XiCon Loss:2.9608 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2055
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1179600
	speed: 0.0144s/iter; left time: 162.9959s
Epoch: 12 cost time: 1.8023052215576172
Epoch: 12, Steps: 128 Train Loss: 29.8616 (Forecasting Loss:0.2312 + XiCon Loss:2.9630 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2054
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5346222
	speed: 0.0157s/iter; left time: 174.9638s
Epoch: 13 cost time: 1.9229490756988525
Epoch: 13, Steps: 128 Train Loss: 29.7742 (Forecasting Loss:0.2311 + XiCon Loss:2.9543 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2055
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0171337
	speed: 0.0152s/iter; left time: 167.3554s
Epoch: 14 cost time: 1.8616359233856201
Epoch: 14, Steps: 128 Train Loss: 29.8991 (Forecasting Loss:0.2311 + XiCon Loss:2.9668 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2055
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.8559875
	speed: 0.0149s/iter; left time: 162.6323s
Epoch: 15 cost time: 1.8438007831573486
Epoch: 15, Steps: 128 Train Loss: 29.8606 (Forecasting Loss:0.2313 + XiCon Loss:2.9629 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2055
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1009369
	speed: 0.0154s/iter; left time: 166.4004s
Epoch: 16 cost time: 1.9509048461914062
Epoch: 16, Steps: 128 Train Loss: 29.7319 (Forecasting Loss:0.2312 + XiCon Loss:2.9501 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2055
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.4703293
	speed: 0.0137s/iter; left time: 145.6396s
Epoch: 17 cost time: 1.7113547325134277
Epoch: 17, Steps: 128 Train Loss: 29.7525 (Forecasting Loss:0.2312 + XiCon Loss:2.9521 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2055
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.9116554
	speed: 0.0137s/iter; left time: 144.2379s
Epoch: 18 cost time: 1.7670528888702393
Epoch: 18, Steps: 128 Train Loss: 29.6642 (Forecasting Loss:0.2311 + XiCon Loss:2.9433 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.5686436
	speed: 0.0145s/iter; left time: 150.4515s
Epoch: 19 cost time: 1.80881667137146
Epoch: 19, Steps: 128 Train Loss: 29.7893 (Forecasting Loss:0.2311 + XiCon Loss:2.9558 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3557377
	speed: 0.0150s/iter; left time: 153.7395s
Epoch: 20 cost time: 1.868689775466919
Epoch: 20, Steps: 128 Train Loss: 29.7826 (Forecasting Loss:0.2313 + XiCon Loss:2.9551 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13117742538452148, mae:0.27966073155403137, mape:0.6627205014228821, mspe:19.759502410888672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1320+-0.00532, MAE:0.2805+-0.00464, MAPE:0.6680+-0.01424, MSPE:20.0034+-1.11831, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4571
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.6192245
	speed: 0.0185s/iter; left time: 231.5312s
Epoch: 1 cost time: 2.215294361114502
Epoch: 1, Steps: 126 Train Loss: 30.7605 (Forecasting Loss:0.3211 + XiCon Loss:3.0439 x Lambda(10.0)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2708
Validation loss decreased (inf --> 0.311301).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.9969482
	speed: 0.0175s/iter; left time: 216.2766s
Epoch: 2 cost time: 2.16040301322937
Epoch: 2, Steps: 126 Train Loss: 28.9293 (Forecasting Loss:0.2933 + XiCon Loss:2.8636 x Lambda(10.0)), Vali MSE Loss: 0.3019 Test MSE Loss: 0.2541
Validation loss decreased (0.311301 --> 0.301924).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.7238464
	speed: 0.0169s/iter; left time: 206.8605s
Epoch: 3 cost time: 2.0967369079589844
Epoch: 3, Steps: 126 Train Loss: 29.2020 (Forecasting Loss:0.2800 + XiCon Loss:2.8922 x Lambda(10.0)), Vali MSE Loss: 0.2939 Test MSE Loss: 0.2605
Validation loss decreased (0.301924 --> 0.293915).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.6533623
	speed: 0.0190s/iter; left time: 230.4359s
Epoch: 4 cost time: 2.354736328125
Epoch: 4, Steps: 126 Train Loss: 31.1748 (Forecasting Loss:0.2729 + XiCon Loss:3.0902 x Lambda(10.0)), Vali MSE Loss: 0.2924 Test MSE Loss: 0.2497
Validation loss decreased (0.293915 --> 0.292351).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.7220535
	speed: 0.0179s/iter; left time: 214.7773s
Epoch: 5 cost time: 2.248215436935425
Epoch: 5, Steps: 126 Train Loss: 31.8251 (Forecasting Loss:0.2708 + XiCon Loss:3.1554 x Lambda(10.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2473
Validation loss decreased (0.292351 --> 0.289706).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.5440292
	speed: 0.0171s/iter; left time: 202.6639s
Epoch: 6 cost time: 2.1030519008636475
Epoch: 6, Steps: 126 Train Loss: 31.8088 (Forecasting Loss:0.2692 + XiCon Loss:3.1540 x Lambda(10.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2488
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.3071671
	speed: 0.0176s/iter; left time: 206.6649s
Epoch: 7 cost time: 2.1665544509887695
Epoch: 7, Steps: 126 Train Loss: 31.5556 (Forecasting Loss:0.2681 + XiCon Loss:3.1288 x Lambda(10.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2470
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.5471020
	speed: 0.0182s/iter; left time: 210.9803s
Epoch: 8 cost time: 2.224729299545288
Epoch: 8, Steps: 126 Train Loss: 31.6018 (Forecasting Loss:0.2676 + XiCon Loss:3.1334 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2463
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.6170750
	speed: 0.0173s/iter; left time: 198.4464s
Epoch: 9 cost time: 2.153031826019287
Epoch: 9, Steps: 126 Train Loss: 31.7199 (Forecasting Loss:0.2675 + XiCon Loss:3.1452 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2469
Validation loss decreased (0.289706 --> 0.289410).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1916847
	speed: 0.0175s/iter; left time: 199.3088s
Epoch: 10 cost time: 2.205747604370117
Epoch: 10, Steps: 126 Train Loss: 31.6768 (Forecasting Loss:0.2671 + XiCon Loss:3.1410 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2468
Validation loss decreased (0.289410 --> 0.289403).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5433540
	speed: 0.0168s/iter; left time: 188.8541s
Epoch: 11 cost time: 2.1063218116760254
Epoch: 11, Steps: 126 Train Loss: 31.6387 (Forecasting Loss:0.2673 + XiCon Loss:3.1371 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
Validation loss decreased (0.289403 --> 0.289347).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9448376
	speed: 0.0168s/iter; left time: 186.4614s
Epoch: 12 cost time: 2.098287343978882
Epoch: 12, Steps: 126 Train Loss: 31.6763 (Forecasting Loss:0.2670 + XiCon Loss:3.1409 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.3845997
	speed: 0.0174s/iter; left time: 191.3558s
Epoch: 13 cost time: 2.1419639587402344
Epoch: 13, Steps: 126 Train Loss: 31.6492 (Forecasting Loss:0.2673 + XiCon Loss:3.1382 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0627594
	speed: 0.0168s/iter; left time: 182.8209s
Epoch: 14 cost time: 2.098600387573242
Epoch: 14, Steps: 126 Train Loss: 31.6688 (Forecasting Loss:0.2671 + XiCon Loss:3.1402 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.1260433
	speed: 0.0167s/iter; left time: 178.8217s
Epoch: 15 cost time: 2.0720927715301514
Epoch: 15, Steps: 126 Train Loss: 31.5248 (Forecasting Loss:0.2670 + XiCon Loss:3.1258 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
Validation loss decreased (0.289347 --> 0.289321).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.6974945
	speed: 0.0182s/iter; left time: 193.6424s
Epoch: 16 cost time: 2.240673065185547
Epoch: 16, Steps: 126 Train Loss: 31.5982 (Forecasting Loss:0.2672 + XiCon Loss:3.1331 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4322834
	speed: 0.0174s/iter; left time: 182.5409s
Epoch: 17 cost time: 2.1716747283935547
Epoch: 17, Steps: 126 Train Loss: 31.6632 (Forecasting Loss:0.2670 + XiCon Loss:3.1396 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.8525314
	speed: 0.0179s/iter; left time: 184.9481s
Epoch: 18 cost time: 2.178133726119995
Epoch: 18, Steps: 126 Train Loss: 31.7028 (Forecasting Loss:0.2672 + XiCon Loss:3.1436 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.1117706
	speed: 0.0172s/iter; left time: 176.5138s
Epoch: 19 cost time: 2.1340644359588623
Epoch: 19, Steps: 126 Train Loss: 31.7001 (Forecasting Loss:0.2667 + XiCon Loss:3.1433 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5370674
	speed: 0.0173s/iter; left time: 175.1150s
Epoch: 20 cost time: 2.155297040939331
Epoch: 20, Steps: 126 Train Loss: 31.7810 (Forecasting Loss:0.2669 + XiCon Loss:3.1514 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.2231827
	speed: 0.0168s/iter; left time: 168.1483s
Epoch: 21 cost time: 2.130859851837158
Epoch: 21, Steps: 126 Train Loss: 31.6264 (Forecasting Loss:0.2672 + XiCon Loss:3.1359 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.7854118
	speed: 0.0175s/iter; left time: 171.9745s
Epoch: 22 cost time: 2.1922874450683594
Epoch: 22, Steps: 126 Train Loss: 31.7051 (Forecasting Loss:0.2669 + XiCon Loss:3.1438 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.9230423
	speed: 0.0169s/iter; left time: 164.0101s
Epoch: 23 cost time: 2.1016221046447754
Epoch: 23, Steps: 126 Train Loss: 31.8437 (Forecasting Loss:0.2667 + XiCon Loss:3.1577 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.0899887
	speed: 0.0174s/iter; left time: 167.4816s
Epoch: 24 cost time: 2.1500790119171143
Epoch: 24, Steps: 126 Train Loss: 31.6757 (Forecasting Loss:0.2670 + XiCon Loss:3.1409 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
Validation loss decreased (0.289321 --> 0.289309).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.7716885
	speed: 0.0178s/iter; left time: 168.3564s
Epoch: 25 cost time: 2.2123851776123047
Epoch: 25, Steps: 126 Train Loss: 31.5705 (Forecasting Loss:0.2671 + XiCon Loss:3.1303 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.6159954
	speed: 0.0177s/iter; left time: 165.5066s
Epoch: 26 cost time: 2.1715989112854004
Epoch: 26, Steps: 126 Train Loss: 31.6428 (Forecasting Loss:0.2668 + XiCon Loss:3.1376 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 33.2709923
	speed: 0.0188s/iter; left time: 172.9864s
Epoch: 27 cost time: 2.361666202545166
Epoch: 27, Steps: 126 Train Loss: 31.6326 (Forecasting Loss:0.2669 + XiCon Loss:3.1366 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
Validation loss decreased (0.289309 --> 0.289308).  Saving model ...
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 31.6355476
	speed: 0.0177s/iter; left time: 160.8174s
Epoch: 28 cost time: 2.180962085723877
Epoch: 28, Steps: 126 Train Loss: 31.5787 (Forecasting Loss:0.2668 + XiCon Loss:3.1312 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 32.1661682
	speed: 0.0172s/iter; left time: 153.8902s
Epoch: 29 cost time: 2.1390113830566406
Epoch: 29, Steps: 126 Train Loss: 31.6084 (Forecasting Loss:0.2671 + XiCon Loss:3.1341 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
Validation loss decreased (0.289308 --> 0.289253).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 32.3781204
	speed: 0.0170s/iter; left time: 150.3350s
Epoch: 30 cost time: 2.118224620819092
Epoch: 30, Steps: 126 Train Loss: 31.6074 (Forecasting Loss:0.2667 + XiCon Loss:3.1341 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.9844704
	speed: 0.0173s/iter; left time: 150.6671s
Epoch: 31 cost time: 2.1348536014556885
Epoch: 31, Steps: 126 Train Loss: 31.5784 (Forecasting Loss:0.2670 + XiCon Loss:3.1311 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.1390553
	speed: 0.0177s/iter; left time: 152.1271s
Epoch: 32 cost time: 2.19245982170105
Epoch: 32, Steps: 126 Train Loss: 31.6630 (Forecasting Loss:0.2669 + XiCon Loss:3.1396 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 30.8004723
	speed: 0.0188s/iter; left time: 159.3396s
Epoch: 33 cost time: 2.2828283309936523
Epoch: 33, Steps: 126 Train Loss: 31.5896 (Forecasting Loss:0.2670 + XiCon Loss:3.1323 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 33.9643631
	speed: 0.0175s/iter; left time: 145.9918s
Epoch: 34 cost time: 2.1667098999023438
Epoch: 34, Steps: 126 Train Loss: 31.7430 (Forecasting Loss:0.2674 + XiCon Loss:3.1476 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 30.0107403
	speed: 0.0178s/iter; left time: 146.4682s
Epoch: 35 cost time: 2.204406976699829
Epoch: 35, Steps: 126 Train Loss: 31.7166 (Forecasting Loss:0.2670 + XiCon Loss:3.1450 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 32.6600800
	speed: 0.0174s/iter; left time: 141.1606s
Epoch: 36 cost time: 2.1563844680786133
Epoch: 36, Steps: 126 Train Loss: 31.9142 (Forecasting Loss:0.2668 + XiCon Loss:3.1647 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2466
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 32.4010582
	speed: 0.0167s/iter; left time: 133.3911s
Epoch: 37 cost time: 2.1637911796569824
Epoch: 37, Steps: 126 Train Loss: 31.7180 (Forecasting Loss:0.2668 + XiCon Loss:3.1451 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 32.2221909
	speed: 0.0177s/iter; left time: 138.8520s
Epoch: 38 cost time: 2.1731114387512207
Epoch: 38, Steps: 126 Train Loss: 31.6397 (Forecasting Loss:0.2670 + XiCon Loss:3.1373 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 33.7687035
	speed: 0.0185s/iter; left time: 143.0723s
Epoch: 39 cost time: 2.263791084289551
Epoch: 39, Steps: 126 Train Loss: 31.7287 (Forecasting Loss:0.2672 + XiCon Loss:3.1462 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2466
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1690034568309784, mae:0.3242036998271942, mape:0.6799407601356506, mspe:20.01616096496582 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3209
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.5026245
	speed: 0.0154s/iter; left time: 192.2668s
Epoch: 1 cost time: 1.900913953781128
Epoch: 1, Steps: 126 Train Loss: 30.7619 (Forecasting Loss:0.3201 + XiCon Loss:3.0442 x Lambda(10.0)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.2675
Validation loss decreased (inf --> 0.309501).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.0475864
	speed: 0.0170s/iter; left time: 209.8418s
Epoch: 2 cost time: 2.1324453353881836
Epoch: 2, Steps: 126 Train Loss: 29.0136 (Forecasting Loss:0.2927 + XiCon Loss:2.8721 x Lambda(10.0)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.2540
Validation loss decreased (0.309501 --> 0.302870).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0267868
	speed: 0.0166s/iter; left time: 203.1323s
Epoch: 3 cost time: 2.0891027450561523
Epoch: 3, Steps: 126 Train Loss: 29.3571 (Forecasting Loss:0.2800 + XiCon Loss:2.9077 x Lambda(10.0)), Vali MSE Loss: 0.2959 Test MSE Loss: 0.2703
Validation loss decreased (0.302870 --> 0.295934).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.5580387
	speed: 0.0162s/iter; left time: 195.9364s
Epoch: 4 cost time: 2.052319288253784
Epoch: 4, Steps: 126 Train Loss: 30.0291 (Forecasting Loss:0.2731 + XiCon Loss:2.9756 x Lambda(10.0)), Vali MSE Loss: 0.2969 Test MSE Loss: 0.2506
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5174389
	speed: 0.0180s/iter; left time: 216.5436s
Epoch: 5 cost time: 2.2374067306518555
Epoch: 5, Steps: 126 Train Loss: 30.3967 (Forecasting Loss:0.2701 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2457
Validation loss decreased (0.295934 --> 0.290784).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.9971714
	speed: 0.0167s/iter; left time: 197.6648s
Epoch: 6 cost time: 2.075727701187134
Epoch: 6, Steps: 126 Train Loss: 30.5204 (Forecasting Loss:0.2687 + XiCon Loss:3.0252 x Lambda(10.0)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.2494
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8661251
	speed: 0.0173s/iter; left time: 203.5599s
Epoch: 7 cost time: 2.1582727432250977
Epoch: 7, Steps: 126 Train Loss: 30.4499 (Forecasting Loss:0.2678 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2474
Validation loss decreased (0.290784 --> 0.289175).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5203686
	speed: 0.0174s/iter; left time: 202.1244s
Epoch: 8 cost time: 2.1323421001434326
Epoch: 8, Steps: 126 Train Loss: 30.4327 (Forecasting Loss:0.2674 + XiCon Loss:3.0165 x Lambda(10.0)), Vali MSE Loss: 0.2904 Test MSE Loss: 0.2476
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0580273
	speed: 0.0174s/iter; left time: 200.3571s
Epoch: 9 cost time: 2.139373540878296
Epoch: 9, Steps: 126 Train Loss: 30.4882 (Forecasting Loss:0.2670 + XiCon Loss:3.0221 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2483
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.7709141
	speed: 0.0172s/iter; left time: 194.9552s
Epoch: 10 cost time: 2.1156299114227295
Epoch: 10, Steps: 126 Train Loss: 30.5500 (Forecasting Loss:0.2672 + XiCon Loss:3.0283 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1523170
	speed: 0.0181s/iter; left time: 202.9021s
Epoch: 11 cost time: 2.256946563720703
Epoch: 11, Steps: 126 Train Loss: 30.4868 (Forecasting Loss:0.2668 + XiCon Loss:3.0220 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3322220
	speed: 0.0168s/iter; left time: 187.0653s
Epoch: 12 cost time: 2.1065874099731445
Epoch: 12, Steps: 126 Train Loss: 30.4198 (Forecasting Loss:0.2667 + XiCon Loss:3.0153 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4038620
	speed: 0.0164s/iter; left time: 180.6483s
Epoch: 13 cost time: 2.0600318908691406
Epoch: 13, Steps: 126 Train Loss: 30.5255 (Forecasting Loss:0.2670 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.3221245
	speed: 0.0172s/iter; left time: 187.0394s
Epoch: 14 cost time: 2.1369452476501465
Epoch: 14, Steps: 126 Train Loss: 30.4297 (Forecasting Loss:0.2668 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2478
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.6338844
	speed: 0.0172s/iter; left time: 185.0418s
Epoch: 15 cost time: 2.121032476425171
Epoch: 15, Steps: 126 Train Loss: 30.5749 (Forecasting Loss:0.2667 + XiCon Loss:3.0308 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0807953
	speed: 0.0164s/iter; left time: 174.2879s
Epoch: 16 cost time: 2.041508197784424
Epoch: 16, Steps: 126 Train Loss: 30.4747 (Forecasting Loss:0.2666 + XiCon Loss:3.0208 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2478
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.7697468
	speed: 0.0180s/iter; left time: 188.7177s
Epoch: 17 cost time: 2.252920389175415
Epoch: 17, Steps: 126 Train Loss: 30.5057 (Forecasting Loss:0.2669 + XiCon Loss:3.0239 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2478
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1701907068490982, mae:0.3246411681175232, mape:0.6810952425003052, mspe:20.215404510498047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2679
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.3806667
	speed: 0.0161s/iter; left time: 201.1730s
Epoch: 1 cost time: 1.998978614807129
Epoch: 1, Steps: 126 Train Loss: 30.7346 (Forecasting Loss:0.3158 + XiCon Loss:3.0419 x Lambda(10.0)), Vali MSE Loss: 0.3088 Test MSE Loss: 0.2682
Validation loss decreased (inf --> 0.308789).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.0654316
	speed: 0.0170s/iter; left time: 210.6680s
Epoch: 2 cost time: 2.1148440837860107
Epoch: 2, Steps: 126 Train Loss: 29.2752 (Forecasting Loss:0.2906 + XiCon Loss:2.8985 x Lambda(10.0)), Vali MSE Loss: 0.3044 Test MSE Loss: 0.2544
Validation loss decreased (0.308789 --> 0.304439).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3638210
	speed: 0.0179s/iter; left time: 219.0042s
Epoch: 3 cost time: 2.1915557384490967
Epoch: 3, Steps: 126 Train Loss: 29.5892 (Forecasting Loss:0.2810 + XiCon Loss:2.9308 x Lambda(10.0)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.2568
Validation loss decreased (0.304439 --> 0.298525).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6950455
	speed: 0.0168s/iter; left time: 203.8147s
Epoch: 4 cost time: 2.0937163829803467
Epoch: 4, Steps: 126 Train Loss: 29.8701 (Forecasting Loss:0.2725 + XiCon Loss:2.9598 x Lambda(10.0)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.2485
Validation loss decreased (0.298525 --> 0.292577).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2612934
	speed: 0.0165s/iter; left time: 197.3892s
Epoch: 5 cost time: 2.037943124771118
Epoch: 5, Steps: 126 Train Loss: 30.0395 (Forecasting Loss:0.2699 + XiCon Loss:2.9770 x Lambda(10.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2470
Validation loss decreased (0.292577 --> 0.288158).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.8473129
	speed: 0.0168s/iter; left time: 200.0007s
Epoch: 6 cost time: 2.1004714965820312
Epoch: 6, Steps: 126 Train Loss: 30.0760 (Forecasting Loss:0.2680 + XiCon Loss:2.9808 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2451
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6535549
	speed: 0.0170s/iter; left time: 199.9145s
Epoch: 7 cost time: 2.0992565155029297
Epoch: 7, Steps: 126 Train Loss: 30.1554 (Forecasting Loss:0.2671 + XiCon Loss:2.9888 x Lambda(10.0)), Vali MSE Loss: 0.2867 Test MSE Loss: 0.2483
Validation loss decreased (0.288158 --> 0.286705).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.5361614
	speed: 0.0163s/iter; left time: 189.8860s
Epoch: 8 cost time: 2.063405752182007
Epoch: 8, Steps: 126 Train Loss: 30.2232 (Forecasting Loss:0.2669 + XiCon Loss:2.9956 x Lambda(10.0)), Vali MSE Loss: 0.2882 Test MSE Loss: 0.2478
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8154984
	speed: 0.0167s/iter; left time: 191.4843s
Epoch: 9 cost time: 2.084713935852051
Epoch: 9, Steps: 126 Train Loss: 30.3112 (Forecasting Loss:0.2670 + XiCon Loss:3.0044 x Lambda(10.0)), Vali MSE Loss: 0.2881 Test MSE Loss: 0.2482
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6978683
	speed: 0.0168s/iter; left time: 190.9949s
Epoch: 10 cost time: 2.0954341888427734
Epoch: 10, Steps: 126 Train Loss: 30.1160 (Forecasting Loss:0.2664 + XiCon Loss:2.9850 x Lambda(10.0)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.2481
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6951141
	speed: 0.0170s/iter; left time: 190.9537s
Epoch: 11 cost time: 2.128173828125
Epoch: 11, Steps: 126 Train Loss: 30.3293 (Forecasting Loss:0.2660 + XiCon Loss:3.0063 x Lambda(10.0)), Vali MSE Loss: 0.2877 Test MSE Loss: 0.2481
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1276226
	speed: 0.0166s/iter; left time: 184.3500s
Epoch: 12 cost time: 2.086629629135132
Epoch: 12, Steps: 126 Train Loss: 30.2256 (Forecasting Loss:0.2664 + XiCon Loss:2.9959 x Lambda(10.0)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.2480
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.9429703
	speed: 0.0171s/iter; left time: 188.1196s
Epoch: 13 cost time: 2.1268458366394043
Epoch: 13, Steps: 126 Train Loss: 30.1789 (Forecasting Loss:0.2663 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.2877 Test MSE Loss: 0.2481
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3019810
	speed: 0.0176s/iter; left time: 190.7302s
Epoch: 14 cost time: 2.200592517852783
Epoch: 14, Steps: 126 Train Loss: 30.1819 (Forecasting Loss:0.2662 + XiCon Loss:2.9916 x Lambda(10.0)), Vali MSE Loss: 0.2875 Test MSE Loss: 0.2480
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.1354485
	speed: 0.0172s/iter; left time: 184.8913s
Epoch: 15 cost time: 2.141469717025757
Epoch: 15, Steps: 126 Train Loss: 30.2072 (Forecasting Loss:0.2664 + XiCon Loss:2.9941 x Lambda(10.0)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.2480
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8585701
	speed: 0.0163s/iter; left time: 173.0546s
Epoch: 16 cost time: 2.023876428604126
Epoch: 16, Steps: 126 Train Loss: 30.2468 (Forecasting Loss:0.2661 + XiCon Loss:2.9981 x Lambda(10.0)), Vali MSE Loss: 0.2877 Test MSE Loss: 0.2480
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6332436
	speed: 0.0177s/iter; left time: 186.0775s
Epoch: 17 cost time: 2.2271974086761475
Epoch: 17, Steps: 126 Train Loss: 30.3541 (Forecasting Loss:0.2659 + XiCon Loss:3.0088 x Lambda(10.0)), Vali MSE Loss: 0.2877 Test MSE Loss: 0.2480
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.17049428820610046, mae:0.3261403739452362, mape:0.6740773320198059, mspe:19.642553329467773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2704
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.6189861
	speed: 0.0159s/iter; left time: 198.4795s
Epoch: 1 cost time: 1.9502053260803223
Epoch: 1, Steps: 126 Train Loss: 30.7031 (Forecasting Loss:0.3185 + XiCon Loss:3.0385 x Lambda(10.0)), Vali MSE Loss: 0.3058 Test MSE Loss: 0.2646
Validation loss decreased (inf --> 0.305799).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1012955
	speed: 0.0172s/iter; left time: 213.0919s
Epoch: 2 cost time: 2.1862823963165283
Epoch: 2, Steps: 126 Train Loss: 29.5066 (Forecasting Loss:0.2911 + XiCon Loss:2.9216 x Lambda(10.0)), Vali MSE Loss: 0.2935 Test MSE Loss: 0.2713
Validation loss decreased (0.305799 --> 0.293506).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7988300
	speed: 0.0173s/iter; left time: 211.9702s
Epoch: 3 cost time: 2.1421773433685303
Epoch: 3, Steps: 126 Train Loss: 29.7194 (Forecasting Loss:0.2777 + XiCon Loss:2.9442 x Lambda(10.0)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.2568
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3516083
	speed: 0.0171s/iter; left time: 207.3047s
Epoch: 4 cost time: 2.1155261993408203
Epoch: 4, Steps: 126 Train Loss: 29.1514 (Forecasting Loss:0.2733 + XiCon Loss:2.8878 x Lambda(10.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.2520
Validation loss decreased (0.293506 --> 0.290516).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.8919430
	speed: 0.0172s/iter; left time: 206.4027s
Epoch: 5 cost time: 2.161043882369995
Epoch: 5, Steps: 126 Train Loss: 29.0794 (Forecasting Loss:0.2693 + XiCon Loss:2.8810 x Lambda(10.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2507
Validation loss decreased (0.290516 --> 0.289195).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5381126
	speed: 0.0180s/iter; left time: 213.3010s
Epoch: 6 cost time: 2.2178878784179688
Epoch: 6, Steps: 126 Train Loss: 28.9549 (Forecasting Loss:0.2676 + XiCon Loss:2.8687 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2477
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.6603794
	speed: 0.0193s/iter; left time: 226.1049s
Epoch: 7 cost time: 2.374171495437622
Epoch: 7, Steps: 126 Train Loss: 28.9515 (Forecasting Loss:0.2666 + XiCon Loss:2.8685 x Lambda(10.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2480
Validation loss decreased (0.289195 --> 0.289006).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.1635342
	speed: 0.0176s/iter; left time: 204.3951s
Epoch: 8 cost time: 2.173626661300659
Epoch: 8, Steps: 126 Train Loss: 28.8819 (Forecasting Loss:0.2667 + XiCon Loss:2.8615 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2480
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3428078
	speed: 0.0176s/iter; left time: 202.2153s
Epoch: 9 cost time: 2.18229079246521
Epoch: 9, Steps: 126 Train Loss: 28.9499 (Forecasting Loss:0.2664 + XiCon Loss:2.8684 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2481
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.2973728
	speed: 0.0169s/iter; left time: 192.3460s
Epoch: 10 cost time: 2.0916101932525635
Epoch: 10, Steps: 126 Train Loss: 28.9474 (Forecasting Loss:0.2662 + XiCon Loss:2.8681 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2479
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.3723125
	speed: 0.0175s/iter; left time: 196.7327s
Epoch: 11 cost time: 2.225623607635498
Epoch: 11, Steps: 126 Train Loss: 28.9006 (Forecasting Loss:0.2663 + XiCon Loss:2.8634 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2479
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3182907
	speed: 0.0175s/iter; left time: 194.1405s
Epoch: 12 cost time: 2.1700246334075928
Epoch: 12, Steps: 126 Train Loss: 28.8948 (Forecasting Loss:0.2660 + XiCon Loss:2.8629 x Lambda(10.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2478
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3149796
	speed: 0.0176s/iter; left time: 192.9675s
Epoch: 13 cost time: 2.1590240001678467
Epoch: 13, Steps: 126 Train Loss: 28.9368 (Forecasting Loss:0.2663 + XiCon Loss:2.8670 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.9937305
	speed: 0.0176s/iter; left time: 191.2519s
Epoch: 14 cost time: 2.186697244644165
Epoch: 14, Steps: 126 Train Loss: 28.9328 (Forecasting Loss:0.2659 + XiCon Loss:2.8667 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9081478
	speed: 0.0178s/iter; left time: 190.8304s
Epoch: 15 cost time: 2.1894893646240234
Epoch: 15, Steps: 126 Train Loss: 28.9792 (Forecasting Loss:0.2661 + XiCon Loss:2.8713 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.9526520
	speed: 0.0171s/iter; left time: 181.1843s
Epoch: 16 cost time: 2.126981019973755
Epoch: 16, Steps: 126 Train Loss: 28.8912 (Forecasting Loss:0.2663 + XiCon Loss:2.8625 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2478
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.0529232
	speed: 0.0191s/iter; left time: 199.7812s
Epoch: 17 cost time: 2.354294776916504
Epoch: 17, Steps: 126 Train Loss: 28.9293 (Forecasting Loss:0.2660 + XiCon Loss:2.8663 x Lambda(10.0)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.2478
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.17096087336540222, mae:0.32494908571243286, mape:0.6764046549797058, mspe:19.858749389648438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2989
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.4777908
	speed: 0.0164s/iter; left time: 204.6755s
Epoch: 1 cost time: 2.018866777420044
Epoch: 1, Steps: 126 Train Loss: 30.8391 (Forecasting Loss:0.3184 + XiCon Loss:3.0521 x Lambda(10.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2636
Validation loss decreased (inf --> 0.312692).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.1583805
	speed: 0.0166s/iter; left time: 205.1809s
Epoch: 2 cost time: 2.0869767665863037
Epoch: 2, Steps: 126 Train Loss: 29.0191 (Forecasting Loss:0.2943 + XiCon Loss:2.8725 x Lambda(10.0)), Vali MSE Loss: 0.2983 Test MSE Loss: 0.2562
Validation loss decreased (0.312692 --> 0.298331).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.7031364
	speed: 0.0170s/iter; left time: 208.2236s
Epoch: 3 cost time: 2.1040728092193604
Epoch: 3, Steps: 126 Train Loss: 29.7321 (Forecasting Loss:0.2800 + XiCon Loss:2.9452 x Lambda(10.0)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2596
Validation loss decreased (0.298331 --> 0.294092).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7593918
	speed: 0.0179s/iter; left time: 217.3644s
Epoch: 4 cost time: 2.240165948867798
Epoch: 4, Steps: 126 Train Loss: 30.8720 (Forecasting Loss:0.2720 + XiCon Loss:3.0600 x Lambda(10.0)), Vali MSE Loss: 0.2937 Test MSE Loss: 0.2528
Validation loss decreased (0.294092 --> 0.293711).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7767239
	speed: 0.0174s/iter; left time: 209.2911s
Epoch: 5 cost time: 2.2004435062408447
Epoch: 5, Steps: 126 Train Loss: 30.8881 (Forecasting Loss:0.2695 + XiCon Loss:3.0619 x Lambda(10.0)), Vali MSE Loss: 0.2945 Test MSE Loss: 0.2462
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.8567543
	speed: 0.0169s/iter; left time: 200.0823s
Epoch: 6 cost time: 2.096200942993164
Epoch: 6, Steps: 126 Train Loss: 30.9607 (Forecasting Loss:0.2679 + XiCon Loss:3.0693 x Lambda(10.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2487
Validation loss decreased (0.293711 --> 0.292200).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.2381058
	speed: 0.0176s/iter; left time: 207.2767s
Epoch: 7 cost time: 2.2191734313964844
Epoch: 7, Steps: 126 Train Loss: 30.8987 (Forecasting Loss:0.2670 + XiCon Loss:3.0632 x Lambda(10.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2475
Validation loss decreased (0.292200 --> 0.292159).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3294449
	speed: 0.0177s/iter; left time: 205.2089s
Epoch: 8 cost time: 2.190279245376587
Epoch: 8, Steps: 126 Train Loss: 31.0380 (Forecasting Loss:0.2668 + XiCon Loss:3.0771 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2471
Validation loss decreased (0.292159 --> 0.290286).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5534115
	speed: 0.0174s/iter; left time: 200.4513s
Epoch: 9 cost time: 2.1640236377716064
Epoch: 9, Steps: 126 Train Loss: 30.8760 (Forecasting Loss:0.2662 + XiCon Loss:3.0610 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2472
Validation loss decreased (0.290286 --> 0.290250).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2472534
	speed: 0.0176s/iter; left time: 200.5951s
Epoch: 10 cost time: 2.171076536178589
Epoch: 10, Steps: 126 Train Loss: 31.0452 (Forecasting Loss:0.2664 + XiCon Loss:3.0779 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2469
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.3567314
	speed: 0.0179s/iter; left time: 201.2826s
Epoch: 11 cost time: 2.274303674697876
Epoch: 11, Steps: 126 Train Loss: 30.8995 (Forecasting Loss:0.2658 + XiCon Loss:3.0634 x Lambda(10.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2469
Validation loss decreased (0.290250 --> 0.290131).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7295647
	speed: 0.0173s/iter; left time: 192.5022s
Epoch: 12 cost time: 2.1519935131073
Epoch: 12, Steps: 126 Train Loss: 30.9895 (Forecasting Loss:0.2664 + XiCon Loss:3.0723 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2469
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.7306213
	speed: 0.0169s/iter; left time: 185.9801s
Epoch: 13 cost time: 2.115795850753784
Epoch: 13, Steps: 126 Train Loss: 31.0277 (Forecasting Loss:0.2658 + XiCon Loss:3.0762 x Lambda(10.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2469
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2730370
	speed: 0.0179s/iter; left time: 193.9763s
Epoch: 14 cost time: 2.2280194759368896
Epoch: 14, Steps: 126 Train Loss: 30.8003 (Forecasting Loss:0.2659 + XiCon Loss:3.0534 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2469
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4824486
	speed: 0.0175s/iter; left time: 187.7746s
Epoch: 15 cost time: 2.1682887077331543
Epoch: 15, Steps: 126 Train Loss: 30.9481 (Forecasting Loss:0.2661 + XiCon Loss:3.0682 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2469
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4886932
	speed: 0.0173s/iter; left time: 183.8607s
Epoch: 16 cost time: 2.158446788787842
Epoch: 16, Steps: 126 Train Loss: 30.9369 (Forecasting Loss:0.2660 + XiCon Loss:3.0671 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2469
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.8711910
	speed: 0.0192s/iter; left time: 201.2324s
Epoch: 17 cost time: 2.363523006439209
Epoch: 17, Steps: 126 Train Loss: 30.9288 (Forecasting Loss:0.2661 + XiCon Loss:3.0663 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2469
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.5120525
	speed: 0.0175s/iter; left time: 181.2657s
Epoch: 18 cost time: 2.1781411170959473
Epoch: 18, Steps: 126 Train Loss: 31.0493 (Forecasting Loss:0.2661 + XiCon Loss:3.0783 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2469
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.3362808
	speed: 0.0171s/iter; left time: 174.5672s
Epoch: 19 cost time: 2.128746509552002
Epoch: 19, Steps: 126 Train Loss: 30.9536 (Forecasting Loss:0.2663 + XiCon Loss:3.0687 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2469
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.6815300
	speed: 0.0174s/iter; left time: 175.7128s
Epoch: 20 cost time: 2.1545121669769287
Epoch: 20, Steps: 126 Train Loss: 31.1500 (Forecasting Loss:0.2663 + XiCon Loss:3.0884 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2469
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.1756287
	speed: 0.0177s/iter; left time: 176.5453s
Epoch: 21 cost time: 2.1939287185668945
Epoch: 21, Steps: 126 Train Loss: 30.8068 (Forecasting Loss:0.2662 + XiCon Loss:3.0541 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2469
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16932548582553864, mae:0.3244456946849823, mape:0.6731983423233032, mspe:19.745805740356445 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1700+-0.00101, MAE:0.3249+-0.00094, MAPE:0.6769+-0.00433, MSPE:19.8957+-0.28085, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4078
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.1213722
	speed: 0.0203s/iter; left time: 249.0981s
Epoch: 1 cost time: 2.4399757385253906
Epoch: 1, Steps: 124 Train Loss: 30.5197 (Forecasting Loss:0.3421 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.3470 Test MSE Loss: 0.2934
Validation loss decreased (inf --> 0.347011).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.9375858
	speed: 0.0204s/iter; left time: 249.0038s
Epoch: 2 cost time: 2.5190398693084717
Epoch: 2, Steps: 124 Train Loss: 28.8721 (Forecasting Loss:0.3140 + XiCon Loss:2.8558 x Lambda(10.0)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2894
Validation loss decreased (0.347011 --> 0.340473).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.9341793
	speed: 0.0209s/iter; left time: 251.9780s
Epoch: 3 cost time: 2.575751543045044
Epoch: 3, Steps: 124 Train Loss: 28.9328 (Forecasting Loss:0.3038 + XiCon Loss:2.8629 x Lambda(10.0)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2765
Validation loss decreased (0.340473 --> 0.336110).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9455986
	speed: 0.0213s/iter; left time: 254.0920s
Epoch: 4 cost time: 2.5993950366973877
Epoch: 4, Steps: 124 Train Loss: 30.5560 (Forecasting Loss:0.2984 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.2766
Validation loss decreased (0.336110 --> 0.331762).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.3702545
	speed: 0.0213s/iter; left time: 251.9807s
Epoch: 5 cost time: 2.7737133502960205
Epoch: 5, Steps: 124 Train Loss: 31.1711 (Forecasting Loss:0.2944 + XiCon Loss:3.0877 x Lambda(10.0)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2748
Validation loss decreased (0.331762 --> 0.329115).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.3659172
	speed: 0.0212s/iter; left time: 248.1035s
Epoch: 6 cost time: 2.630260944366455
Epoch: 6, Steps: 124 Train Loss: 31.0212 (Forecasting Loss:0.2928 + XiCon Loss:3.0728 x Lambda(10.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2738
Validation loss decreased (0.329115 --> 0.328925).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7594852
	speed: 0.0215s/iter; left time: 248.7044s
Epoch: 7 cost time: 2.6382174491882324
Epoch: 7, Steps: 124 Train Loss: 31.0703 (Forecasting Loss:0.2920 + XiCon Loss:3.0778 x Lambda(10.0)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2740
Validation loss decreased (0.328925 --> 0.327237).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4025612
	speed: 0.0214s/iter; left time: 245.2370s
Epoch: 8 cost time: 2.6024270057678223
Epoch: 8, Steps: 124 Train Loss: 31.1507 (Forecasting Loss:0.2915 + XiCon Loss:3.0859 x Lambda(10.0)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2740
Validation loss decreased (0.327237 --> 0.327177).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.8943386
	speed: 0.0217s/iter; left time: 245.5748s
Epoch: 9 cost time: 2.6552088260650635
Epoch: 9, Steps: 124 Train Loss: 31.0929 (Forecasting Loss:0.2914 + XiCon Loss:3.0802 x Lambda(10.0)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2738
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.4419937
	speed: 0.0224s/iter; left time: 250.2346s
Epoch: 10 cost time: 2.7439146041870117
Epoch: 10, Steps: 124 Train Loss: 31.1179 (Forecasting Loss:0.2911 + XiCon Loss:3.0827 x Lambda(10.0)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.2735
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.0465813
	speed: 0.0219s/iter; left time: 241.9382s
Epoch: 11 cost time: 2.6631593704223633
Epoch: 11, Steps: 124 Train Loss: 31.1272 (Forecasting Loss:0.2909 + XiCon Loss:3.0836 x Lambda(10.0)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.2735
Validation loss decreased (0.327177 --> 0.326609).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4446545
	speed: 0.0216s/iter; left time: 235.7693s
Epoch: 12 cost time: 2.6445558071136475
Epoch: 12, Steps: 124 Train Loss: 31.1725 (Forecasting Loss:0.2912 + XiCon Loss:3.0881 x Lambda(10.0)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4584961
	speed: 0.0216s/iter; left time: 233.6208s
Epoch: 13 cost time: 2.6420586109161377
Epoch: 13, Steps: 124 Train Loss: 31.0071 (Forecasting Loss:0.2908 + XiCon Loss:3.0716 x Lambda(10.0)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.2735
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.3676395
	speed: 0.0217s/iter; left time: 231.8203s
Epoch: 14 cost time: 2.6538681983947754
Epoch: 14, Steps: 124 Train Loss: 31.1919 (Forecasting Loss:0.2909 + XiCon Loss:3.0901 x Lambda(10.0)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.2735
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.9670067
	speed: 0.0220s/iter; left time: 232.4775s
Epoch: 15 cost time: 2.723233461380005
Epoch: 15, Steps: 124 Train Loss: 31.1018 (Forecasting Loss:0.2907 + XiCon Loss:3.0811 x Lambda(10.0)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8046055
	speed: 0.0212s/iter; left time: 221.3686s
Epoch: 16 cost time: 2.6106114387512207
Epoch: 16, Steps: 124 Train Loss: 31.2877 (Forecasting Loss:0.2910 + XiCon Loss:3.0997 x Lambda(10.0)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2735
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.9605751
	speed: 0.0211s/iter; left time: 217.2733s
Epoch: 17 cost time: 2.6066720485687256
Epoch: 17, Steps: 124 Train Loss: 31.1296 (Forecasting Loss:0.2908 + XiCon Loss:3.0839 x Lambda(10.0)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.2735
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.2518406
	speed: 0.0222s/iter; left time: 225.8617s
Epoch: 18 cost time: 2.6831493377685547
Epoch: 18, Steps: 124 Train Loss: 31.1264 (Forecasting Loss:0.2910 + XiCon Loss:3.0835 x Lambda(10.0)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.2735
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5919075
	speed: 0.0215s/iter; left time: 216.8168s
Epoch: 19 cost time: 2.6685848236083984
Epoch: 19, Steps: 124 Train Loss: 31.1894 (Forecasting Loss:0.2907 + XiCon Loss:3.0899 x Lambda(10.0)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2735
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.1766911
	speed: 0.0223s/iter; left time: 221.2974s
Epoch: 20 cost time: 2.7121450901031494
Epoch: 20, Steps: 124 Train Loss: 31.3053 (Forecasting Loss:0.2909 + XiCon Loss:3.1014 x Lambda(10.0)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.2735
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.9445267
	speed: 0.0211s/iter; left time: 207.3276s
Epoch: 21 cost time: 2.574861764907837
Epoch: 21, Steps: 124 Train Loss: 31.3063 (Forecasting Loss:0.2910 + XiCon Loss:3.1015 x Lambda(10.0)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2735
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19294309616088867, mae:0.3541547358036041, mape:0.678798258304596, mspe:18.12026023864746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2813
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 29.9356689
	speed: 0.0170s/iter; left time: 208.8384s
Epoch: 1 cost time: 2.078749418258667
Epoch: 1, Steps: 124 Train Loss: 30.4496 (Forecasting Loss:0.3372 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.3429 Test MSE Loss: 0.2847
Validation loss decreased (inf --> 0.342933).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9457302
	speed: 0.0212s/iter; left time: 258.6839s
Epoch: 2 cost time: 2.602271556854248
Epoch: 2, Steps: 124 Train Loss: 29.2363 (Forecasting Loss:0.3144 + XiCon Loss:2.8922 x Lambda(10.0)), Vali MSE Loss: 0.3343 Test MSE Loss: 0.2842
Validation loss decreased (0.342933 --> 0.334334).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.9360657
	speed: 0.0205s/iter; left time: 247.1091s
Epoch: 3 cost time: 2.5026297569274902
Epoch: 3, Steps: 124 Train Loss: 30.5182 (Forecasting Loss:0.3020 + XiCon Loss:3.0216 x Lambda(10.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2736
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.4502506
	speed: 0.0213s/iter; left time: 254.0216s
Epoch: 4 cost time: 2.5828754901885986
Epoch: 4, Steps: 124 Train Loss: 31.2043 (Forecasting Loss:0.2962 + XiCon Loss:3.0908 x Lambda(10.0)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2743
Validation loss decreased (0.334334 --> 0.329161).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8046722
	speed: 0.0207s/iter; left time: 243.7799s
Epoch: 5 cost time: 2.568295955657959
Epoch: 5, Steps: 124 Train Loss: 31.2449 (Forecasting Loss:0.2918 + XiCon Loss:3.0953 x Lambda(10.0)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2701
Validation loss decreased (0.329161 --> 0.326175).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.5524654
	speed: 0.0213s/iter; left time: 248.7203s
Epoch: 6 cost time: 2.5958003997802734
Epoch: 6, Steps: 124 Train Loss: 31.2471 (Forecasting Loss:0.2900 + XiCon Loss:3.0957 x Lambda(10.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2749
Validation loss decreased (0.326175 --> 0.321131).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.5538750
	speed: 0.0216s/iter; left time: 250.2063s
Epoch: 7 cost time: 2.6306509971618652
Epoch: 7, Steps: 124 Train Loss: 31.3773 (Forecasting Loss:0.2893 + XiCon Loss:3.1088 x Lambda(10.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2734
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.9272823
	speed: 0.0210s/iter; left time: 239.9509s
Epoch: 8 cost time: 2.5926265716552734
Epoch: 8, Steps: 124 Train Loss: 31.4230 (Forecasting Loss:0.2888 + XiCon Loss:3.1134 x Lambda(10.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2731
Validation loss decreased (0.321131 --> 0.321022).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.6437225
	speed: 0.0222s/iter; left time: 250.7949s
Epoch: 9 cost time: 2.7146050930023193
Epoch: 9, Steps: 124 Train Loss: 31.4614 (Forecasting Loss:0.2887 + XiCon Loss:3.1173 x Lambda(10.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2728
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1785641
	speed: 0.0215s/iter; left time: 240.8147s
Epoch: 10 cost time: 2.606098175048828
Epoch: 10, Steps: 124 Train Loss: 31.3487 (Forecasting Loss:0.2886 + XiCon Loss:3.1060 x Lambda(10.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2728
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1248188
	speed: 0.0216s/iter; left time: 238.8570s
Epoch: 11 cost time: 2.6128299236297607
Epoch: 11, Steps: 124 Train Loss: 31.5563 (Forecasting Loss:0.2884 + XiCon Loss:3.1268 x Lambda(10.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2728
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.3477211
	speed: 0.0212s/iter; left time: 231.3561s
Epoch: 12 cost time: 2.5706422328948975
Epoch: 12, Steps: 124 Train Loss: 31.3775 (Forecasting Loss:0.2880 + XiCon Loss:3.1090 x Lambda(10.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2728
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.5961246
	speed: 0.0210s/iter; left time: 227.3192s
Epoch: 13 cost time: 2.5626678466796875
Epoch: 13, Steps: 124 Train Loss: 31.5988 (Forecasting Loss:0.2882 + XiCon Loss:3.1311 x Lambda(10.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2728
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 36.0773430
	speed: 0.0215s/iter; left time: 229.8665s
Epoch: 14 cost time: 2.642033338546753
Epoch: 14, Steps: 124 Train Loss: 31.4564 (Forecasting Loss:0.2883 + XiCon Loss:3.1168 x Lambda(10.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2728
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9654217
	speed: 0.0219s/iter; left time: 231.3972s
Epoch: 15 cost time: 2.670680522918701
Epoch: 15, Steps: 124 Train Loss: 31.3594 (Forecasting Loss:0.2884 + XiCon Loss:3.1071 x Lambda(10.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2728
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0321579
	speed: 0.0211s/iter; left time: 220.7775s
Epoch: 16 cost time: 2.597693920135498
Epoch: 16, Steps: 124 Train Loss: 31.3854 (Forecasting Loss:0.2883 + XiCon Loss:3.1097 x Lambda(10.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2728
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.2446709
	speed: 0.0214s/iter; left time: 221.1130s
Epoch: 17 cost time: 2.614655017852783
Epoch: 17, Steps: 124 Train Loss: 31.5681 (Forecasting Loss:0.2883 + XiCon Loss:3.1280 x Lambda(10.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2728
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8321285
	speed: 0.0219s/iter; left time: 223.7231s
Epoch: 18 cost time: 2.6614296436309814
Epoch: 18, Steps: 124 Train Loss: 31.5596 (Forecasting Loss:0.2883 + XiCon Loss:3.1271 x Lambda(10.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2728
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1924014389514923, mae:0.3538932502269745, mape:0.667573869228363, mspe:17.7850399017334 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3434
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.1379375
	speed: 0.0178s/iter; left time: 219.4725s
Epoch: 1 cost time: 2.197117805480957
Epoch: 1, Steps: 124 Train Loss: 30.5791 (Forecasting Loss:0.3378 + XiCon Loss:3.0241 x Lambda(10.0)), Vali MSE Loss: 0.3426 Test MSE Loss: 0.2839
Validation loss decreased (inf --> 0.342635).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4890499
	speed: 0.0212s/iter; left time: 258.4400s
Epoch: 2 cost time: 2.5974810123443604
Epoch: 2, Steps: 124 Train Loss: 28.8304 (Forecasting Loss:0.3164 + XiCon Loss:2.8514 x Lambda(10.0)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2968
Validation loss decreased (0.342635 --> 0.340493).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3512135
	speed: 0.0215s/iter; left time: 259.3565s
Epoch: 3 cost time: 2.623129367828369
Epoch: 3, Steps: 124 Train Loss: 28.9146 (Forecasting Loss:0.3025 + XiCon Loss:2.8612 x Lambda(10.0)), Vali MSE Loss: 0.3323 Test MSE Loss: 0.2776
Validation loss decreased (0.340493 --> 0.332342).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.3183537
	speed: 0.0212s/iter; left time: 252.7356s
Epoch: 4 cost time: 2.6241841316223145
Epoch: 4, Steps: 124 Train Loss: 30.0963 (Forecasting Loss:0.2963 + XiCon Loss:2.9800 x Lambda(10.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2773
Validation loss decreased (0.332342 --> 0.323177).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.7778244
	speed: 0.0222s/iter; left time: 261.5962s
Epoch: 5 cost time: 2.729870319366455
Epoch: 5, Steps: 124 Train Loss: 30.5221 (Forecasting Loss:0.2930 + XiCon Loss:3.0229 x Lambda(10.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2795
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1758862
	speed: 0.0215s/iter; left time: 250.8196s
Epoch: 6 cost time: 2.634436845779419
Epoch: 6, Steps: 124 Train Loss: 30.4630 (Forecasting Loss:0.2912 + XiCon Loss:3.0172 x Lambda(10.0)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.2733
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1214275
	speed: 0.0215s/iter; left time: 248.7236s
Epoch: 7 cost time: 2.638164758682251
Epoch: 7, Steps: 124 Train Loss: 30.5391 (Forecasting Loss:0.2901 + XiCon Loss:3.0249 x Lambda(10.0)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.2762
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9367714
	speed: 0.0217s/iter; left time: 247.8508s
Epoch: 8 cost time: 2.6432719230651855
Epoch: 8, Steps: 124 Train Loss: 30.5091 (Forecasting Loss:0.2894 + XiCon Loss:3.0220 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2757
Validation loss decreased (0.323177 --> 0.323083).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0374527
	speed: 0.0218s/iter; left time: 246.1700s
Epoch: 9 cost time: 2.6872081756591797
Epoch: 9, Steps: 124 Train Loss: 30.3252 (Forecasting Loss:0.2893 + XiCon Loss:3.0036 x Lambda(10.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2750
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.1448421
	speed: 0.0218s/iter; left time: 243.4775s
Epoch: 10 cost time: 2.6801252365112305
Epoch: 10, Steps: 124 Train Loss: 30.3765 (Forecasting Loss:0.2892 + XiCon Loss:3.0087 x Lambda(10.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2751
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.9961128
	speed: 0.0210s/iter; left time: 231.8698s
Epoch: 11 cost time: 2.5688812732696533
Epoch: 11, Steps: 124 Train Loss: 30.3904 (Forecasting Loss:0.2890 + XiCon Loss:3.0101 x Lambda(10.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2752
Validation loss decreased (0.323083 --> 0.322803).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1385155
	speed: 0.0218s/iter; left time: 238.6425s
Epoch: 12 cost time: 2.6442296504974365
Epoch: 12, Steps: 124 Train Loss: 30.4554 (Forecasting Loss:0.2886 + XiCon Loss:3.0167 x Lambda(10.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2752
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0153408
	speed: 0.0210s/iter; left time: 227.5005s
Epoch: 13 cost time: 2.5808348655700684
Epoch: 13, Steps: 124 Train Loss: 30.5359 (Forecasting Loss:0.2886 + XiCon Loss:3.0247 x Lambda(10.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2752
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1023235
	speed: 0.0214s/iter; left time: 229.0938s
Epoch: 14 cost time: 2.622729539871216
Epoch: 14, Steps: 124 Train Loss: 30.4736 (Forecasting Loss:0.2887 + XiCon Loss:3.0185 x Lambda(10.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2752
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.6322441
	speed: 0.0227s/iter; left time: 239.4519s
Epoch: 15 cost time: 2.7713255882263184
Epoch: 15, Steps: 124 Train Loss: 30.4556 (Forecasting Loss:0.2889 + XiCon Loss:3.0167 x Lambda(10.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2752
Validation loss decreased (0.322803 --> 0.322622).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.4059563
	speed: 0.0213s/iter; left time: 222.5523s
Epoch: 16 cost time: 2.6216230392456055
Epoch: 16, Steps: 124 Train Loss: 30.5226 (Forecasting Loss:0.2888 + XiCon Loss:3.0234 x Lambda(10.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2752
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.0169411
	speed: 0.0216s/iter; left time: 222.8840s
Epoch: 17 cost time: 2.660513162612915
Epoch: 17, Steps: 124 Train Loss: 30.5182 (Forecasting Loss:0.2889 + XiCon Loss:3.0229 x Lambda(10.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2752
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6750202
	speed: 0.0212s/iter; left time: 215.6834s
Epoch: 18 cost time: 2.6051204204559326
Epoch: 18, Steps: 124 Train Loss: 30.5660 (Forecasting Loss:0.2889 + XiCon Loss:3.0277 x Lambda(10.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2752
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.6215248
	speed: 0.0217s/iter; left time: 218.3162s
Epoch: 19 cost time: 2.631152629852295
Epoch: 19, Steps: 124 Train Loss: 30.4808 (Forecasting Loss:0.2891 + XiCon Loss:3.0192 x Lambda(10.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2752
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3199005
	speed: 0.0219s/iter; left time: 217.5883s
Epoch: 20 cost time: 2.6800811290740967
Epoch: 20, Steps: 124 Train Loss: 30.4504 (Forecasting Loss:0.2889 + XiCon Loss:3.0162 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2752
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.9462395
	speed: 0.0221s/iter; left time: 217.0409s
Epoch: 21 cost time: 2.6672706604003906
Epoch: 21, Steps: 124 Train Loss: 30.3871 (Forecasting Loss:0.2888 + XiCon Loss:3.0098 x Lambda(10.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2752
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.2680759
	speed: 0.0216s/iter; left time: 209.1027s
Epoch: 22 cost time: 2.6557159423828125
Epoch: 22, Steps: 124 Train Loss: 30.5801 (Forecasting Loss:0.2892 + XiCon Loss:3.0291 x Lambda(10.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2752
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.2102852
	speed: 0.0214s/iter; left time: 205.0756s
Epoch: 23 cost time: 2.6586568355560303
Epoch: 23, Steps: 124 Train Loss: 30.5257 (Forecasting Loss:0.2891 + XiCon Loss:3.0237 x Lambda(10.0)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2752
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.2379742
	speed: 0.0218s/iter; left time: 205.5953s
Epoch: 24 cost time: 2.639571189880371
Epoch: 24, Steps: 124 Train Loss: 30.4519 (Forecasting Loss:0.2888 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.2752
Validation loss decreased (0.322622 --> 0.322487).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.1704845
	speed: 0.0220s/iter; left time: 204.7036s
Epoch: 25 cost time: 2.6804428100585938
Epoch: 25, Steps: 124 Train Loss: 30.4636 (Forecasting Loss:0.2893 + XiCon Loss:3.0174 x Lambda(10.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2752
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.1976852
	speed: 0.0222s/iter; left time: 204.1293s
Epoch: 26 cost time: 2.824054002761841
Epoch: 26, Steps: 124 Train Loss: 30.4545 (Forecasting Loss:0.2890 + XiCon Loss:3.0166 x Lambda(10.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2752
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 28.8654747
	speed: 0.0222s/iter; left time: 201.9074s
Epoch: 27 cost time: 2.7836575508117676
Epoch: 27, Steps: 124 Train Loss: 30.5209 (Forecasting Loss:0.2890 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2752
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 32.1268692
	speed: 0.0217s/iter; left time: 194.4350s
Epoch: 28 cost time: 2.6527090072631836
Epoch: 28, Steps: 124 Train Loss: 30.4322 (Forecasting Loss:0.2891 + XiCon Loss:3.0143 x Lambda(10.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2752
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.4685860
	speed: 0.0219s/iter; left time: 193.7266s
Epoch: 29 cost time: 2.6659469604492188
Epoch: 29, Steps: 124 Train Loss: 30.3864 (Forecasting Loss:0.2884 + XiCon Loss:3.0098 x Lambda(10.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2752
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 29.9014263
	speed: 0.0232s/iter; left time: 201.6155s
Epoch: 30 cost time: 2.810081958770752
Epoch: 30, Steps: 124 Train Loss: 30.4160 (Forecasting Loss:0.2889 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.3230 Test MSE Loss: 0.2752
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.4102688
	speed: 0.0222s/iter; left time: 190.8531s
Epoch: 31 cost time: 2.7221503257751465
Epoch: 31, Steps: 124 Train Loss: 30.4937 (Forecasting Loss:0.2887 + XiCon Loss:3.0205 x Lambda(10.0)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2752
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 29.1144810
	speed: 0.0225s/iter; left time: 189.9168s
Epoch: 32 cost time: 2.762470245361328
Epoch: 32, Steps: 124 Train Loss: 30.5610 (Forecasting Loss:0.2891 + XiCon Loss:3.0272 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2752
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 29.4460678
	speed: 0.0233s/iter; left time: 194.2577s
Epoch: 33 cost time: 2.8378262519836426
Epoch: 33, Steps: 124 Train Loss: 30.4559 (Forecasting Loss:0.2890 + XiCon Loss:3.0167 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2752
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 31.4152145
	speed: 0.0222s/iter; left time: 181.9590s
Epoch: 34 cost time: 2.7185347080230713
Epoch: 34, Steps: 124 Train Loss: 30.4256 (Forecasting Loss:0.2888 + XiCon Loss:3.0137 x Lambda(10.0)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2752
Validation loss decreased (0.322487 --> 0.322449).  Saving model ...
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 29.5437260
	speed: 0.0227s/iter; left time: 183.7040s
Epoch: 35 cost time: 2.7972776889801025
Epoch: 35, Steps: 124 Train Loss: 30.5001 (Forecasting Loss:0.2889 + XiCon Loss:3.0211 x Lambda(10.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2752
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 30.2778339
	speed: 0.0222s/iter; left time: 177.1271s
Epoch: 36 cost time: 2.7753312587738037
Epoch: 36, Steps: 124 Train Loss: 30.4785 (Forecasting Loss:0.2889 + XiCon Loss:3.0190 x Lambda(10.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2752
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 30.5070267
	speed: 0.0214s/iter; left time: 167.6174s
Epoch: 37 cost time: 2.652705669403076
Epoch: 37, Steps: 124 Train Loss: 30.4389 (Forecasting Loss:0.2888 + XiCon Loss:3.0150 x Lambda(10.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2752
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 30.7487717
	speed: 0.0225s/iter; left time: 173.8111s
Epoch: 38 cost time: 2.752855062484741
Epoch: 38, Steps: 124 Train Loss: 30.4138 (Forecasting Loss:0.2887 + XiCon Loss:3.0125 x Lambda(10.0)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.2752
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 30.4557285
	speed: 0.0220s/iter; left time: 167.1049s
Epoch: 39 cost time: 2.7314870357513428
Epoch: 39, Steps: 124 Train Loss: 30.3849 (Forecasting Loss:0.2889 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2752
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 29.3048782
	speed: 0.0226s/iter; left time: 168.5535s
Epoch: 40 cost time: 2.780773162841797
Epoch: 40, Steps: 124 Train Loss: 30.4945 (Forecasting Loss:0.2888 + XiCon Loss:3.0206 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2752
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 30.3555813
	speed: 0.0215s/iter; left time: 157.9624s
Epoch: 41 cost time: 2.658698797225952
Epoch: 41, Steps: 124 Train Loss: 30.3734 (Forecasting Loss:0.2887 + XiCon Loss:3.0085 x Lambda(10.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2752
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.547473508864641e-15
	iters: 100, epoch: 42 | loss: 30.6604633
	speed: 0.0220s/iter; left time: 158.5224s
Epoch: 42 cost time: 2.6956920623779297
Epoch: 42, Steps: 124 Train Loss: 30.4321 (Forecasting Loss:0.2886 + XiCon Loss:3.0144 x Lambda(10.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2752
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.2737367544323206e-15
	iters: 100, epoch: 43 | loss: 30.0916862
	speed: 0.0222s/iter; left time: 157.1541s
Epoch: 43 cost time: 2.7461400032043457
Epoch: 43, Steps: 124 Train Loss: 30.5577 (Forecasting Loss:0.2889 + XiCon Loss:3.0269 x Lambda(10.0)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.2752
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1368683772161603e-15
	iters: 100, epoch: 44 | loss: 31.1083050
	speed: 0.0227s/iter; left time: 158.1324s
Epoch: 44 cost time: 2.77956223487854
Epoch: 44, Steps: 124 Train Loss: 30.3959 (Forecasting Loss:0.2891 + XiCon Loss:3.0107 x Lambda(10.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2752
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19462119042873383, mae:0.3558718264102936, mape:0.6761419177055359, mspe:17.925872802734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3687
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.2213383
	speed: 0.0190s/iter; left time: 233.4948s
Epoch: 1 cost time: 2.34855055809021
Epoch: 1, Steps: 124 Train Loss: 30.5505 (Forecasting Loss:0.3383 + XiCon Loss:3.0212 x Lambda(10.0)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.2841
Validation loss decreased (inf --> 0.340449).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.2815037
	speed: 0.0222s/iter; left time: 270.6632s
Epoch: 2 cost time: 2.7260146141052246
Epoch: 2, Steps: 124 Train Loss: 28.7550 (Forecasting Loss:0.3151 + XiCon Loss:2.8440 x Lambda(10.0)), Vali MSE Loss: 0.3341 Test MSE Loss: 0.2902
Validation loss decreased (0.340449 --> 0.334079).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.9031162
	speed: 0.0223s/iter; left time: 268.2719s
Epoch: 3 cost time: 2.7371466159820557
Epoch: 3, Steps: 124 Train Loss: 28.7717 (Forecasting Loss:0.3015 + XiCon Loss:2.8470 x Lambda(10.0)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.2772
Validation loss decreased (0.334079 --> 0.333004).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7081757
	speed: 0.0213s/iter; left time: 253.6429s
Epoch: 4 cost time: 2.622394323348999
Epoch: 4, Steps: 124 Train Loss: 29.1980 (Forecasting Loss:0.2965 + XiCon Loss:2.8901 x Lambda(10.0)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2819
Validation loss decreased (0.333004 --> 0.326187).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4956894
	speed: 0.0229s/iter; left time: 270.0168s
Epoch: 5 cost time: 2.786975383758545
Epoch: 5, Steps: 124 Train Loss: 29.6524 (Forecasting Loss:0.2920 + XiCon Loss:2.9360 x Lambda(10.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2724
Validation loss decreased (0.326187 --> 0.322643).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6634789
	speed: 0.0216s/iter; left time: 252.7235s
Epoch: 6 cost time: 2.6638545989990234
Epoch: 6, Steps: 124 Train Loss: 30.0001 (Forecasting Loss:0.2891 + XiCon Loss:2.9711 x Lambda(10.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2714
Validation loss decreased (0.322643 --> 0.320439).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8909264
	speed: 0.0215s/iter; left time: 248.8935s
Epoch: 7 cost time: 2.64143443107605
Epoch: 7, Steps: 124 Train Loss: 30.0105 (Forecasting Loss:0.2880 + XiCon Loss:2.9723 x Lambda(10.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2735
Validation loss decreased (0.320439 --> 0.320372).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.8542862
	speed: 0.0215s/iter; left time: 245.7713s
Epoch: 8 cost time: 2.6525423526763916
Epoch: 8, Steps: 124 Train Loss: 30.1648 (Forecasting Loss:0.2870 + XiCon Loss:2.9878 x Lambda(10.0)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2722
Validation loss decreased (0.320372 --> 0.319814).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1911182
	speed: 0.0224s/iter; left time: 252.9201s
Epoch: 9 cost time: 2.7210888862609863
Epoch: 9, Steps: 124 Train Loss: 30.2896 (Forecasting Loss:0.2864 + XiCon Loss:3.0003 x Lambda(10.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2723
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1417522
	speed: 0.0232s/iter; left time: 258.9925s
Epoch: 10 cost time: 2.8263773918151855
Epoch: 10, Steps: 124 Train Loss: 30.2359 (Forecasting Loss:0.2866 + XiCon Loss:2.9949 x Lambda(10.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2722
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5944138
	speed: 0.0223s/iter; left time: 246.4852s
Epoch: 11 cost time: 2.747222661972046
Epoch: 11, Steps: 124 Train Loss: 30.2266 (Forecasting Loss:0.2866 + XiCon Loss:2.9940 x Lambda(10.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2723
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7982178
	speed: 0.0217s/iter; left time: 237.5991s
Epoch: 12 cost time: 2.652794122695923
Epoch: 12, Steps: 124 Train Loss: 30.3291 (Forecasting Loss:0.2862 + XiCon Loss:3.0043 x Lambda(10.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2723
Validation loss decreased (0.319814 --> 0.319732).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.4422646
	speed: 0.0221s/iter; left time: 238.6324s
Epoch: 13 cost time: 2.724266767501831
Epoch: 13, Steps: 124 Train Loss: 30.2442 (Forecasting Loss:0.2862 + XiCon Loss:2.9958 x Lambda(10.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2723
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8934841
	speed: 0.0215s/iter; left time: 230.1924s
Epoch: 14 cost time: 2.6478078365325928
Epoch: 14, Steps: 124 Train Loss: 30.3259 (Forecasting Loss:0.2862 + XiCon Loss:3.0040 x Lambda(10.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2723
Validation loss decreased (0.319732 --> 0.319256).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.0139675
	speed: 0.0231s/iter; left time: 244.4058s
Epoch: 15 cost time: 2.787952184677124
Epoch: 15, Steps: 124 Train Loss: 30.2691 (Forecasting Loss:0.2863 + XiCon Loss:2.9983 x Lambda(10.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2723
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8638134
	speed: 0.0219s/iter; left time: 229.1076s
Epoch: 16 cost time: 2.714188575744629
Epoch: 16, Steps: 124 Train Loss: 30.3501 (Forecasting Loss:0.2864 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2723
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.0991096
	speed: 0.0219s/iter; left time: 226.4402s
Epoch: 17 cost time: 2.76051664352417
Epoch: 17, Steps: 124 Train Loss: 30.2767 (Forecasting Loss:0.2865 + XiCon Loss:2.9990 x Lambda(10.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2723
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3057766
	speed: 0.0215s/iter; left time: 218.7713s
Epoch: 18 cost time: 2.644434690475464
Epoch: 18, Steps: 124 Train Loss: 30.2624 (Forecasting Loss:0.2863 + XiCon Loss:2.9976 x Lambda(10.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2723
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.9362106
	speed: 0.0220s/iter; left time: 221.8487s
Epoch: 19 cost time: 2.6799943447113037
Epoch: 19, Steps: 124 Train Loss: 30.1724 (Forecasting Loss:0.2862 + XiCon Loss:2.9886 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2723
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.9451942
	speed: 0.0230s/iter; left time: 228.8990s
Epoch: 20 cost time: 2.806642770767212
Epoch: 20, Steps: 124 Train Loss: 30.2482 (Forecasting Loss:0.2862 + XiCon Loss:2.9962 x Lambda(10.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2723
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5667725
	speed: 0.0218s/iter; left time: 214.1489s
Epoch: 21 cost time: 2.6878366470336914
Epoch: 21, Steps: 124 Train Loss: 30.2973 (Forecasting Loss:0.2860 + XiCon Loss:3.0011 x Lambda(10.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2723
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.4734039
	speed: 0.0221s/iter; left time: 214.7648s
Epoch: 22 cost time: 2.7073373794555664
Epoch: 22, Steps: 124 Train Loss: 30.2109 (Forecasting Loss:0.2862 + XiCon Loss:2.9925 x Lambda(10.0)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2723
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.1944695
	speed: 0.0219s/iter; left time: 209.4937s
Epoch: 23 cost time: 2.67423677444458
Epoch: 23, Steps: 124 Train Loss: 30.2985 (Forecasting Loss:0.2863 + XiCon Loss:3.0012 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2723
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 28.6941814
	speed: 0.0220s/iter; left time: 207.9022s
Epoch: 24 cost time: 2.6729280948638916
Epoch: 24, Steps: 124 Train Loss: 30.2837 (Forecasting Loss:0.2862 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2723
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1915157288312912, mae:0.3530305027961731, mape:0.6698430776596069, mspe:17.817583084106445 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4492
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.1153412
	speed: 0.0187s/iter; left time: 229.9047s
Epoch: 1 cost time: 2.259005308151245
Epoch: 1, Steps: 124 Train Loss: 30.1611 (Forecasting Loss:0.3346 + XiCon Loss:2.9827 x Lambda(10.0)), Vali MSE Loss: 0.3411 Test MSE Loss: 0.2823
Validation loss decreased (inf --> 0.341148).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4168453
	speed: 0.0219s/iter; left time: 266.5272s
Epoch: 2 cost time: 2.7027902603149414
Epoch: 2, Steps: 124 Train Loss: 29.3561 (Forecasting Loss:0.3148 + XiCon Loss:2.9041 x Lambda(10.0)), Vali MSE Loss: 0.3495 Test MSE Loss: 0.2924
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0768318
	speed: 0.0223s/iter; left time: 268.4720s
Epoch: 3 cost time: 2.7269484996795654
Epoch: 3, Steps: 124 Train Loss: 30.0127 (Forecasting Loss:0.3025 + XiCon Loss:2.9710 x Lambda(10.0)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2808
Validation loss decreased (0.341148 --> 0.326984).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.0600243
	speed: 0.0220s/iter; left time: 262.7633s
Epoch: 4 cost time: 2.7110719680786133
Epoch: 4, Steps: 124 Train Loss: 29.7430 (Forecasting Loss:0.2948 + XiCon Loss:2.9448 x Lambda(10.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2715
Validation loss decreased (0.326984 --> 0.321984).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3940048
	speed: 0.0227s/iter; left time: 267.9712s
Epoch: 5 cost time: 2.799579381942749
Epoch: 5, Steps: 124 Train Loss: 29.8976 (Forecasting Loss:0.2911 + XiCon Loss:2.9606 x Lambda(10.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2670
Validation loss decreased (0.321984 --> 0.321506).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.9478645
	speed: 0.0215s/iter; left time: 250.7382s
Epoch: 6 cost time: 2.629699468612671
Epoch: 6, Steps: 124 Train Loss: 29.7354 (Forecasting Loss:0.2889 + XiCon Loss:2.9447 x Lambda(10.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2674
Validation loss decreased (0.321506 --> 0.320522).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9621830
	speed: 0.0219s/iter; left time: 253.3965s
Epoch: 7 cost time: 2.7154483795166016
Epoch: 7, Steps: 124 Train Loss: 29.7207 (Forecasting Loss:0.2878 + XiCon Loss:2.9433 x Lambda(10.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2655
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7755718
	speed: 0.0223s/iter; left time: 254.9582s
Epoch: 8 cost time: 2.7114429473876953
Epoch: 8, Steps: 124 Train Loss: 29.7566 (Forecasting Loss:0.2871 + XiCon Loss:2.9469 x Lambda(10.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2663
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.0813293
	speed: 0.0214s/iter; left time: 241.5864s
Epoch: 9 cost time: 2.6157145500183105
Epoch: 9, Steps: 124 Train Loss: 29.6970 (Forecasting Loss:0.2869 + XiCon Loss:2.9410 x Lambda(10.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2659
Validation loss decreased (0.320522 --> 0.320445).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.6330051
	speed: 0.0224s/iter; left time: 250.0028s
Epoch: 10 cost time: 2.8022258281707764
Epoch: 10, Steps: 124 Train Loss: 29.6450 (Forecasting Loss:0.2866 + XiCon Loss:2.9358 x Lambda(10.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2656
Validation loss decreased (0.320445 --> 0.320082).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8734856
	speed: 0.0211s/iter; left time: 232.9055s
Epoch: 11 cost time: 2.593331813812256
Epoch: 11, Steps: 124 Train Loss: 29.7344 (Forecasting Loss:0.2866 + XiCon Loss:2.9448 x Lambda(10.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2657
Validation loss decreased (0.320082 --> 0.319922).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6895161
	speed: 0.0215s/iter; left time: 235.2505s
Epoch: 12 cost time: 2.6507530212402344
Epoch: 12, Steps: 124 Train Loss: 29.7194 (Forecasting Loss:0.2864 + XiCon Loss:2.9433 x Lambda(10.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2657
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3852711
	speed: 0.0221s/iter; left time: 238.5669s
Epoch: 13 cost time: 2.698258399963379
Epoch: 13, Steps: 124 Train Loss: 29.7705 (Forecasting Loss:0.2866 + XiCon Loss:2.9484 x Lambda(10.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.3657589
	speed: 0.0216s/iter; left time: 230.6064s
Epoch: 14 cost time: 2.651881217956543
Epoch: 14, Steps: 124 Train Loss: 29.6166 (Forecasting Loss:0.2865 + XiCon Loss:2.9330 x Lambda(10.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2657
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9440575
	speed: 0.0216s/iter; left time: 227.9806s
Epoch: 15 cost time: 2.671003818511963
Epoch: 15, Steps: 124 Train Loss: 29.6529 (Forecasting Loss:0.2864 + XiCon Loss:2.9366 x Lambda(10.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0267105
	speed: 0.0222s/iter; left time: 231.2915s
Epoch: 16 cost time: 2.730058431625366
Epoch: 16, Steps: 124 Train Loss: 29.6675 (Forecasting Loss:0.2863 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.2323494
	speed: 0.0216s/iter; left time: 222.7731s
Epoch: 17 cost time: 2.6578657627105713
Epoch: 17, Steps: 124 Train Loss: 29.6565 (Forecasting Loss:0.2863 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2657
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.1638699
	speed: 0.0212s/iter; left time: 216.4808s
Epoch: 18 cost time: 2.6357598304748535
Epoch: 18, Steps: 124 Train Loss: 29.6134 (Forecasting Loss:0.2865 + XiCon Loss:2.9327 x Lambda(10.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2657
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.0891171
	speed: 0.0226s/iter; left time: 227.8961s
Epoch: 19 cost time: 2.7500791549682617
Epoch: 19, Steps: 124 Train Loss: 29.8306 (Forecasting Loss:0.2865 + XiCon Loss:2.9544 x Lambda(10.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2657
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.4616928
	speed: 0.0231s/iter; left time: 229.8304s
Epoch: 20 cost time: 2.802365779876709
Epoch: 20, Steps: 124 Train Loss: 29.6620 (Forecasting Loss:0.2865 + XiCon Loss:2.9375 x Lambda(10.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2657
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.7789669
	speed: 0.0219s/iter; left time: 215.4917s
Epoch: 21 cost time: 2.6655800342559814
Epoch: 21, Steps: 124 Train Loss: 29.6334 (Forecasting Loss:0.2865 + XiCon Loss:2.9347 x Lambda(10.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18416090309619904, mae:0.3471575379371643, mape:0.6649760007858276, mspe:17.569744110107422 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1911+-0.00504, MAE:0.3528+-0.00413, MAPE:0.6715+-0.00723, MSPE:17.8437+-0.25020, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4032
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.9605961
	speed: 0.0218s/iter; left time: 255.0217s
Epoch: 1 cost time: 2.468200922012329
Epoch: 1, Steps: 118 Train Loss: 31.9428 (Forecasting Loss:0.4748 + XiCon Loss:3.1468 x Lambda(10.0)), Vali MSE Loss: 0.4881 Test MSE Loss: 0.3773
Validation loss decreased (inf --> 0.488087).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 30.5122166
	speed: 0.0190s/iter; left time: 219.7196s
Epoch: 2 cost time: 2.2232439517974854
Epoch: 2, Steps: 118 Train Loss: 30.9137 (Forecasting Loss:0.3802 + XiCon Loss:3.0534 x Lambda(10.0)), Vali MSE Loss: 0.4057 Test MSE Loss: 0.2888
Validation loss decreased (0.488087 --> 0.405667).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.8619423
	speed: 0.0204s/iter; left time: 233.9209s
Epoch: 3 cost time: 2.3839473724365234
Epoch: 3, Steps: 118 Train Loss: 29.9814 (Forecasting Loss:0.3651 + XiCon Loss:2.9616 x Lambda(10.0)), Vali MSE Loss: 0.3941 Test MSE Loss: 0.2836
Validation loss decreased (0.405667 --> 0.394082).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.5804958
	speed: 0.0193s/iter; left time: 219.5552s
Epoch: 4 cost time: 2.2628297805786133
Epoch: 4, Steps: 118 Train Loss: 29.7853 (Forecasting Loss:0.3617 + XiCon Loss:2.9424 x Lambda(10.0)), Vali MSE Loss: 0.4143 Test MSE Loss: 0.3084
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.7164936
	speed: 0.0178s/iter; left time: 199.6029s
Epoch: 5 cost time: 2.1043787002563477
Epoch: 5, Steps: 118 Train Loss: 29.6974 (Forecasting Loss:0.3591 + XiCon Loss:2.9338 x Lambda(10.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 0.3006
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.5933609
	speed: 0.0185s/iter; left time: 205.2539s
Epoch: 6 cost time: 2.1643519401550293
Epoch: 6, Steps: 118 Train Loss: 29.6921 (Forecasting Loss:0.3580 + XiCon Loss:2.9334 x Lambda(10.0)), Vali MSE Loss: 0.4077 Test MSE Loss: 0.2998
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.6887665
	speed: 0.0190s/iter; left time: 208.6827s
Epoch: 7 cost time: 2.204704999923706
Epoch: 7, Steps: 118 Train Loss: 29.6622 (Forecasting Loss:0.3575 + XiCon Loss:2.9305 x Lambda(10.0)), Vali MSE Loss: 0.4037 Test MSE Loss: 0.2935
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.6244850
	speed: 0.0185s/iter; left time: 200.7203s
Epoch: 8 cost time: 2.181702136993408
Epoch: 8, Steps: 118 Train Loss: 29.6695 (Forecasting Loss:0.3574 + XiCon Loss:2.9312 x Lambda(10.0)), Vali MSE Loss: 0.4042 Test MSE Loss: 0.2952
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.6321564
	speed: 0.0211s/iter; left time: 227.0714s
Epoch: 9 cost time: 2.4438838958740234
Epoch: 9, Steps: 118 Train Loss: 29.6709 (Forecasting Loss:0.3571 + XiCon Loss:2.9314 x Lambda(10.0)), Vali MSE Loss: 0.4036 Test MSE Loss: 0.2943
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.6331692
	speed: 0.0188s/iter; left time: 199.5292s
Epoch: 10 cost time: 2.201810121536255
Epoch: 10, Steps: 118 Train Loss: 29.6653 (Forecasting Loss:0.3569 + XiCon Loss:2.9308 x Lambda(10.0)), Vali MSE Loss: 0.4055 Test MSE Loss: 0.2949
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.6596832
	speed: 0.0183s/iter; left time: 192.1307s
Epoch: 11 cost time: 2.128528594970703
Epoch: 11, Steps: 118 Train Loss: 29.6677 (Forecasting Loss:0.3569 + XiCon Loss:2.9311 x Lambda(10.0)), Vali MSE Loss: 0.4039 Test MSE Loss: 0.2949
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.5576897
	speed: 0.0184s/iter; left time: 190.9317s
Epoch: 12 cost time: 2.1457037925720215
Epoch: 12, Steps: 118 Train Loss: 29.6737 (Forecasting Loss:0.3568 + XiCon Loss:2.9317 x Lambda(10.0)), Vali MSE Loss: 0.4051 Test MSE Loss: 0.2950
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.6838741
	speed: 0.0179s/iter; left time: 184.1822s
Epoch: 13 cost time: 2.1022369861602783
Epoch: 13, Steps: 118 Train Loss: 29.6557 (Forecasting Loss:0.3566 + XiCon Loss:2.9299 x Lambda(10.0)), Vali MSE Loss: 0.4040 Test MSE Loss: 0.2950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20340387523174286, mae:0.36387693881988525, mape:0.6263436675071716, mspe:15.37903118133545 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3390
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.8804893
	speed: 0.0195s/iter; left time: 228.2549s
Epoch: 1 cost time: 2.31610107421875
Epoch: 1, Steps: 118 Train Loss: 32.0080 (Forecasting Loss:0.4688 + XiCon Loss:3.1539 x Lambda(10.0)), Vali MSE Loss: 0.4909 Test MSE Loss: 0.3790
Validation loss decreased (inf --> 0.490864).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 30.1648464
	speed: 0.0186s/iter; left time: 215.3569s
Epoch: 2 cost time: 2.177494525909424
Epoch: 2, Steps: 118 Train Loss: 30.8442 (Forecasting Loss:0.3790 + XiCon Loss:3.0465 x Lambda(10.0)), Vali MSE Loss: 0.4236 Test MSE Loss: 0.3145
Validation loss decreased (0.490864 --> 0.423643).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.7658672
	speed: 0.0193s/iter; left time: 221.6538s
Epoch: 3 cost time: 2.2629950046539307
Epoch: 3, Steps: 118 Train Loss: 29.8844 (Forecasting Loss:0.3567 + XiCon Loss:2.9528 x Lambda(10.0)), Vali MSE Loss: 0.4226 Test MSE Loss: 0.3088
Validation loss decreased (0.423643 --> 0.422634).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.4543724
	speed: 0.0183s/iter; left time: 207.4456s
Epoch: 4 cost time: 2.15274977684021
Epoch: 4, Steps: 118 Train Loss: 29.6320 (Forecasting Loss:0.3513 + XiCon Loss:2.9281 x Lambda(10.0)), Vali MSE Loss: 0.4170 Test MSE Loss: 0.2965
Validation loss decreased (0.422634 --> 0.416989).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.4497356
	speed: 0.0185s/iter; left time: 208.0040s
Epoch: 5 cost time: 2.1926331520080566
Epoch: 5, Steps: 118 Train Loss: 29.6040 (Forecasting Loss:0.3482 + XiCon Loss:2.9256 x Lambda(10.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.2935
Validation loss decreased (0.416989 --> 0.415063).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.5565948
	speed: 0.0185s/iter; left time: 205.7335s
Epoch: 6 cost time: 2.2100062370300293
Epoch: 6, Steps: 118 Train Loss: 29.6023 (Forecasting Loss:0.3476 + XiCon Loss:2.9255 x Lambda(10.0)), Vali MSE Loss: 0.4124 Test MSE Loss: 0.2897
Validation loss decreased (0.415063 --> 0.412387).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.2998905
	speed: 0.0194s/iter; left time: 213.5194s
Epoch: 7 cost time: 2.3155999183654785
Epoch: 7, Steps: 118 Train Loss: 29.5911 (Forecasting Loss:0.3475 + XiCon Loss:2.9244 x Lambda(10.0)), Vali MSE Loss: 0.4122 Test MSE Loss: 0.2897
Validation loss decreased (0.412387 --> 0.412218).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.5842934
	speed: 0.0188s/iter; left time: 204.0373s
Epoch: 8 cost time: 2.191849946975708
Epoch: 8, Steps: 118 Train Loss: 29.5758 (Forecasting Loss:0.3480 + XiCon Loss:2.9228 x Lambda(10.0)), Vali MSE Loss: 0.4128 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.5088253
	speed: 0.0185s/iter; left time: 199.5095s
Epoch: 9 cost time: 2.1694324016571045
Epoch: 9, Steps: 118 Train Loss: 29.6014 (Forecasting Loss:0.3481 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4129 Test MSE Loss: 0.2907
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.3461590
	speed: 0.0190s/iter; left time: 202.0181s
Epoch: 10 cost time: 2.254789113998413
Epoch: 10, Steps: 118 Train Loss: 29.6051 (Forecasting Loss:0.3486 + XiCon Loss:2.9257 x Lambda(10.0)), Vali MSE Loss: 0.4129 Test MSE Loss: 0.2904
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.4440975
	speed: 0.0189s/iter; left time: 198.6232s
Epoch: 11 cost time: 2.1961679458618164
Epoch: 11, Steps: 118 Train Loss: 29.5983 (Forecasting Loss:0.3484 + XiCon Loss:2.9250 x Lambda(10.0)), Vali MSE Loss: 0.4124 Test MSE Loss: 0.2903
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.5413704
	speed: 0.0191s/iter; left time: 198.5887s
Epoch: 12 cost time: 2.2291336059570312
Epoch: 12, Steps: 118 Train Loss: 29.5626 (Forecasting Loss:0.3479 + XiCon Loss:2.9215 x Lambda(10.0)), Vali MSE Loss: 0.4126 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.4354820
	speed: 0.0203s/iter; left time: 209.0651s
Epoch: 13 cost time: 2.4028725624084473
Epoch: 13, Steps: 118 Train Loss: 29.5646 (Forecasting Loss:0.3480 + XiCon Loss:2.9217 x Lambda(10.0)), Vali MSE Loss: 0.4125 Test MSE Loss: 0.2904
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.4479332
	speed: 0.0183s/iter; left time: 185.8985s
Epoch: 14 cost time: 2.1771507263183594
Epoch: 14, Steps: 118 Train Loss: 29.5972 (Forecasting Loss:0.3480 + XiCon Loss:2.9249 x Lambda(10.0)), Vali MSE Loss: 0.4118 Test MSE Loss: 0.2904
Validation loss decreased (0.412218 --> 0.411815).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.6067448
	speed: 0.0190s/iter; left time: 191.2774s
Epoch: 15 cost time: 2.227816581726074
Epoch: 15, Steps: 118 Train Loss: 29.5982 (Forecasting Loss:0.3477 + XiCon Loss:2.9251 x Lambda(10.0)), Vali MSE Loss: 0.4122 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 29.6512032
	speed: 0.0188s/iter; left time: 187.1701s
Epoch: 16 cost time: 2.2041335105895996
Epoch: 16, Steps: 118 Train Loss: 29.5968 (Forecasting Loss:0.3475 + XiCon Loss:2.9249 x Lambda(10.0)), Vali MSE Loss: 0.4122 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 29.6234131
	speed: 0.0183s/iter; left time: 179.8529s
Epoch: 17 cost time: 2.1374454498291016
Epoch: 17, Steps: 118 Train Loss: 29.5999 (Forecasting Loss:0.3478 + XiCon Loss:2.9252 x Lambda(10.0)), Vali MSE Loss: 0.4125 Test MSE Loss: 0.2904
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.1691360
	speed: 0.0193s/iter; left time: 187.1065s
Epoch: 18 cost time: 2.2535359859466553
Epoch: 18, Steps: 118 Train Loss: 29.5911 (Forecasting Loss:0.3476 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.4129 Test MSE Loss: 0.2904
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 29.6935959
	speed: 0.0203s/iter; left time: 194.7652s
Epoch: 19 cost time: 2.3707993030548096
Epoch: 19, Steps: 118 Train Loss: 29.5846 (Forecasting Loss:0.3477 + XiCon Loss:2.9237 x Lambda(10.0)), Vali MSE Loss: 0.4125 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 29.7975445
	speed: 0.0192s/iter; left time: 181.5247s
Epoch: 20 cost time: 2.2310538291931152
Epoch: 20, Steps: 118 Train Loss: 29.5874 (Forecasting Loss:0.3476 + XiCon Loss:2.9240 x Lambda(10.0)), Vali MSE Loss: 0.4120 Test MSE Loss: 0.2904
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 29.6496906
	speed: 0.0190s/iter; left time: 177.1589s
Epoch: 21 cost time: 2.1938636302948
Epoch: 21, Steps: 118 Train Loss: 29.5800 (Forecasting Loss:0.3479 + XiCon Loss:2.9232 x Lambda(10.0)), Vali MSE Loss: 0.4116 Test MSE Loss: 0.2904
Validation loss decreased (0.411815 --> 0.411579).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 29.4268551
	speed: 0.0185s/iter; left time: 170.2053s
Epoch: 22 cost time: 2.146522283554077
Epoch: 22, Steps: 118 Train Loss: 29.5760 (Forecasting Loss:0.3480 + XiCon Loss:2.9228 x Lambda(10.0)), Vali MSE Loss: 0.4130 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 29.6534023
	speed: 0.0196s/iter; left time: 178.7415s
Epoch: 23 cost time: 2.2757322788238525
Epoch: 23, Steps: 118 Train Loss: 29.6110 (Forecasting Loss:0.3477 + XiCon Loss:2.9263 x Lambda(10.0)), Vali MSE Loss: 0.4127 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 29.6230927
	speed: 0.0193s/iter; left time: 173.2500s
Epoch: 24 cost time: 2.243417978286743
Epoch: 24, Steps: 118 Train Loss: 29.6006 (Forecasting Loss:0.3476 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4126 Test MSE Loss: 0.2904
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 29.8230114
	speed: 0.0204s/iter; left time: 180.9711s
Epoch: 25 cost time: 2.367581367492676
Epoch: 25, Steps: 118 Train Loss: 29.5706 (Forecasting Loss:0.3480 + XiCon Loss:2.9223 x Lambda(10.0)), Vali MSE Loss: 0.4129 Test MSE Loss: 0.2904
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 29.3758755
	speed: 0.0178s/iter; left time: 155.9248s
Epoch: 26 cost time: 2.122040033340454
Epoch: 26, Steps: 118 Train Loss: 29.6032 (Forecasting Loss:0.3479 + XiCon Loss:2.9255 x Lambda(10.0)), Vali MSE Loss: 0.4117 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 29.3396187
	speed: 0.0192s/iter; left time: 165.5732s
Epoch: 27 cost time: 2.2347378730773926
Epoch: 27, Steps: 118 Train Loss: 29.5554 (Forecasting Loss:0.3482 + XiCon Loss:2.9207 x Lambda(10.0)), Vali MSE Loss: 0.4126 Test MSE Loss: 0.2904
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 29.6067181
	speed: 0.0191s/iter; left time: 162.4627s
Epoch: 28 cost time: 2.2219512462615967
Epoch: 28, Steps: 118 Train Loss: 29.5942 (Forecasting Loss:0.3481 + XiCon Loss:2.9246 x Lambda(10.0)), Vali MSE Loss: 0.4124 Test MSE Loss: 0.2904
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 29.7983551
	speed: 0.0181s/iter; left time: 151.9873s
Epoch: 29 cost time: 2.121307849884033
Epoch: 29, Steps: 118 Train Loss: 29.5834 (Forecasting Loss:0.3477 + XiCon Loss:2.9236 x Lambda(10.0)), Vali MSE Loss: 0.4125 Test MSE Loss: 0.2904
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 29.6644325
	speed: 0.0192s/iter; left time: 159.0804s
Epoch: 30 cost time: 2.2842800617218018
Epoch: 30, Steps: 118 Train Loss: 29.5674 (Forecasting Loss:0.3478 + XiCon Loss:2.9220 x Lambda(10.0)), Vali MSE Loss: 0.4121 Test MSE Loss: 0.2904
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 29.3122234
	speed: 0.0203s/iter; left time: 165.3613s
Epoch: 31 cost time: 2.3694674968719482
Epoch: 31, Steps: 118 Train Loss: 29.5752 (Forecasting Loss:0.3480 + XiCon Loss:2.9227 x Lambda(10.0)), Vali MSE Loss: 0.4133 Test MSE Loss: 0.2904
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.21166548132896423, mae:0.3691105842590332, mape:0.6436155438423157, mspe:15.83812427520752 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2835
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.8117638
	speed: 0.0189s/iter; left time: 221.2602s
Epoch: 1 cost time: 2.209786891937256
Epoch: 1, Steps: 118 Train Loss: 31.8408 (Forecasting Loss:0.4651 + XiCon Loss:3.1376 x Lambda(10.0)), Vali MSE Loss: 0.4753 Test MSE Loss: 0.3595
Validation loss decreased (inf --> 0.475305).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 30.2600098
	speed: 0.0185s/iter; left time: 213.8474s
Epoch: 2 cost time: 2.1490683555603027
Epoch: 2, Steps: 118 Train Loss: 30.8056 (Forecasting Loss:0.3806 + XiCon Loss:3.0425 x Lambda(10.0)), Vali MSE Loss: 0.4135 Test MSE Loss: 0.3092
Validation loss decreased (0.475305 --> 0.413463).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.7687016
	speed: 0.0184s/iter; left time: 211.3935s
Epoch: 3 cost time: 2.196584701538086
Epoch: 3, Steps: 118 Train Loss: 29.8312 (Forecasting Loss:0.3632 + XiCon Loss:2.9468 x Lambda(10.0)), Vali MSE Loss: 0.4119 Test MSE Loss: 0.3090
Validation loss decreased (0.413463 --> 0.411916).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.7511616
	speed: 0.0191s/iter; left time: 217.1683s
Epoch: 4 cost time: 2.2270002365112305
Epoch: 4, Steps: 118 Train Loss: 29.6783 (Forecasting Loss:0.3590 + XiCon Loss:2.9319 x Lambda(10.0)), Vali MSE Loss: 0.4077 Test MSE Loss: 0.3054
Validation loss decreased (0.411916 --> 0.407712).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.6643009
	speed: 0.0195s/iter; left time: 218.6227s
Epoch: 5 cost time: 2.2958383560180664
Epoch: 5, Steps: 118 Train Loss: 29.6394 (Forecasting Loss:0.3571 + XiCon Loss:2.9282 x Lambda(10.0)), Vali MSE Loss: 0.4074 Test MSE Loss: 0.3039
Validation loss decreased (0.407712 --> 0.407389).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.4461689
	speed: 0.0188s/iter; left time: 209.3053s
Epoch: 6 cost time: 2.1840975284576416
Epoch: 6, Steps: 118 Train Loss: 29.6193 (Forecasting Loss:0.3560 + XiCon Loss:2.9263 x Lambda(10.0)), Vali MSE Loss: 0.4070 Test MSE Loss: 0.3049
Validation loss decreased (0.407389 --> 0.406972).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.6509686
	speed: 0.0184s/iter; left time: 202.0411s
Epoch: 7 cost time: 2.158573865890503
Epoch: 7, Steps: 118 Train Loss: 29.6325 (Forecasting Loss:0.3556 + XiCon Loss:2.9277 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.3050
Validation loss decreased (0.406972 --> 0.406663).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.7497253
	speed: 0.0193s/iter; left time: 209.9254s
Epoch: 8 cost time: 2.244309425354004
Epoch: 8, Steps: 118 Train Loss: 29.6190 (Forecasting Loss:0.3557 + XiCon Loss:2.9263 x Lambda(10.0)), Vali MSE Loss: 0.4074 Test MSE Loss: 0.3050
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.5745506
	speed: 0.0192s/iter; left time: 206.4786s
Epoch: 9 cost time: 2.2563719749450684
Epoch: 9, Steps: 118 Train Loss: 29.6009 (Forecasting Loss:0.3554 + XiCon Loss:2.9246 x Lambda(10.0)), Vali MSE Loss: 0.4079 Test MSE Loss: 0.3055
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.3790760
	speed: 0.0188s/iter; left time: 200.0101s
Epoch: 10 cost time: 2.1970672607421875
Epoch: 10, Steps: 118 Train Loss: 29.6205 (Forecasting Loss:0.3553 + XiCon Loss:2.9265 x Lambda(10.0)), Vali MSE Loss: 0.4073 Test MSE Loss: 0.3052
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.6974564
	speed: 0.0198s/iter; left time: 208.4984s
Epoch: 11 cost time: 2.3581230640411377
Epoch: 11, Steps: 118 Train Loss: 29.6081 (Forecasting Loss:0.3551 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.3051
Validation loss decreased (0.406663 --> 0.406643).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.7784195
	speed: 0.0192s/iter; left time: 199.4438s
Epoch: 12 cost time: 2.2501392364501953
Epoch: 12, Steps: 118 Train Loss: 29.5973 (Forecasting Loss:0.3552 + XiCon Loss:2.9242 x Lambda(10.0)), Vali MSE Loss: 0.4073 Test MSE Loss: 0.3052
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.7483521
	speed: 0.0190s/iter; left time: 195.3264s
Epoch: 13 cost time: 2.235886573791504
Epoch: 13, Steps: 118 Train Loss: 29.5900 (Forecasting Loss:0.3547 + XiCon Loss:2.9235 x Lambda(10.0)), Vali MSE Loss: 0.4075 Test MSE Loss: 0.3052
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.6635056
	speed: 0.0195s/iter; left time: 198.0113s
Epoch: 14 cost time: 2.2426106929779053
Epoch: 14, Steps: 118 Train Loss: 29.6078 (Forecasting Loss:0.3551 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.3052
Validation loss decreased (0.406643 --> 0.406561).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.5384350
	speed: 0.0192s/iter; left time: 192.8305s
Epoch: 15 cost time: 2.2376139163970947
Epoch: 15, Steps: 118 Train Loss: 29.6094 (Forecasting Loss:0.3554 + XiCon Loss:2.9254 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3052
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 29.6802101
	speed: 0.0193s/iter; left time: 191.4727s
Epoch: 16 cost time: 2.226743698120117
Epoch: 16, Steps: 118 Train Loss: 29.6195 (Forecasting Loss:0.3551 + XiCon Loss:2.9264 x Lambda(10.0)), Vali MSE Loss: 0.4073 Test MSE Loss: 0.3052
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 29.5359688
	speed: 0.0213s/iter; left time: 209.3247s
Epoch: 17 cost time: 2.485170841217041
Epoch: 17, Steps: 118 Train Loss: 29.5896 (Forecasting Loss:0.3554 + XiCon Loss:2.9234 x Lambda(10.0)), Vali MSE Loss: 0.4083 Test MSE Loss: 0.3052
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.6836510
	speed: 0.0191s/iter; left time: 185.0233s
Epoch: 18 cost time: 2.236283540725708
Epoch: 18, Steps: 118 Train Loss: 29.5981 (Forecasting Loss:0.3548 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3052
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 29.8612957
	speed: 0.0186s/iter; left time: 177.9329s
Epoch: 19 cost time: 2.2027485370635986
Epoch: 19, Steps: 118 Train Loss: 29.5925 (Forecasting Loss:0.3556 + XiCon Loss:2.9237 x Lambda(10.0)), Vali MSE Loss: 0.4076 Test MSE Loss: 0.3052
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 29.7767830
	speed: 0.0187s/iter; left time: 177.0094s
Epoch: 20 cost time: 2.198284864425659
Epoch: 20, Steps: 118 Train Loss: 29.6079 (Forecasting Loss:0.3550 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4074 Test MSE Loss: 0.3052
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 29.5859413
	speed: 0.0189s/iter; left time: 177.0028s
Epoch: 21 cost time: 2.2296814918518066
Epoch: 21, Steps: 118 Train Loss: 29.6079 (Forecasting Loss:0.3551 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.4077 Test MSE Loss: 0.3052
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 29.4427910
	speed: 0.0187s/iter; left time: 172.4249s
Epoch: 22 cost time: 2.1779708862304688
Epoch: 22, Steps: 118 Train Loss: 29.5901 (Forecasting Loss:0.3550 + XiCon Loss:2.9235 x Lambda(10.0)), Vali MSE Loss: 0.4078 Test MSE Loss: 0.3052
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 29.5861549
	speed: 0.0210s/iter; left time: 191.3971s
Epoch: 23 cost time: 2.443791151046753
Epoch: 23, Steps: 118 Train Loss: 29.5977 (Forecasting Loss:0.3550 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.4075 Test MSE Loss: 0.3052
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 29.6374245
	speed: 0.0188s/iter; left time: 168.7704s
Epoch: 24 cost time: 2.1794350147247314
Epoch: 24, Steps: 118 Train Loss: 29.6276 (Forecasting Loss:0.3553 + XiCon Loss:2.9272 x Lambda(10.0)), Vali MSE Loss: 0.4076 Test MSE Loss: 0.3052
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2271375209093094, mae:0.3832089900970459, mape:0.6402345299720764, mspe:14.787033081054688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3605
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.4866657
	speed: 0.0186s/iter; left time: 217.8557s
Epoch: 1 cost time: 2.172887086868286
Epoch: 1, Steps: 118 Train Loss: 31.6572 (Forecasting Loss:0.4722 + XiCon Loss:3.1185 x Lambda(10.0)), Vali MSE Loss: 0.4719 Test MSE Loss: 0.3519
Validation loss decreased (inf --> 0.471941).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 29.7579231
	speed: 0.0200s/iter; left time: 232.1982s
Epoch: 2 cost time: 2.3213236331939697
Epoch: 2, Steps: 118 Train Loss: 30.4145 (Forecasting Loss:0.3819 + XiCon Loss:3.0033 x Lambda(10.0)), Vali MSE Loss: 0.4140 Test MSE Loss: 0.3048
Validation loss decreased (0.471941 --> 0.414032).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.5320148
	speed: 0.0199s/iter; left time: 228.2916s
Epoch: 3 cost time: 2.2893893718719482
Epoch: 3, Steps: 118 Train Loss: 29.5639 (Forecasting Loss:0.3620 + XiCon Loss:2.9202 x Lambda(10.0)), Vali MSE Loss: 0.4138 Test MSE Loss: 0.3057
Validation loss decreased (0.414032 --> 0.413783).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.5508556
	speed: 0.0203s/iter; left time: 229.8539s
Epoch: 4 cost time: 2.3688411712646484
Epoch: 4, Steps: 118 Train Loss: 29.4945 (Forecasting Loss:0.3579 + XiCon Loss:2.9137 x Lambda(10.0)), Vali MSE Loss: 0.4100 Test MSE Loss: 0.3010
Validation loss decreased (0.413783 --> 0.410026).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.5538902
	speed: 0.0184s/iter; left time: 206.4165s
Epoch: 5 cost time: 2.138129472732544
Epoch: 5, Steps: 118 Train Loss: 29.4712 (Forecasting Loss:0.3568 + XiCon Loss:2.9114 x Lambda(10.0)), Vali MSE Loss: 0.4106 Test MSE Loss: 0.3005
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.4801311
	speed: 0.0194s/iter; left time: 215.1995s
Epoch: 6 cost time: 2.2784223556518555
Epoch: 6, Steps: 118 Train Loss: 29.4666 (Forecasting Loss:0.3551 + XiCon Loss:2.9111 x Lambda(10.0)), Vali MSE Loss: 0.4071 Test MSE Loss: 0.2992
Validation loss decreased (0.410026 --> 0.407131).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.4852104
	speed: 0.0188s/iter; left time: 207.1749s
Epoch: 7 cost time: 2.195084810256958
Epoch: 7, Steps: 118 Train Loss: 29.4619 (Forecasting Loss:0.3550 + XiCon Loss:2.9107 x Lambda(10.0)), Vali MSE Loss: 0.4076 Test MSE Loss: 0.2984
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.5704460
	speed: 0.0186s/iter; left time: 202.0815s
Epoch: 8 cost time: 2.163374662399292
Epoch: 8, Steps: 118 Train Loss: 29.4562 (Forecasting Loss:0.3544 + XiCon Loss:2.9102 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2965
Validation loss decreased (0.407131 --> 0.406722).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.3881302
	speed: 0.0190s/iter; left time: 204.3267s
Epoch: 9 cost time: 2.2481133937835693
Epoch: 9, Steps: 118 Train Loss: 29.4551 (Forecasting Loss:0.3542 + XiCon Loss:2.9101 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2972
Validation loss decreased (0.406722 --> 0.406721).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.3783035
	speed: 0.0198s/iter; left time: 210.8586s
Epoch: 10 cost time: 2.344698190689087
Epoch: 10, Steps: 118 Train Loss: 29.4591 (Forecasting Loss:0.3547 + XiCon Loss:2.9104 x Lambda(10.0)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.2973
Validation loss decreased (0.406721 --> 0.406039).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.2715263
	speed: 0.0187s/iter; left time: 197.1609s
Epoch: 11 cost time: 2.1839709281921387
Epoch: 11, Steps: 118 Train Loss: 29.4435 (Forecasting Loss:0.3542 + XiCon Loss:2.9089 x Lambda(10.0)), Vali MSE Loss: 0.4068 Test MSE Loss: 0.2968
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.4297180
	speed: 0.0190s/iter; left time: 197.4274s
Epoch: 12 cost time: 2.241210699081421
Epoch: 12, Steps: 118 Train Loss: 29.4528 (Forecasting Loss:0.3540 + XiCon Loss:2.9099 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2969
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.4591064
	speed: 0.0183s/iter; left time: 188.5726s
Epoch: 13 cost time: 2.165898561477661
Epoch: 13, Steps: 118 Train Loss: 29.4625 (Forecasting Loss:0.3544 + XiCon Loss:2.9108 x Lambda(10.0)), Vali MSE Loss: 0.4071 Test MSE Loss: 0.2968
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 29.4293652
	speed: 0.0184s/iter; left time: 186.6288s
Epoch: 14 cost time: 2.1656579971313477
Epoch: 14, Steps: 118 Train Loss: 29.4556 (Forecasting Loss:0.3546 + XiCon Loss:2.9101 x Lambda(10.0)), Vali MSE Loss: 0.4065 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 29.4820709
	speed: 0.0192s/iter; left time: 192.8433s
Epoch: 15 cost time: 2.2403714656829834
Epoch: 15, Steps: 118 Train Loss: 29.4485 (Forecasting Loss:0.3543 + XiCon Loss:2.9094 x Lambda(10.0)), Vali MSE Loss: 0.4071 Test MSE Loss: 0.2968
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 29.4921684
	speed: 0.0202s/iter; left time: 200.8954s
Epoch: 16 cost time: 2.3676629066467285
Epoch: 16, Steps: 118 Train Loss: 29.4594 (Forecasting Loss:0.3540 + XiCon Loss:2.9105 x Lambda(10.0)), Vali MSE Loss: 0.4071 Test MSE Loss: 0.2968
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 29.4609699
	speed: 0.0194s/iter; left time: 190.1717s
Epoch: 17 cost time: 2.2787554264068604
Epoch: 17, Steps: 118 Train Loss: 29.4428 (Forecasting Loss:0.3538 + XiCon Loss:2.9089 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.2968
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 29.3829384
	speed: 0.0182s/iter; left time: 176.2954s
Epoch: 18 cost time: 2.1134955883026123
Epoch: 18, Steps: 118 Train Loss: 29.4570 (Forecasting Loss:0.3543 + XiCon Loss:2.9103 x Lambda(10.0)), Vali MSE Loss: 0.4055 Test MSE Loss: 0.2968
Validation loss decreased (0.406039 --> 0.405542).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 29.3910141
	speed: 0.0185s/iter; left time: 177.0567s
Epoch: 19 cost time: 2.1598150730133057
Epoch: 19, Steps: 118 Train Loss: 29.4521 (Forecasting Loss:0.3539 + XiCon Loss:2.9098 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2968
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 29.5384560
	speed: 0.0186s/iter; left time: 176.1498s
Epoch: 20 cost time: 2.2104225158691406
Epoch: 20, Steps: 118 Train Loss: 29.4489 (Forecasting Loss:0.3540 + XiCon Loss:2.9095 x Lambda(10.0)), Vali MSE Loss: 0.4075 Test MSE Loss: 0.2968
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 29.3546085
	speed: 0.0190s/iter; left time: 177.2440s
Epoch: 21 cost time: 2.2692222595214844
Epoch: 21, Steps: 118 Train Loss: 29.4488 (Forecasting Loss:0.3541 + XiCon Loss:2.9095 x Lambda(10.0)), Vali MSE Loss: 0.4070 Test MSE Loss: 0.2968
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 29.4556541
	speed: 0.0200s/iter; left time: 184.0462s
Epoch: 22 cost time: 2.307316303253174
Epoch: 22, Steps: 118 Train Loss: 29.4507 (Forecasting Loss:0.3540 + XiCon Loss:2.9097 x Lambda(10.0)), Vali MSE Loss: 0.4061 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 29.5265675
	speed: 0.0186s/iter; left time: 169.1277s
Epoch: 23 cost time: 2.173022985458374
Epoch: 23, Steps: 118 Train Loss: 29.4590 (Forecasting Loss:0.3541 + XiCon Loss:2.9105 x Lambda(10.0)), Vali MSE Loss: 0.4073 Test MSE Loss: 0.2968
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 29.2957897
	speed: 0.0188s/iter; left time: 168.8752s
Epoch: 24 cost time: 2.1998403072357178
Epoch: 24, Steps: 118 Train Loss: 29.4542 (Forecasting Loss:0.3547 + XiCon Loss:2.9100 x Lambda(10.0)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2968
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 29.4784412
	speed: 0.0188s/iter; left time: 167.0690s
Epoch: 25 cost time: 2.2003159523010254
Epoch: 25, Steps: 118 Train Loss: 29.4555 (Forecasting Loss:0.3541 + XiCon Loss:2.9101 x Lambda(10.0)), Vali MSE Loss: 0.4075 Test MSE Loss: 0.2968
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 29.3383121
	speed: 0.0187s/iter; left time: 163.7824s
Epoch: 26 cost time: 2.21880841255188
Epoch: 26, Steps: 118 Train Loss: 29.4496 (Forecasting Loss:0.3539 + XiCon Loss:2.9096 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.2968
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 29.4918365
	speed: 0.0184s/iter; left time: 158.5916s
Epoch: 27 cost time: 2.14978289604187
Epoch: 27, Steps: 118 Train Loss: 29.4584 (Forecasting Loss:0.3541 + XiCon Loss:2.9104 x Lambda(10.0)), Vali MSE Loss: 0.4072 Test MSE Loss: 0.2968
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 29.5723152
	speed: 0.0202s/iter; left time: 171.9427s
Epoch: 28 cost time: 2.3416004180908203
Epoch: 28, Steps: 118 Train Loss: 29.4570 (Forecasting Loss:0.3543 + XiCon Loss:2.9103 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.2968
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.21770817041397095, mae:0.37586942315101624, mape:0.6371398568153381, mspe:15.017619132995605 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3090
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.5858803
	speed: 0.0200s/iter; left time: 233.8468s
Epoch: 1 cost time: 2.3352274894714355
Epoch: 1, Steps: 118 Train Loss: 31.8669 (Forecasting Loss:0.4655 + XiCon Loss:3.1401 x Lambda(10.0)), Vali MSE Loss: 0.4747 Test MSE Loss: 0.3590
Validation loss decreased (inf --> 0.474741).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 30.1633701
	speed: 0.0192s/iter; left time: 222.2120s
Epoch: 2 cost time: 2.2288942337036133
Epoch: 2, Steps: 118 Train Loss: 30.5867 (Forecasting Loss:0.3813 + XiCon Loss:3.0205 x Lambda(10.0)), Vali MSE Loss: 0.3975 Test MSE Loss: 0.2812
Validation loss decreased (0.474741 --> 0.397455).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 29.7309513
	speed: 0.0194s/iter; left time: 222.6237s
Epoch: 3 cost time: 2.268247127532959
Epoch: 3, Steps: 118 Train Loss: 29.8326 (Forecasting Loss:0.3495 + XiCon Loss:2.9483 x Lambda(10.0)), Vali MSE Loss: 0.3733 Test MSE Loss: 0.2622
Validation loss decreased (0.397455 --> 0.373323).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 29.7613640
	speed: 0.0188s/iter; left time: 213.1415s
Epoch: 4 cost time: 2.17683482170105
Epoch: 4, Steps: 118 Train Loss: 29.6556 (Forecasting Loss:0.3327 + XiCon Loss:2.9323 x Lambda(10.0)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 29.6500015
	speed: 0.0203s/iter; left time: 228.0226s
Epoch: 5 cost time: 2.3403568267822266
Epoch: 5, Steps: 118 Train Loss: 29.5978 (Forecasting Loss:0.3266 + XiCon Loss:2.9271 x Lambda(10.0)), Vali MSE Loss: 0.3902 Test MSE Loss: 0.2775
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 29.4003620
	speed: 0.0189s/iter; left time: 209.9759s
Epoch: 6 cost time: 2.192807912826538
Epoch: 6, Steps: 118 Train Loss: 29.5587 (Forecasting Loss:0.3242 + XiCon Loss:2.9234 x Lambda(10.0)), Vali MSE Loss: 0.3843 Test MSE Loss: 0.2750
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 29.7255535
	speed: 0.0187s/iter; left time: 206.0825s
Epoch: 7 cost time: 2.232468843460083
Epoch: 7, Steps: 118 Train Loss: 29.5561 (Forecasting Loss:0.3239 + XiCon Loss:2.9232 x Lambda(10.0)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2714
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 29.5516548
	speed: 0.0184s/iter; left time: 200.1909s
Epoch: 8 cost time: 2.1773509979248047
Epoch: 8, Steps: 118 Train Loss: 29.5352 (Forecasting Loss:0.3223 + XiCon Loss:2.9213 x Lambda(10.0)), Vali MSE Loss: 0.3777 Test MSE Loss: 0.2725
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 29.5892982
	speed: 0.0183s/iter; left time: 196.6315s
Epoch: 9 cost time: 2.1444103717803955
Epoch: 9, Steps: 118 Train Loss: 29.5240 (Forecasting Loss:0.3225 + XiCon Loss:2.9201 x Lambda(10.0)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2711
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 29.5869370
	speed: 0.0184s/iter; left time: 195.8907s
Epoch: 10 cost time: 2.20253849029541
Epoch: 10, Steps: 118 Train Loss: 29.5408 (Forecasting Loss:0.3227 + XiCon Loss:2.9218 x Lambda(10.0)), Vali MSE Loss: 0.3777 Test MSE Loss: 0.2726
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 29.2857933
	speed: 0.0204s/iter; left time: 214.1376s
Epoch: 11 cost time: 2.368492841720581
Epoch: 11, Steps: 118 Train Loss: 29.5209 (Forecasting Loss:0.3221 + XiCon Loss:2.9199 x Lambda(10.0)), Vali MSE Loss: 0.3758 Test MSE Loss: 0.2721
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 29.6178360
	speed: 0.0187s/iter; left time: 194.4821s
Epoch: 12 cost time: 2.1889851093292236
Epoch: 12, Steps: 118 Train Loss: 29.5219 (Forecasting Loss:0.3232 + XiCon Loss:2.9199 x Lambda(10.0)), Vali MSE Loss: 0.3765 Test MSE Loss: 0.2721
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 29.5212421
	speed: 0.0182s/iter; left time: 187.6887s
Epoch: 13 cost time: 2.1547927856445312
Epoch: 13, Steps: 118 Train Loss: 29.5239 (Forecasting Loss:0.3228 + XiCon Loss:2.9201 x Lambda(10.0)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2721
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18031884729862213, mae:0.3441762328147888, mape:0.648613691329956, mspe:19.66227912902832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2080+-0.02205, MAE:0.3672+-0.01838, MAPE:0.6392+-0.01036, MSPE:16.1368+-2.49624, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7083
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.2321777
	speed: 0.0436s/iter; left time: 1154.9075s
	iters: 200, epoch: 1 | loss: 31.6692429
	speed: 0.0380s/iter; left time: 1002.7541s
Epoch: 1 cost time: 10.701599836349487
Epoch: 1, Steps: 266 Train Loss: 32.2719 (Forecasting Loss:0.1694 + XiCon Loss:3.2102 x Lambda(10.0)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.0798
Validation loss decreased (inf --> 0.115380).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.6977158
	speed: 0.0401s/iter; left time: 1052.0728s
	iters: 200, epoch: 2 | loss: 32.6436005
	speed: 0.0386s/iter; left time: 1007.5983s
Epoch: 2 cost time: 10.451083660125732
Epoch: 2, Steps: 266 Train Loss: 32.1876 (Forecasting Loss:0.1505 + XiCon Loss:3.2037 x Lambda(10.0)), Vali MSE Loss: 0.1118 Test MSE Loss: 0.0760
Validation loss decreased (0.115380 --> 0.111759).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.4377918
	speed: 0.0403s/iter; left time: 1046.1325s
	iters: 200, epoch: 3 | loss: 30.6037674
	speed: 0.0382s/iter; left time: 988.7693s
Epoch: 3 cost time: 10.427833795547485
Epoch: 3, Steps: 266 Train Loss: 31.1214 (Forecasting Loss:0.1452 + XiCon Loss:3.0976 x Lambda(10.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0761
Validation loss decreased (0.111759 --> 0.109677).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9646282
	speed: 0.0403s/iter; left time: 1034.7846s
	iters: 200, epoch: 4 | loss: 31.0938625
	speed: 0.0387s/iter; left time: 991.4036s
Epoch: 4 cost time: 10.501341819763184
Epoch: 4, Steps: 266 Train Loss: 30.9711 (Forecasting Loss:0.1433 + XiCon Loss:3.0828 x Lambda(10.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0749
Validation loss decreased (0.109677 --> 0.108577).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8185921
	speed: 0.0403s/iter; left time: 1026.2530s
	iters: 200, epoch: 5 | loss: 30.7792759
	speed: 0.0379s/iter; left time: 960.5684s
Epoch: 5 cost time: 10.3478364944458
Epoch: 5, Steps: 266 Train Loss: 30.9771 (Forecasting Loss:0.1425 + XiCon Loss:3.0835 x Lambda(10.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0744
Validation loss decreased (0.108577 --> 0.107774).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5279713
	speed: 0.0408s/iter; left time: 1026.6290s
	iters: 200, epoch: 6 | loss: 31.0278282
	speed: 0.0391s/iter; left time: 980.3792s
Epoch: 6 cost time: 10.495327472686768
Epoch: 6, Steps: 266 Train Loss: 30.9304 (Forecasting Loss:0.1421 + XiCon Loss:3.0788 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107774 --> 0.107656).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1603680
	speed: 0.0402s/iter; left time: 1002.2009s
	iters: 200, epoch: 7 | loss: 30.5789909
	speed: 0.0387s/iter; left time: 959.3139s
Epoch: 7 cost time: 10.477363586425781
Epoch: 7, Steps: 266 Train Loss: 30.9072 (Forecasting Loss:0.1418 + XiCon Loss:3.0765 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107656 --> 0.107439).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4000702
	speed: 0.0404s/iter; left time: 996.4488s
	iters: 200, epoch: 8 | loss: 30.6495132
	speed: 0.0390s/iter; left time: 956.6949s
Epoch: 8 cost time: 10.510555982589722
Epoch: 8, Steps: 266 Train Loss: 30.9306 (Forecasting Loss:0.1417 + XiCon Loss:3.0789 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6249065
	speed: 0.0409s/iter; left time: 996.1230s
	iters: 200, epoch: 9 | loss: 30.7093735
	speed: 0.0391s/iter; left time: 948.3042s
Epoch: 9 cost time: 10.574826717376709
Epoch: 9, Steps: 266 Train Loss: 30.9470 (Forecasting Loss:0.1416 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3591290
	speed: 0.0403s/iter; left time: 972.4441s
	iters: 200, epoch: 10 | loss: 30.7189045
	speed: 0.0395s/iter; left time: 947.9673s
Epoch: 10 cost time: 10.591641187667847
Epoch: 10, Steps: 266 Train Loss: 30.9414 (Forecasting Loss:0.1416 + XiCon Loss:3.0800 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8863945
	speed: 0.0403s/iter; left time: 961.8125s
	iters: 200, epoch: 11 | loss: 31.3528500
	speed: 0.0379s/iter; left time: 900.0204s
Epoch: 11 cost time: 10.413246631622314
Epoch: 11, Steps: 266 Train Loss: 30.9127 (Forecasting Loss:0.1416 + XiCon Loss:3.0771 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107439 --> 0.107436).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8260555
	speed: 0.0407s/iter; left time: 960.4017s
	iters: 200, epoch: 12 | loss: 30.5433025
	speed: 0.0393s/iter; left time: 922.6306s
Epoch: 12 cost time: 10.53446340560913
Epoch: 12, Steps: 266 Train Loss: 30.9480 (Forecasting Loss:0.1416 + XiCon Loss:3.0806 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107436 --> 0.107424).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.3480701
	speed: 0.0407s/iter; left time: 949.1822s
	iters: 200, epoch: 13 | loss: 30.7642593
	speed: 0.0386s/iter; left time: 895.4605s
Epoch: 13 cost time: 10.572839975357056
Epoch: 13, Steps: 266 Train Loss: 30.9841 (Forecasting Loss:0.1416 + XiCon Loss:3.0842 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.7740231
	speed: 0.0406s/iter; left time: 934.4957s
	iters: 200, epoch: 14 | loss: 31.9816055
	speed: 0.0388s/iter; left time: 890.8313s
Epoch: 14 cost time: 10.555504083633423
Epoch: 14, Steps: 266 Train Loss: 30.8944 (Forecasting Loss:0.1416 + XiCon Loss:3.0753 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107424 --> 0.107366).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.7082691
	speed: 0.0417s/iter; left time: 949.6196s
	iters: 200, epoch: 15 | loss: 30.0338802
	speed: 0.0390s/iter; left time: 883.9309s
Epoch: 15 cost time: 10.5919930934906
Epoch: 15, Steps: 266 Train Loss: 30.8982 (Forecasting Loss:0.1416 + XiCon Loss:3.0757 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8314972
	speed: 0.0404s/iter; left time: 909.4967s
	iters: 200, epoch: 16 | loss: 32.3268547
	speed: 0.0391s/iter; left time: 876.4043s
Epoch: 16 cost time: 10.617906093597412
Epoch: 16, Steps: 266 Train Loss: 30.8842 (Forecasting Loss:0.1415 + XiCon Loss:3.0743 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.6462898
	speed: 0.0399s/iter; left time: 887.1366s
	iters: 200, epoch: 17 | loss: 30.5626850
	speed: 0.0378s/iter; left time: 836.7483s
Epoch: 17 cost time: 10.309428215026855
Epoch: 17, Steps: 266 Train Loss: 30.9018 (Forecasting Loss:0.1416 + XiCon Loss:3.0760 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.2225971
	speed: 0.0414s/iter; left time: 908.9212s
	iters: 200, epoch: 18 | loss: 31.1657505
	speed: 0.0390s/iter; left time: 853.5881s
Epoch: 18 cost time: 10.572954654693604
Epoch: 18, Steps: 266 Train Loss: 30.9012 (Forecasting Loss:0.1416 + XiCon Loss:3.0760 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4453754
	speed: 0.0406s/iter; left time: 881.8927s
	iters: 200, epoch: 19 | loss: 30.6951942
	speed: 0.0379s/iter; left time: 819.9910s
Epoch: 19 cost time: 10.458191156387329
Epoch: 19, Steps: 266 Train Loss: 30.9205 (Forecasting Loss:0.1416 + XiCon Loss:3.0779 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.8339481
	speed: 0.0406s/iter; left time: 871.5904s
	iters: 200, epoch: 20 | loss: 31.5362358
	speed: 0.0391s/iter; left time: 834.2263s
Epoch: 20 cost time: 10.55863094329834
Epoch: 20, Steps: 266 Train Loss: 30.9352 (Forecasting Loss:0.1415 + XiCon Loss:3.0794 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5011177
	speed: 0.0412s/iter; left time: 873.3975s
	iters: 200, epoch: 21 | loss: 30.9964104
	speed: 0.0386s/iter; left time: 813.4065s
Epoch: 21 cost time: 10.506938934326172
Epoch: 21, Steps: 266 Train Loss: 30.9010 (Forecasting Loss:0.1415 + XiCon Loss:3.0759 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.1775169
	speed: 0.0407s/iter; left time: 852.1161s
	iters: 200, epoch: 22 | loss: 30.7252941
	speed: 0.0380s/iter; left time: 791.4237s
Epoch: 22 cost time: 10.483580350875854
Epoch: 22, Steps: 266 Train Loss: 30.9548 (Forecasting Loss:0.1415 + XiCon Loss:3.0813 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107366 --> 0.107348).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.0719566
	speed: 0.0402s/iter; left time: 831.0005s
	iters: 200, epoch: 23 | loss: 30.9358101
	speed: 0.0390s/iter; left time: 802.1503s
Epoch: 23 cost time: 10.450513124465942
Epoch: 23, Steps: 266 Train Loss: 30.9350 (Forecasting Loss:0.1416 + XiCon Loss:3.0793 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.9302921
	speed: 0.0413s/iter; left time: 842.2153s
	iters: 200, epoch: 24 | loss: 31.0110016
	speed: 0.0382s/iter; left time: 775.2991s
Epoch: 24 cost time: 10.525037050247192
Epoch: 24, Steps: 266 Train Loss: 30.9196 (Forecasting Loss:0.1416 + XiCon Loss:3.0778 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.5813408
	speed: 0.0413s/iter; left time: 831.6712s
	iters: 200, epoch: 25 | loss: 30.5605583
	speed: 0.0381s/iter; left time: 762.0522s
Epoch: 25 cost time: 10.651047706604004
Epoch: 25, Steps: 266 Train Loss: 30.9268 (Forecasting Loss:0.1415 + XiCon Loss:3.0785 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.0043850
	speed: 0.0409s/iter; left time: 811.3706s
	iters: 200, epoch: 26 | loss: 30.4898491
	speed: 0.0380s/iter; left time: 751.2771s
Epoch: 26 cost time: 10.446159839630127
Epoch: 26, Steps: 266 Train Loss: 30.9309 (Forecasting Loss:0.1416 + XiCon Loss:3.0789 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.4787674
	speed: 0.0418s/iter; left time: 817.8583s
	iters: 200, epoch: 27 | loss: 30.2112446
	speed: 0.0385s/iter; left time: 750.8204s
Epoch: 27 cost time: 10.512735605239868
Epoch: 27, Steps: 266 Train Loss: 30.9157 (Forecasting Loss:0.1416 + XiCon Loss:3.0774 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 31.3028584
	speed: 0.0411s/iter; left time: 794.5264s
	iters: 200, epoch: 28 | loss: 30.6141529
	speed: 0.0396s/iter; left time: 760.1709s
Epoch: 28 cost time: 10.735566854476929
Epoch: 28, Steps: 266 Train Loss: 30.9209 (Forecasting Loss:0.1416 + XiCon Loss:3.0779 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.6813889
	speed: 0.0402s/iter; left time: 765.0930s
	iters: 200, epoch: 29 | loss: 30.5966415
	speed: 0.0382s/iter; left time: 723.6985s
Epoch: 29 cost time: 10.398939371109009
Epoch: 29, Steps: 266 Train Loss: 30.9669 (Forecasting Loss:0.1416 + XiCon Loss:3.0825 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.8438053
	speed: 0.0417s/iter; left time: 783.8330s
	iters: 200, epoch: 30 | loss: 31.2210484
	speed: 0.0384s/iter; left time: 716.7906s
Epoch: 30 cost time: 10.580390930175781
Epoch: 30, Steps: 266 Train Loss: 30.9367 (Forecasting Loss:0.1415 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.2175770
	speed: 0.0406s/iter; left time: 752.2035s
	iters: 200, epoch: 31 | loss: 30.6491356
	speed: 0.0398s/iter; left time: 732.8036s
Epoch: 31 cost time: 10.724844932556152
Epoch: 31, Steps: 266 Train Loss: 30.9389 (Forecasting Loss:0.1416 + XiCon Loss:3.0797 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.0425014
	speed: 0.0404s/iter; left time: 737.0356s
	iters: 200, epoch: 32 | loss: 32.5465736
	speed: 0.0391s/iter; left time: 709.6749s
Epoch: 32 cost time: 10.524330854415894
Epoch: 32, Steps: 266 Train Loss: 30.8987 (Forecasting Loss:0.1416 + XiCon Loss:3.0757 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02639894001185894, mae:0.1218889057636261, mape:0.098453089594841, mspe:0.019568495452404022 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.3087
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.1132965
	speed: 0.0411s/iter; left time: 1088.4664s
	iters: 200, epoch: 1 | loss: 31.7911358
	speed: 0.0393s/iter; left time: 1037.0600s
Epoch: 1 cost time: 10.51629376411438
Epoch: 1, Steps: 266 Train Loss: 32.3777 (Forecasting Loss:0.1686 + XiCon Loss:3.2209 x Lambda(10.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.0788
Validation loss decreased (inf --> 0.116416).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.6350670
	speed: 0.0408s/iter; left time: 1069.7365s
	iters: 200, epoch: 2 | loss: 32.9110603
	speed: 0.0384s/iter; left time: 1003.6724s
Epoch: 2 cost time: 10.462321758270264
Epoch: 2, Steps: 266 Train Loss: 33.6114 (Forecasting Loss:0.1509 + XiCon Loss:3.3460 x Lambda(10.0)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.0761
Validation loss decreased (0.116416 --> 0.110888).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.3013344
	speed: 0.0406s/iter; left time: 1054.9360s
	iters: 200, epoch: 3 | loss: 33.3674393
	speed: 0.0379s/iter; left time: 981.5818s
Epoch: 3 cost time: 10.380767107009888
Epoch: 3, Steps: 266 Train Loss: 32.7768 (Forecasting Loss:0.1453 + XiCon Loss:3.2631 x Lambda(10.0)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.0753
Validation loss decreased (0.110888 --> 0.108880).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 35.3017883
	speed: 0.0398s/iter; left time: 1021.8900s
	iters: 200, epoch: 4 | loss: 31.7689781
	speed: 0.0398s/iter; left time: 1018.5630s
Epoch: 4 cost time: 10.53776240348816
Epoch: 4, Steps: 266 Train Loss: 32.1904 (Forecasting Loss:0.1433 + XiCon Loss:3.2047 x Lambda(10.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0750
Validation loss decreased (0.108880 --> 0.108374).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.1260681
	speed: 0.0404s/iter; left time: 1028.4251s
	iters: 200, epoch: 5 | loss: 32.1573410
	speed: 0.0387s/iter; left time: 979.4088s
Epoch: 5 cost time: 10.453968286514282
Epoch: 5, Steps: 266 Train Loss: 32.0311 (Forecasting Loss:0.1425 + XiCon Loss:3.1889 x Lambda(10.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0749
Validation loss decreased (0.108374 --> 0.107963).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.4615021
	speed: 0.0415s/iter; left time: 1044.1967s
	iters: 200, epoch: 6 | loss: 31.4726334
	speed: 0.0382s/iter; left time: 956.6110s
Epoch: 6 cost time: 10.4840247631073
Epoch: 6, Steps: 266 Train Loss: 32.0856 (Forecasting Loss:0.1421 + XiCon Loss:3.1943 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0743
Validation loss decreased (0.107963 --> 0.107680).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.6102295
	speed: 0.0404s/iter; left time: 1007.3078s
	iters: 200, epoch: 7 | loss: 32.2097969
	speed: 0.0391s/iter; left time: 968.8961s
Epoch: 7 cost time: 10.4994478225708
Epoch: 7, Steps: 266 Train Loss: 32.0130 (Forecasting Loss:0.1418 + XiCon Loss:3.1871 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107680 --> 0.107336).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3931561
	speed: 0.0404s/iter; left time: 996.4310s
	iters: 200, epoch: 8 | loss: 31.0634995
	speed: 0.0380s/iter; left time: 931.8240s
Epoch: 8 cost time: 10.339962244033813
Epoch: 8, Steps: 266 Train Loss: 31.9584 (Forecasting Loss:0.1416 + XiCon Loss:3.1817 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0742
Validation loss decreased (0.107336 --> 0.107299).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.6258278
	speed: 0.0400s/iter; left time: 973.7862s
	iters: 200, epoch: 9 | loss: 33.5127220
	speed: 0.0550s/iter; left time: 1335.0688s
Epoch: 9 cost time: 13.044015407562256
Epoch: 9, Steps: 266 Train Loss: 32.0171 (Forecasting Loss:0.1416 + XiCon Loss:3.1875 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.5685272
	speed: 0.0393s/iter; left time: 947.1296s
	iters: 200, epoch: 10 | loss: 32.3496742
	speed: 0.0382s/iter; left time: 916.4264s
Epoch: 10 cost time: 10.336930274963379
Epoch: 10, Steps: 266 Train Loss: 32.0215 (Forecasting Loss:0.1416 + XiCon Loss:3.1880 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107299 --> 0.107284).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.6650829
	speed: 0.0413s/iter; left time: 984.4792s
	iters: 200, epoch: 11 | loss: 31.2091351
	speed: 0.0387s/iter; left time: 919.6450s
Epoch: 11 cost time: 10.551008939743042
Epoch: 11, Steps: 266 Train Loss: 31.8103 (Forecasting Loss:0.1415 + XiCon Loss:3.1669 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107284 --> 0.107251).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.5421429
	speed: 0.0407s/iter; left time: 959.4101s
	iters: 200, epoch: 12 | loss: 33.6391602
	speed: 0.0385s/iter; left time: 902.6740s
Epoch: 12 cost time: 10.42782187461853
Epoch: 12, Steps: 266 Train Loss: 31.9043 (Forecasting Loss:0.1415 + XiCon Loss:3.1763 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
Validation loss decreased (0.107251 --> 0.107245).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.1148491
	speed: 0.0409s/iter; left time: 952.5097s
	iters: 200, epoch: 13 | loss: 32.1052666
	speed: 0.0387s/iter; left time: 897.3652s
Epoch: 13 cost time: 10.53989839553833
Epoch: 13, Steps: 266 Train Loss: 31.9605 (Forecasting Loss:0.1415 + XiCon Loss:3.1819 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
Validation loss decreased (0.107245 --> 0.107234).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6586170
	speed: 0.0410s/iter; left time: 945.0917s
	iters: 200, epoch: 14 | loss: 30.8439255
	speed: 0.0403s/iter; left time: 924.6794s
Epoch: 14 cost time: 10.662802934646606
Epoch: 14, Steps: 266 Train Loss: 31.8821 (Forecasting Loss:0.1415 + XiCon Loss:3.1741 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.7590942
	speed: 0.0402s/iter; left time: 914.8593s
	iters: 200, epoch: 15 | loss: 30.6850529
	speed: 0.0384s/iter; left time: 870.4908s
Epoch: 15 cost time: 10.552513599395752
Epoch: 15, Steps: 266 Train Loss: 31.9118 (Forecasting Loss:0.1416 + XiCon Loss:3.1770 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.8417435
	speed: 0.0404s/iter; left time: 910.4147s
	iters: 200, epoch: 16 | loss: 33.0109978
	speed: 0.0378s/iter; left time: 847.8386s
Epoch: 16 cost time: 10.420900106430054
Epoch: 16, Steps: 266 Train Loss: 31.8617 (Forecasting Loss:0.1415 + XiCon Loss:3.1720 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.5404682
	speed: 0.0416s/iter; left time: 926.3692s
	iters: 200, epoch: 17 | loss: 32.6195374
	speed: 0.0389s/iter; left time: 861.3454s
Epoch: 17 cost time: 10.597904682159424
Epoch: 17, Steps: 266 Train Loss: 32.0736 (Forecasting Loss:0.1415 + XiCon Loss:3.1932 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
Validation loss decreased (0.107234 --> 0.107222).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.8155441
	speed: 0.0406s/iter; left time: 892.2082s
	iters: 200, epoch: 18 | loss: 31.5379829
	speed: 0.0379s/iter; left time: 828.7647s
Epoch: 18 cost time: 10.51961636543274
Epoch: 18, Steps: 266 Train Loss: 31.9151 (Forecasting Loss:0.1415 + XiCon Loss:3.1774 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
Validation loss decreased (0.107222 --> 0.107164).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.3009720
	speed: 0.0405s/iter; left time: 880.1149s
	iters: 200, epoch: 19 | loss: 33.5989151
	speed: 0.0390s/iter; left time: 842.2765s
Epoch: 19 cost time: 10.512097597122192
Epoch: 19, Steps: 266 Train Loss: 31.9600 (Forecasting Loss:0.1414 + XiCon Loss:3.1819 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.3538971
	speed: 0.0412s/iter; left time: 884.5115s
	iters: 200, epoch: 20 | loss: 31.8361893
	speed: 0.0389s/iter; left time: 830.1471s
Epoch: 20 cost time: 10.590173959732056
Epoch: 20, Steps: 266 Train Loss: 32.0276 (Forecasting Loss:0.1414 + XiCon Loss:3.1886 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
Validation loss decreased (0.107164 --> 0.107153).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.8038902
	speed: 0.0409s/iter; left time: 865.3729s
	iters: 200, epoch: 21 | loss: 31.5946846
	speed: 0.0399s/iter; left time: 841.9804s
Epoch: 21 cost time: 10.57990550994873
Epoch: 21, Steps: 266 Train Loss: 31.9530 (Forecasting Loss:0.1415 + XiCon Loss:3.1811 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.9321823
	speed: 0.0407s/iter; left time: 851.5877s
	iters: 200, epoch: 22 | loss: 33.2055893
	speed: 0.0383s/iter; left time: 797.8167s
Epoch: 22 cost time: 10.428794622421265
Epoch: 22, Steps: 266 Train Loss: 31.8378 (Forecasting Loss:0.1415 + XiCon Loss:3.1696 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.7744255
	speed: 0.0412s/iter; left time: 850.4206s
	iters: 200, epoch: 23 | loss: 30.2527618
	speed: 0.0381s/iter; left time: 782.0584s
Epoch: 23 cost time: 10.48884129524231
Epoch: 23, Steps: 266 Train Loss: 31.9340 (Forecasting Loss:0.1415 + XiCon Loss:3.1793 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.9363194
	speed: 0.0414s/iter; left time: 843.4515s
	iters: 200, epoch: 24 | loss: 32.1320419
	speed: 0.0388s/iter; left time: 787.8767s
Epoch: 24 cost time: 10.541478872299194
Epoch: 24, Steps: 266 Train Loss: 32.0291 (Forecasting Loss:0.1415 + XiCon Loss:3.1888 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.6809578
	speed: 0.0408s/iter; left time: 820.4381s
	iters: 200, epoch: 25 | loss: 30.8000641
	speed: 0.0380s/iter; left time: 760.6393s
Epoch: 25 cost time: 10.429938554763794
Epoch: 25, Steps: 266 Train Loss: 31.8875 (Forecasting Loss:0.1415 + XiCon Loss:3.1746 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.6487064
	speed: 0.0407s/iter; left time: 807.0124s
	iters: 200, epoch: 26 | loss: 31.1107082
	speed: 0.0389s/iter; left time: 768.4005s
Epoch: 26 cost time: 10.457858800888062
Epoch: 26, Steps: 266 Train Loss: 31.9210 (Forecasting Loss:0.1415 + XiCon Loss:3.1780 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.6787090
	speed: 0.0407s/iter; left time: 796.8982s
	iters: 200, epoch: 27 | loss: 31.4966927
	speed: 0.0399s/iter; left time: 777.7478s
Epoch: 27 cost time: 10.613810300827026
Epoch: 27, Steps: 266 Train Loss: 31.8825 (Forecasting Loss:0.1415 + XiCon Loss:3.1741 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.4915943
	speed: 0.0413s/iter; left time: 797.4786s
	iters: 200, epoch: 28 | loss: 30.7083664
	speed: 0.0387s/iter; left time: 742.8224s
Epoch: 28 cost time: 10.729580879211426
Epoch: 28, Steps: 266 Train Loss: 31.8825 (Forecasting Loss:0.1415 + XiCon Loss:3.1741 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.3179092
	speed: 0.0403s/iter; left time: 768.7209s
	iters: 200, epoch: 29 | loss: 31.6988239
	speed: 0.0379s/iter; left time: 718.7124s
Epoch: 29 cost time: 10.405787944793701
Epoch: 29, Steps: 266 Train Loss: 31.9128 (Forecasting Loss:0.1415 + XiCon Loss:3.1771 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.6273708
	speed: 0.0410s/iter; left time: 769.3860s
	iters: 200, epoch: 30 | loss: 32.7174568
	speed: 0.0385s/iter; left time: 718.8829s
Epoch: 30 cost time: 10.547091484069824
Epoch: 30, Steps: 266 Train Loss: 31.9384 (Forecasting Loss:0.1415 + XiCon Loss:3.1797 x Lambda(10.0)), Vali MSE Loss: 0.1072 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0263685155659914, mae:0.1218751072883606, mape:0.0985630601644516, mspe:0.019633708521723747 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6482
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.9514236
	speed: 0.0403s/iter; left time: 1067.6573s
	iters: 200, epoch: 1 | loss: 31.4267979
	speed: 0.0379s/iter; left time: 1001.2783s
Epoch: 1 cost time: 10.327264070510864
Epoch: 1, Steps: 266 Train Loss: 32.0661 (Forecasting Loss:0.1692 + XiCon Loss:3.1897 x Lambda(10.0)), Vali MSE Loss: 0.1166 Test MSE Loss: 0.0802
Validation loss decreased (inf --> 0.116590).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.2368050
	speed: 0.0405s/iter; left time: 1063.7710s
	iters: 200, epoch: 2 | loss: 32.3211403
	speed: 0.0392s/iter; left time: 1023.9540s
Epoch: 2 cost time: 10.641093254089355
Epoch: 2, Steps: 266 Train Loss: 33.1556 (Forecasting Loss:0.1510 + XiCon Loss:3.3005 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.0785
Validation loss decreased (0.116590 --> 0.113589).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6714745
	speed: 0.0411s/iter; left time: 1067.9334s
	iters: 200, epoch: 3 | loss: 31.6578712
	speed: 0.0391s/iter; left time: 1012.6436s
Epoch: 3 cost time: 10.599451780319214
Epoch: 3, Steps: 266 Train Loss: 32.2596 (Forecasting Loss:0.1455 + XiCon Loss:3.2114 x Lambda(10.0)), Vali MSE Loss: 0.1098 Test MSE Loss: 0.0756
Validation loss decreased (0.113589 --> 0.109840).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2357750
	speed: 0.0412s/iter; left time: 1059.1705s
	iters: 200, epoch: 4 | loss: 31.4027863
	speed: 0.0387s/iter; left time: 991.1872s
Epoch: 4 cost time: 10.62153172492981
Epoch: 4, Steps: 266 Train Loss: 31.2188 (Forecasting Loss:0.1436 + XiCon Loss:3.1075 x Lambda(10.0)), Vali MSE Loss: 0.1085 Test MSE Loss: 0.0750
Validation loss decreased (0.109840 --> 0.108540).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5397205
	speed: 0.0411s/iter; left time: 1046.0305s
	iters: 200, epoch: 5 | loss: 31.3082428
	speed: 0.0385s/iter; left time: 975.5753s
Epoch: 5 cost time: 10.547455310821533
Epoch: 5, Steps: 266 Train Loss: 30.9070 (Forecasting Loss:0.1426 + XiCon Loss:3.0764 x Lambda(10.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0744
Validation loss decreased (0.108540 --> 0.108129).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4090405
	speed: 0.0426s/iter; left time: 1072.3280s
	iters: 200, epoch: 6 | loss: 30.9347668
	speed: 0.0388s/iter; left time: 973.5655s
Epoch: 6 cost time: 10.69869875907898
Epoch: 6, Steps: 266 Train Loss: 30.8469 (Forecasting Loss:0.1421 + XiCon Loss:3.0705 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
Validation loss decreased (0.108129 --> 0.107627).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1098232
	speed: 0.0408s/iter; left time: 1017.1714s
	iters: 200, epoch: 7 | loss: 30.0622520
	speed: 0.0390s/iter; left time: 966.3001s
Epoch: 7 cost time: 10.620415449142456
Epoch: 7, Steps: 266 Train Loss: 30.7094 (Forecasting Loss:0.1418 + XiCon Loss:3.0568 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
Validation loss decreased (0.107627 --> 0.107588).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1269588
	speed: 0.0409s/iter; left time: 1008.0867s
	iters: 200, epoch: 8 | loss: 30.9587193
	speed: 0.0392s/iter; left time: 960.9246s
Epoch: 8 cost time: 10.568512916564941
Epoch: 8, Steps: 266 Train Loss: 30.7363 (Forecasting Loss:0.1417 + XiCon Loss:3.0595 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107588 --> 0.107439).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5331326
	speed: 0.0413s/iter; left time: 1007.6506s
	iters: 200, epoch: 9 | loss: 30.1830845
	speed: 0.0394s/iter; left time: 956.0806s
Epoch: 9 cost time: 10.62110686302185
Epoch: 9, Steps: 266 Train Loss: 30.6353 (Forecasting Loss:0.1417 + XiCon Loss:3.0494 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3416233
	speed: 0.0407s/iter; left time: 981.9679s
	iters: 200, epoch: 10 | loss: 30.7411633
	speed: 0.0400s/iter; left time: 961.3630s
Epoch: 10 cost time: 10.60673713684082
Epoch: 10, Steps: 266 Train Loss: 30.6922 (Forecasting Loss:0.1416 + XiCon Loss:3.0551 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107439 --> 0.107423).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8209190
	speed: 0.0412s/iter; left time: 981.6976s
	iters: 200, epoch: 11 | loss: 30.1059589
	speed: 0.0384s/iter; left time: 912.6323s
Epoch: 11 cost time: 10.539988040924072
Epoch: 11, Steps: 266 Train Loss: 30.6864 (Forecasting Loss:0.1416 + XiCon Loss:3.0545 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6773014
	speed: 0.0409s/iter; left time: 964.2562s
	iters: 200, epoch: 12 | loss: 30.8701820
	speed: 0.0389s/iter; left time: 912.1712s
Epoch: 12 cost time: 10.566195964813232
Epoch: 12, Steps: 266 Train Loss: 30.6233 (Forecasting Loss:0.1416 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2330914
	speed: 0.0417s/iter; left time: 972.2685s
	iters: 200, epoch: 13 | loss: 30.0650692
	speed: 0.0402s/iter; left time: 932.1602s
Epoch: 13 cost time: 10.731479406356812
Epoch: 13, Steps: 266 Train Loss: 30.6415 (Forecasting Loss:0.1416 + XiCon Loss:3.0500 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3021736
	speed: 0.0410s/iter; left time: 944.1127s
	iters: 200, epoch: 14 | loss: 30.8824120
	speed: 0.0389s/iter; left time: 891.5376s
Epoch: 14 cost time: 10.702452659606934
Epoch: 14, Steps: 266 Train Loss: 30.6579 (Forecasting Loss:0.1416 + XiCon Loss:3.0516 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.2424927
	speed: 0.0402s/iter; left time: 916.3969s
	iters: 200, epoch: 15 | loss: 31.2569656
	speed: 0.0388s/iter; left time: 879.0942s
Epoch: 15 cost time: 10.509843587875366
Epoch: 15, Steps: 266 Train Loss: 30.6780 (Forecasting Loss:0.1416 + XiCon Loss:3.0536 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.2554321
	speed: 0.0416s/iter; left time: 935.6642s
	iters: 200, epoch: 16 | loss: 30.0348911
	speed: 0.0392s/iter; left time: 877.6634s
Epoch: 16 cost time: 10.689640522003174
Epoch: 16, Steps: 266 Train Loss: 30.7133 (Forecasting Loss:0.1416 + XiCon Loss:3.0572 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.6882401
	speed: 0.0407s/iter; left time: 904.4466s
	iters: 200, epoch: 17 | loss: 30.6732635
	speed: 0.0382s/iter; left time: 846.7512s
Epoch: 17 cost time: 10.585395574569702
Epoch: 17, Steps: 266 Train Loss: 30.7073 (Forecasting Loss:0.1416 + XiCon Loss:3.0566 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107423 --> 0.107406).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.2529030
	speed: 0.0407s/iter; left time: 895.3919s
	iters: 200, epoch: 18 | loss: 30.9995308
	speed: 0.0386s/iter; left time: 843.7811s
Epoch: 18 cost time: 10.484324932098389
Epoch: 18, Steps: 266 Train Loss: 30.7044 (Forecasting Loss:0.1415 + XiCon Loss:3.0563 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7944965
	speed: 0.0428s/iter; left time: 929.3818s
	iters: 200, epoch: 19 | loss: 31.1270180
	speed: 0.0387s/iter; left time: 836.2293s
Epoch: 19 cost time: 10.730360746383667
Epoch: 19, Steps: 266 Train Loss: 30.7168 (Forecasting Loss:0.1415 + XiCon Loss:3.0575 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.0147781
	speed: 0.0408s/iter; left time: 874.8610s
	iters: 200, epoch: 20 | loss: 30.8413868
	speed: 0.0386s/iter; left time: 824.4861s
Epoch: 20 cost time: 10.524659156799316
Epoch: 20, Steps: 266 Train Loss: 30.6501 (Forecasting Loss:0.1416 + XiCon Loss:3.0508 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.7491837
	speed: 0.0412s/iter; left time: 872.1987s
	iters: 200, epoch: 21 | loss: 30.9190788
	speed: 0.0387s/iter; left time: 816.2636s
Epoch: 21 cost time: 10.570125341415405
Epoch: 21, Steps: 266 Train Loss: 30.7011 (Forecasting Loss:0.1416 + XiCon Loss:3.0559 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.0336018
	speed: 0.0425s/iter; left time: 887.8617s
	iters: 200, epoch: 22 | loss: 30.2631683
	speed: 0.0384s/iter; left time: 798.6795s
Epoch: 22 cost time: 10.630828857421875
Epoch: 22, Steps: 266 Train Loss: 30.6624 (Forecasting Loss:0.1416 + XiCon Loss:3.0521 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.7357426
	speed: 0.0398s/iter; left time: 822.3557s
	iters: 200, epoch: 23 | loss: 30.4470959
	speed: 0.0394s/iter; left time: 809.8913s
Epoch: 23 cost time: 10.478434085845947
Epoch: 23, Steps: 266 Train Loss: 30.6744 (Forecasting Loss:0.1416 + XiCon Loss:3.0533 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.0733337
	speed: 0.0414s/iter; left time: 844.7334s
	iters: 200, epoch: 24 | loss: 30.0511093
	speed: 0.0386s/iter; left time: 783.6927s
Epoch: 24 cost time: 10.607934474945068
Epoch: 24, Steps: 266 Train Loss: 30.6735 (Forecasting Loss:0.1415 + XiCon Loss:3.0532 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.2503452
	speed: 0.0400s/iter; left time: 804.8043s
	iters: 200, epoch: 25 | loss: 31.0189991
	speed: 0.0388s/iter; left time: 776.8302s
Epoch: 25 cost time: 10.492839813232422
Epoch: 25, Steps: 266 Train Loss: 30.6663 (Forecasting Loss:0.1416 + XiCon Loss:3.0525 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.6784649
	speed: 0.0426s/iter; left time: 846.2207s
	iters: 200, epoch: 26 | loss: 30.1435776
	speed: 0.0393s/iter; left time: 776.5135s
Epoch: 26 cost time: 10.774313688278198
Epoch: 26, Steps: 266 Train Loss: 30.6935 (Forecasting Loss:0.1416 + XiCon Loss:3.0552 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.0032234
	speed: 0.0406s/iter; left time: 794.5367s
	iters: 200, epoch: 27 | loss: 31.9926643
	speed: 0.0384s/iter; left time: 748.1879s
Epoch: 27 cost time: 10.54998230934143
Epoch: 27, Steps: 266 Train Loss: 30.6697 (Forecasting Loss:0.1416 + XiCon Loss:3.0528 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02639145217835903, mae:0.1219215989112854, mape:0.09850618243217468, mspe:0.019567517563700676 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6500
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.8160553
	speed: 0.0414s/iter; left time: 1095.8844s
	iters: 200, epoch: 1 | loss: 31.4688301
	speed: 0.0382s/iter; left time: 1008.4133s
Epoch: 1 cost time: 10.442708492279053
Epoch: 1, Steps: 266 Train Loss: 32.3676 (Forecasting Loss:0.1680 + XiCon Loss:3.2200 x Lambda(10.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.0798
Validation loss decreased (inf --> 0.115125).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.0016365
	speed: 0.0406s/iter; left time: 1066.2238s
	iters: 200, epoch: 2 | loss: 32.4251823
	speed: 0.0394s/iter; left time: 1030.7157s
Epoch: 2 cost time: 10.553160429000854
Epoch: 2, Steps: 266 Train Loss: 33.4314 (Forecasting Loss:0.1514 + XiCon Loss:3.3280 x Lambda(10.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.0766
Validation loss decreased (0.115125 --> 0.110527).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.6681499
	speed: 0.0405s/iter; left time: 1052.1045s
	iters: 200, epoch: 3 | loss: 31.7512188
	speed: 0.0383s/iter; left time: 990.2197s
Epoch: 3 cost time: 10.599108219146729
Epoch: 3, Steps: 266 Train Loss: 31.7678 (Forecasting Loss:0.1452 + XiCon Loss:3.1623 x Lambda(10.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.0753
Validation loss decreased (0.110527 --> 0.109112).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2921505
	speed: 0.0402s/iter; left time: 1034.4057s
	iters: 200, epoch: 4 | loss: 30.7753468
	speed: 0.0386s/iter; left time: 988.7584s
Epoch: 4 cost time: 10.451469898223877
Epoch: 4, Steps: 266 Train Loss: 31.5385 (Forecasting Loss:0.1436 + XiCon Loss:3.1395 x Lambda(10.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0747
Validation loss decreased (0.109112 --> 0.108084).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0177898
	speed: 0.0407s/iter; left time: 1034.7851s
	iters: 200, epoch: 5 | loss: 32.2716331
	speed: 0.0381s/iter; left time: 966.2796s
Epoch: 5 cost time: 10.41384768486023
Epoch: 5, Steps: 266 Train Loss: 31.3272 (Forecasting Loss:0.1424 + XiCon Loss:3.1185 x Lambda(10.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0744
Validation loss decreased (0.108084 --> 0.107793).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.6054878
	speed: 0.0402s/iter; left time: 1012.0195s
	iters: 200, epoch: 6 | loss: 30.9460640
	speed: 0.0391s/iter; left time: 981.0053s
Epoch: 6 cost time: 10.592555522918701
Epoch: 6, Steps: 266 Train Loss: 31.2005 (Forecasting Loss:0.1420 + XiCon Loss:3.1058 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107793 --> 0.107664).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.7461624
	speed: 0.0404s/iter; left time: 1006.6036s
	iters: 200, epoch: 7 | loss: 31.3509502
	speed: 0.0391s/iter; left time: 970.4786s
Epoch: 7 cost time: 10.48582649230957
Epoch: 7, Steps: 266 Train Loss: 31.1725 (Forecasting Loss:0.1418 + XiCon Loss:3.1031 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
Validation loss decreased (0.107664 --> 0.107505).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4789543
	speed: 0.0418s/iter; left time: 1030.0793s
	iters: 200, epoch: 8 | loss: 30.8647137
	speed: 0.0387s/iter; left time: 949.5393s
Epoch: 8 cost time: 10.585150480270386
Epoch: 8, Steps: 266 Train Loss: 31.1950 (Forecasting Loss:0.1417 + XiCon Loss:3.1053 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7774754
	speed: 0.0408s/iter; left time: 994.8902s
	iters: 200, epoch: 9 | loss: 30.7195892
	speed: 0.0396s/iter; left time: 960.2415s
Epoch: 9 cost time: 10.658320665359497
Epoch: 9, Steps: 266 Train Loss: 31.1448 (Forecasting Loss:0.1415 + XiCon Loss:3.1003 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.5368557
	speed: 0.0398s/iter; left time: 960.0441s
	iters: 200, epoch: 10 | loss: 30.6368084
	speed: 0.0386s/iter; left time: 925.7996s
Epoch: 10 cost time: 10.375718355178833
Epoch: 10, Steps: 266 Train Loss: 31.1239 (Forecasting Loss:0.1416 + XiCon Loss:3.0982 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
Validation loss decreased (0.107505 --> 0.107493).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4838066
	speed: 0.0414s/iter; left time: 985.8781s
	iters: 200, epoch: 11 | loss: 31.5607109
	speed: 0.0379s/iter; left time: 899.3245s
Epoch: 11 cost time: 10.44239616394043
Epoch: 11, Steps: 266 Train Loss: 31.1295 (Forecasting Loss:0.1415 + XiCon Loss:3.0988 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0744
Validation loss decreased (0.107493 --> 0.107405).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.4492855
	speed: 0.0404s/iter; left time: 952.1675s
	iters: 200, epoch: 12 | loss: 31.1482582
	speed: 0.0395s/iter; left time: 927.2541s
Epoch: 12 cost time: 10.591100692749023
Epoch: 12, Steps: 266 Train Loss: 31.1996 (Forecasting Loss:0.1415 + XiCon Loss:3.1058 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7900238
	speed: 0.0402s/iter; left time: 938.0418s
	iters: 200, epoch: 13 | loss: 30.6857872
	speed: 0.0387s/iter; left time: 897.8698s
Epoch: 13 cost time: 10.512846231460571
Epoch: 13, Steps: 266 Train Loss: 31.1707 (Forecasting Loss:0.1415 + XiCon Loss:3.1029 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.3283691
	speed: 0.0401s/iter; left time: 923.8416s
	iters: 200, epoch: 14 | loss: 31.5685844
	speed: 0.0386s/iter; left time: 884.9569s
Epoch: 14 cost time: 10.42661714553833
Epoch: 14, Steps: 266 Train Loss: 31.1007 (Forecasting Loss:0.1415 + XiCon Loss:3.0959 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.7115097
	speed: 0.0414s/iter; left time: 943.8264s
	iters: 200, epoch: 15 | loss: 31.4021511
	speed: 0.0385s/iter; left time: 873.6290s
Epoch: 15 cost time: 10.551889896392822
Epoch: 15, Steps: 266 Train Loss: 31.1935 (Forecasting Loss:0.1415 + XiCon Loss:3.1052 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0744
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8883514
	speed: 0.0412s/iter; left time: 927.1639s
	iters: 200, epoch: 16 | loss: 31.1937599
	speed: 0.0385s/iter; left time: 862.4401s
Epoch: 16 cost time: 10.578147649765015
Epoch: 16, Steps: 266 Train Loss: 31.1097 (Forecasting Loss:0.1415 + XiCon Loss:3.0968 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.5979481
	speed: 0.0402s/iter; left time: 894.4900s
	iters: 200, epoch: 17 | loss: 30.5132771
	speed: 0.0387s/iter; left time: 857.8001s
Epoch: 17 cost time: 10.47504711151123
Epoch: 17, Steps: 266 Train Loss: 31.0966 (Forecasting Loss:0.1415 + XiCon Loss:3.0955 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.4394608
	speed: 0.0415s/iter; left time: 911.7369s
	iters: 200, epoch: 18 | loss: 31.2043247
	speed: 0.0385s/iter; left time: 842.4727s
Epoch: 18 cost time: 10.599497556686401
Epoch: 18, Steps: 266 Train Loss: 31.1286 (Forecasting Loss:0.1415 + XiCon Loss:3.0987 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5705204
	speed: 0.0411s/iter; left time: 892.6123s
	iters: 200, epoch: 19 | loss: 30.5096188
	speed: 0.0392s/iter; left time: 846.2074s
Epoch: 19 cost time: 10.654614925384521
Epoch: 19, Steps: 266 Train Loss: 31.1636 (Forecasting Loss:0.1415 + XiCon Loss:3.1022 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.4857674
	speed: 0.0411s/iter; left time: 881.3505s
	iters: 200, epoch: 20 | loss: 30.6720963
	speed: 0.0387s/iter; left time: 826.7402s
Epoch: 20 cost time: 10.515035629272461
Epoch: 20, Steps: 266 Train Loss: 31.1733 (Forecasting Loss:0.1415 + XiCon Loss:3.1032 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.6377964
	speed: 0.0412s/iter; left time: 872.0906s
	iters: 200, epoch: 21 | loss: 30.8502045
	speed: 0.0384s/iter; left time: 809.1763s
Epoch: 21 cost time: 10.464335680007935
Epoch: 21, Steps: 266 Train Loss: 31.1292 (Forecasting Loss:0.1415 + XiCon Loss:3.0988 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0744
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02647491917014122, mae:0.12229929119348526, mape:0.0988122820854187, mspe:0.019623715430498123 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2163
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.3716125
	speed: 0.0413s/iter; left time: 1093.3032s
	iters: 200, epoch: 1 | loss: 31.4967918
	speed: 0.0383s/iter; left time: 1010.3037s
Epoch: 1 cost time: 10.55310344696045
Epoch: 1, Steps: 266 Train Loss: 32.4163 (Forecasting Loss:0.1711 + XiCon Loss:3.2245 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.0800
Validation loss decreased (inf --> 0.115585).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.7580185
	speed: 0.0403s/iter; left time: 1055.9689s
	iters: 200, epoch: 2 | loss: 30.8632050
	speed: 0.0393s/iter; left time: 1027.3524s
Epoch: 2 cost time: 10.525369882583618
Epoch: 2, Steps: 266 Train Loss: 32.9377 (Forecasting Loss:0.1503 + XiCon Loss:3.2787 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.0760
Validation loss decreased (0.115585 --> 0.111422).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.4157906
	speed: 0.0421s/iter; left time: 1092.0530s
	iters: 200, epoch: 3 | loss: 31.6585083
	speed: 0.0397s/iter; left time: 1026.5243s
Epoch: 3 cost time: 10.731580972671509
Epoch: 3, Steps: 266 Train Loss: 31.3720 (Forecasting Loss:0.1451 + XiCon Loss:3.1227 x Lambda(10.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.0756
Validation loss decreased (0.111422 --> 0.110045).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5382996
	speed: 0.0404s/iter; left time: 1037.2010s
	iters: 200, epoch: 4 | loss: 32.1426506
	speed: 0.0394s/iter; left time: 1009.6784s
Epoch: 4 cost time: 10.545074939727783
Epoch: 4, Steps: 266 Train Loss: 31.2829 (Forecasting Loss:0.1434 + XiCon Loss:3.1139 x Lambda(10.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0747
Validation loss decreased (0.110045 --> 0.108395).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7743092
	speed: 0.0415s/iter; left time: 1056.6276s
	iters: 200, epoch: 5 | loss: 30.8143654
	speed: 0.0383s/iter; left time: 969.9900s
Epoch: 5 cost time: 10.600244760513306
Epoch: 5, Steps: 266 Train Loss: 31.1657 (Forecasting Loss:0.1426 + XiCon Loss:3.1023 x Lambda(10.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0741
Validation loss decreased (0.108395 --> 0.108095).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.8850651
	speed: 0.0426s/iter; left time: 1072.9310s
	iters: 200, epoch: 6 | loss: 32.1003914
	speed: 0.0400s/iter; left time: 1002.9812s
Epoch: 6 cost time: 10.897748947143555
Epoch: 6, Steps: 266 Train Loss: 31.1001 (Forecasting Loss:0.1420 + XiCon Loss:3.0958 x Lambda(10.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0742
Validation loss decreased (0.108095 --> 0.107843).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1273308
	speed: 0.0412s/iter; left time: 1026.8218s
	iters: 200, epoch: 7 | loss: 31.0950508
	speed: 0.0395s/iter; left time: 980.8506s
Epoch: 7 cost time: 10.66087007522583
Epoch: 7, Steps: 266 Train Loss: 31.1315 (Forecasting Loss:0.1418 + XiCon Loss:3.0990 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0741
Validation loss decreased (0.107843 --> 0.107698).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.6515827
	speed: 0.0416s/iter; left time: 1023.7612s
	iters: 200, epoch: 8 | loss: 30.6035156
	speed: 0.0387s/iter; left time: 948.8264s
Epoch: 8 cost time: 10.633974552154541
Epoch: 8, Steps: 266 Train Loss: 31.1132 (Forecasting Loss:0.1416 + XiCon Loss:3.0972 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.6176109
	speed: 0.0418s/iter; left time: 1019.8244s
	iters: 200, epoch: 9 | loss: 30.3975983
	speed: 0.0389s/iter; left time: 944.3660s
Epoch: 9 cost time: 10.615461111068726
Epoch: 9, Steps: 266 Train Loss: 31.0631 (Forecasting Loss:0.1416 + XiCon Loss:3.0922 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107698 --> 0.107636).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6585751
	speed: 0.0421s/iter; left time: 1014.9010s
	iters: 200, epoch: 10 | loss: 31.2376804
	speed: 0.0402s/iter; left time: 964.5980s
Epoch: 10 cost time: 10.824305772781372
Epoch: 10, Steps: 266 Train Loss: 31.0947 (Forecasting Loss:0.1415 + XiCon Loss:3.0953 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107636 --> 0.107594).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.0040646
	speed: 0.0413s/iter; left time: 983.8225s
	iters: 200, epoch: 11 | loss: 30.8582668
	speed: 0.0386s/iter; left time: 915.6530s
Epoch: 11 cost time: 10.639436483383179
Epoch: 11, Steps: 266 Train Loss: 31.0883 (Forecasting Loss:0.1415 + XiCon Loss:3.0947 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107594 --> 0.107590).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.2727604
	speed: 0.0409s/iter; left time: 964.3883s
	iters: 200, epoch: 12 | loss: 30.6550369
	speed: 0.0389s/iter; left time: 913.1997s
Epoch: 12 cost time: 10.624922275543213
Epoch: 12, Steps: 266 Train Loss: 31.0287 (Forecasting Loss:0.1415 + XiCon Loss:3.0887 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107590 --> 0.107564).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.9337921
	speed: 0.0425s/iter; left time: 991.2152s
	iters: 200, epoch: 13 | loss: 30.5759563
	speed: 0.0402s/iter; left time: 933.0666s
Epoch: 13 cost time: 10.838679790496826
Epoch: 13, Steps: 266 Train Loss: 31.0728 (Forecasting Loss:0.1415 + XiCon Loss:3.0931 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107564 --> 0.107550).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4993229
	speed: 0.0412s/iter; left time: 948.9089s
	iters: 200, epoch: 14 | loss: 30.5444012
	speed: 0.0402s/iter; left time: 922.7437s
Epoch: 14 cost time: 10.72117567062378
Epoch: 14, Steps: 266 Train Loss: 31.0641 (Forecasting Loss:0.1415 + XiCon Loss:3.0923 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.3762665
	speed: 0.0412s/iter; left time: 938.3247s
	iters: 200, epoch: 15 | loss: 31.0421257
	speed: 0.0399s/iter; left time: 904.7565s
Epoch: 15 cost time: 10.679250240325928
Epoch: 15, Steps: 266 Train Loss: 31.0678 (Forecasting Loss:0.1415 + XiCon Loss:3.0926 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.4942951
	speed: 0.0416s/iter; left time: 937.5505s
	iters: 200, epoch: 16 | loss: 30.5375729
	speed: 0.0386s/iter; left time: 865.0078s
Epoch: 16 cost time: 10.604777574539185
Epoch: 16, Steps: 266 Train Loss: 31.0808 (Forecasting Loss:0.1415 + XiCon Loss:3.0939 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.1085072
	speed: 0.0407s/iter; left time: 905.3455s
	iters: 200, epoch: 17 | loss: 31.1122551
	speed: 0.0402s/iter; left time: 890.4930s
Epoch: 17 cost time: 10.757821083068848
Epoch: 17, Steps: 266 Train Loss: 31.0604 (Forecasting Loss:0.1415 + XiCon Loss:3.0919 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4441147
	speed: 0.0423s/iter; left time: 930.4940s
	iters: 200, epoch: 18 | loss: 31.3885784
	speed: 0.0390s/iter; left time: 852.6992s
Epoch: 18 cost time: 10.748369216918945
Epoch: 18, Steps: 266 Train Loss: 31.0301 (Forecasting Loss:0.1415 + XiCon Loss:3.0889 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.2589321
	speed: 0.0418s/iter; left time: 907.2607s
	iters: 200, epoch: 19 | loss: 30.9145908
	speed: 0.0396s/iter; left time: 856.1515s
Epoch: 19 cost time: 10.691818237304688
Epoch: 19, Steps: 266 Train Loss: 31.0517 (Forecasting Loss:0.1416 + XiCon Loss:3.0910 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107550 --> 0.107517).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.6796608
	speed: 0.0428s/iter; left time: 917.0770s
	iters: 200, epoch: 20 | loss: 30.7393398
	speed: 0.0388s/iter; left time: 828.4675s
Epoch: 20 cost time: 10.790211915969849
Epoch: 20, Steps: 266 Train Loss: 31.1040 (Forecasting Loss:0.1415 + XiCon Loss:3.0963 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.8964672
	speed: 0.0408s/iter; left time: 863.7751s
	iters: 200, epoch: 21 | loss: 30.5474300
	speed: 0.0386s/iter; left time: 813.8060s
Epoch: 21 cost time: 10.580850839614868
Epoch: 21, Steps: 266 Train Loss: 31.0974 (Forecasting Loss:0.1415 + XiCon Loss:3.0956 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.6424522
	speed: 0.0415s/iter; left time: 868.8327s
	iters: 200, epoch: 22 | loss: 31.2780342
	speed: 0.0396s/iter; left time: 824.9864s
Epoch: 22 cost time: 10.698022365570068
Epoch: 22, Steps: 266 Train Loss: 31.0773 (Forecasting Loss:0.1415 + XiCon Loss:3.0936 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.8209152
	speed: 0.0422s/iter; left time: 871.1330s
	iters: 200, epoch: 23 | loss: 30.7199707
	speed: 0.0394s/iter; left time: 810.4160s
Epoch: 23 cost time: 10.764174938201904
Epoch: 23, Steps: 266 Train Loss: 31.0651 (Forecasting Loss:0.1415 + XiCon Loss:3.0924 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.4239559
	speed: 0.0414s/iter; left time: 843.2532s
	iters: 200, epoch: 24 | loss: 30.8202477
	speed: 0.0399s/iter; left time: 809.7610s
Epoch: 24 cost time: 10.76180362701416
Epoch: 24, Steps: 266 Train Loss: 31.0554 (Forecasting Loss:0.1415 + XiCon Loss:3.0914 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.4267445
	speed: 0.0414s/iter; left time: 832.2185s
	iters: 200, epoch: 25 | loss: 30.6962681
	speed: 0.0387s/iter; left time: 775.4990s
Epoch: 25 cost time: 10.623723268508911
Epoch: 25, Steps: 266 Train Loss: 31.0635 (Forecasting Loss:0.1416 + XiCon Loss:3.0922 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.5672531
	speed: 0.0419s/iter; left time: 831.0731s
	iters: 200, epoch: 26 | loss: 30.7037468
	speed: 0.0390s/iter; left time: 769.9958s
Epoch: 26 cost time: 10.6850106716156
Epoch: 26, Steps: 266 Train Loss: 31.0839 (Forecasting Loss:0.1416 + XiCon Loss:3.0942 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.8265038
	speed: 0.0413s/iter; left time: 808.2333s
	iters: 200, epoch: 27 | loss: 30.4648781
	speed: 0.0393s/iter; left time: 766.2807s
Epoch: 27 cost time: 10.641728639602661
Epoch: 27, Steps: 266 Train Loss: 31.1229 (Forecasting Loss:0.1416 + XiCon Loss:3.0981 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 31.6972866
	speed: 0.0425s/iter; left time: 821.2802s
	iters: 200, epoch: 28 | loss: 32.4078217
	speed: 0.0393s/iter; left time: 754.3935s
Epoch: 28 cost time: 10.833227396011353
Epoch: 28, Steps: 266 Train Loss: 31.0882 (Forecasting Loss:0.1415 + XiCon Loss:3.0947 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.5018787
	speed: 0.0414s/iter; left time: 788.0493s
	iters: 200, epoch: 29 | loss: 31.8091602
	speed: 0.0396s/iter; left time: 750.8727s
Epoch: 29 cost time: 10.768588542938232
Epoch: 29, Steps: 266 Train Loss: 31.0721 (Forecasting Loss:0.1415 + XiCon Loss:3.0931 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0262816920876503, mae:0.1217278465628624, mape:0.0986117571592331, mspe:0.019778426736593246 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0264+-0.00009, MAE:0.1219+-0.00026, MAPE:0.0986+-0.00017, MSPE:0.0196+-0.00011, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8657
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.5598412
	speed: 0.0528s/iter; left time: 1394.3219s
	iters: 200, epoch: 1 | loss: 30.5775146
	speed: 0.0466s/iter; left time: 1224.4682s
Epoch: 1 cost time: 12.987102508544922
Epoch: 1, Steps: 265 Train Loss: 31.4666 (Forecasting Loss:0.2098 + XiCon Loss:3.1257 x Lambda(10.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.148200).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.6364098
	speed: 0.0531s/iter; left time: 1387.4708s
	iters: 200, epoch: 2 | loss: 33.1038666
	speed: 0.0490s/iter; left time: 1275.0530s
Epoch: 2 cost time: 13.39609694480896
Epoch: 2, Steps: 265 Train Loss: 32.8163 (Forecasting Loss:0.1984 + XiCon Loss:3.2618 x Lambda(10.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0961
Validation loss decreased (0.148200 --> 0.145595).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.4671593
	speed: 0.0526s/iter; left time: 1360.8558s
	iters: 200, epoch: 3 | loss: 32.5942535
	speed: 0.0501s/iter; left time: 1292.4027s
Epoch: 3 cost time: 13.430450201034546
Epoch: 3, Steps: 265 Train Loss: 32.5477 (Forecasting Loss:0.1931 + XiCon Loss:3.2355 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0957
Validation loss decreased (0.145595 --> 0.143847).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5315704
	speed: 0.0503s/iter; left time: 1288.5449s
	iters: 200, epoch: 4 | loss: 31.4614334
	speed: 0.0489s/iter; left time: 1246.0964s
Epoch: 4 cost time: 13.08526873588562
Epoch: 4, Steps: 265 Train Loss: 31.4452 (Forecasting Loss:0.1912 + XiCon Loss:3.1254 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8959217
	speed: 0.0507s/iter; left time: 1284.3138s
	iters: 200, epoch: 5 | loss: 31.5007973
	speed: 0.0485s/iter; left time: 1225.0283s
Epoch: 5 cost time: 13.175249099731445
Epoch: 5, Steps: 265 Train Loss: 31.4313 (Forecasting Loss:0.1905 + XiCon Loss:3.1241 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0951
Validation loss decreased (0.143847 --> 0.142629).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.3960648
	speed: 0.0509s/iter; left time: 1277.4709s
	iters: 200, epoch: 6 | loss: 30.9122467
	speed: 0.0500s/iter; left time: 1247.7999s
Epoch: 6 cost time: 13.337568044662476
Epoch: 6, Steps: 265 Train Loss: 31.5212 (Forecasting Loss:0.1898 + XiCon Loss:3.1331 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0944
Validation loss decreased (0.142629 --> 0.142165).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2080536
	speed: 0.0523s/iter; left time: 1297.0036s
	iters: 200, epoch: 7 | loss: 32.3041039
	speed: 0.0492s/iter; left time: 1215.3048s
Epoch: 7 cost time: 13.350216627120972
Epoch: 7, Steps: 265 Train Loss: 31.9410 (Forecasting Loss:0.1895 + XiCon Loss:3.1752 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.7167854
	speed: 0.0532s/iter; left time: 1306.2320s
	iters: 200, epoch: 8 | loss: 32.7925644
	speed: 0.0507s/iter; left time: 1239.5092s
Epoch: 8 cost time: 13.563534021377563
Epoch: 8, Steps: 265 Train Loss: 31.8200 (Forecasting Loss:0.1894 + XiCon Loss:3.1631 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.6735802
	speed: 0.0508s/iter; left time: 1232.2635s
	iters: 200, epoch: 9 | loss: 30.9831486
	speed: 0.0507s/iter; left time: 1226.2169s
Epoch: 9 cost time: 13.275737524032593
Epoch: 9, Steps: 265 Train Loss: 31.8097 (Forecasting Loss:0.1892 + XiCon Loss:3.1620 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
Validation loss decreased (0.142165 --> 0.142054).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7757988
	speed: 0.0520s/iter; left time: 1248.4002s
	iters: 200, epoch: 10 | loss: 31.7776413
	speed: 0.0494s/iter; left time: 1182.5442s
Epoch: 10 cost time: 13.365708351135254
Epoch: 10, Steps: 265 Train Loss: 31.8097 (Forecasting Loss:0.1892 + XiCon Loss:3.1621 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
Validation loss decreased (0.142054 --> 0.141979).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.3132229
	speed: 0.0507s/iter; left time: 1204.1981s
	iters: 200, epoch: 11 | loss: 30.9633675
	speed: 0.0507s/iter; left time: 1198.0747s
Epoch: 11 cost time: 13.526925086975098
Epoch: 11, Steps: 265 Train Loss: 31.8018 (Forecasting Loss:0.1892 + XiCon Loss:3.1613 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7315998
	speed: 0.0505s/iter; left time: 1186.6613s
	iters: 200, epoch: 12 | loss: 31.7642250
	speed: 0.0495s/iter; left time: 1156.6879s
Epoch: 12 cost time: 13.291887760162354
Epoch: 12, Steps: 265 Train Loss: 31.7876 (Forecasting Loss:0.1891 + XiCon Loss:3.1598 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
Validation loss decreased (0.141979 --> 0.141951).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2846394
	speed: 0.0509s/iter; left time: 1182.7647s
	iters: 200, epoch: 13 | loss: 31.9031563
	speed: 0.0503s/iter; left time: 1163.7981s
Epoch: 13 cost time: 13.345258474349976
Epoch: 13, Steps: 265 Train Loss: 31.8288 (Forecasting Loss:0.1891 + XiCon Loss:3.1640 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.9923382
	speed: 0.0521s/iter; left time: 1194.9745s
	iters: 200, epoch: 14 | loss: 30.5047932
	speed: 0.0496s/iter; left time: 1132.7505s
Epoch: 14 cost time: 13.463003396987915
Epoch: 14, Steps: 265 Train Loss: 31.8237 (Forecasting Loss:0.1892 + XiCon Loss:3.1635 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.6153946
	speed: 0.0534s/iter; left time: 1211.2610s
	iters: 200, epoch: 15 | loss: 31.3875103
	speed: 0.0490s/iter; left time: 1106.6503s
Epoch: 15 cost time: 13.392462015151978
Epoch: 15, Steps: 265 Train Loss: 31.7634 (Forecasting Loss:0.1890 + XiCon Loss:3.1574 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4638748
	speed: 0.0514s/iter; left time: 1152.2285s
	iters: 200, epoch: 16 | loss: 32.3415833
	speed: 0.0498s/iter; left time: 1112.6644s
Epoch: 16 cost time: 13.416887760162354
Epoch: 16, Steps: 265 Train Loss: 31.7114 (Forecasting Loss:0.1891 + XiCon Loss:3.1522 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.141951 --> 0.141903).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.7499084
	speed: 0.0512s/iter; left time: 1134.1222s
	iters: 200, epoch: 17 | loss: 32.4847031
	speed: 0.0503s/iter; left time: 1109.6023s
Epoch: 17 cost time: 13.401130437850952
Epoch: 17, Steps: 265 Train Loss: 31.7918 (Forecasting Loss:0.1891 + XiCon Loss:3.1603 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.8413620
	speed: 0.0513s/iter; left time: 1122.7482s
	iters: 200, epoch: 18 | loss: 32.0333176
	speed: 0.0497s/iter; left time: 1083.1753s
Epoch: 18 cost time: 13.49452829360962
Epoch: 18, Steps: 265 Train Loss: 31.8529 (Forecasting Loss:0.1890 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.4859810
	speed: 0.0517s/iter; left time: 1118.4689s
	iters: 200, epoch: 19 | loss: 32.3062134
	speed: 0.0496s/iter; left time: 1067.7671s
Epoch: 19 cost time: 13.435776710510254
Epoch: 19, Steps: 265 Train Loss: 31.9134 (Forecasting Loss:0.1891 + XiCon Loss:3.1724 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.4778328
	speed: 0.0509s/iter; left time: 1088.4018s
	iters: 200, epoch: 20 | loss: 32.9642296
	speed: 0.0497s/iter; left time: 1057.6331s
Epoch: 20 cost time: 13.295125484466553
Epoch: 20, Steps: 265 Train Loss: 31.8210 (Forecasting Loss:0.1891 + XiCon Loss:3.1632 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.7284851
	speed: 0.0512s/iter; left time: 1080.0458s
	iters: 200, epoch: 21 | loss: 31.4224548
	speed: 0.0487s/iter; left time: 1022.9778s
Epoch: 21 cost time: 13.23122262954712
Epoch: 21, Steps: 265 Train Loss: 31.8666 (Forecasting Loss:0.1890 + XiCon Loss:3.1678 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.0401382
	speed: 0.0516s/iter; left time: 1075.4985s
	iters: 200, epoch: 22 | loss: 32.5683327
	speed: 0.0492s/iter; left time: 1020.1983s
Epoch: 22 cost time: 13.289472818374634
Epoch: 22, Steps: 265 Train Loss: 31.8157 (Forecasting Loss:0.1890 + XiCon Loss:3.1627 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.7223701
	speed: 0.0524s/iter; left time: 1078.2512s
	iters: 200, epoch: 23 | loss: 33.0749435
	speed: 0.0507s/iter; left time: 1037.9128s
Epoch: 23 cost time: 13.62254786491394
Epoch: 23, Steps: 265 Train Loss: 31.8602 (Forecasting Loss:0.1892 + XiCon Loss:3.1671 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.8171959
	speed: 0.0519s/iter; left time: 1053.0774s
	iters: 200, epoch: 24 | loss: 31.6414871
	speed: 0.0500s/iter; left time: 1009.3631s
Epoch: 24 cost time: 13.362367391586304
Epoch: 24, Steps: 265 Train Loss: 31.7497 (Forecasting Loss:0.1891 + XiCon Loss:3.1561 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.8919106
	speed: 0.0511s/iter; left time: 1024.5260s
	iters: 200, epoch: 25 | loss: 30.0270233
	speed: 0.0495s/iter; left time: 986.4756s
Epoch: 25 cost time: 13.421746730804443
Epoch: 25, Steps: 265 Train Loss: 31.7385 (Forecasting Loss:0.1891 + XiCon Loss:3.1549 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.6357193
	speed: 0.0509s/iter; left time: 1007.3950s
	iters: 200, epoch: 26 | loss: 31.9863758
	speed: 0.0493s/iter; left time: 970.0687s
Epoch: 26 cost time: 13.24049162864685
Epoch: 26, Steps: 265 Train Loss: 31.8358 (Forecasting Loss:0.1891 + XiCon Loss:3.1647 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03937326371669769, mae:0.1494835466146469, mape:0.1186443567276001, mspe:0.026347510516643524 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3228
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.9554501
	speed: 0.0506s/iter; left time: 1335.4593s
	iters: 200, epoch: 1 | loss: 30.2868347
	speed: 0.0466s/iter; left time: 1226.5231s
Epoch: 1 cost time: 12.810234546661377
Epoch: 1, Steps: 265 Train Loss: 31.3456 (Forecasting Loss:0.2122 + XiCon Loss:3.1133 x Lambda(10.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.146774).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.6451874
	speed: 0.0528s/iter; left time: 1380.8984s
	iters: 200, epoch: 2 | loss: 33.5912094
	speed: 0.0488s/iter; left time: 1270.7741s
Epoch: 2 cost time: 13.308419704437256
Epoch: 2, Steps: 265 Train Loss: 33.4501 (Forecasting Loss:0.1981 + XiCon Loss:3.3252 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0973
Validation loss decreased (0.146774 --> 0.146369).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4350414
	speed: 0.0508s/iter; left time: 1315.2013s
	iters: 200, epoch: 3 | loss: 31.1939487
	speed: 0.0500s/iter; left time: 1287.9896s
Epoch: 3 cost time: 13.251308917999268
Epoch: 3, Steps: 265 Train Loss: 32.2754 (Forecasting Loss:0.1929 + XiCon Loss:3.2082 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0952
Validation loss decreased (0.146369 --> 0.143729).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.8919468
	speed: 0.0515s/iter; left time: 1319.7289s
	iters: 200, epoch: 4 | loss: 32.1872787
	speed: 0.0488s/iter; left time: 1244.4252s
Epoch: 4 cost time: 13.34843397140503
Epoch: 4, Steps: 265 Train Loss: 32.3777 (Forecasting Loss:0.1915 + XiCon Loss:3.2186 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0948
Validation loss decreased (0.143729 --> 0.142169).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.2827320
	speed: 0.0503s/iter; left time: 1274.2660s
	iters: 200, epoch: 5 | loss: 31.7642002
	speed: 0.0494s/iter; left time: 1246.6150s
Epoch: 5 cost time: 13.291105270385742
Epoch: 5, Steps: 265 Train Loss: 32.0367 (Forecasting Loss:0.1903 + XiCon Loss:3.1846 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.142169 --> 0.141719).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.7272186
	speed: 0.0519s/iter; left time: 1302.5140s
	iters: 200, epoch: 6 | loss: 31.2784443
	speed: 0.0495s/iter; left time: 1237.2624s
Epoch: 6 cost time: 13.352133512496948
Epoch: 6, Steps: 265 Train Loss: 32.0416 (Forecasting Loss:0.1899 + XiCon Loss:3.1852 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.7250671
	speed: 0.0776s/iter; left time: 1926.5739s
	iters: 200, epoch: 7 | loss: 32.4588852
	speed: 0.0474s/iter; left time: 1172.4926s
Epoch: 7 cost time: 15.699132204055786
Epoch: 7, Steps: 265 Train Loss: 32.0625 (Forecasting Loss:0.1896 + XiCon Loss:3.1873 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
Validation loss decreased (0.141719 --> 0.141501).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.5297737
	speed: 0.0507s/iter; left time: 1243.3373s
	iters: 200, epoch: 8 | loss: 31.2840004
	speed: 0.0500s/iter; left time: 1221.5874s
Epoch: 8 cost time: 13.421194553375244
Epoch: 8, Steps: 265 Train Loss: 31.9954 (Forecasting Loss:0.1894 + XiCon Loss:3.1806 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.7261696
	speed: 0.0509s/iter; left time: 1236.8115s
	iters: 200, epoch: 9 | loss: 32.1005135
	speed: 0.0493s/iter; left time: 1191.7685s
Epoch: 9 cost time: 13.353104591369629
Epoch: 9, Steps: 265 Train Loss: 31.9637 (Forecasting Loss:0.1893 + XiCon Loss:3.1774 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3083134
	speed: 0.0512s/iter; left time: 1229.4310s
	iters: 200, epoch: 10 | loss: 33.1889954
	speed: 0.0484s/iter; left time: 1157.2589s
Epoch: 10 cost time: 13.181640386581421
Epoch: 10, Steps: 265 Train Loss: 31.9016 (Forecasting Loss:0.1892 + XiCon Loss:3.1712 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.8214455
	speed: 0.0518s/iter; left time: 1230.5202s
	iters: 200, epoch: 11 | loss: 31.4514217
	speed: 0.0500s/iter; left time: 1182.8231s
Epoch: 11 cost time: 13.326554536819458
Epoch: 11, Steps: 265 Train Loss: 31.9574 (Forecasting Loss:0.1893 + XiCon Loss:3.1768 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.8163223
	speed: 0.0518s/iter; left time: 1216.1512s
	iters: 200, epoch: 12 | loss: 32.2429924
	speed: 0.0478s/iter; left time: 1117.6480s
Epoch: 12 cost time: 13.106077909469604
Epoch: 12, Steps: 265 Train Loss: 31.9408 (Forecasting Loss:0.1892 + XiCon Loss:3.1752 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.6649475
	speed: 0.0517s/iter; left time: 1201.6803s
	iters: 200, epoch: 13 | loss: 31.2170506
	speed: 0.0497s/iter; left time: 1148.3718s
Epoch: 13 cost time: 13.337833166122437
Epoch: 13, Steps: 265 Train Loss: 32.0540 (Forecasting Loss:0.1892 + XiCon Loss:3.1865 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8983154
	speed: 0.0516s/iter; left time: 1183.4230s
	iters: 200, epoch: 14 | loss: 32.1838036
	speed: 0.0513s/iter; left time: 1172.4766s
Epoch: 14 cost time: 13.54429841041565
Epoch: 14, Steps: 265 Train Loss: 31.8988 (Forecasting Loss:0.1893 + XiCon Loss:3.1709 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.7268562
	speed: 0.0515s/iter; left time: 1167.9079s
	iters: 200, epoch: 15 | loss: 32.8399048
	speed: 0.0503s/iter; left time: 1135.6775s
Epoch: 15 cost time: 13.590001106262207
Epoch: 15, Steps: 265 Train Loss: 31.9097 (Forecasting Loss:0.1892 + XiCon Loss:3.1721 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.6364346
	speed: 0.0510s/iter; left time: 1144.0607s
	iters: 200, epoch: 16 | loss: 32.2105789
	speed: 0.0495s/iter; left time: 1105.0220s
Epoch: 16 cost time: 13.307002544403076
Epoch: 16, Steps: 265 Train Loss: 31.9043 (Forecasting Loss:0.1891 + XiCon Loss:3.1715 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.5457916
	speed: 0.0501s/iter; left time: 1111.1677s
	iters: 200, epoch: 17 | loss: 33.2192764
	speed: 0.0490s/iter; left time: 1082.0882s
Epoch: 17 cost time: 13.167890310287476
Epoch: 17, Steps: 265 Train Loss: 31.9094 (Forecasting Loss:0.1892 + XiCon Loss:3.1720 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03931373357772827, mae:0.1496109813451767, mape:0.11903515458106995, mspe:0.02656531147658825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2028
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.5861702
	speed: 0.0501s/iter; left time: 1321.8703s
	iters: 200, epoch: 1 | loss: 30.9920101
	speed: 0.0479s/iter; left time: 1260.8942s
Epoch: 1 cost time: 12.79289722442627
Epoch: 1, Steps: 265 Train Loss: 31.3151 (Forecasting Loss:0.2115 + XiCon Loss:3.1104 x Lambda(10.0)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.147641).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.1986847
	speed: 0.0515s/iter; left time: 1346.3699s
	iters: 200, epoch: 2 | loss: 34.6198235
	speed: 0.0490s/iter; left time: 1274.9597s
Epoch: 2 cost time: 13.174117803573608
Epoch: 2, Steps: 265 Train Loss: 33.9575 (Forecasting Loss:0.1988 + XiCon Loss:3.3759 x Lambda(10.0)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.0977
Validation loss decreased (0.147641 --> 0.146628).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.6478767
	speed: 0.0498s/iter; left time: 1288.3057s
	iters: 200, epoch: 3 | loss: 31.0028534
	speed: 0.0499s/iter; left time: 1286.4917s
Epoch: 3 cost time: 13.243333578109741
Epoch: 3, Steps: 265 Train Loss: 31.8729 (Forecasting Loss:0.1928 + XiCon Loss:3.1680 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0954
Validation loss decreased (0.146628 --> 0.143081).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1527367
	speed: 0.0494s/iter; left time: 1266.1852s
	iters: 200, epoch: 4 | loss: 30.8900299
	speed: 0.0496s/iter; left time: 1264.9051s
Epoch: 4 cost time: 13.106242179870605
Epoch: 4, Steps: 265 Train Loss: 30.9913 (Forecasting Loss:0.1911 + XiCon Loss:3.0800 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0951
Validation loss decreased (0.143081 --> 0.142000).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.9454041
	speed: 0.0502s/iter; left time: 1273.3432s
	iters: 200, epoch: 5 | loss: 30.4994526
	speed: 0.0477s/iter; left time: 1203.9005s
Epoch: 5 cost time: 13.042926788330078
Epoch: 5, Steps: 265 Train Loss: 30.7353 (Forecasting Loss:0.1903 + XiCon Loss:3.0545 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1694145
	speed: 0.0516s/iter; left time: 1292.9221s
	iters: 200, epoch: 6 | loss: 30.7479515
	speed: 0.0492s/iter; left time: 1229.1426s
Epoch: 6 cost time: 13.255763292312622
Epoch: 6, Steps: 265 Train Loss: 30.6675 (Forecasting Loss:0.1899 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.142000 --> 0.141928).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.3993511
	speed: 0.0525s/iter; left time: 1301.7311s
	iters: 200, epoch: 7 | loss: 31.4996929
	speed: 0.0491s/iter; left time: 1214.3090s
Epoch: 7 cost time: 13.395072221755981
Epoch: 7, Steps: 265 Train Loss: 30.6587 (Forecasting Loss:0.1896 + XiCon Loss:3.0469 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141928 --> 0.141696).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1339684
	speed: 0.0513s/iter; left time: 1260.2409s
	iters: 200, epoch: 8 | loss: 30.1583595
	speed: 0.0504s/iter; left time: 1233.0002s
Epoch: 8 cost time: 13.470062255859375
Epoch: 8, Steps: 265 Train Loss: 30.6359 (Forecasting Loss:0.1894 + XiCon Loss:3.0446 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1133518
	speed: 0.0521s/iter; left time: 1264.6879s
	iters: 200, epoch: 9 | loss: 30.0867310
	speed: 0.0495s/iter; left time: 1196.1730s
Epoch: 9 cost time: 13.397262334823608
Epoch: 9, Steps: 265 Train Loss: 30.6378 (Forecasting Loss:0.1893 + XiCon Loss:3.0448 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3614159
	speed: 0.0506s/iter; left time: 1214.8911s
	iters: 200, epoch: 10 | loss: 29.9913254
	speed: 0.0499s/iter; left time: 1193.9395s
Epoch: 10 cost time: 13.402895450592041
Epoch: 10, Steps: 265 Train Loss: 30.6149 (Forecasting Loss:0.1893 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141696 --> 0.141653).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0086098
	speed: 0.0511s/iter; left time: 1212.9079s
	iters: 200, epoch: 11 | loss: 30.3499374
	speed: 0.0500s/iter; left time: 1183.0377s
Epoch: 11 cost time: 13.288835763931274
Epoch: 11, Steps: 265 Train Loss: 30.6205 (Forecasting Loss:0.1893 + XiCon Loss:3.0431 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8062153
	speed: 0.0515s/iter; left time: 1209.4824s
	iters: 200, epoch: 12 | loss: 30.7271614
	speed: 0.0492s/iter; left time: 1149.7242s
Epoch: 12 cost time: 13.318235397338867
Epoch: 12, Steps: 265 Train Loss: 30.5989 (Forecasting Loss:0.1892 + XiCon Loss:3.0410 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4590569
	speed: 0.0521s/iter; left time: 1209.2041s
	iters: 200, epoch: 13 | loss: 30.3241291
	speed: 0.0485s/iter; left time: 1120.6648s
Epoch: 13 cost time: 13.282669305801392
Epoch: 13, Steps: 265 Train Loss: 30.6063 (Forecasting Loss:0.1893 + XiCon Loss:3.0417 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8291225
	speed: 0.0524s/iter; left time: 1203.5170s
	iters: 200, epoch: 14 | loss: 30.1663246
	speed: 0.0499s/iter; left time: 1139.5282s
Epoch: 14 cost time: 13.46970248222351
Epoch: 14, Steps: 265 Train Loss: 30.5938 (Forecasting Loss:0.1893 + XiCon Loss:3.0405 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2635040
	speed: 0.0509s/iter; left time: 1155.7489s
	iters: 200, epoch: 15 | loss: 30.4337597
	speed: 0.0502s/iter; left time: 1134.1049s
Epoch: 15 cost time: 13.290279388427734
Epoch: 15, Steps: 265 Train Loss: 30.5683 (Forecasting Loss:0.1892 + XiCon Loss:3.0379 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141653 --> 0.141604).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.1203461
	speed: 0.0500s/iter; left time: 1120.7008s
	iters: 200, epoch: 16 | loss: 30.9858971
	speed: 0.0501s/iter; left time: 1118.5270s
Epoch: 16 cost time: 13.281504392623901
Epoch: 16, Steps: 265 Train Loss: 30.6058 (Forecasting Loss:0.1893 + XiCon Loss:3.0417 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4102211
	speed: 0.0515s/iter; left time: 1140.8322s
	iters: 200, epoch: 17 | loss: 30.3208675
	speed: 0.0491s/iter; left time: 1083.4412s
Epoch: 17 cost time: 13.327826976776123
Epoch: 17, Steps: 265 Train Loss: 30.5721 (Forecasting Loss:0.1893 + XiCon Loss:3.0383 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2748375
	speed: 0.0510s/iter; left time: 1117.6294s
	iters: 200, epoch: 18 | loss: 30.3373852
	speed: 0.0486s/iter; left time: 1059.5173s
Epoch: 18 cost time: 13.173906803131104
Epoch: 18, Steps: 265 Train Loss: 30.5987 (Forecasting Loss:0.1893 + XiCon Loss:3.0409 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2920780
	speed: 0.0527s/iter; left time: 1139.2376s
	iters: 200, epoch: 19 | loss: 31.8680687
	speed: 0.0489s/iter; left time: 1052.2835s
Epoch: 19 cost time: 13.312559366226196
Epoch: 19, Steps: 265 Train Loss: 30.5931 (Forecasting Loss:0.1892 + XiCon Loss:3.0404 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.4002724
	speed: 0.0523s/iter; left time: 1117.1245s
	iters: 200, epoch: 20 | loss: 29.9808826
	speed: 0.0484s/iter; left time: 1028.4984s
Epoch: 20 cost time: 13.376261234283447
Epoch: 20, Steps: 265 Train Loss: 30.5942 (Forecasting Loss:0.1893 + XiCon Loss:3.0405 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.0424023
	speed: 0.0517s/iter; left time: 1090.4801s
	iters: 200, epoch: 21 | loss: 30.0674171
	speed: 0.0497s/iter; left time: 1044.2854s
Epoch: 21 cost time: 13.307274580001831
Epoch: 21, Steps: 265 Train Loss: 30.6492 (Forecasting Loss:0.1892 + XiCon Loss:3.0460 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.0505333
	speed: 0.0517s/iter; left time: 1077.6365s
	iters: 200, epoch: 22 | loss: 31.0354691
	speed: 0.0517s/iter; left time: 1071.0283s
Epoch: 22 cost time: 13.60500431060791
Epoch: 22, Steps: 265 Train Loss: 30.5990 (Forecasting Loss:0.1892 + XiCon Loss:3.0410 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.6785431
	speed: 0.0513s/iter; left time: 1055.6543s
	iters: 200, epoch: 23 | loss: 31.2121887
	speed: 0.0496s/iter; left time: 1015.7806s
Epoch: 23 cost time: 13.300790548324585
Epoch: 23, Steps: 265 Train Loss: 30.6139 (Forecasting Loss:0.1892 + XiCon Loss:3.0425 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6063805
	speed: 0.0503s/iter; left time: 1021.9953s
	iters: 200, epoch: 24 | loss: 31.8642864
	speed: 0.0488s/iter; left time: 985.6354s
Epoch: 24 cost time: 13.136569261550903
Epoch: 24, Steps: 265 Train Loss: 30.6020 (Forecasting Loss:0.1892 + XiCon Loss:3.0413 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.5975857
	speed: 0.0507s/iter; left time: 1016.3923s
	iters: 200, epoch: 25 | loss: 30.5508919
	speed: 0.0489s/iter; left time: 975.8004s
Epoch: 25 cost time: 13.201489686965942
Epoch: 25, Steps: 265 Train Loss: 30.5869 (Forecasting Loss:0.1893 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039309486746788025, mae:0.14942683279514313, mape:0.11861205846071243, mspe:0.026305552572011948 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.0367
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.1177177
	speed: 0.0500s/iter; left time: 1320.6647s
	iters: 200, epoch: 1 | loss: 30.7181435
	speed: 0.0476s/iter; left time: 1251.3535s
Epoch: 1 cost time: 12.87398386001587
Epoch: 1, Steps: 265 Train Loss: 31.2299 (Forecasting Loss:0.2095 + XiCon Loss:3.1020 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1011
Validation loss decreased (inf --> 0.148570).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 42.3117447
	speed: 0.0525s/iter; left time: 1371.2266s
	iters: 200, epoch: 2 | loss: 37.0770416
	speed: 0.0504s/iter; left time: 1311.1157s
Epoch: 2 cost time: 13.432494163513184
Epoch: 2, Steps: 265 Train Loss: 35.1816 (Forecasting Loss:0.4557 + XiCon Loss:3.4726 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.0960
Validation loss decreased (0.148570 --> 0.144928).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.9287148
	speed: 0.0518s/iter; left time: 1339.6630s
	iters: 200, epoch: 3 | loss: 35.0732231
	speed: 0.0491s/iter; left time: 1265.5370s
Epoch: 3 cost time: 13.358150720596313
Epoch: 3, Steps: 265 Train Loss: 34.8666 (Forecasting Loss:0.1928 + XiCon Loss:3.4674 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0962
Validation loss decreased (0.144928 --> 0.143633).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 35.3958092
	speed: 0.0503s/iter; left time: 1287.3292s
	iters: 200, epoch: 4 | loss: 34.3337822
	speed: 0.0492s/iter; left time: 1255.5899s
Epoch: 4 cost time: 13.300275802612305
Epoch: 4, Steps: 265 Train Loss: 33.8974 (Forecasting Loss:0.1912 + XiCon Loss:3.3706 x Lambda(10.0)), Vali MSE Loss: 0.1407 Test MSE Loss: 0.0948
Validation loss decreased (0.143633 --> 0.140723).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.3475914
	speed: 0.0513s/iter; left time: 1300.1815s
	iters: 200, epoch: 5 | loss: 34.5775414
	speed: 0.0491s/iter; left time: 1239.2033s
Epoch: 5 cost time: 13.290427207946777
Epoch: 5, Steps: 265 Train Loss: 33.7197 (Forecasting Loss:0.1900 + XiCon Loss:3.3530 x Lambda(10.0)), Vali MSE Loss: 0.1410 Test MSE Loss: 0.0952
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.6726265
	speed: 0.0530s/iter; left time: 1327.8898s
	iters: 200, epoch: 6 | loss: 32.8427086
	speed: 0.0492s/iter; left time: 1228.5468s
Epoch: 6 cost time: 13.4660484790802
Epoch: 6, Steps: 265 Train Loss: 33.4758 (Forecasting Loss:0.1895 + XiCon Loss:3.3286 x Lambda(10.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.0948
Validation loss decreased (0.140723 --> 0.140643).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7779579
	speed: 0.0528s/iter; left time: 1309.6530s
	iters: 200, epoch: 7 | loss: 32.7403069
	speed: 0.0499s/iter; left time: 1233.9548s
Epoch: 7 cost time: 13.569941759109497
Epoch: 7, Steps: 265 Train Loss: 33.4553 (Forecasting Loss:0.1893 + XiCon Loss:3.3266 x Lambda(10.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.0948
Validation loss decreased (0.140643 --> 0.140628).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.3882866
	speed: 0.0519s/iter; left time: 1273.2171s
	iters: 200, epoch: 8 | loss: 31.6856327
	speed: 0.0500s/iter; left time: 1222.3963s
Epoch: 8 cost time: 13.46256422996521
Epoch: 8, Steps: 265 Train Loss: 33.4093 (Forecasting Loss:0.1892 + XiCon Loss:3.3220 x Lambda(10.0)), Vali MSE Loss: 0.1407 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.2014656
	speed: 0.0516s/iter; left time: 1253.0547s
	iters: 200, epoch: 9 | loss: 33.8070145
	speed: 0.0513s/iter; left time: 1239.4414s
Epoch: 9 cost time: 13.5158109664917
Epoch: 9, Steps: 265 Train Loss: 33.2801 (Forecasting Loss:0.1891 + XiCon Loss:3.3091 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
Validation loss decreased (0.140628 --> 0.140487).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.1895943
	speed: 0.0511s/iter; left time: 1226.2082s
	iters: 200, epoch: 10 | loss: 34.7638359
	speed: 0.0498s/iter; left time: 1191.2127s
Epoch: 10 cost time: 13.380060911178589
Epoch: 10, Steps: 265 Train Loss: 33.3691 (Forecasting Loss:0.1890 + XiCon Loss:3.3180 x Lambda(10.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 34.4035416
	speed: 0.0521s/iter; left time: 1238.6116s
	iters: 200, epoch: 11 | loss: 31.5176430
	speed: 0.0497s/iter; left time: 1175.8992s
Epoch: 11 cost time: 13.461138010025024
Epoch: 11, Steps: 265 Train Loss: 33.4279 (Forecasting Loss:0.1890 + XiCon Loss:3.3239 x Lambda(10.0)), Vali MSE Loss: 0.1406 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.8022346
	speed: 0.0506s/iter; left time: 1189.1070s
	iters: 200, epoch: 12 | loss: 31.6037827
	speed: 0.0520s/iter; left time: 1215.2846s
Epoch: 12 cost time: 13.463667154312134
Epoch: 12, Steps: 265 Train Loss: 33.3280 (Forecasting Loss:0.1889 + XiCon Loss:3.3139 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
Validation loss decreased (0.140487 --> 0.140482).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.7839317
	speed: 0.0533s/iter; left time: 1236.7482s
	iters: 200, epoch: 13 | loss: 33.0276222
	speed: 0.0494s/iter; left time: 1141.3317s
Epoch: 13 cost time: 13.502474546432495
Epoch: 13, Steps: 265 Train Loss: 33.4146 (Forecasting Loss:0.1890 + XiCon Loss:3.3226 x Lambda(10.0)), Vali MSE Loss: 0.1403 Test MSE Loss: 0.0946
Validation loss decreased (0.140482 --> 0.140342).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.9727287
	speed: 0.0519s/iter; left time: 1190.7051s
	iters: 200, epoch: 14 | loss: 34.8179169
	speed: 0.0482s/iter; left time: 1102.2508s
Epoch: 14 cost time: 13.222671031951904
Epoch: 14, Steps: 265 Train Loss: 33.2911 (Forecasting Loss:0.1891 + XiCon Loss:3.3102 x Lambda(10.0)), Vali MSE Loss: 0.1404 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 35.6054535
	speed: 0.0514s/iter; left time: 1165.6410s
	iters: 200, epoch: 15 | loss: 33.6891136
	speed: 0.0512s/iter; left time: 1157.6791s
Epoch: 15 cost time: 13.48502492904663
Epoch: 15, Steps: 265 Train Loss: 33.3687 (Forecasting Loss:0.1890 + XiCon Loss:3.3180 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.5737038
	speed: 0.0526s/iter; left time: 1178.9644s
	iters: 200, epoch: 16 | loss: 33.5240936
	speed: 0.0504s/iter; left time: 1125.4786s
Epoch: 16 cost time: 13.503634929656982
Epoch: 16, Steps: 265 Train Loss: 33.3314 (Forecasting Loss:0.1891 + XiCon Loss:3.3142 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.6162109
	speed: 0.0507s/iter; left time: 1123.8120s
	iters: 200, epoch: 17 | loss: 34.4545479
	speed: 0.0492s/iter; left time: 1085.4578s
Epoch: 17 cost time: 13.39009141921997
Epoch: 17, Steps: 265 Train Loss: 33.3676 (Forecasting Loss:0.1891 + XiCon Loss:3.3179 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 35.5638046
	speed: 0.0509s/iter; left time: 1115.4224s
	iters: 200, epoch: 18 | loss: 34.3483276
	speed: 0.0499s/iter; left time: 1087.7069s
Epoch: 18 cost time: 13.397634267807007
Epoch: 18, Steps: 265 Train Loss: 33.3814 (Forecasting Loss:0.1890 + XiCon Loss:3.3192 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 35.7137451
	speed: 0.0506s/iter; left time: 1093.7602s
	iters: 200, epoch: 19 | loss: 32.6181374
	speed: 0.0499s/iter; left time: 1074.2827s
Epoch: 19 cost time: 13.337818384170532
Epoch: 19, Steps: 265 Train Loss: 33.4141 (Forecasting Loss:0.1890 + XiCon Loss:3.3225 x Lambda(10.0)), Vali MSE Loss: 0.1404 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 36.3523064
	speed: 0.0525s/iter; left time: 1120.9889s
	iters: 200, epoch: 20 | loss: 32.6530533
	speed: 0.0494s/iter; left time: 1049.7630s
Epoch: 20 cost time: 13.399120569229126
Epoch: 20, Steps: 265 Train Loss: 33.2771 (Forecasting Loss:0.1890 + XiCon Loss:3.3088 x Lambda(10.0)), Vali MSE Loss: 0.1404 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.9095917
	speed: 0.0534s/iter; left time: 1127.6537s
	iters: 200, epoch: 21 | loss: 31.3457565
	speed: 0.0495s/iter; left time: 1038.9380s
Epoch: 21 cost time: 13.593527793884277
Epoch: 21, Steps: 265 Train Loss: 33.2681 (Forecasting Loss:0.1889 + XiCon Loss:3.3079 x Lambda(10.0)), Vali MSE Loss: 0.1404 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.7648544
	speed: 0.0514s/iter; left time: 1070.7445s
	iters: 200, epoch: 22 | loss: 33.1360855
	speed: 0.0503s/iter; left time: 1043.4925s
Epoch: 22 cost time: 13.377529382705688
Epoch: 22, Steps: 265 Train Loss: 33.3459 (Forecasting Loss:0.1891 + XiCon Loss:3.3157 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 35.0616837
	speed: 0.0510s/iter; left time: 1049.5134s
	iters: 200, epoch: 23 | loss: 34.0515518
	speed: 0.0489s/iter; left time: 1000.3391s
Epoch: 23 cost time: 13.330022811889648
Epoch: 23, Steps: 265 Train Loss: 33.3839 (Forecasting Loss:0.1891 + XiCon Loss:3.3195 x Lambda(10.0)), Vali MSE Loss: 0.1405 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039319153875112534, mae:0.1498412936925888, mape:0.11933460831642151, mspe:0.026842694729566574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1017
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.1261902
	speed: 0.0497s/iter; left time: 1312.0765s
	iters: 200, epoch: 1 | loss: 31.0225487
	speed: 0.0465s/iter; left time: 1222.1021s
Epoch: 1 cost time: 12.716485023498535
Epoch: 1, Steps: 265 Train Loss: 31.3810 (Forecasting Loss:0.2124 + XiCon Loss:3.1169 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.148282).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.8191338
	speed: 0.0510s/iter; left time: 1334.0610s
	iters: 200, epoch: 2 | loss: 31.1671486
	speed: 0.0493s/iter; left time: 1283.0640s
Epoch: 2 cost time: 13.206269979476929
Epoch: 2, Steps: 265 Train Loss: 32.9722 (Forecasting Loss:0.1987 + XiCon Loss:3.2773 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0967
Validation loss decreased (0.148282 --> 0.146488).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7818718
	speed: 0.0510s/iter; left time: 1320.0047s
	iters: 200, epoch: 3 | loss: 31.0580196
	speed: 0.0486s/iter; left time: 1252.9927s
Epoch: 3 cost time: 13.117362022399902
Epoch: 3, Steps: 265 Train Loss: 32.1682 (Forecasting Loss:0.1932 + XiCon Loss:3.1975 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0954
Validation loss decreased (0.146488 --> 0.143400).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.3300705
	speed: 0.0522s/iter; left time: 1335.3807s
	iters: 200, epoch: 4 | loss: 31.1934414
	speed: 0.0486s/iter; left time: 1240.1234s
Epoch: 4 cost time: 13.272876024246216
Epoch: 4, Steps: 265 Train Loss: 31.9385 (Forecasting Loss:0.1914 + XiCon Loss:3.1747 x Lambda(10.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0949
Validation loss decreased (0.143400 --> 0.142986).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5872898
	speed: 0.0509s/iter; left time: 1289.0899s
	iters: 200, epoch: 5 | loss: 31.9550972
	speed: 0.0508s/iter; left time: 1281.6826s
Epoch: 5 cost time: 13.437150478363037
Epoch: 5, Steps: 265 Train Loss: 31.6798 (Forecasting Loss:0.1902 + XiCon Loss:3.1490 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0952
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.9350662
	speed: 0.0517s/iter; left time: 1295.5593s
	iters: 200, epoch: 6 | loss: 30.7656136
	speed: 0.0503s/iter; left time: 1256.2075s
Epoch: 6 cost time: 13.45852279663086
Epoch: 6, Steps: 265 Train Loss: 31.6638 (Forecasting Loss:0.1899 + XiCon Loss:3.1474 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0944
Validation loss decreased (0.142986 --> 0.142291).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.4056969
	speed: 0.0514s/iter; left time: 1274.7162s
	iters: 200, epoch: 7 | loss: 33.7355118
	speed: 0.0504s/iter; left time: 1244.6453s
Epoch: 7 cost time: 13.581153392791748
Epoch: 7, Steps: 265 Train Loss: 31.7580 (Forecasting Loss:0.1896 + XiCon Loss:3.1568 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0945
Validation loss decreased (0.142291 --> 0.142208).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.7282352
	speed: 0.0501s/iter; left time: 1229.9355s
	iters: 200, epoch: 8 | loss: 32.5655174
	speed: 0.0498s/iter; left time: 1218.0718s
Epoch: 8 cost time: 13.188679695129395
Epoch: 8, Steps: 265 Train Loss: 31.7829 (Forecasting Loss:0.1894 + XiCon Loss:3.1593 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
Validation loss decreased (0.142208 --> 0.141958).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.7532883
	speed: 0.0520s/iter; left time: 1262.0126s
	iters: 200, epoch: 9 | loss: 31.5590134
	speed: 0.0484s/iter; left time: 1169.6348s
Epoch: 9 cost time: 13.381107807159424
Epoch: 9, Steps: 265 Train Loss: 31.7019 (Forecasting Loss:0.1893 + XiCon Loss:3.1513 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
Validation loss decreased (0.141958 --> 0.141789).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2707310
	speed: 0.0530s/iter; left time: 1273.5196s
	iters: 200, epoch: 10 | loss: 32.3740273
	speed: 0.0505s/iter; left time: 1207.0101s
Epoch: 10 cost time: 13.572693109512329
Epoch: 10, Steps: 265 Train Loss: 31.7462 (Forecasting Loss:0.1892 + XiCon Loss:3.1557 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.9805222
	speed: 0.0518s/iter; left time: 1229.6498s
	iters: 200, epoch: 11 | loss: 32.5971375
	speed: 0.0489s/iter; left time: 1156.3197s
Epoch: 11 cost time: 13.274857759475708
Epoch: 11, Steps: 265 Train Loss: 31.6556 (Forecasting Loss:0.1893 + XiCon Loss:3.1466 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
Validation loss decreased (0.141789 --> 0.141773).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6877842
	speed: 0.0523s/iter; left time: 1227.5107s
	iters: 200, epoch: 12 | loss: 32.1229324
	speed: 0.0508s/iter; left time: 1188.4086s
Epoch: 12 cost time: 13.576614618301392
Epoch: 12, Steps: 265 Train Loss: 31.7788 (Forecasting Loss:0.1892 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2875843
	speed: 0.0510s/iter; left time: 1183.7971s
	iters: 200, epoch: 13 | loss: 32.8191528
	speed: 0.0506s/iter; left time: 1169.8500s
Epoch: 13 cost time: 13.437567710876465
Epoch: 13, Steps: 265 Train Loss: 31.7473 (Forecasting Loss:0.1892 + XiCon Loss:3.1558 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.1047363
	speed: 0.0516s/iter; left time: 1184.1817s
	iters: 200, epoch: 14 | loss: 31.7243786
	speed: 0.0491s/iter; left time: 1123.1196s
Epoch: 14 cost time: 13.39376449584961
Epoch: 14, Steps: 265 Train Loss: 31.7343 (Forecasting Loss:0.1892 + XiCon Loss:3.1545 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.1446285
	speed: 0.0513s/iter; left time: 1164.8897s
	iters: 200, epoch: 15 | loss: 32.3237762
	speed: 0.0494s/iter; left time: 1115.6103s
Epoch: 15 cost time: 13.324458599090576
Epoch: 15, Steps: 265 Train Loss: 31.6418 (Forecasting Loss:0.1891 + XiCon Loss:3.1453 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0551682
	speed: 0.0519s/iter; left time: 1162.9971s
	iters: 200, epoch: 16 | loss: 30.3823624
	speed: 0.0502s/iter; left time: 1119.9696s
Epoch: 16 cost time: 13.488470792770386
Epoch: 16, Steps: 265 Train Loss: 31.6796 (Forecasting Loss:0.1891 + XiCon Loss:3.1491 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.5725460
	speed: 0.0532s/iter; left time: 1178.0624s
	iters: 200, epoch: 17 | loss: 29.9725323
	speed: 0.0489s/iter; left time: 1079.8119s
Epoch: 17 cost time: 13.429149627685547
Epoch: 17, Steps: 265 Train Loss: 31.6905 (Forecasting Loss:0.1893 + XiCon Loss:3.1501 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.6582050
	speed: 0.0519s/iter; left time: 1136.3836s
	iters: 200, epoch: 18 | loss: 32.3275414
	speed: 0.0499s/iter; left time: 1088.5246s
Epoch: 18 cost time: 13.523585319519043
Epoch: 18, Steps: 265 Train Loss: 31.7144 (Forecasting Loss:0.1891 + XiCon Loss:3.1525 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.1390629
	speed: 0.0507s/iter; left time: 1096.9270s
	iters: 200, epoch: 19 | loss: 32.4480324
	speed: 0.0511s/iter; left time: 1100.6049s
Epoch: 19 cost time: 13.438465118408203
Epoch: 19, Steps: 265 Train Loss: 31.7094 (Forecasting Loss:0.1892 + XiCon Loss:3.1520 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.6338234
	speed: 0.0514s/iter; left time: 1097.4039s
	iters: 200, epoch: 20 | loss: 32.3602066
	speed: 0.0494s/iter; left time: 1051.5070s
Epoch: 20 cost time: 13.434676885604858
Epoch: 20, Steps: 265 Train Loss: 31.7663 (Forecasting Loss:0.1892 + XiCon Loss:3.1577 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.2160835
	speed: 0.0507s/iter; left time: 1069.5286s
	iters: 200, epoch: 21 | loss: 32.6048164
	speed: 0.0489s/iter; left time: 1027.5452s
Epoch: 21 cost time: 13.263930082321167
Epoch: 21, Steps: 265 Train Loss: 31.6193 (Forecasting Loss:0.1893 + XiCon Loss:3.1430 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03931235522031784, mae:0.14937138557434082, mape:0.11851407587528229, mspe:0.026257187128067017 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0393+-0.00003, MAE:0.1495+-0.00023, MAPE:0.1188+-0.00043, MSPE:0.0265+-0.00030, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.3168
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 31.0452080
	speed: 0.0433s/iter; left time: 1138.0515s
	iters: 200, epoch: 1 | loss: 30.4955177
	speed: 0.0377s/iter; left time: 987.6076s
Epoch: 1 cost time: 10.437446355819702
Epoch: 1, Steps: 264 Train Loss: 30.8626 (Forecasting Loss:0.2379 + XiCon Loss:3.0625 x Lambda(10.0)), Vali MSE Loss: 0.1741 Test MSE Loss: 0.1135
Validation loss decreased (inf --> 0.174142).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.6607800
	speed: 0.0455s/iter; left time: 1185.5370s
	iters: 200, epoch: 2 | loss: 29.5761662
	speed: 0.0422s/iter; left time: 1095.6606s
Epoch: 2 cost time: 11.40057110786438
Epoch: 2, Steps: 264 Train Loss: 29.4433 (Forecasting Loss:0.2442 + XiCon Loss:2.9199 x Lambda(10.0)), Vali MSE Loss: 0.1788 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.4497662
	speed: 0.0419s/iter; left time: 1079.7035s
	iters: 200, epoch: 3 | loss: 28.7277241
	speed: 0.0419s/iter; left time: 1075.5278s
Epoch: 3 cost time: 11.039686679840088
Epoch: 3, Steps: 264 Train Loss: 28.8573 (Forecasting Loss:0.2341 + XiCon Loss:2.8623 x Lambda(10.0)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1137
Validation loss decreased (0.174142 --> 0.172389).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.9134598
	speed: 0.0427s/iter; left time: 1089.8854s
	iters: 200, epoch: 4 | loss: 29.0145893
	speed: 0.0412s/iter; left time: 1047.7950s
Epoch: 4 cost time: 11.084069013595581
Epoch: 4, Steps: 264 Train Loss: 28.6768 (Forecasting Loss:0.2299 + XiCon Loss:2.8447 x Lambda(10.0)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1138
Validation loss decreased (0.172389 --> 0.171832).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.7927094
	speed: 0.0427s/iter; left time: 1078.3288s
	iters: 200, epoch: 5 | loss: 28.4482803
	speed: 0.0408s/iter; left time: 1026.3843s
Epoch: 5 cost time: 10.956740379333496
Epoch: 5, Steps: 264 Train Loss: 28.6230 (Forecasting Loss:0.2283 + XiCon Loss:2.8395 x Lambda(10.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1126
Validation loss decreased (0.171832 --> 0.171005).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.6364555
	speed: 0.0428s/iter; left time: 1068.1655s
	iters: 200, epoch: 6 | loss: 28.3728542
	speed: 0.0406s/iter; left time: 1010.3080s
Epoch: 6 cost time: 10.982818841934204
Epoch: 6, Steps: 264 Train Loss: 28.6339 (Forecasting Loss:0.2274 + XiCon Loss:2.8406 x Lambda(10.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
Validation loss decreased (0.171005 --> 0.170171).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.6492996
	speed: 0.0429s/iter; left time: 1061.2719s
	iters: 200, epoch: 7 | loss: 28.7667637
	speed: 0.0415s/iter; left time: 1022.1804s
Epoch: 7 cost time: 11.075028657913208
Epoch: 7, Steps: 264 Train Loss: 28.6296 (Forecasting Loss:0.2268 + XiCon Loss:2.8403 x Lambda(10.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1129
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.2310658
	speed: 0.0431s/iter; left time: 1054.0204s
	iters: 200, epoch: 8 | loss: 28.8475704
	speed: 0.0409s/iter; left time: 995.7675s
Epoch: 8 cost time: 11.005513191223145
Epoch: 8, Steps: 264 Train Loss: 28.6021 (Forecasting Loss:0.2265 + XiCon Loss:2.8376 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1125
Validation loss decreased (0.170171 --> 0.169927).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.8132248
	speed: 0.0427s/iter; left time: 1033.2451s
	iters: 200, epoch: 9 | loss: 28.9778194
	speed: 0.0397s/iter; left time: 955.9850s
Epoch: 9 cost time: 10.89653992652893
Epoch: 9, Steps: 264 Train Loss: 28.5843 (Forecasting Loss:0.2263 + XiCon Loss:2.8358 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.4968948
	speed: 0.0431s/iter; left time: 1032.1447s
	iters: 200, epoch: 10 | loss: 28.6191120
	speed: 0.0417s/iter; left time: 994.4169s
Epoch: 10 cost time: 11.10010051727295
Epoch: 10, Steps: 264 Train Loss: 28.5991 (Forecasting Loss:0.2263 + XiCon Loss:2.8373 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169927 --> 0.169809).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 28.2151775
	speed: 0.0432s/iter; left time: 1023.2187s
	iters: 200, epoch: 11 | loss: 28.2961121
	speed: 0.0402s/iter; left time: 946.3971s
Epoch: 11 cost time: 11.069911479949951
Epoch: 11, Steps: 264 Train Loss: 28.5621 (Forecasting Loss:0.2261 + XiCon Loss:2.8336 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1125
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 29.1149712
	speed: 0.0429s/iter; left time: 1003.0675s
	iters: 200, epoch: 12 | loss: 28.3391781
	speed: 0.0397s/iter; left time: 925.0724s
Epoch: 12 cost time: 10.838703632354736
Epoch: 12, Steps: 264 Train Loss: 28.6085 (Forecasting Loss:0.2262 + XiCon Loss:2.8382 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.1160107
	speed: 0.0438s/iter; left time: 1014.3214s
	iters: 200, epoch: 13 | loss: 28.5084095
	speed: 0.0402s/iter; left time: 927.0428s
Epoch: 13 cost time: 11.020583868026733
Epoch: 13, Steps: 264 Train Loss: 28.5610 (Forecasting Loss:0.2262 + XiCon Loss:2.8335 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.6928902
	speed: 0.0420s/iter; left time: 961.3404s
	iters: 200, epoch: 14 | loss: 28.4063644
	speed: 0.0415s/iter; left time: 945.8104s
Epoch: 14 cost time: 10.921394348144531
Epoch: 14, Steps: 264 Train Loss: 28.5733 (Forecasting Loss:0.2261 + XiCon Loss:2.8347 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.4758148
	speed: 0.0430s/iter; left time: 971.3635s
	iters: 200, epoch: 15 | loss: 28.1644211
	speed: 0.0409s/iter; left time: 920.1521s
Epoch: 15 cost time: 11.098932027816772
Epoch: 15, Steps: 264 Train Loss: 28.6003 (Forecasting Loss:0.2261 + XiCon Loss:2.8374 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 28.6584187
	speed: 0.0432s/iter; left time: 964.2639s
	iters: 200, epoch: 16 | loss: 28.7870560
	speed: 0.0408s/iter; left time: 907.7619s
Epoch: 16 cost time: 11.010028839111328
Epoch: 16, Steps: 264 Train Loss: 28.5800 (Forecasting Loss:0.2261 + XiCon Loss:2.8354 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 28.7153111
	speed: 0.0440s/iter; left time: 971.8956s
	iters: 200, epoch: 17 | loss: 28.7873039
	speed: 0.0406s/iter; left time: 891.8810s
Epoch: 17 cost time: 11.083150386810303
Epoch: 17, Steps: 264 Train Loss: 28.6199 (Forecasting Loss:0.2262 + XiCon Loss:2.8394 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 28.2817440
	speed: 0.0428s/iter; left time: 933.3182s
	iters: 200, epoch: 18 | loss: 28.2521057
	speed: 0.0406s/iter; left time: 880.8262s
Epoch: 18 cost time: 10.976695537567139
Epoch: 18, Steps: 264 Train Loss: 28.5816 (Forecasting Loss:0.2262 + XiCon Loss:2.8355 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.0843964
	speed: 0.0429s/iter; left time: 925.0936s
	iters: 200, epoch: 19 | loss: 28.2044601
	speed: 0.0410s/iter; left time: 879.7822s
Epoch: 19 cost time: 11.01315951347351
Epoch: 19, Steps: 264 Train Loss: 28.5834 (Forecasting Loss:0.2261 + XiCon Loss:2.8357 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.2718639
	speed: 0.0443s/iter; left time: 943.5562s
	iters: 200, epoch: 20 | loss: 28.4955349
	speed: 0.0409s/iter; left time: 867.0425s
Epoch: 20 cost time: 11.159442901611328
Epoch: 20, Steps: 264 Train Loss: 28.5546 (Forecasting Loss:0.2261 + XiCon Loss:2.8328 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05246102809906006, mae:0.17236550152301788, mape:0.1345762461423874, mspe:0.03227641433477402 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2690
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 31.3685150
	speed: 0.0420s/iter; left time: 1105.5201s
	iters: 200, epoch: 1 | loss: 30.2481403
	speed: 0.0383s/iter; left time: 1004.7486s
Epoch: 1 cost time: 10.507839918136597
Epoch: 1, Steps: 264 Train Loss: 31.1278 (Forecasting Loss:0.2386 + XiCon Loss:3.0889 x Lambda(10.0)), Vali MSE Loss: 0.1740 Test MSE Loss: 0.1141
Validation loss decreased (inf --> 0.174049).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 30.5784016
	speed: 0.0440s/iter; left time: 1145.2870s
	iters: 200, epoch: 2 | loss: 30.8589725
	speed: 0.0409s/iter; left time: 1060.9261s
Epoch: 2 cost time: 11.043895483016968
Epoch: 2, Steps: 264 Train Loss: 30.4073 (Forecasting Loss:0.2418 + XiCon Loss:3.0165 x Lambda(10.0)), Vali MSE Loss: 0.1779 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 29.9892941
	speed: 0.0426s/iter; left time: 1099.1837s
	iters: 200, epoch: 3 | loss: 29.2995968
	speed: 0.0410s/iter; left time: 1051.7526s
Epoch: 3 cost time: 11.047691106796265
Epoch: 3, Steps: 264 Train Loss: 29.8213 (Forecasting Loss:0.2343 + XiCon Loss:2.9587 x Lambda(10.0)), Vali MSE Loss: 0.1751 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.1596622
	speed: 0.0438s/iter; left time: 1116.2786s
	iters: 200, epoch: 4 | loss: 29.1319828
	speed: 0.0405s/iter; left time: 1029.3698s
Epoch: 4 cost time: 11.030938863754272
Epoch: 4, Steps: 264 Train Loss: 29.0036 (Forecasting Loss:0.2310 + XiCon Loss:2.8773 x Lambda(10.0)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1132
Validation loss decreased (0.174049 --> 0.170947).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.1153736
	speed: 0.0428s/iter; left time: 1080.6780s
	iters: 200, epoch: 5 | loss: 28.8432350
	speed: 0.0419s/iter; left time: 1053.8423s
Epoch: 5 cost time: 11.117566585540771
Epoch: 5, Steps: 264 Train Loss: 28.9393 (Forecasting Loss:0.2284 + XiCon Loss:2.8711 x Lambda(10.0)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1136
Validation loss decreased (0.170947 --> 0.170848).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.8855171
	speed: 0.0436s/iter; left time: 1088.4685s
	iters: 200, epoch: 6 | loss: 28.5848217
	speed: 0.0406s/iter; left time: 1011.0176s
Epoch: 6 cost time: 11.021587371826172
Epoch: 6, Steps: 264 Train Loss: 28.9517 (Forecasting Loss:0.2274 + XiCon Loss:2.8724 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
Validation loss decreased (0.170848 --> 0.170124).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.9757633
	speed: 0.0432s/iter; left time: 1068.4636s
	iters: 200, epoch: 7 | loss: 28.9550667
	speed: 0.0406s/iter; left time: 998.3487s
Epoch: 7 cost time: 11.004253387451172
Epoch: 7, Steps: 264 Train Loss: 28.9050 (Forecasting Loss:0.2268 + XiCon Loss:2.8678 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1125
Validation loss decreased (0.170124 --> 0.169859).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.4758892
	speed: 0.0422s/iter; left time: 1032.6377s
	iters: 200, epoch: 8 | loss: 29.2070484
	speed: 0.0418s/iter; left time: 1017.3155s
Epoch: 8 cost time: 11.05113434791565
Epoch: 8, Steps: 264 Train Loss: 28.9252 (Forecasting Loss:0.2264 + XiCon Loss:2.8699 x Lambda(10.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.2883549
	speed: 0.0428s/iter; left time: 1036.0864s
	iters: 200, epoch: 9 | loss: 28.4745960
	speed: 0.0403s/iter; left time: 969.6538s
Epoch: 9 cost time: 10.900147676467896
Epoch: 9, Steps: 264 Train Loss: 28.8891 (Forecasting Loss:0.2266 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.0429440
	speed: 0.0425s/iter; left time: 1016.1074s
	iters: 200, epoch: 10 | loss: 28.6813030
	speed: 0.0408s/iter; left time: 972.6545s
Epoch: 10 cost time: 11.006169557571411
Epoch: 10, Steps: 264 Train Loss: 28.8681 (Forecasting Loss:0.2265 + XiCon Loss:2.8642 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.2563591
	speed: 0.0440s/iter; left time: 1039.9710s
	iters: 200, epoch: 11 | loss: 28.8986416
	speed: 0.0408s/iter; left time: 962.0505s
Epoch: 11 cost time: 11.082336902618408
Epoch: 11, Steps: 264 Train Loss: 28.8990 (Forecasting Loss:0.2264 + XiCon Loss:2.8673 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 29.2273617
	speed: 0.0420s/iter; left time: 982.5722s
	iters: 200, epoch: 12 | loss: 28.9235516
	speed: 0.0406s/iter; left time: 945.4184s
Epoch: 12 cost time: 10.79508924484253
Epoch: 12, Steps: 264 Train Loss: 28.8783 (Forecasting Loss:0.2264 + XiCon Loss:2.8652 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.9076843
	speed: 0.0418s/iter; left time: 968.0913s
	iters: 200, epoch: 13 | loss: 28.3374882
	speed: 0.0400s/iter; left time: 920.3176s
Epoch: 13 cost time: 10.852579593658447
Epoch: 13, Steps: 264 Train Loss: 28.8886 (Forecasting Loss:0.2263 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 29.5174217
	speed: 0.0427s/iter; left time: 975.7588s
	iters: 200, epoch: 14 | loss: 28.8764286
	speed: 0.0403s/iter; left time: 917.0525s
Epoch: 14 cost time: 10.892903327941895
Epoch: 14, Steps: 264 Train Loss: 28.8781 (Forecasting Loss:0.2263 + XiCon Loss:2.8652 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.7952709
	speed: 0.0422s/iter; left time: 954.8598s
	iters: 200, epoch: 15 | loss: 28.3351746
	speed: 0.0410s/iter; left time: 922.8549s
Epoch: 15 cost time: 10.881312131881714
Epoch: 15, Steps: 264 Train Loss: 28.9115 (Forecasting Loss:0.2264 + XiCon Loss:2.8685 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 28.6771183
	speed: 0.0433s/iter; left time: 966.6814s
	iters: 200, epoch: 16 | loss: 28.6699486
	speed: 0.0406s/iter; left time: 902.9588s
Epoch: 16 cost time: 11.078481674194336
Epoch: 16, Steps: 264 Train Loss: 28.8908 (Forecasting Loss:0.2263 + XiCon Loss:2.8665 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169859 --> 0.169847).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 28.4376545
	speed: 0.0418s/iter; left time: 921.9701s
	iters: 200, epoch: 17 | loss: 29.0343533
	speed: 0.0404s/iter; left time: 888.7013s
Epoch: 17 cost time: 10.849394798278809
Epoch: 17, Steps: 264 Train Loss: 28.9149 (Forecasting Loss:0.2263 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169847 --> 0.169846).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 28.3586960
	speed: 0.0433s/iter; left time: 944.2939s
	iters: 200, epoch: 18 | loss: 28.7721710
	speed: 0.0400s/iter; left time: 868.3321s
Epoch: 18 cost time: 10.97448182106018
Epoch: 18, Steps: 264 Train Loss: 28.8946 (Forecasting Loss:0.2263 + XiCon Loss:2.8668 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.3539219
	speed: 0.0428s/iter; left time: 921.8121s
	iters: 200, epoch: 19 | loss: 28.8781166
	speed: 0.0405s/iter; left time: 867.9886s
Epoch: 19 cost time: 13.517690896987915
Epoch: 19, Steps: 264 Train Loss: 28.8515 (Forecasting Loss:0.2264 + XiCon Loss:2.8625 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.7007275
	speed: 0.0415s/iter; left time: 882.3949s
	iters: 200, epoch: 20 | loss: 28.9034748
	speed: 0.0399s/iter; left time: 844.9653s
Epoch: 20 cost time: 10.679246187210083
Epoch: 20, Steps: 264 Train Loss: 28.9035 (Forecasting Loss:0.2263 + XiCon Loss:2.8677 x Lambda(10.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1124
Validation loss decreased (0.169846 --> 0.169738).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 29.6492424
	speed: 0.0429s/iter; left time: 902.1816s
	iters: 200, epoch: 21 | loss: 28.5834312
	speed: 0.0405s/iter; left time: 846.4251s
Epoch: 21 cost time: 10.913270235061646
Epoch: 21, Steps: 264 Train Loss: 28.8648 (Forecasting Loss:0.2265 + XiCon Loss:2.8638 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 29.0175037
	speed: 0.0423s/iter; left time: 878.2928s
	iters: 200, epoch: 22 | loss: 28.6741772
	speed: 0.0400s/iter; left time: 825.9188s
Epoch: 22 cost time: 10.794386863708496
Epoch: 22, Steps: 264 Train Loss: 28.8270 (Forecasting Loss:0.2264 + XiCon Loss:2.8601 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 28.3696728
	speed: 0.0432s/iter; left time: 886.3146s
	iters: 200, epoch: 23 | loss: 28.9471512
	speed: 0.0404s/iter; left time: 824.1824s
Epoch: 23 cost time: 10.897099733352661
Epoch: 23, Steps: 264 Train Loss: 28.8902 (Forecasting Loss:0.2264 + XiCon Loss:2.8664 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 29.0847092
	speed: 0.0425s/iter; left time: 859.2385s
	iters: 200, epoch: 24 | loss: 29.5233955
	speed: 0.0413s/iter; left time: 831.0698s
Epoch: 24 cost time: 10.948013067245483
Epoch: 24, Steps: 264 Train Loss: 28.9102 (Forecasting Loss:0.2263 + XiCon Loss:2.8684 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 28.8932228
	speed: 0.0420s/iter; left time: 837.6844s
	iters: 200, epoch: 25 | loss: 28.7370396
	speed: 0.0408s/iter; left time: 809.5501s
Epoch: 25 cost time: 10.953582286834717
Epoch: 25, Steps: 264 Train Loss: 28.8941 (Forecasting Loss:0.2263 + XiCon Loss:2.8668 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 29.3436031
	speed: 0.0421s/iter; left time: 829.2219s
	iters: 200, epoch: 26 | loss: 29.6553364
	speed: 0.0405s/iter; left time: 794.5903s
Epoch: 26 cost time: 10.896222591400146
Epoch: 26, Steps: 264 Train Loss: 28.8979 (Forecasting Loss:0.2264 + XiCon Loss:2.8671 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.3714905
	speed: 0.0433s/iter; left time: 841.4551s
	iters: 200, epoch: 27 | loss: 28.8840275
	speed: 0.0402s/iter; left time: 776.8647s
Epoch: 27 cost time: 10.886039972305298
Epoch: 27, Steps: 264 Train Loss: 28.8743 (Forecasting Loss:0.2264 + XiCon Loss:2.8648 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 28.7441978
	speed: 0.0427s/iter; left time: 819.2546s
	iters: 200, epoch: 28 | loss: 28.6074276
	speed: 0.0412s/iter; left time: 784.9921s
Epoch: 28 cost time: 11.069173574447632
Epoch: 28, Steps: 264 Train Loss: 28.8681 (Forecasting Loss:0.2263 + XiCon Loss:2.8642 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 28.8575230
	speed: 0.0434s/iter; left time: 820.3098s
	iters: 200, epoch: 29 | loss: 29.1046696
	speed: 0.0396s/iter; left time: 745.4257s
Epoch: 29 cost time: 10.856847286224365
Epoch: 29, Steps: 264 Train Loss: 28.8649 (Forecasting Loss:0.2264 + XiCon Loss:2.8638 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 28.4559097
	speed: 0.0435s/iter; left time: 810.8085s
	iters: 200, epoch: 30 | loss: 28.8771057
	speed: 0.0402s/iter; left time: 744.5972s
Epoch: 30 cost time: 10.997439622879028
Epoch: 30, Steps: 264 Train Loss: 28.8613 (Forecasting Loss:0.2264 + XiCon Loss:2.8635 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.052477575838565826, mae:0.17228569090366364, mape:0.13432426750659943, mspe:0.03211698308587074 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.0897
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 30.9258041
	speed: 0.0406s/iter; left time: 1067.3427s
	iters: 200, epoch: 1 | loss: 30.2929020
	speed: 0.0394s/iter; left time: 1031.9355s
Epoch: 1 cost time: 10.405282497406006
Epoch: 1, Steps: 264 Train Loss: 30.8929 (Forecasting Loss:0.2380 + XiCon Loss:3.0655 x Lambda(10.0)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1147
Validation loss decreased (inf --> 0.173330).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 30.5546455
	speed: 0.0446s/iter; left time: 1161.3555s
	iters: 200, epoch: 2 | loss: 29.9514942
	speed: 0.0415s/iter; left time: 1077.2570s
Epoch: 2 cost time: 11.263697147369385
Epoch: 2, Steps: 264 Train Loss: 29.9767 (Forecasting Loss:0.2435 + XiCon Loss:2.9733 x Lambda(10.0)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.8375874
	speed: 0.0426s/iter; left time: 1097.5543s
	iters: 200, epoch: 3 | loss: 29.0163059
	speed: 0.0406s/iter; left time: 1042.5409s
Epoch: 3 cost time: 10.967445373535156
Epoch: 3, Steps: 264 Train Loss: 28.9479 (Forecasting Loss:0.2327 + XiCon Loss:2.8715 x Lambda(10.0)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1153
Validation loss decreased (0.173330 --> 0.172966).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.3509483
	speed: 0.0442s/iter; left time: 1128.2354s
	iters: 200, epoch: 4 | loss: 28.1152363
	speed: 0.0414s/iter; left time: 1052.7580s
Epoch: 4 cost time: 11.185676097869873
Epoch: 4, Steps: 264 Train Loss: 28.7424 (Forecasting Loss:0.2301 + XiCon Loss:2.8512 x Lambda(10.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1134
Validation loss decreased (0.172966 --> 0.171159).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.3319225
	speed: 0.0433s/iter; left time: 1092.9799s
	iters: 200, epoch: 5 | loss: 28.5595284
	speed: 0.0401s/iter; left time: 1009.5293s
Epoch: 5 cost time: 11.007112979888916
Epoch: 5, Steps: 264 Train Loss: 28.6538 (Forecasting Loss:0.2282 + XiCon Loss:2.8426 x Lambda(10.0)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1134
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.5078201
	speed: 0.0420s/iter; left time: 1050.1590s
	iters: 200, epoch: 6 | loss: 28.8388920
	speed: 0.0416s/iter; left time: 1034.0363s
Epoch: 6 cost time: 10.928141117095947
Epoch: 6, Steps: 264 Train Loss: 28.6177 (Forecasting Loss:0.2274 + XiCon Loss:2.8390 x Lambda(10.0)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1124
Validation loss decreased (0.171159 --> 0.170303).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.9727535
	speed: 0.0442s/iter; left time: 1091.3258s
	iters: 200, epoch: 7 | loss: 28.6994705
	speed: 0.0404s/iter; left time: 994.6392s
Epoch: 7 cost time: 11.07079029083252
Epoch: 7, Steps: 264 Train Loss: 28.6496 (Forecasting Loss:0.2268 + XiCon Loss:2.8423 x Lambda(10.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1129
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 28.2528934
	speed: 0.0426s/iter; left time: 1041.9522s
	iters: 200, epoch: 8 | loss: 28.5748920
	speed: 0.0416s/iter; left time: 1012.7447s
Epoch: 8 cost time: 11.003592014312744
Epoch: 8, Steps: 264 Train Loss: 28.6159 (Forecasting Loss:0.2267 + XiCon Loss:2.8389 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170303 --> 0.170013).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.4028549
	speed: 0.0434s/iter; left time: 1050.5670s
	iters: 200, epoch: 9 | loss: 27.9852905
	speed: 0.0404s/iter; left time: 973.1204s
Epoch: 9 cost time: 11.028256177902222
Epoch: 9, Steps: 264 Train Loss: 28.6208 (Forecasting Loss:0.2264 + XiCon Loss:2.8394 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170013 --> 0.169951).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.4007912
	speed: 0.0430s/iter; left time: 1029.1770s
	iters: 200, epoch: 10 | loss: 28.4570065
	speed: 0.0409s/iter; left time: 973.3333s
Epoch: 10 cost time: 11.06486701965332
Epoch: 10, Steps: 264 Train Loss: 28.5766 (Forecasting Loss:0.2264 + XiCon Loss:2.8350 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 28.2798729
	speed: 0.0430s/iter; left time: 1017.9486s
	iters: 200, epoch: 11 | loss: 28.6217442
	speed: 0.0409s/iter; left time: 963.3783s
Epoch: 11 cost time: 11.033627271652222
Epoch: 11, Steps: 264 Train Loss: 28.6140 (Forecasting Loss:0.2263 + XiCon Loss:2.8388 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169951 --> 0.169928).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 28.5164318
	speed: 0.0424s/iter; left time: 992.4368s
	iters: 200, epoch: 12 | loss: 28.3163853
	speed: 0.0414s/iter; left time: 965.1343s
Epoch: 12 cost time: 10.99026346206665
Epoch: 12, Steps: 264 Train Loss: 28.6105 (Forecasting Loss:0.2264 + XiCon Loss:2.8384 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.3238029
	speed: 0.0424s/iter; left time: 981.4374s
	iters: 200, epoch: 13 | loss: 28.5181656
	speed: 0.0404s/iter; left time: 929.8846s
Epoch: 13 cost time: 10.894909620285034
Epoch: 13, Steps: 264 Train Loss: 28.6119 (Forecasting Loss:0.2262 + XiCon Loss:2.8386 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169928 --> 0.169927).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.5220394
	speed: 0.0431s/iter; left time: 985.3686s
	iters: 200, epoch: 14 | loss: 28.2603455
	speed: 0.0401s/iter; left time: 913.4472s
Epoch: 14 cost time: 10.921957969665527
Epoch: 14, Steps: 264 Train Loss: 28.6075 (Forecasting Loss:0.2262 + XiCon Loss:2.8381 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.6885509
	speed: 0.0424s/iter; left time: 958.9558s
	iters: 200, epoch: 15 | loss: 28.5027905
	speed: 0.0418s/iter; left time: 939.7213s
Epoch: 15 cost time: 11.029687404632568
Epoch: 15, Steps: 264 Train Loss: 28.6078 (Forecasting Loss:0.2262 + XiCon Loss:2.8382 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169927 --> 0.169906).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 28.7127762
	speed: 0.0434s/iter; left time: 970.4868s
	iters: 200, epoch: 16 | loss: 28.6684933
	speed: 0.0407s/iter; left time: 905.1591s
Epoch: 16 cost time: 11.073583126068115
Epoch: 16, Steps: 264 Train Loss: 28.6309 (Forecasting Loss:0.2262 + XiCon Loss:2.8405 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
Validation loss decreased (0.169906 --> 0.169863).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 28.4141216
	speed: 0.0430s/iter; left time: 949.8375s
	iters: 200, epoch: 17 | loss: 28.2368717
	speed: 0.0407s/iter; left time: 894.1799s
Epoch: 17 cost time: 10.996412992477417
Epoch: 17, Steps: 264 Train Loss: 28.6160 (Forecasting Loss:0.2262 + XiCon Loss:2.8390 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169863 --> 0.169840).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 28.6967564
	speed: 0.0438s/iter; left time: 954.6445s
	iters: 200, epoch: 18 | loss: 28.4598732
	speed: 0.0409s/iter; left time: 888.8951s
Epoch: 18 cost time: 11.110902070999146
Epoch: 18, Steps: 264 Train Loss: 28.6154 (Forecasting Loss:0.2263 + XiCon Loss:2.8389 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.2128811
	speed: 0.0433s/iter; left time: 933.3311s
	iters: 200, epoch: 19 | loss: 28.7820759
	speed: 0.0413s/iter; left time: 885.7741s
Epoch: 19 cost time: 11.129722356796265
Epoch: 19, Steps: 264 Train Loss: 28.5914 (Forecasting Loss:0.2262 + XiCon Loss:2.8365 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.1131992
	speed: 0.0432s/iter; left time: 920.0450s
	iters: 200, epoch: 20 | loss: 28.2882977
	speed: 0.0404s/iter; left time: 856.5645s
Epoch: 20 cost time: 10.969975233078003
Epoch: 20, Steps: 264 Train Loss: 28.6158 (Forecasting Loss:0.2263 + XiCon Loss:2.8390 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 28.7400532
	speed: 0.0427s/iter; left time: 898.4056s
	iters: 200, epoch: 21 | loss: 28.4437275
	speed: 0.0405s/iter; left time: 847.2259s
Epoch: 21 cost time: 10.954176902770996
Epoch: 21, Steps: 264 Train Loss: 28.5937 (Forecasting Loss:0.2262 + XiCon Loss:2.8367 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 28.6398354
	speed: 0.0438s/iter; left time: 908.1777s
	iters: 200, epoch: 22 | loss: 28.7243481
	speed: 0.0401s/iter; left time: 827.5676s
Epoch: 22 cost time: 11.123126029968262
Epoch: 22, Steps: 264 Train Loss: 28.5932 (Forecasting Loss:0.2263 + XiCon Loss:2.8367 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 29.0593662
	speed: 0.0422s/iter; left time: 864.3404s
	iters: 200, epoch: 23 | loss: 28.5582085
	speed: 0.0415s/iter; left time: 847.0234s
Epoch: 23 cost time: 11.058684587478638
Epoch: 23, Steps: 264 Train Loss: 28.6099 (Forecasting Loss:0.2262 + XiCon Loss:2.8384 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 29.0665779
	speed: 0.0431s/iter; left time: 871.1344s
	iters: 200, epoch: 24 | loss: 28.5748482
	speed: 0.0404s/iter; left time: 813.5797s
Epoch: 24 cost time: 10.92710280418396
Epoch: 24, Steps: 264 Train Loss: 28.6075 (Forecasting Loss:0.2263 + XiCon Loss:2.8381 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 28.4521542
	speed: 0.0441s/iter; left time: 881.0874s
	iters: 200, epoch: 25 | loss: 28.1457596
	speed: 0.0404s/iter; left time: 802.3243s
Epoch: 25 cost time: 11.095720767974854
Epoch: 25, Steps: 264 Train Loss: 28.6171 (Forecasting Loss:0.2262 + XiCon Loss:2.8391 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 29.1293983
	speed: 0.0430s/iter; left time: 846.8775s
	iters: 200, epoch: 26 | loss: 28.4499931
	speed: 0.0413s/iter; left time: 809.4792s
Epoch: 26 cost time: 11.062843799591064
Epoch: 26, Steps: 264 Train Loss: 28.6076 (Forecasting Loss:0.2262 + XiCon Loss:2.8381 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.9750633
	speed: 0.0419s/iter; left time: 813.9201s
	iters: 200, epoch: 27 | loss: 28.7598629
	speed: 0.0413s/iter; left time: 798.4290s
Epoch: 27 cost time: 10.9556245803833
Epoch: 27, Steps: 264 Train Loss: 28.6358 (Forecasting Loss:0.2261 + XiCon Loss:2.8410 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1124
Validation loss decreased (0.169840 --> 0.169835).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 28.8920975
	speed: 0.0418s/iter; left time: 800.8389s
	iters: 200, epoch: 28 | loss: 28.2002354
	speed: 0.0414s/iter; left time: 790.1019s
Epoch: 28 cost time: 11.050507545471191
Epoch: 28, Steps: 264 Train Loss: 28.5957 (Forecasting Loss:0.2262 + XiCon Loss:2.8370 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 28.2310734
	speed: 0.0433s/iter; left time: 817.9281s
	iters: 200, epoch: 29 | loss: 28.1701870
	speed: 0.0401s/iter; left time: 753.9400s
Epoch: 29 cost time: 10.995563983917236
Epoch: 29, Steps: 264 Train Loss: 28.6261 (Forecasting Loss:0.2263 + XiCon Loss:2.8400 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 28.2421703
	speed: 0.0437s/iter; left time: 814.8962s
	iters: 200, epoch: 30 | loss: 28.4765816
	speed: 0.0411s/iter; left time: 761.4782s
Epoch: 30 cost time: 11.171402931213379
Epoch: 30, Steps: 264 Train Loss: 28.6223 (Forecasting Loss:0.2262 + XiCon Loss:2.8396 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 28.5688553
	speed: 0.0434s/iter; left time: 798.2024s
	iters: 200, epoch: 31 | loss: 28.5362148
	speed: 0.0407s/iter; left time: 743.6124s
Epoch: 31 cost time: 10.961124420166016
Epoch: 31, Steps: 264 Train Loss: 28.6189 (Forecasting Loss:0.2262 + XiCon Loss:2.8393 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 28.3754215
	speed: 0.0436s/iter; left time: 789.7984s
	iters: 200, epoch: 32 | loss: 28.6075935
	speed: 0.0398s/iter; left time: 716.7275s
Epoch: 32 cost time: 10.937761545181274
Epoch: 32, Steps: 264 Train Loss: 28.6137 (Forecasting Loss:0.2263 + XiCon Loss:2.8387 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 28.8600101
	speed: 0.0431s/iter; left time: 769.4007s
	iters: 200, epoch: 33 | loss: 28.7002144
	speed: 0.0421s/iter; left time: 747.6109s
Epoch: 33 cost time: 11.085060596466064
Epoch: 33, Steps: 264 Train Loss: 28.5903 (Forecasting Loss:0.2262 + XiCon Loss:2.8364 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 28.3964710
	speed: 0.0427s/iter; left time: 751.3595s
	iters: 200, epoch: 34 | loss: 27.9592266
	speed: 0.0400s/iter; left time: 698.9270s
Epoch: 34 cost time: 11.014419794082642
Epoch: 34, Steps: 264 Train Loss: 28.6181 (Forecasting Loss:0.2262 + XiCon Loss:2.8392 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 28.4299355
	speed: 0.0423s/iter; left time: 732.4526s
	iters: 200, epoch: 35 | loss: 28.7079220
	speed: 0.0410s/iter; left time: 706.3173s
Epoch: 35 cost time: 10.965966701507568
Epoch: 35, Steps: 264 Train Loss: 28.5975 (Forecasting Loss:0.2262 + XiCon Loss:2.8371 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 28.1831303
	speed: 0.0435s/iter; left time: 742.2399s
	iters: 200, epoch: 36 | loss: 28.3195171
	speed: 0.0405s/iter; left time: 686.4302s
Epoch: 36 cost time: 11.013410091400146
Epoch: 36, Steps: 264 Train Loss: 28.6183 (Forecasting Loss:0.2262 + XiCon Loss:2.8392 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 28.1812057
	speed: 0.0424s/iter; left time: 711.5509s
	iters: 200, epoch: 37 | loss: 28.8071060
	speed: 0.0433s/iter; left time: 722.2444s
Epoch: 37 cost time: 11.172441244125366
Epoch: 37, Steps: 264 Train Loss: 28.5764 (Forecasting Loss:0.2262 + XiCon Loss:2.8350 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1124
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05247918888926506, mae:0.1723712831735611, mape:0.13450661301612854, mspe:0.032207366079092026 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.6943
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 30.9247856
	speed: 0.0418s/iter; left time: 1100.1392s
	iters: 200, epoch: 1 | loss: 30.3423920
	speed: 0.0381s/iter; left time: 997.5073s
Epoch: 1 cost time: 10.455431938171387
Epoch: 1, Steps: 264 Train Loss: 30.9521 (Forecasting Loss:0.2390 + XiCon Loss:3.0713 x Lambda(10.0)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1150
Validation loss decreased (inf --> 0.172952).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.6339092
	speed: 0.0460s/iter; left time: 1198.3103s
	iters: 200, epoch: 2 | loss: 30.8821602
	speed: 0.0421s/iter; left time: 1090.7527s
Epoch: 2 cost time: 11.449069023132324
Epoch: 2, Steps: 264 Train Loss: 30.0696 (Forecasting Loss:0.2420 + XiCon Loss:2.9828 x Lambda(10.0)), Vali MSE Loss: 0.1780 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 29.8456306
	speed: 0.0436s/iter; left time: 1124.7415s
	iters: 200, epoch: 3 | loss: 29.3790722
	speed: 0.0412s/iter; left time: 1057.8613s
Epoch: 3 cost time: 11.0961754322052
Epoch: 3, Steps: 264 Train Loss: 29.9198 (Forecasting Loss:0.2348 + XiCon Loss:2.9685 x Lambda(10.0)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.5038795
	speed: 0.0431s/iter; left time: 1099.1783s
	iters: 200, epoch: 4 | loss: 29.0793095
	speed: 0.0404s/iter; left time: 1026.6263s
Epoch: 4 cost time: 11.108128547668457
Epoch: 4, Steps: 264 Train Loss: 29.6304 (Forecasting Loss:0.2293 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1148
Validation loss decreased (0.172952 --> 0.170140).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.9104462
	speed: 0.0433s/iter; left time: 1093.4593s
	iters: 200, epoch: 5 | loss: 29.9007149
	speed: 0.0409s/iter; left time: 1028.6804s
Epoch: 5 cost time: 10.990494012832642
Epoch: 5, Steps: 264 Train Loss: 29.4988 (Forecasting Loss:0.2268 + XiCon Loss:2.9272 x Lambda(10.0)), Vali MSE Loss: 0.1686 Test MSE Loss: 0.1168
Validation loss decreased (0.170140 --> 0.168626).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 29.5114880
	speed: 0.0443s/iter; left time: 1106.3687s
	iters: 200, epoch: 6 | loss: 29.3540840
	speed: 0.0411s/iter; left time: 1023.1650s
Epoch: 6 cost time: 11.144593954086304
Epoch: 6, Steps: 264 Train Loss: 29.3819 (Forecasting Loss:0.2252 + XiCon Loss:2.9157 x Lambda(10.0)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1142
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.5512142
	speed: 0.0419s/iter; left time: 1035.2484s
	iters: 200, epoch: 7 | loss: 29.4371738
	speed: 0.0424s/iter; left time: 1043.8390s
Epoch: 7 cost time: 11.14795994758606
Epoch: 7, Steps: 264 Train Loss: 29.3588 (Forecasting Loss:0.2237 + XiCon Loss:2.9135 x Lambda(10.0)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.2225761
	speed: 0.0427s/iter; left time: 1044.2499s
	iters: 200, epoch: 8 | loss: 29.0887585
	speed: 0.0416s/iter; left time: 1013.5794s
Epoch: 8 cost time: 11.106342077255249
Epoch: 8, Steps: 264 Train Loss: 29.3742 (Forecasting Loss:0.2230 + XiCon Loss:2.9151 x Lambda(10.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 28.9298458
	speed: 0.0434s/iter; left time: 1048.6061s
	iters: 200, epoch: 9 | loss: 28.7377415
	speed: 0.0396s/iter; left time: 953.3658s
Epoch: 9 cost time: 10.879476070404053
Epoch: 9, Steps: 264 Train Loss: 29.3481 (Forecasting Loss:0.2228 + XiCon Loss:2.9125 x Lambda(10.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1162
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.4143429
	speed: 0.0436s/iter; left time: 1044.0909s
	iters: 200, epoch: 10 | loss: 29.1170902
	speed: 0.0408s/iter; left time: 971.0590s
Epoch: 10 cost time: 11.164802312850952
Epoch: 10, Steps: 264 Train Loss: 29.3764 (Forecasting Loss:0.2226 + XiCon Loss:2.9154 x Lambda(10.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.0150242
	speed: 0.0438s/iter; left time: 1036.7125s
	iters: 200, epoch: 11 | loss: 30.0962143
	speed: 0.0415s/iter; left time: 976.7806s
Epoch: 11 cost time: 11.161583185195923
Epoch: 11, Steps: 264 Train Loss: 29.4003 (Forecasting Loss:0.2225 + XiCon Loss:2.9178 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1165
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.0520248
	speed: 0.0433s/iter; left time: 1012.8336s
	iters: 200, epoch: 12 | loss: 28.8638973
	speed: 0.0417s/iter; left time: 972.0090s
Epoch: 12 cost time: 11.092328786849976
Epoch: 12, Steps: 264 Train Loss: 29.3366 (Forecasting Loss:0.2224 + XiCon Loss:2.9114 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1165
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 29.4718056
	speed: 0.0437s/iter; left time: 1010.3543s
	iters: 200, epoch: 13 | loss: 29.1616497
	speed: 0.0408s/iter; left time: 938.7085s
Epoch: 13 cost time: 11.086182355880737
Epoch: 13, Steps: 264 Train Loss: 29.3385 (Forecasting Loss:0.2226 + XiCon Loss:2.9116 x Lambda(10.0)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1164
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 29.1774693
	speed: 0.0439s/iter; left time: 1004.3444s
	iters: 200, epoch: 14 | loss: 28.8825436
	speed: 0.0409s/iter; left time: 931.4491s
Epoch: 14 cost time: 11.049017667770386
Epoch: 14, Steps: 264 Train Loss: 29.3312 (Forecasting Loss:0.2225 + XiCon Loss:2.9109 x Lambda(10.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1165
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 29.1300430
	speed: 0.0436s/iter; left time: 985.9730s
	iters: 200, epoch: 15 | loss: 28.7236900
	speed: 0.0412s/iter; left time: 926.7068s
Epoch: 15 cost time: 11.118021488189697
Epoch: 15, Steps: 264 Train Loss: 29.3598 (Forecasting Loss:0.2224 + XiCon Loss:2.9137 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1165
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.055880799889564514, mae:0.17774347960948944, mape:0.13896262645721436, mspe:0.03467576205730438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9728
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 31.2328110
	speed: 0.0405s/iter; left time: 1064.4424s
	iters: 200, epoch: 1 | loss: 30.0645027
	speed: 0.0378s/iter; left time: 991.6502s
Epoch: 1 cost time: 10.27083420753479
Epoch: 1, Steps: 264 Train Loss: 30.8476 (Forecasting Loss:0.2383 + XiCon Loss:3.0609 x Lambda(10.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1145
Validation loss decreased (inf --> 0.173703).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.9138794
	speed: 0.0465s/iter; left time: 1211.5984s
	iters: 200, epoch: 2 | loss: 29.8192291
	speed: 0.0396s/iter; left time: 1026.6363s
Epoch: 2 cost time: 11.189565181732178
Epoch: 2, Steps: 264 Train Loss: 29.8730 (Forecasting Loss:0.2409 + XiCon Loss:2.9632 x Lambda(10.0)), Vali MSE Loss: 0.1750 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.8476391
	speed: 0.0437s/iter; left time: 1126.2531s
	iters: 200, epoch: 3 | loss: 29.4977207
	speed: 0.0409s/iter; left time: 1051.0127s
Epoch: 3 cost time: 11.038437128067017
Epoch: 3, Steps: 264 Train Loss: 29.1676 (Forecasting Loss:0.2330 + XiCon Loss:2.8935 x Lambda(10.0)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1146
Validation loss decreased (0.173703 --> 0.172942).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.5945263
	speed: 0.0430s/iter; left time: 1096.2813s
	iters: 200, epoch: 4 | loss: 28.9741535
	speed: 0.0410s/iter; left time: 1042.5331s
Epoch: 4 cost time: 11.063642740249634
Epoch: 4, Steps: 264 Train Loss: 29.0300 (Forecasting Loss:0.2306 + XiCon Loss:2.8799 x Lambda(10.0)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1135
Validation loss decreased (0.172942 --> 0.171725).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.2316132
	speed: 0.0435s/iter; left time: 1097.3320s
	iters: 200, epoch: 5 | loss: 28.9300251
	speed: 0.0416s/iter; left time: 1045.2349s
Epoch: 5 cost time: 11.13498306274414
Epoch: 5, Steps: 264 Train Loss: 28.9991 (Forecasting Loss:0.2284 + XiCon Loss:2.8771 x Lambda(10.0)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1126
Validation loss decreased (0.171725 --> 0.171206).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.9912853
	speed: 0.0426s/iter; left time: 1063.1786s
	iters: 200, epoch: 6 | loss: 29.0858784
	speed: 0.0409s/iter; left time: 1016.7539s
Epoch: 6 cost time: 10.983287572860718
Epoch: 6, Steps: 264 Train Loss: 28.9834 (Forecasting Loss:0.2274 + XiCon Loss:2.8756 x Lambda(10.0)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1127
Validation loss decreased (0.171206 --> 0.170999).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.6357803
	speed: 0.0439s/iter; left time: 1085.4689s
	iters: 200, epoch: 7 | loss: 28.7736797
	speed: 0.0416s/iter; left time: 1024.5566s
Epoch: 7 cost time: 11.316701412200928
Epoch: 7, Steps: 264 Train Loss: 28.9510 (Forecasting Loss:0.2269 + XiCon Loss:2.8724 x Lambda(10.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1127
Validation loss decreased (0.170999 --> 0.170166).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 28.6347656
	speed: 0.0424s/iter; left time: 1037.5143s
	iters: 200, epoch: 8 | loss: 29.3837433
	speed: 0.0413s/iter; left time: 1004.7044s
Epoch: 8 cost time: 10.98802924156189
Epoch: 8, Steps: 264 Train Loss: 28.9467 (Forecasting Loss:0.2266 + XiCon Loss:2.8720 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170166 --> 0.169952).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.1337376
	speed: 0.0441s/iter; left time: 1066.9858s
	iters: 200, epoch: 9 | loss: 28.8680267
	speed: 0.0411s/iter; left time: 989.4010s
Epoch: 9 cost time: 11.133284568786621
Epoch: 9, Steps: 264 Train Loss: 28.9664 (Forecasting Loss:0.2266 + XiCon Loss:2.8740 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.8835011
	speed: 0.0429s/iter; left time: 1026.9215s
	iters: 200, epoch: 10 | loss: 29.4970016
	speed: 0.0424s/iter; left time: 1010.4493s
Epoch: 10 cost time: 11.171761512756348
Epoch: 10, Steps: 264 Train Loss: 28.9011 (Forecasting Loss:0.2264 + XiCon Loss:2.8675 x Lambda(10.0)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.2040386
	speed: 0.0433s/iter; left time: 1024.1512s
	iters: 200, epoch: 11 | loss: 28.9654198
	speed: 0.0401s/iter; left time: 944.5216s
Epoch: 11 cost time: 10.965997695922852
Epoch: 11, Steps: 264 Train Loss: 28.9405 (Forecasting Loss:0.2263 + XiCon Loss:2.8714 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 28.7788696
	speed: 0.0434s/iter; left time: 1015.6143s
	iters: 200, epoch: 12 | loss: 28.8754711
	speed: 0.0419s/iter; left time: 975.5761s
Epoch: 12 cost time: 11.171351194381714
Epoch: 12, Steps: 264 Train Loss: 28.9260 (Forecasting Loss:0.2263 + XiCon Loss:2.8700 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.8539753
	speed: 0.0443s/iter; left time: 1024.8072s
	iters: 200, epoch: 13 | loss: 28.7667236
	speed: 0.0403s/iter; left time: 927.2332s
Epoch: 13 cost time: 11.03590989112854
Epoch: 13, Steps: 264 Train Loss: 28.9209 (Forecasting Loss:0.2264 + XiCon Loss:2.8695 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.6334915
	speed: 0.0427s/iter; left time: 975.5642s
	iters: 200, epoch: 14 | loss: 28.5664043
	speed: 0.0423s/iter; left time: 963.3735s
Epoch: 14 cost time: 11.130597829818726
Epoch: 14, Steps: 264 Train Loss: 28.9395 (Forecasting Loss:0.2263 + XiCon Loss:2.8713 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.5845795
	speed: 0.0436s/iter; left time: 986.3354s
	iters: 200, epoch: 15 | loss: 28.5899963
	speed: 0.0401s/iter; left time: 901.7567s
Epoch: 15 cost time: 11.003024339675903
Epoch: 15, Steps: 264 Train Loss: 28.9156 (Forecasting Loss:0.2263 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 28.4967480
	speed: 0.0429s/iter; left time: 958.0308s
	iters: 200, epoch: 16 | loss: 28.7869930
	speed: 0.0398s/iter; left time: 886.0360s
Epoch: 16 cost time: 10.808457136154175
Epoch: 16, Steps: 264 Train Loss: 28.9519 (Forecasting Loss:0.2263 + XiCon Loss:2.8726 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
Validation loss decreased (0.169952 --> 0.169936).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 29.6020584
	speed: 0.0418s/iter; left time: 922.2272s
	iters: 200, epoch: 17 | loss: 28.2941341
	speed: 0.0410s/iter; left time: 900.7353s
Epoch: 17 cost time: 10.90410590171814
Epoch: 17, Steps: 264 Train Loss: 28.9522 (Forecasting Loss:0.2263 + XiCon Loss:2.8726 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 29.0111923
	speed: 0.0427s/iter; left time: 931.0843s
	iters: 200, epoch: 18 | loss: 28.9011993
	speed: 0.0402s/iter; left time: 872.9105s
Epoch: 18 cost time: 11.00178575515747
Epoch: 18, Steps: 264 Train Loss: 28.9448 (Forecasting Loss:0.2263 + XiCon Loss:2.8719 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
Validation loss decreased (0.169936 --> 0.169908).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.3332825
	speed: 0.0433s/iter; left time: 933.4235s
	iters: 200, epoch: 19 | loss: 29.4352417
	speed: 0.0411s/iter; left time: 881.1378s
Epoch: 19 cost time: 11.098201274871826
Epoch: 19, Steps: 264 Train Loss: 28.9157 (Forecasting Loss:0.2264 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1123
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.5872135
	speed: 0.0440s/iter; left time: 936.7214s
	iters: 200, epoch: 20 | loss: 28.8085480
	speed: 0.0411s/iter; left time: 870.7487s
Epoch: 20 cost time: 11.154220581054688
Epoch: 20, Steps: 264 Train Loss: 28.9388 (Forecasting Loss:0.2263 + XiCon Loss:2.8712 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 29.4226189
	speed: 0.0441s/iter; left time: 926.6898s
	iters: 200, epoch: 21 | loss: 29.2071838
	speed: 0.0420s/iter; left time: 877.9840s
Epoch: 21 cost time: 11.212192296981812
Epoch: 21, Steps: 264 Train Loss: 28.9371 (Forecasting Loss:0.2264 + XiCon Loss:2.8711 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 28.8428860
	speed: 0.0431s/iter; left time: 893.6533s
	iters: 200, epoch: 22 | loss: 28.6726551
	speed: 0.0410s/iter; left time: 846.2782s
Epoch: 22 cost time: 11.051659345626831
Epoch: 22, Steps: 264 Train Loss: 28.9407 (Forecasting Loss:0.2263 + XiCon Loss:2.8714 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 28.5075340
	speed: 0.0425s/iter; left time: 871.7892s
	iters: 200, epoch: 23 | loss: 29.0523930
	speed: 0.0408s/iter; left time: 831.3482s
Epoch: 23 cost time: 10.961601257324219
Epoch: 23, Steps: 264 Train Loss: 28.9293 (Forecasting Loss:0.2263 + XiCon Loss:2.8703 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 28.9101677
	speed: 0.0434s/iter; left time: 878.2101s
	iters: 200, epoch: 24 | loss: 28.7016296
	speed: 0.0418s/iter; left time: 841.8505s
Epoch: 24 cost time: 11.09685492515564
Epoch: 24, Steps: 264 Train Loss: 28.9316 (Forecasting Loss:0.2263 + XiCon Loss:2.8705 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 29.1578197
	speed: 0.0434s/iter; left time: 865.5079s
	iters: 200, epoch: 25 | loss: 28.8630123
	speed: 0.0415s/iter; left time: 824.9870s
Epoch: 25 cost time: 11.14378547668457
Epoch: 25, Steps: 264 Train Loss: 28.9146 (Forecasting Loss:0.2264 + XiCon Loss:2.8688 x Lambda(10.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 28.4870758
	speed: 0.0439s/iter; left time: 863.8916s
	iters: 200, epoch: 26 | loss: 29.0645103
	speed: 0.0411s/iter; left time: 805.8097s
Epoch: 26 cost time: 11.073452949523926
Epoch: 26, Steps: 264 Train Loss: 28.9828 (Forecasting Loss:0.2264 + XiCon Loss:2.8756 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.6916580
	speed: 0.0427s/iter; left time: 830.7609s
	iters: 200, epoch: 27 | loss: 29.2336464
	speed: 0.0401s/iter; left time: 776.0195s
Epoch: 27 cost time: 10.849995613098145
Epoch: 27, Steps: 264 Train Loss: 28.9455 (Forecasting Loss:0.2261 + XiCon Loss:2.8719 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 29.1192284
	speed: 0.0435s/iter; left time: 833.6850s
	iters: 200, epoch: 28 | loss: 28.6171761
	speed: 0.0408s/iter; left time: 778.1973s
Epoch: 28 cost time: 10.991397142410278
Epoch: 28, Steps: 264 Train Loss: 28.9145 (Forecasting Loss:0.2263 + XiCon Loss:2.8688 x Lambda(10.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.052415791898965836, mae:0.1721932739019394, mape:0.13429614901542664, mspe:0.032097723335027695 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0531+-0.00190, MAE:0.1734+-0.00302, MAPE:0.1353+-0.00252, MSPE:0.0327+-0.00139, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3837
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.2084541
	speed: 0.0443s/iter; left time: 1150.5447s
	iters: 200, epoch: 1 | loss: 33.8580284
	speed: 0.0383s/iter; left time: 992.3559s
Epoch: 1 cost time: 10.671645402908325
Epoch: 1, Steps: 261 Train Loss: 34.0009 (Forecasting Loss:0.2771 + XiCon Loss:3.3724 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
Validation loss decreased (inf --> 0.200732).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.5069141
	speed: 0.0458s/iter; left time: 1179.4030s
	iters: 200, epoch: 2 | loss: 31.4119511
	speed: 0.0444s/iter; left time: 1138.6462s
Epoch: 2 cost time: 11.589134931564331
Epoch: 2, Steps: 261 Train Loss: 31.5727 (Forecasting Loss:0.2749 + XiCon Loss:3.1298 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1419
Validation loss decreased (0.200732 --> 0.198846).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2284126
	speed: 0.0471s/iter; left time: 1201.2020s
	iters: 200, epoch: 3 | loss: 30.9106312
	speed: 0.0444s/iter; left time: 1126.7126s
Epoch: 3 cost time: 11.749918699264526
Epoch: 3, Steps: 261 Train Loss: 30.8933 (Forecasting Loss:0.2678 + XiCon Loss:3.0626 x Lambda(10.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1411
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4392319
	speed: 0.0445s/iter; left time: 1122.2779s
	iters: 200, epoch: 4 | loss: 30.4957829
	speed: 0.0436s/iter; left time: 1095.0896s
Epoch: 4 cost time: 11.477317571640015
Epoch: 4, Steps: 261 Train Loss: 30.5907 (Forecasting Loss:0.2612 + XiCon Loss:3.0329 x Lambda(10.0)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1410
Validation loss decreased (0.198846 --> 0.196692).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5781593
	speed: 0.0452s/iter; left time: 1128.5469s
	iters: 200, epoch: 5 | loss: 30.3730869
	speed: 0.0429s/iter; left time: 1067.0382s
Epoch: 5 cost time: 11.481236696243286
Epoch: 5, Steps: 261 Train Loss: 30.4795 (Forecasting Loss:0.2590 + XiCon Loss:3.0221 x Lambda(10.0)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.1392
Validation loss decreased (0.196692 --> 0.193953).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6030426
	speed: 0.0453s/iter; left time: 1118.1473s
	iters: 200, epoch: 6 | loss: 30.5303764
	speed: 0.0423s/iter; left time: 1040.5949s
Epoch: 6 cost time: 11.387183666229248
Epoch: 6, Steps: 261 Train Loss: 30.4518 (Forecasting Loss:0.2578 + XiCon Loss:3.0194 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1674042
	speed: 0.0461s/iter; left time: 1126.3925s
	iters: 200, epoch: 7 | loss: 30.6256180
	speed: 0.0431s/iter; left time: 1048.7954s
Epoch: 7 cost time: 11.556183099746704
Epoch: 7, Steps: 261 Train Loss: 30.4070 (Forecasting Loss:0.2578 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1386
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4536266
	speed: 0.0453s/iter; left time: 1094.9897s
	iters: 200, epoch: 8 | loss: 30.1601639
	speed: 0.0429s/iter; left time: 1031.8906s
Epoch: 8 cost time: 11.382239580154419
Epoch: 8, Steps: 261 Train Loss: 30.4220 (Forecasting Loss:0.2575 + XiCon Loss:3.0165 x Lambda(10.0)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.1388
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7138214
	speed: 0.0448s/iter; left time: 1071.4940s
	iters: 200, epoch: 9 | loss: 30.4318295
	speed: 0.0419s/iter; left time: 998.8273s
Epoch: 9 cost time: 11.360716342926025
Epoch: 9, Steps: 261 Train Loss: 30.4174 (Forecasting Loss:0.2573 + XiCon Loss:3.0160 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1387
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4795742
	speed: 0.0445s/iter; left time: 1052.7361s
	iters: 200, epoch: 10 | loss: 30.5503063
	speed: 0.0427s/iter; left time: 1005.8263s
Epoch: 10 cost time: 11.323407173156738
Epoch: 10, Steps: 261 Train Loss: 30.3953 (Forecasting Loss:0.2569 + XiCon Loss:3.0138 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.1387
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4506836
	speed: 0.0462s/iter; left time: 1081.2044s
	iters: 200, epoch: 11 | loss: 30.1237488
	speed: 0.0424s/iter; left time: 987.9510s
Epoch: 11 cost time: 11.428044319152832
Epoch: 11, Steps: 261 Train Loss: 30.4154 (Forecasting Loss:0.2572 + XiCon Loss:3.0158 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1386
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3645401
	speed: 0.0453s/iter; left time: 1048.4766s
	iters: 200, epoch: 12 | loss: 30.7877026
	speed: 0.0436s/iter; left time: 1004.8173s
Epoch: 12 cost time: 11.725921630859375
Epoch: 12, Steps: 261 Train Loss: 30.4126 (Forecasting Loss:0.2572 + XiCon Loss:3.0155 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1386
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8122234
	speed: 0.0438s/iter; left time: 1001.8923s
	iters: 200, epoch: 13 | loss: 30.2184563
	speed: 0.0425s/iter; left time: 968.1522s
Epoch: 13 cost time: 11.356632471084595
Epoch: 13, Steps: 261 Train Loss: 30.4061 (Forecasting Loss:0.2572 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1386
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4212456
	speed: 0.0449s/iter; left time: 1014.1531s
	iters: 200, epoch: 14 | loss: 30.3412685
	speed: 0.0420s/iter; left time: 945.2314s
Epoch: 14 cost time: 11.275357484817505
Epoch: 14, Steps: 261 Train Loss: 30.4043 (Forecasting Loss:0.2569 + XiCon Loss:3.0147 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1386
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3014507
	speed: 0.0461s/iter; left time: 1029.7932s
	iters: 200, epoch: 15 | loss: 30.2518730
	speed: 0.0419s/iter; left time: 932.4621s
Epoch: 15 cost time: 11.489502429962158
Epoch: 15, Steps: 261 Train Loss: 30.3897 (Forecasting Loss:0.2571 + XiCon Loss:3.0133 x Lambda(10.0)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1386
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07305603474378586, mae:0.20531709492206573, mape:0.15442855656147003, mspe:0.039573896676301956 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9312
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 33.7974930
	speed: 0.0358s/iter; left time: 930.0218s
	iters: 200, epoch: 1 | loss: 32.8931732
	speed: 0.0313s/iter; left time: 811.7653s
Epoch: 1 cost time: 8.739838361740112
Epoch: 1, Steps: 261 Train Loss: 33.2422 (Forecasting Loss:0.2770 + XiCon Loss:3.2965 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.200308).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.6743450
	speed: 0.0388s/iter; left time: 998.2364s
	iters: 200, epoch: 2 | loss: 31.4613838
	speed: 0.0360s/iter; left time: 923.4230s
Epoch: 2 cost time: 9.70429277420044
Epoch: 2, Steps: 261 Train Loss: 31.5717 (Forecasting Loss:0.2740 + XiCon Loss:3.1298 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1440
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2653160
	speed: 0.0397s/iter; left time: 1012.2844s
	iters: 200, epoch: 3 | loss: 30.3739510
	speed: 0.0382s/iter; left time: 969.5777s
Epoch: 3 cost time: 10.003741264343262
Epoch: 3, Steps: 261 Train Loss: 31.0001 (Forecasting Loss:0.2692 + XiCon Loss:3.0731 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1398
Validation loss decreased (0.200308 --> 0.195813).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6989307
	speed: 0.0408s/iter; left time: 1029.1560s
	iters: 200, epoch: 4 | loss: 30.7594337
	speed: 0.0383s/iter; left time: 961.9125s
Epoch: 4 cost time: 10.24168086051941
Epoch: 4, Steps: 261 Train Loss: 30.5068 (Forecasting Loss:0.2669 + XiCon Loss:3.0240 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1389
Validation loss decreased (0.195813 --> 0.195271).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6171875
	speed: 0.0414s/iter; left time: 1032.4999s
	iters: 200, epoch: 5 | loss: 30.5995216
	speed: 0.0401s/iter; left time: 997.7236s
Epoch: 5 cost time: 10.46041488647461
Epoch: 5, Steps: 261 Train Loss: 30.6995 (Forecasting Loss:0.2659 + XiCon Loss:3.0434 x Lambda(10.0)), Vali MSE Loss: 0.1943 Test MSE Loss: 0.1399
Validation loss decreased (0.195271 --> 0.194324).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7662296
	speed: 0.0425s/iter; left time: 1050.7982s
	iters: 200, epoch: 6 | loss: 30.6548691
	speed: 0.0391s/iter; left time: 962.0272s
Epoch: 6 cost time: 10.581742763519287
Epoch: 6, Steps: 261 Train Loss: 30.7429 (Forecasting Loss:0.2654 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.1397
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0704670
	speed: 0.0422s/iter; left time: 1030.9120s
	iters: 200, epoch: 7 | loss: 30.5205059
	speed: 0.0385s/iter; left time: 937.9487s
Epoch: 7 cost time: 10.511918544769287
Epoch: 7, Steps: 261 Train Loss: 30.7484 (Forecasting Loss:0.2650 + XiCon Loss:3.0483 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1395
Validation loss decreased (0.194324 --> 0.193379).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.7080975
	speed: 0.0422s/iter; left time: 1019.6682s
	iters: 200, epoch: 8 | loss: 30.6350250
	speed: 0.0387s/iter; left time: 932.5555s
Epoch: 8 cost time: 10.48865532875061
Epoch: 8, Steps: 261 Train Loss: 30.7337 (Forecasting Loss:0.2648 + XiCon Loss:3.0469 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1393
Validation loss decreased (0.193379 --> 0.193347).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3594646
	speed: 0.0433s/iter; left time: 1035.6146s
	iters: 200, epoch: 9 | loss: 30.5840416
	speed: 0.0390s/iter; left time: 928.1592s
Epoch: 9 cost time: 10.544576168060303
Epoch: 9, Steps: 261 Train Loss: 30.7144 (Forecasting Loss:0.2646 + XiCon Loss:3.0450 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1392
Validation loss decreased (0.193347 --> 0.193180).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7078056
	speed: 0.0416s/iter; left time: 984.7970s
	iters: 200, epoch: 10 | loss: 30.9434757
	speed: 0.0389s/iter; left time: 916.7431s
Epoch: 10 cost time: 10.438962936401367
Epoch: 10, Steps: 261 Train Loss: 30.7073 (Forecasting Loss:0.2647 + XiCon Loss:3.0443 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1392
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.7087727
	speed: 0.0426s/iter; left time: 996.0594s
	iters: 200, epoch: 11 | loss: 30.8683472
	speed: 0.0381s/iter; left time: 886.2368s
Epoch: 11 cost time: 10.423405885696411
Epoch: 11, Steps: 261 Train Loss: 30.7093 (Forecasting Loss:0.2645 + XiCon Loss:3.0445 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8204994
	speed: 0.0439s/iter; left time: 1014.6854s
	iters: 200, epoch: 12 | loss: 31.0433464
	speed: 0.0406s/iter; left time: 935.0203s
Epoch: 12 cost time: 10.832200050354004
Epoch: 12, Steps: 261 Train Loss: 30.7103 (Forecasting Loss:0.2645 + XiCon Loss:3.0446 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1392
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5212879
	speed: 0.0421s/iter; left time: 962.9862s
	iters: 200, epoch: 13 | loss: 30.5688095
	speed: 0.0403s/iter; left time: 916.8319s
Epoch: 13 cost time: 10.695497989654541
Epoch: 13, Steps: 261 Train Loss: 30.6797 (Forecasting Loss:0.2646 + XiCon Loss:3.0415 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1392
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8382988
	speed: 0.0426s/iter; left time: 963.2983s
	iters: 200, epoch: 14 | loss: 31.2231941
	speed: 0.0407s/iter; left time: 917.0168s
Epoch: 14 cost time: 10.722637176513672
Epoch: 14, Steps: 261 Train Loss: 30.6930 (Forecasting Loss:0.2644 + XiCon Loss:3.0429 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.5726700
	speed: 0.0423s/iter; left time: 944.3736s
	iters: 200, epoch: 15 | loss: 30.8814411
	speed: 0.0388s/iter; left time: 862.9063s
Epoch: 15 cost time: 10.40325117111206
Epoch: 15, Steps: 261 Train Loss: 30.6886 (Forecasting Loss:0.2644 + XiCon Loss:3.0424 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8212910
	speed: 0.0424s/iter; left time: 937.0011s
	iters: 200, epoch: 16 | loss: 30.6835499
	speed: 0.0396s/iter; left time: 871.3989s
Epoch: 16 cost time: 10.647287607192993
Epoch: 16, Steps: 261 Train Loss: 30.6987 (Forecasting Loss:0.2643 + XiCon Loss:3.0434 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1392
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4300289
	speed: 0.0438s/iter; left time: 955.7205s
	iters: 200, epoch: 17 | loss: 30.7168560
	speed: 0.0394s/iter; left time: 856.1760s
Epoch: 17 cost time: 10.724422693252563
Epoch: 17, Steps: 261 Train Loss: 30.7050 (Forecasting Loss:0.2644 + XiCon Loss:3.0441 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.6613216
	speed: 0.0422s/iter; left time: 909.3431s
	iters: 200, epoch: 18 | loss: 30.8266754
	speed: 0.0387s/iter; left time: 831.3977s
Epoch: 18 cost time: 10.45311450958252
Epoch: 18, Steps: 261 Train Loss: 30.7016 (Forecasting Loss:0.2645 + XiCon Loss:3.0437 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7097244
	speed: 0.0427s/iter; left time: 909.5320s
	iters: 200, epoch: 19 | loss: 30.7700176
	speed: 0.0401s/iter; left time: 850.5669s
Epoch: 19 cost time: 10.704958200454712
Epoch: 19, Steps: 261 Train Loss: 30.6904 (Forecasting Loss:0.2644 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1392
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07317973673343658, mae:0.20526593923568726, mape:0.15425865352153778, mspe:0.039540428668260574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1296
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 33.8586731
	speed: 0.0400s/iter; left time: 1040.4131s
	iters: 200, epoch: 1 | loss: 33.3405991
	speed: 0.0347s/iter; left time: 899.7897s
Epoch: 1 cost time: 9.558726787567139
Epoch: 1, Steps: 261 Train Loss: 33.6909 (Forecasting Loss:0.2778 + XiCon Loss:3.3413 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1416
Validation loss decreased (inf --> 0.198734).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.5331764
	speed: 0.0431s/iter; left time: 1108.4263s
	iters: 200, epoch: 2 | loss: 31.4510746
	speed: 0.0388s/iter; left time: 994.2192s
Epoch: 2 cost time: 10.515409708023071
Epoch: 2, Steps: 261 Train Loss: 31.5411 (Forecasting Loss:0.2741 + XiCon Loss:3.1267 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1426
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.3833332
	speed: 0.0418s/iter; left time: 1064.7547s
	iters: 200, epoch: 3 | loss: 31.3400383
	speed: 0.0394s/iter; left time: 1001.1609s
Epoch: 3 cost time: 10.515811920166016
Epoch: 3, Steps: 261 Train Loss: 31.3802 (Forecasting Loss:0.2690 + XiCon Loss:3.1111 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1418
Validation loss decreased (0.198734 --> 0.198211).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5782375
	speed: 0.0408s/iter; left time: 1029.2506s
	iters: 200, epoch: 4 | loss: 31.4558220
	speed: 0.0389s/iter; left time: 977.3833s
Epoch: 4 cost time: 10.351771116256714
Epoch: 4, Steps: 261 Train Loss: 31.3746 (Forecasting Loss:0.2673 + XiCon Loss:3.1107 x Lambda(10.0)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1400
Validation loss decreased (0.198211 --> 0.196873).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.4650517
	speed: 0.0414s/iter; left time: 1032.8261s
	iters: 200, epoch: 5 | loss: 31.2136326
	speed: 0.0383s/iter; left time: 951.7383s
Epoch: 5 cost time: 10.32699704170227
Epoch: 5, Steps: 261 Train Loss: 31.3705 (Forecasting Loss:0.2660 + XiCon Loss:3.1104 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1403
Validation loss decreased (0.196873 --> 0.196586).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.5364780
	speed: 0.0419s/iter; left time: 1033.8240s
	iters: 200, epoch: 6 | loss: 31.3870640
	speed: 0.0388s/iter; left time: 955.1655s
Epoch: 6 cost time: 10.444891452789307
Epoch: 6, Steps: 261 Train Loss: 31.3582 (Forecasting Loss:0.2655 + XiCon Loss:3.1093 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1400
Validation loss decreased (0.196586 --> 0.196088).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2658539
	speed: 0.0416s/iter; left time: 1016.6739s
	iters: 200, epoch: 7 | loss: 31.1740303
	speed: 0.0386s/iter; left time: 940.3634s
Epoch: 7 cost time: 10.408889532089233
Epoch: 7, Steps: 261 Train Loss: 31.3287 (Forecasting Loss:0.2651 + XiCon Loss:3.1064 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1403
Validation loss decreased (0.196088 --> 0.195872).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.2757111
	speed: 0.0385s/iter; left time: 931.6532s
	iters: 200, epoch: 8 | loss: 31.0229683
	speed: 0.0378s/iter; left time: 910.9023s
Epoch: 8 cost time: 10.005969524383545
Epoch: 8, Steps: 261 Train Loss: 31.2469 (Forecasting Loss:0.2650 + XiCon Loss:3.0982 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9916229
	speed: 0.0419s/iter; left time: 1000.8437s
	iters: 200, epoch: 9 | loss: 31.3537979
	speed: 0.0389s/iter; left time: 926.1082s
Epoch: 9 cost time: 10.539200782775879
Epoch: 9, Steps: 261 Train Loss: 31.1629 (Forecasting Loss:0.2650 + XiCon Loss:3.0898 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1402
Validation loss decreased (0.195872 --> 0.195809).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1661091
	speed: 0.0422s/iter; left time: 998.5690s
	iters: 200, epoch: 10 | loss: 31.1902657
	speed: 0.0388s/iter; left time: 913.4599s
Epoch: 10 cost time: 10.37213134765625
Epoch: 10, Steps: 261 Train Loss: 31.1123 (Forecasting Loss:0.2649 + XiCon Loss:3.0847 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2138844
	speed: 0.0415s/iter; left time: 970.3539s
	iters: 200, epoch: 11 | loss: 31.2297230
	speed: 0.0383s/iter; left time: 892.8010s
Epoch: 11 cost time: 10.314413070678711
Epoch: 11, Steps: 261 Train Loss: 31.1135 (Forecasting Loss:0.2649 + XiCon Loss:3.0849 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1402
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9625473
	speed: 0.0428s/iter; left time: 989.5168s
	iters: 200, epoch: 12 | loss: 31.2973576
	speed: 0.0412s/iter; left time: 948.3218s
Epoch: 12 cost time: 11.086612462997437
Epoch: 12, Steps: 261 Train Loss: 31.1070 (Forecasting Loss:0.2648 + XiCon Loss:3.0842 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2795372
	speed: 0.0420s/iter; left time: 960.7039s
	iters: 200, epoch: 13 | loss: 30.9877243
	speed: 0.0390s/iter; left time: 887.0361s
Epoch: 13 cost time: 10.404366970062256
Epoch: 13, Steps: 261 Train Loss: 31.0854 (Forecasting Loss:0.2648 + XiCon Loss:3.0821 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
Validation loss decreased (0.195809 --> 0.195807).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.1202698
	speed: 0.0420s/iter; left time: 949.4553s
	iters: 200, epoch: 14 | loss: 31.1617794
	speed: 0.0386s/iter; left time: 868.7396s
Epoch: 14 cost time: 10.447820663452148
Epoch: 14, Steps: 261 Train Loss: 31.0893 (Forecasting Loss:0.2648 + XiCon Loss:3.0825 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.1777458
	speed: 0.0403s/iter; left time: 901.5347s
	iters: 200, epoch: 15 | loss: 31.0647583
	speed: 0.0393s/iter; left time: 874.9573s
Epoch: 15 cost time: 10.363626956939697
Epoch: 15, Steps: 261 Train Loss: 31.0704 (Forecasting Loss:0.2648 + XiCon Loss:3.0806 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.0903702
	speed: 0.0422s/iter; left time: 931.7508s
	iters: 200, epoch: 16 | loss: 31.1323566
	speed: 0.0379s/iter; left time: 833.8002s
Epoch: 16 cost time: 10.413887023925781
Epoch: 16, Steps: 261 Train Loss: 31.0741 (Forecasting Loss:0.2648 + XiCon Loss:3.0809 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0656166
	speed: 0.0423s/iter; left time: 922.8594s
	iters: 200, epoch: 17 | loss: 31.1470356
	speed: 0.0383s/iter; left time: 831.8373s
Epoch: 17 cost time: 10.379283428192139
Epoch: 17, Steps: 261 Train Loss: 31.0876 (Forecasting Loss:0.2648 + XiCon Loss:3.0823 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
Validation loss decreased (0.195807 --> 0.195779).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.1152954
	speed: 0.0406s/iter; left time: 875.3519s
	iters: 200, epoch: 18 | loss: 31.1596584
	speed: 0.0399s/iter; left time: 856.5267s
Epoch: 18 cost time: 10.41676640510559
Epoch: 18, Steps: 261 Train Loss: 31.0815 (Forecasting Loss:0.2648 + XiCon Loss:3.0817 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.8376255
	speed: 0.0422s/iter; left time: 898.8376s
	iters: 200, epoch: 19 | loss: 31.3681812
	speed: 0.0387s/iter; left time: 819.9148s
Epoch: 19 cost time: 10.406477689743042
Epoch: 19, Steps: 261 Train Loss: 31.0731 (Forecasting Loss:0.2648 + XiCon Loss:3.0808 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.8687897
	speed: 0.0422s/iter; left time: 887.4957s
	iters: 200, epoch: 20 | loss: 31.0567036
	speed: 0.0386s/iter; left time: 807.4301s
Epoch: 20 cost time: 10.46324896812439
Epoch: 20, Steps: 261 Train Loss: 31.0887 (Forecasting Loss:0.2648 + XiCon Loss:3.0824 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.0422306
	speed: 0.0419s/iter; left time: 871.5413s
	iters: 200, epoch: 21 | loss: 31.2979984
	speed: 0.0396s/iter; left time: 819.7471s
Epoch: 21 cost time: 10.553841829299927
Epoch: 21, Steps: 261 Train Loss: 31.0814 (Forecasting Loss:0.2649 + XiCon Loss:3.0817 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.2919140
	speed: 0.0418s/iter; left time: 856.7816s
	iters: 200, epoch: 22 | loss: 30.9791756
	speed: 0.0385s/iter; left time: 785.4615s
Epoch: 22 cost time: 10.379572629928589
Epoch: 22, Steps: 261 Train Loss: 31.0832 (Forecasting Loss:0.2648 + XiCon Loss:3.0818 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.1092873
	speed: 0.0413s/iter; left time: 835.7419s
	iters: 200, epoch: 23 | loss: 31.1656132
	speed: 0.0376s/iter; left time: 758.0708s
Epoch: 23 cost time: 10.282764434814453
Epoch: 23, Steps: 261 Train Loss: 31.0920 (Forecasting Loss:0.2648 + XiCon Loss:3.0827 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.8985958
	speed: 0.0415s/iter; left time: 830.7088s
	iters: 200, epoch: 24 | loss: 31.0815792
	speed: 0.0387s/iter; left time: 769.6110s
Epoch: 24 cost time: 10.397150993347168
Epoch: 24, Steps: 261 Train Loss: 31.0851 (Forecasting Loss:0.2647 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.2225666
	speed: 0.0412s/iter; left time: 813.3818s
	iters: 200, epoch: 25 | loss: 31.0854664
	speed: 0.0391s/iter; left time: 767.6418s
Epoch: 25 cost time: 10.457366943359375
Epoch: 25, Steps: 261 Train Loss: 31.0767 (Forecasting Loss:0.2648 + XiCon Loss:3.0812 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.3284245
	speed: 0.0413s/iter; left time: 803.8987s
	iters: 200, epoch: 26 | loss: 31.2516766
	speed: 0.0380s/iter; left time: 735.5131s
Epoch: 26 cost time: 10.2854745388031
Epoch: 26, Steps: 261 Train Loss: 31.0749 (Forecasting Loss:0.2648 + XiCon Loss:3.0810 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.1564140
	speed: 0.0417s/iter; left time: 800.3735s
	iters: 200, epoch: 27 | loss: 31.0079613
	speed: 0.0393s/iter; left time: 751.7890s
Epoch: 27 cost time: 10.440364837646484
Epoch: 27, Steps: 261 Train Loss: 31.0935 (Forecasting Loss:0.2647 + XiCon Loss:3.0829 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07388029992580414, mae:0.206388458609581, mape:0.15485069155693054, mspe:0.03965095058083534 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6081
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.1369629
	speed: 0.0416s/iter; left time: 1081.1574s
	iters: 200, epoch: 1 | loss: 33.5463295
	speed: 0.0383s/iter; left time: 991.6343s
Epoch: 1 cost time: 10.314804315567017
Epoch: 1, Steps: 261 Train Loss: 33.7697 (Forecasting Loss:0.2776 + XiCon Loss:3.3492 x Lambda(10.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1423
Validation loss decreased (inf --> 0.201049).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.4662666
	speed: 0.0454s/iter; left time: 1169.2020s
	iters: 200, epoch: 2 | loss: 31.4875336
	speed: 0.0432s/iter; left time: 1108.4850s
Epoch: 2 cost time: 11.42345666885376
Epoch: 2, Steps: 261 Train Loss: 31.6255 (Forecasting Loss:0.2737 + XiCon Loss:3.1352 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1422
Validation loss decreased (0.201049 --> 0.196570).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.9729195
	speed: 0.0448s/iter; left time: 1141.3521s
	iters: 200, epoch: 3 | loss: 31.4096737
	speed: 0.0421s/iter; left time: 1068.8581s
Epoch: 3 cost time: 11.307928085327148
Epoch: 3, Steps: 261 Train Loss: 31.5608 (Forecasting Loss:0.2681 + XiCon Loss:3.1293 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1398
Validation loss decreased (0.196570 --> 0.193300).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1966324
	speed: 0.0455s/iter; left time: 1146.6015s
	iters: 200, epoch: 4 | loss: 31.2974472
	speed: 0.0428s/iter; left time: 1076.1786s
Epoch: 4 cost time: 11.461082220077515
Epoch: 4, Steps: 261 Train Loss: 31.2751 (Forecasting Loss:0.2666 + XiCon Loss:3.1009 x Lambda(10.0)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7499638
	speed: 0.0439s/iter; left time: 1096.1693s
	iters: 200, epoch: 5 | loss: 30.8352318
	speed: 0.0413s/iter; left time: 1026.6911s
Epoch: 5 cost time: 11.070544958114624
Epoch: 5, Steps: 261 Train Loss: 31.2210 (Forecasting Loss:0.2659 + XiCon Loss:3.0955 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1393
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.3659019
	speed: 0.0441s/iter; left time: 1089.3389s
	iters: 200, epoch: 6 | loss: 30.8734131
	speed: 0.0422s/iter; left time: 1037.2516s
Epoch: 6 cost time: 11.144795179367065
Epoch: 6, Steps: 261 Train Loss: 31.1423 (Forecasting Loss:0.2648 + XiCon Loss:3.0878 x Lambda(10.0)), Vali MSE Loss: 0.1930 Test MSE Loss: 0.1390
Validation loss decreased (0.193300 --> 0.192980).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6422462
	speed: 0.0448s/iter; left time: 1095.6031s
	iters: 200, epoch: 7 | loss: 31.0796394
	speed: 0.0416s/iter; left time: 1013.2475s
Epoch: 7 cost time: 11.214458465576172
Epoch: 7, Steps: 261 Train Loss: 31.1455 (Forecasting Loss:0.2646 + XiCon Loss:3.0881 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1387
Validation loss decreased (0.192980 --> 0.192859).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.4184780
	speed: 0.0436s/iter; left time: 1055.0076s
	iters: 200, epoch: 8 | loss: 31.2834473
	speed: 0.0430s/iter; left time: 1034.7965s
Epoch: 8 cost time: 11.22895860671997
Epoch: 8, Steps: 261 Train Loss: 31.1167 (Forecasting Loss:0.2644 + XiCon Loss:3.0852 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1390
Validation loss decreased (0.192859 --> 0.192754).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9024601
	speed: 0.0444s/iter; left time: 1061.0437s
	iters: 200, epoch: 9 | loss: 30.7312965
	speed: 0.0423s/iter; left time: 1008.0814s
Epoch: 9 cost time: 11.240751266479492
Epoch: 9, Steps: 261 Train Loss: 31.1062 (Forecasting Loss:0.2644 + XiCon Loss:3.0842 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.2175789
	speed: 0.0445s/iter; left time: 1052.6594s
	iters: 200, epoch: 10 | loss: 30.6187725
	speed: 0.0430s/iter; left time: 1012.5845s
Epoch: 10 cost time: 11.344709873199463
Epoch: 10, Steps: 261 Train Loss: 31.1307 (Forecasting Loss:0.2643 + XiCon Loss:3.0866 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1388
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.3003197
	speed: 0.0454s/iter; left time: 1062.4896s
	iters: 200, epoch: 11 | loss: 30.9625111
	speed: 0.0423s/iter; left time: 984.6559s
Epoch: 11 cost time: 11.392422437667847
Epoch: 11, Steps: 261 Train Loss: 31.1390 (Forecasting Loss:0.2642 + XiCon Loss:3.0875 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1388
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.3949547
	speed: 0.0454s/iter; left time: 1049.6755s
	iters: 200, epoch: 12 | loss: 30.8421936
	speed: 0.0419s/iter; left time: 965.4794s
Epoch: 12 cost time: 11.28110933303833
Epoch: 12, Steps: 261 Train Loss: 31.1047 (Forecasting Loss:0.2643 + XiCon Loss:3.0840 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1388
Validation loss decreased (0.192754 --> 0.192753).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6598186
	speed: 0.0442s/iter; left time: 1010.7991s
	iters: 200, epoch: 13 | loss: 30.8295765
	speed: 0.0418s/iter; left time: 950.6596s
Epoch: 13 cost time: 11.251372814178467
Epoch: 13, Steps: 261 Train Loss: 31.1013 (Forecasting Loss:0.2642 + XiCon Loss:3.0837 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.2773285
	speed: 0.0444s/iter; left time: 1004.2683s
	iters: 200, epoch: 14 | loss: 30.8443928
	speed: 0.0418s/iter; left time: 940.1021s
Epoch: 14 cost time: 11.216524362564087
Epoch: 14, Steps: 261 Train Loss: 31.1081 (Forecasting Loss:0.2643 + XiCon Loss:3.0844 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.7396317
	speed: 0.0451s/iter; left time: 1008.2975s
	iters: 200, epoch: 15 | loss: 31.2964077
	speed: 0.0427s/iter; left time: 950.5331s
Epoch: 15 cost time: 11.438778162002563
Epoch: 15, Steps: 261 Train Loss: 31.1120 (Forecasting Loss:0.2642 + XiCon Loss:3.0848 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.2834682
	speed: 0.0435s/iter; left time: 961.4613s
	iters: 200, epoch: 16 | loss: 31.1278954
	speed: 0.0415s/iter; left time: 912.3277s
Epoch: 16 cost time: 11.158464670181274
Epoch: 16, Steps: 261 Train Loss: 31.1140 (Forecasting Loss:0.2643 + XiCon Loss:3.0850 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.8881207
	speed: 0.0442s/iter; left time: 963.7159s
	iters: 200, epoch: 17 | loss: 31.3049450
	speed: 0.0423s/iter; left time: 919.2504s
Epoch: 17 cost time: 11.273387432098389
Epoch: 17, Steps: 261 Train Loss: 31.1004 (Forecasting Loss:0.2643 + XiCon Loss:3.0836 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.4518661
	speed: 0.0457s/iter; left time: 985.0530s
	iters: 200, epoch: 18 | loss: 30.8545723
	speed: 0.0419s/iter; left time: 899.1593s
Epoch: 18 cost time: 11.273830890655518
Epoch: 18, Steps: 261 Train Loss: 31.1433 (Forecasting Loss:0.2643 + XiCon Loss:3.0879 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.5894547
	speed: 0.0450s/iter; left time: 958.7124s
	iters: 200, epoch: 19 | loss: 31.2444324
	speed: 0.0427s/iter; left time: 904.8392s
Epoch: 19 cost time: 11.298668384552002
Epoch: 19, Steps: 261 Train Loss: 31.0867 (Forecasting Loss:0.2643 + XiCon Loss:3.0822 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1389
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.0104122
	speed: 0.0445s/iter; left time: 935.8766s
	iters: 200, epoch: 20 | loss: 31.1963367
	speed: 0.0407s/iter; left time: 852.1456s
Epoch: 20 cost time: 11.147960901260376
Epoch: 20, Steps: 261 Train Loss: 31.1079 (Forecasting Loss:0.2643 + XiCon Loss:3.0844 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.1407509
	speed: 0.0450s/iter; left time: 935.0783s
	iters: 200, epoch: 21 | loss: 31.0839005
	speed: 0.0419s/iter; left time: 866.1721s
Epoch: 21 cost time: 11.289843797683716
Epoch: 21, Steps: 261 Train Loss: 31.1287 (Forecasting Loss:0.2642 + XiCon Loss:3.0864 x Lambda(10.0)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.1389
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.1799774
	speed: 0.0444s/iter; left time: 911.1223s
	iters: 200, epoch: 22 | loss: 31.3412113
	speed: 0.0418s/iter; left time: 854.3330s
Epoch: 22 cost time: 11.160175085067749
Epoch: 22, Steps: 261 Train Loss: 31.1019 (Forecasting Loss:0.2641 + XiCon Loss:3.0838 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1389
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0726933553814888, mae:0.20498403906822205, mape:0.15456655621528625, mspe:0.03983865678310394 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9657
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 34.1311913
	speed: 0.0390s/iter; left time: 1015.0438s
	iters: 200, epoch: 1 | loss: 33.4725266
	speed: 0.0347s/iter; left time: 899.7760s
Epoch: 1 cost time: 9.581027507781982
Epoch: 1, Steps: 261 Train Loss: 33.8522 (Forecasting Loss:0.2766 + XiCon Loss:3.3576 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1421
Validation loss decreased (inf --> 0.198267).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1804371
	speed: 0.0422s/iter; left time: 1085.1636s
	iters: 200, epoch: 2 | loss: 31.7605076
	speed: 0.0380s/iter; left time: 973.5746s
Epoch: 2 cost time: 10.350637197494507
Epoch: 2, Steps: 261 Train Loss: 31.5213 (Forecasting Loss:0.2736 + XiCon Loss:3.1248 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1426
Validation loss decreased (0.198267 --> 0.198263).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.1037922
	speed: 0.0422s/iter; left time: 1074.6082s
	iters: 200, epoch: 3 | loss: 30.5314274
	speed: 0.0388s/iter; left time: 985.4713s
Epoch: 3 cost time: 10.49813961982727
Epoch: 3, Steps: 261 Train Loss: 31.0679 (Forecasting Loss:0.2690 + XiCon Loss:3.0799 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1397
Validation loss decreased (0.198263 --> 0.197575).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1743679
	speed: 0.0426s/iter; left time: 1075.0012s
	iters: 200, epoch: 4 | loss: 30.4079552
	speed: 0.0394s/iter; left time: 989.0067s
Epoch: 4 cost time: 10.566307544708252
Epoch: 4, Steps: 261 Train Loss: 30.5502 (Forecasting Loss:0.2649 + XiCon Loss:3.0285 x Lambda(10.0)), Vali MSE Loss: 0.1907 Test MSE Loss: 0.1394
Validation loss decreased (0.197575 --> 0.190718).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3961163
	speed: 0.0420s/iter; left time: 1048.5537s
	iters: 200, epoch: 5 | loss: 30.4900818
	speed: 0.0388s/iter; left time: 965.2208s
Epoch: 5 cost time: 10.44248628616333
Epoch: 5, Steps: 261 Train Loss: 30.3435 (Forecasting Loss:0.2619 + XiCon Loss:3.0082 x Lambda(10.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1394
Validation loss decreased (0.190718 --> 0.189996).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.0941982
	speed: 0.0428s/iter; left time: 1057.4562s
	iters: 200, epoch: 6 | loss: 29.9547901
	speed: 0.0389s/iter; left time: 955.8985s
Epoch: 6 cost time: 10.57290267944336
Epoch: 6, Steps: 261 Train Loss: 30.2363 (Forecasting Loss:0.2600 + XiCon Loss:2.9976 x Lambda(10.0)), Vali MSE Loss: 0.1896 Test MSE Loss: 0.1380
Validation loss decreased (0.189996 --> 0.189597).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0196705
	speed: 0.0415s/iter; left time: 1013.2771s
	iters: 200, epoch: 7 | loss: 30.1932983
	speed: 0.0407s/iter; left time: 990.5935s
Epoch: 7 cost time: 10.574965953826904
Epoch: 7, Steps: 261 Train Loss: 30.2049 (Forecasting Loss:0.2592 + XiCon Loss:2.9946 x Lambda(10.0)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1380
Validation loss decreased (0.189597 --> 0.189384).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5080986
	speed: 0.0405s/iter; left time: 978.4424s
	iters: 200, epoch: 8 | loss: 30.0048866
	speed: 0.0394s/iter; left time: 947.7470s
Epoch: 8 cost time: 10.293102025985718
Epoch: 8, Steps: 261 Train Loss: 30.1715 (Forecasting Loss:0.2586 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.1383
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0743046
	speed: 0.0426s/iter; left time: 1018.5728s
	iters: 200, epoch: 9 | loss: 30.3053761
	speed: 0.0384s/iter; left time: 915.0529s
Epoch: 9 cost time: 10.518773794174194
Epoch: 9, Steps: 261 Train Loss: 30.1706 (Forecasting Loss:0.2584 + XiCon Loss:2.9912 x Lambda(10.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1380
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1700726
	speed: 0.0414s/iter; left time: 980.0608s
	iters: 200, epoch: 10 | loss: 29.9049015
	speed: 0.0399s/iter; left time: 939.1780s
Epoch: 10 cost time: 10.489361047744751
Epoch: 10, Steps: 261 Train Loss: 30.1782 (Forecasting Loss:0.2585 + XiCon Loss:2.9920 x Lambda(10.0)), Vali MSE Loss: 0.1902 Test MSE Loss: 0.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6391659
	speed: 0.0420s/iter; left time: 981.9294s
	iters: 200, epoch: 11 | loss: 30.2219486
	speed: 0.0389s/iter; left time: 906.1907s
Epoch: 11 cost time: 10.455856800079346
Epoch: 11, Steps: 261 Train Loss: 30.1719 (Forecasting Loss:0.2584 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0875683
	speed: 0.0418s/iter; left time: 967.1270s
	iters: 200, epoch: 12 | loss: 30.2146988
	speed: 0.0384s/iter; left time: 883.8190s
Epoch: 12 cost time: 10.449611902236938
Epoch: 12, Steps: 261 Train Loss: 30.1646 (Forecasting Loss:0.2583 + XiCon Loss:2.9906 x Lambda(10.0)), Vali MSE Loss: 0.1904 Test MSE Loss: 0.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.9757195
	speed: 0.0419s/iter; left time: 958.2979s
	iters: 200, epoch: 13 | loss: 30.0240612
	speed: 0.0395s/iter; left time: 899.5361s
Epoch: 13 cost time: 10.505072832107544
Epoch: 13, Steps: 261 Train Loss: 30.1864 (Forecasting Loss:0.2585 + XiCon Loss:2.9928 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1379
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2150784
	speed: 0.0422s/iter; left time: 953.6787s
	iters: 200, epoch: 14 | loss: 29.9201450
	speed: 0.0386s/iter; left time: 869.5301s
Epoch: 14 cost time: 10.517894268035889
Epoch: 14, Steps: 261 Train Loss: 30.1717 (Forecasting Loss:0.2582 + XiCon Loss:2.9914 x Lambda(10.0)), Vali MSE Loss: 0.1902 Test MSE Loss: 0.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.0616913
	speed: 0.0421s/iter; left time: 941.6254s
	iters: 200, epoch: 15 | loss: 30.0376396
	speed: 0.0391s/iter; left time: 869.2489s
Epoch: 15 cost time: 10.463538646697998
Epoch: 15, Steps: 261 Train Loss: 30.1756 (Forecasting Loss:0.2582 + XiCon Loss:2.9917 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1379
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4919796
	speed: 0.0422s/iter; left time: 931.3407s
	iters: 200, epoch: 16 | loss: 29.9010925
	speed: 0.0390s/iter; left time: 857.9617s
Epoch: 16 cost time: 10.558998107910156
Epoch: 16, Steps: 261 Train Loss: 30.1679 (Forecasting Loss:0.2583 + XiCon Loss:2.9910 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1379
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.1247883
	speed: 0.0418s/iter; left time: 912.6404s
	iters: 200, epoch: 17 | loss: 30.4784889
	speed: 0.0392s/iter; left time: 850.8116s
Epoch: 17 cost time: 10.484387874603271
Epoch: 17, Steps: 261 Train Loss: 30.1715 (Forecasting Loss:0.2584 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 0.1379
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07194111496210098, mae:0.20408347249031067, mape:0.15567371249198914, mspe:0.041590187698602676 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0730+-0.00088, MAE:0.2052+-0.00102, MAPE:0.1548+-0.00069, MSPE:0.0400+-0.00109, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0776
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.0972481
	speed: 0.0387s/iter; left time: 1025.9667s
	iters: 200, epoch: 1 | loss: 32.2468224
	speed: 0.0332s/iter; left time: 877.0754s
Epoch: 1 cost time: 9.353782892227173
Epoch: 1, Steps: 266 Train Loss: 32.7987 (Forecasting Loss:0.1871 + XiCon Loss:3.2612 x Lambda(10.0)), Vali MSE Loss: 0.1584 Test MSE Loss: 0.1380
Validation loss decreased (inf --> 0.158350).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.8993015
	speed: 0.0351s/iter; left time: 921.8198s
	iters: 200, epoch: 2 | loss: 31.4018288
	speed: 0.0340s/iter; left time: 888.3162s
Epoch: 2 cost time: 9.099344968795776
Epoch: 2, Steps: 266 Train Loss: 31.5936 (Forecasting Loss:0.1588 + XiCon Loss:3.1435 x Lambda(10.0)), Vali MSE Loss: 0.1571 Test MSE Loss: 0.1330
Validation loss decreased (0.158350 --> 0.157054).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1223259
	speed: 0.0349s/iter; left time: 906.7438s
	iters: 200, epoch: 3 | loss: 30.3499050
	speed: 0.0333s/iter; left time: 860.3601s
Epoch: 3 cost time: 9.09322214126587
Epoch: 3, Steps: 266 Train Loss: 30.6082 (Forecasting Loss:0.1522 + XiCon Loss:3.0456 x Lambda(10.0)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.1296
Validation loss decreased (0.157054 --> 0.148509).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9918442
	speed: 0.0349s/iter; left time: 896.9467s
	iters: 200, epoch: 4 | loss: 30.1901016
	speed: 0.0328s/iter; left time: 839.6081s
Epoch: 4 cost time: 8.985034465789795
Epoch: 4, Steps: 266 Train Loss: 30.4707 (Forecasting Loss:0.1497 + XiCon Loss:3.0321 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1277
Validation loss decreased (0.148509 --> 0.145970).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6904984
	speed: 0.0356s/iter; left time: 906.2637s
	iters: 200, epoch: 5 | loss: 30.4966679
	speed: 0.0354s/iter; left time: 897.7591s
Epoch: 5 cost time: 9.491151094436646
Epoch: 5, Steps: 266 Train Loss: 30.4058 (Forecasting Loss:0.1480 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.1260
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5459881
	speed: 0.0346s/iter; left time: 870.7420s
	iters: 200, epoch: 6 | loss: 30.6257935
	speed: 0.0337s/iter; left time: 845.2820s
Epoch: 6 cost time: 8.947919607162476
Epoch: 6, Steps: 266 Train Loss: 30.4157 (Forecasting Loss:0.1474 + XiCon Loss:3.0268 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1246
Validation loss decreased (0.145970 --> 0.144579).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4156857
	speed: 0.0354s/iter; left time: 881.3612s
	iters: 200, epoch: 7 | loss: 30.0769672
	speed: 0.0331s/iter; left time: 822.2854s
Epoch: 7 cost time: 9.10405683517456
Epoch: 7, Steps: 266 Train Loss: 30.4000 (Forecasting Loss:0.1472 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144579 --> 0.144433).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1382198
	speed: 0.0346s/iter; left time: 851.4098s
	iters: 200, epoch: 8 | loss: 30.3978958
	speed: 0.0324s/iter; left time: 795.7208s
Epoch: 8 cost time: 8.999068260192871
Epoch: 8, Steps: 266 Train Loss: 30.3739 (Forecasting Loss:0.1470 + XiCon Loss:3.0227 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
Validation loss decreased (0.144433 --> 0.144200).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5173950
	speed: 0.0342s/iter; left time: 832.6452s
	iters: 200, epoch: 9 | loss: 30.5743771
	speed: 0.0326s/iter; left time: 791.1600s
Epoch: 9 cost time: 8.934992790222168
Epoch: 9, Steps: 266 Train Loss: 30.4069 (Forecasting Loss:0.1469 + XiCon Loss:3.0260 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2700481
	speed: 0.0366s/iter; left time: 881.3964s
	iters: 200, epoch: 10 | loss: 30.6363487
	speed: 0.0357s/iter; left time: 855.9360s
Epoch: 10 cost time: 9.514841079711914
Epoch: 10, Steps: 266 Train Loss: 30.4023 (Forecasting Loss:0.1469 + XiCon Loss:3.0255 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3807621
	speed: 0.0357s/iter; left time: 851.8977s
	iters: 200, epoch: 11 | loss: 30.3036671
	speed: 0.0333s/iter; left time: 790.5657s
Epoch: 11 cost time: 9.206117868423462
Epoch: 11, Steps: 266 Train Loss: 30.3979 (Forecasting Loss:0.1468 + XiCon Loss:3.0251 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.2028770
	speed: 0.0364s/iter; left time: 857.0666s
	iters: 200, epoch: 12 | loss: 30.1544476
	speed: 0.0344s/iter; left time: 807.7910s
Epoch: 12 cost time: 9.324289083480835
Epoch: 12, Steps: 266 Train Loss: 30.3954 (Forecasting Loss:0.1468 + XiCon Loss:3.0249 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.9025803
	speed: 0.0359s/iter; left time: 836.8336s
	iters: 200, epoch: 13 | loss: 31.0424252
	speed: 0.0334s/iter; left time: 775.9122s
Epoch: 13 cost time: 9.33297610282898
Epoch: 13, Steps: 266 Train Loss: 30.3572 (Forecasting Loss:0.1468 + XiCon Loss:3.0210 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
Validation loss decreased (0.144200 --> 0.144025).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5889740
	speed: 0.0388s/iter; left time: 895.0108s
	iters: 200, epoch: 14 | loss: 30.0869999
	speed: 0.0329s/iter; left time: 754.8149s
Epoch: 14 cost time: 9.394661664962769
Epoch: 14, Steps: 266 Train Loss: 30.4035 (Forecasting Loss:0.1468 + XiCon Loss:3.0257 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9115524
	speed: 0.0352s/iter; left time: 800.9011s
	iters: 200, epoch: 15 | loss: 29.9839420
	speed: 0.0336s/iter; left time: 763.0143s
Epoch: 15 cost time: 9.015706777572632
Epoch: 15, Steps: 266 Train Loss: 30.3897 (Forecasting Loss:0.1467 + XiCon Loss:3.0243 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6928291
	speed: 0.0351s/iter; left time: 789.9596s
	iters: 200, epoch: 16 | loss: 30.0918999
	speed: 0.0330s/iter; left time: 739.0680s
Epoch: 16 cost time: 8.952881813049316
Epoch: 16, Steps: 266 Train Loss: 30.3935 (Forecasting Loss:0.1468 + XiCon Loss:3.0247 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.6326847
	speed: 0.0361s/iter; left time: 802.2837s
	iters: 200, epoch: 17 | loss: 30.2760601
	speed: 0.0327s/iter; left time: 724.8121s
Epoch: 17 cost time: 9.033531904220581
Epoch: 17, Steps: 266 Train Loss: 30.3983 (Forecasting Loss:0.1467 + XiCon Loss:3.0252 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.6652775
	speed: 0.0346s/iter; left time: 760.5311s
	iters: 200, epoch: 18 | loss: 30.0416870
	speed: 0.0337s/iter; left time: 737.7010s
Epoch: 18 cost time: 9.195300817489624
Epoch: 18, Steps: 266 Train Loss: 30.3716 (Forecasting Loss:0.1468 + XiCon Loss:3.0225 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3417397
	speed: 0.0360s/iter; left time: 782.6908s
	iters: 200, epoch: 19 | loss: 30.1631317
	speed: 0.0335s/iter; left time: 724.9407s
Epoch: 19 cost time: 9.144492149353027
Epoch: 19, Steps: 266 Train Loss: 30.3939 (Forecasting Loss:0.1468 + XiCon Loss:3.0247 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5947838
	speed: 0.0362s/iter; left time: 775.6117s
	iters: 200, epoch: 20 | loss: 30.2528515
	speed: 0.0340s/iter; left time: 726.2221s
Epoch: 20 cost time: 9.242947340011597
Epoch: 20, Steps: 266 Train Loss: 30.3938 (Forecasting Loss:0.1467 + XiCon Loss:3.0247 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.8136597
	speed: 0.0354s/iter; left time: 750.3865s
	iters: 200, epoch: 21 | loss: 30.1942596
	speed: 0.0341s/iter; left time: 718.7947s
Epoch: 21 cost time: 9.16675329208374
Epoch: 21, Steps: 266 Train Loss: 30.3858 (Forecasting Loss:0.1467 + XiCon Loss:3.0239 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.8821411
	speed: 0.0356s/iter; left time: 745.1457s
	iters: 200, epoch: 22 | loss: 30.3964405
	speed: 0.0335s/iter; left time: 696.4816s
Epoch: 22 cost time: 9.104993343353271
Epoch: 22, Steps: 266 Train Loss: 30.3903 (Forecasting Loss:0.1469 + XiCon Loss:3.0243 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.1901054
	speed: 0.0353s/iter; left time: 729.4217s
	iters: 200, epoch: 23 | loss: 30.7595387
	speed: 0.0334s/iter; left time: 685.6793s
Epoch: 23 cost time: 9.127699375152588
Epoch: 23, Steps: 266 Train Loss: 30.3999 (Forecasting Loss:0.1467 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06463892757892609, mae:0.18432551622390747, mape:0.44844508171081543, mspe:8.12573528289795 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9718
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.0921211
	speed: 0.0347s/iter; left time: 919.9433s
	iters: 200, epoch: 1 | loss: 32.2242012
	speed: 0.0341s/iter; left time: 899.7417s
Epoch: 1 cost time: 9.072823286056519
Epoch: 1, Steps: 266 Train Loss: 32.8978 (Forecasting Loss:0.1857 + XiCon Loss:3.2712 x Lambda(10.0)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1357
Validation loss decreased (inf --> 0.158591).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7496490
	speed: 0.0354s/iter; left time: 929.2264s
	iters: 200, epoch: 2 | loss: 31.5949364
	speed: 0.0339s/iter; left time: 885.8460s
Epoch: 2 cost time: 9.174415826797485
Epoch: 2, Steps: 266 Train Loss: 32.0126 (Forecasting Loss:0.1586 + XiCon Loss:3.1854 x Lambda(10.0)), Vali MSE Loss: 0.1531 Test MSE Loss: 0.1321
Validation loss decreased (0.158591 --> 0.153100).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4695530
	speed: 0.0370s/iter; left time: 960.1050s
	iters: 200, epoch: 3 | loss: 31.0410385
	speed: 0.0342s/iter; left time: 883.9341s
Epoch: 3 cost time: 9.355096340179443
Epoch: 3, Steps: 266 Train Loss: 30.8167 (Forecasting Loss:0.1517 + XiCon Loss:3.0665 x Lambda(10.0)), Vali MSE Loss: 0.1488 Test MSE Loss: 0.1280
Validation loss decreased (0.153100 --> 0.148774).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0990849
	speed: 0.0363s/iter; left time: 931.9047s
	iters: 200, epoch: 4 | loss: 31.1761055
	speed: 0.0328s/iter; left time: 841.0326s
Epoch: 4 cost time: 9.13565707206726
Epoch: 4, Steps: 266 Train Loss: 30.6486 (Forecasting Loss:0.1495 + XiCon Loss:3.0499 x Lambda(10.0)), Vali MSE Loss: 0.1471 Test MSE Loss: 0.1255
Validation loss decreased (0.148774 --> 0.147100).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.9319992
	speed: 0.0354s/iter; left time: 899.7579s
	iters: 200, epoch: 5 | loss: 30.4659328
	speed: 0.0327s/iter; left time: 827.3357s
Epoch: 5 cost time: 9.000989437103271
Epoch: 5, Steps: 266 Train Loss: 30.5919 (Forecasting Loss:0.1478 + XiCon Loss:3.0444 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1253
Validation loss decreased (0.147100 --> 0.144945).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.3703823
	speed: 0.0357s/iter; left time: 897.3809s
	iters: 200, epoch: 6 | loss: 29.9906254
	speed: 0.0325s/iter; left time: 814.8304s
Epoch: 6 cost time: 8.99312949180603
Epoch: 6, Steps: 266 Train Loss: 30.6332 (Forecasting Loss:0.1472 + XiCon Loss:3.0486 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1244
Validation loss decreased (0.144945 --> 0.144589).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5032520
	speed: 0.0350s/iter; left time: 870.4480s
	iters: 200, epoch: 7 | loss: 30.5345268
	speed: 0.0334s/iter; left time: 828.1284s
Epoch: 7 cost time: 9.00914978981018
Epoch: 7, Steps: 266 Train Loss: 30.6038 (Forecasting Loss:0.1469 + XiCon Loss:3.0457 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5888729
	speed: 0.0356s/iter; left time: 877.6905s
	iters: 200, epoch: 8 | loss: 30.4456348
	speed: 0.0340s/iter; left time: 834.4532s
Epoch: 8 cost time: 9.176186323165894
Epoch: 8, Steps: 266 Train Loss: 30.6166 (Forecasting Loss:0.1467 + XiCon Loss:3.0470 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1244
Validation loss decreased (0.144589 --> 0.144468).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4208527
	speed: 0.0364s/iter; left time: 886.0879s
	iters: 200, epoch: 9 | loss: 30.6309166
	speed: 0.0326s/iter; left time: 791.6945s
Epoch: 9 cost time: 9.105129480361938
Epoch: 9, Steps: 266 Train Loss: 30.6076 (Forecasting Loss:0.1467 + XiCon Loss:3.0461 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
Validation loss decreased (0.144468 --> 0.144281).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5555630
	speed: 0.0355s/iter; left time: 855.5757s
	iters: 200, epoch: 10 | loss: 30.7851105
	speed: 0.0330s/iter; left time: 792.8585s
Epoch: 10 cost time: 9.033625364303589
Epoch: 10, Steps: 266 Train Loss: 30.5986 (Forecasting Loss:0.1466 + XiCon Loss:3.0452 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
Validation loss decreased (0.144281 --> 0.144268).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4801273
	speed: 0.0357s/iter; left time: 851.7865s
	iters: 200, epoch: 11 | loss: 30.5935860
	speed: 0.0328s/iter; left time: 778.8340s
Epoch: 11 cost time: 9.089684247970581
Epoch: 11, Steps: 266 Train Loss: 30.6395 (Forecasting Loss:0.1466 + XiCon Loss:3.0493 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8972607
	speed: 0.0352s/iter; left time: 828.9921s
	iters: 200, epoch: 12 | loss: 30.2405319
	speed: 0.0335s/iter; left time: 786.5415s
Epoch: 12 cost time: 9.109616041183472
Epoch: 12, Steps: 266 Train Loss: 30.6108 (Forecasting Loss:0.1465 + XiCon Loss:3.0464 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
Validation loss decreased (0.144268 --> 0.144144).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5858955
	speed: 0.0351s/iter; left time: 819.1440s
	iters: 200, epoch: 13 | loss: 30.1130562
	speed: 0.0343s/iter; left time: 796.3613s
Epoch: 13 cost time: 9.1448814868927
Epoch: 13, Steps: 266 Train Loss: 30.5877 (Forecasting Loss:0.1465 + XiCon Loss:3.0441 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4425488
	speed: 0.0364s/iter; left time: 839.8628s
	iters: 200, epoch: 14 | loss: 30.7174911
	speed: 0.0332s/iter; left time: 760.7284s
Epoch: 14 cost time: 9.124335289001465
Epoch: 14, Steps: 266 Train Loss: 30.6206 (Forecasting Loss:0.1465 + XiCon Loss:3.0474 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4022655
	speed: 0.0343s/iter; left time: 781.6275s
	iters: 200, epoch: 15 | loss: 30.5381775
	speed: 0.0324s/iter; left time: 734.4730s
Epoch: 15 cost time: 8.85693907737732
Epoch: 15, Steps: 266 Train Loss: 30.5967 (Forecasting Loss:0.1465 + XiCon Loss:3.0450 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6101913
	speed: 0.0356s/iter; left time: 801.3149s
	iters: 200, epoch: 16 | loss: 31.2490540
	speed: 0.0333s/iter; left time: 745.1943s
Epoch: 16 cost time: 9.083208560943604
Epoch: 16, Steps: 266 Train Loss: 30.5951 (Forecasting Loss:0.1464 + XiCon Loss:3.0449 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
Validation loss decreased (0.144144 --> 0.144110).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.7167721
	speed: 0.0351s/iter; left time: 781.1276s
	iters: 200, epoch: 17 | loss: 30.4108543
	speed: 0.0331s/iter; left time: 732.7823s
Epoch: 17 cost time: 8.993371725082397
Epoch: 17, Steps: 266 Train Loss: 30.6019 (Forecasting Loss:0.1465 + XiCon Loss:3.0455 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.3263206
	speed: 0.0360s/iter; left time: 790.7642s
	iters: 200, epoch: 18 | loss: 30.4632225
	speed: 0.0351s/iter; left time: 768.9108s
Epoch: 18 cost time: 9.322192668914795
Epoch: 18, Steps: 266 Train Loss: 30.5935 (Forecasting Loss:0.1464 + XiCon Loss:3.0447 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
Validation loss decreased (0.144110 --> 0.144053).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.4142857
	speed: 0.0369s/iter; left time: 802.0539s
	iters: 200, epoch: 19 | loss: 30.4089928
	speed: 0.0335s/iter; left time: 723.9237s
Epoch: 19 cost time: 9.253917694091797
Epoch: 19, Steps: 266 Train Loss: 30.6260 (Forecasting Loss:0.1464 + XiCon Loss:3.0480 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.2547226
	speed: 0.0353s/iter; left time: 757.1773s
	iters: 200, epoch: 20 | loss: 30.5975018
	speed: 0.0340s/iter; left time: 724.9995s
Epoch: 20 cost time: 9.098793745040894
Epoch: 20, Steps: 266 Train Loss: 30.6047 (Forecasting Loss:0.1466 + XiCon Loss:3.0458 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.2843723
	speed: 0.0349s/iter; left time: 739.8388s
	iters: 200, epoch: 21 | loss: 30.2896805
	speed: 0.0341s/iter; left time: 719.2856s
Epoch: 21 cost time: 9.086794137954712
Epoch: 21, Steps: 266 Train Loss: 30.6094 (Forecasting Loss:0.1465 + XiCon Loss:3.0463 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.5037022
	speed: 0.0348s/iter; left time: 728.2055s
	iters: 200, epoch: 22 | loss: 31.2087593
	speed: 0.0356s/iter; left time: 741.0551s
Epoch: 22 cost time: 9.270738363265991
Epoch: 22, Steps: 266 Train Loss: 30.6037 (Forecasting Loss:0.1465 + XiCon Loss:3.0457 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.4484348
	speed: 0.0359s/iter; left time: 741.9657s
	iters: 200, epoch: 23 | loss: 30.3903465
	speed: 0.0340s/iter; left time: 698.7836s
Epoch: 23 cost time: 9.17815089225769
Epoch: 23, Steps: 266 Train Loss: 30.5965 (Forecasting Loss:0.1465 + XiCon Loss:3.0450 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.3259869
	speed: 0.0358s/iter; left time: 730.2627s
	iters: 200, epoch: 24 | loss: 30.8821983
	speed: 0.0332s/iter; left time: 672.9174s
Epoch: 24 cost time: 9.2157723903656
Epoch: 24, Steps: 266 Train Loss: 30.6021 (Forecasting Loss:0.1465 + XiCon Loss:3.0456 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.0478630
	speed: 0.0357s/iter; left time: 718.2382s
	iters: 200, epoch: 25 | loss: 30.3025837
	speed: 0.0328s/iter; left time: 655.6567s
Epoch: 25 cost time: 9.070605039596558
Epoch: 25, Steps: 266 Train Loss: 30.5822 (Forecasting Loss:0.1465 + XiCon Loss:3.0436 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.3388443
	speed: 0.0354s/iter; left time: 702.9754s
	iters: 200, epoch: 26 | loss: 30.9446220
	speed: 0.0324s/iter; left time: 640.6980s
Epoch: 26 cost time: 9.02387022972107
Epoch: 26, Steps: 266 Train Loss: 30.6163 (Forecasting Loss:0.1466 + XiCon Loss:3.0470 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.6922894
	speed: 0.0357s/iter; left time: 698.7992s
	iters: 200, epoch: 27 | loss: 31.1540680
	speed: 0.0342s/iter; left time: 666.2801s
Epoch: 27 cost time: 9.20233964920044
Epoch: 27, Steps: 266 Train Loss: 30.6038 (Forecasting Loss:0.1465 + XiCon Loss:3.0457 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.5250912
	speed: 0.0352s/iter; left time: 679.5650s
	iters: 200, epoch: 28 | loss: 31.0964222
	speed: 0.0323s/iter; left time: 621.0720s
Epoch: 28 cost time: 8.955984830856323
Epoch: 28, Steps: 266 Train Loss: 30.5974 (Forecasting Loss:0.1465 + XiCon Loss:3.0451 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06437215209007263, mae:0.18394960463047028, mape:0.44806593656539917, mspe:8.140165328979492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4444
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.8707924
	speed: 0.0362s/iter; left time: 958.5413s
	iters: 200, epoch: 1 | loss: 32.2001266
	speed: 0.0343s/iter; left time: 906.7434s
Epoch: 1 cost time: 9.243391752243042
Epoch: 1, Steps: 266 Train Loss: 32.7526 (Forecasting Loss:0.1832 + XiCon Loss:3.2569 x Lambda(10.0)), Vali MSE Loss: 0.1580 Test MSE Loss: 0.1364
Validation loss decreased (inf --> 0.157980).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.3160820
	speed: 0.0358s/iter; left time: 939.5918s
	iters: 200, epoch: 2 | loss: 31.6670780
	speed: 0.0328s/iter; left time: 858.5012s
Epoch: 2 cost time: 9.036643743515015
Epoch: 2, Steps: 266 Train Loss: 31.6323 (Forecasting Loss:0.1595 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.1505 Test MSE Loss: 0.1303
Validation loss decreased (0.157980 --> 0.150456).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5096893
	speed: 0.0359s/iter; left time: 932.6263s
	iters: 200, epoch: 3 | loss: 30.5401497
	speed: 0.0331s/iter; left time: 857.0211s
Epoch: 3 cost time: 9.154605150222778
Epoch: 3, Steps: 266 Train Loss: 30.9203 (Forecasting Loss:0.1511 + XiCon Loss:3.0769 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1301
Validation loss decreased (0.150456 --> 0.148592).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4994431
	speed: 0.0359s/iter; left time: 922.7457s
	iters: 200, epoch: 4 | loss: 30.1857204
	speed: 0.0331s/iter; left time: 848.3325s
Epoch: 4 cost time: 9.202739715576172
Epoch: 4, Steps: 266 Train Loss: 30.7480 (Forecasting Loss:0.1494 + XiCon Loss:3.0599 x Lambda(10.0)), Vali MSE Loss: 0.1453 Test MSE Loss: 0.1256
Validation loss decreased (0.148592 --> 0.145331).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.5084896
	speed: 0.0360s/iter; left time: 915.7035s
	iters: 200, epoch: 5 | loss: 31.3505096
	speed: 0.0329s/iter; left time: 833.8134s
Epoch: 5 cost time: 9.002453088760376
Epoch: 5, Steps: 266 Train Loss: 30.6591 (Forecasting Loss:0.1480 + XiCon Loss:3.0511 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.3247795
	speed: 0.0353s/iter; left time: 887.8693s
	iters: 200, epoch: 6 | loss: 30.4320717
	speed: 0.0350s/iter; left time: 877.6396s
Epoch: 6 cost time: 9.318022727966309
Epoch: 6, Steps: 266 Train Loss: 30.6289 (Forecasting Loss:0.1474 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1244
Validation loss decreased (0.145331 --> 0.144876).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6782532
	speed: 0.0356s/iter; left time: 886.1595s
	iters: 200, epoch: 7 | loss: 30.5265198
	speed: 0.0330s/iter; left time: 818.4502s
Epoch: 7 cost time: 9.085837841033936
Epoch: 7, Steps: 266 Train Loss: 30.5944 (Forecasting Loss:0.1471 + XiCon Loss:3.0447 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1241
Validation loss decreased (0.144876 --> 0.144202).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6088333
	speed: 0.0365s/iter; left time: 899.7600s
	iters: 200, epoch: 8 | loss: 30.5453625
	speed: 0.0325s/iter; left time: 796.3795s
Epoch: 8 cost time: 9.054927825927734
Epoch: 8, Steps: 266 Train Loss: 30.5985 (Forecasting Loss:0.1469 + XiCon Loss:3.0452 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1241
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3127422
	speed: 0.0351s/iter; left time: 855.4914s
	iters: 200, epoch: 9 | loss: 30.8824520
	speed: 0.0329s/iter; left time: 798.4680s
Epoch: 9 cost time: 9.100572347640991
Epoch: 9, Steps: 266 Train Loss: 30.6289 (Forecasting Loss:0.1468 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1240
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4921188
	speed: 0.0349s/iter; left time: 841.1211s
	iters: 200, epoch: 10 | loss: 30.9123650
	speed: 0.0335s/iter; left time: 803.4882s
Epoch: 10 cost time: 9.023159265518188
Epoch: 10, Steps: 266 Train Loss: 30.6158 (Forecasting Loss:0.1468 + XiCon Loss:3.0469 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1240
Validation loss decreased (0.144202 --> 0.144000).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.0926876
	speed: 0.0350s/iter; left time: 834.8261s
	iters: 200, epoch: 11 | loss: 31.0280342
	speed: 0.0350s/iter; left time: 830.8377s
Epoch: 11 cost time: 9.246455907821655
Epoch: 11, Steps: 266 Train Loss: 30.6165 (Forecasting Loss:0.1468 + XiCon Loss:3.0470 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9464397
	speed: 0.0354s/iter; left time: 835.0001s
	iters: 200, epoch: 12 | loss: 30.4537601
	speed: 0.0328s/iter; left time: 769.9901s
Epoch: 12 cost time: 9.06460165977478
Epoch: 12, Steps: 266 Train Loss: 30.6336 (Forecasting Loss:0.1467 + XiCon Loss:3.0487 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1240
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7671928
	speed: 0.0354s/iter; left time: 824.8007s
	iters: 200, epoch: 13 | loss: 31.1322727
	speed: 0.0321s/iter; left time: 746.1145s
Epoch: 13 cost time: 8.929551362991333
Epoch: 13, Steps: 266 Train Loss: 30.6284 (Forecasting Loss:0.1467 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4622993
	speed: 0.0363s/iter; left time: 835.5747s
	iters: 200, epoch: 14 | loss: 30.5580273
	speed: 0.0338s/iter; left time: 774.6063s
Epoch: 14 cost time: 9.313460111618042
Epoch: 14, Steps: 266 Train Loss: 30.6096 (Forecasting Loss:0.1468 + XiCon Loss:3.0463 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1240
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.0653992
	speed: 0.0355s/iter; left time: 807.9698s
	iters: 200, epoch: 15 | loss: 30.4191341
	speed: 0.0335s/iter; left time: 759.1010s
Epoch: 15 cost time: 9.126309633255005
Epoch: 15, Steps: 266 Train Loss: 30.6376 (Forecasting Loss:0.1467 + XiCon Loss:3.0491 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6718845
	speed: 0.0348s/iter; left time: 782.6383s
	iters: 200, epoch: 16 | loss: 31.0494423
	speed: 0.0351s/iter; left time: 787.1374s
Epoch: 16 cost time: 9.206266641616821
Epoch: 16, Steps: 266 Train Loss: 30.6233 (Forecasting Loss:0.1466 + XiCon Loss:3.0477 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1240
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5043221
	speed: 0.0354s/iter; left time: 788.4888s
	iters: 200, epoch: 17 | loss: 30.6846466
	speed: 0.0323s/iter; left time: 715.1868s
Epoch: 17 cost time: 8.952485799789429
Epoch: 17, Steps: 266 Train Loss: 30.6246 (Forecasting Loss:0.1467 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.3674202
	speed: 0.0373s/iter; left time: 820.4452s
	iters: 200, epoch: 18 | loss: 30.8691311
	speed: 0.0329s/iter; left time: 719.2815s
Epoch: 18 cost time: 9.29021668434143
Epoch: 18, Steps: 266 Train Loss: 30.5922 (Forecasting Loss:0.1467 + XiCon Loss:3.0446 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5872688
	speed: 0.0350s/iter; left time: 758.9914s
	iters: 200, epoch: 19 | loss: 30.1921062
	speed: 0.0328s/iter; left time: 707.8675s
Epoch: 19 cost time: 9.04684853553772
Epoch: 19, Steps: 266 Train Loss: 30.6273 (Forecasting Loss:0.1466 + XiCon Loss:3.0481 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1240
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5097218
	speed: 0.0350s/iter; left time: 750.7950s
	iters: 200, epoch: 20 | loss: 30.2487621
	speed: 0.0338s/iter; left time: 722.3796s
Epoch: 20 cost time: 9.000248670578003
Epoch: 20, Steps: 266 Train Loss: 30.6182 (Forecasting Loss:0.1466 + XiCon Loss:3.0472 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1240
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06414779275655746, mae:0.1837681531906128, mape:0.4477790892124176, mspe:8.136502265930176 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9834
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 32.8537292
	speed: 0.0374s/iter; left time: 990.7659s
	iters: 200, epoch: 1 | loss: 32.1028137
	speed: 0.0329s/iter; left time: 869.1678s
Epoch: 1 cost time: 9.277658700942993
Epoch: 1, Steps: 266 Train Loss: 32.7034 (Forecasting Loss:0.1865 + XiCon Loss:3.2517 x Lambda(10.0)), Vali MSE Loss: 0.1566 Test MSE Loss: 0.1366
Validation loss decreased (inf --> 0.156554).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.3225899
	speed: 0.0356s/iter; left time: 933.8112s
	iters: 200, epoch: 2 | loss: 31.3743820
	speed: 0.0326s/iter; left time: 850.9061s
Epoch: 2 cost time: 9.000930786132812
Epoch: 2, Steps: 266 Train Loss: 31.6148 (Forecasting Loss:0.1601 + XiCon Loss:3.1455 x Lambda(10.0)), Vali MSE Loss: 0.1613 Test MSE Loss: 0.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.9685287
	speed: 0.0359s/iter; left time: 932.3795s
	iters: 200, epoch: 3 | loss: 30.4450340
	speed: 0.0348s/iter; left time: 901.2233s
Epoch: 3 cost time: 9.25389051437378
Epoch: 3, Steps: 266 Train Loss: 30.8178 (Forecasting Loss:0.1523 + XiCon Loss:3.0666 x Lambda(10.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.1280
Validation loss decreased (0.156554 --> 0.148227).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6384659
	speed: 0.0355s/iter; left time: 913.0380s
	iters: 200, epoch: 4 | loss: 30.4990654
	speed: 0.0333s/iter; left time: 853.5266s
Epoch: 4 cost time: 9.087035179138184
Epoch: 4, Steps: 266 Train Loss: 30.6902 (Forecasting Loss:0.1494 + XiCon Loss:3.0541 x Lambda(10.0)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.1273
Validation loss decreased (0.148227 --> 0.147500).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6578445
	speed: 0.0368s/iter; left time: 936.6940s
	iters: 200, epoch: 5 | loss: 31.5862961
	speed: 0.0332s/iter; left time: 841.5903s
Epoch: 5 cost time: 9.247137546539307
Epoch: 5, Steps: 266 Train Loss: 30.6886 (Forecasting Loss:0.1479 + XiCon Loss:3.0541 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1255
Validation loss decreased (0.147500 --> 0.144035).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5494308
	speed: 0.0352s/iter; left time: 885.9452s
	iters: 200, epoch: 6 | loss: 30.4013844
	speed: 0.0338s/iter; left time: 846.1512s
Epoch: 6 cost time: 9.287585020065308
Epoch: 6, Steps: 266 Train Loss: 30.6476 (Forecasting Loss:0.1473 + XiCon Loss:3.0500 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4348125
	speed: 0.0365s/iter; left time: 908.2016s
	iters: 200, epoch: 7 | loss: 30.3752155
	speed: 0.0330s/iter; left time: 817.9280s
Epoch: 7 cost time: 9.213728666305542
Epoch: 7, Steps: 266 Train Loss: 30.6320 (Forecasting Loss:0.1469 + XiCon Loss:3.0485 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1252
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5511265
	speed: 0.0351s/iter; left time: 864.1133s
	iters: 200, epoch: 8 | loss: 30.8421001
	speed: 0.0337s/iter; left time: 827.4469s
Epoch: 8 cost time: 9.126987934112549
Epoch: 8, Steps: 266 Train Loss: 30.6090 (Forecasting Loss:0.1467 + XiCon Loss:3.0462 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1251
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7745247
	speed: 0.0358s/iter; left time: 873.7116s
	iters: 200, epoch: 9 | loss: 30.5288734
	speed: 0.0323s/iter; left time: 783.2927s
Epoch: 9 cost time: 8.981949806213379
Epoch: 9, Steps: 266 Train Loss: 30.6479 (Forecasting Loss:0.1467 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1249
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.8707962
	speed: 0.0367s/iter; left time: 884.8259s
	iters: 200, epoch: 10 | loss: 30.1945229
	speed: 0.0332s/iter; left time: 797.9307s
Epoch: 10 cost time: 9.217013359069824
Epoch: 10, Steps: 266 Train Loss: 30.6483 (Forecasting Loss:0.1465 + XiCon Loss:3.0502 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1250
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8124981
	speed: 0.0348s/iter; left time: 828.6169s
	iters: 200, epoch: 11 | loss: 30.2703056
	speed: 0.0333s/iter; left time: 789.9284s
Epoch: 11 cost time: 9.097311735153198
Epoch: 11, Steps: 266 Train Loss: 30.6474 (Forecasting Loss:0.1465 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1249
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6652012
	speed: 0.0357s/iter; left time: 841.2838s
	iters: 200, epoch: 12 | loss: 30.6532497
	speed: 0.0338s/iter; left time: 793.5469s
Epoch: 12 cost time: 9.236294269561768
Epoch: 12, Steps: 266 Train Loss: 30.6369 (Forecasting Loss:0.1465 + XiCon Loss:3.0490 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1249
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8839893
	speed: 0.0355s/iter; left time: 826.4109s
	iters: 200, epoch: 13 | loss: 30.3319454
	speed: 0.0347s/iter; left time: 805.9400s
Epoch: 13 cost time: 9.2927827835083
Epoch: 13, Steps: 266 Train Loss: 30.6326 (Forecasting Loss:0.1464 + XiCon Loss:3.0486 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1249
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.7866268
	speed: 0.0355s/iter; left time: 817.2019s
	iters: 200, epoch: 14 | loss: 31.2117233
	speed: 0.0332s/iter; left time: 762.1813s
Epoch: 14 cost time: 9.130227327346802
Epoch: 14, Steps: 266 Train Loss: 30.6360 (Forecasting Loss:0.1465 + XiCon Loss:3.0489 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1250
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.6003189
	speed: 0.0365s/iter; left time: 832.2825s
	iters: 200, epoch: 15 | loss: 30.3843002
	speed: 0.0326s/iter; left time: 738.9881s
Epoch: 15 cost time: 9.126035690307617
Epoch: 15, Steps: 266 Train Loss: 30.6344 (Forecasting Loss:0.1465 + XiCon Loss:3.0488 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1249
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0651194304227829, mae:0.1858745515346527, mape:0.4553004205226898, mspe:8.388622283935547 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2640
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 33.0889816
	speed: 0.0366s/iter; left time: 970.0221s
	iters: 200, epoch: 1 | loss: 32.1003914
	speed: 0.0333s/iter; left time: 878.6987s
Epoch: 1 cost time: 9.255429983139038
Epoch: 1, Steps: 266 Train Loss: 32.8013 (Forecasting Loss:0.1864 + XiCon Loss:3.2615 x Lambda(10.0)), Vali MSE Loss: 0.1592 Test MSE Loss: 0.1380
Validation loss decreased (inf --> 0.159193).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.9226379
	speed: 0.0679s/iter; left time: 1780.6968s
	iters: 200, epoch: 2 | loss: 34.6204376
	speed: 0.0307s/iter; left time: 802.4122s
Epoch: 2 cost time: 12.0534508228302
Epoch: 2, Steps: 266 Train Loss: 33.6674 (Forecasting Loss:0.1593 + XiCon Loss:3.3508 x Lambda(10.0)), Vali MSE Loss: 0.1577 Test MSE Loss: 0.1398
Validation loss decreased (0.159193 --> 0.157682).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.2601585
	speed: 0.0367s/iter; left time: 952.3920s
	iters: 200, epoch: 3 | loss: 32.9476547
	speed: 0.0336s/iter; left time: 867.9994s
Epoch: 3 cost time: 9.275162935256958
Epoch: 3, Steps: 266 Train Loss: 34.1643 (Forecasting Loss:0.1524 + XiCon Loss:3.4012 x Lambda(10.0)), Vali MSE Loss: 0.1494 Test MSE Loss: 0.1288
Validation loss decreased (0.157682 --> 0.149385).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 34.9605827
	speed: 0.0360s/iter; left time: 926.0038s
	iters: 200, epoch: 4 | loss: 33.0433998
	speed: 0.0332s/iter; left time: 850.6614s
Epoch: 4 cost time: 9.123471736907959
Epoch: 4, Steps: 266 Train Loss: 33.9874 (Forecasting Loss:0.1490 + XiCon Loss:3.3838 x Lambda(10.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1261
Validation loss decreased (0.149385 --> 0.145635).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 34.9042473
	speed: 0.0361s/iter; left time: 918.2547s
	iters: 200, epoch: 5 | loss: 33.7938957
	speed: 0.0338s/iter; left time: 855.9655s
Epoch: 5 cost time: 9.217598915100098
Epoch: 5, Steps: 266 Train Loss: 33.8803 (Forecasting Loss:0.1483 + XiCon Loss:3.3732 x Lambda(10.0)), Vali MSE Loss: 0.1462 Test MSE Loss: 0.1257
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 34.6097984
	speed: 0.0349s/iter; left time: 878.7924s
	iters: 200, epoch: 6 | loss: 33.2578735
	speed: 0.0329s/iter; left time: 825.3537s
Epoch: 6 cost time: 8.930159091949463
Epoch: 6, Steps: 266 Train Loss: 33.7768 (Forecasting Loss:0.1475 + XiCon Loss:3.3629 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1253
Validation loss decreased (0.145635 --> 0.144340).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.9463997
	speed: 0.0355s/iter; left time: 885.3573s
	iters: 200, epoch: 7 | loss: 33.6105843
	speed: 0.0333s/iter; left time: 827.2024s
Epoch: 7 cost time: 9.011736631393433
Epoch: 7, Steps: 266 Train Loss: 33.6959 (Forecasting Loss:0.1473 + XiCon Loss:3.3549 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1248
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 34.1775322
	speed: 0.0347s/iter; left time: 856.0709s
	iters: 200, epoch: 8 | loss: 34.4293709
	speed: 0.0343s/iter; left time: 841.4669s
Epoch: 8 cost time: 9.095622301101685
Epoch: 8, Steps: 266 Train Loss: 33.6653 (Forecasting Loss:0.1470 + XiCon Loss:3.3518 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
Validation loss decreased (0.144340 --> 0.144219).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.4510422
	speed: 0.0356s/iter; left time: 867.1321s
	iters: 200, epoch: 9 | loss: 33.8835678
	speed: 0.0341s/iter; left time: 827.0204s
Epoch: 9 cost time: 9.177359819412231
Epoch: 9, Steps: 266 Train Loss: 33.5754 (Forecasting Loss:0.1470 + XiCon Loss:3.3428 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.3867149
	speed: 0.0354s/iter; left time: 852.7120s
	iters: 200, epoch: 10 | loss: 33.0567627
	speed: 0.0333s/iter; left time: 798.9280s
Epoch: 10 cost time: 9.10270380973816
Epoch: 10, Steps: 266 Train Loss: 33.5435 (Forecasting Loss:0.1469 + XiCon Loss:3.3397 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
Validation loss decreased (0.144219 --> 0.144101).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 34.4602318
	speed: 0.0362s/iter; left time: 862.4574s
	iters: 200, epoch: 11 | loss: 35.1605682
	speed: 0.0327s/iter; left time: 775.3049s
Epoch: 11 cost time: 9.084525108337402
Epoch: 11, Steps: 266 Train Loss: 33.5966 (Forecasting Loss:0.1469 + XiCon Loss:3.3450 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.8827248
	speed: 0.0366s/iter; left time: 862.3122s
	iters: 200, epoch: 12 | loss: 33.8788223
	speed: 0.0350s/iter; left time: 821.2969s
Epoch: 12 cost time: 9.329444646835327
Epoch: 12, Steps: 266 Train Loss: 33.5953 (Forecasting Loss:0.1469 + XiCon Loss:3.3448 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.7232971
	speed: 0.0352s/iter; left time: 819.5990s
	iters: 200, epoch: 13 | loss: 33.3748856
	speed: 0.0345s/iter; left time: 799.6685s
Epoch: 13 cost time: 9.188385963439941
Epoch: 13, Steps: 266 Train Loss: 33.5664 (Forecasting Loss:0.1468 + XiCon Loss:3.3420 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.9412689
	speed: 0.0365s/iter; left time: 840.9830s
	iters: 200, epoch: 14 | loss: 34.1143494
	speed: 0.0332s/iter; left time: 761.8659s
Epoch: 14 cost time: 9.1435227394104
Epoch: 14, Steps: 266 Train Loss: 33.5737 (Forecasting Loss:0.1469 + XiCon Loss:3.3427 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.6214790
	speed: 0.0351s/iter; left time: 799.1717s
	iters: 200, epoch: 15 | loss: 34.4023438
	speed: 0.0321s/iter; left time: 728.2738s
Epoch: 15 cost time: 8.912588834762573
Epoch: 15, Steps: 266 Train Loss: 33.6001 (Forecasting Loss:0.1469 + XiCon Loss:3.3453 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.9517441
	speed: 0.0349s/iter; left time: 786.2719s
	iters: 200, epoch: 16 | loss: 33.2860489
	speed: 0.0332s/iter; left time: 743.6358s
Epoch: 16 cost time: 8.946635007858276
Epoch: 16, Steps: 266 Train Loss: 33.6092 (Forecasting Loss:0.1468 + XiCon Loss:3.3462 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 34.2639275
	speed: 0.0350s/iter; left time: 779.0557s
	iters: 200, epoch: 17 | loss: 34.5255165
	speed: 0.0324s/iter; left time: 717.2659s
Epoch: 17 cost time: 9.024187564849854
Epoch: 17, Steps: 266 Train Loss: 33.6864 (Forecasting Loss:0.1469 + XiCon Loss:3.3540 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1246
Validation loss decreased (0.144101 --> 0.144043).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.3973770
	speed: 0.0360s/iter; left time: 790.4861s
	iters: 200, epoch: 18 | loss: 33.2984428
	speed: 0.0348s/iter; left time: 761.0596s
Epoch: 18 cost time: 9.336559295654297
Epoch: 18, Steps: 266 Train Loss: 33.6840 (Forecasting Loss:0.1468 + XiCon Loss:3.3537 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.4292717
	speed: 0.0370s/iter; left time: 804.2599s
	iters: 200, epoch: 19 | loss: 34.4067078
	speed: 0.0338s/iter; left time: 730.3714s
Epoch: 19 cost time: 9.315289735794067
Epoch: 19, Steps: 266 Train Loss: 33.6379 (Forecasting Loss:0.1469 + XiCon Loss:3.3491 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.5403442
	speed: 0.0353s/iter; left time: 756.7836s
	iters: 200, epoch: 20 | loss: 34.0212669
	speed: 0.0328s/iter; left time: 701.0480s
Epoch: 20 cost time: 8.999871253967285
Epoch: 20, Steps: 266 Train Loss: 33.6355 (Forecasting Loss:0.1468 + XiCon Loss:3.3489 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.1203995
	speed: 0.0362s/iter; left time: 767.4135s
	iters: 200, epoch: 21 | loss: 33.6400986
	speed: 0.0333s/iter; left time: 702.9435s
Epoch: 21 cost time: 9.162043333053589
Epoch: 21, Steps: 266 Train Loss: 33.6565 (Forecasting Loss:0.1469 + XiCon Loss:3.3510 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1246
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.5297127
	speed: 0.0351s/iter; left time: 733.8984s
	iters: 200, epoch: 22 | loss: 33.2837296
	speed: 0.0345s/iter; left time: 718.6870s
Epoch: 22 cost time: 9.182759761810303
Epoch: 22, Steps: 266 Train Loss: 33.5857 (Forecasting Loss:0.1468 + XiCon Loss:3.3439 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.6987457
	speed: 0.0349s/iter; left time: 720.1095s
	iters: 200, epoch: 23 | loss: 32.9311752
	speed: 0.0335s/iter; left time: 688.3924s
Epoch: 23 cost time: 8.948434591293335
Epoch: 23, Steps: 266 Train Loss: 33.6070 (Forecasting Loss:0.1468 + XiCon Loss:3.3460 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 34.3825798
	speed: 0.0355s/iter; left time: 723.1031s
	iters: 200, epoch: 24 | loss: 33.2079010
	speed: 0.0339s/iter; left time: 686.7097s
Epoch: 24 cost time: 9.10932183265686
Epoch: 24, Steps: 266 Train Loss: 33.6071 (Forecasting Loss:0.1468 + XiCon Loss:3.3460 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.8958855
	speed: 0.0351s/iter; left time: 707.0159s
	iters: 200, epoch: 25 | loss: 33.6287804
	speed: 0.0335s/iter; left time: 671.1219s
Epoch: 25 cost time: 9.052706956863403
Epoch: 25, Steps: 266 Train Loss: 33.5651 (Forecasting Loss:0.1469 + XiCon Loss:3.3418 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.9955139
	speed: 0.0356s/iter; left time: 706.1122s
	iters: 200, epoch: 26 | loss: 32.1602898
	speed: 0.0334s/iter; left time: 659.5383s
Epoch: 26 cost time: 9.129002094268799
Epoch: 26, Steps: 266 Train Loss: 33.6234 (Forecasting Loss:0.1468 + XiCon Loss:3.3477 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 34.4702492
	speed: 0.0360s/iter; left time: 704.7054s
	iters: 200, epoch: 27 | loss: 33.4302368
	speed: 0.0339s/iter; left time: 660.0153s
Epoch: 27 cost time: 9.198865175247192
Epoch: 27, Steps: 266 Train Loss: 33.5903 (Forecasting Loss:0.1468 + XiCon Loss:3.3443 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06473830342292786, mae:0.1845184862613678, mape:0.44840624928474426, mspe:8.14762020111084 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0646+-0.00046, MAE:0.1845+-0.00103, MAPE:0.4496+-0.00397, MSPE:8.1877+-0.13979, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5434
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.5789070
	speed: 0.0389s/iter; left time: 1026.5880s
	iters: 200, epoch: 1 | loss: 32.7411690
	speed: 0.0346s/iter; left time: 911.2287s
Epoch: 1 cost time: 9.59155535697937
Epoch: 1, Steps: 265 Train Loss: 32.6375 (Forecasting Loss:0.3531 + XiCon Loss:3.2284 x Lambda(10.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2776
Validation loss decreased (inf --> 0.336503).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 31.9247608
	speed: 0.0368s/iter; left time: 960.7261s
	iters: 200, epoch: 2 | loss: 31.6360817
	speed: 0.0340s/iter; left time: 883.9527s
Epoch: 2 cost time: 9.337977170944214
Epoch: 2, Steps: 265 Train Loss: 31.8695 (Forecasting Loss:0.2420 + XiCon Loss:3.1627 x Lambda(10.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.1737
Validation loss decreased (0.336503 --> 0.217844).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 30.4833107
	speed: 0.0355s/iter; left time: 918.9179s
	iters: 200, epoch: 3 | loss: 30.6367264
	speed: 0.0340s/iter; left time: 877.1590s
Epoch: 3 cost time: 9.125977993011475
Epoch: 3, Steps: 265 Train Loss: 30.8045 (Forecasting Loss:0.2147 + XiCon Loss:3.0590 x Lambda(10.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1707
Validation loss decreased (0.217844 --> 0.212488).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 30.3574295
	speed: 0.0367s/iter; left time: 938.7451s
	iters: 200, epoch: 4 | loss: 30.6379395
	speed: 0.0340s/iter; left time: 867.7352s
Epoch: 4 cost time: 9.22520399093628
Epoch: 4, Steps: 265 Train Loss: 30.4804 (Forecasting Loss:0.2113 + XiCon Loss:3.0269 x Lambda(10.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1699
Validation loss decreased (0.212488 --> 0.211079).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 30.2814980
	speed: 0.0364s/iter; left time: 922.7867s
	iters: 200, epoch: 5 | loss: 30.6911030
	speed: 0.0340s/iter; left time: 859.1528s
Epoch: 5 cost time: 9.326095581054688
Epoch: 5, Steps: 265 Train Loss: 30.3587 (Forecasting Loss:0.2099 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1695
Validation loss decreased (0.211079 --> 0.210185).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 30.5312958
	speed: 0.0355s/iter; left time: 889.6055s
	iters: 200, epoch: 6 | loss: 29.9392643
	speed: 0.0325s/iter; left time: 810.9711s
Epoch: 6 cost time: 8.985618114471436
Epoch: 6, Steps: 265 Train Loss: 30.3428 (Forecasting Loss:0.2094 + XiCon Loss:3.0133 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1693
Validation loss decreased (0.210185 --> 0.210004).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 30.5193615
	speed: 0.0357s/iter; left time: 885.1103s
	iters: 200, epoch: 7 | loss: 30.4670773
	speed: 0.0332s/iter; left time: 820.4798s
Epoch: 7 cost time: 9.154465198516846
Epoch: 7, Steps: 265 Train Loss: 30.3266 (Forecasting Loss:0.2093 + XiCon Loss:3.0117 x Lambda(10.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1692
Validation loss decreased (0.210004 --> 0.209989).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 30.3948135
	speed: 0.0366s/iter; left time: 897.5751s
	iters: 200, epoch: 8 | loss: 30.1682053
	speed: 0.0336s/iter; left time: 820.5555s
Epoch: 8 cost time: 9.108095407485962
Epoch: 8, Steps: 265 Train Loss: 30.3126 (Forecasting Loss:0.2091 + XiCon Loss:3.0104 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1692
Validation loss decreased (0.209989 --> 0.209841).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 30.2456856
	speed: 0.0358s/iter; left time: 870.2412s
	iters: 200, epoch: 9 | loss: 30.5701237
	speed: 0.0321s/iter; left time: 776.2212s
Epoch: 9 cost time: 8.944677591323853
Epoch: 9, Steps: 265 Train Loss: 30.3210 (Forecasting Loss:0.2089 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 30.4429131
	speed: 0.0358s/iter; left time: 860.8140s
	iters: 200, epoch: 10 | loss: 30.4010849
	speed: 0.0349s/iter; left time: 835.4014s
Epoch: 10 cost time: 9.399945259094238
Epoch: 10, Steps: 265 Train Loss: 30.2866 (Forecasting Loss:0.2089 + XiCon Loss:3.0078 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
Validation loss decreased (0.209841 --> 0.209665).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 30.2752380
	speed: 0.0352s/iter; left time: 836.7947s
	iters: 200, epoch: 11 | loss: 30.3160706
	speed: 0.0338s/iter; left time: 798.9125s
Epoch: 11 cost time: 9.106718301773071
Epoch: 11, Steps: 265 Train Loss: 30.3229 (Forecasting Loss:0.2089 + XiCon Loss:3.0114 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1691
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 30.3260670
	speed: 0.0355s/iter; left time: 833.2110s
	iters: 200, epoch: 12 | loss: 30.4739819
	speed: 0.0335s/iter; left time: 784.2704s
Epoch: 12 cost time: 9.20567774772644
Epoch: 12, Steps: 265 Train Loss: 30.3158 (Forecasting Loss:0.2089 + XiCon Loss:3.0107 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 30.2327976
	speed: 0.0355s/iter; left time: 823.3162s
	iters: 200, epoch: 13 | loss: 30.4214535
	speed: 0.0334s/iter; left time: 772.2813s
Epoch: 13 cost time: 9.02726411819458
Epoch: 13, Steps: 265 Train Loss: 30.3007 (Forecasting Loss:0.2088 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.2875156
	speed: 0.0353s/iter; left time: 809.7639s
	iters: 200, epoch: 14 | loss: 30.5977097
	speed: 0.0334s/iter; left time: 763.1871s
Epoch: 14 cost time: 9.10657548904419
Epoch: 14, Steps: 265 Train Loss: 30.2991 (Forecasting Loss:0.2089 + XiCon Loss:3.0090 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 29.9933052
	speed: 0.0376s/iter; left time: 853.4626s
	iters: 200, epoch: 15 | loss: 30.5740509
	speed: 0.0339s/iter; left time: 765.2266s
Epoch: 15 cost time: 9.297797203063965
Epoch: 15, Steps: 265 Train Loss: 30.3003 (Forecasting Loss:0.2088 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 30.4914856
	speed: 0.0361s/iter; left time: 809.4977s
	iters: 200, epoch: 16 | loss: 30.4527130
	speed: 0.0343s/iter; left time: 764.9842s
Epoch: 16 cost time: 9.229192018508911
Epoch: 16, Steps: 265 Train Loss: 30.3205 (Forecasting Loss:0.2088 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1691
Validation loss decreased (0.209665 --> 0.209599).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 30.5221539
	speed: 0.0350s/iter; left time: 775.6605s
	iters: 200, epoch: 17 | loss: 30.4846382
	speed: 0.0335s/iter; left time: 739.6970s
Epoch: 17 cost time: 9.029300928115845
Epoch: 17, Steps: 265 Train Loss: 30.3035 (Forecasting Loss:0.2088 + XiCon Loss:3.0095 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1691
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 30.8094864
	speed: 0.0354s/iter; left time: 775.7551s
	iters: 200, epoch: 18 | loss: 30.4360085
	speed: 0.0337s/iter; left time: 735.5130s
Epoch: 18 cost time: 9.154324054718018
Epoch: 18, Steps: 265 Train Loss: 30.2875 (Forecasting Loss:0.2088 + XiCon Loss:3.0079 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 30.3012867
	speed: 0.0357s/iter; left time: 772.9507s
	iters: 200, epoch: 19 | loss: 30.3277855
	speed: 0.0348s/iter; left time: 749.0078s
Epoch: 19 cost time: 9.329016923904419
Epoch: 19, Steps: 265 Train Loss: 30.3001 (Forecasting Loss:0.2088 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 30.0015659
	speed: 0.0366s/iter; left time: 781.9386s
	iters: 200, epoch: 20 | loss: 30.3046207
	speed: 0.0335s/iter; left time: 711.6217s
Epoch: 20 cost time: 9.175451517105103
Epoch: 20, Steps: 265 Train Loss: 30.2925 (Forecasting Loss:0.2088 + XiCon Loss:3.0084 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 30.6727715
	speed: 0.0360s/iter; left time: 759.9282s
	iters: 200, epoch: 21 | loss: 30.2922802
	speed: 0.0335s/iter; left time: 702.9076s
Epoch: 21 cost time: 9.26633882522583
Epoch: 21, Steps: 265 Train Loss: 30.3002 (Forecasting Loss:0.2087 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 30.4787655
	speed: 0.0355s/iter; left time: 739.9686s
	iters: 200, epoch: 22 | loss: 30.4144459
	speed: 0.0335s/iter; left time: 695.1940s
Epoch: 22 cost time: 9.092719316482544
Epoch: 22, Steps: 265 Train Loss: 30.2976 (Forecasting Loss:0.2087 + XiCon Loss:3.0089 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 30.5525703
	speed: 0.0362s/iter; left time: 745.3570s
	iters: 200, epoch: 23 | loss: 30.2488708
	speed: 0.0337s/iter; left time: 690.5138s
Epoch: 23 cost time: 9.263455152511597
Epoch: 23, Steps: 265 Train Loss: 30.2976 (Forecasting Loss:0.2088 + XiCon Loss:3.0089 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1691
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 30.2392616
	speed: 0.0365s/iter; left time: 740.6406s
	iters: 200, epoch: 24 | loss: 30.3815651
	speed: 0.0347s/iter; left time: 700.5262s
Epoch: 24 cost time: 9.371164560317993
Epoch: 24, Steps: 265 Train Loss: 30.2897 (Forecasting Loss:0.2090 + XiCon Loss:3.0081 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1691
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 30.3499050
	speed: 0.0355s/iter; left time: 710.5112s
	iters: 200, epoch: 25 | loss: 30.2299614
	speed: 0.0335s/iter; left time: 668.9893s
Epoch: 25 cost time: 9.042408466339111
Epoch: 25, Steps: 265 Train Loss: 30.3272 (Forecasting Loss:0.2089 + XiCon Loss:3.0118 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1691
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 30.0802841
	speed: 0.0354s/iter; left time: 699.1145s
	iters: 200, epoch: 26 | loss: 30.3765011
	speed: 0.0333s/iter; left time: 654.7916s
Epoch: 26 cost time: 9.092628002166748
Epoch: 26, Steps: 265 Train Loss: 30.3109 (Forecasting Loss:0.2088 + XiCon Loss:3.0102 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1691
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0987873449921608, mae:0.23945309221744537, mape:0.568139374256134, mspe:11.769340515136719 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2481
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.7052689
	speed: 0.0371s/iter; left time: 980.0075s
	iters: 200, epoch: 1 | loss: 32.8652840
	speed: 0.0353s/iter; left time: 927.4538s
Epoch: 1 cost time: 9.552668809890747
Epoch: 1, Steps: 265 Train Loss: 32.7950 (Forecasting Loss:0.3608 + XiCon Loss:3.2434 x Lambda(10.0)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2831
Validation loss decreased (inf --> 0.335598).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 31.9011497
	speed: 0.0359s/iter; left time: 937.3594s
	iters: 200, epoch: 2 | loss: 31.4050102
	speed: 0.0354s/iter; left time: 921.9198s
Epoch: 2 cost time: 9.329615831375122
Epoch: 2, Steps: 265 Train Loss: 31.9059 (Forecasting Loss:0.2428 + XiCon Loss:3.1663 x Lambda(10.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1723
Validation loss decreased (0.335598 --> 0.220130).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 30.5184517
	speed: 0.0357s/iter; left time: 924.4677s
	iters: 200, epoch: 3 | loss: 30.6834431
	speed: 0.0336s/iter; left time: 865.1846s
Epoch: 3 cost time: 9.112730741500854
Epoch: 3, Steps: 265 Train Loss: 30.7328 (Forecasting Loss:0.2146 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1689
Validation loss decreased (0.220130 --> 0.215343).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 30.3884754
	speed: 0.0362s/iter; left time: 926.9327s
	iters: 200, epoch: 4 | loss: 30.3558788
	speed: 0.0340s/iter; left time: 867.1177s
Epoch: 4 cost time: 9.172204732894897
Epoch: 4, Steps: 265 Train Loss: 30.4541 (Forecasting Loss:0.2116 + XiCon Loss:3.0242 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1679
Validation loss decreased (0.215343 --> 0.213123).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 29.9589767
	speed: 0.0360s/iter; left time: 913.4936s
	iters: 200, epoch: 5 | loss: 30.2570457
	speed: 0.0341s/iter; left time: 860.4308s
Epoch: 5 cost time: 9.452317476272583
Epoch: 5, Steps: 265 Train Loss: 30.3448 (Forecasting Loss:0.2108 + XiCon Loss:3.0134 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1678
Validation loss decreased (0.213123 --> 0.212590).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 30.2861195
	speed: 0.0366s/iter; left time: 918.6661s
	iters: 200, epoch: 6 | loss: 30.1320305
	speed: 0.0346s/iter; left time: 864.6850s
Epoch: 6 cost time: 9.325226306915283
Epoch: 6, Steps: 265 Train Loss: 30.3043 (Forecasting Loss:0.2102 + XiCon Loss:3.0094 x Lambda(10.0)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1676
Validation loss decreased (0.212590 --> 0.212224).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 30.2767868
	speed: 0.0364s/iter; left time: 901.8843s
	iters: 200, epoch: 7 | loss: 29.9777565
	speed: 0.0338s/iter; left time: 834.6139s
Epoch: 7 cost time: 9.196739196777344
Epoch: 7, Steps: 265 Train Loss: 30.2946 (Forecasting Loss:0.2100 + XiCon Loss:3.0085 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1676
Validation loss decreased (0.212224 --> 0.211939).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 30.4890118
	speed: 0.0366s/iter; left time: 899.1985s
	iters: 200, epoch: 8 | loss: 30.1574574
	speed: 0.0342s/iter; left time: 836.4689s
Epoch: 8 cost time: 9.251928329467773
Epoch: 8, Steps: 265 Train Loss: 30.2743 (Forecasting Loss:0.2099 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 30.0476532
	speed: 0.0358s/iter; left time: 868.9679s
	iters: 200, epoch: 9 | loss: 29.9216461
	speed: 0.0333s/iter; left time: 804.9489s
Epoch: 9 cost time: 9.07205867767334
Epoch: 9, Steps: 265 Train Loss: 30.2763 (Forecasting Loss:0.2097 + XiCon Loss:3.0067 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1675
Validation loss decreased (0.211939 --> 0.211910).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 29.8203869
	speed: 0.0361s/iter; left time: 866.3904s
	iters: 200, epoch: 10 | loss: 30.1594944
	speed: 0.0335s/iter; left time: 800.3998s
Epoch: 10 cost time: 9.134648084640503
Epoch: 10, Steps: 265 Train Loss: 30.2724 (Forecasting Loss:0.2098 + XiCon Loss:3.0063 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1675
Validation loss decreased (0.211910 --> 0.211641).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 30.3876991
	speed: 0.0354s/iter; left time: 840.7342s
	iters: 200, epoch: 11 | loss: 30.1632710
	speed: 0.0330s/iter; left time: 780.1144s
Epoch: 11 cost time: 8.913777589797974
Epoch: 11, Steps: 265 Train Loss: 30.2836 (Forecasting Loss:0.2096 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 30.0369778
	speed: 0.0354s/iter; left time: 831.9877s
	iters: 200, epoch: 12 | loss: 30.1352215
	speed: 0.0336s/iter; left time: 785.0338s
Epoch: 12 cost time: 9.056421518325806
Epoch: 12, Steps: 265 Train Loss: 30.2627 (Forecasting Loss:0.2097 + XiCon Loss:3.0053 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1675
Validation loss decreased (0.211641 --> 0.211576).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 30.3088703
	speed: 0.0365s/iter; left time: 847.5311s
	iters: 200, epoch: 13 | loss: 30.1674938
	speed: 0.0340s/iter; left time: 786.6469s
Epoch: 13 cost time: 9.269689798355103
Epoch: 13, Steps: 265 Train Loss: 30.2739 (Forecasting Loss:0.2098 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.4892349
	speed: 0.0359s/iter; left time: 824.4522s
	iters: 200, epoch: 14 | loss: 30.4020157
	speed: 0.0342s/iter; left time: 781.2406s
Epoch: 14 cost time: 9.272374391555786
Epoch: 14, Steps: 265 Train Loss: 30.2836 (Forecasting Loss:0.2096 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 30.3087254
	speed: 0.0365s/iter; left time: 829.2742s
	iters: 200, epoch: 15 | loss: 30.2219696
	speed: 0.0347s/iter; left time: 784.8045s
Epoch: 15 cost time: 9.35407280921936
Epoch: 15, Steps: 265 Train Loss: 30.2705 (Forecasting Loss:0.2097 + XiCon Loss:3.0061 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 30.2880573
	speed: 0.0351s/iter; left time: 787.9032s
	iters: 200, epoch: 16 | loss: 30.1599312
	speed: 0.0329s/iter; left time: 735.2693s
Epoch: 16 cost time: 8.979454278945923
Epoch: 16, Steps: 265 Train Loss: 30.2590 (Forecasting Loss:0.2096 + XiCon Loss:3.0049 x Lambda(10.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1675
Validation loss decreased (0.211576 --> 0.211542).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 30.5484562
	speed: 0.0365s/iter; left time: 809.6704s
	iters: 200, epoch: 17 | loss: 30.3865261
	speed: 0.0333s/iter; left time: 735.0951s
Epoch: 17 cost time: 9.11843752861023
Epoch: 17, Steps: 265 Train Loss: 30.2831 (Forecasting Loss:0.2098 + XiCon Loss:3.0073 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 30.2317448
	speed: 0.0355s/iter; left time: 777.5125s
	iters: 200, epoch: 18 | loss: 30.3690243
	speed: 0.0330s/iter; left time: 718.6761s
Epoch: 18 cost time: 8.986740112304688
Epoch: 18, Steps: 265 Train Loss: 30.2565 (Forecasting Loss:0.2098 + XiCon Loss:3.0047 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 30.5761032
	speed: 0.0372s/iter; left time: 804.1054s
	iters: 200, epoch: 19 | loss: 30.4223824
	speed: 0.0357s/iter; left time: 768.2956s
Epoch: 19 cost time: 9.56236720085144
Epoch: 19, Steps: 265 Train Loss: 30.2681 (Forecasting Loss:0.2098 + XiCon Loss:3.0058 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 30.3098507
	speed: 0.0363s/iter; left time: 775.3494s
	iters: 200, epoch: 20 | loss: 30.0265217
	speed: 0.0344s/iter; left time: 732.2312s
Epoch: 20 cost time: 9.342591524124146
Epoch: 20, Steps: 265 Train Loss: 30.2735 (Forecasting Loss:0.2097 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1675
Validation loss decreased (0.211542 --> 0.211507).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 30.3021584
	speed: 0.0360s/iter; left time: 759.4785s
	iters: 200, epoch: 21 | loss: 30.3393269
	speed: 0.0338s/iter; left time: 709.1183s
Epoch: 21 cost time: 9.184166669845581
Epoch: 21, Steps: 265 Train Loss: 30.2730 (Forecasting Loss:0.2096 + XiCon Loss:3.0063 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 30.4467545
	speed: 0.0367s/iter; left time: 763.6838s
	iters: 200, epoch: 22 | loss: 29.9076862
	speed: 0.0326s/iter; left time: 676.8050s
Epoch: 22 cost time: 9.15757155418396
Epoch: 22, Steps: 265 Train Loss: 30.2736 (Forecasting Loss:0.2097 + XiCon Loss:3.0064 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 30.6732407
	speed: 0.0346s/iter; left time: 711.5784s
	iters: 200, epoch: 23 | loss: 30.2423592
	speed: 0.0343s/iter; left time: 701.7716s
Epoch: 23 cost time: 9.14518117904663
Epoch: 23, Steps: 265 Train Loss: 30.2541 (Forecasting Loss:0.2096 + XiCon Loss:3.0044 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 30.3857803
	speed: 0.0361s/iter; left time: 732.7836s
	iters: 200, epoch: 24 | loss: 30.2046375
	speed: 0.0340s/iter; left time: 687.6070s
Epoch: 24 cost time: 9.267761945724487
Epoch: 24, Steps: 265 Train Loss: 30.2834 (Forecasting Loss:0.2098 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 30.2886562
	speed: 0.0369s/iter; left time: 738.5600s
	iters: 200, epoch: 25 | loss: 30.0002823
	speed: 0.0339s/iter; left time: 676.8498s
Epoch: 25 cost time: 9.318436622619629
Epoch: 25, Steps: 265 Train Loss: 30.2719 (Forecasting Loss:0.2096 + XiCon Loss:3.0062 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 30.3630600
	speed: 0.0348s/iter; left time: 687.8543s
	iters: 200, epoch: 26 | loss: 30.4559460
	speed: 0.0333s/iter; left time: 654.4631s
Epoch: 26 cost time: 8.9322350025177
Epoch: 26, Steps: 265 Train Loss: 30.2855 (Forecasting Loss:0.2097 + XiCon Loss:3.0076 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1675
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 30.2866364
	speed: 0.0360s/iter; left time: 702.4151s
	iters: 200, epoch: 27 | loss: 30.4899654
	speed: 0.0334s/iter; left time: 648.3731s
Epoch: 27 cost time: 9.23679780960083
Epoch: 27, Steps: 265 Train Loss: 30.2851 (Forecasting Loss:0.2097 + XiCon Loss:3.0075 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1675
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 30.1752682
	speed: 0.0361s/iter; left time: 695.0068s
	iters: 200, epoch: 28 | loss: 29.9096909
	speed: 0.0342s/iter; left time: 654.0131s
Epoch: 28 cost time: 9.371748447418213
Epoch: 28, Steps: 265 Train Loss: 30.2645 (Forecasting Loss:0.2096 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1675
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 30.6540012
	speed: 0.0358s/iter; left time: 678.8816s
	iters: 200, epoch: 29 | loss: 29.7233715
	speed: 0.0343s/iter; left time: 647.1937s
Epoch: 29 cost time: 9.177830696105957
Epoch: 29, Steps: 265 Train Loss: 30.2489 (Forecasting Loss:0.2098 + XiCon Loss:3.0039 x Lambda(10.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1675
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 30.3280811
	speed: 0.0373s/iter; left time: 697.7320s
	iters: 200, epoch: 30 | loss: 30.3274040
	speed: 0.0336s/iter; left time: 626.0983s
Epoch: 30 cost time: 9.282567262649536
Epoch: 30, Steps: 265 Train Loss: 30.2755 (Forecasting Loss:0.2095 + XiCon Loss:3.0066 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1675
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09742776304483414, mae:0.23752328753471375, mape:0.5684858560562134, mspe:11.99616527557373 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2298
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.5735741
	speed: 0.0390s/iter; left time: 1029.2871s
	iters: 200, epoch: 1 | loss: 32.4573669
	speed: 0.0352s/iter; left time: 924.6415s
Epoch: 1 cost time: 9.750659465789795
Epoch: 1, Steps: 265 Train Loss: 32.6042 (Forecasting Loss:0.3469 + XiCon Loss:3.2257 x Lambda(10.0)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2714
Validation loss decreased (inf --> 0.325156).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 31.9241371
	speed: 0.0372s/iter; left time: 971.9876s
	iters: 200, epoch: 2 | loss: 31.3713017
	speed: 0.0340s/iter; left time: 884.5572s
Epoch: 2 cost time: 9.392494440078735
Epoch: 2, Steps: 265 Train Loss: 31.6672 (Forecasting Loss:0.2403 + XiCon Loss:3.1427 x Lambda(10.0)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1735
Validation loss decreased (0.325156 --> 0.220871).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 31.0519295
	speed: 0.0362s/iter; left time: 936.6607s
	iters: 200, epoch: 3 | loss: 30.4687004
	speed: 0.0339s/iter; left time: 872.8968s
Epoch: 3 cost time: 9.317504167556763
Epoch: 3, Steps: 265 Train Loss: 30.6681 (Forecasting Loss:0.2149 + XiCon Loss:3.0453 x Lambda(10.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1704
Validation loss decreased (0.220871 --> 0.216289).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 30.4877205
	speed: 0.0355s/iter; left time: 910.0957s
	iters: 200, epoch: 4 | loss: 30.2814980
	speed: 0.0339s/iter; left time: 865.4859s
Epoch: 4 cost time: 9.153257369995117
Epoch: 4, Steps: 265 Train Loss: 30.5238 (Forecasting Loss:0.2116 + XiCon Loss:3.0312 x Lambda(10.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1696
Validation loss decreased (0.216289 --> 0.214181).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 30.5098934
	speed: 0.0361s/iter; left time: 915.4049s
	iters: 200, epoch: 5 | loss: 30.4722691
	speed: 0.0341s/iter; left time: 859.9865s
Epoch: 5 cost time: 9.302294969558716
Epoch: 5, Steps: 265 Train Loss: 30.4505 (Forecasting Loss:0.2103 + XiCon Loss:3.0240 x Lambda(10.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1693
Validation loss decreased (0.214181 --> 0.213758).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 30.7926178
	speed: 0.0374s/iter; left time: 938.9323s
	iters: 200, epoch: 6 | loss: 30.5038815
	speed: 0.0347s/iter; left time: 866.2715s
Epoch: 6 cost time: 9.478735208511353
Epoch: 6, Steps: 265 Train Loss: 30.3873 (Forecasting Loss:0.2096 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1691
Validation loss decreased (0.213758 --> 0.213197).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 30.8455162
	speed: 0.0365s/iter; left time: 905.7169s
	iters: 200, epoch: 7 | loss: 30.5565720
	speed: 0.0335s/iter; left time: 826.7709s
Epoch: 7 cost time: 9.192197561264038
Epoch: 7, Steps: 265 Train Loss: 30.3925 (Forecasting Loss:0.2093 + XiCon Loss:3.0183 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1691
Validation loss decreased (0.213197 --> 0.212861).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 30.1948261
	speed: 0.0358s/iter; left time: 878.4919s
	iters: 200, epoch: 8 | loss: 30.0684719
	speed: 0.0341s/iter; left time: 833.8839s
Epoch: 8 cost time: 9.23201847076416
Epoch: 8, Steps: 265 Train Loss: 30.3747 (Forecasting Loss:0.2091 + XiCon Loss:3.0166 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1690
Validation loss decreased (0.212861 --> 0.212802).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 30.5652523
	speed: 0.0362s/iter; left time: 878.6755s
	iters: 200, epoch: 9 | loss: 30.1955662
	speed: 0.0336s/iter; left time: 811.8958s
Epoch: 9 cost time: 9.110719680786133
Epoch: 9, Steps: 265 Train Loss: 30.3718 (Forecasting Loss:0.2091 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1690
Validation loss decreased (0.212802 --> 0.212765).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 30.4823742
	speed: 0.0357s/iter; left time: 856.3049s
	iters: 200, epoch: 10 | loss: 30.1694832
	speed: 0.0351s/iter; left time: 839.0075s
Epoch: 10 cost time: 9.366032361984253
Epoch: 10, Steps: 265 Train Loss: 30.3638 (Forecasting Loss:0.2091 + XiCon Loss:3.0155 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 30.4104233
	speed: 0.0361s/iter; left time: 858.3341s
	iters: 200, epoch: 11 | loss: 30.0929737
	speed: 0.0336s/iter; left time: 793.5551s
Epoch: 11 cost time: 9.129186153411865
Epoch: 11, Steps: 265 Train Loss: 30.3597 (Forecasting Loss:0.2090 + XiCon Loss:3.0151 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 29.7945290
	speed: 0.0358s/iter; left time: 841.2508s
	iters: 200, epoch: 12 | loss: 30.4058838
	speed: 0.0335s/iter; left time: 783.3350s
Epoch: 12 cost time: 9.134612321853638
Epoch: 12, Steps: 265 Train Loss: 30.3602 (Forecasting Loss:0.2090 + XiCon Loss:3.0151 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
Validation loss decreased (0.212765 --> 0.212600).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 30.2715950
	speed: 0.0350s/iter; left time: 811.5844s
	iters: 200, epoch: 13 | loss: 30.7327785
	speed: 0.0331s/iter; left time: 765.7388s
Epoch: 13 cost time: 8.99710750579834
Epoch: 13, Steps: 265 Train Loss: 30.3610 (Forecasting Loss:0.2091 + XiCon Loss:3.0152 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.1768150
	speed: 0.0361s/iter; left time: 828.0431s
	iters: 200, epoch: 14 | loss: 30.2157307
	speed: 0.0335s/iter; left time: 766.3163s
Epoch: 14 cost time: 9.208136320114136
Epoch: 14, Steps: 265 Train Loss: 30.3583 (Forecasting Loss:0.2090 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 30.2658348
	speed: 0.0360s/iter; left time: 816.5724s
	iters: 200, epoch: 15 | loss: 30.7468281
	speed: 0.0336s/iter; left time: 759.0471s
Epoch: 15 cost time: 9.115257024765015
Epoch: 15, Steps: 265 Train Loss: 30.3708 (Forecasting Loss:0.2091 + XiCon Loss:3.0162 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 30.3652344
	speed: 0.0357s/iter; left time: 799.5856s
	iters: 200, epoch: 16 | loss: 30.5736027
	speed: 0.0332s/iter; left time: 742.1034s
Epoch: 16 cost time: 9.10451865196228
Epoch: 16, Steps: 265 Train Loss: 30.3690 (Forecasting Loss:0.2090 + XiCon Loss:3.0160 x Lambda(10.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1690
Validation loss decreased (0.212600 --> 0.212307).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 30.2136154
	speed: 0.0365s/iter; left time: 808.1220s
	iters: 200, epoch: 17 | loss: 30.3283653
	speed: 0.0327s/iter; left time: 720.3191s
Epoch: 17 cost time: 9.065608024597168
Epoch: 17, Steps: 265 Train Loss: 30.3798 (Forecasting Loss:0.2090 + XiCon Loss:3.0171 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 30.2260685
	speed: 0.0367s/iter; left time: 802.6787s
	iters: 200, epoch: 18 | loss: 30.7865009
	speed: 0.0343s/iter; left time: 746.8994s
Epoch: 18 cost time: 9.199164390563965
Epoch: 18, Steps: 265 Train Loss: 30.3593 (Forecasting Loss:0.2090 + XiCon Loss:3.0150 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 30.2902145
	speed: 0.0348s/iter; left time: 751.7663s
	iters: 200, epoch: 19 | loss: 30.2230816
	speed: 0.0343s/iter; left time: 737.8816s
Epoch: 19 cost time: 9.210896253585815
Epoch: 19, Steps: 265 Train Loss: 30.3953 (Forecasting Loss:0.2090 + XiCon Loss:3.0186 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1690
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 30.6515636
	speed: 0.0368s/iter; left time: 785.9406s
	iters: 200, epoch: 20 | loss: 30.3566055
	speed: 0.0337s/iter; left time: 716.8395s
Epoch: 20 cost time: 9.258416891098022
Epoch: 20, Steps: 265 Train Loss: 30.3644 (Forecasting Loss:0.2089 + XiCon Loss:3.0155 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 30.1371861
	speed: 0.0365s/iter; left time: 769.2891s
	iters: 200, epoch: 21 | loss: 30.2616711
	speed: 0.0345s/iter; left time: 725.2150s
Epoch: 21 cost time: 9.449733972549438
Epoch: 21, Steps: 265 Train Loss: 30.3647 (Forecasting Loss:0.2090 + XiCon Loss:3.0156 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 30.7468472
	speed: 0.0364s/iter; left time: 757.5010s
	iters: 200, epoch: 22 | loss: 30.1230831
	speed: 0.0334s/iter; left time: 692.5713s
Epoch: 22 cost time: 9.111109256744385
Epoch: 22, Steps: 265 Train Loss: 30.3730 (Forecasting Loss:0.2090 + XiCon Loss:3.0164 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 30.1684151
	speed: 0.0365s/iter; left time: 749.8821s
	iters: 200, epoch: 23 | loss: 30.1421318
	speed: 0.0346s/iter; left time: 707.8034s
Epoch: 23 cost time: 9.349731206893921
Epoch: 23, Steps: 265 Train Loss: 30.3672 (Forecasting Loss:0.2090 + XiCon Loss:3.0158 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1690
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 30.5153332
	speed: 0.0367s/iter; left time: 745.3444s
	iters: 200, epoch: 24 | loss: 30.1320019
	speed: 0.0359s/iter; left time: 725.0735s
Epoch: 24 cost time: 9.449599504470825
Epoch: 24, Steps: 265 Train Loss: 30.3849 (Forecasting Loss:0.2091 + XiCon Loss:3.0176 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 30.4583473
	speed: 0.0366s/iter; left time: 733.3708s
	iters: 200, epoch: 25 | loss: 30.4762745
	speed: 0.0349s/iter; left time: 696.1747s
Epoch: 25 cost time: 9.282045125961304
Epoch: 25, Steps: 265 Train Loss: 30.3668 (Forecasting Loss:0.2090 + XiCon Loss:3.0158 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1690
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 30.3513298
	speed: 0.0360s/iter; left time: 712.1257s
	iters: 200, epoch: 26 | loss: 30.5407524
	speed: 0.0324s/iter; left time: 638.3623s
Epoch: 26 cost time: 9.098855018615723
Epoch: 26, Steps: 265 Train Loss: 30.3722 (Forecasting Loss:0.2091 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0991317555308342, mae:0.23880037665367126, mape:0.5709085464477539, mspe:11.953444480895996 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0856
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.9928246
	speed: 0.0383s/iter; left time: 1010.5723s
	iters: 200, epoch: 1 | loss: 32.7089081
	speed: 0.0353s/iter; left time: 928.0322s
Epoch: 1 cost time: 9.675538539886475
Epoch: 1, Steps: 265 Train Loss: 32.7394 (Forecasting Loss:0.3611 + XiCon Loss:3.2378 x Lambda(10.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2837
Validation loss decreased (inf --> 0.331496).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.1731300
	speed: 0.0354s/iter; left time: 924.4895s
	iters: 200, epoch: 2 | loss: 31.1580524
	speed: 0.0352s/iter; left time: 916.1507s
Epoch: 2 cost time: 9.265984535217285
Epoch: 2, Steps: 265 Train Loss: 31.6846 (Forecasting Loss:0.2403 + XiCon Loss:3.1444 x Lambda(10.0)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1740
Validation loss decreased (0.331496 --> 0.222613).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 30.0826378
	speed: 0.0363s/iter; left time: 938.4950s
	iters: 200, epoch: 3 | loss: 30.6303139
	speed: 0.0328s/iter; left time: 845.9472s
Epoch: 3 cost time: 9.070758581161499
Epoch: 3, Steps: 265 Train Loss: 30.5619 (Forecasting Loss:0.2142 + XiCon Loss:3.0348 x Lambda(10.0)), Vali MSE Loss: 0.2152 Test MSE Loss: 0.1709
Validation loss decreased (0.222613 --> 0.215194).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 30.1809235
	speed: 0.0364s/iter; left time: 932.0485s
	iters: 200, epoch: 4 | loss: 29.9505100
	speed: 0.0332s/iter; left time: 846.4638s
Epoch: 4 cost time: 9.17069697380066
Epoch: 4, Steps: 265 Train Loss: 30.2859 (Forecasting Loss:0.2115 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1706
Validation loss decreased (0.215194 --> 0.214285).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 30.1670456
	speed: 0.0356s/iter; left time: 901.7931s
	iters: 200, epoch: 5 | loss: 30.1623135
	speed: 0.0339s/iter; left time: 855.3374s
Epoch: 5 cost time: 9.354136228561401
Epoch: 5, Steps: 265 Train Loss: 30.2328 (Forecasting Loss:0.2103 + XiCon Loss:3.0022 x Lambda(10.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1705
Validation loss decreased (0.214285 --> 0.213476).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 29.9531269
	speed: 0.0353s/iter; left time: 885.1442s
	iters: 200, epoch: 6 | loss: 30.2006035
	speed: 0.0338s/iter; left time: 844.9730s
Epoch: 6 cost time: 9.068199872970581
Epoch: 6, Steps: 265 Train Loss: 30.2047 (Forecasting Loss:0.2095 + XiCon Loss:2.9995 x Lambda(10.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1701
Validation loss decreased (0.213476 --> 0.213218).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 30.1373482
	speed: 0.0365s/iter; left time: 905.6294s
	iters: 200, epoch: 7 | loss: 30.5189991
	speed: 0.0344s/iter; left time: 849.5303s
Epoch: 7 cost time: 9.334569931030273
Epoch: 7, Steps: 265 Train Loss: 30.1917 (Forecasting Loss:0.2092 + XiCon Loss:2.9982 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1700
Validation loss decreased (0.213218 --> 0.212909).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 30.1264553
	speed: 0.0360s/iter; left time: 884.5974s
	iters: 200, epoch: 8 | loss: 29.9514923
	speed: 0.0335s/iter; left time: 818.6095s
Epoch: 8 cost time: 9.221209526062012
Epoch: 8, Steps: 265 Train Loss: 30.1858 (Forecasting Loss:0.2092 + XiCon Loss:2.9977 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 30.2841740
	speed: 0.0358s/iter; left time: 869.6949s
	iters: 200, epoch: 9 | loss: 30.1756859
	speed: 0.0334s/iter; left time: 807.5716s
Epoch: 9 cost time: 9.101254224777222
Epoch: 9, Steps: 265 Train Loss: 30.1896 (Forecasting Loss:0.2090 + XiCon Loss:2.9981 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 30.0065842
	speed: 0.0348s/iter; left time: 835.7898s
	iters: 200, epoch: 10 | loss: 30.2575874
	speed: 0.0348s/iter; left time: 832.4683s
Epoch: 10 cost time: 9.284051179885864
Epoch: 10, Steps: 265 Train Loss: 30.1925 (Forecasting Loss:0.2090 + XiCon Loss:2.9983 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
Validation loss decreased (0.212909 --> 0.212897).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 29.9243488
	speed: 0.0359s/iter; left time: 851.5754s
	iters: 200, epoch: 11 | loss: 30.2724991
	speed: 0.0332s/iter; left time: 784.2603s
Epoch: 11 cost time: 9.092063903808594
Epoch: 11, Steps: 265 Train Loss: 30.1787 (Forecasting Loss:0.2089 + XiCon Loss:2.9970 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 30.2973385
	speed: 0.0363s/iter; left time: 852.8913s
	iters: 200, epoch: 12 | loss: 30.3586102
	speed: 0.0349s/iter; left time: 816.3406s
Epoch: 12 cost time: 9.29411268234253
Epoch: 12, Steps: 265 Train Loss: 30.2012 (Forecasting Loss:0.2090 + XiCon Loss:2.9992 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 30.6568031
	speed: 0.0359s/iter; left time: 834.7590s
	iters: 200, epoch: 13 | loss: 30.2639141
	speed: 0.0326s/iter; left time: 753.9229s
Epoch: 13 cost time: 9.090553522109985
Epoch: 13, Steps: 265 Train Loss: 30.1696 (Forecasting Loss:0.2090 + XiCon Loss:2.9961 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.0364971
	speed: 0.0357s/iter; left time: 820.3718s
	iters: 200, epoch: 14 | loss: 30.2577209
	speed: 0.0331s/iter; left time: 755.7534s
Epoch: 14 cost time: 9.07992148399353
Epoch: 14, Steps: 265 Train Loss: 30.1736 (Forecasting Loss:0.2088 + XiCon Loss:2.9965 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
Validation loss decreased (0.212897 --> 0.212879).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 30.3019924
	speed: 0.0356s/iter; left time: 806.9010s
	iters: 200, epoch: 15 | loss: 30.2723846
	speed: 0.0344s/iter; left time: 776.3718s
Epoch: 15 cost time: 9.299195766448975
Epoch: 15, Steps: 265 Train Loss: 30.1596 (Forecasting Loss:0.2089 + XiCon Loss:2.9951 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 30.2281723
	speed: 0.0356s/iter; left time: 798.5696s
	iters: 200, epoch: 16 | loss: 30.6113682
	speed: 0.0333s/iter; left time: 743.4790s
Epoch: 16 cost time: 9.081655502319336
Epoch: 16, Steps: 265 Train Loss: 30.1897 (Forecasting Loss:0.2089 + XiCon Loss:2.9981 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 30.0429382
	speed: 0.0367s/iter; left time: 813.9625s
	iters: 200, epoch: 17 | loss: 30.1338444
	speed: 0.0333s/iter; left time: 734.6153s
Epoch: 17 cost time: 9.275636434555054
Epoch: 17, Steps: 265 Train Loss: 30.1538 (Forecasting Loss:0.2089 + XiCon Loss:2.9945 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
Validation loss decreased (0.212879 --> 0.212759).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 30.0146484
	speed: 0.0361s/iter; left time: 790.2502s
	iters: 200, epoch: 18 | loss: 29.9442463
	speed: 0.0337s/iter; left time: 735.2349s
Epoch: 18 cost time: 9.212435483932495
Epoch: 18, Steps: 265 Train Loss: 30.1811 (Forecasting Loss:0.2090 + XiCon Loss:2.9972 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 30.0486927
	speed: 0.0358s/iter; left time: 774.8970s
	iters: 200, epoch: 19 | loss: 29.5825729
	speed: 0.0334s/iter; left time: 719.9654s
Epoch: 19 cost time: 9.210078954696655
Epoch: 19, Steps: 265 Train Loss: 30.1622 (Forecasting Loss:0.2089 + XiCon Loss:2.9953 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 30.3744297
	speed: 0.0375s/iter; left time: 801.8493s
	iters: 200, epoch: 20 | loss: 29.9153557
	speed: 0.0363s/iter; left time: 771.1018s
Epoch: 20 cost time: 9.752381086349487
Epoch: 20, Steps: 265 Train Loss: 30.1829 (Forecasting Loss:0.2090 + XiCon Loss:2.9974 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 29.8842010
	speed: 0.0361s/iter; left time: 762.4246s
	iters: 200, epoch: 21 | loss: 29.7835331
	speed: 0.0344s/iter; left time: 721.6732s
Epoch: 21 cost time: 9.203484296798706
Epoch: 21, Steps: 265 Train Loss: 30.1809 (Forecasting Loss:0.2091 + XiCon Loss:2.9972 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 30.1255741
	speed: 0.0368s/iter; left time: 767.4203s
	iters: 200, epoch: 22 | loss: 30.4679470
	speed: 0.0335s/iter; left time: 694.6881s
Epoch: 22 cost time: 9.217852354049683
Epoch: 22, Steps: 265 Train Loss: 30.1908 (Forecasting Loss:0.2089 + XiCon Loss:2.9982 x Lambda(10.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 30.0874538
	speed: 0.0359s/iter; left time: 737.7376s
	iters: 200, epoch: 23 | loss: 30.0766354
	speed: 0.0337s/iter; left time: 690.0706s
Epoch: 23 cost time: 9.252994775772095
Epoch: 23, Steps: 265 Train Loss: 30.1750 (Forecasting Loss:0.2089 + XiCon Loss:2.9966 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1699
Validation loss decreased (0.212759 --> 0.212741).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 30.4150009
	speed: 0.0356s/iter; left time: 722.3883s
	iters: 200, epoch: 24 | loss: 29.9765263
	speed: 0.0331s/iter; left time: 668.7993s
Epoch: 24 cost time: 9.006893157958984
Epoch: 24, Steps: 265 Train Loss: 30.1856 (Forecasting Loss:0.2089 + XiCon Loss:2.9977 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 30.2825413
	speed: 0.0355s/iter; left time: 712.0796s
	iters: 200, epoch: 25 | loss: 30.3841400
	speed: 0.0337s/iter; left time: 672.8522s
Epoch: 25 cost time: 9.065245151519775
Epoch: 25, Steps: 265 Train Loss: 30.2043 (Forecasting Loss:0.2089 + XiCon Loss:2.9995 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 30.4546642
	speed: 0.0352s/iter; left time: 695.2453s
	iters: 200, epoch: 26 | loss: 29.7454853
	speed: 0.0331s/iter; left time: 650.6574s
Epoch: 26 cost time: 8.934607744216919
Epoch: 26, Steps: 265 Train Loss: 30.1841 (Forecasting Loss:0.2090 + XiCon Loss:2.9975 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 29.9039116
	speed: 0.0364s/iter; left time: 709.5731s
	iters: 200, epoch: 27 | loss: 30.0361233
	speed: 0.0338s/iter; left time: 655.3451s
Epoch: 27 cost time: 9.223764181137085
Epoch: 27, Steps: 265 Train Loss: 30.1935 (Forecasting Loss:0.2091 + XiCon Loss:2.9984 x Lambda(10.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 30.1379356
	speed: 0.0363s/iter; left time: 698.9038s
	iters: 200, epoch: 28 | loss: 30.4646473
	speed: 0.0337s/iter; left time: 645.3426s
Epoch: 28 cost time: 9.33471965789795
Epoch: 28, Steps: 265 Train Loss: 30.1774 (Forecasting Loss:0.2090 + XiCon Loss:2.9968 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 30.3583374
	speed: 0.0373s/iter; left time: 708.9371s
	iters: 200, epoch: 29 | loss: 29.8646469
	speed: 0.0356s/iter; left time: 672.9170s
Epoch: 29 cost time: 9.684297561645508
Epoch: 29, Steps: 265 Train Loss: 30.1810 (Forecasting Loss:0.2090 + XiCon Loss:2.9972 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 30.2276096
	speed: 0.0363s/iter; left time: 679.9254s
	iters: 200, epoch: 30 | loss: 30.3416862
	speed: 0.0340s/iter; left time: 632.7727s
Epoch: 30 cost time: 9.272488355636597
Epoch: 30, Steps: 265 Train Loss: 30.1993 (Forecasting Loss:0.2090 + XiCon Loss:2.9990 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 30.0585899
	speed: 0.0358s/iter; left time: 661.4452s
	iters: 200, epoch: 31 | loss: 29.9721928
	speed: 0.0329s/iter; left time: 603.4208s
Epoch: 31 cost time: 9.142042875289917
Epoch: 31, Steps: 265 Train Loss: 30.1817 (Forecasting Loss:0.2088 + XiCon Loss:2.9973 x Lambda(10.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1699
Validation loss decreased (0.212741 --> 0.212617).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 30.5752640
	speed: 0.0361s/iter; left time: 657.2251s
	iters: 200, epoch: 32 | loss: 30.3196239
	speed: 0.0334s/iter; left time: 603.1900s
Epoch: 32 cost time: 9.167065620422363
Epoch: 32, Steps: 265 Train Loss: 30.1675 (Forecasting Loss:0.2088 + XiCon Loss:2.9959 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 30.1815147
	speed: 0.0363s/iter; left time: 649.6865s
	iters: 200, epoch: 33 | loss: 29.7790718
	speed: 0.0352s/iter; left time: 627.5944s
Epoch: 33 cost time: 9.35170316696167
Epoch: 33, Steps: 265 Train Loss: 30.1715 (Forecasting Loss:0.2089 + XiCon Loss:2.9963 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 30.0465355
	speed: 0.0366s/iter; left time: 645.3301s
	iters: 200, epoch: 34 | loss: 29.9613533
	speed: 0.0341s/iter; left time: 599.2393s
Epoch: 34 cost time: 9.230148792266846
Epoch: 34, Steps: 265 Train Loss: 30.1825 (Forecasting Loss:0.2090 + XiCon Loss:2.9974 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 29.9121971
	speed: 0.0371s/iter; left time: 645.6224s
	iters: 200, epoch: 35 | loss: 29.9229298
	speed: 0.0336s/iter; left time: 580.7579s
Epoch: 35 cost time: 9.25633716583252
Epoch: 35, Steps: 265 Train Loss: 30.1931 (Forecasting Loss:0.2090 + XiCon Loss:2.9984 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1699
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 30.1036472
	speed: 0.0360s/iter; left time: 615.8610s
	iters: 200, epoch: 36 | loss: 30.1941948
	speed: 0.0340s/iter; left time: 579.5898s
Epoch: 36 cost time: 9.20431113243103
Epoch: 36, Steps: 265 Train Loss: 30.1727 (Forecasting Loss:0.2090 + XiCon Loss:2.9964 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1699
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 30.2585239
	speed: 0.0350s/iter; left time: 589.7354s
	iters: 200, epoch: 37 | loss: 30.0083199
	speed: 0.0335s/iter; left time: 561.0768s
Epoch: 37 cost time: 9.057401418685913
Epoch: 37, Steps: 265 Train Loss: 30.1653 (Forecasting Loss:0.2088 + XiCon Loss:2.9956 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 30.1705761
	speed: 0.0365s/iter; left time: 605.1143s
	iters: 200, epoch: 38 | loss: 30.3004417
	speed: 0.0362s/iter; left time: 597.2684s
Epoch: 38 cost time: 9.561228513717651
Epoch: 38, Steps: 265 Train Loss: 30.1663 (Forecasting Loss:0.2089 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 29.9576015
	speed: 0.0361s/iter; left time: 589.6908s
	iters: 200, epoch: 39 | loss: 30.4546757
	speed: 0.0343s/iter; left time: 556.9376s
Epoch: 39 cost time: 9.278531789779663
Epoch: 39, Steps: 265 Train Loss: 30.1872 (Forecasting Loss:0.2088 + XiCon Loss:2.9978 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 30.0556641
	speed: 0.0364s/iter; left time: 584.4259s
	iters: 200, epoch: 40 | loss: 30.1912956
	speed: 0.0339s/iter; left time: 540.9742s
Epoch: 40 cost time: 9.203696489334106
Epoch: 40, Steps: 265 Train Loss: 30.1932 (Forecasting Loss:0.2089 + XiCon Loss:2.9984 x Lambda(10.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1699
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 30.4185963
	speed: 0.0353s/iter; left time: 557.0553s
	iters: 200, epoch: 41 | loss: 30.3740005
	speed: 0.0335s/iter; left time: 526.1035s
Epoch: 41 cost time: 9.217934608459473
Epoch: 41, Steps: 265 Train Loss: 30.1740 (Forecasting Loss:0.2090 + XiCon Loss:2.9965 x Lambda(10.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1699
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10000269114971161, mae:0.23979447782039642, mape:0.5725531578063965, mspe:11.617633819580078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5976
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.8368454
	speed: 0.0375s/iter; left time: 989.3221s
	iters: 200, epoch: 1 | loss: 32.5833817
	speed: 0.0360s/iter; left time: 947.7761s
Epoch: 1 cost time: 9.636722087860107
Epoch: 1, Steps: 265 Train Loss: 32.7427 (Forecasting Loss:0.3469 + XiCon Loss:3.2396 x Lambda(10.0)), Vali MSE Loss: 0.3279 Test MSE Loss: 0.2725
Validation loss decreased (inf --> 0.327918).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 32.1454620
	speed: 0.0366s/iter; left time: 956.6847s
	iters: 200, epoch: 2 | loss: 31.7883549
	speed: 0.0350s/iter; left time: 911.2435s
Epoch: 2 cost time: 9.447707176208496
Epoch: 2, Steps: 265 Train Loss: 32.0755 (Forecasting Loss:0.2410 + XiCon Loss:3.1834 x Lambda(10.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.1727
Validation loss decreased (0.327918 --> 0.219910).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 31.1066742
	speed: 0.0363s/iter; left time: 940.1192s
	iters: 200, epoch: 3 | loss: 31.2759075
	speed: 0.0336s/iter; left time: 865.9360s
Epoch: 3 cost time: 9.232820749282837
Epoch: 3, Steps: 265 Train Loss: 30.9976 (Forecasting Loss:0.2145 + XiCon Loss:3.0783 x Lambda(10.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1699
Validation loss decreased (0.219910 --> 0.214929).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 30.3819485
	speed: 0.0371s/iter; left time: 949.9518s
	iters: 200, epoch: 4 | loss: 30.7714176
	speed: 0.0335s/iter; left time: 855.4092s
Epoch: 4 cost time: 9.27732801437378
Epoch: 4, Steps: 265 Train Loss: 30.6308 (Forecasting Loss:0.2110 + XiCon Loss:3.0420 x Lambda(10.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1692
Validation loss decreased (0.214929 --> 0.213228).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 30.2359371
	speed: 0.0369s/iter; left time: 935.2060s
	iters: 200, epoch: 5 | loss: 30.6684628
	speed: 0.0359s/iter; left time: 906.9821s
Epoch: 5 cost time: 9.624736309051514
Epoch: 5, Steps: 265 Train Loss: 30.5420 (Forecasting Loss:0.2099 + XiCon Loss:3.0332 x Lambda(10.0)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1688
Validation loss decreased (0.213228 --> 0.212361).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 30.4561939
	speed: 0.0364s/iter; left time: 913.9786s
	iters: 200, epoch: 6 | loss: 30.7779083
	speed: 0.0347s/iter; left time: 867.6745s
Epoch: 6 cost time: 9.313508033752441
Epoch: 6, Steps: 265 Train Loss: 30.4967 (Forecasting Loss:0.2093 + XiCon Loss:3.0287 x Lambda(10.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1687
Validation loss decreased (0.212361 --> 0.211996).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 30.1968422
	speed: 0.0362s/iter; left time: 899.0960s
	iters: 200, epoch: 7 | loss: 30.5168285
	speed: 0.0337s/iter; left time: 833.3649s
Epoch: 7 cost time: 9.184317111968994
Epoch: 7, Steps: 265 Train Loss: 30.4574 (Forecasting Loss:0.2090 + XiCon Loss:3.0248 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1686
Validation loss decreased (0.211996 --> 0.211935).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 30.6192894
	speed: 0.0351s/iter; left time: 862.5207s
	iters: 200, epoch: 8 | loss: 30.5206184
	speed: 0.0337s/iter; left time: 822.9252s
Epoch: 8 cost time: 9.058209657669067
Epoch: 8, Steps: 265 Train Loss: 30.4713 (Forecasting Loss:0.2089 + XiCon Loss:3.0262 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1686
Validation loss decreased (0.211935 --> 0.211807).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 30.4898148
	speed: 0.0335s/iter; left time: 813.9840s
	iters: 200, epoch: 9 | loss: 30.4460411
	speed: 0.0468s/iter; left time: 1131.5469s
Epoch: 9 cost time: 14.06004524230957
Epoch: 9, Steps: 265 Train Loss: 30.4804 (Forecasting Loss:0.2088 + XiCon Loss:3.0272 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1686
Validation loss decreased (0.211807 --> 0.211679).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 30.5467701
	speed: 0.0856s/iter; left time: 2054.7976s
	iters: 200, epoch: 10 | loss: 30.3836937
	speed: 0.0996s/iter; left time: 2382.9581s
Epoch: 10 cost time: 24.66973876953125
Epoch: 10, Steps: 265 Train Loss: 30.4784 (Forecasting Loss:0.2089 + XiCon Loss:3.0269 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1686
Validation loss decreased (0.211679 --> 0.211617).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 30.3711205
	speed: 0.0854s/iter; left time: 2029.5059s
	iters: 200, epoch: 11 | loss: 30.7789707
	speed: 0.0751s/iter; left time: 1776.5942s
Epoch: 11 cost time: 20.644362211227417
Epoch: 11, Steps: 265 Train Loss: 30.4617 (Forecasting Loss:0.2087 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1686
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 30.7188530
	speed: 0.0669s/iter; left time: 1571.2097s
	iters: 200, epoch: 12 | loss: 30.6181278
	speed: 0.0443s/iter; left time: 1036.0915s
Epoch: 12 cost time: 14.07431149482727
Epoch: 12, Steps: 265 Train Loss: 30.4913 (Forecasting Loss:0.2088 + XiCon Loss:3.0283 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1686
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 30.6190529
	speed: 0.0363s/iter; left time: 844.0307s
	iters: 200, epoch: 13 | loss: 30.6284695
	speed: 0.0353s/iter; left time: 816.5976s
Epoch: 13 cost time: 9.376672506332397
Epoch: 13, Steps: 265 Train Loss: 30.4817 (Forecasting Loss:0.2087 + XiCon Loss:3.0273 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1686
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 30.2597389
	speed: 0.0344s/iter; left time: 788.6644s
	iters: 200, epoch: 14 | loss: 30.2238674
	speed: 0.0318s/iter; left time: 727.4364s
Epoch: 14 cost time: 8.671655893325806
Epoch: 14, Steps: 265 Train Loss: 30.4620 (Forecasting Loss:0.2087 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1685
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 30.2986889
	speed: 0.0324s/iter; left time: 735.4633s
	iters: 200, epoch: 15 | loss: 30.9482384
	speed: 0.0293s/iter; left time: 661.5849s
Epoch: 15 cost time: 8.148334264755249
Epoch: 15, Steps: 265 Train Loss: 30.4424 (Forecasting Loss:0.2086 + XiCon Loss:3.0234 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1685
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 30.5392570
	speed: 0.0315s/iter; left time: 706.9363s
	iters: 200, epoch: 16 | loss: 30.7123604
	speed: 0.0297s/iter; left time: 662.2504s
Epoch: 16 cost time: 8.018085479736328
Epoch: 16, Steps: 265 Train Loss: 30.4728 (Forecasting Loss:0.2087 + XiCon Loss:3.0264 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1685
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 30.6273022
	speed: 0.0319s/iter; left time: 705.9397s
	iters: 200, epoch: 17 | loss: 30.4744377
	speed: 0.0295s/iter; left time: 651.5349s
Epoch: 17 cost time: 8.014243125915527
Epoch: 17, Steps: 265 Train Loss: 30.4613 (Forecasting Loss:0.2086 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1685
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 30.4796906
	speed: 0.0312s/iter; left time: 683.9594s
	iters: 200, epoch: 18 | loss: 30.4224834
	speed: 0.0306s/iter; left time: 667.3396s
Epoch: 18 cost time: 8.23723030090332
Epoch: 18, Steps: 265 Train Loss: 30.4606 (Forecasting Loss:0.2086 + XiCon Loss:3.0252 x Lambda(10.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1685
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 30.3231468
	speed: 0.0341s/iter; left time: 738.5259s
	iters: 200, epoch: 19 | loss: 30.4931831
	speed: 0.0326s/iter; left time: 701.7488s
Epoch: 19 cost time: 8.827900886535645
Epoch: 19, Steps: 265 Train Loss: 30.4850 (Forecasting Loss:0.2088 + XiCon Loss:3.0276 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1685
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 30.5856972
	speed: 0.0344s/iter; left time: 734.2832s
	iters: 200, epoch: 20 | loss: 30.4800453
	speed: 0.0317s/iter; left time: 673.2182s
Epoch: 20 cost time: 8.6538987159729
Epoch: 20, Steps: 265 Train Loss: 30.4571 (Forecasting Loss:0.2088 + XiCon Loss:3.0248 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1685
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09855757653713226, mae:0.23856373131275177, mape:0.568934977054596, mspe:11.796858787536621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0988+-0.00116, MAE:0.2388+-0.00109, MAPE:0.5698+-0.00233, MSPE:11.8267+-0.18899, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0854
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 32.7316742
	speed: 0.0421s/iter; left time: 1107.0144s
	iters: 200, epoch: 1 | loss: 32.3252945
	speed: 0.0368s/iter; left time: 964.7078s
Epoch: 1 cost time: 10.241606950759888
Epoch: 1, Steps: 264 Train Loss: 32.5156 (Forecasting Loss:0.3357 + XiCon Loss:3.2180 x Lambda(10.0)), Vali MSE Loss: 0.2969 Test MSE Loss: 0.2337
Validation loss decreased (inf --> 0.296919).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 29.9170666
	speed: 0.0382s/iter; left time: 994.5701s
	iters: 200, epoch: 2 | loss: 29.6630783
	speed: 0.0347s/iter; left time: 900.8411s
Epoch: 2 cost time: 9.526232719421387
Epoch: 2, Steps: 264 Train Loss: 30.6750 (Forecasting Loss:0.2530 + XiCon Loss:3.0422 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1941
Validation loss decreased (0.296919 --> 0.250108).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.0636044
	speed: 0.0369s/iter; left time: 949.9612s
	iters: 200, epoch: 3 | loss: 30.5526714
	speed: 0.0355s/iter; left time: 911.1373s
Epoch: 3 cost time: 9.49680233001709
Epoch: 3, Steps: 264 Train Loss: 31.1983 (Forecasting Loss:0.2453 + XiCon Loss:3.0953 x Lambda(10.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1927
Validation loss decreased (0.250108 --> 0.247882).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.2154083
	speed: 0.0380s/iter; left time: 969.4491s
	iters: 200, epoch: 4 | loss: 32.1736908
	speed: 0.0360s/iter; left time: 913.7556s
Epoch: 4 cost time: 9.60892629623413
Epoch: 4, Steps: 264 Train Loss: 31.3769 (Forecasting Loss:0.2433 + XiCon Loss:3.1134 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1932
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 31.6580772
	speed: 0.0371s/iter; left time: 937.3832s
	iters: 200, epoch: 5 | loss: 32.0044708
	speed: 0.0353s/iter; left time: 887.5701s
Epoch: 5 cost time: 9.45051884651184
Epoch: 5, Steps: 264 Train Loss: 31.3544 (Forecasting Loss:0.2424 + XiCon Loss:3.1112 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1928
Validation loss decreased (0.247882 --> 0.247399).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.2779808
	speed: 0.0374s/iter; left time: 934.7898s
	iters: 200, epoch: 6 | loss: 31.9487896
	speed: 0.0346s/iter; left time: 861.4060s
Epoch: 6 cost time: 9.47650694847107
Epoch: 6, Steps: 264 Train Loss: 31.3037 (Forecasting Loss:0.2422 + XiCon Loss:3.1062 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1924
Validation loss decreased (0.247399 --> 0.246954).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 31.9674282
	speed: 0.0364s/iter; left time: 900.2944s
	iters: 200, epoch: 7 | loss: 31.3707905
	speed: 0.0339s/iter; left time: 834.6604s
Epoch: 7 cost time: 9.24934196472168
Epoch: 7, Steps: 264 Train Loss: 31.2956 (Forecasting Loss:0.2420 + XiCon Loss:3.1054 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1925
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 30.6230774
	speed: 0.0374s/iter; left time: 914.2196s
	iters: 200, epoch: 8 | loss: 30.6403732
	speed: 0.0339s/iter; left time: 825.4872s
Epoch: 8 cost time: 9.45751667022705
Epoch: 8, Steps: 264 Train Loss: 31.3138 (Forecasting Loss:0.2419 + XiCon Loss:3.1072 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1926
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 31.0079689
	speed: 0.0366s/iter; left time: 886.4727s
	iters: 200, epoch: 9 | loss: 31.8824310
	speed: 0.0346s/iter; left time: 834.5759s
Epoch: 9 cost time: 9.392472267150879
Epoch: 9, Steps: 264 Train Loss: 31.3118 (Forecasting Loss:0.2419 + XiCon Loss:3.1070 x Lambda(10.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1926
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.4332008
	speed: 0.0377s/iter; left time: 902.7667s
	iters: 200, epoch: 10 | loss: 30.9537868
	speed: 0.0348s/iter; left time: 827.9298s
Epoch: 10 cost time: 9.471811771392822
Epoch: 10, Steps: 264 Train Loss: 31.2715 (Forecasting Loss:0.2420 + XiCon Loss:3.1030 x Lambda(10.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1926
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 31.0638561
	speed: 0.0369s/iter; left time: 873.1733s
	iters: 200, epoch: 11 | loss: 30.4252453
	speed: 0.0352s/iter; left time: 829.9344s
Epoch: 11 cost time: 9.453399658203125
Epoch: 11, Steps: 264 Train Loss: 31.3106 (Forecasting Loss:0.2419 + XiCon Loss:3.1069 x Lambda(10.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1926
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.1089478
	speed: 0.0376s/iter; left time: 879.1761s
	iters: 200, epoch: 12 | loss: 31.3987408
	speed: 0.0342s/iter; left time: 796.1931s
Epoch: 12 cost time: 9.46224331855774
Epoch: 12, Steps: 264 Train Loss: 31.2735 (Forecasting Loss:0.2416 + XiCon Loss:3.1032 x Lambda(10.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1926
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.8012943
	speed: 0.0403s/iter; left time: 932.5094s
	iters: 200, epoch: 13 | loss: 32.0378075
	speed: 0.0350s/iter; left time: 807.0233s
Epoch: 13 cost time: 9.765605926513672
Epoch: 13, Steps: 264 Train Loss: 31.3102 (Forecasting Loss:0.2417 + XiCon Loss:3.1069 x Lambda(10.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1926
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 31.9579964
	speed: 0.0365s/iter; left time: 834.4367s
	iters: 200, epoch: 14 | loss: 30.7850361
	speed: 0.0364s/iter; left time: 828.7190s
Epoch: 14 cost time: 9.615374326705933
Epoch: 14, Steps: 264 Train Loss: 31.2918 (Forecasting Loss:0.2416 + XiCon Loss:3.1050 x Lambda(10.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1926
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 31.8223572
	speed: 0.0375s/iter; left time: 846.8272s
	iters: 200, epoch: 15 | loss: 30.2972889
	speed: 0.0357s/iter; left time: 803.2428s
Epoch: 15 cost time: 9.637210369110107
Epoch: 15, Steps: 264 Train Loss: 31.2550 (Forecasting Loss:0.2418 + XiCon Loss:3.1013 x Lambda(10.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1926
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 31.0792542
	speed: 0.0379s/iter; left time: 846.6915s
	iters: 200, epoch: 16 | loss: 31.4595261
	speed: 0.0349s/iter; left time: 776.7528s
Epoch: 16 cost time: 9.53192949295044
Epoch: 16, Steps: 264 Train Loss: 31.3120 (Forecasting Loss:0.2418 + XiCon Loss:3.1070 x Lambda(10.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1926
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12094131857156754, mae:0.26394155621528625, mape:0.6305394768714905, mspe:14.391582489013672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4330
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 32.8032265
	speed: 0.0393s/iter; left time: 1034.1705s
	iters: 200, epoch: 1 | loss: 32.4479866
	speed: 0.0365s/iter; left time: 956.8140s
Epoch: 1 cost time: 9.984518051147461
Epoch: 1, Steps: 264 Train Loss: 32.5728 (Forecasting Loss:0.3350 + XiCon Loss:3.2238 x Lambda(10.0)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.296003).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.9744339
	speed: 0.0373s/iter; left time: 970.0759s
	iters: 200, epoch: 2 | loss: 30.9038486
	speed: 0.0383s/iter; left time: 993.0470s
Epoch: 2 cost time: 9.972306966781616
Epoch: 2, Steps: 264 Train Loss: 30.9313 (Forecasting Loss:0.2511 + XiCon Loss:3.0680 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1978
Validation loss decreased (0.296003 --> 0.253155).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.7311554
	speed: 0.0408s/iter; left time: 1051.8092s
	iters: 200, epoch: 3 | loss: 31.6331215
	speed: 0.0381s/iter; left time: 978.3965s
Epoch: 3 cost time: 10.401166677474976
Epoch: 3, Steps: 264 Train Loss: 31.1909 (Forecasting Loss:0.2423 + XiCon Loss:3.0949 x Lambda(10.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1963
Validation loss decreased (0.253155 --> 0.251617).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.8523140
	speed: 0.0402s/iter; left time: 1024.6905s
	iters: 200, epoch: 4 | loss: 31.9274082
	speed: 0.0376s/iter; left time: 954.7084s
Epoch: 4 cost time: 10.217446327209473
Epoch: 4, Steps: 264 Train Loss: 31.7152 (Forecasting Loss:0.2421 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1946
Validation loss decreased (0.251617 --> 0.249008).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.7868462
	speed: 0.0405s/iter; left time: 1022.0716s
	iters: 200, epoch: 5 | loss: 31.9822159
	speed: 0.0372s/iter; left time: 936.3554s
Epoch: 5 cost time: 10.19927167892456
Epoch: 5, Steps: 264 Train Loss: 31.9839 (Forecasting Loss:0.2420 + XiCon Loss:3.1742 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1941
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.1788177
	speed: 0.0403s/iter; left time: 1007.8950s
	iters: 200, epoch: 6 | loss: 31.8491039
	speed: 0.0376s/iter; left time: 934.7083s
Epoch: 6 cost time: 10.1542489528656
Epoch: 6, Steps: 264 Train Loss: 32.0943 (Forecasting Loss:0.2417 + XiCon Loss:3.1853 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 31.5786304
	speed: 0.0394s/iter; left time: 974.5541s
	iters: 200, epoch: 7 | loss: 31.0405827
	speed: 0.0377s/iter; left time: 927.0177s
Epoch: 7 cost time: 10.15095591545105
Epoch: 7, Steps: 264 Train Loss: 32.1545 (Forecasting Loss:0.2414 + XiCon Loss:3.1913 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.1942
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.2549171
	speed: 0.0408s/iter; left time: 998.2706s
	iters: 200, epoch: 8 | loss: 31.6151848
	speed: 0.0377s/iter; left time: 918.5505s
Epoch: 8 cost time: 10.305701732635498
Epoch: 8, Steps: 264 Train Loss: 32.1402 (Forecasting Loss:0.2414 + XiCon Loss:3.1899 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1942
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.0690041
	speed: 0.0393s/iter; left time: 950.5928s
	iters: 200, epoch: 9 | loss: 33.3723068
	speed: 0.0379s/iter; left time: 911.9874s
Epoch: 9 cost time: 10.122271060943604
Epoch: 9, Steps: 264 Train Loss: 32.1225 (Forecasting Loss:0.2413 + XiCon Loss:3.1881 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1942
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.8475418
	speed: 0.0374s/iter; left time: 894.4805s
	iters: 200, epoch: 10 | loss: 31.5377903
	speed: 0.0356s/iter; left time: 848.6972s
Epoch: 10 cost time: 9.694905996322632
Epoch: 10, Steps: 264 Train Loss: 32.1453 (Forecasting Loss:0.2412 + XiCon Loss:3.1904 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.1943
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.5508881
	speed: 0.0408s/iter; left time: 964.7990s
	iters: 200, epoch: 11 | loss: 32.3106270
	speed: 0.0387s/iter; left time: 911.1280s
Epoch: 11 cost time: 10.378787279129028
Epoch: 11, Steps: 264 Train Loss: 32.1569 (Forecasting Loss:0.2414 + XiCon Loss:3.1915 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1942
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.9060459
	speed: 0.0393s/iter; left time: 918.7763s
	iters: 200, epoch: 12 | loss: 31.4762917
	speed: 0.0377s/iter; left time: 877.5077s
Epoch: 12 cost time: 10.195672273635864
Epoch: 12, Steps: 264 Train Loss: 32.1312 (Forecasting Loss:0.2413 + XiCon Loss:3.1890 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.1942
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.6363850
	speed: 0.0399s/iter; left time: 922.9686s
	iters: 200, epoch: 13 | loss: 31.9696674
	speed: 0.0371s/iter; left time: 854.3813s
Epoch: 13 cost time: 10.193117618560791
Epoch: 13, Steps: 264 Train Loss: 32.1555 (Forecasting Loss:0.2412 + XiCon Loss:3.1914 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.1942
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 31.4347935
	speed: 0.0394s/iter; left time: 901.6740s
	iters: 200, epoch: 14 | loss: 32.1137733
	speed: 0.0373s/iter; left time: 850.2945s
Epoch: 14 cost time: 10.115819215774536
Epoch: 14, Steps: 264 Train Loss: 32.1161 (Forecasting Loss:0.2413 + XiCon Loss:3.1875 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1942
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12248051911592484, mae:0.2666759788990021, mape:0.6210917234420776, mspe:13.795312881469727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1867
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 32.3887405
	speed: 0.0388s/iter; left time: 1019.6962s
	iters: 200, epoch: 1 | loss: 32.8113632
	speed: 0.0352s/iter; left time: 921.0706s
Epoch: 1 cost time: 9.679321765899658
Epoch: 1, Steps: 264 Train Loss: 32.6224 (Forecasting Loss:0.3364 + XiCon Loss:3.2286 x Lambda(10.0)), Vali MSE Loss: 0.2964 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.296357).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.6050816
	speed: 0.0384s/iter; left time: 1001.0766s
	iters: 200, epoch: 2 | loss: 30.4760094
	speed: 0.0348s/iter; left time: 902.9362s
Epoch: 2 cost time: 9.811849117279053
Epoch: 2, Steps: 264 Train Loss: 30.7849 (Forecasting Loss:0.2518 + XiCon Loss:3.0533 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1944
Validation loss decreased (0.296357 --> 0.249443).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.1003723
	speed: 0.0410s/iter; left time: 1056.1817s
	iters: 200, epoch: 3 | loss: 31.8933296
	speed: 0.0384s/iter; left time: 986.9497s
Epoch: 3 cost time: 10.436036348342896
Epoch: 3, Steps: 264 Train Loss: 31.0528 (Forecasting Loss:0.2427 + XiCon Loss:3.0810 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1954
Validation loss decreased (0.249443 --> 0.249048).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.4072075
	speed: 0.0398s/iter; left time: 1015.7039s
	iters: 200, epoch: 4 | loss: 31.9950504
	speed: 0.0354s/iter; left time: 898.7984s
Epoch: 4 cost time: 9.780055046081543
Epoch: 4, Steps: 264 Train Loss: 32.2859 (Forecasting Loss:0.2411 + XiCon Loss:3.2045 x Lambda(10.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1969
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 31.8345013
	speed: 0.0401s/iter; left time: 1012.4794s
	iters: 200, epoch: 5 | loss: 33.9703293
	speed: 0.0375s/iter; left time: 942.5428s
Epoch: 5 cost time: 10.187348365783691
Epoch: 5, Steps: 264 Train Loss: 32.7141 (Forecasting Loss:0.2408 + XiCon Loss:3.2473 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1969
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.3080635
	speed: 0.0394s/iter; left time: 983.1350s
	iters: 200, epoch: 6 | loss: 32.6104774
	speed: 0.0378s/iter; left time: 940.4133s
Epoch: 6 cost time: 10.105654954910278
Epoch: 6, Steps: 264 Train Loss: 32.8584 (Forecasting Loss:0.2405 + XiCon Loss:3.2618 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1967
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.3118248
	speed: 0.0405s/iter; left time: 1000.4362s
	iters: 200, epoch: 7 | loss: 33.2601891
	speed: 0.0377s/iter; left time: 927.2021s
Epoch: 7 cost time: 10.208098888397217
Epoch: 7, Steps: 264 Train Loss: 32.8192 (Forecasting Loss:0.2402 + XiCon Loss:3.2579 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1963
Validation loss decreased (0.249048 --> 0.248642).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.9196281
	speed: 0.0398s/iter; left time: 972.0436s
	iters: 200, epoch: 8 | loss: 33.6465759
	speed: 0.0379s/iter; left time: 921.9115s
Epoch: 8 cost time: 10.224999189376831
Epoch: 8, Steps: 264 Train Loss: 32.8845 (Forecasting Loss:0.2402 + XiCon Loss:3.2644 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1964
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.3765144
	speed: 0.0392s/iter; left time: 948.4870s
	iters: 200, epoch: 9 | loss: 33.7502747
	speed: 0.0381s/iter; left time: 916.7195s
Epoch: 9 cost time: 10.120980739593506
Epoch: 9, Steps: 264 Train Loss: 32.8995 (Forecasting Loss:0.2400 + XiCon Loss:3.2660 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1964
Validation loss decreased (0.248642 --> 0.248599).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.2107048
	speed: 0.0396s/iter; left time: 947.9811s
	iters: 200, epoch: 10 | loss: 33.1572151
	speed: 0.0376s/iter; left time: 894.6608s
Epoch: 10 cost time: 10.184712409973145
Epoch: 10, Steps: 264 Train Loss: 32.9027 (Forecasting Loss:0.2401 + XiCon Loss:3.2663 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1964
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.3188553
	speed: 0.0401s/iter; left time: 949.0424s
	iters: 200, epoch: 11 | loss: 32.5070000
	speed: 0.0375s/iter; left time: 883.9459s
Epoch: 11 cost time: 10.0841646194458
Epoch: 11, Steps: 264 Train Loss: 32.8710 (Forecasting Loss:0.2400 + XiCon Loss:3.2631 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1964
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.2357712
	speed: 0.0400s/iter; left time: 934.8932s
	iters: 200, epoch: 12 | loss: 32.3056145
	speed: 0.0370s/iter; left time: 862.3617s
Epoch: 12 cost time: 10.127948522567749
Epoch: 12, Steps: 264 Train Loss: 32.8617 (Forecasting Loss:0.2400 + XiCon Loss:3.2622 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1964
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 32.2187042
	speed: 0.0405s/iter; left time: 937.7914s
	iters: 200, epoch: 13 | loss: 32.9552422
	speed: 0.0370s/iter; left time: 852.4204s
Epoch: 13 cost time: 10.098577499389648
Epoch: 13, Steps: 264 Train Loss: 32.8805 (Forecasting Loss:0.2401 + XiCon Loss:3.2640 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 32.5828209
	speed: 0.0391s/iter; left time: 893.5741s
	iters: 200, epoch: 14 | loss: 33.1532669
	speed: 0.0350s/iter; left time: 795.8206s
Epoch: 14 cost time: 9.717939615249634
Epoch: 14, Steps: 264 Train Loss: 32.9118 (Forecasting Loss:0.2400 + XiCon Loss:3.2672 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1964
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 33.1792030
	speed: 0.0397s/iter; left time: 897.3598s
	iters: 200, epoch: 15 | loss: 32.7333107
	speed: 0.0370s/iter; left time: 833.7225s
Epoch: 15 cost time: 10.115520000457764
Epoch: 15, Steps: 264 Train Loss: 32.8526 (Forecasting Loss:0.2400 + XiCon Loss:3.2613 x Lambda(10.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1964
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 32.8127975
	speed: 0.0400s/iter; left time: 894.2237s
	iters: 200, epoch: 16 | loss: 33.3430405
	speed: 0.0376s/iter; left time: 835.8870s
Epoch: 16 cost time: 10.223975419998169
Epoch: 16, Steps: 264 Train Loss: 32.8900 (Forecasting Loss:0.2400 + XiCon Loss:3.2650 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1964
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 32.1829758
	speed: 0.0400s/iter; left time: 882.5384s
	iters: 200, epoch: 17 | loss: 32.8693466
	speed: 0.0371s/iter; left time: 815.2573s
Epoch: 17 cost time: 10.165496110916138
Epoch: 17, Steps: 264 Train Loss: 32.8629 (Forecasting Loss:0.2398 + XiCon Loss:3.2623 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1964
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 33.2685318
	speed: 0.0396s/iter; left time: 863.4107s
	iters: 200, epoch: 18 | loss: 33.3988686
	speed: 0.0375s/iter; left time: 814.8991s
Epoch: 18 cost time: 10.15891432762146
Epoch: 18, Steps: 264 Train Loss: 32.8520 (Forecasting Loss:0.2400 + XiCon Loss:3.2612 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1964
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 32.6403313
	speed: 0.0401s/iter; left time: 863.4622s
	iters: 200, epoch: 19 | loss: 33.3971252
	speed: 0.0378s/iter; left time: 811.3514s
Epoch: 19 cost time: 10.214085102081299
Epoch: 19, Steps: 264 Train Loss: 32.9055 (Forecasting Loss:0.2400 + XiCon Loss:3.2665 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1964
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12431571632623672, mae:0.2684147357940674, mape:0.6258640885353088, mspe:14.001435279846191 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5609
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 32.4983521
	speed: 0.0389s/iter; left time: 1022.8068s
	iters: 200, epoch: 1 | loss: 32.4417610
	speed: 0.0374s/iter; left time: 980.9013s
Epoch: 1 cost time: 10.000304937362671
Epoch: 1, Steps: 264 Train Loss: 32.4135 (Forecasting Loss:0.3356 + XiCon Loss:3.2078 x Lambda(10.0)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.2335
Validation loss decreased (inf --> 0.296029).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.3682442
	speed: 0.0384s/iter; left time: 999.0898s
	iters: 200, epoch: 2 | loss: 30.0244122
	speed: 0.0351s/iter; left time: 909.6533s
Epoch: 2 cost time: 9.660771131515503
Epoch: 2, Steps: 264 Train Loss: 30.6056 (Forecasting Loss:0.2517 + XiCon Loss:3.0354 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1959
Validation loss decreased (0.296029 --> 0.251654).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.2983437
	speed: 0.0364s/iter; left time: 938.3667s
	iters: 200, epoch: 3 | loss: 30.3090458
	speed: 0.0355s/iter; left time: 910.5836s
Epoch: 3 cost time: 9.408348083496094
Epoch: 3, Steps: 264 Train Loss: 30.0702 (Forecasting Loss:0.2428 + XiCon Loss:2.9827 x Lambda(10.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1976
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 30.2514935
	speed: 0.0364s/iter; left time: 927.8954s
	iters: 200, epoch: 4 | loss: 30.4542084
	speed: 0.0357s/iter; left time: 906.5671s
Epoch: 4 cost time: 9.475481748580933
Epoch: 4, Steps: 264 Train Loss: 29.9703 (Forecasting Loss:0.2403 + XiCon Loss:2.9730 x Lambda(10.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1987
Validation loss decreased (0.251654 --> 0.248018).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 29.5627594
	speed: 0.0376s/iter; left time: 950.1175s
	iters: 200, epoch: 5 | loss: 29.7323780
	speed: 0.0351s/iter; left time: 882.2793s
Epoch: 5 cost time: 9.548800468444824
Epoch: 5, Steps: 264 Train Loss: 29.9325 (Forecasting Loss:0.2391 + XiCon Loss:2.9693 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2001
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 30.0681324
	speed: 0.0382s/iter; left time: 953.6301s
	iters: 200, epoch: 6 | loss: 29.7301464
	speed: 0.0352s/iter; left time: 876.5601s
Epoch: 6 cost time: 9.623307704925537
Epoch: 6, Steps: 264 Train Loss: 29.8890 (Forecasting Loss:0.2389 + XiCon Loss:2.9650 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2004
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 29.9899254
	speed: 0.0381s/iter; left time: 940.6841s
	iters: 200, epoch: 7 | loss: 29.7505360
	speed: 0.0350s/iter; left time: 862.6084s
Epoch: 7 cost time: 9.6318941116333
Epoch: 7, Steps: 264 Train Loss: 29.8483 (Forecasting Loss:0.2383 + XiCon Loss:2.9610 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2010
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 29.8720341
	speed: 0.0384s/iter; left time: 938.4694s
	iters: 200, epoch: 8 | loss: 29.7425041
	speed: 0.0358s/iter; left time: 871.0131s
Epoch: 8 cost time: 9.850175142288208
Epoch: 8, Steps: 264 Train Loss: 29.8795 (Forecasting Loss:0.2384 + XiCon Loss:2.9641 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2010
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 30.0414963
	speed: 0.0374s/iter; left time: 904.9324s
	iters: 200, epoch: 9 | loss: 29.8183079
	speed: 0.0346s/iter; left time: 833.5926s
Epoch: 9 cost time: 9.483190536499023
Epoch: 9, Steps: 264 Train Loss: 29.8696 (Forecasting Loss:0.2383 + XiCon Loss:2.9631 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2009
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 29.8868332
	speed: 0.0375s/iter; left time: 896.3411s
	iters: 200, epoch: 10 | loss: 29.9374828
	speed: 0.0346s/iter; left time: 825.3864s
Epoch: 10 cost time: 9.407691240310669
Epoch: 10, Steps: 264 Train Loss: 29.8569 (Forecasting Loss:0.2382 + XiCon Loss:2.9619 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2010
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 29.7768059
	speed: 0.0372s/iter; left time: 879.5126s
	iters: 200, epoch: 11 | loss: 29.8473721
	speed: 0.0351s/iter; left time: 826.9037s
Epoch: 11 cost time: 9.488330841064453
Epoch: 11, Steps: 264 Train Loss: 29.8643 (Forecasting Loss:0.2380 + XiCon Loss:2.9626 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2009
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 29.6896973
	speed: 0.0371s/iter; left time: 868.2922s
	iters: 200, epoch: 12 | loss: 29.8041534
	speed: 0.0361s/iter; left time: 840.2075s
Epoch: 12 cost time: 9.683765411376953
Epoch: 12, Steps: 264 Train Loss: 29.8731 (Forecasting Loss:0.2382 + XiCon Loss:2.9635 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2009
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 29.9172897
	speed: 0.0364s/iter; left time: 841.3347s
	iters: 200, epoch: 13 | loss: 29.8734589
	speed: 0.0347s/iter; left time: 798.1704s
Epoch: 13 cost time: 9.343576908111572
Epoch: 13, Steps: 264 Train Loss: 29.8554 (Forecasting Loss:0.2386 + XiCon Loss:2.9617 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2009
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 29.7614250
	speed: 0.0359s/iter; left time: 819.9666s
	iters: 200, epoch: 14 | loss: 29.9183559
	speed: 0.0340s/iter; left time: 773.2691s
Epoch: 14 cost time: 9.244003295898438
Epoch: 14, Steps: 264 Train Loss: 29.8570 (Forecasting Loss:0.2383 + XiCon Loss:2.9619 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2009
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12615716457366943, mae:0.27131387591362, mape:0.6530873775482178, mspe:15.596536636352539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4954
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 32.8485756
	speed: 0.0399s/iter; left time: 1049.8385s
	iters: 200, epoch: 1 | loss: 32.7737198
	speed: 0.0362s/iter; left time: 947.6558s
Epoch: 1 cost time: 9.951875925064087
Epoch: 1, Steps: 264 Train Loss: 32.5927 (Forecasting Loss:0.3389 + XiCon Loss:3.2254 x Lambda(10.0)), Vali MSE Loss: 0.2973 Test MSE Loss: 0.2348
Validation loss decreased (inf --> 0.297269).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.3167515
	speed: 0.0370s/iter; left time: 964.1584s
	iters: 200, epoch: 2 | loss: 30.1567707
	speed: 0.0348s/iter; left time: 903.3234s
Epoch: 2 cost time: 9.45003604888916
Epoch: 2, Steps: 264 Train Loss: 30.5615 (Forecasting Loss:0.2533 + XiCon Loss:3.0308 x Lambda(10.0)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.1968
Validation loss decreased (0.297269 --> 0.255834).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.0053158
	speed: 0.0374s/iter; left time: 963.8129s
	iters: 200, epoch: 3 | loss: 30.1921291
	speed: 0.0351s/iter; left time: 902.3230s
Epoch: 3 cost time: 9.54443097114563
Epoch: 3, Steps: 264 Train Loss: 30.1453 (Forecasting Loss:0.2450 + XiCon Loss:2.9900 x Lambda(10.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.1949
Validation loss decreased (0.255834 --> 0.252079).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 30.6596222
	speed: 0.0372s/iter; left time: 947.8183s
	iters: 200, epoch: 4 | loss: 30.1285095
	speed: 0.0355s/iter; left time: 902.4225s
Epoch: 4 cost time: 9.509513139724731
Epoch: 4, Steps: 264 Train Loss: 30.4209 (Forecasting Loss:0.2432 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.1952
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 31.1528339
	speed: 0.0372s/iter; left time: 938.0795s
	iters: 200, epoch: 5 | loss: 30.5483093
	speed: 0.0345s/iter; left time: 867.0378s
Epoch: 5 cost time: 9.373671531677246
Epoch: 5, Steps: 264 Train Loss: 30.5725 (Forecasting Loss:0.2428 + XiCon Loss:3.0330 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1940
Validation loss decreased (0.252079 --> 0.250809).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.6693478
	speed: 0.0372s/iter; left time: 929.2119s
	iters: 200, epoch: 6 | loss: 30.3709545
	speed: 0.0351s/iter; left time: 872.9237s
Epoch: 6 cost time: 9.44158387184143
Epoch: 6, Steps: 264 Train Loss: 30.7953 (Forecasting Loss:0.2425 + XiCon Loss:3.0553 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.1939
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 30.8769913
	speed: 0.0374s/iter; left time: 925.3061s
	iters: 200, epoch: 7 | loss: 30.8795147
	speed: 0.0340s/iter; left time: 837.9956s
Epoch: 7 cost time: 9.471644163131714
Epoch: 7, Steps: 264 Train Loss: 30.9097 (Forecasting Loss:0.2427 + XiCon Loss:3.0667 x Lambda(10.0)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.1935
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 30.8491936
	speed: 0.0382s/iter; left time: 934.3995s
	iters: 200, epoch: 8 | loss: 30.2667465
	speed: 0.0349s/iter; left time: 849.7564s
Epoch: 8 cost time: 9.607735633850098
Epoch: 8, Steps: 264 Train Loss: 31.0002 (Forecasting Loss:0.2427 + XiCon Loss:3.0758 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1936
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 31.6863613
	speed: 0.0367s/iter; left time: 887.7842s
	iters: 200, epoch: 9 | loss: 31.2708473
	speed: 0.0360s/iter; left time: 868.0713s
Epoch: 9 cost time: 9.58483338356018
Epoch: 9, Steps: 264 Train Loss: 31.0243 (Forecasting Loss:0.2428 + XiCon Loss:3.0781 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1934
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.2133770
	speed: 0.0379s/iter; left time: 906.2415s
	iters: 200, epoch: 10 | loss: 30.5327530
	speed: 0.0347s/iter; left time: 825.7832s
Epoch: 10 cost time: 9.510334014892578
Epoch: 10, Steps: 264 Train Loss: 31.0199 (Forecasting Loss:0.2427 + XiCon Loss:3.0777 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1933
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 30.9768429
	speed: 0.0377s/iter; left time: 892.3142s
	iters: 200, epoch: 11 | loss: 31.6857910
	speed: 0.0353s/iter; left time: 831.0984s
Epoch: 11 cost time: 9.602030277252197
Epoch: 11, Steps: 264 Train Loss: 31.0755 (Forecasting Loss:0.2428 + XiCon Loss:3.0833 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1934
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 30.1166420
	speed: 0.0367s/iter; left time: 859.0316s
	iters: 200, epoch: 12 | loss: 31.8014717
	speed: 0.0350s/iter; left time: 815.3460s
Epoch: 12 cost time: 9.481686353683472
Epoch: 12, Steps: 264 Train Loss: 31.0517 (Forecasting Loss:0.2427 + XiCon Loss:3.0809 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1933
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.1782341
	speed: 0.0374s/iter; left time: 865.4575s
	iters: 200, epoch: 13 | loss: 30.3204746
	speed: 0.0360s/iter; left time: 828.8729s
Epoch: 13 cost time: 9.576630592346191
Epoch: 13, Steps: 264 Train Loss: 31.0563 (Forecasting Loss:0.2427 + XiCon Loss:3.0814 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1933
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 30.8885136
	speed: 0.0371s/iter; left time: 848.2080s
	iters: 200, epoch: 14 | loss: 30.9012089
	speed: 0.0350s/iter; left time: 797.7728s
Epoch: 14 cost time: 9.411469221115112
Epoch: 14, Steps: 264 Train Loss: 31.0230 (Forecasting Loss:0.2427 + XiCon Loss:3.0780 x Lambda(10.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1933
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 31.6673527
	speed: 0.0376s/iter; left time: 848.8962s
	iters: 200, epoch: 15 | loss: 31.7191048
	speed: 0.0353s/iter; left time: 793.7726s
Epoch: 15 cost time: 9.527747392654419
Epoch: 15, Steps: 264 Train Loss: 31.0583 (Forecasting Loss:0.2427 + XiCon Loss:3.0816 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1933
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12181229144334793, mae:0.26623275876045227, mape:0.6265869140625, mspe:14.05064582824707 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1231+-0.00260, MAE:0.2673+-0.00341, MAPE:0.6314+-0.01560, MSPE:14.3671+-0.89385, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9306
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.4932861
	speed: 0.0547s/iter; left time: 1423.3725s
	iters: 200, epoch: 1 | loss: 32.3583260
	speed: 0.0489s/iter; left time: 1265.3719s
Epoch: 1 cost time: 13.304027557373047
Epoch: 1, Steps: 261 Train Loss: 32.6024 (Forecasting Loss:0.3722 + XiCon Loss:3.2230 x Lambda(10.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2812
Validation loss decreased (inf --> 0.324217).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.7320232
	speed: 0.0486s/iter; left time: 1252.2333s
	iters: 200, epoch: 2 | loss: 30.3271980
	speed: 0.0474s/iter; left time: 1216.5073s
Epoch: 2 cost time: 12.673928022384644
Epoch: 2, Steps: 261 Train Loss: 30.6649 (Forecasting Loss:0.2997 + XiCon Loss:3.0365 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2461
Validation loss decreased (0.324217 --> 0.290337).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.5322304
	speed: 0.0517s/iter; left time: 1316.5530s
	iters: 200, epoch: 3 | loss: 32.2469292
	speed: 0.0476s/iter; left time: 1207.8663s
Epoch: 3 cost time: 12.922685861587524
Epoch: 3, Steps: 261 Train Loss: 31.0956 (Forecasting Loss:0.2942 + XiCon Loss:3.0801 x Lambda(10.0)), Vali MSE Loss: 0.2849 Test MSE Loss: 0.2454
Validation loss decreased (0.290337 --> 0.284855).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.3049622
	speed: 0.0500s/iter; left time: 1261.1514s
	iters: 200, epoch: 4 | loss: 30.6356239
	speed: 0.0483s/iter; left time: 1212.1827s
Epoch: 4 cost time: 12.76766300201416
Epoch: 4, Steps: 261 Train Loss: 31.3345 (Forecasting Loss:0.2907 + XiCon Loss:3.1044 x Lambda(10.0)), Vali MSE Loss: 0.2823 Test MSE Loss: 0.2423
Validation loss decreased (0.284855 --> 0.282307).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.0838547
	speed: 0.0503s/iter; left time: 1256.4743s
	iters: 200, epoch: 5 | loss: 31.5328846
	speed: 0.0483s/iter; left time: 1200.6435s
Epoch: 5 cost time: 12.823051929473877
Epoch: 5, Steps: 261 Train Loss: 31.1428 (Forecasting Loss:0.2895 + XiCon Loss:3.0853 x Lambda(10.0)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.2411
Validation loss decreased (0.282307 --> 0.279671).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.1748390
	speed: 0.0517s/iter; left time: 1277.4410s
	iters: 200, epoch: 6 | loss: 30.5068474
	speed: 0.0493s/iter; left time: 1212.9610s
Epoch: 6 cost time: 13.097017526626587
Epoch: 6, Steps: 261 Train Loss: 31.0837 (Forecasting Loss:0.2886 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2406
Validation loss decreased (0.279671 --> 0.279227).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 30.5243702
	speed: 0.0511s/iter; left time: 1248.9988s
	iters: 200, epoch: 7 | loss: 31.8342609
	speed: 0.0507s/iter; left time: 1234.1697s
Epoch: 7 cost time: 13.215200662612915
Epoch: 7, Steps: 261 Train Loss: 31.0713 (Forecasting Loss:0.2886 + XiCon Loss:3.0783 x Lambda(10.0)), Vali MSE Loss: 0.2798 Test MSE Loss: 0.2405
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 31.1549854
	speed: 0.0515s/iter; left time: 1244.6569s
	iters: 200, epoch: 8 | loss: 31.0168228
	speed: 0.0504s/iter; left time: 1212.5434s
Epoch: 8 cost time: 13.097951650619507
Epoch: 8, Steps: 261 Train Loss: 31.0826 (Forecasting Loss:0.2882 + XiCon Loss:3.0794 x Lambda(10.0)), Vali MSE Loss: 0.2799 Test MSE Loss: 0.2406
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 30.8999767
	speed: 0.0527s/iter; left time: 1259.5911s
	iters: 200, epoch: 9 | loss: 30.8628407
	speed: 0.0497s/iter; left time: 1182.8462s
Epoch: 9 cost time: 13.14408564567566
Epoch: 9, Steps: 261 Train Loss: 31.1504 (Forecasting Loss:0.2882 + XiCon Loss:3.0862 x Lambda(10.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2407
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.6704750
	speed: 0.0509s/iter; left time: 1203.2082s
	iters: 200, epoch: 10 | loss: 30.6950073
	speed: 0.0491s/iter; left time: 1155.3686s
Epoch: 10 cost time: 13.037623167037964
Epoch: 10, Steps: 261 Train Loss: 31.1034 (Forecasting Loss:0.2882 + XiCon Loss:3.0815 x Lambda(10.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2406
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 30.6400185
	speed: 0.0526s/iter; left time: 1229.6511s
	iters: 200, epoch: 11 | loss: 31.6502419
	speed: 0.0479s/iter; left time: 1116.3154s
Epoch: 11 cost time: 13.076735973358154
Epoch: 11, Steps: 261 Train Loss: 31.0944 (Forecasting Loss:0.2882 + XiCon Loss:3.0806 x Lambda(10.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2406
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.8049278
	speed: 0.0514s/iter; left time: 1189.7686s
	iters: 200, epoch: 12 | loss: 30.9580612
	speed: 0.0489s/iter; left time: 1125.8532s
Epoch: 12 cost time: 12.997954368591309
Epoch: 12, Steps: 261 Train Loss: 31.1012 (Forecasting Loss:0.2880 + XiCon Loss:3.0813 x Lambda(10.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2406
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.7706413
	speed: 0.0512s/iter; left time: 1170.9837s
	iters: 200, epoch: 13 | loss: 31.2187691
	speed: 0.0509s/iter; left time: 1159.6976s
Epoch: 13 cost time: 13.188024520874023
Epoch: 13, Steps: 261 Train Loss: 31.0914 (Forecasting Loss:0.2881 + XiCon Loss:3.0803 x Lambda(10.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2406
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 31.2579384
	speed: 0.0506s/iter; left time: 1143.9416s
	iters: 200, epoch: 14 | loss: 30.7068806
	speed: 0.0501s/iter; left time: 1128.0754s
Epoch: 14 cost time: 13.203969955444336
Epoch: 14, Steps: 261 Train Loss: 31.0912 (Forecasting Loss:0.2880 + XiCon Loss:3.0803 x Lambda(10.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2406
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 30.7918129
	speed: 0.0515s/iter; left time: 1150.2143s
	iters: 200, epoch: 15 | loss: 30.7701492
	speed: 0.0498s/iter; left time: 1107.8266s
Epoch: 15 cost time: 13.214608430862427
Epoch: 15, Steps: 261 Train Loss: 31.1079 (Forecasting Loss:0.2883 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.2799 Test MSE Loss: 0.2406
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 31.2604942
	speed: 0.0510s/iter; left time: 1127.4397s
	iters: 200, epoch: 16 | loss: 30.9010487
	speed: 0.0502s/iter; left time: 1103.7077s
Epoch: 16 cost time: 13.157634735107422
Epoch: 16, Steps: 261 Train Loss: 31.0978 (Forecasting Loss:0.2882 + XiCon Loss:3.0810 x Lambda(10.0)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.2406
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1660071164369583, mae:0.31524527072906494, mape:0.7158567905426025, mspe:20.0836181640625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2024
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.6670609
	speed: 0.0512s/iter; left time: 1330.5194s
	iters: 200, epoch: 1 | loss: 32.3978539
	speed: 0.0500s/iter; left time: 1294.9834s
Epoch: 1 cost time: 13.089718580245972
Epoch: 1, Steps: 261 Train Loss: 32.5452 (Forecasting Loss:0.3730 + XiCon Loss:3.2172 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2804
Validation loss decreased (inf --> 0.319377).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.7292881
	speed: 0.0508s/iter; left time: 1306.3698s
	iters: 200, epoch: 2 | loss: 30.4873371
	speed: 0.0483s/iter; left time: 1237.5491s
Epoch: 2 cost time: 12.930876016616821
Epoch: 2, Steps: 261 Train Loss: 30.6910 (Forecasting Loss:0.2994 + XiCon Loss:3.0392 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2520
Validation loss decreased (0.319377 --> 0.289622).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.1725578
	speed: 0.0522s/iter; left time: 1331.1062s
	iters: 200, epoch: 3 | loss: 29.9692497
	speed: 0.0494s/iter; left time: 1253.0247s
Epoch: 3 cost time: 13.206725597381592
Epoch: 3, Steps: 261 Train Loss: 30.0640 (Forecasting Loss:0.2923 + XiCon Loss:2.9772 x Lambda(10.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.2489
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 29.9181385
	speed: 0.0545s/iter; left time: 1373.7585s
	iters: 200, epoch: 4 | loss: 30.8784218
	speed: 0.0526s/iter; left time: 1320.4828s
Epoch: 4 cost time: 13.98141860961914
Epoch: 4, Steps: 261 Train Loss: 30.5227 (Forecasting Loss:0.2912 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2494
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 31.6883354
	speed: 0.0542s/iter; left time: 1353.1979s
	iters: 200, epoch: 5 | loss: 31.4078178
	speed: 0.0535s/iter; left time: 1330.9774s
Epoch: 5 cost time: 14.01365351676941
Epoch: 5, Steps: 261 Train Loss: 31.1558 (Forecasting Loss:0.2902 + XiCon Loss:3.0866 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2502
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.1410942
	speed: 0.0547s/iter; left time: 1350.4702s
	iters: 200, epoch: 6 | loss: 31.2763958
	speed: 0.0518s/iter; left time: 1273.5296s
Epoch: 6 cost time: 13.870149374008179
Epoch: 6, Steps: 261 Train Loss: 31.4838 (Forecasting Loss:0.2894 + XiCon Loss:3.1194 x Lambda(10.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 31.6653614
	speed: 0.0553s/iter; left time: 1351.2414s
	iters: 200, epoch: 7 | loss: 32.4311371
	speed: 0.0516s/iter; left time: 1254.8928s
Epoch: 7 cost time: 13.718870162963867
Epoch: 7, Steps: 261 Train Loss: 31.6767 (Forecasting Loss:0.2894 + XiCon Loss:3.1387 x Lambda(10.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2500
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 31.3515053
	speed: 0.0555s/iter; left time: 1341.0116s
	iters: 200, epoch: 8 | loss: 31.7889957
	speed: 0.0521s/iter; left time: 1253.4560s
Epoch: 8 cost time: 13.869940519332886
Epoch: 8, Steps: 261 Train Loss: 31.6756 (Forecasting Loss:0.2891 + XiCon Loss:3.1386 x Lambda(10.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2503
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.0694351
	speed: 0.0554s/iter; left time: 1325.5636s
	iters: 200, epoch: 9 | loss: 31.9067612
	speed: 0.0522s/iter; left time: 1244.2290s
Epoch: 9 cost time: 13.949809312820435
Epoch: 9, Steps: 261 Train Loss: 31.7108 (Forecasting Loss:0.2890 + XiCon Loss:3.1422 x Lambda(10.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.8887997
	speed: 0.0540s/iter; left time: 1277.7904s
	iters: 200, epoch: 10 | loss: 31.4792881
	speed: 0.0523s/iter; left time: 1232.1030s
Epoch: 10 cost time: 13.795920848846436
Epoch: 10, Steps: 261 Train Loss: 31.7896 (Forecasting Loss:0.2890 + XiCon Loss:3.1501 x Lambda(10.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2503
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 31.9388332
	speed: 0.0536s/iter; left time: 1253.6666s
	iters: 200, epoch: 11 | loss: 32.0866890
	speed: 0.0524s/iter; left time: 1219.6655s
Epoch: 11 cost time: 13.692115306854248
Epoch: 11, Steps: 261 Train Loss: 31.7366 (Forecasting Loss:0.2890 + XiCon Loss:3.1448 x Lambda(10.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2503
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.8175983
	speed: 0.0535s/iter; left time: 1237.2582s
	iters: 200, epoch: 12 | loss: 30.8260155
	speed: 0.0520s/iter; left time: 1197.3140s
Epoch: 12 cost time: 13.726716995239258
Epoch: 12, Steps: 261 Train Loss: 31.7702 (Forecasting Loss:0.2890 + XiCon Loss:3.1481 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2503
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17633141577243805, mae:0.3276488184928894, mape:0.7102129459381104, mspe:19.101478576660156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3798
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.3873596
	speed: 0.0474s/iter; left time: 1231.3440s
	iters: 200, epoch: 1 | loss: 32.5951424
	speed: 0.0433s/iter; left time: 1121.6850s
Epoch: 1 cost time: 11.730024337768555
Epoch: 1, Steps: 261 Train Loss: 32.5979 (Forecasting Loss:0.3716 + XiCon Loss:3.2226 x Lambda(10.0)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.2841
Validation loss decreased (inf --> 0.331739).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.7902546
	speed: 0.0446s/iter; left time: 1147.9189s
	iters: 200, epoch: 2 | loss: 30.2225780
	speed: 0.0450s/iter; left time: 1153.8115s
Epoch: 2 cost time: 11.704928636550903
Epoch: 2, Steps: 261 Train Loss: 30.7672 (Forecasting Loss:0.2970 + XiCon Loss:3.0470 x Lambda(10.0)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.2530
Validation loss decreased (0.331739 --> 0.292801).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.2406921
	speed: 0.0472s/iter; left time: 1202.4352s
	iters: 200, epoch: 3 | loss: 30.8080616
	speed: 0.0460s/iter; left time: 1167.2055s
Epoch: 3 cost time: 12.348708868026733
Epoch: 3, Steps: 261 Train Loss: 30.2604 (Forecasting Loss:0.2914 + XiCon Loss:2.9969 x Lambda(10.0)), Vali MSE Loss: 0.2942 Test MSE Loss: 0.2512
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.1665649
	speed: 0.0534s/iter; left time: 1345.7806s
	iters: 200, epoch: 4 | loss: 30.9875755
	speed: 0.0511s/iter; left time: 1284.0142s
Epoch: 4 cost time: 13.559221744537354
Epoch: 4, Steps: 261 Train Loss: 31.2602 (Forecasting Loss:0.2912 + XiCon Loss:3.0969 x Lambda(10.0)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.2514
Validation loss decreased (0.292801 --> 0.292474).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 31.8058147
	speed: 0.0540s/iter; left time: 1348.0264s
	iters: 200, epoch: 5 | loss: 31.7088547
	speed: 0.0516s/iter; left time: 1283.6645s
Epoch: 5 cost time: 13.761853218078613
Epoch: 5, Steps: 261 Train Loss: 31.8796 (Forecasting Loss:0.2912 + XiCon Loss:3.1588 x Lambda(10.0)), Vali MSE Loss: 0.2915 Test MSE Loss: 0.2508
Validation loss decreased (0.292474 --> 0.291545).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.7635307
	speed: 0.0532s/iter; left time: 1314.7883s
	iters: 200, epoch: 6 | loss: 32.4164085
	speed: 0.0496s/iter; left time: 1219.6933s
Epoch: 6 cost time: 13.489806413650513
Epoch: 6, Steps: 261 Train Loss: 32.2271 (Forecasting Loss:0.2911 + XiCon Loss:3.1936 x Lambda(10.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.2507
Validation loss decreased (0.291545 --> 0.291097).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.4596329
	speed: 0.0524s/iter; left time: 1280.5797s
	iters: 200, epoch: 7 | loss: 32.4435005
	speed: 0.0500s/iter; left time: 1217.3316s
Epoch: 7 cost time: 13.296412467956543
Epoch: 7, Steps: 261 Train Loss: 32.4091 (Forecasting Loss:0.2912 + XiCon Loss:3.2118 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2508
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.8552094
	speed: 0.0539s/iter; left time: 1303.2117s
	iters: 200, epoch: 8 | loss: 32.6356735
	speed: 0.0510s/iter; left time: 1227.8945s
Epoch: 8 cost time: 13.603692293167114
Epoch: 8, Steps: 261 Train Loss: 32.5022 (Forecasting Loss:0.2911 + XiCon Loss:3.2211 x Lambda(10.0)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.2507
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 33.5049095
	speed: 0.0539s/iter; left time: 1288.2494s
	iters: 200, epoch: 9 | loss: 32.3009377
	speed: 0.0488s/iter; left time: 1161.7852s
Epoch: 9 cost time: 13.206031560897827
Epoch: 9, Steps: 261 Train Loss: 32.4661 (Forecasting Loss:0.2909 + XiCon Loss:3.2175 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2507
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.4885139
	speed: 0.0542s/iter; left time: 1282.6092s
	iters: 200, epoch: 10 | loss: 33.3856850
	speed: 0.0504s/iter; left time: 1187.2260s
Epoch: 10 cost time: 13.66209626197815
Epoch: 10, Steps: 261 Train Loss: 32.5057 (Forecasting Loss:0.2910 + XiCon Loss:3.2215 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2508
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 33.0374451
	speed: 0.0519s/iter; left time: 1213.4531s
	iters: 200, epoch: 11 | loss: 32.4282951
	speed: 0.0500s/iter; left time: 1165.5234s
Epoch: 11 cost time: 13.228307247161865
Epoch: 11, Steps: 261 Train Loss: 32.5566 (Forecasting Loss:0.2911 + XiCon Loss:3.2265 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2507
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.2397346
	speed: 0.0535s/iter; left time: 1237.9411s
	iters: 200, epoch: 12 | loss: 31.8669605
	speed: 0.0523s/iter; left time: 1204.3460s
Epoch: 12 cost time: 13.648332595825195
Epoch: 12, Steps: 261 Train Loss: 32.5302 (Forecasting Loss:0.2909 + XiCon Loss:3.2239 x Lambda(10.0)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.2507
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 32.4997864
	speed: 0.0526s/iter; left time: 1203.4459s
	iters: 200, epoch: 13 | loss: 33.4036064
	speed: 0.0501s/iter; left time: 1140.2718s
Epoch: 13 cost time: 13.524158954620361
Epoch: 13, Steps: 261 Train Loss: 32.5626 (Forecasting Loss:0.2910 + XiCon Loss:3.2272 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2507
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 33.2043343
	speed: 0.0545s/iter; left time: 1231.0710s
	iters: 200, epoch: 14 | loss: 33.2389870
	speed: 0.0506s/iter; left time: 1138.8616s
Epoch: 14 cost time: 13.58694839477539
Epoch: 14, Steps: 261 Train Loss: 32.5193 (Forecasting Loss:0.2911 + XiCon Loss:3.2228 x Lambda(10.0)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.2507
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 32.7824173
	speed: 0.0527s/iter; left time: 1178.2317s
	iters: 200, epoch: 15 | loss: 32.6948471
	speed: 0.0497s/iter; left time: 1106.3690s
Epoch: 15 cost time: 13.50924277305603
Epoch: 15, Steps: 261 Train Loss: 32.5178 (Forecasting Loss:0.2909 + XiCon Loss:3.2227 x Lambda(10.0)), Vali MSE Loss: 0.2921 Test MSE Loss: 0.2507
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 32.5893097
	speed: 0.0530s/iter; left time: 1171.4208s
	iters: 200, epoch: 16 | loss: 32.2740746
	speed: 0.0496s/iter; left time: 1089.7598s
Epoch: 16 cost time: 13.320436477661133
Epoch: 16, Steps: 261 Train Loss: 32.5417 (Forecasting Loss:0.2908 + XiCon Loss:3.2251 x Lambda(10.0)), Vali MSE Loss: 0.2920 Test MSE Loss: 0.2507
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1758577823638916, mae:0.3256094753742218, mape:0.7016269564628601, mspe:18.754987716674805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2888
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.7959137
	speed: 0.0528s/iter; left time: 1373.9297s
	iters: 200, epoch: 1 | loss: 32.4891510
	speed: 0.0487s/iter; left time: 1260.1058s
Epoch: 1 cost time: 13.182768106460571
Epoch: 1, Steps: 261 Train Loss: 32.6521 (Forecasting Loss:0.3698 + XiCon Loss:3.2282 x Lambda(10.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2798
Validation loss decreased (inf --> 0.324232).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.7794304
	speed: 0.0511s/iter; left time: 1315.7087s
	iters: 200, epoch: 2 | loss: 30.3645096
	speed: 0.0487s/iter; left time: 1248.8235s
Epoch: 2 cost time: 13.013893365859985
Epoch: 2, Steps: 261 Train Loss: 30.8275 (Forecasting Loss:0.2972 + XiCon Loss:3.0530 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2486
Validation loss decreased (0.324232 --> 0.290190).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 29.7309761
	speed: 0.0507s/iter; left time: 1291.3908s
	iters: 200, epoch: 3 | loss: 32.2283020
	speed: 0.0495s/iter; left time: 1256.3339s
Epoch: 3 cost time: 13.012893199920654
Epoch: 3, Steps: 261 Train Loss: 30.7779 (Forecasting Loss:0.2927 + XiCon Loss:3.0485 x Lambda(10.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2562
Validation loss decreased (0.290190 --> 0.289206).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.5032883
	speed: 0.0516s/iter; left time: 1300.1538s
	iters: 200, epoch: 4 | loss: 32.5897560
	speed: 0.0483s/iter; left time: 1212.3575s
Epoch: 4 cost time: 12.948507070541382
Epoch: 4, Steps: 261 Train Loss: 32.1552 (Forecasting Loss:0.2888 + XiCon Loss:3.1866 x Lambda(10.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2547
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.5034256
	speed: 0.0520s/iter; left time: 1298.8903s
	iters: 200, epoch: 5 | loss: 31.7306461
	speed: 0.0503s/iter; left time: 1250.3028s
Epoch: 5 cost time: 13.304369688034058
Epoch: 5, Steps: 261 Train Loss: 31.9833 (Forecasting Loss:0.2874 + XiCon Loss:3.1696 x Lambda(10.0)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.2533
Validation loss decreased (0.289206 --> 0.286244).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.2953777
	speed: 0.0525s/iter; left time: 1295.9202s
	iters: 200, epoch: 6 | loss: 32.1159515
	speed: 0.0499s/iter; left time: 1228.1990s
Epoch: 6 cost time: 13.304942846298218
Epoch: 6, Steps: 261 Train Loss: 31.9534 (Forecasting Loss:0.2871 + XiCon Loss:3.1666 x Lambda(10.0)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.2531
Validation loss decreased (0.286244 --> 0.286174).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.5958328
	speed: 0.0520s/iter; left time: 1269.6725s
	iters: 200, epoch: 7 | loss: 32.5058594
	speed: 0.0463s/iter; left time: 1126.1522s
Epoch: 7 cost time: 12.75928282737732
Epoch: 7, Steps: 261 Train Loss: 31.9439 (Forecasting Loss:0.2867 + XiCon Loss:3.1657 x Lambda(10.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2528
Validation loss decreased (0.286174 --> 0.285387).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 31.6017990
	speed: 0.0508s/iter; left time: 1227.3973s
	iters: 200, epoch: 8 | loss: 31.9806118
	speed: 0.0489s/iter; left time: 1177.2702s
Epoch: 8 cost time: 12.995481967926025
Epoch: 8, Steps: 261 Train Loss: 31.8770 (Forecasting Loss:0.2867 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 0.2856 Test MSE Loss: 0.2529
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 31.6310234
	speed: 0.0517s/iter; left time: 1236.2791s
	iters: 200, epoch: 9 | loss: 32.1909752
	speed: 0.0494s/iter; left time: 1176.4254s
Epoch: 9 cost time: 13.055528163909912
Epoch: 9, Steps: 261 Train Loss: 31.8960 (Forecasting Loss:0.2866 + XiCon Loss:3.1609 x Lambda(10.0)), Vali MSE Loss: 0.2861 Test MSE Loss: 0.2529
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.8949451
	speed: 0.0526s/iter; left time: 1244.2894s
	iters: 200, epoch: 10 | loss: 31.8729534
	speed: 0.0512s/iter; left time: 1205.0689s
Epoch: 10 cost time: 13.49693512916565
Epoch: 10, Steps: 261 Train Loss: 31.8652 (Forecasting Loss:0.2866 + XiCon Loss:3.1579 x Lambda(10.0)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.2528
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.0622940
	speed: 0.0512s/iter; left time: 1197.5642s
	iters: 200, epoch: 11 | loss: 32.3779068
	speed: 0.0492s/iter; left time: 1146.1394s
Epoch: 11 cost time: 13.114174604415894
Epoch: 11, Steps: 261 Train Loss: 31.8729 (Forecasting Loss:0.2867 + XiCon Loss:3.1586 x Lambda(10.0)), Vali MSE Loss: 0.2865 Test MSE Loss: 0.2528
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.1197643
	speed: 0.0510s/iter; left time: 1179.5611s
	iters: 200, epoch: 12 | loss: 31.5241280
	speed: 0.0489s/iter; left time: 1125.2705s
Epoch: 12 cost time: 13.081267595291138
Epoch: 12, Steps: 261 Train Loss: 31.9288 (Forecasting Loss:0.2866 + XiCon Loss:3.1642 x Lambda(10.0)), Vali MSE Loss: 0.2861 Test MSE Loss: 0.2528
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.2830772
	speed: 0.0520s/iter; left time: 1189.3859s
	iters: 200, epoch: 13 | loss: 31.2383041
	speed: 0.0496s/iter; left time: 1129.7919s
Epoch: 13 cost time: 13.173346281051636
Epoch: 13, Steps: 261 Train Loss: 31.8959 (Forecasting Loss:0.2866 + XiCon Loss:3.1609 x Lambda(10.0)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.2528
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 31.6865139
	speed: 0.0530s/iter; left time: 1198.2956s
	iters: 200, epoch: 14 | loss: 32.5823517
	speed: 0.0501s/iter; left time: 1127.9243s
Epoch: 14 cost time: 13.297834873199463
Epoch: 14, Steps: 261 Train Loss: 31.8736 (Forecasting Loss:0.2866 + XiCon Loss:3.1587 x Lambda(10.0)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.2528
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 31.9202518
	speed: 0.0513s/iter; left time: 1146.0887s
	iters: 200, epoch: 15 | loss: 31.6839523
	speed: 0.0503s/iter; left time: 1120.0577s
Epoch: 15 cost time: 13.26769232749939
Epoch: 15, Steps: 261 Train Loss: 31.8726 (Forecasting Loss:0.2867 + XiCon Loss:3.1586 x Lambda(10.0)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.2528
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 31.8566799
	speed: 0.0518s/iter; left time: 1144.0936s
	iters: 200, epoch: 16 | loss: 32.1908188
	speed: 0.0497s/iter; left time: 1093.2913s
Epoch: 16 cost time: 13.216584920883179
Epoch: 16, Steps: 261 Train Loss: 31.8482 (Forecasting Loss:0.2865 + XiCon Loss:3.1562 x Lambda(10.0)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.2528
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 32.9826775
	speed: 0.0523s/iter; left time: 1141.1785s
	iters: 200, epoch: 17 | loss: 31.3124104
	speed: 0.0510s/iter; left time: 1108.1774s
Epoch: 17 cost time: 13.451613664627075
Epoch: 17, Steps: 261 Train Loss: 31.8892 (Forecasting Loss:0.2865 + XiCon Loss:3.1603 x Lambda(10.0)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.2528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17789970338344574, mae:0.32776737213134766, mape:0.7144942283630371, mspe:18.970783233642578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3037
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.5787201
	speed: 0.0477s/iter; left time: 1240.8401s
	iters: 200, epoch: 1 | loss: 32.2950516
	speed: 0.0445s/iter; left time: 1151.3119s
Epoch: 1 cost time: 11.928823471069336
Epoch: 1, Steps: 261 Train Loss: 32.5798 (Forecasting Loss:0.3707 + XiCon Loss:3.2209 x Lambda(10.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2817
Validation loss decreased (inf --> 0.324159).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 30.4297714
	speed: 0.0466s/iter; left time: 1199.3097s
	iters: 200, epoch: 2 | loss: 30.0674553
	speed: 0.0462s/iter; left time: 1183.9507s
Epoch: 2 cost time: 12.493341207504272
Epoch: 2, Steps: 261 Train Loss: 30.5701 (Forecasting Loss:0.2990 + XiCon Loss:3.0271 x Lambda(10.0)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.2533
Validation loss decreased (0.324159 --> 0.293131).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 30.5318813
	speed: 0.0574s/iter; left time: 1462.3348s
	iters: 200, epoch: 3 | loss: 31.3190250
	speed: 0.0551s/iter; left time: 1397.7151s
Epoch: 3 cost time: 14.80898380279541
Epoch: 3, Steps: 261 Train Loss: 30.8528 (Forecasting Loss:0.2903 + XiCon Loss:3.0562 x Lambda(10.0)), Vali MSE Loss: 0.2954 Test MSE Loss: 0.2518
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.1222420
	speed: 0.0583s/iter; left time: 1471.3231s
	iters: 200, epoch: 4 | loss: 32.3076782
	speed: 0.0565s/iter; left time: 1418.3855s
Epoch: 4 cost time: 14.875665664672852
Epoch: 4, Steps: 261 Train Loss: 31.8491 (Forecasting Loss:0.2891 + XiCon Loss:3.1560 x Lambda(10.0)), Vali MSE Loss: 0.2963 Test MSE Loss: 0.2499
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 33.0882835
	speed: 0.0579s/iter; left time: 1445.8203s
	iters: 200, epoch: 5 | loss: 32.3195496
	speed: 0.0556s/iter; left time: 1383.0651s
Epoch: 5 cost time: 14.92636251449585
Epoch: 5, Steps: 261 Train Loss: 32.3310 (Forecasting Loss:0.2878 + XiCon Loss:3.2043 x Lambda(10.0)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.2496
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 31.0452271
	speed: 0.0582s/iter; left time: 1438.5241s
	iters: 200, epoch: 6 | loss: 32.0269775
	speed: 0.0555s/iter; left time: 1365.8063s
Epoch: 6 cost time: 14.912854194641113
Epoch: 6, Steps: 261 Train Loss: 32.4586 (Forecasting Loss:0.2875 + XiCon Loss:3.2171 x Lambda(10.0)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.2492
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.4531364
	speed: 0.0580s/iter; left time: 1417.9540s
	iters: 200, epoch: 7 | loss: 32.7603188
	speed: 0.0540s/iter; left time: 1313.0705s
Epoch: 7 cost time: 14.585577726364136
Epoch: 7, Steps: 261 Train Loss: 32.5124 (Forecasting Loss:0.2872 + XiCon Loss:3.2225 x Lambda(10.0)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.2491
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.4849205
	speed: 0.0592s/iter; left time: 1430.9952s
	iters: 200, epoch: 8 | loss: 32.1747932
	speed: 0.0575s/iter; left time: 1384.5409s
Epoch: 8 cost time: 15.070440292358398
Epoch: 8, Steps: 261 Train Loss: 32.5512 (Forecasting Loss:0.2873 + XiCon Loss:3.2264 x Lambda(10.0)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.2491
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.5830307
	speed: 0.0594s/iter; left time: 1420.9254s
	iters: 200, epoch: 9 | loss: 32.3410301
	speed: 0.0549s/iter; left time: 1306.7322s
Epoch: 9 cost time: 14.840347528457642
Epoch: 9, Steps: 261 Train Loss: 32.5777 (Forecasting Loss:0.2873 + XiCon Loss:3.2290 x Lambda(10.0)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.2490
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 33.0960579
	speed: 0.0577s/iter; left time: 1364.1205s
	iters: 200, epoch: 10 | loss: 33.2053223
	speed: 0.0546s/iter; left time: 1285.9364s
Epoch: 10 cost time: 14.543328046798706
Epoch: 10, Steps: 261 Train Loss: 32.6729 (Forecasting Loss:0.2872 + XiCon Loss:3.2386 x Lambda(10.0)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.2490
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.3219032
	speed: 0.0566s/iter; left time: 1323.3666s
	iters: 200, epoch: 11 | loss: 32.0702858
	speed: 0.0544s/iter; left time: 1266.8273s
Epoch: 11 cost time: 14.628214836120605
Epoch: 11, Steps: 261 Train Loss: 32.6308 (Forecasting Loss:0.2872 + XiCon Loss:3.2344 x Lambda(10.0)), Vali MSE Loss: 0.2945 Test MSE Loss: 0.2490
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.7709808
	speed: 0.0579s/iter; left time: 1339.5498s
	iters: 200, epoch: 12 | loss: 32.6517372
	speed: 0.0576s/iter; left time: 1327.6430s
Epoch: 12 cost time: 14.903212308883667
Epoch: 12, Steps: 261 Train Loss: 32.6208 (Forecasting Loss:0.2873 + XiCon Loss:3.2333 x Lambda(10.0)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.2490
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17800049483776093, mae:0.3285772502422333, mape:0.7063360214233398, mspe:18.835384368896484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1748+-0.00623, MAE:0.3250+-0.00689, MAPE:0.7097+-0.00728, MSPE:19.1493+-0.66898, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
