Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6807
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.1865243911743164
Epoch: 1, Steps: 69 Train Loss: 0.1341 (Forecasting Loss:0.1323 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.2841 Test MSE Loss: 0.1489
Validation loss decreased (inf --> 0.284117).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9465429782867432
Epoch: 2, Steps: 69 Train Loss: 0.1111 (Forecasting Loss:0.1093 + XiCon Loss:1.8325 x Lambda(0.001)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1199
Validation loss decreased (0.284117 --> 0.210247).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.954766035079956
Epoch: 3, Steps: 69 Train Loss: 0.1023 (Forecasting Loss:0.1004 + XiCon Loss:1.8406 x Lambda(0.001)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1169
Validation loss decreased (0.210247 --> 0.203248).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9874157905578613
Epoch: 4, Steps: 69 Train Loss: 0.1002 (Forecasting Loss:0.0983 + XiCon Loss:1.8363 x Lambda(0.001)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1161
Validation loss decreased (0.203248 --> 0.200929).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9403176307678223
Epoch: 5, Steps: 69 Train Loss: 0.0993 (Forecasting Loss:0.0975 + XiCon Loss:1.8384 x Lambda(0.001)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1153
Validation loss decreased (0.200929 --> 0.199755).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9691717624664307
Epoch: 6, Steps: 69 Train Loss: 0.0991 (Forecasting Loss:0.0973 + XiCon Loss:1.8346 x Lambda(0.001)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1150
Validation loss decreased (0.199755 --> 0.199297).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9677793979644775
Epoch: 7, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8418 x Lambda(0.001)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1149
Validation loss decreased (0.199297 --> 0.198958).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.002634048461914
Epoch: 8, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8329 x Lambda(0.001)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9505796432495117
Epoch: 9, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1149
Validation loss decreased (0.198958 --> 0.198882).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9602289199829102
Epoch: 10, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0970 + XiCon Loss:1.8399 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198882 --> 0.198850).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9360668659210205
Epoch: 11, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8426 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198850 --> 0.198837).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9528663158416748
Epoch: 12, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8377 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198837 --> 0.198829).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8851883411407471
Epoch: 13, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8390 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198829 --> 0.198825).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9051532745361328
Epoch: 14, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8372 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198825 --> 0.198823).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9997408390045166
Epoch: 15, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0970 + XiCon Loss:1.8418 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198823 --> 0.198822).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.939314603805542
Epoch: 16, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8374 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8897097110748291
Epoch: 17, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8361 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9022128582000732
Epoch: 18, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0967 + XiCon Loss:1.8342 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9022810459136963
Epoch: 19, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9407782554626465
Epoch: 20, Steps: 69 Train Loss: 0.0990 (Forecasting Loss:0.0972 + XiCon Loss:1.8384 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9384574890136719
Epoch: 21, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8309 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9292466640472412
Epoch: 22, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8329 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9215734004974365
Epoch: 23, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9589943885803223
Epoch: 24, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8353 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9509835243225098
Epoch: 25, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8402 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9521691799163818
Epoch: 26, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0967 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9566442966461182
Epoch: 27, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8348 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9657549858093262
Epoch: 28, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8378 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9541535377502441
Epoch: 29, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8351 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.869525671005249
Epoch: 30, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0971 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.869870662689209
Epoch: 31, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8338 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8646488189697266
Epoch: 32, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8624594211578369
Epoch: 33, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8335 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.894580602645874
Epoch: 34, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8383 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9216189384460449
Epoch: 35, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8381 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.909557580947876
Epoch: 36, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9241576194763184
Epoch: 37, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8375 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9133477210998535
Epoch: 38, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8370 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9073936939239502
Epoch: 39, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8378 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8677828311920166
Epoch: 40, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8356 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9053051471710205
Epoch: 41, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0970 + XiCon Loss:1.8376 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.9323155879974365
Epoch: 42, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8380 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8622581958770752
Epoch: 43, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0971 + XiCon Loss:1.8408 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8672192096710205
Epoch: 44, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8394 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8615591526031494
Epoch: 45, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.9250783920288086
Epoch: 46, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0970 + XiCon Loss:1.8340 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
Validation loss decreased (0.198822 --> 0.198822).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8670964241027832
Epoch: 47, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.9175679683685303
Epoch: 48, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8404 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.9321691989898682
Epoch: 49, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8337 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9304611682891846
Epoch: 50, Steps: 69 Train Loss: 0.0990 (Forecasting Loss:0.0971 + XiCon Loss:1.8370 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9465537071228027
Epoch: 51, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8427 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9121763706207275
Epoch: 52, Steps: 69 Train Loss: 0.0989 (Forecasting Loss:0.0970 + XiCon Loss:1.8373 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8575809001922607
Epoch: 53, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8328 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8586280345916748
Epoch: 54, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8369 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9268801212310791
Epoch: 55, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0970 + XiCon Loss:1.8377 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.867316484451294
Epoch: 56, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8369 x Lambda(0.001)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1149
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05357043817639351, mae:0.17613527178764343, mape:0.12257760763168335, mspe:0.03542410209774971 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6145
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8974888324737549
Epoch: 1, Steps: 69 Train Loss: 0.1320 (Forecasting Loss:0.1301 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.1448
Validation loss decreased (inf --> 0.278513).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9317657947540283
Epoch: 2, Steps: 69 Train Loss: 0.1112 (Forecasting Loss:0.1094 + XiCon Loss:1.8330 x Lambda(0.001)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1232
Validation loss decreased (0.278513 --> 0.211386).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9369015693664551
Epoch: 3, Steps: 69 Train Loss: 0.1030 (Forecasting Loss:0.1012 + XiCon Loss:1.8338 x Lambda(0.001)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1184
Validation loss decreased (0.211386 --> 0.207798).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9151284694671631
Epoch: 4, Steps: 69 Train Loss: 0.1016 (Forecasting Loss:0.0998 + XiCon Loss:1.8334 x Lambda(0.001)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1178
Validation loss decreased (0.207798 --> 0.204483).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.88214111328125
Epoch: 5, Steps: 69 Train Loss: 0.1009 (Forecasting Loss:0.0991 + XiCon Loss:1.8393 x Lambda(0.001)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1176
Validation loss decreased (0.204483 --> 0.202956).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9081835746765137
Epoch: 6, Steps: 69 Train Loss: 0.1004 (Forecasting Loss:0.0985 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1171
Validation loss decreased (0.202956 --> 0.202817).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8896851539611816
Epoch: 7, Steps: 69 Train Loss: 0.1004 (Forecasting Loss:0.0986 + XiCon Loss:1.8384 x Lambda(0.001)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1171
Validation loss decreased (0.202817 --> 0.202515).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8639481067657471
Epoch: 8, Steps: 69 Train Loss: 0.0999 (Forecasting Loss:0.0981 + XiCon Loss:1.8373 x Lambda(0.001)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1170
Validation loss decreased (0.202515 --> 0.202407).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9475052356719971
Epoch: 9, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8358 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1170
Validation loss decreased (0.202407 --> 0.202336).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8836619853973389
Epoch: 10, Steps: 69 Train Loss: 0.1000 (Forecasting Loss:0.0981 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1170
Validation loss decreased (0.202336 --> 0.202313).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8929562568664551
Epoch: 11, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0980 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202313 --> 0.202300).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8652374744415283
Epoch: 12, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8321 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202300 --> 0.202292).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8597753047943115
Epoch: 13, Steps: 69 Train Loss: 0.0999 (Forecasting Loss:0.0981 + XiCon Loss:1.8388 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202292 --> 0.202287).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8606960773468018
Epoch: 14, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0980 + XiCon Loss:1.8353 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202287 --> 0.202286).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 1.022787094116211
Epoch: 15, Steps: 69 Train Loss: 0.0996 (Forecasting Loss:0.0977 + XiCon Loss:1.8377 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202286 --> 0.202285).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9234671592712402
Epoch: 16, Steps: 69 Train Loss: 0.0999 (Forecasting Loss:0.0981 + XiCon Loss:1.8328 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202285 --> 0.202284).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9036705493927002
Epoch: 17, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0979 + XiCon Loss:1.8369 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9015731811523438
Epoch: 18, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8332 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8912220001220703
Epoch: 19, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0983 + XiCon Loss:1.8404 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8388457298278809
Epoch: 20, Steps: 69 Train Loss: 0.1000 (Forecasting Loss:0.0981 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8362109661102295
Epoch: 21, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0979 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8507764339447021
Epoch: 22, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8378 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
Validation loss decreased (0.202284 --> 0.202284).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8321382999420166
Epoch: 23, Steps: 69 Train Loss: 0.1002 (Forecasting Loss:0.0984 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8918147087097168
Epoch: 24, Steps: 69 Train Loss: 0.1000 (Forecasting Loss:0.0982 + XiCon Loss:1.8358 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8426403999328613
Epoch: 25, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0979 + XiCon Loss:1.8332 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8766632080078125
Epoch: 26, Steps: 69 Train Loss: 0.0999 (Forecasting Loss:0.0980 + XiCon Loss:1.8340 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9001319408416748
Epoch: 27, Steps: 69 Train Loss: 0.1000 (Forecasting Loss:0.0982 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8782856464385986
Epoch: 28, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8369 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9124572277069092
Epoch: 29, Steps: 69 Train Loss: 0.0999 (Forecasting Loss:0.0980 + XiCon Loss:1.8363 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.865117073059082
Epoch: 30, Steps: 69 Train Loss: 0.1001 (Forecasting Loss:0.0982 + XiCon Loss:1.8334 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9177641868591309
Epoch: 31, Steps: 69 Train Loss: 0.0998 (Forecasting Loss:0.0980 + XiCon Loss:1.8394 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8750858306884766
Epoch: 32, Steps: 69 Train Loss: 0.1002 (Forecasting Loss:0.0984 + XiCon Loss:1.8389 x Lambda(0.001)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1169
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055265605449676514, mae:0.17861957848072052, mape:0.1244732216000557, mspe:0.03644183278083801 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5928
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8313918113708496
Epoch: 1, Steps: 69 Train Loss: 0.1388 (Forecasting Loss:0.1370 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.1528
Validation loss decreased (inf --> 0.294989).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8326294422149658
Epoch: 2, Steps: 69 Train Loss: 0.1156 (Forecasting Loss:0.1138 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1213
Validation loss decreased (0.294989 --> 0.211592).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8813979625701904
Epoch: 3, Steps: 69 Train Loss: 0.1014 (Forecasting Loss:0.0995 + XiCon Loss:1.8370 x Lambda(0.001)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1161
Validation loss decreased (0.211592 --> 0.199656).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9490814208984375
Epoch: 4, Steps: 69 Train Loss: 0.0993 (Forecasting Loss:0.0975 + XiCon Loss:1.8357 x Lambda(0.001)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1156
Validation loss decreased (0.199656 --> 0.198870).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.879176139831543
Epoch: 5, Steps: 69 Train Loss: 0.0990 (Forecasting Loss:0.0972 + XiCon Loss:1.8372 x Lambda(0.001)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.1154
Validation loss decreased (0.198870 --> 0.197273).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8244516849517822
Epoch: 6, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8340 x Lambda(0.001)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8484892845153809
Epoch: 7, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8339 x Lambda(0.001)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8826243877410889
Epoch: 8, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0961 + XiCon Loss:1.8401 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1153
Validation loss decreased (0.197273 --> 0.197012).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8886001110076904
Epoch: 9, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8378 x Lambda(0.001)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8267571926116943
Epoch: 10, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8398 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8379018306732178
Epoch: 11, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8413 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9068820476531982
Epoch: 12, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8373 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8446083068847656
Epoch: 13, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8747580051422119
Epoch: 14, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8328 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9268839359283447
Epoch: 15, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8276727199554443
Epoch: 16, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8362 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8983564376831055
Epoch: 17, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8352 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8312010765075684
Epoch: 18, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8361 x Lambda(0.001)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1152
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.054034072905778885, mae:0.176553413271904, mape:0.12279433757066727, mspe:0.035741399973630905 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5994
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8820314407348633
Epoch: 1, Steps: 69 Train Loss: 0.1364 (Forecasting Loss:0.1346 + XiCon Loss:1.8375 x Lambda(0.001)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.1536
Validation loss decreased (inf --> 0.290210).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8466331958770752
Epoch: 2, Steps: 69 Train Loss: 0.1118 (Forecasting Loss:0.1100 + XiCon Loss:1.8352 x Lambda(0.001)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1183
Validation loss decreased (0.290210 --> 0.204467).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8463711738586426
Epoch: 3, Steps: 69 Train Loss: 0.1006 (Forecasting Loss:0.0988 + XiCon Loss:1.8388 x Lambda(0.001)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1160
Validation loss decreased (0.204467 --> 0.198555).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.843092679977417
Epoch: 4, Steps: 69 Train Loss: 0.0992 (Forecasting Loss:0.0974 + XiCon Loss:1.8320 x Lambda(0.001)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1144
Validation loss decreased (0.198555 --> 0.197480).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8324508666992188
Epoch: 5, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8356 x Lambda(0.001)), Vali MSE Loss: 0.1972 Test MSE Loss: 0.1141
Validation loss decreased (0.197480 --> 0.197215).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8352799415588379
Epoch: 6, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8381 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1142
Validation loss decreased (0.197215 --> 0.196815).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8431026935577393
Epoch: 7, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0963 + XiCon Loss:1.8358 x Lambda(0.001)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8950815200805664
Epoch: 8, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8338 x Lambda(0.001)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1142
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9201462268829346
Epoch: 9, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0963 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1142
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9036858081817627
Epoch: 10, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8378949165344238
Epoch: 11, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0962 + XiCon Loss:1.8390 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8373851776123047
Epoch: 12, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8373 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9242067337036133
Epoch: 13, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0962 + XiCon Loss:1.8356 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196815 --> 0.196813).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8297719955444336
Epoch: 14, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0961 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196813 --> 0.196812).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9235715866088867
Epoch: 15, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0961 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8766038417816162
Epoch: 16, Steps: 69 Train Loss: 0.0979 (Forecasting Loss:0.0961 + XiCon Loss:1.8335 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8629019260406494
Epoch: 17, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9531216621398926
Epoch: 18, Steps: 69 Train Loss: 0.0978 (Forecasting Loss:0.0960 + XiCon Loss:1.8379 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8191690444946289
Epoch: 19, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8368 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.7972018718719482
Epoch: 20, Steps: 69 Train Loss: 0.0979 (Forecasting Loss:0.0961 + XiCon Loss:1.8304 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8478820323944092
Epoch: 21, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0962 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.7938156127929688
Epoch: 22, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0962 + XiCon Loss:1.8355 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8222811222076416
Epoch: 23, Steps: 69 Train Loss: 0.0978 (Forecasting Loss:0.0960 + XiCon Loss:1.8361 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8436329364776611
Epoch: 24, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8356 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.7932801246643066
Epoch: 25, Steps: 69 Train Loss: 0.0976 (Forecasting Loss:0.0957 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.7947940826416016
Epoch: 26, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0962 + XiCon Loss:1.8346 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8137726783752441
Epoch: 27, Steps: 69 Train Loss: 0.0978 (Forecasting Loss:0.0959 + XiCon Loss:1.8368 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8516356945037842
Epoch: 28, Steps: 69 Train Loss: 0.0976 (Forecasting Loss:0.0958 + XiCon Loss:1.8338 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8036139011383057
Epoch: 29, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8357 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8062412738800049
Epoch: 30, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8357 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
Validation loss decreased (0.196812 --> 0.196812).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8110458850860596
Epoch: 31, Steps: 69 Train Loss: 0.0979 (Forecasting Loss:0.0961 + XiCon Loss:1.8383 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.7874176502227783
Epoch: 32, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0961 + XiCon Loss:1.8378 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8162322044372559
Epoch: 33, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0961 + XiCon Loss:1.8354 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8215537071228027
Epoch: 34, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0963 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8074746131896973
Epoch: 35, Steps: 69 Train Loss: 0.0978 (Forecasting Loss:0.0960 + XiCon Loss:1.8376 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.804926872253418
Epoch: 36, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0964 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8057975769042969
Epoch: 37, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0963 + XiCon Loss:1.8433 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.7957494258880615
Epoch: 38, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0962 + XiCon Loss:1.8402 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8593883514404297
Epoch: 39, Steps: 69 Train Loss: 0.0978 (Forecasting Loss:0.0960 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8027160167694092
Epoch: 40, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8366 x Lambda(0.001)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1141
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05321507155895233, mae:0.1750752180814743, mape:0.12140759825706482, mspe:0.03475760668516159 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5652
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8476467132568359
Epoch: 1, Steps: 69 Train Loss: 0.1325 (Forecasting Loss:0.1306 + XiCon Loss:1.8340 x Lambda(0.001)), Vali MSE Loss: 0.2798 Test MSE Loss: 0.1461
Validation loss decreased (inf --> 0.279821).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7919273376464844
Epoch: 2, Steps: 69 Train Loss: 0.1102 (Forecasting Loss:0.1084 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1202
Validation loss decreased (0.279821 --> 0.206556).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8818750381469727
Epoch: 3, Steps: 69 Train Loss: 0.1013 (Forecasting Loss:0.0995 + XiCon Loss:1.8318 x Lambda(0.001)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1158
Validation loss decreased (0.206556 --> 0.200710).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8125078678131104
Epoch: 4, Steps: 69 Train Loss: 0.0993 (Forecasting Loss:0.0975 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1161
Validation loss decreased (0.200710 --> 0.198975).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8110225200653076
Epoch: 5, Steps: 69 Train Loss: 0.0990 (Forecasting Loss:0.0971 + XiCon Loss:1.8372 x Lambda(0.001)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7993433475494385
Epoch: 6, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8342 x Lambda(0.001)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1147
Validation loss decreased (0.198975 --> 0.198582).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.7999818325042725
Epoch: 7, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8396 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1145
Validation loss decreased (0.198582 --> 0.198337).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8040533065795898
Epoch: 8, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.813300371170044
Epoch: 9, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0968 + XiCon Loss:1.8365 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198337 --> 0.198283).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8673326969146729
Epoch: 10, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8348 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198283 --> 0.198279).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8130266666412354
Epoch: 11, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8331 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198279 --> 0.198263).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8603205680847168
Epoch: 12, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198263 --> 0.198262).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8383288383483887
Epoch: 13, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198262 --> 0.198261).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8608827590942383
Epoch: 14, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8380 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.848900556564331
Epoch: 15, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8350 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198261 --> 0.198260).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8916435241699219
Epoch: 16, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8372 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.820019006729126
Epoch: 17, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8321 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8448481559753418
Epoch: 18, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8348 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8532648086547852
Epoch: 19, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8335566520690918
Epoch: 20, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8239336013793945
Epoch: 21, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0965 + XiCon Loss:1.8323 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8879749774932861
Epoch: 22, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8362 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8452117443084717
Epoch: 23, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8383 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.859346866607666
Epoch: 24, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0964 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8237259387969971
Epoch: 25, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8352 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9088089466094971
Epoch: 26, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0966 + XiCon Loss:1.8336 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8296389579772949
Epoch: 27, Steps: 69 Train Loss: 0.0980 (Forecasting Loss:0.0962 + XiCon Loss:1.8355 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8305387496948242
Epoch: 28, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8395 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8458154201507568
Epoch: 29, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8335 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8431077003479004
Epoch: 30, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8367 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8372013568878174
Epoch: 31, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0968 + XiCon Loss:1.8342 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8354952335357666
Epoch: 32, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8351 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9075090885162354
Epoch: 33, Steps: 69 Train Loss: 0.0979 (Forecasting Loss:0.0961 + XiCon Loss:1.8360 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8844723701477051
Epoch: 34, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8331 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8223800659179688
Epoch: 35, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8322 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8812127113342285
Epoch: 36, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8332 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8538126945495605
Epoch: 37, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8333 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9104554653167725
Epoch: 38, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8362 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8201956748962402
Epoch: 39, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0962 + XiCon Loss:1.8404 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8533196449279785
Epoch: 40, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8393 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8854837417602539
Epoch: 41, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0966 + XiCon Loss:1.8364 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8506324291229248
Epoch: 42, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8360 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.822181224822998
Epoch: 43, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0964 + XiCon Loss:1.8364 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8802869319915771
Epoch: 44, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8331 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8702123165130615
Epoch: 45, Steps: 69 Train Loss: 0.0981 (Forecasting Loss:0.0963 + XiCon Loss:1.8354 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8254547119140625
Epoch: 46, Steps: 69 Train Loss: 0.0987 (Forecasting Loss:0.0969 + XiCon Loss:1.8359 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
Validation loss decreased (0.198260 --> 0.198260).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8286890983581543
Epoch: 47, Steps: 69 Train Loss: 0.0983 (Forecasting Loss:0.0964 + XiCon Loss:1.8341 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8160598278045654
Epoch: 48, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8344 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8724637031555176
Epoch: 49, Steps: 69 Train Loss: 0.0988 (Forecasting Loss:0.0969 + XiCon Loss:1.8375 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8811478614807129
Epoch: 50, Steps: 69 Train Loss: 0.0984 (Forecasting Loss:0.0965 + XiCon Loss:1.8332 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.8841736316680908
Epoch: 51, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0963 + XiCon Loss:1.8348 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.8412461280822754
Epoch: 52, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8337 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8563008308410645
Epoch: 53, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8385 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8637094497680664
Epoch: 54, Steps: 69 Train Loss: 0.0982 (Forecasting Loss:0.0964 + XiCon Loss:1.8347 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.8336653709411621
Epoch: 55, Steps: 69 Train Loss: 0.0985 (Forecasting Loss:0.0967 + XiCon Loss:1.8364 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8519253730773926
Epoch: 56, Steps: 69 Train Loss: 0.0986 (Forecasting Loss:0.0967 + XiCon Loss:1.8322 x Lambda(0.001)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1144
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05340148136019707, mae:0.17542031407356262, mape:0.12182603031396866, mspe:0.03493661433458328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0539+-0.00102, MAE:0.1764+-0.00173, MAPE:0.1226+-0.00146, MSPE:0.0355+-0.00084, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6433
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2107493877410889
Epoch: 1, Steps: 64 Train Loss: 0.5035 (Forecasting Loss:0.5015 + XiCon Loss:1.9424 x Lambda(0.001)), Vali MSE Loss: 0.9638 Test MSE Loss: 0.5134
Validation loss decreased (inf --> 0.963817).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9002289772033691
Epoch: 2, Steps: 64 Train Loss: 0.4992 (Forecasting Loss:0.4972 + XiCon Loss:1.9412 x Lambda(0.001)), Vali MSE Loss: 0.9524 Test MSE Loss: 0.5064
Validation loss decreased (0.963817 --> 0.952417).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9052660465240479
Epoch: 3, Steps: 64 Train Loss: 0.4924 (Forecasting Loss:0.4905 + XiCon Loss:1.9409 x Lambda(0.001)), Vali MSE Loss: 0.9418 Test MSE Loss: 0.5035
Validation loss decreased (0.952417 --> 0.941831).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9371256828308105
Epoch: 4, Steps: 64 Train Loss: 0.4902 (Forecasting Loss:0.4883 + XiCon Loss:1.9384 x Lambda(0.001)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8899569511413574
Epoch: 5, Steps: 64 Train Loss: 0.4874 (Forecasting Loss:0.4855 + XiCon Loss:1.9395 x Lambda(0.001)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.5012
Validation loss decreased (0.941831 --> 0.937378).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9365358352661133
Epoch: 6, Steps: 64 Train Loss: 0.4865 (Forecasting Loss:0.4846 + XiCon Loss:1.9397 x Lambda(0.001)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.5008
Validation loss decreased (0.937378 --> 0.937307).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9345653057098389
Epoch: 7, Steps: 64 Train Loss: 0.4866 (Forecasting Loss:0.4846 + XiCon Loss:1.9399 x Lambda(0.001)), Vali MSE Loss: 0.9355 Test MSE Loss: 0.5006
Validation loss decreased (0.937307 --> 0.935452).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9449138641357422
Epoch: 8, Steps: 64 Train Loss: 0.4862 (Forecasting Loss:0.4843 + XiCon Loss:1.9412 x Lambda(0.001)), Vali MSE Loss: 0.9352 Test MSE Loss: 0.5005
Validation loss decreased (0.935452 --> 0.935163).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9007096290588379
Epoch: 9, Steps: 64 Train Loss: 0.4855 (Forecasting Loss:0.4835 + XiCon Loss:1.9398 x Lambda(0.001)), Vali MSE Loss: 0.9361 Test MSE Loss: 0.5005
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.920480489730835
Epoch: 10, Steps: 64 Train Loss: 0.4850 (Forecasting Loss:0.4831 + XiCon Loss:1.9393 x Lambda(0.001)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5005
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.880241870880127
Epoch: 11, Steps: 64 Train Loss: 0.4863 (Forecasting Loss:0.4843 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.9368 Test MSE Loss: 0.5005
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8988111019134521
Epoch: 12, Steps: 64 Train Loss: 0.4858 (Forecasting Loss:0.4839 + XiCon Loss:1.9422 x Lambda(0.001)), Vali MSE Loss: 0.9364 Test MSE Loss: 0.5004
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8964865207672119
Epoch: 13, Steps: 64 Train Loss: 0.4861 (Forecasting Loss:0.4842 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.9381 Test MSE Loss: 0.5004
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8795273303985596
Epoch: 14, Steps: 64 Train Loss: 0.4854 (Forecasting Loss:0.4834 + XiCon Loss:1.9398 x Lambda(0.001)), Vali MSE Loss: 0.9371 Test MSE Loss: 0.5004
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9014546871185303
Epoch: 15, Steps: 64 Train Loss: 0.4865 (Forecasting Loss:0.4846 + XiCon Loss:1.9382 x Lambda(0.001)), Vali MSE Loss: 0.9403 Test MSE Loss: 0.5004
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9229581356048584
Epoch: 16, Steps: 64 Train Loss: 0.4856 (Forecasting Loss:0.4836 + XiCon Loss:1.9379 x Lambda(0.001)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5004
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.891242504119873
Epoch: 17, Steps: 64 Train Loss: 0.4865 (Forecasting Loss:0.4845 + XiCon Loss:1.9400 x Lambda(0.001)), Vali MSE Loss: 0.9342 Test MSE Loss: 0.5004
Validation loss decreased (0.935163 --> 0.934168).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.8926408290863037
Epoch: 18, Steps: 64 Train Loss: 0.4863 (Forecasting Loss:0.4844 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.9359 Test MSE Loss: 0.5004
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8934211730957031
Epoch: 19, Steps: 64 Train Loss: 0.4863 (Forecasting Loss:0.4844 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5004
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8728187084197998
Epoch: 20, Steps: 64 Train Loss: 0.4859 (Forecasting Loss:0.4839 + XiCon Loss:1.9381 x Lambda(0.001)), Vali MSE Loss: 0.9376 Test MSE Loss: 0.5004
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8960714340209961
Epoch: 21, Steps: 64 Train Loss: 0.4853 (Forecasting Loss:0.4833 + XiCon Loss:1.9401 x Lambda(0.001)), Vali MSE Loss: 0.9350 Test MSE Loss: 0.5004
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.8746709823608398
Epoch: 22, Steps: 64 Train Loss: 0.4853 (Forecasting Loss:0.4834 + XiCon Loss:1.9417 x Lambda(0.001)), Vali MSE Loss: 0.9362 Test MSE Loss: 0.5004
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8787660598754883
Epoch: 23, Steps: 64 Train Loss: 0.4852 (Forecasting Loss:0.4832 + XiCon Loss:1.9396 x Lambda(0.001)), Vali MSE Loss: 0.9356 Test MSE Loss: 0.5004
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8865272998809814
Epoch: 24, Steps: 64 Train Loss: 0.4863 (Forecasting Loss:0.4844 + XiCon Loss:1.9379 x Lambda(0.001)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5004
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8783986568450928
Epoch: 25, Steps: 64 Train Loss: 0.4853 (Forecasting Loss:0.4833 + XiCon Loss:1.9399 x Lambda(0.001)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5004
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8667449951171875
Epoch: 26, Steps: 64 Train Loss: 0.4852 (Forecasting Loss:0.4832 + XiCon Loss:1.9411 x Lambda(0.001)), Vali MSE Loss: 0.9364 Test MSE Loss: 0.5004
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8993697166442871
Epoch: 27, Steps: 64 Train Loss: 0.4858 (Forecasting Loss:0.4838 + XiCon Loss:1.9390 x Lambda(0.001)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5004
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4686124324798584, mae:0.5322704315185547, mape:0.44839033484458923, mspe:0.5968640446662903 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5929
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9781649112701416
Epoch: 1, Steps: 64 Train Loss: 0.4947 (Forecasting Loss:0.4928 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.9329 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932935).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9036288261413574
Epoch: 2, Steps: 64 Train Loss: 0.4920 (Forecasting Loss:0.4901 + XiCon Loss:1.9377 x Lambda(0.001)), Vali MSE Loss: 0.9150 Test MSE Loss: 0.5154
Validation loss decreased (0.932935 --> 0.914973).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8834800720214844
Epoch: 3, Steps: 64 Train Loss: 0.4855 (Forecasting Loss:0.4836 + XiCon Loss:1.9381 x Lambda(0.001)), Vali MSE Loss: 0.9122 Test MSE Loss: 0.5128
Validation loss decreased (0.914973 --> 0.912200).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8748924732208252
Epoch: 4, Steps: 64 Train Loss: 0.4824 (Forecasting Loss:0.4805 + XiCon Loss:1.9404 x Lambda(0.001)), Vali MSE Loss: 0.9085 Test MSE Loss: 0.5116
Validation loss decreased (0.912200 --> 0.908523).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9184160232543945
Epoch: 5, Steps: 64 Train Loss: 0.4811 (Forecasting Loss:0.4791 + XiCon Loss:1.9400 x Lambda(0.001)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5110
Validation loss decreased (0.908523 --> 0.905576).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9097611904144287
Epoch: 6, Steps: 64 Train Loss: 0.4810 (Forecasting Loss:0.4791 + XiCon Loss:1.9374 x Lambda(0.001)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9044692516326904
Epoch: 7, Steps: 64 Train Loss: 0.4800 (Forecasting Loss:0.4780 + XiCon Loss:1.9376 x Lambda(0.001)), Vali MSE Loss: 0.9061 Test MSE Loss: 0.5106
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9190635681152344
Epoch: 8, Steps: 64 Train Loss: 0.4794 (Forecasting Loss:0.4775 + XiCon Loss:1.9383 x Lambda(0.001)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5105
Validation loss decreased (0.905576 --> 0.905454).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8861453533172607
Epoch: 9, Steps: 64 Train Loss: 0.4804 (Forecasting Loss:0.4784 + XiCon Loss:1.9392 x Lambda(0.001)), Vali MSE Loss: 0.9061 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9101409912109375
Epoch: 10, Steps: 64 Train Loss: 0.4798 (Forecasting Loss:0.4779 + XiCon Loss:1.9407 x Lambda(0.001)), Vali MSE Loss: 0.9057 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8942267894744873
Epoch: 11, Steps: 64 Train Loss: 0.4788 (Forecasting Loss:0.4769 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8830764293670654
Epoch: 12, Steps: 64 Train Loss: 0.4801 (Forecasting Loss:0.4782 + XiCon Loss:1.9372 x Lambda(0.001)), Vali MSE Loss: 0.9045 Test MSE Loss: 0.5105
Validation loss decreased (0.905454 --> 0.904476).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8972060680389404
Epoch: 13, Steps: 64 Train Loss: 0.4788 (Forecasting Loss:0.4769 + XiCon Loss:1.9382 x Lambda(0.001)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5105
Validation loss decreased (0.904476 --> 0.904239).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9399800300598145
Epoch: 14, Steps: 64 Train Loss: 0.4790 (Forecasting Loss:0.4771 + XiCon Loss:1.9393 x Lambda(0.001)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.877549409866333
Epoch: 15, Steps: 64 Train Loss: 0.4810 (Forecasting Loss:0.4791 + XiCon Loss:1.9373 x Lambda(0.001)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8939213752746582
Epoch: 16, Steps: 64 Train Loss: 0.4799 (Forecasting Loss:0.4780 + XiCon Loss:1.9380 x Lambda(0.001)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5105
Validation loss decreased (0.904239 --> 0.904234).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8731772899627686
Epoch: 17, Steps: 64 Train Loss: 0.4794 (Forecasting Loss:0.4775 + XiCon Loss:1.9390 x Lambda(0.001)), Vali MSE Loss: 0.9015 Test MSE Loss: 0.5105
Validation loss decreased (0.904234 --> 0.901510).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.905353307723999
Epoch: 18, Steps: 64 Train Loss: 0.4790 (Forecasting Loss:0.4771 + XiCon Loss:1.9397 x Lambda(0.001)), Vali MSE Loss: 0.9067 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8803737163543701
Epoch: 19, Steps: 64 Train Loss: 0.4799 (Forecasting Loss:0.4780 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.9022 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.884274959564209
Epoch: 20, Steps: 64 Train Loss: 0.4794 (Forecasting Loss:0.4775 + XiCon Loss:1.9375 x Lambda(0.001)), Vali MSE Loss: 0.9067 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.883873462677002
Epoch: 21, Steps: 64 Train Loss: 0.4790 (Forecasting Loss:0.4771 + XiCon Loss:1.9391 x Lambda(0.001)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5105
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9047038555145264
Epoch: 22, Steps: 64 Train Loss: 0.4794 (Forecasting Loss:0.4775 + XiCon Loss:1.9380 x Lambda(0.001)), Vali MSE Loss: 0.8992 Test MSE Loss: 0.5105
Validation loss decreased (0.901510 --> 0.899219).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8890671730041504
Epoch: 23, Steps: 64 Train Loss: 0.4791 (Forecasting Loss:0.4771 + XiCon Loss:1.9388 x Lambda(0.001)), Vali MSE Loss: 0.9033 Test MSE Loss: 0.5105
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8834004402160645
Epoch: 24, Steps: 64 Train Loss: 0.4796 (Forecasting Loss:0.4776 + XiCon Loss:1.9383 x Lambda(0.001)), Vali MSE Loss: 0.9044 Test MSE Loss: 0.5105
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9038095474243164
Epoch: 25, Steps: 64 Train Loss: 0.4787 (Forecasting Loss:0.4768 + XiCon Loss:1.9387 x Lambda(0.001)), Vali MSE Loss: 0.9008 Test MSE Loss: 0.5105
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.87359619140625
Epoch: 26, Steps: 64 Train Loss: 0.4808 (Forecasting Loss:0.4788 + XiCon Loss:1.9384 x Lambda(0.001)), Vali MSE Loss: 0.9031 Test MSE Loss: 0.5105
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9366412162780762
Epoch: 27, Steps: 64 Train Loss: 0.4800 (Forecasting Loss:0.4781 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.9046 Test MSE Loss: 0.5105
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.8832356929779053
Epoch: 28, Steps: 64 Train Loss: 0.4792 (Forecasting Loss:0.4772 + XiCon Loss:1.9381 x Lambda(0.001)), Vali MSE Loss: 0.9054 Test MSE Loss: 0.5105
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 0.9199247360229492
Epoch: 29, Steps: 64 Train Loss: 0.4796 (Forecasting Loss:0.4777 + XiCon Loss:1.9390 x Lambda(0.001)), Vali MSE Loss: 0.9049 Test MSE Loss: 0.5105
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.9313974380493164
Epoch: 30, Steps: 64 Train Loss: 0.4788 (Forecasting Loss:0.4769 + XiCon Loss:1.9384 x Lambda(0.001)), Vali MSE Loss: 0.9084 Test MSE Loss: 0.5105
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.9206171035766602
Epoch: 31, Steps: 64 Train Loss: 0.4803 (Forecasting Loss:0.4783 + XiCon Loss:1.9397 x Lambda(0.001)), Vali MSE Loss: 0.9023 Test MSE Loss: 0.5105
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 0.9192922115325928
Epoch: 32, Steps: 64 Train Loss: 0.4797 (Forecasting Loss:0.4777 + XiCon Loss:1.9376 x Lambda(0.001)), Vali MSE Loss: 0.9059 Test MSE Loss: 0.5105
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4844039976596832, mae:0.5365079641342163, mape:0.45671552419662476, mspe:0.6292720437049866 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5935
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9430291652679443
Epoch: 1, Steps: 64 Train Loss: 0.5032 (Forecasting Loss:0.5013 + XiCon Loss:1.9408 x Lambda(0.001)), Vali MSE Loss: 0.9738 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973841).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9439749717712402
Epoch: 2, Steps: 64 Train Loss: 0.5000 (Forecasting Loss:0.4980 + XiCon Loss:1.9442 x Lambda(0.001)), Vali MSE Loss: 0.9554 Test MSE Loss: 0.5003
Validation loss decreased (0.973841 --> 0.955394).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9128739833831787
Epoch: 3, Steps: 64 Train Loss: 0.4920 (Forecasting Loss:0.4901 + XiCon Loss:1.9408 x Lambda(0.001)), Vali MSE Loss: 0.9446 Test MSE Loss: 0.4990
Validation loss decreased (0.955394 --> 0.944629).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.901881217956543
Epoch: 4, Steps: 64 Train Loss: 0.4895 (Forecasting Loss:0.4875 + XiCon Loss:1.9424 x Lambda(0.001)), Vali MSE Loss: 0.9381 Test MSE Loss: 0.4989
Validation loss decreased (0.944629 --> 0.938139).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8866357803344727
Epoch: 5, Steps: 64 Train Loss: 0.4861 (Forecasting Loss:0.4841 + XiCon Loss:1.9413 x Lambda(0.001)), Vali MSE Loss: 0.9314 Test MSE Loss: 0.4990
Validation loss decreased (0.938139 --> 0.931419).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.891918420791626
Epoch: 6, Steps: 64 Train Loss: 0.4855 (Forecasting Loss:0.4835 + XiCon Loss:1.9407 x Lambda(0.001)), Vali MSE Loss: 0.9332 Test MSE Loss: 0.4991
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9484131336212158
Epoch: 7, Steps: 64 Train Loss: 0.4839 (Forecasting Loss:0.4819 + XiCon Loss:1.9419 x Lambda(0.001)), Vali MSE Loss: 0.9259 Test MSE Loss: 0.4992
Validation loss decreased (0.931419 --> 0.925929).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.968764066696167
Epoch: 8, Steps: 64 Train Loss: 0.4846 (Forecasting Loss:0.4826 + XiCon Loss:1.9405 x Lambda(0.001)), Vali MSE Loss: 0.9280 Test MSE Loss: 0.4992
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9058868885040283
Epoch: 9, Steps: 64 Train Loss: 0.4833 (Forecasting Loss:0.4814 + XiCon Loss:1.9425 x Lambda(0.001)), Vali MSE Loss: 0.9318 Test MSE Loss: 0.4992
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8924002647399902
Epoch: 10, Steps: 64 Train Loss: 0.4831 (Forecasting Loss:0.4812 + XiCon Loss:1.9398 x Lambda(0.001)), Vali MSE Loss: 0.9240 Test MSE Loss: 0.4992
Validation loss decreased (0.925929 --> 0.924027).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8949332237243652
Epoch: 11, Steps: 64 Train Loss: 0.4838 (Forecasting Loss:0.4818 + XiCon Loss:1.9417 x Lambda(0.001)), Vali MSE Loss: 0.9255 Test MSE Loss: 0.4992
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8957545757293701
Epoch: 12, Steps: 64 Train Loss: 0.4844 (Forecasting Loss:0.4824 + XiCon Loss:1.9445 x Lambda(0.001)), Vali MSE Loss: 0.9322 Test MSE Loss: 0.4992
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8897342681884766
Epoch: 13, Steps: 64 Train Loss: 0.4843 (Forecasting Loss:0.4824 + XiCon Loss:1.9397 x Lambda(0.001)), Vali MSE Loss: 0.9282 Test MSE Loss: 0.4992
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9185123443603516
Epoch: 14, Steps: 64 Train Loss: 0.4841 (Forecasting Loss:0.4822 + XiCon Loss:1.9434 x Lambda(0.001)), Vali MSE Loss: 0.9264 Test MSE Loss: 0.4992
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8962376117706299
Epoch: 15, Steps: 64 Train Loss: 0.4834 (Forecasting Loss:0.4815 + XiCon Loss:1.9433 x Lambda(0.001)), Vali MSE Loss: 0.9282 Test MSE Loss: 0.4992
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9443295001983643
Epoch: 16, Steps: 64 Train Loss: 0.4843 (Forecasting Loss:0.4823 + XiCon Loss:1.9421 x Lambda(0.001)), Vali MSE Loss: 0.9300 Test MSE Loss: 0.4992
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8727657794952393
Epoch: 17, Steps: 64 Train Loss: 0.4845 (Forecasting Loss:0.4826 + XiCon Loss:1.9412 x Lambda(0.001)), Vali MSE Loss: 0.9282 Test MSE Loss: 0.4992
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.956601619720459
Epoch: 18, Steps: 64 Train Loss: 0.4832 (Forecasting Loss:0.4812 + XiCon Loss:1.9392 x Lambda(0.001)), Vali MSE Loss: 0.9295 Test MSE Loss: 0.4992
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9055428504943848
Epoch: 19, Steps: 64 Train Loss: 0.4834 (Forecasting Loss:0.4814 + XiCon Loss:1.9413 x Lambda(0.001)), Vali MSE Loss: 0.9259 Test MSE Loss: 0.4992
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9112420082092285
Epoch: 20, Steps: 64 Train Loss: 0.4832 (Forecasting Loss:0.4812 + XiCon Loss:1.9448 x Lambda(0.001)), Vali MSE Loss: 0.9240 Test MSE Loss: 0.4992
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4676746428012848, mae:0.5306901931762695, mape:0.4473626911640167, mspe:0.5967349410057068 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7320
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.92523193359375
Epoch: 1, Steps: 64 Train Loss: 0.4970 (Forecasting Loss:0.4951 + XiCon Loss:1.9398 x Lambda(0.001)), Vali MSE Loss: 0.9333 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933332).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9411969184875488
Epoch: 2, Steps: 64 Train Loss: 0.4920 (Forecasting Loss:0.4901 + XiCon Loss:1.9378 x Lambda(0.001)), Vali MSE Loss: 0.9160 Test MSE Loss: 0.5149
Validation loss decreased (0.933332 --> 0.915963).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8874251842498779
Epoch: 3, Steps: 64 Train Loss: 0.4816 (Forecasting Loss:0.4797 + XiCon Loss:1.9406 x Lambda(0.001)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5103
Validation loss decreased (0.915963 --> 0.908250).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8892979621887207
Epoch: 4, Steps: 64 Train Loss: 0.4780 (Forecasting Loss:0.4760 + XiCon Loss:1.9397 x Lambda(0.001)), Vali MSE Loss: 0.9018 Test MSE Loss: 0.5079
Validation loss decreased (0.908250 --> 0.901786).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9053399562835693
Epoch: 5, Steps: 64 Train Loss: 0.4756 (Forecasting Loss:0.4737 + XiCon Loss:1.9422 x Lambda(0.001)), Vali MSE Loss: 0.8957 Test MSE Loss: 0.5068
Validation loss decreased (0.901786 --> 0.895690).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9001178741455078
Epoch: 6, Steps: 64 Train Loss: 0.4752 (Forecasting Loss:0.4732 + XiCon Loss:1.9387 x Lambda(0.001)), Vali MSE Loss: 0.8960 Test MSE Loss: 0.5063
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8939473628997803
Epoch: 7, Steps: 64 Train Loss: 0.4743 (Forecasting Loss:0.4724 + XiCon Loss:1.9412 x Lambda(0.001)), Vali MSE Loss: 0.8982 Test MSE Loss: 0.5060
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8938195705413818
Epoch: 8, Steps: 64 Train Loss: 0.4730 (Forecasting Loss:0.4711 + XiCon Loss:1.9395 x Lambda(0.001)), Vali MSE Loss: 0.8978 Test MSE Loss: 0.5059
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8830521106719971
Epoch: 9, Steps: 64 Train Loss: 0.4722 (Forecasting Loss:0.4702 + XiCon Loss:1.9390 x Lambda(0.001)), Vali MSE Loss: 0.8926 Test MSE Loss: 0.5059
Validation loss decreased (0.895690 --> 0.892645).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8834323883056641
Epoch: 10, Steps: 64 Train Loss: 0.4732 (Forecasting Loss:0.4713 + XiCon Loss:1.9380 x Lambda(0.001)), Vali MSE Loss: 0.8959 Test MSE Loss: 0.5058
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9238018989562988
Epoch: 11, Steps: 64 Train Loss: 0.4732 (Forecasting Loss:0.4712 + XiCon Loss:1.9401 x Lambda(0.001)), Vali MSE Loss: 0.8951 Test MSE Loss: 0.5058
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9009263515472412
Epoch: 12, Steps: 64 Train Loss: 0.4731 (Forecasting Loss:0.4711 + XiCon Loss:1.9392 x Lambda(0.001)), Vali MSE Loss: 0.8946 Test MSE Loss: 0.5058
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9385905265808105
Epoch: 13, Steps: 64 Train Loss: 0.4730 (Forecasting Loss:0.4710 + XiCon Loss:1.9429 x Lambda(0.001)), Vali MSE Loss: 0.8947 Test MSE Loss: 0.5058
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8866651058197021
Epoch: 14, Steps: 64 Train Loss: 0.4728 (Forecasting Loss:0.4709 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.8972 Test MSE Loss: 0.5058
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8926799297332764
Epoch: 15, Steps: 64 Train Loss: 0.4736 (Forecasting Loss:0.4717 + XiCon Loss:1.9386 x Lambda(0.001)), Vali MSE Loss: 0.8976 Test MSE Loss: 0.5058
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9163475036621094
Epoch: 16, Steps: 64 Train Loss: 0.4725 (Forecasting Loss:0.4705 + XiCon Loss:1.9396 x Lambda(0.001)), Vali MSE Loss: 0.8901 Test MSE Loss: 0.5058
Validation loss decreased (0.892645 --> 0.890092).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8789091110229492
Epoch: 17, Steps: 64 Train Loss: 0.4727 (Forecasting Loss:0.4707 + XiCon Loss:1.9409 x Lambda(0.001)), Vali MSE Loss: 0.8949 Test MSE Loss: 0.5058
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.8774056434631348
Epoch: 18, Steps: 64 Train Loss: 0.4740 (Forecasting Loss:0.4721 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.8949 Test MSE Loss: 0.5058
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8906259536743164
Epoch: 19, Steps: 64 Train Loss: 0.4737 (Forecasting Loss:0.4717 + XiCon Loss:1.9405 x Lambda(0.001)), Vali MSE Loss: 0.8970 Test MSE Loss: 0.5058
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8762810230255127
Epoch: 20, Steps: 64 Train Loss: 0.4724 (Forecasting Loss:0.4705 + XiCon Loss:1.9378 x Lambda(0.001)), Vali MSE Loss: 0.8954 Test MSE Loss: 0.5058
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9068057537078857
Epoch: 21, Steps: 64 Train Loss: 0.4735 (Forecasting Loss:0.4715 + XiCon Loss:1.9390 x Lambda(0.001)), Vali MSE Loss: 0.8947 Test MSE Loss: 0.5058
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9195766448974609
Epoch: 22, Steps: 64 Train Loss: 0.4731 (Forecasting Loss:0.4712 + XiCon Loss:1.9378 x Lambda(0.001)), Vali MSE Loss: 0.8950 Test MSE Loss: 0.5058
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8780064582824707
Epoch: 23, Steps: 64 Train Loss: 0.4727 (Forecasting Loss:0.4708 + XiCon Loss:1.9381 x Lambda(0.001)), Vali MSE Loss: 0.8932 Test MSE Loss: 0.5058
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8977062702178955
Epoch: 24, Steps: 64 Train Loss: 0.4728 (Forecasting Loss:0.4708 + XiCon Loss:1.9400 x Lambda(0.001)), Vali MSE Loss: 0.8969 Test MSE Loss: 0.5058
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8728876113891602
Epoch: 25, Steps: 64 Train Loss: 0.4727 (Forecasting Loss:0.4708 + XiCon Loss:1.9401 x Lambda(0.001)), Vali MSE Loss: 0.8936 Test MSE Loss: 0.5058
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8984689712524414
Epoch: 26, Steps: 64 Train Loss: 0.4725 (Forecasting Loss:0.4706 + XiCon Loss:1.9380 x Lambda(0.001)), Vali MSE Loss: 0.8970 Test MSE Loss: 0.5058
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.47911354899406433, mae:0.5325049757957458, mape:0.45254507660865784, mspe:0.6178557872772217 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5840
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9272277355194092
Epoch: 1, Steps: 64 Train Loss: 0.4968 (Forecasting Loss:0.4949 + XiCon Loss:1.9398 x Lambda(0.001)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908204).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9076743125915527
Epoch: 2, Steps: 64 Train Loss: 0.4932 (Forecasting Loss:0.4913 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.8918 Test MSE Loss: 0.5397
Validation loss decreased (0.908204 --> 0.891818).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9086644649505615
Epoch: 3, Steps: 64 Train Loss: 0.4880 (Forecasting Loss:0.4861 + XiCon Loss:1.9395 x Lambda(0.001)), Vali MSE Loss: 0.8917 Test MSE Loss: 0.5360
Validation loss decreased (0.891818 --> 0.891706).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9371292591094971
Epoch: 4, Steps: 64 Train Loss: 0.4837 (Forecasting Loss:0.4818 + XiCon Loss:1.9378 x Lambda(0.001)), Vali MSE Loss: 0.8838 Test MSE Loss: 0.5341
Validation loss decreased (0.891706 --> 0.883773).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9040169715881348
Epoch: 5, Steps: 64 Train Loss: 0.4826 (Forecasting Loss:0.4807 + XiCon Loss:1.9384 x Lambda(0.001)), Vali MSE Loss: 0.8819 Test MSE Loss: 0.5331
Validation loss decreased (0.883773 --> 0.881938).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8899538516998291
Epoch: 6, Steps: 64 Train Loss: 0.4807 (Forecasting Loss:0.4788 + XiCon Loss:1.9385 x Lambda(0.001)), Vali MSE Loss: 0.8842 Test MSE Loss: 0.5326
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8827967643737793
Epoch: 7, Steps: 64 Train Loss: 0.4808 (Forecasting Loss:0.4789 + XiCon Loss:1.9410 x Lambda(0.001)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5324
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8779306411743164
Epoch: 8, Steps: 64 Train Loss: 0.4832 (Forecasting Loss:0.4812 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.8876 Test MSE Loss: 0.5323
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8989975452423096
Epoch: 9, Steps: 64 Train Loss: 0.4794 (Forecasting Loss:0.4775 + XiCon Loss:1.9393 x Lambda(0.001)), Vali MSE Loss: 0.8835 Test MSE Loss: 0.5322
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.902435302734375
Epoch: 10, Steps: 64 Train Loss: 0.4811 (Forecasting Loss:0.4792 + XiCon Loss:1.9380 x Lambda(0.001)), Vali MSE Loss: 0.8832 Test MSE Loss: 0.5322
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8875815868377686
Epoch: 11, Steps: 64 Train Loss: 0.4816 (Forecasting Loss:0.4797 + XiCon Loss:1.9407 x Lambda(0.001)), Vali MSE Loss: 0.8821 Test MSE Loss: 0.5322
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8906528949737549
Epoch: 12, Steps: 64 Train Loss: 0.4800 (Forecasting Loss:0.4780 + XiCon Loss:1.9394 x Lambda(0.001)), Vali MSE Loss: 0.8831 Test MSE Loss: 0.5322
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9240963459014893
Epoch: 13, Steps: 64 Train Loss: 0.4816 (Forecasting Loss:0.4796 + XiCon Loss:1.9386 x Lambda(0.001)), Vali MSE Loss: 0.8844 Test MSE Loss: 0.5322
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9776701927185059
Epoch: 14, Steps: 64 Train Loss: 0.4808 (Forecasting Loss:0.4789 + XiCon Loss:1.9402 x Lambda(0.001)), Vali MSE Loss: 0.8827 Test MSE Loss: 0.5322
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8915650844573975
Epoch: 15, Steps: 64 Train Loss: 0.4816 (Forecasting Loss:0.4797 + XiCon Loss:1.9388 x Lambda(0.001)), Vali MSE Loss: 0.8829 Test MSE Loss: 0.5322
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5162195563316345, mae:0.5499944686889648, mape:0.47466084361076355, mspe:0.6863207221031189 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4832+-0.02454, MAE:0.5364+-0.00981, MAPE:0.4559+-0.01379, MSPE:0.6254+-0.04570, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5987
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.4760334491729736
Epoch: 1, Steps: 59 Train Loss: 0.9924 (Forecasting Loss:0.9906 + XiCon Loss:1.8097 x Lambda(0.001)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248617).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.182668685913086
Epoch: 2, Steps: 59 Train Loss: 0.9921 (Forecasting Loss:0.9903 + XiCon Loss:1.8081 x Lambda(0.001)), Vali MSE Loss: 1.2525 Test MSE Loss: 0.9824
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1646625995635986
Epoch: 3, Steps: 59 Train Loss: 0.9909 (Forecasting Loss:0.9891 + XiCon Loss:1.8111 x Lambda(0.001)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1571476459503174
Epoch: 4, Steps: 59 Train Loss: 0.9907 (Forecasting Loss:0.9889 + XiCon Loss:1.8072 x Lambda(0.001)), Vali MSE Loss: 1.2467 Test MSE Loss: 0.9822
Validation loss decreased (1.248617 --> 1.246689).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1735048294067383
Epoch: 5, Steps: 59 Train Loss: 0.9906 (Forecasting Loss:0.9888 + XiCon Loss:1.8115 x Lambda(0.001)), Vali MSE Loss: 1.2507 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1651453971862793
Epoch: 6, Steps: 59 Train Loss: 0.9915 (Forecasting Loss:0.9897 + XiCon Loss:1.8073 x Lambda(0.001)), Vali MSE Loss: 1.2458 Test MSE Loss: 0.9821
Validation loss decreased (1.246689 --> 1.245829).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1528003215789795
Epoch: 7, Steps: 59 Train Loss: 0.9903 (Forecasting Loss:0.9885 + XiCon Loss:1.8095 x Lambda(0.001)), Vali MSE Loss: 1.2448 Test MSE Loss: 0.9821
Validation loss decreased (1.245829 --> 1.244759).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.16243314743042
Epoch: 8, Steps: 59 Train Loss: 0.9897 (Forecasting Loss:0.9879 + XiCon Loss:1.8140 x Lambda(0.001)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.144115924835205
Epoch: 9, Steps: 59 Train Loss: 0.9906 (Forecasting Loss:0.9888 + XiCon Loss:1.8094 x Lambda(0.001)), Vali MSE Loss: 1.2442 Test MSE Loss: 0.9821
Validation loss decreased (1.244759 --> 1.244218).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1589665412902832
Epoch: 10, Steps: 59 Train Loss: 0.9905 (Forecasting Loss:0.9887 + XiCon Loss:1.8102 x Lambda(0.001)), Vali MSE Loss: 1.2552 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1686615943908691
Epoch: 11, Steps: 59 Train Loss: 0.9894 (Forecasting Loss:0.9876 + XiCon Loss:1.8086 x Lambda(0.001)), Vali MSE Loss: 1.2443 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1635234355926514
Epoch: 12, Steps: 59 Train Loss: 0.9904 (Forecasting Loss:0.9885 + XiCon Loss:1.8157 x Lambda(0.001)), Vali MSE Loss: 1.2520 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.147674798965454
Epoch: 13, Steps: 59 Train Loss: 0.9906 (Forecasting Loss:0.9888 + XiCon Loss:1.8082 x Lambda(0.001)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.144963264465332
Epoch: 14, Steps: 59 Train Loss: 0.9905 (Forecasting Loss:0.9887 + XiCon Loss:1.8071 x Lambda(0.001)), Vali MSE Loss: 1.2447 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1616225242614746
Epoch: 15, Steps: 59 Train Loss: 0.9905 (Forecasting Loss:0.9886 + XiCon Loss:1.8111 x Lambda(0.001)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.1621222496032715
Epoch: 16, Steps: 59 Train Loss: 0.9911 (Forecasting Loss:0.9893 + XiCon Loss:1.8101 x Lambda(0.001)), Vali MSE Loss: 1.2488 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1553056240081787
Epoch: 17, Steps: 59 Train Loss: 0.9905 (Forecasting Loss:0.9887 + XiCon Loss:1.8129 x Lambda(0.001)), Vali MSE Loss: 1.2551 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1489357948303223
Epoch: 18, Steps: 59 Train Loss: 0.9913 (Forecasting Loss:0.9895 + XiCon Loss:1.8088 x Lambda(0.001)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.158414602279663
Epoch: 19, Steps: 59 Train Loss: 0.9912 (Forecasting Loss:0.9893 + XiCon Loss:1.8160 x Lambda(0.001)), Vali MSE Loss: 1.2414 Test MSE Loss: 0.9821
Validation loss decreased (1.244218 --> 1.241413).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.160069465637207
Epoch: 20, Steps: 59 Train Loss: 0.9904 (Forecasting Loss:0.9886 + XiCon Loss:1.8133 x Lambda(0.001)), Vali MSE Loss: 1.2436 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1693663597106934
Epoch: 21, Steps: 59 Train Loss: 0.9915 (Forecasting Loss:0.9897 + XiCon Loss:1.8116 x Lambda(0.001)), Vali MSE Loss: 1.2511 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.141648769378662
Epoch: 22, Steps: 59 Train Loss: 0.9919 (Forecasting Loss:0.9901 + XiCon Loss:1.8059 x Lambda(0.001)), Vali MSE Loss: 1.2493 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.1442956924438477
Epoch: 23, Steps: 59 Train Loss: 0.9896 (Forecasting Loss:0.9878 + XiCon Loss:1.8137 x Lambda(0.001)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.1806375980377197
Epoch: 24, Steps: 59 Train Loss: 0.9910 (Forecasting Loss:0.9892 + XiCon Loss:1.8084 x Lambda(0.001)), Vali MSE Loss: 1.2545 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.1565437316894531
Epoch: 25, Steps: 59 Train Loss: 0.9906 (Forecasting Loss:0.9888 + XiCon Loss:1.8070 x Lambda(0.001)), Vali MSE Loss: 1.2519 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.1472854614257812
Epoch: 26, Steps: 59 Train Loss: 0.9907 (Forecasting Loss:0.9889 + XiCon Loss:1.8073 x Lambda(0.001)), Vali MSE Loss: 1.2572 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.1563360691070557
Epoch: 27, Steps: 59 Train Loss: 0.9903 (Forecasting Loss:0.9885 + XiCon Loss:1.8120 x Lambda(0.001)), Vali MSE Loss: 1.2484 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.191002368927002
Epoch: 28, Steps: 59 Train Loss: 0.9917 (Forecasting Loss:0.9899 + XiCon Loss:1.8055 x Lambda(0.001)), Vali MSE Loss: 1.2506 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.1659588813781738
Epoch: 29, Steps: 59 Train Loss: 0.9902 (Forecasting Loss:0.9884 + XiCon Loss:1.8100 x Lambda(0.001)), Vali MSE Loss: 1.2524 Test MSE Loss: 0.9821
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1454936265945435, mae:0.8186579942703247, mape:0.7821159362792969, mspe:1.8303500413894653 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5921
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1613385677337646
Epoch: 1, Steps: 59 Train Loss: 0.9910 (Forecasting Loss:0.9892 + XiCon Loss:1.8061 x Lambda(0.001)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236815).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1655313968658447
Epoch: 2, Steps: 59 Train Loss: 0.9904 (Forecasting Loss:0.9886 + XiCon Loss:1.8102 x Lambda(0.001)), Vali MSE Loss: 1.2342 Test MSE Loss: 0.9931
Validation loss decreased (1.236815 --> 1.234237).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1566319465637207
Epoch: 3, Steps: 59 Train Loss: 0.9891 (Forecasting Loss:0.9873 + XiCon Loss:1.8037 x Lambda(0.001)), Vali MSE Loss: 1.2389 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1680090427398682
Epoch: 4, Steps: 59 Train Loss: 0.9896 (Forecasting Loss:0.9878 + XiCon Loss:1.8153 x Lambda(0.001)), Vali MSE Loss: 1.2405 Test MSE Loss: 0.9930
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1658639907836914
Epoch: 5, Steps: 59 Train Loss: 0.9903 (Forecasting Loss:0.9885 + XiCon Loss:1.8057 x Lambda(0.001)), Vali MSE Loss: 1.2295 Test MSE Loss: 0.9930
Validation loss decreased (1.234237 --> 1.229465).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1735835075378418
Epoch: 6, Steps: 59 Train Loss: 0.9902 (Forecasting Loss:0.9884 + XiCon Loss:1.8095 x Lambda(0.001)), Vali MSE Loss: 1.2379 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1735076904296875
Epoch: 7, Steps: 59 Train Loss: 0.9876 (Forecasting Loss:0.9858 + XiCon Loss:1.8111 x Lambda(0.001)), Vali MSE Loss: 1.2338 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1564998626708984
Epoch: 8, Steps: 59 Train Loss: 0.9885 (Forecasting Loss:0.9867 + XiCon Loss:1.8129 x Lambda(0.001)), Vali MSE Loss: 1.2317 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1543972492218018
Epoch: 9, Steps: 59 Train Loss: 0.9885 (Forecasting Loss:0.9867 + XiCon Loss:1.8108 x Lambda(0.001)), Vali MSE Loss: 1.2310 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1638319492340088
Epoch: 10, Steps: 59 Train Loss: 0.9897 (Forecasting Loss:0.9879 + XiCon Loss:1.8048 x Lambda(0.001)), Vali MSE Loss: 1.2335 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1641664505004883
Epoch: 11, Steps: 59 Train Loss: 0.9891 (Forecasting Loss:0.9873 + XiCon Loss:1.8078 x Lambda(0.001)), Vali MSE Loss: 1.2397 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.147216796875
Epoch: 12, Steps: 59 Train Loss: 0.9895 (Forecasting Loss:0.9877 + XiCon Loss:1.8090 x Lambda(0.001)), Vali MSE Loss: 1.2261 Test MSE Loss: 0.9929
Validation loss decreased (1.229465 --> 1.226055).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1645257472991943
Epoch: 13, Steps: 59 Train Loss: 0.9900 (Forecasting Loss:0.9882 + XiCon Loss:1.8135 x Lambda(0.001)), Vali MSE Loss: 1.2304 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1660099029541016
Epoch: 14, Steps: 59 Train Loss: 0.9895 (Forecasting Loss:0.9877 + XiCon Loss:1.8118 x Lambda(0.001)), Vali MSE Loss: 1.2350 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1774301528930664
Epoch: 15, Steps: 59 Train Loss: 0.9900 (Forecasting Loss:0.9882 + XiCon Loss:1.8105 x Lambda(0.001)), Vali MSE Loss: 1.2263 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.169222116470337
Epoch: 16, Steps: 59 Train Loss: 0.9886 (Forecasting Loss:0.9868 + XiCon Loss:1.8104 x Lambda(0.001)), Vali MSE Loss: 1.2417 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1753602027893066
Epoch: 17, Steps: 59 Train Loss: 0.9892 (Forecasting Loss:0.9874 + XiCon Loss:1.8113 x Lambda(0.001)), Vali MSE Loss: 1.2280 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.163433313369751
Epoch: 18, Steps: 59 Train Loss: 0.9898 (Forecasting Loss:0.9880 + XiCon Loss:1.8080 x Lambda(0.001)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.1730413436889648
Epoch: 19, Steps: 59 Train Loss: 0.9892 (Forecasting Loss:0.9874 + XiCon Loss:1.8107 x Lambda(0.001)), Vali MSE Loss: 1.2358 Test MSE Loss: 0.9929
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.159914255142212
Epoch: 20, Steps: 59 Train Loss: 0.9892 (Forecasting Loss:0.9874 + XiCon Loss:1.8064 x Lambda(0.001)), Vali MSE Loss: 1.2330 Test MSE Loss: 0.9929
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1831660270690918
Epoch: 21, Steps: 59 Train Loss: 0.9893 (Forecasting Loss:0.9875 + XiCon Loss:1.8045 x Lambda(0.001)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9929
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.1591088771820068
Epoch: 22, Steps: 59 Train Loss: 0.9903 (Forecasting Loss:0.9884 + XiCon Loss:1.8108 x Lambda(0.001)), Vali MSE Loss: 1.2298 Test MSE Loss: 0.9929
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1613755226135254, mae:0.8244885802268982, mape:0.7877014875411987, mspe:1.8509843349456787 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5939
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1734888553619385
Epoch: 1, Steps: 59 Train Loss: 0.9920 (Forecasting Loss:0.9902 + XiCon Loss:1.8027 x Lambda(0.001)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247568).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.180856704711914
Epoch: 2, Steps: 59 Train Loss: 0.9923 (Forecasting Loss:0.9905 + XiCon Loss:1.8124 x Lambda(0.001)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9843
Validation loss decreased (1.247568 --> 1.235249).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1558425426483154
Epoch: 3, Steps: 59 Train Loss: 0.9915 (Forecasting Loss:0.9897 + XiCon Loss:1.8024 x Lambda(0.001)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9841
Validation loss decreased (1.235249 --> 1.234311).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.191633701324463
Epoch: 4, Steps: 59 Train Loss: 0.9899 (Forecasting Loss:0.9881 + XiCon Loss:1.8087 x Lambda(0.001)), Vali MSE Loss: 1.2535 Test MSE Loss: 0.9840
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1628968715667725
Epoch: 5, Steps: 59 Train Loss: 0.9901 (Forecasting Loss:0.9883 + XiCon Loss:1.8064 x Lambda(0.001)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9840
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1666650772094727
Epoch: 6, Steps: 59 Train Loss: 0.9909 (Forecasting Loss:0.9890 + XiCon Loss:1.8131 x Lambda(0.001)), Vali MSE Loss: 1.2436 Test MSE Loss: 0.9839
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1724417209625244
Epoch: 7, Steps: 59 Train Loss: 0.9908 (Forecasting Loss:0.9890 + XiCon Loss:1.8049 x Lambda(0.001)), Vali MSE Loss: 1.2492 Test MSE Loss: 0.9839
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.15794038772583
Epoch: 8, Steps: 59 Train Loss: 0.9897 (Forecasting Loss:0.9879 + XiCon Loss:1.8066 x Lambda(0.001)), Vali MSE Loss: 1.2576 Test MSE Loss: 0.9839
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1593303680419922
Epoch: 9, Steps: 59 Train Loss: 0.9891 (Forecasting Loss:0.9873 + XiCon Loss:1.8113 x Lambda(0.001)), Vali MSE Loss: 1.2500 Test MSE Loss: 0.9839
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1659953594207764
Epoch: 10, Steps: 59 Train Loss: 0.9907 (Forecasting Loss:0.9889 + XiCon Loss:1.8092 x Lambda(0.001)), Vali MSE Loss: 1.2532 Test MSE Loss: 0.9839
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.176706075668335
Epoch: 11, Steps: 59 Train Loss: 0.9893 (Forecasting Loss:0.9875 + XiCon Loss:1.8117 x Lambda(0.001)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9839
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1528875827789307
Epoch: 12, Steps: 59 Train Loss: 0.9899 (Forecasting Loss:0.9881 + XiCon Loss:1.8018 x Lambda(0.001)), Vali MSE Loss: 1.2405 Test MSE Loss: 0.9839
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1543588638305664
Epoch: 13, Steps: 59 Train Loss: 0.9903 (Forecasting Loss:0.9885 + XiCon Loss:1.8057 x Lambda(0.001)), Vali MSE Loss: 1.2567 Test MSE Loss: 0.9839
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1478468179702759, mae:0.8203521370887756, mape:0.7830012440681458, mspe:1.8311947584152222 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5813
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1625232696533203
Epoch: 1, Steps: 59 Train Loss: 0.9908 (Forecasting Loss:0.9890 + XiCon Loss:1.8102 x Lambda(0.001)), Vali MSE Loss: 1.2400 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240047).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1760010719299316
Epoch: 2, Steps: 59 Train Loss: 0.9916 (Forecasting Loss:0.9898 + XiCon Loss:1.8087 x Lambda(0.001)), Vali MSE Loss: 1.2224 Test MSE Loss: 0.9958
Validation loss decreased (1.240047 --> 1.222435).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1932802200317383
Epoch: 3, Steps: 59 Train Loss: 0.9896 (Forecasting Loss:0.9878 + XiCon Loss:1.8077 x Lambda(0.001)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9958
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1685514450073242
Epoch: 4, Steps: 59 Train Loss: 0.9906 (Forecasting Loss:0.9888 + XiCon Loss:1.8078 x Lambda(0.001)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1666741371154785
Epoch: 5, Steps: 59 Train Loss: 0.9901 (Forecasting Loss:0.9883 + XiCon Loss:1.8094 x Lambda(0.001)), Vali MSE Loss: 1.2231 Test MSE Loss: 0.9957
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.156052827835083
Epoch: 6, Steps: 59 Train Loss: 0.9907 (Forecasting Loss:0.9889 + XiCon Loss:1.8109 x Lambda(0.001)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9957
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1692657470703125
Epoch: 7, Steps: 59 Train Loss: 0.9899 (Forecasting Loss:0.9880 + XiCon Loss:1.8116 x Lambda(0.001)), Vali MSE Loss: 1.2250 Test MSE Loss: 0.9957
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.163139820098877
Epoch: 8, Steps: 59 Train Loss: 0.9891 (Forecasting Loss:0.9873 + XiCon Loss:1.8146 x Lambda(0.001)), Vali MSE Loss: 1.2237 Test MSE Loss: 0.9957
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1796174049377441
Epoch: 9, Steps: 59 Train Loss: 0.9891 (Forecasting Loss:0.9873 + XiCon Loss:1.8103 x Lambda(0.001)), Vali MSE Loss: 1.2345 Test MSE Loss: 0.9957
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1610705852508545
Epoch: 10, Steps: 59 Train Loss: 0.9900 (Forecasting Loss:0.9882 + XiCon Loss:1.8046 x Lambda(0.001)), Vali MSE Loss: 1.2326 Test MSE Loss: 0.9957
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1679177284240723
Epoch: 11, Steps: 59 Train Loss: 0.9882 (Forecasting Loss:0.9864 + XiCon Loss:1.8115 x Lambda(0.001)), Vali MSE Loss: 1.2317 Test MSE Loss: 0.9957
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1731758117675781
Epoch: 12, Steps: 59 Train Loss: 0.9899 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(0.001)), Vali MSE Loss: 1.2321 Test MSE Loss: 0.9957
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1654984951019287, mae:0.8261470198631287, mape:0.7891296148300171, mspe:1.8551310300827026 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7352
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1688191890716553
Epoch: 1, Steps: 59 Train Loss: 0.9960 (Forecasting Loss:0.9941 + XiCon Loss:1.8055 x Lambda(0.001)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275606).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1554408073425293
Epoch: 2, Steps: 59 Train Loss: 0.9946 (Forecasting Loss:0.9928 + XiCon Loss:1.8095 x Lambda(0.001)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9659
Validation loss decreased (1.275606 --> 1.274299).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1691772937774658
Epoch: 3, Steps: 59 Train Loss: 0.9952 (Forecasting Loss:0.9933 + XiCon Loss:1.8090 x Lambda(0.001)), Vali MSE Loss: 1.2846 Test MSE Loss: 0.9659
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.150233268737793
Epoch: 4, Steps: 59 Train Loss: 0.9940 (Forecasting Loss:0.9922 + XiCon Loss:1.8027 x Lambda(0.001)), Vali MSE Loss: 1.2800 Test MSE Loss: 0.9659
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1659908294677734
Epoch: 5, Steps: 59 Train Loss: 0.9945 (Forecasting Loss:0.9927 + XiCon Loss:1.8088 x Lambda(0.001)), Vali MSE Loss: 1.2739 Test MSE Loss: 0.9659
Validation loss decreased (1.274299 --> 1.273889).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1588118076324463
Epoch: 6, Steps: 59 Train Loss: 0.9952 (Forecasting Loss:0.9934 + XiCon Loss:1.8075 x Lambda(0.001)), Vali MSE Loss: 1.2841 Test MSE Loss: 0.9659
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1560659408569336
Epoch: 7, Steps: 59 Train Loss: 0.9942 (Forecasting Loss:0.9924 + XiCon Loss:1.8067 x Lambda(0.001)), Vali MSE Loss: 1.2771 Test MSE Loss: 0.9659
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1773664951324463
Epoch: 8, Steps: 59 Train Loss: 0.9938 (Forecasting Loss:0.9920 + XiCon Loss:1.8052 x Lambda(0.001)), Vali MSE Loss: 1.2821 Test MSE Loss: 0.9659
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1730632781982422
Epoch: 9, Steps: 59 Train Loss: 0.9948 (Forecasting Loss:0.9930 + XiCon Loss:1.8082 x Lambda(0.001)), Vali MSE Loss: 1.2882 Test MSE Loss: 0.9659
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.165846824645996
Epoch: 10, Steps: 59 Train Loss: 0.9941 (Forecasting Loss:0.9923 + XiCon Loss:1.8041 x Lambda(0.001)), Vali MSE Loss: 1.2788 Test MSE Loss: 0.9659
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1587154865264893
Epoch: 11, Steps: 59 Train Loss: 0.9945 (Forecasting Loss:0.9927 + XiCon Loss:1.8093 x Lambda(0.001)), Vali MSE Loss: 1.2744 Test MSE Loss: 0.9659
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1649959087371826
Epoch: 12, Steps: 59 Train Loss: 0.9951 (Forecasting Loss:0.9933 + XiCon Loss:1.7985 x Lambda(0.001)), Vali MSE Loss: 1.2763 Test MSE Loss: 0.9659
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.185816764831543
Epoch: 13, Steps: 59 Train Loss: 0.9939 (Forecasting Loss:0.9921 + XiCon Loss:1.8065 x Lambda(0.001)), Vali MSE Loss: 1.2816 Test MSE Loss: 0.9659
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1650075912475586
Epoch: 14, Steps: 59 Train Loss: 0.9934 (Forecasting Loss:0.9916 + XiCon Loss:1.8149 x Lambda(0.001)), Vali MSE Loss: 1.2814 Test MSE Loss: 0.9659
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1606478691101074
Epoch: 15, Steps: 59 Train Loss: 0.9945 (Forecasting Loss:0.9927 + XiCon Loss:1.8030 x Lambda(0.001)), Vali MSE Loss: 1.2797 Test MSE Loss: 0.9659
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.120850682258606, mae:0.8109234571456909, mape:0.7732128500938416, mspe:1.7929353713989258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02176, MAE:0.8201+-0.00740, MAPE:0.7830+-0.00776, MSPE:1.8321+-0.03057, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.8195405006408691
Epoch: 1, Steps: 53 Train Loss: 1.4880 (Forecasting Loss:1.4862 + XiCon Loss:1.8276 x Lambda(0.001)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858689).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5171175003051758
Epoch: 2, Steps: 53 Train Loss: 1.4816 (Forecasting Loss:1.4798 + XiCon Loss:1.8233 x Lambda(0.001)), Vali MSE Loss: 1.8409 Test MSE Loss: 0.9186
Validation loss decreased (1.858689 --> 1.840852).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5085899829864502
Epoch: 3, Steps: 53 Train Loss: 1.4753 (Forecasting Loss:1.4734 + XiCon Loss:1.8249 x Lambda(0.001)), Vali MSE Loss: 1.8443 Test MSE Loss: 0.9233
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5126278400421143
Epoch: 4, Steps: 53 Train Loss: 1.4731 (Forecasting Loss:1.4713 + XiCon Loss:1.8267 x Lambda(0.001)), Vali MSE Loss: 1.8417 Test MSE Loss: 0.9256
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5099992752075195
Epoch: 5, Steps: 53 Train Loss: 1.4687 (Forecasting Loss:1.4669 + XiCon Loss:1.8293 x Lambda(0.001)), Vali MSE Loss: 1.8221 Test MSE Loss: 0.9267
Validation loss decreased (1.840852 --> 1.822069).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.508223056793213
Epoch: 6, Steps: 53 Train Loss: 1.4713 (Forecasting Loss:1.4695 + XiCon Loss:1.8259 x Lambda(0.001)), Vali MSE Loss: 1.8251 Test MSE Loss: 0.9272
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.509110927581787
Epoch: 7, Steps: 53 Train Loss: 1.4680 (Forecasting Loss:1.4661 + XiCon Loss:1.8249 x Lambda(0.001)), Vali MSE Loss: 1.7956 Test MSE Loss: 0.9275
Validation loss decreased (1.822069 --> 1.795643).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5189778804779053
Epoch: 8, Steps: 53 Train Loss: 1.4669 (Forecasting Loss:1.4650 + XiCon Loss:1.8201 x Lambda(0.001)), Vali MSE Loss: 1.8519 Test MSE Loss: 0.9277
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5043821334838867
Epoch: 9, Steps: 53 Train Loss: 1.4679 (Forecasting Loss:1.4660 + XiCon Loss:1.8200 x Lambda(0.001)), Vali MSE Loss: 1.8136 Test MSE Loss: 0.9278
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.497307538986206
Epoch: 10, Steps: 53 Train Loss: 1.4694 (Forecasting Loss:1.4676 + XiCon Loss:1.8251 x Lambda(0.001)), Vali MSE Loss: 1.8536 Test MSE Loss: 0.9278
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5137629508972168
Epoch: 11, Steps: 53 Train Loss: 1.4661 (Forecasting Loss:1.4643 + XiCon Loss:1.8250 x Lambda(0.001)), Vali MSE Loss: 1.8356 Test MSE Loss: 0.9278
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5088310241699219
Epoch: 12, Steps: 53 Train Loss: 1.4672 (Forecasting Loss:1.4653 + XiCon Loss:1.8214 x Lambda(0.001)), Vali MSE Loss: 1.8119 Test MSE Loss: 0.9278
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5302057266235352
Epoch: 13, Steps: 53 Train Loss: 1.4679 (Forecasting Loss:1.4661 + XiCon Loss:1.8303 x Lambda(0.001)), Vali MSE Loss: 1.8489 Test MSE Loss: 0.9278
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.516908884048462
Epoch: 14, Steps: 53 Train Loss: 1.4691 (Forecasting Loss:1.4672 + XiCon Loss:1.8244 x Lambda(0.001)), Vali MSE Loss: 1.8033 Test MSE Loss: 0.9278
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.507758378982544
Epoch: 15, Steps: 53 Train Loss: 1.4659 (Forecasting Loss:1.4641 + XiCon Loss:1.8236 x Lambda(0.001)), Vali MSE Loss: 1.8455 Test MSE Loss: 0.9278
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.4902994632720947
Epoch: 16, Steps: 53 Train Loss: 1.4667 (Forecasting Loss:1.4648 + XiCon Loss:1.8194 x Lambda(0.001)), Vali MSE Loss: 1.8257 Test MSE Loss: 0.9278
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5108122825622559
Epoch: 17, Steps: 53 Train Loss: 1.4684 (Forecasting Loss:1.4666 + XiCon Loss:1.8214 x Lambda(0.001)), Vali MSE Loss: 1.8423 Test MSE Loss: 0.9278
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0591129064559937, mae:0.79597008228302, mape:0.7951540350914001, mspe:1.7977385520935059 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6077
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5411689281463623
Epoch: 1, Steps: 53 Train Loss: 1.4848 (Forecasting Loss:1.4830 + XiCon Loss:1.8255 x Lambda(0.001)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828220).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.511181354522705
Epoch: 2, Steps: 53 Train Loss: 1.4806 (Forecasting Loss:1.4788 + XiCon Loss:1.8250 x Lambda(0.001)), Vali MSE Loss: 1.8218 Test MSE Loss: 0.9332
Validation loss decreased (1.828220 --> 1.821849).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5375738143920898
Epoch: 3, Steps: 53 Train Loss: 1.4746 (Forecasting Loss:1.4727 + XiCon Loss:1.8271 x Lambda(0.001)), Vali MSE Loss: 1.7993 Test MSE Loss: 0.9348
Validation loss decreased (1.821849 --> 1.799345).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.514636754989624
Epoch: 4, Steps: 53 Train Loss: 1.4725 (Forecasting Loss:1.4707 + XiCon Loss:1.8356 x Lambda(0.001)), Vali MSE Loss: 1.8020 Test MSE Loss: 0.9355
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5294380187988281
Epoch: 5, Steps: 53 Train Loss: 1.4752 (Forecasting Loss:1.4733 + XiCon Loss:1.8284 x Lambda(0.001)), Vali MSE Loss: 1.8232 Test MSE Loss: 0.9360
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5191645622253418
Epoch: 6, Steps: 53 Train Loss: 1.4700 (Forecasting Loss:1.4682 + XiCon Loss:1.8275 x Lambda(0.001)), Vali MSE Loss: 1.8097 Test MSE Loss: 0.9362
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.521965503692627
Epoch: 7, Steps: 53 Train Loss: 1.4686 (Forecasting Loss:1.4668 + XiCon Loss:1.8284 x Lambda(0.001)), Vali MSE Loss: 1.7841 Test MSE Loss: 0.9363
Validation loss decreased (1.799345 --> 1.784090).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.4965283870697021
Epoch: 8, Steps: 53 Train Loss: 1.4698 (Forecasting Loss:1.4680 + XiCon Loss:1.8304 x Lambda(0.001)), Vali MSE Loss: 1.8265 Test MSE Loss: 0.9363
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5154736042022705
Epoch: 9, Steps: 53 Train Loss: 1.4659 (Forecasting Loss:1.4641 + XiCon Loss:1.8249 x Lambda(0.001)), Vali MSE Loss: 1.8240 Test MSE Loss: 0.9364
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.534247875213623
Epoch: 10, Steps: 53 Train Loss: 1.4713 (Forecasting Loss:1.4695 + XiCon Loss:1.8288 x Lambda(0.001)), Vali MSE Loss: 1.8337 Test MSE Loss: 0.9364
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5381379127502441
Epoch: 11, Steps: 53 Train Loss: 1.4702 (Forecasting Loss:1.4683 + XiCon Loss:1.8257 x Lambda(0.001)), Vali MSE Loss: 1.8421 Test MSE Loss: 0.9364
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.485485315322876
Epoch: 12, Steps: 53 Train Loss: 1.4697 (Forecasting Loss:1.4678 + XiCon Loss:1.8329 x Lambda(0.001)), Vali MSE Loss: 1.7676 Test MSE Loss: 0.9364
Validation loss decreased (1.784090 --> 1.767596).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5167253017425537
Epoch: 13, Steps: 53 Train Loss: 1.4706 (Forecasting Loss:1.4687 + XiCon Loss:1.8311 x Lambda(0.001)), Vali MSE Loss: 1.8108 Test MSE Loss: 0.9364
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5251283645629883
Epoch: 14, Steps: 53 Train Loss: 1.4711 (Forecasting Loss:1.4693 + XiCon Loss:1.8255 x Lambda(0.001)), Vali MSE Loss: 1.8059 Test MSE Loss: 0.9364
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.545088768005371
Epoch: 15, Steps: 53 Train Loss: 1.4676 (Forecasting Loss:1.4658 + XiCon Loss:1.8257 x Lambda(0.001)), Vali MSE Loss: 1.7998 Test MSE Loss: 0.9364
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5277447700500488
Epoch: 16, Steps: 53 Train Loss: 1.4713 (Forecasting Loss:1.4695 + XiCon Loss:1.8276 x Lambda(0.001)), Vali MSE Loss: 1.7926 Test MSE Loss: 0.9364
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5243539810180664
Epoch: 17, Steps: 53 Train Loss: 1.4687 (Forecasting Loss:1.4669 + XiCon Loss:1.8275 x Lambda(0.001)), Vali MSE Loss: 1.8317 Test MSE Loss: 0.9364
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.5154781341552734
Epoch: 18, Steps: 53 Train Loss: 1.4692 (Forecasting Loss:1.4674 + XiCon Loss:1.8291 x Lambda(0.001)), Vali MSE Loss: 1.8246 Test MSE Loss: 0.9364
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.5010507106781006
Epoch: 19, Steps: 53 Train Loss: 1.4724 (Forecasting Loss:1.4706 + XiCon Loss:1.8286 x Lambda(0.001)), Vali MSE Loss: 1.8143 Test MSE Loss: 0.9364
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.5226292610168457
Epoch: 20, Steps: 53 Train Loss: 1.4683 (Forecasting Loss:1.4664 + XiCon Loss:1.8263 x Lambda(0.001)), Vali MSE Loss: 1.8138 Test MSE Loss: 0.9364
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.525439977645874
Epoch: 21, Steps: 53 Train Loss: 1.4696 (Forecasting Loss:1.4678 + XiCon Loss:1.8258 x Lambda(0.001)), Vali MSE Loss: 1.8099 Test MSE Loss: 0.9364
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.5184316635131836
Epoch: 22, Steps: 53 Train Loss: 1.4712 (Forecasting Loss:1.4694 + XiCon Loss:1.8289 x Lambda(0.001)), Vali MSE Loss: 1.8243 Test MSE Loss: 0.9364
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0727849006652832, mae:0.7999657988548279, mape:0.8003687262535095, mspe:1.820378303527832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5773
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5210273265838623
Epoch: 1, Steps: 53 Train Loss: 1.4878 (Forecasting Loss:1.4859 + XiCon Loss:1.8300 x Lambda(0.001)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899211).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5214223861694336
Epoch: 2, Steps: 53 Train Loss: 1.4854 (Forecasting Loss:1.4836 + XiCon Loss:1.8293 x Lambda(0.001)), Vali MSE Loss: 1.8446 Test MSE Loss: 0.9162
Validation loss decreased (1.899211 --> 1.844552).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4982407093048096
Epoch: 3, Steps: 53 Train Loss: 1.4820 (Forecasting Loss:1.4802 + XiCon Loss:1.8242 x Lambda(0.001)), Vali MSE Loss: 1.8752 Test MSE Loss: 0.9189
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5229032039642334
Epoch: 4, Steps: 53 Train Loss: 1.4699 (Forecasting Loss:1.4681 + XiCon Loss:1.8304 x Lambda(0.001)), Vali MSE Loss: 1.8558 Test MSE Loss: 0.9204
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.511606216430664
Epoch: 5, Steps: 53 Train Loss: 1.4739 (Forecasting Loss:1.4721 + XiCon Loss:1.8279 x Lambda(0.001)), Vali MSE Loss: 1.8082 Test MSE Loss: 0.9212
Validation loss decreased (1.844552 --> 1.808180).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.537017583847046
Epoch: 6, Steps: 53 Train Loss: 1.4742 (Forecasting Loss:1.4724 + XiCon Loss:1.8271 x Lambda(0.001)), Vali MSE Loss: 1.8710 Test MSE Loss: 0.9216
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5292863845825195
Epoch: 7, Steps: 53 Train Loss: 1.4756 (Forecasting Loss:1.4738 + XiCon Loss:1.8312 x Lambda(0.001)), Vali MSE Loss: 1.8665 Test MSE Loss: 0.9218
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.519181728363037
Epoch: 8, Steps: 53 Train Loss: 1.4735 (Forecasting Loss:1.4717 + XiCon Loss:1.8243 x Lambda(0.001)), Vali MSE Loss: 1.8513 Test MSE Loss: 0.9219
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5388376712799072
Epoch: 9, Steps: 53 Train Loss: 1.4729 (Forecasting Loss:1.4711 + XiCon Loss:1.8237 x Lambda(0.001)), Vali MSE Loss: 1.8338 Test MSE Loss: 0.9220
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.555483341217041
Epoch: 10, Steps: 53 Train Loss: 1.4693 (Forecasting Loss:1.4674 + XiCon Loss:1.8313 x Lambda(0.001)), Vali MSE Loss: 1.8574 Test MSE Loss: 0.9220
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5310823917388916
Epoch: 11, Steps: 53 Train Loss: 1.4741 (Forecasting Loss:1.4723 + XiCon Loss:1.8301 x Lambda(0.001)), Vali MSE Loss: 1.8439 Test MSE Loss: 0.9220
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5365285873413086
Epoch: 12, Steps: 53 Train Loss: 1.4700 (Forecasting Loss:1.4682 + XiCon Loss:1.8251 x Lambda(0.001)), Vali MSE Loss: 1.8307 Test MSE Loss: 0.9220
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5265965461730957
Epoch: 13, Steps: 53 Train Loss: 1.4693 (Forecasting Loss:1.4674 + XiCon Loss:1.8294 x Lambda(0.001)), Vali MSE Loss: 1.8576 Test MSE Loss: 0.9220
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.529576301574707
Epoch: 14, Steps: 53 Train Loss: 1.4700 (Forecasting Loss:1.4682 + XiCon Loss:1.8303 x Lambda(0.001)), Vali MSE Loss: 1.8328 Test MSE Loss: 0.9220
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.517911434173584
Epoch: 15, Steps: 53 Train Loss: 1.4705 (Forecasting Loss:1.4686 + XiCon Loss:1.8253 x Lambda(0.001)), Vali MSE Loss: 1.8898 Test MSE Loss: 0.9220
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0497021675109863, mae:0.7926231026649475, mape:0.7914011478424072, mspe:1.7810750007629395 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6150
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5317926406860352
Epoch: 1, Steps: 53 Train Loss: 1.5017 (Forecasting Loss:1.4999 + XiCon Loss:1.8280 x Lambda(0.001)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995460).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5186655521392822
Epoch: 2, Steps: 53 Train Loss: 1.4988 (Forecasting Loss:1.4969 + XiCon Loss:1.8331 x Lambda(0.001)), Vali MSE Loss: 1.9487 Test MSE Loss: 0.8749
Validation loss decreased (1.995460 --> 1.948674).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.531477928161621
Epoch: 3, Steps: 53 Train Loss: 1.4908 (Forecasting Loss:1.4890 + XiCon Loss:1.8291 x Lambda(0.001)), Vali MSE Loss: 1.9562 Test MSE Loss: 0.8851
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.536198377609253
Epoch: 4, Steps: 53 Train Loss: 1.4813 (Forecasting Loss:1.4794 + XiCon Loss:1.8271 x Lambda(0.001)), Vali MSE Loss: 1.9360 Test MSE Loss: 0.8923
Validation loss decreased (1.948674 --> 1.936045).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5439743995666504
Epoch: 5, Steps: 53 Train Loss: 1.4745 (Forecasting Loss:1.4727 + XiCon Loss:1.8270 x Lambda(0.001)), Vali MSE Loss: 1.8973 Test MSE Loss: 0.8965
Validation loss decreased (1.936045 --> 1.897312).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5367944240570068
Epoch: 6, Steps: 53 Train Loss: 1.4751 (Forecasting Loss:1.4733 + XiCon Loss:1.8262 x Lambda(0.001)), Vali MSE Loss: 1.9388 Test MSE Loss: 0.8988
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.521629810333252
Epoch: 7, Steps: 53 Train Loss: 1.4773 (Forecasting Loss:1.4755 + XiCon Loss:1.8345 x Lambda(0.001)), Vali MSE Loss: 1.8884 Test MSE Loss: 0.9000
Validation loss decreased (1.897312 --> 1.888404).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5417671203613281
Epoch: 8, Steps: 53 Train Loss: 1.4733 (Forecasting Loss:1.4715 + XiCon Loss:1.8290 x Lambda(0.001)), Vali MSE Loss: 1.8982 Test MSE Loss: 0.9005
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5257554054260254
Epoch: 9, Steps: 53 Train Loss: 1.4735 (Forecasting Loss:1.4717 + XiCon Loss:1.8286 x Lambda(0.001)), Vali MSE Loss: 1.8996 Test MSE Loss: 0.9008
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5269579887390137
Epoch: 10, Steps: 53 Train Loss: 1.4746 (Forecasting Loss:1.4728 + XiCon Loss:1.8313 x Lambda(0.001)), Vali MSE Loss: 1.8770 Test MSE Loss: 0.9009
Validation loss decreased (1.888404 --> 1.876953).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5258049964904785
Epoch: 11, Steps: 53 Train Loss: 1.4742 (Forecasting Loss:1.4724 + XiCon Loss:1.8256 x Lambda(0.001)), Vali MSE Loss: 1.8909 Test MSE Loss: 0.9010
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5149452686309814
Epoch: 12, Steps: 53 Train Loss: 1.4736 (Forecasting Loss:1.4718 + XiCon Loss:1.8243 x Lambda(0.001)), Vali MSE Loss: 1.8589 Test MSE Loss: 0.9010
Validation loss decreased (1.876953 --> 1.858850).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5261151790618896
Epoch: 13, Steps: 53 Train Loss: 1.4745 (Forecasting Loss:1.4727 + XiCon Loss:1.8318 x Lambda(0.001)), Vali MSE Loss: 1.8892 Test MSE Loss: 0.9010
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.517099142074585
Epoch: 14, Steps: 53 Train Loss: 1.4764 (Forecasting Loss:1.4746 + XiCon Loss:1.8253 x Lambda(0.001)), Vali MSE Loss: 1.8934 Test MSE Loss: 0.9010
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5179414749145508
Epoch: 15, Steps: 53 Train Loss: 1.4763 (Forecasting Loss:1.4745 + XiCon Loss:1.8270 x Lambda(0.001)), Vali MSE Loss: 1.8926 Test MSE Loss: 0.9010
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5160565376281738
Epoch: 16, Steps: 53 Train Loss: 1.4731 (Forecasting Loss:1.4713 + XiCon Loss:1.8268 x Lambda(0.001)), Vali MSE Loss: 1.8834 Test MSE Loss: 0.9010
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.519491195678711
Epoch: 17, Steps: 53 Train Loss: 1.4719 (Forecasting Loss:1.4701 + XiCon Loss:1.8259 x Lambda(0.001)), Vali MSE Loss: 1.9030 Test MSE Loss: 0.9010
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.5146846771240234
Epoch: 18, Steps: 53 Train Loss: 1.4726 (Forecasting Loss:1.4708 + XiCon Loss:1.8349 x Lambda(0.001)), Vali MSE Loss: 1.9169 Test MSE Loss: 0.9010
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.531501293182373
Epoch: 19, Steps: 53 Train Loss: 1.4698 (Forecasting Loss:1.4679 + XiCon Loss:1.8333 x Lambda(0.001)), Vali MSE Loss: 1.8816 Test MSE Loss: 0.9010
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.5254409313201904
Epoch: 20, Steps: 53 Train Loss: 1.4760 (Forecasting Loss:1.4741 + XiCon Loss:1.8278 x Lambda(0.001)), Vali MSE Loss: 1.8984 Test MSE Loss: 0.9010
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.5150866508483887
Epoch: 21, Steps: 53 Train Loss: 1.4727 (Forecasting Loss:1.4709 + XiCon Loss:1.8320 x Lambda(0.001)), Vali MSE Loss: 1.8652 Test MSE Loss: 0.9010
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.5246076583862305
Epoch: 22, Steps: 53 Train Loss: 1.4749 (Forecasting Loss:1.4730 + XiCon Loss:1.8317 x Lambda(0.001)), Vali MSE Loss: 1.8928 Test MSE Loss: 0.9010
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0192995071411133, mae:0.7827214598655701, mape:0.7791035175323486, mspe:1.7313696146011353 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5847
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.533552885055542
Epoch: 1, Steps: 53 Train Loss: 1.4782 (Forecasting Loss:1.4763 + XiCon Loss:1.8260 x Lambda(0.001)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740652).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5339202880859375
Epoch: 2, Steps: 53 Train Loss: 1.4749 (Forecasting Loss:1.4730 + XiCon Loss:1.8280 x Lambda(0.001)), Vali MSE Loss: 1.7200 Test MSE Loss: 0.9609
Validation loss decreased (1.740652 --> 1.720039).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5226051807403564
Epoch: 3, Steps: 53 Train Loss: 1.4673 (Forecasting Loss:1.4654 + XiCon Loss:1.8237 x Lambda(0.001)), Vali MSE Loss: 1.7398 Test MSE Loss: 0.9649
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5118908882141113
Epoch: 4, Steps: 53 Train Loss: 1.4646 (Forecasting Loss:1.4628 + XiCon Loss:1.8271 x Lambda(0.001)), Vali MSE Loss: 1.7421 Test MSE Loss: 0.9670
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5345525741577148
Epoch: 5, Steps: 53 Train Loss: 1.4629 (Forecasting Loss:1.4611 + XiCon Loss:1.8301 x Lambda(0.001)), Vali MSE Loss: 1.7443 Test MSE Loss: 0.9681
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5175063610076904
Epoch: 6, Steps: 53 Train Loss: 1.4628 (Forecasting Loss:1.4609 + XiCon Loss:1.8278 x Lambda(0.001)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9687
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5211243629455566
Epoch: 7, Steps: 53 Train Loss: 1.4642 (Forecasting Loss:1.4623 + XiCon Loss:1.8236 x Lambda(0.001)), Vali MSE Loss: 1.7534 Test MSE Loss: 0.9689
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5130815505981445
Epoch: 8, Steps: 53 Train Loss: 1.4614 (Forecasting Loss:1.4596 + XiCon Loss:1.8264 x Lambda(0.001)), Vali MSE Loss: 1.7241 Test MSE Loss: 0.9691
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5320115089416504
Epoch: 9, Steps: 53 Train Loss: 1.4630 (Forecasting Loss:1.4612 + XiCon Loss:1.8289 x Lambda(0.001)), Vali MSE Loss: 1.7699 Test MSE Loss: 0.9692
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5149075984954834
Epoch: 10, Steps: 53 Train Loss: 1.4603 (Forecasting Loss:1.4585 + XiCon Loss:1.8260 x Lambda(0.001)), Vali MSE Loss: 1.7453 Test MSE Loss: 0.9692
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5267829895019531
Epoch: 11, Steps: 53 Train Loss: 1.4628 (Forecasting Loss:1.4610 + XiCon Loss:1.8305 x Lambda(0.001)), Vali MSE Loss: 1.7520 Test MSE Loss: 0.9692
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.525803565979004
Epoch: 12, Steps: 53 Train Loss: 1.4594 (Forecasting Loss:1.4575 + XiCon Loss:1.8376 x Lambda(0.001)), Vali MSE Loss: 1.7508 Test MSE Loss: 0.9692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1092743873596191, mae:0.8126073479652405, mape:0.8145757913589478, mspe:1.879008173942566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0620+-0.04087, MAE:0.7968+-0.01355, MAPE:0.7961+-0.01609, MSPE:1.8019+-0.06719, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.1969
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8841543
	speed: 0.0173s/iter; left time: 843.1185s
	iters: 200, epoch: 1 | loss: 0.7966685
	speed: 0.0126s/iter; left time: 609.9212s
	iters: 300, epoch: 1 | loss: 0.5539953
	speed: 0.0125s/iter; left time: 603.1432s
	iters: 400, epoch: 1 | loss: 0.6108020
	speed: 0.0129s/iter; left time: 625.4487s
Epoch: 1 cost time: 6.669629335403442
Epoch: 1, Steps: 487 Train Loss: 0.7442 (Forecasting Loss:0.7417 + XiCon Loss:2.4911 x Lambda(0.001)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036690).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5027952
	speed: 0.0149s/iter; left time: 715.0365s
	iters: 200, epoch: 2 | loss: 0.4599288
	speed: 0.0126s/iter; left time: 607.2010s
	iters: 300, epoch: 2 | loss: 0.5033154
	speed: 0.0131s/iter; left time: 626.6584s
	iters: 400, epoch: 2 | loss: 0.4075481
	speed: 0.0130s/iter; left time: 620.5627s
Epoch: 2 cost time: 6.526843547821045
Epoch: 2, Steps: 487 Train Loss: 0.4370 (Forecasting Loss:0.4345 + XiCon Loss:2.4916 x Lambda(0.001)), Vali MSE Loss: 0.7458 Test MSE Loss: 0.5268
Validation loss decreased (1.036690 --> 0.745760).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.3188042
	speed: 0.0149s/iter; left time: 712.0029s
	iters: 200, epoch: 3 | loss: 0.4261817
	speed: 0.0125s/iter; left time: 595.8274s
	iters: 300, epoch: 3 | loss: 0.5036643
	speed: 0.0126s/iter; left time: 595.4596s
	iters: 400, epoch: 3 | loss: 0.3547541
	speed: 0.0129s/iter; left time: 609.4637s
Epoch: 3 cost time: 6.445030689239502
Epoch: 3, Steps: 487 Train Loss: 0.4073 (Forecasting Loss:0.4048 + XiCon Loss:2.4911 x Lambda(0.001)), Vali MSE Loss: 0.7388 Test MSE Loss: 0.5208
Validation loss decreased (0.745760 --> 0.738832).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4790896
	speed: 0.0147s/iter; left time: 692.1317s
	iters: 200, epoch: 4 | loss: 0.4116153
	speed: 0.0121s/iter; left time: 568.3791s
	iters: 300, epoch: 4 | loss: 0.4470509
	speed: 0.0122s/iter; left time: 574.8521s
	iters: 400, epoch: 4 | loss: 0.3220202
	speed: 0.0130s/iter; left time: 607.2145s
Epoch: 4 cost time: 6.437676429748535
Epoch: 4, Steps: 487 Train Loss: 0.4017 (Forecasting Loss:0.3992 + XiCon Loss:2.4935 x Lambda(0.001)), Vali MSE Loss: 0.7321 Test MSE Loss: 0.5154
Validation loss decreased (0.738832 --> 0.732072).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.4251537
	speed: 0.0141s/iter; left time: 658.8104s
	iters: 200, epoch: 5 | loss: 0.5153681
	speed: 0.0124s/iter; left time: 579.1692s
	iters: 300, epoch: 5 | loss: 0.3701560
	speed: 0.0134s/iter; left time: 624.6886s
	iters: 400, epoch: 5 | loss: 0.3691073
	speed: 0.0126s/iter; left time: 585.9428s
Epoch: 5 cost time: 6.373967170715332
Epoch: 5, Steps: 487 Train Loss: 0.3992 (Forecasting Loss:0.3968 + XiCon Loss:2.4933 x Lambda(0.001)), Vali MSE Loss: 0.7297 Test MSE Loss: 0.5111
Validation loss decreased (0.732072 --> 0.729651).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4103215
	speed: 0.0149s/iter; left time: 686.9220s
	iters: 200, epoch: 6 | loss: 0.4367147
	speed: 0.0121s/iter; left time: 555.2496s
	iters: 300, epoch: 6 | loss: 0.4237042
	speed: 0.0127s/iter; left time: 582.2670s
	iters: 400, epoch: 6 | loss: 0.3649220
	speed: 0.0126s/iter; left time: 580.1760s
Epoch: 6 cost time: 6.367406845092773
Epoch: 6, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3959 + XiCon Loss:2.4922 x Lambda(0.001)), Vali MSE Loss: 0.7303 Test MSE Loss: 0.5135
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.4045254
	speed: 0.0146s/iter; left time: 666.8658s
	iters: 200, epoch: 7 | loss: 0.3018260
	speed: 0.0117s/iter; left time: 534.9408s
	iters: 300, epoch: 7 | loss: 0.4542421
	speed: 0.0124s/iter; left time: 565.4778s
	iters: 400, epoch: 7 | loss: 0.3825679
	speed: 0.0129s/iter; left time: 586.3536s
Epoch: 7 cost time: 6.353064298629761
Epoch: 7, Steps: 487 Train Loss: 0.3978 (Forecasting Loss:0.3953 + XiCon Loss:2.4917 x Lambda(0.001)), Vali MSE Loss: 0.7293 Test MSE Loss: 0.5126
Validation loss decreased (0.729651 --> 0.729287).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3754590
	speed: 0.0150s/iter; left time: 675.6519s
	iters: 200, epoch: 8 | loss: 0.3274468
	speed: 0.0126s/iter; left time: 569.1264s
	iters: 300, epoch: 8 | loss: 0.3889829
	speed: 0.0131s/iter; left time: 587.5799s
	iters: 400, epoch: 8 | loss: 0.4452934
	speed: 0.0131s/iter; left time: 586.3097s
Epoch: 8 cost time: 6.531310319900513
Epoch: 8, Steps: 487 Train Loss: 0.3975 (Forecasting Loss:0.3951 + XiCon Loss:2.4932 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5123
Validation loss decreased (0.729287 --> 0.729152).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5463963
	speed: 0.0149s/iter; left time: 663.9294s
	iters: 200, epoch: 9 | loss: 0.3344058
	speed: 0.0134s/iter; left time: 599.3471s
	iters: 300, epoch: 9 | loss: 0.4352528
	speed: 0.0128s/iter; left time: 567.4836s
	iters: 400, epoch: 9 | loss: 0.4071352
	speed: 0.0131s/iter; left time: 583.6424s
Epoch: 9 cost time: 6.571522235870361
Epoch: 9, Steps: 487 Train Loss: 0.3973 (Forecasting Loss:0.3948 + XiCon Loss:2.4954 x Lambda(0.001)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5122
Validation loss decreased (0.729152 --> 0.728880).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3435851
	speed: 0.0154s/iter; left time: 680.9048s
	iters: 200, epoch: 10 | loss: 0.3785874
	speed: 0.0127s/iter; left time: 561.2626s
	iters: 300, epoch: 10 | loss: 0.3555726
	speed: 0.0125s/iter; left time: 549.1138s
	iters: 400, epoch: 10 | loss: 0.3115400
	speed: 0.0125s/iter; left time: 549.1832s
Epoch: 10 cost time: 6.473680257797241
Epoch: 10, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3947 + XiCon Loss:2.4960 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3560881
	speed: 0.0140s/iter; left time: 610.2173s
	iters: 200, epoch: 11 | loss: 0.3264438
	speed: 0.0121s/iter; left time: 528.2611s
	iters: 300, epoch: 11 | loss: 0.4192790
	speed: 0.0129s/iter; left time: 562.8545s
	iters: 400, epoch: 11 | loss: 0.3724314
	speed: 0.0128s/iter; left time: 556.9172s
Epoch: 11 cost time: 6.366504430770874
Epoch: 11, Steps: 487 Train Loss: 0.3973 (Forecasting Loss:0.3948 + XiCon Loss:2.4950 x Lambda(0.001)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5122
Validation loss decreased (0.728880 --> 0.728611).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4248340
	speed: 0.0149s/iter; left time: 644.8722s
	iters: 200, epoch: 12 | loss: 0.3539349
	speed: 0.0126s/iter; left time: 543.3378s
	iters: 300, epoch: 12 | loss: 0.3589056
	speed: 0.0132s/iter; left time: 566.4947s
	iters: 400, epoch: 12 | loss: 0.3704294
	speed: 0.0130s/iter; left time: 558.8138s
Epoch: 12 cost time: 6.5261852741241455
Epoch: 12, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4934 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5354580
	speed: 0.0145s/iter; left time: 618.8271s
	iters: 200, epoch: 13 | loss: 0.3889054
	speed: 0.0119s/iter; left time: 508.7026s
	iters: 300, epoch: 13 | loss: 0.3690193
	speed: 0.0124s/iter; left time: 526.1154s
	iters: 400, epoch: 13 | loss: 0.3045503
	speed: 0.0129s/iter; left time: 547.3425s
Epoch: 13 cost time: 6.289576530456543
Epoch: 13, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4925 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4360723
	speed: 0.0151s/iter; left time: 637.8435s
	iters: 200, epoch: 14 | loss: 0.4602185
	speed: 0.0128s/iter; left time: 540.7927s
	iters: 300, epoch: 14 | loss: 0.3363189
	speed: 0.0135s/iter; left time: 568.0705s
	iters: 400, epoch: 14 | loss: 0.3234202
	speed: 0.0133s/iter; left time: 558.0558s
Epoch: 14 cost time: 6.700391054153442
Epoch: 14, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3947 + XiCon Loss:2.4955 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3736293
	speed: 0.0148s/iter; left time: 619.4327s
	iters: 200, epoch: 15 | loss: 0.3910322
	speed: 0.0129s/iter; left time: 536.9061s
	iters: 300, epoch: 15 | loss: 0.4371360
	speed: 0.0122s/iter; left time: 508.8076s
	iters: 400, epoch: 15 | loss: 0.4022699
	speed: 0.0131s/iter; left time: 543.0948s
Epoch: 15 cost time: 6.4738123416900635
Epoch: 15, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4950 x Lambda(0.001)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4520985
	speed: 0.0144s/iter; left time: 592.9885s
	iters: 200, epoch: 16 | loss: 0.4755256
	speed: 0.0126s/iter; left time: 519.0881s
	iters: 300, epoch: 16 | loss: 0.3838650
	speed: 0.0124s/iter; left time: 508.8577s
	iters: 400, epoch: 16 | loss: 0.4170556
	speed: 0.0134s/iter; left time: 549.8337s
Epoch: 16 cost time: 6.455153226852417
Epoch: 16, Steps: 487 Train Loss: 0.3971 (Forecasting Loss:0.3947 + XiCon Loss:2.4903 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3722600
	speed: 0.0145s/iter; left time: 592.5353s
	iters: 200, epoch: 17 | loss: 0.3719382
	speed: 0.0123s/iter; left time: 498.6891s
	iters: 300, epoch: 17 | loss: 0.4563600
	speed: 0.0130s/iter; left time: 526.7770s
	iters: 400, epoch: 17 | loss: 0.4337476
	speed: 0.0132s/iter; left time: 535.1815s
Epoch: 17 cost time: 6.415908336639404
Epoch: 17, Steps: 487 Train Loss: 0.3971 (Forecasting Loss:0.3946 + XiCon Loss:2.4946 x Lambda(0.001)), Vali MSE Loss: 0.7287 Test MSE Loss: 0.5122
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3413785
	speed: 0.0149s/iter; left time: 600.5416s
	iters: 200, epoch: 18 | loss: 0.4183502
	speed: 0.0125s/iter; left time: 502.9832s
	iters: 300, epoch: 18 | loss: 0.3423562
	speed: 0.0138s/iter; left time: 552.2608s
	iters: 400, epoch: 18 | loss: 0.3181399
	speed: 0.0136s/iter; left time: 545.4012s
Epoch: 18 cost time: 6.68710732460022
Epoch: 18, Steps: 487 Train Loss: 0.3969 (Forecasting Loss:0.3944 + XiCon Loss:2.4959 x Lambda(0.001)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5122
Validation loss decreased (0.728611 --> 0.728430).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3764016
	speed: 0.0149s/iter; left time: 592.2313s
	iters: 200, epoch: 19 | loss: 0.3901693
	speed: 0.0126s/iter; left time: 501.6350s
	iters: 300, epoch: 19 | loss: 0.3869579
	speed: 0.0122s/iter; left time: 484.8523s
	iters: 400, epoch: 19 | loss: 0.4110343
	speed: 0.0125s/iter; left time: 493.3925s
Epoch: 19 cost time: 6.382158279418945
Epoch: 19, Steps: 487 Train Loss: 0.3968 (Forecasting Loss:0.3943 + XiCon Loss:2.4928 x Lambda(0.001)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5122
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3924353
	speed: 0.0141s/iter; left time: 555.8801s
	iters: 200, epoch: 20 | loss: 0.3876194
	speed: 0.0122s/iter; left time: 479.5686s
	iters: 300, epoch: 20 | loss: 0.3229390
	speed: 0.0124s/iter; left time: 487.3228s
	iters: 400, epoch: 20 | loss: 0.3619525
	speed: 0.0128s/iter; left time: 500.3197s
Epoch: 20 cost time: 6.309277534484863
Epoch: 20, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3946 + XiCon Loss:2.4974 x Lambda(0.001)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5122
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.3061489
	speed: 0.0145s/iter; left time: 563.4602s
	iters: 200, epoch: 21 | loss: 0.3794152
	speed: 0.0126s/iter; left time: 489.3502s
	iters: 300, epoch: 21 | loss: 0.3258876
	speed: 0.0124s/iter; left time: 481.0369s
	iters: 400, epoch: 21 | loss: 0.4040815
	speed: 0.0126s/iter; left time: 484.8368s
Epoch: 21 cost time: 6.3853185176849365
Epoch: 21, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3947 + XiCon Loss:2.4930 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.3975579
	speed: 0.0150s/iter; left time: 573.9727s
	iters: 200, epoch: 22 | loss: 0.4514444
	speed: 0.0126s/iter; left time: 480.8988s
	iters: 300, epoch: 22 | loss: 0.4647648
	speed: 0.0132s/iter; left time: 505.3109s
	iters: 400, epoch: 22 | loss: 0.3593590
	speed: 0.0133s/iter; left time: 505.8296s
Epoch: 22 cost time: 6.586345434188843
Epoch: 22, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3947 + XiCon Loss:2.4984 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4772135
	speed: 0.0151s/iter; left time: 573.3451s
	iters: 200, epoch: 23 | loss: 0.3556944
	speed: 0.0129s/iter; left time: 485.5809s
	iters: 300, epoch: 23 | loss: 0.3680643
	speed: 0.0124s/iter; left time: 466.3034s
	iters: 400, epoch: 23 | loss: 0.4432555
	speed: 0.0128s/iter; left time: 480.7925s
Epoch: 23 cost time: 6.488898277282715
Epoch: 23, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4919 x Lambda(0.001)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5122
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4827658
	speed: 0.0148s/iter; left time: 553.2049s
	iters: 200, epoch: 24 | loss: 0.3812132
	speed: 0.0127s/iter; left time: 474.1098s
	iters: 300, epoch: 24 | loss: 0.4350949
	speed: 0.0123s/iter; left time: 458.1703s
	iters: 400, epoch: 24 | loss: 0.3254284
	speed: 0.0132s/iter; left time: 489.8482s
Epoch: 24 cost time: 6.48696756362915
Epoch: 24, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4956 x Lambda(0.001)), Vali MSE Loss: 0.7291 Test MSE Loss: 0.5122
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.3917730
	speed: 0.0145s/iter; left time: 536.6173s
	iters: 200, epoch: 25 | loss: 0.4117910
	speed: 0.0115s/iter; left time: 422.2957s
	iters: 300, epoch: 25 | loss: 0.3586173
	speed: 0.0115s/iter; left time: 421.6931s
	iters: 400, epoch: 25 | loss: 0.4043705
	speed: 0.0116s/iter; left time: 424.1261s
Epoch: 25 cost time: 5.864420413970947
Epoch: 25, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4939 x Lambda(0.001)), Vali MSE Loss: 0.7283 Test MSE Loss: 0.5122
Validation loss decreased (0.728430 --> 0.728332).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3658591
	speed: 0.0148s/iter; left time: 540.3328s
	iters: 200, epoch: 26 | loss: 0.3663632
	speed: 0.0126s/iter; left time: 456.0011s
	iters: 300, epoch: 26 | loss: 0.4941094
	speed: 0.0126s/iter; left time: 455.5798s
	iters: 400, epoch: 26 | loss: 0.3299779
	speed: 0.0122s/iter; left time: 440.9042s
Epoch: 26 cost time: 6.366612672805786
Epoch: 26, Steps: 487 Train Loss: 0.3971 (Forecasting Loss:0.3946 + XiCon Loss:2.4972 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3770488
	speed: 0.0153s/iter; left time: 550.6668s
	iters: 200, epoch: 27 | loss: 0.4002304
	speed: 0.0119s/iter; left time: 424.8036s
	iters: 300, epoch: 27 | loss: 0.3317982
	speed: 0.0129s/iter; left time: 460.0834s
	iters: 400, epoch: 27 | loss: 0.3456108
	speed: 0.0131s/iter; left time: 468.5563s
Epoch: 27 cost time: 6.518597602844238
Epoch: 27, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3947 + XiCon Loss:2.4936 x Lambda(0.001)), Vali MSE Loss: 0.7288 Test MSE Loss: 0.5122
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3979046
	speed: 0.0145s/iter; left time: 513.6931s
	iters: 200, epoch: 28 | loss: 0.4033182
	speed: 0.0124s/iter; left time: 438.2374s
	iters: 300, epoch: 28 | loss: 0.4057149
	speed: 0.0122s/iter; left time: 429.6876s
	iters: 400, epoch: 28 | loss: 0.3746161
	speed: 0.0126s/iter; left time: 443.5324s
Epoch: 28 cost time: 6.358365297317505
Epoch: 28, Steps: 487 Train Loss: 0.3968 (Forecasting Loss:0.3943 + XiCon Loss:2.4936 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3432742
	speed: 0.0151s/iter; left time: 527.6972s
	iters: 200, epoch: 29 | loss: 0.4449644
	speed: 0.0123s/iter; left time: 430.1529s
	iters: 300, epoch: 29 | loss: 0.4168612
	speed: 0.0130s/iter; left time: 453.0886s
	iters: 400, epoch: 29 | loss: 0.4061162
	speed: 0.0131s/iter; left time: 455.7267s
Epoch: 29 cost time: 6.522858142852783
Epoch: 29, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3948 + XiCon Loss:2.4961 x Lambda(0.001)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5122
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3698875
	speed: 0.0143s/iter; left time: 494.2698s
	iters: 200, epoch: 30 | loss: 0.3942718
	speed: 0.0122s/iter; left time: 417.6937s
	iters: 300, epoch: 30 | loss: 0.4345193
	speed: 0.0120s/iter; left time: 411.3394s
	iters: 400, epoch: 30 | loss: 0.3816102
	speed: 0.0124s/iter; left time: 423.0183s
Epoch: 30 cost time: 6.2350544929504395
Epoch: 30, Steps: 487 Train Loss: 0.3969 (Forecasting Loss:0.3944 + XiCon Loss:2.4973 x Lambda(0.001)), Vali MSE Loss: 0.7292 Test MSE Loss: 0.5122
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4862954
	speed: 0.0150s/iter; left time: 510.1564s
	iters: 200, epoch: 31 | loss: 0.3105142
	speed: 0.0127s/iter; left time: 428.8987s
	iters: 300, epoch: 31 | loss: 0.4052109
	speed: 0.0127s/iter; left time: 429.3385s
	iters: 400, epoch: 31 | loss: 0.3279641
	speed: 0.0127s/iter; left time: 428.1916s
Epoch: 31 cost time: 6.498994827270508
Epoch: 31, Steps: 487 Train Loss: 0.3969 (Forecasting Loss:0.3944 + XiCon Loss:2.4956 x Lambda(0.001)), Vali MSE Loss: 0.7285 Test MSE Loss: 0.5122
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.3890486
	speed: 0.0143s/iter; left time: 478.5775s
	iters: 200, epoch: 32 | loss: 0.4712189
	speed: 0.0126s/iter; left time: 419.8912s
	iters: 300, epoch: 32 | loss: 0.3431757
	speed: 0.0122s/iter; left time: 407.1413s
	iters: 400, epoch: 32 | loss: 0.3050499
	speed: 0.0125s/iter; left time: 413.8349s
Epoch: 32 cost time: 6.308285713195801
Epoch: 32, Steps: 487 Train Loss: 0.3967 (Forecasting Loss:0.3942 + XiCon Loss:2.4933 x Lambda(0.001)), Vali MSE Loss: 0.7289 Test MSE Loss: 0.5122
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3574002
	speed: 0.0144s/iter; left time: 474.2166s
	iters: 200, epoch: 33 | loss: 0.3156459
	speed: 0.0122s/iter; left time: 401.4224s
	iters: 300, epoch: 33 | loss: 0.4080143
	speed: 0.0129s/iter; left time: 423.3825s
	iters: 400, epoch: 33 | loss: 0.4775576
	speed: 0.0128s/iter; left time: 420.0841s
Epoch: 33 cost time: 6.3926050662994385
Epoch: 33, Steps: 487 Train Loss: 0.3971 (Forecasting Loss:0.3946 + XiCon Loss:2.4953 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3999206
	speed: 0.0143s/iter; left time: 466.2876s
	iters: 200, epoch: 34 | loss: 0.4376550
	speed: 0.0124s/iter; left time: 403.5896s
	iters: 300, epoch: 34 | loss: 0.3552066
	speed: 0.0129s/iter; left time: 418.2984s
	iters: 400, epoch: 34 | loss: 0.3686613
	speed: 0.0131s/iter; left time: 422.1214s
Epoch: 34 cost time: 6.435715436935425
Epoch: 34, Steps: 487 Train Loss: 0.3969 (Forecasting Loss:0.3944 + XiCon Loss:2.4937 x Lambda(0.001)), Vali MSE Loss: 0.7284 Test MSE Loss: 0.5122
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3832633
	speed: 0.0154s/iter; left time: 495.0560s
	iters: 200, epoch: 35 | loss: 0.3162811
	speed: 0.0121s/iter; left time: 387.3346s
	iters: 300, epoch: 35 | loss: 0.3992375
	speed: 0.0126s/iter; left time: 402.4811s
	iters: 400, epoch: 35 | loss: 0.4095533
	speed: 0.0130s/iter; left time: 412.2745s
Epoch: 35 cost time: 6.470129489898682
Epoch: 35, Steps: 487 Train Loss: 0.3970 (Forecasting Loss:0.3945 + XiCon Loss:2.4972 x Lambda(0.001)), Vali MSE Loss: 0.7290 Test MSE Loss: 0.5122
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5189176201820374, mae:0.5053932666778564, mape:3.537503480911255, mspe:1160.219482421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.7461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.6770182
	speed: 0.0152s/iter; left time: 740.1544s
	iters: 200, epoch: 1 | loss: 0.8676786
	speed: 0.0129s/iter; left time: 625.4869s
	iters: 300, epoch: 1 | loss: 0.5617814
	speed: 0.0132s/iter; left time: 638.3243s
	iters: 400, epoch: 1 | loss: 0.4924060
	speed: 0.0130s/iter; left time: 625.9643s
Epoch: 1 cost time: 6.654008388519287
Epoch: 1, Steps: 487 Train Loss: 0.7373 (Forecasting Loss:0.7348 + XiCon Loss:2.4792 x Lambda(0.001)), Vali MSE Loss: 1.0306 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030646).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4934029
	speed: 0.0151s/iter; left time: 726.5991s
	iters: 200, epoch: 2 | loss: 0.4882193
	speed: 0.0129s/iter; left time: 621.3632s
	iters: 300, epoch: 2 | loss: 0.3944836
	speed: 0.0130s/iter; left time: 624.9831s
	iters: 400, epoch: 2 | loss: 0.4770530
	speed: 0.0134s/iter; left time: 639.8661s
Epoch: 2 cost time: 6.596696376800537
Epoch: 2, Steps: 487 Train Loss: 0.4408 (Forecasting Loss:0.4383 + XiCon Loss:2.4903 x Lambda(0.001)), Vali MSE Loss: 0.7331 Test MSE Loss: 0.5271
Validation loss decreased (1.030646 --> 0.733111).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4235674
	speed: 0.0155s/iter; left time: 737.1242s
	iters: 200, epoch: 3 | loss: 0.3908408
	speed: 0.0130s/iter; left time: 618.7871s
	iters: 300, epoch: 3 | loss: 0.4123836
	speed: 0.0131s/iter; left time: 621.5735s
	iters: 400, epoch: 3 | loss: 0.3599455
	speed: 0.0131s/iter; left time: 622.3153s
Epoch: 3 cost time: 6.639528512954712
Epoch: 3, Steps: 487 Train Loss: 0.4074 (Forecasting Loss:0.4049 + XiCon Loss:2.4833 x Lambda(0.001)), Vali MSE Loss: 0.7181 Test MSE Loss: 0.5188
Validation loss decreased (0.733111 --> 0.718085).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.5231568
	speed: 0.0149s/iter; left time: 701.2130s
	iters: 200, epoch: 4 | loss: 0.3674492
	speed: 0.0132s/iter; left time: 618.9042s
	iters: 300, epoch: 4 | loss: 0.5146237
	speed: 0.0132s/iter; left time: 618.1153s
	iters: 400, epoch: 4 | loss: 0.4990624
	speed: 0.0130s/iter; left time: 610.8409s
Epoch: 4 cost time: 6.6057655811309814
Epoch: 4, Steps: 487 Train Loss: 0.4013 (Forecasting Loss:0.3988 + XiCon Loss:2.4808 x Lambda(0.001)), Vali MSE Loss: 0.7119 Test MSE Loss: 0.5167
Validation loss decreased (0.718085 --> 0.711902).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3616781
	speed: 0.0153s/iter; left time: 715.4060s
	iters: 200, epoch: 5 | loss: 0.4195083
	speed: 0.0128s/iter; left time: 594.7825s
	iters: 300, epoch: 5 | loss: 0.3720283
	speed: 0.0127s/iter; left time: 589.6226s
	iters: 400, epoch: 5 | loss: 0.3040889
	speed: 0.0133s/iter; left time: 616.0235s
Epoch: 5 cost time: 6.589695692062378
Epoch: 5, Steps: 487 Train Loss: 0.3991 (Forecasting Loss:0.3966 + XiCon Loss:2.4862 x Lambda(0.001)), Vali MSE Loss: 0.7104 Test MSE Loss: 0.5148
Validation loss decreased (0.711902 --> 0.710438).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3406871
	speed: 0.0155s/iter; left time: 715.8074s
	iters: 200, epoch: 6 | loss: 0.3715010
	speed: 0.0128s/iter; left time: 588.8261s
	iters: 300, epoch: 6 | loss: 0.3051747
	speed: 0.0131s/iter; left time: 601.5242s
	iters: 400, epoch: 6 | loss: 0.4272708
	speed: 0.0130s/iter; left time: 598.0362s
Epoch: 6 cost time: 6.60210108757019
Epoch: 6, Steps: 487 Train Loss: 0.3979 (Forecasting Loss:0.3954 + XiCon Loss:2.4888 x Lambda(0.001)), Vali MSE Loss: 0.7078 Test MSE Loss: 0.5135
Validation loss decreased (0.710438 --> 0.707758).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3527213
	speed: 0.0154s/iter; left time: 704.9518s
	iters: 200, epoch: 7 | loss: 0.3527117
	speed: 0.0133s/iter; left time: 606.5495s
	iters: 300, epoch: 7 | loss: 0.4723879
	speed: 0.0128s/iter; left time: 584.2276s
	iters: 400, epoch: 7 | loss: 0.3636787
	speed: 0.0145s/iter; left time: 658.6406s
Epoch: 7 cost time: 6.8168113231658936
Epoch: 7, Steps: 487 Train Loss: 0.3972 (Forecasting Loss:0.3948 + XiCon Loss:2.4824 x Lambda(0.001)), Vali MSE Loss: 0.7072 Test MSE Loss: 0.5135
Validation loss decreased (0.707758 --> 0.707230).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4352171
	speed: 0.0155s/iter; left time: 698.8423s
	iters: 200, epoch: 8 | loss: 0.4161507
	speed: 0.0124s/iter; left time: 560.3166s
	iters: 300, epoch: 8 | loss: 0.3588297
	speed: 0.0127s/iter; left time: 572.4730s
	iters: 400, epoch: 8 | loss: 0.3051613
	speed: 0.0133s/iter; left time: 597.1012s
Epoch: 8 cost time: 6.556121349334717
Epoch: 8, Steps: 487 Train Loss: 0.3969 (Forecasting Loss:0.3944 + XiCon Loss:2.4824 x Lambda(0.001)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5133
Validation loss decreased (0.707230 --> 0.707028).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3725776
	speed: 0.0155s/iter; left time: 692.1638s
	iters: 200, epoch: 9 | loss: 0.3872674
	speed: 0.0128s/iter; left time: 569.3518s
	iters: 300, epoch: 9 | loss: 0.3783956
	speed: 0.0130s/iter; left time: 580.1221s
	iters: 400, epoch: 9 | loss: 0.4758572
	speed: 0.0133s/iter; left time: 591.8843s
Epoch: 9 cost time: 6.6240997314453125
Epoch: 9, Steps: 487 Train Loss: 0.3966 (Forecasting Loss:0.3942 + XiCon Loss:2.4821 x Lambda(0.001)), Vali MSE Loss: 0.7064 Test MSE Loss: 0.5132
Validation loss decreased (0.707028 --> 0.706361).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3972702
	speed: 0.0157s/iter; left time: 692.9249s
	iters: 200, epoch: 10 | loss: 0.3945446
	speed: 0.0127s/iter; left time: 558.7040s
	iters: 300, epoch: 10 | loss: 0.2706222
	speed: 0.0135s/iter; left time: 596.2769s
	iters: 400, epoch: 10 | loss: 0.4062161
	speed: 0.0135s/iter; left time: 593.0147s
Epoch: 10 cost time: 6.735803127288818
Epoch: 10, Steps: 487 Train Loss: 0.3967 (Forecasting Loss:0.3942 + XiCon Loss:2.4825 x Lambda(0.001)), Vali MSE Loss: 0.7072 Test MSE Loss: 0.5131
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3142047
	speed: 0.0154s/iter; left time: 674.5103s
	iters: 200, epoch: 11 | loss: 0.3575439
	speed: 0.0131s/iter; left time: 571.4583s
	iters: 300, epoch: 11 | loss: 0.3626559
	speed: 0.0132s/iter; left time: 572.7008s
	iters: 400, epoch: 11 | loss: 0.5143792
	speed: 0.0130s/iter; left time: 563.3409s
Epoch: 11 cost time: 6.63799524307251
Epoch: 11, Steps: 487 Train Loss: 0.3963 (Forecasting Loss:0.3939 + XiCon Loss:2.4754 x Lambda(0.001)), Vali MSE Loss: 0.7073 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3719696
	speed: 0.0153s/iter; left time: 661.3129s
	iters: 200, epoch: 12 | loss: 0.4017465
	speed: 0.0129s/iter; left time: 557.5269s
	iters: 300, epoch: 12 | loss: 0.4299512
	speed: 0.0129s/iter; left time: 556.2261s
	iters: 400, epoch: 12 | loss: 0.4139789
	speed: 0.0129s/iter; left time: 555.3666s
Epoch: 12 cost time: 6.573191165924072
Epoch: 12, Steps: 487 Train Loss: 0.3967 (Forecasting Loss:0.3942 + XiCon Loss:2.4821 x Lambda(0.001)), Vali MSE Loss: 0.7072 Test MSE Loss: 0.5131
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4073883
	speed: 0.0151s/iter; left time: 647.1815s
	iters: 200, epoch: 13 | loss: 0.4695191
	speed: 0.0129s/iter; left time: 551.3436s
	iters: 300, epoch: 13 | loss: 0.3614023
	speed: 0.0127s/iter; left time: 541.7842s
	iters: 400, epoch: 13 | loss: 0.3669809
	speed: 0.0132s/iter; left time: 560.3100s
Epoch: 13 cost time: 6.5504162311553955
Epoch: 13, Steps: 487 Train Loss: 0.3967 (Forecasting Loss:0.3942 + XiCon Loss:2.4864 x Lambda(0.001)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5131
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3744114
	speed: 0.0159s/iter; left time: 670.2957s
	iters: 200, epoch: 14 | loss: 0.4093226
	speed: 0.0129s/iter; left time: 545.8527s
	iters: 300, epoch: 14 | loss: 0.3640806
	speed: 0.0130s/iter; left time: 546.7873s
	iters: 400, epoch: 14 | loss: 0.3918863
	speed: 0.0128s/iter; left time: 538.3292s
Epoch: 14 cost time: 6.65310001373291
Epoch: 14, Steps: 487 Train Loss: 0.3965 (Forecasting Loss:0.3940 + XiCon Loss:2.4841 x Lambda(0.001)), Vali MSE Loss: 0.7071 Test MSE Loss: 0.5131
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4489034
	speed: 0.0159s/iter; left time: 663.8303s
	iters: 200, epoch: 15 | loss: 0.4124450
	speed: 0.0132s/iter; left time: 551.0582s
	iters: 300, epoch: 15 | loss: 0.4142942
	speed: 0.0137s/iter; left time: 568.8277s
	iters: 400, epoch: 15 | loss: 0.3751544
	speed: 0.0132s/iter; left time: 545.8344s
Epoch: 15 cost time: 6.735103130340576
Epoch: 15, Steps: 487 Train Loss: 0.3962 (Forecasting Loss:0.3938 + XiCon Loss:2.4783 x Lambda(0.001)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5131
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4181415
	speed: 0.0166s/iter; left time: 686.0885s
	iters: 200, epoch: 16 | loss: 0.4425374
	speed: 0.0130s/iter; left time: 533.5713s
	iters: 300, epoch: 16 | loss: 0.3755150
	speed: 0.0135s/iter; left time: 555.8583s
	iters: 400, epoch: 16 | loss: 0.4572410
	speed: 0.0126s/iter; left time: 517.3554s
Epoch: 16 cost time: 6.745774507522583
Epoch: 16, Steps: 487 Train Loss: 0.3964 (Forecasting Loss:0.3939 + XiCon Loss:2.4814 x Lambda(0.001)), Vali MSE Loss: 0.7072 Test MSE Loss: 0.5131
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3935397
	speed: 0.0162s/iter; left time: 661.3789s
	iters: 200, epoch: 17 | loss: 0.4399650
	speed: 0.0128s/iter; left time: 522.9852s
	iters: 300, epoch: 17 | loss: 0.4108029
	speed: 0.0132s/iter; left time: 537.7181s
	iters: 400, epoch: 17 | loss: 0.4424705
	speed: 0.0130s/iter; left time: 527.4001s
Epoch: 17 cost time: 6.721120119094849
Epoch: 17, Steps: 487 Train Loss: 0.3967 (Forecasting Loss:0.3942 + XiCon Loss:2.4835 x Lambda(0.001)), Vali MSE Loss: 0.7070 Test MSE Loss: 0.5131
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4340557
	speed: 0.0153s/iter; left time: 616.6273s
	iters: 200, epoch: 18 | loss: 0.4143218
	speed: 0.0139s/iter; left time: 558.4177s
	iters: 300, epoch: 18 | loss: 0.5785294
	speed: 0.0132s/iter; left time: 528.8998s
	iters: 400, epoch: 18 | loss: 0.3969085
	speed: 0.0129s/iter; left time: 518.2174s
Epoch: 18 cost time: 6.700814485549927
Epoch: 18, Steps: 487 Train Loss: 0.3964 (Forecasting Loss:0.3939 + XiCon Loss:2.4800 x Lambda(0.001)), Vali MSE Loss: 0.7067 Test MSE Loss: 0.5131
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.2955062
	speed: 0.0156s/iter; left time: 620.4647s
	iters: 200, epoch: 19 | loss: 0.4647793
	speed: 0.0135s/iter; left time: 535.1192s
	iters: 300, epoch: 19 | loss: 0.4219027
	speed: 0.0132s/iter; left time: 522.7901s
	iters: 400, epoch: 19 | loss: 0.3464155
	speed: 0.0129s/iter; left time: 509.3459s
Epoch: 19 cost time: 6.706305503845215
Epoch: 19, Steps: 487 Train Loss: 0.3966 (Forecasting Loss:0.3942 + XiCon Loss:2.4821 x Lambda(0.001)), Vali MSE Loss: 0.7073 Test MSE Loss: 0.5131
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5198995471000671, mae:0.5064544081687927, mape:3.441598653793335, mspe:1081.9058837890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.0835
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1163744
	speed: 0.0145s/iter; left time: 705.9069s
	iters: 200, epoch: 1 | loss: 0.7700716
	speed: 0.0120s/iter; left time: 580.9128s
	iters: 300, epoch: 1 | loss: 0.6830998
	speed: 0.0124s/iter; left time: 602.3661s
	iters: 400, epoch: 1 | loss: 0.7355655
	speed: 0.0132s/iter; left time: 639.1928s
Epoch: 1 cost time: 6.388166666030884
Epoch: 1, Steps: 487 Train Loss: 0.8434 (Forecasting Loss:0.8409 + XiCon Loss:2.4979 x Lambda(0.001)), Vali MSE Loss: 1.1923 Test MSE Loss: 0.6744
Validation loss decreased (inf --> 1.192320).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4467250
	speed: 0.0155s/iter; left time: 744.7129s
	iters: 200, epoch: 2 | loss: 0.4228364
	speed: 0.0126s/iter; left time: 605.3370s
	iters: 300, epoch: 2 | loss: 0.3718752
	speed: 0.0129s/iter; left time: 619.9516s
	iters: 400, epoch: 2 | loss: 0.5142142
	speed: 0.0135s/iter; left time: 645.0173s
Epoch: 2 cost time: 6.589993476867676
Epoch: 2, Steps: 487 Train Loss: 0.4552 (Forecasting Loss:0.4527 + XiCon Loss:2.4928 x Lambda(0.001)), Vali MSE Loss: 0.7519 Test MSE Loss: 0.5337
Validation loss decreased (1.192320 --> 0.751918).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4574414
	speed: 0.0146s/iter; left time: 697.4203s
	iters: 200, epoch: 3 | loss: 0.3905776
	speed: 0.0128s/iter; left time: 605.9750s
	iters: 300, epoch: 3 | loss: 0.3329765
	speed: 0.0126s/iter; left time: 596.8989s
	iters: 400, epoch: 3 | loss: 0.3892750
	speed: 0.0134s/iter; left time: 632.8087s
Epoch: 3 cost time: 6.501538991928101
Epoch: 3, Steps: 487 Train Loss: 0.4107 (Forecasting Loss:0.4082 + XiCon Loss:2.4931 x Lambda(0.001)), Vali MSE Loss: 0.7395 Test MSE Loss: 0.5302
Validation loss decreased (0.751918 --> 0.739478).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.3807872
	speed: 0.0155s/iter; left time: 731.4346s
	iters: 200, epoch: 4 | loss: 0.3510381
	speed: 0.0123s/iter; left time: 579.5567s
	iters: 300, epoch: 4 | loss: 0.4074937
	speed: 0.0138s/iter; left time: 647.2549s
	iters: 400, epoch: 4 | loss: 0.4710220
	speed: 0.0130s/iter; left time: 608.1837s
Epoch: 4 cost time: 6.641353130340576
Epoch: 4, Steps: 487 Train Loss: 0.4051 (Forecasting Loss:0.4026 + XiCon Loss:2.4853 x Lambda(0.001)), Vali MSE Loss: 0.7318 Test MSE Loss: 0.5268
Validation loss decreased (0.739478 --> 0.731778).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3850622
	speed: 0.0147s/iter; left time: 683.8760s
	iters: 200, epoch: 5 | loss: 0.3656057
	speed: 0.0126s/iter; left time: 586.5947s
	iters: 300, epoch: 5 | loss: 0.3943929
	speed: 0.0127s/iter; left time: 590.0469s
	iters: 400, epoch: 5 | loss: 0.4273899
	speed: 0.0129s/iter; left time: 598.0855s
Epoch: 5 cost time: 6.473474025726318
Epoch: 5, Steps: 487 Train Loss: 0.4025 (Forecasting Loss:0.4000 + XiCon Loss:2.4874 x Lambda(0.001)), Vali MSE Loss: 0.7299 Test MSE Loss: 0.5229
Validation loss decreased (0.731778 --> 0.729851).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.3885832
	speed: 0.0147s/iter; left time: 680.4620s
	iters: 200, epoch: 6 | loss: 0.3758925
	speed: 0.0123s/iter; left time: 567.1793s
	iters: 300, epoch: 6 | loss: 0.3874801
	speed: 0.0127s/iter; left time: 584.4610s
	iters: 400, epoch: 6 | loss: 0.3773208
	speed: 0.0126s/iter; left time: 576.5682s
Epoch: 6 cost time: 6.404824256896973
Epoch: 6, Steps: 487 Train Loss: 0.4011 (Forecasting Loss:0.3986 + XiCon Loss:2.4859 x Lambda(0.001)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5220
Validation loss decreased (0.729851 --> 0.727950).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3751823
	speed: 0.0157s/iter; left time: 716.6592s
	iters: 200, epoch: 7 | loss: 0.3911659
	speed: 0.0127s/iter; left time: 579.6712s
	iters: 300, epoch: 7 | loss: 0.4498866
	speed: 0.0127s/iter; left time: 576.1759s
	iters: 400, epoch: 7 | loss: 0.4157963
	speed: 0.0131s/iter; left time: 595.8246s
Epoch: 7 cost time: 6.592180490493774
Epoch: 7, Steps: 487 Train Loss: 0.4006 (Forecasting Loss:0.3982 + XiCon Loss:2.4880 x Lambda(0.001)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
Validation loss decreased (0.727950 --> 0.727573).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4179833
	speed: 0.0141s/iter; left time: 637.8887s
	iters: 200, epoch: 8 | loss: 0.3735744
	speed: 0.0119s/iter; left time: 536.1882s
	iters: 300, epoch: 8 | loss: 0.4045309
	speed: 0.0129s/iter; left time: 579.5922s
	iters: 400, epoch: 8 | loss: 0.3478749
	speed: 0.0134s/iter; left time: 602.7595s
Epoch: 8 cost time: 6.394361257553101
Epoch: 8, Steps: 487 Train Loss: 0.4004 (Forecasting Loss:0.3979 + XiCon Loss:2.4853 x Lambda(0.001)), Vali MSE Loss: 0.7281 Test MSE Loss: 0.5212
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.4727214
	speed: 0.0142s/iter; left time: 636.9967s
	iters: 200, epoch: 9 | loss: 0.3916502
	speed: 0.0119s/iter; left time: 529.5705s
	iters: 300, epoch: 9 | loss: 0.4547762
	speed: 0.0130s/iter; left time: 577.7720s
	iters: 400, epoch: 9 | loss: 0.3192150
	speed: 0.0133s/iter; left time: 590.0425s
Epoch: 9 cost time: 6.3908531665802
Epoch: 9, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4875 x Lambda(0.001)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5213
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4978046
	speed: 0.0145s/iter; left time: 643.3044s
	iters: 200, epoch: 10 | loss: 0.4105215
	speed: 0.0122s/iter; left time: 539.8535s
	iters: 300, epoch: 10 | loss: 0.3536895
	speed: 0.0128s/iter; left time: 561.7277s
	iters: 400, epoch: 10 | loss: 0.3412128
	speed: 0.0127s/iter; left time: 559.4923s
Epoch: 10 cost time: 6.44289755821228
Epoch: 10, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4852 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5212
Validation loss decreased (0.727573 --> 0.727544).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.4130588
	speed: 0.0146s/iter; left time: 637.2992s
	iters: 200, epoch: 11 | loss: 0.3734201
	speed: 0.0124s/iter; left time: 539.8751s
	iters: 300, epoch: 11 | loss: 0.4177358
	speed: 0.0134s/iter; left time: 581.3774s
	iters: 400, epoch: 11 | loss: 0.3566512
	speed: 0.0133s/iter; left time: 576.7812s
Epoch: 11 cost time: 6.576218366622925
Epoch: 11, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4862 x Lambda(0.001)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5212
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.3688170
	speed: 0.0147s/iter; left time: 635.5995s
	iters: 200, epoch: 12 | loss: 0.4922601
	speed: 0.0126s/iter; left time: 542.0125s
	iters: 300, epoch: 12 | loss: 0.3582035
	speed: 0.0130s/iter; left time: 559.1685s
	iters: 400, epoch: 12 | loss: 0.4508941
	speed: 0.0129s/iter; left time: 555.5205s
Epoch: 12 cost time: 6.485465049743652
Epoch: 12, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4853 x Lambda(0.001)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5212
Validation loss decreased (0.727544 --> 0.727402).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3330935
	speed: 0.0147s/iter; left time: 630.5351s
	iters: 200, epoch: 13 | loss: 0.4349230
	speed: 0.0124s/iter; left time: 528.1872s
	iters: 300, epoch: 13 | loss: 0.4323822
	speed: 0.0122s/iter; left time: 520.2779s
	iters: 400, epoch: 13 | loss: 0.3222995
	speed: 0.0129s/iter; left time: 546.6140s
Epoch: 13 cost time: 6.394925832748413
Epoch: 13, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4848 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5211
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.4136571
	speed: 0.0147s/iter; left time: 623.1060s
	iters: 200, epoch: 14 | loss: 0.4745594
	speed: 0.0123s/iter; left time: 516.9983s
	iters: 300, epoch: 14 | loss: 0.3423814
	speed: 0.0124s/iter; left time: 521.0692s
	iters: 400, epoch: 14 | loss: 0.5620558
	speed: 0.0126s/iter; left time: 528.7105s
Epoch: 14 cost time: 6.380004405975342
Epoch: 14, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4817 x Lambda(0.001)), Vali MSE Loss: 0.7270 Test MSE Loss: 0.5211
Validation loss decreased (0.727402 --> 0.726991).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3699929
	speed: 0.0145s/iter; left time: 606.5928s
	iters: 200, epoch: 15 | loss: 0.4291446
	speed: 0.0127s/iter; left time: 527.6576s
	iters: 300, epoch: 15 | loss: 0.4165924
	speed: 0.0128s/iter; left time: 531.5489s
	iters: 400, epoch: 15 | loss: 0.3169863
	speed: 0.0131s/iter; left time: 544.8954s
Epoch: 15 cost time: 6.454258918762207
Epoch: 15, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4837 x Lambda(0.001)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5211
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3274563
	speed: 0.0146s/iter; left time: 601.3674s
	iters: 200, epoch: 16 | loss: 0.3784735
	speed: 0.0119s/iter; left time: 489.4512s
	iters: 300, epoch: 16 | loss: 0.3707179
	speed: 0.0121s/iter; left time: 498.6054s
	iters: 400, epoch: 16 | loss: 0.4363497
	speed: 0.0133s/iter; left time: 546.0820s
Epoch: 16 cost time: 6.390207767486572
Epoch: 16, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4868 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5211
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3794724
	speed: 0.0143s/iter; left time: 585.1471s
	iters: 200, epoch: 17 | loss: 0.4384300
	speed: 0.0127s/iter; left time: 515.7750s
	iters: 300, epoch: 17 | loss: 0.4287489
	speed: 0.0129s/iter; left time: 522.1553s
	iters: 400, epoch: 17 | loss: 0.3229118
	speed: 0.0133s/iter; left time: 540.5668s
Epoch: 17 cost time: 6.3699328899383545
Epoch: 17, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4881 x Lambda(0.001)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5211
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.3594138
	speed: 0.0148s/iter; left time: 597.9898s
	iters: 200, epoch: 18 | loss: 0.5007247
	speed: 0.0121s/iter; left time: 486.2889s
	iters: 300, epoch: 18 | loss: 0.4066690
	speed: 0.0130s/iter; left time: 520.4324s
	iters: 400, epoch: 18 | loss: 0.4656729
	speed: 0.0131s/iter; left time: 522.5953s
Epoch: 18 cost time: 6.4902119636535645
Epoch: 18, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4825 x Lambda(0.001)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5211
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.3221357
	speed: 0.0146s/iter; left time: 582.9094s
	iters: 200, epoch: 19 | loss: 0.3808297
	speed: 0.0124s/iter; left time: 491.5350s
	iters: 300, epoch: 19 | loss: 0.4046859
	speed: 0.0126s/iter; left time: 498.8880s
	iters: 400, epoch: 19 | loss: 0.4818420
	speed: 0.0125s/iter; left time: 493.8950s
Epoch: 19 cost time: 6.359858751296997
Epoch: 19, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4820 x Lambda(0.001)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5211
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3341343
	speed: 0.0153s/iter; left time: 601.5810s
	iters: 200, epoch: 20 | loss: 0.4296697
	speed: 0.0129s/iter; left time: 505.0838s
	iters: 300, epoch: 20 | loss: 0.3676619
	speed: 0.0127s/iter; left time: 498.8471s
	iters: 400, epoch: 20 | loss: 0.4039198
	speed: 0.0133s/iter; left time: 517.8984s
Epoch: 20 cost time: 6.59332537651062
Epoch: 20, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4862 x Lambda(0.001)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5211
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4407864
	speed: 0.0149s/iter; left time: 578.6201s
	iters: 200, epoch: 21 | loss: 0.3936422
	speed: 0.0125s/iter; left time: 485.7798s
	iters: 300, epoch: 21 | loss: 0.4270116
	speed: 0.0128s/iter; left time: 494.5407s
	iters: 400, epoch: 21 | loss: 0.4255238
	speed: 0.0131s/iter; left time: 504.0446s
Epoch: 21 cost time: 6.54339599609375
Epoch: 21, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4877 x Lambda(0.001)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5211
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4722987
	speed: 0.0141s/iter; left time: 540.8550s
	iters: 200, epoch: 22 | loss: 0.3898904
	speed: 0.0128s/iter; left time: 489.1347s
	iters: 300, epoch: 22 | loss: 0.4423426
	speed: 0.0123s/iter; left time: 468.7072s
	iters: 400, epoch: 22 | loss: 0.3660982
	speed: 0.0129s/iter; left time: 492.8997s
Epoch: 22 cost time: 6.392979860305786
Epoch: 22, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4865 x Lambda(0.001)), Vali MSE Loss: 0.7269 Test MSE Loss: 0.5211
Validation loss decreased (0.726991 --> 0.726852).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3962406
	speed: 0.0142s/iter; left time: 537.8411s
	iters: 200, epoch: 23 | loss: 0.4041061
	speed: 0.0120s/iter; left time: 455.0255s
	iters: 300, epoch: 23 | loss: 0.3615846
	speed: 0.0124s/iter; left time: 466.0111s
	iters: 400, epoch: 23 | loss: 0.3869340
	speed: 0.0133s/iter; left time: 500.8112s
Epoch: 23 cost time: 6.365651369094849
Epoch: 23, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4901 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5211
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.3791761
	speed: 0.0151s/iter; left time: 565.6007s
	iters: 200, epoch: 24 | loss: 0.3694954
	speed: 0.0125s/iter; left time: 464.5852s
	iters: 300, epoch: 24 | loss: 0.3729325
	speed: 0.0132s/iter; left time: 491.7343s
	iters: 400, epoch: 24 | loss: 0.4616363
	speed: 0.0132s/iter; left time: 488.5040s
Epoch: 24 cost time: 6.573758125305176
Epoch: 24, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4873 x Lambda(0.001)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5211
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4397947
	speed: 0.0141s/iter; left time: 519.7976s
	iters: 200, epoch: 25 | loss: 0.2981538
	speed: 0.0130s/iter; left time: 476.9496s
	iters: 300, epoch: 25 | loss: 0.3609588
	speed: 0.0128s/iter; left time: 470.9066s
	iters: 400, epoch: 25 | loss: 0.3744449
	speed: 0.0124s/iter; left time: 452.8636s
Epoch: 25 cost time: 6.370245456695557
Epoch: 25, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4862 x Lambda(0.001)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5211
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3758169
	speed: 0.0149s/iter; left time: 541.5699s
	iters: 200, epoch: 26 | loss: 0.4061510
	speed: 0.0127s/iter; left time: 461.1474s
	iters: 300, epoch: 26 | loss: 0.3673625
	speed: 0.0129s/iter; left time: 468.8006s
	iters: 400, epoch: 26 | loss: 0.4195325
	speed: 0.0129s/iter; left time: 465.6596s
Epoch: 26 cost time: 6.544245004653931
Epoch: 26, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4908 x Lambda(0.001)), Vali MSE Loss: 0.7269 Test MSE Loss: 0.5211
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3519391
	speed: 0.0144s/iter; left time: 516.4416s
	iters: 200, epoch: 27 | loss: 0.3685495
	speed: 0.0127s/iter; left time: 453.8760s
	iters: 300, epoch: 27 | loss: 0.4517742
	speed: 0.0126s/iter; left time: 448.6556s
	iters: 400, epoch: 27 | loss: 0.4499802
	speed: 0.0128s/iter; left time: 457.9552s
Epoch: 27 cost time: 6.430768728256226
Epoch: 27, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4838 x Lambda(0.001)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5211
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.4056183
	speed: 0.0149s/iter; left time: 526.6117s
	iters: 200, epoch: 28 | loss: 0.4180610
	speed: 0.0128s/iter; left time: 452.9377s
	iters: 300, epoch: 28 | loss: 0.3825772
	speed: 0.0126s/iter; left time: 442.5571s
	iters: 400, epoch: 28 | loss: 0.3651002
	speed: 0.0131s/iter; left time: 461.2670s
Epoch: 28 cost time: 6.487969875335693
Epoch: 28, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4906 x Lambda(0.001)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5211
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4246060
	speed: 0.0145s/iter; left time: 508.5254s
	iters: 200, epoch: 29 | loss: 0.3919104
	speed: 0.0127s/iter; left time: 442.3482s
	iters: 300, epoch: 29 | loss: 0.4757439
	speed: 0.0129s/iter; left time: 449.0146s
	iters: 400, epoch: 29 | loss: 0.4721873
	speed: 0.0134s/iter; left time: 463.4071s
Epoch: 29 cost time: 6.578351259231567
Epoch: 29, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4871 x Lambda(0.001)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5211
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4658290
	speed: 0.0148s/iter; left time: 511.2349s
	iters: 200, epoch: 30 | loss: 0.4083236
	speed: 0.0125s/iter; left time: 430.0758s
	iters: 300, epoch: 30 | loss: 0.4848714
	speed: 0.0125s/iter; left time: 427.1953s
	iters: 400, epoch: 30 | loss: 0.4136271
	speed: 0.0129s/iter; left time: 441.6593s
Epoch: 30 cost time: 6.475400686264038
Epoch: 30, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3974 + XiCon Loss:2.4815 x Lambda(0.001)), Vali MSE Loss: 0.7270 Test MSE Loss: 0.5211
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.4094917
	speed: 0.0140s/iter; left time: 476.3149s
	iters: 200, epoch: 31 | loss: 0.3041606
	speed: 0.0122s/iter; left time: 413.0310s
	iters: 300, epoch: 31 | loss: 0.3589089
	speed: 0.0125s/iter; left time: 423.2486s
	iters: 400, epoch: 31 | loss: 0.4278734
	speed: 0.0133s/iter; left time: 447.1388s
Epoch: 31 cost time: 6.385194301605225
Epoch: 31, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4906 x Lambda(0.001)), Vali MSE Loss: 0.7267 Test MSE Loss: 0.5211
Validation loss decreased (0.726852 --> 0.726697).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.3835916
	speed: 0.0149s/iter; left time: 499.2963s
	iters: 200, epoch: 32 | loss: 0.3779529
	speed: 0.0127s/iter; left time: 424.0380s
	iters: 300, epoch: 32 | loss: 0.3158144
	speed: 0.0126s/iter; left time: 420.1728s
	iters: 400, epoch: 32 | loss: 0.2953209
	speed: 0.0133s/iter; left time: 441.5770s
Epoch: 32 cost time: 6.528664588928223
Epoch: 32, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3973 + XiCon Loss:2.4787 x Lambda(0.001)), Vali MSE Loss: 0.7278 Test MSE Loss: 0.5211
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3450502
	speed: 0.0143s/iter; left time: 471.6798s
	iters: 200, epoch: 33 | loss: 0.4255056
	speed: 0.0125s/iter; left time: 409.9030s
	iters: 300, epoch: 33 | loss: 0.4031024
	speed: 0.0125s/iter; left time: 410.6061s
	iters: 400, epoch: 33 | loss: 0.3616180
	speed: 0.0131s/iter; left time: 427.5713s
Epoch: 33 cost time: 6.39979100227356
Epoch: 33, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4864 x Lambda(0.001)), Vali MSE Loss: 0.7277 Test MSE Loss: 0.5211
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.4257878
	speed: 0.0148s/iter; left time: 480.1115s
	iters: 200, epoch: 34 | loss: 0.4727755
	speed: 0.0121s/iter; left time: 393.0499s
	iters: 300, epoch: 34 | loss: 0.3678419
	speed: 0.0124s/iter; left time: 402.2748s
	iters: 400, epoch: 34 | loss: 0.4042173
	speed: 0.0130s/iter; left time: 419.2652s
Epoch: 34 cost time: 6.428296327590942
Epoch: 34, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4889 x Lambda(0.001)), Vali MSE Loss: 0.7279 Test MSE Loss: 0.5211
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3476231
	speed: 0.0147s/iter; left time: 472.1762s
	iters: 200, epoch: 35 | loss: 0.3383963
	speed: 0.0127s/iter; left time: 406.0157s
	iters: 300, epoch: 35 | loss: 0.3357320
	speed: 0.0126s/iter; left time: 401.6811s
	iters: 400, epoch: 35 | loss: 0.3713712
	speed: 0.0128s/iter; left time: 406.3379s
Epoch: 35 cost time: 6.433698892593384
Epoch: 35, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4881 x Lambda(0.001)), Vali MSE Loss: 0.7270 Test MSE Loss: 0.5211
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4442679
	speed: 0.0153s/iter; left time: 482.9400s
	iters: 200, epoch: 36 | loss: 0.4487558
	speed: 0.0122s/iter; left time: 383.3122s
	iters: 300, epoch: 36 | loss: 0.3612794
	speed: 0.0119s/iter; left time: 373.9433s
	iters: 400, epoch: 36 | loss: 0.4500307
	speed: 0.0131s/iter; left time: 410.9362s
Epoch: 36 cost time: 6.382380247116089
Epoch: 36, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3976 + XiCon Loss:2.4847 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5211
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3857008
	speed: 0.0146s/iter; left time: 452.8017s
	iters: 200, epoch: 37 | loss: 0.3277602
	speed: 0.0123s/iter; left time: 380.7719s
	iters: 300, epoch: 37 | loss: 0.3934981
	speed: 0.0131s/iter; left time: 405.5836s
	iters: 400, epoch: 37 | loss: 0.4471833
	speed: 0.0129s/iter; left time: 397.5886s
Epoch: 37 cost time: 6.476460218429565
Epoch: 37, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4887 x Lambda(0.001)), Vali MSE Loss: 0.7273 Test MSE Loss: 0.5211
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3738540
	speed: 0.0154s/iter; left time: 471.5089s
	iters: 200, epoch: 38 | loss: 0.4009849
	speed: 0.0129s/iter; left time: 394.0748s
	iters: 300, epoch: 38 | loss: 0.4083678
	speed: 0.0128s/iter; left time: 387.9431s
	iters: 400, epoch: 38 | loss: 0.3465414
	speed: 0.0129s/iter; left time: 389.6682s
Epoch: 38 cost time: 6.556197166442871
Epoch: 38, Steps: 487 Train Loss: 0.4000 (Forecasting Loss:0.3975 + XiCon Loss:2.4894 x Lambda(0.001)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5211
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.3582790
	speed: 0.0147s/iter; left time: 442.5722s
	iters: 200, epoch: 39 | loss: 0.3662634
	speed: 0.0132s/iter; left time: 394.9475s
	iters: 300, epoch: 39 | loss: 0.4015740
	speed: 0.0134s/iter; left time: 401.5078s
	iters: 400, epoch: 39 | loss: 0.3946426
	speed: 0.0135s/iter; left time: 401.1403s
Epoch: 39 cost time: 6.634854793548584
Epoch: 39, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3974 + XiCon Loss:2.4823 x Lambda(0.001)), Vali MSE Loss: 0.7272 Test MSE Loss: 0.5211
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4503432
	speed: 0.0148s/iter; left time: 438.4714s
	iters: 200, epoch: 40 | loss: 0.3907950
	speed: 0.0122s/iter; left time: 359.8072s
	iters: 300, epoch: 40 | loss: 0.4106798
	speed: 0.0126s/iter; left time: 371.6928s
	iters: 400, epoch: 40 | loss: 0.3051754
	speed: 0.0128s/iter; left time: 375.5245s
Epoch: 40 cost time: 6.41559100151062
Epoch: 40, Steps: 487 Train Loss: 0.4001 (Forecasting Loss:0.3976 + XiCon Loss:2.4831 x Lambda(0.001)), Vali MSE Loss: 0.7274 Test MSE Loss: 0.5211
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.4439917
	speed: 0.0147s/iter; left time: 429.4458s
	iters: 200, epoch: 41 | loss: 0.3321896
	speed: 0.0123s/iter; left time: 358.2964s
	iters: 300, epoch: 41 | loss: 0.3760829
	speed: 0.0127s/iter; left time: 368.5730s
	iters: 400, epoch: 41 | loss: 0.3743464
	speed: 0.0132s/iter; left time: 379.0653s
Epoch: 41 cost time: 6.478592157363892
Epoch: 41, Steps: 487 Train Loss: 0.3999 (Forecasting Loss:0.3974 + XiCon Loss:2.4837 x Lambda(0.001)), Vali MSE Loss: 0.7275 Test MSE Loss: 0.5211
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5303983092308044, mae:0.5118685364723206, mape:3.607412815093994, mspe:1216.2401123046875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.1350
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.0849575
	speed: 0.0151s/iter; left time: 736.2163s
	iters: 200, epoch: 1 | loss: 0.8473085
	speed: 0.0132s/iter; left time: 638.3750s
	iters: 300, epoch: 1 | loss: 0.7499645
	speed: 0.0131s/iter; left time: 635.0412s
	iters: 400, epoch: 1 | loss: 0.8139510
	speed: 0.0135s/iter; left time: 650.1227s
Epoch: 1 cost time: 6.688299179077148
Epoch: 1, Steps: 487 Train Loss: 0.8034 (Forecasting Loss:0.8010 + XiCon Loss:2.4509 x Lambda(0.001)), Vali MSE Loss: 1.0983 Test MSE Loss: 0.6609
Validation loss decreased (inf --> 1.098340).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.5532463
	speed: 0.0152s/iter; left time: 730.8880s
	iters: 200, epoch: 2 | loss: 0.4147814
	speed: 0.0133s/iter; left time: 637.2881s
	iters: 300, epoch: 2 | loss: 0.4083166
	speed: 0.0134s/iter; left time: 642.9203s
	iters: 400, epoch: 2 | loss: 0.3715919
	speed: 0.0136s/iter; left time: 652.4931s
Epoch: 2 cost time: 6.774268627166748
Epoch: 2, Steps: 487 Train Loss: 0.4377 (Forecasting Loss:0.4353 + XiCon Loss:2.4484 x Lambda(0.001)), Vali MSE Loss: 0.7548 Test MSE Loss: 0.5193
Validation loss decreased (1.098340 --> 0.754800).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4150306
	speed: 0.0149s/iter; left time: 711.0553s
	iters: 200, epoch: 3 | loss: 0.4270503
	speed: 0.0137s/iter; left time: 650.2881s
	iters: 300, epoch: 3 | loss: 0.4069258
	speed: 0.0135s/iter; left time: 642.6063s
	iters: 400, epoch: 3 | loss: 0.4412595
	speed: 0.0131s/iter; left time: 619.2998s
Epoch: 3 cost time: 6.68288779258728
Epoch: 3, Steps: 487 Train Loss: 0.4048 (Forecasting Loss:0.4023 + XiCon Loss:2.4488 x Lambda(0.001)), Vali MSE Loss: 0.7487 Test MSE Loss: 0.5122
Validation loss decreased (0.754800 --> 0.748723).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.3909383
	speed: 0.0159s/iter; left time: 750.3181s
	iters: 200, epoch: 4 | loss: 0.4039277
	speed: 0.0133s/iter; left time: 623.9621s
	iters: 300, epoch: 4 | loss: 0.4745149
	speed: 0.0130s/iter; left time: 612.2890s
	iters: 400, epoch: 4 | loss: 0.3395942
	speed: 0.0136s/iter; left time: 637.6270s
Epoch: 4 cost time: 6.820570707321167
Epoch: 4, Steps: 487 Train Loss: 0.3998 (Forecasting Loss:0.3974 + XiCon Loss:2.4500 x Lambda(0.001)), Vali MSE Loss: 0.7409 Test MSE Loss: 0.5094
Validation loss decreased (0.748723 --> 0.740933).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3760737
	speed: 0.0159s/iter; left time: 743.5539s
	iters: 200, epoch: 5 | loss: 0.4266714
	speed: 0.0127s/iter; left time: 592.1108s
	iters: 300, epoch: 5 | loss: 0.4201829
	speed: 0.0128s/iter; left time: 595.1266s
	iters: 400, epoch: 5 | loss: 0.4069486
	speed: 0.0130s/iter; left time: 601.4573s
Epoch: 5 cost time: 6.598012447357178
Epoch: 5, Steps: 487 Train Loss: 0.3976 (Forecasting Loss:0.3952 + XiCon Loss:2.4520 x Lambda(0.001)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5094
Validation loss decreased (0.740933 --> 0.739082).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4129829
	speed: 0.0155s/iter; left time: 716.9415s
	iters: 200, epoch: 6 | loss: 0.3626600
	speed: 0.0127s/iter; left time: 587.3238s
	iters: 300, epoch: 6 | loss: 0.4628310
	speed: 0.0131s/iter; left time: 602.8702s
	iters: 400, epoch: 6 | loss: 0.5064580
	speed: 0.0132s/iter; left time: 604.2491s
Epoch: 6 cost time: 6.644825220108032
Epoch: 6, Steps: 487 Train Loss: 0.3966 (Forecasting Loss:0.3941 + XiCon Loss:2.4501 x Lambda(0.001)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5088
Validation loss decreased (0.739082 --> 0.737710).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3833165
	speed: 0.0153s/iter; left time: 699.0871s
	iters: 200, epoch: 7 | loss: 0.3582975
	speed: 0.0130s/iter; left time: 594.3521s
	iters: 300, epoch: 7 | loss: 0.3812338
	speed: 0.0133s/iter; left time: 606.0215s
	iters: 400, epoch: 7 | loss: 0.3875951
	speed: 0.0131s/iter; left time: 593.5398s
Epoch: 7 cost time: 6.65080451965332
Epoch: 7, Steps: 487 Train Loss: 0.3961 (Forecasting Loss:0.3936 + XiCon Loss:2.4446 x Lambda(0.001)), Vali MSE Loss: 0.7379 Test MSE Loss: 0.5084
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.4283109
	speed: 0.0152s/iter; left time: 687.5824s
	iters: 200, epoch: 8 | loss: 0.4564873
	speed: 0.0127s/iter; left time: 574.4841s
	iters: 300, epoch: 8 | loss: 0.3856624
	speed: 0.0130s/iter; left time: 586.9754s
	iters: 400, epoch: 8 | loss: 0.3498249
	speed: 0.0128s/iter; left time: 573.7014s
Epoch: 8 cost time: 6.532797813415527
Epoch: 8, Steps: 487 Train Loss: 0.3957 (Forecasting Loss:0.3933 + XiCon Loss:2.4452 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5081
Validation loss decreased (0.737710 --> 0.737263).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3861986
	speed: 0.0154s/iter; left time: 690.0596s
	iters: 200, epoch: 9 | loss: 0.3847126
	speed: 0.0138s/iter; left time: 616.5107s
	iters: 300, epoch: 9 | loss: 0.4245025
	speed: 0.0129s/iter; left time: 575.5395s
	iters: 400, epoch: 9 | loss: 0.4298790
	speed: 0.0132s/iter; left time: 585.6108s
Epoch: 9 cost time: 6.719135999679565
Epoch: 9, Steps: 487 Train Loss: 0.3958 (Forecasting Loss:0.3933 + XiCon Loss:2.4491 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.4120349
	speed: 0.0151s/iter; left time: 665.5443s
	iters: 200, epoch: 10 | loss: 0.3975668
	speed: 0.0129s/iter; left time: 569.0587s
	iters: 300, epoch: 10 | loss: 0.4737185
	speed: 0.0129s/iter; left time: 566.2919s
	iters: 400, epoch: 10 | loss: 0.4232458
	speed: 0.0134s/iter; left time: 587.0099s
Epoch: 10 cost time: 6.587287902832031
Epoch: 10, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3931 + XiCon Loss:2.4452 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3856227
	speed: 0.0154s/iter; left time: 671.7666s
	iters: 200, epoch: 11 | loss: 0.3339662
	speed: 0.0135s/iter; left time: 588.5307s
	iters: 300, epoch: 11 | loss: 0.3590825
	speed: 0.0133s/iter; left time: 579.4590s
	iters: 400, epoch: 11 | loss: 0.3399631
	speed: 0.0129s/iter; left time: 559.9520s
Epoch: 11 cost time: 6.705986499786377
Epoch: 11, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3930 + XiCon Loss:2.4463 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
Validation loss decreased (0.737263 --> 0.737101).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4857183
	speed: 0.0157s/iter; left time: 679.4215s
	iters: 200, epoch: 12 | loss: 0.3994476
	speed: 0.0129s/iter; left time: 557.2963s
	iters: 300, epoch: 12 | loss: 0.4660959
	speed: 0.0127s/iter; left time: 546.9914s
	iters: 400, epoch: 12 | loss: 0.3556087
	speed: 0.0127s/iter; left time: 546.2086s
Epoch: 12 cost time: 6.581209421157837
Epoch: 12, Steps: 487 Train Loss: 0.3956 (Forecasting Loss:0.3931 + XiCon Loss:2.4507 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.4284363
	speed: 0.0151s/iter; left time: 644.9903s
	iters: 200, epoch: 13 | loss: 0.3941950
	speed: 0.0132s/iter; left time: 561.5207s
	iters: 300, epoch: 13 | loss: 0.3252466
	speed: 0.0131s/iter; left time: 555.7213s
	iters: 400, epoch: 13 | loss: 0.3962256
	speed: 0.0135s/iter; left time: 572.4587s
Epoch: 13 cost time: 6.657969951629639
Epoch: 13, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3930 + XiCon Loss:2.4455 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3622242
	speed: 0.0159s/iter; left time: 671.3247s
	iters: 200, epoch: 14 | loss: 0.3168915
	speed: 0.0129s/iter; left time: 544.3447s
	iters: 300, epoch: 14 | loss: 0.3359903
	speed: 0.0130s/iter; left time: 547.8418s
	iters: 400, epoch: 14 | loss: 0.3914644
	speed: 0.0137s/iter; left time: 574.6499s
Epoch: 14 cost time: 6.76327919960022
Epoch: 14, Steps: 487 Train Loss: 0.3953 (Forecasting Loss:0.3928 + XiCon Loss:2.4461 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5081
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.4175293
	speed: 0.0157s/iter; left time: 658.0816s
	iters: 200, epoch: 15 | loss: 0.3919156
	speed: 0.0133s/iter; left time: 553.2842s
	iters: 300, epoch: 15 | loss: 0.5205423
	speed: 0.0130s/iter; left time: 542.5093s
	iters: 400, epoch: 15 | loss: 0.3398359
	speed: 0.0130s/iter; left time: 539.8942s
Epoch: 15 cost time: 6.665553092956543
Epoch: 15, Steps: 487 Train Loss: 0.3959 (Forecasting Loss:0.3934 + XiCon Loss:2.4439 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
Validation loss decreased (0.737101 --> 0.737051).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.3530010
	speed: 0.0152s/iter; left time: 626.3724s
	iters: 200, epoch: 16 | loss: 0.3364012
	speed: 0.0126s/iter; left time: 521.0680s
	iters: 300, epoch: 16 | loss: 0.3855236
	speed: 0.0131s/iter; left time: 540.0560s
	iters: 400, epoch: 16 | loss: 0.3760208
	speed: 0.0127s/iter; left time: 521.8993s
Epoch: 16 cost time: 6.497874736785889
Epoch: 16, Steps: 487 Train Loss: 0.3953 (Forecasting Loss:0.3929 + XiCon Loss:2.4422 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3791438
	speed: 0.0153s/iter; left time: 625.7888s
	iters: 200, epoch: 17 | loss: 0.3766998
	speed: 0.0132s/iter; left time: 538.4233s
	iters: 300, epoch: 17 | loss: 0.4024026
	speed: 0.0131s/iter; left time: 532.0182s
	iters: 400, epoch: 17 | loss: 0.4049979
	speed: 0.0131s/iter; left time: 529.3496s
Epoch: 17 cost time: 6.670127630233765
Epoch: 17, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3930 + XiCon Loss:2.4527 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4828568
	speed: 0.0152s/iter; left time: 614.3655s
	iters: 200, epoch: 18 | loss: 0.4142283
	speed: 0.0132s/iter; left time: 532.3311s
	iters: 300, epoch: 18 | loss: 0.3530059
	speed: 0.0130s/iter; left time: 522.1391s
	iters: 400, epoch: 18 | loss: 0.3274974
	speed: 0.0132s/iter; left time: 529.0406s
Epoch: 18 cost time: 6.665766477584839
Epoch: 18, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3931 + XiCon Loss:2.4477 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4163864
	speed: 0.0157s/iter; left time: 626.1432s
	iters: 200, epoch: 19 | loss: 0.3970896
	speed: 0.0136s/iter; left time: 539.8259s
	iters: 300, epoch: 19 | loss: 0.3044724
	speed: 0.0136s/iter; left time: 537.3764s
	iters: 400, epoch: 19 | loss: 0.4424285
	speed: 0.0134s/iter; left time: 531.6345s
Epoch: 19 cost time: 6.837059259414673
Epoch: 19, Steps: 487 Train Loss: 0.3956 (Forecasting Loss:0.3931 + XiCon Loss:2.4491 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5081
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.4116293
	speed: 0.0158s/iter; left time: 620.6138s
	iters: 200, epoch: 20 | loss: 0.3656683
	speed: 0.0129s/iter; left time: 507.8571s
	iters: 300, epoch: 20 | loss: 0.3559375
	speed: 0.0128s/iter; left time: 500.5777s
	iters: 400, epoch: 20 | loss: 0.3317768
	speed: 0.0132s/iter; left time: 516.0818s
Epoch: 20 cost time: 6.6263511180877686
Epoch: 20, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3931 + XiCon Loss:2.4476 x Lambda(0.001)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5081
Validation loss decreased (0.737051 --> 0.737049).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4153934
	speed: 0.0154s/iter; left time: 598.6840s
	iters: 200, epoch: 21 | loss: 0.4088282
	speed: 0.0123s/iter; left time: 478.0699s
	iters: 300, epoch: 21 | loss: 0.3289762
	speed: 0.0125s/iter; left time: 483.5751s
	iters: 400, epoch: 21 | loss: 0.3548834
	speed: 0.0130s/iter; left time: 500.3909s
Epoch: 21 cost time: 6.505285739898682
Epoch: 21, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3929 + XiCon Loss:2.4523 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.3999580
	speed: 0.0154s/iter; left time: 590.0418s
	iters: 200, epoch: 22 | loss: 0.4116721
	speed: 0.0131s/iter; left time: 500.4878s
	iters: 300, epoch: 22 | loss: 0.4224571
	speed: 0.0129s/iter; left time: 491.2980s
	iters: 400, epoch: 22 | loss: 0.3711083
	speed: 0.0128s/iter; left time: 486.4324s
Epoch: 22 cost time: 6.618597984313965
Epoch: 22, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3930 + XiCon Loss:2.4507 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.3390331
	speed: 0.0150s/iter; left time: 570.0610s
	iters: 200, epoch: 23 | loss: 0.3651159
	speed: 0.0132s/iter; left time: 499.2557s
	iters: 300, epoch: 23 | loss: 0.4530834
	speed: 0.0136s/iter; left time: 512.1395s
	iters: 400, epoch: 23 | loss: 0.4047067
	speed: 0.0140s/iter; left time: 526.4661s
Epoch: 23 cost time: 6.758064031600952
Epoch: 23, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3929 + XiCon Loss:2.4493 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4150434
	speed: 0.0155s/iter; left time: 581.0911s
	iters: 200, epoch: 24 | loss: 0.4433190
	speed: 0.0129s/iter; left time: 480.0992s
	iters: 300, epoch: 24 | loss: 0.3205900
	speed: 0.0110s/iter; left time: 408.1436s
	iters: 400, epoch: 24 | loss: 0.4273374
	speed: 0.0112s/iter; left time: 415.6091s
Epoch: 24 cost time: 6.093293905258179
Epoch: 24, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3930 + XiCon Loss:2.4444 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5081
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.3821272
	speed: 0.0153s/iter; left time: 565.4392s
	iters: 200, epoch: 25 | loss: 0.3413871
	speed: 0.0130s/iter; left time: 479.7869s
	iters: 300, epoch: 25 | loss: 0.3899715
	speed: 0.0131s/iter; left time: 481.6061s
	iters: 400, epoch: 25 | loss: 0.4232716
	speed: 0.0128s/iter; left time: 468.0048s
Epoch: 25 cost time: 6.608546495437622
Epoch: 25, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3930 + XiCon Loss:2.4508 x Lambda(0.001)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5081
Validation loss decreased (0.737049 --> 0.736709).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.3937037
	speed: 0.0162s/iter; left time: 591.7628s
	iters: 200, epoch: 26 | loss: 0.3478560
	speed: 0.0129s/iter; left time: 469.1662s
	iters: 300, epoch: 26 | loss: 0.4225019
	speed: 0.0135s/iter; left time: 488.1290s
	iters: 400, epoch: 26 | loss: 0.4469983
	speed: 0.0132s/iter; left time: 475.9809s
Epoch: 26 cost time: 6.744070053100586
Epoch: 26, Steps: 487 Train Loss: 0.3953 (Forecasting Loss:0.3929 + XiCon Loss:2.4459 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.3933943
	speed: 0.0151s/iter; left time: 543.0724s
	iters: 200, epoch: 27 | loss: 0.4360348
	speed: 0.0130s/iter; left time: 467.1233s
	iters: 300, epoch: 27 | loss: 0.3444172
	speed: 0.0133s/iter; left time: 474.1640s
	iters: 400, epoch: 27 | loss: 0.3968421
	speed: 0.0133s/iter; left time: 474.2255s
Epoch: 27 cost time: 6.674342393875122
Epoch: 27, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3929 + XiCon Loss:2.4503 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3677913
	speed: 0.0159s/iter; left time: 563.5838s
	iters: 200, epoch: 28 | loss: 0.3631102
	speed: 0.0131s/iter; left time: 462.8365s
	iters: 300, epoch: 28 | loss: 0.3549081
	speed: 0.0134s/iter; left time: 473.2852s
	iters: 400, epoch: 28 | loss: 0.4189925
	speed: 0.0131s/iter; left time: 461.7818s
Epoch: 28 cost time: 6.746991872787476
Epoch: 28, Steps: 487 Train Loss: 0.3956 (Forecasting Loss:0.3931 + XiCon Loss:2.4469 x Lambda(0.001)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5081
Validation loss decreased (0.736709 --> 0.736606).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.4507152
	speed: 0.0152s/iter; left time: 532.5209s
	iters: 200, epoch: 29 | loss: 0.4031482
	speed: 0.0129s/iter; left time: 450.9763s
	iters: 300, epoch: 29 | loss: 0.3596725
	speed: 0.0130s/iter; left time: 453.5862s
	iters: 400, epoch: 29 | loss: 0.3954007
	speed: 0.0132s/iter; left time: 456.6039s
Epoch: 29 cost time: 6.606618404388428
Epoch: 29, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3929 + XiCon Loss:2.4471 x Lambda(0.001)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5081
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.4532471
	speed: 0.0152s/iter; left time: 525.0588s
	iters: 200, epoch: 30 | loss: 0.4291108
	speed: 0.0132s/iter; left time: 452.1555s
	iters: 300, epoch: 30 | loss: 0.3851539
	speed: 0.0129s/iter; left time: 440.8625s
	iters: 400, epoch: 30 | loss: 0.3605012
	speed: 0.0134s/iter; left time: 456.3208s
Epoch: 30 cost time: 6.636132717132568
Epoch: 30, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3930 + XiCon Loss:2.4512 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5081
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3518142
	speed: 0.0161s/iter; left time: 547.4954s
	iters: 200, epoch: 31 | loss: 0.3075640
	speed: 0.0134s/iter; left time: 453.0509s
	iters: 300, epoch: 31 | loss: 0.4317198
	speed: 0.0133s/iter; left time: 449.7419s
	iters: 400, epoch: 31 | loss: 0.3870981
	speed: 0.0133s/iter; left time: 446.4854s
Epoch: 31 cost time: 6.829029560089111
Epoch: 31, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3930 + XiCon Loss:2.4468 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5081
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4425804
	speed: 0.0154s/iter; left time: 515.4023s
	iters: 200, epoch: 32 | loss: 0.4625034
	speed: 0.0129s/iter; left time: 429.5100s
	iters: 300, epoch: 32 | loss: 0.3789482
	speed: 0.0133s/iter; left time: 443.6939s
	iters: 400, epoch: 32 | loss: 0.4042445
	speed: 0.0130s/iter; left time: 430.3283s
Epoch: 32 cost time: 6.6852357387542725
Epoch: 32, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3930 + XiCon Loss:2.4483 x Lambda(0.001)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5081
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.4249469
	speed: 0.0158s/iter; left time: 522.4625s
	iters: 200, epoch: 33 | loss: 0.4183153
	speed: 0.0139s/iter; left time: 456.7511s
	iters: 300, epoch: 33 | loss: 0.3542368
	speed: 0.0131s/iter; left time: 428.2785s
	iters: 400, epoch: 33 | loss: 0.3431624
	speed: 0.0134s/iter; left time: 439.9640s
Epoch: 33 cost time: 6.879734516143799
Epoch: 33, Steps: 487 Train Loss: 0.3953 (Forecasting Loss:0.3929 + XiCon Loss:2.4445 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5081
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3555498
	speed: 0.0158s/iter; left time: 512.4000s
	iters: 200, epoch: 34 | loss: 0.4009157
	speed: 0.0134s/iter; left time: 433.2426s
	iters: 300, epoch: 34 | loss: 0.3109305
	speed: 0.0130s/iter; left time: 418.7441s
	iters: 400, epoch: 34 | loss: 0.3434190
	speed: 0.0135s/iter; left time: 434.1798s
Epoch: 34 cost time: 6.731082916259766
Epoch: 34, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3931 + XiCon Loss:2.4464 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5081
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3869127
	speed: 0.0157s/iter; left time: 501.5430s
	iters: 200, epoch: 35 | loss: 0.4204410
	speed: 0.0126s/iter; left time: 403.1981s
	iters: 300, epoch: 35 | loss: 0.3437336
	speed: 0.0128s/iter; left time: 407.9594s
	iters: 400, epoch: 35 | loss: 0.3358368
	speed: 0.0135s/iter; left time: 428.4189s
Epoch: 35 cost time: 6.679837465286255
Epoch: 35, Steps: 487 Train Loss: 0.3957 (Forecasting Loss:0.3933 + XiCon Loss:2.4457 x Lambda(0.001)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5081
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.3683285
	speed: 0.0159s/iter; left time: 501.9454s
	iters: 200, epoch: 36 | loss: 0.4838550
	speed: 0.0127s/iter; left time: 399.7535s
	iters: 300, epoch: 36 | loss: 0.3543865
	speed: 0.0130s/iter; left time: 407.9200s
	iters: 400, epoch: 36 | loss: 0.4468586
	speed: 0.0133s/iter; left time: 415.2124s
Epoch: 36 cost time: 6.669227838516235
Epoch: 36, Steps: 487 Train Loss: 0.3953 (Forecasting Loss:0.3928 + XiCon Loss:2.4472 x Lambda(0.001)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5081
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.3720310
	speed: 0.0153s/iter; left time: 473.8492s
	iters: 200, epoch: 37 | loss: 0.4050064
	speed: 0.0129s/iter; left time: 398.8795s
	iters: 300, epoch: 37 | loss: 0.4480766
	speed: 0.0133s/iter; left time: 411.9153s
	iters: 400, epoch: 37 | loss: 0.3917524
	speed: 0.0131s/iter; left time: 404.4667s
Epoch: 37 cost time: 6.647876262664795
Epoch: 37, Steps: 487 Train Loss: 0.3955 (Forecasting Loss:0.3931 + XiCon Loss:2.4447 x Lambda(0.001)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5081
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3418334
	speed: 0.0155s/iter; left time: 473.0555s
	iters: 200, epoch: 38 | loss: 0.3352109
	speed: 0.0131s/iter; left time: 399.7453s
	iters: 300, epoch: 38 | loss: 0.4190717
	speed: 0.0129s/iter; left time: 390.9906s
	iters: 400, epoch: 38 | loss: 0.4245715
	speed: 0.0131s/iter; left time: 396.5351s
Epoch: 38 cost time: 6.621740341186523
Epoch: 38, Steps: 487 Train Loss: 0.3954 (Forecasting Loss:0.3930 + XiCon Loss:2.4528 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5081
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5131556391716003, mae:0.5030024647712708, mape:3.5701611042022705, mspe:1174.445068359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.5687
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.8518750
	speed: 0.0162s/iter; left time: 788.4316s
	iters: 200, epoch: 1 | loss: 0.8170758
	speed: 0.0135s/iter; left time: 656.1755s
	iters: 300, epoch: 1 | loss: 0.7194508
	speed: 0.0131s/iter; left time: 635.1720s
	iters: 400, epoch: 1 | loss: 0.6390963
	speed: 0.0137s/iter; left time: 663.8403s
Epoch: 1 cost time: 6.8326756954193115
Epoch: 1, Steps: 487 Train Loss: 0.7553 (Forecasting Loss:0.7529 + XiCon Loss:2.4877 x Lambda(0.001)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005156).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.4990107
	speed: 0.0155s/iter; left time: 745.8908s
	iters: 200, epoch: 2 | loss: 0.4120987
	speed: 0.0126s/iter; left time: 603.5197s
	iters: 300, epoch: 2 | loss: 0.5535015
	speed: 0.0131s/iter; left time: 629.7824s
	iters: 400, epoch: 2 | loss: 0.4003297
	speed: 0.0133s/iter; left time: 635.8450s
Epoch: 2 cost time: 6.628600835800171
Epoch: 2, Steps: 487 Train Loss: 0.4386 (Forecasting Loss:0.4362 + XiCon Loss:2.4832 x Lambda(0.001)), Vali MSE Loss: 0.7604 Test MSE Loss: 0.5393
Validation loss decreased (1.005156 --> 0.760379).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.4555326
	speed: 0.0152s/iter; left time: 721.9373s
	iters: 200, epoch: 3 | loss: 0.3830076
	speed: 0.0129s/iter; left time: 612.7736s
	iters: 300, epoch: 3 | loss: 0.4815201
	speed: 0.0132s/iter; left time: 625.0422s
	iters: 400, epoch: 3 | loss: 0.3579211
	speed: 0.0129s/iter; left time: 610.7978s
Epoch: 3 cost time: 6.602270841598511
Epoch: 3, Steps: 487 Train Loss: 0.4086 (Forecasting Loss:0.4062 + XiCon Loss:2.4810 x Lambda(0.001)), Vali MSE Loss: 0.7457 Test MSE Loss: 0.5193
Validation loss decreased (0.760379 --> 0.745693).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.4864316
	speed: 0.0149s/iter; left time: 703.7944s
	iters: 200, epoch: 4 | loss: 0.4018410
	speed: 0.0132s/iter; left time: 621.9433s
	iters: 300, epoch: 4 | loss: 0.3939881
	speed: 0.0127s/iter; left time: 596.8836s
	iters: 400, epoch: 4 | loss: 0.2930693
	speed: 0.0133s/iter; left time: 623.2074s
Epoch: 4 cost time: 6.617228031158447
Epoch: 4, Steps: 487 Train Loss: 0.4028 (Forecasting Loss:0.4003 + XiCon Loss:2.4755 x Lambda(0.001)), Vali MSE Loss: 0.7461 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.3608167
	speed: 0.0151s/iter; left time: 706.3173s
	iters: 200, epoch: 5 | loss: 0.4627971
	speed: 0.0127s/iter; left time: 590.0822s
	iters: 300, epoch: 5 | loss: 0.3827806
	speed: 0.0136s/iter; left time: 630.4913s
	iters: 400, epoch: 5 | loss: 0.4471165
	speed: 0.0131s/iter; left time: 606.4216s
Epoch: 5 cost time: 6.708275318145752
Epoch: 5, Steps: 487 Train Loss: 0.4007 (Forecasting Loss:0.3982 + XiCon Loss:2.4781 x Lambda(0.001)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5125
Validation loss decreased (0.745693 --> 0.738972).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.4466685
	speed: 0.0157s/iter; left time: 722.5853s
	iters: 200, epoch: 6 | loss: 0.4225940
	speed: 0.0137s/iter; left time: 629.5186s
	iters: 300, epoch: 6 | loss: 0.5711768
	speed: 0.0128s/iter; left time: 587.8227s
	iters: 400, epoch: 6 | loss: 0.4660342
	speed: 0.0130s/iter; left time: 598.1602s
Epoch: 6 cost time: 6.7138307094573975
Epoch: 6, Steps: 487 Train Loss: 0.3994 (Forecasting Loss:0.3969 + XiCon Loss:2.4816 x Lambda(0.001)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5117
Validation loss decreased (0.738972 --> 0.738452).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.3285206
	speed: 0.0154s/iter; left time: 702.4563s
	iters: 200, epoch: 7 | loss: 0.3598808
	speed: 0.0129s/iter; left time: 587.3561s
	iters: 300, epoch: 7 | loss: 0.3203539
	speed: 0.0129s/iter; left time: 588.3058s
	iters: 400, epoch: 7 | loss: 0.3522828
	speed: 0.0131s/iter; left time: 595.7858s
Epoch: 7 cost time: 6.599984407424927
Epoch: 7, Steps: 487 Train Loss: 0.3990 (Forecasting Loss:0.3965 + XiCon Loss:2.4763 x Lambda(0.001)), Vali MSE Loss: 0.7382 Test MSE Loss: 0.5125
Validation loss decreased (0.738452 --> 0.738171).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.3557644
	speed: 0.0149s/iter; left time: 673.0215s
	iters: 200, epoch: 8 | loss: 0.3868268
	speed: 0.0127s/iter; left time: 571.2864s
	iters: 300, epoch: 8 | loss: 0.5486975
	speed: 0.0132s/iter; left time: 594.5517s
	iters: 400, epoch: 8 | loss: 0.4300193
	speed: 0.0134s/iter; left time: 599.5524s
Epoch: 8 cost time: 6.575334310531616
Epoch: 8, Steps: 487 Train Loss: 0.3986 (Forecasting Loss:0.3961 + XiCon Loss:2.4779 x Lambda(0.001)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5118
Validation loss decreased (0.738171 --> 0.737651).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.3582687
	speed: 0.0155s/iter; left time: 693.5418s
	iters: 200, epoch: 9 | loss: 0.4865317
	speed: 0.0124s/iter; left time: 555.2033s
	iters: 300, epoch: 9 | loss: 0.4710067
	speed: 0.0134s/iter; left time: 595.9145s
	iters: 400, epoch: 9 | loss: 0.4064221
	speed: 0.0132s/iter; left time: 587.3833s
Epoch: 9 cost time: 6.65869665145874
Epoch: 9, Steps: 487 Train Loss: 0.3985 (Forecasting Loss:0.3960 + XiCon Loss:2.4791 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5119
Validation loss decreased (0.737651 --> 0.737572).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.3652267
	speed: 0.0153s/iter; left time: 676.9134s
	iters: 200, epoch: 10 | loss: 0.4622439
	speed: 0.0124s/iter; left time: 549.1384s
	iters: 300, epoch: 10 | loss: 0.3822289
	speed: 0.0136s/iter; left time: 598.3207s
	iters: 400, epoch: 10 | loss: 0.4092723
	speed: 0.0129s/iter; left time: 564.6761s
Epoch: 10 cost time: 6.599413156509399
Epoch: 10, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3959 + XiCon Loss:2.4815 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
Validation loss decreased (0.737572 --> 0.737542).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.3787995
	speed: 0.0160s/iter; left time: 698.4022s
	iters: 200, epoch: 11 | loss: 0.4079839
	speed: 0.0126s/iter; left time: 549.1552s
	iters: 300, epoch: 11 | loss: 0.3406210
	speed: 0.0130s/iter; left time: 565.9750s
	iters: 400, epoch: 11 | loss: 0.3985815
	speed: 0.0134s/iter; left time: 582.4267s
Epoch: 11 cost time: 6.655318737030029
Epoch: 11, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4774 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.4405406
	speed: 0.0151s/iter; left time: 655.0984s
	iters: 200, epoch: 12 | loss: 0.2714507
	speed: 0.0130s/iter; left time: 560.8825s
	iters: 300, epoch: 12 | loss: 0.4041055
	speed: 0.0131s/iter; left time: 564.6337s
	iters: 400, epoch: 12 | loss: 0.4360392
	speed: 0.0135s/iter; left time: 579.2521s
Epoch: 12 cost time: 6.698853492736816
Epoch: 12, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4738 x Lambda(0.001)), Vali MSE Loss: 0.7372 Test MSE Loss: 0.5117
Validation loss decreased (0.737542 --> 0.737225).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.3725348
	speed: 0.0156s/iter; left time: 667.6660s
	iters: 200, epoch: 13 | loss: 0.3217352
	speed: 0.0135s/iter; left time: 577.9849s
	iters: 300, epoch: 13 | loss: 0.3902454
	speed: 0.0131s/iter; left time: 558.3386s
	iters: 400, epoch: 13 | loss: 0.3838934
	speed: 0.0131s/iter; left time: 556.6114s
Epoch: 13 cost time: 6.721210479736328
Epoch: 13, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4807 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.3528345
	speed: 0.0151s/iter; left time: 640.3843s
	iters: 200, epoch: 14 | loss: 0.3460436
	speed: 0.0125s/iter; left time: 529.2209s
	iters: 300, epoch: 14 | loss: 0.3810323
	speed: 0.0133s/iter; left time: 560.9537s
	iters: 400, epoch: 14 | loss: 0.3659655
	speed: 0.0137s/iter; left time: 574.9000s
Epoch: 14 cost time: 6.651026248931885
Epoch: 14, Steps: 487 Train Loss: 0.3981 (Forecasting Loss:0.3956 + XiCon Loss:2.4805 x Lambda(0.001)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.3936392
	speed: 0.0155s/iter; left time: 648.2326s
	iters: 200, epoch: 15 | loss: 0.3787907
	speed: 0.0125s/iter; left time: 522.9467s
	iters: 300, epoch: 15 | loss: 0.3959295
	speed: 0.0130s/iter; left time: 541.9175s
	iters: 400, epoch: 15 | loss: 0.4416268
	speed: 0.0130s/iter; left time: 538.2910s
Epoch: 15 cost time: 6.58120584487915
Epoch: 15, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4820 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.4249115
	speed: 0.0151s/iter; left time: 623.1418s
	iters: 200, epoch: 16 | loss: 0.3687088
	speed: 0.0125s/iter; left time: 515.5329s
	iters: 300, epoch: 16 | loss: 0.4673136
	speed: 0.0139s/iter; left time: 571.3690s
	iters: 400, epoch: 16 | loss: 0.4062137
	speed: 0.0132s/iter; left time: 541.2844s
Epoch: 16 cost time: 6.685049057006836
Epoch: 16, Steps: 487 Train Loss: 0.3985 (Forecasting Loss:0.3960 + XiCon Loss:2.4760 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.3121065
	speed: 0.0163s/iter; left time: 665.7188s
	iters: 200, epoch: 17 | loss: 0.3812788
	speed: 0.0133s/iter; left time: 541.1914s
	iters: 300, epoch: 17 | loss: 0.3460595
	speed: 0.0128s/iter; left time: 518.0669s
	iters: 400, epoch: 17 | loss: 0.3210565
	speed: 0.0127s/iter; left time: 513.3576s
Epoch: 17 cost time: 6.692525863647461
Epoch: 17, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4766 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.4071309
	speed: 0.0153s/iter; left time: 617.8376s
	iters: 200, epoch: 18 | loss: 0.3918926
	speed: 0.0128s/iter; left time: 513.7924s
	iters: 300, epoch: 18 | loss: 0.4108398
	speed: 0.0129s/iter; left time: 517.3073s
	iters: 400, epoch: 18 | loss: 0.3230206
	speed: 0.0129s/iter; left time: 516.7790s
Epoch: 18 cost time: 6.553140163421631
Epoch: 18, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3959 + XiCon Loss:2.4783 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.4224069
	speed: 0.0155s/iter; left time: 616.5692s
	iters: 200, epoch: 19 | loss: 0.4452159
	speed: 0.0128s/iter; left time: 509.5171s
	iters: 300, epoch: 19 | loss: 0.3315111
	speed: 0.0127s/iter; left time: 502.4746s
	iters: 400, epoch: 19 | loss: 0.4746902
	speed: 0.0133s/iter; left time: 526.0187s
Epoch: 19 cost time: 6.62553334236145
Epoch: 19, Steps: 487 Train Loss: 0.3982 (Forecasting Loss:0.3958 + XiCon Loss:2.4769 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.3923642
	speed: 0.0160s/iter; left time: 629.3634s
	iters: 200, epoch: 20 | loss: 0.3347810
	speed: 0.0134s/iter; left time: 526.0101s
	iters: 300, epoch: 20 | loss: 0.5327249
	speed: 0.0131s/iter; left time: 513.9719s
	iters: 400, epoch: 20 | loss: 0.4158227
	speed: 0.0134s/iter; left time: 523.3697s
Epoch: 20 cost time: 6.836891174316406
Epoch: 20, Steps: 487 Train Loss: 0.3982 (Forecasting Loss:0.3957 + XiCon Loss:2.4792 x Lambda(0.001)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5117
Validation loss decreased (0.737225 --> 0.736919).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.4189371
	speed: 0.0157s/iter; left time: 609.7496s
	iters: 200, epoch: 21 | loss: 0.3429310
	speed: 0.0135s/iter; left time: 523.5575s
	iters: 300, epoch: 21 | loss: 0.3414484
	speed: 0.0132s/iter; left time: 511.5504s
	iters: 400, epoch: 21 | loss: 0.3919318
	speed: 0.0129s/iter; left time: 496.4818s
Epoch: 21 cost time: 6.663103103637695
Epoch: 21, Steps: 487 Train Loss: 0.3982 (Forecasting Loss:0.3957 + XiCon Loss:2.4777 x Lambda(0.001)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.4019495
	speed: 0.0153s/iter; left time: 585.4828s
	iters: 200, epoch: 22 | loss: 0.3757854
	speed: 0.0128s/iter; left time: 489.4259s
	iters: 300, epoch: 22 | loss: 0.3832090
	speed: 0.0128s/iter; left time: 488.0205s
	iters: 400, epoch: 22 | loss: 0.3988005
	speed: 0.0127s/iter; left time: 483.9229s
Epoch: 22 cost time: 6.538147449493408
Epoch: 22, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4759 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.4062924
	speed: 0.0151s/iter; left time: 570.7543s
	iters: 200, epoch: 23 | loss: 0.4560126
	speed: 0.0134s/iter; left time: 507.8085s
	iters: 300, epoch: 23 | loss: 0.4249278
	speed: 0.0132s/iter; left time: 496.7302s
	iters: 400, epoch: 23 | loss: 0.4259023
	speed: 0.0138s/iter; left time: 518.0615s
Epoch: 23 cost time: 6.69916844367981
Epoch: 23, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4766 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.4411945
	speed: 0.0148s/iter; left time: 551.8617s
	iters: 200, epoch: 24 | loss: 0.4250607
	speed: 0.0131s/iter; left time: 486.8599s
	iters: 300, epoch: 24 | loss: 0.4053639
	speed: 0.0134s/iter; left time: 499.7048s
	iters: 400, epoch: 24 | loss: 0.3600921
	speed: 0.0128s/iter; left time: 473.4248s
Epoch: 24 cost time: 6.568958520889282
Epoch: 24, Steps: 487 Train Loss: 0.3985 (Forecasting Loss:0.3960 + XiCon Loss:2.4752 x Lambda(0.001)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5117
Validation loss decreased (0.736919 --> 0.736799).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.4289293
	speed: 0.0153s/iter; left time: 565.2401s
	iters: 200, epoch: 25 | loss: 0.4234875
	speed: 0.0132s/iter; left time: 484.2432s
	iters: 300, epoch: 25 | loss: 0.4024256
	speed: 0.0130s/iter; left time: 475.4645s
	iters: 400, epoch: 25 | loss: 0.4568765
	speed: 0.0130s/iter; left time: 477.2548s
Epoch: 25 cost time: 6.627516269683838
Epoch: 25, Steps: 487 Train Loss: 0.3985 (Forecasting Loss:0.3960 + XiCon Loss:2.4807 x Lambda(0.001)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.4743313
	speed: 0.0157s/iter; left time: 572.0011s
	iters: 200, epoch: 26 | loss: 0.4179091
	speed: 0.0132s/iter; left time: 477.8190s
	iters: 300, epoch: 26 | loss: 0.3437349
	speed: 0.0133s/iter; left time: 483.0502s
	iters: 400, epoch: 26 | loss: 0.3763797
	speed: 0.0126s/iter; left time: 455.0069s
Epoch: 26 cost time: 6.691565275192261
Epoch: 26, Steps: 487 Train Loss: 0.3982 (Forecasting Loss:0.3957 + XiCon Loss:2.4775 x Lambda(0.001)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.4300986
	speed: 0.0149s/iter; left time: 536.4441s
	iters: 200, epoch: 27 | loss: 0.5396972
	speed: 0.0129s/iter; left time: 460.5578s
	iters: 300, epoch: 27 | loss: 0.3792588
	speed: 0.0131s/iter; left time: 468.1670s
	iters: 400, epoch: 27 | loss: 0.3393959
	speed: 0.0129s/iter; left time: 459.8507s
Epoch: 27 cost time: 6.567673444747925
Epoch: 27, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4775 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.3362580
	speed: 0.0151s/iter; left time: 534.6775s
	iters: 200, epoch: 28 | loss: 0.3465979
	speed: 0.0134s/iter; left time: 473.7526s
	iters: 300, epoch: 28 | loss: 0.4221198
	speed: 0.0133s/iter; left time: 467.2890s
	iters: 400, epoch: 28 | loss: 0.4147306
	speed: 0.0132s/iter; left time: 463.0282s
Epoch: 28 cost time: 6.651691436767578
Epoch: 28, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4765 x Lambda(0.001)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.3562236
	speed: 0.0155s/iter; left time: 543.5723s
	iters: 200, epoch: 29 | loss: 0.3775812
	speed: 0.0132s/iter; left time: 460.5705s
	iters: 300, epoch: 29 | loss: 0.4280312
	speed: 0.0131s/iter; left time: 453.8629s
	iters: 400, epoch: 29 | loss: 0.3644562
	speed: 0.0128s/iter; left time: 443.0392s
Epoch: 29 cost time: 6.6254918575286865
Epoch: 29, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4789 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.3641865
	speed: 0.0147s/iter; left time: 506.2123s
	iters: 200, epoch: 30 | loss: 0.3746895
	speed: 0.0131s/iter; left time: 448.9521s
	iters: 300, epoch: 30 | loss: 0.3184710
	speed: 0.0129s/iter; left time: 440.8212s
	iters: 400, epoch: 30 | loss: 0.3517373
	speed: 0.0130s/iter; left time: 445.1769s
Epoch: 30 cost time: 6.5524232387542725
Epoch: 30, Steps: 487 Train Loss: 0.3981 (Forecasting Loss:0.3956 + XiCon Loss:2.4818 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.3790572
	speed: 0.0147s/iter; left time: 498.7464s
	iters: 200, epoch: 31 | loss: 0.3983246
	speed: 0.0128s/iter; left time: 435.1903s
	iters: 300, epoch: 31 | loss: 0.2993851
	speed: 0.0134s/iter; left time: 453.7992s
	iters: 400, epoch: 31 | loss: 0.3514171
	speed: 0.0136s/iter; left time: 457.4695s
Epoch: 31 cost time: 6.613463878631592
Epoch: 31, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4814 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.4111934
	speed: 0.0155s/iter; left time: 520.4673s
	iters: 200, epoch: 32 | loss: 0.4261187
	speed: 0.0130s/iter; left time: 435.4684s
	iters: 300, epoch: 32 | loss: 0.3432834
	speed: 0.0131s/iter; left time: 435.9911s
	iters: 400, epoch: 32 | loss: 0.4238658
	speed: 0.0131s/iter; left time: 435.6025s
Epoch: 32 cost time: 6.684986114501953
Epoch: 32, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4831 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.3854192
	speed: 0.0158s/iter; left time: 521.9254s
	iters: 200, epoch: 33 | loss: 0.4589876
	speed: 0.0130s/iter; left time: 428.9483s
	iters: 300, epoch: 33 | loss: 0.3516792
	speed: 0.0127s/iter; left time: 415.9350s
	iters: 400, epoch: 33 | loss: 0.4529820
	speed: 0.0132s/iter; left time: 430.3914s
Epoch: 33 cost time: 6.636666774749756
Epoch: 33, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3959 + XiCon Loss:2.4771 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.3908404
	speed: 0.0152s/iter; left time: 493.4797s
	iters: 200, epoch: 34 | loss: 0.4538535
	speed: 0.0129s/iter; left time: 418.2840s
	iters: 300, epoch: 34 | loss: 0.4125868
	speed: 0.0132s/iter; left time: 425.3488s
	iters: 400, epoch: 34 | loss: 0.3935539
	speed: 0.0130s/iter; left time: 420.2866s
Epoch: 34 cost time: 6.639384508132935
Epoch: 34, Steps: 487 Train Loss: 0.3981 (Forecasting Loss:0.3956 + XiCon Loss:2.4788 x Lambda(0.001)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5117
Validation loss decreased (0.736799 --> 0.736484).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.3739684
	speed: 0.0154s/iter; left time: 492.7761s
	iters: 200, epoch: 35 | loss: 0.3730111
	speed: 0.0135s/iter; left time: 430.2738s
	iters: 300, epoch: 35 | loss: 0.4300444
	speed: 0.0132s/iter; left time: 419.5832s
	iters: 400, epoch: 35 | loss: 0.3476167
	speed: 0.0130s/iter; left time: 413.0752s
Epoch: 35 cost time: 6.694601535797119
Epoch: 35, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4836 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.4693026
	speed: 0.0151s/iter; left time: 476.6396s
	iters: 200, epoch: 36 | loss: 0.3208032
	speed: 0.0134s/iter; left time: 420.4070s
	iters: 300, epoch: 36 | loss: 0.3434730
	speed: 0.0132s/iter; left time: 412.4741s
	iters: 400, epoch: 36 | loss: 0.3996862
	speed: 0.0136s/iter; left time: 426.1541s
Epoch: 36 cost time: 6.718282461166382
Epoch: 36, Steps: 487 Train Loss: 0.3981 (Forecasting Loss:0.3956 + XiCon Loss:2.4783 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.4409920
	speed: 0.0153s/iter; left time: 476.0599s
	iters: 200, epoch: 37 | loss: 0.3712139
	speed: 0.0129s/iter; left time: 399.4868s
	iters: 300, epoch: 37 | loss: 0.3758465
	speed: 0.0132s/iter; left time: 406.9206s
	iters: 400, epoch: 37 | loss: 0.4892534
	speed: 0.0134s/iter; left time: 411.2167s
Epoch: 37 cost time: 6.642515420913696
Epoch: 37, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3959 + XiCon Loss:2.4795 x Lambda(0.001)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5117
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.3700184
	speed: 0.0152s/iter; left time: 465.1404s
	iters: 200, epoch: 38 | loss: 0.4072611
	speed: 0.0135s/iter; left time: 410.8493s
	iters: 300, epoch: 38 | loss: 0.3838370
	speed: 0.0132s/iter; left time: 401.8789s
	iters: 400, epoch: 38 | loss: 0.4307872
	speed: 0.0135s/iter; left time: 407.7238s
Epoch: 38 cost time: 6.722676992416382
Epoch: 38, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4832 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.4706076
	speed: 0.0156s/iter; left time: 469.5809s
	iters: 200, epoch: 39 | loss: 0.3446541
	speed: 0.0134s/iter; left time: 400.8582s
	iters: 300, epoch: 39 | loss: 0.4485953
	speed: 0.0131s/iter; left time: 391.1974s
	iters: 400, epoch: 39 | loss: 0.4006020
	speed: 0.0131s/iter; left time: 391.4582s
Epoch: 39 cost time: 6.693066835403442
Epoch: 39, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4801 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.4672484
	speed: 0.0152s/iter; left time: 451.3993s
	iters: 200, epoch: 40 | loss: 0.4160635
	speed: 0.0131s/iter; left time: 387.9711s
	iters: 300, epoch: 40 | loss: 0.3818215
	speed: 0.0133s/iter; left time: 391.6773s
	iters: 400, epoch: 40 | loss: 0.4460947
	speed: 0.0128s/iter; left time: 374.9678s
Epoch: 40 cost time: 6.617552280426025
Epoch: 40, Steps: 487 Train Loss: 0.3985 (Forecasting Loss:0.3960 + XiCon Loss:2.4765 x Lambda(0.001)), Vali MSE Loss: 0.7374 Test MSE Loss: 0.5117
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.3779897
	speed: 0.0156s/iter; left time: 454.3985s
	iters: 200, epoch: 41 | loss: 0.3781483
	speed: 0.0126s/iter; left time: 366.3003s
	iters: 300, epoch: 41 | loss: 0.4272243
	speed: 0.0133s/iter; left time: 384.0419s
	iters: 400, epoch: 41 | loss: 0.4017508
	speed: 0.0127s/iter; left time: 366.0964s
Epoch: 41 cost time: 6.58244514465332
Epoch: 41, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4766 x Lambda(0.001)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5117
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.3383455
	speed: 0.0152s/iter; left time: 433.9142s
	iters: 200, epoch: 42 | loss: 0.3717873
	speed: 0.0127s/iter; left time: 363.7181s
	iters: 300, epoch: 42 | loss: 0.4323796
	speed: 0.0131s/iter; left time: 373.0279s
	iters: 400, epoch: 42 | loss: 0.4686004
	speed: 0.0131s/iter; left time: 371.5883s
Epoch: 42 cost time: 6.616035461425781
Epoch: 42, Steps: 487 Train Loss: 0.3983 (Forecasting Loss:0.3958 + XiCon Loss:2.4796 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.3560105
	speed: 0.0151s/iter; left time: 425.0007s
	iters: 200, epoch: 43 | loss: 0.4588705
	speed: 0.0133s/iter; left time: 374.2682s
	iters: 300, epoch: 43 | loss: 0.3992366
	speed: 0.0136s/iter; left time: 379.8336s
	iters: 400, epoch: 43 | loss: 0.4095348
	speed: 0.0132s/iter; left time: 366.6948s
Epoch: 43 cost time: 6.696784257888794
Epoch: 43, Steps: 487 Train Loss: 0.3984 (Forecasting Loss:0.3960 + XiCon Loss:2.4848 x Lambda(0.001)), Vali MSE Loss: 0.7376 Test MSE Loss: 0.5117
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.3990016
	speed: 0.0150s/iter; left time: 413.9550s
	iters: 200, epoch: 44 | loss: 0.4450397
	speed: 0.0129s/iter; left time: 354.7409s
	iters: 300, epoch: 44 | loss: 0.5087560
	speed: 0.0136s/iter; left time: 372.6096s
	iters: 400, epoch: 44 | loss: 0.4511143
	speed: 0.0134s/iter; left time: 367.5683s
Epoch: 44 cost time: 6.661841154098511
Epoch: 44, Steps: 487 Train Loss: 0.3982 (Forecasting Loss:0.3957 + XiCon Loss:2.4790 x Lambda(0.001)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5117
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5181376338005066, mae:0.5052026510238647, mape:3.480217695236206, mspe:1100.9866943359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5201+-0.00784, MAE:0.5064+-0.00411, MAPE:3.5274+-0.08311, MSPE:1146.7595+-68.22477, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.1379
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9323404
	speed: 0.0293s/iter; left time: 694.4278s
	iters: 200, epoch: 1 | loss: 0.9556950
	speed: 0.0220s/iter; left time: 519.3533s
Epoch: 1 cost time: 6.026588678359985
Epoch: 1, Steps: 238 Train Loss: 0.9829 (Forecasting Loss:0.9803 + XiCon Loss:2.5863 x Lambda(0.001)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755405).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6104466
	speed: 0.0252s/iter; left time: 591.0216s
	iters: 200, epoch: 2 | loss: 0.5865141
	speed: 0.0225s/iter; left time: 525.7604s
Epoch: 2 cost time: 5.675073862075806
Epoch: 2, Steps: 238 Train Loss: 0.6195 (Forecasting Loss:0.6169 + XiCon Loss:2.5861 x Lambda(0.001)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.8581
Validation loss decreased (1.755405 --> 1.036745).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5608016
	speed: 0.0242s/iter; left time: 562.6811s
	iters: 200, epoch: 3 | loss: 0.5674037
	speed: 0.0223s/iter; left time: 516.3180s
Epoch: 3 cost time: 5.5554914474487305
Epoch: 3, Steps: 238 Train Loss: 0.5553 (Forecasting Loss:0.5527 + XiCon Loss:2.5899 x Lambda(0.001)), Vali MSE Loss: 1.0178 Test MSE Loss: 0.8517
Validation loss decreased (1.036745 --> 1.017848).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5413929
	speed: 0.0254s/iter; left time: 584.3239s
	iters: 200, epoch: 4 | loss: 0.5073633
	speed: 0.0227s/iter; left time: 520.4317s
Epoch: 4 cost time: 5.747405290603638
Epoch: 4, Steps: 238 Train Loss: 0.5472 (Forecasting Loss:0.5446 + XiCon Loss:2.5868 x Lambda(0.001)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8495
Validation loss decreased (1.017848 --> 1.010501).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5239304
	speed: 0.0256s/iter; left time: 583.3011s
	iters: 200, epoch: 5 | loss: 0.5708964
	speed: 0.0232s/iter; left time: 524.3422s
Epoch: 5 cost time: 5.7388505935668945
Epoch: 5, Steps: 238 Train Loss: 0.5440 (Forecasting Loss:0.5414 + XiCon Loss:2.5888 x Lambda(0.001)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8492
Validation loss decreased (1.010501 --> 1.007456).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5314211
	speed: 0.0256s/iter; left time: 576.1170s
	iters: 200, epoch: 6 | loss: 0.5448982
	speed: 0.0226s/iter; left time: 505.7795s
Epoch: 6 cost time: 5.693154573440552
Epoch: 6, Steps: 238 Train Loss: 0.5425 (Forecasting Loss:0.5400 + XiCon Loss:2.5854 x Lambda(0.001)), Vali MSE Loss: 1.0061 Test MSE Loss: 0.8489
Validation loss decreased (1.007456 --> 1.006142).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5333038
	speed: 0.0257s/iter; left time: 571.7896s
	iters: 200, epoch: 7 | loss: 0.5440406
	speed: 0.0236s/iter; left time: 523.0093s
Epoch: 7 cost time: 5.864686965942383
Epoch: 7, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5392 + XiCon Loss:2.5900 x Lambda(0.001)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8488
Validation loss decreased (1.006142 --> 1.004464).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4956586
	speed: 0.0249s/iter; left time: 549.5147s
	iters: 200, epoch: 8 | loss: 0.5685471
	speed: 0.0230s/iter; left time: 505.5033s
Epoch: 8 cost time: 5.725095748901367
Epoch: 8, Steps: 238 Train Loss: 0.5413 (Forecasting Loss:0.5387 + XiCon Loss:2.5849 x Lambda(0.001)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8487
Validation loss decreased (1.004464 --> 1.004394).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5716677
	speed: 0.0257s/iter; left time: 559.3487s
	iters: 200, epoch: 9 | loss: 0.5911750
	speed: 0.0229s/iter; left time: 495.8282s
Epoch: 9 cost time: 5.73368763923645
Epoch: 9, Steps: 238 Train Loss: 0.5412 (Forecasting Loss:0.5387 + XiCon Loss:2.5897 x Lambda(0.001)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8487
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5300663
	speed: 0.0250s/iter; left time: 538.4706s
	iters: 200, epoch: 10 | loss: 0.5605513
	speed: 0.0222s/iter; left time: 477.4338s
Epoch: 10 cost time: 5.630969762802124
Epoch: 10, Steps: 238 Train Loss: 0.5411 (Forecasting Loss:0.5385 + XiCon Loss:2.5920 x Lambda(0.001)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8487
Validation loss decreased (1.004394 --> 1.004331).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.4992888
	speed: 0.0254s/iter; left time: 542.2996s
	iters: 200, epoch: 11 | loss: 0.5603869
	speed: 0.0234s/iter; left time: 495.8132s
Epoch: 11 cost time: 5.806842088699341
Epoch: 11, Steps: 238 Train Loss: 0.5408 (Forecasting Loss:0.5382 + XiCon Loss:2.5867 x Lambda(0.001)), Vali MSE Loss: 1.0036 Test MSE Loss: 0.8487
Validation loss decreased (1.004331 --> 1.003556).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5604773
	speed: 0.0255s/iter; left time: 537.2328s
	iters: 200, epoch: 12 | loss: 0.5109563
	speed: 0.0232s/iter; left time: 487.0131s
Epoch: 12 cost time: 5.828433036804199
Epoch: 12, Steps: 238 Train Loss: 0.5408 (Forecasting Loss:0.5382 + XiCon Loss:2.5885 x Lambda(0.001)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8487
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5436493
	speed: 0.0254s/iter; left time: 529.4062s
	iters: 200, epoch: 13 | loss: 0.5336488
	speed: 0.0230s/iter; left time: 476.6714s
Epoch: 13 cost time: 5.7186949253082275
Epoch: 13, Steps: 238 Train Loss: 0.5409 (Forecasting Loss:0.5383 + XiCon Loss:2.5882 x Lambda(0.001)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8487
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4538667
	speed: 0.0251s/iter; left time: 516.6700s
	iters: 200, epoch: 14 | loss: 0.5365905
	speed: 0.0229s/iter; left time: 470.4793s
Epoch: 14 cost time: 5.730526685714722
Epoch: 14, Steps: 238 Train Loss: 0.5407 (Forecasting Loss:0.5382 + XiCon Loss:2.5849 x Lambda(0.001)), Vali MSE Loss: 1.0042 Test MSE Loss: 0.8487
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5429983
	speed: 0.0246s/iter; left time: 501.1242s
	iters: 200, epoch: 15 | loss: 0.5433851
	speed: 0.0224s/iter; left time: 454.6031s
Epoch: 15 cost time: 5.583443641662598
Epoch: 15, Steps: 238 Train Loss: 0.5408 (Forecasting Loss:0.5382 + XiCon Loss:2.5818 x Lambda(0.001)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8487
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5034792
	speed: 0.0249s/iter; left time: 502.2536s
	iters: 200, epoch: 16 | loss: 0.5338377
	speed: 0.0231s/iter; left time: 462.9183s
Epoch: 16 cost time: 5.736676454544067
Epoch: 16, Steps: 238 Train Loss: 0.5411 (Forecasting Loss:0.5385 + XiCon Loss:2.5840 x Lambda(0.001)), Vali MSE Loss: 1.0043 Test MSE Loss: 0.8487
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5334185
	speed: 0.0268s/iter; left time: 532.8641s
	iters: 200, epoch: 17 | loss: 0.5409203
	speed: 0.0230s/iter; left time: 455.9083s
Epoch: 17 cost time: 5.902909755706787
Epoch: 17, Steps: 238 Train Loss: 0.5406 (Forecasting Loss:0.5380 + XiCon Loss:2.5923 x Lambda(0.001)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8487
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5059729
	speed: 0.0257s/iter; left time: 505.5806s
	iters: 200, epoch: 18 | loss: 0.4757398
	speed: 0.0229s/iter; left time: 448.3768s
Epoch: 18 cost time: 5.789441108703613
Epoch: 18, Steps: 238 Train Loss: 0.5408 (Forecasting Loss:0.5382 + XiCon Loss:2.5863 x Lambda(0.001)), Vali MSE Loss: 1.0048 Test MSE Loss: 0.8487
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5434452
	speed: 0.0250s/iter; left time: 484.4661s
	iters: 200, epoch: 19 | loss: 0.5356449
	speed: 0.0238s/iter; left time: 458.7814s
Epoch: 19 cost time: 5.826700210571289
Epoch: 19, Steps: 238 Train Loss: 0.5410 (Forecasting Loss:0.5384 + XiCon Loss:2.5861 x Lambda(0.001)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8487
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5190521
	speed: 0.0253s/iter; left time: 484.3033s
	iters: 200, epoch: 20 | loss: 0.5511760
	speed: 0.0230s/iter; left time: 438.7322s
Epoch: 20 cost time: 5.715249300003052
Epoch: 20, Steps: 238 Train Loss: 0.5407 (Forecasting Loss:0.5381 + XiCon Loss:2.5911 x Lambda(0.001)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8487
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.4955346
	speed: 0.0256s/iter; left time: 485.6859s
	iters: 200, epoch: 21 | loss: 0.5524434
	speed: 0.0227s/iter; left time: 428.3955s
Epoch: 21 cost time: 5.787757396697998
Epoch: 21, Steps: 238 Train Loss: 0.5410 (Forecasting Loss:0.5384 + XiCon Loss:2.5882 x Lambda(0.001)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8487
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9779223799705505, mae:0.7194837927818298, mape:4.779935836791992, mspe:2693.31494140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.3577
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0879569
	speed: 0.0274s/iter; left time: 648.4206s
	iters: 200, epoch: 1 | loss: 1.1615415
	speed: 0.0240s/iter; left time: 565.8964s
Epoch: 1 cost time: 6.054503440856934
Epoch: 1, Steps: 238 Train Loss: 1.1018 (Forecasting Loss:1.0993 + XiCon Loss:2.5769 x Lambda(0.001)), Vali MSE Loss: 1.9677 Test MSE Loss: 1.0361
Validation loss decreased (inf --> 1.967718).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6282471
	speed: 0.0256s/iter; left time: 601.3546s
	iters: 200, epoch: 2 | loss: 0.5442210
	speed: 0.0228s/iter; left time: 531.8342s
Epoch: 2 cost time: 5.756885051727295
Epoch: 2, Steps: 238 Train Loss: 0.6338 (Forecasting Loss:0.6313 + XiCon Loss:2.5717 x Lambda(0.001)), Vali MSE Loss: 1.0220 Test MSE Loss: 0.8588
Validation loss decreased (1.967718 --> 1.021968).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5439922
	speed: 0.0258s/iter; left time: 600.2289s
	iters: 200, epoch: 3 | loss: 0.5269228
	speed: 0.0231s/iter; left time: 535.2460s
Epoch: 3 cost time: 5.817580938339233
Epoch: 3, Steps: 238 Train Loss: 0.5542 (Forecasting Loss:0.5517 + XiCon Loss:2.5682 x Lambda(0.001)), Vali MSE Loss: 1.0007 Test MSE Loss: 0.8528
Validation loss decreased (1.021968 --> 1.000687).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4792004
	speed: 0.0262s/iter; left time: 603.1131s
	iters: 200, epoch: 4 | loss: 0.5630151
	speed: 0.0228s/iter; left time: 521.3659s
Epoch: 4 cost time: 5.8173322677612305
Epoch: 4, Steps: 238 Train Loss: 0.5458 (Forecasting Loss:0.5433 + XiCon Loss:2.5692 x Lambda(0.001)), Vali MSE Loss: 0.9942 Test MSE Loss: 0.8514
Validation loss decreased (1.000687 --> 0.994226).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5701101
	speed: 0.0257s/iter; left time: 584.9865s
	iters: 200, epoch: 5 | loss: 0.5271935
	speed: 0.0231s/iter; left time: 522.4251s
Epoch: 5 cost time: 5.842410564422607
Epoch: 5, Steps: 238 Train Loss: 0.5425 (Forecasting Loss:0.5399 + XiCon Loss:2.5645 x Lambda(0.001)), Vali MSE Loss: 0.9893 Test MSE Loss: 0.8507
Validation loss decreased (0.994226 --> 0.989295).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5188021
	speed: 0.0257s/iter; left time: 578.8214s
	iters: 200, epoch: 6 | loss: 0.5509562
	speed: 0.0232s/iter; left time: 520.8677s
Epoch: 6 cost time: 5.823086738586426
Epoch: 6, Steps: 238 Train Loss: 0.5413 (Forecasting Loss:0.5387 + XiCon Loss:2.5675 x Lambda(0.001)), Vali MSE Loss: 0.9882 Test MSE Loss: 0.8506
Validation loss decreased (0.989295 --> 0.988210).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5423023
	speed: 0.0260s/iter; left time: 578.2910s
	iters: 200, epoch: 7 | loss: 0.5126990
	speed: 0.0235s/iter; left time: 520.5942s
Epoch: 7 cost time: 5.834404468536377
Epoch: 7, Steps: 238 Train Loss: 0.5403 (Forecasting Loss:0.5377 + XiCon Loss:2.5641 x Lambda(0.001)), Vali MSE Loss: 0.9872 Test MSE Loss: 0.8504
Validation loss decreased (0.988210 --> 0.987232).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5467682
	speed: 0.0259s/iter; left time: 571.7362s
	iters: 200, epoch: 8 | loss: 0.5078179
	speed: 0.0228s/iter; left time: 500.7931s
Epoch: 8 cost time: 5.790250301361084
Epoch: 8, Steps: 238 Train Loss: 0.5402 (Forecasting Loss:0.5376 + XiCon Loss:2.5643 x Lambda(0.001)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8504
Validation loss decreased (0.987232 --> 0.987134).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5258016
	speed: 0.0257s/iter; left time: 560.7621s
	iters: 200, epoch: 9 | loss: 0.5776787
	speed: 0.0234s/iter; left time: 508.0043s
Epoch: 9 cost time: 5.841940402984619
Epoch: 9, Steps: 238 Train Loss: 0.5398 (Forecasting Loss:0.5373 + XiCon Loss:2.5660 x Lambda(0.001)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8503
Validation loss decreased (0.987134 --> 0.986120).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5364490
	speed: 0.0257s/iter; left time: 554.6796s
	iters: 200, epoch: 10 | loss: 0.6046009
	speed: 0.0233s/iter; left time: 501.0531s
Epoch: 10 cost time: 5.805967807769775
Epoch: 10, Steps: 238 Train Loss: 0.5397 (Forecasting Loss:0.5371 + XiCon Loss:2.5639 x Lambda(0.001)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8503
Validation loss decreased (0.986120 --> 0.985763).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5432833
	speed: 0.0261s/iter; left time: 555.4749s
	iters: 200, epoch: 11 | loss: 0.5741361
	speed: 0.0223s/iter; left time: 472.7256s
Epoch: 11 cost time: 5.77439284324646
Epoch: 11, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5634 x Lambda(0.001)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8503
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5477025
	speed: 0.0252s/iter; left time: 531.6187s
	iters: 200, epoch: 12 | loss: 0.5002264
	speed: 0.0228s/iter; left time: 478.1056s
Epoch: 12 cost time: 5.57502293586731
Epoch: 12, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5624 x Lambda(0.001)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8503
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5142743
	speed: 0.0256s/iter; left time: 533.8292s
	iters: 200, epoch: 13 | loss: 0.5358602
	speed: 0.0236s/iter; left time: 490.3997s
Epoch: 13 cost time: 5.825167179107666
Epoch: 13, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5668 x Lambda(0.001)), Vali MSE Loss: 0.9867 Test MSE Loss: 0.8503
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.4869502
	speed: 0.0263s/iter; left time: 541.7329s
	iters: 200, epoch: 14 | loss: 0.5267526
	speed: 0.0231s/iter; left time: 474.1914s
Epoch: 14 cost time: 5.86175274848938
Epoch: 14, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5691 x Lambda(0.001)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8503
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5313904
	speed: 0.0259s/iter; left time: 527.4940s
	iters: 200, epoch: 15 | loss: 0.4653855
	speed: 0.0229s/iter; left time: 463.3604s
Epoch: 15 cost time: 5.7891294956207275
Epoch: 15, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5671 x Lambda(0.001)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8503
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5673627
	speed: 0.0258s/iter; left time: 519.0128s
	iters: 200, epoch: 16 | loss: 0.5613665
	speed: 0.0229s/iter; left time: 459.6595s
Epoch: 16 cost time: 5.773046016693115
Epoch: 16, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5370 + XiCon Loss:2.5670 x Lambda(0.001)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8503
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5209408
	speed: 0.0257s/iter; left time: 511.1131s
	iters: 200, epoch: 17 | loss: 0.5704775
	speed: 0.0227s/iter; left time: 449.0398s
Epoch: 17 cost time: 5.727861642837524
Epoch: 17, Steps: 238 Train Loss: 0.5397 (Forecasting Loss:0.5371 + XiCon Loss:2.5607 x Lambda(0.001)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8503
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5599394
	speed: 0.0255s/iter; left time: 500.6840s
	iters: 200, epoch: 18 | loss: 0.6347618
	speed: 0.0230s/iter; left time: 449.6253s
Epoch: 18 cost time: 5.764210939407349
Epoch: 18, Steps: 238 Train Loss: 0.5398 (Forecasting Loss:0.5372 + XiCon Loss:2.5627 x Lambda(0.001)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8503
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5344582
	speed: 0.0263s/iter; left time: 510.3270s
	iters: 200, epoch: 19 | loss: 0.5374304
	speed: 0.0231s/iter; left time: 447.1429s
Epoch: 19 cost time: 5.855595350265503
Epoch: 19, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5692 x Lambda(0.001)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8503
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5482640
	speed: 0.0256s/iter; left time: 491.0948s
	iters: 200, epoch: 20 | loss: 0.5568058
	speed: 0.0230s/iter; left time: 438.4849s
Epoch: 20 cost time: 5.7773332595825195
Epoch: 20, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5654 x Lambda(0.001)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8503
Validation loss decreased (0.985763 --> 0.985725).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.4958279
	speed: 0.0258s/iter; left time: 488.1895s
	iters: 200, epoch: 21 | loss: 0.5101192
	speed: 0.0234s/iter; left time: 440.3974s
Epoch: 21 cost time: 5.8262622356414795
Epoch: 21, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5657 x Lambda(0.001)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8503
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5126597
	speed: 0.0257s/iter; left time: 481.0981s
	iters: 200, epoch: 22 | loss: 0.5353854
	speed: 0.0233s/iter; left time: 432.7503s
Epoch: 22 cost time: 5.8215720653533936
Epoch: 22, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5675 x Lambda(0.001)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8503
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5293799
	speed: 0.0234s/iter; left time: 431.8381s
	iters: 200, epoch: 23 | loss: 0.5145035
	speed: 0.0202s/iter; left time: 370.7306s
Epoch: 23 cost time: 5.172194004058838
Epoch: 23, Steps: 238 Train Loss: 0.5397 (Forecasting Loss:0.5371 + XiCon Loss:2.5632 x Lambda(0.001)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8503
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5532680
	speed: 0.0265s/iter; left time: 483.3321s
	iters: 200, epoch: 24 | loss: 0.5311365
	speed: 0.0226s/iter; left time: 410.1021s
Epoch: 24 cost time: 5.828258275985718
Epoch: 24, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5370 + XiCon Loss:2.5623 x Lambda(0.001)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8503
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5367411
	speed: 0.0262s/iter; left time: 471.7202s
	iters: 200, epoch: 25 | loss: 0.5477297
	speed: 0.0234s/iter; left time: 418.1264s
Epoch: 25 cost time: 5.874005317687988
Epoch: 25, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5679 x Lambda(0.001)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8503
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5592667
	speed: 0.0255s/iter; left time: 453.1435s
	iters: 200, epoch: 26 | loss: 0.5179452
	speed: 0.0233s/iter; left time: 410.7715s
Epoch: 26 cost time: 5.803763389587402
Epoch: 26, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5644 x Lambda(0.001)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8503
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5830890
	speed: 0.0257s/iter; left time: 450.1409s
	iters: 200, epoch: 27 | loss: 0.5792019
	speed: 0.0230s/iter; left time: 399.9887s
Epoch: 27 cost time: 5.783013820648193
Epoch: 27, Steps: 238 Train Loss: 0.5398 (Forecasting Loss:0.5372 + XiCon Loss:2.5651 x Lambda(0.001)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8503
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5145326
	speed: 0.0254s/iter; left time: 438.4150s
	iters: 200, epoch: 28 | loss: 0.5129557
	speed: 0.0232s/iter; left time: 398.0381s
Epoch: 28 cost time: 5.749571800231934
Epoch: 28, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5644 x Lambda(0.001)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8503
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.4674163
	speed: 0.0257s/iter; left time: 438.4432s
	iters: 200, epoch: 29 | loss: 0.5323984
	speed: 0.0230s/iter; left time: 389.3137s
Epoch: 29 cost time: 5.799198627471924
Epoch: 29, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5631 x Lambda(0.001)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8503
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.4821365
	speed: 0.0257s/iter; left time: 431.4206s
	iters: 200, epoch: 30 | loss: 0.5506328
	speed: 0.0235s/iter; left time: 391.9375s
Epoch: 30 cost time: 5.82520055770874
Epoch: 30, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5370 + XiCon Loss:2.5636 x Lambda(0.001)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8503
Validation loss decreased (0.985725 --> 0.985649).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5379363
	speed: 0.0239s/iter; left time: 395.2005s
	iters: 200, epoch: 31 | loss: 0.4967971
	speed: 0.0197s/iter; left time: 324.3151s
Epoch: 31 cost time: 5.120512008666992
Epoch: 31, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5652 x Lambda(0.001)), Vali MSE Loss: 0.9867 Test MSE Loss: 0.8503
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5587724
	speed: 0.0248s/iter; left time: 405.3472s
	iters: 200, epoch: 32 | loss: 0.5834468
	speed: 0.0190s/iter; left time: 308.4261s
Epoch: 32 cost time: 5.13888144493103
Epoch: 32, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5370 + XiCon Loss:2.5638 x Lambda(0.001)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8503
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5266359
	speed: 0.0263s/iter; left time: 422.9298s
	iters: 200, epoch: 33 | loss: 0.5191727
	speed: 0.0235s/iter; left time: 375.9517s
Epoch: 33 cost time: 5.917881727218628
Epoch: 33, Steps: 238 Train Loss: 0.5397 (Forecasting Loss:0.5371 + XiCon Loss:2.5591 x Lambda(0.001)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8503
Validation loss decreased (0.985649 --> 0.985605).  Saving model ...
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5165893
	speed: 0.0255s/iter; left time: 404.6576s
	iters: 200, epoch: 34 | loss: 0.5180196
	speed: 0.0235s/iter; left time: 370.7123s
Epoch: 34 cost time: 5.833818674087524
Epoch: 34, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5371 + XiCon Loss:2.5615 x Lambda(0.001)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8503
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5249566
	speed: 0.0263s/iter; left time: 409.9200s
	iters: 200, epoch: 35 | loss: 0.5772741
	speed: 0.0232s/iter; left time: 359.6477s
Epoch: 35 cost time: 5.866010427474976
Epoch: 35, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5657 x Lambda(0.001)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8503
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5120139
	speed: 0.0258s/iter; left time: 397.1779s
	iters: 200, epoch: 36 | loss: 0.5252858
	speed: 0.0235s/iter; left time: 358.8398s
Epoch: 36 cost time: 5.894489288330078
Epoch: 36, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5369 + XiCon Loss:2.5680 x Lambda(0.001)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8503
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.4950569
	speed: 0.0261s/iter; left time: 394.8075s
	iters: 200, epoch: 37 | loss: 0.5947149
	speed: 0.0192s/iter; left time: 288.6184s
Epoch: 37 cost time: 5.284955978393555
Epoch: 37, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5371 + XiCon Loss:2.5644 x Lambda(0.001)), Vali MSE Loss: 0.9866 Test MSE Loss: 0.8503
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5693314
	speed: 0.0258s/iter; left time: 384.4851s
	iters: 200, epoch: 38 | loss: 0.5713779
	speed: 0.0232s/iter; left time: 343.6209s
Epoch: 38 cost time: 5.8301472663879395
Epoch: 38, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5657 x Lambda(0.001)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8503
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5378542
	speed: 0.0262s/iter; left time: 384.6727s
	iters: 200, epoch: 39 | loss: 0.5715601
	speed: 0.0231s/iter; left time: 336.4786s
Epoch: 39 cost time: 5.849085330963135
Epoch: 39, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5684 x Lambda(0.001)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8503
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.5731919
	speed: 0.0260s/iter; left time: 374.5780s
	iters: 200, epoch: 40 | loss: 0.5645569
	speed: 0.0234s/iter; left time: 335.6427s
Epoch: 40 cost time: 5.844430208206177
Epoch: 40, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5675 x Lambda(0.001)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8503
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.5819235
	speed: 0.0266s/iter; left time: 376.7681s
	iters: 200, epoch: 41 | loss: 0.5137076
	speed: 0.0231s/iter; left time: 325.0806s
Epoch: 41 cost time: 5.890149116516113
Epoch: 41, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5370 + XiCon Loss:2.5662 x Lambda(0.001)), Vali MSE Loss: 0.9868 Test MSE Loss: 0.8503
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.5237892
	speed: 0.0257s/iter; left time: 357.9672s
	iters: 200, epoch: 42 | loss: 0.5387078
	speed: 0.0228s/iter; left time: 315.5340s
Epoch: 42 cost time: 5.7653703689575195
Epoch: 42, Steps: 238 Train Loss: 0.5395 (Forecasting Loss:0.5369 + XiCon Loss:2.5660 x Lambda(0.001)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8503
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.5541186
	speed: 0.0262s/iter; left time: 359.1411s
	iters: 200, epoch: 43 | loss: 0.5473657
	speed: 0.0228s/iter; left time: 310.3256s
Epoch: 43 cost time: 5.808145761489868
Epoch: 43, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5370 + XiCon Loss:2.5647 x Lambda(0.001)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8503
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9791032075881958, mae:0.721458911895752, mape:4.792986869812012, mspe:2699.95654296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.8626
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1179878
	speed: 0.0274s/iter; left time: 649.3234s
	iters: 200, epoch: 1 | loss: 1.0322537
	speed: 0.0234s/iter; left time: 551.7523s
Epoch: 1 cost time: 5.9921793937683105
Epoch: 1, Steps: 238 Train Loss: 1.0996 (Forecasting Loss:1.0971 + XiCon Loss:2.5780 x Lambda(0.001)), Vali MSE Loss: 1.9328 Test MSE Loss: 1.0252
Validation loss decreased (inf --> 1.932796).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5988451
	speed: 0.0267s/iter; left time: 626.9471s
	iters: 200, epoch: 2 | loss: 0.5778005
	speed: 0.0235s/iter; left time: 550.0518s
Epoch: 2 cost time: 5.978883266448975
Epoch: 2, Steps: 238 Train Loss: 0.6261 (Forecasting Loss:0.6235 + XiCon Loss:2.5745 x Lambda(0.001)), Vali MSE Loss: 1.0344 Test MSE Loss: 0.8764
Validation loss decreased (1.932796 --> 1.034402).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5230251
	speed: 0.0267s/iter; left time: 619.9708s
	iters: 200, epoch: 3 | loss: 0.6047997
	speed: 0.0235s/iter; left time: 543.7604s
Epoch: 3 cost time: 5.930967330932617
Epoch: 3, Steps: 238 Train Loss: 0.5549 (Forecasting Loss:0.5523 + XiCon Loss:2.5772 x Lambda(0.001)), Vali MSE Loss: 1.0102 Test MSE Loss: 0.8681
Validation loss decreased (1.034402 --> 1.010160).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5306136
	speed: 0.0271s/iter; left time: 622.8884s
	iters: 200, epoch: 4 | loss: 0.6007442
	speed: 0.0233s/iter; left time: 532.2635s
Epoch: 4 cost time: 5.966224193572998
Epoch: 4, Steps: 238 Train Loss: 0.5461 (Forecasting Loss:0.5435 + XiCon Loss:2.5837 x Lambda(0.001)), Vali MSE Loss: 1.0029 Test MSE Loss: 0.8657
Validation loss decreased (1.010160 --> 1.002941).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5370615
	speed: 0.0272s/iter; left time: 619.8158s
	iters: 200, epoch: 5 | loss: 0.5728482
	speed: 0.0238s/iter; left time: 538.7971s
Epoch: 5 cost time: 6.047682523727417
Epoch: 5, Steps: 238 Train Loss: 0.5425 (Forecasting Loss:0.5399 + XiCon Loss:2.5765 x Lambda(0.001)), Vali MSE Loss: 0.9987 Test MSE Loss: 0.8647
Validation loss decreased (1.002941 --> 0.998708).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5620417
	speed: 0.0277s/iter; left time: 623.1624s
	iters: 200, epoch: 6 | loss: 0.5063992
	speed: 0.0233s/iter; left time: 522.1479s
Epoch: 6 cost time: 6.033984661102295
Epoch: 6, Steps: 238 Train Loss: 0.5409 (Forecasting Loss:0.5384 + XiCon Loss:2.5810 x Lambda(0.001)), Vali MSE Loss: 0.9979 Test MSE Loss: 0.8649
Validation loss decreased (0.998708 --> 0.997852).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5399706
	speed: 0.0280s/iter; left time: 623.4905s
	iters: 200, epoch: 7 | loss: 0.5680352
	speed: 0.0233s/iter; left time: 516.1309s
Epoch: 7 cost time: 6.031445026397705
Epoch: 7, Steps: 238 Train Loss: 0.5400 (Forecasting Loss:0.5375 + XiCon Loss:2.5732 x Lambda(0.001)), Vali MSE Loss: 0.9971 Test MSE Loss: 0.8646
Validation loss decreased (0.997852 --> 0.997139).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5394526
	speed: 0.0274s/iter; left time: 604.0480s
	iters: 200, epoch: 8 | loss: 0.5112525
	speed: 0.0239s/iter; left time: 523.5526s
Epoch: 8 cost time: 6.102535963058472
Epoch: 8, Steps: 238 Train Loss: 0.5396 (Forecasting Loss:0.5371 + XiCon Loss:2.5776 x Lambda(0.001)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8646
Validation loss decreased (0.997139 --> 0.996354).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5649078
	speed: 0.0268s/iter; left time: 584.3185s
	iters: 200, epoch: 9 | loss: 0.5282305
	speed: 0.0246s/iter; left time: 533.2145s
Epoch: 9 cost time: 6.0593647956848145
Epoch: 9, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5755 x Lambda(0.001)), Vali MSE Loss: 0.9971 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5394496
	speed: 0.0270s/iter; left time: 581.3749s
	iters: 200, epoch: 10 | loss: 0.5393265
	speed: 0.0239s/iter; left time: 512.3423s
Epoch: 10 cost time: 6.046938896179199
Epoch: 10, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5365 + XiCon Loss:2.5794 x Lambda(0.001)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8646
Validation loss decreased (0.996354 --> 0.996138).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5368256
	speed: 0.0273s/iter; left time: 581.7040s
	iters: 200, epoch: 11 | loss: 0.5052164
	speed: 0.0237s/iter; left time: 502.1068s
Epoch: 11 cost time: 6.069021224975586
Epoch: 11, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5795 x Lambda(0.001)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8646
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5245101
	speed: 0.0257s/iter; left time: 542.5509s
	iters: 200, epoch: 12 | loss: 0.5247650
	speed: 0.0237s/iter; left time: 496.3469s
Epoch: 12 cost time: 5.8796916007995605
Epoch: 12, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5753 x Lambda(0.001)), Vali MSE Loss: 0.9963 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5068994
	speed: 0.0273s/iter; left time: 568.1435s
	iters: 200, epoch: 13 | loss: 0.4872746
	speed: 0.0234s/iter; left time: 484.7583s
Epoch: 13 cost time: 6.008865833282471
Epoch: 13, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5784 x Lambda(0.001)), Vali MSE Loss: 0.9961 Test MSE Loss: 0.8645
Validation loss decreased (0.996138 --> 0.996073).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5632775
	speed: 0.0270s/iter; left time: 556.9253s
	iters: 200, epoch: 14 | loss: 0.6306338
	speed: 0.0238s/iter; left time: 488.8459s
Epoch: 14 cost time: 6.014853239059448
Epoch: 14, Steps: 238 Train Loss: 0.5392 (Forecasting Loss:0.5366 + XiCon Loss:2.5794 x Lambda(0.001)), Vali MSE Loss: 0.9966 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5138055
	speed: 0.0276s/iter; left time: 562.1669s
	iters: 200, epoch: 15 | loss: 0.5197968
	speed: 0.0245s/iter; left time: 495.7362s
Epoch: 15 cost time: 6.126549482345581
Epoch: 15, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5365 + XiCon Loss:2.5848 x Lambda(0.001)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
Validation loss decreased (0.996073 --> 0.995683).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5629252
	speed: 0.0275s/iter; left time: 554.4405s
	iters: 200, epoch: 16 | loss: 0.5117281
	speed: 0.0234s/iter; left time: 469.7104s
Epoch: 16 cost time: 6.0185675621032715
Epoch: 16, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5824 x Lambda(0.001)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
Validation loss decreased (0.995683 --> 0.995675).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5072137
	speed: 0.0265s/iter; left time: 527.2047s
	iters: 200, epoch: 17 | loss: 0.5606659
	speed: 0.0238s/iter; left time: 471.1288s
Epoch: 17 cost time: 5.94665265083313
Epoch: 17, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5368 + XiCon Loss:2.5800 x Lambda(0.001)), Vali MSE Loss: 0.9967 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5353641
	speed: 0.0277s/iter; left time: 543.8795s
	iters: 200, epoch: 18 | loss: 0.5173134
	speed: 0.0241s/iter; left time: 471.3764s
Epoch: 18 cost time: 6.173556089401245
Epoch: 18, Steps: 238 Train Loss: 0.5392 (Forecasting Loss:0.5366 + XiCon Loss:2.5818 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5329891
	speed: 0.0262s/iter; left time: 508.8294s
	iters: 200, epoch: 19 | loss: 0.5380851
	speed: 0.0239s/iter; left time: 461.0093s
Epoch: 19 cost time: 5.908623933792114
Epoch: 19, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5807 x Lambda(0.001)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
Validation loss decreased (0.995675 --> 0.995666).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5152784
	speed: 0.0266s/iter; left time: 509.7922s
	iters: 200, epoch: 20 | loss: 0.5476650
	speed: 0.0235s/iter; left time: 448.5860s
Epoch: 20 cost time: 5.9314045906066895
Epoch: 20, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5365 + XiCon Loss:2.5807 x Lambda(0.001)), Vali MSE Loss: 0.9965 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5551645
	speed: 0.0267s/iter; left time: 505.6216s
	iters: 200, epoch: 21 | loss: 0.5279686
	speed: 0.0232s/iter; left time: 436.5511s
Epoch: 21 cost time: 5.926268815994263
Epoch: 21, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5778 x Lambda(0.001)), Vali MSE Loss: 0.9960 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.4905567
	speed: 0.0266s/iter; left time: 497.2853s
	iters: 200, epoch: 22 | loss: 0.5321361
	speed: 0.0234s/iter; left time: 435.3906s
Epoch: 22 cost time: 5.9180943965911865
Epoch: 22, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5365 + XiCon Loss:2.5842 x Lambda(0.001)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5635818
	speed: 0.0267s/iter; left time: 493.6988s
	iters: 200, epoch: 23 | loss: 0.5664381
	speed: 0.0237s/iter; left time: 434.8002s
Epoch: 23 cost time: 5.990586280822754
Epoch: 23, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5812 x Lambda(0.001)), Vali MSE Loss: 0.9966 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5080555
	speed: 0.0262s/iter; left time: 477.2716s
	iters: 200, epoch: 24 | loss: 0.5566779
	speed: 0.0239s/iter; left time: 432.9640s
Epoch: 24 cost time: 5.95200777053833
Epoch: 24, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5823 x Lambda(0.001)), Vali MSE Loss: 0.9970 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5713620
	speed: 0.0263s/iter; left time: 473.5083s
	iters: 200, epoch: 25 | loss: 0.5554984
	speed: 0.0235s/iter; left time: 420.7449s
Epoch: 25 cost time: 5.906233549118042
Epoch: 25, Steps: 238 Train Loss: 0.5390 (Forecasting Loss:0.5364 + XiCon Loss:2.5840 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5314686
	speed: 0.0274s/iter; left time: 485.7506s
	iters: 200, epoch: 26 | loss: 0.5809486
	speed: 0.0236s/iter; left time: 416.9942s
Epoch: 26 cost time: 6.048981666564941
Epoch: 26, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5797 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5570790
	speed: 0.0271s/iter; left time: 475.1786s
	iters: 200, epoch: 27 | loss: 0.5430895
	speed: 0.0233s/iter; left time: 406.2982s
Epoch: 27 cost time: 5.989624500274658
Epoch: 27, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5747 x Lambda(0.001)), Vali MSE Loss: 0.9952 Test MSE Loss: 0.8645
Validation loss decreased (0.995666 --> 0.995194).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5635772
	speed: 0.0270s/iter; left time: 466.3419s
	iters: 200, epoch: 28 | loss: 0.5275804
	speed: 0.0245s/iter; left time: 421.2890s
Epoch: 28 cost time: 6.146618366241455
Epoch: 28, Steps: 238 Train Loss: 0.5392 (Forecasting Loss:0.5366 + XiCon Loss:2.5825 x Lambda(0.001)), Vali MSE Loss: 0.9957 Test MSE Loss: 0.8645
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5651123
	speed: 0.0268s/iter; left time: 456.4338s
	iters: 200, epoch: 29 | loss: 0.5421320
	speed: 0.0241s/iter; left time: 407.7887s
Epoch: 29 cost time: 6.033937454223633
Epoch: 29, Steps: 238 Train Loss: 0.5392 (Forecasting Loss:0.5366 + XiCon Loss:2.5756 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5706226
	speed: 0.0266s/iter; left time: 447.6800s
	iters: 200, epoch: 30 | loss: 0.5402141
	speed: 0.0236s/iter; left time: 393.7788s
Epoch: 30 cost time: 5.959216833114624
Epoch: 30, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5828 x Lambda(0.001)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5334858
	speed: 0.0268s/iter; left time: 443.5804s
	iters: 200, epoch: 31 | loss: 0.5375383
	speed: 0.0240s/iter; left time: 394.6259s
Epoch: 31 cost time: 6.042312383651733
Epoch: 31, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5365 + XiCon Loss:2.5790 x Lambda(0.001)), Vali MSE Loss: 0.9964 Test MSE Loss: 0.8645
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5525846
	speed: 0.0266s/iter; left time: 433.7401s
	iters: 200, epoch: 32 | loss: 0.5130614
	speed: 0.0231s/iter; left time: 375.5164s
Epoch: 32 cost time: 5.941600799560547
Epoch: 32, Steps: 238 Train Loss: 0.5394 (Forecasting Loss:0.5368 + XiCon Loss:2.5843 x Lambda(0.001)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5995120
	speed: 0.0264s/iter; left time: 423.8679s
	iters: 200, epoch: 33 | loss: 0.5315605
	speed: 0.0236s/iter; left time: 377.4145s
Epoch: 33 cost time: 5.9179112911224365
Epoch: 33, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5799 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5065764
	speed: 0.0275s/iter; left time: 436.1486s
	iters: 200, epoch: 34 | loss: 0.5707660
	speed: 0.0239s/iter; left time: 376.1291s
Epoch: 34 cost time: 6.063601970672607
Epoch: 34, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5750 x Lambda(0.001)), Vali MSE Loss: 0.9966 Test MSE Loss: 0.8645
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5636777
	speed: 0.0280s/iter; left time: 436.3759s
	iters: 200, epoch: 35 | loss: 0.5188841
	speed: 0.0237s/iter; left time: 368.0373s
Epoch: 35 cost time: 6.082308769226074
Epoch: 35, Steps: 238 Train Loss: 0.5391 (Forecasting Loss:0.5366 + XiCon Loss:2.5755 x Lambda(0.001)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8645
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.4860856
	speed: 0.0269s/iter; left time: 413.9001s
	iters: 200, epoch: 36 | loss: 0.5303274
	speed: 0.0236s/iter; left time: 361.1294s
Epoch: 36 cost time: 6.0127739906311035
Epoch: 36, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5811 x Lambda(0.001)), Vali MSE Loss: 0.9969 Test MSE Loss: 0.8645
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5011382
	speed: 0.0270s/iter; left time: 408.2610s
	iters: 200, epoch: 37 | loss: 0.5445237
	speed: 0.0235s/iter; left time: 352.9339s
Epoch: 37 cost time: 5.976920127868652
Epoch: 37, Steps: 238 Train Loss: 0.5393 (Forecasting Loss:0.5367 + XiCon Loss:2.5798 x Lambda(0.001)), Vali MSE Loss: 0.9962 Test MSE Loss: 0.8645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.997096598148346, mae:0.7319852709770203, mape:5.081603050231934, mspe:3081.706787109375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.3441
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.0692493
	speed: 0.0223s/iter; left time: 529.3560s
	iters: 200, epoch: 1 | loss: 1.0969698
	speed: 0.0190s/iter; left time: 448.9647s
Epoch: 1 cost time: 4.899864435195923
Epoch: 1, Steps: 238 Train Loss: 1.1988 (Forecasting Loss:1.1962 + XiCon Loss:2.5869 x Lambda(0.001)), Vali MSE Loss: 2.1664 Test MSE Loss: 1.1068
Validation loss decreased (inf --> 2.166446).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7766940
	speed: 0.0226s/iter; left time: 530.2336s
	iters: 200, epoch: 2 | loss: 0.5722516
	speed: 0.0189s/iter; left time: 441.8115s
Epoch: 2 cost time: 4.9203362464904785
Epoch: 2, Steps: 238 Train Loss: 0.7308 (Forecasting Loss:0.7282 + XiCon Loss:2.5833 x Lambda(0.001)), Vali MSE Loss: 1.0373 Test MSE Loss: 0.8754
Validation loss decreased (2.166446 --> 1.037341).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5996824
	speed: 0.0223s/iter; left time: 517.9744s
	iters: 200, epoch: 3 | loss: 0.5868710
	speed: 0.0190s/iter; left time: 438.7900s
Epoch: 3 cost time: 4.888788938522339
Epoch: 3, Steps: 238 Train Loss: 0.5631 (Forecasting Loss:0.5605 + XiCon Loss:2.5831 x Lambda(0.001)), Vali MSE Loss: 1.0333 Test MSE Loss: 0.8585
Validation loss decreased (1.037341 --> 1.033341).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5700137
	speed: 0.0224s/iter; left time: 513.9575s
	iters: 200, epoch: 4 | loss: 0.5728956
	speed: 0.0193s/iter; left time: 441.0752s
Epoch: 4 cost time: 4.918437957763672
Epoch: 4, Steps: 238 Train Loss: 0.5506 (Forecasting Loss:0.5480 + XiCon Loss:2.5919 x Lambda(0.001)), Vali MSE Loss: 1.0260 Test MSE Loss: 0.8553
Validation loss decreased (1.033341 --> 1.026010).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5317854
	speed: 0.0225s/iter; left time: 511.3556s
	iters: 200, epoch: 5 | loss: 0.5124239
	speed: 0.0191s/iter; left time: 432.0054s
Epoch: 5 cost time: 4.915896415710449
Epoch: 5, Steps: 238 Train Loss: 0.5473 (Forecasting Loss:0.5447 + XiCon Loss:2.5921 x Lambda(0.001)), Vali MSE Loss: 1.0211 Test MSE Loss: 0.8542
Validation loss decreased (1.026010 --> 1.021135).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5488784
	speed: 0.0220s/iter; left time: 495.4460s
	iters: 200, epoch: 6 | loss: 0.5260752
	speed: 0.0193s/iter; left time: 432.1599s
Epoch: 6 cost time: 4.890223979949951
Epoch: 6, Steps: 238 Train Loss: 0.5457 (Forecasting Loss:0.5431 + XiCon Loss:2.5901 x Lambda(0.001)), Vali MSE Loss: 1.0206 Test MSE Loss: 0.8539
Validation loss decreased (1.021135 --> 1.020636).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5748816
	speed: 0.0226s/iter; left time: 503.0992s
	iters: 200, epoch: 7 | loss: 0.4918155
	speed: 0.0190s/iter; left time: 422.0095s
Epoch: 7 cost time: 4.919616460800171
Epoch: 7, Steps: 238 Train Loss: 0.5445 (Forecasting Loss:0.5420 + XiCon Loss:2.5875 x Lambda(0.001)), Vali MSE Loss: 1.0212 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5596234
	speed: 0.0224s/iter; left time: 493.2401s
	iters: 200, epoch: 8 | loss: 0.6164209
	speed: 0.0191s/iter; left time: 418.1426s
Epoch: 8 cost time: 4.918202877044678
Epoch: 8, Steps: 238 Train Loss: 0.5443 (Forecasting Loss:0.5417 + XiCon Loss:2.5951 x Lambda(0.001)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8537
Validation loss decreased (1.020636 --> 1.019443).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5538746
	speed: 0.0225s/iter; left time: 490.8071s
	iters: 200, epoch: 9 | loss: 0.5370129
	speed: 0.0194s/iter; left time: 420.6165s
Epoch: 9 cost time: 4.953408479690552
Epoch: 9, Steps: 238 Train Loss: 0.5441 (Forecasting Loss:0.5416 + XiCon Loss:2.5906 x Lambda(0.001)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8536
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5572149
	speed: 0.0220s/iter; left time: 474.8198s
	iters: 200, epoch: 10 | loss: 0.5649092
	speed: 0.0190s/iter; left time: 408.7235s
Epoch: 10 cost time: 4.864527225494385
Epoch: 10, Steps: 238 Train Loss: 0.5441 (Forecasting Loss:0.5415 + XiCon Loss:2.5937 x Lambda(0.001)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8536
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5227139
	speed: 0.0223s/iter; left time: 475.0290s
	iters: 200, epoch: 11 | loss: 0.5185620
	speed: 0.0190s/iter; left time: 403.2907s
Epoch: 11 cost time: 4.890934705734253
Epoch: 11, Steps: 238 Train Loss: 0.5440 (Forecasting Loss:0.5414 + XiCon Loss:2.5870 x Lambda(0.001)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8536
Validation loss decreased (1.019443 --> 1.019380).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5325978
	speed: 0.0223s/iter; left time: 469.9915s
	iters: 200, epoch: 12 | loss: 0.5245723
	speed: 0.0191s/iter; left time: 401.7077s
Epoch: 12 cost time: 4.904150485992432
Epoch: 12, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5873 x Lambda(0.001)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8536
Validation loss decreased (1.019380 --> 1.019361).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5286655
	speed: 0.0231s/iter; left time: 480.6939s
	iters: 200, epoch: 13 | loss: 0.6033774
	speed: 0.0190s/iter; left time: 393.8891s
Epoch: 13 cost time: 4.961244821548462
Epoch: 13, Steps: 238 Train Loss: 0.5440 (Forecasting Loss:0.5414 + XiCon Loss:2.5873 x Lambda(0.001)), Vali MSE Loss: 1.0204 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6015670
	speed: 0.0220s/iter; left time: 452.5648s
	iters: 200, epoch: 14 | loss: 0.5536865
	speed: 0.0189s/iter; left time: 387.7332s
Epoch: 14 cost time: 4.8456034660339355
Epoch: 14, Steps: 238 Train Loss: 0.5437 (Forecasting Loss:0.5411 + XiCon Loss:2.5900 x Lambda(0.001)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5360585
	speed: 0.0223s/iter; left time: 453.4910s
	iters: 200, epoch: 15 | loss: 0.5628346
	speed: 0.0194s/iter; left time: 393.1093s
Epoch: 15 cost time: 4.915825128555298
Epoch: 15, Steps: 238 Train Loss: 0.5440 (Forecasting Loss:0.5414 + XiCon Loss:2.5865 x Lambda(0.001)), Vali MSE Loss: 1.0199 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5336197
	speed: 0.0221s/iter; left time: 444.9656s
	iters: 200, epoch: 16 | loss: 0.5230631
	speed: 0.0189s/iter; left time: 378.8686s
Epoch: 16 cost time: 4.858080625534058
Epoch: 16, Steps: 238 Train Loss: 0.5441 (Forecasting Loss:0.5415 + XiCon Loss:2.5894 x Lambda(0.001)), Vali MSE Loss: 1.0193 Test MSE Loss: 0.8535
Validation loss decreased (1.019361 --> 1.019253).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5394833
	speed: 0.0225s/iter; left time: 446.8899s
	iters: 200, epoch: 17 | loss: 0.5353701
	speed: 0.0193s/iter; left time: 382.8071s
Epoch: 17 cost time: 4.933136463165283
Epoch: 17, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5413 + XiCon Loss:2.5873 x Lambda(0.001)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5252973
	speed: 0.0222s/iter; left time: 436.5780s
	iters: 200, epoch: 18 | loss: 0.5947029
	speed: 0.0196s/iter; left time: 382.6579s
Epoch: 18 cost time: 4.942413568496704
Epoch: 18, Steps: 238 Train Loss: 0.5433 (Forecasting Loss:0.5407 + XiCon Loss:2.5887 x Lambda(0.001)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6052650
	speed: 0.0227s/iter; left time: 440.5281s
	iters: 200, epoch: 19 | loss: 0.5796232
	speed: 0.0194s/iter; left time: 373.9811s
Epoch: 19 cost time: 4.960608243942261
Epoch: 19, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5910 x Lambda(0.001)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5811651
	speed: 0.0225s/iter; left time: 431.9115s
	iters: 200, epoch: 20 | loss: 0.5701016
	speed: 0.0189s/iter; left time: 361.0493s
Epoch: 20 cost time: 4.907199382781982
Epoch: 20, Steps: 238 Train Loss: 0.5439 (Forecasting Loss:0.5413 + XiCon Loss:2.5910 x Lambda(0.001)), Vali MSE Loss: 1.0205 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5962164
	speed: 0.0271s/iter; left time: 512.3646s
	iters: 200, epoch: 21 | loss: 0.5021894
	speed: 0.0193s/iter; left time: 363.1984s
Epoch: 21 cost time: 5.407521486282349
Epoch: 21, Steps: 238 Train Loss: 0.5439 (Forecasting Loss:0.5413 + XiCon Loss:2.5924 x Lambda(0.001)), Vali MSE Loss: 1.0193 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5264325
	speed: 0.0220s/iter; left time: 411.5335s
	iters: 200, epoch: 22 | loss: 0.5562840
	speed: 0.0195s/iter; left time: 362.2015s
Epoch: 22 cost time: 4.929094076156616
Epoch: 22, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5928 x Lambda(0.001)), Vali MSE Loss: 1.0204 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5902234
	speed: 0.0222s/iter; left time: 409.7068s
	iters: 200, epoch: 23 | loss: 0.5640161
	speed: 0.0191s/iter; left time: 350.5939s
Epoch: 23 cost time: 4.8793113231658936
Epoch: 23, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5882 x Lambda(0.001)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5675007
	speed: 0.0221s/iter; left time: 401.9421s
	iters: 200, epoch: 24 | loss: 0.5305793
	speed: 0.0190s/iter; left time: 343.7458s
Epoch: 24 cost time: 4.871106147766113
Epoch: 24, Steps: 238 Train Loss: 0.5437 (Forecasting Loss:0.5411 + XiCon Loss:2.5922 x Lambda(0.001)), Vali MSE Loss: 1.0199 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5475442
	speed: 0.0224s/iter; left time: 403.4364s
	iters: 200, epoch: 25 | loss: 0.5650775
	speed: 0.0192s/iter; left time: 344.0054s
Epoch: 25 cost time: 4.935343265533447
Epoch: 25, Steps: 238 Train Loss: 0.5443 (Forecasting Loss:0.5417 + XiCon Loss:2.5854 x Lambda(0.001)), Vali MSE Loss: 1.0198 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5302102
	speed: 0.0222s/iter; left time: 393.7804s
	iters: 200, epoch: 26 | loss: 0.5682636
	speed: 0.0193s/iter; left time: 340.6924s
Epoch: 26 cost time: 4.925006866455078
Epoch: 26, Steps: 238 Train Loss: 0.5439 (Forecasting Loss:0.5413 + XiCon Loss:2.5902 x Lambda(0.001)), Vali MSE Loss: 1.0189 Test MSE Loss: 0.8535
Validation loss decreased (1.019253 --> 1.018864).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5277790
	speed: 0.0226s/iter; left time: 395.1834s
	iters: 200, epoch: 27 | loss: 0.5310396
	speed: 0.0190s/iter; left time: 331.2890s
Epoch: 27 cost time: 4.917907953262329
Epoch: 27, Steps: 238 Train Loss: 0.5439 (Forecasting Loss:0.5413 + XiCon Loss:2.5891 x Lambda(0.001)), Vali MSE Loss: 1.0184 Test MSE Loss: 0.8535
Validation loss decreased (1.018864 --> 1.018449).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5944835
	speed: 0.0222s/iter; left time: 384.1834s
	iters: 200, epoch: 28 | loss: 0.5293458
	speed: 0.0194s/iter; left time: 332.6219s
Epoch: 28 cost time: 4.9182422161102295
Epoch: 28, Steps: 238 Train Loss: 0.5433 (Forecasting Loss:0.5407 + XiCon Loss:2.5898 x Lambda(0.001)), Vali MSE Loss: 1.0193 Test MSE Loss: 0.8535
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5449299
	speed: 0.0221s/iter; left time: 377.3084s
	iters: 200, epoch: 29 | loss: 0.5464504
	speed: 0.0191s/iter; left time: 324.3119s
Epoch: 29 cost time: 4.901443719863892
Epoch: 29, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5848 x Lambda(0.001)), Vali MSE Loss: 1.0199 Test MSE Loss: 0.8535
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5417401
	speed: 0.0225s/iter; left time: 378.2342s
	iters: 200, epoch: 30 | loss: 0.5266033
	speed: 0.0192s/iter; left time: 320.4798s
Epoch: 30 cost time: 4.92815637588501
Epoch: 30, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5933 x Lambda(0.001)), Vali MSE Loss: 1.0200 Test MSE Loss: 0.8535
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5595553
	speed: 0.0224s/iter; left time: 370.2325s
	iters: 200, epoch: 31 | loss: 0.5413324
	speed: 0.0192s/iter; left time: 315.3081s
Epoch: 31 cost time: 4.9167256355285645
Epoch: 31, Steps: 238 Train Loss: 0.5440 (Forecasting Loss:0.5414 + XiCon Loss:2.5920 x Lambda(0.001)), Vali MSE Loss: 1.0206 Test MSE Loss: 0.8535
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.4981194
	speed: 0.0226s/iter; left time: 368.6257s
	iters: 200, epoch: 32 | loss: 0.5835617
	speed: 0.0192s/iter; left time: 311.1196s
Epoch: 32 cost time: 4.934857606887817
Epoch: 32, Steps: 238 Train Loss: 0.5441 (Forecasting Loss:0.5415 + XiCon Loss:2.5861 x Lambda(0.001)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8535
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.4808662
	speed: 0.0221s/iter; left time: 355.0271s
	iters: 200, epoch: 33 | loss: 0.5154403
	speed: 0.0190s/iter; left time: 304.0403s
Epoch: 33 cost time: 4.869261026382446
Epoch: 33, Steps: 238 Train Loss: 0.5434 (Forecasting Loss:0.5408 + XiCon Loss:2.5931 x Lambda(0.001)), Vali MSE Loss: 1.0199 Test MSE Loss: 0.8535
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5424513
	speed: 0.0225s/iter; left time: 356.6959s
	iters: 200, epoch: 34 | loss: 0.5369878
	speed: 0.0190s/iter; left time: 299.6758s
Epoch: 34 cost time: 4.924470663070679
Epoch: 34, Steps: 238 Train Loss: 0.5439 (Forecasting Loss:0.5413 + XiCon Loss:2.5929 x Lambda(0.001)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5331568
	speed: 0.0222s/iter; left time: 346.9923s
	iters: 200, epoch: 35 | loss: 0.5608385
	speed: 0.0191s/iter; left time: 296.1089s
Epoch: 35 cost time: 4.889592170715332
Epoch: 35, Steps: 238 Train Loss: 0.5437 (Forecasting Loss:0.5411 + XiCon Loss:2.5902 x Lambda(0.001)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8535
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5513062
	speed: 0.0224s/iter; left time: 343.6838s
	iters: 200, epoch: 36 | loss: 0.5522047
	speed: 0.0194s/iter; left time: 295.6075s
Epoch: 36 cost time: 4.930155277252197
Epoch: 36, Steps: 238 Train Loss: 0.5438 (Forecasting Loss:0.5412 + XiCon Loss:2.5882 x Lambda(0.001)), Vali MSE Loss: 1.0199 Test MSE Loss: 0.8535
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5332391
	speed: 0.0225s/iter; left time: 341.1835s
	iters: 200, epoch: 37 | loss: 0.5709642
	speed: 0.0193s/iter; left time: 290.3374s
Epoch: 37 cost time: 4.956149339675903
Epoch: 37, Steps: 238 Train Loss: 0.5437 (Forecasting Loss:0.5411 + XiCon Loss:2.5880 x Lambda(0.001)), Vali MSE Loss: 1.0191 Test MSE Loss: 0.8535
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.986043393611908, mae:0.7210431098937988, mape:4.675686359405518, mspe:2545.43505859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.5449
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 0.9483197
	speed: 0.0227s/iter; left time: 537.0205s
	iters: 200, epoch: 1 | loss: 1.0018957
	speed: 0.0191s/iter; left time: 450.7990s
Epoch: 1 cost time: 4.927884578704834
Epoch: 1, Steps: 238 Train Loss: 1.0296 (Forecasting Loss:1.0271 + XiCon Loss:2.5518 x Lambda(0.001)), Vali MSE Loss: 1.8388 Test MSE Loss: 0.9830
Validation loss decreased (inf --> 1.838784).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6267805
	speed: 0.0224s/iter; left time: 526.4223s
	iters: 200, epoch: 2 | loss: 0.5147172
	speed: 0.0190s/iter; left time: 444.9673s
Epoch: 2 cost time: 4.900747299194336
Epoch: 2, Steps: 238 Train Loss: 0.6259 (Forecasting Loss:0.6233 + XiCon Loss:2.5505 x Lambda(0.001)), Vali MSE Loss: 1.0470 Test MSE Loss: 0.8597
Validation loss decreased (1.838784 --> 1.046978).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5737475
	speed: 0.0219s/iter; left time: 509.3301s
	iters: 200, epoch: 3 | loss: 0.5836116
	speed: 0.0189s/iter; left time: 437.8550s
Epoch: 3 cost time: 4.843860626220703
Epoch: 3, Steps: 238 Train Loss: 0.5571 (Forecasting Loss:0.5546 + XiCon Loss:2.5442 x Lambda(0.001)), Vali MSE Loss: 1.0222 Test MSE Loss: 0.8525
Validation loss decreased (1.046978 --> 1.022151).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5736398
	speed: 0.0222s/iter; left time: 510.8195s
	iters: 200, epoch: 4 | loss: 0.5888479
	speed: 0.0190s/iter; left time: 435.2932s
Epoch: 4 cost time: 4.878634214401245
Epoch: 4, Steps: 238 Train Loss: 0.5485 (Forecasting Loss:0.5459 + XiCon Loss:2.5451 x Lambda(0.001)), Vali MSE Loss: 1.0136 Test MSE Loss: 0.8513
Validation loss decreased (1.022151 --> 1.013605).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5679427
	speed: 0.0222s/iter; left time: 505.6320s
	iters: 200, epoch: 5 | loss: 0.5702866
	speed: 0.0190s/iter; left time: 430.6122s
Epoch: 5 cost time: 4.869877099990845
Epoch: 5, Steps: 238 Train Loss: 0.5450 (Forecasting Loss:0.5424 + XiCon Loss:2.5449 x Lambda(0.001)), Vali MSE Loss: 1.0108 Test MSE Loss: 0.8508
Validation loss decreased (1.013605 --> 1.010831).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5213292
	speed: 0.0221s/iter; left time: 498.0076s
	iters: 200, epoch: 6 | loss: 0.5297601
	speed: 0.0189s/iter; left time: 423.8069s
Epoch: 6 cost time: 4.860063552856445
Epoch: 6, Steps: 238 Train Loss: 0.5433 (Forecasting Loss:0.5408 + XiCon Loss:2.5418 x Lambda(0.001)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8504
Validation loss decreased (1.010831 --> 1.008223).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5709352
	speed: 0.0221s/iter; left time: 493.0269s
	iters: 200, epoch: 7 | loss: 0.5617994
	speed: 0.0189s/iter; left time: 418.4955s
Epoch: 7 cost time: 4.854979515075684
Epoch: 7, Steps: 238 Train Loss: 0.5426 (Forecasting Loss:0.5400 + XiCon Loss:2.5471 x Lambda(0.001)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8503
Validation loss decreased (1.008223 --> 1.007945).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6013882
	speed: 0.0221s/iter; left time: 487.8916s
	iters: 200, epoch: 8 | loss: 0.5206366
	speed: 0.0190s/iter; left time: 416.9461s
Epoch: 8 cost time: 4.875141143798828
Epoch: 8, Steps: 238 Train Loss: 0.5421 (Forecasting Loss:0.5395 + XiCon Loss:2.5447 x Lambda(0.001)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8502
Validation loss decreased (1.007945 --> 1.006900).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5178508
	speed: 0.0223s/iter; left time: 487.1587s
	iters: 200, epoch: 9 | loss: 0.5034459
	speed: 0.0190s/iter; left time: 412.8259s
Epoch: 9 cost time: 4.890015363693237
Epoch: 9, Steps: 238 Train Loss: 0.5420 (Forecasting Loss:0.5394 + XiCon Loss:2.5468 x Lambda(0.001)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8502
Validation loss decreased (1.006900 --> 1.006354).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5144113
	speed: 0.0225s/iter; left time: 485.2984s
	iters: 200, epoch: 10 | loss: 0.5489560
	speed: 0.0189s/iter; left time: 405.6417s
Epoch: 10 cost time: 4.896011114120483
Epoch: 10, Steps: 238 Train Loss: 0.5416 (Forecasting Loss:0.5391 + XiCon Loss:2.5466 x Lambda(0.001)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.8502
Validation loss decreased (1.006354 --> 1.005941).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6148689
	speed: 0.0221s/iter; left time: 471.6570s
	iters: 200, epoch: 11 | loss: 0.5329124
	speed: 0.0189s/iter; left time: 400.7717s
Epoch: 11 cost time: 4.84990668296814
Epoch: 11, Steps: 238 Train Loss: 0.5414 (Forecasting Loss:0.5389 + XiCon Loss:2.5447 x Lambda(0.001)), Vali MSE Loss: 1.0066 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5344662
	speed: 0.0220s/iter; left time: 464.8255s
	iters: 200, epoch: 12 | loss: 0.5264158
	speed: 0.0190s/iter; left time: 399.1305s
Epoch: 12 cost time: 4.8644936084747314
Epoch: 12, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5392 + XiCon Loss:2.5505 x Lambda(0.001)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5846701
	speed: 0.0220s/iter; left time: 457.8682s
	iters: 200, epoch: 13 | loss: 0.5703948
	speed: 0.0189s/iter; left time: 391.9053s
Epoch: 13 cost time: 4.84216570854187
Epoch: 13, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5490 x Lambda(0.001)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5686846
	speed: 0.0222s/iter; left time: 456.4663s
	iters: 200, epoch: 14 | loss: 0.5040877
	speed: 0.0190s/iter; left time: 389.4855s
Epoch: 14 cost time: 4.8701841831207275
Epoch: 14, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5505 x Lambda(0.001)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5254421
	speed: 0.0224s/iter; left time: 455.4571s
	iters: 200, epoch: 15 | loss: 0.5873402
	speed: 0.0190s/iter; left time: 384.2005s
Epoch: 15 cost time: 4.889178991317749
Epoch: 15, Steps: 238 Train Loss: 0.5415 (Forecasting Loss:0.5389 + XiCon Loss:2.5434 x Lambda(0.001)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5197980
	speed: 0.0220s/iter; left time: 443.1035s
	iters: 200, epoch: 16 | loss: 0.5217693
	speed: 0.0191s/iter; left time: 381.6885s
Epoch: 16 cost time: 4.869054555892944
Epoch: 16, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5479 x Lambda(0.001)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
Validation loss decreased (1.005941 --> 1.005767).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5495193
	speed: 0.0221s/iter; left time: 439.1027s
	iters: 200, epoch: 17 | loss: 0.5056172
	speed: 0.0190s/iter; left time: 376.6123s
Epoch: 17 cost time: 4.864106178283691
Epoch: 17, Steps: 238 Train Loss: 0.5415 (Forecasting Loss:0.5389 + XiCon Loss:2.5415 x Lambda(0.001)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8502
Validation loss decreased (1.005767 --> 1.004971).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.4968953
	speed: 0.0221s/iter; left time: 433.9328s
	iters: 200, epoch: 18 | loss: 0.6170842
	speed: 0.0190s/iter; left time: 371.0241s
Epoch: 18 cost time: 4.868500709533691
Epoch: 18, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5504 x Lambda(0.001)), Vali MSE Loss: 1.0062 Test MSE Loss: 0.8502
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5143470
	speed: 0.0221s/iter; left time: 429.9750s
	iters: 200, epoch: 19 | loss: 0.5022181
	speed: 0.0191s/iter; left time: 368.6761s
Epoch: 19 cost time: 4.8706138134002686
Epoch: 19, Steps: 238 Train Loss: 0.5414 (Forecasting Loss:0.5388 + XiCon Loss:2.5443 x Lambda(0.001)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8502
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5947379
	speed: 0.0221s/iter; left time: 424.2386s
	iters: 200, epoch: 20 | loss: 0.5238784
	speed: 0.0190s/iter; left time: 362.7310s
Epoch: 20 cost time: 4.870147228240967
Epoch: 20, Steps: 238 Train Loss: 0.5416 (Forecasting Loss:0.5391 + XiCon Loss:2.5457 x Lambda(0.001)), Vali MSE Loss: 1.0061 Test MSE Loss: 0.8502
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5202607
	speed: 0.0224s/iter; left time: 424.0663s
	iters: 200, epoch: 21 | loss: 0.5847938
	speed: 0.0192s/iter; left time: 362.1487s
Epoch: 21 cost time: 4.921370267868042
Epoch: 21, Steps: 238 Train Loss: 0.5418 (Forecasting Loss:0.5392 + XiCon Loss:2.5449 x Lambda(0.001)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8502
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5791188
	speed: 0.0223s/iter; left time: 417.9976s
	iters: 200, epoch: 22 | loss: 0.5711890
	speed: 0.0192s/iter; left time: 356.8969s
Epoch: 22 cost time: 4.909499168395996
Epoch: 22, Steps: 238 Train Loss: 0.5415 (Forecasting Loss:0.5390 + XiCon Loss:2.5445 x Lambda(0.001)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8502
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5444596
	speed: 0.0218s/iter; left time: 402.3537s
	iters: 200, epoch: 23 | loss: 0.5857356
	speed: 0.0191s/iter; left time: 351.3744s
Epoch: 23 cost time: 4.850991487503052
Epoch: 23, Steps: 238 Train Loss: 0.5415 (Forecasting Loss:0.5390 + XiCon Loss:2.5498 x Lambda(0.001)), Vali MSE Loss: 1.0057 Test MSE Loss: 0.8502
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.4694925
	speed: 0.0220s/iter; left time: 400.4957s
	iters: 200, epoch: 24 | loss: 0.5056545
	speed: 0.0189s/iter; left time: 343.2290s
Epoch: 24 cost time: 4.847503423690796
Epoch: 24, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5470 x Lambda(0.001)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5654668
	speed: 0.0222s/iter; left time: 399.4307s
	iters: 200, epoch: 25 | loss: 0.5323968
	speed: 0.0191s/iter; left time: 342.1278s
Epoch: 25 cost time: 4.8886895179748535
Epoch: 25, Steps: 238 Train Loss: 0.5416 (Forecasting Loss:0.5391 + XiCon Loss:2.5466 x Lambda(0.001)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5227532
	speed: 0.0221s/iter; left time: 392.1735s
	iters: 200, epoch: 26 | loss: 0.5641311
	speed: 0.0191s/iter; left time: 337.0865s
Epoch: 26 cost time: 4.872675895690918
Epoch: 26, Steps: 238 Train Loss: 0.5415 (Forecasting Loss:0.5390 + XiCon Loss:2.5498 x Lambda(0.001)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5401031
	speed: 0.0225s/iter; left time: 393.9923s
	iters: 200, epoch: 27 | loss: 0.5114896
	speed: 0.0189s/iter; left time: 329.0644s
Epoch: 27 cost time: 4.898271799087524
Epoch: 27, Steps: 238 Train Loss: 0.5417 (Forecasting Loss:0.5391 + XiCon Loss:2.5481 x Lambda(0.001)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9805903434753418, mae:0.7197731137275696, mape:4.739206314086914, mspe:2656.4580078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9842+-0.00978, MAE:0.7227+-0.00649, MAPE:4.8139+-0.19429, MSPE:2735.3745+-252.39269, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.3353
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 0.9684808
	speed: 0.0337s/iter; left time: 781.3442s
	iters: 200, epoch: 1 | loss: 0.9220234
	speed: 0.0285s/iter; left time: 658.5221s
Epoch: 1 cost time: 7.181562423706055
Epoch: 1, Steps: 233 Train Loss: 1.0217 (Forecasting Loss:1.0189 + XiCon Loss:2.8192 x Lambda(0.001)), Vali MSE Loss: 1.8606 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860574).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6041883
	speed: 0.0298s/iter; left time: 685.2654s
	iters: 200, epoch: 2 | loss: 0.6658692
	speed: 0.0277s/iter; left time: 632.8646s
Epoch: 2 cost time: 6.692784309387207
Epoch: 2, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.6522 + XiCon Loss:2.8181 x Lambda(0.001)), Vali MSE Loss: 1.1271 Test MSE Loss: 1.1493
Validation loss decreased (1.860574 --> 1.127102).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6308814
	speed: 0.0303s/iter; left time: 688.8204s
	iters: 200, epoch: 3 | loss: 0.5733516
	speed: 0.0282s/iter; left time: 637.1917s
Epoch: 3 cost time: 6.812419652938843
Epoch: 3, Steps: 233 Train Loss: 0.5909 (Forecasting Loss:0.5880 + XiCon Loss:2.8170 x Lambda(0.001)), Vali MSE Loss: 1.1044 Test MSE Loss: 1.1435
Validation loss decreased (1.127102 --> 1.104421).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5985439
	speed: 0.0311s/iter; left time: 700.9303s
	iters: 200, epoch: 4 | loss: 0.5962712
	speed: 0.0275s/iter; left time: 615.6480s
Epoch: 4 cost time: 6.822697401046753
Epoch: 4, Steps: 233 Train Loss: 0.5827 (Forecasting Loss:0.5798 + XiCon Loss:2.8174 x Lambda(0.001)), Vali MSE Loss: 1.0971 Test MSE Loss: 1.1409
Validation loss decreased (1.104421 --> 1.097119).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5715455
	speed: 0.0308s/iter; left time: 686.4072s
	iters: 200, epoch: 5 | loss: 0.5681034
	speed: 0.0279s/iter; left time: 618.0545s
Epoch: 5 cost time: 6.795106887817383
Epoch: 5, Steps: 233 Train Loss: 0.5794 (Forecasting Loss:0.5766 + XiCon Loss:2.8198 x Lambda(0.001)), Vali MSE Loss: 1.0937 Test MSE Loss: 1.1400
Validation loss decreased (1.097119 --> 1.093652).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5917339
	speed: 0.0307s/iter; left time: 676.8026s
	iters: 200, epoch: 6 | loss: 0.6024491
	speed: 0.0287s/iter; left time: 629.6400s
Epoch: 6 cost time: 6.919533967971802
Epoch: 6, Steps: 233 Train Loss: 0.5779 (Forecasting Loss:0.5751 + XiCon Loss:2.8226 x Lambda(0.001)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1397
Validation loss decreased (1.093652 --> 1.091955).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5682522
	speed: 0.0311s/iter; left time: 679.0023s
	iters: 200, epoch: 7 | loss: 0.6235952
	speed: 0.0281s/iter; left time: 609.3411s
Epoch: 7 cost time: 6.889323711395264
Epoch: 7, Steps: 233 Train Loss: 0.5771 (Forecasting Loss:0.5743 + XiCon Loss:2.8192 x Lambda(0.001)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1397
Validation loss decreased (1.091955 --> 1.091100).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5458178
	speed: 0.0315s/iter; left time: 680.5303s
	iters: 200, epoch: 8 | loss: 0.5894700
	speed: 0.0283s/iter; left time: 607.1570s
Epoch: 8 cost time: 6.958167791366577
Epoch: 8, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8228 x Lambda(0.001)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1395
Validation loss decreased (1.091100 --> 1.090956).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6224985
	speed: 0.0296s/iter; left time: 631.8757s
	iters: 200, epoch: 9 | loss: 0.6212907
	speed: 0.0279s/iter; left time: 591.6675s
Epoch: 9 cost time: 6.757799386978149
Epoch: 9, Steps: 233 Train Loss: 0.5765 (Forecasting Loss:0.5736 + XiCon Loss:2.8242 x Lambda(0.001)), Vali MSE Loss: 1.0905 Test MSE Loss: 1.1395
Validation loss decreased (1.090956 --> 1.090494).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5446888
	speed: 0.0303s/iter; left time: 638.6210s
	iters: 200, epoch: 10 | loss: 0.5665913
	speed: 0.0278s/iter; left time: 584.8275s
Epoch: 10 cost time: 6.748255729675293
Epoch: 10, Steps: 233 Train Loss: 0.5764 (Forecasting Loss:0.5736 + XiCon Loss:2.8209 x Lambda(0.001)), Vali MSE Loss: 1.0906 Test MSE Loss: 1.1394
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5628307
	speed: 0.0302s/iter; left time: 630.4528s
	iters: 200, epoch: 11 | loss: 0.5873883
	speed: 0.0289s/iter; left time: 599.9111s
Epoch: 11 cost time: 6.874411582946777
Epoch: 11, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8186 x Lambda(0.001)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1394
Validation loss decreased (1.090494 --> 1.090281).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5901271
	speed: 0.0309s/iter; left time: 638.0510s
	iters: 200, epoch: 12 | loss: 0.5759382
	speed: 0.0284s/iter; left time: 582.4522s
Epoch: 12 cost time: 6.891474485397339
Epoch: 12, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8174 x Lambda(0.001)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1394
Validation loss decreased (1.090281 --> 1.090121).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5637999
	speed: 0.0309s/iter; left time: 631.2371s
	iters: 200, epoch: 13 | loss: 0.5884099
	speed: 0.0279s/iter; left time: 567.4413s
Epoch: 13 cost time: 6.8502936363220215
Epoch: 13, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8214 x Lambda(0.001)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1394
Validation loss decreased (1.090121 --> 1.090062).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5874327
	speed: 0.0301s/iter; left time: 606.8948s
	iters: 200, epoch: 14 | loss: 0.5693994
	speed: 0.0279s/iter; left time: 560.8581s
Epoch: 14 cost time: 6.7531092166900635
Epoch: 14, Steps: 233 Train Loss: 0.5762 (Forecasting Loss:0.5734 + XiCon Loss:2.8165 x Lambda(0.001)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1394
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5593822
	speed: 0.0310s/iter; left time: 617.5499s
	iters: 200, epoch: 15 | loss: 0.6121262
	speed: 0.0281s/iter; left time: 557.3685s
Epoch: 15 cost time: 6.882266283035278
Epoch: 15, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8189 x Lambda(0.001)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1394
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5923375
	speed: 0.0307s/iter; left time: 605.3137s
	iters: 200, epoch: 16 | loss: 0.6036703
	speed: 0.0277s/iter; left time: 544.0656s
Epoch: 16 cost time: 6.83535623550415
Epoch: 16, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5734 + XiCon Loss:2.8186 x Lambda(0.001)), Vali MSE Loss: 1.0896 Test MSE Loss: 1.1394
Validation loss decreased (1.090062 --> 1.089648).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5701903
	speed: 0.0312s/iter; left time: 608.1715s
	iters: 200, epoch: 17 | loss: 0.5615225
	speed: 0.0281s/iter; left time: 544.6255s
Epoch: 17 cost time: 6.89637303352356
Epoch: 17, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5734 + XiCon Loss:2.8164 x Lambda(0.001)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1394
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6120747
	speed: 0.0307s/iter; left time: 591.5514s
	iters: 200, epoch: 18 | loss: 0.5835719
	speed: 0.0281s/iter; left time: 538.3692s
Epoch: 18 cost time: 6.816024541854858
Epoch: 18, Steps: 233 Train Loss: 0.5762 (Forecasting Loss:0.5734 + XiCon Loss:2.8197 x Lambda(0.001)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1394
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5660520
	speed: 0.0310s/iter; left time: 588.7861s
	iters: 200, epoch: 19 | loss: 0.6553601
	speed: 0.0281s/iter; left time: 530.3981s
Epoch: 19 cost time: 6.869246482849121
Epoch: 19, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5734 + XiCon Loss:2.8209 x Lambda(0.001)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1394
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5488260
	speed: 0.0308s/iter; left time: 577.6753s
	iters: 200, epoch: 20 | loss: 0.5558025
	speed: 0.0279s/iter; left time: 520.9492s
Epoch: 20 cost time: 6.8348259925842285
Epoch: 20, Steps: 233 Train Loss: 0.5762 (Forecasting Loss:0.5734 + XiCon Loss:2.8192 x Lambda(0.001)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1394
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5761880
	speed: 0.0315s/iter; left time: 583.1912s
	iters: 200, epoch: 21 | loss: 0.5570211
	speed: 0.0280s/iter; left time: 516.4652s
Epoch: 21 cost time: 6.905911922454834
Epoch: 21, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8202 x Lambda(0.001)), Vali MSE Loss: 1.0905 Test MSE Loss: 1.1394
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5493810
	speed: 0.0307s/iter; left time: 561.4974s
	iters: 200, epoch: 22 | loss: 0.5509899
	speed: 0.0282s/iter; left time: 512.8641s
Epoch: 22 cost time: 6.844609975814819
Epoch: 22, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8212 x Lambda(0.001)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1394
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5200185
	speed: 0.0306s/iter; left time: 553.3769s
	iters: 200, epoch: 23 | loss: 0.5769726
	speed: 0.0280s/iter; left time: 503.2251s
Epoch: 23 cost time: 6.808199167251587
Epoch: 23, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5734 + XiCon Loss:2.8169 x Lambda(0.001)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1394
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5651805
	speed: 0.0308s/iter; left time: 549.3594s
	iters: 200, epoch: 24 | loss: 0.5491403
	speed: 0.0281s/iter; left time: 498.5974s
Epoch: 24 cost time: 6.850623369216919
Epoch: 24, Steps: 233 Train Loss: 0.5762 (Forecasting Loss:0.5734 + XiCon Loss:2.8210 x Lambda(0.001)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1394
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5733175
	speed: 0.0307s/iter; left time: 540.4137s
	iters: 200, epoch: 25 | loss: 0.5506579
	speed: 0.0281s/iter; left time: 491.6856s
Epoch: 25 cost time: 6.833060264587402
Epoch: 25, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5735 + XiCon Loss:2.8242 x Lambda(0.001)), Vali MSE Loss: 1.0904 Test MSE Loss: 1.1394
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5510808
	speed: 0.0310s/iter; left time: 538.2274s
	iters: 200, epoch: 26 | loss: 0.6196649
	speed: 0.0284s/iter; left time: 491.0042s
Epoch: 26 cost time: 6.889221668243408
Epoch: 26, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.5734 + XiCon Loss:2.8142 x Lambda(0.001)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1394
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3993337154388428, mae:0.879525899887085, mape:6.133382320404053, mspe:4540.56689453125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.9125
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1532390
	speed: 0.0284s/iter; left time: 659.9772s
	iters: 200, epoch: 1 | loss: 1.1133114
	speed: 0.0238s/iter; left time: 548.8851s
Epoch: 1 cost time: 6.052783727645874
Epoch: 1, Steps: 233 Train Loss: 1.1369 (Forecasting Loss:1.1341 + XiCon Loss:2.8420 x Lambda(0.001)), Vali MSE Loss: 2.0405 Test MSE Loss: 1.3313
Validation loss decreased (inf --> 2.040454).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6824462
	speed: 0.0276s/iter; left time: 634.0446s
	iters: 200, epoch: 2 | loss: 0.5983501
	speed: 0.0248s/iter; left time: 566.9981s
Epoch: 2 cost time: 6.05792236328125
Epoch: 2, Steps: 233 Train Loss: 0.6627 (Forecasting Loss:0.6598 + XiCon Loss:2.8432 x Lambda(0.001)), Vali MSE Loss: 1.1149 Test MSE Loss: 1.1426
Validation loss decreased (2.040454 --> 1.114872).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5753400
	speed: 0.0277s/iter; left time: 628.8918s
	iters: 200, epoch: 3 | loss: 0.5664462
	speed: 0.0237s/iter; left time: 536.4154s
Epoch: 3 cost time: 5.94769287109375
Epoch: 3, Steps: 233 Train Loss: 0.5902 (Forecasting Loss:0.5874 + XiCon Loss:2.8475 x Lambda(0.001)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1375
Validation loss decreased (1.114872 --> 1.091948).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6312461
	speed: 0.0269s/iter; left time: 606.2487s
	iters: 200, epoch: 4 | loss: 0.5600864
	speed: 0.0238s/iter; left time: 533.1247s
Epoch: 4 cost time: 5.892267465591431
Epoch: 4, Steps: 233 Train Loss: 0.5818 (Forecasting Loss:0.5789 + XiCon Loss:2.8456 x Lambda(0.001)), Vali MSE Loss: 1.0846 Test MSE Loss: 1.1359
Validation loss decreased (1.091948 --> 1.084639).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.6523901
	speed: 0.0276s/iter; left time: 615.2761s
	iters: 200, epoch: 5 | loss: 0.5438025
	speed: 0.0239s/iter; left time: 530.5379s
Epoch: 5 cost time: 5.989508867263794
Epoch: 5, Steps: 233 Train Loss: 0.5784 (Forecasting Loss:0.5756 + XiCon Loss:2.8509 x Lambda(0.001)), Vali MSE Loss: 1.0800 Test MSE Loss: 1.1357
Validation loss decreased (1.084639 --> 1.079981).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6384515
	speed: 0.0274s/iter; left time: 604.2752s
	iters: 200, epoch: 6 | loss: 0.6166834
	speed: 0.0239s/iter; left time: 523.5890s
Epoch: 6 cost time: 5.9450695514678955
Epoch: 6, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5740 + XiCon Loss:2.8515 x Lambda(0.001)), Vali MSE Loss: 1.0789 Test MSE Loss: 1.1348
Validation loss decreased (1.079981 --> 1.078877).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5775357
	speed: 0.0276s/iter; left time: 600.7316s
	iters: 200, epoch: 7 | loss: 0.5648443
	speed: 0.0236s/iter; left time: 512.7277s
Epoch: 7 cost time: 5.9327123165130615
Epoch: 7, Steps: 233 Train Loss: 0.5761 (Forecasting Loss:0.5733 + XiCon Loss:2.8483 x Lambda(0.001)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1351
Validation loss decreased (1.078877 --> 1.077404).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5716436
	speed: 0.0275s/iter; left time: 592.7786s
	iters: 200, epoch: 8 | loss: 0.6263203
	speed: 0.0238s/iter; left time: 512.0475s
Epoch: 8 cost time: 5.957860469818115
Epoch: 8, Steps: 233 Train Loss: 0.5756 (Forecasting Loss:0.5727 + XiCon Loss:2.8488 x Lambda(0.001)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1350
Validation loss decreased (1.077404 --> 1.076854).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5531855
	speed: 0.0273s/iter; left time: 582.2056s
	iters: 200, epoch: 9 | loss: 0.5594033
	speed: 0.0238s/iter; left time: 506.0225s
Epoch: 9 cost time: 5.929488182067871
Epoch: 9, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.5726 + XiCon Loss:2.8447 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
Validation loss decreased (1.076854 --> 1.076500).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5830768
	speed: 0.0277s/iter; left time: 583.9061s
	iters: 200, epoch: 10 | loss: 0.5808765
	speed: 0.0237s/iter; left time: 498.0784s
Epoch: 10 cost time: 5.966149568557739
Epoch: 10, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.5726 + XiCon Loss:2.8550 x Lambda(0.001)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1350
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5156196
	speed: 0.0273s/iter; left time: 569.6107s
	iters: 200, epoch: 11 | loss: 0.5779896
	speed: 0.0237s/iter; left time: 492.3161s
Epoch: 11 cost time: 5.912308216094971
Epoch: 11, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5725 + XiCon Loss:2.8445 x Lambda(0.001)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1350
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5569733
	speed: 0.0273s/iter; left time: 563.4128s
	iters: 200, epoch: 12 | loss: 0.5643911
	speed: 0.0237s/iter; left time: 486.9503s
Epoch: 12 cost time: 5.91583514213562
Epoch: 12, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8462 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
Validation loss decreased (1.076500 --> 1.076436).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5930659
	speed: 0.0275s/iter; left time: 560.9421s
	iters: 200, epoch: 13 | loss: 0.5908004
	speed: 0.0238s/iter; left time: 482.5382s
Epoch: 13 cost time: 5.938368797302246
Epoch: 13, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8462 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5611308
	speed: 0.0276s/iter; left time: 556.3038s
	iters: 200, epoch: 14 | loss: 0.5685794
	speed: 0.0236s/iter; left time: 474.0682s
Epoch: 14 cost time: 5.958923578262329
Epoch: 14, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5725 + XiCon Loss:2.8429 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
Validation loss decreased (1.076436 --> 1.076402).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5857053
	speed: 0.0280s/iter; left time: 557.8306s
	iters: 200, epoch: 15 | loss: 0.5477138
	speed: 0.0237s/iter; left time: 469.5436s
Epoch: 15 cost time: 5.996041536331177
Epoch: 15, Steps: 233 Train Loss: 0.5751 (Forecasting Loss:0.5723 + XiCon Loss:2.8459 x Lambda(0.001)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1350
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5815043
	speed: 0.0275s/iter; left time: 541.8880s
	iters: 200, epoch: 16 | loss: 0.6073406
	speed: 0.0235s/iter; left time: 461.5810s
Epoch: 16 cost time: 5.925449848175049
Epoch: 16, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5724 + XiCon Loss:2.8473 x Lambda(0.001)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1350
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5541092
	speed: 0.0273s/iter; left time: 531.8129s
	iters: 200, epoch: 17 | loss: 0.5309619
	speed: 0.0240s/iter; left time: 464.7824s
Epoch: 17 cost time: 5.948195457458496
Epoch: 17, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5723 + XiCon Loss:2.8480 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6169915
	speed: 0.0273s/iter; left time: 524.3809s
	iters: 200, epoch: 18 | loss: 0.5491853
	speed: 0.0240s/iter; left time: 459.5557s
Epoch: 18 cost time: 5.953294038772583
Epoch: 18, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8493 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5441202
	speed: 0.0272s/iter; left time: 517.4030s
	iters: 200, epoch: 19 | loss: 0.5704982
	speed: 0.0237s/iter; left time: 448.5634s
Epoch: 19 cost time: 5.913904190063477
Epoch: 19, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5724 + XiCon Loss:2.8500 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6142014
	speed: 0.0273s/iter; left time: 511.6131s
	iters: 200, epoch: 20 | loss: 0.5479389
	speed: 0.0235s/iter; left time: 438.2742s
Epoch: 20 cost time: 5.8967812061309814
Epoch: 20, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5724 + XiCon Loss:2.8445 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5504421
	speed: 0.0274s/iter; left time: 508.2912s
	iters: 200, epoch: 21 | loss: 0.5707834
	speed: 0.0238s/iter; left time: 438.0665s
Epoch: 21 cost time: 5.9320573806762695
Epoch: 21, Steps: 233 Train Loss: 0.5755 (Forecasting Loss:0.5726 + XiCon Loss:2.8483 x Lambda(0.001)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1350
Validation loss decreased (1.076402 --> 1.076259).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6069832
	speed: 0.0276s/iter; left time: 504.9407s
	iters: 200, epoch: 22 | loss: 0.5925093
	speed: 0.0240s/iter; left time: 437.4090s
Epoch: 22 cost time: 5.989474534988403
Epoch: 22, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8459 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5588728
	speed: 0.0287s/iter; left time: 519.6503s
	iters: 200, epoch: 23 | loss: 0.5964524
	speed: 0.0241s/iter; left time: 432.3668s
Epoch: 23 cost time: 6.094350576400757
Epoch: 23, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5725 + XiCon Loss:2.8483 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5573224
	speed: 0.0812s/iter; left time: 1449.0040s
	iters: 200, epoch: 24 | loss: 0.5432999
	speed: 0.0852s/iter; left time: 1511.0443s
Epoch: 24 cost time: 19.246392250061035
Epoch: 24, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5723 + XiCon Loss:2.8505 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6449158
	speed: 0.0869s/iter; left time: 1530.6170s
	iters: 200, epoch: 25 | loss: 0.5916868
	speed: 0.0794s/iter; left time: 1390.8824s
Epoch: 25 cost time: 19.171481609344482
Epoch: 25, Steps: 233 Train Loss: 0.5751 (Forecasting Loss:0.5723 + XiCon Loss:2.8481 x Lambda(0.001)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1350
Validation loss decreased (1.076259 --> 1.076171).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5911860
	speed: 0.0944s/iter; left time: 1641.1162s
	iters: 200, epoch: 26 | loss: 0.5514231
	speed: 0.0830s/iter; left time: 1433.3741s
Epoch: 26 cost time: 20.58670949935913
Epoch: 26, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8471 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5655335
	speed: 0.0937s/iter; left time: 1605.6018s
	iters: 200, epoch: 27 | loss: 0.6173632
	speed: 0.0781s/iter; left time: 1331.8838s
Epoch: 27 cost time: 19.782572031021118
Epoch: 27, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.5726 + XiCon Loss:2.8497 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5133041
	speed: 0.0901s/iter; left time: 1523.0649s
	iters: 200, epoch: 28 | loss: 0.5804422
	speed: 0.0952s/iter; left time: 1599.5862s
Epoch: 28 cost time: 21.07287359237671
Epoch: 28, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8465 x Lambda(0.001)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1350
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5875967
	speed: 0.0940s/iter; left time: 1567.7888s
	iters: 200, epoch: 29 | loss: 0.5675753
	speed: 0.0861s/iter; left time: 1428.0943s
Epoch: 29 cost time: 20.704211235046387
Epoch: 29, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8492 x Lambda(0.001)), Vali MSE Loss: 1.0768 Test MSE Loss: 1.1350
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5959005
	speed: 0.0874s/iter; left time: 1437.0413s
	iters: 200, epoch: 30 | loss: 0.6027742
	speed: 0.0841s/iter; left time: 1374.3464s
Epoch: 30 cost time: 19.984262466430664
Epoch: 30, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.5725 + XiCon Loss:2.8465 x Lambda(0.001)), Vali MSE Loss: 1.0762 Test MSE Loss: 1.1350
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5528976
	speed: 0.0891s/iter; left time: 1445.0272s
	iters: 200, epoch: 31 | loss: 0.5708387
	speed: 0.0783s/iter; left time: 1262.1234s
Epoch: 31 cost time: 19.729372024536133
Epoch: 31, Steps: 233 Train Loss: 0.5751 (Forecasting Loss:0.5723 + XiCon Loss:2.8465 x Lambda(0.001)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1350
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5931354
	speed: 0.0953s/iter; left time: 1522.2518s
	iters: 200, epoch: 32 | loss: 0.6018616
	speed: 0.0774s/iter; left time: 1228.3016s
Epoch: 32 cost time: 19.76576256752014
Epoch: 32, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5724 + XiCon Loss:2.8469 x Lambda(0.001)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1350
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5406175
	speed: 0.0996s/iter; left time: 1567.5726s
	iters: 200, epoch: 33 | loss: 0.5982028
	speed: 0.1020s/iter; left time: 1595.4420s
Epoch: 33 cost time: 23.51992440223694
Epoch: 33, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.5725 + XiCon Loss:2.8456 x Lambda(0.001)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1350
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5498211
	speed: 0.1021s/iter; left time: 1583.7784s
	iters: 200, epoch: 34 | loss: 0.5508236
	speed: 0.0965s/iter; left time: 1487.6876s
Epoch: 34 cost time: 23.267309188842773
Epoch: 34, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.5725 + XiCon Loss:2.8457 x Lambda(0.001)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1350
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5743920
	speed: 0.0996s/iter; left time: 1521.8472s
	iters: 200, epoch: 35 | loss: 0.5914064
	speed: 0.0980s/iter; left time: 1488.0996s
Epoch: 35 cost time: 23.019192218780518
Epoch: 35, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.5723 + XiCon Loss:2.8498 x Lambda(0.001)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1350
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.392657995223999, mae:0.8772985339164734, mape:6.099455833435059, mspe:4458.435546875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 27.6544
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.1454265
	speed: 0.0999s/iter; left time: 2317.0788s
	iters: 200, epoch: 1 | loss: 0.9636606
	speed: 0.0945s/iter; left time: 2183.2699s
Epoch: 1 cost time: 22.8642361164093
Epoch: 1, Steps: 233 Train Loss: 1.0165 (Forecasting Loss:1.0137 + XiCon Loss:2.8480 x Lambda(0.001)), Vali MSE Loss: 1.8333 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833308).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6466657
	speed: 0.0998s/iter; left time: 2292.0869s
	iters: 200, epoch: 2 | loss: 0.5522886
	speed: 0.0912s/iter; left time: 2085.6001s
Epoch: 2 cost time: 22.1445050239563
Epoch: 2, Steps: 233 Train Loss: 0.6553 (Forecasting Loss:0.6525 + XiCon Loss:2.8475 x Lambda(0.001)), Vali MSE Loss: 1.1218 Test MSE Loss: 1.1452
Validation loss decreased (1.833308 --> 1.121845).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.5843436
	speed: 0.0928s/iter; left time: 2110.0054s
	iters: 200, epoch: 3 | loss: 0.5702525
	speed: 0.0899s/iter; left time: 2034.1674s
Epoch: 3 cost time: 21.234557151794434
Epoch: 3, Steps: 233 Train Loss: 0.5911 (Forecasting Loss:0.5883 + XiCon Loss:2.8400 x Lambda(0.001)), Vali MSE Loss: 1.0999 Test MSE Loss: 1.1378
Validation loss decreased (1.121845 --> 1.099893).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6199087
	speed: 0.0919s/iter; left time: 2068.7884s
	iters: 200, epoch: 4 | loss: 0.5976143
	speed: 0.0915s/iter; left time: 2049.4559s
Epoch: 4 cost time: 21.130442142486572
Epoch: 4, Steps: 233 Train Loss: 0.5826 (Forecasting Loss:0.5798 + XiCon Loss:2.8414 x Lambda(0.001)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1365
Validation loss decreased (1.099893 --> 1.091031).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5493909
	speed: 0.0865s/iter; left time: 1925.5197s
	iters: 200, epoch: 5 | loss: 0.5385825
	speed: 0.0807s/iter; left time: 1789.6863s
Epoch: 5 cost time: 19.362101316452026
Epoch: 5, Steps: 233 Train Loss: 0.5791 (Forecasting Loss:0.5763 + XiCon Loss:2.8396 x Lambda(0.001)), Vali MSE Loss: 1.0869 Test MSE Loss: 1.1360
Validation loss decreased (1.091031 --> 1.086908).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5886482
	speed: 0.0830s/iter; left time: 1829.7996s
	iters: 200, epoch: 6 | loss: 0.5910250
	speed: 0.0813s/iter; left time: 1783.2892s
Epoch: 6 cost time: 19.08952021598816
Epoch: 6, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.5746 + XiCon Loss:2.8452 x Lambda(0.001)), Vali MSE Loss: 1.0852 Test MSE Loss: 1.1358
Validation loss decreased (1.086908 --> 1.085174).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5241603
	speed: 0.0853s/iter; left time: 1860.5493s
	iters: 200, epoch: 7 | loss: 0.6270171
	speed: 0.0807s/iter; left time: 1751.2162s
Epoch: 7 cost time: 19.254385232925415
Epoch: 7, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8404 x Lambda(0.001)), Vali MSE Loss: 1.0843 Test MSE Loss: 1.1357
Validation loss decreased (1.085174 --> 1.084308).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5754548
	speed: 0.0768s/iter; left time: 1657.2232s
	iters: 200, epoch: 8 | loss: 0.5601887
	speed: 0.0711s/iter; left time: 1527.2216s
Epoch: 8 cost time: 17.31992244720459
Epoch: 8, Steps: 233 Train Loss: 0.5762 (Forecasting Loss:0.5734 + XiCon Loss:2.8397 x Lambda(0.001)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1356
Validation loss decreased (1.084308 --> 1.083876).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6039290
	speed: 0.0744s/iter; left time: 1587.8652s
	iters: 200, epoch: 9 | loss: 0.5552103
	speed: 0.0730s/iter; left time: 1549.2532s
Epoch: 9 cost time: 17.25947880744934
Epoch: 9, Steps: 233 Train Loss: 0.5760 (Forecasting Loss:0.5732 + XiCon Loss:2.8493 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1356
Validation loss decreased (1.083876 --> 1.083526).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5459881
	speed: 0.0743s/iter; left time: 1567.1612s
	iters: 200, epoch: 10 | loss: 0.5776651
	speed: 0.0742s/iter; left time: 1558.9636s
Epoch: 10 cost time: 17.26432156562805
Epoch: 10, Steps: 233 Train Loss: 0.5760 (Forecasting Loss:0.5731 + XiCon Loss:2.8445 x Lambda(0.001)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1356
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5783731
	speed: 0.0778s/iter; left time: 1622.7655s
	iters: 200, epoch: 11 | loss: 0.5825896
	speed: 0.0677s/iter; left time: 1407.0016s
Epoch: 11 cost time: 16.76740288734436
Epoch: 11, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5731 + XiCon Loss:2.8398 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
Validation loss decreased (1.083526 --> 1.083428).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5390588
	speed: 0.0682s/iter; left time: 1408.1030s
	iters: 200, epoch: 12 | loss: 0.5398514
	speed: 0.0630s/iter; left time: 1293.7166s
Epoch: 12 cost time: 15.402989387512207
Epoch: 12, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8407 x Lambda(0.001)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6223275
	speed: 0.0676s/iter; left time: 1378.9572s
	iters: 200, epoch: 13 | loss: 0.5735106
	speed: 0.0632s/iter; left time: 1282.8137s
Epoch: 13 cost time: 15.320900201797485
Epoch: 13, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5731 + XiCon Loss:2.8429 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5805680
	speed: 0.0693s/iter; left time: 1397.3095s
	iters: 200, epoch: 14 | loss: 0.5930505
	speed: 0.0668s/iter; left time: 1340.0632s
Epoch: 14 cost time: 15.811853170394897
Epoch: 14, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5729 + XiCon Loss:2.8396 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5328473
	speed: 0.0687s/iter; left time: 1370.0383s
	iters: 200, epoch: 15 | loss: 0.5843215
	speed: 0.0675s/iter; left time: 1339.9753s
Epoch: 15 cost time: 15.90390157699585
Epoch: 15, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5731 + XiCon Loss:2.8408 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5789131
	speed: 0.0455s/iter; left time: 895.7352s
	iters: 200, epoch: 16 | loss: 0.5642830
	speed: 0.0377s/iter; left time: 738.4377s
Epoch: 16 cost time: 9.56734037399292
Epoch: 16, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5731 + XiCon Loss:2.8427 x Lambda(0.001)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5212893
	speed: 0.0401s/iter; left time: 781.6882s
	iters: 200, epoch: 17 | loss: 0.5489100
	speed: 0.0377s/iter; left time: 730.8699s
Epoch: 17 cost time: 9.029825448989868
Epoch: 17, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5730 + XiCon Loss:2.8427 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
Validation loss decreased (1.083428 --> 1.083400).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5865652
	speed: 0.0422s/iter; left time: 812.6829s
	iters: 200, epoch: 18 | loss: 0.5599081
	speed: 0.0370s/iter; left time: 708.2150s
Epoch: 18 cost time: 9.136667728424072
Epoch: 18, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8382 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5621947
	speed: 0.0410s/iter; left time: 779.0183s
	iters: 200, epoch: 19 | loss: 0.5889577
	speed: 0.0357s/iter; left time: 675.2688s
Epoch: 19 cost time: 8.878450155258179
Epoch: 19, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8435 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5987142
	speed: 0.0395s/iter; left time: 741.2580s
	iters: 200, epoch: 20 | loss: 0.5458167
	speed: 0.0358s/iter; left time: 669.3471s
Epoch: 20 cost time: 8.748650550842285
Epoch: 20, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5730 + XiCon Loss:2.8408 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6503162
	speed: 0.0415s/iter; left time: 769.4804s
	iters: 200, epoch: 21 | loss: 0.5128505
	speed: 0.0363s/iter; left time: 669.5906s
Epoch: 21 cost time: 8.925365209579468
Epoch: 21, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8467 x Lambda(0.001)), Vali MSE Loss: 1.0833 Test MSE Loss: 1.1355
Validation loss decreased (1.083400 --> 1.083271).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5284272
	speed: 0.0381s/iter; left time: 697.6566s
	iters: 200, epoch: 22 | loss: 0.5603480
	speed: 0.0313s/iter; left time: 569.3178s
Epoch: 22 cost time: 7.965969562530518
Epoch: 22, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5729 + XiCon Loss:2.8435 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5661311
	speed: 0.0329s/iter; left time: 594.2564s
	iters: 200, epoch: 23 | loss: 0.6230034
	speed: 0.0321s/iter; left time: 576.5827s
Epoch: 23 cost time: 7.537522554397583
Epoch: 23, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8393 x Lambda(0.001)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5317765
	speed: 0.0340s/iter; left time: 606.6129s
	iters: 200, epoch: 24 | loss: 0.5943254
	speed: 0.0304s/iter; left time: 539.2583s
Epoch: 24 cost time: 7.448001861572266
Epoch: 24, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5730 + XiCon Loss:2.8419 x Lambda(0.001)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6350690
	speed: 0.0335s/iter; left time: 589.8857s
	iters: 200, epoch: 25 | loss: 0.4976733
	speed: 0.0320s/iter; left time: 561.1090s
Epoch: 25 cost time: 7.562948226928711
Epoch: 25, Steps: 233 Train Loss: 0.5759 (Forecasting Loss:0.5730 + XiCon Loss:2.8393 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6008463
	speed: 0.0344s/iter; left time: 597.4328s
	iters: 200, epoch: 26 | loss: 0.5830141
	speed: 0.0309s/iter; left time: 533.2046s
Epoch: 26 cost time: 7.5738935470581055
Epoch: 26, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8377 x Lambda(0.001)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5727043
	speed: 0.0352s/iter; left time: 603.1157s
	iters: 200, epoch: 27 | loss: 0.6150937
	speed: 0.0301s/iter; left time: 512.6651s
Epoch: 27 cost time: 7.552952527999878
Epoch: 27, Steps: 233 Train Loss: 0.5757 (Forecasting Loss:0.5729 + XiCon Loss:2.8344 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5718001
	speed: 0.0334s/iter; left time: 564.9281s
	iters: 200, epoch: 28 | loss: 0.5821080
	speed: 0.0309s/iter; left time: 519.1104s
Epoch: 28 cost time: 7.439979314804077
Epoch: 28, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5729 + XiCon Loss:2.8424 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5545475
	speed: 0.0329s/iter; left time: 547.8732s
	iters: 200, epoch: 29 | loss: 0.5751688
	speed: 0.0308s/iter; left time: 511.3821s
Epoch: 29 cost time: 7.448410749435425
Epoch: 29, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8456 x Lambda(0.001)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5802968
	speed: 0.0336s/iter; left time: 553.3395s
	iters: 200, epoch: 30 | loss: 0.5338093
	speed: 0.0307s/iter; left time: 501.4983s
Epoch: 30 cost time: 7.436243772506714
Epoch: 30, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5729 + XiCon Loss:2.8418 x Lambda(0.001)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5265877
	speed: 0.0316s/iter; left time: 513.0637s
	iters: 200, epoch: 31 | loss: 0.5640129
	speed: 0.0289s/iter; left time: 464.9063s
Epoch: 31 cost time: 7.042800426483154
Epoch: 31, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.5730 + XiCon Loss:2.8423 x Lambda(0.001)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3916676044464111, mae:0.8794131875038147, mape:6.169376373291016, mspe:4551.91943359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 19.9378
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0239410
	speed: 0.0341s/iter; left time: 790.3576s
	iters: 200, epoch: 1 | loss: 0.9908425
	speed: 0.0300s/iter; left time: 692.4319s
Epoch: 1 cost time: 7.429190158843994
Epoch: 1, Steps: 233 Train Loss: 1.0306 (Forecasting Loss:1.0277 + XiCon Loss:2.8678 x Lambda(0.001)), Vali MSE Loss: 1.8645 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6280242
	speed: 0.0333s/iter; left time: 765.1502s
	iters: 200, epoch: 2 | loss: 0.6006842
	speed: 0.0298s/iter; left time: 680.8853s
Epoch: 2 cost time: 7.35511040687561
Epoch: 2, Steps: 233 Train Loss: 0.6573 (Forecasting Loss:0.6545 + XiCon Loss:2.8686 x Lambda(0.001)), Vali MSE Loss: 1.1223 Test MSE Loss: 1.1458
Validation loss decreased (1.864491 --> 1.122252).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6088852
	speed: 0.0336s/iter; left time: 764.2726s
	iters: 200, epoch: 3 | loss: 0.6416197
	speed: 0.0303s/iter; left time: 685.1308s
Epoch: 3 cost time: 7.406940221786499
Epoch: 3, Steps: 233 Train Loss: 0.5921 (Forecasting Loss:0.5892 + XiCon Loss:2.8713 x Lambda(0.001)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1396
Validation loss decreased (1.122252 --> 1.102356).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5441522
	speed: 0.0338s/iter; left time: 759.9491s
	iters: 200, epoch: 4 | loss: 0.6028287
	speed: 0.0295s/iter; left time: 661.4245s
Epoch: 4 cost time: 7.3213183879852295
Epoch: 4, Steps: 233 Train Loss: 0.5837 (Forecasting Loss:0.5808 + XiCon Loss:2.8689 x Lambda(0.001)), Vali MSE Loss: 1.0934 Test MSE Loss: 1.1380
Validation loss decreased (1.102356 --> 1.093387).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5615053
	speed: 0.0325s/iter; left time: 723.0921s
	iters: 200, epoch: 5 | loss: 0.5608919
	speed: 0.0283s/iter; left time: 626.5929s
Epoch: 5 cost time: 7.071259260177612
Epoch: 5, Steps: 233 Train Loss: 0.5802 (Forecasting Loss:0.5773 + XiCon Loss:2.8696 x Lambda(0.001)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1376
Validation loss decreased (1.093387 --> 1.089786).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5629481
	speed: 0.0333s/iter; left time: 733.4201s
	iters: 200, epoch: 6 | loss: 0.6004867
	speed: 0.0298s/iter; left time: 652.7411s
Epoch: 6 cost time: 7.311201810836792
Epoch: 6, Steps: 233 Train Loss: 0.5786 (Forecasting Loss:0.5757 + XiCon Loss:2.8754 x Lambda(0.001)), Vali MSE Loss: 1.0876 Test MSE Loss: 1.1376
Validation loss decreased (1.089786 --> 1.087584).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5835017
	speed: 0.0327s/iter; left time: 712.9883s
	iters: 200, epoch: 7 | loss: 0.6016296
	speed: 0.0288s/iter; left time: 625.2206s
Epoch: 7 cost time: 7.1420371532440186
Epoch: 7, Steps: 233 Train Loss: 0.5776 (Forecasting Loss:0.5748 + XiCon Loss:2.8702 x Lambda(0.001)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1377
Validation loss decreased (1.087584 --> 1.086519).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6060846
	speed: 0.0330s/iter; left time: 710.8746s
	iters: 200, epoch: 8 | loss: 0.5611430
	speed: 0.0289s/iter; left time: 621.4419s
Epoch: 8 cost time: 7.194016933441162
Epoch: 8, Steps: 233 Train Loss: 0.5772 (Forecasting Loss:0.5744 + XiCon Loss:2.8694 x Lambda(0.001)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1376
Validation loss decreased (1.086519 --> 1.086161).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5956482
	speed: 0.0329s/iter; left time: 702.9172s
	iters: 200, epoch: 9 | loss: 0.6337007
	speed: 0.0295s/iter; left time: 626.7974s
Epoch: 9 cost time: 7.234960079193115
Epoch: 9, Steps: 233 Train Loss: 0.5770 (Forecasting Loss:0.5741 + XiCon Loss:2.8692 x Lambda(0.001)), Vali MSE Loss: 1.0857 Test MSE Loss: 1.1376
Validation loss decreased (1.086161 --> 1.085679).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5916209
	speed: 0.0324s/iter; left time: 683.1230s
	iters: 200, epoch: 10 | loss: 0.5545775
	speed: 0.0296s/iter; left time: 622.7404s
Epoch: 10 cost time: 7.1884424686431885
Epoch: 10, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5740 + XiCon Loss:2.8729 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
Validation loss decreased (1.085679 --> 1.085526).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5734029
	speed: 0.0332s/iter; left time: 692.3200s
	iters: 200, epoch: 11 | loss: 0.5797891
	speed: 0.0295s/iter; left time: 612.2976s
Epoch: 11 cost time: 7.284964323043823
Epoch: 11, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8728 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
Validation loss decreased (1.085526 --> 1.085433).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6061460
	speed: 0.0315s/iter; left time: 649.8231s
	iters: 200, epoch: 12 | loss: 0.5335786
	speed: 0.0292s/iter; left time: 598.7144s
Epoch: 12 cost time: 7.054694890975952
Epoch: 12, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8748 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6007081
	speed: 0.0334s/iter; left time: 681.1868s
	iters: 200, epoch: 13 | loss: 0.5607243
	speed: 0.0287s/iter; left time: 582.4094s
Epoch: 13 cost time: 7.211889266967773
Epoch: 13, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8683 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5680482
	speed: 0.0323s/iter; left time: 651.1348s
	iters: 200, epoch: 14 | loss: 0.6275551
	speed: 0.0298s/iter; left time: 598.5732s
Epoch: 14 cost time: 7.212302207946777
Epoch: 14, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8710 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6027865
	speed: 0.0322s/iter; left time: 641.3756s
	iters: 200, epoch: 15 | loss: 0.5859372
	speed: 0.0288s/iter; left time: 570.4186s
Epoch: 15 cost time: 7.053925037384033
Epoch: 15, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8718 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5899475
	speed: 0.0327s/iter; left time: 644.5000s
	iters: 200, epoch: 16 | loss: 0.5916355
	speed: 0.0292s/iter; left time: 572.0645s
Epoch: 16 cost time: 7.220736265182495
Epoch: 16, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8722 x Lambda(0.001)), Vali MSE Loss: 1.0852 Test MSE Loss: 1.1376
Validation loss decreased (1.085433 --> 1.085161).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.4907489
	speed: 0.0326s/iter; left time: 633.9431s
	iters: 200, epoch: 17 | loss: 0.6606735
	speed: 0.0291s/iter; left time: 563.4653s
Epoch: 17 cost time: 7.18687105178833
Epoch: 17, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8737 x Lambda(0.001)), Vali MSE Loss: 1.0852 Test MSE Loss: 1.1376
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5848742
	speed: 0.0331s/iter; left time: 637.2080s
	iters: 200, epoch: 18 | loss: 0.5649071
	speed: 0.0284s/iter; left time: 544.1155s
Epoch: 18 cost time: 7.135624647140503
Epoch: 18, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8726 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5898306
	speed: 0.0327s/iter; left time: 620.9287s
	iters: 200, epoch: 19 | loss: 0.6403426
	speed: 0.0290s/iter; left time: 547.5975s
Epoch: 19 cost time: 7.184817552566528
Epoch: 19, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8719 x Lambda(0.001)), Vali MSE Loss: 1.0852 Test MSE Loss: 1.1376
Validation loss decreased (1.085161 --> 1.085153).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6337183
	speed: 0.0322s/iter; left time: 603.7902s
	iters: 200, epoch: 20 | loss: 0.5959253
	speed: 0.0291s/iter; left time: 543.7478s
Epoch: 20 cost time: 7.15466046333313
Epoch: 20, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8741 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5559136
	speed: 0.0325s/iter; left time: 602.8611s
	iters: 200, epoch: 21 | loss: 0.5656794
	speed: 0.0288s/iter; left time: 530.5881s
Epoch: 21 cost time: 7.102587938308716
Epoch: 21, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8654 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5883842
	speed: 0.0322s/iter; left time: 589.8953s
	iters: 200, epoch: 22 | loss: 0.5301371
	speed: 0.0286s/iter; left time: 520.8432s
Epoch: 22 cost time: 7.073596239089966
Epoch: 22, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8697 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5406070
	speed: 0.0322s/iter; left time: 581.3965s
	iters: 200, epoch: 23 | loss: 0.5842124
	speed: 0.0287s/iter; left time: 516.4247s
Epoch: 23 cost time: 7.069610595703125
Epoch: 23, Steps: 233 Train Loss: 0.5766 (Forecasting Loss:0.5737 + XiCon Loss:2.8694 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5689730
	speed: 0.0322s/iter; left time: 574.3058s
	iters: 200, epoch: 24 | loss: 0.6000334
	speed: 0.0286s/iter; left time: 508.0151s
Epoch: 24 cost time: 7.04747748374939
Epoch: 24, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8653 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5415664
	speed: 0.0317s/iter; left time: 558.8696s
	iters: 200, epoch: 25 | loss: 0.5785390
	speed: 0.0285s/iter; left time: 499.5905s
Epoch: 25 cost time: 7.030872583389282
Epoch: 25, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8714 x Lambda(0.001)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1376
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6213970
	speed: 0.0313s/iter; left time: 544.5776s
	iters: 200, epoch: 26 | loss: 0.5897229
	speed: 0.0285s/iter; left time: 491.9218s
Epoch: 26 cost time: 6.9772515296936035
Epoch: 26, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8745 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6063919
	speed: 0.0324s/iter; left time: 555.6465s
	iters: 200, epoch: 27 | loss: 0.5427110
	speed: 0.0288s/iter; left time: 491.3871s
Epoch: 27 cost time: 7.117419004440308
Epoch: 27, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8683 x Lambda(0.001)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1376
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5985897
	speed: 0.0323s/iter; left time: 545.9836s
	iters: 200, epoch: 28 | loss: 0.5833330
	speed: 0.0289s/iter; left time: 486.0960s
Epoch: 28 cost time: 7.1366963386535645
Epoch: 28, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8706 x Lambda(0.001)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1376
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5582452
	speed: 0.0326s/iter; left time: 543.1261s
	iters: 200, epoch: 29 | loss: 0.5962700
	speed: 0.0288s/iter; left time: 477.7579s
Epoch: 29 cost time: 7.1150267124176025
Epoch: 29, Steps: 233 Train Loss: 0.5766 (Forecasting Loss:0.5737 + XiCon Loss:2.8708 x Lambda(0.001)), Vali MSE Loss: 1.0851 Test MSE Loss: 1.1376
Validation loss decreased (1.085153 --> 1.085104).  Saving model ...
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.5488415
	speed: 0.0311s/iter; left time: 511.8112s
	iters: 200, epoch: 30 | loss: 0.5285506
	speed: 0.0286s/iter; left time: 467.0707s
Epoch: 30 cost time: 6.943873167037964
Epoch: 30, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8741 x Lambda(0.001)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1376
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5567648
	speed: 0.0310s/iter; left time: 502.5937s
	iters: 200, epoch: 31 | loss: 0.5794622
	speed: 0.0284s/iter; left time: 458.0413s
Epoch: 31 cost time: 6.915498495101929
Epoch: 31, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8674 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.5623613
	speed: 0.0314s/iter; left time: 502.1377s
	iters: 200, epoch: 32 | loss: 0.5548510
	speed: 0.0282s/iter; left time: 447.5932s
Epoch: 32 cost time: 6.93613338470459
Epoch: 32, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8672 x Lambda(0.001)), Vali MSE Loss: 1.0859 Test MSE Loss: 1.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5327631
	speed: 0.0318s/iter; left time: 500.3430s
	iters: 200, epoch: 33 | loss: 0.6324750
	speed: 0.0282s/iter; left time: 440.5481s
Epoch: 33 cost time: 6.965492010116577
Epoch: 33, Steps: 233 Train Loss: 0.5766 (Forecasting Loss:0.5738 + XiCon Loss:2.8750 x Lambda(0.001)), Vali MSE Loss: 1.0853 Test MSE Loss: 1.1376
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5553689
	speed: 0.0313s/iter; left time: 485.2663s
	iters: 200, epoch: 34 | loss: 0.5453841
	speed: 0.0281s/iter; left time: 432.8528s
Epoch: 34 cost time: 6.903839111328125
Epoch: 34, Steps: 233 Train Loss: 0.5766 (Forecasting Loss:0.5737 + XiCon Loss:2.8691 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5455695
	speed: 0.0315s/iter; left time: 481.4650s
	iters: 200, epoch: 35 | loss: 0.6009793
	speed: 0.0289s/iter; left time: 438.1277s
Epoch: 35 cost time: 7.001901626586914
Epoch: 35, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5738 + XiCon Loss:2.8659 x Lambda(0.001)), Vali MSE Loss: 1.0854 Test MSE Loss: 1.1376
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.6014154
	speed: 0.0313s/iter; left time: 471.2102s
	iters: 200, epoch: 36 | loss: 0.5446488
	speed: 0.0280s/iter; left time: 418.6399s
Epoch: 36 cost time: 6.879654169082642
Epoch: 36, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8682 x Lambda(0.001)), Vali MSE Loss: 1.0853 Test MSE Loss: 1.1376
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.5500230
	speed: 0.0320s/iter; left time: 474.1597s
	iters: 200, epoch: 37 | loss: 0.5937485
	speed: 0.0282s/iter; left time: 414.9172s
Epoch: 37 cost time: 7.008942365646362
Epoch: 37, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8725 x Lambda(0.001)), Vali MSE Loss: 1.0853 Test MSE Loss: 1.1376
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.5672052
	speed: 0.0311s/iter; left time: 453.0113s
	iters: 200, epoch: 38 | loss: 0.5571752
	speed: 0.0284s/iter; left time: 410.8730s
Epoch: 38 cost time: 6.918359279632568
Epoch: 38, Steps: 233 Train Loss: 0.5767 (Forecasting Loss:0.5739 + XiCon Loss:2.8722 x Lambda(0.001)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1376
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.5808946
	speed: 0.0316s/iter; left time: 453.1662s
	iters: 200, epoch: 39 | loss: 0.5547583
	speed: 0.0280s/iter; left time: 399.0128s
Epoch: 39 cost time: 6.925774335861206
Epoch: 39, Steps: 233 Train Loss: 0.5768 (Forecasting Loss:0.5739 + XiCon Loss:2.8693 x Lambda(0.001)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1376
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3960075378417969, mae:0.8792070746421814, mape:6.1732587814331055, mspe:4584.3515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.3381
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.0156733
	speed: 0.0280s/iter; left time: 650.2443s
	iters: 200, epoch: 1 | loss: 0.9606383
	speed: 0.0237s/iter; left time: 547.1079s
Epoch: 1 cost time: 5.970563650131226
Epoch: 1, Steps: 233 Train Loss: 1.0308 (Forecasting Loss:1.0279 + XiCon Loss:2.8259 x Lambda(0.001)), Vali MSE Loss: 1.8929 Test MSE Loss: 1.2473
Validation loss decreased (inf --> 1.892929).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6633170
	speed: 0.0305s/iter; left time: 699.6116s
	iters: 200, epoch: 2 | loss: 0.5829219
	speed: 0.0280s/iter; left time: 641.1233s
Epoch: 2 cost time: 6.797758340835571
Epoch: 2, Steps: 233 Train Loss: 0.6597 (Forecasting Loss:0.6569 + XiCon Loss:2.8380 x Lambda(0.001)), Vali MSE Loss: 1.1381 Test MSE Loss: 1.1436
Validation loss decreased (1.892929 --> 1.138075).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6256311
	speed: 0.0295s/iter; left time: 671.0638s
	iters: 200, epoch: 3 | loss: 0.5592049
	speed: 0.0272s/iter; left time: 616.5823s
Epoch: 3 cost time: 6.61745548248291
Epoch: 3, Steps: 233 Train Loss: 0.5948 (Forecasting Loss:0.5920 + XiCon Loss:2.8381 x Lambda(0.001)), Vali MSE Loss: 1.1167 Test MSE Loss: 1.1348
Validation loss decreased (1.138075 --> 1.116743).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.6298999
	speed: 0.0302s/iter; left time: 679.6961s
	iters: 200, epoch: 4 | loss: 0.5808468
	speed: 0.0282s/iter; left time: 631.3489s
Epoch: 4 cost time: 6.796911716461182
Epoch: 4, Steps: 233 Train Loss: 0.5868 (Forecasting Loss:0.5840 + XiCon Loss:2.8454 x Lambda(0.001)), Vali MSE Loss: 1.1088 Test MSE Loss: 1.1333
Validation loss decreased (1.116743 --> 1.108841).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5978702
	speed: 0.0299s/iter; left time: 665.2917s
	iters: 200, epoch: 5 | loss: 0.5814289
	speed: 0.0276s/iter; left time: 611.1927s
Epoch: 5 cost time: 6.733016014099121
Epoch: 5, Steps: 233 Train Loss: 0.5836 (Forecasting Loss:0.5808 + XiCon Loss:2.8406 x Lambda(0.001)), Vali MSE Loss: 1.1055 Test MSE Loss: 1.1326
Validation loss decreased (1.108841 --> 1.105471).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5787026
	speed: 0.0303s/iter; left time: 667.4382s
	iters: 200, epoch: 6 | loss: 0.6349916
	speed: 0.0279s/iter; left time: 610.9879s
Epoch: 6 cost time: 6.7868123054504395
Epoch: 6, Steps: 233 Train Loss: 0.5822 (Forecasting Loss:0.5793 + XiCon Loss:2.8443 x Lambda(0.001)), Vali MSE Loss: 1.1041 Test MSE Loss: 1.1324
Validation loss decreased (1.105471 --> 1.104133).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5904579
	speed: 0.0303s/iter; left time: 660.0405s
	iters: 200, epoch: 7 | loss: 0.5835184
	speed: 0.0283s/iter; left time: 614.0370s
Epoch: 7 cost time: 6.8134565353393555
Epoch: 7, Steps: 233 Train Loss: 0.5814 (Forecasting Loss:0.5785 + XiCon Loss:2.8459 x Lambda(0.001)), Vali MSE Loss: 1.1029 Test MSE Loss: 1.1322
Validation loss decreased (1.104133 --> 1.102908).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5529434
	speed: 0.0297s/iter; left time: 640.0313s
	iters: 200, epoch: 8 | loss: 0.6177878
	speed: 0.0283s/iter; left time: 606.6429s
Epoch: 8 cost time: 6.75404167175293
Epoch: 8, Steps: 233 Train Loss: 0.5809 (Forecasting Loss:0.5781 + XiCon Loss:2.8405 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1322
Validation loss decreased (1.102908 --> 1.102347).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5683746
	speed: 0.0300s/iter; left time: 640.3566s
	iters: 200, epoch: 9 | loss: 0.6015769
	speed: 0.0270s/iter; left time: 573.6856s
Epoch: 9 cost time: 6.67389988899231
Epoch: 9, Steps: 233 Train Loss: 0.5808 (Forecasting Loss:0.5780 + XiCon Loss:2.8463 x Lambda(0.001)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1322
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5552081
	speed: 0.0299s/iter; left time: 630.8737s
	iters: 200, epoch: 10 | loss: 0.5798402
	speed: 0.0276s/iter; left time: 579.4352s
Epoch: 10 cost time: 6.720875024795532
Epoch: 10, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5778 + XiCon Loss:2.8430 x Lambda(0.001)), Vali MSE Loss: 1.1024 Test MSE Loss: 1.1321
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5419542
	speed: 0.0297s/iter; left time: 618.8426s
	iters: 200, epoch: 11 | loss: 0.5526945
	speed: 0.0277s/iter; left time: 575.0954s
Epoch: 11 cost time: 6.699330806732178
Epoch: 11, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5778 + XiCon Loss:2.8477 x Lambda(0.001)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1321
Validation loss decreased (1.102347 --> 1.102012).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5541427
	speed: 0.0301s/iter; left time: 620.1742s
	iters: 200, epoch: 12 | loss: 0.6172267
	speed: 0.0276s/iter; left time: 567.5122s
Epoch: 12 cost time: 6.7440407276153564
Epoch: 12, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8436 x Lambda(0.001)), Vali MSE Loss: 1.1021 Test MSE Loss: 1.1321
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5953005
	speed: 0.0301s/iter; left time: 613.8602s
	iters: 200, epoch: 13 | loss: 0.5712612
	speed: 0.0277s/iter; left time: 562.8888s
Epoch: 13 cost time: 6.740906238555908
Epoch: 13, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8494 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1321
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.5427598
	speed: 0.0301s/iter; left time: 606.9179s
	iters: 200, epoch: 14 | loss: 0.5673452
	speed: 0.0279s/iter; left time: 559.8759s
Epoch: 14 cost time: 6.73374605178833
Epoch: 14, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8465 x Lambda(0.001)), Vali MSE Loss: 1.1021 Test MSE Loss: 1.1321
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5682892
	speed: 0.0301s/iter; left time: 600.3262s
	iters: 200, epoch: 15 | loss: 0.6006173
	speed: 0.0280s/iter; left time: 555.6899s
Epoch: 15 cost time: 6.769803285598755
Epoch: 15, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5777 + XiCon Loss:2.8494 x Lambda(0.001)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1321
Validation loss decreased (1.102012 --> 1.101965).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6131746
	speed: 0.0299s/iter; left time: 588.6364s
	iters: 200, epoch: 16 | loss: 0.5653729
	speed: 0.0275s/iter; left time: 540.0420s
Epoch: 16 cost time: 6.6990649700164795
Epoch: 16, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5777 + XiCon Loss:2.8476 x Lambda(0.001)), Vali MSE Loss: 1.1018 Test MSE Loss: 1.1321
Validation loss decreased (1.101965 --> 1.101799).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5821632
	speed: 0.0301s/iter; left time: 586.3004s
	iters: 200, epoch: 17 | loss: 0.6049503
	speed: 0.0283s/iter; left time: 547.6727s
Epoch: 17 cost time: 6.799952745437622
Epoch: 17, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8399 x Lambda(0.001)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1321
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6038328
	speed: 0.0299s/iter; left time: 574.4779s
	iters: 200, epoch: 18 | loss: 0.5889805
	speed: 0.0276s/iter; left time: 529.0052s
Epoch: 18 cost time: 6.7096030712127686
Epoch: 18, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5777 + XiCon Loss:2.8482 x Lambda(0.001)), Vali MSE Loss: 1.1017 Test MSE Loss: 1.1321
Validation loss decreased (1.101799 --> 1.101665).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5603909
	speed: 0.0308s/iter; left time: 585.9432s
	iters: 200, epoch: 19 | loss: 0.6345515
	speed: 0.0275s/iter; left time: 520.7746s
Epoch: 19 cost time: 6.788088321685791
Epoch: 19, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5776 + XiCon Loss:2.8441 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1321
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5829587
	speed: 0.0294s/iter; left time: 551.1757s
	iters: 200, epoch: 20 | loss: 0.5545228
	speed: 0.0275s/iter; left time: 513.6059s
Epoch: 20 cost time: 6.670250654220581
Epoch: 20, Steps: 233 Train Loss: 0.5804 (Forecasting Loss:0.5776 + XiCon Loss:2.8436 x Lambda(0.001)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1321
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6006361
	speed: 0.0303s/iter; left time: 561.0167s
	iters: 200, epoch: 21 | loss: 0.5922278
	speed: 0.0274s/iter; left time: 505.7529s
Epoch: 21 cost time: 6.736508369445801
Epoch: 21, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5777 + XiCon Loss:2.8456 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1321
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6005479
	speed: 0.0294s/iter; left time: 538.9715s
	iters: 200, epoch: 22 | loss: 0.5559490
	speed: 0.0277s/iter; left time: 504.1458s
Epoch: 22 cost time: 6.654277801513672
Epoch: 22, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8459 x Lambda(0.001)), Vali MSE Loss: 1.1021 Test MSE Loss: 1.1321
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6006764
	speed: 0.0303s/iter; left time: 547.6828s
	iters: 200, epoch: 23 | loss: 0.5796464
	speed: 0.0276s/iter; left time: 495.8535s
Epoch: 23 cost time: 6.740564584732056
Epoch: 23, Steps: 233 Train Loss: 0.5805 (Forecasting Loss:0.5777 + XiCon Loss:2.8421 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1321
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6068916
	speed: 0.0296s/iter; left time: 527.9139s
	iters: 200, epoch: 24 | loss: 0.5315509
	speed: 0.0282s/iter; left time: 499.5074s
Epoch: 24 cost time: 6.74847674369812
Epoch: 24, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8384 x Lambda(0.001)), Vali MSE Loss: 1.1022 Test MSE Loss: 1.1321
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6244171
	speed: 0.0297s/iter; left time: 522.6522s
	iters: 200, epoch: 25 | loss: 0.5701555
	speed: 0.0275s/iter; left time: 481.4434s
Epoch: 25 cost time: 6.681930303573608
Epoch: 25, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8488 x Lambda(0.001)), Vali MSE Loss: 1.1021 Test MSE Loss: 1.1321
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5838082
	speed: 0.0300s/iter; left time: 521.0036s
	iters: 200, epoch: 26 | loss: 0.6028491
	speed: 0.0280s/iter; left time: 484.3736s
Epoch: 26 cost time: 6.804150104522705
Epoch: 26, Steps: 233 Train Loss: 0.5806 (Forecasting Loss:0.5777 + XiCon Loss:2.8495 x Lambda(0.001)), Vali MSE Loss: 1.1021 Test MSE Loss: 1.1321
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6198844
	speed: 0.0298s/iter; left time: 510.4418s
	iters: 200, epoch: 27 | loss: 0.5462294
	speed: 0.0273s/iter; left time: 465.5080s
Epoch: 27 cost time: 6.696794509887695
Epoch: 27, Steps: 233 Train Loss: 0.5807 (Forecasting Loss:0.5779 + XiCon Loss:2.8426 x Lambda(0.001)), Vali MSE Loss: 1.1023 Test MSE Loss: 1.1321
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.5157630
	speed: 0.0303s/iter; left time: 513.1312s
	iters: 200, epoch: 28 | loss: 0.5460552
	speed: 0.0277s/iter; left time: 465.2658s
Epoch: 28 cost time: 6.735015869140625
Epoch: 28, Steps: 233 Train Loss: 0.5804 (Forecasting Loss:0.5776 + XiCon Loss:2.8454 x Lambda(0.001)), Vali MSE Loss: 1.1020 Test MSE Loss: 1.1321
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3891373872756958, mae:0.8751113414764404, mape:6.025380611419678, mspe:4357.61572265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3938+-0.00493, MAE:0.8781+-0.00237, MAPE:6.1202+-0.07560, MSPE:4498.5776+-113.54143, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.8270
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0977936
	speed: 0.0525s/iter; left time: 1185.9438s
	iters: 200, epoch: 1 | loss: 1.0092075
	speed: 0.0468s/iter; left time: 1053.7972s
Epoch: 1 cost time: 11.182703971862793
Epoch: 1, Steps: 227 Train Loss: 1.0289 (Forecasting Loss:1.0262 + XiCon Loss:2.6949 x Lambda(0.001)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.935977).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6314707
	speed: 0.0499s/iter; left time: 1115.9772s
	iters: 200, epoch: 2 | loss: 0.6137049
	speed: 0.0471s/iter; left time: 1048.3365s
Epoch: 2 cost time: 11.006094694137573
Epoch: 2, Steps: 227 Train Loss: 0.6715 (Forecasting Loss:0.6688 + XiCon Loss:2.6941 x Lambda(0.001)), Vali MSE Loss: 1.2110 Test MSE Loss: 1.2834
Validation loss decreased (1.935977 --> 1.210994).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6237837
	speed: 0.0489s/iter; left time: 1082.4084s
	iters: 200, epoch: 3 | loss: 0.6249838
	speed: 0.0475s/iter; left time: 1047.5448s
Epoch: 3 cost time: 10.930665731430054
Epoch: 3, Steps: 227 Train Loss: 0.6084 (Forecasting Loss:0.6057 + XiCon Loss:2.6916 x Lambda(0.001)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2755
Validation loss decreased (1.210994 --> 1.187746).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5914295
	speed: 0.0489s/iter; left time: 1072.7818s
	iters: 200, epoch: 4 | loss: 0.5794269
	speed: 0.0472s/iter; left time: 1029.3904s
Epoch: 4 cost time: 10.912990093231201
Epoch: 4, Steps: 227 Train Loss: 0.6005 (Forecasting Loss:0.5978 + XiCon Loss:2.6919 x Lambda(0.001)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2733
Validation loss decreased (1.187746 --> 1.181757).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5897077
	speed: 0.0491s/iter; left time: 1065.2811s
	iters: 200, epoch: 5 | loss: 0.6280909
	speed: 0.0473s/iter; left time: 1021.9007s
Epoch: 5 cost time: 10.95478630065918
Epoch: 5, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.6936 x Lambda(0.001)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2722
Validation loss decreased (1.181757 --> 1.178959).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5879567
	speed: 0.0485s/iter; left time: 1040.2432s
	iters: 200, epoch: 6 | loss: 0.6105207
	speed: 0.0475s/iter; left time: 1014.0801s
Epoch: 6 cost time: 10.916747570037842
Epoch: 6, Steps: 227 Train Loss: 0.5958 (Forecasting Loss:0.5931 + XiCon Loss:2.6871 x Lambda(0.001)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2718
Validation loss decreased (1.178959 --> 1.176990).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5391384
	speed: 0.0492s/iter; left time: 1044.5957s
	iters: 200, epoch: 7 | loss: 0.5667177
	speed: 0.0474s/iter; left time: 1002.5027s
Epoch: 7 cost time: 11.014610052108765
Epoch: 7, Steps: 227 Train Loss: 0.5950 (Forecasting Loss:0.5923 + XiCon Loss:2.6912 x Lambda(0.001)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2716
Validation loss decreased (1.176990 --> 1.176424).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6172274
	speed: 0.0486s/iter; left time: 1022.1017s
	iters: 200, epoch: 8 | loss: 0.6595888
	speed: 0.0479s/iter; left time: 1002.1121s
Epoch: 8 cost time: 10.989760398864746
Epoch: 8, Steps: 227 Train Loss: 0.5946 (Forecasting Loss:0.5919 + XiCon Loss:2.6901 x Lambda(0.001)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2715
Validation loss decreased (1.176424 --> 1.175509).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5852079
	speed: 0.0499s/iter; left time: 1038.1048s
	iters: 200, epoch: 9 | loss: 0.6194570
	speed: 0.0473s/iter; left time: 978.4109s
Epoch: 9 cost time: 11.063947916030884
Epoch: 9, Steps: 227 Train Loss: 0.5944 (Forecasting Loss:0.5917 + XiCon Loss:2.6927 x Lambda(0.001)), Vali MSE Loss: 1.1759 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5544171
	speed: 0.0489s/iter; left time: 1006.0415s
	iters: 200, epoch: 10 | loss: 0.5896683
	speed: 0.0475s/iter; left time: 972.6892s
Epoch: 10 cost time: 10.981846809387207
Epoch: 10, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5916 + XiCon Loss:2.6895 x Lambda(0.001)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2714
Validation loss decreased (1.175509 --> 1.175488).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5884665
	speed: 0.0499s/iter; left time: 1013.9411s
	iters: 200, epoch: 11 | loss: 0.6177806
	speed: 0.0480s/iter; left time: 970.4049s
Epoch: 11 cost time: 11.125080347061157
Epoch: 11, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6928 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5884356
	speed: 0.0488s/iter; left time: 980.7602s
	iters: 200, epoch: 12 | loss: 0.5846384
	speed: 0.0468s/iter; left time: 936.9710s
Epoch: 12 cost time: 10.852678060531616
Epoch: 12, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6903 x Lambda(0.001)), Vali MSE Loss: 1.1751 Test MSE Loss: 1.2714
Validation loss decreased (1.175488 --> 1.175108).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5499738
	speed: 0.0503s/iter; left time: 999.1158s
	iters: 200, epoch: 13 | loss: 0.5750624
	speed: 0.0478s/iter; left time: 945.3686s
Epoch: 13 cost time: 11.159506797790527
Epoch: 13, Steps: 227 Train Loss: 0.5944 (Forecasting Loss:0.5917 + XiCon Loss:2.6892 x Lambda(0.001)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6087673
	speed: 0.0493s/iter; left time: 968.1709s
	iters: 200, epoch: 14 | loss: 0.5784851
	speed: 0.0469s/iter; left time: 917.8249s
Epoch: 14 cost time: 10.973509073257446
Epoch: 14, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5916 + XiCon Loss:2.6888 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2714
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5405363
	speed: 0.0493s/iter; left time: 958.4275s
	iters: 200, epoch: 15 | loss: 0.5902784
	speed: 0.0479s/iter; left time: 926.3281s
Epoch: 15 cost time: 11.089836120605469
Epoch: 15, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5916 + XiCon Loss:2.6873 x Lambda(0.001)), Vali MSE Loss: 1.1761 Test MSE Loss: 1.2714
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6016245
	speed: 0.0499s/iter; left time: 957.5871s
	iters: 200, epoch: 16 | loss: 0.5920814
	speed: 0.0478s/iter; left time: 912.4681s
Epoch: 16 cost time: 11.09404444694519
Epoch: 16, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6929 x Lambda(0.001)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2714
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6165876
	speed: 0.0503s/iter; left time: 954.5031s
	iters: 200, epoch: 17 | loss: 0.5633900
	speed: 0.0470s/iter; left time: 885.9834s
Epoch: 17 cost time: 11.074822187423706
Epoch: 17, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6861 x Lambda(0.001)), Vali MSE Loss: 1.1758 Test MSE Loss: 1.2714
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.5759643
	speed: 0.0506s/iter; left time: 948.3833s
	iters: 200, epoch: 18 | loss: 0.6096916
	speed: 0.0477s/iter; left time: 889.3257s
Epoch: 18 cost time: 11.189910650253296
Epoch: 18, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5916 + XiCon Loss:2.6899 x Lambda(0.001)), Vali MSE Loss: 1.1750 Test MSE Loss: 1.2714
Validation loss decreased (1.175108 --> 1.174999).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6382309
	speed: 0.0500s/iter; left time: 926.6458s
	iters: 200, epoch: 19 | loss: 0.6225347
	speed: 0.0480s/iter; left time: 883.2739s
Epoch: 19 cost time: 11.13419222831726
Epoch: 19, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6942 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5446980
	speed: 0.0495s/iter; left time: 905.5109s
	iters: 200, epoch: 20 | loss: 0.5541290
	speed: 0.0478s/iter; left time: 868.5415s
Epoch: 20 cost time: 11.04788875579834
Epoch: 20, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6924 x Lambda(0.001)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2714
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6097586
	speed: 0.0492s/iter; left time: 888.8442s
	iters: 200, epoch: 21 | loss: 0.5802217
	speed: 0.0483s/iter; left time: 866.7727s
Epoch: 21 cost time: 11.10179352760315
Epoch: 21, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6928 x Lambda(0.001)), Vali MSE Loss: 1.1752 Test MSE Loss: 1.2714
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.5852832
	speed: 0.0492s/iter; left time: 878.2257s
	iters: 200, epoch: 22 | loss: 0.6339324
	speed: 0.0475s/iter; left time: 842.9028s
Epoch: 22 cost time: 10.992875576019287
Epoch: 22, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6909 x Lambda(0.001)), Vali MSE Loss: 1.1749 Test MSE Loss: 1.2714
Validation loss decreased (1.174999 --> 1.174924).  Saving model ...
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6342076
	speed: 0.0507s/iter; left time: 893.0401s
	iters: 200, epoch: 23 | loss: 0.5947049
	speed: 0.0477s/iter; left time: 835.5244s
Epoch: 23 cost time: 11.171210289001465
Epoch: 23, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6941 x Lambda(0.001)), Vali MSE Loss: 1.1752 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5876253
	speed: 0.0503s/iter; left time: 873.7667s
	iters: 200, epoch: 24 | loss: 0.6096141
	speed: 0.0483s/iter; left time: 835.3853s
Epoch: 24 cost time: 11.185240507125854
Epoch: 24, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5916 + XiCon Loss:2.6915 x Lambda(0.001)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2714
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5700703
	speed: 0.0498s/iter; left time: 854.0233s
	iters: 200, epoch: 25 | loss: 0.6268784
	speed: 0.0474s/iter; left time: 808.8678s
Epoch: 25 cost time: 11.072640657424927
Epoch: 25, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6923 x Lambda(0.001)), Vali MSE Loss: 1.1757 Test MSE Loss: 1.2714
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5984432
	speed: 0.0489s/iter; left time: 828.4986s
	iters: 200, epoch: 26 | loss: 0.5697691
	speed: 0.0480s/iter; left time: 808.2708s
Epoch: 26 cost time: 11.070384740829468
Epoch: 26, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6896 x Lambda(0.001)), Vali MSE Loss: 1.1758 Test MSE Loss: 1.2714
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.6117936
	speed: 0.0499s/iter; left time: 832.8447s
	iters: 200, epoch: 27 | loss: 0.5926700
	speed: 0.0473s/iter; left time: 785.2300s
Epoch: 27 cost time: 11.053175687789917
Epoch: 27, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6923 x Lambda(0.001)), Vali MSE Loss: 1.1744 Test MSE Loss: 1.2714
Validation loss decreased (1.174924 --> 1.174445).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6098266
	speed: 0.0495s/iter; left time: 814.7241s
	iters: 200, epoch: 28 | loss: 0.6306395
	speed: 0.0483s/iter; left time: 790.0766s
Epoch: 28 cost time: 11.140660047531128
Epoch: 28, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6941 x Lambda(0.001)), Vali MSE Loss: 1.1750 Test MSE Loss: 1.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.5609626
	speed: 0.0502s/iter; left time: 814.8919s
	iters: 200, epoch: 29 | loss: 0.6143404
	speed: 0.0472s/iter; left time: 762.1993s
Epoch: 29 cost time: 11.100281953811646
Epoch: 29, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5917 + XiCon Loss:2.6886 x Lambda(0.001)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2714
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.6195177
	speed: 0.0503s/iter; left time: 806.3464s
	iters: 200, epoch: 30 | loss: 0.5804628
	speed: 0.0474s/iter; left time: 754.0959s
Epoch: 30 cost time: 11.09742522239685
Epoch: 30, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5915 + XiCon Loss:2.6867 x Lambda(0.001)), Vali MSE Loss: 1.1753 Test MSE Loss: 1.2714
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.5787355
	speed: 0.0502s/iter; left time: 792.6387s
	iters: 200, epoch: 31 | loss: 0.6067693
	speed: 0.0467s/iter; left time: 732.2910s
Epoch: 31 cost time: 11.033003091812134
Epoch: 31, Steps: 227 Train Loss: 0.5943 (Forecasting Loss:0.5916 + XiCon Loss:2.6904 x Lambda(0.001)), Vali MSE Loss: 1.1752 Test MSE Loss: 1.2714
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.6107033
	speed: 0.0496s/iter; left time: 772.0631s
	iters: 200, epoch: 32 | loss: 0.5664763
	speed: 0.0483s/iter; left time: 747.3462s
Epoch: 32 cost time: 11.180487155914307
Epoch: 32, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6891 x Lambda(0.001)), Vali MSE Loss: 1.1754 Test MSE Loss: 1.2714
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.5976012
	speed: 0.0506s/iter; left time: 775.4480s
	iters: 200, epoch: 33 | loss: 0.6167954
	speed: 0.0482s/iter; left time: 733.6660s
Epoch: 33 cost time: 11.243320941925049
Epoch: 33, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6888 x Lambda(0.001)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2714
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.5682829
	speed: 0.0494s/iter; left time: 746.4227s
	iters: 200, epoch: 34 | loss: 0.5753297
	speed: 0.0479s/iter; left time: 719.5025s
Epoch: 34 cost time: 11.10276985168457
Epoch: 34, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.6926 x Lambda(0.001)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2714
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.5860614
	speed: 0.0505s/iter; left time: 751.0616s
	iters: 200, epoch: 35 | loss: 0.5825371
	speed: 0.0480s/iter; left time: 709.5896s
Epoch: 35 cost time: 11.179899454116821
Epoch: 35, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6907 x Lambda(0.001)), Vali MSE Loss: 1.1752 Test MSE Loss: 1.2714
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.5843633
	speed: 0.0492s/iter; left time: 721.6418s
	iters: 200, epoch: 36 | loss: 0.5547177
	speed: 0.0475s/iter; left time: 691.3613s
Epoch: 36 cost time: 10.998758554458618
Epoch: 36, Steps: 227 Train Loss: 0.5944 (Forecasting Loss:0.5917 + XiCon Loss:2.6929 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2714
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.6071404
	speed: 0.0490s/iter; left time: 707.1695s
	iters: 200, epoch: 37 | loss: 0.6011677
	speed: 0.0482s/iter; left time: 690.2932s
Epoch: 37 cost time: 11.063899517059326
Epoch: 37, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5915 + XiCon Loss:2.6937 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2714
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5889328718185425, mae:0.9538050889968872, mape:6.218541145324707, mspe:4792.08984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.5735
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0350380
	speed: 0.0492s/iter; left time: 1112.6799s
	iters: 200, epoch: 1 | loss: 1.0024816
	speed: 0.0448s/iter; left time: 1007.1671s
Epoch: 1 cost time: 10.596319437026978
Epoch: 1, Steps: 227 Train Loss: 1.0270 (Forecasting Loss:1.0243 + XiCon Loss:2.7095 x Lambda(0.001)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932087).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6145150
	speed: 0.0485s/iter; left time: 1084.4276s
	iters: 200, epoch: 2 | loss: 0.5992365
	speed: 0.0444s/iter; left time: 989.9474s
Epoch: 2 cost time: 10.506568908691406
Epoch: 2, Steps: 227 Train Loss: 0.6719 (Forecasting Loss:0.6692 + XiCon Loss:2.7162 x Lambda(0.001)), Vali MSE Loss: 1.2129 Test MSE Loss: 1.2802
Validation loss decreased (1.932087 --> 1.212937).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6260012
	speed: 0.0485s/iter; left time: 1075.1888s
	iters: 200, epoch: 3 | loss: 0.6087471
	speed: 0.0437s/iter; left time: 964.4141s
Epoch: 3 cost time: 10.447047233581543
Epoch: 3, Steps: 227 Train Loss: 0.6099 (Forecasting Loss:0.6072 + XiCon Loss:2.7158 x Lambda(0.001)), Vali MSE Loss: 1.1938 Test MSE Loss: 1.2730
Validation loss decreased (1.212937 --> 1.193777).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5846308
	speed: 0.0484s/iter; left time: 1060.2261s
	iters: 200, epoch: 4 | loss: 0.5458224
	speed: 0.0450s/iter; left time: 981.0748s
Epoch: 4 cost time: 10.585406064987183
Epoch: 4, Steps: 227 Train Loss: 0.6025 (Forecasting Loss:0.5998 + XiCon Loss:2.7134 x Lambda(0.001)), Vali MSE Loss: 1.1878 Test MSE Loss: 1.2713
Validation loss decreased (1.193777 --> 1.187779).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5837138
	speed: 0.0486s/iter; left time: 1053.6063s
	iters: 200, epoch: 5 | loss: 0.6448114
	speed: 0.0452s/iter; left time: 976.8075s
Epoch: 5 cost time: 10.644001960754395
Epoch: 5, Steps: 227 Train Loss: 0.5995 (Forecasting Loss:0.5968 + XiCon Loss:2.7136 x Lambda(0.001)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2706
Validation loss decreased (1.187779 --> 1.184973).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5833455
	speed: 0.0474s/iter; left time: 1018.5034s
	iters: 200, epoch: 6 | loss: 0.5773141
	speed: 0.0447s/iter; left time: 954.5563s
Epoch: 6 cost time: 10.496316194534302
Epoch: 6, Steps: 227 Train Loss: 0.5981 (Forecasting Loss:0.5954 + XiCon Loss:2.7108 x Lambda(0.001)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2703
Validation loss decreased (1.184973 --> 1.183126).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5918398
	speed: 0.0487s/iter; left time: 1034.2374s
	iters: 200, epoch: 7 | loss: 0.6125006
	speed: 0.0443s/iter; left time: 935.8695s
Epoch: 7 cost time: 10.481536388397217
Epoch: 7, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7145 x Lambda(0.001)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2702
Validation loss decreased (1.183126 --> 1.182825).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6051628
	speed: 0.0486s/iter; left time: 1021.9023s
	iters: 200, epoch: 8 | loss: 0.6385394
	speed: 0.0458s/iter; left time: 956.8382s
Epoch: 8 cost time: 10.709558486938477
Epoch: 8, Steps: 227 Train Loss: 0.5971 (Forecasting Loss:0.5943 + XiCon Loss:2.7177 x Lambda(0.001)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2701
Validation loss decreased (1.182825 --> 1.182376).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5806191
	speed: 0.0483s/iter; left time: 1003.0914s
	iters: 200, epoch: 9 | loss: 0.5994396
	speed: 0.0454s/iter; left time: 939.5578s
Epoch: 9 cost time: 10.661923170089722
Epoch: 9, Steps: 227 Train Loss: 0.5968 (Forecasting Loss:0.5941 + XiCon Loss:2.7120 x Lambda(0.001)), Vali MSE Loss: 1.1812 Test MSE Loss: 1.2701
Validation loss decreased (1.182376 --> 1.181161).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5456648
	speed: 0.0479s/iter; left time: 985.6149s
	iters: 200, epoch: 10 | loss: 0.5893558
	speed: 0.0444s/iter; left time: 909.2742s
Epoch: 10 cost time: 10.475028276443481
Epoch: 10, Steps: 227 Train Loss: 0.5967 (Forecasting Loss:0.5940 + XiCon Loss:2.7161 x Lambda(0.001)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2701
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5976810
	speed: 0.0483s/iter; left time: 982.6342s
	iters: 200, epoch: 11 | loss: 0.6047971
	speed: 0.0456s/iter; left time: 922.6077s
Epoch: 11 cost time: 10.619330883026123
Epoch: 11, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5939 + XiCon Loss:2.7136 x Lambda(0.001)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2700
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6221446
	speed: 0.0484s/iter; left time: 972.2848s
	iters: 200, epoch: 12 | loss: 0.5706511
	speed: 0.0440s/iter; left time: 879.7669s
Epoch: 12 cost time: 10.43601393699646
Epoch: 12, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5939 + XiCon Loss:2.7146 x Lambda(0.001)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2700
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.6104881
	speed: 0.0485s/iter; left time: 964.6201s
	iters: 200, epoch: 13 | loss: 0.5634566
	speed: 0.0455s/iter; left time: 899.2867s
Epoch: 13 cost time: 10.695985794067383
Epoch: 13, Steps: 227 Train Loss: 0.5967 (Forecasting Loss:0.5939 + XiCon Loss:2.7141 x Lambda(0.001)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2700
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6163210
	speed: 0.0510s/iter; left time: 1002.2260s
	iters: 200, epoch: 14 | loss: 0.6197380
	speed: 0.0456s/iter; left time: 892.1366s
Epoch: 14 cost time: 10.947156190872192
Epoch: 14, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5939 + XiCon Loss:2.7113 x Lambda(0.001)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2700
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5991339
	speed: 0.0490s/iter; left time: 952.6350s
	iters: 200, epoch: 15 | loss: 0.6300129
	speed: 0.0453s/iter; left time: 874.4576s
Epoch: 15 cost time: 10.696958541870117
Epoch: 15, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5938 + XiCon Loss:2.7155 x Lambda(0.001)), Vali MSE Loss: 1.1809 Test MSE Loss: 1.2700
Validation loss decreased (1.181161 --> 1.180866).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.6011935
	speed: 0.0491s/iter; left time: 941.9461s
	iters: 200, epoch: 16 | loss: 0.5845813
	speed: 0.0445s/iter; left time: 848.8254s
Epoch: 16 cost time: 10.565932512283325
Epoch: 16, Steps: 227 Train Loss: 0.5964 (Forecasting Loss:0.5937 + XiCon Loss:2.7158 x Lambda(0.001)), Vali MSE Loss: 1.1816 Test MSE Loss: 1.2700
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6055043
	speed: 0.0490s/iter; left time: 930.3162s
	iters: 200, epoch: 17 | loss: 0.6068242
	speed: 0.0453s/iter; left time: 854.2952s
Epoch: 17 cost time: 10.651061773300171
Epoch: 17, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5939 + XiCon Loss:2.7160 x Lambda(0.001)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2700
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6097388
	speed: 0.0484s/iter; left time: 906.7374s
	iters: 200, epoch: 18 | loss: 0.5776296
	speed: 0.0455s/iter; left time: 848.6064s
Epoch: 18 cost time: 10.654958009719849
Epoch: 18, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5938 + XiCon Loss:2.7109 x Lambda(0.001)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2700
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.6262197
	speed: 0.0482s/iter; left time: 891.9115s
	iters: 200, epoch: 19 | loss: 0.5936031
	speed: 0.0458s/iter; left time: 842.9565s
Epoch: 19 cost time: 10.648919582366943
Epoch: 19, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5938 + XiCon Loss:2.7152 x Lambda(0.001)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2700
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5722366
	speed: 0.0482s/iter; left time: 882.2704s
	iters: 200, epoch: 20 | loss: 0.6111046
	speed: 0.0448s/iter; left time: 813.9281s
Epoch: 20 cost time: 10.539141178131104
Epoch: 20, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5938 + XiCon Loss:2.7164 x Lambda(0.001)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2700
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5870008
	speed: 0.0484s/iter; left time: 874.3033s
	iters: 200, epoch: 21 | loss: 0.5972499
	speed: 0.0451s/iter; left time: 809.7339s
Epoch: 21 cost time: 10.592597961425781
Epoch: 21, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5938 + XiCon Loss:2.7125 x Lambda(0.001)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2700
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6151029
	speed: 0.0479s/iter; left time: 854.0701s
	iters: 200, epoch: 22 | loss: 0.5863408
	speed: 0.0453s/iter; left time: 802.9219s
Epoch: 22 cost time: 10.567182779312134
Epoch: 22, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5937 + XiCon Loss:2.7160 x Lambda(0.001)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2700
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6198518
	speed: 0.0491s/iter; left time: 864.9192s
	iters: 200, epoch: 23 | loss: 0.6137614
	speed: 0.0457s/iter; left time: 800.2176s
Epoch: 23 cost time: 10.685586929321289
Epoch: 23, Steps: 227 Train Loss: 0.5965 (Forecasting Loss:0.5938 + XiCon Loss:2.7096 x Lambda(0.001)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2700
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.6060026
	speed: 0.0498s/iter; left time: 864.8942s
	iters: 200, epoch: 24 | loss: 0.5881370
	speed: 0.0445s/iter; left time: 769.3253s
Epoch: 24 cost time: 10.65612244606018
Epoch: 24, Steps: 227 Train Loss: 0.5964 (Forecasting Loss:0.5937 + XiCon Loss:2.7106 x Lambda(0.001)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2700
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5730904
	speed: 0.0491s/iter; left time: 842.6057s
	iters: 200, epoch: 25 | loss: 0.5972481
	speed: 0.0451s/iter; left time: 768.4902s
Epoch: 25 cost time: 10.68327283859253
Epoch: 25, Steps: 227 Train Loss: 0.5966 (Forecasting Loss:0.5939 + XiCon Loss:2.7126 x Lambda(0.001)), Vali MSE Loss: 1.1812 Test MSE Loss: 1.2700
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.587290644645691, mae:0.9527727961540222, mape:6.202764511108398, mspe:4745.30615234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.6558
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0389524
	speed: 0.0458s/iter; left time: 1034.5302s
	iters: 200, epoch: 1 | loss: 1.0581927
	speed: 0.0419s/iter; left time: 942.3572s
Epoch: 1 cost time: 9.939108610153198
Epoch: 1, Steps: 227 Train Loss: 1.0425 (Forecasting Loss:1.0398 + XiCon Loss:2.7214 x Lambda(0.001)), Vali MSE Loss: 1.9462 Test MSE Loss: 1.3968
Validation loss decreased (inf --> 1.946152).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.5958426
	speed: 0.0453s/iter; left time: 1013.3714s
	iters: 200, epoch: 2 | loss: 0.6060778
	speed: 0.0419s/iter; left time: 933.3118s
Epoch: 2 cost time: 9.928837537765503
Epoch: 2, Steps: 227 Train Loss: 0.6730 (Forecasting Loss:0.6703 + XiCon Loss:2.7252 x Lambda(0.001)), Vali MSE Loss: 1.2034 Test MSE Loss: 1.2775
Validation loss decreased (1.946152 --> 1.203410).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6379829
	speed: 0.0453s/iter; left time: 1003.4123s
	iters: 200, epoch: 3 | loss: 0.6185921
	speed: 0.0415s/iter; left time: 914.9399s
Epoch: 3 cost time: 9.858083248138428
Epoch: 3, Steps: 227 Train Loss: 0.6084 (Forecasting Loss:0.6057 + XiCon Loss:2.7248 x Lambda(0.001)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2712
Validation loss decreased (1.203410 --> 1.181828).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5922483
	speed: 0.0450s/iter; left time: 986.8778s
	iters: 200, epoch: 4 | loss: 0.5999655
	speed: 0.0420s/iter; left time: 915.3678s
Epoch: 4 cost time: 9.907342195510864
Epoch: 4, Steps: 227 Train Loss: 0.6003 (Forecasting Loss:0.5976 + XiCon Loss:2.7222 x Lambda(0.001)), Vali MSE Loss: 1.1756 Test MSE Loss: 1.2706
Validation loss decreased (1.181828 --> 1.175636).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5636607
	speed: 0.0454s/iter; left time: 985.4990s
	iters: 200, epoch: 5 | loss: 0.6197456
	speed: 0.0421s/iter; left time: 909.5605s
Epoch: 5 cost time: 9.940818309783936
Epoch: 5, Steps: 227 Train Loss: 0.5971 (Forecasting Loss:0.5943 + XiCon Loss:2.7224 x Lambda(0.001)), Vali MSE Loss: 1.1713 Test MSE Loss: 1.2700
Validation loss decreased (1.175636 --> 1.171264).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6236913
	speed: 0.0457s/iter; left time: 981.9305s
	iters: 200, epoch: 6 | loss: 0.6171191
	speed: 0.0425s/iter; left time: 907.6668s
Epoch: 6 cost time: 10.018019676208496
Epoch: 6, Steps: 227 Train Loss: 0.5956 (Forecasting Loss:0.5929 + XiCon Loss:2.7236 x Lambda(0.001)), Vali MSE Loss: 1.1702 Test MSE Loss: 1.2695
Validation loss decreased (1.171264 --> 1.170181).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6027209
	speed: 0.0460s/iter; left time: 977.2360s
	iters: 200, epoch: 7 | loss: 0.5724450
	speed: 0.0422s/iter; left time: 892.7656s
Epoch: 7 cost time: 10.052276849746704
Epoch: 7, Steps: 227 Train Loss: 0.5948 (Forecasting Loss:0.5921 + XiCon Loss:2.7223 x Lambda(0.001)), Vali MSE Loss: 1.1692 Test MSE Loss: 1.2696
Validation loss decreased (1.170181 --> 1.169155).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.6277108
	speed: 0.0458s/iter; left time: 963.0913s
	iters: 200, epoch: 8 | loss: 0.5837786
	speed: 0.0433s/iter; left time: 905.8814s
Epoch: 8 cost time: 10.126627683639526
Epoch: 8, Steps: 227 Train Loss: 0.5944 (Forecasting Loss:0.5917 + XiCon Loss:2.7202 x Lambda(0.001)), Vali MSE Loss: 1.1683 Test MSE Loss: 1.2695
Validation loss decreased (1.169155 --> 1.168339).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.5875562
	speed: 0.0457s/iter; left time: 949.4881s
	iters: 200, epoch: 9 | loss: 0.5510362
	speed: 0.0427s/iter; left time: 883.5595s
Epoch: 9 cost time: 10.068081140518188
Epoch: 9, Steps: 227 Train Loss: 0.5944 (Forecasting Loss:0.5917 + XiCon Loss:2.7235 x Lambda(0.001)), Vali MSE Loss: 1.1684 Test MSE Loss: 1.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5842883
	speed: 0.0462s/iter; left time: 950.7493s
	iters: 200, epoch: 10 | loss: 0.6275789
	speed: 0.0430s/iter; left time: 880.1608s
Epoch: 10 cost time: 10.123868227005005
Epoch: 10, Steps: 227 Train Loss: 0.5942 (Forecasting Loss:0.5914 + XiCon Loss:2.7214 x Lambda(0.001)), Vali MSE Loss: 1.1684 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.5687737
	speed: 0.0455s/iter; left time: 924.5884s
	iters: 200, epoch: 11 | loss: 0.5773238
	speed: 0.0432s/iter; left time: 872.9840s
Epoch: 11 cost time: 10.085289239883423
Epoch: 11, Steps: 227 Train Loss: 0.5939 (Forecasting Loss:0.5912 + XiCon Loss:2.7264 x Lambda(0.001)), Vali MSE Loss: 1.1683 Test MSE Loss: 1.2695
Validation loss decreased (1.168339 --> 1.168280).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5889867
	speed: 0.0453s/iter; left time: 911.5825s
	iters: 200, epoch: 12 | loss: 0.6014879
	speed: 0.0426s/iter; left time: 851.6145s
Epoch: 12 cost time: 9.995229959487915
Epoch: 12, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7264 x Lambda(0.001)), Vali MSE Loss: 1.1684 Test MSE Loss: 1.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5930734
	speed: 0.0455s/iter; left time: 903.6008s
	iters: 200, epoch: 13 | loss: 0.6316926
	speed: 0.0429s/iter; left time: 848.7894s
Epoch: 13 cost time: 10.033967971801758
Epoch: 13, Steps: 227 Train Loss: 0.5939 (Forecasting Loss:0.5912 + XiCon Loss:2.7258 x Lambda(0.001)), Vali MSE Loss: 1.1683 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6027178
	speed: 0.0459s/iter; left time: 901.7182s
	iters: 200, epoch: 14 | loss: 0.6215168
	speed: 0.0427s/iter; left time: 835.5540s
Epoch: 14 cost time: 10.053195714950562
Epoch: 14, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.7191 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
Validation loss decreased (1.168280 --> 1.167884).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.6117750
	speed: 0.0476s/iter; left time: 924.2748s
	iters: 200, epoch: 15 | loss: 0.6148796
	speed: 0.0424s/iter; left time: 819.2655s
Epoch: 15 cost time: 10.190041542053223
Epoch: 15, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7201 x Lambda(0.001)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2695
Validation loss decreased (1.167884 --> 1.167683).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5870190
	speed: 0.0455s/iter; left time: 874.2539s
	iters: 200, epoch: 16 | loss: 0.5618951
	speed: 0.0433s/iter; left time: 826.0371s
Epoch: 16 cost time: 10.114274024963379
Epoch: 16, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5912 + XiCon Loss:2.7241 x Lambda(0.001)), Vali MSE Loss: 1.1685 Test MSE Loss: 1.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.6467485
	speed: 0.0455s/iter; left time: 863.6933s
	iters: 200, epoch: 17 | loss: 0.5695090
	speed: 0.0433s/iter; left time: 816.9420s
Epoch: 17 cost time: 10.121340036392212
Epoch: 17, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7224 x Lambda(0.001)), Vali MSE Loss: 1.1680 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6144308
	speed: 0.0456s/iter; left time: 854.3165s
	iters: 200, epoch: 18 | loss: 0.5961167
	speed: 0.0428s/iter; left time: 797.9820s
Epoch: 18 cost time: 10.04477858543396
Epoch: 18, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7189 x Lambda(0.001)), Vali MSE Loss: 1.1677 Test MSE Loss: 1.2695
Validation loss decreased (1.167683 --> 1.167673).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5813707
	speed: 0.0465s/iter; left time: 861.1708s
	iters: 200, epoch: 19 | loss: 0.6128812
	speed: 0.0430s/iter; left time: 792.7054s
Epoch: 19 cost time: 10.171057224273682
Epoch: 19, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5914 + XiCon Loss:2.7253 x Lambda(0.001)), Vali MSE Loss: 1.1681 Test MSE Loss: 1.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5302029
	speed: 0.0456s/iter; left time: 834.0747s
	iters: 200, epoch: 20 | loss: 0.6053693
	speed: 0.0421s/iter; left time: 765.0792s
Epoch: 20 cost time: 9.941612482070923
Epoch: 20, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7233 x Lambda(0.001)), Vali MSE Loss: 1.1680 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6003222
	speed: 0.0456s/iter; left time: 823.8254s
	iters: 200, epoch: 21 | loss: 0.6223958
	speed: 0.0424s/iter; left time: 761.9745s
Epoch: 21 cost time: 9.996294975280762
Epoch: 21, Steps: 227 Train Loss: 0.5939 (Forecasting Loss:0.5911 + XiCon Loss:2.7218 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6290576
	speed: 0.0471s/iter; left time: 840.6194s
	iters: 200, epoch: 22 | loss: 0.6062369
	speed: 0.0424s/iter; left time: 752.0568s
Epoch: 22 cost time: 10.169341087341309
Epoch: 22, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5913 + XiCon Loss:2.7213 x Lambda(0.001)), Vali MSE Loss: 1.1681 Test MSE Loss: 1.2695
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5735157
	speed: 0.0459s/iter; left time: 808.6427s
	iters: 200, epoch: 23 | loss: 0.6135595
	speed: 0.0430s/iter; left time: 753.0603s
Epoch: 23 cost time: 10.099560737609863
Epoch: 23, Steps: 227 Train Loss: 0.5939 (Forecasting Loss:0.5912 + XiCon Loss:2.7230 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5616749
	speed: 0.0460s/iter; left time: 799.7194s
	iters: 200, epoch: 24 | loss: 0.6166843
	speed: 0.0425s/iter; left time: 733.5399s
Epoch: 24 cost time: 10.038789749145508
Epoch: 24, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5912 + XiCon Loss:2.7223 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.5724949
	speed: 0.0455s/iter; left time: 780.6588s
	iters: 200, epoch: 25 | loss: 0.6020496
	speed: 0.0434s/iter; left time: 739.7019s
Epoch: 25 cost time: 10.071476459503174
Epoch: 25, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7222 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.5902632
	speed: 0.0460s/iter; left time: 777.8847s
	iters: 200, epoch: 26 | loss: 0.5896243
	speed: 0.0423s/iter; left time: 712.1487s
Epoch: 26 cost time: 10.041752815246582
Epoch: 26, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5913 + XiCon Loss:2.7250 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5838329
	speed: 0.0451s/iter; left time: 753.3309s
	iters: 200, epoch: 27 | loss: 0.5876527
	speed: 0.0425s/iter; left time: 706.1442s
Epoch: 27 cost time: 9.986513614654541
Epoch: 27, Steps: 227 Train Loss: 0.5941 (Forecasting Loss:0.5913 + XiCon Loss:2.7230 x Lambda(0.001)), Vali MSE Loss: 1.1679 Test MSE Loss: 1.2695
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.6193705
	speed: 0.0464s/iter; left time: 763.6862s
	iters: 200, epoch: 28 | loss: 0.5822523
	speed: 0.0431s/iter; left time: 705.9225s
Epoch: 28 cost time: 10.151145935058594
Epoch: 28, Steps: 227 Train Loss: 0.5940 (Forecasting Loss:0.5912 + XiCon Loss:2.7246 x Lambda(0.001)), Vali MSE Loss: 1.1685 Test MSE Loss: 1.2695
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.585448145866394, mae:0.9535558819770813, mape:6.234130859375, mspe:4785.82568359375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 15.7226
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.1576917
	speed: 0.0462s/iter; left time: 1044.0771s
	iters: 200, epoch: 1 | loss: 1.2326511
	speed: 0.0419s/iter; left time: 943.2070s
Epoch: 1 cost time: 9.995544672012329
Epoch: 1, Steps: 227 Train Loss: 1.1647 (Forecasting Loss:1.1621 + XiCon Loss:2.6924 x Lambda(0.001)), Vali MSE Loss: 2.2071 Test MSE Loss: 1.4654
Validation loss decreased (inf --> 2.207127).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7613153
	speed: 0.0459s/iter; left time: 1026.7404s
	iters: 200, epoch: 2 | loss: 0.6622387
	speed: 0.0425s/iter; left time: 945.9795s
Epoch: 2 cost time: 10.042152404785156
Epoch: 2, Steps: 227 Train Loss: 0.7387 (Forecasting Loss:0.7361 + XiCon Loss:2.6915 x Lambda(0.001)), Vali MSE Loss: 1.2344 Test MSE Loss: 1.3039
Validation loss decreased (2.207127 --> 1.234359).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6445326
	speed: 0.0455s/iter; left time: 1008.4152s
	iters: 200, epoch: 3 | loss: 0.6127586
	speed: 0.0426s/iter; left time: 938.8403s
Epoch: 3 cost time: 9.991349458694458
Epoch: 3, Steps: 227 Train Loss: 0.6201 (Forecasting Loss:0.6174 + XiCon Loss:2.7015 x Lambda(0.001)), Vali MSE Loss: 1.1966 Test MSE Loss: 1.2880
Validation loss decreased (1.234359 --> 1.196560).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5695331
	speed: 0.0452s/iter; left time: 991.7341s
	iters: 200, epoch: 4 | loss: 0.6489317
	speed: 0.0421s/iter; left time: 918.3858s
Epoch: 4 cost time: 9.904656171798706
Epoch: 4, Steps: 227 Train Loss: 0.6043 (Forecasting Loss:0.6016 + XiCon Loss:2.7053 x Lambda(0.001)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2848
Validation loss decreased (1.196560 --> 1.187687).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5934169
	speed: 0.0458s/iter; left time: 993.3157s
	iters: 200, epoch: 5 | loss: 0.5589499
	speed: 0.0428s/iter; left time: 924.6088s
Epoch: 5 cost time: 10.113213062286377
Epoch: 5, Steps: 227 Train Loss: 0.6004 (Forecasting Loss:0.5977 + XiCon Loss:2.7036 x Lambda(0.001)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2838
Validation loss decreased (1.187687 --> 1.184483).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.5873803
	speed: 0.0461s/iter; left time: 990.1432s
	iters: 200, epoch: 6 | loss: 0.5960607
	speed: 0.0428s/iter; left time: 915.4848s
Epoch: 6 cost time: 10.106681108474731
Epoch: 6, Steps: 227 Train Loss: 0.5987 (Forecasting Loss:0.5960 + XiCon Loss:2.7023 x Lambda(0.001)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2831
Validation loss decreased (1.184483 --> 1.182139).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.5703697
	speed: 0.0455s/iter; left time: 966.1606s
	iters: 200, epoch: 7 | loss: 0.5935435
	speed: 0.0426s/iter; left time: 901.2500s
Epoch: 7 cost time: 10.013203620910645
Epoch: 7, Steps: 227 Train Loss: 0.5978 (Forecasting Loss:0.5951 + XiCon Loss:2.7054 x Lambda(0.001)), Vali MSE Loss: 1.1806 Test MSE Loss: 1.2829
Validation loss decreased (1.182139 --> 1.180645).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5952042
	speed: 0.0464s/iter; left time: 975.3082s
	iters: 200, epoch: 8 | loss: 0.6377288
	speed: 0.0438s/iter; left time: 916.8417s
Epoch: 8 cost time: 10.24903917312622
Epoch: 8, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7060 x Lambda(0.001)), Vali MSE Loss: 1.1807 Test MSE Loss: 1.2827
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6157085
	speed: 0.0461s/iter; left time: 957.4831s
	iters: 200, epoch: 9 | loss: 0.5853290
	speed: 0.0437s/iter; left time: 903.2607s
Epoch: 9 cost time: 10.175113677978516
Epoch: 9, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7025 x Lambda(0.001)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2827
Validation loss decreased (1.180645 --> 1.179868).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.6301314
	speed: 0.0463s/iter; left time: 952.4908s
	iters: 200, epoch: 10 | loss: 0.5881194
	speed: 0.0434s/iter; left time: 888.2731s
Epoch: 10 cost time: 10.186554670333862
Epoch: 10, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7109 x Lambda(0.001)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6158147
	speed: 0.0470s/iter; left time: 954.8257s
	iters: 200, epoch: 11 | loss: 0.5709371
	speed: 0.0427s/iter; left time: 864.0034s
Epoch: 11 cost time: 10.209457874298096
Epoch: 11, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7045 x Lambda(0.001)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
Validation loss decreased (1.179868 --> 1.179598).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.5678537
	speed: 0.0458s/iter; left time: 920.5795s
	iters: 200, epoch: 12 | loss: 0.6028009
	speed: 0.0438s/iter; left time: 877.1056s
Epoch: 12 cost time: 10.172833919525146
Epoch: 12, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7113 x Lambda(0.001)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5785292
	speed: 0.0463s/iter; left time: 919.6509s
	iters: 200, epoch: 13 | loss: 0.5897722
	speed: 0.0435s/iter; left time: 859.4445s
Epoch: 13 cost time: 10.240576267242432
Epoch: 13, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7044 x Lambda(0.001)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2826
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6040502
	speed: 0.0456s/iter; left time: 896.7198s
	iters: 200, epoch: 14 | loss: 0.6065629
	speed: 0.0432s/iter; left time: 843.7101s
Epoch: 14 cost time: 10.116312026977539
Epoch: 14, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7055 x Lambda(0.001)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5818780
	speed: 0.0458s/iter; left time: 889.1887s
	iters: 200, epoch: 15 | loss: 0.5937258
	speed: 0.0425s/iter; left time: 821.1774s
Epoch: 15 cost time: 10.010872840881348
Epoch: 15, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7057 x Lambda(0.001)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5890536
	speed: 0.0463s/iter; left time: 889.3634s
	iters: 200, epoch: 16 | loss: 0.5940632
	speed: 0.0430s/iter; left time: 820.1818s
Epoch: 16 cost time: 10.10774827003479
Epoch: 16, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7028 x Lambda(0.001)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2826
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5664460
	speed: 0.0460s/iter; left time: 873.4554s
	iters: 200, epoch: 17 | loss: 0.5975627
	speed: 0.0426s/iter; left time: 803.1173s
Epoch: 17 cost time: 10.038152933120728
Epoch: 17, Steps: 227 Train Loss: 0.5968 (Forecasting Loss:0.5941 + XiCon Loss:2.7069 x Lambda(0.001)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2826
Validation loss decreased (1.179598 --> 1.179285).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6056188
	speed: 0.0452s/iter; left time: 847.2967s
	iters: 200, epoch: 18 | loss: 0.5797555
	speed: 0.0427s/iter; left time: 796.4547s
Epoch: 18 cost time: 10.000499725341797
Epoch: 18, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7088 x Lambda(0.001)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5824357
	speed: 0.0459s/iter; left time: 850.0483s
	iters: 200, epoch: 19 | loss: 0.5882816
	speed: 0.0424s/iter; left time: 779.9857s
Epoch: 19 cost time: 10.030025959014893
Epoch: 19, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7035 x Lambda(0.001)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2826
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.6039860
	speed: 0.0464s/iter; left time: 848.3690s
	iters: 200, epoch: 20 | loss: 0.6278849
	speed: 0.0430s/iter; left time: 782.8391s
Epoch: 20 cost time: 10.169803619384766
Epoch: 20, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7097 x Lambda(0.001)), Vali MSE Loss: 1.1805 Test MSE Loss: 1.2826
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.6002530
	speed: 0.0463s/iter; left time: 836.3942s
	iters: 200, epoch: 21 | loss: 0.6060096
	speed: 0.0432s/iter; left time: 775.4701s
Epoch: 21 cost time: 10.129819393157959
Epoch: 21, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7040 x Lambda(0.001)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2826
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6254947
	speed: 0.0463s/iter; left time: 826.4105s
	iters: 200, epoch: 22 | loss: 0.6129054
	speed: 0.0423s/iter; left time: 750.9140s
Epoch: 22 cost time: 10.060529232025146
Epoch: 22, Steps: 227 Train Loss: 0.5967 (Forecasting Loss:0.5940 + XiCon Loss:2.7085 x Lambda(0.001)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2826
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.6065754
	speed: 0.0460s/iter; left time: 809.4753s
	iters: 200, epoch: 23 | loss: 0.5686985
	speed: 0.0428s/iter; left time: 749.5517s
Epoch: 23 cost time: 10.07733416557312
Epoch: 23, Steps: 227 Train Loss: 0.5967 (Forecasting Loss:0.5940 + XiCon Loss:2.7054 x Lambda(0.001)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2826
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5223159
	speed: 0.0459s/iter; left time: 798.5880s
	iters: 200, epoch: 24 | loss: 0.6033840
	speed: 0.0438s/iter; left time: 756.4630s
Epoch: 24 cost time: 10.176174640655518
Epoch: 24, Steps: 227 Train Loss: 0.5968 (Forecasting Loss:0.5941 + XiCon Loss:2.7079 x Lambda(0.001)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.6248040
	speed: 0.0453s/iter; left time: 777.8269s
	iters: 200, epoch: 25 | loss: 0.5713075
	speed: 0.0427s/iter; left time: 728.2529s
Epoch: 25 cost time: 10.016834735870361
Epoch: 25, Steps: 227 Train Loss: 0.5968 (Forecasting Loss:0.5941 + XiCon Loss:2.7073 x Lambda(0.001)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2826
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.6006908
	speed: 0.0467s/iter; left time: 791.1208s
	iters: 200, epoch: 26 | loss: 0.5357552
	speed: 0.0434s/iter; left time: 729.6749s
Epoch: 26 cost time: 10.198152542114258
Epoch: 26, Steps: 227 Train Loss: 0.5969 (Forecasting Loss:0.5942 + XiCon Loss:2.7021 x Lambda(0.001)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2826
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.5778009
	speed: 0.0457s/iter; left time: 763.0605s
	iters: 200, epoch: 27 | loss: 0.5777650
	speed: 0.0430s/iter; left time: 714.1204s
Epoch: 27 cost time: 10.068830013275146
Epoch: 27, Steps: 227 Train Loss: 0.5968 (Forecasting Loss:0.5941 + XiCon Loss:2.7069 x Lambda(0.001)), Vali MSE Loss: 1.1804 Test MSE Loss: 1.2826
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.6069999933242798, mae:0.9581841230392456, mape:6.242280006408691, mspe:4861.8623046875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.9196
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.0763251
	speed: 0.0489s/iter; left time: 1105.6114s
	iters: 200, epoch: 1 | loss: 0.9431425
	speed: 0.0451s/iter; left time: 1015.8290s
Epoch: 1 cost time: 10.687751770019531
Epoch: 1, Steps: 227 Train Loss: 1.0378 (Forecasting Loss:1.0350 + XiCon Loss:2.7230 x Lambda(0.001)), Vali MSE Loss: 1.9641 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964088).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6017252
	speed: 0.0483s/iter; left time: 1079.6503s
	iters: 200, epoch: 2 | loss: 0.6417518
	speed: 0.0440s/iter; left time: 979.7345s
Epoch: 2 cost time: 10.41607403755188
Epoch: 2, Steps: 227 Train Loss: 0.6740 (Forecasting Loss:0.6713 + XiCon Loss:2.7256 x Lambda(0.001)), Vali MSE Loss: 1.2174 Test MSE Loss: 1.2828
Validation loss decreased (1.964088 --> 1.217375).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.6183160
	speed: 0.0481s/iter; left time: 1064.6093s
	iters: 200, epoch: 3 | loss: 0.5641339
	speed: 0.0446s/iter; left time: 983.1920s
Epoch: 3 cost time: 10.5002121925354
Epoch: 3, Steps: 227 Train Loss: 0.6109 (Forecasting Loss:0.6082 + XiCon Loss:2.7233 x Lambda(0.001)), Vali MSE Loss: 1.1983 Test MSE Loss: 1.2766
Validation loss decreased (1.217375 --> 1.198311).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.5974446
	speed: 0.0489s/iter; left time: 1072.2520s
	iters: 200, epoch: 4 | loss: 0.5902590
	speed: 0.0443s/iter; left time: 965.6846s
Epoch: 4 cost time: 10.561728477478027
Epoch: 4, Steps: 227 Train Loss: 0.6031 (Forecasting Loss:0.6004 + XiCon Loss:2.7233 x Lambda(0.001)), Vali MSE Loss: 1.1904 Test MSE Loss: 1.2749
Validation loss decreased (1.198311 --> 1.190397).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.5997673
	speed: 0.0480s/iter; left time: 1040.6299s
	iters: 200, epoch: 5 | loss: 0.5993794
	speed: 0.0444s/iter; left time: 958.0802s
Epoch: 5 cost time: 10.461302995681763
Epoch: 5, Steps: 227 Train Loss: 0.6000 (Forecasting Loss:0.5973 + XiCon Loss:2.7210 x Lambda(0.001)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2741
Validation loss decreased (1.190397 --> 1.187030).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.6239656
	speed: 0.0481s/iter; left time: 1032.0197s
	iters: 200, epoch: 6 | loss: 0.6256937
	speed: 0.0445s/iter; left time: 949.7778s
Epoch: 6 cost time: 10.482352256774902
Epoch: 6, Steps: 227 Train Loss: 0.5988 (Forecasting Loss:0.5960 + XiCon Loss:2.7210 x Lambda(0.001)), Vali MSE Loss: 1.1855 Test MSE Loss: 1.2737
Validation loss decreased (1.187030 --> 1.185499).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.6007947
	speed: 0.0485s/iter; left time: 1030.6279s
	iters: 200, epoch: 7 | loss: 0.6685921
	speed: 0.0449s/iter; left time: 949.5979s
Epoch: 7 cost time: 10.599316596984863
Epoch: 7, Steps: 227 Train Loss: 0.5982 (Forecasting Loss:0.5955 + XiCon Loss:2.7209 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2736
Validation loss decreased (1.185499 --> 1.184364).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.5711715
	speed: 0.0488s/iter; left time: 1026.3321s
	iters: 200, epoch: 8 | loss: 0.6385133
	speed: 0.0447s/iter; left time: 935.4691s
Epoch: 8 cost time: 10.560031414031982
Epoch: 8, Steps: 227 Train Loss: 0.5978 (Forecasting Loss:0.5951 + XiCon Loss:2.7214 x Lambda(0.001)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2736
Validation loss decreased (1.184364 --> 1.184203).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.6053516
	speed: 0.0486s/iter; left time: 1010.6694s
	iters: 200, epoch: 9 | loss: 0.5819001
	speed: 0.0435s/iter; left time: 899.8039s
Epoch: 9 cost time: 10.470133066177368
Epoch: 9, Steps: 227 Train Loss: 0.5976 (Forecasting Loss:0.5948 + XiCon Loss:2.7194 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.5822452
	speed: 0.0484s/iter; left time: 994.4804s
	iters: 200, epoch: 10 | loss: 0.5895483
	speed: 0.0456s/iter; left time: 932.3915s
Epoch: 10 cost time: 10.686161518096924
Epoch: 10, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7218 x Lambda(0.001)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2735
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.6484643
	speed: 0.0486s/iter; left time: 988.9328s
	iters: 200, epoch: 11 | loss: 0.5991574
	speed: 0.0461s/iter; left time: 931.8152s
Epoch: 11 cost time: 10.729166984558105
Epoch: 11, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7176 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2735
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.6221488
	speed: 0.0492s/iter; left time: 988.7156s
	iters: 200, epoch: 12 | loss: 0.6182401
	speed: 0.0453s/iter; left time: 906.0665s
Epoch: 12 cost time: 10.65753722190857
Epoch: 12, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7184 x Lambda(0.001)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.5888957
	speed: 0.0481s/iter; left time: 955.8670s
	iters: 200, epoch: 13 | loss: 0.5347604
	speed: 0.0444s/iter; left time: 878.8306s
Epoch: 13 cost time: 10.488001108169556
Epoch: 13, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7196 x Lambda(0.001)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2735
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.6217973
	speed: 0.0495s/iter; left time: 971.9224s
	iters: 200, epoch: 14 | loss: 0.6093365
	speed: 0.0451s/iter; left time: 881.7286s
Epoch: 14 cost time: 10.69028615951538
Epoch: 14, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7217 x Lambda(0.001)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2735
Validation loss decreased (1.184203 --> 1.183385).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.5828677
	speed: 0.0491s/iter; left time: 953.2814s
	iters: 200, epoch: 15 | loss: 0.5930395
	speed: 0.0461s/iter; left time: 891.4961s
Epoch: 15 cost time: 10.785550355911255
Epoch: 15, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7210 x Lambda(0.001)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.5844827
	speed: 0.0495s/iter; left time: 949.5376s
	iters: 200, epoch: 16 | loss: 0.5788329
	speed: 0.0453s/iter; left time: 865.0741s
Epoch: 16 cost time: 10.712719917297363
Epoch: 16, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7217 x Lambda(0.001)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2735
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.5824805
	speed: 0.0485s/iter; left time: 920.6698s
	iters: 200, epoch: 17 | loss: 0.6162804
	speed: 0.0454s/iter; left time: 857.2262s
Epoch: 17 cost time: 10.750350952148438
Epoch: 17, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7196 x Lambda(0.001)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2735
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.6043688
	speed: 0.0482s/iter; left time: 903.3559s
	iters: 200, epoch: 18 | loss: 0.5718565
	speed: 0.0458s/iter; left time: 853.1661s
Epoch: 18 cost time: 10.625473260879517
Epoch: 18, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5945 + XiCon Loss:2.7194 x Lambda(0.001)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.5696374
	speed: 0.0492s/iter; left time: 910.9725s
	iters: 200, epoch: 19 | loss: 0.5826713
	speed: 0.0457s/iter; left time: 841.6601s
Epoch: 19 cost time: 10.724233865737915
Epoch: 19, Steps: 227 Train Loss: 0.5970 (Forecasting Loss:0.5943 + XiCon Loss:2.7213 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2735
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.5403968
	speed: 0.0480s/iter; left time: 878.6100s
	iters: 200, epoch: 20 | loss: 0.6240157
	speed: 0.0451s/iter; left time: 819.4257s
Epoch: 20 cost time: 10.578546285629272
Epoch: 20, Steps: 227 Train Loss: 0.5971 (Forecasting Loss:0.5944 + XiCon Loss:2.7221 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2735
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.5965457
	speed: 0.0480s/iter; left time: 866.8343s
	iters: 200, epoch: 21 | loss: 0.6385828
	speed: 0.0458s/iter; left time: 822.5663s
Epoch: 21 cost time: 10.62977647781372
Epoch: 21, Steps: 227 Train Loss: 0.5972 (Forecasting Loss:0.5944 + XiCon Loss:2.7199 x Lambda(0.001)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2735
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.6023934
	speed: 0.0487s/iter; left time: 868.5198s
	iters: 200, epoch: 22 | loss: 0.5889156
	speed: 0.0443s/iter; left time: 785.5437s
Epoch: 22 cost time: 10.516224145889282
Epoch: 22, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7188 x Lambda(0.001)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2735
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.5740245
	speed: 0.0490s/iter; left time: 862.1880s
	iters: 200, epoch: 23 | loss: 0.6299524
	speed: 0.0456s/iter; left time: 797.6549s
Epoch: 23 cost time: 10.67678165435791
Epoch: 23, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7206 x Lambda(0.001)), Vali MSE Loss: 1.1843 Test MSE Loss: 1.2735
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.5830660
	speed: 0.0484s/iter; left time: 841.0290s
	iters: 200, epoch: 24 | loss: 0.6199755
	speed: 0.0441s/iter; left time: 762.6719s
Epoch: 24 cost time: 10.450567960739136
Epoch: 24, Steps: 227 Train Loss: 0.5973 (Forecasting Loss:0.5946 + XiCon Loss:2.7208 x Lambda(0.001)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2735
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5923776626586914, mae:0.954662024974823, mape:6.220149517059326, mspe:4780.9755859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5922+-0.01074, MAE:0.9546+-0.00263, MAPE:6.2236+-0.01895, MSPE:4793.2124+-52.72827, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
