Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6642
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2510028
	speed: 0.0290s/iter; left time: 368.3220s
Epoch: 1 cost time: 3.3952488899230957
Epoch: 1, Steps: 128 Train Loss: 3.2796 (Forecasting Loss:0.2444 + XiCon Loss:3.0353 x Lambda(1.0)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173759).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0821633
	speed: 0.0353s/iter; left time: 443.5787s
Epoch: 2 cost time: 4.523514986038208
Epoch: 2, Steps: 128 Train Loss: 3.0802 (Forecasting Loss:0.2457 + XiCon Loss:2.8345 x Lambda(1.0)), Vali MSE Loss: 0.1758 Test MSE Loss: 0.1335
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 2.9967566
	speed: 0.0314s/iter; left time: 390.5891s
Epoch: 3 cost time: 3.7850470542907715
Epoch: 3, Steps: 128 Train Loss: 3.0996 (Forecasting Loss:0.2322 + XiCon Loss:2.8674 x Lambda(1.0)), Vali MSE Loss: 0.1682 Test MSE Loss: 0.1241
Validation loss decreased (0.173759 --> 0.168199).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1279135
	speed: 0.0306s/iter; left time: 377.5149s
Epoch: 4 cost time: 3.643031358718872
Epoch: 4, Steps: 128 Train Loss: 3.2300 (Forecasting Loss:0.2222 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.1160
Validation loss decreased (0.168199 --> 0.167853).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2621098
	speed: 0.0267s/iter; left time: 325.6814s
Epoch: 5 cost time: 3.260720729827881
Epoch: 5, Steps: 128 Train Loss: 3.2673 (Forecasting Loss:0.2171 + XiCon Loss:3.0502 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1166
Validation loss decreased (0.167853 --> 0.165026).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1818700
	speed: 0.0327s/iter; left time: 394.0744s
Epoch: 6 cost time: 4.048134803771973
Epoch: 6, Steps: 128 Train Loss: 3.2175 (Forecasting Loss:0.2155 + XiCon Loss:3.0020 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1155
Validation loss decreased (0.165026 --> 0.164055).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2331247
	speed: 0.0270s/iter; left time: 321.9189s
Epoch: 7 cost time: 3.500060796737671
Epoch: 7, Steps: 128 Train Loss: 3.2153 (Forecasting Loss:0.2143 + XiCon Loss:3.0010 x Lambda(1.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1164
Validation loss decreased (0.164055 --> 0.162793).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2354326
	speed: 0.0312s/iter; left time: 367.8994s
Epoch: 8 cost time: 3.845996618270874
Epoch: 8, Steps: 128 Train Loss: 3.2073 (Forecasting Loss:0.2140 + XiCon Loss:2.9933 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1920111
	speed: 0.0325s/iter; left time: 379.4916s
Epoch: 9 cost time: 3.955963373184204
Epoch: 9, Steps: 128 Train Loss: 3.2117 (Forecasting Loss:0.2136 + XiCon Loss:2.9980 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1104057
	speed: 0.0316s/iter; left time: 365.0666s
Epoch: 10 cost time: 3.8953254222869873
Epoch: 10, Steps: 128 Train Loss: 3.2008 (Forecasting Loss:0.2134 + XiCon Loss:2.9874 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.3879988
	speed: 0.0261s/iter; left time: 298.1226s
Epoch: 11 cost time: 3.4528913497924805
Epoch: 11, Steps: 128 Train Loss: 3.1888 (Forecasting Loss:0.2132 + XiCon Loss:2.9756 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1156
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1229553
	speed: 0.0260s/iter; left time: 293.0919s
Epoch: 12 cost time: 3.1729040145874023
Epoch: 12, Steps: 128 Train Loss: 3.1851 (Forecasting Loss:0.2131 + XiCon Loss:2.9720 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.2868443
	speed: 0.0303s/iter; left time: 338.3194s
Epoch: 13 cost time: 3.8273589611053467
Epoch: 13, Steps: 128 Train Loss: 3.2131 (Forecasting Loss:0.2131 + XiCon Loss:3.0001 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.4620414
	speed: 0.0328s/iter; left time: 362.2630s
Epoch: 14 cost time: 4.070852994918823
Epoch: 14, Steps: 128 Train Loss: 3.2055 (Forecasting Loss:0.2132 + XiCon Loss:2.9922 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1261342
	speed: 0.0296s/iter; left time: 322.4001s
Epoch: 15 cost time: 3.8509445190429688
Epoch: 15, Steps: 128 Train Loss: 3.2017 (Forecasting Loss:0.2131 + XiCon Loss:2.9886 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1156
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0597689
	speed: 0.0263s/iter; left time: 283.0527s
Epoch: 16 cost time: 3.203148126602173
Epoch: 16, Steps: 128 Train Loss: 3.2081 (Forecasting Loss:0.2132 + XiCon Loss:2.9948 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1156
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1624212
	speed: 0.0300s/iter; left time: 319.1049s
Epoch: 17 cost time: 3.5734591484069824
Epoch: 17, Steps: 128 Train Loss: 3.1989 (Forecasting Loss:0.2133 + XiCon Loss:2.9856 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1156
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05470932647585869, mae:0.17811113595962524, mape:0.14097577333450317, mspe:0.03676801547408104 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7329
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2012331
	speed: 0.0260s/iter; left time: 330.4502s
Epoch: 1 cost time: 3.2932939529418945
Epoch: 1, Steps: 128 Train Loss: 3.2542 (Forecasting Loss:0.2418 + XiCon Loss:3.0124 x Lambda(1.0)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1218
Validation loss decreased (inf --> 0.174181).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0625081
	speed: 0.0291s/iter; left time: 366.3609s
Epoch: 2 cost time: 3.8272111415863037
Epoch: 2, Steps: 128 Train Loss: 3.0929 (Forecasting Loss:0.2448 + XiCon Loss:2.8482 x Lambda(1.0)), Vali MSE Loss: 0.1791 Test MSE Loss: 0.1223
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.5094433
	speed: 0.0371s/iter; left time: 462.1688s
Epoch: 3 cost time: 4.485724210739136
Epoch: 3, Steps: 128 Train Loss: 3.2809 (Forecasting Loss:0.2325 + XiCon Loss:3.0484 x Lambda(1.0)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1218
Validation loss decreased (0.174181 --> 0.168398).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0604026
	speed: 0.0328s/iter; left time: 404.0129s
Epoch: 4 cost time: 4.329383850097656
Epoch: 4, Steps: 128 Train Loss: 3.2378 (Forecasting Loss:0.2230 + XiCon Loss:3.0148 x Lambda(1.0)), Vali MSE Loss: 0.1668 Test MSE Loss: 0.1188
Validation loss decreased (0.168398 --> 0.166799).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1291490
	speed: 0.0279s/iter; left time: 340.0123s
Epoch: 5 cost time: 3.6404590606689453
Epoch: 5, Steps: 128 Train Loss: 3.1825 (Forecasting Loss:0.2178 + XiCon Loss:2.9647 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1170
Validation loss decreased (0.166799 --> 0.164558).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2997513
	speed: 0.0257s/iter; left time: 310.4160s
Epoch: 6 cost time: 3.2748541831970215
Epoch: 6, Steps: 128 Train Loss: 3.1891 (Forecasting Loss:0.2158 + XiCon Loss:2.9733 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1167
Validation loss decreased (0.164558 --> 0.164185).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1595356
	speed: 0.0341s/iter; left time: 406.9954s
Epoch: 7 cost time: 4.109019756317139
Epoch: 7, Steps: 128 Train Loss: 3.1705 (Forecasting Loss:0.2141 + XiCon Loss:2.9563 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1138
Validation loss decreased (0.164185 --> 0.163580).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.5073357
	speed: 0.0314s/iter; left time: 370.9113s
Epoch: 8 cost time: 3.8904383182525635
Epoch: 8, Steps: 128 Train Loss: 3.1930 (Forecasting Loss:0.2133 + XiCon Loss:2.9797 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1146
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0943012
	speed: 0.0250s/iter; left time: 292.3477s
Epoch: 9 cost time: 3.561741590499878
Epoch: 9, Steps: 128 Train Loss: 3.1653 (Forecasting Loss:0.2131 + XiCon Loss:2.9522 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1957183
	speed: 0.0277s/iter; left time: 319.4327s
Epoch: 10 cost time: 3.4272708892822266
Epoch: 10, Steps: 128 Train Loss: 3.1803 (Forecasting Loss:0.2129 + XiCon Loss:2.9674 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1144
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1691990
	speed: 0.0284s/iter; left time: 324.3817s
Epoch: 11 cost time: 3.582545757293701
Epoch: 11, Steps: 128 Train Loss: 3.1651 (Forecasting Loss:0.2129 + XiCon Loss:2.9522 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1143
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1612897
	speed: 0.0226s/iter; left time: 255.5174s
Epoch: 12 cost time: 3.032177209854126
Epoch: 12, Steps: 128 Train Loss: 3.1865 (Forecasting Loss:0.2128 + XiCon Loss:2.9737 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1142
Validation loss decreased (0.163580 --> 0.163474).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0377812
	speed: 0.0245s/iter; left time: 273.9658s
Epoch: 13 cost time: 3.3724517822265625
Epoch: 13, Steps: 128 Train Loss: 3.1708 (Forecasting Loss:0.2129 + XiCon Loss:2.9579 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1142
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0506809
	speed: 0.0316s/iter; left time: 349.0935s
Epoch: 14 cost time: 4.089993953704834
Epoch: 14, Steps: 128 Train Loss: 3.1737 (Forecasting Loss:0.2129 + XiCon Loss:2.9608 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1142
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0984197
	speed: 0.0294s/iter; left time: 320.8168s
Epoch: 15 cost time: 3.5994327068328857
Epoch: 15, Steps: 128 Train Loss: 3.1900 (Forecasting Loss:0.2127 + XiCon Loss:2.9773 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1142
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1679392
	speed: 0.0283s/iter; left time: 305.6277s
Epoch: 16 cost time: 3.3966994285583496
Epoch: 16, Steps: 128 Train Loss: 3.1701 (Forecasting Loss:0.2128 + XiCon Loss:2.9573 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1142
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1144421
	speed: 0.0248s/iter; left time: 264.4760s
Epoch: 17 cost time: 3.004300832748413
Epoch: 17, Steps: 128 Train Loss: 3.1938 (Forecasting Loss:0.2127 + XiCon Loss:2.9810 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1142
Validation loss decreased (0.163474 --> 0.163315).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1837234
	speed: 0.0282s/iter; left time: 296.4668s
Epoch: 18 cost time: 3.4262750148773193
Epoch: 18, Steps: 128 Train Loss: 3.1678 (Forecasting Loss:0.2127 + XiCon Loss:2.9550 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1142
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2990296
	speed: 0.0285s/iter; left time: 295.8841s
Epoch: 19 cost time: 3.362014055252075
Epoch: 19, Steps: 128 Train Loss: 3.1764 (Forecasting Loss:0.2129 + XiCon Loss:2.9635 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1142
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1969953
	speed: 0.0286s/iter; left time: 293.9047s
Epoch: 20 cost time: 3.620234489440918
Epoch: 20, Steps: 128 Train Loss: 3.1762 (Forecasting Loss:0.2129 + XiCon Loss:2.9634 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1142
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1612957
	speed: 0.0244s/iter; left time: 247.0120s
Epoch: 21 cost time: 3.0326592922210693
Epoch: 21, Steps: 128 Train Loss: 3.1928 (Forecasting Loss:0.2128 + XiCon Loss:2.9801 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1142
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1494675
	speed: 0.0255s/iter; left time: 255.1140s
Epoch: 22 cost time: 3.3323006629943848
Epoch: 22, Steps: 128 Train Loss: 3.1838 (Forecasting Loss:0.2128 + XiCon Loss:2.9711 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0331061
	speed: 0.0356s/iter; left time: 351.8100s
Epoch: 23 cost time: 4.225919246673584
Epoch: 23, Steps: 128 Train Loss: 3.1772 (Forecasting Loss:0.2129 + XiCon Loss:2.9643 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1142
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1618247
	speed: 0.0272s/iter; left time: 265.3565s
Epoch: 24 cost time: 3.4365506172180176
Epoch: 24, Steps: 128 Train Loss: 3.1836 (Forecasting Loss:0.2128 + XiCon Loss:2.9708 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1142
Validation loss decreased (0.163315 --> 0.163311).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.2986548
	speed: 0.0274s/iter; left time: 263.7474s
Epoch: 25 cost time: 3.3895745277404785
Epoch: 25, Steps: 128 Train Loss: 3.1977 (Forecasting Loss:0.2129 + XiCon Loss:2.9848 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2333312
	speed: 0.0292s/iter; left time: 277.4124s
Epoch: 26 cost time: 3.6108474731445312
Epoch: 26, Steps: 128 Train Loss: 3.1873 (Forecasting Loss:0.2128 + XiCon Loss:2.9745 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1459677
	speed: 0.0325s/iter; left time: 304.6395s
Epoch: 27 cost time: 3.9564387798309326
Epoch: 27, Steps: 128 Train Loss: 3.1744 (Forecasting Loss:0.2128 + XiCon Loss:2.9616 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1142
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1372004
	speed: 0.0288s/iter; left time: 265.9146s
Epoch: 28 cost time: 3.935138702392578
Epoch: 28, Steps: 128 Train Loss: 3.1708 (Forecasting Loss:0.2129 + XiCon Loss:2.9578 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1142
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.3274498
	speed: 0.0247s/iter; left time: 225.5889s
Epoch: 29 cost time: 2.909644365310669
Epoch: 29, Steps: 128 Train Loss: 3.1773 (Forecasting Loss:0.2129 + XiCon Loss:2.9644 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1142
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 2.9232540
	speed: 0.0296s/iter; left time: 266.2326s
Epoch: 30 cost time: 3.5885229110717773
Epoch: 30, Steps: 128 Train Loss: 3.1634 (Forecasting Loss:0.2128 + XiCon Loss:2.9507 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.2334073
	speed: 0.0282s/iter; left time: 250.1625s
Epoch: 31 cost time: 3.5875608921051025
Epoch: 31, Steps: 128 Train Loss: 3.1989 (Forecasting Loss:0.2129 + XiCon Loss:2.9860 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1518321
	speed: 0.0311s/iter; left time: 271.5398s
Epoch: 32 cost time: 3.9647462368011475
Epoch: 32, Steps: 128 Train Loss: 3.1883 (Forecasting Loss:0.2127 + XiCon Loss:2.9755 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.4418578
	speed: 0.0258s/iter; left time: 221.7602s
Epoch: 33 cost time: 3.297170639038086
Epoch: 33, Steps: 128 Train Loss: 3.1992 (Forecasting Loss:0.2128 + XiCon Loss:2.9864 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1142
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1395280
	speed: 0.0294s/iter; left time: 249.0496s
Epoch: 34 cost time: 3.6183998584747314
Epoch: 34, Steps: 128 Train Loss: 3.1680 (Forecasting Loss:0.2128 + XiCon Loss:2.9552 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1142
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.052919451147317886, mae:0.17553819715976715, mape:0.1399202197790146, mspe:0.036690853536129 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7240
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.1804066
	speed: 0.0313s/iter; left time: 397.0034s
Epoch: 1 cost time: 3.7830119132995605
Epoch: 1, Steps: 128 Train Loss: 3.2364 (Forecasting Loss:0.2447 + XiCon Loss:2.9918 x Lambda(1.0)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1204
Validation loss decreased (inf --> 0.173306).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0880005
	speed: 0.0239s/iter; left time: 300.2019s
Epoch: 2 cost time: 3.0682971477508545
Epoch: 2, Steps: 128 Train Loss: 3.0863 (Forecasting Loss:0.2453 + XiCon Loss:2.8411 x Lambda(1.0)), Vali MSE Loss: 0.1783 Test MSE Loss: 0.1273
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1062186
	speed: 0.0341s/iter; left time: 423.7618s
Epoch: 3 cost time: 4.014122247695923
Epoch: 3, Steps: 128 Train Loss: 3.1557 (Forecasting Loss:0.2283 + XiCon Loss:2.9274 x Lambda(1.0)), Vali MSE Loss: 0.1690 Test MSE Loss: 0.1199
Validation loss decreased (0.173306 --> 0.168965).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.3247836
	speed: 0.0335s/iter; left time: 412.1438s
Epoch: 4 cost time: 4.024058103561401
Epoch: 4, Steps: 128 Train Loss: 3.2700 (Forecasting Loss:0.2208 + XiCon Loss:3.0492 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1170
Validation loss decreased (0.168965 --> 0.165153).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0484514
	speed: 0.0290s/iter; left time: 353.2497s
Epoch: 5 cost time: 3.6296231746673584
Epoch: 5, Steps: 128 Train Loss: 3.2091 (Forecasting Loss:0.2143 + XiCon Loss:2.9947 x Lambda(1.0)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2142465
	speed: 0.0229s/iter; left time: 276.6289s
Epoch: 6 cost time: 2.938971757888794
Epoch: 6, Steps: 128 Train Loss: 3.1855 (Forecasting Loss:0.2121 + XiCon Loss:2.9734 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1167
Validation loss decreased (0.165153 --> 0.163960).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2102668
	speed: 0.0292s/iter; left time: 348.1555s
Epoch: 7 cost time: 3.5646281242370605
Epoch: 7, Steps: 128 Train Loss: 3.1847 (Forecasting Loss:0.2111 + XiCon Loss:2.9736 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 2.9563067
	speed: 0.0364s/iter; left time: 430.2869s
Epoch: 8 cost time: 4.499082803726196
Epoch: 8, Steps: 128 Train Loss: 3.1662 (Forecasting Loss:0.2092 + XiCon Loss:2.9570 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
Validation loss decreased (0.163960 --> 0.163720).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1711171
	speed: 0.0350s/iter; left time: 408.5533s
Epoch: 9 cost time: 4.020511627197266
Epoch: 9, Steps: 128 Train Loss: 3.1687 (Forecasting Loss:0.2086 + XiCon Loss:2.9602 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1592474
	speed: 0.0291s/iter; left time: 335.9912s
Epoch: 10 cost time: 3.7013213634490967
Epoch: 10, Steps: 128 Train Loss: 3.1777 (Forecasting Loss:0.2086 + XiCon Loss:2.9691 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0501223
	speed: 0.0279s/iter; left time: 319.0150s
Epoch: 11 cost time: 3.564833641052246
Epoch: 11, Steps: 128 Train Loss: 3.1589 (Forecasting Loss:0.2091 + XiCon Loss:2.9498 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3124297
	speed: 0.0278s/iter; left time: 313.9447s
Epoch: 12 cost time: 3.419027328491211
Epoch: 12, Steps: 128 Train Loss: 3.1782 (Forecasting Loss:0.2078 + XiCon Loss:2.9703 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1245503
	speed: 0.0290s/iter; left time: 323.9783s
Epoch: 13 cost time: 3.6067392826080322
Epoch: 13, Steps: 128 Train Loss: 3.1726 (Forecasting Loss:0.2085 + XiCon Loss:2.9640 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.3492193
	speed: 0.0297s/iter; left time: 328.1484s
Epoch: 14 cost time: 3.8532912731170654
Epoch: 14, Steps: 128 Train Loss: 3.1924 (Forecasting Loss:0.2087 + XiCon Loss:2.9837 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 2.9967484
	speed: 0.0318s/iter; left time: 347.0404s
Epoch: 15 cost time: 3.9991157054901123
Epoch: 15, Steps: 128 Train Loss: 3.1615 (Forecasting Loss:0.2087 + XiCon Loss:2.9529 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0886524
	speed: 0.0293s/iter; left time: 315.9213s
Epoch: 16 cost time: 3.4803993701934814
Epoch: 16, Steps: 128 Train Loss: 3.1838 (Forecasting Loss:0.2089 + XiCon Loss:2.9749 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1156
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0653963
	speed: 0.0272s/iter; left time: 289.7008s
Epoch: 17 cost time: 3.3828306198120117
Epoch: 17, Steps: 128 Train Loss: 3.1709 (Forecasting Loss:0.2087 + XiCon Loss:2.9622 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1156
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 2.9974539
	speed: 0.0297s/iter; left time: 312.8661s
Epoch: 18 cost time: 3.939363956451416
Epoch: 18, Steps: 128 Train Loss: 3.1912 (Forecasting Loss:0.2086 + XiCon Loss:2.9826 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05409959331154823, mae:0.1777021586894989, mape:0.14207036793231964, mspe:0.038696903735399246 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8135
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2399755
	speed: 0.0319s/iter; left time: 405.5174s
Epoch: 1 cost time: 3.7208786010742188
Epoch: 1, Steps: 128 Train Loss: 3.2673 (Forecasting Loss:0.2454 + XiCon Loss:3.0218 x Lambda(1.0)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1224
Validation loss decreased (inf --> 0.173001).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2887049
	speed: 0.0374s/iter; left time: 470.7627s
Epoch: 2 cost time: 4.717979431152344
Epoch: 2, Steps: 128 Train Loss: 3.1532 (Forecasting Loss:0.2493 + XiCon Loss:2.9039 x Lambda(1.0)), Vali MSE Loss: 0.1797 Test MSE Loss: 0.1320
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.3741119
	speed: 0.0302s/iter; left time: 375.4752s
Epoch: 3 cost time: 3.772291660308838
Epoch: 3, Steps: 128 Train Loss: 3.2162 (Forecasting Loss:0.2302 + XiCon Loss:2.9860 x Lambda(1.0)), Vali MSE Loss: 0.1695 Test MSE Loss: 0.1238
Validation loss decreased (0.173001 --> 0.169495).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2218182
	speed: 0.0286s/iter; left time: 352.0767s
Epoch: 4 cost time: 3.79038667678833
Epoch: 4, Steps: 128 Train Loss: 3.1503 (Forecasting Loss:0.2218 + XiCon Loss:2.9285 x Lambda(1.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2025561
	speed: 0.0173s/iter; left time: 211.4333s
Epoch: 5 cost time: 2.1701252460479736
Epoch: 5, Steps: 128 Train Loss: 3.1532 (Forecasting Loss:0.2178 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1152
Validation loss decreased (0.169495 --> 0.165472).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 2.9672849
	speed: 0.0173s/iter; left time: 209.1276s
Epoch: 6 cost time: 2.185771942138672
Epoch: 6, Steps: 128 Train Loss: 3.1193 (Forecasting Loss:0.2154 + XiCon Loss:2.9039 x Lambda(1.0)), Vali MSE Loss: 0.1651 Test MSE Loss: 0.1168
Validation loss decreased (0.165472 --> 0.165125).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1400294
	speed: 0.0275s/iter; left time: 328.0710s
Epoch: 7 cost time: 3.4693963527679443
Epoch: 7, Steps: 128 Train Loss: 3.1319 (Forecasting Loss:0.2142 + XiCon Loss:2.9177 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
Validation loss decreased (0.165125 --> 0.163676).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 2.9785326
	speed: 0.0295s/iter; left time: 347.9780s
Epoch: 8 cost time: 3.7265515327453613
Epoch: 8, Steps: 128 Train Loss: 3.1185 (Forecasting Loss:0.2135 + XiCon Loss:2.9050 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0641885
	speed: 0.0291s/iter; left time: 339.7995s
Epoch: 9 cost time: 3.592905282974243
Epoch: 9, Steps: 128 Train Loss: 3.1183 (Forecasting Loss:0.2132 + XiCon Loss:2.9051 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
Validation loss decreased (0.163676 --> 0.163414).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1795864
	speed: 0.0275s/iter; left time: 317.8076s
Epoch: 10 cost time: 3.251605272293091
Epoch: 10, Steps: 128 Train Loss: 3.1334 (Forecasting Loss:0.2131 + XiCon Loss:2.9203 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1159
Validation loss decreased (0.163414 --> 0.163273).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2893302
	speed: 0.0315s/iter; left time: 359.4297s
Epoch: 11 cost time: 3.769822597503662
Epoch: 11, Steps: 128 Train Loss: 3.1243 (Forecasting Loss:0.2129 + XiCon Loss:2.9114 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0839491
	speed: 0.0262s/iter; left time: 295.7577s
Epoch: 12 cost time: 3.454800605773926
Epoch: 12, Steps: 128 Train Loss: 3.1085 (Forecasting Loss:0.2126 + XiCon Loss:2.8959 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.4299400
	speed: 0.0244s/iter; left time: 272.9667s
Epoch: 13 cost time: 3.0857717990875244
Epoch: 13, Steps: 128 Train Loss: 3.1288 (Forecasting Loss:0.2128 + XiCon Loss:2.9159 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0216250
	speed: 0.0245s/iter; left time: 270.0642s
Epoch: 14 cost time: 2.8619961738586426
Epoch: 14, Steps: 128 Train Loss: 3.1297 (Forecasting Loss:0.2129 + XiCon Loss:2.9168 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.2955332
	speed: 0.0186s/iter; left time: 203.3065s
Epoch: 15 cost time: 2.3493714332580566
Epoch: 15, Steps: 128 Train Loss: 3.1167 (Forecasting Loss:0.2129 + XiCon Loss:2.9038 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0964103
	speed: 0.0307s/iter; left time: 330.4431s
Epoch: 16 cost time: 3.7181084156036377
Epoch: 16, Steps: 128 Train Loss: 3.1339 (Forecasting Loss:0.2129 + XiCon Loss:2.9210 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1853971
	speed: 0.0261s/iter; left time: 278.2819s
Epoch: 17 cost time: 3.400209426879883
Epoch: 17, Steps: 128 Train Loss: 3.1163 (Forecasting Loss:0.2127 + XiCon Loss:2.9036 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.3678794
	speed: 0.0261s/iter; left time: 274.9914s
Epoch: 18 cost time: 3.1744606494903564
Epoch: 18, Steps: 128 Train Loss: 3.1218 (Forecasting Loss:0.2128 + XiCon Loss:2.9090 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 2.9777293
	speed: 0.0277s/iter; left time: 287.5502s
Epoch: 19 cost time: 3.2971463203430176
Epoch: 19, Steps: 128 Train Loss: 3.1298 (Forecasting Loss:0.2128 + XiCon Loss:2.9169 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0705531
	speed: 0.0262s/iter; left time: 269.3521s
Epoch: 20 cost time: 3.1595637798309326
Epoch: 20, Steps: 128 Train Loss: 3.1176 (Forecasting Loss:0.2129 + XiCon Loss:2.9047 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1160
Validation loss decreased (0.163273 --> 0.163266).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0552962
	speed: 0.0257s/iter; left time: 260.8308s
Epoch: 21 cost time: 3.316152811050415
Epoch: 21, Steps: 128 Train Loss: 3.1228 (Forecasting Loss:0.2128 + XiCon Loss:2.9100 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 2.9298334
	speed: 0.0348s/iter; left time: 348.9321s
Epoch: 22 cost time: 4.285149812698364
Epoch: 22, Steps: 128 Train Loss: 3.1479 (Forecasting Loss:0.2128 + XiCon Loss:2.9351 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0561554
	speed: 0.0180s/iter; left time: 177.5201s
Epoch: 23 cost time: 2.22442626953125
Epoch: 23, Steps: 128 Train Loss: 3.1295 (Forecasting Loss:0.2128 + XiCon Loss:2.9167 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1409450
	speed: 0.0210s/iter; left time: 205.0980s
Epoch: 24 cost time: 2.837360382080078
Epoch: 24, Steps: 128 Train Loss: 3.1171 (Forecasting Loss:0.2128 + XiCon Loss:2.9043 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0788398
	speed: 0.0266s/iter; left time: 256.0969s
Epoch: 25 cost time: 3.442997455596924
Epoch: 25, Steps: 128 Train Loss: 3.1131 (Forecasting Loss:0.2129 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 2.9498072
	speed: 0.0229s/iter; left time: 217.3131s
Epoch: 26 cost time: 3.0919950008392334
Epoch: 26, Steps: 128 Train Loss: 3.1153 (Forecasting Loss:0.2129 + XiCon Loss:2.9025 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.3947701
	speed: 0.0309s/iter; left time: 289.7023s
Epoch: 27 cost time: 3.8325552940368652
Epoch: 27, Steps: 128 Train Loss: 3.1152 (Forecasting Loss:0.2129 + XiCon Loss:2.9023 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.2961702
	speed: 0.0326s/iter; left time: 301.7717s
Epoch: 28 cost time: 3.962594509124756
Epoch: 28, Steps: 128 Train Loss: 3.1185 (Forecasting Loss:0.2128 + XiCon Loss:2.9057 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1160
Validation loss decreased (0.163266 --> 0.163049).  Saving model ...
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1154296
	speed: 0.0353s/iter; left time: 321.5495s
Epoch: 29 cost time: 4.324502229690552
Epoch: 29, Steps: 128 Train Loss: 3.1135 (Forecasting Loss:0.2129 + XiCon Loss:2.9006 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 2.9757447
	speed: 0.0279s/iter; left time: 251.1082s
Epoch: 30 cost time: 3.496152877807617
Epoch: 30, Steps: 128 Train Loss: 3.1216 (Forecasting Loss:0.2129 + XiCon Loss:2.9087 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0302451
	speed: 0.0282s/iter; left time: 249.4991s
Epoch: 31 cost time: 3.234253406524658
Epoch: 31, Steps: 128 Train Loss: 3.1356 (Forecasting Loss:0.2128 + XiCon Loss:2.9228 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.3057389
	speed: 0.0169s/iter; left time: 147.5987s
Epoch: 32 cost time: 2.091526746749878
Epoch: 32, Steps: 128 Train Loss: 3.1236 (Forecasting Loss:0.2128 + XiCon Loss:2.9108 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2572227
	speed: 0.0231s/iter; left time: 198.3802s
Epoch: 33 cost time: 3.2295749187469482
Epoch: 33, Steps: 128 Train Loss: 3.1353 (Forecasting Loss:0.2125 + XiCon Loss:2.9228 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 2.9839523
	speed: 0.0276s/iter; left time: 233.7716s
Epoch: 34 cost time: 3.667262077331543
Epoch: 34, Steps: 128 Train Loss: 3.1202 (Forecasting Loss:0.2129 + XiCon Loss:2.9074 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.1660469
	speed: 0.0240s/iter; left time: 200.5735s
Epoch: 35 cost time: 2.8973453044891357
Epoch: 35, Steps: 128 Train Loss: 3.1314 (Forecasting Loss:0.2128 + XiCon Loss:2.9187 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.2148440
	speed: 0.0317s/iter; left time: 260.2121s
Epoch: 36 cost time: 3.7944464683532715
Epoch: 36, Steps: 128 Train Loss: 3.1098 (Forecasting Loss:0.2130 + XiCon Loss:2.8968 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.0624030
	speed: 0.0243s/iter; left time: 196.3744s
Epoch: 37 cost time: 2.9428064823150635
Epoch: 37, Steps: 128 Train Loss: 3.1349 (Forecasting Loss:0.2127 + XiCon Loss:2.9221 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.1407168
	speed: 0.0220s/iter; left time: 175.1831s
Epoch: 38 cost time: 2.981473684310913
Epoch: 38, Steps: 128 Train Loss: 3.1007 (Forecasting Loss:0.2128 + XiCon Loss:2.8879 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054262228310108185, mae:0.17770543694496155, mape:0.14123107492923737, mspe:0.037295617163181305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8351
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2666295
	speed: 0.0300s/iter; left time: 380.9128s
Epoch: 1 cost time: 4.1870574951171875
Epoch: 1, Steps: 128 Train Loss: 3.2703 (Forecasting Loss:0.2452 + XiCon Loss:3.0251 x Lambda(1.0)), Vali MSE Loss: 0.1755 Test MSE Loss: 0.1240
Validation loss decreased (inf --> 0.175515).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0910897
	speed: 0.0279s/iter; left time: 350.2085s
Epoch: 2 cost time: 3.654115676879883
Epoch: 2, Steps: 128 Train Loss: 3.1172 (Forecasting Loss:0.2506 + XiCon Loss:2.8666 x Lambda(1.0)), Vali MSE Loss: 0.1765 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0485175
	speed: 0.0260s/iter; left time: 323.9365s
Epoch: 3 cost time: 3.3755688667297363
Epoch: 3, Steps: 128 Train Loss: 3.0431 (Forecasting Loss:0.2292 + XiCon Loss:2.8139 x Lambda(1.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1208
Validation loss decreased (0.175515 --> 0.167955).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2808249
	speed: 0.0329s/iter; left time: 405.8071s
Epoch: 4 cost time: 3.9639687538146973
Epoch: 4, Steps: 128 Train Loss: 3.2515 (Forecasting Loss:0.2215 + XiCon Loss:3.0299 x Lambda(1.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.1179
Validation loss decreased (0.167955 --> 0.167892).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.3127279
	speed: 0.0302s/iter; left time: 367.6568s
Epoch: 5 cost time: 3.7426419258117676
Epoch: 5, Steps: 128 Train Loss: 3.3641 (Forecasting Loss:0.2177 + XiCon Loss:3.1464 x Lambda(1.0)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1186
Validation loss decreased (0.167892 --> 0.165419).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.3128109
	speed: 0.0257s/iter; left time: 310.2787s
Epoch: 6 cost time: 3.4632279872894287
Epoch: 6, Steps: 128 Train Loss: 3.3135 (Forecasting Loss:0.2152 + XiCon Loss:3.0983 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
Validation loss decreased (0.165419 --> 0.163502).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.3007283
	speed: 0.0288s/iter; left time: 344.1901s
Epoch: 7 cost time: 3.6761770248413086
Epoch: 7, Steps: 128 Train Loss: 3.3281 (Forecasting Loss:0.2136 + XiCon Loss:3.1144 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.3194544
	speed: 0.0272s/iter; left time: 321.0782s
Epoch: 8 cost time: 3.3595714569091797
Epoch: 8, Steps: 128 Train Loss: 3.3128 (Forecasting Loss:0.2124 + XiCon Loss:3.1004 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1157
Validation loss decreased (0.163502 --> 0.163275).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.5571454
	speed: 0.0330s/iter; left time: 385.1544s
Epoch: 9 cost time: 4.214984178543091
Epoch: 9, Steps: 128 Train Loss: 3.2852 (Forecasting Loss:0.2117 + XiCon Loss:3.0735 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1154
Validation loss decreased (0.163275 --> 0.163145).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.4694993
	speed: 0.0250s/iter; left time: 288.4918s
Epoch: 10 cost time: 3.4973978996276855
Epoch: 10, Steps: 128 Train Loss: 3.2802 (Forecasting Loss:0.2114 + XiCon Loss:3.0688 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2742016
	speed: 0.0238s/iter; left time: 271.7962s
Epoch: 11 cost time: 2.9908807277679443
Epoch: 11, Steps: 128 Train Loss: 3.2659 (Forecasting Loss:0.2117 + XiCon Loss:3.0542 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3238602
	speed: 0.0318s/iter; left time: 359.5161s
Epoch: 12 cost time: 3.782599687576294
Epoch: 12, Steps: 128 Train Loss: 3.2902 (Forecasting Loss:0.2112 + XiCon Loss:3.0790 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.4688761
	speed: 0.0380s/iter; left time: 424.5424s
Epoch: 13 cost time: 4.587847948074341
Epoch: 13, Steps: 128 Train Loss: 3.2889 (Forecasting Loss:0.2115 + XiCon Loss:3.0774 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.3409421
	speed: 0.0300s/iter; left time: 330.6924s
Epoch: 14 cost time: 3.996426820755005
Epoch: 14, Steps: 128 Train Loss: 3.2777 (Forecasting Loss:0.2113 + XiCon Loss:3.0663 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1153
Validation loss decreased (0.163145 --> 0.163012).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.3016286
	speed: 0.0226s/iter; left time: 246.8654s
Epoch: 15 cost time: 3.0412769317626953
Epoch: 15, Steps: 128 Train Loss: 3.2868 (Forecasting Loss:0.2113 + XiCon Loss:3.0756 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2986288
	speed: 0.0313s/iter; left time: 337.3372s
Epoch: 16 cost time: 3.733989953994751
Epoch: 16, Steps: 128 Train Loss: 3.2973 (Forecasting Loss:0.2112 + XiCon Loss:3.0860 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1153
Validation loss decreased (0.163012 --> 0.162929).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.3162711
	speed: 0.0301s/iter; left time: 320.2699s
Epoch: 17 cost time: 3.8149688243865967
Epoch: 17, Steps: 128 Train Loss: 3.2868 (Forecasting Loss:0.2114 + XiCon Loss:3.0753 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.5159352
	speed: 0.0270s/iter; left time: 284.0388s
Epoch: 18 cost time: 3.463015556335449
Epoch: 18, Steps: 128 Train Loss: 3.2925 (Forecasting Loss:0.2111 + XiCon Loss:3.0814 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2063293
	speed: 0.0309s/iter; left time: 320.7557s
Epoch: 19 cost time: 3.9305496215820312
Epoch: 19, Steps: 128 Train Loss: 3.2845 (Forecasting Loss:0.2113 + XiCon Loss:3.0732 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.3281400
	speed: 0.0271s/iter; left time: 277.7895s
Epoch: 20 cost time: 3.2027783393859863
Epoch: 20, Steps: 128 Train Loss: 3.2816 (Forecasting Loss:0.2111 + XiCon Loss:3.0705 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.2260869
	speed: 0.0286s/iter; left time: 289.7572s
Epoch: 21 cost time: 3.7399065494537354
Epoch: 21, Steps: 128 Train Loss: 3.2836 (Forecasting Loss:0.2111 + XiCon Loss:3.0725 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1153
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.3409002
	speed: 0.0291s/iter; left time: 291.2013s
Epoch: 22 cost time: 3.7246105670928955
Epoch: 22, Steps: 128 Train Loss: 3.2815 (Forecasting Loss:0.2114 + XiCon Loss:3.0701 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2111108
	speed: 0.0308s/iter; left time: 304.2080s
Epoch: 23 cost time: 3.8828811645507812
Epoch: 23, Steps: 128 Train Loss: 3.2937 (Forecasting Loss:0.2113 + XiCon Loss:3.0825 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1153
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.2842841
	speed: 0.0270s/iter; left time: 263.3003s
Epoch: 24 cost time: 3.3731462955474854
Epoch: 24, Steps: 128 Train Loss: 3.2981 (Forecasting Loss:0.2112 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1153
Validation loss decreased (0.162929 --> 0.162805).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.3545594
	speed: 0.0309s/iter; left time: 297.1074s
Epoch: 25 cost time: 3.685551643371582
Epoch: 25, Steps: 128 Train Loss: 3.2749 (Forecasting Loss:0.2115 + XiCon Loss:3.0634 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2339308
	speed: 0.0314s/iter; left time: 298.6067s
Epoch: 26 cost time: 3.8634510040283203
Epoch: 26, Steps: 128 Train Loss: 3.2711 (Forecasting Loss:0.2110 + XiCon Loss:3.0601 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.3976755
	speed: 0.0318s/iter; left time: 298.1939s
Epoch: 27 cost time: 4.050726652145386
Epoch: 27, Steps: 128 Train Loss: 3.3023 (Forecasting Loss:0.2114 + XiCon Loss:3.0910 x Lambda(1.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.5709350
	speed: 0.0237s/iter; left time: 219.2274s
Epoch: 28 cost time: 3.7162461280822754
Epoch: 28, Steps: 128 Train Loss: 3.3198 (Forecasting Loss:0.2113 + XiCon Loss:3.1085 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.3475602
	speed: 0.0272s/iter; left time: 248.1376s
Epoch: 29 cost time: 3.6109156608581543
Epoch: 29, Steps: 128 Train Loss: 3.2946 (Forecasting Loss:0.2112 + XiCon Loss:3.0834 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1133466
	speed: 0.0330s/iter; left time: 296.5545s
Epoch: 30 cost time: 4.257067918777466
Epoch: 30, Steps: 128 Train Loss: 3.2877 (Forecasting Loss:0.2116 + XiCon Loss:3.0761 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1499479
	speed: 0.0303s/iter; left time: 268.2717s
Epoch: 31 cost time: 3.7416651248931885
Epoch: 31, Steps: 128 Train Loss: 3.3039 (Forecasting Loss:0.2114 + XiCon Loss:3.0925 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.3118310
	speed: 0.0287s/iter; left time: 250.2793s
Epoch: 32 cost time: 3.410953998565674
Epoch: 32, Steps: 128 Train Loss: 3.2975 (Forecasting Loss:0.2112 + XiCon Loss:3.0862 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1153
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2708235
	speed: 0.0310s/iter; left time: 266.5603s
Epoch: 33 cost time: 3.791189670562744
Epoch: 33, Steps: 128 Train Loss: 3.2678 (Forecasting Loss:0.2114 + XiCon Loss:3.0565 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1950097
	speed: 0.0283s/iter; left time: 240.2890s
Epoch: 34 cost time: 3.578933000564575
Epoch: 34, Steps: 128 Train Loss: 3.2841 (Forecasting Loss:0.2112 + XiCon Loss:3.0729 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.053880687803030014, mae:0.17669172585010529, mape:0.14072507619857788, mspe:0.037617068737745285 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0540+-0.00082, MAE:0.1771+-0.00129, MAPE:0.1410+-0.00097, MSPE:0.0374+-0.00101, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.7532444
	speed: 0.0523s/iter; left time: 611.6061s
Epoch: 1 cost time: 6.272945404052734
Epoch: 1, Steps: 118 Train Loss: 30.9758 (Forecasting Loss:0.3699 + XiCon Loss:3.0606 x Lambda(10.0)), Vali MSE Loss: 0.2737 Test MSE Loss: 0.1791
Validation loss decreased (inf --> 0.273722).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.1240959
	speed: 0.0488s/iter; left time: 565.6201s
Epoch: 2 cost time: 5.839788198471069
Epoch: 2, Steps: 118 Train Loss: 28.8966 (Forecasting Loss:0.3351 + XiCon Loss:2.8561 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1562
Validation loss decreased (0.273722 --> 0.250412).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7450294
	speed: 0.0491s/iter; left time: 563.2797s
Epoch: 3 cost time: 5.782468318939209
Epoch: 3, Steps: 118 Train Loss: 30.2143 (Forecasting Loss:0.2990 + XiCon Loss:2.9915 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1436
Validation loss decreased (0.250412 --> 0.235226).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1110153
	speed: 0.0499s/iter; left time: 566.0898s
Epoch: 4 cost time: 5.852664232254028
Epoch: 4, Steps: 118 Train Loss: 30.3736 (Forecasting Loss:0.2773 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.2366 Test MSE Loss: 0.1460
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.0155201
	speed: 0.0546s/iter; left time: 613.2900s
Epoch: 5 cost time: 6.369600534439087
Epoch: 5, Steps: 118 Train Loss: 29.8778 (Forecasting Loss:0.2699 + XiCon Loss:2.9608 x Lambda(10.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.9477196
	speed: 0.0462s/iter; left time: 513.5695s
Epoch: 6 cost time: 5.537592649459839
Epoch: 6, Steps: 118 Train Loss: 29.8628 (Forecasting Loss:0.2645 + XiCon Loss:2.9598 x Lambda(10.0)), Vali MSE Loss: 0.2370 Test MSE Loss: 0.1428
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4453373
	speed: 0.0502s/iter; left time: 552.3161s
Epoch: 7 cost time: 5.94618034362793
Epoch: 7, Steps: 118 Train Loss: 29.6160 (Forecasting Loss:0.2631 + XiCon Loss:2.9353 x Lambda(10.0)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.1427
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 27.8396034
	speed: 0.0465s/iter; left time: 505.5855s
Epoch: 8 cost time: 5.4686219692230225
Epoch: 8, Steps: 118 Train Loss: 29.6156 (Forecasting Loss:0.2639 + XiCon Loss:2.9352 x Lambda(10.0)), Vali MSE Loss: 0.2377 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1676464
	speed: 0.0495s/iter; left time: 532.3784s
Epoch: 9 cost time: 6.020238399505615
Epoch: 9, Steps: 118 Train Loss: 29.5702 (Forecasting Loss:0.2620 + XiCon Loss:2.9308 x Lambda(10.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1433
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.8070908
	speed: 0.0527s/iter; left time: 560.1475s
Epoch: 10 cost time: 6.184489488601685
Epoch: 10, Steps: 118 Train Loss: 29.5379 (Forecasting Loss:0.2621 + XiCon Loss:2.9276 x Lambda(10.0)), Vali MSE Loss: 0.2372 Test MSE Loss: 0.1430
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2812576
	speed: 0.0512s/iter; left time: 538.9949s
Epoch: 11 cost time: 5.941311836242676
Epoch: 11, Steps: 118 Train Loss: 29.7272 (Forecasting Loss:0.2621 + XiCon Loss:2.9465 x Lambda(10.0)), Vali MSE Loss: 0.2385 Test MSE Loss: 0.1429
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.1103230
	speed: 0.0502s/iter; left time: 522.6012s
Epoch: 12 cost time: 5.801501989364624
Epoch: 12, Steps: 118 Train Loss: 29.3490 (Forecasting Loss:0.2610 + XiCon Loss:2.9088 x Lambda(10.0)), Vali MSE Loss: 0.2386 Test MSE Loss: 0.1429
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.1525459
	speed: 0.0473s/iter; left time: 486.6928s
Epoch: 13 cost time: 5.879467248916626
Epoch: 13, Steps: 118 Train Loss: 29.5182 (Forecasting Loss:0.2621 + XiCon Loss:2.9256 x Lambda(10.0)), Vali MSE Loss: 0.2383 Test MSE Loss: 0.1429
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07253456115722656, mae:0.21465589106082916, mape:0.15945132076740265, mspe:0.04199362173676491 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7660
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.0190487
	speed: 0.0460s/iter; left time: 538.4117s
Epoch: 1 cost time: 5.189073801040649
Epoch: 1, Steps: 118 Train Loss: 30.8714 (Forecasting Loss:0.3552 + XiCon Loss:3.0516 x Lambda(10.0)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.1653
Validation loss decreased (inf --> 0.253855).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.5406647
	speed: 0.0489s/iter; left time: 566.1168s
Epoch: 2 cost time: 5.962524890899658
Epoch: 2, Steps: 118 Train Loss: 29.0761 (Forecasting Loss:0.3450 + XiCon Loss:2.8731 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1686
Validation loss decreased (0.253855 --> 0.251804).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.9016418
	speed: 0.0464s/iter; left time: 532.5191s
Epoch: 3 cost time: 5.659420728683472
Epoch: 3, Steps: 118 Train Loss: 28.7610 (Forecasting Loss:0.3328 + XiCon Loss:2.8428 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1658
Validation loss decreased (0.251804 --> 0.249115).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.4542503
	speed: 0.0509s/iter; left time: 577.4997s
Epoch: 4 cost time: 5.831482887268066
Epoch: 4, Steps: 118 Train Loss: 31.5569 (Forecasting Loss:0.3252 + XiCon Loss:3.1232 x Lambda(10.0)), Vali MSE Loss: 0.2433 Test MSE Loss: 0.1608
Validation loss decreased (0.249115 --> 0.243269).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.6607361
	speed: 0.0535s/iter; left time: 600.8266s
Epoch: 5 cost time: 6.436958074569702
Epoch: 5, Steps: 118 Train Loss: 32.0700 (Forecasting Loss:0.3168 + XiCon Loss:3.1753 x Lambda(10.0)), Vali MSE Loss: 0.2364 Test MSE Loss: 0.1557
Validation loss decreased (0.243269 --> 0.236383).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3604908
	speed: 0.0510s/iter; left time: 566.9632s
Epoch: 6 cost time: 5.960233688354492
Epoch: 6, Steps: 118 Train Loss: 32.0374 (Forecasting Loss:0.3075 + XiCon Loss:3.1730 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1556
Validation loss decreased (0.236383 --> 0.234893).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.3921585
	speed: 0.0470s/iter; left time: 516.2058s
Epoch: 7 cost time: 5.622636318206787
Epoch: 7, Steps: 118 Train Loss: 31.9725 (Forecasting Loss:0.3038 + XiCon Loss:3.1669 x Lambda(10.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.1536
Validation loss decreased (0.234893 --> 0.231711).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.5725899
	speed: 0.0525s/iter; left time: 571.4198s
Epoch: 8 cost time: 6.05343770980835
Epoch: 8, Steps: 118 Train Loss: 31.9121 (Forecasting Loss:0.3009 + XiCon Loss:3.1611 x Lambda(10.0)), Vali MSE Loss: 0.2310 Test MSE Loss: 0.1531
Validation loss decreased (0.231711 --> 0.230951).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1333542
	speed: 0.0453s/iter; left time: 487.4239s
Epoch: 9 cost time: 5.533267259597778
Epoch: 9, Steps: 118 Train Loss: 32.0552 (Forecasting Loss:0.2993 + XiCon Loss:3.1756 x Lambda(10.0)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.1528
Validation loss decreased (0.230951 --> 0.230800).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7693729
	speed: 0.0480s/iter; left time: 510.9737s
Epoch: 10 cost time: 5.467889785766602
Epoch: 10, Steps: 118 Train Loss: 31.9350 (Forecasting Loss:0.2990 + XiCon Loss:3.1636 x Lambda(10.0)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1531
Validation loss decreased (0.230800 --> 0.230524).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.9508629
	speed: 0.0398s/iter; left time: 419.1567s
Epoch: 11 cost time: 4.835237979888916
Epoch: 11, Steps: 118 Train Loss: 32.2175 (Forecasting Loss:0.2983 + XiCon Loss:3.1919 x Lambda(10.0)), Vali MSE Loss: 0.2299 Test MSE Loss: 0.1529
Validation loss decreased (0.230524 --> 0.229945).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3217335
	speed: 0.0512s/iter; left time: 532.1146s
Epoch: 12 cost time: 5.878860235214233
Epoch: 12, Steps: 118 Train Loss: 32.0692 (Forecasting Loss:0.2991 + XiCon Loss:3.1770 x Lambda(10.0)), Vali MSE Loss: 0.2306 Test MSE Loss: 0.1529
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.3524170
	speed: 0.0491s/iter; left time: 504.9952s
Epoch: 13 cost time: 5.859235048294067
Epoch: 13, Steps: 118 Train Loss: 31.7800 (Forecasting Loss:0.2993 + XiCon Loss:3.1481 x Lambda(10.0)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1528
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.7931938
	speed: 0.0480s/iter; left time: 488.2854s
Epoch: 14 cost time: 5.58514666557312
Epoch: 14, Steps: 118 Train Loss: 31.8197 (Forecasting Loss:0.2986 + XiCon Loss:3.1521 x Lambda(10.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.1528
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.1441154
	speed: 0.0503s/iter; left time: 505.3154s
Epoch: 15 cost time: 5.954478740692139
Epoch: 15, Steps: 118 Train Loss: 31.8135 (Forecasting Loss:0.2994 + XiCon Loss:3.1514 x Lambda(10.0)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1528
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.4565697
	speed: 0.0351s/iter; left time: 348.6098s
Epoch: 16 cost time: 4.2639479637146
Epoch: 16, Steps: 118 Train Loss: 31.8439 (Forecasting Loss:0.2984 + XiCon Loss:3.1546 x Lambda(10.0)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.1528
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.6070023
	speed: 0.0512s/iter; left time: 502.2054s
Epoch: 17 cost time: 6.06655478477478
Epoch: 17, Steps: 118 Train Loss: 31.8870 (Forecasting Loss:0.2985 + XiCon Loss:3.1588 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1528
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.5669861
	speed: 0.0526s/iter; left time: 509.8454s
Epoch: 18 cost time: 6.056328535079956
Epoch: 18, Steps: 118 Train Loss: 31.9139 (Forecasting Loss:0.2989 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.1528
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.9430122
	speed: 0.0499s/iter; left time: 478.2269s
Epoch: 19 cost time: 6.077796459197998
Epoch: 19, Steps: 118 Train Loss: 32.0038 (Forecasting Loss:0.2995 + XiCon Loss:3.1704 x Lambda(10.0)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1528
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.1499939
	speed: 0.0497s/iter; left time: 469.7082s
Epoch: 20 cost time: 5.872530698776245
Epoch: 20, Steps: 118 Train Loss: 32.0257 (Forecasting Loss:0.2986 + XiCon Loss:3.1727 x Lambda(10.0)), Vali MSE Loss: 0.2302 Test MSE Loss: 0.1528
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.6779556
	speed: 0.0522s/iter; left time: 487.2402s
Epoch: 21 cost time: 5.962612628936768
Epoch: 21, Steps: 118 Train Loss: 31.9136 (Forecasting Loss:0.2987 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.2304 Test MSE Loss: 0.1528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08025186508893967, mae:0.22560852766036987, mape:0.16587619483470917, mspe:0.04388444870710373 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7554
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.7300320
	speed: 0.0457s/iter; left time: 534.8039s
Epoch: 1 cost time: 5.400040864944458
Epoch: 1, Steps: 118 Train Loss: 30.8748 (Forecasting Loss:0.3568 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1677
Validation loss decreased (inf --> 0.259245).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4466629
	speed: 0.0454s/iter; left time: 525.7412s
Epoch: 2 cost time: 5.4510884284973145
Epoch: 2, Steps: 118 Train Loss: 29.2708 (Forecasting Loss:0.3348 + XiCon Loss:2.8936 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1692
Validation loss decreased (0.259245 --> 0.249816).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0593433
	speed: 0.0535s/iter; left time: 613.1137s
Epoch: 3 cost time: 6.144886016845703
Epoch: 3, Steps: 118 Train Loss: 30.2626 (Forecasting Loss:0.3022 + XiCon Loss:2.9960 x Lambda(10.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1580
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3684940
	speed: 0.0454s/iter; left time: 515.3470s
Epoch: 4 cost time: 5.497179269790649
Epoch: 4, Steps: 118 Train Loss: 29.7139 (Forecasting Loss:0.2853 + XiCon Loss:2.9429 x Lambda(10.0)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1477
Validation loss decreased (0.249816 --> 0.242579).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.2387848
	speed: 0.0456s/iter; left time: 511.7583s
Epoch: 5 cost time: 5.533561706542969
Epoch: 5, Steps: 118 Train Loss: 29.4906 (Forecasting Loss:0.2734 + XiCon Loss:2.9217 x Lambda(10.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1483
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6536217
	speed: 0.0480s/iter; left time: 533.2141s
Epoch: 6 cost time: 5.513620853424072
Epoch: 6, Steps: 118 Train Loss: 29.4974 (Forecasting Loss:0.2681 + XiCon Loss:2.9229 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1489
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.5349178
	speed: 0.0508s/iter; left time: 558.0556s
Epoch: 7 cost time: 5.822759628295898
Epoch: 7, Steps: 118 Train Loss: 29.4290 (Forecasting Loss:0.2654 + XiCon Loss:2.9164 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1490
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.2514801
	speed: 0.0483s/iter; left time: 525.6933s
Epoch: 8 cost time: 5.784834146499634
Epoch: 8, Steps: 118 Train Loss: 29.4399 (Forecasting Loss:0.2650 + XiCon Loss:2.9175 x Lambda(10.0)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1505
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.0756321
	speed: 0.0464s/iter; left time: 498.9671s
Epoch: 9 cost time: 5.51735782623291
Epoch: 9, Steps: 118 Train Loss: 29.3618 (Forecasting Loss:0.2650 + XiCon Loss:2.9097 x Lambda(10.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1500
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0152092
	speed: 0.0443s/iter; left time: 471.4999s
Epoch: 10 cost time: 5.2582480907440186
Epoch: 10, Steps: 118 Train Loss: 29.3456 (Forecasting Loss:0.2639 + XiCon Loss:2.9082 x Lambda(10.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1497
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.1816101
	speed: 0.0511s/iter; left time: 537.1965s
Epoch: 11 cost time: 5.774566888809204
Epoch: 11, Steps: 118 Train Loss: 29.4926 (Forecasting Loss:0.2641 + XiCon Loss:2.9229 x Lambda(10.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1498
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.2441559
	speed: 0.0458s/iter; left time: 475.9565s
Epoch: 12 cost time: 5.6613054275512695
Epoch: 12, Steps: 118 Train Loss: 29.2419 (Forecasting Loss:0.2647 + XiCon Loss:2.8977 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1499
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.9258404
	speed: 0.0464s/iter; left time: 477.5118s
Epoch: 13 cost time: 5.664099931716919
Epoch: 13, Steps: 118 Train Loss: 29.3229 (Forecasting Loss:0.2634 + XiCon Loss:2.9060 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1499
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.7087345
	speed: 0.0526s/iter; left time: 535.2914s
Epoch: 14 cost time: 6.098928689956665
Epoch: 14, Steps: 118 Train Loss: 29.4102 (Forecasting Loss:0.2642 + XiCon Loss:2.9146 x Lambda(10.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1499
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07669437676668167, mae:0.21869948506355286, mape:0.159995436668396, mspe:0.04235939681529999 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8181
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.6340752
	speed: 0.0431s/iter; left time: 504.0975s
Epoch: 1 cost time: 5.0875701904296875
Epoch: 1, Steps: 118 Train Loss: 30.8216 (Forecasting Loss:0.3665 + XiCon Loss:3.0455 x Lambda(10.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.1757
Validation loss decreased (inf --> 0.269322).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8449593
	speed: 0.0439s/iter; left time: 509.0517s
Epoch: 2 cost time: 5.4106972217559814
Epoch: 2, Steps: 118 Train Loss: 29.1389 (Forecasting Loss:0.3452 + XiCon Loss:2.8794 x Lambda(10.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1659
Validation loss decreased (0.269322 --> 0.258564).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7377625
	speed: 0.0486s/iter; left time: 557.6378s
Epoch: 3 cost time: 5.627203702926636
Epoch: 3, Steps: 118 Train Loss: 29.9295 (Forecasting Loss:0.3297 + XiCon Loss:2.9600 x Lambda(10.0)), Vali MSE Loss: 0.2374 Test MSE Loss: 0.1542
Validation loss decreased (0.258564 --> 0.237380).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9898529
	speed: 0.0474s/iter; left time: 537.6486s
Epoch: 4 cost time: 5.700406312942505
Epoch: 4, Steps: 118 Train Loss: 29.2719 (Forecasting Loss:0.2884 + XiCon Loss:2.8983 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1412
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.4357624
	speed: 0.0489s/iter; left time: 548.6330s
Epoch: 5 cost time: 5.838029623031616
Epoch: 5, Steps: 118 Train Loss: 28.9570 (Forecasting Loss:0.2723 + XiCon Loss:2.8685 x Lambda(10.0)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1455
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4310303
	speed: 0.0482s/iter; left time: 535.4859s
Epoch: 6 cost time: 5.674512147903442
Epoch: 6, Steps: 118 Train Loss: 29.0307 (Forecasting Loss:0.2693 + XiCon Loss:2.8761 x Lambda(10.0)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1447
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.1139259
	speed: 0.0517s/iter; left time: 568.2485s
Epoch: 7 cost time: 5.9079906940460205
Epoch: 7, Steps: 118 Train Loss: 28.8537 (Forecasting Loss:0.2674 + XiCon Loss:2.8586 x Lambda(10.0)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.1438
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.6059208
	speed: 0.0472s/iter; left time: 513.1407s
Epoch: 8 cost time: 5.675368547439575
Epoch: 8, Steps: 118 Train Loss: 28.9154 (Forecasting Loss:0.2673 + XiCon Loss:2.8648 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3140659
	speed: 0.0485s/iter; left time: 521.8739s
Epoch: 9 cost time: 5.726542949676514
Epoch: 9, Steps: 118 Train Loss: 28.9513 (Forecasting Loss:0.2671 + XiCon Loss:2.8684 x Lambda(10.0)), Vali MSE Loss: 0.2380 Test MSE Loss: 0.1448
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.0493488
	speed: 0.0516s/iter; left time: 549.1380s
Epoch: 10 cost time: 5.884742498397827
Epoch: 10, Steps: 118 Train Loss: 29.0067 (Forecasting Loss:0.2668 + XiCon Loss:2.8740 x Lambda(10.0)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.1446
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.4406891
	speed: 0.0490s/iter; left time: 515.7318s
Epoch: 11 cost time: 5.937166452407837
Epoch: 11, Steps: 118 Train Loss: 28.9426 (Forecasting Loss:0.2659 + XiCon Loss:2.8677 x Lambda(10.0)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1445
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.5877514
	speed: 0.0480s/iter; left time: 498.9792s
Epoch: 12 cost time: 5.872581481933594
Epoch: 12, Steps: 118 Train Loss: 29.0346 (Forecasting Loss:0.2666 + XiCon Loss:2.8768 x Lambda(10.0)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1446
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.5971069
	speed: 0.0504s/iter; left time: 518.7117s
Epoch: 13 cost time: 5.909348964691162
Epoch: 13, Steps: 118 Train Loss: 28.9418 (Forecasting Loss:0.2664 + XiCon Loss:2.8675 x Lambda(10.0)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0823250487446785, mae:0.22615735232830048, mape:0.1650831699371338, mspe:0.04418797418475151 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7647
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.7236595
	speed: 0.0431s/iter; left time: 504.1703s
Epoch: 1 cost time: 5.2628679275512695
Epoch: 1, Steps: 118 Train Loss: 30.8063 (Forecasting Loss:0.3746 + XiCon Loss:3.0432 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1759
Validation loss decreased (inf --> 0.270212).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.9322586
	speed: 0.0532s/iter; left time: 616.5008s
Epoch: 2 cost time: 6.37834906578064
Epoch: 2, Steps: 118 Train Loss: 29.0534 (Forecasting Loss:0.3453 + XiCon Loss:2.8708 x Lambda(10.0)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1682
Validation loss decreased (0.270212 --> 0.255045).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.1831398
	speed: 0.0572s/iter; left time: 655.4590s
Epoch: 3 cost time: 6.466829776763916
Epoch: 3, Steps: 118 Train Loss: 29.6588 (Forecasting Loss:0.3322 + XiCon Loss:2.9327 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1654
Validation loss decreased (0.255045 --> 0.250078).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2375221
	speed: 0.0502s/iter; left time: 569.2758s
Epoch: 4 cost time: 5.9423394203186035
Epoch: 4, Steps: 118 Train Loss: 30.0644 (Forecasting Loss:0.3187 + XiCon Loss:2.9746 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1488
Validation loss decreased (0.250078 --> 0.239387).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.2487335
	speed: 0.0470s/iter; left time: 528.0889s
Epoch: 5 cost time: 5.697970151901245
Epoch: 5, Steps: 118 Train Loss: 29.9122 (Forecasting Loss:0.3077 + XiCon Loss:2.9604 x Lambda(10.0)), Vali MSE Loss: 0.2380 Test MSE Loss: 0.1527
Validation loss decreased (0.239387 --> 0.238049).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.3722687
	speed: 0.0542s/iter; left time: 601.9087s
Epoch: 6 cost time: 6.161721229553223
Epoch: 6, Steps: 118 Train Loss: 29.8084 (Forecasting Loss:0.2998 + XiCon Loss:2.9509 x Lambda(10.0)), Vali MSE Loss: 0.2375 Test MSE Loss: 0.1476
Validation loss decreased (0.238049 --> 0.237503).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.6083145
	speed: 0.0525s/iter; left time: 577.6393s
Epoch: 7 cost time: 6.265464544296265
Epoch: 7, Steps: 118 Train Loss: 29.7227 (Forecasting Loss:0.2968 + XiCon Loss:2.9426 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1497
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3447590
	speed: 0.0489s/iter; left time: 531.3368s
Epoch: 8 cost time: 5.804018259048462
Epoch: 8, Steps: 118 Train Loss: 29.7159 (Forecasting Loss:0.2950 + XiCon Loss:2.9421 x Lambda(10.0)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.1488
Validation loss decreased (0.237503 --> 0.237122).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5917130
	speed: 0.0493s/iter; left time: 530.5684s
Epoch: 9 cost time: 5.6845386028289795
Epoch: 9, Steps: 118 Train Loss: 29.7058 (Forecasting Loss:0.2942 + XiCon Loss:2.9412 x Lambda(10.0)), Vali MSE Loss: 0.2367 Test MSE Loss: 0.1489
Validation loss decreased (0.237122 --> 0.236693).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.6165619
	speed: 0.0483s/iter; left time: 513.8195s
Epoch: 10 cost time: 6.006273508071899
Epoch: 10, Steps: 118 Train Loss: 29.6186 (Forecasting Loss:0.2930 + XiCon Loss:2.9326 x Lambda(10.0)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.1492
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7354679
	speed: 0.0547s/iter; left time: 575.5124s
Epoch: 11 cost time: 6.415583372116089
Epoch: 11, Steps: 118 Train Loss: 29.8396 (Forecasting Loss:0.2930 + XiCon Loss:2.9547 x Lambda(10.0)), Vali MSE Loss: 0.2375 Test MSE Loss: 0.1489
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3458176
	speed: 0.0502s/iter; left time: 522.4812s
Epoch: 12 cost time: 6.024668455123901
Epoch: 12, Steps: 118 Train Loss: 29.7991 (Forecasting Loss:0.2921 + XiCon Loss:2.9507 x Lambda(10.0)), Vali MSE Loss: 0.2370 Test MSE Loss: 0.1488
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.8359318
	speed: 0.0444s/iter; left time: 456.8780s
Epoch: 13 cost time: 5.339589357376099
Epoch: 13, Steps: 118 Train Loss: 29.7075 (Forecasting Loss:0.2927 + XiCon Loss:2.9415 x Lambda(10.0)), Vali MSE Loss: 0.2380 Test MSE Loss: 0.1487
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.8468933
	speed: 0.0487s/iter; left time: 495.5102s
Epoch: 14 cost time: 5.576272487640381
Epoch: 14, Steps: 118 Train Loss: 29.6992 (Forecasting Loss:0.2930 + XiCon Loss:2.9406 x Lambda(10.0)), Vali MSE Loss: 0.2371 Test MSE Loss: 0.1487
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9517689
	speed: 0.0508s/iter; left time: 510.2940s
Epoch: 15 cost time: 5.734832763671875
Epoch: 15, Steps: 118 Train Loss: 29.7401 (Forecasting Loss:0.2923 + XiCon Loss:2.9448 x Lambda(10.0)), Vali MSE Loss: 0.2374 Test MSE Loss: 0.1487
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4956207
	speed: 0.0399s/iter; left time: 396.4820s
Epoch: 16 cost time: 4.901511907577515
Epoch: 16, Steps: 118 Train Loss: 29.7468 (Forecasting Loss:0.2925 + XiCon Loss:2.9454 x Lambda(10.0)), Vali MSE Loss: 0.2376 Test MSE Loss: 0.1487
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.3427773
	speed: 0.0521s/iter; left time: 511.1555s
Epoch: 17 cost time: 5.953937292098999
Epoch: 17, Steps: 118 Train Loss: 29.6499 (Forecasting Loss:0.2930 + XiCon Loss:2.9357 x Lambda(10.0)), Vali MSE Loss: 0.2375 Test MSE Loss: 0.1487
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4499016
	speed: 0.0479s/iter; left time: 463.9188s
Epoch: 18 cost time: 5.678805351257324
Epoch: 18, Steps: 118 Train Loss: 29.6613 (Forecasting Loss:0.2925 + XiCon Loss:2.9369 x Lambda(10.0)), Vali MSE Loss: 0.2376 Test MSE Loss: 0.1487
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.3789768
	speed: 0.0542s/iter; left time: 518.7066s
Epoch: 19 cost time: 6.433838367462158
Epoch: 19, Steps: 118 Train Loss: 29.7407 (Forecasting Loss:0.2921 + XiCon Loss:2.9449 x Lambda(10.0)), Vali MSE Loss: 0.2379 Test MSE Loss: 0.1487
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0782310962677002, mae:0.2195747345685959, mape:0.159232035279274, mspe:0.04085186868906021 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0780+-0.00462, MAE:0.2209+-0.00606, MAPE:0.1619+-0.00406, MSPE:0.0427+-0.00172, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5984
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.7976994
	speed: 0.0675s/iter; left time: 715.1705s
Epoch: 1 cost time: 7.265836477279663
Epoch: 1, Steps: 107 Train Loss: 0.8398 (Forecasting Loss:0.5324 + XiCon Loss:3.0741 x Lambda(0.1)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.1973
Validation loss decreased (inf --> 0.345993).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5761282
	speed: 0.0654s/iter; left time: 686.4577s
Epoch: 2 cost time: 7.017933368682861
Epoch: 2, Steps: 107 Train Loss: 0.6798 (Forecasting Loss:0.3783 + XiCon Loss:3.0151 x Lambda(0.1)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1391
Validation loss decreased (0.345993 --> 0.253842).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5593160
	speed: 0.0683s/iter; left time: 709.3619s
Epoch: 3 cost time: 7.272616863250732
Epoch: 3, Steps: 107 Train Loss: 0.5645 (Forecasting Loss:0.2695 + XiCon Loss:2.9496 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.1404
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5465636
	speed: 0.0602s/iter; left time: 619.2538s
Epoch: 4 cost time: 6.5808892250061035
Epoch: 4, Steps: 107 Train Loss: 0.5475 (Forecasting Loss:0.2548 + XiCon Loss:2.9274 x Lambda(0.1)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5364929
	speed: 0.0684s/iter; left time: 696.3009s
Epoch: 5 cost time: 7.383085012435913
Epoch: 5, Steps: 107 Train Loss: 0.5376 (Forecasting Loss:0.2464 + XiCon Loss:2.9116 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5281414
	speed: 0.0650s/iter; left time: 654.2194s
Epoch: 6 cost time: 7.009891033172607
Epoch: 6, Steps: 107 Train Loss: 0.5331 (Forecasting Loss:0.2430 + XiCon Loss:2.9006 x Lambda(0.1)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5085327
	speed: 0.0688s/iter; left time: 684.7610s
Epoch: 7 cost time: 7.434678792953491
Epoch: 7, Steps: 107 Train Loss: 0.5313 (Forecasting Loss:0.2416 + XiCon Loss:2.8974 x Lambda(0.1)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5369668
	speed: 0.0632s/iter; left time: 622.4428s
Epoch: 8 cost time: 6.809852361679077
Epoch: 8, Steps: 107 Train Loss: 0.5303 (Forecasting Loss:0.2411 + XiCon Loss:2.8929 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1415
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5435134
	speed: 0.0662s/iter; left time: 645.3151s
Epoch: 9 cost time: 7.134639501571655
Epoch: 9, Steps: 107 Train Loss: 0.5299 (Forecasting Loss:0.2404 + XiCon Loss:2.8943 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1413
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5382333
	speed: 0.0690s/iter; left time: 664.8677s
Epoch: 10 cost time: 7.458921909332275
Epoch: 10, Steps: 107 Train Loss: 0.5294 (Forecasting Loss:0.2400 + XiCon Loss:2.8936 x Lambda(0.1)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1412
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5306273
	speed: 0.0714s/iter; left time: 680.5158s
Epoch: 11 cost time: 7.745364427566528
Epoch: 11, Steps: 107 Train Loss: 0.5292 (Forecasting Loss:0.2400 + XiCon Loss:2.8923 x Lambda(0.1)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1409
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5377284
	speed: 0.0649s/iter; left time: 611.7599s
Epoch: 12 cost time: 6.999762296676636
Epoch: 12, Steps: 107 Train Loss: 0.5291 (Forecasting Loss:0.2399 + XiCon Loss:2.8923 x Lambda(0.1)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1406
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06915809959173203, mae:0.20905767381191254, mape:0.15434886515140533, mspe:0.039988789707422256 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7386
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8036025
	speed: 0.0640s/iter; left time: 678.7839s
Epoch: 1 cost time: 6.8975982666015625
Epoch: 1, Steps: 107 Train Loss: 0.8549 (Forecasting Loss:0.5476 + XiCon Loss:3.0731 x Lambda(0.1)), Vali MSE Loss: 0.3473 Test MSE Loss: 0.2133
Validation loss decreased (inf --> 0.347254).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5734801
	speed: 0.0756s/iter; left time: 793.3037s
Epoch: 2 cost time: 8.198189973831177
Epoch: 2, Steps: 107 Train Loss: 0.6943 (Forecasting Loss:0.3890 + XiCon Loss:3.0526 x Lambda(0.1)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.1622
Validation loss decreased (0.347254 --> 0.306342).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5590186
	speed: 0.0787s/iter; left time: 817.3319s
Epoch: 3 cost time: 8.518123388290405
Epoch: 3, Steps: 107 Train Loss: 0.5703 (Forecasting Loss:0.2657 + XiCon Loss:3.0467 x Lambda(0.1)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.1620
Validation loss decreased (0.306342 --> 0.259806).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5659525
	speed: 0.0802s/iter; left time: 824.4057s
Epoch: 4 cost time: 8.696943998336792
Epoch: 4, Steps: 107 Train Loss: 0.5581 (Forecasting Loss:0.2502 + XiCon Loss:3.0787 x Lambda(0.1)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1570
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5567742
	speed: 0.0804s/iter; left time: 818.1815s
Epoch: 5 cost time: 8.652053356170654
Epoch: 5, Steps: 107 Train Loss: 0.5504 (Forecasting Loss:0.2430 + XiCon Loss:3.0742 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1571
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5510138
	speed: 0.0779s/iter; left time: 784.1186s
Epoch: 6 cost time: 8.41749882698059
Epoch: 6, Steps: 107 Train Loss: 0.5476 (Forecasting Loss:0.2394 + XiCon Loss:3.0817 x Lambda(0.1)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.1569
Validation loss decreased (0.259806 --> 0.255913).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5412213
	speed: 0.0781s/iter; left time: 777.9118s
Epoch: 7 cost time: 8.40421748161316
Epoch: 7, Steps: 107 Train Loss: 0.5463 (Forecasting Loss:0.2379 + XiCon Loss:3.0845 x Lambda(0.1)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1564
Validation loss decreased (0.255913 --> 0.255447).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5319443
	speed: 0.0791s/iter; left time: 779.0563s
Epoch: 8 cost time: 8.469619512557983
Epoch: 8, Steps: 107 Train Loss: 0.5449 (Forecasting Loss:0.2368 + XiCon Loss:3.0813 x Lambda(0.1)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1568
Validation loss decreased (0.255447 --> 0.254922).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5336127
	speed: 0.0774s/iter; left time: 754.2914s
Epoch: 9 cost time: 8.34486436843872
Epoch: 9, Steps: 107 Train Loss: 0.5446 (Forecasting Loss:0.2361 + XiCon Loss:3.0848 x Lambda(0.1)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1565
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5343974
	speed: 0.0797s/iter; left time: 768.0105s
Epoch: 10 cost time: 8.517918109893799
Epoch: 10, Steps: 107 Train Loss: 0.5440 (Forecasting Loss:0.2358 + XiCon Loss:3.0816 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1581
Validation loss decreased (0.254922 --> 0.254439).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5370692
	speed: 0.0806s/iter; left time: 768.3700s
Epoch: 11 cost time: 8.686309814453125
Epoch: 11, Steps: 107 Train Loss: 0.5438 (Forecasting Loss:0.2355 + XiCon Loss:3.0834 x Lambda(0.1)), Vali MSE Loss: 0.2553 Test MSE Loss: 0.1568
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5492714
	speed: 0.0799s/iter; left time: 753.1873s
Epoch: 12 cost time: 8.690690279006958
Epoch: 12, Steps: 107 Train Loss: 0.5435 (Forecasting Loss:0.2358 + XiCon Loss:3.0772 x Lambda(0.1)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.1573
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5385346
	speed: 0.0785s/iter; left time: 731.2116s
Epoch: 13 cost time: 8.525871992111206
Epoch: 13, Steps: 107 Train Loss: 0.5450 (Forecasting Loss:0.2358 + XiCon Loss:3.0916 x Lambda(0.1)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.1576
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5344492
	speed: 0.0766s/iter; left time: 705.1563s
Epoch: 14 cost time: 8.26223635673523
Epoch: 14, Steps: 107 Train Loss: 0.5439 (Forecasting Loss:0.2352 + XiCon Loss:3.0865 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1576
Validation loss decreased (0.254439 --> 0.254434).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5296686
	speed: 0.0747s/iter; left time: 679.7160s
Epoch: 15 cost time: 8.108241558074951
Epoch: 15, Steps: 107 Train Loss: 0.5441 (Forecasting Loss:0.2356 + XiCon Loss:3.0845 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1576
Validation loss decreased (0.254434 --> 0.254362).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5353564
	speed: 0.0786s/iter; left time: 707.0920s
Epoch: 16 cost time: 8.450187683105469
Epoch: 16, Steps: 107 Train Loss: 0.5441 (Forecasting Loss:0.2354 + XiCon Loss:3.0871 x Lambda(0.1)), Vali MSE Loss: 0.2547 Test MSE Loss: 0.1575
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5419675
	speed: 0.0776s/iter; left time: 690.1460s
Epoch: 17 cost time: 8.319975852966309
Epoch: 17, Steps: 107 Train Loss: 0.5442 (Forecasting Loss:0.2356 + XiCon Loss:3.0860 x Lambda(0.1)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.1575
Validation loss decreased (0.254362 --> 0.253984).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5484644
	speed: 0.0798s/iter; left time: 701.1776s
Epoch: 18 cost time: 8.537424087524414
Epoch: 18, Steps: 107 Train Loss: 0.5435 (Forecasting Loss:0.2356 + XiCon Loss:3.0792 x Lambda(0.1)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1575
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5396060
	speed: 0.0821s/iter; left time: 711.8540s
Epoch: 19 cost time: 8.783231735229492
Epoch: 19, Steps: 107 Train Loss: 0.5441 (Forecasting Loss:0.2357 + XiCon Loss:3.0847 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1575
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5424621
	speed: 0.0780s/iter; left time: 668.4478s
Epoch: 20 cost time: 8.398380756378174
Epoch: 20, Steps: 107 Train Loss: 0.5440 (Forecasting Loss:0.2351 + XiCon Loss:3.0889 x Lambda(0.1)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.1575
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5372804
	speed: 0.0830s/iter; left time: 701.9847s
Epoch: 21 cost time: 8.993531942367554
Epoch: 21, Steps: 107 Train Loss: 0.5434 (Forecasting Loss:0.2356 + XiCon Loss:3.0777 x Lambda(0.1)), Vali MSE Loss: 0.2543 Test MSE Loss: 0.1575
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5480902
	speed: 0.0838s/iter; left time: 700.0425s
Epoch: 22 cost time: 9.13249397277832
Epoch: 22, Steps: 107 Train Loss: 0.5435 (Forecasting Loss:0.2351 + XiCon Loss:3.0838 x Lambda(0.1)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1575
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.5397837
	speed: 0.0775s/iter; left time: 639.3388s
Epoch: 23 cost time: 8.384126901626587
Epoch: 23, Steps: 107 Train Loss: 0.5433 (Forecasting Loss:0.2358 + XiCon Loss:3.0747 x Lambda(0.1)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.1575
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.5433630
	speed: 0.0778s/iter; left time: 633.3898s
Epoch: 24 cost time: 8.368948698043823
Epoch: 24, Steps: 107 Train Loss: 0.5439 (Forecasting Loss:0.2353 + XiCon Loss:3.0858 x Lambda(0.1)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.1575
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5397285
	speed: 0.0773s/iter; left time: 620.9174s
Epoch: 25 cost time: 8.31766414642334
Epoch: 25, Steps: 107 Train Loss: 0.5436 (Forecasting Loss:0.2357 + XiCon Loss:3.0787 x Lambda(0.1)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.1575
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.5441254
	speed: 0.0703s/iter; left time: 556.8521s
Epoch: 26 cost time: 7.609275817871094
Epoch: 26, Steps: 107 Train Loss: 0.5434 (Forecasting Loss:0.2352 + XiCon Loss:3.0816 x Lambda(0.1)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.1575
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.5459914
	speed: 0.0766s/iter; left time: 599.0820s
Epoch: 27 cost time: 8.186157941818237
Epoch: 27, Steps: 107 Train Loss: 0.5446 (Forecasting Loss:0.2355 + XiCon Loss:3.0909 x Lambda(0.1)), Vali MSE Loss: 0.2547 Test MSE Loss: 0.1575
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08499330282211304, mae:0.230036199092865, mape:0.16634468734264374, mspe:0.045735761523246765 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7411
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.7453259
	speed: 0.0646s/iter; left time: 684.6665s
Epoch: 1 cost time: 6.93630313873291
Epoch: 1, Steps: 107 Train Loss: 0.8366 (Forecasting Loss:0.5288 + XiCon Loss:3.0779 x Lambda(0.1)), Vali MSE Loss: 0.3408 Test MSE Loss: 0.2143
Validation loss decreased (inf --> 0.340830).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5918922
	speed: 0.0710s/iter; left time: 745.5142s
Epoch: 2 cost time: 7.53186297416687
Epoch: 2, Steps: 107 Train Loss: 0.6927 (Forecasting Loss:0.3872 + XiCon Loss:3.0550 x Lambda(0.1)), Vali MSE Loss: 0.2800 Test MSE Loss: 0.1809
Validation loss decreased (0.340830 --> 0.279991).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5540748
	speed: 0.0641s/iter; left time: 666.3057s
Epoch: 3 cost time: 7.005144834518433
Epoch: 3, Steps: 107 Train Loss: 0.5660 (Forecasting Loss:0.2584 + XiCon Loss:3.0758 x Lambda(0.1)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.1626
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5617378
	speed: 0.0644s/iter; left time: 661.8427s
Epoch: 4 cost time: 7.046138525009155
Epoch: 4, Steps: 107 Train Loss: 0.5569 (Forecasting Loss:0.2483 + XiCon Loss:3.0860 x Lambda(0.1)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.1707
Validation loss decreased (0.279991 --> 0.276498).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5568813
	speed: 0.0654s/iter; left time: 665.7311s
Epoch: 5 cost time: 7.056389808654785
Epoch: 5, Steps: 107 Train Loss: 0.5535 (Forecasting Loss:0.2433 + XiCon Loss:3.1018 x Lambda(0.1)), Vali MSE Loss: 0.2822 Test MSE Loss: 0.1632
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5525044
	speed: 0.0776s/iter; left time: 780.9219s
Epoch: 6 cost time: 8.344374895095825
Epoch: 6, Steps: 107 Train Loss: 0.5504 (Forecasting Loss:0.2408 + XiCon Loss:3.0959 x Lambda(0.1)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.1629
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5496254
	speed: 0.0648s/iter; left time: 645.7815s
Epoch: 7 cost time: 7.033527374267578
Epoch: 7, Steps: 107 Train Loss: 0.5497 (Forecasting Loss:0.2397 + XiCon Loss:3.1002 x Lambda(0.1)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.1619
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5835087
	speed: 0.0677s/iter; left time: 667.4271s
Epoch: 8 cost time: 7.239795923233032
Epoch: 8, Steps: 107 Train Loss: 0.5486 (Forecasting Loss:0.2388 + XiCon Loss:3.0986 x Lambda(0.1)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.1624
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5448313
	speed: 0.0702s/iter; left time: 683.6588s
Epoch: 9 cost time: 7.544448614120483
Epoch: 9, Steps: 107 Train Loss: 0.5494 (Forecasting Loss:0.2385 + XiCon Loss:3.1093 x Lambda(0.1)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.1612
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5610766
	speed: 0.0660s/iter; left time: 636.1600s
Epoch: 10 cost time: 7.05718469619751
Epoch: 10, Steps: 107 Train Loss: 0.5497 (Forecasting Loss:0.2386 + XiCon Loss:3.1103 x Lambda(0.1)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.1612
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5466535
	speed: 0.0559s/iter; left time: 532.4574s
Epoch: 11 cost time: 5.946668863296509
Epoch: 11, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2383 + XiCon Loss:3.1114 x Lambda(0.1)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.1614
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5573438
	speed: 0.0628s/iter; left time: 591.3820s
Epoch: 12 cost time: 6.720483779907227
Epoch: 12, Steps: 107 Train Loss: 0.5489 (Forecasting Loss:0.2388 + XiCon Loss:3.1008 x Lambda(0.1)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.1615
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5485018
	speed: 0.0703s/iter; left time: 655.0732s
Epoch: 13 cost time: 7.602502822875977
Epoch: 13, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2382 + XiCon Loss:3.1124 x Lambda(0.1)), Vali MSE Loss: 0.2845 Test MSE Loss: 0.1613
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5521349
	speed: 0.0654s/iter; left time: 601.8842s
Epoch: 14 cost time: 7.128403186798096
Epoch: 14, Steps: 107 Train Loss: 0.5489 (Forecasting Loss:0.2387 + XiCon Loss:3.1024 x Lambda(0.1)), Vali MSE Loss: 0.2856 Test MSE Loss: 0.1613
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09666511416435242, mae:0.24465686082839966, mape:0.173324853181839, mspe:0.04759606719017029 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6805
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8586400
	speed: 0.0736s/iter; left time: 780.0683s
Epoch: 1 cost time: 7.912818193435669
Epoch: 1, Steps: 107 Train Loss: 0.8409 (Forecasting Loss:0.5349 + XiCon Loss:3.0609 x Lambda(0.1)), Vali MSE Loss: 0.3626 Test MSE Loss: 0.2148
Validation loss decreased (inf --> 0.362640).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5683909
	speed: 0.0845s/iter; left time: 887.2509s
Epoch: 2 cost time: 9.263903379440308
Epoch: 2, Steps: 107 Train Loss: 0.6301 (Forecasting Loss:0.3276 + XiCon Loss:3.0256 x Lambda(0.1)), Vali MSE Loss: 0.3994 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5452617
	speed: 0.0988s/iter; left time: 1026.1443s
Epoch: 3 cost time: 10.595883846282959
Epoch: 3, Steps: 107 Train Loss: 0.5550 (Forecasting Loss:0.2500 + XiCon Loss:3.0497 x Lambda(0.1)), Vali MSE Loss: 0.3020 Test MSE Loss: 0.1609
Validation loss decreased (0.362640 --> 0.301975).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5424155
	speed: 0.1057s/iter; left time: 1086.9797s
Epoch: 4 cost time: 11.30004358291626
Epoch: 4, Steps: 107 Train Loss: 0.5443 (Forecasting Loss:0.2363 + XiCon Loss:3.0791 x Lambda(0.1)), Vali MSE Loss: 0.3549 Test MSE Loss: 0.1530
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5220550
	speed: 0.1001s/iter; left time: 1017.9873s
Epoch: 5 cost time: 10.81403136253357
Epoch: 5, Steps: 107 Train Loss: 0.5414 (Forecasting Loss:0.2322 + XiCon Loss:3.0917 x Lambda(0.1)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.1605
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5706670
	speed: 0.1031s/iter; left time: 1038.2452s
Epoch: 6 cost time: 11.160074949264526
Epoch: 6, Steps: 107 Train Loss: 0.5414 (Forecasting Loss:0.2303 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.1554
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5527417
	speed: 0.1025s/iter; left time: 1021.1023s
Epoch: 7 cost time: 10.97974967956543
Epoch: 7, Steps: 107 Train Loss: 0.5402 (Forecasting Loss:0.2288 + XiCon Loss:3.1134 x Lambda(0.1)), Vali MSE Loss: 0.3395 Test MSE Loss: 0.1486
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5609236
	speed: 0.1044s/iter; left time: 1028.8367s
Epoch: 8 cost time: 11.372332334518433
Epoch: 8, Steps: 107 Train Loss: 0.5394 (Forecasting Loss:0.2281 + XiCon Loss:3.1135 x Lambda(0.1)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.1505
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5615424
	speed: 0.1068s/iter; left time: 1040.3343s
Epoch: 9 cost time: 11.521767377853394
Epoch: 9, Steps: 107 Train Loss: 0.5405 (Forecasting Loss:0.2282 + XiCon Loss:3.1231 x Lambda(0.1)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.1489
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5479082
	speed: 0.1028s/iter; left time: 991.2614s
Epoch: 10 cost time: 11.061387538909912
Epoch: 10, Steps: 107 Train Loss: 0.5398 (Forecasting Loss:0.2277 + XiCon Loss:3.1205 x Lambda(0.1)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.1493
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5347798
	speed: 0.1048s/iter; left time: 998.7670s
Epoch: 11 cost time: 11.29009222984314
Epoch: 11, Steps: 107 Train Loss: 0.5406 (Forecasting Loss:0.2278 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.3394 Test MSE Loss: 0.1486
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5437124
	speed: 0.1013s/iter; left time: 954.5643s
Epoch: 12 cost time: 10.873483419418335
Epoch: 12, Steps: 107 Train Loss: 0.5398 (Forecasting Loss:0.2278 + XiCon Loss:3.1203 x Lambda(0.1)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.1491
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5475863
	speed: 0.1077s/iter; left time: 1003.7943s
Epoch: 13 cost time: 11.584533929824829
Epoch: 13, Steps: 107 Train Loss: 0.5403 (Forecasting Loss:0.2276 + XiCon Loss:3.1262 x Lambda(0.1)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.1493
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08737144619226456, mae:0.2343403846025467, mape:0.16531941294670105, mspe:0.041659045964479446 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7466
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8079526
	speed: 0.0669s/iter; left time: 709.0623s
Epoch: 1 cost time: 7.303284406661987
Epoch: 1, Steps: 107 Train Loss: 0.8346 (Forecasting Loss:0.5258 + XiCon Loss:3.0880 x Lambda(0.1)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.1966
Validation loss decreased (inf --> 0.330963).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6168298
	speed: 0.0702s/iter; left time: 736.3100s
Epoch: 2 cost time: 7.652132749557495
Epoch: 2, Steps: 107 Train Loss: 0.7059 (Forecasting Loss:0.4066 + XiCon Loss:2.9930 x Lambda(0.1)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.1529
Validation loss decreased (0.330963 --> 0.248943).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5723605
	speed: 0.0628s/iter; left time: 652.4597s
Epoch: 3 cost time: 6.832046031951904
Epoch: 3, Steps: 107 Train Loss: 0.5825 (Forecasting Loss:0.2878 + XiCon Loss:2.9471 x Lambda(0.1)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1385
Validation loss decreased (0.248943 --> 0.240051).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5521524
	speed: 0.0670s/iter; left time: 688.2842s
Epoch: 4 cost time: 7.253799200057983
Epoch: 4, Steps: 107 Train Loss: 0.5552 (Forecasting Loss:0.2633 + XiCon Loss:2.9185 x Lambda(0.1)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1370
Validation loss decreased (0.240051 --> 0.232883).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5313676
	speed: 0.0668s/iter; left time: 679.3340s
Epoch: 5 cost time: 7.208800792694092
Epoch: 5, Steps: 107 Train Loss: 0.5433 (Forecasting Loss:0.2530 + XiCon Loss:2.9024 x Lambda(0.1)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1436
Validation loss decreased (0.232883 --> 0.222669).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5449937
	speed: 0.0730s/iter; left time: 734.4965s
Epoch: 6 cost time: 7.933573246002197
Epoch: 6, Steps: 107 Train Loss: 0.5368 (Forecasting Loss:0.2476 + XiCon Loss:2.8922 x Lambda(0.1)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1418
Validation loss decreased (0.222669 --> 0.220630).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5357583
	speed: 0.0721s/iter; left time: 718.3415s
Epoch: 7 cost time: 7.71807336807251
Epoch: 7, Steps: 107 Train Loss: 0.5340 (Forecasting Loss:0.2455 + XiCon Loss:2.8852 x Lambda(0.1)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1395
Validation loss decreased (0.220630 --> 0.218546).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5201938
	speed: 0.0566s/iter; left time: 557.7004s
Epoch: 8 cost time: 6.145631313323975
Epoch: 8, Steps: 107 Train Loss: 0.5323 (Forecasting Loss:0.2439 + XiCon Loss:2.8843 x Lambda(0.1)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5250744
	speed: 0.0632s/iter; left time: 616.0757s
Epoch: 9 cost time: 6.8458521366119385
Epoch: 9, Steps: 107 Train Loss: 0.5316 (Forecasting Loss:0.2435 + XiCon Loss:2.8804 x Lambda(0.1)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1386
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5358166
	speed: 0.0704s/iter; left time: 678.3649s
Epoch: 10 cost time: 7.655460834503174
Epoch: 10, Steps: 107 Train Loss: 0.5316 (Forecasting Loss:0.2434 + XiCon Loss:2.8819 x Lambda(0.1)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1399
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5494008
	speed: 0.0669s/iter; left time: 637.5765s
Epoch: 11 cost time: 7.262949466705322
Epoch: 11, Steps: 107 Train Loss: 0.5314 (Forecasting Loss:0.2433 + XiCon Loss:2.8804 x Lambda(0.1)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1400
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5277433
	speed: 0.0722s/iter; left time: 680.6529s
Epoch: 12 cost time: 7.797609806060791
Epoch: 12, Steps: 107 Train Loss: 0.5313 (Forecasting Loss:0.2432 + XiCon Loss:2.8806 x Lambda(0.1)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1403
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5310304
	speed: 0.0715s/iter; left time: 666.2592s
Epoch: 13 cost time: 7.6535186767578125
Epoch: 13, Steps: 107 Train Loss: 0.5311 (Forecasting Loss:0.2431 + XiCon Loss:2.8806 x Lambda(0.1)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1404
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5329977
	speed: 0.0678s/iter; left time: 624.1569s
Epoch: 14 cost time: 7.318427085876465
Epoch: 14, Steps: 107 Train Loss: 0.5312 (Forecasting Loss:0.2430 + XiCon Loss:2.8823 x Lambda(0.1)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1404
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5365300
	speed: 0.0731s/iter; left time: 665.7307s
Epoch: 15 cost time: 7.870771646499634
Epoch: 15, Steps: 107 Train Loss: 0.5316 (Forecasting Loss:0.2433 + XiCon Loss:2.8830 x Lambda(0.1)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1404
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5271242
	speed: 0.0724s/iter; left time: 651.3400s
Epoch: 16 cost time: 7.754557847976685
Epoch: 16, Steps: 107 Train Loss: 0.5310 (Forecasting Loss:0.2432 + XiCon Loss:2.8787 x Lambda(0.1)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1403
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5295641
	speed: 0.0681s/iter; left time: 605.1358s
Epoch: 17 cost time: 7.343970775604248
Epoch: 17, Steps: 107 Train Loss: 0.5315 (Forecasting Loss:0.2434 + XiCon Loss:2.8810 x Lambda(0.1)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1403
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07080648839473724, mae:0.2082631140947342, mape:0.1486719697713852, mspe:0.03583857789635658 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0818+-0.01447, MAE:0.2253+-0.01995, MAPE:0.1616+-0.01232, MSPE:0.0422+-0.00580, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6596
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.60448956489563
Epoch: 1, Steps: 96 Train Loss: 1.0526 (Forecasting Loss:0.7437 + XiCon Loss:3.0893 x Lambda(0.1)), Vali MSE Loss: 0.4371 Test MSE Loss: 0.2931
Validation loss decreased (inf --> 0.437119).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.686445713043213
Epoch: 2, Steps: 96 Train Loss: 0.8544 (Forecasting Loss:0.5500 + XiCon Loss:3.0437 x Lambda(0.1)), Vali MSE Loss: 0.2686 Test MSE Loss: 0.1713
Validation loss decreased (0.437119 --> 0.268646).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.540741920471191
Epoch: 3, Steps: 96 Train Loss: 0.5962 (Forecasting Loss:0.2960 + XiCon Loss:3.0020 x Lambda(0.1)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.1545
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.668428421020508
Epoch: 4, Steps: 96 Train Loss: 0.5561 (Forecasting Loss:0.2585 + XiCon Loss:2.9757 x Lambda(0.1)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.1669
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.43326735496521
Epoch: 5, Steps: 96 Train Loss: 0.5475 (Forecasting Loss:0.2501 + XiCon Loss:2.9739 x Lambda(0.1)), Vali MSE Loss: 0.2971 Test MSE Loss: 0.1654
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 14.102858781814575
Epoch: 6, Steps: 96 Train Loss: 0.5449 (Forecasting Loss:0.2465 + XiCon Loss:2.9843 x Lambda(0.1)), Vali MSE Loss: 0.3010 Test MSE Loss: 0.1632
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.1877601146698
Epoch: 7, Steps: 96 Train Loss: 0.5440 (Forecasting Loss:0.2447 + XiCon Loss:2.9930 x Lambda(0.1)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.1669
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.886686325073242
Epoch: 8, Steps: 96 Train Loss: 0.5429 (Forecasting Loss:0.2437 + XiCon Loss:2.9922 x Lambda(0.1)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.1627
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.213673830032349
Epoch: 9, Steps: 96 Train Loss: 0.5433 (Forecasting Loss:0.2436 + XiCon Loss:2.9967 x Lambda(0.1)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.1664
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.658053636550903
Epoch: 10, Steps: 96 Train Loss: 0.5421 (Forecasting Loss:0.2432 + XiCon Loss:2.9890 x Lambda(0.1)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.1662
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 14.188915967941284
Epoch: 11, Steps: 96 Train Loss: 0.5431 (Forecasting Loss:0.2430 + XiCon Loss:3.0004 x Lambda(0.1)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.1654
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 14.065370082855225
Epoch: 12, Steps: 96 Train Loss: 0.5420 (Forecasting Loss:0.2429 + XiCon Loss:2.9918 x Lambda(0.1)), Vali MSE Loss: 0.2971 Test MSE Loss: 0.1659
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09655539691448212, mae:0.24597987532615662, mape:0.1739051342010498, mspe:0.04557659476995468 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6845
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.776362657546997
Epoch: 1, Steps: 96 Train Loss: 1.0299 (Forecasting Loss:0.7214 + XiCon Loss:3.0844 x Lambda(0.1)), Vali MSE Loss: 0.4322 Test MSE Loss: 0.2618
Validation loss decreased (inf --> 0.432190).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.606886863708496
Epoch: 2, Steps: 96 Train Loss: 0.7743 (Forecasting Loss:0.4718 + XiCon Loss:3.0250 x Lambda(0.1)), Vali MSE Loss: 0.3102 Test MSE Loss: 0.1485
Validation loss decreased (0.432190 --> 0.310236).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 14.234195232391357
Epoch: 3, Steps: 96 Train Loss: 0.5811 (Forecasting Loss:0.2812 + XiCon Loss:2.9981 x Lambda(0.1)), Vali MSE Loss: 0.2863 Test MSE Loss: 0.1441
Validation loss decreased (0.310236 --> 0.286285).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.502085208892822
Epoch: 4, Steps: 96 Train Loss: 0.5599 (Forecasting Loss:0.2598 + XiCon Loss:3.0009 x Lambda(0.1)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1435
Validation loss decreased (0.286285 --> 0.271612).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.204376459121704
Epoch: 5, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2521 + XiCon Loss:3.0165 x Lambda(0.1)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.1442
Validation loss decreased (0.271612 --> 0.266665).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 12.586023092269897
Epoch: 6, Steps: 96 Train Loss: 0.5512 (Forecasting Loss:0.2488 + XiCon Loss:3.0237 x Lambda(0.1)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.613080978393555
Epoch: 7, Steps: 96 Train Loss: 0.5493 (Forecasting Loss:0.2472 + XiCon Loss:3.0216 x Lambda(0.1)), Vali MSE Loss: 0.2645 Test MSE Loss: 0.1410
Validation loss decreased (0.266665 --> 0.264500).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.435353994369507
Epoch: 8, Steps: 96 Train Loss: 0.5490 (Forecasting Loss:0.2458 + XiCon Loss:3.0313 x Lambda(0.1)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.1411
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.034841775894165
Epoch: 9, Steps: 96 Train Loss: 0.5485 (Forecasting Loss:0.2459 + XiCon Loss:3.0258 x Lambda(0.1)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.1430
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.875375509262085
Epoch: 10, Steps: 96 Train Loss: 0.5486 (Forecasting Loss:0.2457 + XiCon Loss:3.0285 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.1417
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.59995174407959
Epoch: 11, Steps: 96 Train Loss: 0.5489 (Forecasting Loss:0.2457 + XiCon Loss:3.0327 x Lambda(0.1)), Vali MSE Loss: 0.2652 Test MSE Loss: 0.1420
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 14.471218585968018
Epoch: 12, Steps: 96 Train Loss: 0.5485 (Forecasting Loss:0.2453 + XiCon Loss:3.0321 x Lambda(0.1)), Vali MSE Loss: 0.2652 Test MSE Loss: 0.1420
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.679977178573608
Epoch: 13, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2454 + XiCon Loss:3.0265 x Lambda(0.1)), Vali MSE Loss: 0.2645 Test MSE Loss: 0.1419
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 13.569996118545532
Epoch: 14, Steps: 96 Train Loss: 0.5477 (Forecasting Loss:0.2451 + XiCon Loss:3.0268 x Lambda(0.1)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.1419
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 13.853179693222046
Epoch: 15, Steps: 96 Train Loss: 0.5487 (Forecasting Loss:0.2452 + XiCon Loss:3.0347 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1420
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 13.30761981010437
Epoch: 16, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2449 + XiCon Loss:3.0312 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1420
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 13.380859136581421
Epoch: 17, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2449 + XiCon Loss:3.0341 x Lambda(0.1)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.1420
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.071782186627388, mae:0.21019548177719116, mape:0.15459954738616943, mspe:0.040504150092601776 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5752
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.45167589187622
Epoch: 1, Steps: 96 Train Loss: 1.0281 (Forecasting Loss:0.7198 + XiCon Loss:3.0837 x Lambda(0.1)), Vali MSE Loss: 0.4130 Test MSE Loss: 0.2474
Validation loss decreased (inf --> 0.413013).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.88219404220581
Epoch: 2, Steps: 96 Train Loss: 0.7846 (Forecasting Loss:0.4808 + XiCon Loss:3.0379 x Lambda(0.1)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.1656
Validation loss decreased (0.413013 --> 0.346587).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.309093952178955
Epoch: 3, Steps: 96 Train Loss: 0.6174 (Forecasting Loss:0.3167 + XiCon Loss:3.0071 x Lambda(0.1)), Vali MSE Loss: 0.2569 Test MSE Loss: 0.1376
Validation loss decreased (0.346587 --> 0.256911).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.333073616027832
Epoch: 4, Steps: 96 Train Loss: 0.5799 (Forecasting Loss:0.2819 + XiCon Loss:2.9809 x Lambda(0.1)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1399
Validation loss decreased (0.256911 --> 0.250309).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.129092454910278
Epoch: 5, Steps: 96 Train Loss: 0.5657 (Forecasting Loss:0.2680 + XiCon Loss:2.9775 x Lambda(0.1)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1419
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.94778561592102
Epoch: 6, Steps: 96 Train Loss: 0.5590 (Forecasting Loss:0.2610 + XiCon Loss:2.9806 x Lambda(0.1)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.1397
Validation loss decreased (0.250309 --> 0.246633).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.507983684539795
Epoch: 7, Steps: 96 Train Loss: 0.5566 (Forecasting Loss:0.2576 + XiCon Loss:2.9907 x Lambda(0.1)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1395
Validation loss decreased (0.246633 --> 0.246216).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.602503061294556
Epoch: 8, Steps: 96 Train Loss: 0.5560 (Forecasting Loss:0.2567 + XiCon Loss:2.9928 x Lambda(0.1)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1420
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.796701192855835
Epoch: 9, Steps: 96 Train Loss: 0.5556 (Forecasting Loss:0.2559 + XiCon Loss:2.9974 x Lambda(0.1)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1403
Validation loss decreased (0.246216 --> 0.245244).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.349303007125854
Epoch: 10, Steps: 96 Train Loss: 0.5546 (Forecasting Loss:0.2550 + XiCon Loss:2.9953 x Lambda(0.1)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1410
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.30379033088684
Epoch: 11, Steps: 96 Train Loss: 0.5549 (Forecasting Loss:0.2553 + XiCon Loss:2.9960 x Lambda(0.1)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1408
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 12.713354587554932
Epoch: 12, Steps: 96 Train Loss: 0.5549 (Forecasting Loss:0.2553 + XiCon Loss:2.9953 x Lambda(0.1)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1411
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.693294286727905
Epoch: 13, Steps: 96 Train Loss: 0.5540 (Forecasting Loss:0.2544 + XiCon Loss:2.9966 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 14.210856199264526
Epoch: 14, Steps: 96 Train Loss: 0.5541 (Forecasting Loss:0.2544 + XiCon Loss:2.9971 x Lambda(0.1)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1409
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 13.757837295532227
Epoch: 15, Steps: 96 Train Loss: 0.5545 (Forecasting Loss:0.2549 + XiCon Loss:2.9962 x Lambda(0.1)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1410
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 13.85989260673523
Epoch: 16, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2547 + XiCon Loss:2.9951 x Lambda(0.1)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1410
Validation loss decreased (0.245244 --> 0.245233).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 13.295673847198486
Epoch: 17, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2543 + XiCon Loss:2.9957 x Lambda(0.1)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1410
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 14.053428411483765
Epoch: 18, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2543 + XiCon Loss:2.9959 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 14.162964582443237
Epoch: 19, Steps: 96 Train Loss: 0.5543 (Forecasting Loss:0.2546 + XiCon Loss:2.9968 x Lambda(0.1)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1410
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 13.410100936889648
Epoch: 20, Steps: 96 Train Loss: 0.5546 (Forecasting Loss:0.2548 + XiCon Loss:2.9973 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 13.96925663948059
Epoch: 21, Steps: 96 Train Loss: 0.5544 (Forecasting Loss:0.2550 + XiCon Loss:2.9941 x Lambda(0.1)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1410
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 14.214910507202148
Epoch: 22, Steps: 96 Train Loss: 0.5549 (Forecasting Loss:0.2553 + XiCon Loss:2.9968 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 13.331642150878906
Epoch: 23, Steps: 96 Train Loss: 0.5546 (Forecasting Loss:0.2547 + XiCon Loss:2.9986 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 14.255874872207642
Epoch: 24, Steps: 96 Train Loss: 0.5540 (Forecasting Loss:0.2547 + XiCon Loss:2.9933 x Lambda(0.1)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1410
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 13.697453022003174
Epoch: 25, Steps: 96 Train Loss: 0.5535 (Forecasting Loss:0.2542 + XiCon Loss:2.9933 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 13.844619035720825
Epoch: 26, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2548 + XiCon Loss:2.9939 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1410
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07211152464151382, mae:0.20995260775089264, mape:0.15164558589458466, mspe:0.03760652244091034 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8642
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.763620853424072
Epoch: 1, Steps: 96 Train Loss: 1.0770 (Forecasting Loss:0.7684 + XiCon Loss:3.0863 x Lambda(0.1)), Vali MSE Loss: 0.5526 Test MSE Loss: 0.3521
Validation loss decreased (inf --> 0.552605).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 21.20696520805359
Epoch: 2, Steps: 96 Train Loss: 0.6560 (Forecasting Loss:0.3559 + XiCon Loss:3.0017 x Lambda(0.1)), Vali MSE Loss: 0.2774 Test MSE Loss: 0.1632
Validation loss decreased (0.552605 --> 0.277405).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 21.29693341255188
Epoch: 3, Steps: 96 Train Loss: 0.5454 (Forecasting Loss:0.2489 + XiCon Loss:2.9654 x Lambda(0.1)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.1604
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 21.767256498336792
Epoch: 4, Steps: 96 Train Loss: 0.5391 (Forecasting Loss:0.2394 + XiCon Loss:2.9964 x Lambda(0.1)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.1632
Validation loss decreased (0.277405 --> 0.267088).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 22.456217765808105
Epoch: 5, Steps: 96 Train Loss: 0.5348 (Forecasting Loss:0.2342 + XiCon Loss:3.0061 x Lambda(0.1)), Vali MSE Loss: 0.2770 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 21.90744137763977
Epoch: 6, Steps: 96 Train Loss: 0.5326 (Forecasting Loss:0.2315 + XiCon Loss:3.0111 x Lambda(0.1)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.1626
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 21.995784044265747
Epoch: 7, Steps: 96 Train Loss: 0.5318 (Forecasting Loss:0.2307 + XiCon Loss:3.0108 x Lambda(0.1)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.1598
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 21.637726068496704
Epoch: 8, Steps: 96 Train Loss: 0.5317 (Forecasting Loss:0.2303 + XiCon Loss:3.0145 x Lambda(0.1)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1623
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 21.955833673477173
Epoch: 9, Steps: 96 Train Loss: 0.5312 (Forecasting Loss:0.2297 + XiCon Loss:3.0144 x Lambda(0.1)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.1612
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 21.89176368713379
Epoch: 10, Steps: 96 Train Loss: 0.5308 (Forecasting Loss:0.2299 + XiCon Loss:3.0083 x Lambda(0.1)), Vali MSE Loss: 0.2737 Test MSE Loss: 0.1609
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 21.672908782958984
Epoch: 11, Steps: 96 Train Loss: 0.5312 (Forecasting Loss:0.2295 + XiCon Loss:3.0168 x Lambda(0.1)), Vali MSE Loss: 0.2733 Test MSE Loss: 0.1605
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 22.133748531341553
Epoch: 12, Steps: 96 Train Loss: 0.5308 (Forecasting Loss:0.2295 + XiCon Loss:3.0130 x Lambda(0.1)), Vali MSE Loss: 0.2752 Test MSE Loss: 0.1611
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 22.245386123657227
Epoch: 13, Steps: 96 Train Loss: 0.5310 (Forecasting Loss:0.2296 + XiCon Loss:3.0145 x Lambda(0.1)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.1608
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 22.033732175827026
Epoch: 14, Steps: 96 Train Loss: 0.5309 (Forecasting Loss:0.2295 + XiCon Loss:3.0146 x Lambda(0.1)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.1608
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09041003882884979, mae:0.2359253168106079, mape:0.17521078884601593, mspe:0.05557229742407799 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8529
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.772735357284546
Epoch: 1, Steps: 96 Train Loss: 1.0686 (Forecasting Loss:0.7599 + XiCon Loss:3.0869 x Lambda(0.1)), Vali MSE Loss: 0.5336 Test MSE Loss: 0.3389
Validation loss decreased (inf --> 0.533567).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 19.30295968055725
Epoch: 2, Steps: 96 Train Loss: 0.7170 (Forecasting Loss:0.4143 + XiCon Loss:3.0278 x Lambda(0.1)), Vali MSE Loss: 0.4689 Test MSE Loss: 0.2045
Validation loss decreased (0.533567 --> 0.468939).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 21.128124475479126
Epoch: 3, Steps: 96 Train Loss: 0.5628 (Forecasting Loss:0.2613 + XiCon Loss:3.0142 x Lambda(0.1)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.1789
Validation loss decreased (0.468939 --> 0.311247).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 20.972633600234985
Epoch: 4, Steps: 96 Train Loss: 0.5525 (Forecasting Loss:0.2482 + XiCon Loss:3.0427 x Lambda(0.1)), Vali MSE Loss: 0.2681 Test MSE Loss: 0.1694
Validation loss decreased (0.311247 --> 0.268084).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 20.500262022018433
Epoch: 5, Steps: 96 Train Loss: 0.5500 (Forecasting Loss:0.2432 + XiCon Loss:3.0683 x Lambda(0.1)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.1650
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 20.766249895095825
Epoch: 6, Steps: 96 Train Loss: 0.5495 (Forecasting Loss:0.2404 + XiCon Loss:3.0911 x Lambda(0.1)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.1727
Validation loss decreased (0.268084 --> 0.267704).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 20.626854419708252
Epoch: 7, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2385 + XiCon Loss:3.0947 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1697
Validation loss decreased (0.267704 --> 0.264037).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 20.667099237442017
Epoch: 8, Steps: 96 Train Loss: 0.5479 (Forecasting Loss:0.2379 + XiCon Loss:3.1001 x Lambda(0.1)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.1716
Validation loss decreased (0.264037 --> 0.262382).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 21.072881937026978
Epoch: 9, Steps: 96 Train Loss: 0.5482 (Forecasting Loss:0.2378 + XiCon Loss:3.1038 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1709
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 20.744001150131226
Epoch: 10, Steps: 96 Train Loss: 0.5476 (Forecasting Loss:0.2370 + XiCon Loss:3.1060 x Lambda(0.1)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1718
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 20.874553203582764
Epoch: 11, Steps: 96 Train Loss: 0.5485 (Forecasting Loss:0.2373 + XiCon Loss:3.1116 x Lambda(0.1)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1705
Validation loss decreased (0.262382 --> 0.262347).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 20.87067174911499
Epoch: 12, Steps: 96 Train Loss: 0.5482 (Forecasting Loss:0.2370 + XiCon Loss:3.1114 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1702
Validation loss decreased (0.262347 --> 0.261633).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 20.795788526535034
Epoch: 13, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2371 + XiCon Loss:3.1092 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 21.484751224517822
Epoch: 14, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2372 + XiCon Loss:3.1092 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 21.14327836036682
Epoch: 15, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2367 + XiCon Loss:3.1110 x Lambda(0.1)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.1701
Validation loss decreased (0.261633 --> 0.261503).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 20.77735710144043
Epoch: 16, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2372 + XiCon Loss:3.1082 x Lambda(0.1)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1701
Validation loss decreased (0.261503 --> 0.261441).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 21.346078395843506
Epoch: 17, Steps: 96 Train Loss: 0.5486 (Forecasting Loss:0.2371 + XiCon Loss:3.1151 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.1701
Validation loss decreased (0.261441 --> 0.261302).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 20.99899411201477
Epoch: 18, Steps: 96 Train Loss: 0.5479 (Forecasting Loss:0.2373 + XiCon Loss:3.1059 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 20.586448431015015
Epoch: 19, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2368 + XiCon Loss:3.1103 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 20.70682954788208
Epoch: 20, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2372 + XiCon Loss:3.1083 x Lambda(0.1)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1701
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 21.577873468399048
Epoch: 21, Steps: 96 Train Loss: 0.5486 (Forecasting Loss:0.2372 + XiCon Loss:3.1143 x Lambda(0.1)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 20.79087734222412
Epoch: 22, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2372 + XiCon Loss:3.1079 x Lambda(0.1)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 20.99369239807129
Epoch: 23, Steps: 96 Train Loss: 0.5479 (Forecasting Loss:0.2373 + XiCon Loss:3.1056 x Lambda(0.1)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 20.686450242996216
Epoch: 24, Steps: 96 Train Loss: 0.5486 (Forecasting Loss:0.2371 + XiCon Loss:3.1146 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1701
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 21.10681939125061
Epoch: 25, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2374 + XiCon Loss:3.1040 x Lambda(0.1)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1701
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 20.521737813949585
Epoch: 26, Steps: 96 Train Loss: 0.5480 (Forecasting Loss:0.2372 + XiCon Loss:3.1076 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1701
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 20.74243950843811
Epoch: 27, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2369 + XiCon Loss:3.1097 x Lambda(0.1)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09655474126338959, mae:0.24362210929393768, mape:0.17977453768253326, mspe:0.05895991995930672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0855+-0.01566, MAE:0.2291+-0.02209, MAPE:0.1670+-0.01604, MSPE:0.0476+-0.01156, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7024
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.1132374
	speed: 0.0307s/iter; left time: 389.3810s
Epoch: 1 cost time: 3.7806880474090576
Epoch: 1, Steps: 128 Train Loss: 30.4537 (Forecasting Loss:0.2931 + XiCon Loss:3.0161 x Lambda(10.0)), Vali MSE Loss: 0.2772 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.277220).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4560337
	speed: 0.0250s/iter; left time: 314.8308s
Epoch: 2 cost time: 3.1770083904266357
Epoch: 2, Steps: 128 Train Loss: 28.7215 (Forecasting Loss:0.2574 + XiCon Loss:2.8464 x Lambda(10.0)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.2209
Validation loss decreased (0.277220 --> 0.258701).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3761139
	speed: 0.0276s/iter; left time: 343.6253s
Epoch: 3 cost time: 3.336940288543701
Epoch: 3, Steps: 128 Train Loss: 28.3000 (Forecasting Loss:0.2435 + XiCon Loss:2.8056 x Lambda(10.0)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.2202
Validation loss decreased (0.258701 --> 0.252452).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.7043533
	speed: 0.0293s/iter; left time: 361.2857s
Epoch: 4 cost time: 3.5291075706481934
Epoch: 4, Steps: 128 Train Loss: 28.9604 (Forecasting Loss:0.2377 + XiCon Loss:2.8723 x Lambda(10.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.2048
Validation loss decreased (0.252452 --> 0.252207).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.7261066
	speed: 0.0313s/iter; left time: 382.0331s
Epoch: 5 cost time: 3.9896929264068604
Epoch: 5, Steps: 128 Train Loss: 29.3512 (Forecasting Loss:0.2347 + XiCon Loss:2.9117 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2073
Validation loss decreased (0.252207 --> 0.250078).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.5776005
	speed: 0.0257s/iter; left time: 309.6439s
Epoch: 6 cost time: 3.433873414993286
Epoch: 6, Steps: 128 Train Loss: 29.4666 (Forecasting Loss:0.2330 + XiCon Loss:2.9234 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2057
Validation loss decreased (0.250078 --> 0.248950).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.6684418
	speed: 0.0295s/iter; left time: 352.6201s
Epoch: 7 cost time: 3.951178550720215
Epoch: 7, Steps: 128 Train Loss: 29.5939 (Forecasting Loss:0.2318 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2063
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2062588
	speed: 0.0297s/iter; left time: 351.0341s
Epoch: 8 cost time: 3.71032977104187
Epoch: 8, Steps: 128 Train Loss: 29.6972 (Forecasting Loss:0.2315 + XiCon Loss:2.9466 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2057
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8549709
	speed: 0.0341s/iter; left time: 397.7267s
Epoch: 9 cost time: 4.178043842315674
Epoch: 9, Steps: 128 Train Loss: 29.6910 (Forecasting Loss:0.2315 + XiCon Loss:2.9459 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2050
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5870514
	speed: 0.0337s/iter; left time: 388.8590s
Epoch: 10 cost time: 4.1749913692474365
Epoch: 10, Steps: 128 Train Loss: 29.8016 (Forecasting Loss:0.2313 + XiCon Loss:2.9570 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2052
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.1817741
	speed: 0.0344s/iter; left time: 393.2917s
Epoch: 11 cost time: 4.126562595367432
Epoch: 11, Steps: 128 Train Loss: 29.6265 (Forecasting Loss:0.2312 + XiCon Loss:2.9395 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2052
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.8317719
	speed: 0.0263s/iter; left time: 296.9605s
Epoch: 12 cost time: 3.6232821941375732
Epoch: 12, Steps: 128 Train Loss: 29.7788 (Forecasting Loss:0.2312 + XiCon Loss:2.9548 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2051
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3918705
	speed: 0.0248s/iter; left time: 276.8379s
Epoch: 13 cost time: 3.1982743740081787
Epoch: 13, Steps: 128 Train Loss: 29.8164 (Forecasting Loss:0.2312 + XiCon Loss:2.9585 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2052
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1022701
	speed: 0.0244s/iter; left time: 268.8565s
Epoch: 14 cost time: 3.0702648162841797
Epoch: 14, Steps: 128 Train Loss: 29.8085 (Forecasting Loss:0.2309 + XiCon Loss:2.9578 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2051
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.7617321
	speed: 0.0342s/iter; left time: 373.4831s
Epoch: 15 cost time: 4.4593505859375
Epoch: 15, Steps: 128 Train Loss: 29.7005 (Forecasting Loss:0.2309 + XiCon Loss:2.9470 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2052
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8565731
	speed: 0.0299s/iter; left time: 322.1450s
Epoch: 16 cost time: 3.847264289855957
Epoch: 16, Steps: 128 Train Loss: 29.7152 (Forecasting Loss:0.2311 + XiCon Loss:2.9484 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2052
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1314738392829895, mae:0.2798691391944885, mape:0.6594917178153992, mspe:19.54165267944336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8590
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.1353760
	speed: 0.0315s/iter; left time: 400.0651s
Epoch: 1 cost time: 3.9261491298675537
Epoch: 1, Steps: 128 Train Loss: 30.3133 (Forecasting Loss:0.2941 + XiCon Loss:3.0019 x Lambda(10.0)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.2318
Validation loss decreased (inf --> 0.274452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6534595
	speed: 0.0285s/iter; left time: 358.7955s
Epoch: 2 cost time: 3.5181941986083984
Epoch: 2, Steps: 128 Train Loss: 29.2202 (Forecasting Loss:0.2579 + XiCon Loss:2.8962 x Lambda(10.0)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.2174
Validation loss decreased (0.274452 --> 0.264964).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8644981
	speed: 0.0277s/iter; left time: 344.8867s
Epoch: 3 cost time: 3.558284282684326
Epoch: 3, Steps: 128 Train Loss: 30.6696 (Forecasting Loss:0.2425 + XiCon Loss:3.0427 x Lambda(10.0)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.2090
Validation loss decreased (0.264964 --> 0.256361).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.4977074
	speed: 0.0257s/iter; left time: 317.0871s
Epoch: 4 cost time: 3.2866427898406982
Epoch: 4, Steps: 128 Train Loss: 31.4444 (Forecasting Loss:0.2377 + XiCon Loss:3.1207 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2079
Validation loss decreased (0.256361 --> 0.249610).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.7309151
	speed: 0.0257s/iter; left time: 313.4392s
Epoch: 5 cost time: 3.3273983001708984
Epoch: 5, Steps: 128 Train Loss: 31.6241 (Forecasting Loss:0.2346 + XiCon Loss:3.1389 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2100
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.3087006
	speed: 0.0301s/iter; left time: 363.1980s
Epoch: 6 cost time: 3.7497904300689697
Epoch: 6, Steps: 128 Train Loss: 31.5968 (Forecasting Loss:0.2330 + XiCon Loss:3.1364 x Lambda(10.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2065
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.0733337
	speed: 0.0348s/iter; left time: 415.1116s
Epoch: 7 cost time: 4.052686452865601
Epoch: 7, Steps: 128 Train Loss: 31.6030 (Forecasting Loss:0.2322 + XiCon Loss:3.1371 x Lambda(10.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1853809
	speed: 0.0278s/iter; left time: 328.3467s
Epoch: 8 cost time: 3.2825324535369873
Epoch: 8, Steps: 128 Train Loss: 31.6472 (Forecasting Loss:0.2317 + XiCon Loss:3.1415 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.6501808
	speed: 0.0231s/iter; left time: 270.2717s
Epoch: 9 cost time: 3.1573140621185303
Epoch: 9, Steps: 128 Train Loss: 31.8409 (Forecasting Loss:0.2314 + XiCon Loss:3.1610 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2058
Validation loss decreased (0.249610 --> 0.249283).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.4384499
	speed: 0.0270s/iter; left time: 311.4871s
Epoch: 10 cost time: 3.2296454906463623
Epoch: 10, Steps: 128 Train Loss: 31.7469 (Forecasting Loss:0.2314 + XiCon Loss:3.1516 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2841358
	speed: 0.0278s/iter; left time: 316.9736s
Epoch: 11 cost time: 3.5266306400299072
Epoch: 11, Steps: 128 Train Loss: 31.7015 (Forecasting Loss:0.2313 + XiCon Loss:3.1470 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2057
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.4284515
	speed: 0.0371s/iter; left time: 419.1059s
Epoch: 12 cost time: 4.438207626342773
Epoch: 12, Steps: 128 Train Loss: 31.6542 (Forecasting Loss:0.2313 + XiCon Loss:3.1423 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.3599586
	speed: 0.0367s/iter; left time: 409.5147s
Epoch: 13 cost time: 4.638015270233154
Epoch: 13, Steps: 128 Train Loss: 31.7050 (Forecasting Loss:0.2313 + XiCon Loss:3.1474 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2057
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.9945717
	speed: 0.0308s/iter; left time: 339.5857s
Epoch: 14 cost time: 3.9585251808166504
Epoch: 14, Steps: 128 Train Loss: 31.7391 (Forecasting Loss:0.2312 + XiCon Loss:3.1508 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.7897587
	speed: 0.0273s/iter; left time: 297.6326s
Epoch: 15 cost time: 3.820193290710449
Epoch: 15, Steps: 128 Train Loss: 31.6580 (Forecasting Loss:0.2312 + XiCon Loss:3.1427 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.6513805
	speed: 0.0284s/iter; left time: 306.2082s
Epoch: 16 cost time: 3.7552413940429688
Epoch: 16, Steps: 128 Train Loss: 31.6318 (Forecasting Loss:0.2312 + XiCon Loss:3.1401 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.9224434
	speed: 0.0285s/iter; left time: 303.5189s
Epoch: 17 cost time: 3.631601095199585
Epoch: 17, Steps: 128 Train Loss: 31.6519 (Forecasting Loss:0.2312 + XiCon Loss:3.1421 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.7665520
	speed: 0.0266s/iter; left time: 279.6625s
Epoch: 18 cost time: 3.382476329803467
Epoch: 18, Steps: 128 Train Loss: 31.6918 (Forecasting Loss:0.2312 + XiCon Loss:3.1461 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.1966515
	speed: 0.0284s/iter; left time: 295.2503s
Epoch: 19 cost time: 3.3980579376220703
Epoch: 19, Steps: 128 Train Loss: 31.6572 (Forecasting Loss:0.2313 + XiCon Loss:3.1426 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2057
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13143275678157806, mae:0.28021174669265747, mape:0.6588196158409119, mspe:19.354597091674805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7804
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.5092297
	speed: 0.0267s/iter; left time: 339.3765s
Epoch: 1 cost time: 3.2705719470977783
Epoch: 1, Steps: 128 Train Loss: 30.6103 (Forecasting Loss:0.2883 + XiCon Loss:3.0322 x Lambda(10.0)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2264
Validation loss decreased (inf --> 0.272459).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.2175236
	speed: 0.0292s/iter; left time: 366.9720s
Epoch: 2 cost time: 3.648958683013916
Epoch: 2, Steps: 128 Train Loss: 28.8495 (Forecasting Loss:0.2588 + XiCon Loss:2.8591 x Lambda(10.0)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.2175
Validation loss decreased (0.272459 --> 0.262741).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.2055111
	speed: 0.0354s/iter; left time: 440.5524s
Epoch: 3 cost time: 4.609972953796387
Epoch: 3, Steps: 128 Train Loss: 28.9324 (Forecasting Loss:0.2431 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.2108
Validation loss decreased (0.262741 --> 0.253546).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.0265980
	speed: 0.0342s/iter; left time: 420.9951s
Epoch: 4 cost time: 4.123817682266235
Epoch: 4, Steps: 128 Train Loss: 30.2972 (Forecasting Loss:0.2376 + XiCon Loss:3.0060 x Lambda(10.0)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.2080
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.6033821
	speed: 0.0291s/iter; left time: 355.3008s
Epoch: 5 cost time: 3.7010550498962402
Epoch: 5, Steps: 128 Train Loss: 30.0996 (Forecasting Loss:0.2349 + XiCon Loss:2.9865 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2034
Validation loss decreased (0.253546 --> 0.252672).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2415390
	speed: 0.0259s/iter; left time: 311.9743s
Epoch: 6 cost time: 3.2947888374328613
Epoch: 6, Steps: 128 Train Loss: 29.9055 (Forecasting Loss:0.2328 + XiCon Loss:2.9673 x Lambda(10.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2051
Validation loss decreased (0.252672 --> 0.251952).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1653461
	speed: 0.0270s/iter; left time: 321.8521s
Epoch: 7 cost time: 3.283510446548462
Epoch: 7, Steps: 128 Train Loss: 29.7428 (Forecasting Loss:0.2324 + XiCon Loss:2.9510 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2074
Validation loss decreased (0.251952 --> 0.250378).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9355659
	speed: 0.0288s/iter; left time: 340.5671s
Epoch: 8 cost time: 3.4937191009521484
Epoch: 8, Steps: 128 Train Loss: 29.8062 (Forecasting Loss:0.2319 + XiCon Loss:2.9574 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2064
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.7587547
	speed: 0.0286s/iter; left time: 334.4594s
Epoch: 9 cost time: 3.7136452198028564
Epoch: 9, Steps: 128 Train Loss: 29.6452 (Forecasting Loss:0.2316 + XiCon Loss:2.9414 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2058
Validation loss decreased (0.250378 --> 0.250376).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.8636074
	speed: 0.0335s/iter; left time: 387.3963s
Epoch: 10 cost time: 3.9340786933898926
Epoch: 10, Steps: 128 Train Loss: 29.8153 (Forecasting Loss:0.2315 + XiCon Loss:2.9584 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4137115
	speed: 0.0361s/iter; left time: 412.0475s
Epoch: 11 cost time: 4.6180946826934814
Epoch: 11, Steps: 128 Train Loss: 29.5735 (Forecasting Loss:0.2315 + XiCon Loss:2.9342 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
Validation loss decreased (0.250376 --> 0.250063).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.2532158
	speed: 0.0267s/iter; left time: 301.2851s
Epoch: 12 cost time: 3.4843173027038574
Epoch: 12, Steps: 128 Train Loss: 29.6302 (Forecasting Loss:0.2313 + XiCon Loss:2.9399 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.8460865
	speed: 0.0241s/iter; left time: 269.5971s
Epoch: 13 cost time: 3.0508034229278564
Epoch: 13, Steps: 128 Train Loss: 29.6277 (Forecasting Loss:0.2314 + XiCon Loss:2.9396 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.0933762
	speed: 0.0291s/iter; left time: 321.4938s
Epoch: 14 cost time: 3.5240962505340576
Epoch: 14, Steps: 128 Train Loss: 29.7338 (Forecasting Loss:0.2315 + XiCon Loss:2.9502 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2060
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.0471020
	speed: 0.0360s/iter; left time: 393.0140s
Epoch: 15 cost time: 4.362122297286987
Epoch: 15, Steps: 128 Train Loss: 29.7518 (Forecasting Loss:0.2312 + XiCon Loss:2.9521 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.5406971
	speed: 0.0317s/iter; left time: 342.0609s
Epoch: 16 cost time: 4.009264230728149
Epoch: 16, Steps: 128 Train Loss: 29.6691 (Forecasting Loss:0.2314 + XiCon Loss:2.9438 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
Validation loss decreased (0.250063 --> 0.249969).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.1736622
	speed: 0.0284s/iter; left time: 302.6809s
Epoch: 17 cost time: 3.5977017879486084
Epoch: 17, Steps: 128 Train Loss: 29.5652 (Forecasting Loss:0.2315 + XiCon Loss:2.9334 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.5243778
	speed: 0.0275s/iter; left time: 289.1699s
Epoch: 18 cost time: 3.499311923980713
Epoch: 18, Steps: 128 Train Loss: 29.6846 (Forecasting Loss:0.2314 + XiCon Loss:2.9453 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2060
Validation loss decreased (0.249969 --> 0.249463).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.0823479
	speed: 0.0375s/iter; left time: 390.0592s
Epoch: 19 cost time: 4.683394908905029
Epoch: 19, Steps: 128 Train Loss: 29.6200 (Forecasting Loss:0.2313 + XiCon Loss:2.9389 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.8676434
	speed: 0.0304s/iter; left time: 311.8766s
Epoch: 20 cost time: 3.5568578243255615
Epoch: 20, Steps: 128 Train Loss: 29.6365 (Forecasting Loss:0.2312 + XiCon Loss:2.9405 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.1870041
	speed: 0.0327s/iter; left time: 331.5931s
Epoch: 21 cost time: 3.988280773162842
Epoch: 21, Steps: 128 Train Loss: 29.5081 (Forecasting Loss:0.2314 + XiCon Loss:2.9277 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2060
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.1816730
	speed: 0.0341s/iter; left time: 341.6132s
Epoch: 22 cost time: 4.167250394821167
Epoch: 22, Steps: 128 Train Loss: 29.5939 (Forecasting Loss:0.2314 + XiCon Loss:2.9363 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.6669731
	speed: 0.0274s/iter; left time: 270.8130s
Epoch: 23 cost time: 3.7287402153015137
Epoch: 23, Steps: 128 Train Loss: 29.6286 (Forecasting Loss:0.2315 + XiCon Loss:2.9397 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.0590363
	speed: 0.0255s/iter; left time: 248.5072s
Epoch: 24 cost time: 3.3910510540008545
Epoch: 24, Steps: 128 Train Loss: 29.8093 (Forecasting Loss:0.2314 + XiCon Loss:2.9578 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.4917431
	speed: 0.0270s/iter; left time: 259.5086s
Epoch: 25 cost time: 3.4387600421905518
Epoch: 25, Steps: 128 Train Loss: 29.6882 (Forecasting Loss:0.2314 + XiCon Loss:2.9457 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.7554665
	speed: 0.0272s/iter; left time: 258.0794s
Epoch: 26 cost time: 3.2134485244750977
Epoch: 26, Steps: 128 Train Loss: 29.7142 (Forecasting Loss:0.2312 + XiCon Loss:2.9483 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2060
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.6146221
	speed: 0.0341s/iter; left time: 319.4351s
Epoch: 27 cost time: 4.270528554916382
Epoch: 27, Steps: 128 Train Loss: 29.6991 (Forecasting Loss:0.2315 + XiCon Loss:2.9468 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.3790512
	speed: 0.0363s/iter; left time: 335.3806s
Epoch: 28 cost time: 4.3909595012664795
Epoch: 28, Steps: 128 Train Loss: 29.6937 (Forecasting Loss:0.2313 + XiCon Loss:2.9462 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2060
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13183438777923584, mae:0.2801074683666229, mape:0.6631049513816833, mspe:19.579505920410156 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6693
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.3528671
	speed: 0.0336s/iter; left time: 426.3311s
Epoch: 1 cost time: 3.9591712951660156
Epoch: 1, Steps: 128 Train Loss: 30.4110 (Forecasting Loss:0.2947 + XiCon Loss:3.0116 x Lambda(10.0)), Vali MSE Loss: 0.2752 Test MSE Loss: 0.2287
Validation loss decreased (inf --> 0.275235).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4991932
	speed: 0.0367s/iter; left time: 461.6662s
Epoch: 2 cost time: 4.50068998336792
Epoch: 2, Steps: 128 Train Loss: 28.7742 (Forecasting Loss:0.2562 + XiCon Loss:2.8518 x Lambda(10.0)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.2168
Validation loss decreased (0.275235 --> 0.259632).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.5722904
	speed: 0.0379s/iter; left time: 472.2359s
Epoch: 3 cost time: 4.795701503753662
Epoch: 3, Steps: 128 Train Loss: 28.5822 (Forecasting Loss:0.2429 + XiCon Loss:2.8339 x Lambda(10.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.2101
Validation loss decreased (0.259632 --> 0.257687).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.0742931
	speed: 0.0337s/iter; left time: 414.7366s
Epoch: 4 cost time: 4.2466089725494385
Epoch: 4, Steps: 128 Train Loss: 28.8854 (Forecasting Loss:0.2377 + XiCon Loss:2.8648 x Lambda(10.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2131
Validation loss decreased (0.257687 --> 0.247838).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2001190
	speed: 0.0283s/iter; left time: 344.7625s
Epoch: 5 cost time: 3.4205493927001953
Epoch: 5, Steps: 128 Train Loss: 29.5318 (Forecasting Loss:0.2347 + XiCon Loss:2.9297 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2075
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.9290447
	speed: 0.0258s/iter; left time: 310.6253s
Epoch: 6 cost time: 3.5122599601745605
Epoch: 6, Steps: 128 Train Loss: 29.6884 (Forecasting Loss:0.2327 + XiCon Loss:2.9456 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.2086
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9984035
	speed: 0.0246s/iter; left time: 293.8059s
Epoch: 7 cost time: 2.9903135299682617
Epoch: 7, Steps: 128 Train Loss: 29.8509 (Forecasting Loss:0.2318 + XiCon Loss:2.9619 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2087
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.8649063
	speed: 0.0235s/iter; left time: 277.2326s
Epoch: 8 cost time: 2.9438419342041016
Epoch: 8, Steps: 128 Train Loss: 29.9358 (Forecasting Loss:0.2313 + XiCon Loss:2.9704 x Lambda(10.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2080
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.2988377
	speed: 0.0235s/iter; left time: 274.1357s
Epoch: 9 cost time: 3.718463897705078
Epoch: 9, Steps: 128 Train Loss: 29.9503 (Forecasting Loss:0.2311 + XiCon Loss:2.9719 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2078
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.0251579
	speed: 0.0330s/iter; left time: 381.5144s
Epoch: 10 cost time: 4.266263961791992
Epoch: 10, Steps: 128 Train Loss: 29.9639 (Forecasting Loss:0.2306 + XiCon Loss:2.9733 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2082
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7660618
	speed: 0.0321s/iter; left time: 366.1541s
Epoch: 11 cost time: 3.9262208938598633
Epoch: 11, Steps: 128 Train Loss: 29.9169 (Forecasting Loss:0.2308 + XiCon Loss:2.9686 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2082
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9112530
	speed: 0.0330s/iter; left time: 372.7536s
Epoch: 12 cost time: 4.027604341506958
Epoch: 12, Steps: 128 Train Loss: 29.9663 (Forecasting Loss:0.2309 + XiCon Loss:2.9735 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2082
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.5926228
	speed: 0.0301s/iter; left time: 336.0392s
Epoch: 13 cost time: 3.736945629119873
Epoch: 13, Steps: 128 Train Loss: 30.0506 (Forecasting Loss:0.2307 + XiCon Loss:2.9820 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2081
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4929276
	speed: 0.0251s/iter; left time: 277.2928s
Epoch: 14 cost time: 3.2660939693450928
Epoch: 14, Steps: 128 Train Loss: 30.0862 (Forecasting Loss:0.2306 + XiCon Loss:2.9856 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2081
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1391606479883194, mae:0.287126362323761, mape:0.6875455975532532, mspe:21.48265838623047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8192
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.1427841
	speed: 0.0292s/iter; left time: 370.9089s
Epoch: 1 cost time: 3.8153882026672363
Epoch: 1, Steps: 128 Train Loss: 30.2785 (Forecasting Loss:0.2910 + XiCon Loss:2.9988 x Lambda(10.0)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.2267
Validation loss decreased (inf --> 0.272658).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4270611
	speed: 0.0205s/iter; left time: 257.9327s
Epoch: 2 cost time: 2.599698543548584
Epoch: 2, Steps: 128 Train Loss: 28.7895 (Forecasting Loss:0.2604 + XiCon Loss:2.8529 x Lambda(10.0)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.2307
Validation loss decreased (0.272658 --> 0.260957).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 27.6862717
	speed: 0.0227s/iter; left time: 282.1563s
Epoch: 3 cost time: 3.1051812171936035
Epoch: 3, Steps: 128 Train Loss: 28.4099 (Forecasting Loss:0.2418 + XiCon Loss:2.8168 x Lambda(10.0)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.2052
Validation loss decreased (0.260957 --> 0.260066).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.4412766
	speed: 0.0252s/iter; left time: 310.7421s
Epoch: 4 cost time: 3.124621868133545
Epoch: 4, Steps: 128 Train Loss: 29.0684 (Forecasting Loss:0.2367 + XiCon Loss:2.8832 x Lambda(10.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.2161
Validation loss decreased (0.260066 --> 0.253694).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1897049
	speed: 0.0302s/iter; left time: 367.5667s
Epoch: 5 cost time: 3.7077810764312744
Epoch: 5, Steps: 128 Train Loss: 29.8968 (Forecasting Loss:0.2349 + XiCon Loss:2.9662 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2043
Validation loss decreased (0.253694 --> 0.250457).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.1987457
	speed: 0.0353s/iter; left time: 426.0911s
Epoch: 6 cost time: 4.346102476119995
Epoch: 6, Steps: 128 Train Loss: 30.0568 (Forecasting Loss:0.2332 + XiCon Loss:2.9824 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2092
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9381027
	speed: 0.0302s/iter; left time: 360.7168s
Epoch: 7 cost time: 3.9159646034240723
Epoch: 7, Steps: 128 Train Loss: 30.0529 (Forecasting Loss:0.2322 + XiCon Loss:2.9821 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2052
Validation loss decreased (0.250457 --> 0.249540).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8988400
	speed: 0.0301s/iter; left time: 355.6288s
Epoch: 8 cost time: 3.7668263912200928
Epoch: 8, Steps: 128 Train Loss: 29.8961 (Forecasting Loss:0.2318 + XiCon Loss:2.9664 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2054
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9120064
	speed: 0.0329s/iter; left time: 383.6959s
Epoch: 9 cost time: 4.249329566955566
Epoch: 9, Steps: 128 Train Loss: 30.1137 (Forecasting Loss:0.2314 + XiCon Loss:2.9882 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2052
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.2780228
	speed: 0.0222s/iter; left time: 256.2211s
Epoch: 10 cost time: 2.70304012298584
Epoch: 10, Steps: 128 Train Loss: 30.1420 (Forecasting Loss:0.2313 + XiCon Loss:2.9911 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2052
Validation loss decreased (0.249540 --> 0.249076).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7625542
	speed: 0.0184s/iter; left time: 210.1696s
Epoch: 11 cost time: 2.3062326908111572
Epoch: 11, Steps: 128 Train Loss: 30.1394 (Forecasting Loss:0.2314 + XiCon Loss:2.9908 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5243626
	speed: 0.0316s/iter; left time: 356.8679s
Epoch: 12 cost time: 3.935654401779175
Epoch: 12, Steps: 128 Train Loss: 30.1105 (Forecasting Loss:0.2312 + XiCon Loss:2.9879 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2051
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5497036
	speed: 0.0304s/iter; left time: 339.8355s
Epoch: 13 cost time: 3.8101987838745117
Epoch: 13, Steps: 128 Train Loss: 29.9804 (Forecasting Loss:0.2312 + XiCon Loss:2.9749 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2051
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8127518
	speed: 0.0330s/iter; left time: 363.8078s
Epoch: 14 cost time: 4.0725789070129395
Epoch: 14, Steps: 128 Train Loss: 30.0714 (Forecasting Loss:0.2312 + XiCon Loss:2.9840 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2051
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.7920589
	speed: 0.0315s/iter; left time: 343.4902s
Epoch: 15 cost time: 3.8912272453308105
Epoch: 15, Steps: 128 Train Loss: 30.2039 (Forecasting Loss:0.2314 + XiCon Loss:2.9973 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2051
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.5157433
	speed: 0.0283s/iter; left time: 305.5778s
Epoch: 16 cost time: 3.557858467102051
Epoch: 16, Steps: 128 Train Loss: 30.1251 (Forecasting Loss:0.2313 + XiCon Loss:2.9894 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2051
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.3998871
	speed: 0.0262s/iter; left time: 279.2263s
Epoch: 17 cost time: 3.356480360031128
Epoch: 17, Steps: 128 Train Loss: 30.0256 (Forecasting Loss:0.2313 + XiCon Loss:2.9794 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2051
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.0365582
	speed: 0.0363s/iter; left time: 382.5155s
Epoch: 18 cost time: 4.316128969192505
Epoch: 18, Steps: 128 Train Loss: 29.9722 (Forecasting Loss:0.2312 + XiCon Loss:2.9741 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2051
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2271652
	speed: 0.0330s/iter; left time: 343.0312s
Epoch: 19 cost time: 3.9384336471557617
Epoch: 19, Steps: 128 Train Loss: 30.0332 (Forecasting Loss:0.2312 + XiCon Loss:2.9802 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2051
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.6107101
	speed: 0.0351s/iter; left time: 360.7484s
Epoch: 20 cost time: 4.236680746078491
Epoch: 20, Steps: 128 Train Loss: 30.0731 (Forecasting Loss:0.2314 + XiCon Loss:2.9842 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2051
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13101164996623993, mae:0.2793143689632416, mape:0.6633093953132629, mspe:19.68266487121582 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1330+-0.00430, MAE:0.2813+-0.00405, MAPE:0.6665+-0.01486, MSPE:19.9282+-1.08896, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7593
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4399753
	speed: 0.0415s/iter; left time: 485.2012s
Epoch: 1 cost time: 4.589249134063721
Epoch: 1, Steps: 118 Train Loss: 0.4446 (Forecasting Loss:0.4140 + XiCon Loss:3.0608 x Lambda(0.01)), Vali MSE Loss: 0.4301 Test MSE Loss: 0.3242
Validation loss decreased (inf --> 0.430064).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3034452
	speed: 0.0439s/iter; left time: 508.2813s
Epoch: 2 cost time: 5.517733097076416
Epoch: 2, Steps: 118 Train Loss: 0.3317 (Forecasting Loss:0.3008 + XiCon Loss:3.0861 x Lambda(0.01)), Vali MSE Loss: 0.3560 Test MSE Loss: 0.2724
Validation loss decreased (0.430064 --> 0.356019).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3012695
	speed: 0.0500s/iter; left time: 573.6030s
Epoch: 3 cost time: 5.786354064941406
Epoch: 3, Steps: 118 Train Loss: 0.2896 (Forecasting Loss:0.2592 + XiCon Loss:3.0422 x Lambda(0.01)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2690
Validation loss decreased (0.356019 --> 0.313896).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2928957
	speed: 0.0519s/iter; left time: 588.7863s
Epoch: 4 cost time: 6.166631698608398
Epoch: 4, Steps: 118 Train Loss: 0.2755 (Forecasting Loss:0.2453 + XiCon Loss:3.0240 x Lambda(0.01)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.2581
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2551490
	speed: 0.0499s/iter; left time: 560.3633s
Epoch: 5 cost time: 5.815333843231201
Epoch: 5, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2386 + XiCon Loss:3.0168 x Lambda(0.01)), Vali MSE Loss: 0.3175 Test MSE Loss: 0.2520
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2534039
	speed: 0.0484s/iter; left time: 538.2395s
Epoch: 6 cost time: 5.9731574058532715
Epoch: 6, Steps: 118 Train Loss: 0.2654 (Forecasting Loss:0.2352 + XiCon Loss:3.0131 x Lambda(0.01)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2535
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2706821
	speed: 0.0527s/iter; left time: 579.1098s
Epoch: 7 cost time: 6.441681146621704
Epoch: 7, Steps: 118 Train Loss: 0.2636 (Forecasting Loss:0.2335 + XiCon Loss:3.0099 x Lambda(0.01)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2566
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2423083
	speed: 0.0512s/iter; left time: 557.2741s
Epoch: 8 cost time: 6.0552191734313965
Epoch: 8, Steps: 118 Train Loss: 0.2627 (Forecasting Loss:0.2326 + XiCon Loss:3.0090 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2554
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2547480
	speed: 0.0456s/iter; left time: 490.8986s
Epoch: 9 cost time: 5.503551721572876
Epoch: 9, Steps: 118 Train Loss: 0.2622 (Forecasting Loss:0.2321 + XiCon Loss:3.0092 x Lambda(0.01)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2541
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2590671
	speed: 0.0528s/iter; left time: 561.6710s
Epoch: 10 cost time: 6.016578674316406
Epoch: 10, Steps: 118 Train Loss: 0.2620 (Forecasting Loss:0.2319 + XiCon Loss:3.0071 x Lambda(0.01)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2549
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2593743
	speed: 0.0473s/iter; left time: 498.1275s
Epoch: 11 cost time: 5.639058351516724
Epoch: 11, Steps: 118 Train Loss: 0.2617 (Forecasting Loss:0.2317 + XiCon Loss:3.0071 x Lambda(0.01)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.2541
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2626416
	speed: 0.0499s/iter; left time: 519.4213s
Epoch: 12 cost time: 5.638200283050537
Epoch: 12, Steps: 118 Train Loss: 0.2616 (Forecasting Loss:0.2316 + XiCon Loss:3.0084 x Lambda(0.01)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2546
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2600783
	speed: 0.0456s/iter; left time: 468.9256s
Epoch: 13 cost time: 5.43456768989563
Epoch: 13, Steps: 118 Train Loss: 0.2617 (Forecasting Loss:0.2316 + XiCon Loss:3.0099 x Lambda(0.01)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2546
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18693459033966064, mae:0.35097068548202515, mape:0.661102831363678, mspe:18.862573623657227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8874
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3421015
	speed: 0.0451s/iter; left time: 528.2851s
Epoch: 1 cost time: 5.581663131713867
Epoch: 1, Steps: 118 Train Loss: 0.4439 (Forecasting Loss:0.4135 + XiCon Loss:3.0417 x Lambda(0.01)), Vali MSE Loss: 0.4213 Test MSE Loss: 0.3108
Validation loss decreased (inf --> 0.421260).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3105558
	speed: 0.0460s/iter; left time: 532.3064s
Epoch: 2 cost time: 5.599670886993408
Epoch: 2, Steps: 118 Train Loss: 0.3455 (Forecasting Loss:0.3150 + XiCon Loss:3.0458 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2856
Validation loss decreased (0.421260 --> 0.325026).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3081204
	speed: 0.0462s/iter; left time: 530.1070s
Epoch: 3 cost time: 5.59602427482605
Epoch: 3, Steps: 118 Train Loss: 0.2893 (Forecasting Loss:0.2587 + XiCon Loss:3.0645 x Lambda(0.01)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.2544
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2694887
	speed: 0.0434s/iter; left time: 493.0086s
Epoch: 4 cost time: 5.016470670700073
Epoch: 4, Steps: 118 Train Loss: 0.2734 (Forecasting Loss:0.2425 + XiCon Loss:3.0923 x Lambda(0.01)), Vali MSE Loss: 0.3586 Test MSE Loss: 0.2616
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2684523
	speed: 0.0490s/iter; left time: 549.7915s
Epoch: 5 cost time: 5.77530312538147
Epoch: 5, Steps: 118 Train Loss: 0.2662 (Forecasting Loss:0.2351 + XiCon Loss:3.1071 x Lambda(0.01)), Vali MSE Loss: 0.3568 Test MSE Loss: 0.2671
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2514699
	speed: 0.0512s/iter; left time: 569.0666s
Epoch: 6 cost time: 6.020653963088989
Epoch: 6, Steps: 118 Train Loss: 0.2634 (Forecasting Loss:0.2323 + XiCon Loss:3.1093 x Lambda(0.01)), Vali MSE Loss: 0.3602 Test MSE Loss: 0.2655
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2559169
	speed: 0.0517s/iter; left time: 568.0652s
Epoch: 7 cost time: 5.882320404052734
Epoch: 7, Steps: 118 Train Loss: 0.2619 (Forecasting Loss:0.2307 + XiCon Loss:3.1194 x Lambda(0.01)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.2685
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2653009
	speed: 0.0451s/iter; left time: 490.7851s
Epoch: 8 cost time: 5.334222793579102
Epoch: 8, Steps: 118 Train Loss: 0.2611 (Forecasting Loss:0.2299 + XiCon Loss:3.1164 x Lambda(0.01)), Vali MSE Loss: 0.3602 Test MSE Loss: 0.2675
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2882862
	speed: 0.0509s/iter; left time: 547.1193s
Epoch: 9 cost time: 5.8611719608306885
Epoch: 9, Steps: 118 Train Loss: 0.2606 (Forecasting Loss:0.2294 + XiCon Loss:3.1180 x Lambda(0.01)), Vali MSE Loss: 0.3611 Test MSE Loss: 0.2665
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2576479
	speed: 0.0447s/iter; left time: 475.4790s
Epoch: 10 cost time: 5.256876707077026
Epoch: 10, Steps: 118 Train Loss: 0.2605 (Forecasting Loss:0.2294 + XiCon Loss:3.1167 x Lambda(0.01)), Vali MSE Loss: 0.3628 Test MSE Loss: 0.2669
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2573218
	speed: 0.0441s/iter; left time: 463.6695s
Epoch: 11 cost time: 5.297378301620483
Epoch: 11, Steps: 118 Train Loss: 0.2603 (Forecasting Loss:0.2292 + XiCon Loss:3.1116 x Lambda(0.01)), Vali MSE Loss: 0.3633 Test MSE Loss: 0.2667
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2648995
	speed: 0.0435s/iter; left time: 452.5669s
Epoch: 12 cost time: 5.030771255493164
Epoch: 12, Steps: 118 Train Loss: 0.2605 (Forecasting Loss:0.2293 + XiCon Loss:3.1192 x Lambda(0.01)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2663
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20484043657779694, mae:0.36635926365852356, mape:0.6536756753921509, mspe:16.97556495666504 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8473
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3854325
	speed: 0.0455s/iter; left time: 532.5481s
Epoch: 1 cost time: 5.281217813491821
Epoch: 1, Steps: 118 Train Loss: 0.4310 (Forecasting Loss:0.4003 + XiCon Loss:3.0694 x Lambda(0.01)), Vali MSE Loss: 0.4157 Test MSE Loss: 0.2924
Validation loss decreased (inf --> 0.415732).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3526841
	speed: 0.0481s/iter; left time: 556.9588s
Epoch: 2 cost time: 5.526301145553589
Epoch: 2, Steps: 118 Train Loss: 0.3575 (Forecasting Loss:0.3271 + XiCon Loss:3.0390 x Lambda(0.01)), Vali MSE Loss: 0.3766 Test MSE Loss: 0.3120
Validation loss decreased (0.415732 --> 0.376627).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3089052
	speed: 0.0509s/iter; left time: 583.3902s
Epoch: 3 cost time: 6.21147894859314
Epoch: 3, Steps: 118 Train Loss: 0.3164 (Forecasting Loss:0.2862 + XiCon Loss:3.0262 x Lambda(0.01)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2955
Validation loss decreased (0.376627 --> 0.360379).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2631397
	speed: 0.0432s/iter; left time: 490.6259s
Epoch: 4 cost time: 5.066434383392334
Epoch: 4, Steps: 118 Train Loss: 0.2874 (Forecasting Loss:0.2572 + XiCon Loss:3.0137 x Lambda(0.01)), Vali MSE Loss: 0.3473 Test MSE Loss: 0.2622
Validation loss decreased (0.360379 --> 0.347306).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2842214
	speed: 0.0507s/iter; left time: 569.5385s
Epoch: 5 cost time: 5.974971055984497
Epoch: 5, Steps: 118 Train Loss: 0.2781 (Forecasting Loss:0.2480 + XiCon Loss:3.0083 x Lambda(0.01)), Vali MSE Loss: 0.3450 Test MSE Loss: 0.2639
Validation loss decreased (0.347306 --> 0.344980).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2675063
	speed: 0.0410s/iter; left time: 456.0588s
Epoch: 6 cost time: 5.057006597518921
Epoch: 6, Steps: 118 Train Loss: 0.2745 (Forecasting Loss:0.2445 + XiCon Loss:3.0072 x Lambda(0.01)), Vali MSE Loss: 0.3413 Test MSE Loss: 0.2590
Validation loss decreased (0.344980 --> 0.341292).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2729090
	speed: 0.0475s/iter; left time: 522.2944s
Epoch: 7 cost time: 5.686586856842041
Epoch: 7, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2420 + XiCon Loss:3.0029 x Lambda(0.01)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.2576
Validation loss decreased (0.341292 --> 0.331215).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2770699
	speed: 0.0485s/iter; left time: 527.3405s
Epoch: 8 cost time: 5.578216075897217
Epoch: 8, Steps: 118 Train Loss: 0.2712 (Forecasting Loss:0.2411 + XiCon Loss:3.0057 x Lambda(0.01)), Vali MSE Loss: 0.3344 Test MSE Loss: 0.2562
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2523701
	speed: 0.0466s/iter; left time: 500.9601s
Epoch: 9 cost time: 5.5916924476623535
Epoch: 9, Steps: 118 Train Loss: 0.2705 (Forecasting Loss:0.2405 + XiCon Loss:3.0055 x Lambda(0.01)), Vali MSE Loss: 0.3353 Test MSE Loss: 0.2562
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2566557
	speed: 0.0441s/iter; left time: 468.6696s
Epoch: 10 cost time: 5.1793739795684814
Epoch: 10, Steps: 118 Train Loss: 0.2709 (Forecasting Loss:0.2408 + XiCon Loss:3.0024 x Lambda(0.01)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.2572
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2712587
	speed: 0.0463s/iter; left time: 487.4476s
Epoch: 11 cost time: 5.39941930770874
Epoch: 11, Steps: 118 Train Loss: 0.2703 (Forecasting Loss:0.2402 + XiCon Loss:3.0026 x Lambda(0.01)), Vali MSE Loss: 0.3322 Test MSE Loss: 0.2565
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2595273
	speed: 0.0467s/iter; left time: 485.6871s
Epoch: 12 cost time: 5.520350456237793
Epoch: 12, Steps: 118 Train Loss: 0.2701 (Forecasting Loss:0.2401 + XiCon Loss:3.0022 x Lambda(0.01)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.2563
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2775376
	speed: 0.0479s/iter; left time: 492.1471s
Epoch: 13 cost time: 5.4139180183410645
Epoch: 13, Steps: 118 Train Loss: 0.2700 (Forecasting Loss:0.2400 + XiCon Loss:3.0025 x Lambda(0.01)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.2565
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2806237
	speed: 0.0437s/iter; left time: 444.5401s
Epoch: 14 cost time: 4.99381685256958
Epoch: 14, Steps: 118 Train Loss: 0.2701 (Forecasting Loss:0.2400 + XiCon Loss:3.0044 x Lambda(0.01)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.2565
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2523821
	speed: 0.0439s/iter; left time: 441.3409s
Epoch: 15 cost time: 5.2316200733184814
Epoch: 15, Steps: 118 Train Loss: 0.2701 (Forecasting Loss:0.2401 + XiCon Loss:3.0038 x Lambda(0.01)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.2565
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2768641
	speed: 0.0443s/iter; left time: 440.1059s
Epoch: 16 cost time: 5.108768463134766
Epoch: 16, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2404 + XiCon Loss:3.0046 x Lambda(0.01)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.2565
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2592250
	speed: 0.0502s/iter; left time: 493.0805s
Epoch: 17 cost time: 5.790342569351196
Epoch: 17, Steps: 118 Train Loss: 0.2700 (Forecasting Loss:0.2400 + XiCon Loss:3.0024 x Lambda(0.01)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.2565
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1761583387851715, mae:0.3390395939350128, mape:0.6712971329689026, mspe:18.96877098083496 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4250
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3968701
	speed: 0.0350s/iter; left time: 409.1240s
Epoch: 1 cost time: 4.181988477706909
Epoch: 1, Steps: 118 Train Loss: 0.4231 (Forecasting Loss:0.3923 + XiCon Loss:3.0761 x Lambda(0.01)), Vali MSE Loss: 0.4029 Test MSE Loss: 0.2806
Validation loss decreased (inf --> 0.402876).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3097899
	speed: 0.0446s/iter; left time: 516.1487s
Epoch: 2 cost time: 5.3892600536346436
Epoch: 2, Steps: 118 Train Loss: 0.3525 (Forecasting Loss:0.3222 + XiCon Loss:3.0345 x Lambda(0.01)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.2806
Validation loss decreased (0.402876 --> 0.376161).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2991964
	speed: 0.0467s/iter; left time: 535.2664s
Epoch: 3 cost time: 5.3559181690216064
Epoch: 3, Steps: 118 Train Loss: 0.3017 (Forecasting Loss:0.2716 + XiCon Loss:3.0067 x Lambda(0.01)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.2573
Validation loss decreased (0.376161 --> 0.338702).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3020728
	speed: 0.0505s/iter; left time: 573.2040s
Epoch: 4 cost time: 5.858788251876831
Epoch: 4, Steps: 118 Train Loss: 0.2834 (Forecasting Loss:0.2534 + XiCon Loss:2.9979 x Lambda(0.01)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.2472
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2873857
	speed: 0.0466s/iter; left time: 522.8085s
Epoch: 5 cost time: 5.439016819000244
Epoch: 5, Steps: 118 Train Loss: 0.2786 (Forecasting Loss:0.2486 + XiCon Loss:2.9926 x Lambda(0.01)), Vali MSE Loss: 0.3507 Test MSE Loss: 0.2463
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2714251
	speed: 0.0350s/iter; left time: 389.0844s
Epoch: 6 cost time: 3.9788360595703125
Epoch: 6, Steps: 118 Train Loss: 0.2748 (Forecasting Loss:0.2448 + XiCon Loss:2.9956 x Lambda(0.01)), Vali MSE Loss: 0.3545 Test MSE Loss: 0.2541
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2883984
	speed: 0.0401s/iter; left time: 441.0966s
Epoch: 7 cost time: 5.007973670959473
Epoch: 7, Steps: 118 Train Loss: 0.2734 (Forecasting Loss:0.2435 + XiCon Loss:2.9928 x Lambda(0.01)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2487
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2804471
	speed: 0.0391s/iter; left time: 424.8865s
Epoch: 8 cost time: 4.782599687576294
Epoch: 8, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2422 + XiCon Loss:2.9886 x Lambda(0.01)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.2492
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2652512
	speed: 0.0429s/iter; left time: 461.4430s
Epoch: 9 cost time: 5.179885387420654
Epoch: 9, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2422 + XiCon Loss:2.9920 x Lambda(0.01)), Vali MSE Loss: 0.3510 Test MSE Loss: 0.2461
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2699476
	speed: 0.0424s/iter; left time: 451.4483s
Epoch: 10 cost time: 5.055648565292358
Epoch: 10, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2419 + XiCon Loss:2.9915 x Lambda(0.01)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2478
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2733104
	speed: 0.0456s/iter; left time: 479.5375s
Epoch: 11 cost time: 5.495702266693115
Epoch: 11, Steps: 118 Train Loss: 0.2714 (Forecasting Loss:0.2415 + XiCon Loss:2.9895 x Lambda(0.01)), Vali MSE Loss: 0.3478 Test MSE Loss: 0.2457
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2653517
	speed: 0.0333s/iter; left time: 346.2662s
Epoch: 12 cost time: 3.788210391998291
Epoch: 12, Steps: 118 Train Loss: 0.2713 (Forecasting Loss:0.2414 + XiCon Loss:2.9901 x Lambda(0.01)), Vali MSE Loss: 0.3485 Test MSE Loss: 0.2466
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2586933
	speed: 0.0432s/iter; left time: 444.1311s
Epoch: 13 cost time: 5.231103897094727
Epoch: 13, Steps: 118 Train Loss: 0.2712 (Forecasting Loss:0.2413 + XiCon Loss:2.9913 x Lambda(0.01)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2469
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17545150220394135, mae:0.339082807302475, mape:0.686572253704071, mspe:19.931541442871094 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8612
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4094464
	speed: 0.0429s/iter; left time: 502.3908s
Epoch: 1 cost time: 4.991479396820068
Epoch: 1, Steps: 118 Train Loss: 0.4333 (Forecasting Loss:0.4027 + XiCon Loss:3.0560 x Lambda(0.01)), Vali MSE Loss: 0.4264 Test MSE Loss: 0.3147
Validation loss decreased (inf --> 0.426351).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3366714
	speed: 0.0461s/iter; left time: 533.7440s
Epoch: 2 cost time: 5.696880340576172
Epoch: 2, Steps: 118 Train Loss: 0.3467 (Forecasting Loss:0.3162 + XiCon Loss:3.0468 x Lambda(0.01)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.2715
Validation loss decreased (0.426351 --> 0.327397).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2886718
	speed: 0.0461s/iter; left time: 529.1057s
Epoch: 3 cost time: 5.232316255569458
Epoch: 3, Steps: 118 Train Loss: 0.2977 (Forecasting Loss:0.2674 + XiCon Loss:3.0260 x Lambda(0.01)), Vali MSE Loss: 0.3423 Test MSE Loss: 0.2657
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2809540
	speed: 0.0546s/iter; left time: 619.7850s
Epoch: 4 cost time: 6.404462099075317
Epoch: 4, Steps: 118 Train Loss: 0.2817 (Forecasting Loss:0.2514 + XiCon Loss:3.0350 x Lambda(0.01)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2695
Validation loss decreased (0.327397 --> 0.318670).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2729959
	speed: 0.0492s/iter; left time: 552.3743s
Epoch: 5 cost time: 5.861833810806274
Epoch: 5, Steps: 118 Train Loss: 0.2727 (Forecasting Loss:0.2422 + XiCon Loss:3.0484 x Lambda(0.01)), Vali MSE Loss: 0.3491 Test MSE Loss: 0.2709
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2704879
	speed: 0.0441s/iter; left time: 490.0621s
Epoch: 6 cost time: 5.068554162979126
Epoch: 6, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2386 + XiCon Loss:3.0543 x Lambda(0.01)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.2618
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2868647
	speed: 0.0424s/iter; left time: 465.6148s
Epoch: 7 cost time: 5.182714462280273
Epoch: 7, Steps: 118 Train Loss: 0.2661 (Forecasting Loss:0.2356 + XiCon Loss:3.0501 x Lambda(0.01)), Vali MSE Loss: 0.3391 Test MSE Loss: 0.2644
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2676320
	speed: 0.0491s/iter; left time: 533.9430s
Epoch: 8 cost time: 5.7076146602630615
Epoch: 8, Steps: 118 Train Loss: 0.2656 (Forecasting Loss:0.2350 + XiCon Loss:3.0545 x Lambda(0.01)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.2638
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2663193
	speed: 0.0427s/iter; left time: 459.6084s
Epoch: 9 cost time: 5.0266687870025635
Epoch: 9, Steps: 118 Train Loss: 0.2647 (Forecasting Loss:0.2342 + XiCon Loss:3.0515 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2644
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2593517
	speed: 0.0449s/iter; left time: 478.0428s
Epoch: 10 cost time: 5.520238399505615
Epoch: 10, Steps: 118 Train Loss: 0.2647 (Forecasting Loss:0.2342 + XiCon Loss:3.0493 x Lambda(0.01)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.2665
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2606026
	speed: 0.0483s/iter; left time: 508.6672s
Epoch: 11 cost time: 5.556883811950684
Epoch: 11, Steps: 118 Train Loss: 0.2645 (Forecasting Loss:0.2339 + XiCon Loss:3.0633 x Lambda(0.01)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.2647
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2639042
	speed: 0.0467s/iter; left time: 486.0853s
Epoch: 12 cost time: 5.637279987335205
Epoch: 12, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2336 + XiCon Loss:3.0517 x Lambda(0.01)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2648
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2725956
	speed: 0.0498s/iter; left time: 511.8661s
Epoch: 13 cost time: 5.942169189453125
Epoch: 13, Steps: 118 Train Loss: 0.2646 (Forecasting Loss:0.2340 + XiCon Loss:3.0591 x Lambda(0.01)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2650
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2507176
	speed: 0.0457s/iter; left time: 465.0518s
Epoch: 14 cost time: 5.224481582641602
Epoch: 14, Steps: 118 Train Loss: 0.2640 (Forecasting Loss:0.2335 + XiCon Loss:3.0462 x Lambda(0.01)), Vali MSE Loss: 0.3359 Test MSE Loss: 0.2650
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18669728934764862, mae:0.352312833070755, mape:0.6346971392631531, mspe:16.107715606689453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1860+-0.01475, MAE:0.3496+-0.01405, MAPE:0.6615+-0.02408, MSPE:18.1692+-1.95344, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6240
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5830431
	speed: 0.0604s/iter; left time: 640.6242s
Epoch: 1 cost time: 6.399565696716309
Epoch: 1, Steps: 107 Train Loss: 0.6371 (Forecasting Loss:0.6340 + XiCon Loss:3.0829 x Lambda(0.001)), Vali MSE Loss: 0.5963 Test MSE Loss: 0.4668
Validation loss decreased (inf --> 0.596256).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3031876
	speed: 0.0637s/iter; left time: 668.9870s
Epoch: 2 cost time: 6.841696262359619
Epoch: 2, Steps: 107 Train Loss: 0.3636 (Forecasting Loss:0.3605 + XiCon Loss:3.1328 x Lambda(0.001)), Vali MSE Loss: 0.4618 Test MSE Loss: 0.2866
Validation loss decreased (0.596256 --> 0.461832).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2670585
	speed: 0.0650s/iter; left time: 674.6686s
Epoch: 3 cost time: 6.917078971862793
Epoch: 3, Steps: 107 Train Loss: 0.2786 (Forecasting Loss:0.2755 + XiCon Loss:3.1190 x Lambda(0.001)), Vali MSE Loss: 0.3675 Test MSE Loss: 0.2403
Validation loss decreased (0.461832 --> 0.367460).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2615367
	speed: 0.0602s/iter; left time: 618.7040s
Epoch: 4 cost time: 6.611151695251465
Epoch: 4, Steps: 107 Train Loss: 0.2666 (Forecasting Loss:0.2635 + XiCon Loss:3.1146 x Lambda(0.001)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2385
Validation loss decreased (0.367460 --> 0.354004).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2733729
	speed: 0.0650s/iter; left time: 660.9602s
Epoch: 5 cost time: 7.162113189697266
Epoch: 5, Steps: 107 Train Loss: 0.2618 (Forecasting Loss:0.2587 + XiCon Loss:3.1127 x Lambda(0.001)), Vali MSE Loss: 0.3557 Test MSE Loss: 0.2387
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2476207
	speed: 0.0652s/iter; left time: 656.3004s
Epoch: 6 cost time: 7.0291125774383545
Epoch: 6, Steps: 107 Train Loss: 0.2591 (Forecasting Loss:0.2560 + XiCon Loss:3.1123 x Lambda(0.001)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2391
Validation loss decreased (0.354004 --> 0.353512).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2609477
	speed: 0.0636s/iter; left time: 633.4182s
Epoch: 7 cost time: 6.830480098724365
Epoch: 7, Steps: 107 Train Loss: 0.2576 (Forecasting Loss:0.2544 + XiCon Loss:3.1093 x Lambda(0.001)), Vali MSE Loss: 0.3525 Test MSE Loss: 0.2393
Validation loss decreased (0.353512 --> 0.352505).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2562875
	speed: 0.0653s/iter; left time: 643.1519s
Epoch: 8 cost time: 7.018564939498901
Epoch: 8, Steps: 107 Train Loss: 0.2572 (Forecasting Loss:0.2541 + XiCon Loss:3.1094 x Lambda(0.001)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.2418
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2595682
	speed: 0.0668s/iter; left time: 650.7226s
Epoch: 9 cost time: 7.158567667007446
Epoch: 9, Steps: 107 Train Loss: 0.2567 (Forecasting Loss:0.2536 + XiCon Loss:3.1097 x Lambda(0.001)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.2415
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2526191
	speed: 0.0615s/iter; left time: 592.8630s
Epoch: 10 cost time: 6.622557163238525
Epoch: 10, Steps: 107 Train Loss: 0.2563 (Forecasting Loss:0.2532 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2402
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2551139
	speed: 0.0621s/iter; left time: 592.3200s
Epoch: 11 cost time: 6.699991226196289
Epoch: 11, Steps: 107 Train Loss: 0.2565 (Forecasting Loss:0.2534 + XiCon Loss:3.1053 x Lambda(0.001)), Vali MSE Loss: 0.3539 Test MSE Loss: 0.2399
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2458163
	speed: 0.0665s/iter; left time: 627.0552s
Epoch: 12 cost time: 7.050831317901611
Epoch: 12, Steps: 107 Train Loss: 0.2560 (Forecasting Loss:0.2529 + XiCon Loss:3.1077 x Lambda(0.001)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.2397
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2554139
	speed: 0.0655s/iter; left time: 609.8022s
Epoch: 13 cost time: 7.00088906288147
Epoch: 13, Steps: 107 Train Loss: 0.2561 (Forecasting Loss:0.2530 + XiCon Loss:3.1071 x Lambda(0.001)), Vali MSE Loss: 0.3536 Test MSE Loss: 0.2398
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2540062
	speed: 0.0673s/iter; left time: 619.9462s
Epoch: 14 cost time: 7.253290891647339
Epoch: 14, Steps: 107 Train Loss: 0.2560 (Forecasting Loss:0.2529 + XiCon Loss:3.1081 x Lambda(0.001)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2400
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2650006
	speed: 0.0652s/iter; left time: 593.7678s
Epoch: 15 cost time: 7.0439772605896
Epoch: 15, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.1069 x Lambda(0.001)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.2399
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2597713
	speed: 0.0693s/iter; left time: 623.5084s
Epoch: 16 cost time: 7.507522821426392
Epoch: 16, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.1074 x Lambda(0.001)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2399
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2608069
	speed: 0.0607s/iter; left time: 539.7426s
Epoch: 17 cost time: 6.593556880950928
Epoch: 17, Steps: 107 Train Loss: 0.2560 (Forecasting Loss:0.2529 + XiCon Loss:3.1080 x Lambda(0.001)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2400
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.15636518597602844, mae:0.32221096754074097, mape:0.6571516990661621, mspe:18.080812454223633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6106042
	speed: 0.0529s/iter; left time: 561.1914s
Epoch: 1 cost time: 5.686540842056274
Epoch: 1, Steps: 107 Train Loss: 0.6217 (Forecasting Loss:0.6187 + XiCon Loss:3.0722 x Lambda(0.001)), Vali MSE Loss: 0.5551 Test MSE Loss: 0.4220
Validation loss decreased (inf --> 0.555065).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3238110
	speed: 0.0559s/iter; left time: 587.0825s
Epoch: 2 cost time: 6.018453121185303
Epoch: 2, Steps: 107 Train Loss: 0.4184 (Forecasting Loss:0.4154 + XiCon Loss:3.0546 x Lambda(0.001)), Vali MSE Loss: 0.3901 Test MSE Loss: 0.2625
Validation loss decreased (0.555065 --> 0.390068).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2923012
	speed: 0.0597s/iter; left time: 620.6114s
Epoch: 3 cost time: 6.409269571304321
Epoch: 3, Steps: 107 Train Loss: 0.2955 (Forecasting Loss:0.2924 + XiCon Loss:3.0459 x Lambda(0.001)), Vali MSE Loss: 0.3480 Test MSE Loss: 0.2524
Validation loss decreased (0.390068 --> 0.347954).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2783611
	speed: 0.0556s/iter; left time: 571.1742s
Epoch: 4 cost time: 5.982019424438477
Epoch: 4, Steps: 107 Train Loss: 0.2702 (Forecasting Loss:0.2671 + XiCon Loss:3.0435 x Lambda(0.001)), Vali MSE Loss: 0.3411 Test MSE Loss: 0.2890
Validation loss decreased (0.347954 --> 0.341148).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2490758
	speed: 0.0551s/iter; left time: 560.7907s
Epoch: 5 cost time: 6.006847381591797
Epoch: 5, Steps: 107 Train Loss: 0.2623 (Forecasting Loss:0.2593 + XiCon Loss:3.0454 x Lambda(0.001)), Vali MSE Loss: 0.3406 Test MSE Loss: 0.2669
Validation loss decreased (0.341148 --> 0.340618).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2595965
	speed: 0.0538s/iter; left time: 541.4132s
Epoch: 6 cost time: 5.907567977905273
Epoch: 6, Steps: 107 Train Loss: 0.2575 (Forecasting Loss:0.2545 + XiCon Loss:3.0424 x Lambda(0.001)), Vali MSE Loss: 0.3411 Test MSE Loss: 0.2645
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2389602
	speed: 0.0548s/iter; left time: 545.2983s
Epoch: 7 cost time: 5.866277456283569
Epoch: 7, Steps: 107 Train Loss: 0.2558 (Forecasting Loss:0.2527 + XiCon Loss:3.0423 x Lambda(0.001)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2511
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2560581
	speed: 0.0536s/iter; left time: 527.6638s
Epoch: 8 cost time: 5.784164667129517
Epoch: 8, Steps: 107 Train Loss: 0.2549 (Forecasting Loss:0.2519 + XiCon Loss:3.0435 x Lambda(0.001)), Vali MSE Loss: 0.3454 Test MSE Loss: 0.2744
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2595232
	speed: 0.0582s/iter; left time: 567.3902s
Epoch: 9 cost time: 6.259344577789307
Epoch: 9, Steps: 107 Train Loss: 0.2548 (Forecasting Loss:0.2517 + XiCon Loss:3.0446 x Lambda(0.001)), Vali MSE Loss: 0.3443 Test MSE Loss: 0.2679
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2464257
	speed: 0.0549s/iter; left time: 529.0836s
Epoch: 10 cost time: 5.811533689498901
Epoch: 10, Steps: 107 Train Loss: 0.2540 (Forecasting Loss:0.2509 + XiCon Loss:3.0471 x Lambda(0.001)), Vali MSE Loss: 0.3443 Test MSE Loss: 0.2645
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2418293
	speed: 0.0566s/iter; left time: 539.3712s
Epoch: 11 cost time: 6.009689092636108
Epoch: 11, Steps: 107 Train Loss: 0.2541 (Forecasting Loss:0.2510 + XiCon Loss:3.0480 x Lambda(0.001)), Vali MSE Loss: 0.3455 Test MSE Loss: 0.2629
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2558329
	speed: 0.0422s/iter; left time: 398.0408s
Epoch: 12 cost time: 4.567983150482178
Epoch: 12, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2506 + XiCon Loss:3.0480 x Lambda(0.001)), Vali MSE Loss: 0.3447 Test MSE Loss: 0.2631
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2556845
	speed: 0.0481s/iter; left time: 448.2145s
Epoch: 13 cost time: 5.27973484992981
Epoch: 13, Steps: 107 Train Loss: 0.2540 (Forecasting Loss:0.2509 + XiCon Loss:3.0459 x Lambda(0.001)), Vali MSE Loss: 0.3444 Test MSE Loss: 0.2638
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2579262
	speed: 0.0525s/iter; left time: 483.2334s
Epoch: 14 cost time: 5.673426151275635
Epoch: 14, Steps: 107 Train Loss: 0.2538 (Forecasting Loss:0.2507 + XiCon Loss:3.0449 x Lambda(0.001)), Vali MSE Loss: 0.3453 Test MSE Loss: 0.2636
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2557611
	speed: 0.0495s/iter; left time: 450.5736s
Epoch: 15 cost time: 5.268381834030151
Epoch: 15, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2507 + XiCon Loss:3.0475 x Lambda(0.001)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.2637
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.18576909601688385, mae:0.3480444848537445, mape:0.5606098771095276, mspe:11.482080459594727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.9743
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5914356
	speed: 0.0554s/iter; left time: 586.8953s
Epoch: 1 cost time: 5.91306209564209
Epoch: 1, Steps: 107 Train Loss: 0.6202 (Forecasting Loss:0.6171 + XiCon Loss:3.0993 x Lambda(0.001)), Vali MSE Loss: 0.5247 Test MSE Loss: 0.3790
Validation loss decreased (inf --> 0.524672).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3157621
	speed: 0.0544s/iter; left time: 570.6792s
Epoch: 2 cost time: 5.930217504501343
Epoch: 2, Steps: 107 Train Loss: 0.4000 (Forecasting Loss:0.3969 + XiCon Loss:3.0692 x Lambda(0.001)), Vali MSE Loss: 0.3756 Test MSE Loss: 0.3225
Validation loss decreased (0.524672 --> 0.375579).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2847008
	speed: 0.0509s/iter; left time: 528.4624s
Epoch: 3 cost time: 5.459213733673096
Epoch: 3, Steps: 107 Train Loss: 0.2929 (Forecasting Loss:0.2899 + XiCon Loss:3.0467 x Lambda(0.001)), Vali MSE Loss: 0.3451 Test MSE Loss: 0.2545
Validation loss decreased (0.375579 --> 0.345069).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2603343
	speed: 0.0528s/iter; left time: 542.7463s
Epoch: 4 cost time: 5.677121877670288
Epoch: 4, Steps: 107 Train Loss: 0.2708 (Forecasting Loss:0.2677 + XiCon Loss:3.0420 x Lambda(0.001)), Vali MSE Loss: 0.3477 Test MSE Loss: 0.2907
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2725653
	speed: 0.0584s/iter; left time: 593.7096s
Epoch: 5 cost time: 6.2466981410980225
Epoch: 5, Steps: 107 Train Loss: 0.2634 (Forecasting Loss:0.2604 + XiCon Loss:3.0396 x Lambda(0.001)), Vali MSE Loss: 0.3669 Test MSE Loss: 0.2882
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2616384
	speed: 0.0403s/iter; left time: 406.1321s
Epoch: 6 cost time: 4.4660351276397705
Epoch: 6, Steps: 107 Train Loss: 0.2602 (Forecasting Loss:0.2572 + XiCon Loss:3.0380 x Lambda(0.001)), Vali MSE Loss: 0.3611 Test MSE Loss: 0.2715
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2482759
	speed: 0.0554s/iter; left time: 551.8315s
Epoch: 7 cost time: 5.891149997711182
Epoch: 7, Steps: 107 Train Loss: 0.2581 (Forecasting Loss:0.2551 + XiCon Loss:3.0409 x Lambda(0.001)), Vali MSE Loss: 0.3608 Test MSE Loss: 0.2996
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2600462
	speed: 0.0519s/iter; left time: 510.9550s
Epoch: 8 cost time: 5.664141654968262
Epoch: 8, Steps: 107 Train Loss: 0.2572 (Forecasting Loss:0.2541 + XiCon Loss:3.0386 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.3010
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2522334
	speed: 0.0495s/iter; left time: 481.9896s
Epoch: 9 cost time: 5.412251234054565
Epoch: 9, Steps: 107 Train Loss: 0.2567 (Forecasting Loss:0.2536 + XiCon Loss:3.0410 x Lambda(0.001)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2942
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2472361
	speed: 0.0507s/iter; left time: 488.4464s
Epoch: 10 cost time: 5.504231214523315
Epoch: 10, Steps: 107 Train Loss: 0.2564 (Forecasting Loss:0.2534 + XiCon Loss:3.0370 x Lambda(0.001)), Vali MSE Loss: 0.3612 Test MSE Loss: 0.2961
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2553784
	speed: 0.0571s/iter; left time: 543.9710s
Epoch: 11 cost time: 6.1866912841796875
Epoch: 11, Steps: 107 Train Loss: 0.2563 (Forecasting Loss:0.2532 + XiCon Loss:3.0384 x Lambda(0.001)), Vali MSE Loss: 0.3647 Test MSE Loss: 0.2963
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2539609
	speed: 0.0508s/iter; left time: 478.9078s
Epoch: 12 cost time: 5.504679203033447
Epoch: 12, Steps: 107 Train Loss: 0.2561 (Forecasting Loss:0.2531 + XiCon Loss:3.0396 x Lambda(0.001)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.2991
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2516340
	speed: 0.0509s/iter; left time: 473.8456s
Epoch: 13 cost time: 5.48070764541626
Epoch: 13, Steps: 107 Train Loss: 0.2561 (Forecasting Loss:0.2531 + XiCon Loss:3.0387 x Lambda(0.001)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2988
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17188069224357605, mae:0.33720511198043823, mape:0.5750593543052673, mspe:13.283647537231445 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8007
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6119441
	speed: 0.0532s/iter; left time: 563.6763s
Epoch: 1 cost time: 5.814992427825928
Epoch: 1, Steps: 107 Train Loss: 0.6206 (Forecasting Loss:0.6175 + XiCon Loss:3.0907 x Lambda(0.001)), Vali MSE Loss: 0.5745 Test MSE Loss: 0.4260
Validation loss decreased (inf --> 0.574468).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2893170
	speed: 0.0613s/iter; left time: 643.5726s
Epoch: 2 cost time: 6.647100448608398
Epoch: 2, Steps: 107 Train Loss: 0.3382 (Forecasting Loss:0.3351 + XiCon Loss:3.0743 x Lambda(0.001)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.2481
Validation loss decreased (0.574468 --> 0.374715).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2617131
	speed: 0.0597s/iter; left time: 619.6910s
Epoch: 3 cost time: 6.387967109680176
Epoch: 3, Steps: 107 Train Loss: 0.2714 (Forecasting Loss:0.2683 + XiCon Loss:3.0694 x Lambda(0.001)), Vali MSE Loss: 0.3899 Test MSE Loss: 0.2626
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2592323
	speed: 0.0610s/iter; left time: 627.5723s
Epoch: 4 cost time: 6.568310976028442
Epoch: 4, Steps: 107 Train Loss: 0.2588 (Forecasting Loss:0.2558 + XiCon Loss:3.0621 x Lambda(0.001)), Vali MSE Loss: 0.3943 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2631785
	speed: 0.0662s/iter; left time: 672.9638s
Epoch: 5 cost time: 7.089749813079834
Epoch: 5, Steps: 107 Train Loss: 0.2544 (Forecasting Loss:0.2513 + XiCon Loss:3.0595 x Lambda(0.001)), Vali MSE Loss: 0.4022 Test MSE Loss: 0.2466
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2543005
	speed: 0.0620s/iter; left time: 624.5515s
Epoch: 6 cost time: 6.7115936279296875
Epoch: 6, Steps: 107 Train Loss: 0.2517 (Forecasting Loss:0.2486 + XiCon Loss:3.0586 x Lambda(0.001)), Vali MSE Loss: 0.3994 Test MSE Loss: 0.2469
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2512422
	speed: 0.0645s/iter; left time: 642.0406s
Epoch: 7 cost time: 6.991278171539307
Epoch: 7, Steps: 107 Train Loss: 0.2505 (Forecasting Loss:0.2474 + XiCon Loss:3.0577 x Lambda(0.001)), Vali MSE Loss: 0.4057 Test MSE Loss: 0.2558
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2625814
	speed: 0.0634s/iter; left time: 624.2637s
Epoch: 8 cost time: 6.833211421966553
Epoch: 8, Steps: 107 Train Loss: 0.2495 (Forecasting Loss:0.2464 + XiCon Loss:3.0576 x Lambda(0.001)), Vali MSE Loss: 0.4056 Test MSE Loss: 0.2518
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2457824
	speed: 0.0674s/iter; left time: 656.5367s
Epoch: 9 cost time: 7.269955396652222
Epoch: 9, Steps: 107 Train Loss: 0.2491 (Forecasting Loss:0.2461 + XiCon Loss:3.0593 x Lambda(0.001)), Vali MSE Loss: 0.4057 Test MSE Loss: 0.2512
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2554469
	speed: 0.0641s/iter; left time: 617.7588s
Epoch: 10 cost time: 6.802381992340088
Epoch: 10, Steps: 107 Train Loss: 0.2492 (Forecasting Loss:0.2461 + XiCon Loss:3.0579 x Lambda(0.001)), Vali MSE Loss: 0.4062 Test MSE Loss: 0.2516
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2555560
	speed: 0.0624s/iter; left time: 594.8599s
Epoch: 11 cost time: 6.789637565612793
Epoch: 11, Steps: 107 Train Loss: 0.2489 (Forecasting Loss:0.2458 + XiCon Loss:3.0569 x Lambda(0.001)), Vali MSE Loss: 0.4055 Test MSE Loss: 0.2525
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2420269
	speed: 0.0673s/iter; left time: 634.5648s
Epoch: 12 cost time: 7.205539226531982
Epoch: 12, Steps: 107 Train Loss: 0.2490 (Forecasting Loss:0.2459 + XiCon Loss:3.0561 x Lambda(0.001)), Vali MSE Loss: 0.4061 Test MSE Loss: 0.2530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.16559408605098724, mae:0.3306276500225067, mape:0.7266013026237488, mspe:23.259252548217773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8468
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5706084
	speed: 0.0530s/iter; left time: 561.7195s
Epoch: 1 cost time: 5.655350923538208
Epoch: 1, Steps: 107 Train Loss: 0.6231 (Forecasting Loss:0.6200 + XiCon Loss:3.0889 x Lambda(0.001)), Vali MSE Loss: 0.5415 Test MSE Loss: 0.4030
Validation loss decreased (inf --> 0.541466).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3158553
	speed: 0.0562s/iter; left time: 589.4515s
Epoch: 2 cost time: 6.056438684463501
Epoch: 2, Steps: 107 Train Loss: 0.4120 (Forecasting Loss:0.4089 + XiCon Loss:3.0994 x Lambda(0.001)), Vali MSE Loss: 0.3523 Test MSE Loss: 0.2863
Validation loss decreased (0.541466 --> 0.352317).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2862227
	speed: 0.0522s/iter; left time: 542.2025s
Epoch: 3 cost time: 5.619907855987549
Epoch: 3, Steps: 107 Train Loss: 0.2865 (Forecasting Loss:0.2835 + XiCon Loss:3.0638 x Lambda(0.001)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.3342
Validation loss decreased (0.352317 --> 0.321565).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2606148
	speed: 0.0580s/iter; left time: 595.8778s
Epoch: 4 cost time: 6.185737133026123
Epoch: 4, Steps: 107 Train Loss: 0.2661 (Forecasting Loss:0.2630 + XiCon Loss:3.0638 x Lambda(0.001)), Vali MSE Loss: 0.3106 Test MSE Loss: 0.3263
Validation loss decreased (0.321565 --> 0.310592).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2583876
	speed: 0.0502s/iter; left time: 510.6263s
Epoch: 5 cost time: 5.489155292510986
Epoch: 5, Steps: 107 Train Loss: 0.2578 (Forecasting Loss:0.2547 + XiCon Loss:3.0618 x Lambda(0.001)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3243
Validation loss decreased (0.310592 --> 0.309339).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2448178
	speed: 0.0550s/iter; left time: 553.3494s
Epoch: 6 cost time: 5.935727119445801
Epoch: 6, Steps: 107 Train Loss: 0.2533 (Forecasting Loss:0.2503 + XiCon Loss:3.0627 x Lambda(0.001)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2516003
	speed: 0.0553s/iter; left time: 550.8420s
Epoch: 7 cost time: 6.003604173660278
Epoch: 7, Steps: 107 Train Loss: 0.2515 (Forecasting Loss:0.2485 + XiCon Loss:3.0633 x Lambda(0.001)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.3070
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2291157
	speed: 0.0588s/iter; left time: 579.4318s
Epoch: 8 cost time: 6.31872820854187
Epoch: 8, Steps: 107 Train Loss: 0.2504 (Forecasting Loss:0.2474 + XiCon Loss:3.0600 x Lambda(0.001)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.3064
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2476385
	speed: 0.0529s/iter; left time: 515.5531s
Epoch: 9 cost time: 5.7618114948272705
Epoch: 9, Steps: 107 Train Loss: 0.2501 (Forecasting Loss:0.2470 + XiCon Loss:3.0624 x Lambda(0.001)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2587573
	speed: 0.0521s/iter; left time: 502.3252s
Epoch: 10 cost time: 5.613484621047974
Epoch: 10, Steps: 107 Train Loss: 0.2499 (Forecasting Loss:0.2468 + XiCon Loss:3.0606 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.3062
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2474214
	speed: 0.0522s/iter; left time: 497.9864s
Epoch: 11 cost time: 5.49333381652832
Epoch: 11, Steps: 107 Train Loss: 0.2497 (Forecasting Loss:0.2466 + XiCon Loss:3.0626 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.3070
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2528830
	speed: 0.0555s/iter; left time: 523.0100s
Epoch: 12 cost time: 5.950673580169678
Epoch: 12, Steps: 107 Train Loss: 0.2497 (Forecasting Loss:0.2466 + XiCon Loss:3.0613 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.3061
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2445422
	speed: 0.0503s/iter; left time: 468.2204s
Epoch: 13 cost time: 5.4505455493927
Epoch: 13, Steps: 107 Train Loss: 0.2496 (Forecasting Loss:0.2466 + XiCon Loss:3.0611 x Lambda(0.001)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.3061
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2496754
	speed: 0.0523s/iter; left time: 481.2756s
Epoch: 14 cost time: 5.592190742492676
Epoch: 14, Steps: 107 Train Loss: 0.2494 (Forecasting Loss:0.2463 + XiCon Loss:3.0604 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.3061
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2515171
	speed: 0.0529s/iter; left time: 481.4541s
Epoch: 15 cost time: 5.677497625350952
Epoch: 15, Steps: 107 Train Loss: 0.2493 (Forecasting Loss:0.2462 + XiCon Loss:3.0622 x Lambda(0.001)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.3062
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.24550582468509674, mae:0.4031180143356323, mape:0.6401588320732117, mspe:13.342523574829102 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1850+-0.04403, MAE:0.3482+-0.03985, MAPE:0.6319+-0.08326, MSPE:15.8897+-5.94892, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6800
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.253771781921387
Epoch: 1, Steps: 96 Train Loss: 1.2851 (Forecasting Loss:0.9746 + XiCon Loss:3.1053 x Lambda(0.1)), Vali MSE Loss: 0.6604 Test MSE Loss: 0.9189
Validation loss decreased (inf --> 0.660393).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.2380406856536865
Epoch: 2, Steps: 96 Train Loss: 1.0562 (Forecasting Loss:0.7477 + XiCon Loss:3.0844 x Lambda(0.1)), Vali MSE Loss: 0.6157 Test MSE Loss: 0.2715
Validation loss decreased (0.660393 --> 0.615667).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.890941143035889
Epoch: 3, Steps: 96 Train Loss: 0.8662 (Forecasting Loss:0.5575 + XiCon Loss:3.0867 x Lambda(0.1)), Vali MSE Loss: 0.5600 Test MSE Loss: 0.2551
Validation loss decreased (0.615667 --> 0.560008).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.5228307247161865
Epoch: 4, Steps: 96 Train Loss: 0.8305 (Forecasting Loss:0.5228 + XiCon Loss:3.0771 x Lambda(0.1)), Vali MSE Loss: 0.5169 Test MSE Loss: 0.2578
Validation loss decreased (0.560008 --> 0.516944).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.889150142669678
Epoch: 5, Steps: 96 Train Loss: 0.8156 (Forecasting Loss:0.5082 + XiCon Loss:3.0741 x Lambda(0.1)), Vali MSE Loss: 0.5032 Test MSE Loss: 0.2571
Validation loss decreased (0.516944 --> 0.503194).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.514204025268555
Epoch: 6, Steps: 96 Train Loss: 0.8084 (Forecasting Loss:0.5011 + XiCon Loss:3.0723 x Lambda(0.1)), Vali MSE Loss: 0.4918 Test MSE Loss: 0.2640
Validation loss decreased (0.503194 --> 0.491784).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.366081237792969
Epoch: 7, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4980 + XiCon Loss:3.0695 x Lambda(0.1)), Vali MSE Loss: 0.4964 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.36128568649292
Epoch: 8, Steps: 96 Train Loss: 0.8023 (Forecasting Loss:0.4954 + XiCon Loss:3.0691 x Lambda(0.1)), Vali MSE Loss: 0.4911 Test MSE Loss: 0.2617
Validation loss decreased (0.491784 --> 0.491095).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.663659334182739
Epoch: 9, Steps: 96 Train Loss: 0.8014 (Forecasting Loss:0.4946 + XiCon Loss:3.0682 x Lambda(0.1)), Vali MSE Loss: 0.4918 Test MSE Loss: 0.2612
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.620594501495361
Epoch: 10, Steps: 96 Train Loss: 0.8016 (Forecasting Loss:0.4948 + XiCon Loss:3.0683 x Lambda(0.1)), Vali MSE Loss: 0.4916 Test MSE Loss: 0.2611
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.8083460330963135
Epoch: 11, Steps: 96 Train Loss: 0.8015 (Forecasting Loss:0.4946 + XiCon Loss:3.0686 x Lambda(0.1)), Vali MSE Loss: 0.4909 Test MSE Loss: 0.2612
Validation loss decreased (0.491095 --> 0.490914).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.549945831298828
Epoch: 12, Steps: 96 Train Loss: 0.8010 (Forecasting Loss:0.4941 + XiCon Loss:3.0690 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2614
Validation loss decreased (0.490914 --> 0.490651).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 3.5810065269470215
Epoch: 13, Steps: 96 Train Loss: 0.8004 (Forecasting Loss:0.4936 + XiCon Loss:3.0681 x Lambda(0.1)), Vali MSE Loss: 0.4909 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.225690603256226
Epoch: 14, Steps: 96 Train Loss: 0.8005 (Forecasting Loss:0.4935 + XiCon Loss:3.0700 x Lambda(0.1)), Vali MSE Loss: 0.4904 Test MSE Loss: 0.2614
Validation loss decreased (0.490651 --> 0.490414).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.081564664840698
Epoch: 15, Steps: 96 Train Loss: 0.8006 (Forecasting Loss:0.4935 + XiCon Loss:3.0709 x Lambda(0.1)), Vali MSE Loss: 0.4903 Test MSE Loss: 0.2614
Validation loss decreased (0.490414 --> 0.490255).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.934786558151245
Epoch: 16, Steps: 96 Train Loss: 0.8001 (Forecasting Loss:0.4932 + XiCon Loss:3.0690 x Lambda(0.1)), Vali MSE Loss: 0.4908 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.965806722640991
Epoch: 17, Steps: 96 Train Loss: 0.8009 (Forecasting Loss:0.4941 + XiCon Loss:3.0684 x Lambda(0.1)), Vali MSE Loss: 0.4902 Test MSE Loss: 0.2614
Validation loss decreased (0.490255 --> 0.490203).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.575443267822266
Epoch: 18, Steps: 96 Train Loss: 0.7998 (Forecasting Loss:0.4928 + XiCon Loss:3.0699 x Lambda(0.1)), Vali MSE Loss: 0.4904 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.867860794067383
Epoch: 19, Steps: 96 Train Loss: 0.8002 (Forecasting Loss:0.4936 + XiCon Loss:3.0667 x Lambda(0.1)), Vali MSE Loss: 0.4906 Test MSE Loss: 0.2614
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.968139410018921
Epoch: 20, Steps: 96 Train Loss: 0.7998 (Forecasting Loss:0.4931 + XiCon Loss:3.0669 x Lambda(0.1)), Vali MSE Loss: 0.4908 Test MSE Loss: 0.2614
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.675498962402344
Epoch: 21, Steps: 96 Train Loss: 0.8002 (Forecasting Loss:0.4932 + XiCon Loss:3.0694 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2614
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.611388683319092
Epoch: 22, Steps: 96 Train Loss: 0.8012 (Forecasting Loss:0.4942 + XiCon Loss:3.0703 x Lambda(0.1)), Vali MSE Loss: 0.4901 Test MSE Loss: 0.2614
Validation loss decreased (0.490203 --> 0.490143).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.242472410202026
Epoch: 23, Steps: 96 Train Loss: 0.8009 (Forecasting Loss:0.4939 + XiCon Loss:3.0703 x Lambda(0.1)), Vali MSE Loss: 0.4903 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 5.057685375213623
Epoch: 24, Steps: 96 Train Loss: 0.8012 (Forecasting Loss:0.4943 + XiCon Loss:3.0682 x Lambda(0.1)), Vali MSE Loss: 0.4909 Test MSE Loss: 0.2614
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 3.780348300933838
Epoch: 25, Steps: 96 Train Loss: 0.8002 (Forecasting Loss:0.4932 + XiCon Loss:3.0700 x Lambda(0.1)), Vali MSE Loss: 0.4906 Test MSE Loss: 0.2614
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 5.27069878578186
Epoch: 26, Steps: 96 Train Loss: 0.7998 (Forecasting Loss:0.4930 + XiCon Loss:3.0682 x Lambda(0.1)), Vali MSE Loss: 0.4904 Test MSE Loss: 0.2614
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 5.426056861877441
Epoch: 27, Steps: 96 Train Loss: 0.7993 (Forecasting Loss:0.4926 + XiCon Loss:3.0676 x Lambda(0.1)), Vali MSE Loss: 0.4911 Test MSE Loss: 0.2614
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 4.423970460891724
Epoch: 28, Steps: 96 Train Loss: 0.8014 (Forecasting Loss:0.4945 + XiCon Loss:3.0695 x Lambda(0.1)), Vali MSE Loss: 0.4904 Test MSE Loss: 0.2614
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 4.80330753326416
Epoch: 29, Steps: 96 Train Loss: 0.8004 (Forecasting Loss:0.4935 + XiCon Loss:3.0687 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2614
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.82874321937561
Epoch: 30, Steps: 96 Train Loss: 0.7996 (Forecasting Loss:0.4926 + XiCon Loss:3.0698 x Lambda(0.1)), Vali MSE Loss: 0.4905 Test MSE Loss: 0.2614
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 5.3451666831970215
Epoch: 31, Steps: 96 Train Loss: 0.8007 (Forecasting Loss:0.4940 + XiCon Loss:3.0677 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2614
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 4.8952765464782715
Epoch: 32, Steps: 96 Train Loss: 0.8001 (Forecasting Loss:0.4931 + XiCon Loss:3.0700 x Lambda(0.1)), Vali MSE Loss: 0.4905 Test MSE Loss: 0.2614
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.1833987683057785, mae:0.3394666612148285, mape:0.6762248277664185, mspe:21.00571060180664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7764
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.850273370742798
Epoch: 1, Steps: 96 Train Loss: 1.2818 (Forecasting Loss:0.9713 + XiCon Loss:3.1051 x Lambda(0.1)), Vali MSE Loss: 0.6862 Test MSE Loss: 0.9603
Validation loss decreased (inf --> 0.686215).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.642055034637451
Epoch: 2, Steps: 96 Train Loss: 1.1087 (Forecasting Loss:0.8000 + XiCon Loss:3.0871 x Lambda(0.1)), Vali MSE Loss: 0.5791 Test MSE Loss: 0.4626
Validation loss decreased (0.686215 --> 0.579076).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.11833381652832
Epoch: 3, Steps: 96 Train Loss: 0.9032 (Forecasting Loss:0.5965 + XiCon Loss:3.0671 x Lambda(0.1)), Vali MSE Loss: 0.4856 Test MSE Loss: 0.3131
Validation loss decreased (0.579076 --> 0.485637).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.854811906814575
Epoch: 4, Steps: 96 Train Loss: 0.8104 (Forecasting Loss:0.5046 + XiCon Loss:3.0574 x Lambda(0.1)), Vali MSE Loss: 0.4866 Test MSE Loss: 0.3188
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.7738118171691895
Epoch: 5, Steps: 96 Train Loss: 0.7883 (Forecasting Loss:0.4835 + XiCon Loss:3.0481 x Lambda(0.1)), Vali MSE Loss: 0.4886 Test MSE Loss: 0.3254
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.608782768249512
Epoch: 6, Steps: 96 Train Loss: 0.7800 (Forecasting Loss:0.4752 + XiCon Loss:3.0485 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3376
Validation loss decreased (0.485637 --> 0.481861).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.8199543952941895
Epoch: 7, Steps: 96 Train Loss: 0.7772 (Forecasting Loss:0.4731 + XiCon Loss:3.0418 x Lambda(0.1)), Vali MSE Loss: 0.4831 Test MSE Loss: 0.3327
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.3876402378082275
Epoch: 8, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.4699 + XiCon Loss:3.0419 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3369
Validation loss decreased (0.481861 --> 0.480833).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.972385883331299
Epoch: 9, Steps: 96 Train Loss: 0.7725 (Forecasting Loss:0.4683 + XiCon Loss:3.0425 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3406
Validation loss decreased (0.480833 --> 0.480758).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.819114446640015
Epoch: 10, Steps: 96 Train Loss: 0.7728 (Forecasting Loss:0.4685 + XiCon Loss:3.0422 x Lambda(0.1)), Vali MSE Loss: 0.4809 Test MSE Loss: 0.3338
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.549439430236816
Epoch: 11, Steps: 96 Train Loss: 0.7700 (Forecasting Loss:0.4658 + XiCon Loss:3.0424 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3356
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.815135955810547
Epoch: 12, Steps: 96 Train Loss: 0.7735 (Forecasting Loss:0.4691 + XiCon Loss:3.0440 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3360
Validation loss decreased (0.480758 --> 0.480515).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.862752437591553
Epoch: 13, Steps: 96 Train Loss: 0.7724 (Forecasting Loss:0.4683 + XiCon Loss:3.0410 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.69759202003479
Epoch: 14, Steps: 96 Train Loss: 0.7712 (Forecasting Loss:0.4671 + XiCon Loss:3.0414 x Lambda(0.1)), Vali MSE Loss: 0.4820 Test MSE Loss: 0.3365
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.188636541366577
Epoch: 15, Steps: 96 Train Loss: 0.7722 (Forecasting Loss:0.4678 + XiCon Loss:3.0449 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3367
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.925752639770508
Epoch: 16, Steps: 96 Train Loss: 0.7717 (Forecasting Loss:0.4674 + XiCon Loss:3.0427 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3366
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.644024610519409
Epoch: 17, Steps: 96 Train Loss: 0.7729 (Forecasting Loss:0.4685 + XiCon Loss:3.0440 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3367
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 5.035144805908203
Epoch: 18, Steps: 96 Train Loss: 0.7725 (Forecasting Loss:0.4682 + XiCon Loss:3.0424 x Lambda(0.1)), Vali MSE Loss: 0.4814 Test MSE Loss: 0.3367
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.721402645111084
Epoch: 19, Steps: 96 Train Loss: 0.7742 (Forecasting Loss:0.4698 + XiCon Loss:3.0445 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3367
Validation loss decreased (0.480515 --> 0.480437).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.822073698043823
Epoch: 20, Steps: 96 Train Loss: 0.7721 (Forecasting Loss:0.4675 + XiCon Loss:3.0459 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3367
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.60204553604126
Epoch: 21, Steps: 96 Train Loss: 0.7709 (Forecasting Loss:0.4666 + XiCon Loss:3.0431 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3367
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.6906163692474365
Epoch: 22, Steps: 96 Train Loss: 0.7739 (Forecasting Loss:0.4695 + XiCon Loss:3.0436 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3367
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 5.233291149139404
Epoch: 23, Steps: 96 Train Loss: 0.7714 (Forecasting Loss:0.4673 + XiCon Loss:3.0406 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3367
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.912748575210571
Epoch: 24, Steps: 96 Train Loss: 0.7724 (Forecasting Loss:0.4682 + XiCon Loss:3.0424 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3367
Validation loss decreased (0.480437 --> 0.479525).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 5.196263790130615
Epoch: 25, Steps: 96 Train Loss: 0.7725 (Forecasting Loss:0.4683 + XiCon Loss:3.0419 x Lambda(0.1)), Vali MSE Loss: 0.4798 Test MSE Loss: 0.3367
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.715571641921997
Epoch: 26, Steps: 96 Train Loss: 0.7724 (Forecasting Loss:0.4680 + XiCon Loss:3.0435 x Lambda(0.1)), Vali MSE Loss: 0.4810 Test MSE Loss: 0.3367
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 4.413933277130127
Epoch: 27, Steps: 96 Train Loss: 0.7735 (Forecasting Loss:0.4691 + XiCon Loss:3.0433 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3367
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 4.987498044967651
Epoch: 28, Steps: 96 Train Loss: 0.7735 (Forecasting Loss:0.4692 + XiCon Loss:3.0437 x Lambda(0.1)), Vali MSE Loss: 0.4801 Test MSE Loss: 0.3367
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 4.853772878646851
Epoch: 29, Steps: 96 Train Loss: 0.7724 (Forecasting Loss:0.4679 + XiCon Loss:3.0450 x Lambda(0.1)), Vali MSE Loss: 0.4815 Test MSE Loss: 0.3367
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.899585008621216
Epoch: 30, Steps: 96 Train Loss: 0.7717 (Forecasting Loss:0.4673 + XiCon Loss:3.0439 x Lambda(0.1)), Vali MSE Loss: 0.4793 Test MSE Loss: 0.3367
Validation loss decreased (0.479525 --> 0.479255).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 4.893840551376343
Epoch: 31, Steps: 96 Train Loss: 0.7734 (Forecasting Loss:0.4690 + XiCon Loss:3.0435 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3367
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 4.579484939575195
Epoch: 32, Steps: 96 Train Loss: 0.7704 (Forecasting Loss:0.4661 + XiCon Loss:3.0429 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3367
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 5.11440634727478
Epoch: 33, Steps: 96 Train Loss: 0.7712 (Forecasting Loss:0.4667 + XiCon Loss:3.0446 x Lambda(0.1)), Vali MSE Loss: 0.4828 Test MSE Loss: 0.3367
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 5.278332233428955
Epoch: 34, Steps: 96 Train Loss: 0.7709 (Forecasting Loss:0.4665 + XiCon Loss:3.0435 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3367
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 4.972321033477783
Epoch: 35, Steps: 96 Train Loss: 0.7722 (Forecasting Loss:0.4680 + XiCon Loss:3.0417 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3367
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 5.134044408798218
Epoch: 36, Steps: 96 Train Loss: 0.7728 (Forecasting Loss:0.4684 + XiCon Loss:3.0437 x Lambda(0.1)), Vali MSE Loss: 0.4812 Test MSE Loss: 0.3367
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 4.829275369644165
Epoch: 37, Steps: 96 Train Loss: 0.7720 (Forecasting Loss:0.4676 + XiCon Loss:3.0436 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3367
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 5.441789388656616
Epoch: 38, Steps: 96 Train Loss: 0.7721 (Forecasting Loss:0.4678 + XiCon Loss:3.0435 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3367
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 4.858993768692017
Epoch: 39, Steps: 96 Train Loss: 0.7722 (Forecasting Loss:0.4679 + XiCon Loss:3.0430 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3367
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 4.946540117263794
Epoch: 40, Steps: 96 Train Loss: 0.7720 (Forecasting Loss:0.4676 + XiCon Loss:3.0434 x Lambda(0.1)), Vali MSE Loss: 0.4829 Test MSE Loss: 0.3367
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2683778703212738, mae:0.4049473702907562, mape:0.7775201797485352, mspe:28.23638916015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8205
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.194476842880249
Epoch: 1, Steps: 96 Train Loss: 1.2463 (Forecasting Loss:0.9379 + XiCon Loss:3.0839 x Lambda(0.1)), Vali MSE Loss: 0.6599 Test MSE Loss: 0.8489
Validation loss decreased (inf --> 0.659861).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.225157737731934
Epoch: 2, Steps: 96 Train Loss: 1.0502 (Forecasting Loss:0.7437 + XiCon Loss:3.0650 x Lambda(0.1)), Vali MSE Loss: 0.5994 Test MSE Loss: 0.3535
Validation loss decreased (0.659861 --> 0.599436).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.97328782081604
Epoch: 3, Steps: 96 Train Loss: 0.8633 (Forecasting Loss:0.5578 + XiCon Loss:3.0557 x Lambda(0.1)), Vali MSE Loss: 0.5638 Test MSE Loss: 0.2604
Validation loss decreased (0.599436 --> 0.563841).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.6878502368927
Epoch: 4, Steps: 96 Train Loss: 0.8220 (Forecasting Loss:0.5166 + XiCon Loss:3.0548 x Lambda(0.1)), Vali MSE Loss: 0.6218 Test MSE Loss: 0.2652
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.709622859954834
Epoch: 5, Steps: 96 Train Loss: 0.8081 (Forecasting Loss:0.5032 + XiCon Loss:3.0487 x Lambda(0.1)), Vali MSE Loss: 0.5334 Test MSE Loss: 0.2834
Validation loss decreased (0.563841 --> 0.533422).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.605086803436279
Epoch: 6, Steps: 96 Train Loss: 0.7999 (Forecasting Loss:0.4949 + XiCon Loss:3.0496 x Lambda(0.1)), Vali MSE Loss: 0.5288 Test MSE Loss: 0.2896
Validation loss decreased (0.533422 --> 0.528827).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.154346466064453
Epoch: 7, Steps: 96 Train Loss: 0.7966 (Forecasting Loss:0.4916 + XiCon Loss:3.0502 x Lambda(0.1)), Vali MSE Loss: 0.5339 Test MSE Loss: 0.2842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.2074127197265625
Epoch: 8, Steps: 96 Train Loss: 0.7956 (Forecasting Loss:0.4908 + XiCon Loss:3.0489 x Lambda(0.1)), Vali MSE Loss: 0.5361 Test MSE Loss: 0.2823
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.603543281555176
Epoch: 9, Steps: 96 Train Loss: 0.7933 (Forecasting Loss:0.4881 + XiCon Loss:3.0511 x Lambda(0.1)), Vali MSE Loss: 0.5365 Test MSE Loss: 0.2827
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.466187953948975
Epoch: 10, Steps: 96 Train Loss: 0.7929 (Forecasting Loss:0.4880 + XiCon Loss:3.0489 x Lambda(0.1)), Vali MSE Loss: 0.5389 Test MSE Loss: 0.2826
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.4674296379089355
Epoch: 11, Steps: 96 Train Loss: 0.7931 (Forecasting Loss:0.4880 + XiCon Loss:3.0506 x Lambda(0.1)), Vali MSE Loss: 0.5363 Test MSE Loss: 0.2831
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.940183162689209
Epoch: 12, Steps: 96 Train Loss: 0.7922 (Forecasting Loss:0.4872 + XiCon Loss:3.0507 x Lambda(0.1)), Vali MSE Loss: 0.5349 Test MSE Loss: 0.2840
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.316465854644775
Epoch: 13, Steps: 96 Train Loss: 0.7927 (Forecasting Loss:0.4877 + XiCon Loss:3.0506 x Lambda(0.1)), Vali MSE Loss: 0.5358 Test MSE Loss: 0.2839
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 3.712005376815796
Epoch: 14, Steps: 96 Train Loss: 0.7918 (Forecasting Loss:0.4871 + XiCon Loss:3.0474 x Lambda(0.1)), Vali MSE Loss: 0.5354 Test MSE Loss: 0.2840
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.6885457038879395
Epoch: 15, Steps: 96 Train Loss: 0.7933 (Forecasting Loss:0.4882 + XiCon Loss:3.0507 x Lambda(0.1)), Vali MSE Loss: 0.5357 Test MSE Loss: 0.2840
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.653668403625488
Epoch: 16, Steps: 96 Train Loss: 0.7932 (Forecasting Loss:0.4882 + XiCon Loss:3.0499 x Lambda(0.1)), Vali MSE Loss: 0.5369 Test MSE Loss: 0.2840
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.21455787122249603, mae:0.3647216856479645, mape:0.7273738980293274, mspe:24.30099868774414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.464757680892944
Epoch: 1, Steps: 96 Train Loss: 1.2324 (Forecasting Loss:0.9243 + XiCon Loss:3.0815 x Lambda(0.1)), Vali MSE Loss: 0.6503 Test MSE Loss: 0.8086
Validation loss decreased (inf --> 0.650290).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.343340158462524
Epoch: 2, Steps: 96 Train Loss: 1.1088 (Forecasting Loss:0.8008 + XiCon Loss:3.0797 x Lambda(0.1)), Vali MSE Loss: 0.5711 Test MSE Loss: 0.4029
Validation loss decreased (0.650290 --> 0.571074).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.728491306304932
Epoch: 3, Steps: 96 Train Loss: 0.8689 (Forecasting Loss:0.5607 + XiCon Loss:3.0819 x Lambda(0.1)), Vali MSE Loss: 0.6486 Test MSE Loss: 0.2742
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.6649999618530273
Epoch: 4, Steps: 96 Train Loss: 0.8043 (Forecasting Loss:0.4969 + XiCon Loss:3.0745 x Lambda(0.1)), Vali MSE Loss: 0.5476 Test MSE Loss: 0.2846
Validation loss decreased (0.571074 --> 0.547598).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.425991058349609
Epoch: 5, Steps: 96 Train Loss: 0.7843 (Forecasting Loss:0.4774 + XiCon Loss:3.0697 x Lambda(0.1)), Vali MSE Loss: 0.5660 Test MSE Loss: 0.2817
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.811383962631226
Epoch: 6, Steps: 96 Train Loss: 0.7767 (Forecasting Loss:0.4699 + XiCon Loss:3.0676 x Lambda(0.1)), Vali MSE Loss: 0.5691 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.255856513977051
Epoch: 7, Steps: 96 Train Loss: 0.7713 (Forecasting Loss:0.4643 + XiCon Loss:3.0699 x Lambda(0.1)), Vali MSE Loss: 0.5565 Test MSE Loss: 0.2850
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.875985145568848
Epoch: 8, Steps: 96 Train Loss: 0.7691 (Forecasting Loss:0.4624 + XiCon Loss:3.0678 x Lambda(0.1)), Vali MSE Loss: 0.5579 Test MSE Loss: 0.2850
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.662571907043457
Epoch: 9, Steps: 96 Train Loss: 0.7685 (Forecasting Loss:0.4618 + XiCon Loss:3.0666 x Lambda(0.1)), Vali MSE Loss: 0.5540 Test MSE Loss: 0.2868
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.152368545532227
Epoch: 10, Steps: 96 Train Loss: 0.7692 (Forecasting Loss:0.4623 + XiCon Loss:3.0692 x Lambda(0.1)), Vali MSE Loss: 0.5531 Test MSE Loss: 0.2872
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 2.8940529823303223
Epoch: 11, Steps: 96 Train Loss: 0.7696 (Forecasting Loss:0.4630 + XiCon Loss:3.0668 x Lambda(0.1)), Vali MSE Loss: 0.5544 Test MSE Loss: 0.2868
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.771444082260132
Epoch: 12, Steps: 96 Train Loss: 0.7685 (Forecasting Loss:0.4619 + XiCon Loss:3.0662 x Lambda(0.1)), Vali MSE Loss: 0.5549 Test MSE Loss: 0.2866
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.528770208358765
Epoch: 13, Steps: 96 Train Loss: 0.7680 (Forecasting Loss:0.4614 + XiCon Loss:3.0661 x Lambda(0.1)), Vali MSE Loss: 0.5538 Test MSE Loss: 0.2865
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.348190546035767
Epoch: 14, Steps: 96 Train Loss: 0.7668 (Forecasting Loss:0.4601 + XiCon Loss:3.0677 x Lambda(0.1)), Vali MSE Loss: 0.5538 Test MSE Loss: 0.2866
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.20785105228424072, mae:0.3613930344581604, mape:0.6845754981040955, mspe:21.169029235839844 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7514
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.8052520751953125
Epoch: 1, Steps: 96 Train Loss: 1.2223 (Forecasting Loss:0.9104 + XiCon Loss:3.1198 x Lambda(0.1)), Vali MSE Loss: 0.6232 Test MSE Loss: 0.7929
Validation loss decreased (inf --> 0.623230).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.08254861831665
Epoch: 2, Steps: 96 Train Loss: 1.0382 (Forecasting Loss:0.7328 + XiCon Loss:3.0537 x Lambda(0.1)), Vali MSE Loss: 0.5166 Test MSE Loss: 0.2716
Validation loss decreased (0.623230 --> 0.516617).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.7669517993927
Epoch: 3, Steps: 96 Train Loss: 0.8295 (Forecasting Loss:0.5278 + XiCon Loss:3.0170 x Lambda(0.1)), Vali MSE Loss: 0.5520 Test MSE Loss: 0.2856
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.994734287261963
Epoch: 4, Steps: 96 Train Loss: 0.7932 (Forecasting Loss:0.4931 + XiCon Loss:3.0008 x Lambda(0.1)), Vali MSE Loss: 0.5269 Test MSE Loss: 0.3249
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.631540775299072
Epoch: 5, Steps: 96 Train Loss: 0.7779 (Forecasting Loss:0.4785 + XiCon Loss:2.9944 x Lambda(0.1)), Vali MSE Loss: 0.5567 Test MSE Loss: 0.2962
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.496577978134155
Epoch: 6, Steps: 96 Train Loss: 0.7721 (Forecasting Loss:0.4725 + XiCon Loss:2.9953 x Lambda(0.1)), Vali MSE Loss: 0.5295 Test MSE Loss: 0.3129
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.953407049179077
Epoch: 7, Steps: 96 Train Loss: 0.7664 (Forecasting Loss:0.4670 + XiCon Loss:2.9941 x Lambda(0.1)), Vali MSE Loss: 0.5250 Test MSE Loss: 0.3238
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.520635366439819
Epoch: 8, Steps: 96 Train Loss: 0.7659 (Forecasting Loss:0.4667 + XiCon Loss:2.9915 x Lambda(0.1)), Vali MSE Loss: 0.5254 Test MSE Loss: 0.3203
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.047916650772095
Epoch: 9, Steps: 96 Train Loss: 0.7651 (Forecasting Loss:0.4662 + XiCon Loss:2.9894 x Lambda(0.1)), Vali MSE Loss: 0.5269 Test MSE Loss: 0.3198
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.4899046421051025
Epoch: 10, Steps: 96 Train Loss: 0.7641 (Forecasting Loss:0.4648 + XiCon Loss:2.9927 x Lambda(0.1)), Vali MSE Loss: 0.5249 Test MSE Loss: 0.3212
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.637279748916626
Epoch: 11, Steps: 96 Train Loss: 0.7647 (Forecasting Loss:0.4656 + XiCon Loss:2.9908 x Lambda(0.1)), Vali MSE Loss: 0.5245 Test MSE Loss: 0.3223
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.502883434295654
Epoch: 12, Steps: 96 Train Loss: 0.7657 (Forecasting Loss:0.4667 + XiCon Loss:2.9902 x Lambda(0.1)), Vali MSE Loss: 0.5245 Test MSE Loss: 0.3223
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.19365207850933075, mae:0.3496335446834564, mape:0.689545214176178, mspe:21.079004287719727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2136+-0.04092, MAE:0.3640+-0.03099, MAPE:0.7110+-0.05217, MSPE:23.1582+-3.92683, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.6883
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.2900715
	speed: 0.0640s/iter; left time: 1690.0333s
	iters: 200, epoch: 1 | loss: 29.6536541
	speed: 0.0647s/iter; left time: 1700.8087s
Epoch: 1 cost time: 16.683491230010986
Epoch: 1, Steps: 265 Train Loss: 30.5562 (Forecasting Loss:0.2126 + XiCon Loss:3.0344 x Lambda(10.0)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.146710).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.1794701
	speed: 0.0639s/iter; left time: 1670.9778s
	iters: 200, epoch: 2 | loss: 30.2853985
	speed: 0.0645s/iter; left time: 1680.5311s
Epoch: 2 cost time: 17.09114146232605
Epoch: 2, Steps: 265 Train Loss: 30.6341 (Forecasting Loss:0.1981 + XiCon Loss:3.0436 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0957
Validation loss decreased (0.146710 --> 0.144183).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.1334686
	speed: 0.0649s/iter; left time: 1680.2306s
	iters: 200, epoch: 3 | loss: 31.2397766
	speed: 0.0588s/iter; left time: 1515.5842s
Epoch: 3 cost time: 16.223283052444458
Epoch: 3, Steps: 265 Train Loss: 29.8381 (Forecasting Loss:0.1936 + XiCon Loss:2.9644 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0955
Validation loss decreased (0.144183 --> 0.143346).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.8087540
	speed: 0.0626s/iter; left time: 1603.5762s
	iters: 200, epoch: 4 | loss: 30.2140503
	speed: 0.0598s/iter; left time: 1526.4858s
Epoch: 4 cost time: 16.653932332992554
Epoch: 4, Steps: 265 Train Loss: 29.6923 (Forecasting Loss:0.1914 + XiCon Loss:2.9501 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0955
Validation loss decreased (0.143346 --> 0.143310).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5634365
	speed: 0.0632s/iter; left time: 1601.3158s
	iters: 200, epoch: 5 | loss: 29.4076900
	speed: 0.0572s/iter; left time: 1443.3360s
Epoch: 5 cost time: 15.652804851531982
Epoch: 5, Steps: 265 Train Loss: 29.6718 (Forecasting Loss:0.1903 + XiCon Loss:2.9482 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0950
Validation loss decreased (0.143310 --> 0.142109).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2313156
	speed: 0.0648s/iter; left time: 1624.5657s
	iters: 200, epoch: 6 | loss: 29.4849720
	speed: 0.0619s/iter; left time: 1544.9106s
Epoch: 6 cost time: 16.60973882675171
Epoch: 6, Steps: 265 Train Loss: 29.6621 (Forecasting Loss:0.1898 + XiCon Loss:2.9472 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.142109 --> 0.141620).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.2944126
	speed: 0.0599s/iter; left time: 1485.9606s
	iters: 200, epoch: 7 | loss: 29.1042290
	speed: 0.0631s/iter; left time: 1559.6697s
Epoch: 7 cost time: 16.590480089187622
Epoch: 7, Steps: 265 Train Loss: 29.6599 (Forecasting Loss:0.1896 + XiCon Loss:2.9470 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.4273968
	speed: 0.0619s/iter; left time: 1519.6588s
	iters: 200, epoch: 8 | loss: 29.9271774
	speed: 0.0554s/iter; left time: 1354.6565s
Epoch: 8 cost time: 15.472790956497192
Epoch: 8, Steps: 265 Train Loss: 29.7038 (Forecasting Loss:0.1893 + XiCon Loss:2.9514 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1237774
	speed: 0.0658s/iter; left time: 1597.6232s
	iters: 200, epoch: 9 | loss: 29.5114517
	speed: 0.0660s/iter; left time: 1595.8600s
Epoch: 9 cost time: 17.3761990070343
Epoch: 9, Steps: 265 Train Loss: 29.6170 (Forecasting Loss:0.1894 + XiCon Loss:2.9428 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1212788
	speed: 0.0629s/iter; left time: 1510.2973s
	iters: 200, epoch: 10 | loss: 30.2076263
	speed: 0.0581s/iter; left time: 1389.5519s
Epoch: 10 cost time: 16.13247060775757
Epoch: 10, Steps: 265 Train Loss: 29.6047 (Forecasting Loss:0.1893 + XiCon Loss:2.9415 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4598083
	speed: 0.0674s/iter; left time: 1601.1281s
	iters: 200, epoch: 11 | loss: 29.8273525
	speed: 0.0513s/iter; left time: 1214.1073s
Epoch: 11 cost time: 15.946750164031982
Epoch: 11, Steps: 265 Train Loss: 29.6522 (Forecasting Loss:0.1893 + XiCon Loss:2.9463 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.3785686
	speed: 0.0672s/iter; left time: 1578.0316s
	iters: 200, epoch: 12 | loss: 31.0592976
	speed: 0.0607s/iter; left time: 1420.2039s
Epoch: 12 cost time: 16.584672212600708
Epoch: 12, Steps: 265 Train Loss: 29.6770 (Forecasting Loss:0.1893 + XiCon Loss:2.9488 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.9582996
	speed: 0.0613s/iter; left time: 1422.6402s
	iters: 200, epoch: 13 | loss: 30.0542049
	speed: 0.0615s/iter; left time: 1421.0838s
Epoch: 13 cost time: 15.733237504959106
Epoch: 13, Steps: 265 Train Loss: 29.5607 (Forecasting Loss:0.1892 + XiCon Loss:2.9372 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141620 --> 0.141521).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1836491
	speed: 0.0567s/iter; left time: 1301.9245s
	iters: 200, epoch: 14 | loss: 30.8548183
	speed: 0.0585s/iter; left time: 1337.6437s
Epoch: 14 cost time: 15.413660287857056
Epoch: 14, Steps: 265 Train Loss: 29.5685 (Forecasting Loss:0.1893 + XiCon Loss:2.9379 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4938126
	speed: 0.0637s/iter; left time: 1445.9895s
	iters: 200, epoch: 15 | loss: 29.0290203
	speed: 0.0617s/iter; left time: 1393.2379s
Epoch: 15 cost time: 16.458722352981567
Epoch: 15, Steps: 265 Train Loss: 29.6776 (Forecasting Loss:0.1892 + XiCon Loss:2.9488 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.3159790
	speed: 0.0671s/iter; left time: 1504.3871s
	iters: 200, epoch: 16 | loss: 31.9816875
	speed: 0.0589s/iter; left time: 1314.3814s
Epoch: 16 cost time: 16.216378927230835
Epoch: 16, Steps: 265 Train Loss: 29.5541 (Forecasting Loss:0.1892 + XiCon Loss:2.9365 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.4745693
	speed: 0.0645s/iter; left time: 1429.0207s
	iters: 200, epoch: 17 | loss: 29.5853214
	speed: 0.0573s/iter; left time: 1263.6060s
Epoch: 17 cost time: 16.266100883483887
Epoch: 17, Steps: 265 Train Loss: 29.6017 (Forecasting Loss:0.1891 + XiCon Loss:2.9413 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6304874
	speed: 0.0633s/iter; left time: 1386.0606s
	iters: 200, epoch: 18 | loss: 30.9392395
	speed: 0.0606s/iter; left time: 1320.8939s
Epoch: 18 cost time: 16.294123649597168
Epoch: 18, Steps: 265 Train Loss: 29.5595 (Forecasting Loss:0.1891 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.1773357
	speed: 0.0654s/iter; left time: 1413.8296s
	iters: 200, epoch: 19 | loss: 29.2134991
	speed: 0.0595s/iter; left time: 1280.2837s
Epoch: 19 cost time: 16.730419874191284
Epoch: 19, Steps: 265 Train Loss: 29.5708 (Forecasting Loss:0.1892 + XiCon Loss:2.9382 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.1550922
	speed: 0.0652s/iter; left time: 1392.8810s
	iters: 200, epoch: 20 | loss: 31.0391769
	speed: 0.0611s/iter; left time: 1298.7529s
Epoch: 20 cost time: 16.38656735420227
Epoch: 20, Steps: 265 Train Loss: 29.7013 (Forecasting Loss:0.1891 + XiCon Loss:2.9512 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.0943813
	speed: 0.0585s/iter; left time: 1233.5223s
	iters: 200, epoch: 21 | loss: 29.7345829
	speed: 0.0628s/iter; left time: 1319.6481s
Epoch: 21 cost time: 16.686070919036865
Epoch: 21, Steps: 265 Train Loss: 29.6610 (Forecasting Loss:0.1893 + XiCon Loss:2.9472 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.7353001
	speed: 0.0627s/iter; left time: 1307.1897s
	iters: 200, epoch: 22 | loss: 29.8303337
	speed: 0.0581s/iter; left time: 1205.1683s
Epoch: 22 cost time: 15.847394227981567
Epoch: 22, Steps: 265 Train Loss: 29.6036 (Forecasting Loss:0.1892 + XiCon Loss:2.9414 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.6875038
	speed: 0.0648s/iter; left time: 1332.6105s
	iters: 200, epoch: 23 | loss: 28.6275406
	speed: 0.0651s/iter; left time: 1332.2551s
Epoch: 23 cost time: 16.664870977401733
Epoch: 23, Steps: 265 Train Loss: 29.6787 (Forecasting Loss:0.1893 + XiCon Loss:2.9489 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03937198221683502, mae:0.1495266854763031, mape:0.1186683177947998, mspe:0.026329241693019867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.8727
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.4779072
	speed: 0.0619s/iter; left time: 1633.0594s
	iters: 200, epoch: 1 | loss: 29.7826805
	speed: 0.0624s/iter; left time: 1640.6058s
Epoch: 1 cost time: 16.046133518218994
Epoch: 1, Steps: 265 Train Loss: 30.4924 (Forecasting Loss:0.2100 + XiCon Loss:3.0282 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.0976
Validation loss decreased (inf --> 0.147931).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.1075783
	speed: 0.0624s/iter; left time: 1630.9849s
	iters: 200, epoch: 2 | loss: 30.9094200
	speed: 0.0606s/iter; left time: 1577.7366s
Epoch: 2 cost time: 15.887089252471924
Epoch: 2, Steps: 265 Train Loss: 31.0449 (Forecasting Loss:0.1983 + XiCon Loss:3.0847 x Lambda(10.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0979
Validation loss decreased (0.147931 --> 0.146337).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.0178719
	speed: 0.0630s/iter; left time: 1628.5826s
	iters: 200, epoch: 3 | loss: 30.2112637
	speed: 0.0646s/iter; left time: 1665.4197s
Epoch: 3 cost time: 16.951432704925537
Epoch: 3, Steps: 265 Train Loss: 29.8110 (Forecasting Loss:0.1935 + XiCon Loss:2.9617 x Lambda(10.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0957
Validation loss decreased (0.146337 --> 0.143482).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.6277199
	speed: 0.0620s/iter; left time: 1587.0510s
	iters: 200, epoch: 4 | loss: 28.9602928
	speed: 0.0603s/iter; left time: 1539.0619s
Epoch: 4 cost time: 16.287699222564697
Epoch: 4, Steps: 265 Train Loss: 29.5994 (Forecasting Loss:0.1910 + XiCon Loss:2.9408 x Lambda(10.0)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.0953
Validation loss decreased (0.143482 --> 0.142920).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.5205173
	speed: 0.0669s/iter; left time: 1696.1178s
	iters: 200, epoch: 5 | loss: 29.4745636
	speed: 0.0630s/iter; left time: 1590.8420s
Epoch: 5 cost time: 17.032684564590454
Epoch: 5, Steps: 265 Train Loss: 29.4947 (Forecasting Loss:0.1900 + XiCon Loss:2.9305 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
Validation loss decreased (0.142920 --> 0.141878).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6857262
	speed: 0.0612s/iter; left time: 1533.7330s
	iters: 200, epoch: 6 | loss: 31.0466709
	speed: 0.0599s/iter; left time: 1495.0244s
Epoch: 6 cost time: 15.694474220275879
Epoch: 6, Steps: 265 Train Loss: 29.4634 (Forecasting Loss:0.1896 + XiCon Loss:2.9274 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4008312
	speed: 0.0712s/iter; left time: 1767.2218s
	iters: 200, epoch: 7 | loss: 29.5297451
	speed: 0.0585s/iter; left time: 1445.0761s
Epoch: 7 cost time: 16.78445076942444
Epoch: 7, Steps: 265 Train Loss: 29.4982 (Forecasting Loss:0.1893 + XiCon Loss:2.9309 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141878 --> 0.141733).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2057476
	speed: 0.0640s/iter; left time: 1570.9602s
	iters: 200, epoch: 8 | loss: 29.5885487
	speed: 0.0606s/iter; left time: 1482.2661s
Epoch: 8 cost time: 16.348625898361206
Epoch: 8, Steps: 265 Train Loss: 29.4345 (Forecasting Loss:0.1892 + XiCon Loss:2.9245 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8047562
	speed: 0.0652s/iter; left time: 1584.1121s
	iters: 200, epoch: 9 | loss: 30.1987381
	speed: 0.0618s/iter; left time: 1493.3994s
Epoch: 9 cost time: 16.562570810317993
Epoch: 9, Steps: 265 Train Loss: 29.5344 (Forecasting Loss:0.1891 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141733 --> 0.141478).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0696163
	speed: 0.0677s/iter; left time: 1626.1058s
	iters: 200, epoch: 10 | loss: 29.2239475
	speed: 0.0599s/iter; left time: 1431.9922s
Epoch: 10 cost time: 16.6656813621521
Epoch: 10, Steps: 265 Train Loss: 29.5350 (Forecasting Loss:0.1889 + XiCon Loss:2.9346 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0465717
	speed: 0.0633s/iter; left time: 1503.7173s
	iters: 200, epoch: 11 | loss: 29.2539597
	speed: 0.0477s/iter; left time: 1128.5615s
Epoch: 11 cost time: 14.431874752044678
Epoch: 11, Steps: 265 Train Loss: 29.4865 (Forecasting Loss:0.1890 + XiCon Loss:2.9298 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6105766
	speed: 0.0621s/iter; left time: 1459.0158s
	iters: 200, epoch: 12 | loss: 29.6770039
	speed: 0.0576s/iter; left time: 1346.2251s
Epoch: 12 cost time: 15.936187028884888
Epoch: 12, Steps: 265 Train Loss: 29.4937 (Forecasting Loss:0.1890 + XiCon Loss:2.9305 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0852585
	speed: 0.0663s/iter; left time: 1538.8077s
	iters: 200, epoch: 13 | loss: 30.9303150
	speed: 0.0598s/iter; left time: 1382.8411s
Epoch: 13 cost time: 16.918755054473877
Epoch: 13, Steps: 265 Train Loss: 29.5474 (Forecasting Loss:0.1891 + XiCon Loss:2.9358 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.7663078
	speed: 0.0611s/iter; left time: 1401.8321s
	iters: 200, epoch: 14 | loss: 31.0534420
	speed: 0.0594s/iter; left time: 1357.9783s
Epoch: 14 cost time: 15.999269485473633
Epoch: 14, Steps: 265 Train Loss: 29.4505 (Forecasting Loss:0.1890 + XiCon Loss:2.9261 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.6504974
	speed: 0.0610s/iter; left time: 1383.6882s
	iters: 200, epoch: 15 | loss: 30.2171764
	speed: 0.0625s/iter; left time: 1411.5266s
Epoch: 15 cost time: 16.479291200637817
Epoch: 15, Steps: 265 Train Loss: 29.4384 (Forecasting Loss:0.1890 + XiCon Loss:2.9249 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.2371922
	speed: 0.0626s/iter; left time: 1404.0202s
	iters: 200, epoch: 16 | loss: 29.0614777
	speed: 0.0620s/iter; left time: 1384.0006s
Epoch: 16 cost time: 16.55471181869507
Epoch: 16, Steps: 265 Train Loss: 29.4849 (Forecasting Loss:0.1889 + XiCon Loss:2.9296 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.3014107
	speed: 0.0628s/iter; left time: 1391.1861s
	iters: 200, epoch: 17 | loss: 28.8346195
	speed: 0.0611s/iter; left time: 1347.4719s
Epoch: 17 cost time: 16.29078960418701
Epoch: 17, Steps: 265 Train Loss: 29.4585 (Forecasting Loss:0.1890 + XiCon Loss:2.9270 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.1861134
	speed: 0.0631s/iter; left time: 1381.3296s
	iters: 200, epoch: 18 | loss: 28.3903542
	speed: 0.0618s/iter; left time: 1346.6067s
Epoch: 18 cost time: 16.54854440689087
Epoch: 18, Steps: 265 Train Loss: 29.4314 (Forecasting Loss:0.1891 + XiCon Loss:2.9242 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.9830856
	speed: 0.0610s/iter; left time: 1319.8493s
	iters: 200, epoch: 19 | loss: 29.6299229
	speed: 0.0637s/iter; left time: 1371.3896s
Epoch: 19 cost time: 16.34708309173584
Epoch: 19, Steps: 265 Train Loss: 29.4833 (Forecasting Loss:0.1890 + XiCon Loss:2.9294 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03936275094747543, mae:0.14949454367160797, mape:0.11878084391355515, mspe:0.026421228423714638 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.3429
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.5234509
	speed: 0.0634s/iter; left time: 1673.6121s
	iters: 200, epoch: 1 | loss: 29.8507614
	speed: 0.0623s/iter; left time: 1637.3140s
Epoch: 1 cost time: 15.499979496002197
Epoch: 1, Steps: 265 Train Loss: 30.3972 (Forecasting Loss:0.2113 + XiCon Loss:3.0186 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.146442).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.6045132
	speed: 0.0680s/iter; left time: 1777.1206s
	iters: 200, epoch: 2 | loss: 30.0989037
	speed: 0.0628s/iter; left time: 1635.4449s
Epoch: 2 cost time: 17.178834199905396
Epoch: 2, Steps: 265 Train Loss: 31.1897 (Forecasting Loss:0.1984 + XiCon Loss:3.0991 x Lambda(10.0)), Vali MSE Loss: 0.1471 Test MSE Loss: 0.0986
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8208675
	speed: 0.0634s/iter; left time: 1640.2569s
	iters: 200, epoch: 3 | loss: 30.2579155
	speed: 0.0645s/iter; left time: 1663.1126s
Epoch: 3 cost time: 16.62774682044983
Epoch: 3, Steps: 265 Train Loss: 30.6898 (Forecasting Loss:0.1927 + XiCon Loss:3.0497 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0980
Validation loss decreased (0.146442 --> 0.143850).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1108131
	speed: 0.0630s/iter; left time: 1612.7811s
	iters: 200, epoch: 4 | loss: 29.2212696
	speed: 0.0598s/iter; left time: 1524.1986s
Epoch: 4 cost time: 16.127805709838867
Epoch: 4, Steps: 265 Train Loss: 30.2331 (Forecasting Loss:0.1909 + XiCon Loss:3.0042 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0966
Validation loss decreased (0.143850 --> 0.142124).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4181957
	speed: 0.0654s/iter; left time: 1657.5839s
	iters: 200, epoch: 5 | loss: 29.6696186
	speed: 0.0601s/iter; left time: 1516.3380s
Epoch: 5 cost time: 16.80485510826111
Epoch: 5, Steps: 265 Train Loss: 29.8448 (Forecasting Loss:0.1897 + XiCon Loss:2.9655 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0973
Validation loss decreased (0.142124 --> 0.142003).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5150032
	speed: 0.0584s/iter; left time: 1463.9786s
	iters: 200, epoch: 6 | loss: 28.8382282
	speed: 0.0588s/iter; left time: 1469.6076s
Epoch: 6 cost time: 15.697493076324463
Epoch: 6, Steps: 265 Train Loss: 29.6146 (Forecasting Loss:0.1891 + XiCon Loss:2.9425 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0969
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.3914757
	speed: 0.0650s/iter; left time: 1611.6721s
	iters: 200, epoch: 7 | loss: 29.6622581
	speed: 0.0614s/iter; left time: 1518.2872s
Epoch: 7 cost time: 16.482553482055664
Epoch: 7, Steps: 265 Train Loss: 29.5992 (Forecasting Loss:0.1888 + XiCon Loss:2.9410 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0970
Validation loss decreased (0.142003 --> 0.141734).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9448776
	speed: 0.0614s/iter; left time: 1507.1471s
	iters: 200, epoch: 8 | loss: 29.0835762
	speed: 0.0609s/iter; left time: 1487.8193s
Epoch: 8 cost time: 16.166396856307983
Epoch: 8, Steps: 265 Train Loss: 29.6177 (Forecasting Loss:0.1887 + XiCon Loss:2.9429 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7764168
	speed: 0.0656s/iter; left time: 1592.8393s
	iters: 200, epoch: 9 | loss: 30.6237030
	speed: 0.0596s/iter; left time: 1441.1742s
Epoch: 9 cost time: 16.558937788009644
Epoch: 9, Steps: 265 Train Loss: 29.6144 (Forecasting Loss:0.1886 + XiCon Loss:2.9426 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0969
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7252121
	speed: 0.0602s/iter; left time: 1446.3133s
	iters: 200, epoch: 10 | loss: 29.8853722
	speed: 0.0648s/iter; left time: 1550.4917s
Epoch: 10 cost time: 16.58226180076599
Epoch: 10, Steps: 265 Train Loss: 29.5045 (Forecasting Loss:0.1887 + XiCon Loss:2.9316 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8931370
	speed: 0.0661s/iter; left time: 1571.0672s
	iters: 200, epoch: 11 | loss: 30.6117134
	speed: 0.0611s/iter; left time: 1444.2673s
Epoch: 11 cost time: 16.52152991294861
Epoch: 11, Steps: 265 Train Loss: 29.6152 (Forecasting Loss:0.1886 + XiCon Loss:2.9427 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
Validation loss decreased (0.141734 --> 0.141727).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.1471119
	speed: 0.0622s/iter; left time: 1460.0669s
	iters: 200, epoch: 12 | loss: 28.4088020
	speed: 0.0599s/iter; left time: 1401.6356s
Epoch: 12 cost time: 15.972507238388062
Epoch: 12, Steps: 265 Train Loss: 29.5937 (Forecasting Loss:0.1885 + XiCon Loss:2.9405 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.1357574
	speed: 0.0610s/iter; left time: 1415.6960s
	iters: 200, epoch: 13 | loss: 30.4961548
	speed: 0.0461s/iter; left time: 1065.1403s
Epoch: 13 cost time: 14.706088781356812
Epoch: 13, Steps: 265 Train Loss: 29.5248 (Forecasting Loss:0.1885 + XiCon Loss:2.9336 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
Validation loss decreased (0.141727 --> 0.141665).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.7844982
	speed: 0.0600s/iter; left time: 1376.8489s
	iters: 200, epoch: 14 | loss: 30.8018684
	speed: 0.0593s/iter; left time: 1355.1091s
Epoch: 14 cost time: 15.661413669586182
Epoch: 14, Steps: 265 Train Loss: 29.5738 (Forecasting Loss:0.1886 + XiCon Loss:2.9385 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.1855812
	speed: 0.0637s/iter; left time: 1446.5240s
	iters: 200, epoch: 15 | loss: 29.1063023
	speed: 0.0621s/iter; left time: 1402.5144s
Epoch: 15 cost time: 16.414416790008545
Epoch: 15, Steps: 265 Train Loss: 29.5569 (Forecasting Loss:0.1886 + XiCon Loss:2.9368 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0968
Validation loss decreased (0.141665 --> 0.141634).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9495335
	speed: 0.0613s/iter; left time: 1373.6473s
	iters: 200, epoch: 16 | loss: 31.1002369
	speed: 0.0602s/iter; left time: 1344.5780s
Epoch: 16 cost time: 16.41516923904419
Epoch: 16, Steps: 265 Train Loss: 29.5941 (Forecasting Loss:0.1885 + XiCon Loss:2.9406 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5883179
	speed: 0.0610s/iter; left time: 1351.1331s
	iters: 200, epoch: 17 | loss: 28.6551456
	speed: 0.0688s/iter; left time: 1518.3976s
Epoch: 17 cost time: 17.139910459518433
Epoch: 17, Steps: 265 Train Loss: 29.4753 (Forecasting Loss:0.1884 + XiCon Loss:2.9287 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.9634476
	speed: 0.0647s/iter; left time: 1417.0085s
	iters: 200, epoch: 18 | loss: 29.3300095
	speed: 0.0627s/iter; left time: 1366.9721s
Epoch: 18 cost time: 16.550976991653442
Epoch: 18, Steps: 265 Train Loss: 29.6222 (Forecasting Loss:0.1885 + XiCon Loss:2.9434 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8369122
	speed: 0.0604s/iter; left time: 1306.7650s
	iters: 200, epoch: 19 | loss: 28.5983028
	speed: 0.0650s/iter; left time: 1400.5022s
Epoch: 19 cost time: 16.510156393051147
Epoch: 19, Steps: 265 Train Loss: 29.6253 (Forecasting Loss:0.1886 + XiCon Loss:2.9437 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.4212818
	speed: 0.0631s/iter; left time: 1348.4594s
	iters: 200, epoch: 20 | loss: 29.0834904
	speed: 0.0623s/iter; left time: 1325.1194s
Epoch: 20 cost time: 16.19474744796753
Epoch: 20, Steps: 265 Train Loss: 29.5334 (Forecasting Loss:0.1884 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0968
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.9644070
	speed: 0.0690s/iter; left time: 1456.6271s
	iters: 200, epoch: 21 | loss: 28.4957733
	speed: 0.0646s/iter; left time: 1355.6473s
Epoch: 21 cost time: 17.274717092514038
Epoch: 21, Steps: 265 Train Loss: 29.4661 (Forecasting Loss:0.1886 + XiCon Loss:2.9278 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0968
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.0163689
	speed: 0.0642s/iter; left time: 1337.2440s
	iters: 200, epoch: 22 | loss: 29.7862339
	speed: 0.0617s/iter; left time: 1279.8483s
Epoch: 22 cost time: 16.790740251541138
Epoch: 22, Steps: 265 Train Loss: 29.6215 (Forecasting Loss:0.1886 + XiCon Loss:2.9433 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.1740513
	speed: 0.0669s/iter; left time: 1375.3637s
	iters: 200, epoch: 23 | loss: 29.4000530
	speed: 0.0607s/iter; left time: 1243.5992s
Epoch: 23 cost time: 16.592239141464233
Epoch: 23, Steps: 265 Train Loss: 29.5972 (Forecasting Loss:0.1885 + XiCon Loss:2.9409 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0968
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.2734108
	speed: 0.0650s/iter; left time: 1319.2643s
	iters: 200, epoch: 24 | loss: 28.7227993
	speed: 0.0621s/iter; left time: 1255.6545s
Epoch: 24 cost time: 16.717033863067627
Epoch: 24, Steps: 265 Train Loss: 29.5496 (Forecasting Loss:0.1885 + XiCon Loss:2.9361 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0968
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 28.3346615
	speed: 0.0683s/iter; left time: 1369.6054s
	iters: 200, epoch: 25 | loss: 29.7113113
	speed: 0.0561s/iter; left time: 1118.9158s
Epoch: 25 cost time: 16.26613140106201
Epoch: 25, Steps: 265 Train Loss: 29.5296 (Forecasting Loss:0.1886 + XiCon Loss:2.9341 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0968
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04226180166006088, mae:0.15140439569950104, mape:0.11998774856328964, mspe:0.027615655213594437 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.6092
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.7555084
	speed: 0.0616s/iter; left time: 1625.4725s
	iters: 200, epoch: 1 | loss: 29.5497189
	speed: 0.0564s/iter; left time: 1483.0192s
Epoch: 1 cost time: 15.570274829864502
Epoch: 1, Steps: 265 Train Loss: 30.6318 (Forecasting Loss:0.2106 + XiCon Loss:3.0421 x Lambda(10.0)), Vali MSE Loss: 0.1491 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.149108).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.5521011
	speed: 0.0614s/iter; left time: 1605.7286s
	iters: 200, epoch: 2 | loss: 29.9780197
	speed: 0.0601s/iter; left time: 1564.6193s
Epoch: 2 cost time: 16.358399629592896
Epoch: 2, Steps: 265 Train Loss: 31.0741 (Forecasting Loss:0.1984 + XiCon Loss:3.0876 x Lambda(10.0)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.0973
Validation loss decreased (0.149108 --> 0.147198).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7143898
	speed: 0.0615s/iter; left time: 1590.8006s
	iters: 200, epoch: 3 | loss: 28.7194633
	speed: 0.0578s/iter; left time: 1490.8001s
Epoch: 3 cost time: 15.812963247299194
Epoch: 3, Steps: 265 Train Loss: 29.5860 (Forecasting Loss:0.1932 + XiCon Loss:2.9393 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0966
Validation loss decreased (0.147198 --> 0.143942).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7876472
	speed: 0.0593s/iter; left time: 1518.2626s
	iters: 200, epoch: 4 | loss: 29.8585300
	speed: 0.0619s/iter; left time: 1578.4550s
Epoch: 4 cost time: 16.556682109832764
Epoch: 4, Steps: 265 Train Loss: 29.4393 (Forecasting Loss:0.1909 + XiCon Loss:2.9248 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0953
Validation loss decreased (0.143942 --> 0.142490).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8810673
	speed: 0.0605s/iter; left time: 1532.9549s
	iters: 200, epoch: 5 | loss: 28.6005306
	speed: 0.0651s/iter; left time: 1644.1173s
Epoch: 5 cost time: 16.692002534866333
Epoch: 5, Steps: 265 Train Loss: 29.4557 (Forecasting Loss:0.1897 + XiCon Loss:2.9266 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0953
Validation loss decreased (0.142490 --> 0.142337).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.5700321
	speed: 0.0674s/iter; left time: 1689.6760s
	iters: 200, epoch: 6 | loss: 28.9342976
	speed: 0.0676s/iter; left time: 1687.5489s
Epoch: 6 cost time: 17.648678302764893
Epoch: 6, Steps: 265 Train Loss: 29.3732 (Forecasting Loss:0.1890 + XiCon Loss:2.9184 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0956
Validation loss decreased (0.142337 --> 0.142097).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.0842476
	speed: 0.0549s/iter; left time: 1361.9269s
	iters: 200, epoch: 7 | loss: 28.5789261
	speed: 0.0655s/iter; left time: 1619.1277s
Epoch: 7 cost time: 16.190133094787598
Epoch: 7, Steps: 265 Train Loss: 29.4278 (Forecasting Loss:0.1889 + XiCon Loss:2.9239 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
Validation loss decreased (0.142097 --> 0.141791).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.4353256
	speed: 0.0617s/iter; left time: 1515.2016s
	iters: 200, epoch: 8 | loss: 30.2085762
	speed: 0.0578s/iter; left time: 1413.9971s
Epoch: 8 cost time: 15.710064888000488
Epoch: 8, Steps: 265 Train Loss: 29.3637 (Forecasting Loss:0.1887 + XiCon Loss:2.9175 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0955
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.7776146
	speed: 0.0621s/iter; left time: 1507.4145s
	iters: 200, epoch: 9 | loss: 28.5619850
	speed: 0.0590s/iter; left time: 1426.2939s
Epoch: 9 cost time: 15.191540956497192
Epoch: 9, Steps: 265 Train Loss: 29.4048 (Forecasting Loss:0.1886 + XiCon Loss:2.9216 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0070438
	speed: 0.0565s/iter; left time: 1357.8909s
	iters: 200, epoch: 10 | loss: 28.6280136
	speed: 0.0602s/iter; left time: 1439.3486s
Epoch: 10 cost time: 15.797233581542969
Epoch: 10, Steps: 265 Train Loss: 29.3629 (Forecasting Loss:0.1884 + XiCon Loss:2.9174 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.8661728
	speed: 0.0640s/iter; left time: 1518.9302s
	iters: 200, epoch: 11 | loss: 29.5185738
	speed: 0.0615s/iter; left time: 1454.6591s
Epoch: 11 cost time: 16.718084573745728
Epoch: 11, Steps: 265 Train Loss: 29.4494 (Forecasting Loss:0.1884 + XiCon Loss:2.9261 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.8267765
	speed: 0.0501s/iter; left time: 1176.7327s
	iters: 200, epoch: 12 | loss: 29.7057800
	speed: 0.0575s/iter; left time: 1343.9787s
Epoch: 12 cost time: 14.838344097137451
Epoch: 12, Steps: 265 Train Loss: 29.4418 (Forecasting Loss:0.1884 + XiCon Loss:2.9253 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0954
Validation loss decreased (0.141791 --> 0.141746).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2586460
	speed: 0.0623s/iter; left time: 1446.9615s
	iters: 200, epoch: 13 | loss: 29.9237366
	speed: 0.0583s/iter; left time: 1346.8954s
Epoch: 13 cost time: 15.801869869232178
Epoch: 13, Steps: 265 Train Loss: 29.3658 (Forecasting Loss:0.1884 + XiCon Loss:2.9177 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.8602295
	speed: 0.0686s/iter; left time: 1575.1464s
	iters: 200, epoch: 14 | loss: 29.0651646
	speed: 0.0616s/iter; left time: 1407.7097s
Epoch: 14 cost time: 16.924440383911133
Epoch: 14, Steps: 265 Train Loss: 29.3379 (Forecasting Loss:0.1884 + XiCon Loss:2.9149 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4418316
	speed: 0.0618s/iter; left time: 1401.3228s
	iters: 200, epoch: 15 | loss: 29.0350971
	speed: 0.0569s/iter; left time: 1284.4027s
Epoch: 15 cost time: 16.147854566574097
Epoch: 15, Steps: 265 Train Loss: 29.4480 (Forecasting Loss:0.1883 + XiCon Loss:2.9260 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0954
Validation loss decreased (0.141746 --> 0.141735).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.2156982
	speed: 0.0682s/iter; left time: 1529.5008s
	iters: 200, epoch: 16 | loss: 28.8354435
	speed: 0.0623s/iter; left time: 1390.2474s
Epoch: 16 cost time: 16.92299461364746
Epoch: 16, Steps: 265 Train Loss: 29.3648 (Forecasting Loss:0.1884 + XiCon Loss:2.9176 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0954
Validation loss decreased (0.141735 --> 0.141687).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.1293392
	speed: 0.0662s/iter; left time: 1467.0006s
	iters: 200, epoch: 17 | loss: 29.1258278
	speed: 0.0592s/iter; left time: 1306.1405s
Epoch: 17 cost time: 16.66301727294922
Epoch: 17, Steps: 265 Train Loss: 29.3244 (Forecasting Loss:0.1885 + XiCon Loss:2.9136 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.9186459
	speed: 0.0660s/iter; left time: 1444.1398s
	iters: 200, epoch: 18 | loss: 30.8377209
	speed: 0.0577s/iter; left time: 1258.2927s
Epoch: 18 cost time: 16.437761545181274
Epoch: 18, Steps: 265 Train Loss: 29.4130 (Forecasting Loss:0.1884 + XiCon Loss:2.9225 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7633381
	speed: 0.0631s/iter; left time: 1364.8916s
	iters: 200, epoch: 19 | loss: 30.1741009
	speed: 0.0570s/iter; left time: 1227.8028s
Epoch: 19 cost time: 15.90311574935913
Epoch: 19, Steps: 265 Train Loss: 29.4039 (Forecasting Loss:0.1884 + XiCon Loss:2.9215 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.1961021
	speed: 0.0634s/iter; left time: 1353.7181s
	iters: 200, epoch: 20 | loss: 29.5110550
	speed: 0.0600s/iter; left time: 1276.5443s
Epoch: 20 cost time: 16.5182101726532
Epoch: 20, Steps: 265 Train Loss: 29.3970 (Forecasting Loss:0.1885 + XiCon Loss:2.9208 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.3601971
	speed: 0.0641s/iter; left time: 1352.6592s
	iters: 200, epoch: 21 | loss: 28.6336250
	speed: 0.0566s/iter; left time: 1187.9535s
Epoch: 21 cost time: 16.39498734474182
Epoch: 21, Steps: 265 Train Loss: 29.3397 (Forecasting Loss:0.1884 + XiCon Loss:2.9151 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.5686283
	speed: 0.0641s/iter; left time: 1336.0344s
	iters: 200, epoch: 22 | loss: 28.7443123
	speed: 0.0599s/iter; left time: 1242.7566s
Epoch: 22 cost time: 16.16776943206787
Epoch: 22, Steps: 265 Train Loss: 29.3731 (Forecasting Loss:0.1883 + XiCon Loss:2.9185 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.9066601
	speed: 0.0602s/iter; left time: 1237.6579s
	iters: 200, epoch: 23 | loss: 28.3524189
	speed: 0.0623s/iter; left time: 1274.3297s
Epoch: 23 cost time: 16.78494358062744
Epoch: 23, Steps: 265 Train Loss: 29.3922 (Forecasting Loss:0.1885 + XiCon Loss:2.9204 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.7879982
	speed: 0.0614s/iter; left time: 1247.5338s
	iters: 200, epoch: 24 | loss: 29.2878399
	speed: 0.0611s/iter; left time: 1235.2583s
Epoch: 24 cost time: 16.240484714508057
Epoch: 24, Steps: 265 Train Loss: 29.3854 (Forecasting Loss:0.1885 + XiCon Loss:2.9197 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.2422714
	speed: 0.0669s/iter; left time: 1339.9088s
	iters: 200, epoch: 25 | loss: 29.5083466
	speed: 0.0609s/iter; left time: 1214.0854s
Epoch: 25 cost time: 17.01451849937439
Epoch: 25, Steps: 265 Train Loss: 29.3939 (Forecasting Loss:0.1885 + XiCon Loss:2.9205 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.8687611
	speed: 0.0581s/iter; left time: 1148.8431s
	iters: 200, epoch: 26 | loss: 30.4624977
	speed: 0.0570s/iter; left time: 1121.0490s
Epoch: 26 cost time: 15.799124240875244
Epoch: 26, Steps: 265 Train Loss: 29.3824 (Forecasting Loss:0.1885 + XiCon Loss:2.9194 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0954
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039888471364974976, mae:0.15100185573101044, mape:0.11975757032632828, mspe:0.02661745995283127 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.9716
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.9316330
	speed: 0.0623s/iter; left time: 1645.7669s
	iters: 200, epoch: 1 | loss: 30.0973568
	speed: 0.0555s/iter; left time: 1460.9070s
Epoch: 1 cost time: 15.672072887420654
Epoch: 1, Steps: 265 Train Loss: 30.6558 (Forecasting Loss:0.2107 + XiCon Loss:3.0445 x Lambda(10.0)), Vali MSE Loss: 0.1498 Test MSE Loss: 0.0987
Validation loss decreased (inf --> 0.149831).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.4723701
	speed: 0.0598s/iter; left time: 1562.2689s
	iters: 200, epoch: 2 | loss: 29.3624897
	speed: 0.0659s/iter; left time: 1715.5109s
Epoch: 2 cost time: 16.3615939617157
Epoch: 2, Steps: 265 Train Loss: 31.2684 (Forecasting Loss:0.1981 + XiCon Loss:3.1070 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0964
Validation loss decreased (0.149831 --> 0.145677).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.0570621
	speed: 0.0620s/iter; left time: 1602.8663s
	iters: 200, epoch: 3 | loss: 29.1728344
	speed: 0.0603s/iter; left time: 1553.8827s
Epoch: 3 cost time: 16.198211431503296
Epoch: 3, Steps: 265 Train Loss: 30.1131 (Forecasting Loss:0.1935 + XiCon Loss:2.9920 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0958
Validation loss decreased (0.145677 --> 0.143673).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.4745464
	speed: 0.0632s/iter; left time: 1619.4452s
	iters: 200, epoch: 4 | loss: 29.2729015
	speed: 0.0646s/iter; left time: 1648.6611s
Epoch: 4 cost time: 17.089457511901855
Epoch: 4, Steps: 265 Train Loss: 30.1040 (Forecasting Loss:0.1913 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0952
Validation loss decreased (0.143673 --> 0.142335).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7845325
	speed: 0.0582s/iter; left time: 1474.3145s
	iters: 200, epoch: 5 | loss: 29.6030121
	speed: 0.0616s/iter; left time: 1554.9549s
Epoch: 5 cost time: 15.708442211151123
Epoch: 5, Steps: 265 Train Loss: 30.0417 (Forecasting Loss:0.1903 + XiCon Loss:2.9851 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
Validation loss decreased (0.142335 --> 0.141997).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6795101
	speed: 0.0608s/iter; left time: 1525.5420s
	iters: 200, epoch: 6 | loss: 31.6901360
	speed: 0.0597s/iter; left time: 1489.8739s
Epoch: 6 cost time: 15.82431173324585
Epoch: 6, Steps: 265 Train Loss: 29.9718 (Forecasting Loss:0.1899 + XiCon Loss:2.9782 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141997 --> 0.141794).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0835438
	speed: 0.0517s/iter; left time: 1283.0739s
	iters: 200, epoch: 7 | loss: 28.7367744
	speed: 0.0607s/iter; left time: 1499.7691s
Epoch: 7 cost time: 14.898025512695312
Epoch: 7, Steps: 265 Train Loss: 29.9409 (Forecasting Loss:0.1896 + XiCon Loss:2.9751 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141794 --> 0.141698).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9872398
	speed: 0.0583s/iter; left time: 1431.5863s
	iters: 200, epoch: 8 | loss: 30.4555683
	speed: 0.0572s/iter; left time: 1399.1359s
Epoch: 8 cost time: 15.341926336288452
Epoch: 8, Steps: 265 Train Loss: 29.9537 (Forecasting Loss:0.1894 + XiCon Loss:2.9764 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6971474
	speed: 0.0709s/iter; left time: 1722.3824s
	iters: 200, epoch: 9 | loss: 29.6625748
	speed: 0.0600s/iter; left time: 1451.8542s
Epoch: 9 cost time: 16.991191625595093
Epoch: 9, Steps: 265 Train Loss: 29.9651 (Forecasting Loss:0.1893 + XiCon Loss:2.9776 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.5590858
	speed: 0.0613s/iter; left time: 1472.9181s
	iters: 200, epoch: 10 | loss: 29.5926704
	speed: 0.0636s/iter; left time: 1521.3707s
Epoch: 10 cost time: 16.274937629699707
Epoch: 10, Steps: 265 Train Loss: 29.9042 (Forecasting Loss:0.1893 + XiCon Loss:2.9715 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.9643536
	speed: 0.0658s/iter; left time: 1563.7185s
	iters: 200, epoch: 11 | loss: 29.7227173
	speed: 0.0590s/iter; left time: 1395.8134s
Epoch: 11 cost time: 16.31493830680847
Epoch: 11, Steps: 265 Train Loss: 29.8886 (Forecasting Loss:0.1893 + XiCon Loss:2.9699 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.9471664
	speed: 0.0682s/iter; left time: 1601.5595s
	iters: 200, epoch: 12 | loss: 30.6445370
	speed: 0.0606s/iter; left time: 1417.5531s
Epoch: 12 cost time: 16.770955801010132
Epoch: 12, Steps: 265 Train Loss: 29.9320 (Forecasting Loss:0.1892 + XiCon Loss:2.9743 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.9063740
	speed: 0.0629s/iter; left time: 1459.7013s
	iters: 200, epoch: 13 | loss: 31.8609066
	speed: 0.0589s/iter; left time: 1362.6008s
Epoch: 13 cost time: 16.11631417274475
Epoch: 13, Steps: 265 Train Loss: 29.9390 (Forecasting Loss:0.1892 + XiCon Loss:2.9750 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.7336388
	speed: 0.0626s/iter; left time: 1436.3562s
	iters: 200, epoch: 14 | loss: 30.5522232
	speed: 0.0585s/iter; left time: 1337.5841s
Epoch: 14 cost time: 16.104342460632324
Epoch: 14, Steps: 265 Train Loss: 29.9438 (Forecasting Loss:0.1892 + XiCon Loss:2.9755 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5851784
	speed: 0.0649s/iter; left time: 1471.9011s
	iters: 200, epoch: 15 | loss: 31.2863636
	speed: 0.0604s/iter; left time: 1363.4947s
Epoch: 15 cost time: 16.29197335243225
Epoch: 15, Steps: 265 Train Loss: 29.9144 (Forecasting Loss:0.1892 + XiCon Loss:2.9725 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141698 --> 0.141661).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.5764256
	speed: 0.0616s/iter; left time: 1380.3603s
	iters: 200, epoch: 16 | loss: 29.3181705
	speed: 0.0600s/iter; left time: 1338.9903s
Epoch: 16 cost time: 16.83315634727478
Epoch: 16, Steps: 265 Train Loss: 29.9624 (Forecasting Loss:0.1893 + XiCon Loss:2.9773 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141661 --> 0.141653).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.4788246
	speed: 0.0600s/iter; left time: 1330.3721s
	iters: 200, epoch: 17 | loss: 31.1028023
	speed: 0.0559s/iter; left time: 1232.7368s
Epoch: 17 cost time: 15.324738025665283
Epoch: 17, Steps: 265 Train Loss: 29.9241 (Forecasting Loss:0.1892 + XiCon Loss:2.9735 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4110794
	speed: 0.0644s/iter; left time: 1411.1065s
	iters: 200, epoch: 18 | loss: 30.1835041
	speed: 0.0654s/iter; left time: 1426.1368s
Epoch: 18 cost time: 17.1060471534729
Epoch: 18, Steps: 265 Train Loss: 29.8983 (Forecasting Loss:0.1892 + XiCon Loss:2.9709 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.8871174
	speed: 0.0643s/iter; left time: 1390.6814s
	iters: 200, epoch: 19 | loss: 29.0224991
	speed: 0.0578s/iter; left time: 1244.6387s
Epoch: 19 cost time: 16.17410397529602
Epoch: 19, Steps: 265 Train Loss: 29.9333 (Forecasting Loss:0.1893 + XiCon Loss:2.9744 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141653 --> 0.141590).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.7737675
	speed: 0.0661s/iter; left time: 1413.1807s
	iters: 200, epoch: 20 | loss: 31.0140858
	speed: 0.0639s/iter; left time: 1358.9705s
Epoch: 20 cost time: 16.768457174301147
Epoch: 20, Steps: 265 Train Loss: 29.9004 (Forecasting Loss:0.1892 + XiCon Loss:2.9711 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.1699963
	speed: 0.0615s/iter; left time: 1297.1346s
	iters: 200, epoch: 21 | loss: 30.7860622
	speed: 0.0611s/iter; left time: 1283.6499s
Epoch: 21 cost time: 16.225005626678467
Epoch: 21, Steps: 265 Train Loss: 29.9631 (Forecasting Loss:0.1893 + XiCon Loss:2.9774 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.7009048
	speed: 0.0617s/iter; left time: 1286.0020s
	iters: 200, epoch: 22 | loss: 30.8282986
	speed: 0.0628s/iter; left time: 1301.7813s
Epoch: 22 cost time: 16.405853271484375
Epoch: 22, Steps: 265 Train Loss: 29.9641 (Forecasting Loss:0.1893 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.1497879
	speed: 0.0628s/iter; left time: 1291.0225s
	iters: 200, epoch: 23 | loss: 29.7704506
	speed: 0.0613s/iter; left time: 1255.3271s
Epoch: 23 cost time: 16.164841175079346
Epoch: 23, Steps: 265 Train Loss: 29.8408 (Forecasting Loss:0.1891 + XiCon Loss:2.9652 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.6998978
	speed: 0.0570s/iter; left time: 1158.4273s
	iters: 200, epoch: 24 | loss: 29.5402489
	speed: 0.0612s/iter; left time: 1237.2212s
Epoch: 24 cost time: 16.005987405776978
Epoch: 24, Steps: 265 Train Loss: 29.8912 (Forecasting Loss:0.1893 + XiCon Loss:2.9702 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.5385609
	speed: 0.0641s/iter; left time: 1285.4839s
	iters: 200, epoch: 25 | loss: 30.7443962
	speed: 0.0583s/iter; left time: 1162.0759s
Epoch: 25 cost time: 15.879507541656494
Epoch: 25, Steps: 265 Train Loss: 29.9228 (Forecasting Loss:0.1893 + XiCon Loss:2.9734 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.5326309
	speed: 0.0663s/iter; left time: 1311.7565s
	iters: 200, epoch: 26 | loss: 30.7667007
	speed: 0.0606s/iter; left time: 1192.9817s
Epoch: 26 cost time: 16.62115216255188
Epoch: 26, Steps: 265 Train Loss: 29.8959 (Forecasting Loss:0.1892 + XiCon Loss:2.9707 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.1034698
	speed: 0.0601s/iter; left time: 1173.3870s
	iters: 200, epoch: 27 | loss: 29.1841545
	speed: 0.0575s/iter; left time: 1116.7704s
Epoch: 27 cost time: 15.959680795669556
Epoch: 27, Steps: 265 Train Loss: 29.9331 (Forecasting Loss:0.1891 + XiCon Loss:2.9744 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.2464294
	speed: 0.0635s/iter; left time: 1222.7108s
	iters: 200, epoch: 28 | loss: 32.9204636
	speed: 0.0641s/iter; left time: 1227.2644s
Epoch: 28 cost time: 15.566519498825073
Epoch: 28, Steps: 265 Train Loss: 29.9696 (Forecasting Loss:0.1892 + XiCon Loss:2.9780 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.3057861
	speed: 0.0478s/iter; left time: 907.3976s
	iters: 200, epoch: 29 | loss: 29.0316696
	speed: 0.0602s/iter; left time: 1136.0915s
Epoch: 29 cost time: 14.677602529525757
Epoch: 29, Steps: 265 Train Loss: 29.9146 (Forecasting Loss:0.1891 + XiCon Loss:2.9725 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03934904932975769, mae:0.1495269387960434, mape:0.11874011158943176, mspe:0.026349687948822975 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0400+-0.00156, MAE:0.1502+-0.00116, MAPE:0.1192+-0.00079, MSPE:0.0267+-0.00067, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.7807
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3443139
	speed: 0.0948s/iter; left time: 2417.2449s
	iters: 200, epoch: 1 | loss: 0.3094819
	speed: 0.0980s/iter; left time: 2490.2312s
Epoch: 1 cost time: 24.967228651046753
Epoch: 1, Steps: 256 Train Loss: 0.3297 (Forecasting Loss:0.2982 + XiCon Loss:3.1567 x Lambda(0.01)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1593
Validation loss decreased (inf --> 0.208945).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2717099
	speed: 0.1335s/iter; left time: 3369.2240s
	iters: 200, epoch: 2 | loss: 0.2514511
	speed: 0.1421s/iter; left time: 3573.5958s
Epoch: 2 cost time: 35.73210644721985
Epoch: 2, Steps: 256 Train Loss: 0.2718 (Forecasting Loss:0.2408 + XiCon Loss:3.0945 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1761
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2261444
	speed: 0.1509s/iter; left time: 3769.6899s
	iters: 200, epoch: 3 | loss: 0.2191030
	speed: 0.1408s/iter; left time: 3503.6922s
Epoch: 3 cost time: 37.4283561706543
Epoch: 3, Steps: 256 Train Loss: 0.2216 (Forecasting Loss:0.1915 + XiCon Loss:3.0091 x Lambda(0.01)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1929
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2072402
	speed: 0.1422s/iter; left time: 3517.4155s
	iters: 200, epoch: 4 | loss: 0.1934421
	speed: 0.1437s/iter; left time: 3540.2373s
Epoch: 4 cost time: 36.87610459327698
Epoch: 4, Steps: 256 Train Loss: 0.1995 (Forecasting Loss:0.1698 + XiCon Loss:2.9734 x Lambda(0.01)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1910
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1818670
	speed: 0.1445s/iter; left time: 3536.0207s
	iters: 200, epoch: 5 | loss: 0.1841915
	speed: 0.1453s/iter; left time: 3541.7681s
Epoch: 5 cost time: 36.83708381652832
Epoch: 5, Steps: 256 Train Loss: 0.1879 (Forecasting Loss:0.1583 + XiCon Loss:2.9575 x Lambda(0.01)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.1974
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1906808
	speed: 0.1424s/iter; left time: 3448.1320s
	iters: 200, epoch: 6 | loss: 0.1781863
	speed: 0.1413s/iter; left time: 3407.1806s
Epoch: 6 cost time: 36.599623918533325
Epoch: 6, Steps: 256 Train Loss: 0.1822 (Forecasting Loss:0.1527 + XiCon Loss:2.9522 x Lambda(0.01)), Vali MSE Loss: 0.2325 Test MSE Loss: 0.1987
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1823147
	speed: 0.1454s/iter; left time: 3484.3389s
	iters: 200, epoch: 7 | loss: 0.1751121
	speed: 0.1417s/iter; left time: 3382.1365s
Epoch: 7 cost time: 36.657103061676025
Epoch: 7, Steps: 256 Train Loss: 0.1794 (Forecasting Loss:0.1499 + XiCon Loss:2.9512 x Lambda(0.01)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1998
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1863927
	speed: 0.1462s/iter; left time: 3466.6217s
	iters: 200, epoch: 8 | loss: 0.1767631
	speed: 0.1424s/iter; left time: 3361.5061s
Epoch: 8 cost time: 36.998281717300415
Epoch: 8, Steps: 256 Train Loss: 0.1780 (Forecasting Loss:0.1485 + XiCon Loss:2.9503 x Lambda(0.01)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.2004
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1798218
	speed: 0.1420s/iter; left time: 3330.4177s
	iters: 200, epoch: 9 | loss: 0.1691688
	speed: 0.1436s/iter; left time: 3354.2790s
Epoch: 9 cost time: 36.408442974090576
Epoch: 9, Steps: 256 Train Loss: 0.1772 (Forecasting Loss:0.1478 + XiCon Loss:2.9458 x Lambda(0.01)), Vali MSE Loss: 0.2327 Test MSE Loss: 0.2005
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1736341
	speed: 0.1372s/iter; left time: 3182.9836s
	iters: 200, epoch: 10 | loss: 0.1795227
	speed: 0.1387s/iter; left time: 3204.0357s
Epoch: 10 cost time: 35.86059021949768
Epoch: 10, Steps: 256 Train Loss: 0.1769 (Forecasting Loss:0.1474 + XiCon Loss:2.9477 x Lambda(0.01)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.2006
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1796723
	speed: 0.1396s/iter; left time: 3203.3833s
	iters: 200, epoch: 11 | loss: 0.1726617
	speed: 0.1397s/iter; left time: 3190.7003s
Epoch: 11 cost time: 36.18418335914612
Epoch: 11, Steps: 256 Train Loss: 0.1767 (Forecasting Loss:0.1472 + XiCon Loss:2.9467 x Lambda(0.01)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.2008
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08753684163093567, mae:0.23113326728343964, mape:0.1700771450996399, mspe:0.04571157321333885 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.3258
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3379874
	speed: 0.1085s/iter; left time: 2766.8686s
	iters: 200, epoch: 1 | loss: 0.3045792
	speed: 0.1006s/iter; left time: 2555.7731s
Epoch: 1 cost time: 26.92188262939453
Epoch: 1, Steps: 256 Train Loss: 0.3207 (Forecasting Loss:0.2889 + XiCon Loss:3.1802 x Lambda(0.01)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.1549
Validation loss decreased (inf --> 0.204447).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3002074
	speed: 0.1118s/iter; left time: 2822.2861s
	iters: 200, epoch: 2 | loss: 0.2539478
	speed: 0.1049s/iter; left time: 2636.9774s
Epoch: 2 cost time: 28.371398448944092
Epoch: 2, Steps: 256 Train Loss: 0.2883 (Forecasting Loss:0.2574 + XiCon Loss:3.0888 x Lambda(0.01)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1644
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2217572
	speed: 0.1110s/iter; left time: 2773.4325s
	iters: 200, epoch: 3 | loss: 0.2211790
	speed: 0.1078s/iter; left time: 2682.9140s
Epoch: 3 cost time: 27.98667001724243
Epoch: 3, Steps: 256 Train Loss: 0.2317 (Forecasting Loss:0.2009 + XiCon Loss:3.0771 x Lambda(0.01)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1789
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2137809
	speed: 0.1062s/iter; left time: 2626.8079s
	iters: 200, epoch: 4 | loss: 0.2007354
	speed: 0.1062s/iter; left time: 2617.0290s
Epoch: 4 cost time: 27.64981961250305
Epoch: 4, Steps: 256 Train Loss: 0.2111 (Forecasting Loss:0.1798 + XiCon Loss:3.1274 x Lambda(0.01)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.1861
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2038024
	speed: 0.1101s/iter; left time: 2694.1741s
	iters: 200, epoch: 5 | loss: 0.1849762
	speed: 0.1081s/iter; left time: 2635.3352s
Epoch: 5 cost time: 27.999104499816895
Epoch: 5, Steps: 256 Train Loss: 0.2002 (Forecasting Loss:0.1686 + XiCon Loss:3.1620 x Lambda(0.01)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1875
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1896830
	speed: 0.1196s/iter; left time: 2895.8720s
	iters: 200, epoch: 6 | loss: 0.1902681
	speed: 0.1117s/iter; left time: 2694.8512s
Epoch: 6 cost time: 28.833587169647217
Epoch: 6, Steps: 256 Train Loss: 0.1943 (Forecasting Loss:0.1625 + XiCon Loss:3.1802 x Lambda(0.01)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1899
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1915088
	speed: 0.1112s/iter; left time: 2665.2247s
	iters: 200, epoch: 7 | loss: 0.1865275
	speed: 0.1047s/iter; left time: 2498.5531s
Epoch: 7 cost time: 27.8577938079834
Epoch: 7, Steps: 256 Train Loss: 0.1910 (Forecasting Loss:0.1591 + XiCon Loss:3.1868 x Lambda(0.01)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1886
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1880983
	speed: 0.1133s/iter; left time: 2686.6397s
	iters: 200, epoch: 8 | loss: 0.1874645
	speed: 0.1068s/iter; left time: 2521.7849s
Epoch: 8 cost time: 28.484387636184692
Epoch: 8, Steps: 256 Train Loss: 0.1894 (Forecasting Loss:0.1575 + XiCon Loss:3.1905 x Lambda(0.01)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.1896
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1883935
	speed: 0.1080s/iter; left time: 2532.2891s
	iters: 200, epoch: 9 | loss: 0.1900653
	speed: 0.1116s/iter; left time: 2605.6226s
Epoch: 9 cost time: 28.2196204662323
Epoch: 9, Steps: 256 Train Loss: 0.1885 (Forecasting Loss:0.1565 + XiCon Loss:3.1971 x Lambda(0.01)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1901
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1895531
	speed: 0.1015s/iter; left time: 2354.1132s
	iters: 200, epoch: 10 | loss: 0.1869468
	speed: 0.1079s/iter; left time: 2491.8139s
Epoch: 10 cost time: 27.29348087310791
Epoch: 10, Steps: 256 Train Loss: 0.1879 (Forecasting Loss:0.1560 + XiCon Loss:3.1912 x Lambda(0.01)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1905
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1956588
	speed: 0.1006s/iter; left time: 2307.0463s
	iters: 200, epoch: 11 | loss: 0.1929013
	speed: 0.1005s/iter; left time: 2295.3725s
Epoch: 11 cost time: 27.54649305343628
Epoch: 11, Steps: 256 Train Loss: 0.1878 (Forecasting Loss:0.1559 + XiCon Loss:3.1959 x Lambda(0.01)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.1905
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08453026413917542, mae:0.22525614500045776, mape:0.16651727259159088, mspe:0.04495083913207054 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.0106
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3127178
	speed: 0.1217s/iter; left time: 3102.5380s
	iters: 200, epoch: 1 | loss: 0.3308835
	speed: 0.1090s/iter; left time: 2769.8647s
Epoch: 1 cost time: 29.03475308418274
Epoch: 1, Steps: 256 Train Loss: 0.3188 (Forecasting Loss:0.2872 + XiCon Loss:3.1610 x Lambda(0.01)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1526
Validation loss decreased (inf --> 0.198246).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2809724
	speed: 0.1600s/iter; left time: 4038.4524s
	iters: 200, epoch: 2 | loss: 0.2727168
	speed: 0.1725s/iter; left time: 4337.0937s
Epoch: 2 cost time: 43.24040961265564
Epoch: 2, Steps: 256 Train Loss: 0.2949 (Forecasting Loss:0.2634 + XiCon Loss:3.1486 x Lambda(0.01)), Vali MSE Loss: 0.2365 Test MSE Loss: 0.1797
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2369120
	speed: 0.1770s/iter; left time: 4422.2693s
	iters: 200, epoch: 3 | loss: 0.2410652
	speed: 0.1717s/iter; left time: 4273.5707s
Epoch: 3 cost time: 44.414623975753784
Epoch: 3, Steps: 256 Train Loss: 0.2441 (Forecasting Loss:0.2129 + XiCon Loss:3.1144 x Lambda(0.01)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1867
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2309075
	speed: 0.1713s/iter; left time: 4236.8378s
	iters: 200, epoch: 4 | loss: 0.2351663
	speed: 0.1736s/iter; left time: 4276.1810s
Epoch: 4 cost time: 44.34550333023071
Epoch: 4, Steps: 256 Train Loss: 0.2325 (Forecasting Loss:0.2012 + XiCon Loss:3.1326 x Lambda(0.01)), Vali MSE Loss: 0.2362 Test MSE Loss: 0.1854
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2227855
	speed: 0.1696s/iter; left time: 4151.6726s
	iters: 200, epoch: 5 | loss: 0.2351711
	speed: 0.1672s/iter; left time: 4074.9320s
Epoch: 5 cost time: 43.25143623352051
Epoch: 5, Steps: 256 Train Loss: 0.2270 (Forecasting Loss:0.1956 + XiCon Loss:3.1364 x Lambda(0.01)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1848
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2298431
	speed: 0.1710s/iter; left time: 4142.5916s
	iters: 200, epoch: 6 | loss: 0.2210050
	speed: 0.1633s/iter; left time: 3939.8658s
Epoch: 6 cost time: 43.332130908966064
Epoch: 6, Steps: 256 Train Loss: 0.2238 (Forecasting Loss:0.1923 + XiCon Loss:3.1452 x Lambda(0.01)), Vali MSE Loss: 0.2390 Test MSE Loss: 0.1858
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2228823
	speed: 0.1676s/iter; left time: 4016.3182s
	iters: 200, epoch: 7 | loss: 0.2248353
	speed: 0.1704s/iter; left time: 4066.5944s
Epoch: 7 cost time: 42.83506894111633
Epoch: 7, Steps: 256 Train Loss: 0.2217 (Forecasting Loss:0.1902 + XiCon Loss:3.1456 x Lambda(0.01)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1844
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2248665
	speed: 0.1678s/iter; left time: 3977.3417s
	iters: 200, epoch: 8 | loss: 0.2263126
	speed: 0.1724s/iter; left time: 4069.7458s
Epoch: 8 cost time: 43.416280031204224
Epoch: 8, Steps: 256 Train Loss: 0.2206 (Forecasting Loss:0.1891 + XiCon Loss:3.1497 x Lambda(0.01)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1854
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2237168
	speed: 0.1686s/iter; left time: 3955.2155s
	iters: 200, epoch: 9 | loss: 0.2156963
	speed: 0.1661s/iter; left time: 3879.0155s
Epoch: 9 cost time: 43.046183824539185
Epoch: 9, Steps: 256 Train Loss: 0.2198 (Forecasting Loss:0.1883 + XiCon Loss:3.1493 x Lambda(0.01)), Vali MSE Loss: 0.2389 Test MSE Loss: 0.1854
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2186699
	speed: 0.1678s/iter; left time: 3892.9542s
	iters: 200, epoch: 10 | loss: 0.2150600
	speed: 0.1692s/iter; left time: 3909.1411s
Epoch: 10 cost time: 42.96670079231262
Epoch: 10, Steps: 256 Train Loss: 0.2195 (Forecasting Loss:0.1880 + XiCon Loss:3.1518 x Lambda(0.01)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1854
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2168655
	speed: 0.1668s/iter; left time: 3826.2105s
	iters: 200, epoch: 11 | loss: 0.2157831
	speed: 0.1636s/iter; left time: 3736.8387s
Epoch: 11 cost time: 42.491586208343506
Epoch: 11, Steps: 256 Train Loss: 0.2194 (Forecasting Loss:0.1879 + XiCon Loss:3.1510 x Lambda(0.01)), Vali MSE Loss: 0.2392 Test MSE Loss: 0.1856
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08255909383296967, mae:0.22268028557300568, mape:0.16564379632472992, mspe:0.044837936758995056 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.2051
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3134219
	speed: 0.1084s/iter; left time: 2765.1897s
	iters: 200, epoch: 1 | loss: 0.3078427
	speed: 0.1077s/iter; left time: 2735.7831s
Epoch: 1 cost time: 28.48136878013611
Epoch: 1, Steps: 256 Train Loss: 0.3255 (Forecasting Loss:0.2940 + XiCon Loss:3.1569 x Lambda(0.01)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1600
Validation loss decreased (inf --> 0.206073).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2676830
	speed: 0.1248s/iter; left time: 3149.9644s
	iters: 200, epoch: 2 | loss: 0.2490889
	speed: 0.1395s/iter; left time: 3508.4698s
Epoch: 2 cost time: 34.78632831573486
Epoch: 2, Steps: 256 Train Loss: 0.2721 (Forecasting Loss:0.2412 + XiCon Loss:3.0829 x Lambda(0.01)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1807
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2220269
	speed: 0.1442s/iter; left time: 3604.6403s
	iters: 200, epoch: 3 | loss: 0.2080714
	speed: 0.1483s/iter; left time: 3690.8953s
Epoch: 3 cost time: 38.10599708557129
Epoch: 3, Steps: 256 Train Loss: 0.2207 (Forecasting Loss:0.1892 + XiCon Loss:3.1541 x Lambda(0.01)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.1817
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1955597
	speed: 0.1205s/iter; left time: 2979.9743s
	iters: 200, epoch: 4 | loss: 0.1871268
	speed: 0.1456s/iter; left time: 3586.9163s
Epoch: 4 cost time: 34.918654441833496
Epoch: 4, Steps: 256 Train Loss: 0.1968 (Forecasting Loss:0.1648 + XiCon Loss:3.2010 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1899
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1860773
	speed: 0.1563s/iter; left time: 3825.1939s
	iters: 200, epoch: 5 | loss: 0.1838687
	speed: 0.1558s/iter; left time: 3797.0423s
Epoch: 5 cost time: 39.761242389678955
Epoch: 5, Steps: 256 Train Loss: 0.1853 (Forecasting Loss:0.1531 + XiCon Loss:3.2226 x Lambda(0.01)), Vali MSE Loss: 0.2214 Test MSE Loss: 0.1938
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1854406
	speed: 0.1501s/iter; left time: 3636.2463s
	iters: 200, epoch: 6 | loss: 0.1785810
	speed: 0.1536s/iter; left time: 3704.3320s
Epoch: 6 cost time: 39.18033528327942
Epoch: 6, Steps: 256 Train Loss: 0.1800 (Forecasting Loss:0.1478 + XiCon Loss:3.2269 x Lambda(0.01)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1966
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1718618
	speed: 0.1537s/iter; left time: 3683.3620s
	iters: 200, epoch: 7 | loss: 0.1798071
	speed: 0.1517s/iter; left time: 3619.7189s
Epoch: 7 cost time: 39.076244592666626
Epoch: 7, Steps: 256 Train Loss: 0.1774 (Forecasting Loss:0.1451 + XiCon Loss:3.2282 x Lambda(0.01)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.1972
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1783026
	speed: 0.1525s/iter; left time: 3616.2278s
	iters: 200, epoch: 8 | loss: 0.1713383
	speed: 0.1519s/iter; left time: 3585.5329s
Epoch: 8 cost time: 39.15828728675842
Epoch: 8, Steps: 256 Train Loss: 0.1760 (Forecasting Loss:0.1437 + XiCon Loss:3.2338 x Lambda(0.01)), Vali MSE Loss: 0.2260 Test MSE Loss: 0.1976
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1755608
	speed: 0.1566s/iter; left time: 3672.3361s
	iters: 200, epoch: 9 | loss: 0.1761893
	speed: 0.1550s/iter; left time: 3620.0963s
Epoch: 9 cost time: 39.91216969490051
Epoch: 9, Steps: 256 Train Loss: 0.1755 (Forecasting Loss:0.1431 + XiCon Loss:3.2341 x Lambda(0.01)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.1978
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1675843
	speed: 0.1557s/iter; left time: 3611.2815s
	iters: 200, epoch: 10 | loss: 0.1792332
	speed: 0.1510s/iter; left time: 3486.8335s
Epoch: 10 cost time: 39.62133455276489
Epoch: 10, Steps: 256 Train Loss: 0.1751 (Forecasting Loss:0.1428 + XiCon Loss:3.2320 x Lambda(0.01)), Vali MSE Loss: 0.2263 Test MSE Loss: 0.1978
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1785409
	speed: 0.1501s/iter; left time: 3443.7075s
	iters: 200, epoch: 11 | loss: 0.1705012
	speed: 0.1534s/iter; left time: 3503.5962s
Epoch: 11 cost time: 38.68350291252136
Epoch: 11, Steps: 256 Train Loss: 0.1750 (Forecasting Loss:0.1426 + XiCon Loss:3.2351 x Lambda(0.01)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1978
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08777716755867004, mae:0.23221935331821442, mape:0.1723121702671051, mspe:0.04759785905480385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.9686
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3179351
	speed: 0.1122s/iter; left time: 2862.4207s
	iters: 200, epoch: 1 | loss: 0.3103950
	speed: 0.1100s/iter; left time: 2795.1486s
Epoch: 1 cost time: 28.38795566558838
Epoch: 1, Steps: 256 Train Loss: 0.3193 (Forecasting Loss:0.2875 + XiCon Loss:3.1771 x Lambda(0.01)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1517
Validation loss decreased (inf --> 0.200695).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2938263
	speed: 0.1232s/iter; left time: 3109.6035s
	iters: 200, epoch: 2 | loss: 0.2647744
	speed: 0.1493s/iter; left time: 3755.0244s
Epoch: 2 cost time: 36.27473521232605
Epoch: 2, Steps: 256 Train Loss: 0.2956 (Forecasting Loss:0.2640 + XiCon Loss:3.1573 x Lambda(0.01)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1744
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2410316
	speed: 0.1593s/iter; left time: 3980.1193s
	iters: 200, epoch: 3 | loss: 0.2270027
	speed: 0.1520s/iter; left time: 3782.8276s
Epoch: 3 cost time: 39.35887289047241
Epoch: 3, Steps: 256 Train Loss: 0.2398 (Forecasting Loss:0.2081 + XiCon Loss:3.1684 x Lambda(0.01)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1847
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2160191
	speed: 0.1500s/iter; left time: 3709.3980s
	iters: 200, epoch: 4 | loss: 0.2129138
	speed: 0.1518s/iter; left time: 3740.2412s
Epoch: 4 cost time: 38.972665309906006
Epoch: 4, Steps: 256 Train Loss: 0.2187 (Forecasting Loss:0.1868 + XiCon Loss:3.1865 x Lambda(0.01)), Vali MSE Loss: 0.2328 Test MSE Loss: 0.1960
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2004647
	speed: 0.1563s/iter; left time: 3825.2999s
	iters: 200, epoch: 5 | loss: 0.2097309
	speed: 0.1538s/iter; left time: 3749.8742s
Epoch: 5 cost time: 40.35516166687012
Epoch: 5, Steps: 256 Train Loss: 0.2077 (Forecasting Loss:0.1758 + XiCon Loss:3.1956 x Lambda(0.01)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1984
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2000105
	speed: 0.1304s/iter; left time: 3157.9233s
	iters: 200, epoch: 6 | loss: 0.2033598
	speed: 0.1505s/iter; left time: 3631.1035s
Epoch: 6 cost time: 36.30915570259094
Epoch: 6, Steps: 256 Train Loss: 0.2021 (Forecasting Loss:0.1701 + XiCon Loss:3.1945 x Lambda(0.01)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2013
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1911429
	speed: 0.1541s/iter; left time: 3691.9687s
	iters: 200, epoch: 7 | loss: 0.2021239
	speed: 0.1512s/iter; left time: 3608.4601s
Epoch: 7 cost time: 39.60615372657776
Epoch: 7, Steps: 256 Train Loss: 0.1989 (Forecasting Loss:0.1670 + XiCon Loss:3.1948 x Lambda(0.01)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2020
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2059039
	speed: 0.1574s/iter; left time: 3732.2955s
	iters: 200, epoch: 8 | loss: 0.1932899
	speed: 0.1565s/iter; left time: 3695.9482s
Epoch: 8 cost time: 40.15238404273987
Epoch: 8, Steps: 256 Train Loss: 0.1976 (Forecasting Loss:0.1655 + XiCon Loss:3.2060 x Lambda(0.01)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2016
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1929872
	speed: 0.1529s/iter; left time: 3586.7329s
	iters: 200, epoch: 9 | loss: 0.1979043
	speed: 0.1556s/iter; left time: 3634.3095s
Epoch: 9 cost time: 39.80397057533264
Epoch: 9, Steps: 256 Train Loss: 0.1966 (Forecasting Loss:0.1646 + XiCon Loss:3.1981 x Lambda(0.01)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2012
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1844370
	speed: 0.1522s/iter; left time: 3530.0044s
	iters: 200, epoch: 10 | loss: 0.1956696
	speed: 0.1575s/iter; left time: 3637.8064s
Epoch: 10 cost time: 39.97991132736206
Epoch: 10, Steps: 256 Train Loss: 0.1963 (Forecasting Loss:0.1643 + XiCon Loss:3.2018 x Lambda(0.01)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2025
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2005263
	speed: 0.1573s/iter; left time: 3607.5224s
	iters: 200, epoch: 11 | loss: 0.1960163
	speed: 0.1550s/iter; left time: 3540.6932s
Epoch: 11 cost time: 40.51068067550659
Epoch: 11, Steps: 256 Train Loss: 0.1961 (Forecasting Loss:0.1641 + XiCon Loss:3.1968 x Lambda(0.01)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2034
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08148901909589767, mae:0.2219190001487732, mape:0.16582220792770386, mspe:0.04514804109930992 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0848+-0.00353, MAE:0.2266+-0.00593, MAPE:0.1681+-0.00369, MSPE:0.0456+-0.00142, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.1260
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3432139
	speed: 0.1533s/iter; left time: 3725.8874s
	iters: 200, epoch: 1 | loss: 0.3180947
	speed: 0.1649s/iter; left time: 3991.5575s
Epoch: 1 cost time: 40.530786991119385
Epoch: 1, Steps: 244 Train Loss: 0.3525 (Forecasting Loss:0.3492 + XiCon Loss:3.2430 x Lambda(0.001)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1564
Validation loss decreased (inf --> 0.228288).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3201864
	speed: 0.2036s/iter; left time: 4898.1006s
	iters: 200, epoch: 2 | loss: 0.2800270
	speed: 0.1978s/iter; left time: 4737.5323s
Epoch: 2 cost time: 49.02033591270447
Epoch: 2, Steps: 244 Train Loss: 0.3078 (Forecasting Loss:0.3046 + XiCon Loss:3.2004 x Lambda(0.001)), Vali MSE Loss: 0.2776 Test MSE Loss: 0.1573
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2496448
	speed: 0.1982s/iter; left time: 4720.6521s
	iters: 200, epoch: 3 | loss: 0.2472951
	speed: 0.1973s/iter; left time: 4679.2771s
Epoch: 3 cost time: 48.36635184288025
Epoch: 3, Steps: 244 Train Loss: 0.2590 (Forecasting Loss:0.2558 + XiCon Loss:3.1790 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.1518
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2413065
	speed: 0.1987s/iter; left time: 4682.5006s
	iters: 200, epoch: 4 | loss: 0.2409033
	speed: 0.1935s/iter; left time: 4542.3881s
Epoch: 4 cost time: 48.22451734542847
Epoch: 4, Steps: 244 Train Loss: 0.2414 (Forecasting Loss:0.2382 + XiCon Loss:3.1734 x Lambda(0.001)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.1601
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2398236
	speed: 0.1965s/iter; left time: 4582.8815s
	iters: 200, epoch: 5 | loss: 0.2301413
	speed: 0.1940s/iter; left time: 4504.5803s
Epoch: 5 cost time: 48.02111625671387
Epoch: 5, Steps: 244 Train Loss: 0.2327 (Forecasting Loss:0.2295 + XiCon Loss:3.1708 x Lambda(0.001)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.1568
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2287725
	speed: 0.2001s/iter; left time: 4619.4833s
	iters: 200, epoch: 6 | loss: 0.2368240
	speed: 0.2007s/iter; left time: 4611.6485s
Epoch: 6 cost time: 48.71411657333374
Epoch: 6, Steps: 244 Train Loss: 0.2288 (Forecasting Loss:0.2256 + XiCon Loss:3.1669 x Lambda(0.001)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.1638
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2179004
	speed: 0.2074s/iter; left time: 4737.0811s
	iters: 200, epoch: 7 | loss: 0.2227007
	speed: 0.1718s/iter; left time: 3906.2202s
Epoch: 7 cost time: 46.34862971305847
Epoch: 7, Steps: 244 Train Loss: 0.2268 (Forecasting Loss:0.2237 + XiCon Loss:3.1665 x Lambda(0.001)), Vali MSE Loss: 0.3367 Test MSE Loss: 0.1628
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2379977
	speed: 0.2019s/iter; left time: 4562.3062s
	iters: 200, epoch: 8 | loss: 0.2245286
	speed: 0.1967s/iter; left time: 4423.7246s
Epoch: 8 cost time: 48.54267978668213
Epoch: 8, Steps: 244 Train Loss: 0.2257 (Forecasting Loss:0.2226 + XiCon Loss:3.1649 x Lambda(0.001)), Vali MSE Loss: 0.3322 Test MSE Loss: 0.1616
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2140226
	speed: 0.2013s/iter; left time: 4499.4764s
	iters: 200, epoch: 9 | loss: 0.2207925
	speed: 0.1965s/iter; left time: 4372.9303s
Epoch: 9 cost time: 48.463953495025635
Epoch: 9, Steps: 244 Train Loss: 0.2251 (Forecasting Loss:0.2220 + XiCon Loss:3.1636 x Lambda(0.001)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.1632
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2251857
	speed: 0.2030s/iter; left time: 4486.2560s
	iters: 200, epoch: 10 | loss: 0.2197716
	speed: 0.1981s/iter; left time: 4358.9324s
Epoch: 10 cost time: 48.97319293022156
Epoch: 10, Steps: 244 Train Loss: 0.2248 (Forecasting Loss:0.2217 + XiCon Loss:3.1648 x Lambda(0.001)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.1633
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2152315
	speed: 0.1966s/iter; left time: 4297.2963s
	iters: 200, epoch: 11 | loss: 0.2166287
	speed: 0.1942s/iter; left time: 4225.9757s
Epoch: 11 cost time: 48.119311571121216
Epoch: 11, Steps: 244 Train Loss: 0.2247 (Forecasting Loss:0.2215 + XiCon Loss:3.1646 x Lambda(0.001)), Vali MSE Loss: 0.3342 Test MSE Loss: 0.1632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08475134521722794, mae:0.22810351848602295, mape:0.16170287132263184, mspe:0.0399690680205822 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.2332
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3342230
	speed: 0.1354s/iter; left time: 3289.3502s
	iters: 200, epoch: 1 | loss: 0.3393518
	speed: 0.1369s/iter; left time: 3312.8645s
Epoch: 1 cost time: 33.08079957962036
Epoch: 1, Steps: 244 Train Loss: 0.3418 (Forecasting Loss:0.3386 + XiCon Loss:3.2301 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1588
Validation loss decreased (inf --> 0.221872).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2894852
	speed: 0.2024s/iter; left time: 4869.9411s
	iters: 200, epoch: 2 | loss: 0.2787742
	speed: 0.2154s/iter; left time: 5160.2221s
Epoch: 2 cost time: 51.29207730293274
Epoch: 2, Steps: 244 Train Loss: 0.3059 (Forecasting Loss:0.3027 + XiCon Loss:3.1784 x Lambda(0.001)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.1646
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2531840
	speed: 0.2113s/iter; left time: 5032.8079s
	iters: 200, epoch: 3 | loss: 0.2413272
	speed: 0.2036s/iter; left time: 4827.8858s
Epoch: 3 cost time: 50.38598704338074
Epoch: 3, Steps: 244 Train Loss: 0.2554 (Forecasting Loss:0.2523 + XiCon Loss:3.1345 x Lambda(0.001)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.1664
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2310803
	speed: 0.2089s/iter; left time: 4923.2432s
	iters: 200, epoch: 4 | loss: 0.2317771
	speed: 0.1966s/iter; left time: 4613.3699s
Epoch: 4 cost time: 49.62322282791138
Epoch: 4, Steps: 244 Train Loss: 0.2412 (Forecasting Loss:0.2381 + XiCon Loss:3.1290 x Lambda(0.001)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1654
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2457617
	speed: 0.2036s/iter; left time: 4749.5771s
	iters: 200, epoch: 5 | loss: 0.2365768
	speed: 0.1967s/iter; left time: 4567.3663s
Epoch: 5 cost time: 48.718453884124756
Epoch: 5, Steps: 244 Train Loss: 0.2340 (Forecasting Loss:0.2308 + XiCon Loss:3.1285 x Lambda(0.001)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1677
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2314207
	speed: 0.1900s/iter; left time: 4386.3119s
	iters: 200, epoch: 6 | loss: 0.2365576
	speed: 0.2026s/iter; left time: 4655.5215s
Epoch: 6 cost time: 47.81742763519287
Epoch: 6, Steps: 244 Train Loss: 0.2304 (Forecasting Loss:0.2273 + XiCon Loss:3.1286 x Lambda(0.001)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1730
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2340254
	speed: 0.1936s/iter; left time: 4420.2584s
	iters: 200, epoch: 7 | loss: 0.2330425
	speed: 0.1967s/iter; left time: 4471.5753s
Epoch: 7 cost time: 48.28281831741333
Epoch: 7, Steps: 244 Train Loss: 0.2286 (Forecasting Loss:0.2255 + XiCon Loss:3.1259 x Lambda(0.001)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.1700
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2283388
	speed: 0.2007s/iter; left time: 4535.0513s
	iters: 200, epoch: 8 | loss: 0.2161182
	speed: 0.2012s/iter; left time: 4524.8309s
Epoch: 8 cost time: 48.91983699798584
Epoch: 8, Steps: 244 Train Loss: 0.2277 (Forecasting Loss:0.2245 + XiCon Loss:3.1266 x Lambda(0.001)), Vali MSE Loss: 0.2628 Test MSE Loss: 0.1708
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2279674
	speed: 0.1715s/iter; left time: 3833.4524s
	iters: 200, epoch: 9 | loss: 0.2307148
	speed: 0.1883s/iter; left time: 4188.7351s
Epoch: 9 cost time: 44.509509325027466
Epoch: 9, Steps: 244 Train Loss: 0.2272 (Forecasting Loss:0.2241 + XiCon Loss:3.1274 x Lambda(0.001)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1704
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2357043
	speed: 0.2022s/iter; left time: 4469.4796s
	iters: 200, epoch: 10 | loss: 0.2282297
	speed: 0.2009s/iter; left time: 4421.7337s
Epoch: 10 cost time: 49.30127024650574
Epoch: 10, Steps: 244 Train Loss: 0.2270 (Forecasting Loss:0.2239 + XiCon Loss:3.1282 x Lambda(0.001)), Vali MSE Loss: 0.2628 Test MSE Loss: 0.1713
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2227795
	speed: 0.2001s/iter; left time: 4373.4146s
	iters: 200, epoch: 11 | loss: 0.2350090
	speed: 0.1983s/iter; left time: 4315.9412s
Epoch: 11 cost time: 48.806894302368164
Epoch: 11, Steps: 244 Train Loss: 0.2268 (Forecasting Loss:0.2236 + XiCon Loss:3.1285 x Lambda(0.001)), Vali MSE Loss: 0.2626 Test MSE Loss: 0.1704
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08615349233150482, mae:0.23149217665195465, mape:0.16735589504241943, mspe:0.04365731403231621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.8701
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3776956
	speed: 0.1364s/iter; left time: 3313.8042s
	iters: 200, epoch: 1 | loss: 0.3453805
	speed: 0.1343s/iter; left time: 3251.0774s
Epoch: 1 cost time: 34.10375094413757
Epoch: 1, Steps: 244 Train Loss: 0.3561 (Forecasting Loss:0.3529 + XiCon Loss:3.2195 x Lambda(0.001)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1521
Validation loss decreased (inf --> 0.235613).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3085890
	speed: 0.1849s/iter; left time: 4447.0195s
	iters: 200, epoch: 2 | loss: 0.2849423
	speed: 0.1874s/iter; left time: 4490.1925s
Epoch: 2 cost time: 45.82721495628357
Epoch: 2, Steps: 244 Train Loss: 0.3127 (Forecasting Loss:0.3096 + XiCon Loss:3.1667 x Lambda(0.001)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1647
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2737832
	speed: 0.1900s/iter; left time: 4524.4150s
	iters: 200, epoch: 3 | loss: 0.2556806
	speed: 0.1850s/iter; left time: 4387.1168s
Epoch: 3 cost time: 45.70917630195618
Epoch: 3, Steps: 244 Train Loss: 0.2730 (Forecasting Loss:0.2698 + XiCon Loss:3.1528 x Lambda(0.001)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.1527
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2604201
	speed: 0.1836s/iter; left time: 4326.7751s
	iters: 200, epoch: 4 | loss: 0.2528226
	speed: 0.1872s/iter; left time: 4393.6096s
Epoch: 4 cost time: 45.396294593811035
Epoch: 4, Steps: 244 Train Loss: 0.2615 (Forecasting Loss:0.2583 + XiCon Loss:3.1525 x Lambda(0.001)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2507529
	speed: 0.1885s/iter; left time: 4395.7747s
	iters: 200, epoch: 5 | loss: 0.2580612
	speed: 0.1818s/iter; left time: 4221.2420s
Epoch: 5 cost time: 44.895811319351196
Epoch: 5, Steps: 244 Train Loss: 0.2552 (Forecasting Loss:0.2521 + XiCon Loss:3.1524 x Lambda(0.001)), Vali MSE Loss: 0.3323 Test MSE Loss: 0.1607
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2533230
	speed: 0.1838s/iter; left time: 4243.4213s
	iters: 200, epoch: 6 | loss: 0.2364306
	speed: 0.1832s/iter; left time: 4210.9144s
Epoch: 6 cost time: 45.058549642562866
Epoch: 6, Steps: 244 Train Loss: 0.2510 (Forecasting Loss:0.2479 + XiCon Loss:3.1532 x Lambda(0.001)), Vali MSE Loss: 0.3453 Test MSE Loss: 0.1675
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2600805
	speed: 0.1902s/iter; left time: 4343.1407s
	iters: 200, epoch: 7 | loss: 0.2520334
	speed: 0.1834s/iter; left time: 4169.0125s
Epoch: 7 cost time: 45.676005601882935
Epoch: 7, Steps: 244 Train Loss: 0.2487 (Forecasting Loss:0.2455 + XiCon Loss:3.1530 x Lambda(0.001)), Vali MSE Loss: 0.3375 Test MSE Loss: 0.1679
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2573620
	speed: 0.1854s/iter; left time: 4188.4492s
	iters: 200, epoch: 8 | loss: 0.2421407
	speed: 0.1779s/iter; left time: 4002.5158s
Epoch: 8 cost time: 44.47153902053833
Epoch: 8, Steps: 244 Train Loss: 0.2476 (Forecasting Loss:0.2445 + XiCon Loss:3.1533 x Lambda(0.001)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.1666
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2509706
	speed: 0.1703s/iter; left time: 3806.1031s
	iters: 200, epoch: 9 | loss: 0.2504582
	speed: 0.1455s/iter; left time: 3238.2425s
Epoch: 9 cost time: 39.689117670059204
Epoch: 9, Steps: 244 Train Loss: 0.2470 (Forecasting Loss:0.2438 + XiCon Loss:3.1494 x Lambda(0.001)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.1678
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2568806
	speed: 0.1937s/iter; left time: 4282.7577s
	iters: 200, epoch: 10 | loss: 0.2540729
	speed: 0.1793s/iter; left time: 3945.7099s
Epoch: 10 cost time: 46.03482747077942
Epoch: 10, Steps: 244 Train Loss: 0.2468 (Forecasting Loss:0.2436 + XiCon Loss:3.1496 x Lambda(0.001)), Vali MSE Loss: 0.3418 Test MSE Loss: 0.1675
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2549433
	speed: 0.1797s/iter; left time: 3929.4495s
	iters: 200, epoch: 11 | loss: 0.2473394
	speed: 0.1960s/iter; left time: 4264.4444s
Epoch: 11 cost time: 45.97213840484619
Epoch: 11, Steps: 244 Train Loss: 0.2465 (Forecasting Loss:0.2433 + XiCon Loss:3.1508 x Lambda(0.001)), Vali MSE Loss: 0.3451 Test MSE Loss: 0.1675
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08023455739021301, mae:0.22395116090774536, mape:0.16083116829395294, mspe:0.039692919701337814 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.0682
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3645999
	speed: 0.1352s/iter; left time: 3285.1762s
	iters: 200, epoch: 1 | loss: 0.3294300
	speed: 0.1202s/iter; left time: 2909.0920s
Epoch: 1 cost time: 32.57504153251648
Epoch: 1, Steps: 244 Train Loss: 0.3492 (Forecasting Loss:0.3460 + XiCon Loss:3.2200 x Lambda(0.001)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1486
Validation loss decreased (inf --> 0.240095).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3277824
	speed: 0.2146s/iter; left time: 5162.8624s
	iters: 200, epoch: 2 | loss: 0.2564850
	speed: 0.2081s/iter; left time: 4985.5963s
Epoch: 2 cost time: 51.15108942985535
Epoch: 2, Steps: 244 Train Loss: 0.2977 (Forecasting Loss:0.2945 + XiCon Loss:3.2033 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.1642
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2717400
	speed: 0.2058s/iter; left time: 4900.4223s
	iters: 200, epoch: 3 | loss: 0.2608794
	speed: 0.2022s/iter; left time: 4795.4919s
Epoch: 3 cost time: 49.69661021232605
Epoch: 3, Steps: 244 Train Loss: 0.2586 (Forecasting Loss:0.2554 + XiCon Loss:3.1933 x Lambda(0.001)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2421308
	speed: 0.2010s/iter; left time: 4737.7718s
	iters: 200, epoch: 4 | loss: 0.2415020
	speed: 0.2010s/iter; left time: 4717.6638s
Epoch: 4 cost time: 49.006996870040894
Epoch: 4, Steps: 244 Train Loss: 0.2412 (Forecasting Loss:0.2380 + XiCon Loss:3.1920 x Lambda(0.001)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.1696
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2361735
	speed: 0.2064s/iter; left time: 4813.8530s
	iters: 200, epoch: 5 | loss: 0.2236889
	speed: 0.2051s/iter; left time: 4762.4156s
Epoch: 5 cost time: 50.283671855926514
Epoch: 5, Steps: 244 Train Loss: 0.2315 (Forecasting Loss:0.2283 + XiCon Loss:3.1928 x Lambda(0.001)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.1621
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2279704
	speed: 0.2041s/iter; left time: 4710.6661s
	iters: 200, epoch: 6 | loss: 0.2290611
	speed: 0.2011s/iter; left time: 4622.2509s
Epoch: 6 cost time: 49.532851696014404
Epoch: 6, Steps: 244 Train Loss: 0.2271 (Forecasting Loss:0.2239 + XiCon Loss:3.1898 x Lambda(0.001)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.1652
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2158278
	speed: 0.2055s/iter; left time: 4693.2258s
	iters: 200, epoch: 7 | loss: 0.2202459
	speed: 0.1990s/iter; left time: 4525.4157s
Epoch: 7 cost time: 49.735572814941406
Epoch: 7, Steps: 244 Train Loss: 0.2247 (Forecasting Loss:0.2215 + XiCon Loss:3.1910 x Lambda(0.001)), Vali MSE Loss: 0.3124 Test MSE Loss: 0.1653
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2205747
	speed: 0.2036s/iter; left time: 4599.3798s
	iters: 200, epoch: 8 | loss: 0.2247616
	speed: 0.2001s/iter; left time: 4500.1549s
Epoch: 8 cost time: 49.570011377334595
Epoch: 8, Steps: 244 Train Loss: 0.2237 (Forecasting Loss:0.2205 + XiCon Loss:3.1884 x Lambda(0.001)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.1659
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2171689
	speed: 0.2031s/iter; left time: 4538.9467s
	iters: 200, epoch: 9 | loss: 0.2175200
	speed: 0.2060s/iter; left time: 4582.5878s
Epoch: 9 cost time: 49.47469449043274
Epoch: 9, Steps: 244 Train Loss: 0.2230 (Forecasting Loss:0.2198 + XiCon Loss:3.1881 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.1667
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2222727
	speed: 0.1988s/iter; left time: 4395.4542s
	iters: 200, epoch: 10 | loss: 0.2293469
	speed: 0.2013s/iter; left time: 4429.6796s
Epoch: 10 cost time: 49.03333353996277
Epoch: 10, Steps: 244 Train Loss: 0.2226 (Forecasting Loss:0.2195 + XiCon Loss:3.1885 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.1659
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2289563
	speed: 0.2006s/iter; left time: 4385.8219s
	iters: 200, epoch: 11 | loss: 0.2211341
	speed: 0.1983s/iter; left time: 4315.5286s
Epoch: 11 cost time: 48.95852971076965
Epoch: 11, Steps: 244 Train Loss: 0.2224 (Forecasting Loss:0.2192 + XiCon Loss:3.1904 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.1668
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.07752268761396408, mae:0.2197035253047943, mape:0.15788207948207855, mspe:0.03847568854689598 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.4246
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3526168
	speed: 0.1426s/iter; left time: 3466.4764s
	iters: 200, epoch: 1 | loss: 0.2785073
	speed: 0.1369s/iter; left time: 3314.2123s
Epoch: 1 cost time: 34.128352880477905
Epoch: 1, Steps: 244 Train Loss: 0.3453 (Forecasting Loss:0.3420 + XiCon Loss:3.2248 x Lambda(0.001)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.234757).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3163964
	speed: 0.2131s/iter; left time: 5126.8749s
	iters: 200, epoch: 2 | loss: 0.2839526
	speed: 0.2241s/iter; left time: 5368.2812s
Epoch: 2 cost time: 53.850518226623535
Epoch: 2, Steps: 244 Train Loss: 0.3297 (Forecasting Loss:0.3265 + XiCon Loss:3.2013 x Lambda(0.001)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1613
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2474626
	speed: 0.2283s/iter; left time: 5436.6637s
	iters: 200, epoch: 3 | loss: 0.2628687
	speed: 0.2262s/iter; left time: 5362.7007s
Epoch: 3 cost time: 55.567362785339355
Epoch: 3, Steps: 244 Train Loss: 0.2578 (Forecasting Loss:0.2546 + XiCon Loss:3.1778 x Lambda(0.001)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1622
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2414865
	speed: 0.2275s/iter; left time: 5362.8345s
	iters: 200, epoch: 4 | loss: 0.2382527
	speed: 0.2201s/iter; left time: 5164.6150s
Epoch: 4 cost time: 53.96763014793396
Epoch: 4, Steps: 244 Train Loss: 0.2393 (Forecasting Loss:0.2361 + XiCon Loss:3.1729 x Lambda(0.001)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.1662
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2365070
	speed: 0.1783s/iter; left time: 4158.2678s
	iters: 200, epoch: 5 | loss: 0.2335280
	speed: 0.2116s/iter; left time: 4914.2066s
Epoch: 5 cost time: 49.004718542099
Epoch: 5, Steps: 244 Train Loss: 0.2301 (Forecasting Loss:0.2269 + XiCon Loss:3.1697 x Lambda(0.001)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.1652
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2302214
	speed: 0.2130s/iter; left time: 4917.2610s
	iters: 200, epoch: 6 | loss: 0.2230271
	speed: 0.2106s/iter; left time: 4839.1277s
Epoch: 6 cost time: 51.53392720222473
Epoch: 6, Steps: 244 Train Loss: 0.2260 (Forecasting Loss:0.2228 + XiCon Loss:3.1689 x Lambda(0.001)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.1708
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2177878
	speed: 0.2182s/iter; left time: 4982.5425s
	iters: 200, epoch: 7 | loss: 0.2206677
	speed: 0.2007s/iter; left time: 4563.9758s
Epoch: 7 cost time: 51.31848096847534
Epoch: 7, Steps: 244 Train Loss: 0.2240 (Forecasting Loss:0.2208 + XiCon Loss:3.1691 x Lambda(0.001)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.1675
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2282995
	speed: 0.2078s/iter; left time: 4694.1867s
	iters: 200, epoch: 8 | loss: 0.2120400
	speed: 0.2207s/iter; left time: 4964.0873s
Epoch: 8 cost time: 52.497856855392456
Epoch: 8, Steps: 244 Train Loss: 0.2229 (Forecasting Loss:0.2197 + XiCon Loss:3.1689 x Lambda(0.001)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1692
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2283715
	speed: 0.2126s/iter; left time: 4750.4108s
	iters: 200, epoch: 9 | loss: 0.2290555
	speed: 0.2193s/iter; left time: 4879.9653s
Epoch: 9 cost time: 52.54139494895935
Epoch: 9, Steps: 244 Train Loss: 0.2224 (Forecasting Loss:0.2192 + XiCon Loss:3.1700 x Lambda(0.001)), Vali MSE Loss: 0.2713 Test MSE Loss: 0.1694
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2240050
	speed: 0.2169s/iter; left time: 4794.2919s
	iters: 200, epoch: 10 | loss: 0.2196828
	speed: 0.2139s/iter; left time: 4706.4735s
Epoch: 10 cost time: 52.346641540527344
Epoch: 10, Steps: 244 Train Loss: 0.2221 (Forecasting Loss:0.2190 + XiCon Loss:3.1661 x Lambda(0.001)), Vali MSE Loss: 0.2720 Test MSE Loss: 0.1702
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2318893
	speed: 0.2172s/iter; left time: 4748.1820s
	iters: 200, epoch: 11 | loss: 0.2239522
	speed: 0.2098s/iter; left time: 4565.2889s
Epoch: 11 cost time: 52.55055809020996
Epoch: 11, Steps: 244 Train Loss: 0.2219 (Forecasting Loss:0.2187 + XiCon Loss:3.1673 x Lambda(0.001)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.1696
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08993992954492569, mae:0.23591481149196625, mape:0.1695144772529602, mspe:0.04447275027632713 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0837+-0.00609, MAE:0.2278+-0.00785, MAPE:0.1635+-0.00599, MSPE:0.0413+-0.00328, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.0476
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7509805
	speed: 0.1283s/iter; left time: 2977.0743s
	iters: 200, epoch: 1 | loss: 0.7300848
	speed: 0.1261s/iter; left time: 2912.2600s
Epoch: 1 cost time: 29.678793907165527
Epoch: 1, Steps: 233 Train Loss: 0.7533 (Forecasting Loss:0.4292 + XiCon Loss:3.2411 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1704
Validation loss decreased (inf --> 0.299159).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6593331
	speed: 0.1300s/iter; left time: 2986.6202s
	iters: 200, epoch: 2 | loss: 0.6068588
	speed: 0.1299s/iter; left time: 2971.2339s
Epoch: 2 cost time: 30.26110529899597
Epoch: 2, Steps: 233 Train Loss: 0.6470 (Forecasting Loss:0.3346 + XiCon Loss:3.1243 x Lambda(0.1)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.1658
Validation loss decreased (0.299159 --> 0.235843).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5995566
	speed: 0.1292s/iter; left time: 2937.6964s
	iters: 200, epoch: 3 | loss: 0.5888608
	speed: 0.1319s/iter; left time: 2984.8886s
Epoch: 3 cost time: 30.381572008132935
Epoch: 3, Steps: 233 Train Loss: 0.5958 (Forecasting Loss:0.2863 + XiCon Loss:3.0953 x Lambda(0.1)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1528
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5862657
	speed: 0.1383s/iter; left time: 3112.9912s
	iters: 200, epoch: 4 | loss: 0.5829790
	speed: 0.1314s/iter; left time: 2943.0535s
Epoch: 4 cost time: 31.266667127609253
Epoch: 4, Steps: 233 Train Loss: 0.5852 (Forecasting Loss:0.2771 + XiCon Loss:3.0813 x Lambda(0.1)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1591
Validation loss decreased (0.235843 --> 0.230326).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5776715
	speed: 0.1329s/iter; left time: 2959.0871s
	iters: 200, epoch: 5 | loss: 0.5756688
	speed: 0.1328s/iter; left time: 2944.3706s
Epoch: 5 cost time: 30.945684671401978
Epoch: 5, Steps: 233 Train Loss: 0.5800 (Forecasting Loss:0.2730 + XiCon Loss:3.0695 x Lambda(0.1)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.1522
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5878158
	speed: 0.1285s/iter; left time: 2831.3729s
	iters: 200, epoch: 6 | loss: 0.5823336
	speed: 0.1274s/iter; left time: 2794.0855s
Epoch: 6 cost time: 29.623497486114502
Epoch: 6, Steps: 233 Train Loss: 0.5783 (Forecasting Loss:0.2710 + XiCon Loss:3.0726 x Lambda(0.1)), Vali MSE Loss: 0.2312 Test MSE Loss: 0.1571
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5949627
	speed: 0.1373s/iter; left time: 2992.7918s
	iters: 200, epoch: 7 | loss: 0.5906150
	speed: 0.1231s/iter; left time: 2671.0726s
Epoch: 7 cost time: 30.419323205947876
Epoch: 7, Steps: 233 Train Loss: 0.5765 (Forecasting Loss:0.2698 + XiCon Loss:3.0678 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1547
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5642722
	speed: 0.1372s/iter; left time: 2958.5483s
	iters: 200, epoch: 8 | loss: 0.5880972
	speed: 0.1186s/iter; left time: 2545.8393s
Epoch: 8 cost time: 30.0212242603302
Epoch: 8, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.2692 + XiCon Loss:3.0661 x Lambda(0.1)), Vali MSE Loss: 0.2395 Test MSE Loss: 0.1552
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5621414
	speed: 0.1360s/iter; left time: 2901.5488s
	iters: 200, epoch: 9 | loss: 0.5823095
	speed: 0.1291s/iter; left time: 2741.4645s
Epoch: 9 cost time: 30.833163499832153
Epoch: 9, Steps: 233 Train Loss: 0.5753 (Forecasting Loss:0.2689 + XiCon Loss:3.0636 x Lambda(0.1)), Vali MSE Loss: 0.2382 Test MSE Loss: 0.1562
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5735908
	speed: 0.1377s/iter; left time: 2906.7908s
	iters: 200, epoch: 10 | loss: 0.5754818
	speed: 0.1331s/iter; left time: 2795.4270s
Epoch: 10 cost time: 31.39109969139099
Epoch: 10, Steps: 233 Train Loss: 0.5752 (Forecasting Loss:0.2685 + XiCon Loss:3.0660 x Lambda(0.1)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1544
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5899321
	speed: 0.1357s/iter; left time: 2831.5778s
	iters: 200, epoch: 11 | loss: 0.5798256
	speed: 0.1329s/iter; left time: 2759.6571s
Epoch: 11 cost time: 31.274842739105225
Epoch: 11, Steps: 233 Train Loss: 0.5751 (Forecasting Loss:0.2687 + XiCon Loss:3.0637 x Lambda(0.1)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1558
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5763909
	speed: 0.1373s/iter; left time: 2832.9182s
	iters: 200, epoch: 12 | loss: 0.5564135
	speed: 0.1300s/iter; left time: 2670.2268s
Epoch: 12 cost time: 31.21562361717224
Epoch: 12, Steps: 233 Train Loss: 0.5748 (Forecasting Loss:0.2684 + XiCon Loss:3.0639 x Lambda(0.1)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1559
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5815345
	speed: 0.1378s/iter; left time: 2811.7413s
	iters: 200, epoch: 13 | loss: 0.5770794
	speed: 0.1379s/iter; left time: 2800.2002s
Epoch: 13 cost time: 31.970974922180176
Epoch: 13, Steps: 233 Train Loss: 0.5746 (Forecasting Loss:0.2684 + XiCon Loss:3.0616 x Lambda(0.1)), Vali MSE Loss: 0.2407 Test MSE Loss: 0.1553
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5691933
	speed: 0.1379s/iter; left time: 2781.0093s
	iters: 200, epoch: 14 | loss: 0.5627793
	speed: 0.1293s/iter; left time: 2595.7900s
Epoch: 14 cost time: 31.279547214508057
Epoch: 14, Steps: 233 Train Loss: 0.5754 (Forecasting Loss:0.2686 + XiCon Loss:3.0675 x Lambda(0.1)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1555
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08574744313955307, mae:0.23249733448028564, mape:0.16566620767116547, mspe:0.041968706995248795 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 24.5120
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7639452
	speed: 0.1213s/iter; left time: 2814.5185s
	iters: 200, epoch: 1 | loss: 0.7148840
	speed: 0.0968s/iter; left time: 2235.5776s
Epoch: 1 cost time: 25.68851947784424
Epoch: 1, Steps: 233 Train Loss: 0.7501 (Forecasting Loss:0.4272 + XiCon Loss:3.2288 x Lambda(0.1)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.1701
Validation loss decreased (inf --> 0.301508).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6393884
	speed: 0.1183s/iter; left time: 2716.3170s
	iters: 200, epoch: 2 | loss: 0.6126499
	speed: 0.1029s/iter; left time: 2353.2184s
Epoch: 2 cost time: 24.76863408088684
Epoch: 2, Steps: 233 Train Loss: 0.6438 (Forecasting Loss:0.3322 + XiCon Loss:3.1161 x Lambda(0.1)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1620
Validation loss decreased (0.301508 --> 0.240831).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5922632
	speed: 0.1208s/iter; left time: 2745.8819s
	iters: 200, epoch: 3 | loss: 0.5939547
	speed: 0.1204s/iter; left time: 2725.7203s
Epoch: 3 cost time: 28.39941668510437
Epoch: 3, Steps: 233 Train Loss: 0.5950 (Forecasting Loss:0.2859 + XiCon Loss:3.0909 x Lambda(0.1)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1492
Validation loss decreased (0.240831 --> 0.239774).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5810366
	speed: 0.1224s/iter; left time: 2754.0752s
	iters: 200, epoch: 4 | loss: 0.5755451
	speed: 0.1202s/iter; left time: 2693.2433s
Epoch: 4 cost time: 28.28486704826355
Epoch: 4, Steps: 233 Train Loss: 0.5832 (Forecasting Loss:0.2733 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2377 Test MSE Loss: 0.1493
Validation loss decreased (0.239774 --> 0.237678).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5749830
	speed: 0.1109s/iter; left time: 2468.9906s
	iters: 200, epoch: 5 | loss: 0.5657468
	speed: 0.1220s/iter; left time: 2704.8262s
Epoch: 5 cost time: 27.247318267822266
Epoch: 5, Steps: 233 Train Loss: 0.5770 (Forecasting Loss:0.2672 + XiCon Loss:3.0988 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1491
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5802292
	speed: 0.1272s/iter; left time: 2802.4724s
	iters: 200, epoch: 6 | loss: 0.5689464
	speed: 0.1223s/iter; left time: 2683.8567s
Epoch: 6 cost time: 28.924943685531616
Epoch: 6, Steps: 233 Train Loss: 0.5740 (Forecasting Loss:0.2644 + XiCon Loss:3.0959 x Lambda(0.1)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1469
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5521554
	speed: 0.1319s/iter; left time: 2876.5377s
	iters: 200, epoch: 7 | loss: 0.5819516
	speed: 0.1173s/iter; left time: 2546.8211s
Epoch: 7 cost time: 28.920585870742798
Epoch: 7, Steps: 233 Train Loss: 0.5722 (Forecasting Loss:0.2627 + XiCon Loss:3.0941 x Lambda(0.1)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1490
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5753431
	speed: 0.1294s/iter; left time: 2791.1176s
	iters: 200, epoch: 8 | loss: 0.5646089
	speed: 0.1168s/iter; left time: 2507.9358s
Epoch: 8 cost time: 28.685821294784546
Epoch: 8, Steps: 233 Train Loss: 0.5713 (Forecasting Loss:0.2619 + XiCon Loss:3.0939 x Lambda(0.1)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1468
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5790522
	speed: 0.1231s/iter; left time: 2625.5264s
	iters: 200, epoch: 9 | loss: 0.5765980
	speed: 0.1223s/iter; left time: 2597.9877s
Epoch: 9 cost time: 28.815269708633423
Epoch: 9, Steps: 233 Train Loss: 0.5707 (Forecasting Loss:0.2614 + XiCon Loss:3.0933 x Lambda(0.1)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1481
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5826457
	speed: 0.1270s/iter; left time: 2679.6876s
	iters: 200, epoch: 10 | loss: 0.5594867
	speed: 0.1248s/iter; left time: 2622.3318s
Epoch: 10 cost time: 29.25663733482361
Epoch: 10, Steps: 233 Train Loss: 0.5708 (Forecasting Loss:0.2615 + XiCon Loss:3.0927 x Lambda(0.1)), Vali MSE Loss: 0.2396 Test MSE Loss: 0.1480
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5746683
	speed: 0.1215s/iter; left time: 2536.1488s
	iters: 200, epoch: 11 | loss: 0.5605949
	speed: 0.1267s/iter; left time: 2632.3571s
Epoch: 11 cost time: 28.94112253189087
Epoch: 11, Steps: 233 Train Loss: 0.5704 (Forecasting Loss:0.2610 + XiCon Loss:3.0939 x Lambda(0.1)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1479
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5751120
	speed: 0.1240s/iter; left time: 2559.1738s
	iters: 200, epoch: 12 | loss: 0.5726672
	speed: 0.1227s/iter; left time: 2520.7329s
Epoch: 12 cost time: 28.32748818397522
Epoch: 12, Steps: 233 Train Loss: 0.5702 (Forecasting Loss:0.2609 + XiCon Loss:3.0928 x Lambda(0.1)), Vali MSE Loss: 0.2392 Test MSE Loss: 0.1477
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5683290
	speed: 0.1227s/iter; left time: 2503.0078s
	iters: 200, epoch: 13 | loss: 0.5783939
	speed: 0.1179s/iter; left time: 2394.3783s
Epoch: 13 cost time: 28.411033153533936
Epoch: 13, Steps: 233 Train Loss: 0.5705 (Forecasting Loss:0.2614 + XiCon Loss:3.0912 x Lambda(0.1)), Vali MSE Loss: 0.2396 Test MSE Loss: 0.1475
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5609145
	speed: 0.1243s/iter; left time: 2506.9641s
	iters: 200, epoch: 14 | loss: 0.5789838
	speed: 0.1245s/iter; left time: 2499.1190s
Epoch: 14 cost time: 28.94472074508667
Epoch: 14, Steps: 233 Train Loss: 0.5705 (Forecasting Loss:0.2611 + XiCon Loss:3.0937 x Lambda(0.1)), Vali MSE Loss: 0.2397 Test MSE Loss: 0.1476
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.07739408314228058, mae:0.22112807631492615, mape:0.15983931720256805, mspe:0.040496889501810074 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.5276
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7581557
	speed: 0.1207s/iter; left time: 2799.2466s
	iters: 200, epoch: 1 | loss: 0.7529706
	speed: 0.1153s/iter; left time: 2663.6271s
Epoch: 1 cost time: 27.709380388259888
Epoch: 1, Steps: 233 Train Loss: 0.7640 (Forecasting Loss:0.4413 + XiCon Loss:3.2275 x Lambda(0.1)), Vali MSE Loss: 0.2974 Test MSE Loss: 0.1915
Validation loss decreased (inf --> 0.297393).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6284453
	speed: 0.1378s/iter; left time: 3164.2580s
	iters: 200, epoch: 2 | loss: 0.5731786
	speed: 0.1506s/iter; left time: 3444.9195s
Epoch: 2 cost time: 34.04775857925415
Epoch: 2, Steps: 233 Train Loss: 0.6218 (Forecasting Loss:0.3126 + XiCon Loss:3.0918 x Lambda(0.1)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5552176
	speed: 0.1339s/iter; left time: 3044.2556s
	iters: 200, epoch: 3 | loss: 0.5646216
	speed: 0.1439s/iter; left time: 3257.0162s
Epoch: 3 cost time: 32.67306041717529
Epoch: 3, Steps: 233 Train Loss: 0.5758 (Forecasting Loss:0.2709 + XiCon Loss:3.0489 x Lambda(0.1)), Vali MSE Loss: 0.2954 Test MSE Loss: 0.1722
Validation loss decreased (0.297393 --> 0.295353).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5603882
	speed: 0.1515s/iter; left time: 3408.9430s
	iters: 200, epoch: 4 | loss: 0.5816228
	speed: 0.1505s/iter; left time: 3372.4903s
Epoch: 4 cost time: 34.81955528259277
Epoch: 4, Steps: 233 Train Loss: 0.5660 (Forecasting Loss:0.2634 + XiCon Loss:3.0258 x Lambda(0.1)), Vali MSE Loss: 0.3072 Test MSE Loss: 0.1541
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5697796
	speed: 0.1508s/iter; left time: 3358.3001s
	iters: 200, epoch: 5 | loss: 0.5553368
	speed: 0.1447s/iter; left time: 3207.8326s
Epoch: 5 cost time: 34.30811309814453
Epoch: 5, Steps: 233 Train Loss: 0.5612 (Forecasting Loss:0.2596 + XiCon Loss:3.0158 x Lambda(0.1)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.1530
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5675859
	speed: 0.1457s/iter; left time: 3210.1281s
	iters: 200, epoch: 6 | loss: 0.5540447
	speed: 0.1585s/iter; left time: 3477.3333s
Epoch: 6 cost time: 35.833134174346924
Epoch: 6, Steps: 233 Train Loss: 0.5581 (Forecasting Loss:0.2572 + XiCon Loss:3.0084 x Lambda(0.1)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.1550
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5692632
	speed: 0.1523s/iter; left time: 3320.8639s
	iters: 200, epoch: 7 | loss: 0.5467535
	speed: 0.1390s/iter; left time: 3016.8333s
Epoch: 7 cost time: 34.46306657791138
Epoch: 7, Steps: 233 Train Loss: 0.5570 (Forecasting Loss:0.2561 + XiCon Loss:3.0084 x Lambda(0.1)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.1549
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5700532
	speed: 0.1527s/iter; left time: 3292.7809s
	iters: 200, epoch: 8 | loss: 0.5636162
	speed: 0.1505s/iter; left time: 3230.9337s
Epoch: 8 cost time: 35.34596920013428
Epoch: 8, Steps: 233 Train Loss: 0.5562 (Forecasting Loss:0.2554 + XiCon Loss:3.0084 x Lambda(0.1)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.1548
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5550482
	speed: 0.1481s/iter; left time: 3160.7639s
	iters: 200, epoch: 9 | loss: 0.5515069
	speed: 0.1527s/iter; left time: 3243.2915s
Epoch: 9 cost time: 35.06203508377075
Epoch: 9, Steps: 233 Train Loss: 0.5556 (Forecasting Loss:0.2550 + XiCon Loss:3.0058 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.1553
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5443445
	speed: 0.1505s/iter; left time: 3175.6769s
	iters: 200, epoch: 10 | loss: 0.5533682
	speed: 0.1539s/iter; left time: 3233.1990s
Epoch: 10 cost time: 35.16158437728882
Epoch: 10, Steps: 233 Train Loss: 0.5556 (Forecasting Loss:0.2548 + XiCon Loss:3.0079 x Lambda(0.1)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.1549
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5488089
	speed: 0.1500s/iter; left time: 3130.9331s
	iters: 200, epoch: 11 | loss: 0.5377891
	speed: 0.1494s/iter; left time: 3102.4820s
Epoch: 11 cost time: 34.98356914520264
Epoch: 11, Steps: 233 Train Loss: 0.5558 (Forecasting Loss:0.2551 + XiCon Loss:3.0071 x Lambda(0.1)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.1559
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5609912
	speed: 0.1478s/iter; left time: 3050.5663s
	iters: 200, epoch: 12 | loss: 0.5628734
	speed: 0.1546s/iter; left time: 3176.0411s
Epoch: 12 cost time: 34.83858275413513
Epoch: 12, Steps: 233 Train Loss: 0.5557 (Forecasting Loss:0.2547 + XiCon Loss:3.0102 x Lambda(0.1)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.1557
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5720927
	speed: 0.1471s/iter; left time: 3002.3683s
	iters: 200, epoch: 13 | loss: 0.5476669
	speed: 0.1564s/iter; left time: 3175.0990s
Epoch: 13 cost time: 35.66327404975891
Epoch: 13, Steps: 233 Train Loss: 0.5549 (Forecasting Loss:0.2546 + XiCon Loss:3.0027 x Lambda(0.1)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.1560
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09786143153905869, mae:0.24652233719825745, mape:0.17493219673633575, mspe:0.04791257902979851 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.9022
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7916356
	speed: 0.1214s/iter; left time: 2815.9230s
	iters: 200, epoch: 1 | loss: 0.7469203
	speed: 0.1194s/iter; left time: 2758.2828s
Epoch: 1 cost time: 28.269590616226196
Epoch: 1, Steps: 233 Train Loss: 0.7615 (Forecasting Loss:0.4404 + XiCon Loss:3.2115 x Lambda(0.1)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.1702
Validation loss decreased (inf --> 0.294337).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6258292
	speed: 0.1395s/iter; left time: 3204.0381s
	iters: 200, epoch: 2 | loss: 0.6057887
	speed: 0.1375s/iter; left time: 3143.9766s
Epoch: 2 cost time: 32.55444550514221
Epoch: 2, Steps: 233 Train Loss: 0.6286 (Forecasting Loss:0.3170 + XiCon Loss:3.1154 x Lambda(0.1)), Vali MSE Loss: 0.4265 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6072800
	speed: 0.1438s/iter; left time: 3268.1705s
	iters: 200, epoch: 3 | loss: 0.5851110
	speed: 0.1401s/iter; left time: 3171.0534s
Epoch: 3 cost time: 32.98656487464905
Epoch: 3, Steps: 233 Train Loss: 0.5936 (Forecasting Loss:0.2898 + XiCon Loss:3.0376 x Lambda(0.1)), Vali MSE Loss: 0.4040 Test MSE Loss: 0.1560
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6066635
	speed: 0.1505s/iter; left time: 3387.4979s
	iters: 200, epoch: 4 | loss: 0.5857838
	speed: 0.1424s/iter; left time: 3190.8558s
Epoch: 4 cost time: 34.273292541503906
Epoch: 4, Steps: 233 Train Loss: 0.5811 (Forecasting Loss:0.2806 + XiCon Loss:3.0050 x Lambda(0.1)), Vali MSE Loss: 0.4625 Test MSE Loss: 0.1548
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5778214
	speed: 0.1498s/iter; left time: 3335.8851s
	iters: 200, epoch: 5 | loss: 0.5859929
	speed: 0.1427s/iter; left time: 3162.6760s
Epoch: 5 cost time: 34.016974449157715
Epoch: 5, Steps: 233 Train Loss: 0.5740 (Forecasting Loss:0.2742 + XiCon Loss:2.9972 x Lambda(0.1)), Vali MSE Loss: 0.4361 Test MSE Loss: 0.1577
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5758700
	speed: 0.1488s/iter; left time: 3278.6564s
	iters: 200, epoch: 6 | loss: 0.5746834
	speed: 0.1408s/iter; left time: 3089.0226s
Epoch: 6 cost time: 33.70109844207764
Epoch: 6, Steps: 233 Train Loss: 0.5705 (Forecasting Loss:0.2714 + XiCon Loss:2.9907 x Lambda(0.1)), Vali MSE Loss: 0.4388 Test MSE Loss: 0.1554
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5547709
	speed: 0.1480s/iter; left time: 3226.8075s
	iters: 200, epoch: 7 | loss: 0.5650687
	speed: 0.1464s/iter; left time: 3177.2832s
Epoch: 7 cost time: 34.63045644760132
Epoch: 7, Steps: 233 Train Loss: 0.5696 (Forecasting Loss:0.2703 + XiCon Loss:2.9930 x Lambda(0.1)), Vali MSE Loss: 0.4604 Test MSE Loss: 0.1574
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5555685
	speed: 0.1533s/iter; left time: 3307.4079s
	iters: 200, epoch: 8 | loss: 0.5632032
	speed: 0.1055s/iter; left time: 2265.6307s
Epoch: 8 cost time: 29.787296295166016
Epoch: 8, Steps: 233 Train Loss: 0.5683 (Forecasting Loss:0.2695 + XiCon Loss:2.9874 x Lambda(0.1)), Vali MSE Loss: 0.4612 Test MSE Loss: 0.1581
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5668887
	speed: 0.1488s/iter; left time: 3175.6277s
	iters: 200, epoch: 9 | loss: 0.5490746
	speed: 0.1348s/iter; left time: 2862.2967s
Epoch: 9 cost time: 32.66650319099426
Epoch: 9, Steps: 233 Train Loss: 0.5682 (Forecasting Loss:0.2691 + XiCon Loss:2.9912 x Lambda(0.1)), Vali MSE Loss: 0.4534 Test MSE Loss: 0.1591
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5547775
	speed: 0.1498s/iter; left time: 3162.0719s
	iters: 200, epoch: 10 | loss: 0.5559577
	speed: 0.1382s/iter; left time: 2902.6302s
Epoch: 10 cost time: 33.593307971954346
Epoch: 10, Steps: 233 Train Loss: 0.5676 (Forecasting Loss:0.2688 + XiCon Loss:2.9883 x Lambda(0.1)), Vali MSE Loss: 0.4519 Test MSE Loss: 0.1592
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5599370
	speed: 0.1431s/iter; left time: 2986.0894s
	iters: 200, epoch: 11 | loss: 0.5876094
	speed: 0.1284s/iter; left time: 2667.3806s
Epoch: 11 cost time: 32.21940732002258
Epoch: 11, Steps: 233 Train Loss: 0.5674 (Forecasting Loss:0.2687 + XiCon Loss:2.9868 x Lambda(0.1)), Vali MSE Loss: 0.4543 Test MSE Loss: 0.1588
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.0947810709476471, mae:0.24555917084217072, mape:0.17456500232219696, mspe:0.04593809321522713 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.5527
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7719861
	speed: 0.1054s/iter; left time: 2446.2651s
	iters: 200, epoch: 1 | loss: 0.7159423
	speed: 0.1102s/iter; left time: 2545.8852s
Epoch: 1 cost time: 25.524085998535156
Epoch: 1, Steps: 233 Train Loss: 0.7616 (Forecasting Loss:0.4414 + XiCon Loss:3.2022 x Lambda(0.1)), Vali MSE Loss: 0.2934 Test MSE Loss: 0.1775
Validation loss decreased (inf --> 0.293364).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6559908
	speed: 0.1208s/iter; left time: 2775.0461s
	iters: 200, epoch: 2 | loss: 0.6170802
	speed: 0.1137s/iter; left time: 2599.9109s
Epoch: 2 cost time: 27.25185465812683
Epoch: 2, Steps: 233 Train Loss: 0.6455 (Forecasting Loss:0.3355 + XiCon Loss:3.0997 x Lambda(0.1)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1489
Validation loss decreased (0.293364 --> 0.214901).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5862774
	speed: 0.1170s/iter; left time: 2660.2132s
	iters: 200, epoch: 3 | loss: 0.5860577
	speed: 0.1175s/iter; left time: 2659.1856s
Epoch: 3 cost time: 27.265197038650513
Epoch: 3, Steps: 233 Train Loss: 0.5905 (Forecasting Loss:0.2826 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1418
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5773973
	speed: 0.1164s/iter; left time: 2620.3532s
	iters: 200, epoch: 4 | loss: 0.5707030
	speed: 0.1136s/iter; left time: 2544.9124s
Epoch: 4 cost time: 26.744571685791016
Epoch: 4, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2684 + XiCon Loss:3.0905 x Lambda(0.1)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1406
Validation loss decreased (0.214901 --> 0.213765).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5900807
	speed: 0.1200s/iter; left time: 2671.7967s
	iters: 200, epoch: 5 | loss: 0.5558763
	speed: 0.1129s/iter; left time: 2503.2552s
Epoch: 5 cost time: 27.215465784072876
Epoch: 5, Steps: 233 Train Loss: 0.5703 (Forecasting Loss:0.2617 + XiCon Loss:3.0857 x Lambda(0.1)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1417
Validation loss decreased (0.213765 --> 0.212314).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5587900
	speed: 0.1204s/iter; left time: 2652.5931s
	iters: 200, epoch: 6 | loss: 0.5713614
	speed: 0.1133s/iter; left time: 2484.7579s
Epoch: 6 cost time: 27.224098205566406
Epoch: 6, Steps: 233 Train Loss: 0.5663 (Forecasting Loss:0.2576 + XiCon Loss:3.0877 x Lambda(0.1)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1417
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5703570
	speed: 0.1192s/iter; left time: 2598.3382s
	iters: 200, epoch: 7 | loss: 0.5739857
	speed: 0.1136s/iter; left time: 2465.8963s
Epoch: 7 cost time: 26.99107527732849
Epoch: 7, Steps: 233 Train Loss: 0.5641 (Forecasting Loss:0.2555 + XiCon Loss:3.0857 x Lambda(0.1)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1426
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5748869
	speed: 0.1166s/iter; left time: 2515.6695s
	iters: 200, epoch: 8 | loss: 0.5482002
	speed: 0.1119s/iter; left time: 2402.1444s
Epoch: 8 cost time: 26.91592764854431
Epoch: 8, Steps: 233 Train Loss: 0.5635 (Forecasting Loss:0.2552 + XiCon Loss:3.0835 x Lambda(0.1)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1413
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5605014
	speed: 0.1200s/iter; left time: 2560.8763s
	iters: 200, epoch: 9 | loss: 0.5717543
	speed: 0.1133s/iter; left time: 2406.4246s
Epoch: 9 cost time: 27.063934564590454
Epoch: 9, Steps: 233 Train Loss: 0.5630 (Forecasting Loss:0.2549 + XiCon Loss:3.0811 x Lambda(0.1)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1420
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5680519
	speed: 0.1190s/iter; left time: 2511.6173s
	iters: 200, epoch: 10 | loss: 0.5548800
	speed: 0.1189s/iter; left time: 2496.3770s
Epoch: 10 cost time: 27.525838375091553
Epoch: 10, Steps: 233 Train Loss: 0.5627 (Forecasting Loss:0.2545 + XiCon Loss:3.0821 x Lambda(0.1)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1413
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5602837
	speed: 0.1144s/iter; left time: 2386.9056s
	iters: 200, epoch: 11 | loss: 0.5575894
	speed: 0.1144s/iter; left time: 2375.5931s
Epoch: 11 cost time: 26.608318567276
Epoch: 11, Steps: 233 Train Loss: 0.5631 (Forecasting Loss:0.2545 + XiCon Loss:3.0852 x Lambda(0.1)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.1414
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5713973
	speed: 0.1178s/iter; left time: 2431.5766s
	iters: 200, epoch: 12 | loss: 0.5558860
	speed: 0.1150s/iter; left time: 2362.5568s
Epoch: 12 cost time: 27.171959400177002
Epoch: 12, Steps: 233 Train Loss: 0.5624 (Forecasting Loss:0.2540 + XiCon Loss:3.0838 x Lambda(0.1)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.1413
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5540717
	speed: 0.1169s/iter; left time: 2385.6240s
	iters: 200, epoch: 13 | loss: 0.5593320
	speed: 0.1161s/iter; left time: 2357.8155s
Epoch: 13 cost time: 27.475101947784424
Epoch: 13, Steps: 233 Train Loss: 0.5626 (Forecasting Loss:0.2542 + XiCon Loss:3.0842 x Lambda(0.1)), Vali MSE Loss: 0.2151 Test MSE Loss: 0.1415
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5676829
	speed: 0.1160s/iter; left time: 2340.9333s
	iters: 200, epoch: 14 | loss: 0.5683558
	speed: 0.1154s/iter; left time: 2316.0474s
Epoch: 14 cost time: 26.925184726715088
Epoch: 14, Steps: 233 Train Loss: 0.5624 (Forecasting Loss:0.2541 + XiCon Loss:3.0829 x Lambda(0.1)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1414
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5689415
	speed: 0.1188s/iter; left time: 2368.3387s
	iters: 200, epoch: 15 | loss: 0.5660613
	speed: 0.1155s/iter; left time: 2291.7066s
Epoch: 15 cost time: 27.283767700195312
Epoch: 15, Steps: 233 Train Loss: 0.5625 (Forecasting Loss:0.2544 + XiCon Loss:3.0810 x Lambda(0.1)), Vali MSE Loss: 0.2153 Test MSE Loss: 0.1414
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.07162609696388245, mae:0.21176591515541077, mape:0.15521588921546936, mspe:0.03967192769050598 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0855+-0.01384, MAE:0.2315+-0.01884, MAPE:0.1660+-0.01089, MSPE:0.0432+-0.00443, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5189
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.5367470
	speed: 0.0530s/iter; left time: 1400.5380s
	iters: 200, epoch: 1 | loss: 30.8688164
	speed: 0.0491s/iter; left time: 1290.8271s
Epoch: 1 cost time: 13.153231620788574
Epoch: 1, Steps: 265 Train Loss: 31.3410 (Forecasting Loss:0.2279 + XiCon Loss:3.1113 x Lambda(10.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1682
Validation loss decreased (inf --> 0.208951).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8255386
	speed: 0.0497s/iter; left time: 1299.2270s
	iters: 200, epoch: 2 | loss: 29.8660393
	speed: 0.0450s/iter; left time: 1171.2590s
Epoch: 2 cost time: 12.562824010848999
Epoch: 2, Steps: 265 Train Loss: 30.5887 (Forecasting Loss:0.2091 + XiCon Loss:3.0380 x Lambda(10.0)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.1672
Validation loss decreased (0.208951 --> 0.206989).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.6609764
	speed: 0.0537s/iter; left time: 1389.8871s
	iters: 200, epoch: 3 | loss: 30.7560139
	speed: 0.0489s/iter; left time: 1261.1657s
Epoch: 3 cost time: 13.29774284362793
Epoch: 3, Steps: 265 Train Loss: 30.1787 (Forecasting Loss:0.2012 + XiCon Loss:2.9978 x Lambda(10.0)), Vali MSE Loss: 0.2039 Test MSE Loss: 0.1622
Validation loss decreased (0.206989 --> 0.203906).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.1829815
	speed: 0.0492s/iter; left time: 1260.2123s
	iters: 200, epoch: 4 | loss: 30.8789806
	speed: 0.0463s/iter; left time: 1181.6302s
Epoch: 4 cost time: 12.503931045532227
Epoch: 4, Steps: 265 Train Loss: 30.1119 (Forecasting Loss:0.1991 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1609
Validation loss decreased (0.203906 --> 0.201061).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.0001450
	speed: 0.0524s/iter; left time: 1328.0975s
	iters: 200, epoch: 5 | loss: 30.5726967
	speed: 0.0497s/iter; left time: 1253.2826s
Epoch: 5 cost time: 13.27553129196167
Epoch: 5, Steps: 265 Train Loss: 30.0602 (Forecasting Loss:0.1972 + XiCon Loss:2.9863 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1598
Validation loss decreased (0.201061 --> 0.199323).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.4041824
	speed: 0.0507s/iter; left time: 1270.8992s
	iters: 200, epoch: 6 | loss: 31.3195572
	speed: 0.0459s/iter; left time: 1147.2157s
Epoch: 6 cost time: 12.70447325706482
Epoch: 6, Steps: 265 Train Loss: 30.1304 (Forecasting Loss:0.1965 + XiCon Loss:2.9934 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9498978
	speed: 0.0526s/iter; left time: 1306.2681s
	iters: 200, epoch: 7 | loss: 30.3517971
	speed: 0.0456s/iter; left time: 1127.6173s
Epoch: 7 cost time: 12.941758871078491
Epoch: 7, Steps: 265 Train Loss: 30.0802 (Forecasting Loss:0.1963 + XiCon Loss:2.9884 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6051025
	speed: 0.0531s/iter; left time: 1304.0623s
	iters: 200, epoch: 8 | loss: 29.7383957
	speed: 0.0472s/iter; left time: 1154.3619s
Epoch: 8 cost time: 12.969974756240845
Epoch: 8, Steps: 265 Train Loss: 30.0231 (Forecasting Loss:0.1960 + XiCon Loss:2.9827 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.7598553
	speed: 0.0482s/iter; left time: 1169.8605s
	iters: 200, epoch: 9 | loss: 29.9566097
	speed: 0.0439s/iter; left time: 1060.3945s
Epoch: 9 cost time: 11.635913133621216
Epoch: 9, Steps: 265 Train Loss: 30.0794 (Forecasting Loss:0.1959 + XiCon Loss:2.9884 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
Validation loss decreased (0.199323 --> 0.199282).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1945381
	speed: 0.0640s/iter; left time: 1537.1310s
	iters: 200, epoch: 10 | loss: 30.0638924
	speed: 0.0314s/iter; left time: 751.4754s
Epoch: 10 cost time: 11.6492600440979
Epoch: 10, Steps: 265 Train Loss: 30.0246 (Forecasting Loss:0.1958 + XiCon Loss:2.9829 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5761566
	speed: 0.0500s/iter; left time: 1188.2579s
	iters: 200, epoch: 11 | loss: 30.1356869
	speed: 0.0499s/iter; left time: 1179.1151s
Epoch: 11 cost time: 13.439744472503662
Epoch: 11, Steps: 265 Train Loss: 30.1073 (Forecasting Loss:0.1959 + XiCon Loss:2.9911 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9731045
	speed: 0.0546s/iter; left time: 1282.3527s
	iters: 200, epoch: 12 | loss: 29.4248962
	speed: 0.0477s/iter; left time: 1115.3859s
Epoch: 12 cost time: 12.21560001373291
Epoch: 12, Steps: 265 Train Loss: 30.0837 (Forecasting Loss:0.1958 + XiCon Loss:2.9888 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6905003
	speed: 0.0523s/iter; left time: 1214.1146s
	iters: 200, epoch: 13 | loss: 29.8206539
	speed: 0.0509s/iter; left time: 1177.2297s
Epoch: 13 cost time: 13.47555422782898
Epoch: 13, Steps: 265 Train Loss: 30.0787 (Forecasting Loss:0.1958 + XiCon Loss:2.9883 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6235905
	speed: 0.0495s/iter; left time: 1136.6073s
	iters: 200, epoch: 14 | loss: 30.4440613
	speed: 0.0463s/iter; left time: 1058.6519s
Epoch: 14 cost time: 11.428787469863892
Epoch: 14, Steps: 265 Train Loss: 30.0775 (Forecasting Loss:0.1957 + XiCon Loss:2.9882 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.5189819
	speed: 0.0471s/iter; left time: 1068.1127s
	iters: 200, epoch: 15 | loss: 29.3144398
	speed: 0.0475s/iter; left time: 1072.2296s
Epoch: 15 cost time: 12.959399700164795
Epoch: 15, Steps: 265 Train Loss: 30.0874 (Forecasting Loss:0.1958 + XiCon Loss:2.9892 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1589
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0588627
	speed: 0.0508s/iter; left time: 1138.5672s
	iters: 200, epoch: 16 | loss: 30.3558941
	speed: 0.0455s/iter; left time: 1015.0030s
Epoch: 16 cost time: 11.50953459739685
Epoch: 16, Steps: 265 Train Loss: 30.1114 (Forecasting Loss:0.1958 + XiCon Loss:2.9916 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1589
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.1426849
	speed: 0.0487s/iter; left time: 1078.1328s
	iters: 200, epoch: 17 | loss: 29.9811020
	speed: 0.0465s/iter; left time: 1025.7333s
Epoch: 17 cost time: 12.72316837310791
Epoch: 17, Steps: 265 Train Loss: 30.0767 (Forecasting Loss:0.1957 + XiCon Loss:2.9881 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.7231770
	speed: 0.0521s/iter; left time: 1141.2944s
	iters: 200, epoch: 18 | loss: 29.3933964
	speed: 0.0469s/iter; left time: 1022.3464s
Epoch: 18 cost time: 11.837544202804565
Epoch: 18, Steps: 265 Train Loss: 30.0729 (Forecasting Loss:0.1958 + XiCon Loss:2.9877 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2098866
	speed: 0.0538s/iter; left time: 1162.9868s
	iters: 200, epoch: 19 | loss: 30.6419239
	speed: 0.0526s/iter; left time: 1132.2889s
Epoch: 19 cost time: 13.756307125091553
Epoch: 19, Steps: 265 Train Loss: 30.1470 (Forecasting Loss:0.1958 + XiCon Loss:2.9951 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09203475713729858, mae:0.22566530108451843, mape:0.5430352687835693, mspe:11.27361011505127 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9418
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.6076069
	speed: 0.0531s/iter; left time: 1402.3801s
	iters: 200, epoch: 1 | loss: 30.3518162
	speed: 0.0497s/iter; left time: 1308.2261s
Epoch: 1 cost time: 13.545011043548584
Epoch: 1, Steps: 265 Train Loss: 31.1936 (Forecasting Loss:0.2276 + XiCon Loss:3.0966 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1672
Validation loss decreased (inf --> 0.210333).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.3995323
	speed: 0.0477s/iter; left time: 1247.5829s
	iters: 200, epoch: 2 | loss: 30.7048550
	speed: 0.0482s/iter; left time: 1254.3177s
Epoch: 2 cost time: 12.58628249168396
Epoch: 2, Steps: 265 Train Loss: 30.7611 (Forecasting Loss:0.2075 + XiCon Loss:3.0554 x Lambda(10.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1680
Validation loss decreased (0.210333 --> 0.206583).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7457314
	speed: 0.0493s/iter; left time: 1275.0721s
	iters: 200, epoch: 3 | loss: 31.2442837
	speed: 0.0479s/iter; left time: 1233.3268s
Epoch: 3 cost time: 12.87814998626709
Epoch: 3, Steps: 265 Train Loss: 30.4296 (Forecasting Loss:0.2010 + XiCon Loss:3.0229 x Lambda(10.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1623
Validation loss decreased (0.206583 --> 0.205034).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3311100
	speed: 0.0506s/iter; left time: 1296.0585s
	iters: 200, epoch: 4 | loss: 30.6713505
	speed: 0.0490s/iter; left time: 1250.7978s
Epoch: 4 cost time: 13.127277374267578
Epoch: 4, Steps: 265 Train Loss: 30.6885 (Forecasting Loss:0.1988 + XiCon Loss:3.0490 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1609
Validation loss decreased (0.205034 --> 0.201217).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0892372
	speed: 0.0507s/iter; left time: 1285.4050s
	iters: 200, epoch: 5 | loss: 29.8233681
	speed: 0.0446s/iter; left time: 1126.9473s
Epoch: 5 cost time: 12.602592945098877
Epoch: 5, Steps: 265 Train Loss: 30.4114 (Forecasting Loss:0.1972 + XiCon Loss:3.0214 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1600
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.3945827
	speed: 0.0504s/iter; left time: 1263.1423s
	iters: 200, epoch: 6 | loss: 32.3470726
	speed: 0.0473s/iter; left time: 1180.6344s
Epoch: 6 cost time: 13.052048206329346
Epoch: 6, Steps: 265 Train Loss: 30.3500 (Forecasting Loss:0.1964 + XiCon Loss:3.0154 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
Validation loss decreased (0.201217 --> 0.199629).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6658325
	speed: 0.0534s/iter; left time: 1324.0577s
	iters: 200, epoch: 7 | loss: 30.8766556
	speed: 0.0438s/iter; left time: 1081.2562s
Epoch: 7 cost time: 13.046679019927979
Epoch: 7, Steps: 265 Train Loss: 30.3171 (Forecasting Loss:0.1962 + XiCon Loss:3.0121 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2240543
	speed: 0.0511s/iter; left time: 1253.7058s
	iters: 200, epoch: 8 | loss: 30.4462261
	speed: 0.0480s/iter; left time: 1172.8628s
Epoch: 8 cost time: 13.121176481246948
Epoch: 8, Steps: 265 Train Loss: 30.3293 (Forecasting Loss:0.1960 + XiCon Loss:3.0133 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.2808151
	speed: 0.0475s/iter; left time: 1153.7475s
	iters: 200, epoch: 9 | loss: 32.5042572
	speed: 0.0444s/iter; left time: 1074.0766s
Epoch: 9 cost time: 12.230995178222656
Epoch: 9, Steps: 265 Train Loss: 30.3497 (Forecasting Loss:0.1958 + XiCon Loss:3.0154 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1589
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1541386
	speed: 0.0518s/iter; left time: 1243.1449s
	iters: 200, epoch: 10 | loss: 29.4032555
	speed: 0.0475s/iter; left time: 1136.3363s
Epoch: 10 cost time: 13.045358896255493
Epoch: 10, Steps: 265 Train Loss: 30.3517 (Forecasting Loss:0.1958 + XiCon Loss:3.0156 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.2803612
	speed: 0.0500s/iter; left time: 1187.7602s
	iters: 200, epoch: 11 | loss: 30.9725475
	speed: 0.0472s/iter; left time: 1116.1538s
Epoch: 11 cost time: 12.757351160049438
Epoch: 11, Steps: 265 Train Loss: 30.2919 (Forecasting Loss:0.1957 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.7362175
	speed: 0.0543s/iter; left time: 1274.4511s
	iters: 200, epoch: 12 | loss: 30.2523460
	speed: 0.0468s/iter; left time: 1095.5412s
Epoch: 12 cost time: 13.157365798950195
Epoch: 12, Steps: 265 Train Loss: 30.2459 (Forecasting Loss:0.1957 + XiCon Loss:3.0050 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8760948
	speed: 0.0544s/iter; left time: 1263.2898s
	iters: 200, epoch: 13 | loss: 29.6027298
	speed: 0.0486s/iter; left time: 1124.4694s
Epoch: 13 cost time: 13.389212846755981
Epoch: 13, Steps: 265 Train Loss: 30.3451 (Forecasting Loss:0.1957 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1588
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5202599
	speed: 0.0532s/iter; left time: 1220.2040s
	iters: 200, epoch: 14 | loss: 30.7528038
	speed: 0.0442s/iter; left time: 1009.7036s
Epoch: 14 cost time: 12.994911909103394
Epoch: 14, Steps: 265 Train Loss: 30.3139 (Forecasting Loss:0.1957 + XiCon Loss:3.0118 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1588
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2625999
	speed: 0.0531s/iter; left time: 1205.6215s
	iters: 200, epoch: 15 | loss: 29.7987595
	speed: 0.0475s/iter; left time: 1073.6126s
Epoch: 15 cost time: 13.200786828994751
Epoch: 15, Steps: 265 Train Loss: 30.2829 (Forecasting Loss:0.1957 + XiCon Loss:3.0087 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1588
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9748058
	speed: 0.0487s/iter; left time: 1092.7472s
	iters: 200, epoch: 16 | loss: 29.0888767
	speed: 0.0469s/iter; left time: 1047.8843s
Epoch: 16 cost time: 12.648706912994385
Epoch: 16, Steps: 265 Train Loss: 30.2390 (Forecasting Loss:0.1956 + XiCon Loss:3.0043 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1588
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0920223593711853, mae:0.22585034370422363, mape:0.5436030626296997, mspe:11.271316528320312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.7716
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.0951462
	speed: 0.0487s/iter; left time: 1284.8130s
	iters: 200, epoch: 1 | loss: 31.0658073
	speed: 0.0464s/iter; left time: 1219.4346s
Epoch: 1 cost time: 12.596493482589722
Epoch: 1, Steps: 265 Train Loss: 31.5381 (Forecasting Loss:0.2259 + XiCon Loss:3.1312 x Lambda(10.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1671
Validation loss decreased (inf --> 0.210994).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.5290051
	speed: 0.0501s/iter; left time: 1309.5723s
	iters: 200, epoch: 2 | loss: 32.5010948
	speed: 0.0461s/iter; left time: 1199.8963s
Epoch: 2 cost time: 12.52040433883667
Epoch: 2, Steps: 265 Train Loss: 31.1790 (Forecasting Loss:0.2083 + XiCon Loss:3.0971 x Lambda(10.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1647
Validation loss decreased (0.210994 --> 0.205468).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.9305744
	speed: 0.0511s/iter; left time: 1321.1729s
	iters: 200, epoch: 3 | loss: 30.2787342
	speed: 0.0496s/iter; left time: 1278.2347s
Epoch: 3 cost time: 13.534953594207764
Epoch: 3, Steps: 265 Train Loss: 31.0313 (Forecasting Loss:0.2014 + XiCon Loss:3.0830 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1622
Validation loss decreased (0.205468 --> 0.202352).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1348820
	speed: 0.0500s/iter; left time: 1281.3402s
	iters: 200, epoch: 4 | loss: 31.8024025
	speed: 0.0433s/iter; left time: 1103.7718s
Epoch: 4 cost time: 12.654442071914673
Epoch: 4, Steps: 265 Train Loss: 30.7224 (Forecasting Loss:0.1984 + XiCon Loss:3.0524 x Lambda(10.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1617
Validation loss decreased (0.202352 --> 0.202062).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7430534
	speed: 0.0521s/iter; left time: 1319.0573s
	iters: 200, epoch: 5 | loss: 31.2940636
	speed: 0.0495s/iter; left time: 1249.9296s
Epoch: 5 cost time: 13.28899097442627
Epoch: 5, Steps: 265 Train Loss: 30.6120 (Forecasting Loss:0.1970 + XiCon Loss:3.0415 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1593
Validation loss decreased (0.202062 --> 0.200319).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.8901672
	speed: 0.0459s/iter; left time: 1149.7610s
	iters: 200, epoch: 6 | loss: 30.8582497
	speed: 0.0462s/iter; left time: 1152.7011s
Epoch: 6 cost time: 12.170375347137451
Epoch: 6, Steps: 265 Train Loss: 30.5829 (Forecasting Loss:0.1968 + XiCon Loss:3.0386 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5275364
	speed: 0.0556s/iter; left time: 1380.2043s
	iters: 200, epoch: 7 | loss: 30.1153336
	speed: 0.0505s/iter; left time: 1248.9290s
Epoch: 7 cost time: 13.622925043106079
Epoch: 7, Steps: 265 Train Loss: 30.5642 (Forecasting Loss:0.1962 + XiCon Loss:3.0368 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1594
Validation loss decreased (0.200319 --> 0.199270).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1319695
	speed: 0.0494s/iter; left time: 1212.4821s
	iters: 200, epoch: 8 | loss: 30.3376999
	speed: 0.0466s/iter; left time: 1138.3655s
Epoch: 8 cost time: 12.590478658676147
Epoch: 8, Steps: 265 Train Loss: 30.6175 (Forecasting Loss:0.1960 + XiCon Loss:3.0421 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4683685
	speed: 0.0545s/iter; left time: 1324.2419s
	iters: 200, epoch: 9 | loss: 30.8086948
	speed: 0.0460s/iter; left time: 1112.6337s
Epoch: 9 cost time: 13.05908465385437
Epoch: 9, Steps: 265 Train Loss: 30.5621 (Forecasting Loss:0.1960 + XiCon Loss:3.0366 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1624031
	speed: 0.0547s/iter; left time: 1314.0194s
	iters: 200, epoch: 10 | loss: 31.3851566
	speed: 0.0500s/iter; left time: 1195.8614s
Epoch: 10 cost time: 13.70123839378357
Epoch: 10, Steps: 265 Train Loss: 30.5536 (Forecasting Loss:0.1959 + XiCon Loss:3.0358 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5151901
	speed: 0.0515s/iter; left time: 1224.0753s
	iters: 200, epoch: 11 | loss: 30.2522621
	speed: 0.0451s/iter; left time: 1066.9381s
Epoch: 11 cost time: 12.756154537200928
Epoch: 11, Steps: 265 Train Loss: 30.5744 (Forecasting Loss:0.1959 + XiCon Loss:3.0378 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5996590
	speed: 0.0502s/iter; left time: 1177.9906s
	iters: 200, epoch: 12 | loss: 30.8667240
	speed: 0.0481s/iter; left time: 1125.5317s
Epoch: 12 cost time: 12.983285188674927
Epoch: 12, Steps: 265 Train Loss: 30.5427 (Forecasting Loss:0.1959 + XiCon Loss:3.0347 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2314491
	speed: 0.0486s/iter; left time: 1128.4940s
	iters: 200, epoch: 13 | loss: 32.2100525
	speed: 0.0488s/iter; left time: 1128.2447s
Epoch: 13 cost time: 12.905295372009277
Epoch: 13, Steps: 265 Train Loss: 30.6361 (Forecasting Loss:0.1958 + XiCon Loss:3.0440 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.1988182
	speed: 0.0530s/iter; left time: 1216.0034s
	iters: 200, epoch: 14 | loss: 29.7447281
	speed: 0.0478s/iter; left time: 1093.2808s
Epoch: 14 cost time: 13.19636583328247
Epoch: 14, Steps: 265 Train Loss: 30.5930 (Forecasting Loss:0.1958 + XiCon Loss:3.0397 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.8495350
	speed: 0.0494s/iter; left time: 1120.6356s
	iters: 200, epoch: 15 | loss: 30.3221893
	speed: 0.0487s/iter; left time: 1099.5495s
Epoch: 15 cost time: 12.986238241195679
Epoch: 15, Steps: 265 Train Loss: 30.6477 (Forecasting Loss:0.1958 + XiCon Loss:3.0452 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.3089085
	speed: 0.0504s/iter; left time: 1129.2745s
	iters: 200, epoch: 16 | loss: 31.0014839
	speed: 0.0462s/iter; left time: 1032.1433s
Epoch: 16 cost time: 12.458862543106079
Epoch: 16, Steps: 265 Train Loss: 30.5506 (Forecasting Loss:0.1959 + XiCon Loss:3.0355 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
Validation loss decreased (0.199270 --> 0.199269).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3089943
	speed: 0.0322s/iter; left time: 714.0072s
	iters: 200, epoch: 17 | loss: 31.9044037
	speed: 0.0590s/iter; left time: 1301.3455s
Epoch: 17 cost time: 14.40870451927185
Epoch: 17, Steps: 265 Train Loss: 30.5736 (Forecasting Loss:0.1958 + XiCon Loss:3.0378 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.8828602
	speed: 0.0358s/iter; left time: 783.9703s
	iters: 200, epoch: 18 | loss: 30.7062607
	speed: 0.0285s/iter; left time: 620.1528s
Epoch: 18 cost time: 8.700353145599365
Epoch: 18, Steps: 265 Train Loss: 30.5564 (Forecasting Loss:0.1958 + XiCon Loss:3.0361 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.7118416
	speed: 0.0544s/iter; left time: 1177.1870s
	iters: 200, epoch: 19 | loss: 30.6168060
	speed: 0.0526s/iter; left time: 1132.3818s
Epoch: 19 cost time: 14.157182931900024
Epoch: 19, Steps: 265 Train Loss: 30.5031 (Forecasting Loss:0.1959 + XiCon Loss:3.0307 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.6356678
	speed: 0.0536s/iter; left time: 1146.1316s
	iters: 200, epoch: 20 | loss: 31.8819580
	speed: 0.0470s/iter; left time: 999.4287s
Epoch: 20 cost time: 12.805463790893555
Epoch: 20, Steps: 265 Train Loss: 30.5915 (Forecasting Loss:0.1959 + XiCon Loss:3.0396 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.8540592
	speed: 0.0342s/iter; left time: 721.1450s
	iters: 200, epoch: 21 | loss: 29.4495945
	speed: 0.0506s/iter; left time: 1062.5319s
Epoch: 21 cost time: 11.82390809059143
Epoch: 21, Steps: 265 Train Loss: 30.5479 (Forecasting Loss:0.1958 + XiCon Loss:3.0352 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.4713039
	speed: 0.0521s/iter; left time: 1086.4342s
	iters: 200, epoch: 22 | loss: 30.9766235
	speed: 0.0507s/iter; left time: 1051.3976s
Epoch: 22 cost time: 13.594374179840088
Epoch: 22, Steps: 265 Train Loss: 30.5786 (Forecasting Loss:0.1959 + XiCon Loss:3.0383 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.5327377
	speed: 0.0488s/iter; left time: 1004.1557s
	iters: 200, epoch: 23 | loss: 31.7169914
	speed: 0.0295s/iter; left time: 603.2474s
Epoch: 23 cost time: 9.747627258300781
Epoch: 23, Steps: 265 Train Loss: 30.5431 (Forecasting Loss:0.1959 + XiCon Loss:3.0347 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1588
Validation loss decreased (0.199269 --> 0.199243).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.9707527
	speed: 0.0549s/iter; left time: 1114.9683s
	iters: 200, epoch: 24 | loss: 30.7521381
	speed: 0.0517s/iter; left time: 1044.9727s
Epoch: 24 cost time: 14.071755409240723
Epoch: 24, Steps: 265 Train Loss: 30.5726 (Forecasting Loss:0.1958 + XiCon Loss:3.0377 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.5258198
	speed: 0.0550s/iter; left time: 1102.4162s
	iters: 200, epoch: 25 | loss: 31.6865196
	speed: 0.0624s/iter; left time: 1243.7496s
Epoch: 25 cost time: 15.8635835647583
Epoch: 25, Steps: 265 Train Loss: 30.5844 (Forecasting Loss:0.1958 + XiCon Loss:3.0389 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.5809078
	speed: 0.0369s/iter; left time: 730.2054s
	iters: 200, epoch: 26 | loss: 31.6612396
	speed: 0.0540s/iter; left time: 1061.6910s
Epoch: 26 cost time: 13.05801796913147
Epoch: 26, Steps: 265 Train Loss: 30.4738 (Forecasting Loss:0.1959 + XiCon Loss:3.0278 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1588
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.5202980
	speed: 0.0599s/iter; left time: 1169.4639s
	iters: 200, epoch: 27 | loss: 29.8572006
	speed: 0.0585s/iter; left time: 1136.2575s
Epoch: 27 cost time: 15.924337148666382
Epoch: 27, Steps: 265 Train Loss: 30.5614 (Forecasting Loss:0.1958 + XiCon Loss:3.0366 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.6402245
	speed: 0.0642s/iter; left time: 1235.6355s
	iters: 200, epoch: 28 | loss: 30.5944977
	speed: 0.0600s/iter; left time: 1149.5622s
Epoch: 28 cost time: 16.374265670776367
Epoch: 28, Steps: 265 Train Loss: 30.5470 (Forecasting Loss:0.1958 + XiCon Loss:3.0351 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.2983704
	speed: 0.0692s/iter; left time: 1313.4262s
	iters: 200, epoch: 29 | loss: 30.0544605
	speed: 0.0639s/iter; left time: 1205.7251s
Epoch: 29 cost time: 17.492958068847656
Epoch: 29, Steps: 265 Train Loss: 30.5879 (Forecasting Loss:0.1958 + XiCon Loss:3.0392 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 29.8973408
	speed: 0.0617s/iter; left time: 1153.8545s
	iters: 200, epoch: 30 | loss: 30.0716152
	speed: 0.0601s/iter; left time: 1118.1623s
Epoch: 30 cost time: 16.166569232940674
Epoch: 30, Steps: 265 Train Loss: 30.5678 (Forecasting Loss:0.1958 + XiCon Loss:3.0372 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.3016911
	speed: 0.0660s/iter; left time: 1217.1285s
	iters: 200, epoch: 31 | loss: 30.8749104
	speed: 0.0613s/iter; left time: 1124.5103s
Epoch: 31 cost time: 16.602919816970825
Epoch: 31, Steps: 265 Train Loss: 30.5206 (Forecasting Loss:0.1959 + XiCon Loss:3.0325 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 30.4474792
	speed: 0.0676s/iter; left time: 1228.5159s
	iters: 200, epoch: 32 | loss: 30.1263618
	speed: 0.0640s/iter; left time: 1157.0742s
Epoch: 32 cost time: 16.987298250198364
Epoch: 32, Steps: 265 Train Loss: 30.5308 (Forecasting Loss:0.1958 + XiCon Loss:3.0335 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1588
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 30.4401226
	speed: 0.0652s/iter; left time: 1168.4019s
	iters: 200, epoch: 33 | loss: 30.4757977
	speed: 0.0641s/iter; left time: 1142.9910s
Epoch: 33 cost time: 16.97761034965515
Epoch: 33, Steps: 265 Train Loss: 30.5300 (Forecasting Loss:0.1959 + XiCon Loss:3.0334 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09201529622077942, mae:0.22564193606376648, mape:0.5429502725601196, mspe:11.246891975402832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.9657
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.2470703
	speed: 0.0690s/iter; left time: 1822.7852s
	iters: 200, epoch: 1 | loss: 30.3905087
	speed: 0.0617s/iter; left time: 1622.3830s
Epoch: 1 cost time: 17.125072717666626
Epoch: 1, Steps: 265 Train Loss: 31.2111 (Forecasting Loss:0.2285 + XiCon Loss:3.0983 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1677
Validation loss decreased (inf --> 0.209861).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.4932117
	speed: 0.0651s/iter; left time: 1700.2731s
	iters: 200, epoch: 2 | loss: 30.9809685
	speed: 0.0603s/iter; left time: 1570.9827s
Epoch: 2 cost time: 16.58273482322693
Epoch: 2, Steps: 265 Train Loss: 30.8493 (Forecasting Loss:0.2072 + XiCon Loss:3.0642 x Lambda(10.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1673
Validation loss decreased (0.209861 --> 0.209673).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1613674
	speed: 0.0590s/iter; left time: 1525.7565s
	iters: 200, epoch: 3 | loss: 29.8382778
	speed: 0.0595s/iter; left time: 1534.0139s
Epoch: 3 cost time: 15.701918601989746
Epoch: 3, Steps: 265 Train Loss: 30.4838 (Forecasting Loss:0.2009 + XiCon Loss:3.0283 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1621
Validation loss decreased (0.209673 --> 0.201890).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1443100
	speed: 0.0675s/iter; left time: 1728.1347s
	iters: 200, epoch: 4 | loss: 30.4323826
	speed: 0.0582s/iter; left time: 1485.2095s
Epoch: 4 cost time: 16.728718519210815
Epoch: 4, Steps: 265 Train Loss: 30.5008 (Forecasting Loss:0.1982 + XiCon Loss:3.0303 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1608
Validation loss decreased (0.201890 --> 0.200147).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7277946
	speed: 0.0608s/iter; left time: 1540.9462s
	iters: 200, epoch: 5 | loss: 29.3749294
	speed: 0.0647s/iter; left time: 1633.0272s
Epoch: 5 cost time: 16.879268646240234
Epoch: 5, Steps: 265 Train Loss: 30.1650 (Forecasting Loss:0.1971 + XiCon Loss:2.9968 x Lambda(10.0)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1620
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2266521
	speed: 0.0679s/iter; left time: 1701.4870s
	iters: 200, epoch: 6 | loss: 30.4055786
	speed: 0.0602s/iter; left time: 1502.3782s
Epoch: 6 cost time: 16.84583830833435
Epoch: 6, Steps: 265 Train Loss: 30.2978 (Forecasting Loss:0.1963 + XiCon Loss:3.0102 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1593
Validation loss decreased (0.200147 --> 0.199804).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9040985
	speed: 0.0671s/iter; left time: 1665.3088s
	iters: 200, epoch: 7 | loss: 29.6868286
	speed: 0.0619s/iter; left time: 1529.8260s
Epoch: 7 cost time: 17.104592323303223
Epoch: 7, Steps: 265 Train Loss: 30.2250 (Forecasting Loss:0.1959 + XiCon Loss:3.0029 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4992599
	speed: 0.0601s/iter; left time: 1474.5132s
	iters: 200, epoch: 8 | loss: 30.2735195
	speed: 0.0641s/iter; left time: 1566.8178s
Epoch: 8 cost time: 16.667912244796753
Epoch: 8, Steps: 265 Train Loss: 30.3654 (Forecasting Loss:0.1958 + XiCon Loss:3.0170 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1589
Validation loss decreased (0.199804 --> 0.199632).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9692650
	speed: 0.0676s/iter; left time: 1642.1408s
	iters: 200, epoch: 9 | loss: 30.8501759
	speed: 0.0632s/iter; left time: 1528.1185s
Epoch: 9 cost time: 17.098496198654175
Epoch: 9, Steps: 265 Train Loss: 30.3604 (Forecasting Loss:0.1956 + XiCon Loss:3.0165 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1585
Validation loss decreased (0.199632 --> 0.199494).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7696800
	speed: 0.0688s/iter; left time: 1653.1951s
	iters: 200, epoch: 10 | loss: 30.5936871
	speed: 0.0629s/iter; left time: 1505.5093s
Epoch: 10 cost time: 17.506629467010498
Epoch: 10, Steps: 265 Train Loss: 30.2846 (Forecasting Loss:0.1955 + XiCon Loss:3.0089 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
Validation loss decreased (0.199494 --> 0.199340).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1999493
	speed: 0.0621s/iter; left time: 1474.0449s
	iters: 200, epoch: 11 | loss: 30.8014240
	speed: 0.0612s/iter; left time: 1448.4839s
Epoch: 11 cost time: 16.510685682296753
Epoch: 11, Steps: 265 Train Loss: 30.2680 (Forecasting Loss:0.1955 + XiCon Loss:3.0072 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4420071
	speed: 0.0657s/iter; left time: 1542.8884s
	iters: 200, epoch: 12 | loss: 30.6340046
	speed: 0.0571s/iter; left time: 1335.7349s
Epoch: 12 cost time: 15.980755090713501
Epoch: 12, Steps: 265 Train Loss: 30.1807 (Forecasting Loss:0.1955 + XiCon Loss:2.9985 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.5484314
	speed: 0.0682s/iter; left time: 1582.6183s
	iters: 200, epoch: 13 | loss: 29.7072124
	speed: 0.0651s/iter; left time: 1505.8158s
Epoch: 13 cost time: 17.41366457939148
Epoch: 13, Steps: 265 Train Loss: 30.3295 (Forecasting Loss:0.1956 + XiCon Loss:3.0134 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1957703
	speed: 0.0659s/iter; left time: 1513.1739s
	iters: 200, epoch: 14 | loss: 29.2748623
	speed: 0.0624s/iter; left time: 1425.1797s
Epoch: 14 cost time: 17.07869553565979
Epoch: 14, Steps: 265 Train Loss: 30.3302 (Forecasting Loss:0.1955 + XiCon Loss:3.0135 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
Validation loss decreased (0.199340 --> 0.199197).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.8712502
	speed: 0.0636s/iter; left time: 1442.8359s
	iters: 200, epoch: 15 | loss: 29.3018055
	speed: 0.0661s/iter; left time: 1493.3251s
Epoch: 15 cost time: 17.30461072921753
Epoch: 15, Steps: 265 Train Loss: 30.2968 (Forecasting Loss:0.1955 + XiCon Loss:3.0101 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9205837
	speed: 0.0636s/iter; left time: 1426.2886s
	iters: 200, epoch: 16 | loss: 30.1249218
	speed: 0.0634s/iter; left time: 1414.6911s
Epoch: 16 cost time: 16.900527477264404
Epoch: 16, Steps: 265 Train Loss: 30.2247 (Forecasting Loss:0.1955 + XiCon Loss:3.0029 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.8696327
	speed: 0.0668s/iter; left time: 1480.4224s
	iters: 200, epoch: 17 | loss: 30.3531456
	speed: 0.0593s/iter; left time: 1308.9166s
Epoch: 17 cost time: 16.656689405441284
Epoch: 17, Steps: 265 Train Loss: 30.2360 (Forecasting Loss:0.1954 + XiCon Loss:3.0041 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2575054
	speed: 0.0673s/iter; left time: 1473.8704s
	iters: 200, epoch: 18 | loss: 29.9528618
	speed: 0.0617s/iter; left time: 1345.4360s
Epoch: 18 cost time: 17.30578088760376
Epoch: 18, Steps: 265 Train Loss: 30.3432 (Forecasting Loss:0.1956 + XiCon Loss:3.0148 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8762894
	speed: 0.0641s/iter; left time: 1386.7338s
	iters: 200, epoch: 19 | loss: 31.2674198
	speed: 0.0647s/iter; left time: 1393.2398s
Epoch: 19 cost time: 16.776859283447266
Epoch: 19, Steps: 265 Train Loss: 30.2901 (Forecasting Loss:0.1956 + XiCon Loss:3.0095 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
Validation loss decreased (0.199197 --> 0.199186).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3290539
	speed: 0.0704s/iter; left time: 1503.8478s
	iters: 200, epoch: 20 | loss: 30.4376125
	speed: 0.0654s/iter; left time: 1390.7226s
Epoch: 20 cost time: 17.711395025253296
Epoch: 20, Steps: 265 Train Loss: 30.2818 (Forecasting Loss:0.1955 + XiCon Loss:3.0086 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.7277660
	speed: 0.0647s/iter; left time: 1364.5841s
	iters: 200, epoch: 21 | loss: 29.6138802
	speed: 0.0626s/iter; left time: 1314.7136s
Epoch: 21 cost time: 16.78207802772522
Epoch: 21, Steps: 265 Train Loss: 30.3308 (Forecasting Loss:0.1955 + XiCon Loss:3.0135 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
Validation loss decreased (0.199186 --> 0.199163).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.9789524
	speed: 0.0583s/iter; left time: 1214.6104s
	iters: 200, epoch: 22 | loss: 29.3107796
	speed: 0.0651s/iter; left time: 1350.4423s
Epoch: 22 cost time: 16.323471546173096
Epoch: 22, Steps: 265 Train Loss: 30.2807 (Forecasting Loss:0.1956 + XiCon Loss:3.0085 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.5687637
	speed: 0.0572s/iter; left time: 1175.9156s
	iters: 200, epoch: 23 | loss: 30.1350422
	speed: 0.0600s/iter; left time: 1227.9221s
Epoch: 23 cost time: 15.581651210784912
Epoch: 23, Steps: 265 Train Loss: 30.2279 (Forecasting Loss:0.1955 + XiCon Loss:3.0032 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6563988
	speed: 0.0642s/iter; left time: 1304.3137s
	iters: 200, epoch: 24 | loss: 29.6359730
	speed: 0.0627s/iter; left time: 1267.7916s
Epoch: 24 cost time: 17.159428596496582
Epoch: 24, Steps: 265 Train Loss: 30.2439 (Forecasting Loss:0.1955 + XiCon Loss:3.0048 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.6637287
	speed: 0.0658s/iter; left time: 1318.5050s
	iters: 200, epoch: 25 | loss: 29.8483868
	speed: 0.0644s/iter; left time: 1283.6621s
Epoch: 25 cost time: 16.9103901386261
Epoch: 25, Steps: 265 Train Loss: 30.2666 (Forecasting Loss:0.1954 + XiCon Loss:3.0071 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.0334492
	speed: 0.0682s/iter; left time: 1347.8323s
	iters: 200, epoch: 26 | loss: 30.1044159
	speed: 0.0614s/iter; left time: 1207.4945s
Epoch: 26 cost time: 16.912312507629395
Epoch: 26, Steps: 265 Train Loss: 30.2876 (Forecasting Loss:0.1955 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.7298584
	speed: 0.0655s/iter; left time: 1277.9428s
	iters: 200, epoch: 27 | loss: 29.7006054
	speed: 0.0598s/iter; left time: 1161.4135s
Epoch: 27 cost time: 16.845865726470947
Epoch: 27, Steps: 265 Train Loss: 30.2970 (Forecasting Loss:0.1954 + XiCon Loss:3.0102 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1586
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.8988838
	speed: 0.0633s/iter; left time: 1218.9141s
	iters: 200, epoch: 28 | loss: 30.4551144
	speed: 0.0677s/iter; left time: 1295.7930s
Epoch: 28 cost time: 17.31482172012329
Epoch: 28, Steps: 265 Train Loss: 30.3063 (Forecasting Loss:0.1954 + XiCon Loss:3.0111 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 29.6337376
	speed: 0.0686s/iter; left time: 1302.6260s
	iters: 200, epoch: 29 | loss: 29.8663483
	speed: 0.0613s/iter; left time: 1157.9561s
Epoch: 29 cost time: 16.993716716766357
Epoch: 29, Steps: 265 Train Loss: 30.2878 (Forecasting Loss:0.1955 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 29.8293858
	speed: 0.0633s/iter; left time: 1185.5214s
	iters: 200, epoch: 30 | loss: 30.8459740
	speed: 0.0617s/iter; left time: 1147.9264s
Epoch: 30 cost time: 16.59631371498108
Epoch: 30, Steps: 265 Train Loss: 30.2427 (Forecasting Loss:0.1954 + XiCon Loss:3.0047 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1586
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 29.0760689
	speed: 0.0622s/iter; left time: 1147.9779s
	iters: 200, epoch: 31 | loss: 31.1721382
	speed: 0.0618s/iter; left time: 1134.5064s
Epoch: 31 cost time: 16.535667419433594
Epoch: 31, Steps: 265 Train Loss: 30.2868 (Forecasting Loss:0.1955 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09181530028581619, mae:0.22538182139396667, mape:0.5421206951141357, mspe:11.219279289245605 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.0115
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 31.9784603
	speed: 0.0638s/iter; left time: 1683.5034s
	iters: 200, epoch: 1 | loss: 30.3612576
	speed: 0.0659s/iter; left time: 1733.4013s
Epoch: 1 cost time: 16.969990730285645
Epoch: 1, Steps: 265 Train Loss: 31.5106 (Forecasting Loss:0.2285 + XiCon Loss:3.1282 x Lambda(10.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1663
Validation loss decreased (inf --> 0.209610).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.6481705
	speed: 0.0591s/iter; left time: 1544.0851s
	iters: 200, epoch: 2 | loss: 29.6807308
	speed: 0.0786s/iter; left time: 2047.7134s
Epoch: 2 cost time: 20.289687156677246
Epoch: 2, Steps: 265 Train Loss: 30.7159 (Forecasting Loss:0.2096 + XiCon Loss:3.0506 x Lambda(10.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.1661
Validation loss decreased (0.209610 --> 0.204763).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5308247
	speed: 0.0512s/iter; left time: 1324.2628s
	iters: 200, epoch: 3 | loss: 31.0192337
	speed: 0.0494s/iter; left time: 1271.8482s
Epoch: 3 cost time: 13.977925539016724
Epoch: 3, Steps: 265 Train Loss: 31.4395 (Forecasting Loss:0.2010 + XiCon Loss:3.1238 x Lambda(10.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1622
Validation loss decreased (0.204763 --> 0.202022).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7232971
	speed: 0.0671s/iter; left time: 1717.6257s
	iters: 200, epoch: 4 | loss: 29.5920792
	speed: 0.0610s/iter; left time: 1554.8125s
Epoch: 4 cost time: 17.141754150390625
Epoch: 4, Steps: 265 Train Loss: 30.9553 (Forecasting Loss:0.1987 + XiCon Loss:3.0757 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1603
Validation loss decreased (0.202022 --> 0.200042).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6677227
	speed: 0.0617s/iter; left time: 1563.6532s
	iters: 200, epoch: 5 | loss: 29.9332333
	speed: 0.0559s/iter; left time: 1411.6958s
Epoch: 5 cost time: 14.000128984451294
Epoch: 5, Steps: 265 Train Loss: 30.5633 (Forecasting Loss:0.1972 + XiCon Loss:3.0366 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1602
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.0545483
	speed: 0.0639s/iter; left time: 1602.1503s
	iters: 200, epoch: 6 | loss: 29.7660713
	speed: 0.0625s/iter; left time: 1561.2444s
Epoch: 6 cost time: 16.7672860622406
Epoch: 6, Steps: 265 Train Loss: 30.4572 (Forecasting Loss:0.1967 + XiCon Loss:3.0261 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1599
Validation loss decreased (0.200042 --> 0.199859).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.2884254
	speed: 0.0684s/iter; left time: 1697.7212s
	iters: 200, epoch: 7 | loss: 29.8224926
	speed: 0.0624s/iter; left time: 1541.3688s
Epoch: 7 cost time: 17.771013021469116
Epoch: 7, Steps: 265 Train Loss: 30.3680 (Forecasting Loss:0.1964 + XiCon Loss:3.0172 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9496403
	speed: 0.0396s/iter; left time: 971.4616s
	iters: 200, epoch: 8 | loss: 30.2579632
	speed: 0.0474s/iter; left time: 1159.3943s
Epoch: 8 cost time: 12.84449315071106
Epoch: 8, Steps: 265 Train Loss: 30.4068 (Forecasting Loss:0.1963 + XiCon Loss:3.0211 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
Validation loss decreased (0.199859 --> 0.199551).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7446537
	speed: 0.0667s/iter; left time: 1619.5315s
	iters: 200, epoch: 9 | loss: 29.9265099
	speed: 0.0647s/iter; left time: 1564.9857s
Epoch: 9 cost time: 17.52588129043579
Epoch: 9, Steps: 265 Train Loss: 30.4322 (Forecasting Loss:0.1960 + XiCon Loss:3.0236 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1590
Validation loss decreased (0.199551 --> 0.199312).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7568474
	speed: 0.0632s/iter; left time: 1518.3013s
	iters: 200, epoch: 10 | loss: 30.3864212
	speed: 0.0559s/iter; left time: 1337.3309s
Epoch: 10 cost time: 13.965041637420654
Epoch: 10, Steps: 265 Train Loss: 30.4775 (Forecasting Loss:0.1960 + XiCon Loss:3.0282 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1590
Validation loss decreased (0.199312 --> 0.199255).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2096252
	speed: 0.0312s/iter; left time: 741.8817s
	iters: 200, epoch: 11 | loss: 30.1562157
	speed: 0.0605s/iter; left time: 1431.1365s
Epoch: 11 cost time: 13.431588888168335
Epoch: 11, Steps: 265 Train Loss: 30.3901 (Forecasting Loss:0.1960 + XiCon Loss:3.0194 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1589
Validation loss decreased (0.199255 --> 0.198720).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4048424
	speed: 0.0639s/iter; left time: 1500.5326s
	iters: 200, epoch: 12 | loss: 30.2866364
	speed: 0.0655s/iter; left time: 1532.7575s
Epoch: 12 cost time: 17.12782907485962
Epoch: 12, Steps: 265 Train Loss: 30.4085 (Forecasting Loss:0.1958 + XiCon Loss:3.0213 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6393318
	speed: 0.0640s/iter; left time: 1486.0205s
	iters: 200, epoch: 13 | loss: 30.3891239
	speed: 0.0612s/iter; left time: 1414.5234s
Epoch: 13 cost time: 17.139204502105713
Epoch: 13, Steps: 265 Train Loss: 30.4468 (Forecasting Loss:0.1960 + XiCon Loss:3.0251 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1589
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6461563
	speed: 0.0678s/iter; left time: 1557.5478s
	iters: 200, epoch: 14 | loss: 30.9690418
	speed: 0.0645s/iter; left time: 1473.5630s
Epoch: 14 cost time: 17.272835969924927
Epoch: 14, Steps: 265 Train Loss: 30.4767 (Forecasting Loss:0.1959 + XiCon Loss:3.0281 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1589
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.0387917
	speed: 0.0710s/iter; left time: 1609.9345s
	iters: 200, epoch: 15 | loss: 30.0551414
	speed: 0.0365s/iter; left time: 825.5119s
Epoch: 15 cost time: 13.46746826171875
Epoch: 15, Steps: 265 Train Loss: 30.4712 (Forecasting Loss:0.1959 + XiCon Loss:3.0275 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8038311
	speed: 0.0727s/iter; left time: 1629.6953s
	iters: 200, epoch: 16 | loss: 31.3210773
	speed: 0.0646s/iter; left time: 1443.0037s
Epoch: 16 cost time: 17.823930978775024
Epoch: 16, Steps: 265 Train Loss: 30.4725 (Forecasting Loss:0.1958 + XiCon Loss:3.0277 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1589
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.6347809
	speed: 0.0692s/iter; left time: 1533.7350s
	iters: 200, epoch: 17 | loss: 30.3586617
	speed: 0.0622s/iter; left time: 1371.3479s
Epoch: 17 cost time: 16.95862078666687
Epoch: 17, Steps: 265 Train Loss: 30.3727 (Forecasting Loss:0.1959 + XiCon Loss:3.0177 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1589
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.5549221
	speed: 0.0685s/iter; left time: 1499.3445s
	iters: 200, epoch: 18 | loss: 29.9067822
	speed: 0.0636s/iter; left time: 1386.9961s
Epoch: 18 cost time: 17.428120851516724
Epoch: 18, Steps: 265 Train Loss: 30.4621 (Forecasting Loss:0.1958 + XiCon Loss:3.0266 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1589
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3780918
	speed: 0.0658s/iter; left time: 1424.3225s
	iters: 200, epoch: 19 | loss: 30.7671318
	speed: 0.0655s/iter; left time: 1409.9118s
Epoch: 19 cost time: 17.638805627822876
Epoch: 19, Steps: 265 Train Loss: 30.4772 (Forecasting Loss:0.1959 + XiCon Loss:3.0281 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1589
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.6979942
	speed: 0.0665s/iter; left time: 1419.9884s
	iters: 200, epoch: 20 | loss: 29.8796730
	speed: 0.0672s/iter; left time: 1428.5991s
Epoch: 20 cost time: 17.485305309295654
Epoch: 20, Steps: 265 Train Loss: 30.4301 (Forecasting Loss:0.1959 + XiCon Loss:3.0234 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1589
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.7853889
	speed: 0.0691s/iter; left time: 1457.1551s
	iters: 200, epoch: 21 | loss: 30.7996197
	speed: 0.0571s/iter; left time: 1198.3053s
Epoch: 21 cost time: 16.541327476501465
Epoch: 21, Steps: 265 Train Loss: 30.4181 (Forecasting Loss:0.1958 + XiCon Loss:3.0222 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1589
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09203039109706879, mae:0.2257828414440155, mape:0.5438427329063416, mspe:11.247565269470215 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0920+-0.00012, MAE:0.2257+-0.00022, MAPE:0.5431+-0.00083, MSPE:11.2517+-0.02746, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.9144
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4582856
	speed: 0.0828s/iter; left time: 2110.8033s
	iters: 200, epoch: 1 | loss: 0.4928105
	speed: 0.0804s/iter; left time: 2041.4040s
Epoch: 1 cost time: 21.07314944267273
Epoch: 1, Steps: 256 Train Loss: 0.4666 (Forecasting Loss:0.4343 + XiCon Loss:3.2280 x Lambda(0.01)), Vali MSE Loss: 0.4131 Test MSE Loss: 0.3830
Validation loss decreased (inf --> 0.413074).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3579229
	speed: 0.0899s/iter; left time: 2269.5259s
	iters: 200, epoch: 2 | loss: 0.3649496
	speed: 0.0823s/iter; left time: 2070.5944s
Epoch: 2 cost time: 21.73451852798462
Epoch: 2, Steps: 256 Train Loss: 0.3716 (Forecasting Loss:0.3394 + XiCon Loss:3.2177 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3039
Validation loss decreased (0.413074 --> 0.327820).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3486888
	speed: 0.0922s/iter; left time: 2303.3325s
	iters: 200, epoch: 3 | loss: 0.3540007
	speed: 0.0878s/iter; left time: 2184.9600s
Epoch: 3 cost time: 22.54698085784912
Epoch: 3, Steps: 256 Train Loss: 0.3477 (Forecasting Loss:0.3156 + XiCon Loss:3.2042 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.3006
Validation loss decreased (0.327820 --> 0.320487).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3530253
	speed: 0.0857s/iter; left time: 2119.3759s
	iters: 200, epoch: 4 | loss: 0.3477463
	speed: 0.0808s/iter; left time: 1990.3722s
Epoch: 4 cost time: 21.076062202453613
Epoch: 4, Steps: 256 Train Loss: 0.3450 (Forecasting Loss:0.3130 + XiCon Loss:3.2021 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.3001
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3550535
	speed: 0.0898s/iter; left time: 2197.7187s
	iters: 200, epoch: 5 | loss: 0.3654348
	speed: 0.0807s/iter; left time: 1967.4055s
Epoch: 5 cost time: 21.853170156478882
Epoch: 5, Steps: 256 Train Loss: 0.3440 (Forecasting Loss:0.3120 + XiCon Loss:3.2013 x Lambda(0.01)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3337717
	speed: 0.0832s/iter; left time: 2015.2572s
	iters: 200, epoch: 6 | loss: 0.3185048
	speed: 0.0857s/iter; left time: 2067.9620s
Epoch: 6 cost time: 21.528979063034058
Epoch: 6, Steps: 256 Train Loss: 0.3435 (Forecasting Loss:0.3115 + XiCon Loss:3.2015 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2996
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3618435
	speed: 0.0820s/iter; left time: 1964.3103s
	iters: 200, epoch: 7 | loss: 0.3324792
	speed: 0.0866s/iter; left time: 2066.0514s
Epoch: 7 cost time: 20.40286684036255
Epoch: 7, Steps: 256 Train Loss: 0.3433 (Forecasting Loss:0.3113 + XiCon Loss:3.2013 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3406067
	speed: 0.0833s/iter; left time: 1974.2318s
	iters: 200, epoch: 8 | loss: 0.3256205
	speed: 0.0819s/iter; left time: 1932.6800s
Epoch: 8 cost time: 20.93827724456787
Epoch: 8, Steps: 256 Train Loss: 0.3433 (Forecasting Loss:0.3113 + XiCon Loss:3.2020 x Lambda(0.01)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2996
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3732974
	speed: 0.0821s/iter; left time: 1926.2200s
	iters: 200, epoch: 9 | loss: 0.3448546
	speed: 0.0825s/iter; left time: 1927.6261s
Epoch: 9 cost time: 21.07407307624817
Epoch: 9, Steps: 256 Train Loss: 0.3431 (Forecasting Loss:0.3111 + XiCon Loss:3.2020 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3476582
	speed: 0.0818s/iter; left time: 1897.3971s
	iters: 200, epoch: 10 | loss: 0.3546030
	speed: 0.0830s/iter; left time: 1917.4588s
Epoch: 10 cost time: 21.10768747329712
Epoch: 10, Steps: 256 Train Loss: 0.3431 (Forecasting Loss:0.3111 + XiCon Loss:3.2008 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3535307
	speed: 0.0786s/iter; left time: 1803.3191s
	iters: 200, epoch: 11 | loss: 0.3600800
	speed: 0.0875s/iter; left time: 1999.3760s
Epoch: 11 cost time: 21.16590404510498
Epoch: 11, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3111 + XiCon Loss:3.2025 x Lambda(0.01)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2996
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3493882
	speed: 0.0883s/iter; left time: 2002.8072s
	iters: 200, epoch: 12 | loss: 0.3330867
	speed: 0.0808s/iter; left time: 1823.8936s
Epoch: 12 cost time: 21.164839267730713
Epoch: 12, Steps: 256 Train Loss: 0.3431 (Forecasting Loss:0.3111 + XiCon Loss:3.2020 x Lambda(0.01)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2996
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3508016
	speed: 0.0917s/iter; left time: 2057.0251s
	iters: 200, epoch: 13 | loss: 0.3416877
	speed: 0.0801s/iter; left time: 1788.8201s
Epoch: 13 cost time: 22.006751775741577
Epoch: 13, Steps: 256 Train Loss: 0.3431 (Forecasting Loss:0.3111 + XiCon Loss:3.2027 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2995
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22693587839603424, mae:0.37425899505615234, mape:0.7467696070671082, mspe:18.97787094116211 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.5511
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.5310968
	speed: 0.0835s/iter; left time: 2129.2185s
	iters: 200, epoch: 1 | loss: 0.4535078
	speed: 0.0735s/iter; left time: 1867.7048s
Epoch: 1 cost time: 19.92654585838318
Epoch: 1, Steps: 256 Train Loss: 0.4676 (Forecasting Loss:0.4349 + XiCon Loss:3.2718 x Lambda(0.01)), Vali MSE Loss: 0.4158 Test MSE Loss: 0.3855
Validation loss decreased (inf --> 0.415771).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3535599
	speed: 0.0793s/iter; left time: 2001.1895s
	iters: 200, epoch: 2 | loss: 0.3392826
	speed: 0.0844s/iter; left time: 2122.2521s
Epoch: 2 cost time: 20.511704921722412
Epoch: 2, Steps: 256 Train Loss: 0.3783 (Forecasting Loss:0.3460 + XiCon Loss:3.2262 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2977
Validation loss decreased (0.415771 --> 0.316198).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3571687
	speed: 0.0791s/iter; left time: 1975.7865s
	iters: 200, epoch: 3 | loss: 0.3489793
	speed: 0.0739s/iter; left time: 1839.6433s
Epoch: 3 cost time: 20.06304359436035
Epoch: 3, Steps: 256 Train Loss: 0.3494 (Forecasting Loss:0.3174 + XiCon Loss:3.2024 x Lambda(0.01)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2951
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3469312
	speed: 0.0817s/iter; left time: 2019.4512s
	iters: 200, epoch: 4 | loss: 0.3495148
	speed: 0.0737s/iter; left time: 1815.6673s
Epoch: 4 cost time: 20.142428636550903
Epoch: 4, Steps: 256 Train Loss: 0.3465 (Forecasting Loss:0.3145 + XiCon Loss:3.2001 x Lambda(0.01)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2944
Validation loss decreased (0.316198 --> 0.315651).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3886552
	speed: 0.0758s/iter; left time: 1855.7336s
	iters: 200, epoch: 5 | loss: 0.3591558
	speed: 0.0799s/iter; left time: 1948.7211s
Epoch: 5 cost time: 19.614569187164307
Epoch: 5, Steps: 256 Train Loss: 0.3454 (Forecasting Loss:0.3134 + XiCon Loss:3.1997 x Lambda(0.01)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3528353
	speed: 0.0831s/iter; left time: 2013.2494s
	iters: 200, epoch: 6 | loss: 0.3335998
	speed: 0.0813s/iter; left time: 1961.0745s
Epoch: 6 cost time: 20.762949466705322
Epoch: 6, Steps: 256 Train Loss: 0.3449 (Forecasting Loss:0.3129 + XiCon Loss:3.1971 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2940
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3367732
	speed: 0.0826s/iter; left time: 1979.6590s
	iters: 200, epoch: 7 | loss: 0.3483043
	speed: 0.0745s/iter; left time: 1777.0477s
Epoch: 7 cost time: 20.027822494506836
Epoch: 7, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3126 + XiCon Loss:3.1977 x Lambda(0.01)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2940
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3665005
	speed: 0.0788s/iter; left time: 1869.2837s
	iters: 200, epoch: 8 | loss: 0.3382884
	speed: 0.0810s/iter; left time: 1912.6849s
Epoch: 8 cost time: 20.16556215286255
Epoch: 8, Steps: 256 Train Loss: 0.3445 (Forecasting Loss:0.3125 + XiCon Loss:3.1978 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3254252
	speed: 0.0810s/iter; left time: 1900.0368s
	iters: 200, epoch: 9 | loss: 0.3655215
	speed: 0.0807s/iter; left time: 1884.8552s
Epoch: 9 cost time: 20.910486221313477
Epoch: 9, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3124 + XiCon Loss:3.1971 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3744843
	speed: 0.0830s/iter; left time: 1926.2656s
	iters: 200, epoch: 10 | loss: 0.3361375
	speed: 0.0705s/iter; left time: 1627.2401s
Epoch: 10 cost time: 19.821460723876953
Epoch: 10, Steps: 256 Train Loss: 0.3443 (Forecasting Loss:0.3124 + XiCon Loss:3.1979 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3613778
	speed: 0.0784s/iter; left time: 1798.0400s
	iters: 200, epoch: 11 | loss: 0.3461215
	speed: 0.0801s/iter; left time: 1830.4348s
Epoch: 11 cost time: 20.385854721069336
Epoch: 11, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3124 + XiCon Loss:3.1955 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3261682
	speed: 0.0793s/iter; left time: 1799.1225s
	iters: 200, epoch: 12 | loss: 0.3360388
	speed: 0.0732s/iter; left time: 1652.1449s
Epoch: 12 cost time: 19.414581060409546
Epoch: 12, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3124 + XiCon Loss:3.1977 x Lambda(0.01)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.2939
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3387495
	speed: 0.0865s/iter; left time: 1939.3262s
	iters: 200, epoch: 13 | loss: 0.3791888
	speed: 0.0752s/iter; left time: 1678.5390s
Epoch: 13 cost time: 20.737470149993896
Epoch: 13, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3124 + XiCon Loss:3.1972 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3459857
	speed: 0.0748s/iter; left time: 1657.6170s
	iters: 200, epoch: 14 | loss: 0.3388216
	speed: 0.0819s/iter; left time: 1806.7892s
Epoch: 14 cost time: 21.901835918426514
Epoch: 14, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3124 + XiCon Loss:3.2001 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2939
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22009634971618652, mae:0.36877205967903137, mape:0.749479353427887, mspe:19.593107223510742 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.2989
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4373047
	speed: 0.0862s/iter; left time: 2197.8238s
	iters: 200, epoch: 1 | loss: 0.4382454
	speed: 0.0795s/iter; left time: 2020.0103s
Epoch: 1 cost time: 20.939084768295288
Epoch: 1, Steps: 256 Train Loss: 0.4642 (Forecasting Loss:0.4320 + XiCon Loss:3.2265 x Lambda(0.01)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3812
Validation loss decreased (inf --> 0.411452).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3649239
	speed: 0.0557s/iter; left time: 1405.6383s
	iters: 200, epoch: 2 | loss: 0.3524449
	speed: 0.0830s/iter; left time: 2088.2009s
Epoch: 2 cost time: 18.70986247062683
Epoch: 2, Steps: 256 Train Loss: 0.3757 (Forecasting Loss:0.3436 + XiCon Loss:3.2060 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.3001
Validation loss decreased (0.411452 --> 0.330516).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3458869
	speed: 0.0926s/iter; left time: 2314.7265s
	iters: 200, epoch: 3 | loss: 0.3354601
	speed: 0.0774s/iter; left time: 1925.7547s
Epoch: 3 cost time: 20.580272436141968
Epoch: 3, Steps: 256 Train Loss: 0.3490 (Forecasting Loss:0.3171 + XiCon Loss:3.1932 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2960
Validation loss decreased (0.330516 --> 0.321252).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3295819
	speed: 0.0771s/iter; left time: 1907.3211s
	iters: 200, epoch: 4 | loss: 0.3588853
	speed: 0.0859s/iter; left time: 2114.8285s
Epoch: 4 cost time: 20.879172801971436
Epoch: 4, Steps: 256 Train Loss: 0.3465 (Forecasting Loss:0.3145 + XiCon Loss:3.1936 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2969
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3725892
	speed: 0.0888s/iter; left time: 2174.3806s
	iters: 200, epoch: 5 | loss: 0.3514095
	speed: 0.0770s/iter; left time: 1875.8236s
Epoch: 5 cost time: 21.190836191177368
Epoch: 5, Steps: 256 Train Loss: 0.3454 (Forecasting Loss:0.3135 + XiCon Loss:3.1942 x Lambda(0.01)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2964
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3230516
	speed: 0.0909s/iter; left time: 2200.5602s
	iters: 200, epoch: 6 | loss: 0.3436190
	speed: 0.0849s/iter; left time: 2046.6795s
Epoch: 6 cost time: 22.269773483276367
Epoch: 6, Steps: 256 Train Loss: 0.3449 (Forecasting Loss:0.3130 + XiCon Loss:3.1895 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2966
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3368029
	speed: 0.0730s/iter; left time: 1749.6414s
	iters: 200, epoch: 7 | loss: 0.3506123
	speed: 0.0524s/iter; left time: 1251.0891s
Epoch: 7 cost time: 17.454136610031128
Epoch: 7, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3128 + XiCon Loss:3.1937 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3410226
	speed: 0.0891s/iter; left time: 2111.6045s
	iters: 200, epoch: 8 | loss: 0.3390746
	speed: 0.0827s/iter; left time: 1953.4649s
Epoch: 8 cost time: 21.999245166778564
Epoch: 8, Steps: 256 Train Loss: 0.3445 (Forecasting Loss:0.3127 + XiCon Loss:3.1897 x Lambda(0.01)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2965
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3342448
	speed: 0.0589s/iter; left time: 1382.5028s
	iters: 200, epoch: 9 | loss: 0.3341924
	speed: 0.0643s/iter; left time: 1500.7006s
Epoch: 9 cost time: 16.932531595230103
Epoch: 9, Steps: 256 Train Loss: 0.3445 (Forecasting Loss:0.3126 + XiCon Loss:3.1922 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2966
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3751482
	speed: 0.0874s/iter; left time: 2027.1978s
	iters: 200, epoch: 10 | loss: 0.3578413
	speed: 0.0841s/iter; left time: 1942.0175s
Epoch: 10 cost time: 21.44297695159912
Epoch: 10, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3125 + XiCon Loss:3.1916 x Lambda(0.01)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2966
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3733276
	speed: 0.0837s/iter; left time: 1919.4615s
	iters: 200, epoch: 11 | loss: 0.3607748
	speed: 0.0826s/iter; left time: 1886.8723s
Epoch: 11 cost time: 21.214261770248413
Epoch: 11, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3125 + XiCon Loss:3.1941 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2966
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3176865
	speed: 0.0858s/iter; left time: 1946.9887s
	iters: 200, epoch: 12 | loss: 0.3345123
	speed: 0.0821s/iter; left time: 1854.1961s
Epoch: 12 cost time: 21.6422336101532
Epoch: 12, Steps: 256 Train Loss: 0.3444 (Forecasting Loss:0.3125 + XiCon Loss:3.1935 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2966
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3624794
	speed: 0.0898s/iter; left time: 2013.6415s
	iters: 200, epoch: 13 | loss: 0.3579272
	speed: 0.0861s/iter; left time: 1923.4010s
Epoch: 13 cost time: 22.33340620994568
Epoch: 13, Steps: 256 Train Loss: 0.3445 (Forecasting Loss:0.3126 + XiCon Loss:3.1935 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2966
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22194649279117584, mae:0.3701089918613434, mape:0.7375949621200562, mspe:18.815271377563477 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.8885
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4644339
	speed: 0.0802s/iter; left time: 2044.5331s
	iters: 200, epoch: 1 | loss: 0.4483191
	speed: 0.0681s/iter; left time: 1730.5107s
Epoch: 1 cost time: 18.50276756286621
Epoch: 1, Steps: 256 Train Loss: 0.4642 (Forecasting Loss:0.4319 + XiCon Loss:3.2338 x Lambda(0.01)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3766
Validation loss decreased (inf --> 0.405967).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3605027
	speed: 0.0769s/iter; left time: 1941.0804s
	iters: 200, epoch: 2 | loss: 0.3711829
	speed: 0.0723s/iter; left time: 1819.2036s
Epoch: 2 cost time: 19.06257462501526
Epoch: 2, Steps: 256 Train Loss: 0.3770 (Forecasting Loss:0.3449 + XiCon Loss:3.2050 x Lambda(0.01)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3029
Validation loss decreased (0.405967 --> 0.338538).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3516839
	speed: 0.0812s/iter; left time: 2030.1918s
	iters: 200, epoch: 3 | loss: 0.3469478
	speed: 0.0615s/iter; left time: 1530.0982s
Epoch: 3 cost time: 18.206547498703003
Epoch: 3, Steps: 256 Train Loss: 0.3550 (Forecasting Loss:0.3231 + XiCon Loss:3.1899 x Lambda(0.01)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.2995
Validation loss decreased (0.338538 --> 0.334897).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3642431
	speed: 0.0752s/iter; left time: 1860.4327s
	iters: 200, epoch: 4 | loss: 0.3582979
	speed: 0.0761s/iter; left time: 1874.0823s
Epoch: 4 cost time: 19.287692308425903
Epoch: 4, Steps: 256 Train Loss: 0.3514 (Forecasting Loss:0.3196 + XiCon Loss:3.1841 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2985
Validation loss decreased (0.334897 --> 0.332148).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3487137
	speed: 0.0717s/iter; left time: 1754.4577s
	iters: 200, epoch: 5 | loss: 0.3540485
	speed: 0.0661s/iter; left time: 1612.0052s
Epoch: 5 cost time: 18.06265139579773
Epoch: 5, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3182 + XiCon Loss:3.1811 x Lambda(0.01)), Vali MSE Loss: 0.3303 Test MSE Loss: 0.2978
Validation loss decreased (0.332148 --> 0.330283).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3385977
	speed: 0.0786s/iter; left time: 1903.6598s
	iters: 200, epoch: 6 | loss: 0.3615146
	speed: 0.0774s/iter; left time: 1866.0582s
Epoch: 6 cost time: 19.63781452178955
Epoch: 6, Steps: 256 Train Loss: 0.3493 (Forecasting Loss:0.3175 + XiCon Loss:3.1764 x Lambda(0.01)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2976
Validation loss decreased (0.330283 --> 0.329570).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3191094
	speed: 0.0739s/iter; left time: 1770.7943s
	iters: 200, epoch: 7 | loss: 0.3391652
	speed: 0.0722s/iter; left time: 1722.1984s
Epoch: 7 cost time: 18.80593252182007
Epoch: 7, Steps: 256 Train Loss: 0.3490 (Forecasting Loss:0.3173 + XiCon Loss:3.1763 x Lambda(0.01)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3559565
	speed: 0.0764s/iter; left time: 1812.3126s
	iters: 200, epoch: 8 | loss: 0.3483442
	speed: 0.0747s/iter; left time: 1764.5423s
Epoch: 8 cost time: 18.83171272277832
Epoch: 8, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1768 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2975
Validation loss decreased (0.329570 --> 0.329348).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3345766
	speed: 0.0831s/iter; left time: 1948.3863s
	iters: 200, epoch: 9 | loss: 0.3386977
	speed: 0.0747s/iter; left time: 1743.5055s
Epoch: 9 cost time: 19.763332843780518
Epoch: 9, Steps: 256 Train Loss: 0.3488 (Forecasting Loss:0.3170 + XiCon Loss:3.1771 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
Validation loss decreased (0.329348 --> 0.329238).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3702597
	speed: 0.0760s/iter; left time: 1763.7022s
	iters: 200, epoch: 10 | loss: 0.3359853
	speed: 0.0635s/iter; left time: 1466.4692s
Epoch: 10 cost time: 17.428703546524048
Epoch: 10, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1746 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3525895
	speed: 0.0764s/iter; left time: 1752.3315s
	iters: 200, epoch: 11 | loss: 0.3558487
	speed: 0.0721s/iter; left time: 1647.7836s
Epoch: 11 cost time: 18.891725301742554
Epoch: 11, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1769 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
Validation loss decreased (0.329238 --> 0.329069).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3275372
	speed: 0.0762s/iter; left time: 1728.1461s
	iters: 200, epoch: 12 | loss: 0.3450865
	speed: 0.0607s/iter; left time: 1369.8481s
Epoch: 12 cost time: 17.7400484085083
Epoch: 12, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1757 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3391869
	speed: 0.0754s/iter; left time: 1690.7167s
	iters: 200, epoch: 13 | loss: 0.3660219
	speed: 0.0773s/iter; left time: 1726.8618s
Epoch: 13 cost time: 19.347853183746338
Epoch: 13, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1746 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3552793
	speed: 0.0722s/iter; left time: 1600.4346s
	iters: 200, epoch: 14 | loss: 0.3393539
	speed: 0.0675s/iter; left time: 1490.5341s
Epoch: 14 cost time: 18.257927656173706
Epoch: 14, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1767 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3474876
	speed: 0.0782s/iter; left time: 1713.8824s
	iters: 200, epoch: 15 | loss: 0.3434990
	speed: 0.0746s/iter; left time: 1626.4619s
Epoch: 15 cost time: 19.04379892349243
Epoch: 15, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1775 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
Validation loss decreased (0.329069 --> 0.329063).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3437833
	speed: 0.0742s/iter; left time: 1606.5021s
	iters: 200, epoch: 16 | loss: 0.3249783
	speed: 0.0697s/iter; left time: 1502.3856s
Epoch: 16 cost time: 18.249024152755737
Epoch: 16, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1757 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329063 --> 0.329026).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3611232
	speed: 0.0764s/iter; left time: 1635.2493s
	iters: 200, epoch: 17 | loss: 0.3488877
	speed: 0.0678s/iter; left time: 1443.5023s
Epoch: 17 cost time: 17.979100704193115
Epoch: 17, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1758 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.3350473
	speed: 0.0779s/iter; left time: 1646.5821s
	iters: 200, epoch: 18 | loss: 0.3289885
	speed: 0.0755s/iter; left time: 1588.2559s
Epoch: 18 cost time: 19.82667064666748
Epoch: 18, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1779 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329026 --> 0.329008).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.3531644
	speed: 0.0750s/iter; left time: 1567.9538s
	iters: 200, epoch: 19 | loss: 0.3404197
	speed: 0.0662s/iter; left time: 1375.8852s
Epoch: 19 cost time: 17.91905951499939
Epoch: 19, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1772 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.3376992
	speed: 0.0801s/iter; left time: 1653.5907s
	iters: 200, epoch: 20 | loss: 0.3395349
	speed: 0.0720s/iter; left time: 1478.9630s
Epoch: 20 cost time: 19.23550772666931
Epoch: 20, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1768 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.3571573
	speed: 0.0759s/iter; left time: 1547.7087s
	iters: 200, epoch: 21 | loss: 0.3522393
	speed: 0.0669s/iter; left time: 1357.6035s
Epoch: 21 cost time: 18.379350662231445
Epoch: 21, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1771 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329008 --> 0.328961).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.3545446
	speed: 0.0752s/iter; left time: 1512.4755s
	iters: 200, epoch: 22 | loss: 0.3545042
	speed: 0.0758s/iter; left time: 1517.9660s
Epoch: 22 cost time: 19.263270139694214
Epoch: 22, Steps: 256 Train Loss: 0.3485 (Forecasting Loss:0.3168 + XiCon Loss:3.1751 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.3378178
	speed: 0.0706s/iter; left time: 1403.2925s
	iters: 200, epoch: 23 | loss: 0.3509547
	speed: 0.0723s/iter; left time: 1429.7857s
Epoch: 23 cost time: 18.14513373374939
Epoch: 23, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1751 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.3591098
	speed: 0.0790s/iter; left time: 1549.1576s
	iters: 200, epoch: 24 | loss: 0.3355996
	speed: 0.0756s/iter; left time: 1474.7810s
Epoch: 24 cost time: 19.39355754852295
Epoch: 24, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1768 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.3545465
	speed: 0.0802s/iter; left time: 1551.9640s
	iters: 200, epoch: 25 | loss: 0.3835258
	speed: 0.0709s/iter; left time: 1365.7471s
Epoch: 25 cost time: 19.25538969039917
Epoch: 25, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3170 + XiCon Loss:3.1763 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.3540104
	speed: 0.0743s/iter; left time: 1418.3842s
	iters: 200, epoch: 26 | loss: 0.3412905
	speed: 0.0739s/iter; left time: 1404.8732s
Epoch: 26 cost time: 18.493841648101807
Epoch: 26, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1766 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328961 --> 0.328939).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.3633336
	speed: 0.0780s/iter; left time: 1470.1682s
	iters: 200, epoch: 27 | loss: 0.3424992
	speed: 0.0726s/iter; left time: 1360.3732s
Epoch: 27 cost time: 19.280406951904297
Epoch: 27, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1773 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.3445540
	speed: 0.0785s/iter; left time: 1459.0821s
	iters: 200, epoch: 28 | loss: 0.3569361
	speed: 0.0667s/iter; left time: 1232.3417s
Epoch: 28 cost time: 18.079370498657227
Epoch: 28, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1756 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.3462632
	speed: 0.0849s/iter; left time: 1556.0437s
	iters: 200, epoch: 29 | loss: 0.3554086
	speed: 0.0703s/iter; left time: 1281.9743s
Epoch: 29 cost time: 19.649359464645386
Epoch: 29, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1732 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.3799985
	speed: 0.0691s/iter; left time: 1248.9860s
	iters: 200, epoch: 30 | loss: 0.3542275
	speed: 0.0608s/iter; left time: 1092.3521s
Epoch: 30 cost time: 16.16598343849182
Epoch: 30, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1755 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.3421369
	speed: 0.1014s/iter; left time: 1807.1550s
	iters: 200, epoch: 31 | loss: 0.3401766
	speed: 0.0515s/iter; left time: 911.7871s
Epoch: 31 cost time: 18.532464742660522
Epoch: 31, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1755 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.3453181
	speed: 0.0773s/iter; left time: 1358.1444s
	iters: 200, epoch: 32 | loss: 0.3460958
	speed: 0.0701s/iter; left time: 1224.7866s
Epoch: 32 cost time: 18.8925838470459
Epoch: 32, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1771 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2974
Validation loss decreased (0.328939 --> 0.328846).  Saving model ...
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.3421496
	speed: 0.0737s/iter; left time: 1275.2975s
	iters: 200, epoch: 33 | loss: 0.3417861
	speed: 0.0598s/iter; left time: 1028.8060s
Epoch: 33 cost time: 15.243152618408203
Epoch: 33, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1751 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.3372345
	speed: 0.0780s/iter; left time: 1330.1703s
	iters: 200, epoch: 34 | loss: 0.3192865
	speed: 0.0749s/iter; left time: 1269.6365s
Epoch: 34 cost time: 19.17283582687378
Epoch: 34, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1759 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.3425479
	speed: 0.0745s/iter; left time: 1251.3736s
	iters: 200, epoch: 35 | loss: 0.3419247
	speed: 0.0691s/iter; left time: 1153.9279s
Epoch: 35 cost time: 18.385951042175293
Epoch: 35, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3168 + XiCon Loss:3.1790 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.3357641
	speed: 0.0673s/iter; left time: 1113.5543s
	iters: 200, epoch: 36 | loss: 0.3280285
	speed: 0.0697s/iter; left time: 1146.7458s
Epoch: 36 cost time: 17.746599674224854
Epoch: 36, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1757 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.3304907
	speed: 0.0763s/iter; left time: 1242.7543s
	iters: 200, epoch: 37 | loss: 0.3283274
	speed: 0.0729s/iter; left time: 1179.3253s
Epoch: 37 cost time: 18.911234378814697
Epoch: 37, Steps: 256 Train Loss: 0.3485 (Forecasting Loss:0.3168 + XiCon Loss:3.1768 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.3411378
	speed: 0.0408s/iter; left time: 653.7094s
	iters: 200, epoch: 38 | loss: 0.3550037
	speed: 0.0686s/iter; left time: 1092.8073s
Epoch: 38 cost time: 14.898460149765015
Epoch: 38, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1758 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.3428405
	speed: 0.0759s/iter; left time: 1197.1868s
	iters: 200, epoch: 39 | loss: 0.3296534
	speed: 0.0656s/iter; left time: 1028.2048s
Epoch: 39 cost time: 18.180097579956055
Epoch: 39, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1754 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.3737606
	speed: 0.0542s/iter; left time: 840.2548s
	iters: 200, epoch: 40 | loss: 0.3825481
	speed: 0.0523s/iter; left time: 807.0654s
Epoch: 40 cost time: 14.64436650276184
Epoch: 40, Steps: 256 Train Loss: 0.3486 (Forecasting Loss:0.3169 + XiCon Loss:3.1766 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.3622562
	speed: 0.0753s/iter; left time: 1149.2019s
	iters: 200, epoch: 41 | loss: 0.3519832
	speed: 0.0769s/iter; left time: 1166.6268s
Epoch: 41 cost time: 19.290987014770508
Epoch: 41, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1791 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.3815604
	speed: 0.0685s/iter; left time: 1028.5455s
	iters: 200, epoch: 42 | loss: 0.3344208
	speed: 0.0428s/iter; left time: 637.3222s
Epoch: 42 cost time: 14.456075668334961
Epoch: 42, Steps: 256 Train Loss: 0.3487 (Forecasting Loss:0.3169 + XiCon Loss:3.1760 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2205902338027954, mae:0.3742353022098541, mape:0.7275823354721069, mspe:18.847963333129883 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.5047
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4345624
	speed: 0.0779s/iter; left time: 1986.8910s
	iters: 200, epoch: 1 | loss: 0.4893216
	speed: 0.0727s/iter; left time: 1847.9064s
Epoch: 1 cost time: 18.942046642303467
Epoch: 1, Steps: 256 Train Loss: 0.4705 (Forecasting Loss:0.4380 + XiCon Loss:3.2416 x Lambda(0.01)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.3709
Validation loss decreased (inf --> 0.398277).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3830732
	speed: 0.0809s/iter; left time: 2041.5670s
	iters: 200, epoch: 2 | loss: 0.4042217
	speed: 0.0755s/iter; left time: 1897.7356s
Epoch: 2 cost time: 19.788734912872314
Epoch: 2, Steps: 256 Train Loss: 0.3830 (Forecasting Loss:0.3509 + XiCon Loss:3.2154 x Lambda(0.01)), Vali MSE Loss: 0.3303 Test MSE Loss: 0.3010
Validation loss decreased (0.398277 --> 0.330300).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3517419
	speed: 0.0702s/iter; left time: 1753.4754s
	iters: 200, epoch: 3 | loss: 0.3554304
	speed: 0.0697s/iter; left time: 1735.3562s
Epoch: 3 cost time: 18.07609224319458
Epoch: 3, Steps: 256 Train Loss: 0.3542 (Forecasting Loss:0.3224 + XiCon Loss:3.1854 x Lambda(0.01)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.3014
Validation loss decreased (0.330300 --> 0.311240).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3286904
	speed: 0.0734s/iter; left time: 1814.5918s
	iters: 200, epoch: 4 | loss: 0.3410686
	speed: 0.0722s/iter; left time: 1777.4693s
Epoch: 4 cost time: 18.65165114402771
Epoch: 4, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3144 + XiCon Loss:3.1793 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3032
Validation loss decreased (0.311240 --> 0.308567).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3255510
	speed: 0.0712s/iter; left time: 1743.9389s
	iters: 200, epoch: 5 | loss: 0.3290026
	speed: 0.0726s/iter; left time: 1770.2984s
Epoch: 5 cost time: 18.531455278396606
Epoch: 5, Steps: 256 Train Loss: 0.3438 (Forecasting Loss:0.3120 + XiCon Loss:3.1773 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3037
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3396395
	speed: 0.0798s/iter; left time: 1932.0226s
	iters: 200, epoch: 6 | loss: 0.3410984
	speed: 0.0745s/iter; left time: 1798.1685s
Epoch: 6 cost time: 19.390317678451538
Epoch: 6, Steps: 256 Train Loss: 0.3428 (Forecasting Loss:0.3110 + XiCon Loss:3.1772 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3040
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3409254
	speed: 0.0698s/iter; left time: 1671.7726s
	iters: 200, epoch: 7 | loss: 0.3691362
	speed: 0.0722s/iter; left time: 1722.1821s
Epoch: 7 cost time: 18.127903699874878
Epoch: 7, Steps: 256 Train Loss: 0.3422 (Forecasting Loss:0.3104 + XiCon Loss:3.1749 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3042
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3403485
	speed: 0.0788s/iter; left time: 1868.5699s
	iters: 200, epoch: 8 | loss: 0.3528985
	speed: 0.0713s/iter; left time: 1684.0978s
Epoch: 8 cost time: 19.05652117729187
Epoch: 8, Steps: 256 Train Loss: 0.3421 (Forecasting Loss:0.3103 + XiCon Loss:3.1773 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3313992
	speed: 0.0719s/iter; left time: 1686.7727s
	iters: 200, epoch: 9 | loss: 0.3472591
	speed: 0.0725s/iter; left time: 1694.1999s
Epoch: 9 cost time: 18.240972757339478
Epoch: 9, Steps: 256 Train Loss: 0.3419 (Forecasting Loss:0.3101 + XiCon Loss:3.1739 x Lambda(0.01)), Vali MSE Loss: 0.3094 Test MSE Loss: 0.3043
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3302798
	speed: 0.0759s/iter; left time: 1761.0470s
	iters: 200, epoch: 10 | loss: 0.3337506
	speed: 0.0716s/iter; left time: 1653.2236s
Epoch: 10 cost time: 18.532554626464844
Epoch: 10, Steps: 256 Train Loss: 0.3419 (Forecasting Loss:0.3101 + XiCon Loss:3.1743 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3043
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3457523
	speed: 0.0815s/iter; left time: 1870.2966s
	iters: 200, epoch: 11 | loss: 0.3322650
	speed: 0.0727s/iter; left time: 1659.7648s
Epoch: 11 cost time: 19.42203950881958
Epoch: 11, Steps: 256 Train Loss: 0.3419 (Forecasting Loss:0.3101 + XiCon Loss:3.1760 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3043
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3489710
	speed: 0.0738s/iter; left time: 1673.9988s
	iters: 200, epoch: 12 | loss: 0.3511504
	speed: 0.0689s/iter; left time: 1556.3779s
Epoch: 12 cost time: 17.6334285736084
Epoch: 12, Steps: 256 Train Loss: 0.3418 (Forecasting Loss:0.3101 + XiCon Loss:3.1748 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3043
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3131865
	speed: 0.0754s/iter; left time: 1691.5428s
	iters: 200, epoch: 13 | loss: 0.3600384
	speed: 0.0724s/iter; left time: 1615.8979s
Epoch: 13 cost time: 18.33022952079773
Epoch: 13, Steps: 256 Train Loss: 0.3418 (Forecasting Loss:0.3101 + XiCon Loss:3.1746 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3043
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3552085
	speed: 0.0777s/iter; left time: 1721.9379s
	iters: 200, epoch: 14 | loss: 0.3357087
	speed: 0.0696s/iter; left time: 1535.5521s
Epoch: 14 cost time: 18.41752791404724
Epoch: 14, Steps: 256 Train Loss: 0.3418 (Forecasting Loss:0.3100 + XiCon Loss:3.1761 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3043
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2297523319721222, mae:0.3765532076358795, mape:0.7674784064292908, mspe:20.816144943237305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2239+-0.00529, MAE:0.3728+-0.00401, MAPE:0.7458+-0.01845, MSPE:19.4101+-1.05122, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.6430
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6360698
	speed: 0.1195s/iter; left time: 2903.7291s
	iters: 200, epoch: 1 | loss: 3.6264167
	speed: 0.1172s/iter; left time: 2835.6615s
Epoch: 1 cost time: 28.61443257331848
Epoch: 1, Steps: 244 Train Loss: 3.6824 (Forecasting Loss:0.4576 + XiCon Loss:3.2248 x Lambda(1.0)), Vali MSE Loss: 0.4551 Test MSE Loss: 0.3565
Validation loss decreased (inf --> 0.455139).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4281335
	speed: 0.1173s/iter; left time: 2822.0585s
	iters: 200, epoch: 2 | loss: 3.2770607
	speed: 0.1117s/iter; left time: 2675.1936s
Epoch: 2 cost time: 28.32990574836731
Epoch: 2, Steps: 244 Train Loss: 3.4225 (Forecasting Loss:0.3629 + XiCon Loss:3.0596 x Lambda(1.0)), Vali MSE Loss: 0.3823 Test MSE Loss: 0.3148
Validation loss decreased (0.455139 --> 0.382319).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4606862
	speed: 0.1235s/iter; left time: 2940.5030s
	iters: 200, epoch: 3 | loss: 3.4680076
	speed: 0.1162s/iter; left time: 2755.1935s
Epoch: 3 cost time: 29.24176001548767
Epoch: 3, Steps: 244 Train Loss: 3.4679 (Forecasting Loss:0.3511 + XiCon Loss:3.1168 x Lambda(1.0)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2860
Validation loss decreased (0.382319 --> 0.363904).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4391696
	speed: 0.1217s/iter; left time: 2868.6377s
	iters: 200, epoch: 4 | loss: 3.5910566
	speed: 0.1199s/iter; left time: 2814.8368s
Epoch: 4 cost time: 29.610015630722046
Epoch: 4, Steps: 244 Train Loss: 3.4784 (Forecasting Loss:0.3444 + XiCon Loss:3.1340 x Lambda(1.0)), Vali MSE Loss: 0.3636 Test MSE Loss: 0.2853
Validation loss decreased (0.363904 --> 0.363613).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5369160
	speed: 0.1184s/iter; left time: 2762.0622s
	iters: 200, epoch: 5 | loss: 3.4989631
	speed: 0.1259s/iter; left time: 2923.6153s
Epoch: 5 cost time: 29.663755655288696
Epoch: 5, Steps: 244 Train Loss: 3.4820 (Forecasting Loss:0.3425 + XiCon Loss:3.1396 x Lambda(1.0)), Vali MSE Loss: 0.3597 Test MSE Loss: 0.2854
Validation loss decreased (0.363613 --> 0.359737).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4292140
	speed: 0.1219s/iter; left time: 2814.6627s
	iters: 200, epoch: 6 | loss: 3.4794006
	speed: 0.1201s/iter; left time: 2761.0023s
Epoch: 6 cost time: 29.270130157470703
Epoch: 6, Steps: 244 Train Loss: 3.4791 (Forecasting Loss:0.3413 + XiCon Loss:3.1378 x Lambda(1.0)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.2881
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4978845
	speed: 0.1216s/iter; left time: 2776.4282s
	iters: 200, epoch: 7 | loss: 3.4250796
	speed: 0.1183s/iter; left time: 2690.4615s
Epoch: 7 cost time: 29.360881090164185
Epoch: 7, Steps: 244 Train Loss: 3.4825 (Forecasting Loss:0.3408 + XiCon Loss:3.1417 x Lambda(1.0)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2868
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4109864
	speed: 0.1234s/iter; left time: 2787.0200s
	iters: 200, epoch: 8 | loss: 3.4840653
	speed: 0.1207s/iter; left time: 2714.0080s
Epoch: 8 cost time: 29.67797875404358
Epoch: 8, Steps: 244 Train Loss: 3.4767 (Forecasting Loss:0.3407 + XiCon Loss:3.1360 x Lambda(1.0)), Vali MSE Loss: 0.3642 Test MSE Loss: 0.2872
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4587126
	speed: 0.1200s/iter; left time: 2681.3260s
	iters: 200, epoch: 9 | loss: 3.4577138
	speed: 0.1206s/iter; left time: 2682.7429s
Epoch: 9 cost time: 29.001315355300903
Epoch: 9, Steps: 244 Train Loss: 3.4753 (Forecasting Loss:0.3403 + XiCon Loss:3.1350 x Lambda(1.0)), Vali MSE Loss: 0.3611 Test MSE Loss: 0.2864
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3994913
	speed: 0.1212s/iter; left time: 2678.9261s
	iters: 200, epoch: 10 | loss: 3.4972055
	speed: 0.1226s/iter; left time: 2698.3256s
Epoch: 10 cost time: 30.013943433761597
Epoch: 10, Steps: 244 Train Loss: 3.4702 (Forecasting Loss:0.3403 + XiCon Loss:3.1299 x Lambda(1.0)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.2866
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6007996
	speed: 0.1233s/iter; left time: 2695.5176s
	iters: 200, epoch: 11 | loss: 3.4061029
	speed: 0.1217s/iter; left time: 2648.1363s
Epoch: 11 cost time: 29.890096187591553
Epoch: 11, Steps: 244 Train Loss: 3.4802 (Forecasting Loss:0.3406 + XiCon Loss:3.1397 x Lambda(1.0)), Vali MSE Loss: 0.3613 Test MSE Loss: 0.2865
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4714365
	speed: 0.1213s/iter; left time: 2621.4936s
	iters: 200, epoch: 12 | loss: 3.4344413
	speed: 0.1173s/iter; left time: 2523.8431s
Epoch: 12 cost time: 29.22821021080017
Epoch: 12, Steps: 244 Train Loss: 3.4712 (Forecasting Loss:0.3404 + XiCon Loss:3.1308 x Lambda(1.0)), Vali MSE Loss: 0.3611 Test MSE Loss: 0.2864
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5426486
	speed: 0.1267s/iter; left time: 2706.9518s
	iters: 200, epoch: 13 | loss: 3.3781939
	speed: 0.1128s/iter; left time: 2399.8653s
Epoch: 13 cost time: 29.141159057617188
Epoch: 13, Steps: 244 Train Loss: 3.4761 (Forecasting Loss:0.3399 + XiCon Loss:3.1362 x Lambda(1.0)), Vali MSE Loss: 0.3606 Test MSE Loss: 0.2863
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4360378
	speed: 0.1234s/iter; left time: 2606.4541s
	iters: 200, epoch: 14 | loss: 3.5503979
	speed: 0.1198s/iter; left time: 2519.4164s
Epoch: 14 cost time: 29.613895416259766
Epoch: 14, Steps: 244 Train Loss: 3.4768 (Forecasting Loss:0.3402 + XiCon Loss:3.1367 x Lambda(1.0)), Vali MSE Loss: 0.3606 Test MSE Loss: 0.2863
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5195591
	speed: 0.1358s/iter; left time: 2835.4815s
	iters: 200, epoch: 15 | loss: 3.5328526
	speed: 0.0989s/iter; left time: 2055.9976s
Epoch: 15 cost time: 27.234632968902588
Epoch: 15, Steps: 244 Train Loss: 3.4750 (Forecasting Loss:0.3403 + XiCon Loss:3.1346 x Lambda(1.0)), Vali MSE Loss: 0.3608 Test MSE Loss: 0.2863
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.20664571225643158, mae:0.3641904294490814, mape:0.6746746897697449, mspe:18.46622085571289 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.2381
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6441574
	speed: 0.0966s/iter; left time: 2347.4679s
	iters: 200, epoch: 1 | loss: 3.6646848
	speed: 0.0906s/iter; left time: 2192.5044s
Epoch: 1 cost time: 23.36805558204651
Epoch: 1, Steps: 244 Train Loss: 3.6825 (Forecasting Loss:0.4646 + XiCon Loss:3.2179 x Lambda(1.0)), Vali MSE Loss: 0.4797 Test MSE Loss: 0.3855
Validation loss decreased (inf --> 0.479717).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4042416
	speed: 0.1084s/iter; left time: 2607.5033s
	iters: 200, epoch: 2 | loss: 3.3699982
	speed: 0.1104s/iter; left time: 2645.7929s
Epoch: 2 cost time: 26.468461990356445
Epoch: 2, Steps: 244 Train Loss: 3.4444 (Forecasting Loss:0.3878 + XiCon Loss:3.0567 x Lambda(1.0)), Vali MSE Loss: 0.4290 Test MSE Loss: 0.3095
Validation loss decreased (0.479717 --> 0.428998).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4466729
	speed: 0.1160s/iter; left time: 2761.9331s
	iters: 200, epoch: 3 | loss: 3.5034547
	speed: 0.1125s/iter; left time: 2668.0804s
Epoch: 3 cost time: 27.832757234573364
Epoch: 3, Steps: 244 Train Loss: 3.4846 (Forecasting Loss:0.3618 + XiCon Loss:3.1228 x Lambda(1.0)), Vali MSE Loss: 0.3701 Test MSE Loss: 0.3043
Validation loss decreased (0.428998 --> 0.370088).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6545429
	speed: 0.1051s/iter; left time: 2477.9318s
	iters: 200, epoch: 4 | loss: 3.5817251
	speed: 0.0594s/iter; left time: 1392.9626s
Epoch: 4 cost time: 19.80679154396057
Epoch: 4, Steps: 244 Train Loss: 3.5311 (Forecasting Loss:0.3593 + XiCon Loss:3.1718 x Lambda(1.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3014
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5880306
	speed: 0.1179s/iter; left time: 2750.6051s
	iters: 200, epoch: 5 | loss: 3.5059693
	speed: 0.1158s/iter; left time: 2688.5744s
Epoch: 5 cost time: 28.337746381759644
Epoch: 5, Steps: 244 Train Loss: 3.5342 (Forecasting Loss:0.3563 + XiCon Loss:3.1779 x Lambda(1.0)), Vali MSE Loss: 0.3814 Test MSE Loss: 0.3020
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5657172
	speed: 0.1138s/iter; left time: 2626.5680s
	iters: 200, epoch: 6 | loss: 3.5779848
	speed: 0.1118s/iter; left time: 2568.5776s
Epoch: 6 cost time: 27.57928729057312
Epoch: 6, Steps: 244 Train Loss: 3.5357 (Forecasting Loss:0.3545 + XiCon Loss:3.1812 x Lambda(1.0)), Vali MSE Loss: 0.3790 Test MSE Loss: 0.3019
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4983845
	speed: 0.1110s/iter; left time: 2534.1444s
	iters: 200, epoch: 7 | loss: 3.5954280
	speed: 0.0673s/iter; left time: 1531.0873s
Epoch: 7 cost time: 22.923962116241455
Epoch: 7, Steps: 244 Train Loss: 3.5246 (Forecasting Loss:0.3538 + XiCon Loss:3.1707 x Lambda(1.0)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4997602
	speed: 0.1135s/iter; left time: 2564.0929s
	iters: 200, epoch: 8 | loss: 3.4746466
	speed: 0.1149s/iter; left time: 2583.6040s
Epoch: 8 cost time: 27.556230545043945
Epoch: 8, Steps: 244 Train Loss: 3.5213 (Forecasting Loss:0.3532 + XiCon Loss:3.1681 x Lambda(1.0)), Vali MSE Loss: 0.3744 Test MSE Loss: 0.3020
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6024919
	speed: 0.1147s/iter; left time: 2564.2446s
	iters: 200, epoch: 9 | loss: 3.4691606
	speed: 0.1082s/iter; left time: 2408.1095s
Epoch: 9 cost time: 27.20011043548584
Epoch: 9, Steps: 244 Train Loss: 3.5231 (Forecasting Loss:0.3528 + XiCon Loss:3.1702 x Lambda(1.0)), Vali MSE Loss: 0.3734 Test MSE Loss: 0.3021
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4895992
	speed: 0.1139s/iter; left time: 2517.5517s
	iters: 200, epoch: 10 | loss: 3.6430967
	speed: 0.1096s/iter; left time: 2411.8960s
Epoch: 10 cost time: 27.469582319259644
Epoch: 10, Steps: 244 Train Loss: 3.5219 (Forecasting Loss:0.3524 + XiCon Loss:3.1695 x Lambda(1.0)), Vali MSE Loss: 0.3733 Test MSE Loss: 0.3022
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5611598
	speed: 0.1121s/iter; left time: 2449.9602s
	iters: 200, epoch: 11 | loss: 3.5257900
	speed: 0.1053s/iter; left time: 2290.5229s
Epoch: 11 cost time: 26.98200750350952
Epoch: 11, Steps: 244 Train Loss: 3.5215 (Forecasting Loss:0.3525 + XiCon Loss:3.1690 x Lambda(1.0)), Vali MSE Loss: 0.3742 Test MSE Loss: 0.3020
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6636260
	speed: 0.1145s/iter; left time: 2474.9297s
	iters: 200, epoch: 12 | loss: 3.4905815
	speed: 0.1128s/iter; left time: 2426.3419s
Epoch: 12 cost time: 27.445130586624146
Epoch: 12, Steps: 244 Train Loss: 3.5212 (Forecasting Loss:0.3525 + XiCon Loss:3.1687 x Lambda(1.0)), Vali MSE Loss: 0.3740 Test MSE Loss: 0.3021
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4601929
	speed: 0.1127s/iter; left time: 2409.7817s
	iters: 200, epoch: 13 | loss: 3.4827557
	speed: 0.1141s/iter; left time: 2428.0389s
Epoch: 13 cost time: 27.931278944015503
Epoch: 13, Steps: 244 Train Loss: 3.5190 (Forecasting Loss:0.3527 + XiCon Loss:3.1663 x Lambda(1.0)), Vali MSE Loss: 0.3735 Test MSE Loss: 0.3021
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22696754336357117, mae:0.38171660900115967, mape:0.7235985398292542, mspe:20.94507598876953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.8933
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6933904
	speed: 0.1104s/iter; left time: 2683.9836s
	iters: 200, epoch: 1 | loss: 3.6710546
	speed: 0.1052s/iter; left time: 2546.8923s
Epoch: 1 cost time: 26.074146270751953
Epoch: 1, Steps: 244 Train Loss: 3.6969 (Forecasting Loss:0.4630 + XiCon Loss:3.2339 x Lambda(1.0)), Vali MSE Loss: 0.4757 Test MSE Loss: 0.3820
Validation loss decreased (inf --> 0.475748).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5098326
	speed: 0.1085s/iter; left time: 2609.1869s
	iters: 200, epoch: 2 | loss: 3.3907404
	speed: 0.1098s/iter; left time: 2629.8706s
Epoch: 2 cost time: 26.671797513961792
Epoch: 2, Steps: 244 Train Loss: 3.4563 (Forecasting Loss:0.3996 + XiCon Loss:3.0567 x Lambda(1.0)), Vali MSE Loss: 0.4308 Test MSE Loss: 0.3366
Validation loss decreased (0.475748 --> 0.430818).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3804107
	speed: 0.1102s/iter; left time: 2623.9086s
	iters: 200, epoch: 3 | loss: 3.3473527
	speed: 0.1092s/iter; left time: 2588.5251s
Epoch: 3 cost time: 26.892847776412964
Epoch: 3, Steps: 244 Train Loss: 3.3622 (Forecasting Loss:0.3836 + XiCon Loss:2.9785 x Lambda(1.0)), Vali MSE Loss: 0.4166 Test MSE Loss: 0.3276
Validation loss decreased (0.430818 --> 0.416571).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3642919
	speed: 0.1165s/iter; left time: 2745.7285s
	iters: 200, epoch: 4 | loss: 3.3629935
	speed: 0.1167s/iter; left time: 2739.7353s
Epoch: 4 cost time: 28.696636199951172
Epoch: 4, Steps: 244 Train Loss: 3.3546 (Forecasting Loss:0.3777 + XiCon Loss:2.9769 x Lambda(1.0)), Vali MSE Loss: 0.4157 Test MSE Loss: 0.3277
Validation loss decreased (0.416571 --> 0.415673).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3869202
	speed: 0.1259s/iter; left time: 2936.6358s
	iters: 200, epoch: 5 | loss: 3.3674033
	speed: 0.1203s/iter; left time: 2792.8922s
Epoch: 5 cost time: 30.29650640487671
Epoch: 5, Steps: 244 Train Loss: 3.3809 (Forecasting Loss:0.3786 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.4113 Test MSE Loss: 0.3242
Validation loss decreased (0.415673 --> 0.411308).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3907409
	speed: 0.1289s/iter; left time: 2974.0458s
	iters: 200, epoch: 6 | loss: 3.4166985
	speed: 0.1250s/iter; left time: 2872.4566s
Epoch: 6 cost time: 30.91178798675537
Epoch: 6, Steps: 244 Train Loss: 3.4025 (Forecasting Loss:0.3791 + XiCon Loss:3.0234 x Lambda(1.0)), Vali MSE Loss: 0.4137 Test MSE Loss: 0.3264
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3785877
	speed: 0.1271s/iter; left time: 2902.7042s
	iters: 200, epoch: 7 | loss: 3.4027109
	speed: 0.1269s/iter; left time: 2886.0948s
Epoch: 7 cost time: 30.93189263343811
Epoch: 7, Steps: 244 Train Loss: 3.4051 (Forecasting Loss:0.3786 + XiCon Loss:3.0265 x Lambda(1.0)), Vali MSE Loss: 0.4103 Test MSE Loss: 0.3232
Validation loss decreased (0.411308 --> 0.410259).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4017699
	speed: 0.1298s/iter; left time: 2931.8629s
	iters: 200, epoch: 8 | loss: 3.4030743
	speed: 0.1287s/iter; left time: 2894.3871s
Epoch: 8 cost time: 31.367613554000854
Epoch: 8, Steps: 244 Train Loss: 3.4181 (Forecasting Loss:0.3791 + XiCon Loss:3.0390 x Lambda(1.0)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3239
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4376073
	speed: 0.1206s/iter; left time: 2695.1302s
	iters: 200, epoch: 9 | loss: 3.4297886
	speed: 0.1264s/iter; left time: 2811.7705s
Epoch: 9 cost time: 30.32509422302246
Epoch: 9, Steps: 244 Train Loss: 3.4146 (Forecasting Loss:0.3788 + XiCon Loss:3.0358 x Lambda(1.0)), Vali MSE Loss: 0.4109 Test MSE Loss: 0.3238
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4405410
	speed: 0.1280s/iter; left time: 2830.2241s
	iters: 200, epoch: 10 | loss: 3.4145322
	speed: 0.1223s/iter; left time: 2691.6925s
Epoch: 10 cost time: 30.68805503845215
Epoch: 10, Steps: 244 Train Loss: 3.4178 (Forecasting Loss:0.3786 + XiCon Loss:3.0392 x Lambda(1.0)), Vali MSE Loss: 0.4105 Test MSE Loss: 0.3235
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4502847
	speed: 0.1292s/iter; left time: 2823.7206s
	iters: 200, epoch: 11 | loss: 3.4661036
	speed: 0.1230s/iter; left time: 2677.1693s
Epoch: 11 cost time: 30.614296913146973
Epoch: 11, Steps: 244 Train Loss: 3.4159 (Forecasting Loss:0.3787 + XiCon Loss:3.0371 x Lambda(1.0)), Vali MSE Loss: 0.4106 Test MSE Loss: 0.3235
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4206049
	speed: 0.1305s/iter; left time: 2822.0188s
	iters: 200, epoch: 12 | loss: 3.4287715
	speed: 0.1301s/iter; left time: 2799.6032s
Epoch: 12 cost time: 31.070297241210938
Epoch: 12, Steps: 244 Train Loss: 3.4150 (Forecasting Loss:0.3786 + XiCon Loss:3.0364 x Lambda(1.0)), Vali MSE Loss: 0.4108 Test MSE Loss: 0.3236
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3623731
	speed: 0.1271s/iter; left time: 2716.3558s
	iters: 200, epoch: 13 | loss: 3.4326143
	speed: 0.1278s/iter; left time: 2718.8364s
Epoch: 13 cost time: 31.022902727127075
Epoch: 13, Steps: 244 Train Loss: 3.4161 (Forecasting Loss:0.3789 + XiCon Loss:3.0372 x Lambda(1.0)), Vali MSE Loss: 0.4106 Test MSE Loss: 0.3235
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4387696
	speed: 0.1254s/iter; left time: 2649.5957s
	iters: 200, epoch: 14 | loss: 3.4417894
	speed: 0.1268s/iter; left time: 2667.2611s
Epoch: 14 cost time: 31.02673029899597
Epoch: 14, Steps: 244 Train Loss: 3.4148 (Forecasting Loss:0.3790 + XiCon Loss:3.0358 x Lambda(1.0)), Vali MSE Loss: 0.4105 Test MSE Loss: 0.3235
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4116578
	speed: 0.1224s/iter; left time: 2556.5822s
	iters: 200, epoch: 15 | loss: 3.3914282
	speed: 0.1257s/iter; left time: 2612.6721s
Epoch: 15 cost time: 30.682839393615723
Epoch: 15, Steps: 244 Train Loss: 3.4149 (Forecasting Loss:0.3788 + XiCon Loss:3.0362 x Lambda(1.0)), Vali MSE Loss: 0.4108 Test MSE Loss: 0.3235
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4272814
	speed: 0.1279s/iter; left time: 2640.5110s
	iters: 200, epoch: 16 | loss: 3.4831564
	speed: 0.1188s/iter; left time: 2440.3053s
Epoch: 16 cost time: 30.298646450042725
Epoch: 16, Steps: 244 Train Loss: 3.4191 (Forecasting Loss:0.3784 + XiCon Loss:3.0408 x Lambda(1.0)), Vali MSE Loss: 0.4108 Test MSE Loss: 0.3235
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.3944006
	speed: 0.1297s/iter; left time: 2645.8224s
	iters: 200, epoch: 17 | loss: 3.4014831
	speed: 0.1226s/iter; left time: 2488.8617s
Epoch: 17 cost time: 30.55671787261963
Epoch: 17, Steps: 244 Train Loss: 3.4155 (Forecasting Loss:0.3787 + XiCon Loss:3.0368 x Lambda(1.0)), Vali MSE Loss: 0.4106 Test MSE Loss: 0.3235
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.24810540676116943, mae:0.3982606530189514, mape:0.6507607102394104, mspe:14.25342845916748 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.7724
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6731517
	speed: 0.1014s/iter; left time: 2464.5637s
	iters: 200, epoch: 1 | loss: 3.6413834
	speed: 0.0638s/iter; left time: 1544.3011s
Epoch: 1 cost time: 21.249111890792847
Epoch: 1, Steps: 244 Train Loss: 3.6947 (Forecasting Loss:0.4637 + XiCon Loss:3.2309 x Lambda(1.0)), Vali MSE Loss: 0.4721 Test MSE Loss: 0.3768
Validation loss decreased (inf --> 0.472053).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4164732
	speed: 0.0665s/iter; left time: 1600.9324s
	iters: 200, epoch: 2 | loss: 3.4444938
	speed: 0.1147s/iter; left time: 2747.9961s
Epoch: 2 cost time: 23.16059184074402
Epoch: 2, Steps: 244 Train Loss: 3.4729 (Forecasting Loss:0.3754 + XiCon Loss:3.0975 x Lambda(1.0)), Vali MSE Loss: 0.3847 Test MSE Loss: 0.3048
Validation loss decreased (0.472053 --> 0.384701).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5554559
	speed: 0.1108s/iter; left time: 2638.9042s
	iters: 200, epoch: 3 | loss: 3.5076561
	speed: 0.1060s/iter; left time: 2513.1011s
Epoch: 3 cost time: 26.19611167907715
Epoch: 3, Steps: 244 Train Loss: 3.5270 (Forecasting Loss:0.3559 + XiCon Loss:3.1712 x Lambda(1.0)), Vali MSE Loss: 0.3781 Test MSE Loss: 0.2978
Validation loss decreased (0.384701 --> 0.378100).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5596762
	speed: 0.0626s/iter; left time: 1475.1968s
	iters: 200, epoch: 4 | loss: 3.4066067
	speed: 0.1134s/iter; left time: 2661.5581s
Epoch: 4 cost time: 22.734350442886353
Epoch: 4, Steps: 244 Train Loss: 3.4885 (Forecasting Loss:0.3478 + XiCon Loss:3.1406 x Lambda(1.0)), Vali MSE Loss: 0.3701 Test MSE Loss: 0.2958
Validation loss decreased (0.378100 --> 0.370059).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4512665
	speed: 0.1210s/iter; left time: 2823.1907s
	iters: 200, epoch: 5 | loss: 3.4735007
	speed: 0.1189s/iter; left time: 2761.7409s
Epoch: 5 cost time: 29.1867733001709
Epoch: 5, Steps: 244 Train Loss: 3.4786 (Forecasting Loss:0.3456 + XiCon Loss:3.1330 x Lambda(1.0)), Vali MSE Loss: 0.3696 Test MSE Loss: 0.2951
Validation loss decreased (0.370059 --> 0.369618).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4544961
	speed: 0.0919s/iter; left time: 2120.8152s
	iters: 200, epoch: 6 | loss: 3.4592495
	speed: 0.1191s/iter; left time: 2738.0708s
Epoch: 6 cost time: 26.335336208343506
Epoch: 6, Steps: 244 Train Loss: 3.4771 (Forecasting Loss:0.3448 + XiCon Loss:3.1323 x Lambda(1.0)), Vali MSE Loss: 0.3641 Test MSE Loss: 0.2949
Validation loss decreased (0.369618 --> 0.364073).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4700506
	speed: 0.1164s/iter; left time: 2659.3201s
	iters: 200, epoch: 7 | loss: 3.4763923
	speed: 0.1150s/iter; left time: 2614.8304s
Epoch: 7 cost time: 25.989034414291382
Epoch: 7, Steps: 244 Train Loss: 3.4765 (Forecasting Loss:0.3446 + XiCon Loss:3.1319 x Lambda(1.0)), Vali MSE Loss: 0.3628 Test MSE Loss: 0.2947
Validation loss decreased (0.364073 --> 0.362776).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4440901
	speed: 0.1119s/iter; left time: 2529.2340s
	iters: 200, epoch: 8 | loss: 3.4333146
	speed: 0.1162s/iter; left time: 2614.7112s
Epoch: 8 cost time: 28.02237606048584
Epoch: 8, Steps: 244 Train Loss: 3.4714 (Forecasting Loss:0.3442 + XiCon Loss:3.1272 x Lambda(1.0)), Vali MSE Loss: 0.3635 Test MSE Loss: 0.2948
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5440004
	speed: 0.1178s/iter; left time: 2633.2354s
	iters: 200, epoch: 9 | loss: 3.4227912
	speed: 0.1117s/iter; left time: 2485.8716s
Epoch: 9 cost time: 28.04136872291565
Epoch: 9, Steps: 244 Train Loss: 3.4697 (Forecasting Loss:0.3441 + XiCon Loss:3.1256 x Lambda(1.0)), Vali MSE Loss: 0.3624 Test MSE Loss: 0.2951
Validation loss decreased (0.362776 --> 0.362446).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6141729
	speed: 0.1170s/iter; left time: 2587.0388s
	iters: 200, epoch: 10 | loss: 3.4002459
	speed: 0.1157s/iter; left time: 2546.6688s
Epoch: 10 cost time: 28.29399847984314
Epoch: 10, Steps: 244 Train Loss: 3.4680 (Forecasting Loss:0.3444 + XiCon Loss:3.1236 x Lambda(1.0)), Vali MSE Loss: 0.3627 Test MSE Loss: 0.2949
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5550215
	speed: 0.1140s/iter; left time: 2491.8555s
	iters: 200, epoch: 11 | loss: 3.3846784
	speed: 0.1199s/iter; left time: 2609.7001s
Epoch: 11 cost time: 28.54109239578247
Epoch: 11, Steps: 244 Train Loss: 3.4734 (Forecasting Loss:0.3438 + XiCon Loss:3.1296 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2949
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4047194
	speed: 0.1170s/iter; left time: 2529.9257s
	iters: 200, epoch: 12 | loss: 3.4868228
	speed: 0.1130s/iter; left time: 2431.1772s
Epoch: 12 cost time: 28.425770044326782
Epoch: 12, Steps: 244 Train Loss: 3.4679 (Forecasting Loss:0.3444 + XiCon Loss:3.1235 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2949
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4981127
	speed: 0.1172s/iter; left time: 2504.2829s
	iters: 200, epoch: 13 | loss: 3.4524386
	speed: 0.1191s/iter; left time: 2532.6814s
Epoch: 13 cost time: 28.552618741989136
Epoch: 13, Steps: 244 Train Loss: 3.4714 (Forecasting Loss:0.3443 + XiCon Loss:3.1271 x Lambda(1.0)), Vali MSE Loss: 0.3627 Test MSE Loss: 0.2949
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4957743
	speed: 0.1171s/iter; left time: 2474.4530s
	iters: 200, epoch: 14 | loss: 3.3951211
	speed: 0.1143s/iter; left time: 2402.7107s
Epoch: 14 cost time: 28.183592796325684
Epoch: 14, Steps: 244 Train Loss: 3.4702 (Forecasting Loss:0.3444 + XiCon Loss:3.1258 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2949
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5838490
	speed: 0.1165s/iter; left time: 2433.2292s
	iters: 200, epoch: 15 | loss: 3.5040827
	speed: 0.1116s/iter; left time: 2319.2170s
Epoch: 15 cost time: 27.607044219970703
Epoch: 15, Steps: 244 Train Loss: 3.4716 (Forecasting Loss:0.3444 + XiCon Loss:3.1272 x Lambda(1.0)), Vali MSE Loss: 0.3627 Test MSE Loss: 0.2949
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.5119624
	speed: 0.1196s/iter; left time: 2467.7442s
	iters: 200, epoch: 16 | loss: 3.4029019
	speed: 0.1128s/iter; left time: 2316.1174s
Epoch: 16 cost time: 28.42780351638794
Epoch: 16, Steps: 244 Train Loss: 3.4715 (Forecasting Loss:0.3441 + XiCon Loss:3.1274 x Lambda(1.0)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.2949
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4730787
	speed: 0.1169s/iter; left time: 2385.1048s
	iters: 200, epoch: 17 | loss: 3.4151118
	speed: 0.1156s/iter; left time: 2346.5525s
Epoch: 17 cost time: 28.24737787246704
Epoch: 17, Steps: 244 Train Loss: 3.4688 (Forecasting Loss:0.3440 + XiCon Loss:3.1248 x Lambda(1.0)), Vali MSE Loss: 0.3627 Test MSE Loss: 0.2949
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.3791556
	speed: 0.1177s/iter; left time: 2372.5811s
	iters: 200, epoch: 18 | loss: 3.4821653
	speed: 0.1161s/iter; left time: 2328.9325s
Epoch: 18 cost time: 28.30994153022766
Epoch: 18, Steps: 244 Train Loss: 3.4681 (Forecasting Loss:0.3440 + XiCon Loss:3.1241 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2949
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.5241578
	speed: 0.1225s/iter; left time: 2438.8368s
	iters: 200, epoch: 19 | loss: 3.3620234
	speed: 0.1168s/iter; left time: 2313.1601s
Epoch: 19 cost time: 28.839847803115845
Epoch: 19, Steps: 244 Train Loss: 3.4634 (Forecasting Loss:0.3441 + XiCon Loss:3.1194 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.2949
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.21689647436141968, mae:0.373252809047699, mape:0.6817680597305298, mspe:18.639801025390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.0403
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6726043
	speed: 0.1214s/iter; left time: 2950.7247s
	iters: 200, epoch: 1 | loss: 3.6716952
	speed: 0.1103s/iter; left time: 2669.0480s
Epoch: 1 cost time: 28.18134593963623
Epoch: 1, Steps: 244 Train Loss: 3.6840 (Forecasting Loss:0.4595 + XiCon Loss:3.2245 x Lambda(1.0)), Vali MSE Loss: 0.4566 Test MSE Loss: 0.3588
Validation loss decreased (inf --> 0.456561).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.4249246
	speed: 0.1257s/iter; left time: 3022.9585s
	iters: 200, epoch: 2 | loss: 3.4596825
	speed: 0.1241s/iter; left time: 2973.6256s
Epoch: 2 cost time: 31.48268151283264
Epoch: 2, Steps: 244 Train Loss: 3.4658 (Forecasting Loss:0.3998 + XiCon Loss:3.0660 x Lambda(1.0)), Vali MSE Loss: 0.4227 Test MSE Loss: 0.3305
Validation loss decreased (0.456561 --> 0.422705).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4692278
	speed: 0.1395s/iter; left time: 3320.8761s
	iters: 200, epoch: 3 | loss: 3.5340629
	speed: 0.1503s/iter; left time: 3563.0737s
Epoch: 3 cost time: 35.68529939651489
Epoch: 3, Steps: 244 Train Loss: 3.4882 (Forecasting Loss:0.3906 + XiCon Loss:3.0975 x Lambda(1.0)), Vali MSE Loss: 0.4221 Test MSE Loss: 0.3274
Validation loss decreased (0.422705 --> 0.422102).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5863492
	speed: 0.1529s/iter; left time: 3603.0843s
	iters: 200, epoch: 4 | loss: 3.5456407
	speed: 0.1384s/iter; left time: 3247.9013s
Epoch: 4 cost time: 35.60963582992554
Epoch: 4, Steps: 244 Train Loss: 3.5568 (Forecasting Loss:0.3905 + XiCon Loss:3.1663 x Lambda(1.0)), Vali MSE Loss: 0.4242 Test MSE Loss: 0.3317
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6425126
	speed: 0.1496s/iter; left time: 3490.3023s
	iters: 200, epoch: 5 | loss: 3.5236132
	speed: 0.1449s/iter; left time: 3364.3750s
Epoch: 5 cost time: 35.66221237182617
Epoch: 5, Steps: 244 Train Loss: 3.5784 (Forecasting Loss:0.3905 + XiCon Loss:3.1879 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3266
Validation loss decreased (0.422102 --> 0.418777).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5994084
	speed: 0.1452s/iter; left time: 3351.2873s
	iters: 200, epoch: 6 | loss: 3.6157825
	speed: 0.1501s/iter; left time: 3450.3005s
Epoch: 6 cost time: 36.207284927368164
Epoch: 6, Steps: 244 Train Loss: 3.5860 (Forecasting Loss:0.3901 + XiCon Loss:3.1959 x Lambda(1.0)), Vali MSE Loss: 0.4192 Test MSE Loss: 0.3273
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4701979
	speed: 0.1425s/iter; left time: 3253.1495s
	iters: 200, epoch: 7 | loss: 3.6037512
	speed: 0.1474s/iter; left time: 3351.6424s
Epoch: 7 cost time: 35.62171912193298
Epoch: 7, Steps: 244 Train Loss: 3.5870 (Forecasting Loss:0.3897 + XiCon Loss:3.1973 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3262
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5478587
	speed: 0.1455s/iter; left time: 3287.4897s
	iters: 200, epoch: 8 | loss: 3.6064901
	speed: 0.1457s/iter; left time: 3277.0949s
Epoch: 8 cost time: 35.65084934234619
Epoch: 8, Steps: 244 Train Loss: 3.5926 (Forecasting Loss:0.3895 + XiCon Loss:3.2031 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3261
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6187863
	speed: 0.1481s/iter; left time: 3310.5032s
	iters: 200, epoch: 9 | loss: 3.6374998
	speed: 0.1453s/iter; left time: 3232.9257s
Epoch: 9 cost time: 35.73264455795288
Epoch: 9, Steps: 244 Train Loss: 3.5879 (Forecasting Loss:0.3894 + XiCon Loss:3.1986 x Lambda(1.0)), Vali MSE Loss: 0.4186 Test MSE Loss: 0.3262
Validation loss decreased (0.418777 --> 0.418601).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5956230
	speed: 0.1478s/iter; left time: 3266.5854s
	iters: 200, epoch: 10 | loss: 3.6171038
	speed: 0.1435s/iter; left time: 3158.4481s
Epoch: 10 cost time: 35.78366541862488
Epoch: 10, Steps: 244 Train Loss: 3.5940 (Forecasting Loss:0.3894 + XiCon Loss:3.2046 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3261
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5546479
	speed: 0.1450s/iter; left time: 3170.5656s
	iters: 200, epoch: 11 | loss: 3.6512451
	speed: 0.1453s/iter; left time: 3162.2052s
Epoch: 11 cost time: 35.52059864997864
Epoch: 11, Steps: 244 Train Loss: 3.5892 (Forecasting Loss:0.3891 + XiCon Loss:3.2001 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3260
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5688539
	speed: 0.1464s/iter; left time: 3164.3368s
	iters: 200, epoch: 12 | loss: 3.5584884
	speed: 0.1396s/iter; left time: 3003.3815s
Epoch: 12 cost time: 35.26353669166565
Epoch: 12, Steps: 244 Train Loss: 3.5908 (Forecasting Loss:0.3892 + XiCon Loss:3.2015 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6411171
	speed: 0.1517s/iter; left time: 3241.2814s
	iters: 200, epoch: 13 | loss: 3.5494952
	speed: 0.1441s/iter; left time: 3064.3893s
Epoch: 13 cost time: 35.89245557785034
Epoch: 13, Steps: 244 Train Loss: 3.5911 (Forecasting Loss:0.3894 + XiCon Loss:3.2018 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3260
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.7126381
	speed: 0.1459s/iter; left time: 3083.5056s
	iters: 200, epoch: 14 | loss: 3.5910394
	speed: 0.1459s/iter; left time: 3067.8062s
Epoch: 14 cost time: 35.71541166305542
Epoch: 14, Steps: 244 Train Loss: 3.5971 (Forecasting Loss:0.3892 + XiCon Loss:3.2079 x Lambda(1.0)), Vali MSE Loss: 0.4191 Test MSE Loss: 0.3260
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5674143
	speed: 0.1457s/iter; left time: 3043.3253s
	iters: 200, epoch: 15 | loss: 3.6067395
	speed: 0.1443s/iter; left time: 2999.2302s
Epoch: 15 cost time: 35.50881624221802
Epoch: 15, Steps: 244 Train Loss: 3.5926 (Forecasting Loss:0.3893 + XiCon Loss:3.2032 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3260
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.5971961
	speed: 0.1467s/iter; left time: 3028.4573s
	iters: 200, epoch: 16 | loss: 3.5360813
	speed: 0.1290s/iter; left time: 2649.5594s
Epoch: 16 cost time: 33.35544562339783
Epoch: 16, Steps: 244 Train Loss: 3.5914 (Forecasting Loss:0.3891 + XiCon Loss:3.2022 x Lambda(1.0)), Vali MSE Loss: 0.4190 Test MSE Loss: 0.3260
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5700746
	speed: 0.1060s/iter; left time: 2161.2974s
	iters: 200, epoch: 17 | loss: 3.5587449
	speed: 0.1491s/iter; left time: 3026.2820s
Epoch: 17 cost time: 31.967811584472656
Epoch: 17, Steps: 244 Train Loss: 3.5932 (Forecasting Loss:0.3895 + XiCon Loss:3.2038 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3260
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6666965
	speed: 0.1458s/iter; left time: 2939.0484s
	iters: 200, epoch: 18 | loss: 3.6251829
	speed: 0.1233s/iter; left time: 2471.5589s
Epoch: 18 cost time: 30.423915147781372
Epoch: 18, Steps: 244 Train Loss: 3.5923 (Forecasting Loss:0.3894 + XiCon Loss:3.2028 x Lambda(1.0)), Vali MSE Loss: 0.4185 Test MSE Loss: 0.3260
Validation loss decreased (0.418601 --> 0.418521).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6708803
	speed: 0.1499s/iter; left time: 2983.3992s
	iters: 200, epoch: 19 | loss: 3.6043177
	speed: 0.1525s/iter; left time: 3020.0461s
Epoch: 19 cost time: 36.75659489631653
Epoch: 19, Steps: 244 Train Loss: 3.5928 (Forecasting Loss:0.3894 + XiCon Loss:3.2033 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6044528
	speed: 0.1128s/iter; left time: 2218.1884s
	iters: 200, epoch: 20 | loss: 3.5843954
	speed: 0.1318s/iter; left time: 2579.3892s
Epoch: 20 cost time: 31.1634738445282
Epoch: 20, Steps: 244 Train Loss: 3.5891 (Forecasting Loss:0.3894 + XiCon Loss:3.1997 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3260
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6272278
	speed: 0.1536s/iter; left time: 2982.6139s
	iters: 200, epoch: 21 | loss: 3.5755529
	speed: 0.1448s/iter; left time: 2796.8919s
Epoch: 21 cost time: 33.8594126701355
Epoch: 21, Steps: 244 Train Loss: 3.5888 (Forecasting Loss:0.3896 + XiCon Loss:3.1992 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3260
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.6632915
	speed: 0.1227s/iter; left time: 2353.0701s
	iters: 200, epoch: 22 | loss: 3.5860617
	speed: 0.1472s/iter; left time: 2808.2871s
Epoch: 22 cost time: 33.476444482803345
Epoch: 22, Steps: 244 Train Loss: 3.5891 (Forecasting Loss:0.3895 + XiCon Loss:3.1996 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3260
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.5850313
	speed: 0.1485s/iter; left time: 2811.6954s
	iters: 200, epoch: 23 | loss: 3.5767424
	speed: 0.1468s/iter; left time: 2764.8570s
Epoch: 23 cost time: 36.15595817565918
Epoch: 23, Steps: 244 Train Loss: 3.5894 (Forecasting Loss:0.3893 + XiCon Loss:3.2001 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3260
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.6139772
	speed: 0.1499s/iter; left time: 2801.3248s
	iters: 200, epoch: 24 | loss: 3.5066757
	speed: 0.1468s/iter; left time: 2729.7013s
Epoch: 24 cost time: 36.03398060798645
Epoch: 24, Steps: 244 Train Loss: 3.5918 (Forecasting Loss:0.3894 + XiCon Loss:3.2024 x Lambda(1.0)), Vali MSE Loss: 0.4184 Test MSE Loss: 0.3260
Validation loss decreased (0.418521 --> 0.418444).  Saving model ...
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.6264524
	speed: 0.1495s/iter; left time: 2756.7059s
	iters: 200, epoch: 25 | loss: 3.5758886
	speed: 0.1425s/iter; left time: 2614.9741s
Epoch: 25 cost time: 35.722983837127686
Epoch: 25, Steps: 244 Train Loss: 3.5966 (Forecasting Loss:0.3893 + XiCon Loss:3.2073 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.6349978
	speed: 0.1470s/iter; left time: 2676.1414s
	iters: 200, epoch: 26 | loss: 3.6074488
	speed: 0.1477s/iter; left time: 2672.6356s
Epoch: 26 cost time: 35.918368339538574
Epoch: 26, Steps: 244 Train Loss: 3.5884 (Forecasting Loss:0.3893 + XiCon Loss:3.1992 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.6182225
	speed: 0.1383s/iter; left time: 2484.0356s
	iters: 200, epoch: 27 | loss: 3.7090814
	speed: 0.1477s/iter; left time: 2637.5712s
Epoch: 27 cost time: 35.094762325286865
Epoch: 27, Steps: 244 Train Loss: 3.5915 (Forecasting Loss:0.3893 + XiCon Loss:3.2022 x Lambda(1.0)), Vali MSE Loss: 0.4190 Test MSE Loss: 0.3260
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.5193889
	speed: 0.1486s/iter; left time: 2632.3593s
	iters: 200, epoch: 28 | loss: 3.5583339
	speed: 0.1323s/iter; left time: 2330.0568s
Epoch: 28 cost time: 34.57789587974548
Epoch: 28, Steps: 244 Train Loss: 3.5872 (Forecasting Loss:0.3892 + XiCon Loss:3.1980 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.6332088
	speed: 0.1466s/iter; left time: 2560.3357s
	iters: 200, epoch: 29 | loss: 3.7210302
	speed: 0.1468s/iter; left time: 2549.9436s
Epoch: 29 cost time: 35.51709985733032
Epoch: 29, Steps: 244 Train Loss: 3.5953 (Forecasting Loss:0.3893 + XiCon Loss:3.2060 x Lambda(1.0)), Vali MSE Loss: 0.4189 Test MSE Loss: 0.3260
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.5824988
	speed: 0.1440s/iter; left time: 2480.0728s
	iters: 200, epoch: 30 | loss: 3.5668375
	speed: 0.1476s/iter; left time: 2527.0662s
Epoch: 30 cost time: 35.90859770774841
Epoch: 30, Steps: 244 Train Loss: 3.5957 (Forecasting Loss:0.3894 + XiCon Loss:3.2063 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.6630180
	speed: 0.1401s/iter; left time: 2379.6192s
	iters: 200, epoch: 31 | loss: 3.6081104
	speed: 0.1475s/iter; left time: 2490.2950s
Epoch: 31 cost time: 35.357778787612915
Epoch: 31, Steps: 244 Train Loss: 3.5979 (Forecasting Loss:0.3894 + XiCon Loss:3.2086 x Lambda(1.0)), Vali MSE Loss: 0.4186 Test MSE Loss: 0.3260
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.5307784
	speed: 0.1474s/iter; left time: 2467.4360s
	iters: 200, epoch: 32 | loss: 3.5877900
	speed: 0.1368s/iter; left time: 2276.2214s
Epoch: 32 cost time: 34.71724081039429
Epoch: 32, Steps: 244 Train Loss: 3.5929 (Forecasting Loss:0.3893 + XiCon Loss:3.2036 x Lambda(1.0)), Vali MSE Loss: 0.4186 Test MSE Loss: 0.3260
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.5170996
	speed: 0.1481s/iter; left time: 2442.1907s
	iters: 200, epoch: 33 | loss: 3.5746570
	speed: 0.1443s/iter; left time: 2365.5405s
Epoch: 33 cost time: 35.35929799079895
Epoch: 33, Steps: 244 Train Loss: 3.5908 (Forecasting Loss:0.3894 + XiCon Loss:3.2014 x Lambda(1.0)), Vali MSE Loss: 0.4188 Test MSE Loss: 0.3260
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 3.6875811
	speed: 0.1479s/iter; left time: 2402.8734s
	iters: 200, epoch: 34 | loss: 3.6717577
	speed: 0.1452s/iter; left time: 2345.3669s
Epoch: 34 cost time: 35.835758447647095
Epoch: 34, Steps: 244 Train Loss: 3.5956 (Forecasting Loss:0.3896 + XiCon Loss:3.2060 x Lambda(1.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3260
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.25014498829841614, mae:0.40194469690322876, mape:0.6563175916671753, mspe:14.27832317352295 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2298+-0.02372, MAE:0.3839+-0.02001, MAPE:0.6774+-0.03574, MSPE:17.3166+-3.66514, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.9674
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8423649
	speed: 0.2219s/iter; left time: 5149.1667s
	iters: 200, epoch: 1 | loss: 0.8687321
	speed: 0.2218s/iter; left time: 5124.7109s
Epoch: 1 cost time: 52.31406378746033
Epoch: 1, Steps: 233 Train Loss: 0.8698 (Forecasting Loss:0.5456 + XiCon Loss:3.2416 x Lambda(0.1)), Vali MSE Loss: 0.4972 Test MSE Loss: 0.3890
Validation loss decreased (inf --> 0.497225).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7039037
	speed: 0.2315s/iter; left time: 5316.2614s
	iters: 200, epoch: 2 | loss: 0.6902976
	speed: 0.2308s/iter; left time: 5276.9101s
Epoch: 2 cost time: 53.80353569984436
Epoch: 2, Steps: 233 Train Loss: 0.7153 (Forecasting Loss:0.3959 + XiCon Loss:3.1939 x Lambda(0.1)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.3450
Validation loss decreased (0.497225 --> 0.377320).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6932169
	speed: 0.2279s/iter; left time: 5181.5565s
	iters: 200, epoch: 3 | loss: 0.6862803
	speed: 0.2292s/iter; left time: 5187.1629s
Epoch: 3 cost time: 53.32666063308716
Epoch: 3, Steps: 233 Train Loss: 0.6902 (Forecasting Loss:0.3756 + XiCon Loss:3.1465 x Lambda(0.1)), Vali MSE Loss: 0.3780 Test MSE Loss: 0.3375
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6720697
	speed: 0.2233s/iter; left time: 5024.9009s
	iters: 200, epoch: 4 | loss: 0.6630957
	speed: 0.2268s/iter; left time: 5080.8959s
Epoch: 4 cost time: 52.661067485809326
Epoch: 4, Steps: 233 Train Loss: 0.6818 (Forecasting Loss:0.3690 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.3746 Test MSE Loss: 0.3247
Validation loss decreased (0.377320 --> 0.374583).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6926442
	speed: 0.2261s/iter; left time: 5033.9850s
	iters: 200, epoch: 5 | loss: 0.6805869
	speed: 0.2311s/iter; left time: 5123.0255s
Epoch: 5 cost time: 53.24410796165466
Epoch: 5, Steps: 233 Train Loss: 0.6775 (Forecasting Loss:0.3657 + XiCon Loss:3.1174 x Lambda(0.1)), Vali MSE Loss: 0.3717 Test MSE Loss: 0.3199
Validation loss decreased (0.374583 --> 0.371707).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6728380
	speed: 0.2238s/iter; left time: 4931.5846s
	iters: 200, epoch: 6 | loss: 0.6831274
	speed: 0.2155s/iter; left time: 4726.6148s
Epoch: 6 cost time: 51.20616340637207
Epoch: 6, Steps: 233 Train Loss: 0.6748 (Forecasting Loss:0.3636 + XiCon Loss:3.1124 x Lambda(0.1)), Vali MSE Loss: 0.3742 Test MSE Loss: 0.3227
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6764374
	speed: 0.2241s/iter; left time: 4885.3821s
	iters: 200, epoch: 7 | loss: 0.6863519
	speed: 0.2282s/iter; left time: 4953.0940s
Epoch: 7 cost time: 52.7114520072937
Epoch: 7, Steps: 233 Train Loss: 0.6735 (Forecasting Loss:0.3624 + XiCon Loss:3.1106 x Lambda(0.1)), Vali MSE Loss: 0.3717 Test MSE Loss: 0.3213
Validation loss decreased (0.371707 --> 0.371666).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6620796
	speed: 0.2287s/iter; left time: 4932.7448s
	iters: 200, epoch: 8 | loss: 0.6562766
	speed: 0.2215s/iter; left time: 4756.5887s
Epoch: 8 cost time: 53.17798972129822
Epoch: 8, Steps: 233 Train Loss: 0.6733 (Forecasting Loss:0.3620 + XiCon Loss:3.1126 x Lambda(0.1)), Vali MSE Loss: 0.3710 Test MSE Loss: 0.3216
Validation loss decreased (0.371666 --> 0.371042).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6620027
	speed: 0.2221s/iter; left time: 4738.4761s
	iters: 200, epoch: 9 | loss: 0.6737771
	speed: 0.2251s/iter; left time: 4781.2756s
Epoch: 9 cost time: 52.332980155944824
Epoch: 9, Steps: 233 Train Loss: 0.6724 (Forecasting Loss:0.3616 + XiCon Loss:3.1074 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3212
Validation loss decreased (0.371042 --> 0.369021).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6871685
	speed: 0.2046s/iter; left time: 4317.1048s
	iters: 200, epoch: 10 | loss: 0.6802483
	speed: 0.1790s/iter; left time: 3760.4530s
Epoch: 10 cost time: 45.43104815483093
Epoch: 10, Steps: 233 Train Loss: 0.6724 (Forecasting Loss:0.3614 + XiCon Loss:3.1097 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3212
Validation loss decreased (0.369021 --> 0.369018).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6738597
	speed: 0.2233s/iter; left time: 4660.4419s
	iters: 200, epoch: 11 | loss: 0.6607299
	speed: 0.1776s/iter; left time: 3689.4445s
Epoch: 11 cost time: 47.7837278842926
Epoch: 11, Steps: 233 Train Loss: 0.6723 (Forecasting Loss:0.3614 + XiCon Loss:3.1091 x Lambda(0.1)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.3211
Validation loss decreased (0.369018 --> 0.368871).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6801949
	speed: 0.2239s/iter; left time: 4620.9394s
	iters: 200, epoch: 12 | loss: 0.6630359
	speed: 0.1987s/iter; left time: 4081.2573s
Epoch: 12 cost time: 47.40636610984802
Epoch: 12, Steps: 233 Train Loss: 0.6720 (Forecasting Loss:0.3613 + XiCon Loss:3.1072 x Lambda(0.1)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.3212
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6379532
	speed: 0.2189s/iter; left time: 4465.7729s
	iters: 200, epoch: 13 | loss: 0.6737800
	speed: 0.2272s/iter; left time: 4613.5076s
Epoch: 13 cost time: 50.776310443878174
Epoch: 13, Steps: 233 Train Loss: 0.6720 (Forecasting Loss:0.3614 + XiCon Loss:3.1061 x Lambda(0.1)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.3212
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6810715
	speed: 0.2208s/iter; left time: 4454.1485s
	iters: 200, epoch: 14 | loss: 0.6671317
	speed: 0.2228s/iter; left time: 4471.6874s
Epoch: 14 cost time: 51.27365517616272
Epoch: 14, Steps: 233 Train Loss: 0.6723 (Forecasting Loss:0.3615 + XiCon Loss:3.1081 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3211
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6767925
	speed: 0.2226s/iter; left time: 4438.1970s
	iters: 200, epoch: 15 | loss: 0.6687428
	speed: 0.2154s/iter; left time: 4273.6923s
Epoch: 15 cost time: 51.28015446662903
Epoch: 15, Steps: 233 Train Loss: 0.6722 (Forecasting Loss:0.3615 + XiCon Loss:3.1068 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3211
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6770458
	speed: 0.2259s/iter; left time: 4452.3202s
	iters: 200, epoch: 16 | loss: 0.6649568
	speed: 0.2235s/iter; left time: 4382.6011s
Epoch: 16 cost time: 52.20310926437378
Epoch: 16, Steps: 233 Train Loss: 0.6724 (Forecasting Loss:0.3614 + XiCon Loss:3.1094 x Lambda(0.1)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.3211
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6912121
	speed: 0.2207s/iter; left time: 4297.5936s
	iters: 200, epoch: 17 | loss: 0.6961321
	speed: 0.2182s/iter; left time: 4226.2643s
Epoch: 17 cost time: 51.14862060546875
Epoch: 17, Steps: 233 Train Loss: 0.6722 (Forecasting Loss:0.3613 + XiCon Loss:3.1092 x Lambda(0.1)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.3211
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6654688
	speed: 0.2192s/iter; left time: 4216.5969s
	iters: 200, epoch: 18 | loss: 0.6576974
	speed: 0.2146s/iter; left time: 4108.2009s
Epoch: 18 cost time: 50.94412326812744
Epoch: 18, Steps: 233 Train Loss: 0.6719 (Forecasting Loss:0.3613 + XiCon Loss:3.1062 x Lambda(0.1)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.3211
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.6916589
	speed: 0.2229s/iter; left time: 4236.3674s
	iters: 200, epoch: 19 | loss: 0.6742268
	speed: 0.2209s/iter; left time: 4176.5959s
Epoch: 19 cost time: 52.00797653198242
Epoch: 19, Steps: 233 Train Loss: 0.6722 (Forecasting Loss:0.3613 + XiCon Loss:3.1086 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3211
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6722974
	speed: 0.2271s/iter; left time: 4263.8401s
	iters: 200, epoch: 20 | loss: 0.6730444
	speed: 0.2144s/iter; left time: 4003.9418s
Epoch: 20 cost time: 52.05560874938965
Epoch: 20, Steps: 233 Train Loss: 0.6720 (Forecasting Loss:0.3614 + XiCon Loss:3.1063 x Lambda(0.1)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.3211
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6656440
	speed: 0.2215s/iter; left time: 4107.6204s
	iters: 200, epoch: 21 | loss: 0.6501181
	speed: 0.2248s/iter; left time: 4146.2409s
Epoch: 21 cost time: 52.12695670127869
Epoch: 21, Steps: 233 Train Loss: 0.6722 (Forecasting Loss:0.3614 + XiCon Loss:3.1072 x Lambda(0.1)), Vali MSE Loss: 0.3690 Test MSE Loss: 0.3211
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.25105947256088257, mae:0.3912217617034912, mape:0.6857401132583618, mspe:19.057905197143555 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.6564
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8893179
	speed: 0.2146s/iter; left time: 4978.2947s
	iters: 200, epoch: 1 | loss: 0.8292211
	speed: 0.2176s/iter; left time: 5027.8044s
Epoch: 1 cost time: 50.67441773414612
Epoch: 1, Steps: 233 Train Loss: 0.8745 (Forecasting Loss:0.5509 + XiCon Loss:3.2365 x Lambda(0.1)), Vali MSE Loss: 0.5001 Test MSE Loss: 0.4023
Validation loss decreased (inf --> 0.500099).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7216070
	speed: 0.2214s/iter; left time: 5085.0298s
	iters: 200, epoch: 2 | loss: 0.6854852
	speed: 0.2092s/iter; left time: 4783.1586s
Epoch: 2 cost time: 50.21704697608948
Epoch: 2, Steps: 233 Train Loss: 0.7156 (Forecasting Loss:0.4013 + XiCon Loss:3.1423 x Lambda(0.1)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3196
Validation loss decreased (0.500099 --> 0.370363).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6791823
	speed: 0.2200s/iter; left time: 5000.8599s
	iters: 200, epoch: 3 | loss: 0.6695133
	speed: 0.2113s/iter; left time: 4782.5679s
Epoch: 3 cost time: 50.5929753780365
Epoch: 3, Steps: 233 Train Loss: 0.6717 (Forecasting Loss:0.3656 + XiCon Loss:3.0604 x Lambda(0.1)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.3114
Validation loss decreased (0.370363 --> 0.352020).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6566049
	speed: 0.2171s/iter; left time: 4884.8697s
	iters: 200, epoch: 4 | loss: 0.6429912
	speed: 0.2186s/iter; left time: 4897.8124s
Epoch: 4 cost time: 51.01644587516785
Epoch: 4, Steps: 233 Train Loss: 0.6543 (Forecasting Loss:0.3440 + XiCon Loss:3.1034 x Lambda(0.1)), Vali MSE Loss: 0.3263 Test MSE Loss: 0.3123
Validation loss decreased (0.352020 --> 0.326341).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6598787
	speed: 0.2163s/iter; left time: 4817.6790s
	iters: 200, epoch: 5 | loss: 0.6641887
	speed: 0.2148s/iter; left time: 4760.9034s
Epoch: 5 cost time: 50.477951765060425
Epoch: 5, Steps: 233 Train Loss: 0.6462 (Forecasting Loss:0.3337 + XiCon Loss:3.1253 x Lambda(0.1)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.3346
Validation loss decreased (0.326341 --> 0.324734).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6334432
	speed: 0.2189s/iter; left time: 4823.8536s
	iters: 200, epoch: 6 | loss: 0.6452819
	speed: 0.2141s/iter; left time: 4695.6086s
Epoch: 6 cost time: 50.35754108428955
Epoch: 6, Steps: 233 Train Loss: 0.6442 (Forecasting Loss:0.3310 + XiCon Loss:3.1313 x Lambda(0.1)), Vali MSE Loss: 0.3255 Test MSE Loss: 0.3179
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6387421
	speed: 0.2169s/iter; left time: 4729.3714s
	iters: 200, epoch: 7 | loss: 0.6453477
	speed: 0.2153s/iter; left time: 4672.4029s
Epoch: 7 cost time: 50.83290648460388
Epoch: 7, Steps: 233 Train Loss: 0.6429 (Forecasting Loss:0.3297 + XiCon Loss:3.1325 x Lambda(0.1)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.3206
Validation loss decreased (0.324734 --> 0.322157).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6472291
	speed: 0.2146s/iter; left time: 4629.4096s
	iters: 200, epoch: 8 | loss: 0.6446536
	speed: 0.2138s/iter; left time: 4591.1784s
Epoch: 8 cost time: 50.095463037490845
Epoch: 8, Steps: 233 Train Loss: 0.6422 (Forecasting Loss:0.3289 + XiCon Loss:3.1322 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3204
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6452272
	speed: 0.2218s/iter; left time: 4732.4995s
	iters: 200, epoch: 9 | loss: 0.6462451
	speed: 0.2104s/iter; left time: 4468.4480s
Epoch: 9 cost time: 50.34904861450195
Epoch: 9, Steps: 233 Train Loss: 0.6424 (Forecasting Loss:0.3289 + XiCon Loss:3.1349 x Lambda(0.1)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.3215
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6416458
	speed: 0.2212s/iter; left time: 4668.2482s
	iters: 200, epoch: 10 | loss: 0.6235478
	speed: 0.2119s/iter; left time: 4450.8710s
Epoch: 10 cost time: 50.685200214385986
Epoch: 10, Steps: 233 Train Loss: 0.6423 (Forecasting Loss:0.3289 + XiCon Loss:3.1342 x Lambda(0.1)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.3188
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6204302
	speed: 0.2211s/iter; left time: 4615.6061s
	iters: 200, epoch: 11 | loss: 0.6472281
	speed: 0.2174s/iter; left time: 4515.7432s
Epoch: 11 cost time: 51.39549899101257
Epoch: 11, Steps: 233 Train Loss: 0.6421 (Forecasting Loss:0.3287 + XiCon Loss:3.1340 x Lambda(0.1)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.3202
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6541771
	speed: 0.1968s/iter; left time: 4062.0213s
	iters: 200, epoch: 12 | loss: 0.6636674
	speed: 0.1555s/iter; left time: 3192.9690s
Epoch: 12 cost time: 42.45034956932068
Epoch: 12, Steps: 233 Train Loss: 0.6422 (Forecasting Loss:0.3288 + XiCon Loss:3.1335 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3201
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6521795
	speed: 0.2121s/iter; left time: 4327.2331s
	iters: 200, epoch: 13 | loss: 0.6572750
	speed: 0.2099s/iter; left time: 4261.4073s
Epoch: 13 cost time: 46.37708377838135
Epoch: 13, Steps: 233 Train Loss: 0.6425 (Forecasting Loss:0.3289 + XiCon Loss:3.1357 x Lambda(0.1)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.3199
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6483290
	speed: 0.2223s/iter; left time: 4483.3009s
	iters: 200, epoch: 14 | loss: 0.6397638
	speed: 0.2195s/iter; left time: 4405.3652s
Epoch: 14 cost time: 51.60582160949707
Epoch: 14, Steps: 233 Train Loss: 0.6419 (Forecasting Loss:0.3286 + XiCon Loss:3.1330 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3200
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6273566
	speed: 0.1615s/iter; left time: 3220.1989s
	iters: 200, epoch: 15 | loss: 0.6253044
	speed: 0.2211s/iter; left time: 4385.4161s
Epoch: 15 cost time: 45.77597427368164
Epoch: 15, Steps: 233 Train Loss: 0.6420 (Forecasting Loss:0.3287 + XiCon Loss:3.1326 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3200
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6518814
	speed: 0.1775s/iter; left time: 3497.9494s
	iters: 200, epoch: 16 | loss: 0.6465601
	speed: 0.2005s/iter; left time: 3931.6764s
Epoch: 16 cost time: 44.79593062400818
Epoch: 16, Steps: 233 Train Loss: 0.6423 (Forecasting Loss:0.3287 + XiCon Loss:3.1354 x Lambda(0.1)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.3200
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6370306
	speed: 0.2245s/iter; left time: 4371.6223s
	iters: 200, epoch: 17 | loss: 0.6418886
	speed: 0.2178s/iter; left time: 4220.1284s
Epoch: 17 cost time: 51.847848415374756
Epoch: 17, Steps: 233 Train Loss: 0.6422 (Forecasting Loss:0.3289 + XiCon Loss:3.1331 x Lambda(0.1)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.3200
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2422003597021103, mae:0.3990210294723511, mape:0.6143190264701843, mspe:12.766491889953613 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.9293
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8613019
	speed: 0.2149s/iter; left time: 4985.3806s
	iters: 200, epoch: 1 | loss: 0.8725271
	speed: 0.2149s/iter; left time: 4964.5423s
Epoch: 1 cost time: 50.029956102371216
Epoch: 1, Steps: 233 Train Loss: 0.8708 (Forecasting Loss:0.5484 + XiCon Loss:3.2238 x Lambda(0.1)), Vali MSE Loss: 0.5259 Test MSE Loss: 0.4336
Validation loss decreased (inf --> 0.525897).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7108831
	speed: 0.2227s/iter; left time: 5114.0954s
	iters: 200, epoch: 2 | loss: 0.6805137
	speed: 0.2155s/iter; left time: 4928.5847s
Epoch: 2 cost time: 51.00479006767273
Epoch: 2, Steps: 233 Train Loss: 0.7174 (Forecasting Loss:0.4016 + XiCon Loss:3.1575 x Lambda(0.1)), Vali MSE Loss: 0.3724 Test MSE Loss: 0.3172
Validation loss decreased (0.525897 --> 0.372409).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6952304
	speed: 0.2130s/iter; left time: 4841.4559s
	iters: 200, epoch: 3 | loss: 0.6670645
	speed: 0.2113s/iter; left time: 4783.2762s
Epoch: 3 cost time: 49.853981256484985
Epoch: 3, Steps: 233 Train Loss: 0.6838 (Forecasting Loss:0.3729 + XiCon Loss:3.1088 x Lambda(0.1)), Vali MSE Loss: 0.3663 Test MSE Loss: 0.3056
Validation loss decreased (0.372409 --> 0.366274).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6395724
	speed: 0.2238s/iter; left time: 5036.0629s
	iters: 200, epoch: 4 | loss: 0.7001662
	speed: 0.2150s/iter; left time: 4816.1344s
Epoch: 4 cost time: 50.80666255950928
Epoch: 4, Steps: 233 Train Loss: 0.6737 (Forecasting Loss:0.3641 + XiCon Loss:3.0957 x Lambda(0.1)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.3043
Validation loss decreased (0.366274 --> 0.353658).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6859132
	speed: 0.2179s/iter; left time: 4853.0282s
	iters: 200, epoch: 5 | loss: 0.6380934
	speed: 0.2153s/iter; left time: 4773.3333s
Epoch: 5 cost time: 50.80526924133301
Epoch: 5, Steps: 233 Train Loss: 0.6656 (Forecasting Loss:0.3569 + XiCon Loss:3.0876 x Lambda(0.1)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.3015
Validation loss decreased (0.353658 --> 0.340360).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.7014304
	speed: 0.2306s/iter; left time: 5080.7667s
	iters: 200, epoch: 6 | loss: 0.6789780
	speed: 0.2153s/iter; left time: 4722.3875s
Epoch: 6 cost time: 52.29033041000366
Epoch: 6, Steps: 233 Train Loss: 0.6604 (Forecasting Loss:0.3517 + XiCon Loss:3.0873 x Lambda(0.1)), Vali MSE Loss: 0.3396 Test MSE Loss: 0.3049
Validation loss decreased (0.340360 --> 0.339634).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6700532
	speed: 0.2194s/iter; left time: 4784.0277s
	iters: 200, epoch: 7 | loss: 0.6593223
	speed: 0.2203s/iter; left time: 4781.8374s
Epoch: 7 cost time: 50.71186137199402
Epoch: 7, Steps: 233 Train Loss: 0.6569 (Forecasting Loss:0.3486 + XiCon Loss:3.0827 x Lambda(0.1)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.3029
Validation loss decreased (0.339634 --> 0.336930).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6409067
	speed: 0.2262s/iter; left time: 4878.7343s
	iters: 200, epoch: 8 | loss: 0.6421546
	speed: 0.2123s/iter; left time: 4557.9224s
Epoch: 8 cost time: 51.37306475639343
Epoch: 8, Steps: 233 Train Loss: 0.6556 (Forecasting Loss:0.3475 + XiCon Loss:3.0815 x Lambda(0.1)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.3045
Validation loss decreased (0.336930 --> 0.336524).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6697612
	speed: 0.2196s/iter; left time: 4685.5397s
	iters: 200, epoch: 9 | loss: 0.6434276
	speed: 0.2227s/iter; left time: 4728.8754s
Epoch: 9 cost time: 51.83105444908142
Epoch: 9, Steps: 233 Train Loss: 0.6552 (Forecasting Loss:0.3472 + XiCon Loss:3.0798 x Lambda(0.1)), Vali MSE Loss: 0.3359 Test MSE Loss: 0.3046
Validation loss decreased (0.336524 --> 0.335906).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6524044
	speed: 0.2230s/iter; left time: 4706.5123s
	iters: 200, epoch: 10 | loss: 0.6694703
	speed: 0.2157s/iter; left time: 4530.0059s
Epoch: 10 cost time: 51.08898973464966
Epoch: 10, Steps: 233 Train Loss: 0.6540 (Forecasting Loss:0.3463 + XiCon Loss:3.0771 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3049
Validation loss decreased (0.335906 --> 0.335518).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6690469
	speed: 0.2173s/iter; left time: 4536.2836s
	iters: 200, epoch: 11 | loss: 0.6563280
	speed: 0.2188s/iter; left time: 4545.3904s
Epoch: 11 cost time: 50.63901424407959
Epoch: 11, Steps: 233 Train Loss: 0.6542 (Forecasting Loss:0.3463 + XiCon Loss:3.0785 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3051
Validation loss decreased (0.335518 --> 0.335475).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6288152
	speed: 0.2168s/iter; left time: 4473.4237s
	iters: 200, epoch: 12 | loss: 0.6776116
	speed: 0.2184s/iter; left time: 4484.8250s
Epoch: 12 cost time: 50.739765882492065
Epoch: 12, Steps: 233 Train Loss: 0.6541 (Forecasting Loss:0.3463 + XiCon Loss:3.0784 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3052
Validation loss decreased (0.335475 --> 0.335441).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6503404
	speed: 0.2133s/iter; left time: 4351.8625s
	iters: 200, epoch: 13 | loss: 0.6506912
	speed: 0.2168s/iter; left time: 4402.8627s
Epoch: 13 cost time: 50.6716787815094
Epoch: 13, Steps: 233 Train Loss: 0.6542 (Forecasting Loss:0.3463 + XiCon Loss:3.0793 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3052
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6683676
	speed: 0.2236s/iter; left time: 4510.3733s
	iters: 200, epoch: 14 | loss: 0.6590443
	speed: 0.2134s/iter; left time: 4284.0925s
Epoch: 14 cost time: 51.30922842025757
Epoch: 14, Steps: 233 Train Loss: 0.6539 (Forecasting Loss:0.3461 + XiCon Loss:3.0785 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3052
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6767657
	speed: 0.2256s/iter; left time: 4498.5819s
	iters: 200, epoch: 15 | loss: 0.6788644
	speed: 0.2177s/iter; left time: 4319.5575s
Epoch: 15 cost time: 51.63317632675171
Epoch: 15, Steps: 233 Train Loss: 0.6541 (Forecasting Loss:0.3462 + XiCon Loss:3.0787 x Lambda(0.1)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.3053
Validation loss decreased (0.335441 --> 0.335203).  Saving model ...
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6552279
	speed: 0.2231s/iter; left time: 4397.2664s
	iters: 200, epoch: 16 | loss: 0.6449448
	speed: 0.2208s/iter; left time: 4328.1922s
Epoch: 16 cost time: 51.91856575012207
Epoch: 16, Steps: 233 Train Loss: 0.6538 (Forecasting Loss:0.3458 + XiCon Loss:3.0804 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6555530
	speed: 0.2135s/iter; left time: 4158.0362s
	iters: 200, epoch: 17 | loss: 0.6517023
	speed: 0.2260s/iter; left time: 4378.8457s
Epoch: 17 cost time: 51.443565130233765
Epoch: 17, Steps: 233 Train Loss: 0.6538 (Forecasting Loss:0.3462 + XiCon Loss:3.0763 x Lambda(0.1)), Vali MSE Loss: 0.3353 Test MSE Loss: 0.3053
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6240388
	speed: 0.2209s/iter; left time: 4251.0772s
	iters: 200, epoch: 18 | loss: 0.6618134
	speed: 0.2229s/iter; left time: 4266.7349s
Epoch: 18 cost time: 51.41222047805786
Epoch: 18, Steps: 233 Train Loss: 0.6540 (Forecasting Loss:0.3460 + XiCon Loss:3.0791 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.6434019
	speed: 0.1978s/iter; left time: 3759.6436s
	iters: 200, epoch: 19 | loss: 0.6402051
	speed: 0.1689s/iter; left time: 3194.1968s
Epoch: 19 cost time: 44.06325364112854
Epoch: 19, Steps: 233 Train Loss: 0.6539 (Forecasting Loss:0.3460 + XiCon Loss:3.0790 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3053
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6744994
	speed: 0.2131s/iter; left time: 4000.7488s
	iters: 200, epoch: 20 | loss: 0.6560245
	speed: 0.1882s/iter; left time: 3514.3284s
Epoch: 20 cost time: 46.06376266479492
Epoch: 20, Steps: 233 Train Loss: 0.6538 (Forecasting Loss:0.3458 + XiCon Loss:3.0802 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6775453
	speed: 0.2148s/iter; left time: 3983.0084s
	iters: 200, epoch: 21 | loss: 0.6714376
	speed: 0.2227s/iter; left time: 4106.9039s
Epoch: 21 cost time: 48.63807797431946
Epoch: 21, Steps: 233 Train Loss: 0.6541 (Forecasting Loss:0.3460 + XiCon Loss:3.0804 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 0.6663121
	speed: 0.2167s/iter; left time: 3966.7199s
	iters: 200, epoch: 22 | loss: 0.6638560
	speed: 0.2085s/iter; left time: 3796.0075s
Epoch: 22 cost time: 49.64073991775513
Epoch: 22, Steps: 233 Train Loss: 0.6539 (Forecasting Loss:0.3459 + XiCon Loss:3.0794 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 0.6634156
	speed: 0.2020s/iter; left time: 3651.5940s
	iters: 200, epoch: 23 | loss: 0.6398468
	speed: 0.2114s/iter; left time: 3800.5341s
Epoch: 23 cost time: 48.49244523048401
Epoch: 23, Steps: 233 Train Loss: 0.6540 (Forecasting Loss:0.3462 + XiCon Loss:3.0779 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 0.6650064
	speed: 0.2191s/iter; left time: 3909.7613s
	iters: 200, epoch: 24 | loss: 0.6730722
	speed: 0.2136s/iter; left time: 3790.4022s
Epoch: 24 cost time: 50.45518183708191
Epoch: 24, Steps: 233 Train Loss: 0.6540 (Forecasting Loss:0.3460 + XiCon Loss:3.0796 x Lambda(0.1)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3053
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 0.6505965
	speed: 0.2116s/iter; left time: 3726.8409s
	iters: 200, epoch: 25 | loss: 0.6318305
	speed: 0.2159s/iter; left time: 3780.6283s
Epoch: 25 cost time: 50.142067670822144
Epoch: 25, Steps: 233 Train Loss: 0.6543 (Forecasting Loss:0.3463 + XiCon Loss:3.0803 x Lambda(0.1)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3053
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.22861862182617188, mae:0.38190534710884094, mape:0.6274954080581665, mspe:14.966448783874512 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.0062
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8263175
	speed: 0.2122s/iter; left time: 4922.6382s
	iters: 200, epoch: 1 | loss: 0.8369840
	speed: 0.2105s/iter; left time: 4861.7065s
Epoch: 1 cost time: 49.5034122467041
Epoch: 1, Steps: 233 Train Loss: 0.8752 (Forecasting Loss:0.5506 + XiCon Loss:3.2461 x Lambda(0.1)), Vali MSE Loss: 0.5321 Test MSE Loss: 0.4415
Validation loss decreased (inf --> 0.532056).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6540315
	speed: 0.2180s/iter; left time: 5007.5017s
	iters: 200, epoch: 2 | loss: 0.6561533
	speed: 0.2433s/iter; left time: 5563.9929s
Epoch: 2 cost time: 55.33037447929382
Epoch: 2, Steps: 233 Train Loss: 0.7030 (Forecasting Loss:0.3846 + XiCon Loss:3.1845 x Lambda(0.1)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.2962
Validation loss decreased (0.532056 --> 0.330388).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6437868
	speed: 0.2725s/iter; left time: 6196.0283s
	iters: 200, epoch: 3 | loss: 0.6515565
	speed: 0.2908s/iter; left time: 6582.0444s
Epoch: 3 cost time: 66.36279487609863
Epoch: 3, Steps: 233 Train Loss: 0.6438 (Forecasting Loss:0.3256 + XiCon Loss:3.1823 x Lambda(0.1)), Vali MSE Loss: 0.3579 Test MSE Loss: 0.2942
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6394929
	speed: 0.3042s/iter; left time: 6845.2759s
	iters: 200, epoch: 4 | loss: 0.6393796
	speed: 0.3094s/iter; left time: 6930.0857s
Epoch: 4 cost time: 71.82948589324951
Epoch: 4, Steps: 233 Train Loss: 0.6365 (Forecasting Loss:0.3181 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.2968
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6237435
	speed: 0.3201s/iter; left time: 7128.6772s
	iters: 200, epoch: 5 | loss: 0.6248423
	speed: 0.3164s/iter; left time: 7014.7801s
Epoch: 5 cost time: 74.42324328422546
Epoch: 5, Steps: 233 Train Loss: 0.6337 (Forecasting Loss:0.3149 + XiCon Loss:3.1882 x Lambda(0.1)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.2988
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6444936
	speed: 0.3166s/iter; left time: 6975.7153s
	iters: 200, epoch: 6 | loss: 0.6234970
	speed: 0.3215s/iter; left time: 7053.4064s
Epoch: 6 cost time: 74.75240540504456
Epoch: 6, Steps: 233 Train Loss: 0.6322 (Forecasting Loss:0.3138 + XiCon Loss:3.1842 x Lambda(0.1)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2994
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6677593
	speed: 0.3202s/iter; left time: 6982.2946s
	iters: 200, epoch: 7 | loss: 0.6078440
	speed: 0.3209s/iter; left time: 6963.7504s
Epoch: 7 cost time: 75.00090670585632
Epoch: 7, Steps: 233 Train Loss: 0.6315 (Forecasting Loss:0.3130 + XiCon Loss:3.1842 x Lambda(0.1)), Vali MSE Loss: 0.3505 Test MSE Loss: 0.2985
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6348532
	speed: 0.3283s/iter; left time: 7081.5619s
	iters: 200, epoch: 8 | loss: 0.6181128
	speed: 0.3212s/iter; left time: 6896.2635s
Epoch: 8 cost time: 75.74189472198486
Epoch: 8, Steps: 233 Train Loss: 0.6313 (Forecasting Loss:0.3127 + XiCon Loss:3.1861 x Lambda(0.1)), Vali MSE Loss: 0.3536 Test MSE Loss: 0.2969
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6140080
	speed: 0.3200s/iter; left time: 6828.1139s
	iters: 200, epoch: 9 | loss: 0.6476721
	speed: 0.3244s/iter; left time: 6889.4519s
Epoch: 9 cost time: 75.18673205375671
Epoch: 9, Steps: 233 Train Loss: 0.6311 (Forecasting Loss:0.3126 + XiCon Loss:3.1853 x Lambda(0.1)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2980
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6323071
	speed: 0.3248s/iter; left time: 6854.4438s
	iters: 200, epoch: 10 | loss: 0.6356969
	speed: 0.3177s/iter; left time: 6673.0116s
Epoch: 10 cost time: 75.11954116821289
Epoch: 10, Steps: 233 Train Loss: 0.6312 (Forecasting Loss:0.3123 + XiCon Loss:3.1885 x Lambda(0.1)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.2978
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6350002
	speed: 0.3169s/iter; left time: 6613.0934s
	iters: 200, epoch: 11 | loss: 0.6439616
	speed: 0.3209s/iter; left time: 6666.1422s
Epoch: 11 cost time: 74.64275908470154
Epoch: 11, Steps: 233 Train Loss: 0.6311 (Forecasting Loss:0.3125 + XiCon Loss:3.1866 x Lambda(0.1)), Vali MSE Loss: 0.3541 Test MSE Loss: 0.2979
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6239864
	speed: 0.3294s/iter; left time: 6798.4140s
	iters: 200, epoch: 12 | loss: 0.6203474
	speed: 0.3178s/iter; left time: 6527.3349s
Epoch: 12 cost time: 75.74804186820984
Epoch: 12, Steps: 233 Train Loss: 0.6308 (Forecasting Loss:0.3123 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.3541 Test MSE Loss: 0.2980
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21752217411994934, mae:0.37489062547683716, mape:0.6331852078437805, mspe:14.824919700622559 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3199
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8768900
	speed: 0.1682s/iter; left time: 3903.5320s
	iters: 200, epoch: 1 | loss: 0.8683852
	speed: 0.1420s/iter; left time: 3280.8220s
Epoch: 1 cost time: 36.76239228248596
Epoch: 1, Steps: 233 Train Loss: 0.8835 (Forecasting Loss:0.5587 + XiCon Loss:3.2477 x Lambda(0.1)), Vali MSE Loss: 0.5594 Test MSE Loss: 0.4754
Validation loss decreased (inf --> 0.559423).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6676812
	speed: 0.1811s/iter; left time: 4159.3478s
	iters: 200, epoch: 2 | loss: 0.6270643
	speed: 0.2010s/iter; left time: 4595.8916s
Epoch: 2 cost time: 44.66916370391846
Epoch: 2, Steps: 233 Train Loss: 0.6911 (Forecasting Loss:0.3770 + XiCon Loss:3.1407 x Lambda(0.1)), Vali MSE Loss: 0.3668 Test MSE Loss: 0.2963
Validation loss decreased (0.559423 --> 0.366818).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6514221
	speed: 0.2135s/iter; left time: 4853.7631s
	iters: 200, epoch: 3 | loss: 0.6278179
	speed: 0.2112s/iter; left time: 4781.1391s
Epoch: 3 cost time: 49.474236249923706
Epoch: 3, Steps: 233 Train Loss: 0.6410 (Forecasting Loss:0.3251 + XiCon Loss:3.1592 x Lambda(0.1)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.3058
Validation loss decreased (0.366818 --> 0.353661).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6311051
	speed: 0.2072s/iter; left time: 4661.8860s
	iters: 200, epoch: 4 | loss: 0.6430406
	speed: 0.2055s/iter; left time: 4602.6712s
Epoch: 4 cost time: 49.0588104724884
Epoch: 4, Steps: 233 Train Loss: 0.6400 (Forecasting Loss:0.3207 + XiCon Loss:3.1937 x Lambda(0.1)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3011
Validation loss decreased (0.353661 --> 0.338499).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6175479
	speed: 0.2141s/iter; left time: 4768.0928s
	iters: 200, epoch: 5 | loss: 0.6608505
	speed: 0.2215s/iter; left time: 4911.1004s
Epoch: 5 cost time: 50.65223264694214
Epoch: 5, Steps: 233 Train Loss: 0.6387 (Forecasting Loss:0.3183 + XiCon Loss:3.2045 x Lambda(0.1)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.3025
Validation loss decreased (0.338499 --> 0.335153).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6152580
	speed: 0.2185s/iter; left time: 4814.7324s
	iters: 200, epoch: 6 | loss: 0.6464914
	speed: 0.2172s/iter; left time: 4764.0899s
Epoch: 6 cost time: 50.991530418395996
Epoch: 6, Steps: 233 Train Loss: 0.6377 (Forecasting Loss:0.3170 + XiCon Loss:3.2065 x Lambda(0.1)), Vali MSE Loss: 0.3343 Test MSE Loss: 0.3031
Validation loss decreased (0.335153 --> 0.334259).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6256992
	speed: 0.2190s/iter; left time: 4774.3765s
	iters: 200, epoch: 7 | loss: 0.6543502
	speed: 0.2235s/iter; left time: 4849.5765s
Epoch: 7 cost time: 51.48548245429993
Epoch: 7, Steps: 233 Train Loss: 0.6367 (Forecasting Loss:0.3163 + XiCon Loss:3.2038 x Lambda(0.1)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.3035
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6685561
	speed: 0.2177s/iter; left time: 4695.5203s
	iters: 200, epoch: 8 | loss: 0.6326705
	speed: 0.2213s/iter; left time: 4751.8700s
Epoch: 8 cost time: 51.59595823287964
Epoch: 8, Steps: 233 Train Loss: 0.6372 (Forecasting Loss:0.3163 + XiCon Loss:3.2090 x Lambda(0.1)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.3038
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6435750
	speed: 0.2173s/iter; left time: 4636.9834s
	iters: 200, epoch: 9 | loss: 0.6311822
	speed: 0.2255s/iter; left time: 4787.9686s
Epoch: 9 cost time: 51.878960609436035
Epoch: 9, Steps: 233 Train Loss: 0.6370 (Forecasting Loss:0.3161 + XiCon Loss:3.2097 x Lambda(0.1)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.3037
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6202865
	speed: 0.2221s/iter; left time: 4687.7261s
	iters: 200, epoch: 10 | loss: 0.6452229
	speed: 0.2197s/iter; left time: 4615.3691s
Epoch: 10 cost time: 51.55583930015564
Epoch: 10, Steps: 233 Train Loss: 0.6373 (Forecasting Loss:0.3159 + XiCon Loss:3.2136 x Lambda(0.1)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.3044
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6466726
	speed: 0.2252s/iter; left time: 4699.1118s
	iters: 200, epoch: 11 | loss: 0.6493909
	speed: 0.2218s/iter; left time: 4606.0229s
Epoch: 11 cost time: 52.09001111984253
Epoch: 11, Steps: 233 Train Loss: 0.6370 (Forecasting Loss:0.3161 + XiCon Loss:3.2088 x Lambda(0.1)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.3036
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6263236
	speed: 0.2263s/iter; left time: 4670.4245s
	iters: 200, epoch: 12 | loss: 0.6578419
	speed: 0.1860s/iter; left time: 3819.2119s
Epoch: 12 cost time: 48.6893150806427
Epoch: 12, Steps: 233 Train Loss: 0.6362 (Forecasting Loss:0.3155 + XiCon Loss:3.2074 x Lambda(0.1)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3035
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6320718
	speed: 0.2264s/iter; left time: 4618.7606s
	iters: 200, epoch: 13 | loss: 0.6206543
	speed: 0.2193s/iter; left time: 4452.7462s
Epoch: 13 cost time: 51.976234912872314
Epoch: 13, Steps: 233 Train Loss: 0.6365 (Forecasting Loss:0.3157 + XiCon Loss:3.2082 x Lambda(0.1)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.3036
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6264437
	speed: 0.2284s/iter; left time: 4607.7963s
	iters: 200, epoch: 14 | loss: 0.6300797
	speed: 0.2224s/iter; left time: 4464.8040s
Epoch: 14 cost time: 52.647197008132935
Epoch: 14, Steps: 233 Train Loss: 0.6366 (Forecasting Loss:0.3158 + XiCon Loss:3.2076 x Lambda(0.1)), Vali MSE Loss: 0.3381 Test MSE Loss: 0.3036
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6611128
	speed: 0.2245s/iter; left time: 4476.0845s
	iters: 200, epoch: 15 | loss: 0.6248291
	speed: 0.2207s/iter; left time: 4379.1931s
Epoch: 15 cost time: 52.26640820503235
Epoch: 15, Steps: 233 Train Loss: 0.6368 (Forecasting Loss:0.3158 + XiCon Loss:3.2094 x Lambda(0.1)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.3036
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6388400
	speed: 0.2281s/iter; left time: 4495.2487s
	iters: 200, epoch: 16 | loss: 0.6461645
	speed: 0.2230s/iter; left time: 4371.2151s
Epoch: 16 cost time: 52.46900248527527
Epoch: 16, Steps: 233 Train Loss: 0.6369 (Forecasting Loss:0.3160 + XiCon Loss:3.2085 x Lambda(0.1)), Vali MSE Loss: 0.3381 Test MSE Loss: 0.3036
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.22567185759544373, mae:0.380511999130249, mape:0.6915158629417419, mspe:17.57642364501953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2330+-0.01670, MAE:0.3855+-0.01188, MAPE:0.6505+-0.04417, MSPE:15.8384+-3.07985, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
